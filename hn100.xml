<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 13 Aug 2025 09:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Online Safety Act – shutdowns and site blocks (195 pts)]]></title>
            <link>https://www.blocked.org.uk/osa-blocks</link>
            <guid>44885295</guid>
            <pubDate>Wed, 13 Aug 2025 06:40:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.blocked.org.uk/osa-blocks">https://www.blocked.org.uk/osa-blocks</a>, See on <a href="https://news.ycombinator.com/item?id=44885295">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h3>Submit a new site</h3>
<p>Tell us about a site that is shutting down or restricting access to UK users as a result of the Online Safety Act</p>

</div><div>


<div>
        <h3>
            <a href="https://www.reddit.com/r/darkjokes/" rel="nofollow">www.reddit.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.reddit.com/r/darkjokes/</small></p>
        <p>Reported: 13 August, 2025 at 07:49</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Jokes of a dark or adult nature.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://jav.guru/" rel="nofollow">jav.guru | Just a moment...</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://jav.guru</small></p>
        <p>Reported: 13 August, 2025 at 07:39</p>
        
        <p>Shut down on: 01 August, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Japanese Adult Video porn website
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://raddle.me/" rel="nofollow">raddle.me | 451 Unavailable For Legal Reasons</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://raddle.me</small></p>
        <p>Reported: 12 August, 2025 at 23:56</p>
        
        <p>Shut down on: 12 August, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Forum / link aggragator. The oldest surviving reddit alternative.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://elajo.itch.io/" rel="nofollow">elajo.itch.io | Ela Maxima - itch.io</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://elajo.itch.io</small></p>
        <p>Reported: 10 August, 2025 at 22:28</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Ela Maxima's itch.io Author page is blocked.
But games can still be accesses by Googling the game pages, even 18+ ones.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://flowgpt.com/" rel="nofollow">flowgpt.com | Attention Required! | Cloudflare</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://flowgpt.com</small></p>
        <p>Reported: 09 August, 2025 at 21:24</p>
        
        <p>Shut down on: 24 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Chat with AI characters for free on FlowGPT! More than 1 million characters and bots to chat with, AI boyfriend, girlfriend, uncencored chat and AI tools.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://irish.session.nz/" rel="nofollow">irish.session.nz</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://irish.session.nz</small></p>
        <p>Reported: 09 August, 2025 at 00:10</p>
        
        <p>Shut down on: 08 August, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Resources for learning Irish music by ear
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://irodoricomics.com/blocked.html" rel="nofollow">irodoricomics.com | Access Blocked – Irodori Comics</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://irodoricomics.com/blocked.html</small></p>
        <p>Reported: 08 August, 2025 at 11:39</p>
        
        <p>Shut down on: 07 August, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            A online manga store that sells independently published manga (doujinshi) into English. Sells all-ages, LGBT and R18 manga, but all are in separate categories and R18 material needed to be paid by credit card, so was blocked to children, even before the UK Block.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://bsky.app/profile/greg.org/post/3lvt3mjvskk2i" rel="nofollow">bsky.app | @greg.org on Bluesky</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://bsky.app/profile/greg.org/post/3lvt3mjvskk2i</small></p>
        <p>Reported: 07 August, 2025 at 19:53</p>
        
        <p>Shut down on: 07 August, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Statue of |david behind age verification filter
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://www.reddit.com/r/jpouch/" rel="nofollow">www.reddit.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.reddit.com/r/jpouch/</small></p>
        <p>Reported: 07 August, 2025 at 15:17</p>
        
        <p>Shut down on: 24 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            reddit discussion about a type of bowel surgery
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://forums.aura-online.co.uk/" rel="nofollow">forums.aura-online.co.uk | Aura Forums - Information</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://forums.aura-online.co.uk</small></p>
        <p>Reported: 06 August, 2025 at 20:48</p>
        
        <p>Shut down on: 19 March, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            An old web forum for a loosely knit community of Final Fantasy fans and others. It ran for 25 years.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="http://forum.guitarbuilderscollective.com/" rel="nofollow">forum.guitarbuilderscollective.com</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>http://forum.guitarbuilderscollective.com</small></p>
        <p>Reported: 06 August, 2025 at 17:33</p>
        
        <p>Shut down on: 01 August, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            A discussion board for fans of building guitars.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://lgbtqia.space/" rel="nofollow">lgbtqia.space | LGBTQIA.Space</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://lgbtqia.space</small></p>
        <p>Reported: 06 August, 2025 at 14:16</p>
        
        <p>Shut down on: 05 August, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            LGBTQIA focused Mastodon instance.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://newsgrouper.org/" rel="nofollow">newsgrouper.org | Httpd_Error: 451</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://newsgrouper.org</small></p>
        <p>Reported: 06 August, 2025 at 14:11</p>
        
        <p>Shut down on: 17 March, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            A web interface to Usenet discussion groups (text only)
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://reddit.com/" rel="nofollow">reddit.com | Reddit - Dive into anything</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://reddit.com</small></p>
        <p>Reported: 06 August, 2025 at 11:26</p>
        
        <p>Shut down on: 21 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Reddit.com; The OSA has made it impossible to do my subreddit moderation work: I need to be able to review a user's profile if they submit a post/comments to any of the subreddits I moderate. Any profile marked as "18+", which DOES NOT imply pornographic content, is now blocked from view when accessing Reddit from the UK. I refuse outright to scan my face into a dodgy third-party site, so I HAVE to use a VPN to continue moderating my (medical professional) subreddits. It's insane.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>





<div>
        <h3>
            <a href="https://www.reddit.com/r/SoccerBetting/" rel="nofollow">www.reddit.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.reddit.com/r/SoccerBetting/</small></p>
        <p>Reported: 06 August, 2025 at 10:45</p>
        
        <p>Shut down on: 28 June, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            A site that provides betting tips
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://welcometoheavenblog.net/" rel="nofollow">welcometoheavenblog.net</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://welcometoheavenblog.net</small></p>
        <p>Reported: 04 August, 2025 at 09:03</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Wholesome 18+ queer webcomics by artist who goes by the name "Welcome to Heaven"
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://microcosm.app/" rel="nofollow">microcosm.app</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://microcosm.app</small></p>
        <p>Reported: 31 July, 2025 at 08:18</p>
        
        <p>Shut down on: 16 March, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            Open Source platform hosting hosting approximately 300 small communities, all of which will either shut down or have to migrate within three months. Announced Dec 2024. Microcosm also hosted LFGSS which you've included in your list. 
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="http://irodoricomics.com/" rel="nofollow">irodoricomics.com | Irodori Comics</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>http://irodoricomics.com</small></p>
        <p>Reported: 29 July, 2025 at 22:29</p>
        
        <p>Shut down on: 29 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Manga and Doujinshi shop
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://www.reddit.com/r/stopsmoking/" rel="nofollow">www.reddit.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.reddit.com/r/stopsmoking/</small></p>
        <p>Reported: 29 July, 2025 at 13:45</p>
        
        <p>Shut down on: 29 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Stop smoking subreddit
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://www.reddit.com/r/AlJazeera/" rel="nofollow">www.reddit.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.reddit.com/r/AlJazeera/</small></p>
        <p>Reported: 29 July, 2025 at 08:54</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Reddit news subreddit, age gated in UK
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://ifarchive.org/" rel="nofollow">ifarchive.org | The Interactive Fiction Archive</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://ifarchive.org</small></p>
        <p>Reported: 29 July, 2025 at 01:17</p>
        
        <p>Shut down on: 28 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            The Interactive Fiction Archive -- 30 years of amateur/free mostly-text games
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://spacehey.com/home" rel="nofollow">spacehey.com | Login | SpaceHey</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://spacehey.com/home</small></p>
        <p>Reported: 27 July, 2025 at 20:09</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Spacehey, a remake of classic MySpace
Completely removed support for UK people(s) due to the OSA and the additional resources that this would require
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://kandipatterns.com/" rel="nofollow">kandipatterns.com | Kandi Patterns: Blocked</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://kandipatterns.com</small></p>
        <p>Reported: 27 July, 2025 at 07:25</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            A website to view and discuss patterns for making kandi (bracelets and other crafts made with pony beads and string). 
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://janitorai.com/" rel="nofollow">janitorai.com | Access Restricted</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://janitorai.com</small></p>
        <p>Reported: 26 July, 2025 at 18:12</p>
        
        <p>Shut down on: 24 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Janitor AI is a chatbot platform where users can create and interact with AI characters for personalized role-playing and conversations. It was launched in 2023 and quickly gained popularity, especially among those interested in engaging with AI in an immersive and emotional way. The platform allows for customisation of character personalities, appearances, and dialogue settings, and supports different Large Language Models (LLMs). 

The site is of 18+ maturity and is only advertised for adults. The website is based outside of the UK.

Janitor ai also has a large creative community akin to fanficton sites like Ao3 or Wattpad. Many people use this site for creative expression and connecting with other users who also enjoy the fandoms and original characters that are created on the site.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>







<div>
        <h3>
            <a href="https://forum.zrythm.org/" rel="nofollow">forum.zrythm.org</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://forum.zrythm.org</small></p>
        <p>Reported: 25 July, 2025 at 22:51</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Discussion forum for users of the zrythm music production software 
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://x.com/BenBarryJones/status/1948830460668158130" rel="nofollow">x.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://x.com/BenBarryJones/status/1948830460668158130</small></p>
        <p>Reported: 25 July, 2025 at 21:31</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Post on social media website X claiming that content relating to protests has been age-gated due to the Online Safety Act.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://clippsly.com/" rel="nofollow">clippsly.com | Clippsly</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://clippsly.com</small></p>
        <p>Reported: 25 July, 2025 at 17:59</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Clippsly - A Roblox music-sharing platform
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>









<div>
        <h3>
            <a href="https://itch.io/" rel="nofollow">itch.io | Download the latest indie games - itch.io</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://itch.io</small></p>
        <p>Reported: 25 July, 2025 at 14:03</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Itch.io blocks certain pages due to the OSA. However, directly accessing the pages allows you to view content anyway. The content may or may not even be "adult".

Example: Pages on itch are organised by domain with the name of an author. The main index at https://elajo.itch.io Gives a message about the OSA. But pages within can be accessed if you already know the exact path name.

        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>





<div>
        <h3>
            <a href="https://pjuu.com/" rel="nofollow">pjuu.com | Pjuu</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://pjuu.com</small></p>
        <p>Reported: 25 July, 2025 at 12:30</p>
        
        <p>Shut down on: 28 February, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            Micro blogging site similar to twitter with a focus on privacy
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://www.renaultevclub.co.uk/" rel="nofollow">www.renaultevclub.co.uk | Renault EV Club | For Renaut Electric Car Drivers</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://www.renaultevclub.co.uk</small></p>
        <p>Reported: 25 July, 2025 at 11:21</p>
        
        <p>Shut down on: 24 May, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            The Place Online for Renault Electric Vehicle Owners &amp; Drivers.

Get the most out of your Renault Electric car by joining a community of people just like you. Launched in January 2022, we're at the start of our journey and we hope you'll come along for the ride.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://www.girlonthenet.com/" rel="nofollow">www.girlonthenet.com | Sexy stories, mostly true | Girl on the Net</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.girlonthenet.com</small></p>
        <p>Reported: 25 July, 2025 at 11:07</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Professional sex blogger, audio porn producer and pervert. Amateur anxious mess.

I write real-life sex stories and occasional horny fiction.

I also ramble about feminism, consent, online dating tips, mental health, the business of sex blogging and other topics that are vaguely adjacent to these things.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://pmvhaven.com/" rel="nofollow">pmvhaven.com</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://pmvhaven.com</small></p>
        <p>Reported: 25 July, 2025 at 06:57</p>
        
        <p>Shut down on: 25 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            "Access Restricted

This website is currently unavailable in the United Kingdom.

Due to regulatory requirements from the UK government related to identity verification and age assurance, we are unable to provide access to this service at this time.

We apologize for the inconvenience and appreciate your understanding."
        </p>
        
    </div>



<div>
        <h3>
            <a href="https://yodayo.com/" rel="nofollow">yodayo.com | Access Restricted - UK</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://yodayo.com</small></p>
        <p>Reported: 24 July, 2025 at 18:07</p>
        
        <p>Shut down on: 24 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Explore AI generated anime art, find best prompts, create beautiful images with our free AI art generator, and share it with other anime fans!
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://www.bitchute.com/" rel="nofollow">www.bitchute.com | Bitchute</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.bitchute.com</small></p>
        <p>Reported: 24 July, 2025 at 17:55</p>
        
        <p>Shut down on: 14 April, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            BitChute is a video service that prioritizes creators and champions users' freedoms and privacy.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://beta.4wall.ai/" rel="nofollow">beta.4wall.ai | 4Wall AI | Chat with AI Characters</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://beta.4wall.ai</small></p>
        <p>Reported: 24 July, 2025 at 17:48</p>
        
        <p>Shut down on: 24 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            4Wall AI is an interactive platform that allows users to engage in unfiltered, real-time conversations with AI-generated characters. Users can create their own AI personas, customize their traits, and immerse themselves in dynamic, story-driven environments.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://isthisyiff.net/" rel="nofollow">isthisyiff.net | Woah There...</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://isthisyiff.net</small></p>
        <p>Reported: 24 July, 2025 at 17:36</p>
        
        <p>Shut down on: 01 May, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            An online game where players guess whether drawn artwork is NSFW or not based on a cropped image.
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>



<div>
        <h3>
            <a href="https://www.noodledude.io/blocked" rel="nofollow">www.noodledude.io | Access Restricted - NoodleDude</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://www.noodledude.io/blocked</small></p>
        <p>Reported: 24 July, 2025 at 14:25</p>
        
        <p>Shut down on: 23 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            Noodle Dude PMV is a pornographic website that creates porn movies put to music. 
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://thisvid.com/" rel="nofollow">thisvid.com | Access blocked</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://thisvid.com</small></p>
        <p>Reported: 23 July, 2025 at 13:11</p>
        
        <p>Shut down on: 22 July, 2025</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            popular pornographic site
        </p>
        <p><span>
                Submitted
            </span>
            
        </p>
    </div>

<div>
        <h3>
            <a href="https://www.redpassion.co.uk/" rel="nofollow">www.redpassion.co.uk | Red Passion</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://www.redpassion.co.uk</small></p>
        <p>Reported: 17 March, 2025 at 13:52</p>
        
        <p>Shut down on: 16 March, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            The No1 Wrexham Association Football Club fansite Red Passion has been online since the mid 90's in various forms, and was the name of a paper fanzine in the 90's and 2010. This site has closed to new user registrations  
        </p>
        
    </div>



<div>
        <h3>
            <a href="https://www.dadswithkids.co.uk/" rel="nofollow">www.dadswithkids.co.uk | Dads with Kids Forum</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://www.dadswithkids.co.uk</small></p>
        <p>Reported: 17 March, 2025 at 13:50</p>
        
        <p>Shut down on: 16 March, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            Community for single Dads and divorcing Dads seeking help with seeing their children after separation
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://forums.hexus.net/" rel="nofollow">forums.hexus.net</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://forums.hexus.net</small></p>
        <p>Reported: 14 March, 2025 at 19:33</p>
        
        <p>Shut down on: 01 March, 2025</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            A computing gaming and general discussion forum, with approximately 310,000 registered users. Some migration to an alternative non UK forum
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://urbandead.com/shutdown.html" rel="nofollow">urbandead.com | Urban Dead is shutting down</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://urbandead.com/shutdown.html</small></p>
        <p>Reported: 10 March, 2025 at 12:23</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            Urban Dead, a massively multi-player web-based zombie apocalypse game, with over 1,500 players active on 2025-03-03
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://www.readytogo.net/smb/threads/" rel="nofollow">www.readytogo.net | There is a problem: | RTG Sunderland Message Boards</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://www.readytogo.net/smb/threads/</small></p>
        <p>Reported: 10 March, 2025 at 12:23</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            https://web.archive.org/web/20250103040011/https://www.readytogo.net/smb/threads/the-end-of-the-forum-is-nigh.1646227/ Ready To Go, a discussion forum about Sunderland AFC, a football club
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://social.treehouse.systems/" rel="nofollow">social.treehouse.systems | Treehouse Mastodon</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://social.treehouse.systems</small></p>
        <p>Reported: 10 March, 2025 at 12:22</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            https://web.archive.org/web/20250104064609/https://social.treehouse.systems/@dee/113662184456889247 Microcosm, a forum-hosting service, reported as having about 275,000 monthly average users, mostly from the UK 
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://lobste.rs/" rel="nofollow">lobste.rs | Lobsters</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://lobste.rs</small></p>
        <p>Reported: 10 March, 2025 at 12:21</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            Lobste.rs, a tech discussion forum with around 2,500 daily active users and more than 110,000 daily readers
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://www.lfgss.com/" rel="nofollow">www.lfgss.com | LFGSS </a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://www.lfgss.com</small></p>
        <p>Reported: 10 March, 2025 at 12:20</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            https://web.archive.org/web/20250109072916/https://www.lfgss.com/conversations/401475/ LFGSS (London Fixed Gear and Single-Speed), a cycling forum
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://lemmy.zip/" rel="nofollow">lemmy.zip | Lemmy.zip and the OSA</a>
        
            <span title="Site is geo-blocking content">
        
        </span></h3>
        <p><small>https://lemmy.zip</small></p>
        <p>Reported: 10 March, 2025 at 12:20</p>
        
        <p>Geoblocking due to OSA</p>
        <p>
            https://web.archive.org/web/20250227173838/https://uk.lemmy.zip/  discussion community focussed on tech, PCs, and gaming, with approximately 260 daily users, and 3,300 total users
        </p>
        
    </div>

<div>
        <h3>
            <a href="https://www.thegreenlivingforum.net/forum/" rel="nofollow">www.thegreenlivingforum.net</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://www.thegreenlivingforum.net/forum/</small></p>
        <p>Reported: 10 March, 2025 at 12:11</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            The Green Living Forum, a discussion board running since 2006, with just under 500,000 posts about sustainable living  https://web.archive.org/web/20250120205725/https://www.thegreenlivingforum.net/forum/viewtopic.php?f=2&amp;t=114519
        </p>
        
    </div>



<div>
        <h3>
            <a href="https://furry.energy/" rel="nofollow">furry.energy | Furry.Energy</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://furry.energy</small></p>
        <p>Reported: 10 March, 2025 at 11:39</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            https://archive.is/vmxXK  UK based Mastodon Server oriented towards those in the furry &amp; LGBTQA+ communities
        </p>
        
    </div>



<div>
        <h3>
            <a href="https://awscommunity.social/" rel="nofollow">awscommunity.social</a>
        
            <span title="Site has shut down">
        
        </span></h3>
        <p><small>https://awscommunity.social</small></p>
        <p>Reported: 10 March, 2025 at 11:35</p>
        
        <p>Shutting down due to OSA</p>
        <p>
            A Mastodon instance for discussing AWS technologies, with approximately 300 users https://web.archive.org/web/20250110144134/https://awscommunity.social/@Ric_/113803857188109600
        </p>
        
    </div>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: F-Droid build servers can't build modern Android apps due to outdated CPUs (162 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44884709</link>
            <guid>44884709</guid>
            <pubDate>Wed, 13 Aug 2025 04:43:39 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44884709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="44885476"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44885476" href="https://news.ycombinator.com/vote?id=44885476&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I don't fully understand: aren't gradle and aapt2 open-source ?</p><p>If you want to build buildroot or openwrt, the first thing it will do is compiling your own toolchain (rather than reusing the one from your distro) so that it can lead to predictable results. I would have the same rationale for f-droid : why not compile the whole toolchain from source rather than using a binary gradle/aapt2 that uses unsupported instructions?</p></div></td></tr></tbody></table></td></tr><tr id="44885007"><td></td></tr><tr id="44885016"><td></td></tr><tr id="44884781"><td></td></tr><tr id="44884851"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884851" href="https://news.ycombinator.com/vote?id=44884851&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>The Catima thread makes FDroid sound like a really difficult commmunity to work with. Although I'm basing this on one person's comment and other people agreeing, not on any knowledge or experience.</p><p>&gt; But this is like everything with F-Droid: everything always falls on a deaf man's ears. So I would rather not waste more time talking to a brick wall. If I had the feeling it was possible to improve F-Droid by raising issues and trying to discuss how to solve them I wouldn't have left the project out of frustration after years of putting so much time and energy into it.</p></div></td></tr></tbody></table></td></tr><tr id="44885456"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885456" href="https://news.ycombinator.com/vote?id=44885456&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>F-droid are thoroughly understaffed and yet incredibly ambitious and shrewd around their goals - they want to build all the apps in a reproducible manner. There’s lots of friction around deviating from builds that fit within their model. The system is also slow, takes a long while before a build shows up. I think f-droid could benefit immensely from more funding, saying that as someone who has never seen f-droid’s side, but have worked on an app that was published there.</p></div></td></tr></tbody></table></td></tr><tr id="44885300"><td></td></tr><tr id="44884865"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44884865" href="https://news.ycombinator.com/vote?id=44884865&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>This is pretty concerning, especially as FDroid is by far the largest non-google android store at the moment, something that I feel is really needed, regardless of your feelings about google.</p><p>Does anyone know of plans to resolve this? Will FDroid update their servers? Are google looking into rolling back the requirement? (this last one sounds unlikely)</p></div></td></tr></tbody></table></td></tr><tr id="44884902"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884902" href="https://news.ycombinator.com/vote?id=44884902&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I agree it’s a bit concerning but please keep in mind F-Droid is a volunteer-run community project. Especially with some EU countries moving to open source software, it would be nice to see some public funding for projects like F-Droid.</p></div></td></tr></tbody></table></td></tr><tr id="44885719"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885719" href="https://news.ycombinator.com/vote?id=44885719&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt; please keep in mind F-Droid is a volunteer-run community project.</p><p>To, me, that's the worrying part.</p><p>Not that it's ran by volunteers. But that all there's left between a full-on "tech monopoly" or hegemony, and a free internet, is small bands of underfunded volunteers.</p><p>Opposition to market dominance and monopolies by multibillion multinationals shouldn't just come from a few volunteers. If that's the case, just roll over and give up; the cause is lost. (As I've done, hence my defaitism)</p><p>Aside from that: it being "a volunteer ran community" shouldn't be put as an excuse for why it's in trouble/has poor UX/is hard to use/is behind/etc. It should be a killer feature. Something that makes it more resilient/better attuned/easier/earlier adopting/etc.</p></div></td></tr></tbody></table></td></tr><tr id="44884927"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44884927" href="https://news.ycombinator.com/vote?id=44884927&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt; Nice to see some public funding for projects like F-Droid</p><p>Definitely, SSE4.1 instruction set based CPU, for building apps in 2025, No way!!</p></div></td></tr></tbody></table></td></tr><tr id="44884931"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44884931" href="https://news.ycombinator.com/vote?id=44884931&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Hope I didn't come across as criticising FDroid here- It seems sucky to have build requirements change under your feet.</p><p>It's just I think that FDroid is an important project, and hope this doesn't block their progress.</p></div></td></tr></tbody></table></td></tr><tr id="44885039"><td></td></tr><tr id="44885226"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885226" href="https://news.ycombinator.com/vote?id=44885226&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I'm not quite sure if I'm over reading into this, but this comes across as a snarky response as if I've said "boo, fdroid sucks and owes me a free app store!".</p><p>Appologies if I came across like that, here's what I'm trying to convey:</p><p>- Fdroid is important</p><p>- This sounds like a problem, not necessarily one that's any fault of fdroid</p><p>- Does anyone know of a plan to fix the issue?</p><p>For what it's worth, I do donate on a monthly basis to fdroid through liberapay, but I don't think that's really relevant here?</p></div></td></tr></tbody></table></td></tr><tr id="44885283"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885283" href="https://news.ycombinator.com/vote?id=44885283&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>This has now become a major issue for F-Droid, as well as for FOSS app developers. People are starting to complain about devs because they haven't been able to release the new version for their apps  (at least it doesn't show up on F-Droid) as promised</p></div></td></tr></tbody></table></td></tr><tr id="44885065"><td></td></tr><tr id="44884905"><td></td></tr><tr id="44885121"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885121" href="https://news.ycombinator.com/vote?id=44885121&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Funny true story: I got my first smartphone in 2018, a Samsung Galaxy A5.  I have it to this day, and it is the only smartphone I ever used.  This is the first time I hear about Samsung Galaxy store! (≧▽≦)</p></div></td></tr></tbody></table></td></tr><tr id="44885091"><td></td></tr><tr id="44884918"><td></td></tr><tr id="44884943"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884943" href="https://news.ycombinator.com/vote?id=44884943&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt; FDroid is by far the largest non-google android store at the moment</p><p>Not even sure it's in the top 10</p></div></td></tr></tbody></table></td></tr><tr id="44885240"><td></td></tr><tr id="44885341"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44885341" href="https://news.ycombinator.com/vote?id=44885341&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>There are at least six Android app stores in China that have more than 100 million MAUs each: Huawei AppGallery, Tencent MyApp, Xiaomi Mi Store (or GetApps), Oppo, Vivo, and Honor stores.</p></div></td></tr></tbody></table></td></tr><tr id="44885893"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44885893" href="https://news.ycombinator.com/vote?id=44885893&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Huawei and Honor are seperate app stores?</p><p>And Oppo and Vivo too?</p><p>In both instances one company owns the other - why have competing app stores?</p></div></td></tr></tbody></table></td></tr><tr id="44885689"><td></td></tr><tr id="44884904"><td></td></tr><tr id="44884948"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884948" href="https://news.ycombinator.com/vote?id=44884948&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt; However at the same time, not even offering a fallback path in non-assembly?</p><p>There's probably not any hand-written assembly at issue here, just a compiler told to target x86_64-v2. Among others, RHEL 9 and derivatives were built with such options. (RHEL 10 bumped up the minimum spec again to x86_64-v3, allowing use of AVX.)</p></div></td></tr></tbody></table></td></tr><tr id="44885099"><td></td></tr><tr id="44885714"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885714" href="https://news.ycombinator.com/vote?id=44885714&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>at this point they're guzzling so much power the electricity is more expensive than replacement platform</p></div></td></tr></tbody></table></td></tr><tr id="44885600"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885600" href="https://news.ycombinator.com/vote?id=44885600&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I can imagine this has to be like that as they usually get $1500 per month in donations.</p><p>You could buy a newer one but I guess they have other stuff they have to pay for.</p></div></td></tr></tbody></table></td></tr><tr id="44885138"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44885138" href="https://news.ycombinator.com/vote?id=44885138&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt; Google’s new aapt2 binary in AGP 8.12.0</p><p>Given F-Droid's emphasis on isolating and protecting their build environment, I'm kind of surprised that they're just using upstream binaries and not building from source.</p></div></td></tr></tbody></table></td></tr><tr id="44885022"><td></td></tr><tr id="44885083"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885083" href="https://news.ycombinator.com/vote?id=44885083&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>There is no point for Google to push planned obsolescence on the PC or server space. They don't have a market there.</p></div></td></tr></tbody></table></td></tr><tr id="44885118"><td></td></tr><tr id="44885215"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44885215" href="https://news.ycombinator.com/vote?id=44885215&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>When you mention "competitors," what industries or markets are you referring to?</p><p>No one would write Android apps on a Chromebook, and making it harder to do so would only reduce the incentive for companies to develop Android apps.</p><p>How could Google benefit from pushing a newer instruction set standard on Windows and macOS?</p></div></td></tr></tbody></table></td></tr><tr id="44885301"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44885301" href="https://news.ycombinator.com/vote?id=44885301&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>The one moderately popular competitor is the project in the OP that is suffering directly from this upstream change.</p></div></td></tr></tbody></table></td></tr><tr id="44885386"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44885386" href="https://news.ycombinator.com/vote?id=44885386&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>While your perspective makes some sense, it's highly improbable. It's unlikely that Google was aware of F-Droid's  infrastructure specs, or its inability to fix the issue in advance.</p><p>It seems you're suggesting a very specific, targeted attack.</p></div></td></tr></tbody></table></td></tr><tr id="44885304"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885304" href="https://news.ycombinator.com/vote?id=44885304&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>"If I had the time, I'd try to compile a binary of it that will run on Win95 just to give my fuckings to the planned obsolescence crowd"</p><p>The idea that not supporting a 20+ year old system is "planned obsolescence" is a bit shallow</p></div></td></tr></tbody></table></td></tr><tr id="44884889"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44884889" href="https://news.ycombinator.com/vote?id=44884889&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>It seems quite implausible that F-Droid is actually running on hardware that predates those instruction set extensions. They're seeing wider adoption by default these days precisely because hardware which doesn't support them is getting very rare, especially in servers still in production use. Are you sure this isn't simply a matter of F-Droid using VMs that are configured to not expose those instructions as supported?</p></div></td></tr></tbody></table></td></tr><tr id="44885018"><td></td></tr><tr id="44884926"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44884926" href="https://news.ycombinator.com/vote?id=44884926&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Note: the underlying blame here fundamentally belongs to whoever built AGP / Gradle with non-universal flags, then distributed it.</p><p>It's fine to ship binaries with hard-coded cpu flag requirements <i>if</i> you control the universe, but otherwise not, especially if you are in an ecosystem where you make it hard for users to rebuild everything from source.</p></div></td></tr></tbody></table></td></tr><tr id="44884996"><td></td></tr><tr id="44885261"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885261" href="https://news.ycombinator.com/vote?id=44885261&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Exactly. Everything should be compiled to target i386.</p><p>/s (should be obvious but probably not for this audience)</p></div></td></tr></tbody></table></td></tr><tr id="44885181"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44885181" href="https://news.ycombinator.com/vote?id=44885181&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>As far as I can see, sse4.1 has been introduced in CPUs in 2011. That's more than 10 years ago. I wonder why such old servers are still in use. I'd assume that a modern CPU would do the same amount of work with a fraction of energy so that it does not even make economical sense to run such outdated hardware.</p><p>Does anyone know the numbers of build servers and the specs?</p></div></td></tr></tbody></table></td></tr><tr id="44885380"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885380" href="https://news.ycombinator.com/vote?id=44885380&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I haven’t seen the real answer that I suspect here - the build servers are that one dual socket AMD board which runs open firmware and has no ME/PSP .</p></div></td></tr></tbody></table></td></tr><tr id="44885536"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885536" href="https://news.ycombinator.com/vote?id=44885536&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>It has been introduced in Intel Penryn, in November 2007.</p><p>However the AMD CPUs did not implement it until Bulldozer, in mid 2011.</p><p>While they lacked the many additional instructions provided by Bulldozer, also including AVX and FMA, for many applications the older Opteron CPUs were significantly faster than the Bulldozer-based CPUs, so there were few incentives for upgrading them, before the launch of AMD Epyc in mid 2017.</p><p>SSE 4.1 is a cut point in supporting old CPUs for many software packages, because older CPUs have a very high overhead for divergent computations (e.g. with if ... else ...) inside loops that are parallelized with SIMD instructions.</p></div></td></tr></tbody></table></td></tr><tr id="44885308"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885308" href="https://news.ycombinator.com/vote?id=44885308&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I was going to say that I assume that the reason for such old CPUs is the ability to use Canoeboot/GNU Boot.  But you absolutely can put an SSE4.2 CPU in a KGPE-D16 motherboard.  So IDK.</p></div></td></tr></tbody></table></td></tr><tr id="44885282"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885282" href="https://news.ycombinator.com/vote?id=44885282&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Hardware after the first couple of generations of x86_64 muliticore processors are perfectly capable machines to use as servers, even for tasks you want to put off to a build farm.</p></div></td></tr></tbody></table></td></tr><tr id="44884847"><td></td></tr><tr id="44884911"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884911" href="https://news.ycombinator.com/vote?id=44884911&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>The build servers appear to be AMD Opteron G3s, which only support part of SSE4 (SSE4a). Full SSE4 support didn't land until Bulldozer (late 2011).</p></div></td></tr></tbody></table></td></tr><tr id="44885037"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885037" href="https://news.ycombinator.com/vote?id=44885037&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I appreciate that this is a volunteer project, but my back of the hand math suggests that if they upgraded to a $300 laptop using a 10nm intel chip, it would pay for itself in power usage within a few years.  Actually, probably less, considering an i3-N305 has more cores and substantially faster single thread.</p><p>And yes, you could get that cost down easily.</p></div></td></tr></tbody></table></td></tr><tr id="44885048"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44885048" href="https://news.ycombinator.com/vote?id=44885048&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Yes, a used laptop would be an upgrade from server hardware of that vintage, in performance and probably in reliability. If they're really using hardware that old, that is itself a big red flag that F-Droid's infrastructure is fragile and unmaintained.</p><p>(A server <i>that</i> old might not have any SSDs, which would be <i>insane</i> for a software build server unless it was doing everything in RAM.)</p></div></td></tr></tbody></table></td></tr><tr id="44885486"><td></td></tr><tr id="44885480"><td></td></tr><tr id="44885752"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44885752" href="https://news.ycombinator.com/vote?id=44885752&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>there are a handful of vendors that will sell you an intel chip with the me disabled, as well as arm vendors that ship boards without an me-equivalent at all</p><p>the point of my post still stands</p></div></td></tr></tbody></table></td></tr><tr id="44885314"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885314" href="https://news.ycombinator.com/vote?id=44885314&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>it's insane, i would give them my old xeon haswell machine for free, but the shipping cost is likely more than the cost of the machine itself.</p></div></td></tr></tbody></table></td></tr><tr id="44884901"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884901" href="https://news.ycombinator.com/vote?id=44884901&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Yes, SSE4.1 and SSSE3 have been introduced in ~2006. The F-Droid build server still uses that to build modern and some of the most popular FOSS apps.</p></div></td></tr></tbody></table></td></tr><tr id="44884925"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44884925" href="https://news.ycombinator.com/vote?id=44884925&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Man, Android could have been way cooler if it actually used real virtual machines, or at least the JVMs.</p></div></td></tr></tbody></table></td></tr><tr id="44885175"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885175" href="https://news.ycombinator.com/vote?id=44885175&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I stood by Oracle, because in the long term as it has been proven, Android is Google's J++, and Kotlin became Google's C#.</p><p>Hardly any different from what was in the genesis of .NET.</p><p>Nowadays they support up to Java 17 LTS, a subset only as usual, mostly because Android was being left behind accessing the Java ecosystem on Maven central.</p><p>And even though now ART is updatable via PlayStore, all the way down to Android 12, they see no need to move beyond Java 17 subset, until most likely they start again missing on key libraries that decided to adopt newer features.</p><p>Also stuff like Panama, Loom, Vector, Valhala (if ever), don't count them ever being supported on ART.</p><p>At least, they managed to push into mainstream the closest idea of OSes like Oberon, Inferno, Java OS and co, where regardless of what think about the superiotity of UNIX clones, here they have to contend themselves with a managed userspace, something that Microsoft failed at with Longhorn, Singularity and Midori due to their internal politics.</p></div></td></tr></tbody></table></td></tr><tr id="44885758"><td></td></tr><tr id="44885273"><td></td></tr><tr id="44885070"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44885070" href="https://news.ycombinator.com/vote?id=44885070&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I’ve got an old Ivy Bridge-EP Dell workstation they can borrow goddamn SSE4.1 is nearly old enough to drink.</p></div></td></tr></tbody></table></td></tr><tr id="44885278"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44885278" href="https://news.ycombinator.com/vote?id=44885278&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Yeah I was kind of shocked too. Core 2 could do both of those instruction sets. A used Dell Precision can be had for very little and probably would be grossly more efficient than whatever they're using.</p></div></td></tr></tbody></table></td></tr><tr id="44884959"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44884959" href="https://news.ycombinator.com/vote?id=44884959&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>wtf they cannot be still running opterons. it was to be that they are using qemu with g3 as a cpu profile.. right?</p></div></td></tr></tbody></table></td></tr><tr id="44885539"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44885539" href="https://news.ycombinator.com/vote?id=44885539&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt;&gt; This has led to multiple “maintenance” versions in a short time, confusing users and wasting developer time, just to work around infrastructure issues outside the developer’s control.</p><p>What an entitled conclusion.</p></div></td></tr></tbody></table></td></tr><tr id="44884973"><td></td></tr><tr id="44885062"><td></td></tr><tr id="44885180"><td></td></tr><tr id="44884939"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44884939" href="https://news.ycombinator.com/vote?id=44884939&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Requiring (supposedly) universally available CPU instructions is one thing. Starting to require it in a minor version update (8.11.1 -&gt; 8.12.0) is a whole different thing. What the heck happened to semantic versioning? We can't even trust patch updates anymore these days. The version numbers might as well be git commit IDs.</p></div></td></tr></tbody></table></td></tr><tr id="44885430"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44885430" href="https://news.ycombinator.com/vote?id=44885430&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>&gt; The root cause: Google’s new aapt2 binary in AGP 8.12.0 started requiring CPU instructions (SSE4.1, SSSE3) that F-Droid’s build farm hardware doesn’t support.</p><p>Very intelligent move from Google. Now you can't compile "Hello World" without SSE4.1, SSSE3. /s</p><p>Are there any X86 tablets with Android ?</p></div></td></tr></tbody></table></td></tr><tr id="44885627"><td></td></tr><tr id="44884891"><td></td></tr><tr id="44885172"><td></td></tr><tr id="44884933"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44884933" href="https://news.ycombinator.com/vote?id=44884933&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>I have it installed. But the only thing I get updates for is Obtainium itself. There's no catalogue of apps, so I haven't installed anything via Obtainium.</p></div></td></tr></tbody></table></td></tr><tr id="44885051"><td></td></tr><tr id="44885400"><td></td></tr><tr id="44885068"><td></td></tr><tr id="44884942"><td></td></tr><tr id="44885143"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885143" href="https://news.ycombinator.com/vote?id=44885143&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>At this point it is not political, the banner mention a fact and a tragedy and link for donations to reputable NGOs.</p></div></td></tr></tbody></table></td></tr><tr id="44885078"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44885078" href="https://news.ycombinator.com/vote?id=44885078&amp;how=up&amp;goto=item%3Fid%3D44884709"></a></center></td><td><br>
<div><p>Wow. That banner slipped by me on first read. Thanks for pointing it out. I tried to go to the dev's webpage, and I needed a VPN to access it. If he actually believed what he said, he wouldn't block IPs, he'd attempt to educate. Seems like bad-faith xenophobia role-playing as compassion.</p></div></td></tr></tbody></table></td></tr><tr id="44885085"><td></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Search all text in New York City (317 pts)]]></title>
            <link>https://www.alltext.nyc/</link>
            <guid>44883304</guid>
            <pubDate>Wed, 13 Aug 2025 00:17:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alltext.nyc/">https://www.alltext.nyc/</a>, See on <a href="https://news.ycombinator.com/item?id=44883304">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="region" aria-label="Notifications (F8)" tabindex="-1"><ol tabindex="-1"></ol></div><main><form novalidate="" action="/search"><div><a href="https://www.alltext.nyc/">all text in nyc</a></div></form></main><a href="https://www.alltext.nyc/about"><p><span>i</span></p></a></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go 1.25 Release Notes (223 pts)]]></title>
            <link>https://go.dev/doc/go1.25</link>
            <guid>44881977</guid>
            <pubDate>Tue, 12 Aug 2025 21:25:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go.dev/doc/go1.25">https://go.dev/doc/go1.25</a>, See on <a href="https://news.ycombinator.com/item?id=44881977">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
  


<article>
















<div>

<h2 id="introduction">Introduction to Go 1.25</h2>
<p>The latest Go release, version 1.25, arrives in <a href="https://go.dev/doc/devel/release#go1.25.0">August 2025</a>, six months after <a href="https://go.dev/doc/go1.24">Go 1.24</a>.
Most of its changes are in the implementation of the toolchain, runtime, and libraries.
As always, the release maintains the Go 1 promise of compatibility.
We expect almost all Go programs to continue to compile and run as before.</p>
<h2 id="language">Changes to the language</h2>
<!-- go.dev/issue/70128 -->
<p>There are no languages changes that affect Go programs in Go 1.25.
However, in the <a href="https://go.dev/ref/spec">language specification</a> the notion of core types
has been removed in favor of dedicated prose.
See the respective <a href="https://go.dev/blog/coretypes">blog post</a> for more information.</p>

<h3 id="go-command">Go command</h3>
<p>The <code>go build</code> <code>-asan</code> option now defaults to doing leak detection at
program exit.
This will report an error if memory allocated by C is not freed and is
not referenced by any other memory allocated by either C or Go.
These new error reports may be disabled by setting
<code>ASAN_OPTIONS=detect_leaks=0</code> in the environment when running the
program.</p>
<!-- go.dev/issue/71867 -->
<p>The Go distribution will include fewer prebuilt tool binaries. Core
toolchain binaries such as the compiler and linker will still be
included, but tools not invoked by build or test operations will be built
and run by <code>go tool</code> as needed.</p>
<!-- go.dev/issue/42965 -->
<p>The new <code>go.mod</code> <code>ignore</code> <a href="https://go.dev/ref/mod#go-mod-file-ignore">directive</a> can be used to
specify directories the <code>go</code> command should ignore. Files in these directories
and their subdirectories  will be ignored by the <code>go</code> command when matching package
patterns, such as <code>all</code> or <code>./...</code>, but will still be included in module zip files.</p>
<!-- go.dev/issue/68106 -->
<p>The new <code>go doc</code> <code>-http</code> option will start a documentation server showing
documentation for the requested object, and open the documentation in a browser
window.</p>
<!-- go.dev/issue/69712 -->
<p>The new <code>go version -m -json</code> option will print the JSON encodings of the
<code>runtime/debug.BuildInfo</code> structures embedded in the given Go binary files.</p>
<!-- go.dev/issue/34055 -->
<p>The <code>go</code> command now supports using a subdirectory of a repository as the
path for a module root, when <a href="https://go.dev/ref/mod#vcs-find">resolving a module path</a> using the syntax
<code>&lt;meta name="go-import" content="root-path vcs repo-url subdir"&gt;</code> to indicate
that the <code>root-path</code> corresponds to the <code>subdir</code> of the <code>repo-url</code> with
version control system <code>vcs</code>.</p>
<!-- go.dev/issue/71294 -->
<p>The new <code>work</code> package pattern matches all packages in the work (formerly called main)
modules: either the single work module in module mode or the set of workspace modules
in workspace mode.</p>
<!-- go.dev/issue/65847 -->
<p>When the go command updates the <code>go</code> line in a <code>go.mod</code> or <code>go.work</code> file,
it <a href="https://go.dev/ref/mod#go-mod-file-toolchain">no longer</a> adds a toolchain line
specifying the command’s current version.</p>
<h3 id="vet">Vet</h3>
<p>The <code>go vet</code> command includes new analyzers:</p>
<!-- go.dev/issue/18022 -->
<ul>
<li><a href="https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/waitgroup" rel="noreferrer" target="_blank">waitgroup</a>,
which reports misplaced calls to <a href="https://go.dev/pkg/sync#WaitGroup.Add"><code>sync.WaitGroup.Add</code></a>; and</li>
</ul>
<!-- go.dev/issue/28308 -->
<ul>
<li><a href="https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/hostport" rel="noreferrer" target="_blank">hostport</a>,
which reports uses of <code>fmt.Sprintf("%s:%d", host, port)</code> to
construct addresses for <a href="https://go.dev/pkg/net#Dial"><code>net.Dial</code></a>, as these will not work with
IPv6; instead it suggests using <a href="https://go.dev/pkg/net#JoinHostPort"><code>net.JoinHostPort</code></a>.</li>
</ul>
<h2 id="runtime">Runtime</h2>
<h3 id="container-aware-gomaxprocs">Container-aware <code>GOMAXPROCS</code></h3>
<!-- go.dev/issue/73193 -->
<p>The default behavior of the <code>GOMAXPROCS</code> has changed. In prior versions of Go,
<code>GOMAXPROCS</code> defaults to the number of logical CPUs available at startup
(<a href="https://go.dev/pkg/runtime#NumCPU"><code>runtime.NumCPU</code></a>). Go 1.25 introduces two changes:</p>
<ol>
<li>
<p>On Linux, the runtime considers the CPU bandwidth limit of the cgroup
containing the process, if any. If the CPU bandwidth limit is lower than the
number of logical CPUs available, <code>GOMAXPROCS</code> will default to the lower
limit. In container runtime systems like Kubernetes, cgroup CPU bandwidth
limits generally correspond to the “CPU limit” option. The Go runtime does
not consider the “CPU requests” option.</p>
</li>
<li>
<p>On all OSes, the runtime periodically updates <code>GOMAXPROCS</code> if the number
of logical CPUs available or the cgroup CPU bandwidth limit change.</p>
</li>
</ol>
<p>Both of these behaviors are automatically disabled if <code>GOMAXPROCS</code> is set
manually via the <code>GOMAXPROCS</code> environment variable or a call to
<a href="https://go.dev/pkg/runtime#GOMAXPROCS"><code>runtime.GOMAXPROCS</code></a>. They can also be disabled explicitly with the <a href="https://go.dev/doc/godebug">GODEBUG
settings</a> <code>containermaxprocs=0</code> and <code>updatemaxprocs=0</code>,
respectively.</p>
<p>In order to support reading updated cgroup limits, the runtime will keep cached
file descriptors for the cgroup files for the duration of the process lifetime.</p>
<h3 id="new-experimental-garbage-collector">New experimental garbage collector</h3>
<!-- go.dev/issue/73581 -->
<p>A new garbage collector is now available as an experiment. This garbage
collector’s design improves the performance of marking and scanning small objects
through better locality and CPU scalability. Benchmark result vary, but we expect
somewhere between a 10—40% reduction in garbage collection overhead in real-world
programs that heavily use the garbage collector.</p>
<p>The new garbage collector may be enabled by setting <code>GOEXPERIMENT=greenteagc</code>
at build time. We expect the design to continue to evolve and improve. To that
end, we encourage Go developers to try it out and report back their experiences.
See the <a href="https://go.dev/issue/73581">GitHub issue</a> for more details on the design and
instructions for sharing feedback.</p>
<h3 id="trace-flight-recorder">Trace flight recorder</h3>
<!-- go.dev/issue/63185 -->
<p><a href="https://go.dev/pkg/runtime/trace">Runtime execution traces</a> have long provided a powerful,
but expensive way to understand and debug the low-level behavior of an
application. Unfortunately, because of their size and the cost of continuously
writing an execution trace, they were generally impractical for debugging rare
events.</p>
<p>The new <a href="https://go.dev/pkg/runtime/trace#FlightRecorder"><code>runtime/trace.FlightRecorder</code></a> API
provides a lightweight way to capture a runtime execution trace by continuously
recording the trace into an in-memory ring buffer. When a significant event
occurs, a program can call
<a href="https://go.dev/pkg/runtime/trace#FlightRecorder.WriteTo"><code>FlightRecorder.WriteTo</code></a> to
snapshot the last few seconds of the trace to a file. This approach produces a
much smaller trace by enabling applications to capture only the traces that
matter.</p>
<p>The length of time and amount of data captured by a
<a href="https://go.dev/pkg/runtime/trace#FlightRecorder"><code>FlightRecorder</code></a> may be configured within
the <a href="https://go.dev/pkg/runtime/trace#FlightRecorderConfig"><code>FlightRecorderConfig</code></a>.</p>
<h3 id="change-to-unhandled-panic-output">Change to unhandled panic output</h3>
<!-- go.dev/issue/71517 -->
<p>The message printed when a program exits due to an unhandled panic
that was recovered and repanicked no longer repeats the text of
the panic value.</p>
<p>Previously, a program which panicked with <code>panic("PANIC")</code>,
recovered the panic, and then repanicked with the original
value would print:</p>
<pre><code>panic: PANIC [recovered]
  panic: PANIC
</code></pre>
<p>This program will now print:</p>
<pre><code>panic: PANIC [recovered, repanicked]
</code></pre>
<h3 id="vma-names-on-linux">VMA names on Linux</h3>
<!-- go.dev/issue/71546 -->
<p>On Linux systems with kernel support for anonymous virtual memory area (VMA) names
(<code>CONFIG_ANON_VMA_NAME</code>), the Go runtime will annotate anonymous memory
mappings with context about their purpose. e.g., <code>[anon: Go: heap]</code> for heap
memory. This can be disabled with the <a href="https://go.dev/doc/godebug">GODEBUG setting</a>
<code>decoratemappings=0</code>.</p>
<h2 id="compiler">Compiler</h2>
<h3 id="nil-pointer-bug"><code>nil</code> pointer bug</h3>
<!-- https://go.dev/issue/72860, CL 657715 -->
<p>This release fixes a <a href="https://go.dev/issue/72860">compiler bug</a>, introduced in Go 1.21, that
could incorrectly delay nil pointer checks. Programs like the following, which
used to execute successfully (incorrectly), will now (correctly) panic with a
nil-pointer exception:</p>
<pre><code>package main

import "os"

func main() {
    f, err := os.Open("nonExistentFile")
    name := f.Name()
    if err != nil {
        return
    }
    println(name)
}
</code></pre>
<p>This program is incorrect because it uses the result of <code>os.Open</code> before
checking the error. If <code>err</code> is non-nil, then the <code>f</code> result may be nil, in
which case <code>f.Name()</code> should panic. However, in Go versions 1.21 through 1.24,
the compiler incorrectly delayed the nil check until <em>after</em> the error check,
causing the program to execute successfully, in violation of the Go spec. In Go
1.25, it will no longer run successfully. If this change is affecting your code,
the solution is to put the non-nil error check earlier in your code, preferably
immediately after the error-generating statement.</p>
<h3 id="dwarf5-support">DWARF5 support</h3>
<!-- https://go.dev/issue/26379 -->
<p>The compiler and linker in Go 1.25 now generate debug information
using <a href="https://dwarfstd.org/dwarf5std.html" rel="noreferrer" target="_blank">DWARF version 5</a>. The
newer DWARF version reduces the space required for debugging
information in Go binaries, and reduces the time for linking,
especially for large Go binaries.
DWARF 5 generation can be disabled by setting the environment
variable <code>GOEXPERIMENT=nodwarf5</code> at build time
(this fallback may be removed in a future Go release).</p>
<h3 id="faster-slices">Faster slices</h3>
<!-- CLs 653856, 657937, 663795, 664299 -->
<p>The compiler can now allocate the backing store for slices on the
stack in more situations, which improves performance. This change has
the potential to amplify the effects of incorrect
<a href="https://go.dev/pkg/unsafe#Pointer">unsafe.Pointer</a> usage, see for example <a href="https://go.dev/issue/73199">issue
73199</a>. In order to track down these problems, the
<a href="https://pkg.go.dev/golang.org/x/tools/cmd/bisect" rel="noreferrer" target="_blank">bisect tool</a> can be
used to find the allocation causing trouble using the
<code>-compile=variablemake</code> flag. All such new stack allocations can also
be turned off using <code>-gcflags=all=-d=variablemakehash=n</code>.</p>
<h2 id="linker">Linker</h2>
<!-- CL 660996 -->
<p>The linker now accepts a <code>-funcalign=N</code> command line option, which
specifies the alignment of function entries.
The default value is platform-dependent, and is unchanged in this
release.</p>
<h2 id="library">Standard library</h2>
<h3 id="new-testingsynctest-package">New testing/synctest package</h3>
<!-- go.dev/issue/67434, go.dev/issue/73567 -->
<p>The new <a href="https://go.dev/pkg/testing/synctest"><code>testing/synctest</code></a> package
provides support for testing concurrent code.</p>
<p>The <a href="https://go.dev/pkg/testing/synctest#Test"><code>Test</code></a> function runs a test function in an isolated
“bubble”. Within the bubble, time is virtualized: <a href="https://go.dev/pkg/time"><code>time</code></a> package
functions operate on a fake clock and the clock moves forward instantaneously if
all goroutines in the bubble are blocked.</p>
<p>The <a href="https://go.dev/pkg/testing/synctest#Wait"><code>Wait</code></a> function waits for all goroutines in the
current bubble to block.</p>
<p>This package was first available in Go 1.24 under <code>GOEXPERIMENT=synctest</code>, with
a slightly different API. The experiment has now graduated to general
availability. The old API is still present if <code>GOEXPERIMENT=synctest</code> is set,
but will be removed in Go 1.26.</p>
<h3 id="json_v2">New experimental encoding/json/v2 package</h3>
<p>Go 1.25 includes a new, experimental JSON implementation,
which can be enabled by setting the environment variable
<code>GOEXPERIMENT=jsonv2</code> at build time.</p>
<p>When enabled, two new packages are available:</p>
<ul>
<li>The <a href="https://go.dev/pkg/encoding/json/v2"><code>encoding/json/v2</code></a> package is
a major revision of the <code>encoding/json</code> package.</li>
<li>The <a href="https://go.dev/pkg/encoding/json/jsontext"><code>encoding/json/jsontext</code></a> package
provides lower-level processing of JSON syntax.</li>
</ul>
<p>In addition, when the “jsonv2” GOEXPERIMENT is enabled:</p>
<ul>
<li>The <a href="https://go.dev/pkg/encoding/json"><code>encoding/json</code></a> package
uses the new JSON implementation.
Marshaling and unmarshaling behavior is unaffected,
but the text of errors returned by package function may change.</li>
<li>The <a href="https://go.dev/pkg/encoding/json"><code>encoding/json</code></a> package contains
a number of new options which may be used
to configure the marshaler and unmarshaler.</li>
</ul>
<p>The new implementation performs substantially better than
the existing one under many scenarios. In general,
encoding performance is at parity between the implementations
and decoding is substantially faster in the new one.
See the <a href="https://github.com/go-json-experiment/jsonbench" rel="noreferrer" target="_blank">github.com/go-json-experiment/jsonbench</a>
repository for more detailed analysis.</p>
<p>See the <a href="https://go.dev/issue/71497">proposal issue</a> for more details.</p>
<p>We encourage users of <a href="https://go.dev/pkg/encoding/json"><code>encoding/json</code></a> to test
their programs with <code>GOEXPERIMENT=jsonv2</code> enabled to help detect
any compatibility issues with the new implementation.</p>
<p>We expect the design of <a href="https://go.dev/pkg/encoding/json/v2"><code>encoding/json/v2</code></a>
to continue to evolve. We encourage developers to try out the new
API and provide feedback on the <a href="https://go.dev/issue/71497">proposal issue</a>.</p>
<h3 id="minor_library_changes">Minor changes to the library</h3>
<h4 id="archivetarpkgarchivetar"><a href="https://go.dev/pkg/archive/tar/"><code>archive/tar</code></a></h4>
<p>The <a href="https://go.dev/pkg/archive/tar#Writer.AddFS"><code>Writer.AddFS</code></a> implementation now supports symbolic links
for filesystems that implement <a href="https://go.dev/pkg/io/fs#ReadLinkFS"><code>io/fs.ReadLinkFS</code></a>.</p>
<h4 id="encodingasn1pkgencodingasn1"><a href="https://go.dev/pkg/encoding/asn1/"><code>encoding/asn1</code></a></h4>
<p><a href="https://go.dev/pkg/encoding/asn1#Unmarshal"><code>Unmarshal</code></a> and <a href="https://go.dev/pkg/encoding/asn1#UnmarshalWithParams"><code>UnmarshalWithParams</code></a>
now parse the ASN.1 types T61String and BMPString more consistently. This may
result in some previously accepted malformed encodings now being rejected.</p>
<h4 id="cryptopkgcrypto"><a href="https://go.dev/pkg/crypto/"><code>crypto</code></a></h4>
<p><a href="https://go.dev/pkg/crypto#MessageSigner"><code>MessageSigner</code></a> is a new signing interface that can
be implemented by signers that wish to hash the message to be signed themselves.
A new function is also introduced, <a href="https://go.dev/pkg/crypto#SignMessage"><code>SignMessage</code></a>,
which attempts to upgrade a <a href="https://go.dev/pkg/crypto#Signer"><code>Signer</code></a> interface to
<a href="https://go.dev/pkg/crypto#MessageSigner"><code>MessageSigner</code></a>, using the
<a href="https://go.dev/pkg/crypto#MessageSigner.SignMessage"><code>MessageSigner.SignMessage</code></a> method if
successful, and <a href="https://go.dev/pkg/crypto#Signer.Sign"><code>Signer.Sign</code></a> if not. This can be
used when code wishes to support both <a href="https://go.dev/pkg/crypto#Signer"><code>Signer</code></a> and
<a href="https://go.dev/pkg/crypto#MessageSigner"><code>MessageSigner</code></a>.</p>
<p>Changing the <code>fips140</code> <a href="https://go.dev/doc/godebug">GODEBUG setting</a> after the program has started is now a no-op.
Previously, it was documented as not allowed, and could cause a panic if changed.</p>
<p>SHA-1, SHA-256, and SHA-512 are now slower on amd64 when AVX2 instructions are not available.
All server processors (and most others) produced since 2015 support AVX2.</p>
<h4 id="cryptoecdsapkgcryptoecdsa"><a href="https://go.dev/pkg/crypto/ecdsa/"><code>crypto/ecdsa</code></a></h4>
<p>The new <a href="https://go.dev/pkg/crypto/ecdsa#ParseRawPrivateKey"><code>ParseRawPrivateKey</code></a>,
<a href="https://go.dev/pkg/crypto/ecdsa#ParseUncompressedPublicKey"><code>ParseUncompressedPublicKey</code></a>,
<a href="https://go.dev/pkg/crypto/ecdsa#PrivateKey.Bytes"><code>PrivateKey.Bytes</code></a>, and
<a href="https://go.dev/pkg/crypto/ecdsa#PublicKey.Bytes"><code>PublicKey.Bytes</code></a> functions and methods
implement low-level encodings, replacing the need to use
<a href="https://go.dev/pkg/crypto/elliptic"><code>crypto/elliptic</code></a> or <a href="https://go.dev/pkg/math/big"><code>math/big</code></a>
functions and methods.</p>
<p>When FIPS 140-3 mode is enabled, signing is now four times faster, matching the
performance of non-FIPS mode.</p>
<h4 id="cryptoed25519pkgcryptoed25519"><a href="https://go.dev/pkg/crypto/ed25519/"><code>crypto/ed25519</code></a></h4>
<p>When FIPS 140-3 mode is enabled, signing is now four times faster, matching the
performance of non-FIPS mode.</p>
<h4 id="cryptoellipticpkgcryptoelliptic"><a href="https://go.dev/pkg/crypto/elliptic/"><code>crypto/elliptic</code></a></h4>
<p>The hidden and undocumented <code>Inverse</code> and <code>CombinedMult</code> methods on some
<a href="https://go.dev/pkg/crypto/elliptic#Curve"><code>Curve</code></a> implementations have been removed.</p>
<h4 id="cryptorsapkgcryptorsa"><a href="https://go.dev/pkg/crypto/rsa/"><code>crypto/rsa</code></a></h4>
<p><a href="https://go.dev/pkg/crypto/rsa#PublicKey"><code>PublicKey</code></a> no longer claims that the modulus value
is treated as secret. <a href="https://go.dev/pkg/crypto/rsa#VerifyPKCS1v15"><code>VerifyPKCS1v15</code></a> and
<a href="https://go.dev/pkg/crypto/rsa#VerifyPSS"><code>VerifyPSS</code></a> already warned that all inputs are
public and could be leaked, and there are mathematical attacks that can recover
the modulus from other public values.</p>
<p>Key generation is now three times faster.</p>
<h4 id="cryptosha1pkgcryptosha1"><a href="https://go.dev/pkg/crypto/sha1/"><code>crypto/sha1</code></a></h4>
<p>Hashing is now two times faster on amd64 when SHA-NI instructions are available.</p>
<h4 id="cryptosha3pkgcryptosha3"><a href="https://go.dev/pkg/crypto/sha3/"><code>crypto/sha3</code></a></h4>
<p>The new <a href="https://go.dev/pkg/crypto/sha3#SHA3.Clone"><code>SHA3.Clone</code></a> method implements <a href="https://go.dev/pkg/hash#Cloner"><code>hash.Cloner</code></a>.</p>
<p>Hashing is now two times faster on Apple M processors.</p>
<h4 id="cryptotlspkgcryptotls"><a href="https://go.dev/pkg/crypto/tls/"><code>crypto/tls</code></a></h4>
<p>The new <a href="https://go.dev/pkg/crypto/tls#ConnectionState.CurveID"><code>ConnectionState.CurveID</code></a>
field exposes the key exchange mechanism used to establish the connection.</p>
<p>The new <a href="https://go.dev/pkg/crypto/tls#Config.GetEncryptedClientHelloKeys"><code>Config.GetEncryptedClientHelloKeys</code></a>
callback can be used to set the <a href="https://go.dev/pkg/crypto/tls#EncryptedClientHelloKey"><code>EncryptedClientHelloKey</code></a>s
for a server to use when a client sends an Encrypted Client Hello extension.</p>
<p>SHA-1 signature algorithms are now disallowed in TLS 1.2 handshakes, per
<a href="https://www.rfc-editor.org/rfc/rfc9155.html" rel="noreferrer" target="_blank">RFC 9155</a>.
They can be re-enabled with the <a href="https://go.dev/doc/godebug">GODEBUG setting</a> <code>tlssha1=1</code>.</p>
<p>When <a href="https://go.dev/doc/security/fips140">FIPS 140-3 mode</a> is enabled, Extended Master Secret
is now required in TLS 1.2, and Ed25519 and X25519MLKEM768 are now allowed.</p>
<p>TLS servers now prefer the highest supported protocol version, even if it isn’t
the client’s most preferred protocol version.</p>
<!-- CL 687855 -->
<p>Both TLS clients and servers are now stricter in following the specifications
and in rejecting off-spec behavior. Connections with compliant peers should be
unaffected.</p>
<h4 id="cryptox509pkgcryptox509"><a href="https://go.dev/pkg/crypto/x509/"><code>crypto/x509</code></a></h4>
<p><a href="https://go.dev/pkg/crypto/x509#CreateCertificate"><code>CreateCertificate</code></a>,
<a href="https://go.dev/pkg/crypto/x509#CreateCertificateRequest"><code>CreateCertificateRequest</code></a>, and
<a href="https://go.dev/pkg/crypto/x509#CreateRevocationList"><code>CreateRevocationList</code></a> can now accept a
<a href="https://go.dev/pkg/crypto#MessageSigner"><code>crypto.MessageSigner</code></a> signing interface as well as
<a href="https://go.dev/pkg/crypto#Signer"><code>crypto.Signer</code></a>. This allows these functions to use
signers which implement “one-shot” signing interfaces, where hashing is done as
part of the signing operation, instead of by the caller.</p>
<p><a href="https://go.dev/pkg/crypto/x509#CreateCertificate"><code>CreateCertificate</code></a> now uses truncated
SHA-256 to populate the <code>SubjectKeyId</code> if it is missing.
The <a href="https://go.dev/doc/godebug">GODEBUG setting</a> <code>x509sha256skid=0</code> reverts to SHA-1.</p>
<p><a href="https://go.dev/pkg/crypto/x509#ParseCertificate"><code>ParseCertificate</code></a> now rejects certificates
which contain a BasicConstraints extension that contains a negative pathLenConstraint.</p>
<p><a href="https://go.dev/pkg/crypto/x509#ParseCertificate"><code>ParseCertificate</code></a> now handles strings encoded
with the ASN.1 T61String and BMPString types more consistently. This may result in
some previously accepted malformed encodings now being rejected.</p>
<h4 id="debugelfpkgdebugelf"><a href="https://go.dev/pkg/debug/elf/"><code>debug/elf</code></a></h4>
<p>The <a href="https://go.dev/pkg/debug/elf"><code>debug/elf</code></a> package adds two new constants:</p>
<ul>
<li><a href="https://go.dev/pkg/debug/elf#PT_RISCV_ATTRIBUTES"><code>PT_RISCV_ATTRIBUTES</code></a></li>
<li><a href="https://go.dev/pkg/debug/elf#SHT_RISCV_ATTRIBUTES"><code>SHT_RISCV_ATTRIBUTES</code></a>
for RISC-V ELF parsing.</li>
</ul>
<h4 id="goastpkggoast"><a href="https://go.dev/pkg/go/ast/"><code>go/ast</code></a></h4>
<p>The <a href="https://go.dev/pkg/ast#FilterPackage"><code>FilterPackage</code></a>, <a href="https://go.dev/pkg/ast#PackageExports"><code>PackageExports</code></a>, and
<a href="https://go.dev/pkg/ast#MergePackageFiles"><code>MergePackageFiles</code></a> functions, and the <a href="https://go.dev/pkg/go/ast#MergeMode"><code>MergeMode</code></a> type and its
constants, are all deprecated, as they are for use only with the
long-deprecated <a href="https://go.dev/pkg/ast#Object"><code>Object</code></a> and <a href="https://go.dev/pkg/ast#Package"><code>Package</code></a> machinery.</p>
<p>The new <a href="https://go.dev/pkg/go/ast#PreorderStack"><code>PreorderStack</code></a> function, like <a href="https://go.dev/pkg/go/ast#Inspect"><code>Inspect</code></a>, traverses a syntax
tree and provides control over descent into subtrees, but as a
convenience it also provides the stack of enclosing nodes at each
point.</p>
<h4 id="goparserpkggoparser"><a href="https://go.dev/pkg/go/parser/"><code>go/parser</code></a></h4>
<p>The <a href="https://go.dev/pkg/go/parser#ParseDir"><code>ParseDir</code></a> function is deprecated.</p>
<h4 id="gotokenpkggotoken"><a href="https://go.dev/pkg/go/token/"><code>go/token</code></a></h4>
<p>The new <a href="https://go.dev/pkg/go/token#FileSet.AddExistingFiles"><code>FileSet.AddExistingFiles</code></a> method enables existing
<a href="https://go.dev/pkg/go/token#File"><code>File</code></a>s to be added to a <a href="https://go.dev/pkg/go/token#FileSet"><code>FileSet</code></a>,
or a <a href="https://go.dev/pkg/go/token#FileSet"><code>FileSet</code></a> to be constructed for an arbitrary
set of <a href="https://go.dev/pkg/go/token#File"><code>File</code></a>s, alleviating the problems associated with a single global
<a href="https://go.dev/pkg/go/token#FileSet"><code>FileSet</code></a> in long-lived applications.</p>
<h4 id="gotypespkggotypes"><a href="https://go.dev/pkg/go/types/"><code>go/types</code></a></h4>
<p><a href="https://go.dev/pkg/go/types#Var"><code>Var</code></a> now has a <a href="https://go.dev/pkg/go/types#Var.Kind"><code>Var.Kind</code></a> method that classifies the variable as one
of: package-level, receiver, parameter, result, local variable, or
a struct field.</p>
<p>The new <a href="https://go.dev/pkg/go/types#LookupSelection"><code>LookupSelection</code></a> function looks up the field or method of a
given name and receiver type, like the existing <a href="https://go.dev/pkg/go/types#LookupFieldOrMethod"><code>LookupFieldOrMethod</code></a>
function, but returns the result in the form of a <a href="https://go.dev/pkg/go/types#Selection"><code>Selection</code></a>.</p>
<h4 id="hashpkghash"><a href="https://go.dev/pkg/hash/"><code>hash</code></a></h4>
<p>The new <a href="https://go.dev/pkg/hash#XOF"><code>XOF</code></a> interface can be implemented by “extendable output
functions”, which are hash functions with arbitrary or unlimited output length
such as <a href="https://go.dev/pkg/crypto/sha3#SHAKE">SHAKE</a>.</p>
<p>Hashes implementing the new <a href="https://go.dev/pkg/hash#Cloner"><code>Cloner</code></a> interface can return a copy of their state.
All standard library <a href="https://go.dev/pkg/hash#Hash"><code>Hash</code></a> implementations now implement <a href="https://go.dev/pkg/hash#Cloner"><code>Cloner</code></a>.</p>
<h4 id="hashmaphashpkghashmaphash"><a href="https://go.dev/pkg/hash/maphash/"><code>hash/maphash</code></a></h4>
<p>The new <a href="https://go.dev/pkg/hash/maphash#Hash.Clone"><code>Hash.Clone</code></a> method implements <a href="https://go.dev/pkg/hash#Cloner"><code>hash.Cloner</code></a>.</p>
<h4 id="iofspkgiofs"><a href="https://go.dev/pkg/io/fs/"><code>io/fs</code></a></h4>
<p>A new <a href="https://go.dev/pkg/io/fs#ReadLinkFS"><code>ReadLinkFS</code></a> interface provides the ability to read symbolic links in a filesystem.</p>
<h4 id="logslogpkglogslog"><a href="https://go.dev/pkg/log/slog/"><code>log/slog</code></a></h4>
<p><a href="https://go.dev/pkg/log/slog#GroupAttrs"><code>GroupAttrs</code></a> creates a group <a href="https://go.dev/pkg/log/slog#Attr"><code>Attr</code></a> from a slice of <a href="https://go.dev/pkg/log/slog#Attr"><code>Attr</code></a> values.</p>
<p><a href="https://go.dev/pkg/log/slog#Record"><code>Record</code></a> now has a <a href="https://go.dev/pkg/log/slog#Record.Source"><code>Source</code></a> method,
returning its source location or nil if unavailable.</p>
<h4 id="mimemultipartpkgmimemultipart"><a href="https://go.dev/pkg/mime/multipart/"><code>mime/multipart</code></a></h4>
<p>The new helper function <a href="https://go.dev/pkg/mime/multipart#FileContentDisposition"><code>FileContentDisposition</code></a> builds multipart
Content-Disposition header fields.</p>
<h4 id="netpkgnet"><a href="https://go.dev/pkg/net/"><code>net</code></a></h4>
<p><a href="https://go.dev/pkg/net#LookupMX"><code>LookupMX</code></a> and <a href="https://go.dev/pkg/net#Resolver.LookupMX"><code>Resolver.LookupMX</code></a> now return DNS names that look
like valid IP address, as well as valid domain names.
Previously if a name server returned an IP address as a DNS name,
<a href="https://go.dev/pkg/net#LookupMX"><code>LookupMX</code></a> would discard it, as required by the RFCs.
However, name servers in practice do sometimes return IP addresses.</p>
<p>On Windows, <a href="https://go.dev/pkg/net#ListenMulticastUDP"><code>ListenMulticastUDP</code></a> now supports IPv6 addresses.</p>
<p>On Windows, it is now possible to convert between an <a href="https://go.dev/pkg/os#File"><code>os.File</code></a>
and a network connection. Specifcally, the <a href="https://go.dev/pkg/net#FileConn"><code>FileConn</code></a>,
<a href="https://go.dev/pkg/net#FilePacketConn"><code>FilePacketConn</code></a>, and
<a href="https://go.dev/pkg/net#FileListener"><code>FileListener</code></a> functions are now implemented, and
return a network connection or listener corresponding to an open file.
Similarly, the <code>File</code> methods of <a href="https://go.dev/pkg/net#TCPConn.File"><code>TCPConn</code></a>,
<a href="https://go.dev/pkg/net#UDPConn.File"><code>UDPConn</code></a>, <a href="https://go.dev/pkg/net#UnixConn.File"><code>UnixConn</code></a>,
<a href="https://go.dev/pkg/net#IPConn.File"><code>IPConn</code></a>, <a href="https://go.dev/pkg/net#TCPListener.File"><code>TCPListener</code></a>,
and <a href="https://go.dev/pkg/net#UnixListener.File"><code>UnixListener</code></a> are now implemented, and return
the underlying <a href="https://go.dev/pkg/os#File"><code>os.File</code></a> of a network connection.</p>
<h4 id="nethttppkgnethttp"><a href="https://go.dev/pkg/net/http/"><code>net/http</code></a></h4>
<p>The new <a href="https://go.dev/pkg/net/http#CrossOriginProtection"><code>CrossOriginProtection</code></a> implements protections against <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Attacks/CSRF" rel="noreferrer" target="_blank">Cross-Site
Request Forgery (CSRF)</a> by rejecting non-safe cross-origin browser requests.
It uses <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Sec-Fetch-Site" rel="noreferrer" target="_blank">modern browser Fetch metadata</a>, doesn’t require tokens
or cookies, and supports origin-based and pattern-based bypasses.</p>
<h4 id="ospkgos"><a href="https://go.dev/pkg/os/"><code>os</code></a></h4>
<p>On Windows, <a href="https://go.dev/pkg/os#NewFile"><code>NewFile</code></a> now supports handles opened for asynchronous I/O (that is,
<a href="https://go.dev/pkg/syscall#FILE_FLAG_OVERLAPPED"><code>syscall.FILE_FLAG_OVERLAPPED</code></a> is specified in the <a href="https://go.dev/pkg/syscall#CreateFile"><code>syscall.CreateFile</code></a> call).
These handles are associated with the Go runtime’s I/O completion port,
which provides the following benefits for the resulting <a href="https://go.dev/pkg/os#File"><code>File</code></a>:</p>
<ul>
<li>I/O methods (<a href="https://go.dev/pkg/os#File.Read"><code>File.Read</code></a>, <a href="https://go.dev/pkg/os#File.Write"><code>File.Write</code></a>, <a href="https://go.dev/pkg/os#File.ReadAt"><code>File.ReadAt</code></a>, and <a href="https://go.dev/pkg/os#File.WriteAt"><code>File.WriteAt</code></a>) do not block an OS thread.</li>
<li>Deadline methods (<a href="https://go.dev/pkg/os#File.SetDeadline"><code>File.SetDeadline</code></a>, <a href="https://go.dev/pkg/os#File.SetReadDeadline"><code>File.SetReadDeadline</code></a>, and <a href="https://go.dev/pkg/os#File.SetWriteDeadline"><code>File.SetWriteDeadline</code></a>) are supported.</li>
</ul>
<p>This enhancement is especially beneficial for applications that communicate via named pipes on Windows.</p>
<p>Note that a handle can only be associated with one completion port at a time.
If the handle provided to <a href="https://go.dev/pkg/os#NewFile"><code>NewFile</code></a> is already associated with a completion port,
the returned <a href="https://go.dev/pkg/os#File"><code>File</code></a> is downgraded to synchronous I/O mode.
In this case, I/O methods will block an OS thread, and the deadline methods have no effect.</p>
<p>The filesystems returned by <a href="https://go.dev/pkg/os#DirFS"><code>DirFS</code></a> and <a href="https://go.dev/pkg/os#Root.FS"><code>Root.FS</code></a> implement the new <a href="https://go.dev/pkg/io/fs#ReadLinkFS"><code>io/fs.ReadLinkFS</code></a> interface.
<a href="https://go.dev/pkg/os#CopyFS"><code>CopyFS</code></a> supports symlinks when copying filesystems that implement <a href="https://go.dev/pkg/io/fs#ReadLinkFS"><code>io/fs.ReadLinkFS</code></a>.</p>
<p>The <a href="https://go.dev/pkg/os#Root"><code>Root</code></a> type supports the following additional methods:</p>
<ul>
<li><a href="https://go.dev/pkg/os#Root.Chmod"><code>Root.Chmod</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Chown"><code>Root.Chown</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Chtimes"><code>Root.Chtimes</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Lchown"><code>Root.Lchown</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Link"><code>Root.Link</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.MkdirAll"><code>Root.MkdirAll</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.ReadFile"><code>Root.ReadFile</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Readlink"><code>Root.Readlink</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.RemoveAll"><code>Root.RemoveAll</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Rename"><code>Root.Rename</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.Symlink"><code>Root.Symlink</code></a></li>
<li><a href="https://go.dev/pkg/os#Root.WriteFile"><code>Root.WriteFile</code></a></li>
</ul>
<!-- go.dev/issue/73126 is documented as part of 67002 -->
<h4 id="reflectpkgreflect"><a href="https://go.dev/pkg/reflect/"><code>reflect</code></a></h4>
<p>The new <a href="https://go.dev/pkg/reflect#TypeAssert"><code>TypeAssert</code></a> function permits converting a <a href="https://go.dev/pkg/reflect#Value"><code>Value</code></a> directly to a Go value
of the given type. This is like using a type assertion on the result of <a href="https://go.dev/pkg/reflect#Value.Interface"><code>Value.Interface</code></a>,
but avoids unnecessary memory allocations.</p>
<h4 id="regexpsyntaxpkgregexpsyntax"><a href="https://go.dev/pkg/regexp/syntax/"><code>regexp/syntax</code></a></h4>
<p>The <code>\p{name}</code> and <code>\P{name}</code> character class syntaxes now accept the names
Any, ASCII, Assigned, Cn, and LC, as well as Unicode category aliases like <code>\p{Letter}</code> for <code>\pL</code>.
Following <a href="https://unicode.org/reports/tr18/" rel="noreferrer" target="_blank">Unicode TR18</a>, they also now use
case-insensitive name lookups, ignoring spaces, underscores, and hyphens.</p>
<h4 id="runtimepkgruntime"><a href="https://go.dev/pkg/runtime/"><code>runtime</code></a></h4>
<p>Cleanup functions scheduled by <a href="https://go.dev/pkg/runtime#AddCleanup"><code>AddCleanup</code></a> are now executed
concurrently and in parallel, making cleanups more viable for heavy
use like the <a href="https://go.dev/pkg/unique"><code>unique</code></a> package. Note that individual cleanups should
still shunt their work to a new goroutine if they must execute or
block for a long time to avoid blocking the cleanup queue.</p>
<p>A new <code>GODEBUG=checkfinalizers=1</code> setting helps find common issues with
finalizers and cleanups, such as those described <a href="https://go.dev/doc/gc-guide#Finalizers_cleanups_and_weak_pointers">in the GC
guide</a>.
In this mode, the runtime runs diagnostics on each garbage collection cycle,
and will also regularly report the finalizer and
cleanup queue lengths to stderr to help identify issues with
long-running finalizers and/or cleanups.
See the <a href="https://pkg.go.dev/runtime#hdr-Environment_Variables" rel="noreferrer" target="_blank">GODEBUG documentation</a>
for more details.</p>
<p>The new <a href="https://go.dev/pkg/runtime#SetDefaultGOMAXPROCS"><code>SetDefaultGOMAXPROCS</code></a> function sets <code>GOMAXPROCS</code> to the runtime
default value, as if the <code>GOMAXPROCS</code> environment variable is not set. This is
useful for enabling the <a href="#container-aware-gomaxprocs">new <code>GOMAXPROCS</code> default</a> if it has been
disabled by the <code>GOMAXPROCS</code> environment variable or a prior call to
<a href="https://go.dev/pkg/runtime#GOMAXPROCS"><code>GOMAXPROCS</code></a>.</p>
<h4 id="runtimepprofpkgruntimepprof"><a href="https://go.dev/pkg/runtime/pprof/"><code>runtime/pprof</code></a></h4>
<p>The mutex profile for contention on runtime-internal locks now correctly points
to the end of the critical section that caused the delay. This matches the
profile’s behavior for contention on <code>sync.Mutex</code> values. The
<code>runtimecontentionstacks</code> setting for <code>GODEBUG</code>, which allowed opting in to the
unusual behavior of Go 1.22 through 1.24 for this part of the profile, is now
gone.</p>
<h4 id="syncpkgsync"><a href="https://go.dev/pkg/sync/"><code>sync</code></a></h4>
<p>The new <a href="https://go.dev/pkg/sync#WaitGroup.Go"><code>WaitGroup.Go</code></a> method
makes the common pattern of creating and counting goroutines more convenient.</p>
<h4 id="testingpkgtesting"><a href="https://go.dev/pkg/testing/"><code>testing</code></a></h4>
<p>The new methods <a href="https://go.dev/pkg/testing#T.Attr"><code>T.Attr</code></a>, <a href="https://go.dev/pkg/testing#B.Attr"><code>B.Attr</code></a>, and <a href="https://go.dev/pkg/testing#F.Attr"><code>F.Attr</code></a> emit an
attribute to the test log. An attribute is an arbitrary
key and value associated with a test.</p>
<p>For example, in a test named <code>TestF</code>,
<code>t.Attr("key", "value")</code> emits:</p>
<pre><code>=== ATTR  TestF key value
</code></pre>
<p>With the <code>-json</code> flag, attributes appear as a new “attr” action.</p>
<!-- go.dev/issue/59928 -->
<p>The new <a href="https://go.dev/pkg/testing#T.Output"><code>Output</code></a> method of <a href="https://go.dev/pkg/testing#T"><code>T</code></a>, <a href="https://go.dev/pkg/testing#B"><code>B</code></a> and <a href="https://go.dev/pkg/testing#F"><code>F</code></a> provides an <a href="https://go.dev/pkg/io#Writer"><code>io.Writer</code></a>
that writes to the same test output stream as <a href="https://go.dev/pkg/testing#TB.Log"><code>TB.Log</code></a>.
Like <code>TB.Log</code>, the output is indented, but it does not include the file and line number.</p>
<!-- https://go.dev/issue/70464, CL 630137 -->
<p>The <a href="https://go.dev/pkg/testing#AllocsPerRun"><code>AllocsPerRun</code></a> function now panics
if parallel tests are running.
The result of <a href="https://go.dev/pkg/testing#AllocsPerRun"><code>AllocsPerRun</code></a> is inherently
flaky if other tests are running.
The new panicking behavior helps catch such bugs.</p>
<h4 id="testingfstestpkgtestingfstest"><a href="https://go.dev/pkg/testing/fstest/"><code>testing/fstest</code></a></h4>
<p><a href="https://go.dev/pkg/testing/fstest#MapFS"><code>MapFS</code></a> implements the new <a href="https://go.dev/pkg/io/fs#ReadLinkFS"><code>io/fs.ReadLinkFS</code></a> interface.
<a href="https://go.dev/pkg/testing/fstest#TestFS"><code>TestFS</code></a> will verify the functionality of the <a href="https://go.dev/pkg/io/fs#ReadLinkFS"><code>io/fs.ReadLinkFS</code></a> interface if implemented.
<a href="https://go.dev/pkg/testing/fstest#TestFS"><code>TestFS</code></a> will no longer follow symlinks to avoid unbounded recursion.</p>
<!-- #### [`testing/synctest`](/pkg/testing/synctest/) mentioned above -->
<h4 id="unicodepkgunicode"><a href="https://go.dev/pkg/unicode/"><code>unicode</code></a></h4>
<p>The new <a href="https://go.dev/pkg/unicode#CategoryAliases"><code>CategoryAliases</code></a> map provides access to category alias names, such as “Letter” for “L”.</p>
<p>The new categories <a href="https://go.dev/pkg/unicode#Cn"><code>Cn</code></a> and <a href="https://go.dev/pkg/unicode#LC"><code>LC</code></a> define unassigned codepoints and cased letters, respectively.
These have always been defined by Unicode but were inadvertently omitted in earlier versions of Go.
The <a href="https://go.dev/pkg/unicode#C"><code>C</code></a> category now includes <a href="https://go.dev/pkg/unicode#Cn"><code>Cn</code></a>, meaning it has added all unassigned code points.</p>
<h4 id="uniquepkgunique"><a href="https://go.dev/pkg/unique/"><code>unique</code></a></h4>
<p>The <a href="https://go.dev/pkg/unique"><code>unique</code></a> package now reclaims interned values more eagerly,
more efficiently, and in parallel. As a consequence, applications using
<a href="https://go.dev/pkg/unique#Make"><code>Make</code></a> are now less likely to experience memory blow-up when lots of
truly unique values are interned.</p>
<p>Values passed to <a href="https://go.dev/pkg/unique#Make"><code>Make</code></a> containing <a href="https://go.dev/pkg/unique#Handle"><code>Handle</code></a>s previously required multiple
garbage collection cycles to collect, proportional to the depth of the chain
of <a href="https://go.dev/pkg/unique#Handle"><code>Handle</code></a> values. Now, once
unused, they are collected promptly in a single cycle.</p>
<h2 id="ports">Ports</h2>
<h3 id="darwin">Darwin</h3>
<!-- go.dev/issue/69839 -->
<p>As <a href="https://go.dev/doc/go1.24#darwin">announced</a> in the Go 1.24 release notes, Go 1.25 requires macOS 12 Monterey or later.
Support for previous versions has been discontinued.</p>
<h3 id="windows">Windows</h3>
<!-- go.dev/issue/71671 -->
<p>Go 1.25 is the last release that contains the <a href="https://go.dev/doc/go1.24#windows">broken</a> 32-bit windows/arm port (<code>GOOS=windows</code> <code>GOARCH=arm</code>). It will be removed in Go 1.26.</p>
<h3 id="loong64">Loong64</h3>
<!-- CLs 533717, 533716, 543316, 604176 -->
<p>The linux/loong64 port now supports the race detector, gathering traceback information from C code
using <a href="https://go.dev/pkg/runtime#SetCgoTraceback"><code>runtime.SetCgoTraceback</code></a>, and linking cgo programs with the
internal link mode.</p>
<h3 id="risc-v">RISC-V</h3>
<!-- CL 420114 -->
<p>The linux/riscv64 port now supports the <code>plugin</code> build mode.</p>
<!-- https://go.dev/issue/61476, CL 633417 -->
<p>The <code>GORISCV64</code> environment variable now accepts a new value <code>rva23u64</code>,
which selects the RVA23U64 user-mode application profile.</p>
<!--
Output from relnote todo that was generated and reviewed on 2025-05-23, plus summary info from bug/CL: -->
<!-- Items that don't need to be mentioned in Go 1.25 release notes but are picked up by relnote todo
Just updating old prposals
accepted proposal https://go.dev/issue/30999 (from https://go.dev/cl/671795)
accepted proposal https://go.dev/issue/36532 (from https://go.dev/cl/647555)
accepted proposal https://go.dev/issue/48429 (from https://go.dev/cl/648577)
accepted proposal https://go.dev/issue/51572 (from https://go.dev/cl/651996)
accepted proposal https://go.dev/issue/51430 (from https://go.dev/cl/644997, https://go.dev/cl/646355)
accepted proposal https://go.dev/issue/60905 (from https://go.dev/cl/645795)
accepted proposal https://go.dev/issue/61716 (from https://go.dev/cl/644475)
accepted proposal https://go.dev/issue/64876 (from https://go.dev/cl/649435)
accepted proposal https://go.dev/issue/70123 (from https://go.dev/cl/657116)
accepted proposal https://go.dev/issue/61901 (from https://go.dev/cl/647875)
accepted proposal https://go.dev/issue/64207 (from https://go.dev/cl/647015, https://go.dev/cl/652235)
accepted proposal https://go.dev/issue/70200 (from https://go.dev/cl/674916)

For subrepos:
accepted proposal https://go.dev/issue/53757 (from https://go.dev/cl/644575)
accepted proposal https://go.dev/issue/54743 (from https://go.dev/cl/532415)
accepted proposal https://go.dev/issue/57792 (from https://go.dev/cl/649716, https://go.dev/cl/651737)
accepted proposal https://go.dev/issue/58523 (from https://go.dev/cl/538235)
accepted proposal https://go.dev/issue/61537 (from https://go.dev/cl/531935)
accepted proposal https://go.dev/issue/61940 (from https://go.dev/cl/650235)
accepted proposal https://go.dev/issue/67839 (from https://go.dev/cl/646535)
accepted proposal https://go.dev/issue/68780 (from https://go.dev/cl/659835)
accepted proposal https://go.dev/issue/69095 (from https://go.dev/cl/649320, https://go.dev/cl/649321, https://go.dev/cl/649337, https://go.dev/cl/649376, https://go.dev/cl/649377, https://go.dev/cl/649378, https://go.dev/cl/649379, https://go.dev/cl/649380, https://go.dev/cl/649397, https://go.dev/cl/649398, https://go.dev/cl/649419, https://go.dev/cl/649497, https://go.dev/cl/649498, https://go.dev/cl/649618, https://go.dev/cl/649675, https://go.dev/cl/649676, https://go.dev/cl/649677, https://go.dev/cl/649695, https://go.dev/cl/649696, https://go.dev/cl/649697, https://go.dev/cl/649698, https://go.dev/cl/649715, https://go.dev/cl/649717, https://go.dev/cl/649718, https://go.dev/cl/649755, https://go.dev/cl/649775, https://go.dev/cl/649795, https://go.dev/cl/649815, https://go.dev/cl/649835, https://go.dev/cl/651336, https://go.dev/cl/651736, https://go.dev/cl/651737, https://go.dev/cl/658018)
accepted proposal https://go.dev/issue/70859 (from https://go.dev/cl/666056, https://go.dev/cl/670835, https://go.dev/cl/672015, https://go.dev/cl/672016, https://go.dev/cl/672017)
accepted proposal https://go.dev/issue/32816 (from https://go.dev/cl/645155, https://go.dev/cl/645455, https://go.dev/cl/645955, https://go.dev/cl/646255, https://go.dev/cl/646455, https://go.dev/cl/646495, https://go.dev/cl/646655, https://go.dev/cl/646875, https://go.dev/cl/647298, https://go.dev/cl/647299, https://go.dev/cl/647736, https://go.dev/cl/648581, https://go.dev/cl/648715, https://go.dev/cl/648976, https://go.dev/cl/648995, https://go.dev/cl/649055, https://go.dev/cl/649056, https://go.dev/cl/649057, https://go.dev/cl/649456, https://go.dev/cl/649476, https://go.dev/cl/650755, https://go.dev/cl/651615, https://go.dev/cl/651617, https://go.dev/cl/651655, https://go.dev/cl/653436)
-->
</div>







</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Missing Protocol: Let Me Know (102 pts)]]></title>
            <link>https://deanebarker.net/tech/blog/let-me-know/</link>
            <guid>44881287</guid>
            <pubDate>Tue, 12 Aug 2025 20:15:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deanebarker.net/tech/blog/let-me-know/">https://deanebarker.net/tech/blog/let-me-know/</a>, See on <a href="https://news.ycombinator.com/item?id=44881287">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    


<hgroup>
  
  
</hgroup>



<header data-no-index="">
    
  

    
      
    
    
      
    
    <span>•</span>
  

  
    <span><time datetime="2025-08-05">August 5, 2025</time></span>
    <span>•</span>
  
  
  

</header>





    




    


    

    










<img src="https://deanebarker.net/tech/blog/images/lmk.png?w=400" loading="lazy">



<p>I want a new protocol, tentatively called “Let Me Know” (LMK). The purpose is to provide someone an anonymous way to get notified when a singular, specific event occurs.</p>
<p>Here’s a basic use case:</p>
<blockquote>
<p>Some random blog author has published Parts 1 and 2 of a series. You enjoyed it, and you want to know when Part 3 is published.</p>
<p>You don’t want to give away any personal information, you don’t want to subscribe to an RSS feed of other content, you don’t want to follow them on social media, etc. You just want an anonymous way to find out when Part 3 is published without having to manually check their website and evaluate it for the content.</p>
</blockquote>
<p>My idea is that there’s a button at the bottom of Part 2, called “Let Me Know.”</p>
<p>The user clicks this, and it registers an endpoint with some agent.</p>
<ul>
<li>The “endpoint” is a URL specific to that singular event.</li>
<li>An “agent” is a persistent background service of some kind that will check to see if this event has occurred. For example, a browser extension will add it to a “check list.” Alternately, some subscription service could add it to a list.</li>
</ul>
<p>Whatever agent registers the endpoint will ping the end point at a specific interval. Let’s say once per day by default.</p>
<p>The endpoint will often simply return:</p>
<pre><code>{
  "happened": false
}
</code></pre>
<p>Or:</p>
<pre><code>204 No Content
</code></pre>
<p>Either of those responses mean, “The subscribed event has not happened yet. Check back later.”</p>
<p>Alternately, the endpoint can advise the agent when to check again.</p>
<pre><code>{
  "happened": "false",
  "delay": 604800 // Don't check again for one week
}
</code></pre>
<p>Your agent will keep dutifully checking on its default schedule, or obeying the delay response if it’s provided.</p>
<p>But hopefully, on some bright shining day in the future, something like this will be returned:</p>
<pre><code>{
  "happened": true,
  "when": "2025-08-06T05:38:20.234Z",

  // This can be included in the notification
  "message": "Part 3 of the Awesome Blog Post Series has finally been published!",

  // The notification can provide one or more things to do from here
  "actions":
  [
    {
      "Read the post",
      "https://domain.com/part-3"
    },
    {
      "Visit the home page",
      "https://domain.com/"
    }
  ]
}
</code></pre>
<p>You will get this notification… somehow.</p>
<ul>
<li>If your agent is in a browser extension, you might get a pop-up.</li>
<li>If you agent is some subscription service, you might get an email.</li>
<li>If your agent is a mobile app, you might get a push notification.</li>
</ul>
<p>But <em>somehow</em>, you will be notified that the event – whatever the thing was you were waiting for – has occured.</p>








<picture><source srcset="https://deanebarker.net/tech/blog/images/lmk-alert.png?w=480" media="(max-width: 480px)"><img src="https://deanebarker.net/tech/blog/images/lmk-alert.png?w=500" loading="lazy" width="500" height="124"></picture>



<p>And then – and this is key – <em>the endpoint is automatically deleted from your agent</em>.</p>
<p>The event has happened, so the agent does not check again. The one task you assigned to it has been completed. If you want to find out about Part 4, you’ll subscribe (presumably) using a button at the bottom of Part 3. Or not. Whatever.</p>
<p>At any given time, you can review the endpoints registered in your agent, see when they were registered, when they were last checked, when they are scheduled to check again, force then to check again, etc. And you can delete any that you don’t really care about anymore.</p>
<p>As for the button that lets you subscribe to the event (which has now occurred), a few things could happen:</p>
<ol>
<li>The author could manually delete it.</li>
<li>If the endpoint architecture was built into their CMS, it could be automatically suppressed when the event happens (or, more likely, proactively display when the event hasn’t happened yet; default would be to not display).</li>
<li>The button could consist of some client-side code that would ping the endpoint itself and decide whether or not to display.</li>
</ol>
<p>If the button still shows up after the event has occured, it’s not that big of a deal. If an agent tries to register an endpoint for an event that has occured, the worst that could happen is that it notifies immediately. Alternately, the agent could detect this when it tries to register and notify the user that there’s no point in registering it and provide the actions from the response.</p>
<p>From the author’s standpoint, their CMS or other system could have an “LMK Control Panel” that would let them register new endpoints, manually resolve endpoints by providing messages and actions (they would “publish a resolution,” archive endpoints, get “ping analytics” of the traffic to specific endpoints, etc.</p>
<p>And… that’s it. That’s all it does.</p>
<p>You register an endpoint, the agent starts checking it, and then the agent lets you know when the endpoint returns in the affirmative.</p>
<p>You have never given anyone any personal information. Your agent checking the endpoint is as anonymous as you visiting the website. There is no commitment or cognitive overhead – you’re not exposed to a bunch of other events of content you don’t care about, and if the event never happens, you will never hear about it again.</p>
<p>There’s no AI to this. No magic. No problems to be solved. Like any standard or protocol, it’s just a matter of agreeing on it and evangelizing it.</p>
<p>But…</p>
<p>I showed this all to a friend, and he pointed out the “Subscribe” button “at the bottom of every YouTube video.”</p>
<p>I responded:</p>
<blockquote>
<p>Yeah, but I don’t want to “subscribe.” I just want to know when this ONE THING happens.</p>
<p>There might be 20 unrelated videos between the one I watched and the Part 2 that I want to see. Just yell when Part 2 is out, and then never talk to me again and forget we ever had this interaction, unless I subscribe to something else.</p>
</blockquote>
<p>And he responded with the cold, hard truth:</p>
<blockquote>
<p>That makes sense. I can understand why you’re asking for that, and can understand why creators would never want to build it</p>
</blockquote>
<p>…[sigh]. Yeah.</p>
<h2>Technical Postscript</h2>
<p>The only thing I might add is a <code>/meta</code> pseudo-endpoint that would provide data about the endpoint. It could return something like this:</p>
<pre><code>{
  "created": "2025-08-05",
  "purpose": "To notify when Part 2 of Awesome Blog Post Series is published"
  "contact": "deane@deanebarker.net &lt;Deane Barker&gt;",
  "happened": false // So the agent can filter for active events
}
</code></pre>
<p>Your agent could retrieve this when the endpoint is registered and use the data to maintain its list and give you more information about the endpoints you’re checking.</p>



<!--
<link rel="stylesheet" href="/assets/highlight/styles/base16/railscasts.min.css"/>
<script src="/assets/highlight/highlight.min.js"></script>
<script src="/assets/highlight/languages/javascript.min.js"></script>
<script src="/assets/highlight/languages/html.min.js"></script>
<script src="/assets/highlight/languages/css.min.js"></script>
<script src="/assets/highlight/languages/json.min.js"></script>

<script>document.addEventListener('DOMContentLoaded', (e) => { hljs.highlightAll(); });</script>
-->
<!-- 2025-08-05: I changed how this is managed. This code will gradually get removed from the site. -->




    



    

</article><p>
            This is item <strong>#2</strong> in a sequence of <strong>364</strong> items.
        </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ashet Home Computer (256 pts)]]></title>
            <link>https://ashet.computer/</link>
            <guid>44880401</guid>
            <pubDate>Tue, 12 Aug 2025 18:56:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ashet.computer/">https://ashet.computer/</a>, See on <a href="https://news.ycombinator.com/item?id=44880401">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    The Ashet Home Computer is an expandable and hackable computer in the spirit of the 80's home computers.

    Fully understandable by a single person, yet powerful enough to run a graphical desktop OS, it tries to bridge the gap between Arduinos and a RaspberryPi.

    It is designed and engineered for fun and learning, which go best hand in hand.
  </p><div><h2>Project Status &amp; Roadmap</h2><h3><img src="https://ashet.computer/img/check.svg"> Design</h3><p>The Ashet Home Computer has completed its design phase, and a practical, achievable hardware concept is now finalized.</p><p>There are still many smaller design components to be refined, but the overall concept is done.</p><p><em>Check out the <a href="https://ashet.computer/hardware/">hardware design</a> to learn more about the system.</em></p><h3><img src="https://ashet.computer/img/check.svg"> Prototyping</h3><p>A functional <em>cable clutter prototype</em> has been created which validates all of the design ideas.</p><p>This includes:</p><ul><li>PSRAM Support</li><li>DVI Video Generation</li><li>Backplane Communication</li><li>Expansion Card Drivers</li><li>Ethernet</li><li>I²C Subsystem</li></ul><p>Currently, the RP2350 processor successfully boots the operating system and supports launching desktop applications.</p><p>The mechanical design is also validated by building a mock-up of the final hardware and case assembly.</p><p><em>Check out the prototype images and videos in the <a href="https://ashet.computer/gallery/#home-computer-photo">gallery</a>!</em></p><h3><img src="https://ashet.computer/img/wrench-clock.svg"> Engineering</h3><p>The next stage after prototyping will be the actual engineering. This includes creating schematics, pcb layouts, evaluation of hardware limits and EMI emissions.</p><p>In this phase, the fully production-ready computer will be built.</p><p>To fund development for this critical next stage, we will launch a crowdfunding campaign on a platform such as Indiegogo or Kickstarter.</p><p><em>Subscribe to our <a href="https://buttondown.com/ashet.computer" target="_blank">newsletter</a> to get notified when the fundraiser starts!</em></p><h3><img src="https://ashet.computer/img/wrench-clock.svg"> Production &amp; Release</h3><p>In parallel to the engineering, a manufacturing partner must be found that will produce and distribute the Ashet Home Computer.</p><p>One of the goals is to make the computer available for 250€ or less, but if that’s possible depends on so many details that it’s hard to tell in the current phase.</p><p>No matter what’s the outcome of this phase, the whole computer design will be available for free under a <em>permissive&nbsp;licence</em> and can be built by everyone.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's get real about the one-person billion dollar company (115 pts)]]></title>
            <link>https://www.marcrand.com/p/lets-get-real-about-the-one-person</link>
            <guid>44879853</guid>
            <pubDate>Tue, 12 Aug 2025 18:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marcrand.com/p/lets-get-real-about-the-one-person">https://www.marcrand.com/p/lets-get-real-about-the-one-person</a>, See on <a href="https://news.ycombinator.com/item?id=44879853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>If you like this post, follow my journey on Twitter: </span><a href="https://x.com/random" rel="">https://x.com/random</a></em></p><div><p><strong>The biggest hurdle to the one-person billion dollar company is not AI capability, but founder pain tolerance.</strong><span> </span></p><p><span>Sam Altman is betting on it in his private group chats. </span></p></div><p>Dario Amodei predicted it'll happen in 2026.</p><p><span>These geniuses think the one-person billion dollar company is inevitable, and unicorn teams are getting smaller, but a </span><em>one</em><span> person? </span></p><p><span>That’s not going to </span><em>just happen</em><span>. </span></p><p>One person is an intentional choice by an individual with a particular set of skills.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!oTiq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!oTiq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!oTiq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!oTiq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!oTiq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!oTiq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!oTiq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!oTiq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!oTiq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!oTiq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb73c2878-8725-488c-8adb-6d1d6e0ee659_1536x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>It's Alex Honnold free-soloing El Capitan. </p><p>It's David Goggins running an ultramarathon on broken feet. </p><p><strong>The unicorn founders I know can’t even manage their email on their own, so who are we talking about here?</strong></p><p>The person likely closest to the milestone today is Heather Cox Richardson, who could easily replace her two copy editors with Claude.</p><p><span>Her newsletter reportedly brings in </span><a href="https://growthinreverse.com/heather-cox-richardson/" rel="">$12 million / year</a><span> and a revenue multiple of 2-4x typical for newsletters values her business at ~$50 million.</span></p><p>A far cry from 1 billion.</p><p>Touching that B will likely require an app with recurring revenue and network effects, that can justify higher revenue multiples.</p><p><strong>If it’s doable, it will probably be by:</strong></p><ol><li><p><strong>Someone with a Flappy Bird product that goes vertical and sells at the top, or</strong></p></li><li><p><strong>Someone with an Instagram product who both “calls their shot” from the beginning and has the desire + technical ability to follow through on it.</strong><span> </span></p></li></ol><p>Anything outside of consumer is highly unlikely. Enterprise money comes with enterprise headaches which will absolutely destroy a solo founder.</p><p><span>But let’s be honest:</span><br><strong><br><span>If you’re lucky enough to build something many people love, you’ll want to hire if for no other reason than to make the product as great as it can be.</span></strong></p><div><p><span>Maybe there’s a way to do it by only hiring agencies, which technically are a form of automation, but not in the spirit of Sam and Dario’s prediction.</span></p><p><span>Let’s see! The future is exciting 🚀</span></p></div><div><p>Subscribe for more thoughts on the one-person billion dollar company.</p></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[H-1B Visa Changes Approved by White House (150 pts)]]></title>
            <link>https://www.newsweek.com/h-1b-visas-changes-approved-white-house-report-2112216</link>
            <guid>44879746</guid>
            <pubDate>Tue, 12 Aug 2025 17:58:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newsweek.com/h-1b-visas-changes-approved-white-house-report-2112216">https://www.newsweek.com/h-1b-visas-changes-approved-white-house-report-2112216</a>, See on <a href="https://news.ycombinator.com/item?id=44879746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-system-main" data-gtm-action="Main_Page_Content"><div>
<article><div id="v_article">      <div><p>
By <span>
<span id="tooltip_reporter_0"><p>Robert Charles Alexander is the Senior Crime and Court Reporter for Newsweek based in London. He formerly worked as a Political Correspondent for the Local Democracy Service of the BBC, and is a lawyer. He is also&nbsp;the acclaimed author of seven published books, ranging from biographies to mountaineering and architectural history. His first book, The Inventor of Stereo – The Life and Works of Alan Dower Blumlein was dramatized for BBC Radio 4 in August 2008, and is now being turned into a major new movie for Universal Pictures Films.<br>He is currently working on his eighth, ninth and tenth books.&nbsp;You can get in touch with Robert by emailing r.alexnader<a href="mailto:j.doe@newsweek.com" data-mce-href="mailto:j.doe@newsweek.com">@newsweek.com</a>. Languages: English, French, German.&nbsp;</p>
</span>

</span></p><p>Senior Crime &amp; Court Reporter</p></div>  <div id="audio-player-container">
<p>🎙️ Voice is AI-generated. Inconsistencies may occur.</p>
</div>   <div><p>A proposed <a href="https://www.newsweek.com/topic/department-of-homeland-security" data-sys="1">Department of Homeland Security</a> rule that would alter how H-1B visas are allocated has cleared review by the White House's Office of Information and Regulatory Affairs (OIRA), according to <a href="https://www.newsweek.com/topic/bloomberg" data-sys="1">Bloomberg</a> Law.</p><p>Federal regulators cleared a proposed rule that would apply a "weighted selection process" by replacing the current random lottery with a new system that gives priority in the selection process to registrants who meet or exceed certain criteria, such as wage or education level.</p><p><em>Newsweek</em> reached out to the DHS and the OIRA for comment.</p><h2><strong>Why It Matters</strong></h2><p>The H-1B program supplies tens of thousands of specialty-occupation workers to U.S. employers each year and is heavily used by the technology sector. Any shift from a random lottery to a weighted, wage- or skill-based system could change hiring incentives for employers, affecting which foreign professionals obtain U.S. work authorization.</p><p>The H-1B cap of 85,000 slots annually influences employers' ability to hire specialized foreign workers in fields including engineering, computer science and business specialties. Any change to the selection criteria could incentivize employers to offer higher wages to improve odds in a weighted system or change recruitment strategies.</p><figure><div>
<picture width="1200" height="801"><source type="image/webp" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.webp?w=790&amp;f=955da3a9625d106150e455f9bb03a784 1x"><source type="image/jpeg" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.jpg?w=790&amp;f=955da3a9625d106150e455f9bb03a784 1x"><source type="image/webp" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.webp?w=900&amp;f=41d8895261eee6671df3b1a223ed5114 1x"><source type="image/jpeg" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.jpg?w=900&amp;f=41d8895261eee6671df3b1a223ed5114 1x"><source type="image/webp" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.webp?w=790&amp;f=955da3a9625d106150e455f9bb03a784 1x"><source type="image/jpeg" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.jpg?w=790&amp;f=955da3a9625d106150e455f9bb03a784 1x"><source type="image/webp" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.webp?w=450&amp;f=2d1bd07a49960f848b26ff750c6f9a1e 1x"><source type="image/jpeg" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.jpg?w=450&amp;f=2d1bd07a49960f848b26ff750c6f9a1e 1x"><source type="image/webp" srcset="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.webp?w=1200&amp;f=aeae525f1da5e1026bc4adee52906929"><img loading="lazy" id="i2701070" src="https://d.newsweek.com/en/full/2701070/h-1b-visa-stock-image.jpg?w=1200&amp;f=aeae525f1da5e1026bc4adee52906929" alt="H-1B visa stock image " width="1200" height="801"></picture></div><figcaption>
<span id="short-cap-description">Stock image of an H-1B visa.</span>

<span>Getty Images</span>
</figcaption>  </figure><h2><strong>What To Know</strong></h2><p>Federal review clearance by the OIRA typically preceded publication of a proposed rule in the Federal Register and a public comment period. The next step is a Federal Register publication, followed by a 30- to 60-day comment window and a multistep process before any final rule could take effect.</p><p>The proposed weighted-selection concept echoes a 2021 DHS plan under President <a href="https://www.newsweek.com/topic/donald-trump" data-sys="1">Donald Trump</a>'s first administration that had sought to rank and select petitions by wage tiers (OES wage levels IV down to I), an approach that the Trump administration argued would prioritize higher-paid, highly skilled hires. That earlier plan faced opposition, was withdrawn by the Biden administration and saw related regulations blocked in federal court.</p><p>The Institute for Progress, a nonpartisan think tank examining innovation policy, earlier this year suggested eliminating the H-1B lottery. It argued that the economic value of the visa program could be increased by 88 percent if applicants were evaluated based on seniority or salary.</p><p>The H-1B visa has come under increasing scrutiny since Trump assumed office in January, as the president's supporters have called into question the number of visas handed out to foreign nationals at what they claim is the expense of American workers. For example, <a href="https://www.newsweek.com/microsoft-layoffs-h1b-visa-applications-2094370" target="_blank" rel="noopener">Microsoft is under growing pressure</a> to account for its H-1B visa requests while the company has issued major layoffs in recent months.</p><p>The Washington-based tech giant applied for 9,491 H-1B visas during the last fiscal year, all of which were approved. The company has laid off nearly 16,000 people in total this year, out of a 228,000-strong global employee base.</p><h2><strong>What People Are Saying</strong></h2><p><strong>U.S. Citizenship and Immigration Services agency guidance, July 18, 2025:</strong> "USCIS has announced that it has received enough petitions to meet the congressionally mandated 65,000 H-1B visa regular cap and the 20,000 H-1B visa U.S. advanced degree exemption, also known as the master's cap, for fiscal year 2026."</p><p><strong>Immigration attorneys Fragomen LLP, in an August 11 article:</strong> "The next step for the proposal is publication in the Federal Register for public feedback."</p><h2><strong>What Happens Next</strong></h2><p>Industry advisers and regulatory watchers expected the administration to publish the proposed rule in the Federal Register, which would trigger a formal public comment period.</p><p>A proposed rule overhauling the allocation of H-1B visas for specialty occupation workers was approved by a key White House office, signaling it may be released publicly soon.</p>  </div></div>   <div data-pollid="7" data-articleid="2112216" data-gtm-category="FairnessMeter" data-gtmaction="original"><div><div>
<p><img src="https://g.newsweek.com/www/images/NW_ICON_CommonGround.png" alt="Newsweek Logo" width="92" height="113"></p><h2>fairness meter</h2><div><h2>fairness meter</h2><div><p>Newsweek is committed to journalism that's factual and fair.</p><p>Hold us accountable and submit your rating of this article on the meter. <a href="https://www.newsweek.com/fairness-meter" data-gtm-action="Fairness_Meter_original_Support_Page"><span></span></a></p></div></div></div><div><p>Newsweek is committed to journalism that's factual and fair.</p><p>Hold us accountable and submit your rating of this article on the meter. <a href="https://www.newsweek.com/fairness-meter" data-gtm-action="Fairness_Meter_original_Support_Page"><span></span></a></p></div></div><div>
<figure><p><span>Click On Meter </span><span>To Rate This Article</span></p>
</figure></div></div></article></div>     <div data-gtm-action="Top_Stories"><h2>
Top stories</h2></div><section data-gtm-action="About_The_Writer"><h3>About the writer</h3>
<span>
<span id="tooltip_reporter_0"><p>Robert Charles Alexander is the Senior Crime and Court Reporter for Newsweek based in London. He formerly worked as a Political Correspondent for the Local Democracy Service of the BBC, and is a lawyer. He is also&nbsp;the acclaimed author of seven published books, ranging from biographies to mountaineering and architectural history. His first book, The Inventor of Stereo – The Life and Works of Alan Dower Blumlein was dramatized for BBC Radio 4 in August 2008, and is now being turned into a major new movie for Universal Pictures Films.<br>He is currently working on his eighth, ninth and tenth books.&nbsp;You can get in touch with Robert by emailing r.alexnader<a href="mailto:j.doe@newsweek.com" data-mce-href="mailto:j.doe@newsweek.com">@newsweek.com</a>. Languages: English, French, German.&nbsp;</p>
</span>
<a href="javascript:void(0);" rel="author" data-id="reporter_0"> Robert Alexander </a>
</span>            
<p>
<span id="dots-description"><p>Robert Charles Alexander is the Senior Crime and Court Reporter for Newsweek based in London. He formerly worked as a                                    ...
<a onclick="toggleDescription()" id="read-more-btn">Read more</a>
</p></span></p>  </section>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is the A.I. Boom Turning Into an A.I. Bubble? (105 pts)]]></title>
            <link>https://www.newyorker.com/news/the-financial-page/is-the-ai-boom-turning-into-an-ai-bubble</link>
            <guid>44879373</guid>
            <pubDate>Tue, 12 Aug 2025 17:25:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/the-financial-page/is-the-ai-boom-turning-into-an-ai-bubble">https://www.newyorker.com/news/the-financial-page/is-the-ai-boom-turning-into-an-ai-bubble</a>, See on <a href="https://news.ycombinator.com/item?id=44879373">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="ArticlePageChunks"><figure data-testid="cne-audio-embed-figure"></figure><p>When <a href="https://www.newyorker.com/magazine/2023/12/04/how-jensen-huangs-nvidia-is-powering-the-ai-revolution">Jensen Huang</a>, the chief executive of the chipmaker Nvidia, met with <a href="https://www.newyorker.com/tag/donald-trump">Donald Trump</a> in the White House last week, he had reason to be cheerful. Most of Nvidia’s chips, which are widely used to train generative artificial-intelligence models, are manufactured in Asia. Earlier this year, it pledged to increase production in the United States, and on Wednesday Trump announced that chip companies that promise to build products in the United States would be exempt from some hefty new tariffs on semiconductors that his Administration is preparing to impose. The next day, Nvidia’s stock hit a new all-time high, and its market capitalization reached $4.4 trillion, making it the world’s most valuable company, ahead of Microsoft, which is also heavily involved in A.I.</p><p>Welcome to the A.I. boom, or should I say the A.I. bubble? It has been more than a quarter of a century since the bursting of the great dot-com bubble, during which hundreds of unprofitable internet startups issued stock on the Nasdaq, and the share prices of many tech companies rose into the stratosphere. In March and April of 2000, tech stocks plummeted; subsequently many, but by no means all, of the internet startups went out of business. There has been some discussion on Wall Street in the past few months about whether the current surge in tech is following a similar trajectory. In a <a data-offer-url="https://www.goldmansachs.com/pdfs/insights/goldman-sachs-research/25-years-on-lessons-from-the-bursting-of-the-tech-bubble/redaction.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.goldmansachs.com/pdfs/insights/goldman-sachs-research/25-years-on-lessons-from-the-bursting-of-the-tech-bubble/redaction.pdf&quot;}" href="https://www.goldmansachs.com/pdfs/insights/goldman-sachs-research/25-years-on-lessons-from-the-bursting-of-the-tech-bubble/redaction.pdf" rel="nofollow noopener" target="_blank">research paper</a> entitled “25 Years On; Lessons from the Bursting of the Technology Bubble,” which was published in March, a team of investment analysts from Goldman Sachs argued that it wasn’t: “While enthusiasm for technology stocks has risen sharply in recent years, this has not represented a bubble because the price appreciation has been justified by strong profit fundamentals.” The analysts pointed to the earnings power of the so-called Magnificent Seven companies: Alphabet, Amazon, Apple, Meta, Microsoft, Nvidia, and Tesla. Between the first quarter of 2022 and the first quarter of this year, Nvidia’s revenues quintupled, and its after-tax profits rose more than tenfold.</p><p>The Goldman paper also provided a salutary history lesson. Between 1995 and 2000, it pointed out, the tech-heavy Nasdaq index rose fivefold, and at the peak of the market a widely used valuation measure for the stocks that trade on it—the price-to-earnings ratio, or “P/E”—topped a hundred and fifty, a level not seen before or since then. By comparison, the five-year period from March, 2020, to March, 2025, had been relatively tame. It’s true, the Nasdaq had roughly doubled, and the P/E ratio had gone up considerably; but it hadn’t got anywhere near three figures.</p><p>Having written <a data-offer-url="https://www.amazon.com/Dot-America-Lost-Money-Internet/dp/0060008814" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Dot-America-Lost-Money-Internet/dp/0060008814&quot;}" href="https://www.amazon.com/Dot-America-Lost-Money-Internet/dp/0060008814" rel="nofollow noopener" target="_blank" data-aps-asin="0060008814" data-aps-asc-tag="">extensively</a> on the dot-com boom and bust, I found some of Goldman’s analysis persuasive. Many people have either forgotten, or are too young to remember, the extremes reached during the dot-com years. In the logic of speculative hysterias—from the seventeenth-century “tulipmania” in Holland to the rise of Pets.com—greed, <em>FOMO</em>, and the greater-fool theory of investing eventually combine to banish caution, common sense, and financial gravity. Back in March, there was plenty of <em>FOMO</em> and trend-following on Wall Street, but it hadn’t reached the levels of the late nineties. Five months on, however, echoes of the dot-com era are getting louder.</p><p>Consider Palantir Technologies, whose A.I. software is used by the Pentagon, the C.I.A., and <em>ICE</em>, not to mention by many commercial companies. A couple of days before Huang visited the White House, Palantir released a positive earnings report. By the end of the week, according to the Yahoo Finance database, the market was valuing the company at more than six hundred times its earnings from the past twelve months, and at about a hundred and thirty times its sales in that same time span. Even during the late nineties, figures like these would have raised eyebrows.</p><p>Eye-popping I.P.O.s, another feature of the dot-com era, are also making a comeback. At the end of July, Figma, a firm that makes software used by internet developers, and which has added A.I. features to its suite of products, issued stock on the New York Stock Exchange at thirty-three dollars a share. When trading started, the price jumped to eighty-five. It closed the day at $115.50—a two-hundred-and-fifty-per-cent gain on the offering price. Watching this market action, I was reminded of August 9, 1995, when Netscape, which made the Netscape Navigator web browser, went public. Its stock was priced at twenty-eight dollars, rose to seventy-five, and closed at $58.25. In percentage terms, this leap was smaller than the first-day rise in Figma’s stock, but it’s often described as the beginning of the dot-com bubble.</p><p>It should be noted that, since Figma’s I.P.O., its stock has fallen back to below eighty dollars. This could be interpreted as a sign of sanity prevailing, but, given that the shares are still trading at more than double the offering price, other privately owned A.I. companies will be encouraged to enter the stock market. Renaissance Capital, a research firm that specializes in I.P.O.s, lists eight prominent candidates: OpenAI, Anthropic, Cohere, Databricks, SymphonyAI, Waymo, Scale AI, and Perplexity. Almost all of these companies are unicorns: they have been valued at more than a billion dollars in fund-raising deals with venture capitalists and other early investors. But, across the country, according to the research firm Tracxn, there are about seven thousand smaller and lesser-known A.I. companies, more than a thousand of which have already received Series A funding from external backers to finance their operations.</p><p>The ready availability of early-stage funding means that a necessary condition for a dot-com-style bubble is in place. So are three more: excitement among investors about a pathbreaking technology—generative A.I. clearly has the potential to impact great swaths of the economy; a Wall Street production line staffed by investment bankers eager to earn fees for organizing I.P.O.s; and accommodative policy. Last month, the Trump Administration announced an “<a href="https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf">AI Action Plan</a>,” which aims to remove barriers to the deployment of the new technology and to deter individual states from introducing “burdensome” regulatory A.I. laws. The Federal Reserve, meanwhile, appears to be preparing to <a href="https://www.newyorker.com/news/the-financial-page/donald-trumps-war-with-jerome-powell-and-the-fed-is-far-from-over">cut interest rates</a> next month, which could give another boost to the markets.</p><p>There are, however, some important differences between now and the nineties, one of which is that the online economy is no longer a vast open plain on which enterprising individuals can propose to build castles to the sky. It is a redoubt of monopoly capitalism, in which Big Tech dominates the horizon. During the dot-com era, or its early stages, anyway, small startups could reasonably hope to exploit first-mover advantage, gain early traction, and create durable business franchises. In the A.I. economy, it seems possible that many of the rewards will go to top firms that can afford to build and maintain large A.I. models and can use their market power and financial might to ward off, or buy out, potential competitors. A vigorous antitrust policy could perhaps prevent this from happening, but, as the <em>Wall Street Journal</em> <a data-offer-url="https://www.wsj.com/us-news/law/maga-antitrust-agenda-under-siege-by-lobbyists-close-to-trump-18558898" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.wsj.com/us-news/law/maga-antitrust-agenda-under-siege-by-lobbyists-close-to-trump-18558898&quot;}" href="https://www.wsj.com/us-news/law/maga-antitrust-agenda-under-siege-by-lobbyists-close-to-trump-18558898" rel="nofollow noopener" target="_blank">reported</a> last week, the Administration’s pledge to pursue such a policy is now under threat from lobbyists and power brokers with close ties to the President. If investors decide that monopolies are the future of the A.I.-driven economy, the outcome in the stock market could well mean further gains for existing industry giants rather than a broad-based bubble.</p><p>All of this is uncertain, of course. The A.I. boom is still in the stage of building out infrastructure—training large language models, building data centers, and so on. A.I. applications are just beginning to diffuse throughout the economy, and nobody knows for sure just how transformative, and profitable, the technology will be. In this environment, many investors are following the time-honored gold-rush strategy of buying the shovel-makers and big mine owners. But history teaches us that even this strategy is far from risk-free. In an interesting analysis that was posted on the financial-news platform Seeking Alpha, an analyst identified as KCI Research compared Nvidia to Cisco Systems, one of the firms whose stock went parabolic in 1998-99. Just as Nvidia’s G.P.U.s (graphics-processing units) are now widely regarded as must-have components of A.I. infrastructure, Cisco’s routers and other network equipment were viewed as essential components of the internet build-out; for a time, demand for them seemed virtually unlimited. Like Nvidia, Cisco was an innovative and highly profitable company. But, in April of 2000, its stock dropped by almost forty per cent, and a year later it had fallen by about eighty per cent. A quarter of a century on, it still hasn’t recovered the high it hit in early 2000, although, lately, it has come close.</p><p>The Nvidia-Cisco comparison was a useful reminder of a dictum from the pioneering stock analyst Benjamin Graham, who was a mentor to Warren Buffett: in the short run, the stock market is a voting machine, but in the long run it is a weighing machine that weighs the cash flows that companies generate. Ironically, the Nvidia-Cisco analogy also inadvertently demonstrated how long the short run can last for, and how dangerous it can be to predict its end date. The analysis was posted in February of last year. Since then, Nvidia’s stock price has risen by another hundred and fifty per cent.&nbsp;♦</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude vs. Gemini: Testing on 1M Tokens of Context (141 pts)]]></title>
            <link>https://every.to/vibe-check/vibe-check-claude-sonnet-4-now-has-a-1-million-token-context-window</link>
            <guid>44878999</guid>
            <pubDate>Tue, 12 Aug 2025 16:59:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://every.to/vibe-check/vibe-check-claude-sonnet-4-now-has-a-1-million-token-context-window">https://every.to/vibe-check/vibe-check-claude-sonnet-4-now-has-a-1-million-token-context-window</a>, See on <a href="https://news.ycombinator.com/item?id=44878999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><a>
        <img src="https://every.to/assets/every-logo-white-d8b0c13c4b860174d4ac9717f446538ba8fa4f3b3736dde0de86e37bfc756789.svg" alt="Every">
      </a></p><h2>
       What Comes <span>N</span>ext
      </h2>
      <p>
        New ideas to help you build the future—in your inbox, every day.
      </p>
      
      <p>
        This site is protected by reCAPTCHA and the Google
        <a href="https://policies.google.com/privacy">Privacy Policy</a> and
        <a href="https://policies.google.com/terms">Terms of Service</a> apply.
      </p>
      <p><span>©2025 Every Media, Inc.</span>
    </p></div><p><span>©2025 Every Media, Inc.</span>
  </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WHY2025: How to become your own ISP [video] (161 pts)]]></title>
            <link>https://media.ccc.de/v/why2025-9-how-to-become-your-own-isp</link>
            <guid>44878916</guid>
            <pubDate>Tue, 12 Aug 2025 16:53:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/why2025-9-how-to-become-your-own-isp">https://media.ccc.de/v/why2025-9-how-to-become-your-own-isp</a>, See on <a href="https://news.ycombinator.com/item?id=44878916">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
<ol>
<li>
<a href="https://media.ccc.de/b">
browse
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/conferences">
conferences
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/conferences/camp-NL">
camp-NL
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/conferences/camp-NL/why2025">
why2025
</a>
</li>
<li>
<span></span>
event
</li>
</ol>
</div>

<main>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Nick+Bouwhuis">Nick Bouwhuis</a>

</p>

<a href="https://media.ccc.de/c/WHY2025/Brachium" rel="tag">Brachium</a>
<a href="https://media.ccc.de/c/WHY2025/Wonderful%20creations" rel="tag">Wonderful creations</a>
Playlists:
<a href="https://media.ccc.de/v/why2025-9-how-to-become-your-own-isp/playlist">'WHY2025' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/why2025-9-how-to-become-your-own-isp/audio">audio</a>

<!-- %h3 About -->
<p>This talk will take you along with a deep dive on how the internet works at its core and how you can participate yourself. You'll learn all about BGP, AS- numbers, IP-prefixes and more.</p>

<p>Ever wanted to become sovereign on the internet? Want to know what its like to run an ISP? Are you a sysadmin that wants to learn more about networking? Then you're at the right place.</p>

<p>This talk will take you along with a deep dive on how the internet works at its core and how you can participate yourself. You'll learn all about BGP, AS- numbers, IP-prefixes and what you need to do if you want to participate. You will walk away with practical knowledge on how you can get started. </p>

<p>We'll also take a short tour of my own network, how I set it up and what I use it for.</p>

<p>Licensed to the public under https://creativecommons.org/licenses/by/4.0/</p>

<h3>Download</h3>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</main>





</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Omnara – Run Claude Code from Anywhere (258 pts)]]></title>
            <link>https://github.com/omnara-ai/omnara</link>
            <guid>44878650</guid>
            <pubDate>Tue, 12 Aug 2025 16:33:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/omnara-ai/omnara">https://github.com/omnara-ai/omnara</a>, See on <a href="https://news.ycombinator.com/item?id=44878650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Omnara - Mission Control for Your AI Agents 🚀</h2><a id="user-content-omnara---mission-control-for-your-ai-agents-" aria-label="Permalink: Omnara - Mission Control for Your AI Agents 🚀" href="#omnara---mission-control-for-your-ai-agents-"></a></p>
<p dir="auto"><strong>Your AI workforce launchpad, in your pocket.</strong></p>
<p dir="auto"><a href="https://badge.fury.io/py/omnara" rel="nofollow"><img src="https://camo.githubusercontent.com/4e9f14c1aac8602c0a5034778f609314d70f54cb7541229060d5d60d870d919f/68747470733a2f2f62616467652e667572792e696f2f70792f6f6d6e6172612e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/omnara.svg"></a>
<a href="https://pepy.tech/project/omnara" rel="nofollow"><img src="https://camo.githubusercontent.com/b1a6283158a416f2cbb8e0b6c827c299fc90cc79a0db9e49794df703ab4c9397/68747470733a2f2f706570792e746563682f62616467652f6f6d6e617261" alt="Downloads" data-canonical-src="https://pepy.tech/badge/omnara"></a>
<a href="https://pypi.org/project/omnara/" rel="nofollow"><img src="https://camo.githubusercontent.com/f26a090cb9637e79f33aa901f555c51112f59499cb33499162b774fe8e2fc0af/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6f6d6e6172612e737667" alt="Python Versions" data-canonical-src="https://img.shields.io/pypi/pyversions/omnara.svg"></a>
<a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"><img src="https://camo.githubusercontent.com/5ce2e21e84680df1ab24807babebc3417d27d66e0826a350eb04ab57f4c8f3e5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368655f322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache_2.0-blue.svg"></a>
<a href="https://github.com/omnara-ai/omnara"><img src="https://camo.githubusercontent.com/616c2bbd8593ee60f04a41c8c44e87113b33eab0839196d0caa2eb7d85767d92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6d6e6172612d61692f6f6d6e6172613f7374796c653d736f6369616c" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/omnara-ai/omnara?style=social"></a>
<a href="https://github.com/astral-sh/ruff"><img src="https://camo.githubusercontent.com/051a04ae958f4a1a5d6444df4cdc520305eef93d5028e6d4c7cd16efa3136cd4/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f75726c3d68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f61737472616c2d73682f727566662f6d61696e2f6173736574732f62616467652f76322e6a736f6e" alt="Ruff" data-canonical-src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/omnara-ai/omnara/blob/main/docs/assets/three-panel.png"><img src="https://github.com/omnara-ai/omnara/raw/main/docs/assets/three-panel.png" alt="Omnara Mobile Experience"></a></p>

<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 What is Omnara?</h2><a id="user-content--what-is-omnara" aria-label="Permalink: 🚀 What is Omnara?" href="#-what-is-omnara"></a></p>
<p dir="auto">Omnara transforms your AI agents (Claude Code, Cursor, GitHub Copilot, and more) from silent workers into communicative teammates. Get real-time visibility into what your agents are doing, respond to their questions instantly, and guide them to success - all from your phone.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">✨ Key Features</h3><a id="user-content--key-features" aria-label="Permalink: ✨ Key Features" href="#-key-features"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>📊 Real-Time Monitoring</strong></td>
<td>See every step your AI agents take as they work</td>
</tr>
<tr>
<td><strong>💬 Interactive Q&amp;A</strong></td>
<td>Respond instantly when agents need guidance</td>
</tr>
<tr>
<td><strong>📱 Mobile-First Design</strong></td>
<td>Full control from your phone, tablet, or desktop</td>
</tr>
<tr>
<td><strong>🔔 Smart Notifications</strong></td>
<td>Get alerted only when your input is needed</td>
</tr>
<tr>
<td><strong>🎯 Universal Dashboard</strong></td>
<td>All your AI agents in one unified interface</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">🎬 See It In Action</h3><a id="user-content--see-it-in-action" aria-label="Permalink: 🎬 See It In Action" href="#-see-it-in-action"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/omnara-ai/omnara/blob/main/docs/assets/iNotifications-Stack.gif"><img src="https://github.com/omnara-ai/omnara/raw/main/docs/assets/iNotifications-Stack.gif" alt="Mobile Notifications" data-animated-image=""></a></p>
<blockquote>
<p dir="auto"><em>The moment your agent needs help, you're there. No more returning to failed jobs hours later.</em></p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/omnara-ai/omnara/blob/main/docs/assets/Mobile-app-showcase.gif"><img src="https://github.com/omnara-ai/omnara/raw/main/docs/assets/Mobile-app-showcase.gif" alt="Agent Activity Feed" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">💡 Why Omnara?</h2><a id="user-content--why-omnara" aria-label="Permalink: 💡 Why Omnara?" href="#-why-omnara"></a></p>
<p dir="auto">We built Omnara because we were tired of:</p>
<ul dir="auto">
<li>❌ Starting long agent jobs and finding them stuck hours later</li>
<li>❌ Missing critical questions that blocked progress</li>
<li>❌ Having no visibility into what our AI was actually doing</li>
<li>❌ Being tied to our desks while agents worked</li>
</ul>
<p dir="auto"><strong>Now you can:</strong></p>
<ul dir="auto">
<li>✅ Launch agents and monitor them from anywhere</li>
<li>✅ Get push notifications when input is needed</li>
<li>✅ Send real-time feedback to guide your agents</li>
<li>✅ Have confidence your AI workforce is productive</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Real-World Use Cases</h2><a id="user-content--real-world-use-cases" aria-label="Permalink: 🎯 Real-World Use Cases" href="#-real-world-use-cases"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔍 <strong>Code Review Assistant</strong></h3><a id="user-content--code-review-assistant" aria-label="Permalink: 🔍 Code Review Assistant" href="#-code-review-assistant"></a></p>
<p dir="auto">Launch Claude to review PRs while you're at lunch. Get notified only if it needs clarification on architectural decisions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🚨 <strong>Production Firefighter</strong></h3><a id="user-content--production-firefighter" aria-label="Permalink: 🚨 Production Firefighter" href="#-production-firefighter"></a></p>
<p dir="auto">Debug production issues from your phone at 2am. See exactly what your agent is investigating and guide it to the right logs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📊 <strong>Data Pipeline Guardian</strong></h3><a id="user-content--data-pipeline-guardian" aria-label="Permalink: 📊 Data Pipeline Guardian" href="#-data-pipeline-guardian"></a></p>
<p dir="auto">Start a 6-hour data migration before leaving work. Get alerts if anything looks suspicious, approve schema changes on the go.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🏗️ <strong>Refactoring Copilot</strong></h3><a id="user-content-️-refactoring-copilot" aria-label="Permalink: 🏗️ Refactoring Copilot" href="#️-refactoring-copilot"></a></p>
<p dir="auto">Let Claude refactor that legacy module while you're in meetings. Answer its questions about business logic without context switching.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🧪 <strong>Test Suite Doctor</strong></h3><a id="user-content--test-suite-doctor" aria-label="Permalink: 🧪 Test Suite Doctor" href="#-test-suite-doctor"></a></p>
<p dir="auto">Have Claude fix failing tests overnight. Wake up to either green builds or specific questions about expected behavior.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Architecture Overview</h2><a id="user-content-️-architecture-overview" aria-label="Permalink: 🏗️ Architecture Overview" href="#️-architecture-overview"></a></p>
<p dir="auto">Omnara provides a unified platform for monitoring and controlling your AI agents:</p>
<section data-identity="a42a6243-d3d4-49ce-b2c7-b23ca2d94e54" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;graph TB\n    subgraph \&quot;Your AI Agents\&quot;\n        A[🤖 AI Agents&amp;lt;br/&amp;gt;Claude Code, Cursor, etc.]\n    end\n\n    subgraph \&quot;Omnara Platform\&quot;\n        API[🌐 API Server]\n        DB[(📊 PostgreSQL)]\n        NOTIFY[🔔 Notification Service&amp;lt;br/&amp;gt;Push/Email/SMS]\n    end\n\n    subgraph \&quot;Your Devices\&quot;\n        M[📱 Mobile App]\n        W[💻 Web Dashboard]\n    end\n\n    A --&amp;gt;|Send updates| API\n    API --&amp;gt;|Store data| DB\n    API --&amp;gt;|Trigger notifications| NOTIFY\n    NOTIFY --&amp;gt;|Alert users| M\n    DB --&amp;gt;|Real-time sync| M\n    DB --&amp;gt;|Real-time sync| W\n    M --&amp;gt;|User responses| API\n    W --&amp;gt;|User responses| API\n    API --&amp;gt;|Deliver feedback| A\n\n    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    style API fill:#c8e6c9,stroke:#388e3c,stroke-width:2px\n    style DB fill:#ffccbc,stroke:#d84315,stroke-width:2px\n    style NOTIFY fill:#fff59d,stroke:#f57f17,stroke-width:2px\n    style M fill:#f8bbd0,stroke:#c2185b,stroke-width:3px\n    style W fill:#f8bbd0,stroke:#c2185b,stroke-width:3px\n&quot;}" data-plain="graph TB
    subgraph &quot;Your AI Agents&quot;
        A[🤖 AI Agents<br/>Claude Code, Cursor, etc.]
    end

    subgraph &quot;Omnara Platform&quot;
        API[🌐 API Server]
        DB[(📊 PostgreSQL)]
        NOTIFY[🔔 Notification Service<br/>Push/Email/SMS]
    end

    subgraph &quot;Your Devices&quot;
        M[📱 Mobile App]
        W[💻 Web Dashboard]
    end

    A -->|Send updates| API
    API -->|Store data| DB
    API -->|Trigger notifications| NOTIFY
    NOTIFY -->|Alert users| M
    DB -->|Real-time sync| M
    DB -->|Real-time sync| W
    M -->|User responses| API
    W -->|User responses| API
    API -->|Deliver feedback| A

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style API fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    style DB fill:#ffccbc,stroke:#d84315,stroke-width:2px
    style NOTIFY fill:#fff59d,stroke:#f57f17,stroke-width:2px
    style M fill:#f8bbd0,stroke:#c2185b,stroke-width:3px
    style W fill:#f8bbd0,stroke:#c2185b,stroke-width:3px
">
      <pre lang="mermaid" aria-label="Raw mermaid code">graph TB
    subgraph "Your AI Agents"
        A[🤖 AI Agents&lt;br/&gt;Claude Code, Cursor, etc.]
    end

    subgraph "Omnara Platform"
        API[🌐 API Server]
        DB[(📊 PostgreSQL)]
        NOTIFY[🔔 Notification Service&lt;br/&gt;Push/Email/SMS]
    end

    subgraph "Your Devices"
        M[📱 Mobile App]
        W[💻 Web Dashboard]
    end

    A --&gt;|Send updates| API
    API --&gt;|Store data| DB
    API --&gt;|Trigger notifications| NOTIFY
    NOTIFY --&gt;|Alert users| M
    DB --&gt;|Real-time sync| M
    DB --&gt;|Real-time sync| W
    M --&gt;|User responses| API
    W --&gt;|User responses| API
    API --&gt;|Deliver feedback| A

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style API fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    style DB fill:#ffccbc,stroke:#d84315,stroke-width:2px
    style NOTIFY fill:#fff59d,stroke:#f57f17,stroke-width:2px
    style M fill:#f8bbd0,stroke:#c2185b,stroke-width:3px
    style W fill:#f8bbd0,stroke:#c2185b,stroke-width:3px
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h3 tabindex="-1" dir="auto">🚀 How It Works</h3><a id="user-content--how-it-works" aria-label="Permalink: 🚀 How It Works" href="#-how-it-works"></a></p>
<p dir="auto"><strong>1. Connect Your Agent</strong> → Install Omnara SDK or wrapper<br>
<strong>2. Get Real-Time Updates</strong> → See every step your agent takes<br>
<strong>3. Respond Instantly</strong> → Answer questions from anywhere</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔄 Two Ways to Use Omnara</h3><a id="user-content--two-ways-to-use-omnara" aria-label="Permalink: 🔄 Two Ways to Use Omnara" href="#-two-ways-to-use-omnara"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Mode</th>
<th>Setup</th>
<th>How It Works</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Real-Time Monitoring</strong></td>
<td><code>omnara</code> or <code>uv run omnara</code></td>
<td>Monitor your Claude session, forwards to Omnara</td>
</tr>
<tr>
<td><strong>Remote Launch</strong></td>
<td><code>omnara serve</code> or <code>uv run omnara serve</code></td>
<td>Launch agents from phone, communicate via MCP</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔧 Technical Stack</h3><a id="user-content--technical-stack" aria-label="Permalink: 🔧 Technical Stack" href="#-technical-stack"></a></p>
<ul dir="auto">
<li><strong>Backend</strong>: FastAPI with separate read/write servers for optimal performance</li>
<li><strong>Frontend</strong>: React (Web) + React Native (Mobile)</li>
<li><strong>Protocol</strong>: Model Context Protocol (MCP) + REST API</li>
<li><strong>Database</strong>: PostgreSQL with SQLAlchemy ORM</li>
<li><strong>Auth</strong>: Dual JWT system (Supabase for users, custom for agents)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Monitor Your Claude Sessions</h3><a id="user-content-option-1-monitor-your-claude-sessions" aria-label="Permalink: Option 1: Monitor Your Claude Sessions" href="#option-1-monitor-your-claude-sessions"></a></p>
<p dir="auto">See what Claude is doing in real-time:</p>
<ol dir="auto">
<li><strong>Install Omnara</strong>:
<div dir="auto" data-snippet-clipboard-copy-content="# Using pip
pip install omnara

# Using uv (faster)
uv pip install omnara"><pre><span><span>#</span> Using pip</span>
pip install omnara

<span><span>#</span> Using uv (faster)</span>
uv pip install omnara</pre></div>
</li>
<li><strong>Start monitoring</strong>:
<div dir="auto" data-snippet-clipboard-copy-content="# If installed with pip
omnara

# If installed with uv
uv run omnara"><pre><span><span>#</span> If installed with pip</span>
omnara

<span><span>#</span> If installed with uv</span>
uv run omnara</pre></div>
</li>
<li><strong>Authenticate</strong> in your browser (opens automatically)</li>
<li><strong>See everything</strong> your agent does in the Omnara dashboard!</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Launch Agents Remotely</h3><a id="user-content-option-2-launch-agents-remotely" aria-label="Permalink: Option 2: Launch Agents Remotely" href="#option-2-launch-agents-remotely"></a></p>
<p dir="auto">Trigger Claude from your phone:</p>
<ol dir="auto">
<li><strong>Start the server</strong> on your computer:
<div dir="auto" data-snippet-clipboard-copy-content="# Using pip
pip install omnara
omnara serve

# Using uv (faster)
uv pip install omnara
uv run omnara serve"><pre><span><span>#</span> Using pip</span>
pip install omnara
omnara serve

<span><span>#</span> Using uv (faster)</span>
uv pip install omnara
uv run omnara serve</pre></div>
</li>
<li><strong>Set up your agent</strong> in the mobile app with the webhook URL shown</li>
<li><strong>Launch agents</strong> from anywhere - beach, coffee shop, bed!</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">For Developers</h3><a id="user-content-for-developers" aria-label="Permalink: For Developers" href="#for-developers"></a></p>
<details>
<summary><b>🛠️ Development Setup</b></summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisites</h4><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Python 3.10+</li>
<li>PostgreSQL</li>
<li>Node.js (for CLI tools)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Setup Steps</h4><a id="user-content-setup-steps" aria-label="Permalink: Setup Steps" href="#setup-steps"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Clone and enter the repository</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/omnara-ai/omnara
cd omnara"><pre>git clone https://github.com/omnara-ai/omnara
<span>cd</span> omnara</pre></div>
</li>
<li>
<p dir="auto"><strong>Set up Python environment</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
make dev-install"><pre>python -m venv .venv
<span>source</span> .venv/bin/activate  <span><span>#</span> Windows: .venv\Scripts\activate</span>
make dev-install</pre></div>
</li>
<li>
<p dir="auto"><strong>Generate JWT keys</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/generate_jwt_keys.py"><pre>python scripts/generate_jwt_keys.py</pre></div>
</li>
<li>
<p dir="auto"><strong>Configure environment</strong> (create <code>.env</code> file)</p>
<div dir="auto" data-snippet-clipboard-copy-content="DATABASE_URL=postgresql://user:password@localhost:5432/omnara
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
JWT_PRIVATE_KEY='-----BEGIN RSA PRIVATE KEY-----\n...'
JWT_PUBLIC_KEY='-----BEGIN PUBLIC KEY-----\n...'"><pre><span>DATABASE_URL</span><span>=</span><span>postgresql://user:password@localhost:5432/omnara</span>
<span>SUPABASE_URL</span><span>=</span><span>https://your-project.supabase.co</span>
<span>SUPABASE_ANON_KEY</span><span>=</span><span>your-anon-key</span>
<span>JWT_PRIVATE_KEY</span><span>=</span><span><span>'</span>-----BEGIN RSA PRIVATE KEY-----\n...<span>'</span></span>
<span>JWT_PUBLIC_KEY</span><span>=</span><span><span>'</span>-----BEGIN PUBLIC KEY-----\n...<span>'</span></span></pre></div>
</li>
<li>
<p dir="auto"><strong>Initialize database</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd shared/
alembic upgrade head
cd .."><pre><span>cd</span> shared/
alembic upgrade head
<span>cd</span> ..</pre></div>
</li>
<li>
<p dir="auto"><strong>Run services</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Terminal 1: MCP + REST Server
python -m servers.app

# Terminal 2: Backend API
cd backend &amp;&amp; python -m main"><pre><span><span>#</span> Terminal 1: MCP + REST Server</span>
python -m servers.app

<span><span>#</span> Terminal 2: Backend API</span>
<span>cd</span> backend <span>&amp;&amp;</span> python -m main</pre></div>
</li>
</ol>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Advanced Usage (Without CLI)</h2><a id="user-content--advanced-usage-without-cli" aria-label="Permalink: 🔧 Advanced Usage (Without CLI)" href="#-advanced-usage-without-cli"></a></p>
<blockquote>
<p dir="auto"><strong>Note</strong>: Most users should use the simple <code>omnara</code> or <code>omnara serve</code> commands shown above. These methods are for advanced users who need custom integrations or want to run the underlying scripts directly.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 1: Direct Wrapper Script</h3><a id="user-content-method-1-direct-wrapper-script" aria-label="Permalink: Method 1: Direct Wrapper Script" href="#method-1-direct-wrapper-script"></a></p>
<p dir="auto">Run the monitoring wrapper directly (what <code>omnara</code> does under the hood):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Basic usage
python -m webhooks.claude_wrapper_v3 --api-key YOUR_API_KEY

# With git diff tracking
python -m webhooks.claude_wrapper_v3 --api-key YOUR_API_KEY --git-diff

# Custom API endpoint (for self-hosted)
python -m webhooks.claude_wrapper_v3 --api-key YOUR_API_KEY --base-url https://your-server.com"><pre><span><span>#</span> Basic usage</span>
python -m webhooks.claude_wrapper_v3 --api-key YOUR_API_KEY

<span><span>#</span> With git diff tracking</span>
python -m webhooks.claude_wrapper_v3 --api-key YOUR_API_KEY --git-diff

<span><span>#</span> Custom API endpoint (for self-hosted)</span>
python -m webhooks.claude_wrapper_v3 --api-key YOUR_API_KEY --base-url https://your-server.com</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 2: Manual MCP Configuration</h3><a id="user-content-method-2-manual-mcp-configuration" aria-label="Permalink: Method 2: Manual MCP Configuration" href="#method-2-manual-mcp-configuration"></a></p>
<p dir="auto">For custom MCP setups, you can configure manually:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;mcpServers&quot;: {
    &quot;omnara&quot;: {
      &quot;command&quot;: &quot;pipx&quot;,
      &quot;args&quot;: [&quot;run&quot;, &quot;--no-cache&quot;, &quot;omnara&quot;, &quot;mcp&quot;, &quot;--api-key&quot;, &quot;YOUR_API_KEY&quot;]
    }
  }
}"><pre>{
  <span>"mcpServers"</span>: {
    <span>"omnara"</span>: {
      <span>"command"</span>: <span><span>"</span>pipx<span>"</span></span>,
      <span>"args"</span>: [<span><span>"</span>run<span>"</span></span>, <span><span>"</span>--no-cache<span>"</span></span>, <span><span>"</span>omnara<span>"</span></span>, <span><span>"</span>mcp<span>"</span></span>, <span><span>"</span>--api-key<span>"</span></span>, <span><span>"</span>YOUR_API_KEY<span>"</span></span>]
    }
  }
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 3: Python SDK</h3><a id="user-content-method-3-python-sdk" aria-label="Permalink: Method 3: Python SDK" href="#method-3-python-sdk"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from omnara import OmnaraClient
import uuid

client = OmnaraClient(api_key=&quot;your-api-key&quot;)
instance_id = str(uuid.uuid4())

# Log progress and check for user feedback
response = client.send_message(
    agent_type=&quot;claude-code&quot;,
    content=&quot;Analyzing codebase structure&quot;,
    agent_instance_id=instance_id,
    requires_user_input=False
)

# Ask for user input when needed
answer = client.send_message(
    content=&quot;Should I refactor this legacy module?&quot;,
    agent_instance_id=instance_id,
    requires_user_input=True
)"><pre><span>from</span> <span>omnara</span> <span>import</span> <span>OmnaraClient</span>
<span>import</span> <span>uuid</span>

<span>client</span> <span>=</span> <span>OmnaraClient</span>(<span>api_key</span><span>=</span><span>"your-api-key"</span>)
<span>instance_id</span> <span>=</span> <span>str</span>(<span>uuid</span>.<span>uuid4</span>())

<span># Log progress and check for user feedback</span>
<span>response</span> <span>=</span> <span>client</span>.<span>send_message</span>(
    <span>agent_type</span><span>=</span><span>"claude-code"</span>,
    <span>content</span><span>=</span><span>"Analyzing codebase structure"</span>,
    <span>agent_instance_id</span><span>=</span><span>instance_id</span>,
    <span>requires_user_input</span><span>=</span><span>False</span>
)

<span># Ask for user input when needed</span>
<span>answer</span> <span>=</span> <span>client</span>.<span>send_message</span>(
    <span>content</span><span>=</span><span>"Should I refactor this legacy module?"</span>,
    <span>agent_instance_id</span><span>=</span><span>instance_id</span>,
    <span>requires_user_input</span><span>=</span><span>True</span>
)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 4: REST API</h3><a id="user-content-method-4-rest-api" aria-label="Permalink: Method 4: REST API" href="#method-4-rest-api"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -X POST https://api.omnara.ai/api/v1/messages/agent \
  -H &quot;Authorization: Bearer YOUR_API_KEY&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d '{&quot;content&quot;: &quot;Starting deployment process&quot;, &quot;agent_type&quot;: &quot;claude-code&quot;, &quot;requires_user_input&quot;: false}'"><pre>curl -X POST https://api.omnara.ai/api/v1/messages/agent \
  -H <span><span>"</span>Authorization: Bearer YOUR_API_KEY<span>"</span></span> \
  -H <span><span>"</span>Content-Type: application/json<span>"</span></span> \
  -d <span><span>'</span>{"content": "Starting deployment process", "agent_type": "claude-code", "requires_user_input": false}<span>'</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">We love contributions! Check out our <a href="https://github.com/omnara-ai/omnara/blob/main/CONTRIBUTING.md">Contributing Guide</a> to get started.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development Commands</h3><a id="user-content-development-commands" aria-label="Permalink: Development Commands" href="#development-commands"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="make lint       # Run code quality checks
make format     # Auto-format code
make test       # Run test suite
make dev-serve  # Start development servers"><pre>make lint       <span><span>#</span> Run code quality checks</span>
make format     <span><span>#</span> Auto-format code</span>
make <span>test</span>       <span><span>#</span> Run test suite</span>
make dev-serve  <span><span>#</span> Start development servers</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Pricing</h2><a id="user-content--pricing" aria-label="Permalink: 📊 Pricing" href="#-pricing"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Price</th>
<th>Features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Free</strong></td>
<td>$0/mo</td>
<td>10 agents/month, Core features</td>
</tr>
<tr>
<td><strong>Pro</strong></td>
<td>$9/mo</td>
<td>Unlimited agents, Priority support</td>
</tr>
<tr>
<td><strong>Enterprise</strong></td>
<td><a href="https://cal.com/ishaan-sehgal-8kc22w/omnara-demo" rel="nofollow">Contact Us</a></td>
<td>Teams, SSO, Custom integrations</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">🆘 Support</h2><a id="user-content--support" aria-label="Permalink: 🆘 Support" href="#-support"></a></p>
<ul dir="auto">
<li>📖 <a href="https://docs.omnara.ai/" rel="nofollow">Documentation</a></li>
<li>💬 <a href="https://github.com/omnara-ai/omnara/discussions">GitHub Discussions</a></li>
<li>🐛 <a href="https://github.com/omnara-ai/omnara/issues">Report Issues</a></li>
<li>📧 <a href="mailto:ishaan@omnara.com">Email Support</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📜 License</h2><a id="user-content--license" aria-label="Permalink: 📜 License" href="#-license"></a></p>
<p dir="auto">Omnara is open source software licensed under the <a href="https://github.com/omnara-ai/omnara/blob/main/LICENSE">Apache 2.0 License</a>.</p>
<hr>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Building a web search engine from scratch with 3B neural embeddings (486 pts)]]></title>
            <link>https://blog.wilsonl.in/search-engine/</link>
            <guid>44878151</guid>
            <pubDate>Tue, 12 Aug 2025 16:02:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.wilsonl.in/search-engine/">https://blog.wilsonl.in/search-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=44878151">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><header><p><time datetime="2025-08-10T00:00:00.000Z">Published August 10, 2025</time><span>34 min read</span></p></header>
<a href="https://blog.wilsonl.in/search-engine/serp-rocksdb.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-rocksdb.png" alt="Screenshot of SERP."></a>
<p>A while back, I decided to undertake a project to challenge myself: build a web search engine from scratch. Aside from the fun deep dive opportunity, there were two motivators:</p>
<ul>
<li>Search engines seemed to be getting worse, with more SEO spam and less relevant quality content.</li>
<li>Transformer-based <a href="https://huggingface.co/spaces/mteb/leaderboard" target="_blank" rel="noopener">text embedding models</a> were taking off and showing amazing natural comprehension of language.</li>
</ul>
<p>A simple question I had was: why couldn't a search engine <em>always</em> result in top quality content? Such content may be rare, but the Internet's <a href="https://en.wikipedia.org/wiki/Long_tail" target="_blank" rel="noopener">tail is long</a>, and better quality results should rank higher than the prolific inorganic content and engagement bait you see today.</p>
<p>Another pain point was that search engines often felt underpowered, closer to keyword matching than human-level intelligence. A reasonably complex or subtle query couldn't be answered by most search engines at all, but the ability to would be powerful:</p>
<a href="https://blog.wilsonl.in/search-engine/serp-paragraph-cropped.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-paragraph-cropped.png" alt="SERP result of paragraph-length query."></a>
<p>Search engines cover broad areas of computer science, linguistics, ontology, NLP, ML, distributed systems, performance engineering, and so on. I thought it'd be interesting to see how much I could learn and cover in a short period. Plus, it'd be cool to have my own search engine. Given all these points, I dived right in.</p>
<p>In this post, I go over the 2-month journey end-to-end, starting from no infra, bootstrapped data, or any experience around building a web search engine. Some highlights:</p>
<ul>
<li>A cluster of 200 GPUs generated a combined 3 billion <a href="https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1" target="_blank" rel="noopener">SBERT</a> embeddings.</li>
<li>At peak, hundreds of crawlers ingested 50K pages per second, culminating in an index of 280 million.</li>
<li>End-to-end query latency landed around 500 ms.</li>
<li>RocksDB and HNSW were <a href="https://blog.wilsonl.in/corenn/" target="_blank" rel="noopener">sharded</a> across 200 cores, 4 TB of RAM, and 82 TB of SSDs.</li>
</ul>
<p>You can play around with a deployed instance of this search engine as a <a href="#live-demo">live demo</a>. Here's a high-level architecture map of the system that will be covered in this post:</p>

<ul><li><a href="#proving-ground">Proving ground</a></li><li><a href="#normalization">Normalization</a></li><li><a href="#chunking">Chunking</a><ul><li><a href="#semantic-context">Semantic context</a></li><li><a href="#statement-chaining">Statement chaining</a></li></ul></li><li><a href="#initial-results">Initial results</a></li><li><a href="#crawler">Crawler</a></li><li><a href="#pipeline">Pipeline</a></li><li><a href="#storage">Storage</a></li><li><a href="#service-mesh">Service mesh</a></li><li><a href="#gpu-buildout">GPU buildout</a></li><li><a href="#sharded-hnsw">Sharded HNSW</a></li><li><a href="#optimizing-latency">Optimizing latency</a></li><li><a href="#knowledge-graph">Knowledge graph</a></li><li><a href="#serp">SERP</a><ul><li><a href="#ai-assistant">AI assistant</a></li><li><a href="#state-tracking">State tracking</a></li></ul></li><li><a href="#search-quality">Search quality</a></li><li><a href="#live-demo">Live demo</a></li><li><a href="#costs">Costs</a></li><li><a href="#conclusion-and-what's-next">Conclusion and what's next</a></li></ul><h2 id="proving-ground">Proving ground</h2>
<p>I started off by creating a minimal playground to experiment if <a href="https://huggingface.co/spaces/mteb/leaderboard" target="_blank" rel="noopener">neural embeddings</a> were superior for search: take some web page, chunk it up, and see if I can answer complex indirect natural language queries with precision.</p>
<p>As an example, let's say I'm looking at the S3 documentation. Here are how some queries are answered by current systems, and how I envisioned they should be answered:</p>






























<div><table><thead><tr><th>Query</th><th>Traditional search</th><th>Neural search</th></tr></thead><tbody><tr><td>i want to use s3 instead of postgres but with databases i can tag some human comment with some file in another column</td><td><em>Random results about Postgres, S3, files</em></td><td>You can also specify custom metadata at the time that the object is stored.</td></tr><tr><td>why does CORS still not work after allowing all?</td><td><em>Random snippet about CORS, "S3 not working", object permissions</em></td><td>Bucket configurations have an eventual consistency model...</td></tr><tr><td>could files get lost or corrupted?</td><td><em>(No result shown)</em></td><td>If a PUT request is successful, your data is safely stored.</td></tr><tr><td>can i use s3 from lua?</td><td><em>(No result shown)</em></td><td>The architecture of Amazon S3 is designed to be programming language-neutral, ... With the REST API, you use standard HTTP requests to create, fetch, and delete buckets and objects.</td></tr></tbody></table></div>
<p>Basically, the search engine should understand <em>intent</em>, not <em>keywords</em>:</p>
<ul>
<li>Queries are understood as a whole instead of broken down into keywords and phrases.</li>
<li>No need for query engineering: operators, format, right words to use.</li>
<li>"Tip of the tongue", implicit, and conceptual queries are mapped correctly to the right answer.</li>
<li>You can ask multi-concept, complex, nuanced queries and surface non-obvious relationships.</li>
<li>It should be far less susceptible to keyword spam and SEO tactics.</li>
</ul>
<p>This is already great for searches in general. But it'd also be great for finding insights, unnoticed connections, and hidden gems. You can ask some very sophisticated specific query, and the search engine will surface a <a href="https://en.wiktionary.org/wiki/needle_in_a_haystack" target="_blank" rel="noopener">one-line sentence</a> in an obscure quality essay. You could write a paragraph of your thoughts and views, and find other writers and areas with similar perspectives. You could query with phrases that signal quality and depth, to find content and communities of similar values.</p>
<p>Here's the sandbox flywheel I initially created to prove the concept:</p>
<ol>
<li>Grow set of gathered diverse raw web pages.</li>
<li>Parse, normalize, augment, and embed them into a queryable HNSW index.</li>
<li>Build and expand the test dataset of queries as I crawl, debug, experiment, and eval.</li>
<li>Create a UI to introspect data at each stage, see failure points, and tune.</li>
</ol>
<h2 id="normalization">Normalization</h2>
<p>HTML represents content in tags which have various intents: layout, text, media, interactivity, metadata, and app programming. Since a search engine focuses on text content, the first step of any pipeline is to sanitize and regularize the noisy markup from a crawled page and extract out semantic text. <a href="https://html.spec.whatwg.org/multipage/" target="_blank" rel="noopener">WHATWG</a> already defines plenty of semantic elements and rules, which I subsetted into the following mini-spec:</p>
<ul>
<li>Structures should be consistent: <code>table &gt; (thead, tbody, tfoot) &gt; tr &gt; (th, td)</code>; <code>(ul, ol) &gt; li</code>.</li>
<li>Only semantic text elements should be kept: <code>p, table, pre, blockquote, ul, ol, dl</code>.</li>
<li>Text is trimmed and collapsed; no loose or unexpected text nodes outside of <code>&lt;p&gt;</code>.</li>
<li>Flatten text trees so that retrieving and mutating text spans (which happens often) doesn't require traversing and reconciling trees.</li>
<li>Remove or unwrap as many nodes as possible: scripts, attributes, empty elements, <code>&lt;head&gt;</code>, comment nodes, foreign/layout elements.</li>
<li>If <code>main &gt; article</code> exists, use it instead of whole page.</li>
</ul>
<p>One goal is to remove all of the <a href="https://www.nngroup.com/articles/browser-and-gui-chrome/" target="_blank" rel="noopener">chrome</a> on a page as they're not part of the content, which pollute the context and distort meaning:</p>
<ul>
<li>Menu bars, nav links, banners, footers, site information.</li>
<li>Comments sections, asides, links to other articles.</li>
<li>Interface elements, forms, controls, social media buttons.</li>
</ul>
<p>These can get mixed up with the primary content and dilute the search engine's understanding of the page's actual content and intent, causing poor query results.</p>
<p>Removing these is straightforward if the page uses <a href="https://developer.mozilla.org/en-US/curriculum/core/semantic-html/" target="_blank" rel="noopener">semantic elements</a> like <code>&lt;article&gt;</code> or <a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/Reference/Roles" target="_blank" rel="noopener">ARIA roles</a>, but otherwise devolves into heuristics and NLP. Methods like pattern matching on classes and IDs is fraught, and removing content by accident is worse than keeping in noise. More advanced methods like <a href="https://developer.chrome.com/docs/chromium/headless" target="_blank" rel="noopener">visually</a> classifying DOM structure or training <a href="https://fasttext.cc/" target="_blank" rel="noopener">statistical text models</a> are possible given more time and resources.</p>
<p>Given HTML's laxness, many sites don't follow these rules rigorously, so you get undercoverage and overcoverage. Unfortunately, this even applies to some <a href="https://en.wikipedia.org/" target="_blank" rel="noopener">big</a> sites that could not be ignored, so I had to hard code some special rules for them (<a href="https://github.com/WebKit/WebKit/blob/main/Source/WebCore/page/Quirks.cpp" target="_blank" rel="noopener">much like a well-known browser</a>).</p>
<details>
<summary>Example special rules for en.wikipedia.org</summary>
<pre><code><span>if</span><span> re.match(</span><span>r"^en\.wikipedia\.org/wiki/"</span><span>, url):
</span><span>    </span><span>if</span><span> tag_name </span><span>not</span><span> </span><span>in</span><span> HEADING_ELEMS:
</span><span>        last_heading = find_prev_sibling(child, </span><span>lambda</span><span> e: e.tagName </span><span>in</span><span> HEADING_ELEMS)
</span><span>        </span><span>if</span><span> (
</span>            last_heading
<span>            </span><span>and</span><span> last_heading.tagName == </span><span>"h2"</span><span>
</span><span>            </span><span>and</span><span> get_text_content(last_heading).replace(</span><span>"[edit]"</span><span>, </span><span>""</span><span>).strip()
</span><span>            </span><span>in</span><span> (</span><span>"Sources"</span><span>, </span><span>"Further reading"</span><span>, </span><span>"External links"</span><span>, </span><span>"See also"</span><span>)
</span>        ):
<span>            </span><span># This is in a section we don't want to keep.</span><span>
</span><span>            </span><span>continue</span><span>
</span>
<span>    classes = </span><span>set</span><span>(child.getAttribute(</span><span>"class"</span><span>).split(</span><span>" "</span><span>))
</span><span>    </span><span>if</span><span> </span><span>"hatnote"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove "meta" information about the Wikipedia article itself. See https://en.wikipedia.org/wiki/Wikipedia:Hatnote.</span><span>
</span><span>    </span><span>if</span><span> tag_name == </span><span>"ol"</span><span> </span><span>and</span><span> </span><span>"references"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove section containing list of references.</span><span>
</span><span>    </span><span>if</span><span> tag_name == </span><span>"table"</span><span> </span><span>and</span><span> </span><span>"sidebar"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove sidebar, which sometimes contains useful facts but often just contains "adjacent" information and links, and is hard to parse due to use of table for formatting (not semantics).</span><span>
</span><span>    </span><span>if</span><span> </span><span>"thumb"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove figures.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"navbox"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove the navigation boxes at the bottom of the page.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"printfooter"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove the message "Retrieved from $url".</span><span>
</span><span>    </span><span>if</span><span> child.getAttribute(</span><span>"id"</span><span>) == </span><span>"siteSub"</span><span>: </span><span>continue</span><span> </span><span># Remove the message "From Wikipedia, the free encyclopedia".</span><span>
</span>
<span>    </span><span>if</span><span> c.tagName == </span><span>"sup"</span><span> </span><span>and</span><span> </span><span>"reference"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove numbered references around square brackets within body text.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"mw-jump-link"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove "Jump to content" link.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"mw-editsection"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove "[edit]" links.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"mw-ui-button"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove UI buttons.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"wb-langlinks-edit"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># Remove "Edit links" link.</span><span>
</span><span>    </span><span>if</span><span> </span><span>"mwe-math-fallback-image-display"</span><span> </span><span>in</span><span> classes </span><span>or</span><span> </span><span>"mwe-math-fallback-image-inline"</span><span> </span><span>in</span><span> classes: </span><span>continue</span><span> </span><span># This is a fallback, we can remove it as we handle &lt;math&gt; elements.</span><span>
</span></code></pre>
</details>
<p>There's a lot of rich structured data available on many pages. <code>&lt;meta&gt;</code> tags like <a href="https://ogp.me/" target="_blank" rel="noopener">OpenGraph</a> are well-known. There's also an entire <a href="https://schema.org/docs/gs.html" target="_blank" rel="noopener">spec</a> to representing <a href="https://schema.org/docs/full.html" target="_blank" rel="noopener">almost anything</a> in a web page for robots to consume. Search engines use these to power <a href="https://developers.google.com/search/docs/appearance/structured-data/search-gallery" target="_blank" rel="noopener">enhanced rich results</a> and build their <a href="https://en.wikipedia.org/wiki/Knowledge_Graph_(Google)" target="_blank" rel="noopener">knowledge graphs</a>. It's how they know something is mentioning a <a href="https://en.wikipedia.org/wiki/Steve_Jobs_(film)" target="_blank" rel="noopener">movie</a> and not a <a href="https://en.wikipedia.org/wiki/Steve_Jobs_(book)" target="_blank" rel="noopener">book</a> or <a href="https://en.wikipedia.org/wiki/Steve_Jobs" target="_blank" rel="noopener">person</a> to improve relevancy, discover new emerging <a href="https://en.wikipedia.org/wiki/Ontology" target="_blank" rel="noopener">things</a> in the world, and show fancy shopping, rating, carousel, and "near me" results.</p>
<h2 id="chunking">Chunking</h2>
<p>Once the text is ready, the next step is to <a href="https://www.pinecone.io/learn/chunking-strategies/" target="_blank" rel="noopener">chunk it</a>. Most embedding models can't take in whole-page inputs and tend to <a href="https://jina.ai/news/long-context-embedding-models-are-blind-beyond-4k-tokens/" target="_blank" rel="noopener">lose representational power at such lengths</a> anyway. Embedding at the page level is also too coarse, not helpful for pinpointing.</p>
<p>A common approach is to simply split at every <em>n</em> characters or words. But this can crudely cut off words, grammar, and structure that destroy meaning. My approach was to break into sentences, a natural coherent boundary, using a trained <a href="https://spacy.io/api/sentencizer" target="_blank" rel="noopener">sentencizer</a>. These models are trained on a large corpus of texts and have a good understanding of grammar and syntax for high accuracy. I found spaCy's model to work the best here, handling subtleties like abbreviations, decimals, URLs, and informal style grammar.</p>
<p>It seemed to me that breaking into sentences would be a good atomic unit of detail: enough to pinpoint the exact relevant part or answer to a query, useful for featured direct snippets or result highlights. This would also allow building larger embedding units (e.g. paragraph sized) with more control over length while still maintaining semantic coherence.</p>
<h3 id="semantic-context">Semantic context</h3>
<p>But a big problem with chunking is context. A sentence builds on top of previous sentences, the containing paragraph, current section, actively discussed concepts, and so on. Indirect references ("it", "the", "then", etc.) lose meaning if chunk is broken off from establishing context.</p>
<p>An initial step was to leverage the normalized semantic document tree. For example:</p>
<ul>
<li>Headings indicate nesting or splitting sections; the content under a <code>&lt;h2&gt;</code> is associated with that heading's text.</li>
<li>Table headings indicate labels for cells in each row; paragraphs indicate semantic text break points; <code>&lt;dd&gt;</code> is associated with its <code>&lt;dt&gt;</code>; and so on.</li>
<li>A "leading" sentence like <em>Here are the suggested values:</em> before a list explains what that list is and so would be associated with that list.</li>
</ul>
<p>Therefore, a page like:</p>
<blockquote>
<h2 id="postgresql-performance-tuning-guide">PostgreSQL Performance Tuning Guide</h2>
<p>…</p>
<h2 id="connection-settings">Connection Settings</h2>
<p>…</p>
<h3 id="maximum-connections">Maximum connections</h3>
<p>Each connection uses a new process. This is different to most other database systems. Therefore, the setting may have surprising performance impact. Due to this design, connections use more resources than in a thread-based system, and so require extra consideration. Here are some recommended values:</p>
<ul>
<li>If you are using version 16 or greater:






























<div><table><thead><tr><th>Environment</th><th>Recommended Setting</th><th>…</th></tr></thead><tbody><tr><td>Development</td><td>100</td><td>…</td></tr><tr><td>Web Application</td><td>200-400</td><td>…</td></tr><tr><td>Data Warehouse</td><td>50-100</td><td>…</td></tr><tr><td>Microservices</td><td>20-50 per service</td><td>…</td></tr></tbody></table></div>
</li>
<li>If you are using version 15:






























<div><table><thead><tr><th>Environment</th><th>Recommended Setting</th><th>…</th></tr></thead><tbody><tr><td>Development</td><td>100</td><td>…</td></tr><tr><td>Web Application</td><td>200-400</td><td>…</td></tr><tr><td>Data Warehouse</td><td>50-100</td><td>…</td></tr><tr><td>Microservices</td><td>20-50 per service</td><td>…</td></tr></tbody></table></div>
</li>
</ul>
<p>…</p>
</blockquote>
<p>would represent the first "Development" table row as</p>
<pre><code><span>[
</span><span>  </span><span>"PostgreSQL Performance Tuning Guide"</span><span>, </span><span>// (heading 1)</span><span>
</span><span>  </span><span>"Connection Settings"</span><span>, </span><span>// (heading 2)</span><span>
</span><span>  </span><span>"Maximum connections"</span><span>, </span><span>// (heading 3)</span><span>
</span><span>  </span><span>"Here are some recommended values:"</span><span>, </span><span>// (leading statement before list)</span><span>
</span><span>  </span><span>"If you are using version 16 or greater:"</span><span>, </span><span>// (leading statement before table)</span><span>
</span><span>  </span><span>"Environment: Development | Recommended Setting: 100 | …"</span><span>, </span><span>// denormalized row to provide column headings as context</span><span>
</span><span>].join(</span><span>"\n"</span><span>)
</span></code></pre>
<p>rather than</p>
<pre><code><span>"Development | 100 | …"</span><span>
</span></code></pre>
<p>which loses meaning due to lack of context.</p>
<p>This context also provides disambiguation and relevancy. In the above example, both tables are only differentiated by the version mention before each table.</p>
<h3 id="statement-chaining">Statement chaining</h3>
<p>This doesn't resolve the problem of nearby local context: follow on sentences, anaphora, etc. To tackle this further, I trained a <a href="https://huggingface.co/distilbert/distilbert-base-uncased" target="_blank" rel="noopener">DistilBERT</a> classifier model that would take a sentence and the preceding sentences, and label which one (if any) it depends upon in order to retain meaning. Therefore, when embedding a statement, I would follow the "chain" backwards to ensure all dependents were also provided in context.</p>
<p>This also had the benefit of labelling sentences that should never be matched, because they were not "leaf" sentences by themselves.</p>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/statement-labeller.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/statement-labeller.png" alt="Screenshot of the statement labeller UX."></a>
  <figcaption>
    The built internal statement labeller UX for quick labelling with instructions.
  </figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/admin-statement-chain-debug.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/admin-statement-chain-debug.png" alt="Screenshot of the statement debug view."></a>
  <figcaption>
    A statement with its semantic context and AI-labelled antecedent dependent statement.
  </figcaption>
</figure>
<p>Using the previous web page, here is an example:</p>
<pre><code><span>[
</span><span>  </span><span>"PostgreSQL Performance Tuning Guide"</span><span>, </span><span>// heading 1</span><span>
</span><span>  </span><span>"Connection Settings"</span><span>, </span><span>// heading 2</span><span>
</span><span>  </span><span>"Maximum connections"</span><span>, </span><span>// heading 3,</span><span>
</span><span>  </span><span>"Each connection uses a new process."</span><span>, </span><span>// necessary to understand the sentence</span><span>
</span><span>  </span><span>// ...skipped unnecessary sentences</span><span>
</span><span>  </span><span>"Due to this design, connections use more resources than in a thread-based system, and so require extra consideration."</span><span>, </span><span>// the target sentence</span><span>
</span><span>].join(</span><span>"\n"</span><span>)
</span></code></pre>
<p>Another example that has multiple hops:</p>
<pre><code><span>[
</span><span>  </span><span>"PostgreSQL Performance Tuning Guide"</span><span>, </span><span>// heading 1</span><span>
</span><span>  </span><span>"Connection Settings"</span><span>, </span><span>// heading 2</span><span>
</span><span>  </span><span>"Maximum connections"</span><span>, </span><span>// heading 3</span><span>
</span><span>  </span><span>"Each connection uses a new process."</span><span>, </span><span>// to understand the next line</span><span>
</span><span>  </span><span>"This is different to most other database systems."</span><span>, </span><span>// to understand the next line</span><span>
</span><span>  </span><span>"Therefore, the setting may have surprising performance impact."</span><span>, </span><span>// the target sentence</span><span>
</span><span>].join(</span><span>"\n"</span><span>)
</span></code></pre>
<p>Chunking while preserving context is a hard problem. Anthropic has an interesting analysis and offer their own approach <a href="https://www.anthropic.com/news/contextual-retrieval" target="_blank" rel="noopener">here</a>. Another approach that I would experiment with is <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/" target="_blank" rel="noopener">late chunking</a>.</p>
<h2 id="initial-results">Initial results</h2>
<p>I built a UX to visualize and interact with pages in my sandbox and test out queries. The results seemed to be pretty good.</p>
<p>For example, on <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html" target="_blank" rel="noopener">this S3 documentation page</a>, using a natural language question gave multiple relevant direct answers, not just keyword matches, from disparate snippets that weren't simply in sections directly related to the query:</p>
<a href="https://blog.wilsonl.in/search-engine/poc-when-should-i-use-multipart-uploads.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-when-should-i-use-multipart-uploads.png" alt="Prototype search results for &quot;when should i use multipart uploads?&quot; over S3 documentation."></a>
<p>Here's another example, querying <a href="https://www.psychologytoday.com/us/blog/understanding-the-anxious-mind/202303/are-you-a-life-optimizer-what-to-do-about-perfectionism" target="_blank" rel="noopener">this web page</a>, where the search engine matched against "It's not worth it", which is arguably the most relevant and direct response, but without context would not make sense and therefore not get matched. The other matches also provide more relevant perspectives to the query.</p>
<a href="https://blog.wilsonl.in/search-engine/poc-is-perfectionism-worth-it.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-is-perfectionism-worth-it.png" alt="Prototype search results for &quot;is perfectionism worth it?&quot; over a blog post on perfectionism."></a>
<p>Here are more examples, where the query has very different keywords to their answers, and don't directly refer to them, yet are good matches:</p>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/poc-im-charged-for-invisible-space.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-im-charged-for-invisible-space.png"></a>
  <figcaption>I'm trying to figure out why my billed usage is higher than my actual usage. Without using words from the answer (which I don't know), the search engine finds me the relevant answer.</figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/poc-race-conditions.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-race-conditions.png"></a>
  <figcaption>The search engine is able to pick up information <em>related in concept</em> to race conditions, despite the article not mentioning "race conditions".</figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/poc-can-i-use-lua.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-can-i-use-lua.png"></a>
  <figcaption>AWS doesn't have an SDK for Lua. Instead of just giving back no or nonsense results, it points out that I can use the REST API, accessible to all languages.</figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/poc-what-do-i-pay-for.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-what-do-i-pay-for.png"></a>
  <figcaption>What do I get charged? Without knowing the words and concepts around what S3 multipart upload charges for, and no article section called "what you pay", the search engine knows what to surface.</figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/poc-how-can-i-attach-some-human-english-comment-to-a-file.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-how-can-i-attach-some-human-english-comment-to-a-file.png"></a>
  <figcaption>The search engine explains what a file is in S3 and how I can achieve my goal. Note that the keywords in the query and results basically don't overlap.</figcaption>
</figure>
<p>More direct queries that have straightforward (but not exact keyword matching) answers are also matched well:</p>
<a href="https://blog.wilsonl.in/search-engine/poc-can-i-upload-without-knowing-size-ahead-of-time.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-can-i-upload-without-knowing-size-ahead-of-time.png" alt="Screenshot of first result of query &quot;can i know upload without knowing size ahead of time&quot;."></a>
<a href="https://blog.wilsonl.in/search-engine/poc-can-uploads-be-interrupted.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-can-uploads-be-interrupted.png" alt="Screenshot of first result of query &quot;can uploads be interrupted&quot;."></a>
<p>Plenty of important snippets and statements lie within rich markup like nested table rows, lists, and definitions:</p>
<a href="https://blog.wilsonl.in/search-engine/poc-what-permissions-do-i-need-to-upload.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/poc-what-permissions-do-i-need-to-upload.png" alt="Screenshot of query for &quot;what permissions do i need to upload&quot;."></a>
<h2 id="crawler">Crawler</h2>
<p>I felt confident that the pipeline and resulting embeddings deliver good results, so I moved on to building out the actual search engine, starting with a Node.js crawler. Some requirements:</p>
<ul>
<li>A form of work stealing for distributing tasks is likely needed as how long requests take varies significantly.</li>
<li>Trust nothing: control and verify DNS resolution, URLs, redirects, headers, and <a href="https://en.wikipedia.org/wiki/Slowloris_(cyber_attack)" target="_blank" rel="noopener">timers</a>.</li>
<li>Origins often rate limit by IP, so tasks should be distributed across crawlers and handle origin-specific rate limits.</li>
<li>Lots of requests = lots of potential memory leaks. Manage resources (sockets, keepalives, pools) strictly, and use streaming wherever possible to keep memory O(1).</li>
</ul>
<p>The approach ended up being:</p>
<ul>
<li>up to N-per-origin concurrent Promises, which are essentially green threads as primary workload is async I/O</li>
<li>self-imposed sliding window and concurrency rate limiting per origin, with jittered delays between requests and exponential backoff between failures</li>
<li>use Node.js streams to fetch, decompress, and ingest in fixed-sized buffers for memory usage stability</li>
</ul>
<p>Each node grabs a diverse set of URLs from the DB across domains, which is then randomly work-stolen across green threads. This multi-level stochastic queues setup reduces contention from needing global coordination, frequent polling due to the high-throughput nature, and excessive hitting of any single origin, compared to simply ordered polling from a global crawl queue.</p>
<p>Origins that are rate limited get excluded when polling for more URLs, and existing polled tasks get sent back to global queue.</p>
<a href="https://blog.wilsonl.in/search-engine/multi-level-crawl-queues.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/multi-level-crawl-queues.png" alt="Diagram of multi-level crawl queues."></a>
<p>A surprising failure point was DNS. EAI_AGAIN and SERVFAIL caused a non-insignificant amount of failures. DNS resolution for every crawl was done manually to verify that the resolved IP was not a private IP, to avoid leaking internal data.</p>
<p>There's a surprising amount of detail that I overlook normally. For example, URLs seem straightforward, but can actually be subtle to deal with. All URLs, before entering the system, were strictly processed as they were central to many systems and records:</p>
<ul>
<li>They must have <code>https:</code> protocol, not <code>ftp:</code>, <code>data:</code>, <code>javascript:</code>, etc.</li>
<li>They must have a valid <a href="https://publicsuffix.org/list/" target="_blank" rel="noopener">eTLD</a> and <a href="https://en.wikipedia.org/wiki/Hostname#Syntax" target="_blank" rel="noopener">hostname</a>, and can't have ports, usernames, or passwords.</li>
<li>Canonicalization is done to deduplicate. All components are percent-decoded then re-encoded with a minimal consistent charset. Query parameters are dropped or sorted. Origins are lowercased.</li>
<li>Some URLs are extremely long, and you can run into rare limits like HTTP headers and database index page sizes.</li>
<li>Some URLs also have <a href="https://en.wikipedia.org/wiki/C0_and_C1_control_codes" target="_blank" rel="noopener">strange characters</a> that you wouldn't think would be in a URL, but will get rejected downstream by systems like <a href="https://www.postgresql.org/docs/current/datatype-character.html#:~:text=the%20character%20with%20code%20zero%20(sometimes%20called%20NUL)%20cannot%20be%20stored" target="_blank" rel="noopener">PostgreSQL</a> and <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_SendMessage.html" target="_blank" rel="noopener">SQS</a>.</li>
</ul>
<h2 id="pipeline">Pipeline</h2>
<a href="https://blog.wilsonl.in/search-engine/pipeline.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/pipeline.png" alt="Search engine pipeline state and data flow diagram."></a>
<p>Each web page was stored in PostgreSQL with a state shown in the above diagram. Workers would poll from PostgreSQL directly using <code>SELECT ... FOR UPDATE SKIP LOCKED</code> transactions, transitioning the state once completed. However, lots of long transactions and single-row lock → read → update queries from many distant connections is not efficient with PostgreSQL, so a Rust coordinator service was introduced:</p>
<ul>
<li>Kept entire queue state in memory, and efficiently tracked heartbeats and expiration.</li>
<li>Handled locking, state transitions, and integrity via faster in-memory state.</li>
<li>Used efficient RPC over multiplexed HTTP/2 with clients and only a few PostgreSQL connections to the DB with queued batched upserts.</li>
</ul>
<p>This in-memory queue was designed for high throughput:</p>
<ul>
<li>An <code>Arc&lt;Mutex&lt;Task&gt;&gt;</code> was shared between three data structures:
<ul>
<li>HashMap <code>task ID -&gt; task</code> for fetching and mutating tasks.</li>
<li>Binary heap over tasks, keyed by visibility timeouts, for making expired polled tasks available again.</li>
<li>Grouped by origin (<code>origin</code> -&gt; <code>list of tasks in that origin</code>) for fair scheduling across origins, with separate tracked list of available origins.</li>
<li>Random polling within origin list, with O(1) <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.swap_remove" target="_blank" rel="noopener"><code>swap_remove</code></a> of self-indexed position (which also means only one other self-indexed position needs updating, no mass shift-down-by-one).</li>
</ul>
</li>
<li>Graceful drift handling was adopted over global locking:
<ul>
<li>Atomicity maintained via per-task locks.</li>
<li>Changes in timeout (e.g. heartbeats) don't mutate heap; instead, the latest expiration is re-checked when background loop goes through timeout heap.</li>
<li>An available origin that becomes empty isn't removed from available origins list until next access (poller), amortizing costs.</li>
<li><code>Arc&lt;Mutex&lt;Task&gt;&gt;</code> is source of truth; data structures are merely indices that may be stale (e.g. completed tasks in heap, empty origins in list, phantom polled task).</li>
</ul>
</li>
</ul>
<p>The result was efficient sublinear complexity for all operations:</p>








































<div><table><thead><tr><th>Operation</th><th>Time complexity</th><th>Process</th></tr></thead><tbody><tr><td><strong>Push task</strong></td><td>O(1)</td><td>HashMap insert + Vec push to origin list + update task's stored index</td></tr><tr><td><strong>Pop random</strong></td><td>O(k) average<br><em>k = excluded origins</em></td><td>O(1) random index into origins list → O(1) random index into origin's tasks<br>→ O(1) swap_remove using stored index → O(log n) heap push</td></tr><tr><td><strong>Complete task</strong></td><td>O(1)</td><td>HashMap lookup → lock task → state transition<br>→ O(1) swap_remove from origin list using stored index</td></tr><tr><td><strong>Heartbeat</strong></td><td>O(1)</td><td>HashMap lookup → update timeout in-place (no heap rebuild)</td></tr><tr><td><strong>Release timeouts</strong></td><td>O(log n) per task</td><td>Heap pop → check if expired<br>→ if yes: O(1) push to origin list; if no: O(log n) re-push to heap</td></tr><tr><td><strong>Find task</strong></td><td>O(1)</td><td>Direct HashMap lookup</td></tr></tbody></table></div>
<p>Each task only occupied around 100 bytes of memory, so despite being memory-bound in theory, in reality it was scalable to 1 billion active tasks on a typical 128 GB RAM server.</p>
<p>This also helped with the multi-level stochastic queue setup described previously. Thousands of crawlers all frequently polling a random set of URLs that avoid an arbitrary set of origins, as well as sending back rate limited origin URLs, is a hard database query to optimize for, but more straightforward if global state is kept in memory via a central coordinator.</p>
<p>An interesting optimization was to try and reduce the memory impact of buffering so many URLs in memory:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/String_interning" target="_blank" rel="noopener">Interning</a>: avoided copies, which was helpful.</li>
<li><a href="https://en.wikipedia.org/wiki/Zstd" target="_blank" rel="noopener">Zstd</a>: doesn't work well on small strings, even with custom trained dictionary.</li>
<li><a href="https://en.wikipedia.org/wiki/Trie" target="_blank" rel="noopener">Trie</a>: high memory usage in reality due to pointer widths, usize offsets, sparseness, node allocations.</li>
<li>Custom compression algorithm that tries to find patterns in URL components: UUIDs, enums, base64, etc. This was very CPU expensive.</li>
</ul>
<p>Eventually, this in-memory system was retired in favor of a queue service. SQS had very low concurrent rate limits that could not keep up with the throughput of thousands of workers across the pipeline. SQS was also very expensive, <a href="https://aws.amazon.com/sqs/pricing/" target="_blank" rel="noopener">charging per message</a>. I decided to write an <a href="https://github.com/wilsonzlin/queued" target="_blank" rel="noopener">open source RocksDB-based queue</a> that was as simple as SQS, while able to perform 300K operations per second from a single node.</p>
<p>In order to persist the multi-level random/fair scheduling, I appended crawl tasks with a random initial <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html" target="_blank" rel="noopener">visibility timeout</a> to approximate shuffling and therefore diversify origins in any sequence of polled tasks. Crawler nodes polled a very large batch rather than one-by-one to continue avoiding excessive global polling via the multi-level queues approach.</p>
<h2 id="storage">Storage</h2>
<p>I initially chose Oracle Cloud for infra needs due to their <a href="https://www.oracle.com/cloud/networking/virtual-cloud-network/pricing/" target="_blank" rel="noopener">very low egress costs</a> with 10 TB free per month. As I'd store terabytes of data, this was a good reassurance that if I ever needed to move or export data (e.g. processing, backups), I wouldn't have a hole in my wallet. Their compute was also <a href="https://www.oracle.com/cloud/pricing/" target="_blank" rel="noopener">far cheaper</a> than other clouds, while still being a reliable major provider.</p>
<p>Their object storage service was the initial place for storing raw pages and derived data, and it was similar to S3 in function and performance. However, that quickly ran into scaling issues due to frequency of large-sized writes, which was expected as services like S3 have quite low rate limits — there are <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html" target="_blank" rel="noopener">hard limits</a>, but also dynamic per-account/bucket quotas and high rates of 500s during periods of internal auto scaling. Since it's a managed shared service, I couldn't manually scale or adjust those.</p>
<p>For a while afterwards, I stored blobs in PostgreSQL alongside regular row data as it was manually scalable and I had it set up already. Typically you'd never do this as fat columns can cause chokepoints like write amplification around logging, bloating caches, and exceeding disk page sizes. However, PostgreSQL does have a mechanism called <a href="https://www.postgresql.org/docs/current/storage-toast.html" target="_blank" rel="noopener">TOAST</a> which chunks and stores these large blobs in a separate table "out of the way", mitigating some of these issues.</p>
<p>This worked for a while, but eventually also hit limits. PostgreSQL was already struggling to keep up with merely inserting metadata rows at the high processing rate of the pipeline, and the additional workload of writing large blobs at those rates tipped it over the edge — I was seeing crawls that were taking minutes to ingest, and frequent vacuuming to reduce bloat that caused complete database stalls. There were a series of attempts to stretch PostgreSQL to avoid migrating:</p>
<ul>
<li>Avoiding any indices, transactions, FKs/constraints, joins, sequences, complex queries, wide columns, or fat tables.</li>
<li>Moving all upserts to the Rust coordinator RPC service that pooled connections and queued and <a href="https://www.tigerdata.com/blog/boosting-postgres-insert-performance" target="_blank" rel="noopener">batched</a> them.</li>
<li>Moving to bare metal machines with low latency NVMe SSDs and <a href="https://www.sqlite.org/atomiccommit.html" target="_blank" rel="noopener">atomic writes</a>.</li>
<li>Using <a href="https://www.citusdata.com/" target="_blank" rel="noopener">Citus</a>, which keeps the design constraints of PostgreSQL but splits into horizontal shards to scale out writes and spread the overhead.</li>
</ul>
<p>But fundamentally, this workload was not suited for the way PostgreSQL is designed:</p>
<ul>
<li>Updates create new tuples rather than updating in place, causing bloat and necessitating vacuuming that compete for I/O, but is needed for non-blocking concurrency with ACID guarantees via <a href="https://www.postgresql.org/docs/current/mvcc.html" target="_blank" rel="noopener">MVCC</a>.</li>
<li>Every upsert is a tree lookup to a likely random page (given no predictability to crawled URLs), hitting many random pages (causing cache thrashing), and rewriting an entire page for only one entry (write amplification).</li>
<li>Every upsert also requires checking constraints and modifying separate index trees (e.g. primary keys, uniqueness).</li>
<li>These changes are double-written due to the WAL, which is at the larger page (not record) level to provide <a href="https://wiki.postgresql.org/wiki/Full_page_writes" target="_blank" rel="noopener">torn write protection</a>, increasing write amplification.</li>
<li>Connections are resource-heavy processes, have lots of state tracking, and execute sequentially, not optimized for thousands of few-row writers.</li>
<li>SQL queries are very general and powerful, so things like the wire protocol, query planning, and transaction isolation add a lot of overhead for simple INSERTs.</li>
</ul>
<p>Using Citus did not help much to mitigate these overheads as they caused order of magnitude slower writes compared to raw disk I/O. It also added a coordinator, distributed query planner, and intra-cluster connections that I did not control or understand well. PostgreSQL does a lot of work for relational and ACID functionality, but what I needed was a barebones KV store with fast write performance. So I turned to <a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a> for both records/metadata and blobs.</p>
<p>RocksDB directly resolves many of the aforementioned limitations:</p>
<ul>
<li>Writes are sequentially written to the WAL (of records, not pages), and kept sorted in <a href="https://github.com/facebook/rocksdb/wiki/Memtable" target="_blank" rel="noopener">memory</a>. Only much later are they sequentially written to disk as SSTs in the background. This avoids much random I/O and write amplification.</li>
<li>Fast simple path to inserts, directly going into MemTables, skipping much of the RDBMS machinery.</li>
<li>Direct <a href="https://docs.rs/rocksdb/latest/rocksdb/" target="_blank" rel="noopener">embeddable library</a> function calls rather than wire protocols and connections. I can choose a more efficient, simpler, multiplexing protocol like HTTP/2, that scales to thousands of inserters.</li>
<li>It still has features like immediately visible writes, atomic batch updates, and <a href="https://github.com/facebook/rocksdb/wiki/Iterator#consistent-view" target="_blank" rel="noopener">snapshot consistency</a>.</li>
</ul>
<p>Keen to avoid the previous experience and migration due to slow writes, I configured RocksDB from the beginning to optimize for writes and make full use of the NVMe SSDs.</p>
<details>
<summary>RocksDB configuration I used</summary>
<pre><code><span>fn</span><span> </span><span>rocksdb_opts</span><span>() -&gt; rocksdb::Options {
</span><span>  </span><span>let</span><span> </span><span>mut</span><span> opt = rocksdb::Options::default();
</span><span>  </span><span>// Maximize disk I/O utilization.</span><span>
</span><span>  opt.set_max_background_jobs(num_cpus::get() </span><span>as</span><span> </span><span>i32</span><span> * </span><span>2</span><span>);
</span><span>  opt.set_bytes_per_sync(</span><span>1024</span><span> * </span><span>1024</span><span> * </span><span>4</span><span>);
</span>
<span>  </span><span>// Enable BlobDB.</span><span>
</span><span>  opt.set_enable_blob_files(</span><span>true</span><span>);
</span><span>  opt.set_min_blob_size(</span><span>1024</span><span>);
</span><span>  opt.set_enable_blob_gc(</span><span>true</span><span>);
</span>
<span>  </span><span>// Use more RAM for better performance.</span><span>
</span><span>  </span><span>// https://github.com/facebook/rocksdb/wiki/Block-Cache.</span><span>
</span><span>  </span><span>let</span><span> block_cache = Cache::new_lru_cache(</span><span>1024</span><span> * </span><span>1024</span><span> * </span><span>1024</span><span> * </span><span>32</span><span>);
</span><span>  </span><span>let</span><span> </span><span>mut</span><span> bbt_opt = BlockBasedOptions::default();
</span><span>  opt.set_write_buffer_size(</span><span>1024</span><span> * </span><span>1024</span><span> * </span><span>256</span><span>);
</span>
<span>  </span><span>// Enable partitioned index filters: https://github.com/facebook/rocksdb/wiki/Partitioned-Index-Filters</span><span>
</span><span>  </span><span>// </span><span>NOTE:</span><span> We cannot use HashSearch as that requires a prefix extractor.</span><span>
</span>  bbt_opt.set_index_type(BlockBasedIndexType::TwoLevelIndexSearch);
<span>  bbt_opt.set_bloom_filter(</span><span>10.0</span><span>, </span><span>false</span><span>);
</span><span>  bbt_opt.set_partition_filters(</span><span>true</span><span>);
</span><span>  bbt_opt.set_metadata_block_size(</span><span>4096</span><span>);
</span><span>  bbt_opt.set_cache_index_and_filter_blocks(</span><span>true</span><span>);
</span><span>  bbt_opt.set_pin_top_level_index_and_filter(</span><span>true</span><span>);
</span><span>  bbt_opt.set_pin_l0_filter_and_index_blocks_in_cache(</span><span>true</span><span>);
</span>
<span>  </span><span>// Optimize for point lookups.</span><span>
</span><span>  </span><span>// Don't use `optimize_for_point_lookup()`, which just sets a custom BlockBasedOptions; we'll use our own custom options instead.</span><span>
</span><span>  </span><span>// </span><span>NOTE:</span><span> We don't enable memtable_whole_key_filtering as that uses a lot more memory for an unknown performance benefit (key lookups in memory should already be fast, and memtables should not be that large).</span><span>
</span><span>  </span><span>// https://github.com/facebook/rocksdb/wiki/BlobDB#performance-tuning</span><span>
</span><span>  bbt_opt.set_block_size(</span><span>1024</span><span> * </span><span>64</span><span>);
</span>  bbt_opt.set_block_cache(&amp;block_cache);
<span>  bbt_opt.set_format_version(</span><span>5</span><span>);
</span><span>  </span><span>// https://github.com/facebook/rocksdb/blob/25b08eb4386768b05a0748bfdb505ab58921281a/options/options.cc#L615.</span><span>
</span>  bbt_opt.set_data_block_index_type(DataBlockIndexType::BinaryAndHash);
<span>  bbt_opt.set_data_block_hash_ratio(</span><span>0.5</span><span>);
</span><span>  </span><span>// https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter#ribbon-filter.</span><span>
</span><span>  </span><span>// Don't set this too high, as benefits drop off exponentially while memory increases linearly.</span><span>
</span><span>  bbt_opt.set_ribbon_filter(</span><span>10.0</span><span>);
</span>  opt.set_block_based_table_factory(&amp;bbt_opt);
  opt
}
</code></pre>
</details>
<p>I tuned it for point lookups (the dominant access pattern): bloom filters, hash indices, partitioned indices, and large block caches. For writes, large write buffers and thread pools were used to saturate disk I/O.</p>
<p>The most interesting feature of RocksDB was <a href="https://github.com/facebook/rocksdb/wiki/BlobDB" target="_blank" rel="noopener">BlobDB</a>. Large values may have an outsized impact on <a href="https://github.com/facebook/rocksdb/wiki/Compaction" target="_blank" rel="noopener">compaction</a> performance due to exacerbating write amplification. BlobDB mitigates this by storing large blobs in separate files outside the normal SSTs, leaving only small pointers there. This was highly relevant due to the large blobs I had, and made it possible to use RocksDB for both metadata/records and blobs.</p>
<p>Eventually I ran into the disk I/O limits, so I decided to scale out via sharding. A typical go-to is <a href="https://en.wikipedia.org/wiki/Consistent_hashing" target="_blank" rel="noopener">consistent hashing</a>, which allows shards and nodes to expand and contract for future growth or node loss. However, it's not straightforward to implement and therefore harder to guarantee correctness via simplicity, especially around inserts and rebalance operations. Instead, I opted for a fixed set of 64 RocksDB shards, which simplified operations and client routing, while providing enough distribution capacity for the foreseeable future.</p>
<p>Reads and writes get routed by the <a href="https://xxhash.com/" target="_blank" rel="noopener">xxHash</a> of keys. Since the set of nodes almost never changes, the shard mapping was simply a static file distributed with code, requiring no metadata or discovery service. After this sharding, the coordinator service quickly became the bottleneck, as the I/O traffic and request volume of 64 shards went through one machine, so it was later dropped and clients directly read from and wrote to RocksDB shard nodes.</p>
<p>For representing rows, I used Serde-defined types with custom compact keys to reduce de/serialization time and storage. I used <a href="https://msgpack.org/index.html" target="_blank" rel="noopener">MessagePack</a> instead of an <a href="https://github.com/djkoloski/rust_serialization_benchmark" target="_blank" rel="noopener">even faster, more compact</a> format as those are typically tied to Rust and are sensitive to field ordering, and I opted for some extra insurance against both.</p>
<pre><code><span>#[skip_serializing_none]</span><span>
</span><span></span><span>#[derive(Serialize, Deserialize, Debug)]</span><span>
</span><span></span><span>pub</span><span> </span><span>struct</span><span> </span><span>Resource</span><span> {
</span><span>  </span><span>#[serde(rename = </span><span>"1"</span><span>)]</span><span>
</span><span>  </span><span>pub</span><span> state: ResourceState,
</span><span>  </span><span>#[serde(rename = </span><span>"2"</span><span>)]</span><span>
</span><span>  </span><span>pub</span><span> http_status: </span><span>Option</span><span>&lt;</span><span>u16</span><span>&gt;,
</span><span>  </span><span>#[serde(rename = </span><span>"3"</span><span>)]</span><span>
</span><span>  </span><span>pub</span><span> original_content_encoding: </span><span>Option</span><span>&lt;</span><span>String</span><span>&gt;,
</span>  ..
}
</code></pre>
<p>At its peak, this system could ingest 200K writes per second across thousands of clients (crawlers, parsers, vectorizers). Each web page not only consisted of raw source HTML, but also normalized data, contextualized chunks, hundreds of high dimensional embeddings, and lots of metadata.</p>
<h2 id="service-mesh">Service mesh</h2>
<p>As the system expanded in complexity, I needed a way to discover service instances rather than hard code IPs, and communicate securely across the Internet (as I began to leverage cheaper resources elsewhere).</p>
<p>I used mTLS as a universal way to provide encryption + authentication, simpler than handling the myriad of protocols and auth methods for each service in its own way. A custom root CA was generated, and then a certificate and key was generated for each node at the OS level.</p>
<p>HTTP/2 was adopted as the protocol, and MessagePack the serialization mechanism: binary, self-describing, and supported timestamps and maps. This scaffolding allowed easily setting up and using new services via a tuned universal internal client SDK. HTTP/2 was a good protocol as I had many long fat pipes over the public Internet across nodes, not as low latency or reliable as private datacenter networks. It provided multiplexing and simple request and retry semantics, a benefit over many other protocols (e.g. PostgreSQL). mTLS + HTTP/2-based RPC made secure private service calls simple no matter where my infra resided.</p>
<p>An internal DNS service was also implemented: a control plane to see and edit internal DNS entries, and a <a href="https://coredns.io/" target="_blank" rel="noopener">CoreDNS</a> daemon on all nodes to serve DNS requests, intercepting requests to internal DNS names and proxying the rest. I initially tried to simply use public DNS names for internal infra, but this was too unreliable, with many internal requests failing simply due to transient DNS resolution timeouts or failures.</p>
<p>I did also try ZeroTier and Tailscale, providing a single package for encrypted and authenticated communications, DNS, routing, and discovery. But they often had issues at scale (delays and transient errors joining, propagating, and discovering changes), and traffic limitations and overhead — at the time, they could not easily saturate 10 Gbps connections and consumed a lot of CPU usage. They were also harder to use within Docker containers due to touching lower networking stack layers. In the end, HTTP + mTLS was much more straightforward, required no special networking, and saturated connections with almost no overhead. It was also safer, like <a href="https://www.beyondcorp.com/" target="_blank" rel="noopener">Zero Trust</a>, as services could be publicly exposed and not rely on security via routing, firewalls or secrets, which are easy to misconfigure or leak.</p>
<p>systemd services were used for setting up definitions (e.g. env vars, limits), accounting (via cgroups), and management tools and logs (via journald). It seemed like a good trade off:</p>
<ul>
<li>Simple yet comprehensive without custom scripts and workflows. Easy to debug on any out-of-the-box Linux machine.</li>
<li>Lightweight framework: declarative, structured, but no building images, repos, deployment opinions, etc.</li>
<li>No performance overhead and multiple layers of abstraction.</li>
</ul>
<h2 id="gpu-buildout">GPU buildout</h2>
<p>My initial prototype used OpenAI embeddings, available via API. That became economically infeasible as I scaled, so I set out to run inference myself.</p>
<p>In search of the most cost effective scalable solution, I discovered <a href="https://www.runpod.io/" target="_blank" rel="noopener">Runpod</a>, who offer high performance-per-dollar GPUs like the RTX 4090 at far cheaper per-hour rates than AWS and Lambda. These were operated from tier 3 DCs with stable fast networking and lots of reliable compute capacity.</p>
<p>A key concern was GPU efficiency: they are expensive so I wanted to make sure they're fully utilized. Essentially, this meant that the operations before and after inference should not block the GPU:</p>
<ul>
<li>Polling for pending jobs and fetching input data</li>
<li>Parsing and tokenizing input data</li>
<li>Processing and storing output embeddings</li>
</ul>
<p>These Runpod workers were far from my main infra, so the long fat pipe was a concern. The latency meant that the GPU could finish inference before inputs and outputs could be transferred. Therefore, I implemented a Rust pipeline wrapping the Python core inference that could:</p>
<ul>
<li>operate each stage asynchronously without blocking upstream steps</li>
<li>signal backpressure to pause upstream stages and not overwhelm system resources</li>
</ul>
<p>These traits gave the benefit of dynamic tuning — I did not have to manually tune or limit based on specific hardware and data; the pipeline would fill up as quickly as any subsystem could handle, then signal backpressure to prevent overflowing, leading to peak efficiency automatically, as well as handling any bursts and slowdowns (e.g. network outages). Each stage utilized different hardware (CPU, networking, RAM, GPU) so a simple serial execution would needlessly block and idle resources.</p>

<p>A minor feature was the use of IPC over named pipes to talk to the Python process, rather than repeated subprocess spawns, reading/writing files, or spinning up a local HTTP/RPC server. Nowadays, I'd probably use <a href="https://github.com/PyO3/pyo3" target="_blank" rel="noopener">PyO3</a> or <a href="https://github.com/huggingface/candle" target="_blank" rel="noopener">candle-rs</a>.</p>
<p>Using job queues also meant autorecovery when workers died. This made it trivial to use cheaper preemptible workers and scale up and down at any time. The result was a service that generated 100K embeddings per second across 250 GPUs at peak, with 90% average GPU utilization.</p>
<h2 id="sharded-hnsw">Sharded HNSW</h2>
<p>I used <a href="https://github.com/nmslib/hnswlib" target="_blank" rel="noopener">HNSW</a> as the algorithm and index for low latency vector searches. It's an in-memory optimized graph data structure that allows for sublinear <a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search" target="_blank" rel="noopener">ANN</a> querying. I go into detail about ANN, graph algorithms, and HNSW <a href="https://blog.wilsonl.in/graph-vector-search/" target="_blank" rel="noopener">in this post</a>.</p>
<p>As the HNSW index began to outgrow the available RAM on a single machine, I investigated ways to scale it. Existing vector databases were overly complex to operationalize and slow at ingesting and querying due to serving broader needs. They also required subtle tuning and knowledge of various indexing methods and trade offs that would affect recall.</p>
<p>I decided to stick with tried-and-true HNSW and uniformly shard it into 64 nodes, enough to scale for the foreseeable future. This retained the same low latency and high accuracy, since each shard is queried in parallel and remains a high-quality (not quantized or downgraded) full HNSW index, while now scalable to far larger combined index sizes.</p>
<p>However, the downside to this is that it requires lots of expensive RAM, and maintains the HNSW limitations of lack of updatability. Whenever I needed to update the index, it involved loading giant HNSW indices into the RAM of builder nodes, inserting the new embeddings, and performing a full dump. I decided to dive deep into this and built a vector database that uses cheaper disk and can perform live graph updates, downsizing the entire cluster to one machine with only 128 GB RAM and requiring no complex update pipelines, while still retaining high recall over 3 billion embeddings. It's an open source vector DB called <strong>CoreNN</strong>, which I go into detail in <a href="https://blog.wilsonl.in/corenn/" target="_blank" rel="noopener">this blog post</a>.</p>
<h2 id="optimizing-latency">Optimizing latency</h2>
<p>The user experience of a search engine is interesting, as there is an emphasis on latency specifically and not flashiness or sophisticated design. Many search engines feel different from the typical modern app: they lack loading indicators and animations, have plain designs and not much interactivity, and stream in like a "traditional" web page. As such, instant results is a baseline user expectation for search engines. To optimize for responsiveness, I sought to reduce latency at all layers of the stack.</p>
<p>I used <a href="https://www.cloudflare.com/en-au/application-services/products/argo-smart-routing/" target="_blank" rel="noopener">Cloudflare Argo</a> so that users hit closer edge PoP servers, which then routes via internal Cloudflare <a href="https://en.wikipedia.org/wiki/Wide_area_network" target="_blank" rel="noopener">private networks</a> rather than the Internet, meaning fewer hops, <a href="https://en.wikipedia.org/wiki/Packet_loss" target="_blank" rel="noopener">drops</a>, and congestion. Cloudflare also uses HTTP/3 at these edge PoPs, which reduces handshake overhead and head-of-line blocking. Setting up read replicas across the globe was too expensive.</p>
<p>Rather than making many client-server round-trip API requests, the app server fetches all necessary data and prepares the entire response page on the <a href="https://developer.mozilla.org/en-US/docs/Glossary/SSR" target="_blank" rel="noopener">server side</a>, minified and compressed. An endpoint handler defines the rendered tree with Promises (that start executing immediately in background) at subtrees that need fetched data, and a custom SSR framework eagerly streams out HTML as it traverses, awaiting each Promise only when reached to not block ready content. This is done to reduce <a href="https://en.wikipedia.org/wiki/Time_to_first_byte" target="_blank" rel="noopener">TTFB</a> and make the page feel responsive by streaming in rather than appear all at once after a long delay.</p>
<pre><code><span>class</span><span> </span><span>Element</span><span> </span><span>{
</span><span>  </span><span>// Core rendering loop.</span><span>
</span><span>  </span><span>private</span><span> </span><span>async</span><span> </span><span>streamInner</span><span>(</span><span>out: Writable</span><span>)</span><span> {
</span><span>    </span><span>// Write eagerly.</span><span>
</span><span>    out.write(</span><span>`&lt;</span><span>${</span><span>this</span><span>.tagName}</span><span>`</span><span>);
</span><span>    </span><span>for</span><span> (</span><span>const</span><span> [n, v] </span><span>of</span><span> </span><span>Object</span><span>.entries(</span><span>this</span><span>.attrs)) {
</span><span>      out.write(</span><span>` </span><span>${htmlEscape(n)}</span><span>="</span><span>${htmlEscape(v)}</span><span>"`</span><span>);
</span>    }
<span>    out.write(</span><span>"&gt;"</span><span>);
</span><span>    </span><span>for</span><span> (</span><span>const</span><span> cRaw </span><span>of</span><span> </span><span>this</span><span>.children) {
</span><span>      </span><span>// Lazily await.</span><span>
</span><span>      </span><span>const</span><span> c = </span><span>await</span><span> cRaw;
</span><span>      </span><span>if</span><span> (</span><span>typeof</span><span> c == </span><span>"string"</span><span>) {
</span>        out.write(htmlEscape(c));
<span>      } </span><span>else</span><span> {
</span><span>        </span><span>await</span><span> c.streamInner(out);
</span>      }
    }
<span>    </span><span>if</span><span> (!VOID_ELEMS.has(</span><span>this</span><span>.tagName)) {
</span><span>      out.write(</span><span>`&lt;/</span><span>${</span><span>this</span><span>.tagName}</span><span>&gt;`</span><span>);
</span>    }
  }
}

<span></span><span>// Example endpoint definition.</span><span>
</span><span></span><span>const</span><span> endpoint = </span><span>() =&gt;</span><span> (
</span><span>  h(</span><span>".page"</span><span>,
</span><span>    </span><span>// Subtrees can be Promises.</span><span>
</span><span>    (</span><span>async</span><span> () =&gt; {
</span><span>      </span><span>const</span><span> results = </span><span>await</span><span> fetchResults();
</span><span>      </span><span>return</span><span> h(</span><span>".results"</span><span>, ...results.map(</span><span>r</span><span> =&gt;</span><span> (
</span><span>        h(</span><span>".result"</span><span>, ...)
</span>      )));
    })(),
<span>    </span><span>// All Promises begin executing concurrently without delay.</span><span>
</span><span>    (</span><span>async</span><span> () =&gt; {
</span><span>      </span><span>const</span><span> profile = </span><span>await</span><span> fetchProfile();
</span>      ...
    })(),
  ),
);
</code></pre>
<p>JSX would probably be more elegant, but would've required some work to customize transpilation and the runtime (to handle Promises).</p>
<p>In terms of throughput of internal services, the RocksDB and HNSW shards already provided ample read capacity. The only scaling that was done for queries was to introduce a vectorizer service for generating embeddings for queries. This ran on CPU as the limited batching plus latency of distant GPUs negated any gains via fast floating point operations.</p>
<h2 id="knowledge-graph">Knowledge graph</h2>
<p>I wanted to reproduce the <a href="https://support.google.com/knowledgepanel/answer/9163198?hl=en" target="_blank" rel="noopener">knowledge panel</a> that shows on the right side of search results. Wikipedia and Wikidata seemed like good sources to populate this panel, but their APIs are slow and rate limited. Fortunately, they offer <a href="https://dumps.wikimedia.org/" target="_blank" rel="noopener">full exports</a> of all their data on a regular cadence, which I used to build local optimized indices and query services.</p>
<p>Wikipedia offers nice structured data for articles (e.g. <a href="https://en.wikipedia.org/api/rest_v1/page/summary/Australia" target="_blank" rel="noopener">Australia</a>) that contains a relevant image, an extract, and a reference to a Wikidata <a href="https://www.wikidata.org/wiki/Help:Items" target="_blank" rel="noopener">item</a>. These have associated properties that describe their relationships to other entities, useful for populating the "quick facts" (e.g. date of birth) in a knowledge panel. Combined, they form a good initial system for knowledge panels:</p>
<ul>
<li>Articles form the base set of knowledge panels.</li>
<li>The title + summary are combined to generate embeddings for retrieving the relevant knowledge panel to show for a query.</li>
<li>The image, title, description, and summary are shown in the top half of the panel.</li>
<li>If there's a linked Wikidata item, that entity is looked up in the knowledge base and specific associated properties are retrieved.</li>
</ul>
<p>Not all Wikipedia articles should be shown as knowledge panels (e.g. lists), and embedding retrieval may not give the most relevant results (e.g. showing a specific adjacent article rather than the base/broader topic). Similarly, not all Wikidata properties are worth showing. There are also lots of other data sources available to incorporate. So there are still lots of improvements to be had, but it worked well as a good starting point.</p>
<h2 id="serp">SERP</h2>
<p>The resulting search engine results page (<a href="https://en.wikipedia.org/wiki/Search_engine_results_page" target="_blank" rel="noopener">SERP</a>) looks like this:</p>
<a href="https://blog.wilsonl.in/search-engine/serp-rocksdb.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-rocksdb.png" alt="Screenshot of final SERP without AI features."></a>
<p>I aimed for a clean minimal look to go for the "signal over noise" aesthetic. The specific statement snippets show up under "fact" pages like docs and wikis, to give quick references and answers for queries. Another example:</p>
<a href="https://blog.wilsonl.in/search-engine/serp-protein-in-chicken.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-protein-in-chicken.png" alt="Screenshot of SERP with statement snippets."></a>
<p>What's great is the comparable lack of SEO spam. For example, I queried "best programming blogs" on a well known search engine and compared it to mine:</p>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/serp-blogs-theirs.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-blogs-theirs.png"></a>
  <figcaption>Results from a major search engine.</figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/serp-blogs-mine.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-blogs-mine.png"></a>
  <figcaption>Results from my search engine.</figcaption>
</figure>
<p>Here's an example of finding some interesting writings and insights around a query:</p>
<a href="https://blog.wilsonl.in/search-engine/serp-crypto.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-crypto.png" alt="Screenshot of SERP for &quot;the case for/against crypto&quot; query."></a>
<p>As mentioned in the beginning, the search engine is able to understand very complex queries, including entire paragraphs about ideas. For example, I entered an entire paragraph from an LLM discussion, and found some interesting high quality essays revolving around that and adjacent topics:</p>
<a href="https://blog.wilsonl.in/search-engine/serp-paragraph.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-paragraph.png" alt="Screenshot of SERP for a paragraph about self-worth and high achievers."></a>
<p>The above UI is from the modernized <a href="#live-demo">live demo</a>.</p>
<h3 id="ai-assistant">AI assistant</h3>
<p>As LLMs were taking off around the time (which has only grown since), I decided to see if I could add some subtle useful AI features. I thought they could be helpful in three ways:</p>
<ul>
<li>Provide a very quick concise answer to a straightforward query that doesn't need research.</li>
<li>Have conversations with an AI assistant.</li>
<li>Summarize results relative to the query.</li>
</ul>
<p>It resulted in helpful augmentation without ruining the search experience:</p>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/serp-ai-s3.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-ai-s3.png"></a>
  <figcaption>AI features give quick answers, related questions, and more tailored summaries, while still leaving main experience as is.</figcaption>
</figure>
<figure>
  <a href="https://blog.wilsonl.in/search-engine/serp-guarantee-clause.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-guarantee-clause.png"></a>
  <figcaption>I found the statement snippets to be helpful for official references, while AI provides a quick direct answer.</figcaption>
</figure>
<p>I found it especially useful for programming queries, where I often knew what was right and just needed a quick refresher. The AI quick answer was very concise and to the point, which aligned with my needs.</p>
<a href="https://blog.wilsonl.in/search-engine/serp-ai-go-init-map.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-ai-go-init-map.png"></a>
<p>It's able to remain clear even for more complex queries, while high quality results remain ranked at the top if you want to dive deeper:</p>
<a href="https://blog.wilsonl.in/search-engine/serp-parted.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-parted.png"></a>
<h3 id="state-tracking">State tracking</h3>
<p>Tracking clicks is useful for improving search quality and finding "dead zones", spam results, and poor ranking. To prevent abuse, all results go through an <code>/act</code> URL with an AES-256-GCM encrypted data string containing important result data, which tracks important metrics and then redirects to the result URL.</p>
<p>Since the app is entirely SSR, it used <a href="https://en.wikipedia.org/wiki/Post/Redirect/Get" target="_blank" rel="noopener">PRG</a> to handle client actions. Often, there's a need to show or alter some UX upon redirecting after the action to indicate to the user the result. This means some state needed to be persisted across the POST to the GET, which I decided to use one-off cookies to relay the state, skipping the need for any server-side state. This also allowed the app to remain JS-free.</p>
<h2 id="search-quality">Search quality</h2>
<p>Two big things I learnt about search engine quality:</p>
<ol>
<li>Quantity is quality. If a search engine can't find something, it's not useful.</li>
<li>Crawling and filtering is the most difficult and most important aspect.</li>
</ol>
<p>The first point was obvious in retrospect. It's a limitation of my search engine; due to time and resource constraints, I was unable to crawl the whole web. Since the web and space of information is so large, this means large uneven gaps in search results.</p>
<p>The second point was tricky. The Internet is such a large search space, that figuring out direction and filtering is basically a necessity, to avoid picking up entire swathes of junk, spiralling in ever more deserted corners of the web, or going too deep in one area and leaving gaps in others. Yet this is a hard problem to solve, without a clear immediate starting point or obvious direction/implementation. It has to operate on large amounts of unstructured data, which often means complex <a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank" rel="noopener">language</a> and <a href="https://en.wikipedia.org/wiki/Network_theory#Link_analysis" target="_blank" rel="noopener">network</a> analysis, at the scale of the web. Determining authenticity, trust, originality, accuracy, and quality automatically is not trivial.</p>
<p>I have ideas about how to tackle this, and if I started over I would put more emphasis on researching and developing this aspect first. Infamously, search engines use <a href="https://www.google.com/intl/en_us/search/howsearchworks/how-search-works/ranking-results/" target="_blank" rel="noopener">thousands of signals</a> on ranking and filtering pages, but I believe newer transformer-based approaches towards content evaluation and link analysis should be simpler, cost effective, and more accurate. I also believe agentic search will play a big role in the near future, being able to comprehend, filter, rank, and beam search instead of simple retrieval.</p>
<p>At query time, some basic quality filters are applied:</p>
<ul>
<li>Non-English.</li>
<li>Pages with empty titles or contents.</li>
<li>Matches <a href="https://github.com/hagezi/dns-blocklists" target="_blank" rel="noopener">blocklists</a>.</li>
<li>Duplicates, measured using <a href="https://en.wikipedia.org/wiki/Jaccard_index" target="_blank" rel="noopener">Jaccard similarity</a> of <a href="https://en.wikipedia.org/wiki/Trigram" target="_blank" rel="noopener">trigrams</a>.</li>
</ul>
<h2 id="live-demo">Live demo</h2>
<a href="https://blog.wilsonl.in/search-engine/serp-demo.png" target="_blank" rel="noopener"><img src="https://blog.wilsonl.in/search-engine/serp-demo.png" alt="Screenshot of demo SERP."></a>
<p>I have re-deployed the search engine as a usable demo with a more modern minimalist app that focuses on search results only.</p>
<p>I've added LLM-based reranking and filtering, which those two final sliders represent. I'm experimenting to see if using the latest general intelligence LLMs can help achieve better reranking and filtering without the need for a custom model and training data. <a href="https://groq.com/" target="_blank" rel="noopener">Groq</a> is the inference backend to ensure low latency responses — general intelligence at subsecond latency seems like a powerful underrated tool.</p>
<p>Because this is a demo environment, it's not as low latency as the regular production setup. As mentioned in <a href="#search-quality">search quality</a>, there will be noticeable gaps in search result quality for various queries due to incomplete index and quality filtering. The index cutoff is around August 2023.</p>
<p>Play around with the live demo at <a href="https://search.wilsonl.in/" target="_blank" rel="noopener">search.wilsonl.in</a>.</p>
<h2 id="costs">Costs</h2>
<p>I sought out ways to leverage lesser-known order-of-magnitude cost efficiencies as it was a side project:</p>

































































<div><table><thead><tr><th>Component</th><th>Typical</th><th>Optimized</th><th>Comparison</th></tr></thead><tbody><tr><td>Vector database, billion 768-dim. inserts</td><td>Turbopuffer writes + storage — $3578.88</td><td><a href="https://blog.wilsonl.in/corenn/" target="_blank" rel="noopener">CoreNN</a> on Hetzner Auction — $150</td><td>Turbopuffer is 23.86×</td></tr><tr><td>Memory-heavy server, RAM TB month</td><td>AWS EC2 r7a — $7011.53</td><td>Hetzner Auction — $164.00</td><td>AWS is 42.75×</td></tr><tr><td>Storage server, NVMe TB month</td><td>AWS i4g — $243.30</td><td>Hetzner Auction — $6.63</td><td>AWS is 36.70×</td></tr><tr><td>Internet egress, TB month</td><td>AWS — $92.16</td><td>Oracle Cloud — $8.70</td><td>AWS is 10.59×</td></tr><tr><td>NVIDIA GPU (FP16), hour</td><td>AWS g6e (362 TFLOPS) — $1.86</td><td>Runpod RTX 4090 (660 TFLOPS) — $0.79</td><td>AWS is 4.28× (normalized)</td></tr><tr><td>Write-heavy KV store, billion 1 KB writes</td><td>AWS DynamoDB on-demand — $5000</td><td>RocksDB on Hetzner Auction — $125</td><td>AWS is 40×</td></tr><tr><td>Blob store, billion 100 KB writes</td><td>AWS S3 PUTs and storage — $5000 + $2300</td><td>BlobDB on Hetzner Auction — $250</td><td>AWS is 29.2×</td></tr><tr><td>Queue, billion messages</td><td>AWS SQS (push + poll + delete) — $1200</td><td><a href="https://github.com/wilsonzlin/queued" target="_blank" rel="noopener">queued</a> — ~$0</td><td>AWS is ~∞×</td></tr><tr><td>CPU on-demand, core month</td><td>AWS EC2 m7a — $83.52</td><td>Oracle Cloud E4 — $18.00</td><td>AWS is 4.63×</td></tr></tbody></table></div>
<p>Not only did these low-hanging cost savings save a lot of money when added up, they lowered the barrier that made the project feasible at all, and able to scale on constrained and commodity resources. I was surprised at the lower cost than I expected going in, given the size of the infra and data, involving hundreds of GPUs and terabytes of data.</p>
<p>However, I did have to stop indexing as it was a solo project paid out of pocket. I estimate that this search engine project could be sustained by around 10K $5/month subscriptions, which is not very high for adding another indigenous search index to the limited handful that currently exist in the world, especially one focused on quality and not ads. I think optimizing towards building an index of quality over quantity is also useful for <a href="https://arxiv.org/pdf/2407.21783#page=5" target="_blank" rel="noopener">training LLMs</a>.</p>
<p>There was one surprise when I revisited costs: OpenAI charges an unusually low <a href="https://platform.openai.com/docs/pricing#embeddings" target="_blank" rel="noopener">$0.0001 / 1M tokens</a> for batch inference on their latest embedding model. Even conservatively assuming I had 1 billion crawled pages, each with 1K tokens (abnormally long), it would only cost <strong>$100</strong> to generate embeddings for all of them. By comparison, running my own inference, even with cheap Runpod spot GPUs, would cost on the order of 100× more expensive, to say nothing of <a href="https://cohere.com/pricing" target="_blank" rel="noopener">other</a> <a href="https://jina.ai/embeddings/" target="_blank" rel="noopener">APIs</a>. This wasn't available at the time, so I couldn't take advantage of this, but I'm keeping it in mind for future projects.</p>
<h2 id="conclusion-and-what's-next">Conclusion and what's next</h2>
<p>I find that one of the biggest values of neural embeddings is the ability to find great content, insights, and references. These often reside in essays and documentations, and are article-like content. Queries that are just "bookmarks" (e.g. <code>python download windows</code>) or exact phrase matching require a very broad index (including very obscure pages) but also don't leverage intelligence or comprehension; bookmarks could be indexed only by <code>&lt;title&gt;</code> keywords and URL substrings. Given this, one direction I want to explore is a more focused index that selects specifically for high quality interesting content across the long tail of the web. In general, exploring how to have sub-engines for more accurate, tailored, relevant, and efficient results for different domains and intents is worthwhile.</p>
<p>Embeddings do seem to be far more powerful than traditional search, and seeing the superior quality results (when the index has enough data) made me excited about the future of search and retrieval. With typical search engines, the more specific you get, the worse the results. Being able to narrow down and zoom in via a very specific query to find exactly what you want (quality, vibe, perspective, thought, idea, etc.) via obscure insights and relationships is very powerful and underexplored.</p>
<p>Despite the rise of LLMs, I think that search will always play a role: LLMs can't and shouldn't memorize all knowledge, using parameters that could be used for more intelligence and capability. Instead, LLMs can offload that to representations of knowledge via these efficient dense indices, which would also mean less hallucinations and more up-to-date information. Perhaps we will have community-maintained open-source local search indices alongside our open-source local models.</p>
<p>Besides <a href="#search-quality">systematic data quality assurance</a>, there are other low hanging optimizations to explore:</p>
<ul>
<li>Is it possible to leverage existing crawling infrastructure like <a href="https://commoncrawl.org/" target="_blank" rel="noopener">Common Crawl</a>?</li>
<li>Could <a href="https://huggingface.co/blog/static-embeddings" target="_blank" rel="noopener">static embeddings</a>, which are 400x faster to infer, be used?</li>
<li>Embedding models: <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/" target="_blank" rel="noopener">late chunking</a>, quantization, long context (to avoid chunking), incorporating new knowledge without re-generating all embeddings, and leveraging <a href="https://onnx.ai/" target="_blank" rel="noopener">ONNX</a>.</li>
<li>Leveraging data APIs, dumps, and agreements rather than crawling.</li>
<li>Rewriting the crawler and parser in Rust for order of magnitude speedups.</li>
</ul>
<p>I plan on posting further write-ups on this project, including:</p>
<ul>
<li>A deeper analysis of the crawled index, with large scale visual and textual content evaluations and <a href="https://umap-learn.readthedocs.io/en/latest/" target="_blank" rel="noopener">semantic maps</a>.</li>
<li>Building a dataset from the crawled data, to test recall of the search engine, and compare it to how much knowledge LLMs memorize.</li>
<li>An <a href="https://man7.org/linux/man-pages/man7/io_uring.7.html" target="_blank" rel="noopener">io_uring</a> based KV store written from scratch that did not make it to production.</li>
<li>An investigation into how agentic search, <a href="https://groq.com/" target="_blank" rel="noopener">ultrafast</a> <a href="https://www.cerebras.ai/" target="_blank" rel="noopener">LLM</a> reranking and filtering, and generative UX could alter the search experience.</li>
</ul>
<p>You can subscribe to my <a href="https://wilsonzlin.kit.com/" target="_blank" rel="noopener">email newsletter</a> or <a href="https://blog.wilsonl.in/rss.xml" target="_blank" rel="noopener">RSS feed</a>, or follow me on <a href="https://x.com/wilsonzlin" target="_blank" rel="noopener">X</a> to keep updated on these new posts and other projects I'm working on.</p>
<p>If you found this post interesting, you may also be interested in the <a href="https://blog.wilsonl.in/hackerverse/" target="_blank" rel="noopener">Hackerverse</a>, where I do something similar on a smaller scale (over Hacker News), and <a href="https://blog.wilsonl.in/corenn/" target="_blank" rel="noopener">CoreNN</a>, a billion-scale vector database developed in response to lack of scalability of existing solutions during this project.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Sonnet 4 now supports 1M tokens of context (1114 pts)]]></title>
            <link>https://www.anthropic.com/news/1m-context</link>
            <guid>44878147</guid>
            <pubDate>Tue, 12 Aug 2025 16:02:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/1m-context">https://www.anthropic.com/news/1m-context</a>, See on <a href="https://news.ycombinator.com/item?id=44878147">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Claude Sonnet 4 now supports up to 1 million tokens of context on the Anthropic API—a 5x increase that lets you process entire codebases with over 75,000 lines of code or dozens of research papers in a single request.</p><p>Long context support for Sonnet 4 is now in public beta on the Anthropic API and in Amazon Bedrock, with Google Cloud’s Vertex AI coming soon.</p><h2 id="longer-context-more-use-cases">Longer context, more use cases</h2><p>With longer context, developers can run more comprehensive and data-intensive use cases with Claude, including:</p><ul><li><strong>Large-scale code analysis: </strong>Load entire codebases including source files, tests, and documentation. Claude can understand project architecture, identify cross-file dependencies, and suggest improvements that account for the complete system design.</li><li><strong>Document synthesis:</strong> Process extensive document sets like legal contracts, research papers, or technical specifications. Analyze relationships across hundreds of documents while maintaining full context.</li><li><strong>Context-aware agents: </strong>Build agents that maintain context across hundreds of tool calls and multi-step workflows. Include complete API documentation, tool definitions, and interaction histories without losing coherence.</li></ul><h2 id="api-pricing">API pricing</h2><p>To account for increased computational requirements, <a href="https://www.anthropic.com/pricing#api">pricing</a> adjusts for prompts over 200K tokens:</p><div><div aria-label="Claude Sonnet 4 pricing on the Anthropic API" role="region" tabindex="0"><table><tbody><tr><th> </th><th>Prompts ≤ 200K</th><th>Prompts &gt; 200K</th></tr><tr><td>Input</td><td>$3 / MTok</td><td>$6 / MTok</td></tr><tr><td>Output</td><td>$15 / MTok</td><td>$22.50 / MTok</td></tr></tbody></table></div><figcaption>Claude Sonnet 4 pricing on the Anthropic API</figcaption></div><p>When combined with <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching">prompt caching</a>, users can reduce latency and costs for Claude Sonnet 4 with long context. The 1M context window can also be used with <a href="https://docs.anthropic.com/en/docs/build-with-claude/batch-processing">batch processing</a> for an additional 50% cost savings.</p><h2 id="customer-spotlight-boltnew">Customer spotlight: Bolt.new</h2><p>Bolt.new transforms web development by integrating Claude into their browser-based development platform.</p><p>“Claude Sonnet 4 remains our go-to model for code generation workflows, consistently outperforming other leading models in production. With the 1M context window, developers can now work on significantly larger projects while maintaining the high accuracy we need for real-world coding," said Eric Simons, CEO and Co-founder of Bolt.new.</p><h2 id="customer-spotlight-igent-ai">Customer spotlight: iGent AI</h2><p>London-based iGent AI is advancing the field of software development with Maestro, an AI partner that transforms conversations into executable code.</p><p>"What was once impossible is now reality: Claude Sonnet 4 with 1M token context has supercharged autonomous capabilities in Maestro, our software engineering agent at iGent AI. This leap unlocks true production-scale engineering—multi-day sessions on real-world codebases—establishing a new paradigm in agentic software engineering," said Sean Ward, CEO and Co-founder of iGent AI.</p><h2 id="get-started">Get started</h2><p>Long context support for Sonnet 4 is now in public beta on the Anthropic API for customers with Tier 4 and custom rate limits, with broader availability rolling out over the coming weeks. Long context is also available in Amazon Bedrock, and is coming soon to Google Cloud's Vertex AI. We’re also exploring how to bring long context to other Claude products.</p><p>To learn more about Sonnet 4 and the 1M context window, see our <a href="https://docs.anthropic.com/en/docs/build-with-claude/context-windows#1m-token-context-window">documentation</a> and <a href="https://www.anthropic.com/pricing#api">pricing page</a>.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexity Makes Longshot $34.5B Offer for Chrome (180 pts)]]></title>
            <link>https://www.wsj.com/tech/perplexity-makes-longshot-34-5-billion-offer-for-chrome-5ddb7a22</link>
            <guid>44877656</guid>
            <pubDate>Tue, 12 Aug 2025 15:33:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/perplexity-makes-longshot-34-5-billion-offer-for-chrome-5ddb7a22">https://www.wsj.com/tech/perplexity-makes-longshot-34-5-billion-offer-for-chrome-5ddb7a22</a>, See on <a href="https://news.ycombinator.com/item?id=44877656">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/perplexity-makes-longshot-34-5-billion-offer-for-chrome-5ddb7a22: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[UK government advises deleting emails to save water (131 pts)]]></title>
            <link>https://www.gov.uk/government/news/national-drought-group-meets-to-address-nationally-significant-water-shortfall</link>
            <guid>44877292</guid>
            <pubDate>Tue, 12 Aug 2025 15:12:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gov.uk/government/news/national-drought-group-meets-to-address-nationally-significant-water-shortfall">https://www.gov.uk/government/news/national-drought-group-meets-to-address-nationally-significant-water-shortfall</a>, See on <a href="https://news.ycombinator.com/item?id=44877292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-module="govspeak">
<p>The National Drought Group met today (Monday 11 August) with the current water shortfall situation in England now defined as a “nationally significant incident.”&nbsp;&nbsp;</p>

<p>Five areas are officially in drought, with six more experiencing prolonged dry weather following the driest six months to July since 1976.&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p>Despite the unsettled weather last month, many river flows and reservoir levels in England continued to recede compared to June.&nbsp;&nbsp;&nbsp;</p>

<p>Rainstorms and showers helped mask the fact that July was still the fifth warmest on record.&nbsp;&nbsp;&nbsp;</p>

<p>August has started to see a return of drier conditions and the fourth heatwave of the summer - putting more pressure on already struggling public water supplies and navigational waterways.&nbsp;&nbsp;&nbsp;</p>

<p>The National Drought Group - which includes the Met Office, government, regulators, water companies, the National Farmers’ Union, Canal &amp; River Trust, anglers, and conservation experts – used the meeting to highlight the water-saving measures each sector is taking.&nbsp;&nbsp;&nbsp;</p>

<p>They also praised the public for reducing their own daily usage, with Yorkshire Water reporting a 10% reduction in domestic demand following their hosepipe ban. This equates to saving up to 80 million litres per day – equivalent to 32 Olympic-sized swimming pools.&nbsp;&nbsp;&nbsp;</p>

<p>The less water that is used, the less needs to be abstracted from local rivers – therefore protecting the health of our waterways and wildlife.&nbsp;&nbsp;&nbsp;</p>

<h4 id="the-environment-agencys-director-of-water-and-ndg-chair-helen-wakeham-said">The Environment Agency’s Director of Water and NDG chair, Helen Wakeham said:</h4>
<blockquote>

  <p>The current situation is nationally significant, and we are calling on everyone to play their part and help reduce the pressure on our water environment.&nbsp;&nbsp;</p>

  <p>Water companies must continue to quickly fix leaks and lead the way in saving water. We know the challenges farmers are facing and will continue to work with them, other land users, and businesses to ensure everyone acts sustainably.&nbsp;&nbsp;</p>

  <p>We are grateful to the public for following the restrictions, where in place, to conserve water in these dry conditions. Simple, everyday choices – such as turning off a tap or deleting old emails – also really helps the collective effort to reduce demand and help preserve the health of our rivers and wildlife.</p>
</blockquote>

<p>The recent rainfall has been welcomed by growers, although the impacts from the dry weather remain as farmers continue their harvest.&nbsp;&nbsp;&nbsp;</p>

<p>The National Farmers Union noted how water shortages have impacted the growing season this year. &nbsp;</p>

<h4 id="nfu-vice-president-rachel-hallos-said">NFU Vice-President, Rachel Hallos said:</h4>
<blockquote>

  <p>British farmers and growers continue to face extremely dry conditions, with harvest underway and crop yields proving mixed across the country. Some farms are reporting a significant drop in yields, which is financially devasting for the farm business and could have impacts for the UK’s overall harvest. &nbsp;</p>

  <p>Farming is a long-term industry and there is growing concern about the months ahead. Minimal grass growth means many livestock farmers are already tapping into winter feed stocks, raising the risk of higher production costs later in the year.&nbsp;</p>

  <p>Access to clean, reliable water is essential for food production. What’s worked well during this drought has been early, coordinated communication with stakeholders around licence restrictions and drought permits and orders and it’s crucial this continues.&nbsp;</p>

  <p>To avoid the swing between extreme drought and flooding and to secure water supplies for food production, we urgently need investment in water infrastructure and a more effective planning system.</p>
</blockquote>

<p>Periods of dry weather and low rivers reduce oxygen levels in water that can lead to fish kills and more algal blooms. Lower river flows also prevent wildlife from moving up or downstream.&nbsp;&nbsp;&nbsp;</p>

<p>Drying out wetlands can be devastating for species that depend on those habits while England has seen an increase in wildfires, devastating vulnerable areas of heathland and moorland.&nbsp;&nbsp;&nbsp;</p>

<p>The Met Office updated the group on the future weather outlook, noting drier weather has returned.</p>

<h4 id="chief-meteorologist-at-the-met-office-dr-will-lang-said">Chief Meteorologist at the Met Office, Dr Will Lang said:</h4>
<blockquote>

  <p>This week is starting off warmer than of late across England and Wales with temperatures getting towards the mid-30s Celsius for some in the south.</p>

  <p>While conditions remain mostly&nbsp;settled across the south, the picture is more unsettled further northwest, with rain or showers at times.</p>

  <p>As we move into the second half of August, there are indications of high pressure building and therefore largely settled conditions overall. Although dry weather is more likely, rain, showers or thunderstorms cannot be ruled out.</p>
</blockquote>

<p>The heat and climate change also impact human health, through issues such as heatstroke, dehydration, and respiratory problems.&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p>Steve Reed, Secretary of State for Environment, Food and Rural Affairs, and Philip Duffy, Chief Executive of the Environment Agency, have also briefed Pat McFadden, the Chancellor of the Duchy of Lancaster, about the situation.&nbsp;&nbsp;</p>

<h4 id="speaking-after-attending-the-meeting-water-minister-emma-hardy-said">Speaking after attending the meeting, Water Minister Emma Hardy said:</h4>
<blockquote>

  <p>Working with the National Drought Group, the Government is urgently stepping up its response to ensure we are successfully managing the impacts of ongoing dry weather. &nbsp;</p>

  <p>Water companies must now take action to follow their drought plans - I will hold them to account if they delay.&nbsp;&nbsp;&nbsp;</p>

  <p>We face a growing water shortage in the next decade. That’s why we are pushing ahead with root and branch reform under our Plan for Change, which includes £104 billion of private investment to build nine reservoirs and new pipes to cut leaks.</p>
</blockquote>

<h4 id="current-situation">CURRENT SITUATION</h4>

<ul>
  <li>
    <p>Drought has been declared in: Yorkshire, Cumbria and Lancashire, Greater Manchester Merseyside and Cheshire, East Midlands, and the West Midlands.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Areas in prolonged dry weather (the phase before drought) are: Northeast, Lincolnshire and Northamptonshire, East Anglia, Thames, Wessex, Solent and South Downs.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>The remaining areas are normal: Hertfordshire, London, Kent, Devon and Cornwall.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Yorkshire Water has a Temporary Usage Ban (TUB aka hosepipe ban) in place for all its customers.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Thames, South East Water, and Southern Water have postcode-specific bans.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Reservoirs fell by 2% last week and are now 67.7% full on average across England. The average for the first week of August is 80.5%. Last month, the average was 75.6%&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>The lowest reservoirs are Blithfield (49.1%), Derwent Valley (47.2%), Chew Valley Lake (48.3%), Blagdon (46.3%).&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Rainfall in July was 89% of long-term average for the month across England. This is the sixth consecutive month of below average rainfall.&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Across the country, 51% of river flows were normal with the rest below normal, notably low or exceptionally low.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Two rivers – Wye and Ely Ouse – were the lowest on record for July&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>There are currently navigation closures or restrictions across sections of the Leeds and Liverpool, Macclesfield, Trent and Mersey, Peak Forest, Rochdale, Oxford and Grand Union Canal.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>More information here <a href="https://www.gov.uk/government/publications/dry-weather-and-drought-in-england-summary-reports/dry-weather-and-drought-in-england-25-to-31-july-2025">Dry weather and drought in England: 25 to 31 July 2025 - GOV.UK</a></p>
  </li>
</ul>

<h4 id="actions-by-national-drought-group-members">ACTIONS BY NATIONAL DROUGHT GROUP MEMBERS&nbsp;&nbsp;</h4>

<ul>
  <li>
    <p>The UK Health Security Agency is working with the National Drought Group to update its <a href="https://www.gov.uk/guidance/public-health-impact-of-drought-advice-for-the-public">public health impacts of drought guidance</a>&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Water companies are communicating with customers about current risks and advising them how to use water wisely during this dry period.&nbsp;</p>
  </li>
  <li>
    <p>Water companies have stepped up action on leakage, with leaks down 41% compared to the level in 1989 when the industry was privatised.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Over £700 million has been committed by water companies to tackle leaks over the next five years.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Water companies have committed to reducing leakage by 50% from a 2017-18 baseline by 2050.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Yorkshire Water reported that repairs of leaks identified by smart meters had saved 1.5 million litres per day.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Yorkshire Water is fixing over 800 leaks per week.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Dwr Cymru Welsh Water is fixing over 700 leaks per week.</p>
  </li>
  <li>
    <p>Over 500,000 customers with Anglian Water have had leaks identified via their smart meters. This helped the firm reduce leaks by a total of 187 million litres a day, equivalent to 75 Olympic-sized swimming pools.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Anglian Water’s satellite technology has also helped prioritise leak detection, saving over 320,000 litres of water a day in rural areas, enough to supply 1,000 homes.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Southern Water has 24,000 acoustic sensors attached to the 15,500km of their water network to help detect leaks.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>In the last 12 months, Southern Water have reduced leaks by almost 20%, saving 138.7 million litres per day.&nbsp;</p>
  </li>
  <li>
    <p>Severn Trent has handed out 700 x 1,100 litre bowsers to farmers and several to the West Midlands Safari Park so livestock and animals have water.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Water-saving messaging has helped reduce demand in the Severn Trent area by 20%, compared to the peak on 11th July.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>United Utilities are repairing more than 800 leaks a week and have seen a 200% increase in reports of leaks from customers.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>United Utilities is offering free home water audits in some areas, with more than 3,700 booked in.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Thames Water has installed over one million smart meters, which are critical in helping locate leaks. &nbsp;</p>
  </li>
  <li>
    <p>Since June, Thames Water has fixed over 1,000 leaks in the region impacted by the hosepipe ban.&nbsp;</p>
  </li>
</ul>

<h4 id="drought-and-the-environment-agency">DROUGHT AND THE ENVIRONMENT AGENCY</h4>

<ul>
  <li>
    <p>The Environment Agency continues to work with Government, including Defra and the Cabinet Office, on the drought response.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>The Environment Agency has escalated its operational response and diverted resources to ensure a rapid and nationwide response.&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>It is conducting more compliance checks on businesses who abstract water to ensure regulations are met.&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>It is actively engaging with water companies on requests for drought permits and drought orders and ensuring they follow their drought plans.&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>There is increased monitoring of river and groundwater level and more modelling of rainfall patterns to inform decisions, including additional restrictions.&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>The Environment Agency  is working closely with farmers in East Anglia, requesting voluntary reductions on surface water abstraction. This will help conserve and extend the total period when water is available for abstraction, protect the environment and delay the need for any formal restrictions.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>The regulator has sped up the process of alerting abstractors about restrictions.&nbsp; <a href="https://www.gov.uk/guidance/manage-your-water-abstraction-or-impoundment-licences-online">Manage your water abstraction licence online - GOV.UK</a>.&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>The EA is managing potential navigation issues caused by low flows on the Rivers Thames, Lark and Great Ouse.&nbsp;&nbsp;&nbsp;</p>
  </li>
</ul>

<h4 id="how-to-save-water-at-home">HOW TO SAVE WATER AT HOME</h4>

<ul>
  <li>
    <p>Install a rain butt to collect rainwater to use in the garden.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Fix a leaking toilet – leaky loos can waste 200-400 litres a day.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Use water from the kitchen to water your plants.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Avoid watering your lawn – brown grass will grow back healthy.&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Turn off the taps when brushing teeth or shaving.&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Take shorter showers.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
  </li>
  <li>
    <p>Delete old emails and pictures as data centres require vast amounts of water to cool their systems.</p>
  </li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ex-CIA agents deciding Facebook's content policy (2022) (107 pts)]]></title>
            <link>https://mronline.org/2022/07/14/meet-the-ex-cia-agents-deciding-facebooks-content-policy/</link>
            <guid>44877221</guid>
            <pubDate>Tue, 12 Aug 2025 15:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mronline.org/2022/07/14/meet-the-ex-cia-agents-deciding-facebooks-content-policy/">https://mronline.org/2022/07/14/meet-the-ex-cia-agents-deciding-facebooks-content-policy/</a>, See on <a href="https://news.ycombinator.com/item?id=44877221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>It is an uncomfortable job for anyone trying to draw the line between “harmful content and protecting freedom of speech. It’s a balance”, Aaron says. In this <a href="https://about.facebook.com/regulations/" target="_blank" rel="noopener">official Facebook video</a>, Aaron identifies himself as the manager of “the team that writes the rules for Facebook”, determining “what is acceptable and what is not.” Thus, he and his team effectively decide what content the platform’s 2.9 billion active users see and what they don’t see.</p>
<p>Aaron is being interviewed in a bright warehouse-turned-studio. He is wearing a purple sweater and blue jeans. He comes across as a very likable, smiley person. It is not an easy job, of course, but someone has to make those calls. “Transparency is incredibly important in the work that I do,” he says.</p>
<p>Aaron is CIA. Or at least he was until July 2019, when he left his job as a senior analytic manager at the agency to become senior product policy manager for misinformation at Meta, the company that owns Facebook, Instagram and WhatsApp. In his 15-year career, Aaron Berman rose to become a highly influential part of the CIA. For years, he prepared and edited the president of the United States’ daily brief, “wr[iting] and overs[eeing] intelligence analysis to enable the President and senior U.S. officials to make decisions on the most critical national security issues,” especially on “the impact of influence operations on social movements, security, and democracy,” his LinkedIn <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-017-29-Aaron-Berman-LinkedIn-www.linkedin.com_.png">profile</a> reads. None of this is mentioned in the Facebook video.</p>
<p><img title="Aaron Berman | MR Online" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy-1024x798.jpg" alt="Aaron Berman" width="810" height="631" srcset="https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy-1024x798.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy-350x273.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy-768x598.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy-810x631.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy-1140x888.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-10_edited-copy.jpg 1181w" sizes="(max-width: 810px) 100vw, 810px"></p>
<p>Berman’s case is far from unique, however. Studying Meta’s reports, as well as employment websites and databases, <i>MintPress</i> has found that Facebook has recruited dozens of individuals from the Central Intelligence Agency (CIA), as well as many more from other agencies like the FBI and Department of Defense (DoD). These hires are primarily in highly politically sensitive sectors such as trust, security and content moderation, to the point where some might feel it becomes difficult to see where the U.S. national security state ends and Facebook begins.</p>
<p>In previous investigations, this author has detailed how <a href="https://www.mintpressnews.com/nato-tiktok-pipeline-why-tiktok-employing-national-security-agents/280336/">TikTok is flooded</a> with NATO officials, how <a href="https://www.mintpressnews.com/twitter-hiring-alarming-number-spooks-secret-agents/281114/">former FBI agents</a> abound at Twitter, and how Reddit is led by a <a href="https://www.mintpressnews.com/jessica-ashooh-reddit-national-security-state-plant/277639/">former war planner</a> for the NATO think tank, the Atlantic Council. But the sheer scale of infiltration of Facebook blows these away. Facebook, in short, is utterly swarming with spooks.</p>
<h2>TRUST ME, BRO</h2>
<p>In a political sense, trust, safety and misinformation are the most sensitive parts of Meta’s operation. It is here where decisions about what content is allowed, what will be promoted and who or what will be suppressed are made. These decisions affect what news and information billions of people across the world see every day. Therefore, those in charge of the algorithms hold far more power and influence over the public sphere than even editors at the largest news outlets.</p>
<p>There are a number of other ex-CIA agents working in these fields. Deborah Berman, for example, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-018-29-Deborah-Berman.-LinkedIn-www.linkedin.com_.png">spent</a> 10 years as a data and intelligence analyst at the CIA before recently being brought on as a trust and safety project manager for Meta. Little is known about what she did at the agency, but her pre-agency <a href="https://www.researchgate.net/publication/358031653_5_THE_SYRIAN_NUCLEAR_PUZZLE" target="_blank" rel="noopener">publications</a> indicate she was a specialist on Syria.</p>
<p><img title="Deborah Berman | MR Online" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Deborah-M-1024x689.jpg" alt="Deborah Berman" width="810" height="545" srcset="https://mronline.org/wp-content/uploads/2022/07/Deborah-M-1024x689.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Deborah-M-350x236.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Deborah-M-768x517.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Deborah-M-810x545.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Deborah-M-1140x768.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Deborah-M.jpg 1200w" sizes="(max-width: 810px) 100vw, 810px"></p>
<p>Between 2006 and 2010, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-020-29-Experience-Bryan-Weisbard-LinkedIn-www.linkedin.com_.png">Bryan Weisbard</a> was a CIA intelligence officer, his job entailing, in his own words, leading “global teams to conduct counter-terrorism and digital cyber investigations,” and “Identif[ying] online social media misinformation propaganda and covert influence campaigns”. Directly after that, he became a diplomat (underlining how close the line is between those two professions), and is currently a director of trust and safety, security and data privacy for Meta.</p>
<p>Meanwhile, the LinkedIn profile of <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-019-29-Cameron-Harris-LinkedIn-www.linkedin.com_.png">Cameron Harris</a>–a CIA analyst until 2019–notes that he is now a Meta trust and safety project manager.</p>
<p><img title="Cameron Harris | MR Online" loading="lazy" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-1024x1024.jpg" alt="Cameron Harris" width="810" height="810" srcset="https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-1024x1024.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-350x350.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-200x200.jpg 200w, https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-768x768.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-810x810.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris-1140x1140.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Cameron-Harris.jpg 1200w" sizes="auto, (max-width: 810px) 100vw, 810px"></p>
<p>Individuals from other state institutions abound as well. <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-027-65-Emily-Vacher-LinkedIn-www.linkedin.com_.png">Emily Vacher</a> was an FBI employee between 2001 and 2011, rising to the rank of supervisory special agent. From there she was headhunted by Facebook/Meta, and is now a director of trust and safety. Between 2010 and 2020, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-028-65-Experience-Mike-Bradow-LinkedIn-www.linkedin.com_.png">Mike Bradow</a> worked for USAID, eventually becoming deputy director of policy for the organization. USAID is a U.S. government-funded influence organization which has bankrolled or stage managed multiple regime change operations abroad, including in <a href="https://venezuelanalysis.com/analysis/800" target="_blank" rel="noopener">Venezuela</a> in 2002, <a href="https://www.mintpressnews.com/documents-point-to-us-hand-in-cuba-protests/277987/">Cuba</a> in 2021, and ongoing attempts in <a href="https://thegrayzone.com/2020/08/04/usaid-document-nicaragua-coup/" target="_blank" rel="noopener">Nicaragua</a>. Since 2020, Meta has employed Bradow as a misinformation policy manager.</p>
<p><img title="Emily Vacher | MR Online" loading="lazy" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-1024x1024.jpg" alt="Emily Vacher" width="810" height="810" srcset="https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-1024x1024.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-350x350.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-200x200.jpg 200w, https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-768x768.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-810x810.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher-1140x1140.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Emily-Vacher.jpg 1200w" sizes="auto, (max-width: 810px) 100vw, 810px"></p>
<p>Others have similar pasts. <a href="https://www.linkedin.com/in/neilpotts/details/experience/" target="_blank" rel="noopener">Neil Potts</a>, a former intelligence officer with the U.S. Marine Corps, is vice president of trust and safety at Facebook. In 2020, <a href="https://www.linkedin.com/in/sherikama/" target="_blank" rel="noopener">Sherif Kamal</a> left his job as a program manager at the Pentagon to take up the post of Meta trust and safety program manager.</p>
<p><a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-031-65-Joey-Chan-LinkedIn-www.linkedin.com_.png">Joey Chan</a> currently holds the same trust and safety post as Kamal. Until last year, Chan was a U.S. Army officer commanding a company of over 100 troops in the Asia Pacific region.</p>
<p><img title="Joey Chan | MR Online" loading="lazy" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-1024x1024.jpg" alt="Joey Chan" width="810" height="810" srcset="https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-1024x1024.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-350x350.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-200x200.jpg 200w, https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-768x768.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-810x810.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Joey-Chan-1140x1140.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Joey-Chan.jpg 1200w" sizes="auto, (max-width: 810px) 100vw, 810px"></p>
<p>None of this is to say that any of those named are not conscientious, that they are bad people or bad at their job. Vacher, for example, <a href="https://www.teenvogue.com/story/emily-vacher-interview-facebook-amber-alert-women-in-tech" target="_blank" rel="noopener">helped</a> design Facebook’s amber alert program, notifying people to missing children in their area. But hiring so many ex-U.S. state officials to run Facebook’s most politically sensitive operations raises troubling questions about the company’s impartiality and its proximity to government power. Meta is so full of national security state agents that at some point, it almost becomes more difficult to find individuals in trust and safety who were <i>not</i> formerly agents of the state.</p>
<p>Despite its <a href="https://www.independent.co.uk/news/world/americas/cia-recruitment-video-backlash-wokeness-b1841656.html" target="_blank" rel="noopener">efforts</a> to brand itself as a progressive, “woke” organization, the Central Intelligence Agency remains deeply controversial. It has been charged with <a href="https://www.mintpressnews.com/cia-continues-cover-involvement-chiles-911-coup/220254/">overthrowing</a> or attempting to overthrow <a href="https://www.mintpressnews.com/state-department-release-official-history-of-cia-orchestrated-iranian-coup/228961/">numerous</a> foreign governments (some of them democratically elected), <a href="https://ips-dc.org/the_cias_worst-kept_secret_newly_declassified_files_confirm_united_states_collaboration_with_nazis/" target="_blank" rel="noopener">helping</a> prominent Nazis escape punishment after World War Two, funnelling large quantities of <a href="https://www.mintpressnews.com/cia-afghanistan-drug-trade-opium/277780/">drugs</a> and <a href="https://ips-dc.org/the_cia_contras_gangs_and_crack/" target="_blank" rel="noopener">weapons</a> around the world, <a href="https://www.mintpressnews.com/spooks-establishment-journalists-circling-wagons/281217/">penetrating</a> domestic media outlets, routinely spreading false information and <a href="https://www.mintpressnews.com/cia-guantanamo-bay-torture-programs-mkultra-roots/280275/">operating</a> a global network of “black sites” where prisoners are repeatedly tortured. Therefore, critics argue that putting operatives from this organization in control of our news feeds is deeply inappropriate.</p>
<p>One of these critics is Elizabeth Murray, who, in 2010, retired from a 27-year career at the CIA and other U.S. intelligence organizations. “This is insidious,” Murray told <i>MintPress</i>, adding,</p>
<blockquote><p>I see it as part of the gradual and sinister migration of ambitious young professionals originally trained (with CIA’s virtually unlimited, U.S.-taxpayer funded pot of resources) to surveil and target ‘the bad guys’ during the so-called Global War on Terror of the post-9-11 era.</p></blockquote>
<p><i>MintPress</i> also contacted Facebook/Meta for comment but has not received a response.</p>
<h2>ARM’S LENGTH CONTROL</h2>
<p>Some may ask what the big fuss is. There is a limited pool of individuals with the necessary skills and experience in these new tech and cybersecurity fields, and many of them come from government institutions. Casinos, after all, regularly hire card sharks to protect themselves. But there is little evidence that this is a poacher-turned-gamekeeper scenario; Facebook is certainly not hiring whistleblowers. The problem is not that these individuals are incompetant. The problem is that having so many former CIA employees running the world’s most important information and news platform is only one small step removed from the agency itself deciding what you see and what we do not see online–and all with essentially no public oversight.</p>
<p>In this sense, this arrangement constitutes the best of both worlds for Washington. They can exert significant influence over global news and information flows but maintain some veneer of plausible deniability. The U.S. government does not need to directly tell Facebook what policies to enact. This is because the people in decision-making positions are inordinately those who rose through the ranks of the national security state beforehand, meaning their outlooks match those of Washington’s. And if Facebook does not play ball, quiet threats about regulation or breaking up the company’s enormous monopoly can also achieve the desired outcomes.</p>
<p>Again, this article is not claiming that any of the named individuals are nefarious actors, or even that they are anything but model employees. This is a structural problem. Put another way, if Facebook were hiring dozens of managers from Russian intelligence agencies like the FSB or GRU, everybody would recognize the inherent dangers. It should be little different when it hires individuals from the CIA, an organization responsible for some of the worst crimes of the modern era.</p>
<h2>FROM STATE INTELLIGENCE TO PRIVATE INTELLIGENCE</h2>
<p>Facebook has also hired a plethora of ex-national security state officers to run its intelligence and online security operations. Until 2013, <a href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-032-65-Scott-Stern-LinkedIn-www.linkedin.com_.png">Scott Stern</a> was a targeting officer at the CIA, rising to become chief of targeting. In this role, he helped select the targets for U.S. drone strikes across South and West Asia. Today, however, as a senior manager of risk intelligence for Meta, “misinformation” and “malicious actors” are his targets. Hopefully he is more accurate at Facebook than at the CIA, where the government’s own internal assessments <a href="https://www.amnesty.org.uk/thank-you-us-deadly-drones" target="_blank" rel="noopener">show</a> that at least 90% of Afghans killed in drone strikes were innocent civilians.</p>
<p>Other former CIA men at Facebook include <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-034-65-Mike-Torrey-LinkedIn-www.linkedin.com_.png">Mike Torrey</a>, who left his job as a senior analyst at the agency to become Meta’s technical lead of detection, investigations and disruptions of complex information operations threats, and former CIA contractor <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-035-65-Hagan-Barnett-LinkedIn-www.linkedin.com_.png">Hagan Barnett</a>, who is now head of harmful content operations at the Silicon Valley giant.</p>
<p><img title="Hagan Barnett | MR Online" loading="lazy" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-1024x1024.jpg" alt="Hagan Barnett" width="810" height="810" srcset="https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-1024x1024.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-350x350.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-200x200.jpg 200w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-768x768.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-810x810.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy-1140x1140.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-5-copy.jpg 1200w" sizes="auto, (max-width: 810px) 100vw, 810px"></p>
<p>Meta’s intelligence and online security team includes individuals from virtually every government agency imaginable. In 2015, Department of Defense intelligence officer <a href="https://www.linkedin.com/in/suzannalee/" target="_blank" rel="noopener">Suzanna Morrow</a> left her post to become director of global security intelligence for Meta. The FBI is represented by threat investigations manager <a href="https://www.linkedin.com/in/ellen-nixon-b160b771/" target="_blank" rel="noopener">Ellen Nixon</a> and head of cyber espionage investigations <a href="https://www.cyberwarcon.com/mike-dvilyanski" target="_blank" rel="noopener">Mike Dvilyanski</a>. Facebook’s influence operations policy manager <a href="https://www.linkedin.com/in/olgabelogolova/details/experience/" target="_blank" rel="noopener">Olga Belogolova</a> had stints at the State Department and the Office of the Secretary of Defense.</p>
<p>Before Meta, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-039-65-Experience-David-Agranovich-LinkedIn-www.linkedin.com_.png">David Agranovich</a> and <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-040-65-Experience-Nathaniel-Gleicher-LinkedIn-www.linkedin.com_.png">Nathaniel Gleicher</a> both worked for the National Security Council. Agranovich is director of global threat disruption at Facebook while Gleicher is head of security policy. <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-041-65-Hayley-Chang.-LinkedIn-www.linkedin.com_.png">Hayley Chang</a>, director and associate general counsel for cybersecurity and investigations, worked formerly for both the FBI and Department of Homeland Security. And Meta’s global head of interaction operations, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-042-65-Experience-David-Hansell-LinkedIn-www.linkedin.com_.png">David Hansell</a>, was once an Air Force and Defense Intelligence Agency man.</p>
<p><img title="Suzanna Morrow | MR Online" loading="lazy" decoding="async" src="https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-1024x1024.jpg" alt="Suzanna Morrow" width="810" height="810" srcset="https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-1024x1024.jpg 1024w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-350x350.jpg 350w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-200x200.jpg 200w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-768x768.jpg 768w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-810x810.jpg 810w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy-1140x1140.jpg 1140w, https://mronline.org/wp-content/uploads/2022/07/Untitled-design-6-copy.jpg 1200w" sizes="auto, (max-width: 810px) 100vw, 810px"></p>
<p>One of Meta’s most outwardly-facing employees is its global threat intelligence lead for influence operations, Ben Nimmo, a character <i>MintPress</i> has <a href="https://www.mintpressnews.com/nicaraguans-ignore-facebook-spooks-trick-treating-election/278870/">covered</a> before. Between 2011 and 2014, he served as NATO’s press officer, moving the next year to the Institute for Statecraft, a <a href="https://www.mintpressnews.com/new-documents-reveal-covert-uk-military-intelligence-smear-machine-meddling-in-us-politics/253658/"> U.K. government-funded</a> propaganda operation aimed at spreading misleading information about enemies of the British state. He was also a senior fellow at the Atlantic Council, NATO’s semi-official think tank.</p>
<p>Perhaps then, it is not surprising that Facebook never seems to find U.S. government influence operations online–they are part of one!</p>
<h2>CYBER WAR, CYBER WARRIORS</h2>
<p>While Meta has not unmasked any nefarious U.S. government action, it regularly uncovers what it claims are foreign disinformation campaigns. According to a recent Facebook <a href="https://about.fb.com/wp-content/uploads/2021/05/IO-Threat-Report-May-20-2021.pdf" target="_blank" rel="noopener">report</a>, the top five locations of coordinated inauthentic behavior between 2017 and 2020 on its platform are Russia, Iran, Myanmar, the United States and Ukraine. However, it was at pains to note that American operations were driven by fringe far-right elements, white supremacists and conspiracy theorists, and not the government.</p>
<p>This is despite the fact that it is now well-established that the Pentagon fields a clandestine army of at least 60,000 people whose job is to influence public opinion, the majority of them doing so from their keyboards. A <a href="https://www.newsweek.com/exclusive-inside-militarys-secret-undercover-army-1591881" target="_blank" rel="noopener"><i>Newsweek</i></a> exposé from last year called it “The largest undercover force the world has ever known,” adding,</p>
<blockquote><p>The explosion of Pentagon cyber warfare, moreover, has led to thousands of spies who carry out their day-to-day work in various made-up personas, the very type of nefarious operations the United States decries when Russian and Chinese spies do the same.</p></blockquote>
<p><i>Newsweek</i> warned that this army was likely breaking both U.S. and international law by doing so, explaining that,</p>
<blockquote><p>These are the cutting-edge cyber fighters and intelligence collectors who assume false personas online, employing ‘nonattribution’ and ‘misattribution’ techniques to hide the who and the where of their online presence while they search for high-value targets and collect what is called ‘publicly accessible information’—or even engage in campaigns to influence and manipulate social media.</p></blockquote>
<p>As far back as 2011, <a href="https://www.theguardian.com/technology/2011/mar/17/us-spy-operation-social-networks" target="_blank" rel="noopener"><i>The Guardian</i></a> was reporting on this enormous cyber force, whose job it was to “secretly manipulate social media sites by using fake online personas to influence internet conversations and spread pro-American propaganda.” Yet the ex-military and ex-CIA officials Facebook employs do not seem to have found any trace of their former colleagues’ at work on the platform.</p>
<h2>DIGITALLY SWINGING ELECTIONS</h2>
<p>Since its beginnings in 2004, Facebook has grown to become a massive global empire and by far the most important news distributor the planet has ever known. The company boasts almost <a href="https://investor.fb.com/investor-news/press-release-details/2022/Meta-Reports-First-Quarter-2022-Results/default.aspx" target="_blank" rel="noopener">3 billion</a> active users, meaning that nearly 2 in 5 people worldwide use the platform. A recent 12-country study <a href="https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2022-06/Digital_News-Report_2022.pdf" target="_blank" rel="noopener">suggested</a> that around 30% of the entire world gets its news via their Facebook feeds. This gives whoever is in charge of curating those feeds and controlling those algorithms inestimable power. It also represents a serious national security threat for all other countries, especially those that might wish to take a path independent from the United States. That those people are in large part former spooks makes this threat all the more perilous.</p>
<p>This is far from a hypothetical quandary. In November, less than a week before the country’s election, Facebook took the decision to <a href="https://www.mintpressnews.com/meet-nicaraguans-facebook-falsely-branded-bots-censored-days-elections/278835/">delete</a> hundreds of pages and accounts belonging to individuals and groups that supported the Nicaraguan Sandinista party–a longtime U.S. target for regime change. These included many of the nation’s most influential journalists and media outlets. Considering that around <a href="https://napoleoncat.com/stats/facebook-users-in-nicaragua/2020/02/" target="_blank" rel="noopener">half of the country</a> uses the platform for news and entertainment, the decision could barely have been more intrusive, and was likely designed to try to swing the election towards the pro-U.S. candidate.</p>
<p>Facebook <a href="https://about.fb.com/news/2021/11/october-2021-coordinated-inauthentic-behavior-report/" target="_blank" rel="noopener">claims</a> that those accounts were bots engaged in “inauthentic behavior.” When those individuals migrated on to Twitter, recording videos identifying who they were to show they were not bots, Twitter immediately <a href="https://www.mintpressnews.com/meet-nicaraguans-facebook-falsely-branded-bots-censored-days-elections/278835/">deleted</a> those accounts too, in what was dubbed a coordinated attempt at suppression.</p>
<p>The individual behind this attempt was the aforementioned Ben Nimmo, who co-authored an unconvincing <a href="https://about.fb.com/wp-content/uploads/2021/11/October-2021-CIB-Report-Updated-Nov-5.pdf" target="_blank" rel="noopener">report</a>, full of questionable assumptions and allegations. This included an insinuation that accounts following a pattern of activity whereby their Facebook usage levels peaked in the morning and afternoon and dwindled to almost nothing after midnight Nicaragua time suggested they were bots.</p>
<p>Facebook was also <a href="https://www.mintpressnews.com/private-facebook-group-organized-july-protests-cuba-plans-bigger-ones-soon/278598/">used</a> by right-wing Cubans to attempt a U.S.-backed color revolution against the ruling Communist government last year.</p>
<p>Giving any individual or group that much control over the airwaves of communication raises huge questions about national security and sovereignty–doubly so when those individuals are so intimately connected to the U.S. national security state.</p>
<p>When asked what the public’s reaction would be to the news of such an intimate connection between Facebook her former employer, Murray stated that she was unsure whether many would be bothered:</p>
<blockquote><p>I would like to think that the American public would strenuously object. However the CIA and other agencies have worked over many decades to cultivate a positive–indeed almost glamorous–image in the eyes of the vast majority of the public, mostly through TV series, Hollywood films, and favorable media coverage–so sadly my guess is that the vast majority of the public probably believes that these are the folks who should be in charge.</p></blockquote>
<p>However, she said, the news would likely land a very different way in countries that have been the target of Washington’s ire. “As you’re no doubt aware, the CIA has an atrocious public reputation in most parts of the world,” she added.</p>
<h2>SPOOKS IN EVERY DEPARTMENT</h2>
<p><i>MintPress</i> has found former representatives of the U.S. national security state in virtually every politically sensitive department at Facebook. This includes even higher levels. Between 2020 and 2021, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-043-65-Experience-Kris-Rose-LinkedIn-www.linkedin.com_.png">Kris Rose</a> was a member of Meta’s governance oversight board–the group responsible for the overall direction of the platform. He left his job at the Director of National Intelligence as the president’s daily brief writer to take up the role. Before that, he had spent six years at the CIA as a political and counterterrorism analyst. Meanwhile, <a href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-044-65-Gina-Kim-Sumilas-LinkedIn-www.linkedin.com_.png">Gina Kim Sumilas</a>, Facebook’s director and associate general counsel for the Asia Pacific region, spent nearly twelve years in the CIA before moving into the tech private sector.</p>
<p>There is also considerable overlap with the U.S. government in the company’s front facing staff. <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-045-65-Experience-Kadia-Koroma-LinkedIn-www.linkedin.com_.png">Kadia Koroma</a>, for instance, was plucked from her position as an FBI spokesperson in January 2020 to become media relations manager at Facebook. <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-046-65-Experience-Jeffrey-Gelman-LinkedIn-www.linkedin.com_.png">Jeffrey Gelman</a>, policy communications manager for Facebook’s oversight board, is a member of the Council on Foreign Relations and held influential roles in both the State Department and the National Security Council. And executive communications spokesman <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-047-65-Experience-Kevin-Lewis-LinkedIn-www.linkedin.com_.png">Kevin Lewis</a> spent many years in the White House as President Obama’s spokesperson.</p>
<p>Meta’s vice president of legal strategy is <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-048-65-Rachel-Carlson-Lieber-LinkedIn-www.linkedin.com_.png">Rachel Carlson Lieber</a>, who went straight from the CIA into Facebook. Her first role at the Silicon Valley giant was as head of the North America regulatory and strategic response, a department that continues to feature a number of former state officials. This includes head of strategic programs, <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-049-65-Robert-Flaim-LinkedIn-www.linkedin.com_.png">Robert Flaim</a>, who spent more than twenty years as an FBI, and <a href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-050-65-Experience-Erin-C.-LinkedIn-www.linkedin.com_.png">Erin Clancy</a>, who left a 16-year career at the State Department to become a manager of strategic response policy.</p>
<p>Clancy’s official work centered around U.S. policy in the Middle East. Her own bio boasts that she worked on the U.S. sanctions regime placed on Iraq and Sudan. She also worked at the U.S. Embassy in Damascus at the time of the Arab Spring and the beginning of the Syrian Civil War. It is known that she also <a href="https://www.atlanticcouncil.org/about/lgbti-at-the-council/lgbti-in-foreign-affairs-fellowship/meet-the-lgbti-fellows/" target="_blank" rel="noopener">coordinated closely</a> with the White Helmets, a controversial aid organization that some have <a href="https://www.mintpressnews.com/spooks-establishment-journalists-circling-wagons/281217/">alleged</a> is far too close to Al-Qaeda and its affiliates. Even after her Facebook appointment, Clancy moonlighted as a member of the Council on Foreign Relations and as a fellow at the Atlantic Council, the hawkish body that serves as NATO’s brain trust.</p>
<p>Why are these national security state officials so attractive to Meta? One reason, Murray explained, is financial. “By snagging a CIA employee a company can save a considerable sum,” she said, explaining that, “The individual has likely undergone extensive professional training (at taxpayer expense) and probably has a security clearance,” something that is difficult, expensive and time-consuming to obtain in private sector work. Therefore, companies dealing with matters of state secrecy (such as defense contractors) have historically courted both current and former officers to fill their ranks, enticing them with much higher salaries than they can receive in government service.</p>
<blockquote><p>“What is new (or at least newly known to us!) is that now these professionals are being sought after by social media companies like Facebook, Google and others who are now heavily into monitoring, surveilling, and censoring content, and then sharing data about users with U.S. government entities,” Murray added.</p></blockquote>
<p>Such is the need for these individuals in these fields that private companies often hire former national security agents to do the recruiting for them. For instance, <a href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-051-65-Experience-John-L.-Papp-Jr.-LinkedIn-www.linkedin.com_.png">John Papp</a>, who spent 12 years at the CIA as a senior intelligence officer and 4 years as an imagery analyst at the Defense Intelligence Agency, went on to work as a recruiter for many of the largest <a href="https://www.mintpressnews.com/1-3-big-defense-contractors-profit-us-prisoner-suffering/279648/">defense contractors</a> in Washington. These included Booz Allen Hamilton, Raytheon, Northrop Grumman, IBM and Lockheed Martin. Today, he works as a recruiter for Meta.</p>
<p>Perhaps unsurprisingly, Meta also employs former spooks for their internal security operations. The company’s vice president, chief security officer is <a href="https://www.linkedin.com/in/nick-lovrien-cpp-a5a98392/details/experience/" target="_blank" rel="noopener">Nick Lovrien</a>, a former counterterrorism operations officer at the CIA, while its head of insider protection is ex-CIA operational psychologist and “<a href="https://thegooddrnik.com/about-dr-nik/" target="_blank" rel="noopener">undercover officer</a>” <a href="https://www.linkedin.com/in/drnikalford/" target="_blank" rel="noopener">Nicole Alford</a>.</p>
<p>Meanwhile, Meta’s director of global security governance–the individual <a href="https://futurism.com/the-byte/zuckerberg-panic-chute-escape-facebook" target="_blank" rel="noopener">reportedly</a> responsible for the personal safety of Facebook co-founder Mark Zuckerberg–is <a title="" href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-055-65-Jill-Leavens-Jones-LinkedIn-www.linkedin.com_.png">Jill Leavens Jones</a>. Jones left her job as a U.S. Secret Service special agent to take the appointment. And director of global security operations <a href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-056-65-Experience-Alexander-Carrillo-LinkedIn-www.linkedin.com_.png">Alexander Carrillo</a> continued on as a lieutenant commander in the Coast Guard for several months after his appointment at Facebook. The company also hires former feds to work directly with law enforcement on legal issues. One example of this is former FBI special agent <a href="https://www.mintpressnews.com/wp-content/uploads/2022/07/FireShot-Capture-057-65-Brian-Kelley-LinkedIn-www.linkedin.com_.png">Brian Kelley</a>.</p>
<h2>A LONG PATTERN OF INFILTRATION</h2>
<p>45 years ago, legendary journalist Carl Bernstein released an <a href="https://www.mintpressnews.com/spooks-establishment-journalists-circling-wagons/281217/">investigation</a> documenting how the CIA had managed to infiltrate U.S. and global media. The CIA had placed hundreds of agents into newsrooms and had convinced hundreds more reporters to collaborate with them. These included individuals at some of the most influential outlets, including <i>The New York Times</i>. The CIA needed to do this clandestinely because any attempt to do so openly would harm the effectiveness of the operation and provoke stiff public resistance. But by 2015, there was barely a murmur of disapproval when <i>Reuters</i> announced that it was hiring 33-year veteran CIA manager and director Dawn Scalici as a global director, even when the company <a href="https://www.thomsonreuters.com/en-us/posts/authors/dawn-scalici/" target="_blank" rel="noopener">announced</a> that her primary responsibility was to “advanc[e] Thomson Reuters’ ability to meet the disparate needs of the U.S. government.”</p>
<p>Facebook, however, is vastly more influential than the <i>New York Times</i> or <i>Reuters</i>, reaching billions of people daily. In that sense, it stands to reason that it would be a prime target of any intelligence organization. It has become so big and ubiquitous that many consider it a de facto public commons and believe it should no longer be treated as a private company. Considering who is making many of the decisions on the platform, that distinction between public and private entities is even more blurry than many presume.</p>
	</div><p><i>Monthly Review</i> does not necessarily adhere to all of the views conveyed in articles republished at MR Online. Our goal is to share a variety of left perspectives that we think our readers will find interesting or useful. 
		</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why are there so many rationalist cults? (464 pts)]]></title>
            <link>https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults</link>
            <guid>44877076</guid>
            <pubDate>Tue, 12 Aug 2025 14:56:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults">https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults</a>, See on <a href="https://news.ycombinator.com/item?id=44877076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<div data-mode="add-marker">
		<p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
		
	</div>

	<section>
				
		 			<h2>
				   
					<span>Ozy Brennan</span>
							</h2>
			</section>
	
			<section id="rangyscope">
					<p>There’s a lot to like about the Rationalist community, but they do have a certain tendency to spawn — shall we say — high demand groups. We sent a card-carrying Rat to investigate what’s really going on.</p>
				<div>
											<div><p>The rationalist community was drawn together by AI researcher Eliezer Yudkowsky’s blog post series The Sequences, a set of essays about how to think more rationally. You would think, then, that they’d be paragons of critical thinking and skepticism — or at least that they wouldn’t wind up summoning demons. &nbsp;</p><p>And yet, the rationalist community has hosted perhaps half a dozen small groups with very strange beliefs (including two separate groups that wound up interacting with demons). Some — which I won’t name in this article for privacy reasons — seem to have caused no harm but bad takes. But the most famous, a loose group of vegan anarchist transhumanists nicknamed the Zizians, have been linked to <a href="https://www.wired.com/story/delirious-violent-impossible-true-story-zizians/">six violent deaths</a>. Other groups, while less violent, have left a trail of trauma in their wake. One is Black Lotus, a Burning Man camp led by alleged rapist Brent Dill, which developed a metaphysical system based on the tabletop roleplaying game Mage the Ascension. Another is Leverage Research, an independent research organization that became sucked into the occult and wound up as Workplace Harassment With New Age Characteristics.&nbsp;</p><p>For this article, I spoke to ten people who were associated with various rationalist-adjacent groups, including Black Lotus, Leverage Research, and the Zizians. I also spoke with people who were familiar with the early development of the rationalist community. I myself am a rationalist, and the rationalist community is closely knit; my interviewees included exes, former clients, and the dad of my kid’s best friend. I am close to my subject in a way most journalists aren’t. At the same time, I got an unprecedented level of access and honesty from members of a community that is often hostile to outsiders.&nbsp;</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/11/why-are-there-so-many-rationalist-cults/b614cade73-1752695106/banach.png" alt="">
  </p>
    <p>
    Karol Banach  </p>
  </figure>
</div>
											<p><h2>The problem of young rationalists</h2>
</p>
											<div><p>The rationalist community as a whole is remarkably functional. Like any subculture, it is rife with gossip, personality conflicts, and drama that is utterly incomprehensible to outsiders. But overall, the community’s activities are less drinking the Kool-Aid and more mutual support and vegan-inclusive summer barbeques.&nbsp;</p><p>Nevertheless, some groups within the community have wound up wildly <em>dys</em>functional–a term I’m using to sidestep definitional arguments about what is and isn’t a cult. And some of the blame can be put on the rationalist community’s marketing.</p><p>The Sequences make certain implicit promises. <em>There is an art of thinking better, and we’ve figured it out. If you learn it, you can solve all your problems, become brilliant and hardworking and successful and happy, and be one of the small elite shaping not only society but the entire future of humanity.&nbsp;</em></p><p>This is, not to put too fine a point on it, not true.&nbsp;</p><p>Multiple interviewees remarked that the Sequences create the raw material for a cult. To his credit, their author, Eliezer Yudkowsky, shows little interest in running one. He has consistently been distant from and uninvolved in rationalist community-building efforts, from Benton House (the first rationalist group house) to today’s Lightcone Infrastructure (which hosts LessWrong, an online forum, and Lighthaven, a conference center). He surrounds himself with people who disagree with him, discourages social isolation, and rarely directs his fans to do anything other than read his BDSM-themed fanfiction.&nbsp;</p><p>But people who are drawn to the rationalist community by the Sequences often <em>want</em> to be in a cult. To be sure, no one wants to be exploited or traumatized. But they want some trustworthy authority to change the way they think until they become perfect, and then to assign them to their role in the grand plan to save humanity. They’re disappointed to discover a community made of mere mortals, with no brain tricks you can’t get from Statistics 101 and a good CBT workbook, whose approach to world problems involves a lot fewer grand plans and a lot more muddling through.</p><p>Black Lotus used a number of shared frameworks, including the roleplaying game Mage: the Ascension, that would allow them to cut through social norms and exercise true agency over their lives. Brent supposedly had the most insight into the framework, and so had a lot of control over the members of Black Lotus — control he was unable to use wisely.&nbsp;</p><p>However, if Brent wasn’t there, Black Lotus would have been fine. One interviewee said that, when Brent wasn’t there, Black Lotus led to beautiful peak experiences that he still cherishes: “Brent surrounded himself with people who built the thing he yearned for, missed, and couldn’t have.”&nbsp;</p><p>But in other cases — as in Leverage Research — the toxic dynamics emerged from the&nbsp; bottom up. Interviewees with experience at Leverage Research were clear that there was no single wrongdoer. Leverage was fractured into many smaller research groups, which did everything from writing articles about the grand scope of human history to incubating a cryptocurrency. Some research groups stayed basically normal to the end; others spiralled into self-perpetuating cycles of abuse. In those research groups, everyone was a victim and everyone was a perpetrator. The trainer who broke you down in a marathon six-hour debugging session was unable to sleep because of the panic attacks caused by her own.</p><p>Worse, the promise of the Sequences is more appealing to people who have very serious life problems they need desperately to solve. While some members of dysfunctional rationalist groups are rich, stable, and as neurotypical as rationalists ever get, most are in precarious life positions: mentally ill (sometimes severely), traumatized, survivors of abuse, unemployed, barely able to scrape together enough money to find a place to sleep at night in the notoriously high-rent Bay Area. Members of dysfunctional rationalist groups are particularly likely to be transgender: transgender people are often cut off by their families and may have a difficult time finding friends who accept them as they are. The dysfunctional group can feel like a safe haven from the transphobic world.&nbsp;</p><p>People in vulnerable positions are both more likely to wind up mistreated and less likely to be able to leave. Elizabeth Van Nostrand, who knows many members of dysfunctional groups both rationalist and non-rationalist, said, “I know people who've had very good experiences in organizations where other people had very bad ones. Sometimes different people come out of the same group with very different experiences, and one of the major differences is whether they feel secure enough to push back or leave if they need to. There isn't a substitute for a good BATNA.”<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
</p><p>Still, vulnerability alone can’t explain why some members of the rationalist community end up in abusive groups. Mike Blume was a member of Benton House, which was intended to recruit talented young rationalists. He said, “I was totally coming out of a super depressive and dysfunctional phase in my life, and this was a big upswing in my mood and ability to do things. We were doing something really important. In retrospect, I feel like this is the sort of thing you can't do forever. You burn out on it eventually. But I would wake up in the morning and I'd be a little bit tired and trying to get out of bed and I'd be like, well, you know, the lightcone<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
 depends on me getting out of bed and going to sleep and learning how to program. So I'd better get on that.”</p><p>Mike Blume was depressed, lonely, and unemployed when he entered the rationalist community, and he sincerely believed in both the art of rationality and the importance of the cause. The difference wasn’t his vulnerability. The difference was that his community helped him use his idealism and belief in the cause to learn real skills, become less depressed, and get to a more stable place.</p><p>One interviewee observed that the early rationalist community had been more supportive of less functional rationalists, perhaps because it was smaller. While it wasn’t capable of transforming them into a superhumanly rational elite (no one can do that), it helped them learn useful skills, and become independent. This interviewee said that, once the early rationalists became functional, they pulled the ladder up behind them. They (understandably) only wanted to hang out with people who already have their shit together. But without the support of more successful people, less functional new rationalists can be easy prey for anyone willing to offer help. &nbsp;</p><p>I’m not sure I agree. The early rationalist community had a number of success stories; it also had a guy that multiple people referred to, sighed, and said “that wasn’t a cult, he just did too many whippets.” The rationalist community I see provides a lot of support to many people who are neurodivergent, traumatized, or transgender; it also fails a lot of people. &nbsp;</p></div>
											<p><h2>Taking ideas seriously</h2>
</p>
											<div><p>When discussing dysfunctional or abusive groups, many academics treat their beliefs as secondary. The real coercive control comes from threats or sleep deprivation, social isolation or the manipulations of the leader; the beliefs are so many rationalizations. Most of my interviewees took great pains to say that this wasn’t true for them. While the problems were certainly exacerbated by social isolation and other interpersonal dynamics, the core reason for the dysfunctionality was the beliefs.</p><p>It’s difficult to understand the internal dynamics of the Zizians. They don’t have former members, and members tend to isolate themselves from their former friends. So anything I say about them is inherently speculative.</p><p>However, my interviewees and my own experiences are unequivocal: when the Zizians stabbed their landlord with a katana or got in a shootout with the cops, this was <em>really actually</em> because they believed an obscure version of decision theory that meant that you should always escalate when threatened. Social isolation likely made these beliefs seem more plausible, and their&nbsp; meditation techniques — including their belief that half of the brain can fall asleep while the other half remains awake, known as “hemispheric sleep” — likely made them less able to reason rationally.&nbsp;</p><p>But, long before weapons and violence were brought into the mix, Zizians seriously and coherently argued for their unusual version of decision theory. Their actions derive directly from beliefs they had for years. And several Zizians behaved violently without any opportunity for anyone to exercise coercive control. Most notably, Maximilian Snyder allegedly murdered Curtis Lind, who was the primary witness in the case against several Zizians. Before he was arrested, Snyder seems to have had little contact with Ziz other than reading her blog.</p><p>Leverage Research put a lot of work into developing a grand unified theory of psychology. What they called “Connection Theory” purported to explain how people’s goals, beliefs, and other mental processes interrelated. “Charting”— diagramming how an individual’s mental processes are connected — would allow people to understand themselves and resolve their mental problems. Charting was combined with “belief reporting”: setting a firm intention to tell the truth and then saying what you ‘really’ believe.</p><p>People would try to act in accordance with the artificially simple model of the mind created by these techniques, which could in itself cause mental health problems. For example, someone who belief-reported that they didn’t love their partner could wind up breaking up with their partner, even if in reality it just reflected transient irritation. But Leverage soon noticed that Connection Theory wasn’t a complete explanation of the mind. They began to explore alternate models, such as bodywork.&nbsp;</p><p>Through their explorations of bodywork and other “woo” practices, Leverage researchers began to believe that mental processes can interact and pass from mind to mind through microexpressions and other subconscious things. Leverage researchers initially used “demons” as a metaphor for these mental processes, but over time many researchers became more convinced that the occult was a real, powerful way to manipulate the subconscious. Occult beliefs pervaded many research groups. Routine tasks, such as deciding whose turn it was to pick up the groceries, required working around other people’s beliefs in demons, magic, and other paranormal phenomena. Eventually these beliefs collided with preexisting social conflict, and Leverage broke apart into factions that fought with each other internally through occult rituals.&nbsp;</p><p>Similarly, Brent promoted a cynical version of the world, in which humans were inherently bad, selfish, and engaged in constant deception of themselves and others. He taught that people make all their choices for hidden reasons: men, mostly to get sex; women, mostly to get resources for their children. Whenever someone outside Black Lotus made a choice, Brent would dissect it to reveal the hidden selfish motivations. Whenever someone outside Black Lotus was well-respected or popular, Brent would point out (or make up) ways that they were exploiting those weaker than them for their own benefit. This became a self-fulfilling prophecy. One interviewee identified this ideology as the worst harm of Black Lotus, more than sexual boundary violations or being coerced into taking drugs. It took a long time to rebuild their ability to trust and have faith in other people.</p><p>Jessica Taylor, an AI researcher who knew both Zizians and participants in Leverage Research, put it bluntly. “There’s this belief [among rationalists],” she said, “that society has these really bad behaviors, like developing self-improving AI, or that mainstream epistemology is really bad–not just religion, but also normal ‘trust-the-experts’ science. That can lead to the idea that we should figure it out ourselves. And what can show up is that some people aren't actually smart enough to form very good conclusions once they start thinking for themselves.”</p><p>One way that thinking for yourself goes wrong is that you realize your society is wrong about something, don’t realize that you can’t outperform it, and wind up even wronger. But another potential failure is that, knowing both that your society is wrong and that you can’t do better, you start looking for someone even more right. Paradoxically, the desire to ignore the experts can make rationalists more vulnerable to a charismatic leader. &nbsp;</p><p>Or, as Jessica Taylor said, “They do outsource their thinking to others, but not to the typical authorities.”</p><p>In and of itself, that dynamic is bad but not necessarily seriously so. Many effective altruists–members of a community closely linked to the rationality community–similarly defer to more experienced effective altruists. While effective altruists <a href="https://forum.effectivealtruism.org/posts/Jx6ncakmergiC74kG/deference-culture-in-ea">have widely critiqued this habit</a>, it results only in poorly thought out viewpoints about charity evaluation, not in violent crime. But bad actors can easily take advantage of the desire to find someone to think for you. If you’re using neither the normal error-checking processes of society nor your own mind, how can you tell if someone is wrong?</p><p>A rationalist virtue is “taking ideas seriously”: when you are convinced of a belief, you notice all its implications and act on them. Another rationalist virtue is “agency”: taking actions to pursue your goals, even if the actions are unusual or break the rules. Together, these are dangerous. We know what happens if you do normal things; an enormous number of previous normal people have found that out for us..&nbsp;</p><p>But if you’re using your decision theory to make decisions and not just to get a PhD in mathematics, it really matters that you chose correctly. If you’re using your all-encompassing theory of human psychology to decide how to treat people, it really matters that you actually understand it. And all of these are more dangerous if, instead of following reasoning you understand, you’re deferring to the judgment of someone else who seems like they’ve thought about it a lot. &nbsp;</p><p>Agency and taking ideas seriously aren’t bad. Rationalists came to correct views about the COVID-19 pandemic while many others were saying masks didn’t work and only hypochondriacs worried about covid; rationalists were some of the first people to warn about the threat of artificial intelligence. If you want better outcomes than normal people, then you also need to do something different than what normal people do. But diverging from the norm is often risky and the risks have often not been taken seriously.</p></div>
											<p><h2>Beware psychology</h2>
</p>
											<div><p>The most interesting question I asked my interviewees was “what was your day-to-day life in the group like?”</p><p>Here is a sampling of answers from people in and close to dysfunctional groups: “We spent all our time talking about philosophy and psychology and human social dynamics, often within the group.” “Really tense ten-hour conversations about whether, when you ate the last chip, that was a signal that you were intending to let down your comrades in selfish ways in the future.” “Like somebody's going through a real bad breakup and you need to, like, hold their hair out of the toilet over text, tell them that it's going to be okay and help them put their life back together, except for years.”&nbsp;</p><p>Conversely, when I asked interviewees in high-demand groups that wound up basically functional, like Benton House, they gave answers like: “I learned to drive, which was really important. I got my first programming job. We played calibration games and a rationalist version of Family Feud called Schelling Point.” "I wrote LessWrong posts and started a rationalist fiction novel, helped someone immigrate, and once scrambled like thirty eggs in a wok."</p><p>One Black Lotus member wanted to emphasize to me that Black Lotus wasn’t all bad. The abuse was real. But he had been stuck in a dead-end job for years when Brent Dill looked at him and said “you’re smart, you can be in charge of build for my Burning Man camp.” Suddenly, he was putting in sixteen-hour days running a team of a dozen people, and he was <em>good </em>at it. He realized that he could manage people, troubleshoot problems, and build something he was proud of. He felt capable in a way he never had before.&nbsp;</p><p>Similarly, interviewees who knew about Leverage Research emphasized that some research groups were much more dysfunctional than others. Research groups that focused on real-world goals — like incubating the cryptocurrency <a href="https://reserve.org/">Reserve</a> — tended to be more functional. On the other hand, research groups that focused on ten-hour debugging sessions using Connection Theory were recognized even within the group as being cultier.&nbsp;</p><p>The rationalist organization the Center for Applied Rationality seems at first blush like an exception to this rule. It develops curricula and teaches workshops about how to think more rationally, but — while in the past it occasionally blurred the line between rationality curriculum development, people management, and therapy — it doesn’t seem to have approached the level of Leverage Research. CFAR mostly tests its newly developed rationality techniques on outside volunteers, for about an hour each. They don’t do eight-hour debugging sessions. They also strove to be empirical as best they could. If a technique seemed to make workshop participants happier and better off, it stayed; otherwise, it was removed. &nbsp;</p><p>Rationalist groups tend to be functional to the extent that their activities involve learning to program, writing papers for general publication, building a giant dome on the playa, or otherwise interacting with the real world. Rationalist groups tend to be dysfunctional to the extent that their activities involve very long conversations about human psychology and social dynamics, especially dynamics within the group itself. Relatedly, the clearest-cut cases of rationalists being right have involved external events in the world and not the nature of human beings.</p><p>Diving deep into human psychology isn’t an unusual pattern for the Bay Area: from Esalen to Circling, many groups outside the rationalist community become obsessed with the inner workings of the mind and how they manifest in the group dynamic. But I think this obsession tends to inflame a number of harmful dynamics. They, of course, offer a lot of opportunities for bad actors to manipulate group members, but even if everyone involved is well-intentioned they end badly. There is no conflict so small that five hours straight of emotional processing can’t make it feel both profoundly important and profoundly unsolvable. This kind of conversation leads to guilt and shame when you don’t measure up; it leads to paranoia and isolation when outsiders don’t. And without the steadying influence of some kind of external goal you either achieve or don’t achieve, your beliefs can get arbitrarily disconnected from reality — which is very dangerous if you’re going to act on them.&nbsp; &nbsp;</p><p>One interviewee said, “One kind of cult you can have is when you and ten of your closest friends all live in a house together and you have the blackout curtains drawn and a lot of MDMA, and you sit around and talk about the implications of the whatever.” The rationalist community keeps spawning groups like this. Most are nothing but a (possibly fun) waste of time. But when the conversations become fraught and obsessively inward-facing, it can spawn Leverage Research, or Black Lotus, or the Zizians.<sup>
    <!-- <a id="fnref-3" href="#fn-3"> -->
    <span id="fnref-3">
        3    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>Unlike agency or taking ideas seriously, I feel no compunctions about warning against very long, stressful conversations alternating between broader theories of human psychology and specific processing of the group members’ emotions. That kind of conversation is neither fun nor productive. If you’re having a tense conversation about feelings for ten hours, you might not be in a cult, but <em>something</em> has gone wrong.&nbsp;</p></div>
											<p><h2>Consequentialism&nbsp;</h2>
</p>
											<div><p>Several interviewees identified consequentialism as one of the riskier ideas to take seriously.&nbsp;</p><p>Brent Dill convinced some people that he was an extraordinary genius who would be capable of fantastic achievements, just as soon as he stopped being depressed. Therefore, from a consequentialist perspective, you should focus your effort on fixing his depression, no matter how much time or money or emotional energy it takes (and if you could throw your vagina into the bargain that would help too). The costs to you, no matter how large, are outweighed by the benefit a non-depressed Brent could bring to the world.</p><p>Several interviewees noted particular risks from overriding harms. “The issue is that ‘something, something dead babies’ justifies an awful lot,” said one interviewee. The long-term benefit that rationalists tend to be most worried about is AI. Many rationalists believe that an artificial general intelligence (AGI) will be developed very soon: for example, a mostly-rationalist team wrote the forecast <a href="https://ai-2027.com/">AI 2027</a>. Many of them also expect that, without heroic effort, AGI development will lead to human extinction.&nbsp;</p><p>These beliefs can make it difficult to care about much of anything else: what good is it to be a nurse or a notary or a novelist, if humanity is about to go extinct? Unfortunately, many people simply don’t have the skills to become AI policymakers or technical AI safety researchers. The vulnerable people particularly attracted by the Sequences are especially likely to not have enough work ethic or mental health to be able to contribute.&nbsp;</p><p>What do you do? You attach yourself to any project that seems like it might be able to help. The lucky ones accumulate a stack of rejections, or aimlessly drift from small grant to small grant and from badly-run nonprofit to badly-run nonprofit. The unlucky ones get sucked into a dysfunctional group.&nbsp;</p><p>Many people keep having the tense psychology discussions I talked about because they think AI is important and right now they can’t do anything to help. If you’re acutely aware that your ADHD or your trauma, your depression or your subclinical procrastination tendencies, are keeping you from preventing human extinction, then you’d do anything to fix it.&nbsp;</p><p>The overwhelming stakes of AGI can lead to a dangerous sense of grandiosity. “It’s a story in which they matter and in which it is justified for them to do weird stuff and stand up for themselves,” said an interviewee familiar with the Zizians. “Every action has great meaning, and that hooks into people in two ways. One of which is that it's empowering, and the other of which is that it's a great trigger for becoming obsessed with whether you're a bad person.”</p><p>He continued, “It makes it easy for small things to seem very big. And I think it also&nbsp; makes it easy for big things to seem sort of the same size as small things. When you get pulled over and then you get in a gunfight with the cops or whatever, this is the same level of treating the situation like it is anomalous or a big deal as having an argument about who washed the dishes.”</p><p>Early rationalist writing, such as the Sequences and the Harry Potter fanfiction <em>Harry Potter and the Methods of Rationality</em>, emphasized the lone hero, standing defiantly against an uncaring world. But the actual process of saving the world is not very glamorous. It involves filling out paperwork, making small tweaks to code, running A/B tests on Twitter posts. Most rationalists — like Mike Blume — adjust well to the normalcy of world-saving. (Today he works as a programmer and donates to AI safety and global health nonprofits, a common rationalist career trajectory.) Others want acts of heroism as grand as the threat they face.</p><p>The Zizians and researchers at Leverage Research both felt like heroes, like some of the most important people who had ever lived. Of course, these groups couldn’t conjure up a literal Dark Lord to fight. But they could imbue everything with a profound sense of meaning. All the minor details of their lives felt like they had the fate of humanity or all sentient life as the stakes. Even the guilt and martyrdom could be perversely appealing: you could know that you’re the kind of person who would sacrifice everything for your beliefs.&nbsp;</p><p>The project itself in each of these dysfunctional groups was vague, free-floating, and almost magical. As soon as you have to accomplish specific goals in the real world, the mundanity of everyday life comes flooding in, with its endless slog of tasks variously boring, frustrating, and annoying. But as long as you’re sitting in a room taking LSD with the blackout curtains over the windows, you can be Superman.&nbsp;</p></div>
											<p><h2>Beware isolation</h2>
</p>
											<div><p>When asked how people could tell that their project wasn’t a cult, one interviewee said, “You leave the house regularly. Or if there's an office, you leave <em>both</em> the office and the house regularly.”&nbsp;</p><p>A recurring theme in my interviews was social isolation and groupthink: speaking primarily or only to people inside the group; rejecting dissidents or outsiders as unenlightened, as ignorant, as evil. Several people remarked that the main sign that someone had become a Zizian was that they disappeared from the Internet for a few months, and the next you hear from them is a news article talking about how they’re wanted for murder.&nbsp;</p><p>Interviewees particularly emphasized the epistemic problems created by social isolation. People tend to check in with the people around them to see whether their actions or beliefs are reasonable. But if you want to trick someone into believing absolute nonsense, you can introduce them to four people who already believe it and keep them away from critics. Then it seems like “everyone” agrees.&nbsp;</p><p>Sometimes this dynamic was created deliberately. If one of his followers objected to his behavior, Brent Dill would ask a few of his other followers to talk to them about it. Even if three of them told Brent Dill he was in the wrong, the fourth might agree — and that was the one Brent sent to talk to the dissident. &nbsp;</p><p>Other times, the dynamic occurred more-or-less by accident. Researchers at Leverage all lived together, which seemed like a reasonable cost-saving measure. Researchers typically socialized and dated within the group. Leverage took care of many of its researchers’ needs: meals, transportation, even handling their mail. When members had mental health crises due to unpacking their trauma in debugging sessions, Leverage stepped in to make sure their needs were met. Although apparently compassionate, this pattern meant that many researchers got everything from Leverage: sense of purpose and meaning, work, therapy, friendship, romance, food, housing, and routine life maintenance. Connections to the outside world often faded. Some researchers, after they left, found themselves helpless in the wider world.&nbsp;</p><p>Sometimes, the broader rationalist community played into this isolation. Members of organizations that were on the outs among rationalists, including Leverage Research, have trouble talking about their work at parties. Instead of normal small talk, they find themselves having to justify or apologize for their group. Naturally, they wind up going to fewer parties — and losing contact with the broader rationalist community.&nbsp;</p><p>Leverage Research didn’t like firing people. When a researcher was a poor fit, or the program they’d originally joined closed, they were shuffled from group to group. That explains some of the wildly different experiences people had at Leverage: Leverage didn’t expel people who really shouldn’t have been there, either because Connection Theory was harming them or because they were hurting others. &nbsp;</p><p>The isolation and groupthink was reinforced by a culture of secrecy. The norm was that individual research groups kept their research secret, even from other research groups within Leverage. That meant that the more functional research groups couldn’t provide a check on the less functional groups. Without much ability to learn what other research groups were actually doing, dysfunctional research groups became paranoid about (sometimes demon-related) sabotage — further isolating themselves from any kind of outside influence.&nbsp;</p></div>
											<p><h2>Conclusion</h2>
</p>
											<div><p>One of my interviewees speculated that rationalists aren’t actually any more dysfunctional than anywhere else; we’re just more <em>interestingly </em>dysfunctional. Dysfunctional workplaces, rape, abuse, and even murder aren’t unusual. People are more interested in rape or murder when it has a complicated and unusual philosophical justification, but we shouldn’t confuse being more fun to talk about with being more common.&nbsp;</p><p>Bearing that possibility in mind, what conclusions does my project suggest?</p><p>To some extent, dysfunctional rationalist groups are a product of features of rationalist culture that rationalists would rather not give up. For better or worse, rationalists want to act on their beliefs, and they want to do things differently from the society around them. But I believe it is possible to reduce the number of dysfunctional groups and how damaging they are.</p><p>For individuals concerned about joining a dysfunctional group, I suggest:</p><p>1. If your relationship with a person or a group consists mostly of discussions about human psychology and social dynamics, that is a yellow flag. It is a red flag if:<br>a. The conversations are many hours long and displace other activities in your life.<br>b. The conversations generally focus on group members’ feelings and interactions, rather than social science or philosophy.<br>c. The conversations are tense, stressful, and not fun.&nbsp;</p><p>2. Try to do things where there is some external gauge of whether you’re succeeding at them or not. Similarly, try to test your beliefs against reality.&nbsp;</p><p>3. Maintain multiple social groups. Ideally, have several friends who aren’t rationalists.&nbsp;</p><p>4. Keep your work, housing, and therapy separate.&nbsp;</p><p>5. Before assuming that something is true because everyone else seems to believe it, either check the argument yourself or talk to someone outside the friend group and who wasn’t introduced to you by anyone in the group.&nbsp;</p><p>6. The longer and more abstract a chain of reasoning is, the less you should believe it. This is particularly true if the chain of reasoning concludes:<br>a. That it’s okay to do something that hurts people.<br>b. That something is of such overwhelming importance that nothing else matters.&nbsp;</p><p>7. Be cautious about joining high-demand groups if you have nowhere else to go.&nbsp;</p><p>My recommendations for the general rationalist community are:</p><p>If someone is in a group that is heading towards dysfunctionality, try to maintain your relationship with them; don’t attack them or make them defend the group. Let them have normal conversations with you.&nbsp;</p><p>Think carefully about how we can create more realistic expectations in new rationalists and whether it would be possible to offer more of them the support they need to become useful community members.</p><p>Give people realistic expectations about whether they will ever be able to get a job in AI safety. Don’t act like people are uncool or their lives are pointless if they can’t work in AI safety.&nbsp;</p><p>Consider talking about “ethical injunctions:” things you shouldn’t do even if you have a really good argument that you should do them. (Like murder.)&nbsp;</p></div>
										 
				</div>
		
	</section>
	 	<section>
		 		 <p><strong>Ozy Brennan</strong> is an animal welfare researcher and science fiction author. They blog at Thing of Things.</p>		 		 		 </section>
	 	<section>            
		<p>
			Published August 2025		</p>
		
		<p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>		                        
	</section>	
	
	<!--end published content, not coming soon-->

	<!--tags-->
		<section>
		<h4>Further Reading</h4>                
			<p>
				More:  
									<span data-no="tag-1">culture</span>
							</p>
			<!--related articles-->
			             
	</section>
	 
	
	  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Enlisting in the Fight Against Link Rot (162 pts)]]></title>
            <link>https://jszym.com/blog/archiving_googl/</link>
            <guid>44877021</guid>
            <pubDate>Tue, 12 Aug 2025 14:52:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jszym.com/blog/archiving_googl/">https://jszym.com/blog/archiving_googl/</a>, See on <a href="https://news.ycombinator.com/item?id=44877021">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
			<h4>11 August 2025</h4>
			<p><em>"… all of this ended up in storage rooms, and everything became rotten and full of holes, and he himself finally turned into some kind of hole in humanity."</em> <label for="sidenote-93ddda7838c7ad12371082b0cf1d67ff4bdc19533c6c2fa9de1c1ad52834c956">✪</label><span><span>✪</span>“…все это сваливалось в кладовые, и все становилось гниль и прореха, и сам он обратился наконец в какую-то прореху на человечестве.”</span></p>
<p>— <del>Google</del> Gogol, <a href="https://ilibrary.ru/text/78/p.7/index.html"><em>Dead Souls</em> Vol. 1, Chp. 6</a></p>
<p>In <a href="https://web.archive.org/web/20101001064512/http://googleblog.blogspot.com/2009/12/making-urls-shorter-for-google-toolbar.html">December 2009</a>, Google launched a URL shortening service alongside an update to their toolbar and FeedBurner. TechCrunch heralded the new service as the <a href="https://web.archive.org/web/20101001083657/https://techcrunch.com/2010/09/30/googlegoo-gl-is-a-go-the-stablest-most-secure-and-fastest-url-shortener-on-the-web/">“Stablest, Most Secure, And Fastest URL Shortener On The Web”</a> in an article released at the time. Those words — stable, secure, fast — weren’t chosen by an overexcited editor either, they appear on the <a href="https://web.archive.org/web/20091217094012/http://goo.gl/">goo.gl website on day one</a>.</p>
<p>Smash cut to July 2024, when <a href="https://developers.googleblog.com/en/google-url-shortener-links-will-no-longer-be-available/">Google announces</a> in a blog post that their super stable and secure URL shortener is getting nuked from orbit in just over a year.</p>
<figure>
    <a href="https://jszym.com/post_images/archiving_googl/before_after.webp" target="_new"><img src="https://jszym.com/post_images/archiving_googl/before_after.webp" alt="A two panel image. The left panel is a screenshot from the homepage of goo.gl showing text that claims the service offers 'stability', 'security', and 'speed'. The bottom of the left panel is super-imposed text that reads '2009'. The right panel is a screenshot of the blog post announcing that goo.gl links will no longer be available. The bottom of the right panel is super-imposed text that reads '2024'." role="img"></a>
    <figcaption><h4>*Curb theme plays*</h4></figcaption>
</figure>
<p>Now, I know I’m framing this as a completely unforseen outcome, a surprise betrayal, but the truth is that folks knew this would happen from the get-go. <a href="https://luxagraf.net/">Scott Gilbertson</a> wrote this in <a href="https://web.archive.org/web/20100408045015/http://www.webmonkey.com/2009/12/google_jumps_on_the_url-shortening_bandwagon_with_goodotgl">an article for Webmonkey/Wired</a> covering the services introduction in 2009:</p>
<blockquote>
<p>Of course the bigger problems with URL shorteners — link-rot, spam and redirect mishaps to name a few — are still problems regardless of whether the shortener is controlled by Google or anyone else. And for anyone who thinks that Google services have a better chance of being around far into the future, may we remind you that Google Notebook, Google Answers and several other services have disappeared over the years.</p>
</blockquote>
<p>Prescient, right? The fact is that URL shorteners which don’t share their database (read: all URL shortners if you round up) are a terrible, no good, very bad idea. Link rot makes us amnesiacs, and if our history is our future, it’s looking very hazy.</p>
<h2 id="the-resistance">The Resistance</h2>
<p>Time and time again, moments before the ossified arches of a website are set to crumble due to active neglect by the arsonists on payroll in Mergers &amp; Acquisitions, a certain brigade of ragtag vigilantes always rush in to save the furniture and family photos. I’m of course talking about the famed <a href="https://archiveteam.org/">Archive Team</a>.</p>
<p>The Archive Team are the same folks that saved <a href="https://www.theregister.com/2009/04/28/geocities_preservation/">Geocities</a> from Yahoo!, <a href="https://gizmodo.com/were-archiving-yahoo-answers-so-youll-always-know-how-b-1846643969">Yahoo! Answers</a> from Yahoo!, and <a href="https://www.washingtonpost.com/technology/2019/12/11/these-crusaders-want-preserve-human-culture-online-their-latest-target-yahoo-groups/">Yahoo! Groups</a> from… uh… well, <a href="https://www.theatlantic.com/technology/archive/2021/04/how-yahoo-became-internet-villain/618681/">you know</a>.</p>
<p>Now, I know what you’re thinking now: “wow, these Archive Team people are the coolest ever, I bet they have clear skin and healthy hair”. Well, what if I could tell you that anyone who can operate a terminal can join the war effort in as little as two commands. Despair not if you don’t meet that description but desire to join the club, it’s also pretty easy to do by pointing and clicking.</p>
<h2 id="enlisting-in-the-fight-against-link-rot">Enlisting in the Fight Against Link Rot</h2>
<p>To join in the effort to help stem the damage goo.gl’s shutdown will cause, the Archive Team is trying to map all the short URLs (<em>e.g.</em>, <code>http://goo.gl/gEdpoS</code>) to their long URLs (<em>e.g.</em>, <code>https://www.clubic.com/int...</code>). How do we do that? Well it’s very simple, and very stupid:</p>
<ol>
<li>Visit a goo.gl short link.</li>
<li>Observe what URL it redirects to, if any.</li>
<li>Do this again for every possible short link.</li>
</ol>
<p>As best as I can tell from the Archive Team tracker, it looks like there are about <del>3 billion</del> 230 billion<label for="sidenote-dcd0837b899bc60769b94246e448d3a3f914640aadb0a821f6612f301807a1f2">✪</label><span><span>✪</span>Thanks to arkiver on the Archive Team IRC for correcting this number.</span> links that need visiting. That’s just too many for one person to do. At the time of writing, <strong>there’s less than two weeks left to archive all these links</strong>.</p>
<p>Luckily, the Archive Team have put together a handy programme that automates this. It’s so easy to use that &gt;3,000<label for="sidenote-af20bb82e7c1f18070cfc4c8f24375d6a85082e086bda45836f021bc42031741">✪</label><span><span>✪</span>A quick estimate from quickly grep’ing the <a href="https://tracker.archiveteam.org/goo-gl/">leaderboard</a> so don’t hold me to that number.</span> other folks have used it to save goo.gl short links.</p>
<p>As I alluded to, there are two ways to run this programme (known as the Archive Team <a href="https://wiki.archiveteam.org/index.php/ArchiveTeam_Warrior">Warrior</a>). It’s super easy and anyone can do it. Just don’t use a VPN or run this over an ISP that will block or alter websites. More info <a href="https://wiki.archiveteam.org/index.php/ArchiveTeam_Warrior#Can_I_use_whatever_internet_access_for_the_Warrior?">here</a> about that.</p>
<h3 id="using-the-command-line-and-docker">Using the Command Line and Docker</h3>
<p>Quoting from the <del>sacred texts</del> <a href="https://wiki.archiveteam.org/index.php/ArchiveTeam_Warrior">Archive Team wiki</a>, you need simply:</p>
<ol>
<li><a href="https://docs.docker.com/engine/install/">Download and install Docker</a></li>
<li>Open your terminal on Mac and Linux, or your Command Prompt on Windows.</li>
<li>Copy/paste the first encantation</li>
</ol>
<div><pre tabindex="0"><code data-lang="bash"><span><span>docker run --detach --name watchtower --restart<span>=</span>on-failure --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --label-enable --include-restarting --cleanup --interval <span>3600</span>
</span></span></code></pre></div><ol start="4">
<li>Copy/paste the second encantation</li>
</ol>
<div><pre tabindex="0"><code data-lang="bash"><span><span>docker run --detach --name archiveteam-warrior --label<span>=</span>com.centurylinklabs.watchtower.enable<span>=</span><span>true</span> --log-driver json-file --log-opt max-size<span>=</span>50m --restart<span>=</span>on-failure --publish 8001:8001 atdr.meo.ws/archiveteam/warrior-dockerfile
</span></span></code></pre></div><ol start="5">
<li>Visit <code>http://localhost:8001</code></li>
</ol>
<p>And that’s it! Follow the on-screen instructions and make sure you click on the Goo.gl project (selecting “ArchiveTeam’s Choice” will do it). You can run this on your desktop or laptop, or even better yet, set-it-and-forget-it on a VPS or server somewhere in cloud land.</p>
<p>If you can’t/won’t use Docker, here are instructions for how to do this with <a href="https://wiki.archiveteam.org/index.php/ArchiveTeam_Warrior#Installing_and_running_with_Podman">Podman</a> and <a href="https://wiki.archiveteam.org/index.php/ArchiveTeam_Warrior#Installing_and_running_with_Orbstack">Orbstack</a>.</p>
<h3 id="pointing-and-clicking-with-virtualbox">Pointing and Clicking with VirtualBox</h3>
<ol>
<li><a href="https://www.virtualbox.org/wiki/Downloads">Install VirtualBox</a></li>
<li>Grab the <a href="https://warriorhq.archiveteam.org/downloads/warrior4/archiveteam-warrior-v4.1-20240906.ova">Warrior Virtual Machine</a></li>
<li>In VirtualBox, click File &gt; Import Appliance… and open the file.</li>
<li>Start the virtual machine.</li>
<li>Outside of the virtual machine (<em>i.e.</em>, on your host), visit <code>http://localhost:8001</code></li>
</ol>
<h2 id="im-doing-my-part">“I’m Doing My Part!”</h2>
<p>I started running the Warrior on the 9th of August and, according to the <a href="https://tracker.archiveteam.org/goo-gl/">leaderboard</a>, I’ve uploaded more than 370,000 URLs, or about 14Gb worth at the time of writing<label for="sidenote-a4758764483dacd5447ee072256a27443ec300c88223948d4758d8f83d623b88">✪</label><span><span>✪</span>If you’re thinking the data size and the number of URLs is disproportionate, I’m right with you. I’m not sure what the deal is, but I know I’m misunderstanding something about the leaderboard.</span> other folks have used it to save goo.gl short links. We have less than two weeks with just under half a billion left to go as of the night of the 11th of August.</p>
<figure>
    <a href="https://jszym.com/post_images/archiving_googl/leaderboard.webp" target="_new"><img src="https://jszym.com/post_images/archiving_googl/leaderboard.webp" alt="" role="img"></a>
    <figcaption></figcaption>
</figure>
<figure>
    <video controls="" loop="">
        <source src="https://jszym.com/post_images/archiving_googl/warrior.av1.mp4" type="video/mp4; codecs=av01">
        
        <source src="https://jszym.com/post_images/archiving_googl/warrior.webm" type="video/webm">
        
        <source src="https://jszym.com/post_images/archiving_googl/warrior.h264.mp4" type="video/mp4">
        Download the video:
        <a href="https://jszym.com/post_images/archiving_googl/warrior.av1.mp4"> AV1 </a>
        
        <a href="https://jszym.com/post_images/archiving_googl/warrior.webm"> WEBM </a>
        
        <a href="https://jszym.com/post_images/archiving_googl/warrior.h264.mp4"> MP4 </a>
        </video>
    <figcaption><h4>I could watch this run all day.</h4></figcaption>
</figure>
<p>I’m not going to lie, I am more than a little bit motivated by the fact that I am above the median of individuals who’ve backed up goo.gl URLs (as judged by the position of the scroll bar when I Ctrl+F <code>jszym</code>). But I’ve also spent untold hours on the <a href="https://web.archive.org/">Wayback Machine</a> and the <a href="https://geocities.restorativland.org/">Geocities Gallery</a>. I’ve made stuff for the internet, relied on services to keep it around, and have them disappear due to capital interests or indifference. I’m happy to think that there is a very remote chance that I’m helping someone in the future unlock the secrets of our collective past.</p>
<p><strong>EDIT:</strong> HackerNews took a shine to this post. You can read/join some of the interesting <a href="https://news.ycombinator.com/item?id=44877021">discussion</a> there.</p>

		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub is (again) having issues (336 pts)]]></title>
            <link>https://www.githubstatus.com/incidents/9rfydl2xdqqj</link>
            <guid>44876784</guid>
            <pubDate>Tue, 12 Aug 2025 14:37:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.githubstatus.com/incidents/9rfydl2xdqqj">https://www.githubstatus.com/incidents/9rfydl2xdqqj</a>, See on <a href="https://news.ycombinator.com/item?id=44876784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are experiencing increased latency in our API layers and inconsistently degraded experiences when loading or querying issues, pull requests, labels, packages, releases, workflow runs, projects, and repositories, among others. Investigation is underway.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1755012018000"></span>Aug <var data-var="date">12</var>, <var data-var="year">2025</var> - <var data-var="time">15:20</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are investigating reports of degraded performance in services backed by search. The team continues to investigate why requests are failing to reach our search clusters.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1755010423000"></span>Aug <var data-var="date">12</var>, <var data-var="year">2025</var> - <var data-var="time">14:53</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Packages is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1755009014000"></span>Aug <var data-var="date">12</var>, <var data-var="year">2025</var> - <var data-var="time">14:30</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Investigating
          </h2>
          <div>
            <p><span>We are investigating reports of degraded performance for API Requests, Actions, Issues and Pull Requests</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1755007930000"></span>Aug <var data-var="date">12</var>, <var data-var="year">2025</var> - <var data-var="time">14:12</var> UTC
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affects: API Requests, Issues, Pull Requests, Actions, and Packages.
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[That viral video of a 'deactivated' Tesla Cybertruck is a fake (176 pts)]]></title>
            <link>https://www.theverge.com/tesla/757594/tesla-cybertruck-deactivated-viral-video-fake</link>
            <guid>44876449</guid>
            <pubDate>Tue, 12 Aug 2025 14:12:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/tesla/757594/tesla-cybertruck-deactivated-viral-video-fake">https://www.theverge.com/tesla/757594/tesla-cybertruck-deactivated-viral-video-fake</a>, See on <a href="https://news.ycombinator.com/item?id=44876449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/andrew-j-hawkins"><img alt="Andrew J. Hawkins" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195793/ANDREW_HAWKINS.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195793/ANDREW_HAWKINS.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195793/ANDREW_HAWKINS.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6MTIy"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Andrew J. Hawkins</span></span></span></p> <p><span>is transportation editor with 10+ years of experience who covers EVs, public transportation, and aviation. His work has appeared in The New York Daily News and City &amp; State.</span></p></div></div><div id="zephr-anchor"><p>Did Tesla remotely deactivate a Cybertruck in the middle of a highway because the owner featured it in an unauthorized music video? The story already seemed highly unlikely, and on Monday afternoon, Tesla <a href="https://x.com/Tesla/status/1954992987223757149?t=ySHgoE7tozr0eGDFHRrpaw&amp;s=19">tweeted</a> about the video, saying, “This is fake – that’s not our screen. Tesla does NOT disable vehicles remotely.”</p><p>On Sunday, Instagram user @bighuey313 <a href="https://www.instagram.com/p/DNJTGxYuCEV/">posted a video</a> of his supposed deactivated Cybertruck, complete with a flashing red warning message on the truck’s main touchscreen. “Dog wtf my cybertruck just shut off on the freeway! 😡” he wrote in the caption. “Almost just crashed wtf <a href="https://www.instagram.com/teslamotors/">@teslamotors</a>.”</p><div><div><p><a href="https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0,7.1992110453649,100,85.60157790927" data-pswp-height="1157.3333333333333" data-pswp-width="1736" target="_blank" rel="noreferrer"><img alt="screengrab of Instagram video of deactivated Tesla Cybertruck viral video" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=256 256w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=376 376w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=384 384w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=415 415w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=480 480w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=540 540w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=640 640w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=750 750w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=828 828w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=1080 1080w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=1200 1200w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=1440 1440w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=1920 1920w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=2048 2048w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=2400 2400w" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/Screenshot-2025-08-11-at-1.35.54%E2%80%AFPM.png?quality=90&amp;strip=all&amp;crop=0%2C7.1992110453649%2C100%2C85.60157790927&amp;w=2400"></a></p></div><p><cite>Image: Screenshot / @bighuey313</cite></p></div><p>The owner also <a href="https://www.instagram.com/p/DNJuc0buCUl/">posted an image</a> of what he claimed was a cease-and-desist letter from Tesla’s vice president of legal affairs, Dinna Eskin. The letter cites “unauthorized use of Tesla’s intellectual property in musical content distributed under your name.”</p><p>The video quickly went viral on BlueSky, where anti-Elon Musk sentiment has helped fuel nationwide protests against Tesla. But users quickly noticed a number of discrepancies, such as the fact that the letter opens “We represent Tesla” despite being signed by the company’s in-house counsel. The letter also uses Eskin’s old title, “Sr. Director and Deputy General Counsel,” <a href="https://www.linkedin.com/in/dinna-eskin-743a7435/">despite her current title of VP</a>. And the warning message isn’t formatted like Tesla’s typical in-vehicle alerts and notifications. <a href="https://x.com/jeremyjudkins_/status/1954892424825667602">An X user</a> speculated that the flashing red title was likely just a YouTube video playing on fullscreen to simulate a legitimate error.</p><p>Despite these issues, the video went viral on BlueSky, X, and Reddit — and likely will continue to travel far and wide, confirming many people’s prior opinions about Tesla and Elon Musk.</p><div><p><em><strong>Update August 11th:</strong> <a href="https://x.com/Tesla/status/1954992987223757149?t=ySHgoE7tozr0eGDFHRrpaw&amp;s=19">Tesla posted on X</a> confirming the video is fake. </em></p></div><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6MTIy"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Andrew J. Hawkins</span></span></span></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Journaling using Nix, Vim and coreutils (125 pts)]]></title>
            <link>https://tangled.sh/@oppi.li/journal</link>
            <guid>44876356</guid>
            <pubDate>Tue, 12 Aug 2025 14:04:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tangled.sh/@oppi.li/journal">https://tangled.sh/@oppi.li/journal</a>, See on <a href="https://news.ycombinator.com/item?id=44876356">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <nav>
            
        </nav>
        <section>
            
    <main>
        
            
    

        
        
        
    </main>

        </section>
        <section>
            <article><p>I cobbled together a journaling system with {neo,}vim,
coreutils and <a href="http://www.fresse.org/dateutils">dateutils</a>.
This system is loosely based on <a href="https://www.rydercarroll.com/">Ryder
Caroll's</a> Bullet Journal
method.</p>
<p><a href="https://u.peppe.rs/SpF.png"><img src="https://camo.tangled.sh/60766f1144b836ae8a2cd11efbcedf1f57ab96af784ab1073f50f8b1ca3f76b5/68747470733a2f2f752e70657070652e72732f5370462e706e67" alt=""></a></p>
<h3 id="the-format">The format</h3>
<p>The journal for a given year is a directory:</p>
<pre><code>λ ls journal/
2022/   2023/
</code></pre>
<p>In each directory are 12 files, one for each month of the
year, numbered like so:</p>
<pre><code>λ ls journal/2023/
01  02  03  04  05  06  07  08  09  10  11  12
</code></pre>
<p>We can now begin writing stuff down:</p>
<pre><code>λ vim journal/2023/1
</code></pre>
<p>Every month must start with a calendar of course, fill that
in with:</p>
<pre><code>:read !cal -m
</code></pre>
<p>Your entry for January might look like this:</p>
<pre><code>λ cat journal/2023/01
    January 2023
Mo Tu We Th Fr Sa Su
                   1
 2  3  4  5  6  7  8
 9 10 11 12 13 14 15
16 17 18 19 20 21 22
23 24 25 26 27 28 29
30 31
</code></pre>
<p>I prefer planning week by week, as opposed to creating a
task-list every day, here's what I have for the first couple
of weeks:</p>
<pre><code>    January 2023
Mo Tu We Th Fr Sa Su
                   1
 2  3  4  5  6  7  8
 9 10 11 12 13 14 15
16 17 18 19 20 21 22
23 24 25 26 27 28 29
30 31


week 1

done apply leaves
done dload boarding pass
moved reply to dan


week 2

todo reply to dan
todo pack bags
done travel insurance
todo weigh luggage
</code></pre>
<p>I start the week by writing a header and each item that week
is placed on its own line. The items are prefixed with a
<code>todo</code> or a <code>done</code> signifier.</p>
<h3 id="form-over-function">Form over function</h3>
<p>Right off the bat, the signifiers look very noisy, Even more
so once we start introducing variety (I use "event", "note"
and "moved"):</p>
<pre><code>week 1

todo apply leaves
done dload boarding pass
todo reply to dan
event fr trip
note weight 68.6
</code></pre>
<p>We can clean this up with "abbreviations" (<code>:h abbreviations</code>):</p>
<pre><code>:iabbrev todo ·
:iabbrev done ×
</code></pre>
<p>Now, typing this:</p>
<pre><code>todo apply leaves
</code></pre>
<p>Automatically inserts:</p>
<pre><code>· apply leaves
</code></pre>
<p>You can use <code>x</code> and <code>o</code> as well, but <code>×</code> (U+00D7,
MULTIPLICATION SIGN) and <code>·</code> (U+00B7, MIDDLE DOT) are more
... <em>gourmet</em>.</p>
<p>The other signifiers I use are:</p>
<ul>
<li><code>-</code> for note</li>
<li><code>o</code> for event</li>
<li><code>&gt;</code> for moved.</li>
</ul>
<p>Nit #2 is the lack of order. We can employ vim to introduce
grouping and sorting. Select the list of entries for this
week:</p>
<pre><code>vip         " line-wise select inner paragraph
:'&lt;,'&gt;sort  " the markers '&lt; and '&gt; are automatically inserted,
            " they mark the start and end of the selection
</code></pre>
<p>We end up with:</p>
<pre><code>week 1

· apply leaves
· reply to dan
× dload boarding pass
</code></pre>
<p>The lines are grouped by their signifiers, segregating todo
items from completed items. Luckily, MIDDLE DOT is lesser
than MULTIPLICATION SIGN, so todo items are placed at the
top. The same goes for <code>o</code> and <code>x</code> symbols, either set of
signifiers will result in the same sorting order.</p>
<p>We can shorten this select-paragraph-invoke-sort dance by
setting the <code>formatprg</code> variable:</p>
<pre><code>:set formatprg=sort\ -V
</code></pre>
<p>Now, hitting <code>gqip</code> should automatically group and sort the
items for the week under the cursor, moving todo items to
the top. Finding signifier glyphs that suit your sorting
preference is a fun exercise.</p>
<h3 id="syntax-highlighting">Syntax highlighting</h3>
<p>Adding color to items introduces another layer of visual
distinction. In truth, I like to deck it out just because.</p>
<p>First, create a few syntax groups:</p>
<pre><code>:syntax match JournalAll /.*/        " captures the entire buffer
:syntax match JournalDone /^×.*/     " lines containing 'done'  items: ×
:syntax match JournalTodo /^·.*/     " lines containing 'todo'  items: ·
:syntax match JournalEvent /^o.*/    " lines containing 'event' items: o
:syntax match JournalNote /^- .*/    " lines containing 'note'  items: -
:syntax match JournalMoved /^&gt;.*/    " lines containing 'moved' items: &gt;
</code></pre>
<p>Add highlights to each group:</p>
<pre><code>:highlight JournalAll    ctermfg=12   " bright black
:highlight JournalDone   ctermfg=12   " bright black
:highlight JournalEvent  ctermfg=6    " cyan
:highlight JournalMoved  ctermfg=5    " magenta
:highlight JournalNote   ctermfg=3    " yellow
</code></pre>
<p>In my terminal, this is rendered like so:</p>
<p><a href="https://u.peppe.rs/Du6.png"><img src="https://camo.tangled.sh/154fd2fa914950789f163eb94c2bd1f17b09db2e1fcd304a1e5a27378836f7d7/68747470733a2f2f752e70657070652e72732f4475362e706e67" alt=""></a></p>
<h3 id="habit-tracking">Habit tracking</h3>
<p>While this is not a part of my journaling system anymore, a
few headers and an awk script is all it takes to track
habits. My weekly entries would include a couple of habit
headers like so:</p>
<pre><code>week 1 --------------

× wake up on time
× water the plants

spend 7.5 7 10
---------------------


week 2 --------------

· make the bed
· go to bed

spend 30 2.75 6
---------------------
</code></pre>
<p>Here, under the <code>spend</code> header in week 1, are a list of
expenditures accumulated over the week. The monthly spend is
calculated with this awk script:</p>
<pre><code>BEGIN {spend=0;}
/spend/ {for(i=1;i&lt;=$NF;i++) spend+=$i;}
END { printf spend "eur"}
</code></pre>
<p>And invoked like so:</p>
<pre><code>λ awk -f spend.awk journal/2023/01
63.25eur
</code></pre>
<h3 id="reflection">Reflection</h3>
<p>Journaling is not just about planning what is to come, but
also reflecting on what has passed. It would make sense to
simultaneously look at the past few weeks' entries while
making your current one. To open multiple months of entries
at the same time:</p>
<pre><code>λ vim -O journal/2023/0{1,2,3}
</code></pre>
<p>Opens 3 months, side-by-side, in vertical splits:</p>
<pre><code>JANUARY ------------  │  FEBRUARY -----------  │  MARCH --------------
                      │                        │
Mo Tu We Th Fr Sa Su  │  Mo Tu We Th Fr Sa Su  │  Mo Tu We Th Fr Sa Su
                   1  │         1  2  3  4  5  │         1  2  3  4  5
 2  3  4  5  6  7  8  │   6  7  8  9 10 11 12  │   6  7  8  9 10 11 12
 9 10 11 12 13 14 15  │  13 14 15 16 17 18 19  │  13 14 15 16 17 18 19
16 17 18 19 20 21 22  │  20 21 22 23 24 25 26  │  20 21 22 23 24 25 26
23 24 25 26 27 28 29  │  27 28                 │  27 28 29 30 31
30 31                 │                        │
                      │                        │
                      │                        │
WEEK 1 -------------  │  WEEK 1 -------------  │  WEEK 1 -------------
                      │                        │
&gt; latex setup         │  &gt; forex               │  - weight: 64
× make the bed        │  × clean shoes         │  &gt; close sg-pr
× 03: dentist         │  × buy clothes         │  × facewash
× integrate tsg       │  × draw                │  × groceries
                      │                        │
                      │                        │
WEEK 2 -------------  │  WEEK 2 -------------  │  WEEK 2 -------------
                      │                        │
× latex setup         │  - viral fever         │  &gt; close sg-pr
× send invoice        │  × forex               │  × plan meet
× stack-graph pr      │  × activate sim        │  × sg storage
                      │  × bitlbee             │
</code></pre>
<h3 id="reducing-friction">Reducing friction</h3>
<p>Journaling already requires a solid amount of discipline and
consistency. The added friction of typing <code>vim journal/$CURRENT_YEAR/$CURRENT_MONTH</code> each time is doing no
favors.</p>
<p>To open the current month based on system time:</p>
<pre><code>λ vim $(date +"%Y/%m")
</code></pre>
<p>To open all the months within a 2 month window of today, is
a little trickier. The command we wish to generate is (if
today is 2023/12):</p>
<pre><code>λ vim -O 2023/10 2023/11 2023/12 2024/01 2024/02
</code></pre>
<p>And that is where <code>dateseq</code> from
<a href="http://www.fresse.org/dateutils">dateutils</a> comes in handy,
for example:</p>
<pre><code>λ dateseq 2012-02-01 2012-03-01
2012-02-01
2012-02-02
2012-02-03
...
2012-02-28
2012-02-29
2012-03-01
</code></pre>
<p>This script opens all months within a 2 month window of
today:</p>
<pre><code>λ vim -O $(
  dateseq \
      "$(date --date "2 months ago" +%Y/%m)" \
      "$(date --date "2 months" +%Y/%m)" \
      -i %Y/%m \
      -f %Y/%m
)
</code></pre>
<h3 id="fin">Fin</h3>
<p>You can find a sample vimrc in this repository,
along with a nix flake file to kick things off:</p>
<pre><code>λ nix develop
λ cd examples
λ journal
</code></pre>
<p>Plain text journaling can be just as much fun as a pen and
paper. Throw in some ASCII art for each month, use swankier
signifiers, or louder syntax highlighting. Don't expect
forgiveness from org-mode users though.</p>
<p><a href="https://u.peppe.rs/ZCK.png"><img src="https://camo.tangled.sh/6d169237740fefcd7587aa725d1a29e418f837a4d3bdb9c2d3c90841e8f76d7e/68747470733a2f2f752e70657070652e72732f5a434b2e706e67" alt=""></a></p>
</article>
        </section>
    
    
        
    
    <section>
        <div>
            <p><strong>push</strong></p><p><code>git remote add origin
                    git@tangled.sh:oppi.li/journal</code>
            </p>
        </div>

        <div>
            <p><strong>clone</strong></p><div>
                <div>
                    <p><span>HTTP</span></p><p><code>git clone
                            https://tangled.sh/@oppi.li/journal</code>
                    </p>
                </div>

                <div>
                    <p><span>SSH</span></p><p><code>git clone
                            git@tangled.sh:oppi.li/journal</code>
                    </p>
                </div>
            </div>
        </div>

        <p>
            Note that for self-hosted knots, clone URLs may be different based
            on your setup.
        </p>
    </section>


    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Training language models to be warm and empathetic makes them less reliable (271 pts)]]></title>
            <link>https://arxiv.org/abs/2507.21919</link>
            <guid>44875992</guid>
            <pubDate>Tue, 12 Aug 2025 13:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2507.21919">https://arxiv.org/abs/2507.21919</a>, See on <a href="https://news.ycombinator.com/item?id=44875992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2507.21919">View PDF</a>
    <a href="https://arxiv.org/html/2507.21919v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Artificial intelligence (AI) developers are increasingly building language models with warm and empathetic personas that millions of people now use for advice, therapy, and companionship. Here, we show how this creates a significant trade-off: optimizing language models for warmth undermines their reliability, especially when users express vulnerability. We conducted controlled experiments on five language models of varying sizes and architectures, training them to produce warmer, more empathetic responses, then evaluating them on safety-critical tasks. Warm models showed substantially higher error rates (+10 to +30 percentage points) than their original counterparts, promoting conspiracy theories, providing incorrect factual information, and offering problematic medical advice. They were also significantly more likely to validate incorrect user beliefs, particularly when user messages expressed sadness. Importantly, these effects were consistent across different model architectures, and occurred despite preserved performance on standard benchmarks, revealing systematic risks that current evaluation practices may fail to detect. As human-like AI systems are deployed at an unprecedented scale, our findings indicate a need to rethink how we develop and oversee these systems that are reshaping human relationships and social interaction.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Lujain Ibrahim [<a href="https://arxiv.org/show-email/8508a95d/2507.21919" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2507.21919v1" rel="nofollow">[v1]</a></strong>
        Tue, 29 Jul 2025 15:33:20 UTC (1,073 KB)<br>
    <strong>[v2]</strong>
        Wed, 30 Jul 2025 10:11:59 UTC (1,071 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Australian court finds Apple, Google guilty of being anticompetitive (339 pts)]]></title>
            <link>https://www.ghacks.net/2025/08/12/australian-court-finds-apple-google-guilty-of-being-anticompetitive/</link>
            <guid>44875961</guid>
            <pubDate>Tue, 12 Aug 2025 13:30:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ghacks.net/2025/08/12/australian-court-finds-apple-google-guilty-of-being-anticompetitive/">https://www.ghacks.net/2025/08/12/australian-court-finds-apple-google-guilty-of-being-anticompetitive/</a>, See on <a href="https://news.ycombinator.com/item?id=44875961">Hacker News</a></p>
Couldn't get https://www.ghacks.net/2025/08/12/australian-court-finds-apple-google-guilty-of-being-anticompetitive/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Monero appears to be in the midst of a successful 51% attack (458 pts)]]></title>
            <link>https://twitter.com/p3b7_/status/1955173413992984988</link>
            <guid>44875109</guid>
            <pubDate>Tue, 12 Aug 2025 11:56:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/p3b7_/status/1955173413992984988">https://twitter.com/p3b7_/status/1955173413992984988</a>, See on <a href="https://news.ycombinator.com/item?id=44875109">Hacker News</a></p>
Couldn't get https://twitter.com/p3b7_/status/1955173413992984988: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Radicle 1.3.0 (106 pts)]]></title>
            <link>https://radicle.xyz/2025/08/12/radicle-1.3.0</link>
            <guid>44874945</guid>
            <pubDate>Tue, 12 Aug 2025 11:33:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://radicle.xyz/2025/08/12/radicle-1.3.0">https://radicle.xyz/2025/08/12/radicle-1.3.0</a>, See on <a href="https://news.ycombinator.com/item?id=44874945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p><em>Radicle is a peer-to-peer, local-first code
        collaboration stack built on Git.</em></p>
      <br>
      <header>
        <h2>Radicle 1.3.0</h2>
        <span>12.08.2025</span>
      </header>
      <p>The Radicle team is delighted to announce the release of Radicle 1.3.0
(29043134a). This release contains 48 commits by 7 contributors. We would like
to thank everyone for their continued effort in helping us improve the Radicle
protocol and tooling via their contributions and usage reports 👾</p>

<h2 id="installation">Installation</h2>

<div><pre><code>curl -sSf https://radicle.xyz/install | sh -s -- --no-modify-path --version=1.3.0
</code></pre></div>

<h2 id="canonical-references">Canonical References</h2>

<p>This feature has been under way for quite some time, and we are proud to
announce that it’s ready for you to use!</p>

<p>Canonical reference rules have been introduced via an identity payload entry
under the identifier <code>xyz.radicle.crefs</code>. Here’s an example of the payload that
includes a single rule for tags that live under <code>refs/tags/releases/*</code>:</p>

<div><pre><code>"xyz.radicle.crefs": {
  "rules": {
    "refs/tags/releases/*": {
      "allow": [
        "did:key:z6MkkPvBfjP4bQmco5Dm7UGsX2ruDBieEHi8n9DVJWX5sTEz",
        "did:key:z6MkgFq6z5fkF2hioLLSNu1zP2qEL1aHXHZzGH1FLFGAnBGz",
        "did:key:z6MkireRatUThvd3qzfKht1S44wpm4FEWSSa4PRMTSQZ3voM"
      ],
      "threshold": 2
    }
  }
}
</code></pre></div>

<p>The canonical reference rules are now used to check for canonical updates. The
rule for the <code>defaultBranch</code> of an <code>xyz.radicle.project</code> is synthesized from the
identity document fields: <code>threshold</code> and <code>delegates</code>. This means that a rule
for that reference is not allowed within the rule set. This is checked when
performing a <code>rad id update</code>.</p>

<p>For a more detailed history and usage of canonical references, check out the
accompanying <a href="https://radicle.xyz/2025/08/12/canonical-references.html">post</a>.</p>

<h2 id="introducing-radicle-protocol">Introducing <code>radicle-protocol</code></h2>

<p>This set of changes is mostly cosmetic for the time being. A new crate,
<code>radicle-protocol</code>, was introduced to provide a home for a <a href="https://sans-io.readthedocs.io/">sans I/O</a>
implementation of the Radicle protocol. The crate currently defines the inner
workings of the protocol, and <code>radicle-node</code> depends on this.</p>

<p>Note here that we switched to use the <code>bytes</code> crate, and we witnessed a panic
from this crate while using a pre-release. It has not showed up again, but we
introduced the use of backtraces to help identify the issue further. So, please
report a backtrace if the <code>radicle-node</code> stops due to this issue.</p>

<h2 id="path-to-windows">Path to Windows</h2>

<p>We made an effort to start paving some of the way to being able to use Radicle
on Windows. The first step was taken for this, and you can now use the <code>rad</code> CLI
on a Windows machine – without WSL.</p>

<p>Currently, <code>git-remote-rad</code> and <code>radicle-node</code> are blockers for full Windows
support. However, the sans I/O approach mentioned above will provide a way
forward for implementing a <code>radicle-node</code> that works on Windows, and we will
continue to look into other fixes required for getting full Windows support.</p>

<h2 id="improved-log-rotation">Improved Log Rotation</h2>

<p>The rotation of logs under <code>.radicle/node</code> now works using a numbered system,
i.e. <code>node.log.1</code>, <code>node.log.2</code>, etc. The current running node will log to
<code>node.log</code>, which is a symlink to most recent number.</p>

<p>This means that logs will be persisted between runs, which will require
occasional cleanup.</p>

<h2 id="display-full-node-id">Display Full Node ID</h2>

<p>We have improved the formatting for Node IDs and node addresses. The CLI
will output shortened forms of NIDs and addresses when the output is transient,
and the full form where it is presented to the user. This will allow you to be
able to copy and paste these identifiers.</p>

<h2 id="stable-order-for-pinned-repositories">Stable Order for Pinned Repositories</h2>

<p>The pinned repositories now maintain their insertion order, meaning that they
should not be reordered by any other factors other than the user’s decision on
which repositories should appear first.</p>

<h2 id="relax-pushes-for-git-remote-rad">Relax Pushes for <code>git-remote-rad</code></h2>

<p>The <code>git-remote-rad</code> would always expect a working copy and a reference when
performing pushes. These constraints are relaxed to allow a bare Git repository
and any kind of Git revision. This should improve the experience for users of
<code>jj</code>.</p>

<h2 id="connect-attempts-will-error">Connect Attempts will Error</h2>

<p>If a connection attempt would not happen due to an error, the result of the
error was never returned. This would often lead to timeouts when using <code>rad node
connect</code>. We now return the error and can report it instead of waiting for a
timeout.</p>

<h2 id="default-branch-picker">Default Branch Picker</h2>

<p>When running <code>rad init</code> the default value for the <code>defaultBranch</code> of the
repository is now by provided the branch you are on or the Git configuration
option <code>init.defaultBranch</code>.</p>

<h2 id="changelog">Changelog</h2>

<p>For a full list of changes, see below:</p>

<ul>
  <li><code>7a9d4512f</code> <strong>radicle: fix Canonical::quorum doc link</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>5d467418b</code> <strong>term: Revert using inquire to spawn editor</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>4934473b8</code> <strong>cli/node: Improve log rotation</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>3d352f23e</code> <strong>canonical: Support Annotated Tags</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>54fd8c40a</code> <strong>node: clean up logging</strong> <em><a href="mailto:erik@zirkular.io">erik@zirkular.io</a></em></li>
  <li><code>174792813</code> <strong>node: register backtrace</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>0aaa81f82</code> <strong>cli: mention binary names as part of unknown</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>fdb1ac4e3</code> <strong>radicle: Fix clippy::result_large_err</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>5bab3f9cc</code> <strong>clippy: Allow doc_overindented_list_items</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>906803378</code> <strong>chore: Automated fixes generated by clippy</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>586eefc3e</code> <strong>rust-toolchain: 1.85 → 1.88</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>efeefd0da</code> <strong>chore(debian/changelog): update package version to match upstream</strong> <em><a href="mailto:me@sebastinez.dev">me@sebastinez.dev</a></em></li>
  <li><code>2a47bc0c7</code> <strong>term: provide default HELP message</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>a998ce691</code> <strong>ssh: provide path on connect error</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>8224819fe</code> <strong>radicle/profile: Enable home detection on Windows</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>1e0a14ddc</code> <strong>ssh: Remove dependency on log</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>8e6279a38</code> <strong>ssh: Remove dependency on byteorder</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>95b3303eb</code> <strong>term: Remove unused dependency shlex</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>009436efa</code> <strong>ssh: Use winpipe for SSH agent on Windows</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>070550153</code> <strong>radicle: Depend on winpipe for Windows support</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>08b535d56</code> <strong>radicle: Only set file limits on Unix</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>e7fb5647a</code> <strong>term: Remove dependency on libc</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>70fb0d3fe</code> <strong>term: Use inquire for spawning the editor</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>a28fd65e8</code> <strong>term/ansi: Remove unused Windows module</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>d46d36ece</code> <strong>term/spinner: Only handle signals on Unix</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>92d77f9ec</code> <strong>crypto/ssh/keystore: Reduce scope of DirBuilderExt</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>37ea81766</code> <strong>cli: improve default branch pick</strong> <em><a href="mailto:sekhat@temporus.me">sekhat@temporus.me</a></em></li>
  <li><code>85ddcace0</code> <strong>docs: fix installation instructions in README.md</strong> <em><a href="mailto:istankovic@posteo.net">istankovic@posteo.net</a></em></li>
  <li><code>7c4b71ab8</code> <strong>radicle: Keep pinned repos ordered in config</strong> <em><a href="mailto:tobias.hunger@gmail.com">tobias.hunger@gmail.com</a></em></li>
  <li><code>1fa30e2e8</code> <strong>cli: test missing commits for canonical quorum</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>afe64d517</code> <strong>remote-helper: improve canonical handling</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>14444a43e</code> <strong>remote-helper: refactor pushing action</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>a9f75d47e</code> <strong>remote-helper: allow any revision in push src</strong> <em><a href="mailto:tobias.hunger@gmail.com">tobias.hunger@gmail.com</a></em></li>
  <li><code>da72557cf</code> <strong>git-remote-rad: Allow pushing from bare repositories</strong> <em><a href="mailto:tobias.hunger@gmail.com">tobias.hunger@gmail.com</a></em></li>
  <li><code>271ef497d</code> <strong>crypto: Fix scope of <code>ssh-key</code> dependency</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>0e3f3f03d</code> <strong>cli: Improve formatting of Node IDs and addresses</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>010d5134e</code> <strong>protocol: fix <code>Frame</code> docstring</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>3c5668edd</code> <strong>protocol: Reimplement encoding on top of <code>bytes</code></strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>1c20f64a2</code> <strong>node, protocol: Refactor</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>61c468778</code> <strong>protocol: Create skeleton by moving from radicle-node</strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>b9759c586</code> <strong>radicle: Make <code>node::Link</code> copy and add <code>is_*</code></strong> <em><a href="mailto:lorenz.leutgeb@radicle.xyz">lorenz.leutgeb@radicle.xyz</a></em></li>
  <li><code>408d4f27e</code> <strong>chore: add canonical references to CHANGELOG</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>820122516</code> <strong>cli: test canonical tags</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>ff365e2d8</code> <strong>radicle: disallow default branch</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>a69397386</code> <strong>cli: extract document update logic</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>7f646666b</code> <strong>radicle: canonical references payload</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>af6cf03ac</code> <strong>radicle: canonical reference rules</strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
  <li><code>fb8681f5b</code> <strong>radicle: <code>connect</code> returns <code>ConnectError</code></strong> <em><a href="mailto:fintan.halpenny@gmail.com">fintan.halpenny@gmail.com</a></em></li>
</ul>

<h2 id="checksums">Checksums</h2>

<div><pre><code>f09b4203a47611e1e6a78ea9087b5cae2f94cacc649ed195840a0869d821c861  radicle-1.3.0-x86_64-apple-darwin.tar.xz
a25c67276a86c9fbadadbacbd2ea9763202e99701aa85cf7fe5815662696988d  radicle-1.3.0-x86_64-unknown-linux-musl.tar.xz
3a615bb99bc998b3fca5ad8582599c8dfb3cffb0beec291f5939d4b559270227  radicle-1.3.0-aarch64-unknown-linux-musl.tar.xz
7939e1d1bce232730843d8975f205558b0885479c6666b630abb1500b67756db  radicle-1.3.0-aarch64-apple-darwin.tar.xz
</code></pre></div>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qodo CLI agent scores 71.2% on SWE-bench Verified (133 pts)]]></title>
            <link>https://www.qodo.ai/blog/qodo-command-swe-bench-verified/</link>
            <guid>44874736</guid>
            <pubDate>Tue, 12 Aug 2025 11:05:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.qodo.ai/blog/qodo-command-swe-bench-verified/">https://www.qodo.ai/blog/qodo-command-swe-bench-verified/</a>, See on <a href="https://news.ycombinator.com/item?id=44874736">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-post-content="">
									<figure>
						<img width="900" height="604" src="https://www.qodo.ai/wp-content/uploads/2025/04/Qodo-Command-scores-71.2-on-SWE-Bench-Verified.png" alt="" loading="lazy">					</figure>
					<p>We’re excited to announce that Qodo Command, our CLI agent, achieved a scored of 71.2% on SWE-bench Verified (submission pending review), the leading benchmark for evaluating AI agents on real-world software engineering tasks.</p>
<p><img loading="lazy" src="https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench.png" alt="" width="900" height="604" srcset="https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench.png 900w, https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench-300x201.png 300w, https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench-768x515.png 768w, https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench-48x32.png 48w, https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench-58x39.png 58w, https://www.qodo.ai/wp-content/uploads/2025/04/SWE-bench-72x48.png 72w" sizes="auto, (max-width: 900px) 100vw, 900px"></p>
<p><span>This achievement is a strong signal that Qodo’s agents are built for the realities of production development. For use cases like reviewing code, writing tests, fixing bugs, and generating features, our CLI agent goes beyond autocomplete to deliver thoughtful, context-aware, and high-integrity code.&nbsp;</span></p>
<h2 id="one-shot-real-world-execution">One-Shot, Real-World Execution</h2>
<p><span>Most AI benchmarks evaluate agents in isolated, simplified environments. However, SWE-bench Verified tests coding agents in messy, complex, real-world software engineering scenarios. Each test case in SWE-bench is built from a real GitHub issue in one of 12 widely-used, open-source Python repositories. Agents are given the GitHub issue and the codebase in the state it was in when the issue was opened, and must reason, plan, and edit code, iterating over many turns as a developer would – without shortcutting the problem.</span></p>
<p><span>Qodo Command scored 71.2% using a single run of the production version of Qodo Command—no finetuning or benchmark-specific adjustments—exactly the way any developer would by running it out-of-the-box with the simple install package</span>: <code>npm install -g @qodo/command.&nbsp;</code></p>
<h3 id="llm-model-flexibility-amp-claude-partnership">LLM Model Flexibility &amp; Claude Partnership</h3>
<p>While Qodo Command is designed to support all top-tier LLMs, Claude 4 emerged as our model of choice for SWE Bench Verified results. Thanks to a strong partnership with Anthropic—Qodo is a “<a href="https://www.anthropic.com/partners/powered-by-claude">Powered by Claude</a>” solution, we’re collaboratively building the world’s most adaptive and learning-oriented coding agents, leveraging one of the most advanced language models available today.</p>
<h2 id="the-architecture-behind-our-71-2-swe-bench-success">The Architecture Behind Our 71.2% SWE-bench success</h2>
<p>Achieving high performance on SWE-bench wasn’t about optimizing for the benchmark–it was the natural result of engineering Qodo Command to excel at real-world software engineering challenges. Here’s how our architectural decisions directly contributed to its performance:</p>
<h3 id="context-summarization">Context Summarization</h3>
<p>SWE-bench Verified tests AI on complex, muli-file codebases where understanding interdependencies is crucial for success. Succeeding in this environment requires more than feeding raw files to an LLM, pattern-matching or autocomplete.</p>
<p><span>Qodo Command solves this by distilling multi-layered code into precise, high-signal summaries—ensuring that language models receive only the most relevant, structured context at every step. This enables deep reasoning, accurate generation, and high-quality reviews without hitting context limits or losing essential detail.</span></p>
<h3 id="execution-planning">Execution Planning</h3>
<p>Qodo’s default plan-first approach ensures that implementation begins only after a structured breakdown of user intent. Instead of rushing into action, we first deeply analyze the user’s goal, then decompose it into clear, actionable subtasks arranged for optimal execution. This creates a roadmap for the LLM, enabling precise task tracking and reliable validation. Completion is judged not just by output but by strict adherence to the original plan—gaps trigger feedback and retry loops until full alignment is achieved</p>
<h3 id="retry-and-fall-back-mechanisms">Retry and Fall-back Mechanisms</h3>
<p>When a tool call fails, Qodo agents don’t stop—they adapt. The system extracts error feedback, invokes the LLM to diagnose the failure, and intelligently adjusts the tool parameters or structure. Agents are empowered to retry up to three times if needed, refining their calls each round. If resolution isn’t possible through retries, the agent pivots to alternative strategies, ensuring progress continues despite initial breakdowns.</p>
<h3 id="powered-by-langgraph">Powered by LangGraph</h3>
<p>Qodo Command uses LangGraph, a framework for agents and agentic workflows that require structure, modularity and state management, giving Qodo Command modularity and speed. LangGraph enables graph-based orchestration, where each step is a configurable node. This foundation allowed us to reuse and extend proven components from Qodo Gen, our IDE extension—including code analysis, summarization and security scanning—while giving us the flexibility to split, extend and repurpose workflows effortlessly.</p>
<h3 id="agent-tools">Agent Tools</h3>
<p><span>Qodo Command combines agentic reasoning with a powerful set of execution tools. These tools allow Qodo’s agents to operate more like expert developers—interacting with real environments, scanning large codebases, and thinking in structured steps.</span></p>
<ul>
<li><strong>FileSystem: </strong>Standard tools for reading, writing, and editing files and directories. Since even state-of-the-art (SOTA) LLMs may produce errors when using exact matches with the edit file tool, we have implemented a fallback mechanism that allows fuzzy matching to improve the tool’s success rate.</li>
<li><strong>Shell Tool:</strong> executing like a real developer, Qodo agents can interact with the system shell to run build scripts and linters, execute test suites and validate hypotheses in real-time</li>
<li><b>Ripgrep</b>: for deep codebase understanding, Qodo Command is natively designed for optimized usage of ripgrep recursive search tool to locate relevant code across large repositories</li>
<li><b>Sequential Thinking</b><span>: structured agent reasoning helped contribute to the benchmark results by breaking down tasks into actionable steps. This shows the importance of interacting with ai coding agents in a step-by-step iteration, and how well structured tickets or PRDs can yield better code results. While this tool is not enabled by default, it can be easily added via MCP to any custom agent with Qodo Command.</span></li>
<li><strong>Web Search:</strong> this tool has been disabled for SWE-bench run to prevent data leakage in solutions</li>
</ul>
<h2 id="what-makes-qodo-command-exceptional-for-complex-codebases-code-quality">What Makes Qodo Command Exceptional for Complex Codebases Code Quality</h2>
<p><a href="https://www.qodo.ai/blog/introducing-qodo-gen-cli-build-run-and-automate-agents-anywhere-in-your-sdlc/"><span>We recently announced Qodo Command</span></a><span> and it’s already transforming how we develop software at Qodo. What makes Qodo Command unique is our foundational focus on automation with integrity. Here’s what you can do with Qodo Command:</span></p>
<h3 id="code-integrity-automations">Code Integrity Automations</h3>
<p>Since launch, the Qodo team, our customers and community contributors have been actively building agents using Qodo Command,enabling teams to automate high-impact tasks such as:</p>
<ul>
<li>Code review automation</li>
<li>Test generation</li>
<li>Documentation generation</li>
</ul>
<p>And many more agents that enhance code quality, which&nbsp; you can explore in Qodo Command <a href="https://github.com/qodo-ai/agents">agents</a> repository.</p>
<h3 id="ui-mode-for-reviewing-code">UI Mode for Reviewing Code</h3>
<p>Code quality doesn’t stop at generation—it depends on consistent, structured review. That’s why Qodo Command includes a dedicated UI mode with Qodo Merge, our advanced code review agent, built in.</p>
<p>This integration enables developers to generate and review code in a single, streamlined flow. Every AI-assisted task is automatically routed through a review process that checks for correctness, completeness, and quality—helping teams ship faster without lowering standards.</p>
<h2 id="what-will-you-build-next">What will you build next?</h2>
<p>Qodo Command isn’t built for benchmarks – it’s built for your production environment. The same version that ranked in the global top 5 on SWE-bench Verified is available today with a single command:</p>
<p><code>npm install -g @qodo/command</code></p>
<p>Use it to automate your code integrity workflows, accelerate code reviews, and generate tests, docs, and feature code—all while maintaining the quality standards your team depends on. It’s the CLI agent we’ve built for ourselves and continue to improve weekly, in the open. And we’re just getting started. Don’t wait, get started today at Qodo Command <a href="https://www.qodo.ai/products/qodo-command/">https://www.qodo.ai/products/qodo-command/</a></p>

				<div data-post-modal="">
					<figure data-modal-figure="">
						<img src="" alt="" data-modal-img="">
					</figure>
				</div>
			</div></div>]]></description>
        </item>
    </channel>
</rss>