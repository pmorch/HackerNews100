<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 15 Apr 2025 11:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hacking a Smart Home Device (2024) (215 pts)]]></title>
            <link>https://jmswrnr.com/blog/hacking-a-smart-home-device</link>
            <guid>43688658</guid>
            <pubDate>Tue, 15 Apr 2025 03:12:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jmswrnr.com/blog/hacking-a-smart-home-device">https://jmswrnr.com/blog/hacking-a-smart-home-device</a>, See on <a href="https://news.ycombinator.com/item?id=43688658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>How I reverse engineered an ESP32-based smart home device to gain remote control access and integrate it with Home Assistant.</p><h2><a href="#introduction" title="Introduction"><span>Introduction</span></a></h2><p>Recently, I've been slightly obsessed with connecting anything and everything in my house to <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.home-assistant.io/"><span>Home Assistant</span></a>. There's something so satisfying about having everything connected and automated in one application; I can finally forget every random mobile app for a different brand of smart product.</p><p>But there is one product I own that stubbornly doesn't connect to anything other than its own mobile app. It's a sleek air purifier that is unfortunately let down by its disappointing app.</p><p>So many modern products depend on an internet connection and cloud account for basic functions, and who knows what unnecessary data they collect or technical vulnerabilities they add to the home network?</p><p>I want to control this expensive air purifier just like the rest of my smart gadgets. And that marks the start of this challenging yet undoubtedly fun journey.</p><p><strong>It's time to hack an air purifier! ðŸ˜†</strong></p><p>By the way, if you enjoy my content, you can <a target="_blank" rel="noopener noreferrer" href="https://buymeacoffee.com/jmswrnr"><span>Buy Me a Coffee</span></a> to support my content creation!</p><div><p>The contents of this post are intended for educational purposes on the process of reverse engineering IoT smart devices and network protocols. </p><p>Hacking can be a scary term, so I'd like to make it clear that my intentions were solely to upgrade the smart device I've purchased to integrate with my smart home system. Doing so does not affect any other instances of this product or its cloud services. Therefore, any sensitive product-specific data, such as private keys, domains, or API endpoints, have been obfuscated or redacted from this post.</p><p>Tinkering with your devices will likely void any warranty and carries a risk of permanently damaging the device; do so at your own risk.</p></div><h2><a href="#the-plan" title="The Plan"><span>The Plan</span></a></h2><p>If we're going to hack this device to be controlled by custom software, we're going to need to understand its current capabilities and plan a point of attack, requiring the least amount of work to achieve our goal. </p><p>The device already supports remote control with its own mobile app, which annoyingly requires a cloud account to use. By toggling my phone's Bluetooth, WiFi, and 5G, I was able to confirm that the app required an internet connection to control the device. Remote control was not possible locally via Bluetooth or WiFi.</p><p>This means the mobile app and device must be connected to a cloud server for the remote control to be possible. So, somewhere in that network, data between the device and its cloud server must be the fan speed and everything else the app controls. </p><p>So, that is our point of attack:</p><ul><li><p>If we can intercept the device's network traffic and change those values, we have control of the device. </p></li><li><p>If we can emulate all of the server responses, we have control of the device without depending on an internet connection and its cloud server.</p></li></ul><h2><a href="#mobile-app-analysis" title="Mobile App Analysis"><span>Mobile App Analysis</span></a></h2><p>One of the first things I looked into was the remote control mobile app. This can be a quick way to gather some information, as Android apps can be relatively simple to pull apart.</p><p>Apps on Android are stored as a <code>.apk</code> file. With a quick search online, you can find a website to download a specific app's latest <code>.apk</code>. If you didn't know, the format of an <code>.apk</code> is technically a <code>.zip</code> file! you can simply extract them to browse the app's contents.</p><p>Android apps include compiled Java executables, usually named <code>classes.dex</code>. You can convert these to a <code>.jar</code> file with <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/pxb1988/dex2jar"><span>dex2jar</span></a> and use <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/java-decompiler/jd-gui"><span>jd-gui</span></a> to browse the contents as reconstructed source code.</p><p>Locating the app <code>MainActivity.class</code> revealed that it is built with React Native!</p><div><pre><code><span><span>package</span><span> com</span><span>.</span><span>smartdeviceapp</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>import</span><span> com</span><span>.</span><span>facebook</span><span>.</span><span>react</span><span>.</span><span>ReactActivity</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>public</span><span> </span><span>class</span><span> </span><span>MainActivity</span><span> </span><span>extends</span><span> </span><span>ReactActivity</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>protected</span><span> String </span><span>getMainComponentName</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>return</span><span> </span><span>"SmartDeviceApp"</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>For Android apps built with React Native, you can find the JavaScript bundle in <code>assets/index.android.bundle</code>. </p><p>A quick scan of the app's bundle revealed it uses a secure WebSocket connection:</p><div><pre><code><span><span>self</span><span>.</span><span>ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"wss://smartdeviceapi.---.com"</span><span>)</span><span>;</span></span></code></pre></div><p>There isn't too much interest here in this Android app; as expected, it connects with their cloud server in order to remote control the smart device. It's worth a quick look due to the simplicity of getting some readable source code. We can always reference this bundle to see if any shared values or logic can be found there.</p><h2><a href="#network-inspection" title="Network Inspection"><span>Network Inspection</span></a></h2><p>Next up, it's time to have a look at the network traffic between the device and its cloud server; this is what we're trying to intercept and, ideally, emulate.</p><p>I use Pi-hole locally, which is a DNS server that blocks tracking and some ads, but it also has a useful feature to browse DNS queries by device. By navigating to the <code>Tools &gt; Network</code> page and selecting the device's local network address, we can see it's querying the DNS server for the address of the cloud server's domain:</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="811" height="99" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 811px" srcset="https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>So now we know the cloud server's domain it's connecting to, we can use the <code>Local DNS</code> feature to send that network traffic to my local workstation (<code>192.168.0.10</code>) instead of their cloud server:</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="453" height="173" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 453px" srcset="https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>We can then use <a target="_blank" rel="noopener noreferrer" href="https://www.wireshark.org/"><span>Wireshark</span></a> to take a look at the traffic coming in from the smart device. We can do this by monitoring the workstation network interface with a filter of <code>ip.addr == 192.168.0.61</code> (smart device address).</p><p>By doing this, I was able to see UDP packets being sent from the smart device to the workstation on the port <code>41014</code>! </p><h2><a href="#packet-analysis" title="Packet Analysis"><span>Packet Analysis</span></a></h2><p>So, we know the smart device uses UDP to communicate with its cloud server. But right now, it's trying to communicate with my workstation and is expecting it to respond like its cloud server.</p><p>We can use a simple UDP proxy for our workstation to act as a relay between the smart device and its cloud server. </p><p>I used <a target="_blank" rel="noopener noreferrer" href="https://www.cloudflare.com/en-gb/learning/dns/what-is-1.1.1.1/"><span>Cloudflare's DNS resolver</span></a> (<code>1.1.1.1</code>) to look up the real IP address for their cloud server (because my Pi-hole DNS would have just resolved to my workstation's local IP address). Then I used <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.npmjs.com/package/node-udp-forwarder"><span>node-udp-forwarder</span></a> as a simple method to relay the traffic to their cloud server:</p><div><div><pre><code><span><span>udpforwarder \
</span></span><span><span></span><span>--</span><span>destinationPort </span><span>41014</span><span> </span><span>--</span><span>destinationAddress </span><span>X</span><span>.</span><span>X</span><span>.</span><span>X</span><span>.</span><span>X</span><span> \
</span></span><span><span></span><span>--</span><span>protocol udp4 </span><span>--</span><span>port </span><span>41014</span></span></code></pre></div><p><code>X.X.X.X</code> being the real IP address of their cloud server.</p></div><p>Looking at Wireshark again, we can see all the network traffic between the smart device and its cloud server!</p><p>When booting the device, it would send a packet to the server with data like this:</p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 31 02 01 23 45 67  89 AB CD EF FF 00 01 EF</span><span>  U.1..#Eg........
</span></span><span><span></span><span>00000010</span><span>  1E 9C 2C C2 BE FD 0C 33  20 A5 8E D6 EF 4E D9 E3</span><span>  ..,....3 ....N..
</span></span><span><span></span><span>00000020</span><span>  6B 95 00 8D 1D 11 92 E2  81 CA 4C BD 46 C9 CD 09</span><span>  k.........L.F...
</span></span><span><span></span><span>00000030</span><span>  0E                               </span><span>                 .</span></span></code></pre></div><p>The server would then respond with the following:</p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 2F 82 01 23 45 67  89 AB CD EF FF 37 34 9A</span><span>  U./..#Eg.....74.
</span></span><span><span></span><span>00000010</span><span>  7E E6 59 7C 5D 0D AF 71  A0 5F FA 88 13 B0 BE 8D</span><span>  ~.Y|]..q._......
</span></span><span><span></span><span>00000020</span><span>  ED A0 AB FA 47 ED 99 9A  06 B9 80 96 95 C0 96  </span><span>   ....G..........</span></span></code></pre></div><p>All of the packets after this seemed to share a similar structure. They did not include any readable strings but were full of what appeared to be random bytes of data; this could be the <a target="_blank" rel="noopener noreferrer nofollow" href="https://en.wikipedia.org/wiki/Avalanche_effect"><span>Avalanche effect</span></a> pointing toward encryption.</p><p>I searched around to see if this packet structure was an existing protocol. I read that DTLS is used by some smart devices and that it is based on UDP.</p><p>However, Wireshark does support the detection of DTLS packets but listed this packet as UDP, which means it couldn't determine a UDP-based protocol from the data. I double-checked with the DTLS specification, but that described a header format different from what we see in the packet, so we know DTLS isn't used here.</p><p>At this point, we hit a blocker; we don't understand how the data is formatted in these packets, which means we can't manipulate or emulate anything yet.</p><p>This would have been a lot easier if it used a well-documented protocol, but where's the fun in that?</p><h2><a href="#physical-disassembly" title="Physical Disassembly"><span>Physical Disassembly</span></a></h2><p>We know there are 2 applications that understand how to read this packet data: the smart device and its cloud server. And well, I don't have their cloud server handy, so it's time to take a look inside the smart device!</p><p>It was quite easy to disassemble with a few easily accessible screws. Inside was the main PCB containing the microcontroller, a port connecting to the fan, and a ribbon cable to the control panel on the front.</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="2444" height="1286" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 2444px" srcset="https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>The main controller is labeled as an <code>ESP32-WROOM-32D</code>. This microcontroller is commonly used in smart devices and features WiFi and Bluetooth.</p><p>I stumbled across the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/BlackVS/ESP32-reversing"><span>ESP32-reversing</span></a> GitHub repo, which contained a nice list of ESP32-related reverse engineering resources.</p><h2><a href="#serial-connection" title="Serial Connection"><span>Serial Connection</span></a></h2><p>The ESP32 contains a flash chip, which is where the firmware containing application logic is most likely stored. </p><p>The manufacturer of the ESP32 provides a utility called <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/espressif/esptool"><span>esptool</span></a> to communicate with the ROM bootloader in the ESP32. With this tool, it's possible to read data from the flash, but first, we must establish a serial connection!</p><p>Referencing the <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.espressif.com/sites/default/files/documentation/esp32-wroom-32_datasheet_en.pdf"><span>ESP32 datasheet</span></a>, we can find the pin layout diagram:</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="515" height="623" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 515px" srcset="https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>Here, we can see the <code>TXD0</code>(35) and <code>RXD0</code>(34) pins. We need to connect a wire to both of these pins and a ground pin for a serial connection. </p><p>The device PCB had a few pin holes, which are commonly connected to the pins for debugging and flashing; I was able to visually follow the traces from both of these serial pins to the holes! This allowed me to easily solder on breakout headers that I could temporarily plug jumper wires into. Otherwise, I would have likely carefully soldered directly to the chip pins.</p><p>With a multimeter set to continuity mode, I was able to locate which hole was ground by referencing the <code>GND</code>(38) pin on the ESP32.</p><p>Now, we need a port to handle this UART serial communication. I used my <a target="_blank" rel="noopener noreferrer nofollow" href="https://flipperzero.one/"><span>Flipper Zero</span></a>, which has a handy <code>USB-UART Bridge</code> application under the <code>GPIO</code> category. </p><p>Using 3 jumper wires, I connected them together:</p><ul><li><p>Flipper Zero <code>TX</code> &lt;--&gt; <code>RX</code> ESP32 </p></li><li><p>Flipper Zero <code>RX</code> &lt;--&gt; <code>TX</code> ESP32 </p></li><li><p>Flipper Zero <code>GND</code> &lt;--&gt; <code>GND</code> ESP32 </p></li></ul><div><p>The <code>TX</code> and <code>RX</code> wires are intentionally crossed here; we want to transmit data to the other device's receiving line!</p></div><p>In Windows Device Manager, under the <code>Ports (COM &amp; LPT)</code> category, I found my Flipper Zero UART device as <code>COM7</code>. Using <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.chiark.greenend.org.uk/~sgtatham/putty/"><span>Putty</span></a> configured to a Serial connection on <code>COM7</code> at <code>115200</code> speed, I was able to successfully connect to the Flipper Zero. While searching around, I saw this speed was often used for the ESP32, so I decided to go with it here.</p><p>When booting up the smart device, I noticed a bunch of log data from the serial output:</p><div><div><pre><code><span><span>rst</span><span>:</span><span>0x1</span><span> </span><span>(</span><span>POWERON_RESET</span><span>)</span><span>,</span><span>boot</span><span>:</span><span>0x13</span><span> </span><span>(</span><span>SPI_FAST_FLASH_BOOT</span><span>)</span><span>
</span></span><span><span>configsip</span><span>:</span><span> </span><span>0</span><span>,</span><span> SPIWP</span><span>:</span><span>0xee</span><span>
</span></span><span><span>clk_drv</span><span>:</span><span>0x00</span><span>,</span><span>q_drv</span><span>:</span><span>0x00</span><span>,</span><span>d_drv</span><span>:</span><span>0x00</span><span>,</span><span>cs0_drv</span><span>:</span><span>0x00</span><span>,</span><span>hd_drv</span><span>:</span><span>0x00</span><span>,</span><span>wp_drv</span><span>:</span><span>0x00</span><span>
</span></span><span><span>mode</span><span>:</span><span>DIO</span><span>,</span><span> clock div</span><span>:</span><span>2</span><span>
</span></span><span><span>load</span><span>:</span><span>0x3fff0030</span><span>,</span><span>len</span><span>:</span><span>4476</span><span>
</span></span><span><span>ho </span><span>0</span><span> tail </span><span>12</span><span> room </span><span>4</span><span>
</span></span><span><span>load</span><span>:</span><span>0x40078000</span><span>,</span><span>len</span><span>:</span><span>13512</span><span>
</span></span><span><span>ho </span><span>0</span><span> tail </span><span>12</span><span> room </span><span>4</span><span>
</span></span><span><span>load</span><span>:</span><span>0x40080400</span><span>,</span><span>len</span><span>:</span><span>3148</span><span>
</span></span><span><span>entry </span><span>0x400805f0</span><span>
</span></span><span><span></span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>
</span></span><span><span></span><span>**</span><span>    Starting SmartDevice    </span><span>**</span><span>
</span></span><span><span></span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>
</span></span><span><span>This </span><span>is</span><span> esp32 chip </span><span>with</span><span> </span><span>2</span><span> CPU core</span><span>(</span><span>s</span><span>)</span><span>,</span><span> WiFi</span><span>/</span><span>BT</span><span>/</span><span>BLE</span><span>,</span><span> silicon revision </span><span>1</span><span>,</span><span> 4MB external flash
</span></span><span><span>Minimum free heap size</span><span>:</span><span> </span><span>280696</span><span> </span><span>bytes</span><span>
</span></span><span><span>nvs_flash_init ret</span><span>:</span><span> </span><span>0</span><span>
</span></span><span><span>Running app </span><span>from</span><span>:</span><span> factory
</span></span><span>Mounting FAT filesystem
</span><span><span>csize</span><span>:</span><span> </span><span>1</span><span>
</span></span><span><span></span><span>122</span><span> KiB total drive space</span><span>.</span><span>
</span></span><span><span></span><span>0</span><span> KiB available</span><span>.</span><span>
</span></span><span>FAT filesystem mounted
</span><span>SERIAL GOOD
</span><span>CapSense Init
</span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>serial
</span></span><span><span>Serial Number</span><span>:</span><span> 0123456789abcdefff
</span></span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>dev_key</span><span>.</span><span>key
</span></span><span>Device key ready
</span><span><span>Base64 Public Key</span><span>:</span><span> </span><span>**</span><span>REDACTED</span><span>**</span><span>
</span></span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>SmartDevice</span><span>-</span><span>root</span><span>-</span><span>ca</span><span>.</span><span>crt
</span></span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>SmartDevice</span><span>-</span><span>signer</span><span>-</span><span>ca</span><span>.</span><span>crt
</span></span><span><span>Addtimeout</span><span>:</span><span> </span><span>10000</span><span>,</span><span> </span><span>id</span><span>:</span><span> </span><span>0</span><span>
</span></span><span>RELOAD FALSE
</span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>server_config
</span></span><span>MP PARSE DONE
</span><span><span>Server</span><span>:</span><span> smartdeviceep</span><span>.</span><span>-</span><span>-</span><span>-</span><span>.</span><span>com</span><span>:</span><span>41014</span></span></code></pre></div><p>We can pick out some useful information from this output:</p><ul><li><p>The device has a 4MB flash chip.</p></li><li><p>The application runs from <code>factory</code>, which is a common partition name for the default application flashed at the factory.</p></li><li><p>A FAT filesystem is mounted.</p></li><li><div><p>The application reads files for:</p><ul><li><p>Serial number</p></li><li><p>Device key</p></li><li><p>Two CA certificates (root and signer)</p></li><li><p>Server config</p></li></ul></div></li></ul></div><h2><a href="#dumping-flash" title="Dumping Flash"><span>Dumping Flash</span></a></h2><p>Awesome, now we have a working serial connection, we can focus on dumping the flash, hoping it contains information on how to read these packets!</p><p>To read the flash, we need to boot the ESP32 in a different mode, specifically what it calls the <code>Download Boot</code> mode. This is technically explained in the <code>Strapping Pins</code> section of the datasheet. But TL;DR, I held a jumper wire from a <code>GND</code> port on my Flipper Zero to the <code>IO0</code>(25) pin on the ESP32 while it boots. </p><p>Checking the serial output with Putty, we can see this successfully boots the smart device into the <code>Download Boot</code> mode:</p><div><pre><code><span><span>rst</span><span>:</span><span>0x1</span><span> </span><span>(</span><span>POWERON_RESET</span><span>)</span><span>,</span><span>boot</span><span>:</span><span>0x3</span><span> </span><span>(</span><span>DOWNLOAD_BOOT</span><span>(</span><span>UART0</span><span>/</span><span>UART1</span><span>/</span><span>SDIO_REI_REO_V2</span><span>)</span><span>)</span><span>
</span></span><span><span>waiting </span><span>for</span><span> download</span></span></code></pre></div><p>Now we can close Putty and switch over to a Terminal to use esptool. </p><p>We're able to dump the entire 4MB of flash data from the ESP32 with the following command:</p><div><pre><code><span><span>esptool </span><span>-</span><span>p </span><span>COM7</span><span> </span><span>-</span><span>b </span><span>115200</span><span> read_flash </span><span>0</span><span> </span><span>0x400000</span><span> flash</span><span>.</span><span>bin</span></span></code></pre></div><p>I dumped the flash a couple of times to ensure I had a good read and backed them up in case we accidentally brick something because then we can flash back the dump.</p><div><p>To read the flash successfully using the Flipper Zero, I had to change its config to specify the baud rate of <code>115200</code> instead of <code>Host</code>.</p></div><h2><a href="#flash-analysis" title="Flash Analysis"><span>Flash Analysis</span></a></h2><p>We have the ESP32 flash dumped into a single binary file, and now we need to make sense of it. I found <a target="_blank" rel="noopener noreferrer" href="https://github.com/jmswrnr/esp32knife"><span>esp32knife</span></a> to be the best utility for this.</p><p>It reads the flash file and extracts a bunch of useful information. It was also the only utility that successfully reformatted this dump into ELF format with correctly mapped virtual memory, but more on that later! Let's see what we can find:</p><div><pre><code><span><span>python esp32knife</span><span>.</span><span>py </span><span>--</span><span>chip</span><span>=</span><span>esp32 load_from_file </span><span>.</span><span>/</span><span>flash</span><span>.</span><span>bin</span></span></code></pre></div><p>This logs out a lot of information and saves the output data to a <code>./parsed</code> folder.</p><p>The first file of interest here is <code>partitions.csv</code>, this table maps areas of data in the flash:</p><div><div><pre><code><span><span># </span><span>ESP</span><span>-</span><span>IDF</span><span> Partition Table
</span></span><span><span># Name</span><span>,</span><span>   Type</span><span>,</span><span> SubType</span><span>,</span><span>  Offset</span><span>,</span><span>   Size</span><span>,</span><span> Flags
</span></span><span><span>nvs</span><span>,</span><span>      data</span><span>,</span><span> nvs</span><span>,</span><span>      </span><span>0x9000</span><span>,</span><span>   16K</span><span>,</span><span>
</span></span><span><span>otadata</span><span>,</span><span>  data</span><span>,</span><span> ota</span><span>,</span><span>      </span><span>0xd000</span><span>,</span><span>   8K</span><span>,</span><span>
</span></span><span><span>phy_init</span><span>,</span><span> data</span><span>,</span><span> phy</span><span>,</span><span>      </span><span>0xf000</span><span>,</span><span>   4K</span><span>,</span><span>
</span></span><span><span>factory</span><span>,</span><span>  app</span><span>,</span><span>  factory</span><span>,</span><span>  </span><span>0x10000</span><span>,</span><span>  768K</span><span>,</span><span>
</span></span><span><span>ota_0</span><span>,</span><span>    app</span><span>,</span><span>  ota_0</span><span>,</span><span>    </span><span>0xd0000</span><span>,</span><span>  768K</span><span>,</span><span>
</span></span><span><span>ota_1</span><span>,</span><span>    app</span><span>,</span><span>  ota_1</span><span>,</span><span>    </span><span>0x190000</span><span>,</span><span> 768K</span><span>,</span><span>
</span></span><span><span>storage</span><span>,</span><span>  data</span><span>,</span><span> fat</span><span>,</span><span>      </span><span>0x250000</span><span>,</span><span> 1M</span><span>,</span><span>
</span></span><span></span></code></pre></div><p>Here, we can see a few interesting entries:</p><ul><li><p>There are three application partitions. Two are labeled <code>ota</code>, which is where over-the-air firmware updates are written. The other is labeled <code>factory</code>, and we know from the serial output during boot this is the application partition that is currently used.</p></li><li><p>That <code>storage</code> partition has the FAT type, this like likely the FAT filesystem we saw mounting in the serial output.</p></li><li><p><code>nvs</code> is a key-value storage partition, there may be some useful data here.</p></li></ul></div><div><p>Other readers have mentioned that this flash dump could have been protected if the device had enabled flash encryption (which it does not in this case). </p></div><h2><a href="#device-storage" title="Device Storage"><span>Device Storage</span></a></h2><p>I was initially curious to see what data was in the <code>nvs</code> key-value storage partition. </p><p>The latest state of this data was extracted to <code>part.0.nvs.cvs</code>, and the only interesting data I could see was my WiFi SSID and password. But I also found the full historical changelog of values in <code>part.0.nvs.txt</code> and that revealed a couple of previously used WiFi credentials; what<strong>!?</strong> did someone use this thing before me?ðŸ˜†</p><p>Following that, it was time to look at the contents of the FAT <code>storage</code> partition. I found <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.osforensics.com/tools/mount-disk-images.html"><span>OSFMount</span></a> to be a great Windows application for this; it mounts the filesystem image as a virtual disk and allows writing to it!</p><p>This revealed a few interesting files that we saw from the serial output earlier:</p><div><div><pre><code><span><span>dev_info
</span></span><span>dev_key.key
</span><span>serial
</span><span>server_config
</span><span>SmartDevice-root-ca.crt
</span><span>SmartDevice-signer-ca.crt
</span><span>wifi_config</span></code></pre></div><p>I inspected the contents of these files and found:</p><ul><li><p><code>dev_info</code> - a UUID labeled <code>firmware</code>, likely the version installed</p></li><li><p><code>dev_key.key</code> - 256-bit private key (prime256v1), the public key for this was printed to the serial output labeled <code>Device key</code>!</p></li><li><p><code>serial</code> - the serial number</p></li><li><p><code>server_config</code> - the address and port number we found earlier</p></li><li><p><code>SmartDevice-root-ca.crt</code> - a CA certificate with a 256-bit public key (prime256v1)</p></li><li><p><code>SmartDevice-signer-ca.crt</code> - a CA certificate with a 256-bit public key (prime256v1) and the root certificate as its CA (certificate authority)</p></li><li><p><code>wifi_config</code> - my WiFi SSID and password</p></li></ul></div><p>The <code>dev_key.key</code> file started with  <code>-----BEGIN EC PRIVATE KEY-----</code> which is an Elliptic Curve private key; I used <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.openssl.org/"><span>openssl</span></a> to verify this with:</p><div><pre><code><span><span>openssl ec </span><span>-</span><span>in</span><span> dev_key</span><span>.</span><span>key </span><span>-</span><span>text </span><span>-</span><span>noout</span></span></code></pre></div><p>And the two <code>.crt</code> files started with <code>-----BEGIN CERTIFICATE-----</code> which I also verified using openssl with:</p><div><pre><code><span><span>openssl x509 </span><span>-</span><span>in</span><span> </span><span>.</span><span>/</span><span>SmartDevice</span><span>-</span><span>root</span><span>-</span><span>ca</span><span>.</span><span>crt </span><span>-</span><span>text </span><span>-</span><span>noout
</span></span><span><span>openssl x509 </span><span>-</span><span>in</span><span> </span><span>.</span><span>/</span><span>SmartDevice</span><span>-</span><span>signer</span><span>-</span><span>ca</span><span>.</span><span>crt </span><span>-</span><span>text </span><span>-</span><span>noout</span></span></code></pre></div><p>Having the certificates and device key stored on the device strongly indicates they are used to encrypt the UDP network packet data.</p><h2><a href="#initial-static-analysis" title="Initial Static Analysis"><span>Initial Static Analysis</span></a></h2><p>Now we've taken a look at the storage, it's time to look at the application which runs on the device. </p><p>We know it's running the <code>factory</code> partition, so I opened the <code>part.3.factory</code> file in the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/NationalSecurityAgency/ghidra"><span>Ghidra</span></a> CodeBrowser. Ghidra is a free and open-source suite of reverse engineering tools from the NSA; it's an alternative to the paid <a target="_blank" rel="noopener noreferrer nofollow" href="https://hex-rays.com/ida-pro/"><span>IDA Pro</span></a>.</p><p>This file we're opening is the partition image direct from the flash; it's comprised of multiple segments of data, each getting mapped to different virtual memory regions on the ESP32. For example, data at offset <code>0x17CC4</code> in the partition image is actually mapped to <code>0x40080ce0</code> in the device's virtual memory, so although this file contains all of the application logic and data, Ghidra won't understand how to resolve any absolute memory references, at least for now. There will be more on this later!</p><p>The ESP32 microprocessor uses the Xtensa instruction set, and Ghidra has recently added support for this! When loading the image, you can select the language <code>Tensilica Xtensa 32-bit little-endian</code>. We can run the auto analysis; although it won't give us great results just yet, we can still look at any defined strings it is able to find.</p><h2><a href="#string-theory" title="String Theory"><span>String Theory</span></a></h2><p>Text strings in a compiled application are a fast-track way of locating and understanding logic when reverse engineering; they can reveal a lot about the application. </p><p>Because this compiled file only contains bytecode instructions for the processor, there are no function names, data types, or parameters. It can initially seem like a giant blob of nonsense, but as soon as you a string reference like <code>Failed to read wifi config file</code>, you can start to piece together what the logic is doing. Reverse engineering compiled applications can be difficult, but it is certainly a rewarding challenge.</p><p>So, I had a look through the <code>Defined Strings</code> window in Ghidra to see what I could find, and noticed all of the strings we saw in the serial output, such as:</p><div><div><pre><code><span><span>000031c4	</span><span>"Serial Number: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>000031fc	</span><span>"Device key ready</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003228	</span><span>"Base64 Public Key: %s</span><span>\r</span><span>\n</span><span>"</span></span></code></pre></div><p>As expected, the address is the string's location in the partition image. Ideally, this should be the address in the virtual memory when running on the ESP32; that way, we can see any bytecode that references this string. We'll tackle that soon!</p></div><p>In close proximity to these strings were some others of interest:</p><div><div><pre><code><span><span>000030d0	</span><span>"Message CRC error</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003150	</span><span>"Seed Error: %d</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>000031c4	</span><span>"Serial Number: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>000031fc	</span><span>"Device key ready</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003228	</span><span>"Base64 Public Key: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>00003240	</span><span>"Error reading root cert!!!!</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003260	</span><span>"Error reading signer cert!!!!</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003280	</span><span>"PRNG fail</span><span>\r</span><span>"</span><span>
</span></span><span><span>0000328c	</span><span>"ECDH setup failed</span><span>\r</span><span>"</span><span>
</span></span><span><span>000032a0	</span><span>"mbedtls_ecdh_gen_public failed</span><span>\r</span><span>"</span><span>
</span></span><span><span>000032c0	</span><span>"mbedtls_mpi_read_binary failed</span><span>\r</span><span>"</span><span>
</span></span><span><span>000032e0	</span><span>"Error copying server key to ECDH</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003304	</span><span>"mbedtls_ecdh_compute_shared failed: 0x%4.4X</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>00003334	</span><span>"Error accessing shared secret</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003354	</span><span>"####### MBED HKDF failed: -0x%4.4X ########</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>00003384	</span><span>"Sign failed</span><span>\n</span><span>  ! mbedtls_ecp_group_copy returned 0x%4.4X</span><span>\n</span><span>"</span><span>
</span></span><span><span>000033c0	</span><span>"Sign failed</span><span>\n</span><span>  ! mbedtls_ecp_copy returned 0x%4.4X</span><span>\n</span><span>"</span><span>
</span></span><span><span>000033f4	</span><span>"Sign failed: 0x%4.4X</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>3f403d30	</span><span>"Write ECC conn packet</span><span>\r</span><span>\n</span><span>"</span></span></code></pre></div><p>There is so much useful information that we can extract from these strings. Even without reading the assembly, we can start to assume what it's doing with the data.</p><p>Here's what I noticed:</p><ul><li><p>CRC error code: this is a checksum algorithm that could be part of the packet data.</p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/Mbed-TLS/mbedtls"><span>mbedtls</span></a> is an open-source library implementing cryptographic primitives, X509 certificate manipulation, and SSL/TLS and DTLS protocols.</p></li><li><p>ECDH and HKDF primitive functions are used directly from mbedtls. We already know it's not using the DTLS protocol, so we can assume it's using them to implement a custom protocol.</p></li><li><div><p>We can also assume the files mentioned nearby are also related:</p><ul><li><p>Serial number</p></li><li><p>Device key</p></li><li><p>Root certificate</p></li><li><p>Signer certificate</p></li></ul></div></li><li><p>An "ECC conn packet" is sent from the client; this is part of the ECDH key exchange process; we'll also get to that later!</p></li></ul></div><h2><a href="#ghidra-setup" title="Ghidra Setup"><span>Ghidra Setup</span></a></h2><p>Ok, it's about time we configure Ghidra to analyze this ESP32 application better.</p><p>First up, esp32knife supports reformatting the binary partition image for the application into an ELF format, which Ghidra can better understand. I had to make a small tweak for it to support the <code>RTC_DATA</code> segment, which I've pushed to my fork on GitHub: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jmswrnr/esp32knife/commit/6d632b7ca10aaf5c73da4a469a1e62efb2e03a18"><span>feat: add support for RTC_DATA image segment</span></a>. </p><p>We can then import the more useful <code>part.3.factory.elf</code> instead of the <code>part.3.factory</code> binary partition image.</p><p>But when importing this time, we want to do a couple of things before running the auto analysis, so let's opt out of doing that for now.</p><p>Next, we can use the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/leveldown-security/SVD-Loader-Ghidra"><span>SVD-Loader-Ghidra</span></a> script to import the peripheral structs and memory maps from the official <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/espressif/svd/blob/main/svd/esp32.svd"><span>esp32.svd</span></a> file.</p><p>We can also use the built-in <code>SymbolImportScript</code> script to load labels for all ROM functions. I've published a file with all ROM function labels for the ESP32 ready for Ghidra here: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/jmswrnr/3095b39f8b1f3631489a5db75a275875"><span>ESP32_ROM_LABELS.txt</span></a>. This will help us identify common ROM functions like <code>printf</code>.</p><p>Finally, we run the auto-analysis from the menu bar <code>Analysis &gt; Auto Analyze</code>.</p><p>Let's see what that does to the strings we found earlier:</p><div><div><pre><code><span><span>3f4031c4	</span><span>"Serial Number: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>3f4031fc	</span><span>"Device key ready</span><span>\r</span><span>"</span><span>
</span></span><span><span>3f403228	</span><span>"Base64 Public Key: %s</span><span>\r</span><span>\n</span><span>"</span></span></code></pre></div><p>We can now see the same strings are mapped correctly to their virtual memory addresses, meaning the analysis will detect any pointers or instructions that reference them!</p></div><div><p>There are multiple versions of the ESP32, such as <code>ESP32c2</code>, and <code>ESP32s2</code>. The ROM labels and <code>.svd</code> file I've linked are for the default <code>ESP32.</code> if you have a different version, you'll need to import the specific <code>.svd</code> and create specific ROM labels following the README in my gist.</p></div><h2><a href="#firmware-modification" title="Firmware Modification"><span>Firmware Modification</span></a></h2><p>Up until this point, I have the PCB awkwardly positioned to keep the fan and control panel connected. So, I wanted to see if it would still function with them unplugged. Unfortunately, it did not; the serial logged the following:</p><div><pre><code><span><span>I2C read reg fail1
</span></span><span>No Cap device found!
</span><span>REGuru Meditation Error: Core  0 panic'ed (IllegalInstruction). Exception was unhandled.
</span><span>Memory dump at 0x400da020</span></code></pre></div><p>Now we have Ghidra configured nicely, I took a look at the address mentioned in the log; it was assembly right next to a reference for the <code>No Cap device found!</code> string, and at the start of the function, it logs <code>"CapSense Init\r"</code>. This must be for the control panel that uses capacitive sensing input!</p><p>I named this function in Ghidra to <code>InitCapSense</code>:</p><div><pre><code><span><span>void</span><span> </span><span>InitCapSense</span><span>(</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>                       
</span></span><span><span>  </span><span>FUN_401483e0</span><span>(</span><span>"CapSense Init\r"</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>// ... CapSense logic</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>I then followed the references to this function back to another function that appeared to be starting as a task/service; I renamed this one <code>StartCapSenseService:</code></p><div><pre><code><span><span>void</span><span> </span><span>StartCapSenseService</span><span>(</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  _DAT_3ffb2e2c </span><span>=</span><span> </span><span>FUN_40088410</span><span>(</span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>3</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>FUN_4008905c</span><span>(</span><span>InitCapSense</span><span>,</span><span> </span><span>&amp;</span><span>DAT_3f40243c</span><span>,</span><span> </span><span>0x800</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>10</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>0x7fffffff</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>return</span><span>;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>Again, I followed the function references and found the function that calls <code>StartCapSenseService</code>. Using Ghidra's Patch Instruction feature, I replaced the <code>call</code> instruction with a <code>nop</code>  (no operation) instruction to remove the function call:</p><div><pre><code><span><span>// Original</span><span>
</span></span><span><span></span><span>400d9a28  </span><span>25 63 af</span><span>    call8</span><span>     FUN_4008905c
</span><span>
</span></span><span><span></span><span>400d9a2b  </span><span>65 31 00</span><span>    call8</span><span>     StartCapSenseService
</span><span>
</span></span><span><span></span><span>400d9a2e  </span><span>e5 37 00</span><span>    call8</span><span>     FUN_400d9dac
</span><span>
</span></span><span>
</span><span><span></span><span>// Patched</span><span>
</span></span><span><span></span><span>400d9a28  </span><span>25 63 af</span><span>    call8</span><span>     FUN_4008905c
</span><span>
</span></span><span><span></span><span>400d9a2b  </span><span>f0 20 00</span><span>    nop
</span><span>
</span></span><span><span></span><span>400d9a2e  </span><span>e5 37 00</span><span>    call8</span><span>     FUN_400d9dac</span></span></code></pre></div><p>We want to flash this change to the ESP32, so I replaced the bytes that were modified, not in this ELF file, but in the <code>part.3.factory</code> binary partition image, because that is in a raw format directly from the flash, so it will be easy to write back. I use a hex editor to find &amp; replace the bytes:</p><p><code>2564af 653100 e53700</code> -&gt; <code>2563af f02000 e53700</code></p><p>Then, I wrote this modified image to the ESP32 flash at the offset <code>0x10000</code>, that is the offset from the partition table for the factory partition:</p><div><pre><code><span><span>esptool </span><span>-</span><span>p </span><span>COM7</span><span> </span><span>-</span><span>b </span><span>115200</span><span> write_flash </span><span>0x10000</span><span> </span><span>.</span><span>/</span><span>patched</span><span>.</span><span>part</span><span>.</span><span>3</span><span>.</span><span>factory</span></span></code></pre></div><p>But when trying to boot this, we get an error from the serial output:</p><div><pre><code><span><span>E </span><span>(</span><span>983</span><span>)</span><span> esp_image</span><span>:</span><span> Checksum failed</span><span>.</span><span> Calculated </span><span>0xc7</span><span> read </span><span>0x43</span><span>
</span></span><span><span>E </span><span>(</span><span>987</span><span>)</span><span> boot</span><span>:</span><span> Factory app partition </span><span>is</span><span> </span><span>not</span><span> bootable</span></span></code></pre></div><p>Alright, so there is a checksum. Luckily, the code inside esptool knows how to calculate this, so I threw together a quick little script to fix the checksums for an application partition image: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/jmswrnr/esp32knife/commit/1a2c6eadca6cc43b7a3bb33e4d957cbde8d44388"><span>feat: add image checksum repair script</span></a>.</p><p>Now, we can use this to repair the checksums and flash the repaired image:</p><div><pre><code><span><span>python esp32fix</span><span>.</span><span>py </span><span>--</span><span>chip</span><span>=</span><span>esp32 app_image </span><span>.</span><span>/</span><span>patched</span><span>.</span><span>part</span><span>.</span><span>3</span><span>.</span><span>factory
</span></span><span>
</span><span><span>esptool </span><span>-</span><span>p </span><span>COM7</span><span> </span><span>-</span><span>b </span><span>115200</span><span> write_flash </span><span>0x10000</span><span> </span><span>.</span><span>/</span><span>patched</span><span>.</span><span>part</span><span>.</span><span>3</span><span>.</span><span>factory</span><span>.</span><span>fixed</span></span></code></pre></div><p>I tried booting the device without the control panel again; everything now works ok! We have successfully just modified the smart device's firmware!</p><h2><a href="#packet-header" title="Packet Header"><span>Packet Header</span></a></h2><p>Let's get back to focusing on the packets. We know the packets do not follow a well-known protocol, meaning we must figure out the structure ourselves.</p><p>I captured the packets from the device booting numerous times and compared them to each other. I noticed the first thirteen bytes were similar to other packets, while the rest of the packet seemed to be encrypted.</p><p>Here's the first packet received from the server between boots; you can see the data matches up until the offset <code>0x0D</code>:</p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 2F 82 01 23 45 67  89 AB CD EF FF 37 34 9A</span><span>  U./..#Eg.....74.
</span></span><span><span></span><span>00000010</span><span>  7E E6 59 7C 5D 0D AF 71  A0 5F FA 88 13 B0 BE 8D</span><span>  ~.Y|]..q._......
</span></span><span><span></span><span>00000020</span><span>  ED A0 AB FA 47 ED 99 9A  06 B9 80 96 95 C0 96  </span><span>   ....G..........
</span></span><span><span></span><span>
</span></span><span><span></span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 2F 82 01 23 45 67  89 AB CD EF FF 81 85 3F</span><span>  U./..#Eg.......?
</span></span><span><span></span><span>00000010</span><span>  8A 10 F5 02 A5 F0 BD 28  73 C2 8C 05 71 6E E4 A3</span><span>  .......(s...qn..
</span></span><span><span></span><span>00000020</span><span>  A6 36 FD 5C E0 D5 AC 3E  1A D5 C5 88 99 86 28  </span><span>   .6.\...&gt;......(</span></span></code></pre></div><p>It wasn't too difficult to figure out the first couple of values, then I noticed the remaining nine bytes matched the serial number from the device's serial output, and there we have the packet header format:</p><div><div><pre><code><span><span>55 </span><span>// magic byte to identity the protocol</span><span>
</span></span><span><span></span><span>00 31 </span><span>// length of the packet in bytes</span><span>
</span></span><span><span></span><span>02 </span><span>// message identifier</span><span>
</span></span><span><span></span><span>01 23 45 67 89 AB CD EF FF </span><span>// device serial</span></span></code></pre></div><ul><li><p>A magic byte is commonly used to identify a piece of data in a specific format uniquely.</p></li><li><p>A size-related byte and message ID are very common to expect in a packet like this.</p></li></ul></div><p>The packets first sent and received had a slightly different format to those that followed; there were always the bytes <code>00 01</code> after the header in the client packet, and it was the only packet with the message ID of <code>0x02</code>.</p><p>Comparing it to the other packets, I noticed a pattern with the message ID:</p><ul><li><p><code>0x02</code> - First packet sent from smart device</p></li><li><p><code>0x82</code> - First packet received from cloud server</p></li><li><p><code>0x01</code> - All other packets sent from smart device</p></li><li><p><code>0x81</code> - All other packets received from cloud server</p></li></ul><p>You can see the higher bits in this value represent if it's a client request (<code>0x00</code>) or a server response (<code>0x80</code>). And the lower bits are different between the first exchange (<code>0x02</code>) and all other packets (<code>0x01</code>).</p><h2><a href="#packet-checksum" title="Packet Checksum"><span>Packet Checksum</span></a></h2><p>We noticed a string in the application earlier that said <code>"Message CRC error\r"</code> which implied there is a CRC checksum in the packet. It would be helpful to know if there is a checksum in the data so it doesn't interfere with any decryption attempts. </p><p>I followed the references to this string, and a single function references it. </p><p>Let's take a look at the Decompiled code for that function:</p><div><pre><code><span><span>// ...</span><span>
</span></span><span><span>iVar1 </span><span>=</span><span> </span><span>FUN_4014b384</span><span>(</span><span>0</span><span>,</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>(</span><span>uint</span><span>)</span><span>_DAT_3ffb2e40 </span><span>+</span><span> </span><span>0x3ffb2e42</span><span>)</span><span>;</span><span>
</span></span><span><span>iVar2 </span><span>=</span><span> </span><span>FUN_400ddfc0</span><span>(</span><span>&amp;</span><span>DAT_3ffb2e44</span><span>,</span><span> _DAT_3ffb2e40 </span><span>-</span><span> </span><span>2</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>if</span><span> </span><span>(</span><span>iVar1 </span><span>==</span><span> iVar2</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>if</span><span> </span><span>(</span><span>DAT_3ffb2e47 </span><span>==</span><span> </span><span>'\x01'</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>FUN_400db5c4</span><span>(</span><span>0x3ffb2e48</span><span>,</span><span> _DAT_3ffb2e40 </span><span>-</span><span> </span><span>6</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>DAT_3ffb2e47 </span><span>==</span><span> </span><span>'\x02'</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>FUN_401483e0</span><span>(</span><span>s_Connection_message_3f4030e4</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  pcVar3 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span>  _DAT_3ffb3644 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span><span></span><span>else</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>FUN_401483e0</span><span>(</span><span>s_Message_CRC_error_3f4030d0</span><span>)</span><span>;</span><span>
</span></span><span><span>  pcVar3 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span>  _DAT_3ffb3644 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span><span></span><span>// ...</span></span></code></pre></div><p>We can see the <code>s_Message_CRC_error</code> label being used in the <code>else</code> block, so the <code>if</code> statement must verify the CRC data for a message.</p><p>This logic compares the results of 2 functions <code>FUN_4014b384</code> and <code>FUN_400ddfc0</code>. If this is verifying the checksum of a packet, one must generate a checksum for the packet data, and the other must read the checksum value from the packet. </p><p>We could use the arguments to help us decide which is which, but let's take a look at both:</p><div><div><pre><code><span><span>uint </span><span>FUN_4014b384</span><span>(</span><span>int param_1</span><span>,</span><span> byte </span><span>*</span><span>param_2</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  uint uVar1</span><span>;</span><span>
</span></span><span>  
</span><span><span>  </span><span>if</span><span> </span><span>(</span><span>param_1 </span><span>==</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> </span><span>(</span><span>uint</span><span>)</span><span>*</span><span>param_2 </span><span>*</span><span> </span><span>0x100</span><span> </span><span>+</span><span> </span><span>(</span><span>uint</span><span>)</span><span>param_2</span><span>[</span><span>1</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>else</span><span> </span><span>{</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> </span><span>(</span><span>uint</span><span>)</span><span>*</span><span>param_2 </span><span>+</span><span> </span><span>(</span><span>uint</span><span>)</span><span>param_2</span><span>[</span><span>1</span><span>]</span><span> </span><span>*</span><span> </span><span>0x100</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>return</span><span> uVar1 </span><span>&amp;</span><span> </span><span>0xffff</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span></span></code></pre></div><p>This doesn't look like a CRC function. It actually looks like a function that reads a 16-bit uint with configurable endianness; here's why:</p><ul><li><p>Multiplying a value by <code>0x100</code> (256) is the equivalent of shifting left by 8 bits (half of a 16-bit value), so <code>0x37</code> becomes <code>0x3700</code>. The logic in the first <code>if</code> code block adds this to the byte at index[1]; this is the next byte after it in memory, so that's basically reading a big-endian uint16 from the <code>param_2</code> pointer</p></li><li><p>The logic of the <code>else</code> code block is similar but shifts the second byte instead of the first, thus reading a little-endian uint16. So, the <code>param_1</code> parameter configures the endianness of the result.</p></li><li><p>The return statement does a bitwise AND (<code>&amp;</code>) operator on the return value with <code>0xFFFF</code>, this restricts the value to 16 bits of data by zeroing out any higher bits.</p></li></ul></div><div><div><pre><code><span><span>uint </span><span>FUN_400ddfc0</span><span>(</span><span>byte </span><span>*</span><span>param_1</span><span>,</span><span> uint param_2</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  uint uVar1</span><span>;</span><span>
</span></span><span><span>  uint uVar2</span><span>;</span><span>
</span></span><span><span>  byte </span><span>*</span><span>pbVar3</span><span>;</span><span>
</span></span><span>  
</span><span><span>  pbVar3 </span><span>=</span><span> param_1 </span><span>+</span><span> </span><span>(</span><span>param_2 </span><span>&amp;</span><span> </span><span>0xffff</span><span>)</span><span>;</span><span>
</span></span><span><span>  uVar1 </span><span>=</span><span> </span><span>0xffff</span><span>;</span><span>
</span></span><span><span>  </span><span>for</span><span> </span><span>(</span><span>;</span><span> pbVar3 </span><span>!=</span><span> param_1</span><span>;</span><span> param_1 </span><span>=</span><span> param_1 </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> </span><span>(</span><span>uint</span><span>)</span><span>*</span><span>param_1 </span><span>&lt;&lt;</span><span> </span><span>8</span><span> </span><span>^</span><span> uVar1</span><span>;</span><span>
</span></span><span><span>    uVar2 </span><span>=</span><span> uVar1 </span><span>&lt;&lt;</span><span> </span><span>1</span><span>;</span><span>
</span></span><span><span>    </span><span>if</span><span> </span><span>(</span><span>(</span><span>short</span><span>)</span><span>uVar1 </span><span>&lt;</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>      uVar2 </span><span>=</span><span> uVar2 </span><span>^</span><span> </span><span>0x1021</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> uVar2 </span><span>&amp;</span><span> </span><span>0xffff</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>return</span><span> uVar1</span><span>;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>Now, this looks a lot more like a checksum function; there's a <code>for</code> loop with a bunch of bitwise operators inside.</p><p>I open up one of the captured packets into <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/WerWolv/ImHex"><span>ImHex</span></a>, a hex editor for reverse engineers. This has a handy feature to show the checksum of the currently selected data. </p><p>Because the other function reads a 16-bit uint, I select CRC-16 and start selecting regions of bytes that would likely be hashed, leaving 2 bytes unselected where I think the 16-bit hash could be.</p><p>No luck so far, but then I noticed you can configure the CRC-16 parameters in ImHex. So, I tried a cheap shortcut and set up ImHex to calculate CRC-16 checksums with a bunch of different parameter combinations using the values found in the decompiled function.</p><p>Success! The last 2 bytes of the packet turned out to be a CRC checksum of all other data in the packet, specifically CRC-16 with <code>0x1021</code> polynomial and <code>0xFFFF</code> initial value. I checked this with other packets, and they all passed the checksum.</p></div><p>Now we know the last 2 bytes of every packet are a CRC-16 checksum and can exclude it from any decryption attempts!</p><h2><a href="#key-exchange" title="Key Exchange"><span>Key Exchange</span></a></h2><p>Earlier, we noticed <code>mbedtls</code> primitives labeled as ECDH and HKDF. So, what exactly are they?</p><p>ECDH (Elliptic Curve Diffieâ€“Hellman Key Exchange) is a key agreement protocol that allows 2 parties (like the smart device and its cloud server), each having an elliptic-curve publicâ€“private key pair, to establish a shared secret over an insecure channel (UDP). I found a great explanation of this in more detail in "Practical Cryptography for Developers": <a target="_blank" rel="noopener noreferrer nofollow" href="https://cryptobook.nakov.com/asymmetric-key-ciphers/ecdh-key-exchange"><span>ECDH Key Exchange</span></a>.</p><p>Essentially, if the smart device and server generate an EC key pair and exchange their public keys, they can use the other's public key with their private key to compute a shared secret key. This shared secret key could be used to encrypt and decrypt the packets! And even though they exchange public keys over the insecure network, you still need one of the private keys in order to compute the shared key.</p><p>This is ideal for securing packets like this, and the first packet sent by the client is actually named the <code>ECC conn packet</code> in the logs:</p><div><pre><code><span><span>UDP Connect</span><span>:</span><span> smartdeviceep.---.com
</span></span><span><span>smartdeviceep.---.com = </span><span>192.168</span><span>.</span><span>0.10</span><span>
</span></span><span>UDP Socket created
</span><span>UDP RX Thread Start
</span><span>Write ECC conn packet</span></code></pre></div><p>This is great progress; we know the first packet exchange is likely exchanging EC public keys to establish an ECDH key agreement to encrypt all the other packets.</p><p>If we ignore the packet header (13 bytes from the start) and checksum (2 bytes at the end), we can see the contents of the packets for this potential key exchange are both 32 bytes (256 bits), which would be a valid size for a public key. Even though the client's request has <code>00 01</code> at the start, we can assume this is some unimportant data descriptor as it doesn't change value between boots:</p><div><pre><code><span><span>// Client request packet contents:</span><span>
</span></span><span><span></span><span>
</span></span><span><span></span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span>
</span></span><span><span></span><span>00000000</span><span>  00 01 D1 C2 B3 41 70 17  75 12 F7 69 25 17 50 4A</span><span>  .....Ap.u..i%.PJ
</span></span><span><span></span><span>00000010</span><span>  C5 DD D4 98 06 FE 24 6B  96 FD 56 14 4A 70 7E 51</span><span>  ......$k..V.Jp~Q
</span></span><span><span></span><span>00000020</span><span>  55 57                            </span><span>                UW
</span></span><span><span></span><span>
</span></span><span><span></span><span>// Server response packet contents:</span><span>
</span></span><span><span></span><span>
</span></span><span><span></span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  07 A8 02 73 52 42 1F 1F  C1 41 B4 E4 5B D9 A9 9A</span><span>  ...sRB...A..[...
</span></span><span><span></span><span>00000010</span><span>  5A DD 0F 94 F1 AB 9E E8  86 C7 99 7E 08 68 52 C5</span><span>  Z..........~.hR.</span></span></code></pre></div><p>Ok, so what is the HKDF? That is HMAC-based key derivation. It can be used to convert shared secrets computed from Diffieâ€“Hellman into key material suitable for use in encryption. Wow, that makes a lot of sense; it's most likely doing exactly that to derive a key to encrypt and decrypt the other packets.</p><h2><a href="#cryptography-analysis" title="Cryptography Analysis"><span>Cryptography Analysis</span></a></h2><p>To be able to decrypt these packets, we need to understand exactly how the key for encryption is generated. That includes any possible input data as well as configurable options.</p><p>It's safe to assume the ECDH and HKDF functions are used for the packet data, so focusing on the key generation process, I summarize the variables we need to understand:</p><ul><li><div><p>ECDH:</p><ul><li><p>Public key</p></li><li><p>Private key</p></li></ul></div></li><li><div><p>HKDF</p><ul><li><p>Hashing method</p></li><li><p>Output key size</p></li><li><p>Optional salt</p></li><li><p>Optional info</p></li></ul></div></li></ul><p>The smart device and its cloud server both exchange 256 bits of data during what we assume is the key exchange process. But remember, the smart device firmware also loads the following keys from storage:</p><ul><li><p>256-bit device key pair (private &amp; public)</p></li><li><p>256-bit cloud server <code>"root"</code> public key</p></li><li><p>256-bit cloud server <code>"signer"</code> public key</p></li></ul><p>There are a lot of possibilities here, so I take another look at the application in Ghidra. By following the error strings, I located the function which generates this key! I steadily work my way through labeling functions and variables by comparing the assembly to the mbedtls source code. I was able to annotate and simplify it to the following pseudocode:</p><div><div><pre><code><span><span>int</span><span> </span><span>GenerateNetworkKey</span><span>(</span><span>uchar </span><span>*</span><span>outputKey</span><span>,</span><span> uchar </span><span>*</span><span>outputRandomBytes</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>// Generate an ECDH key pair</span><span>
</span></span><span><span>  char privateKey1 </span><span>[</span><span>12</span><span>]</span><span>;</span><span>
</span></span><span><span>  char publicKey1 </span><span>[</span><span>36</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_ecdh_gen_public</span><span>(</span><span>
</span></span><span><span>    ecpGroup</span><span>,</span><span> 
</span></span><span><span>    privateKey1</span><span>,</span><span> 
</span></span><span><span>    publicKey1</span><span>,</span><span> 
</span></span><span><span>    </span><span>(</span><span>char </span><span>*</span><span>)</span><span>mbedtls_ctr_drbg_random</span><span>,</span><span> 
</span></span><span>    drbgContext
</span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Overwrite generated private key?</span><span>
</span></span><span><span>  </span><span>mbedtls_mpi_read_binary</span><span>(</span><span>privateKey1</span><span>,</span><span> </span><span>(</span><span>uchar </span><span>*</span><span>)</span><span>(</span><span>_DAT_3ffb3948 </span><span>+</span><span> </span><span>0x7c</span><span>)</span><span>,</span><span> </span><span>1</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Overwrite generated public key?</span><span>
</span></span><span><span>  </span><span>mbedtls_ecp_copy</span><span>(</span><span>publicKey1</span><span>,</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>(</span><span>_DAT_3ffb3948 </span><span>+</span><span> </span><span>0x88</span><span>)</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Load another public key?</span><span>
</span></span><span><span>  char publicKey2 </span><span>[</span><span>36</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_ecp_copy</span><span>(</span><span>publicKey2</span><span>,</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>(</span><span>_DAT_3ffb38cc </span><span>+</span><span> </span><span>0x88</span><span>)</span><span>)</span><span>;</span><span>
</span></span><span>  
</span><span><span>  </span><span>// Compute shared secret key using privateKey1 and publicKey 2</span><span>
</span></span><span><span>  char computedSharedSecret </span><span>[</span><span>100</span><span>]</span><span>;</span><span>
</span></span><span><span>  uchar binarySharedSecret </span><span>[</span><span>35</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_ecdh_compute_shared</span><span>(</span><span>
</span></span><span><span>    ecpGroup</span><span>,</span><span>
</span></span><span><span>    computedSharedSecret</span><span>,</span><span>
</span></span><span><span>    publicKey2</span><span>,</span><span>
</span></span><span><span>    privateKey1</span><span>,</span><span>
</span></span><span><span>    </span><span>(</span><span>char </span><span>*</span><span>)</span><span>mbedtls_ctr_drbg_random</span><span>,</span><span>
</span></span><span>    drbgContext
</span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_mpi_write_binary</span><span>(</span><span>computedSharedSecret</span><span>,</span><span> binarySharedSecret</span><span>,</span><span> </span><span>0x20</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Generate random bytes</span><span>
</span></span><span><span>  </span><span>mbedtls_ctr_drbg_random</span><span>(</span><span>globalDrbgContext</span><span>,</span><span> outputRandomBytes</span><span>,</span><span> </span><span>0x20</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Derive key</span><span>
</span></span><span><span>  mbedtls_md_info_t </span><span>*</span><span>md </span><span>=</span><span> </span><span>mbedtls_md_info_from_type</span><span>(</span><span>MBEDTLS_MD_SHA256</span><span>)</span><span>;</span><span>
</span></span><span><span>  uchar</span><span>*</span><span> deviceSerialNumber </span><span>=</span><span> </span><span>(</span><span>uchar </span><span>*</span><span>)</span><span>GetDeviceSerialNumber</span><span>(</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_hkdf</span><span>(</span><span>
</span></span><span><span>    md</span><span>,</span><span> 
</span></span><span><span>    binarySharedSecret</span><span>,</span><span> </span><span>// salt</span><span>
</span></span><span><span>    </span><span>0x20</span><span>,</span><span>
</span></span><span><span>    outputRandomBytes</span><span>,</span><span> </span><span>// input</span><span>
</span></span><span><span>    </span><span>0x20</span><span>,</span><span>
</span></span><span><span>    deviceSerialNumber</span><span>,</span><span> </span><span>// info</span><span>
</span></span><span><span>    </span><span>9</span><span>,</span><span>
</span></span><span><span>    outputKey</span><span>,</span><span>
</span></span><span><span>    </span><span>0x10</span><span>
</span></span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>Being able to interpret assembly or even the decompiled code in Ghidra is certainly an acquired skill; I'd like to emphasize this took a while to figure out, with many breaks in between!</p><p>This function does something unusual; here's what we can learn from it:</p><ul><li><p>The generated ECDH key pair is discarded and replaced by keys loaded from somewhere else in memory, which is strange. Because the ECDH key pair generation function isn't used elsewhere in the application, it's likely these keys are the files from the firmware storage we saw earlier.</p></li><li><p>The algorithm used for the HKDF is <code>SHA-256</code>.</p></li><li><p>The computed shared secret is used as the HKDF <code>salt</code>.</p></li><li><p>Random bytes are generated as the HKDF <code>input</code>. </p></li><li><p>The device serial number is used as the HKDF <code>info</code>. </p></li><li><p>The HKDF output key size is <code>0x10</code> (16 bytes / 128 bits).</p></li></ul></div><p>We now have a much better understanding of how the smart device generates the potential encryption key. </p><p>It's useful to keep in mind that their cloud server also has to generate this key, meaning it needs to have all the same input variables to the HKDF. </p><p>Knowing this, we can recap the three dynamic inputs to the HKDF function and understand how the server will also have them:</p><ul><li><p><code>salt</code> - Shared secret:  The server must have access to the same private and public keys used for the ECDH shared secret computation or use the public to our private and the private to our public.</p></li><li><p><code>input</code> - Random bytes: The server must have access to these randomly generated bytes on the smart device; either we send these bytes to the server, or technically, the server could recreate the pseudo RNG method used. However, the generated bytes have the size of <code>0x20</code> (32 bytes / 256 bits) which exactly matches the size of the data sent in the key exchange packet, so it's highly likely we're sending it there!</p></li><li><p><code>info</code> - <strong>Device serial number:</strong> We already know the device serial number is part of the packet header, so the server easily has access to this value. </p></li></ul><p>Curious to know what the application did with these randomly generated bytes, I checked what the calling function did with them:</p><div><div><pre><code><span><span>stack</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>0x00</span><span>;</span><span>
</span></span><span><span>stack</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>0x01</span><span>;</span><span>
</span></span><span><span></span><span>GenerateNetworkKey</span><span>(</span><span>&amp;</span><span>KeyOutput</span><span>,</span><span> stack</span><span>[</span><span>2</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>log</span><span>(</span><span>2</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>"Write ECC conn packet\r\n"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>SendPacket</span><span>(</span><span>(</span><span>int</span><span>)</span><span>param_1</span><span>,</span><span> </span><span>2</span><span>,</span><span> stack</span><span>[</span><span>0</span><span>]</span><span>,</span><span> </span><span>0x22</span><span>)</span><span>;</span></span></code></pre></div><p>We can see the random bytes from <code>GenerateNetworkKey</code> are written out to the stack, and better yet, the <code>00 01</code> bytes are written to the stack just before it, and then all <code>0x22</code> bytes are sent in the packet. That exactly matches the format we saw in the key exchange packet!  </p></div><h2><a href="#logging-key-data" title="Logging Key Data"><span>Logging Key Data</span></a></h2><p>Much progress has been made via static analysis, and the final value we need to calculate the decryption key is the shared secret.</p><p>At this point of reverse engineering, I hadn't reversed the functions as cleanly as shown in this blog post and wanted to try to dynamically obtain keys directly from the device.</p><p>Debugging via JTAG would be the sensible choice here. However, I didn't notice breakout points for these pins on the PCB, and I wanted to avoid soldering directly to the ESP32 pins, so I thought I'd challenge myself to patch the firmware to print it over serial!</p><p>The CapSense service is still disabled, so I thought I'd write a function over that logic to print out the shared secret key and call it right after it was computed!</p><p>So, planning in pseudocode, I'd want to add my function call to the <code>GenerateNetworkKey</code> function. Right after it has generated the key.:</p><div><pre><code><span><span>int</span><span> </span><span>GenerateNetworkKey</span><span>(</span><span>uchar </span><span>*</span><span>outputKey</span><span>,</span><span> uchar </span><span>*</span><span>outputRandomBytes</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>// ... </span><span>
</span></span><span>  
</span><span><span>  </span><span>// Add my function call:</span><span>
</span></span><span><span>  </span><span>print_key</span><span>(</span><span>binarySharedSecret</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Custom function saved over unused logic:</span><span>
</span></span><span><span></span><span>void</span><span> </span><span>print_key</span><span>(</span><span>char </span><span>*</span><span>key</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>for</span><span> </span><span>(</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> </span><span>32</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>log</span><span>(</span><span>"%2.2x"</span><span>,</span><span> key</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>While referring to the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/eerimoq/hardware-reference/blob/master/esp32/xtensa%20Instruction%20Set%20Architecture%20(ISA)%20Reference%20Manual.pdf"><span>Xtensa instruction set architecture manual</span></a>, I threw together some assembly like this:</p><div><div><pre><code><span><span>// Original</span><span>
</span></span><span><span></span><span>400dbf2d  </span><span>25 4b 6c</span><span>    call8</span><span>     GetDeviceSerialNumber</span><span>
</span></span><span>
</span><span><span></span><span>// Patched</span><span>
</span></span><span><span></span><span>400dbf2d  </span><span>e5 ff fd</span><span>    call8</span><span>     print_key</span><span>
</span></span><span>
</span><span><span></span><span>// print_key:</span><span>
</span></span><span><span></span><span>400d9f2c  </span><span>36 41 00</span><span>    entry</span><span>     </span><span>a1</span><span>,</span><span> 0x20</span><span>
</span></span><span><span></span><span>400d9f3b  </span><span>42 c2 20</span><span>    addi</span><span>      </span><span>a4</span><span>,</span><span> </span><span>a2</span><span>,</span><span> 0x20</span><span>
</span></span><span><span></span><span>400d9f3e  </span><span>52 a0 02</span><span>    movi</span><span>      </span><span>a5</span><span>,</span><span> 0x2</span><span>
</span></span><span><span></span><span>400d9f41  </span><span>61 ea db</span><span>    l32r</span><span>      </span><span>a6</span><span>,</span><span> PTR_s_%2.2x </span><span>// "%2.2x"</span><span>
</span></span><span><span></span><span>400d9f44  </span><span>d2 02 00</span><span>    l8ui</span><span>      </span><span>a13</span><span>,</span><span> </span><span>a2</span><span>,</span><span> 0x0</span><span>
</span></span><span><span></span><span>400d9f47  </span><span>60 c6 20</span><span>    mov</span><span>       </span><span>a12</span><span>,</span><span> </span><span>a6</span><span>
</span></span><span><span></span><span>400d9f4a  </span><span>50 b5 20</span><span>    mov</span><span>       </span><span>a11</span><span>,</span><span> </span><span>a5</span><span>
</span></span><span><span></span><span>400d9f4d  </span><span>50 a5 20</span><span>    mov</span><span>       </span><span>a10</span><span>,</span><span> </span><span>a5</span><span>
</span></span><span><span></span><span>400d9f50  </span><span>22 c2 01</span><span>    addi</span><span>      </span><span>a2</span><span>,</span><span> </span><span>a2</span><span>,</span><span> 0x1</span><span>
</span></span><span><span></span><span>400d9f53  </span><span>25 ed 05</span><span>    call8</span><span>     log</span><span>
</span></span><span><span></span><span>400d9f56  </span><span>27 94 ea</span><span>    bne</span><span>       </span><span>a4</span><span>,</span><span> </span><span>a2</span><span>,</span><span> LAB_400d9f44</span><span>
</span></span><span><span></span><span>400d9f59  </span><span>22 a0 00</span><span>    movi</span><span>      </span><span>a2</span><span>,</span><span> 0x0</span><span>
</span></span><span><span></span><span>400d9f5c  </span><span>90 00 00</span><span>    retw</span><span>
</span></span><span></span></code></pre></div><p>We patch over the <code>GetDeviceSerialNumber</code> function call because this is directly after the generation of the shared secret key, and the pointer to the key is still in the register <code>a2</code>.</p></div><p>I flashed the modified firmware, booted up the device, and checked the serial output:</p><div><pre><code><span><span>Write ECC conn packet
</span></span><span>e883eaed93c63d2c09cddebce6bb15a7f4cb5cedf00c1d882b8b292796254c9c</span></code></pre></div><p>Success! We've printed out the shared secret key! </p><p>I rebooted the device numerous times to see if the key changed, and it remained the same. It is most likely computed using the keys in the firmware storage, but now we have the computed static value, we don't need to reverse the computation process.</p><h2><a href="#packet-decryption" title="Packet Decryption"><span>Packet Decryption</span></a></h2><p>Alright, we now understand the method to derive the decryption key and have all input values; it looks something like this: </p><div><pre><code><span><span>const</span><span> hkdfOutputKey </span><span>=</span><span> </span><span>hkdf</span><span>(</span><span>{</span><span>
</span></span><span><span>  </span><span>method</span><span>:</span><span> </span><span>'SHA-256'</span><span>,</span><span>
</span></span><span><span>  </span><span>salt</span><span>:</span><span> Buffer</span><span>.</span><span>from</span><span>(</span><span>
</span></span><span><span>    </span><span>'e883eaed93c63d2c09cddebce6bb15a7f4cb5cedf00c1d882b8b292796254c9c'</span><span>,</span><span> </span><span>'hex'</span><span>
</span></span><span><span>  </span><span>)</span><span>,</span><span>
</span></span><span><span>  </span><span>input</span><span>:</span><span> randomBytesFromDeviceKeyExchangePacket</span><span>,</span><span>
</span></span><span><span>  </span><span>info</span><span>:</span><span> deviceSerialNumber</span><span>,</span><span>
</span></span><span><span>  </span><span>outputKeySize</span><span>:</span><span> </span><span>0x10</span><span>,</span><span>
</span></span><span><span></span><span>}</span><span>)</span><span>;</span></span></code></pre></div><p>To be on the safe side, I wrote another firmware patch to print the key output from the HKDF call and tried recreating the key from captured packets. It works! That confirms we have correctly reverse-engineered the key creation function and are able to replicate the key creation logic in our own application.</p><p>But now we need to find which encryption algorithm is used. I refer back to the function which formats packets and found the call to the encryption function:</p><div><div><pre><code><span><span>char randomBytes </span><span>[</span><span>16</span><span>]</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Write device serial</span><span>
</span></span><span><span></span><span>memcpy</span><span>(</span><span>0x3ffb3ce0</span><span>,</span><span> deviceSerialNumber</span><span>,</span><span> </span><span>9</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Generate and write random bytes</span><span>
</span></span><span><span></span><span>mbedtls_ctr_drbg_random</span><span>(</span><span>globalDrbgContext</span><span>,</span><span> randomBytes</span><span>,</span><span> </span><span>0x10</span><span>)</span><span>
</span></span><span><span></span><span>memcpy</span><span>(</span><span>0x3ffb3ce9</span><span>,</span><span> randomBytes</span><span>,</span><span> </span><span>0x10</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Write packet data</span><span>
</span></span><span><span></span><span>memcpy</span><span>(</span><span>0x3ffb3cf9</span><span>,</span><span> data</span><span>,</span><span> dataSize</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Pad with random bytes</span><span>
</span></span><span><span></span><span>mbedtls_ctr_drbg_random</span><span>(</span><span>globalDrbgContext dataSize </span><span>+</span><span> </span><span>0x3ffb3cf9</span><span>,</span><span> paddingSize</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Run encryption on the data + padding</span><span>
</span></span><span><span></span><span>FUN_400e2368</span><span>(</span><span>0x3ffb3cf9</span><span>,</span><span> dataSize </span><span>+</span><span> paddingSize</span><span>,</span><span> </span><span>&amp;</span><span>HKDFOutputKey</span><span>,</span><span> randomBytes</span><span>)</span><span>;</span></span></code></pre></div><p>I noticed that after the device serial number is copied to the packet, 16 random bytes are generated and copied directly after it. These bytes are also provided to the encryption function. So, we know they are an input variable to the encryption algorithm.</p></div><p>We know the key is 128 bits, with another 128 bits of additional random data.</p><p>I looked into the encryption function, which is very clearly crypto-related due to the looping of a bunch of bitwise operations, and noticed a reference to a static block of data.</p><p>This data started with <code>63 7C 77 7B F2 6B 6F C5</code>, a search in the mbedtls source code revealed it is the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/Mbed-TLS/mbedtls/blob/47c74a477378ec3f0d1ba80547db836e078fa3a0/library/aes.c#L78"><span>AES Forward S-Box</span></a>!</p><p>I decided to jump straight into attempting AES decryption on the captured packets and <strong>successfully decrypted a packet!! ðŸŽ‰</strong></p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  00 00 65 00 53 00 82 A4  74 79 70 65 AF 6D 69 72</span><span>  ..e.S...type.mir
</span></span><span><span></span><span>00000010</span><span>  72 6F 72 5F 64 61 74 61  5F 67 65 74 A4 64 61 74</span><span>  ror_data_get.dat
</span></span><span><span></span><span>00000020</span><span>  61 85 A9 74 69 6D 65 73  74 61 6D 70 CF 00 00 01</span><span>  a..timestamp....
</span></span><span><span></span><span>00000030</span><span>  8D 18 05 31 FB A9 46 41  4E 5F 53 50 45 45 44 00</span><span>  ...1..FAN_SPEED.
</span></span><span><span></span><span>00000040</span><span>  A5 42 4F 4F 53 54 C2 A7  46 49 4C 54 45 52 31 00</span><span>  .BOOST..FILTER1.
</span></span><span><span></span><span>00000050</span><span>  A7 46 49 4C 54 45 52 32  00 07 07 07 07 07 07 07</span><span>  .FILTER2........</span></span></code></pre></div><p>The algorithm was <code>AES-128-CBC</code> and the additional random data was used as the <code>IV</code> (Initialization vector).</p><h2><a href="#mitm-attack" title="MITM Attack"><span>MITM Attack</span></a></h2><p>We can now create an MITM (man in the middle) attack that does not require any firmware patching. This is because the private key of the device is now known, the key derivation logic has been reverse-engineered, and any required dynamic data is exposed over the insecure network.</p><p>If it correctly implemented ECDH, the smart device would have a unique private key that isn't exposed, and our easiest route of attack would be to generate our own server key pair and do any firmware modifications so the device accepts our custom public key.</p><p>But because of their custom protocol's design, we can write an MITM script that can intercept, decrypt, and potentially modify network communications without any modifications to the smart device. So, that's what we're going to do!</p><p>The main aim now is to decrypt and log as much data as possible; then, we can reference that to write a local server endpoint that entirely replaces their cloud server.</p><p>I hack together a quick Node.js script to do this:</p><div><div><pre><code><span><span>const</span><span> dns </span><span>=</span><span> </span><span>require</span><span>(</span><span>"dns"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> udp </span><span>=</span><span> </span><span>require</span><span>(</span><span>"dgram"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> crypto </span><span>=</span><span> </span><span>require</span><span>(</span><span>"crypto"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> hkdf </span><span>=</span><span> </span><span>require</span><span>(</span><span>"futoin-hkdf"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> fs </span><span>=</span><span> </span><span>require</span><span>(</span><span>"fs"</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Key Gen</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> sharedSecretKey </span><span>=</span><span> Buffer</span><span>.</span><span>from</span><span>(</span><span>
</span></span><span><span>  </span><span>"e883eaed93c63d2c09cddebce6bb15a7f4cb5cedf00c1d882b8b292796254c9c"</span><span>,</span><span>
</span></span><span><span>  </span><span>"hex"</span><span>
</span></span><span><span></span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>calculateAesKey</span><span>(</span><span>deviceSerialNumber</span><span>,</span><span> inputData</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>return</span><span> </span><span>hkdf</span><span>(</span><span>inputData</span><span>,</span><span> </span><span>16</span><span>,</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>salt</span><span>:</span><span> sharedSecretKey</span><span>,</span><span>
</span></span><span><span>    </span><span>info</span><span>:</span><span> deviceSerialNumber</span><span>,</span><span>
</span></span><span><span>    </span><span>hash</span><span>:</span><span> </span><span>"SHA-256"</span><span>,</span><span>
</span></span><span><span>  </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Packet Parsing</span><span>
</span></span><span>
</span><span><span></span><span>let</span><span> latestAesKey </span><span>=</span><span> </span><span>null</span><span>;</span><span>
</span></span><span><span></span><span>let</span><span> packetCounter </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> proxyLogDir </span><span>=</span><span> path</span><span>.</span><span>join</span><span>(</span><span>__dirname</span><span>,</span><span> </span><span>"decrypted-packets"</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>decryptPacket</span><span>(</span><span>data</span><span>,</span><span> deviceSerial</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>const</span><span> </span><span>IV</span><span> </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>0xd</span><span>,</span><span> </span><span>0x1d</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>const</span><span> encryptedBuffer </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>0x1d</span><span>,</span><span> data</span><span>.</span><span>length </span><span>-</span><span> </span><span>2</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>const</span><span> decipher </span><span>=</span><span> crypto</span><span>.</span><span>createDecipheriv</span><span>(</span><span>
</span></span><span><span>    </span><span>"aes-128-cbc"</span><span>,</span><span>
</span></span><span><span>    latestAesKey</span><span>,</span><span>
</span></span><span><span>    parsed</span><span>.</span><span>IV</span><span>
</span></span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span><span>  decipher</span><span>.</span><span>setAutoPadding</span><span>(</span><span>false</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>return</span><span> Buffer</span><span>.</span><span>concat</span><span>(</span><span>[</span><span>decipher</span><span>.</span><span>update</span><span>(</span><span>encryptedBuffer</span><span>)</span><span>,</span><span> decipher</span><span>.</span><span>final</span><span>(</span><span>)</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>logPacket</span><span>(</span><span>data</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>const</span><span> messageId </span><span>=</span><span> data</span><span>.</span><span>readUInt8</span><span>(</span><span>3</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>const</span><span> deviceSerial </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>4</span><span>,</span><span> </span><span>4</span><span> </span><span>+</span><span> </span><span>9</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>if</span><span> </span><span>(</span><span>messageId </span><span>===</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>// Key Exchange</span><span>
</span></span><span><span>    </span><span>const</span><span> randomlyGeneratedBytes </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>0xf</span><span>,</span><span> data</span><span>.</span><span>length </span><span>-</span><span> </span><span>2</span><span>)</span><span>;</span><span>
</span></span><span><span>    latestAesKey </span><span>=</span><span> </span><span>calculateAesKey</span><span>(</span><span>deviceSerial</span><span>,</span><span> randomlyGeneratedBytes</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>// Encrypted Packets</span><span>
</span></span><span><span>    fs</span><span>.</span><span>writeFileSync</span><span>(</span><span>
</span></span><span><span>      path</span><span>.</span><span>join</span><span>(</span><span>proxyLogDir</span><span>,</span><span> </span><span>`</span><span>packet-</span><span>${</span><span>id</span><span>}</span><span>.bin</span><span>`</span><span>)</span><span>,</span><span>
</span></span><span><span>      </span><span>decryptPacket</span><span>(</span><span>data</span><span>)</span><span>
</span></span><span><span>    </span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Networking</span><span>
</span></span><span>
</span><span><span>dns</span><span>.</span><span>setServers</span><span>(</span><span>[</span><span>"1.1.1.1"</span><span>,</span><span> </span><span>"[2606:4700:4700::1111]"</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> </span><span>PORT</span><span> </span><span>=</span><span> </span><span>41014</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> cloudIp </span><span>=</span><span> dns</span><span>.</span><span>resolve4</span><span>(</span><span>"smartdeviceep.---.com"</span><span>)</span><span>[</span><span>0</span><span>]</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> cloud </span><span>=</span><span> udp</span><span>.</span><span>createSocket</span><span>(</span><span>"udp4"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>let</span><span> latestClientIp </span><span>=</span><span> </span><span>null</span><span>;</span><span>
</span></span><span><span></span><span>let</span><span> latestClientPort </span><span>=</span><span> </span><span>null</span><span>;</span><span>
</span></span><span>
</span><span><span>cloud</span><span>.</span><span>on</span><span>(</span><span>"message"</span><span>,</span><span> </span><span>function</span><span> </span><span>(</span><span>data</span><span>,</span><span> info</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>logPacket</span><span>(</span><span>data</span><span>)</span><span>;</span><span>
</span></span><span><span>  local</span><span>.</span><span>send</span><span>(</span><span>data</span><span>,</span><span> latestClientIp</span><span>,</span><span> latestClientPort</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> local </span><span>=</span><span> udp</span><span>.</span><span>createSocket</span><span>(</span><span>"udp4"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>local</span><span>.</span><span>bind</span><span>(</span><span>PORT</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>local</span><span>.</span><span>on</span><span>(</span><span>"message"</span><span>,</span><span> </span><span>function</span><span> </span><span>(</span><span>data</span><span>,</span><span> info</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>logPacket</span><span>(</span><span>data</span><span>)</span><span>;</span><span>
</span></span><span><span>  latestClientIp </span><span>=</span><span> info</span><span>.</span><span>address</span><span>;</span><span>
</span></span><span><span>  latestClientPort </span><span>=</span><span> info</span><span>.</span><span>port</span><span>;</span><span>
</span></span><span><span>  cloud</span><span>.</span><span>send</span><span>(</span><span>data</span><span>,</span><span> </span><span>PORT</span><span>,</span><span> cloudIp</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>)</span><span>;</span><span>
</span></span><span></span></code></pre></div><p>Here, we combine all of our research to implement an MITM attack.</p><p>Just like when we first captured packets, we configure Node.js to use Cloudflare's DNS resolver to bypass our local DNS server.</p><p>We create a UDP socket locally to accept packets from the smart device and also a socket to communicate with the cloud server.</p><ul><li><p>Anything we receive from the smart device, we log and send to the cloud server</p></li><li><p>Anything we receive from the cloud server, we log and send to the smart device</p></li></ul><p>We treat packets with the <code>messageId</code> of 2 to be the key exchange packet where the smart device send the random bytes to the server, we then calculate the AES key used to decrypt future packets.</p></div><p>While capturing, I used their mobile app to remotely control the smart device so we could reference the logs and replicate the logic ourselves.</p><h2><a href="#data-exchange-format" title="Data Exchange Format"><span>Data Exchange Format</span></a></h2><p>We now have the decrypted packet data, but the data is still in a serialized binary format:</p><div><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  01 00 64 00 29 00 82 A4  74 79 70 65 A7 63 6F 6E</span><span>  ..d.)...type.con
</span></span><span><span></span><span>00000010</span><span>  6E 65 63 74 A8 66 69 72  6D 77 61 72 65 C4 10 00</span><span>  nect.firmware...
</span></span><span><span></span><span>00000020</span><span>  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 83</span><span>  ................</span></span></code></pre></div><p>My mind was deep in the world of reverse engineering, and I managed to reverse the structure for all packets and hack together some JavaScript to convert the data to and from JSON.</p><p>The header was quite simple, again just some IDs and length, but in little endianness:</p><ul><li><p><code>01 00</code> - packet ID</p></li><li><p><code>64 00</code> - transaction ID</p></li><li><p><code>29 00</code> - serialized data length</p></li></ul><p>And with some tinkering, I figured out the serialized format:</p><ul><li><p><code>82</code> - Map</p></li><li><p><code>A4</code> - String of 4 length</p></li><li><p><code>A7</code> - String of 7 length</p></li></ul><p>This was fun to reverse because the typing was more described in bits, but it's clearly readable from the bytes for these simple cases.</p></div><p>Looking back on this, I'm not sure why I didn't look for an existing solution that matches this serialized binary data format; I was expecting everything to be a custom solution at this point. But having a search now, this is just <a target="_blank" rel="noopener noreferrer nofollow" href="https://msgpack.org/"><span>MessagePack</span></a>, so I guess I just reverse-engineered and wrote a partial msgpack implementation ðŸ˜†</p><p>Switching over to a popular implementation, we can see the data is easily unpacked into JSON:</p><div><pre><code><span><span>const</span><span> </span><span>{</span><span> unpack</span><span>,</span><span> pack </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'msgpackr'</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> packedData </span><span>=</span><span> Buffer</span><span>.</span><span>from</span><span>(</span><span>
</span></span><span><span>  </span><span>'82A474797065A7636F6E6E656374A86669726D77617265C41000000000000000000000000000000000'</span><span>,</span><span> 
</span></span><span><span>  </span><span>'hex'</span><span>
</span></span><span><span></span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> unpackedData </span><span>=</span><span> </span><span>unpack</span><span>(</span><span>packedData</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// unpackedData:</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'connect'</span><span>,</span><span>
</span></span><span><span>  </span><span>firmware</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><h2><a href="#network-log-analysis" title="Network Log Analysis"><span>Network Log Analysis</span></a></h2><p>In preparation for writing a custom local server for the smart device, let's take a look at the unpacked network logs we've captured:</p><p><strong>ðŸ”‘ Key Exchange Packet:</strong></p><p>The smart device sends random bytes to the server to be used in the HKDF.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>D1C2B34170177512F7692517504AC5DDD49806FE246B96FD56144A707E515557</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>00000000000000000000000000000000</span></span></code></pre></div><p>â†™ï¸ <strong>Get Device State:</strong></p><p>The smart device fetches its initial state from the server when it boots.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>'mirror_data_get'</span><span> </span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'mirror_data_get'</span><span>,</span><span>
</span></span><span><span>  </span><span>data</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>timestamp</span><span>:</span><span> </span><span>1705505010171n</span><span>,</span><span>
</span></span><span><span>    </span><span>FAN_SPEED</span><span>:</span><span> </span><span>0</span><span>,</span><span>
</span></span><span><span>    </span><span>BOOST</span><span>:</span><span> </span><span>false</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER1</span><span>:</span><span> </span><span>0</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER2</span><span>:</span><span> </span><span>0</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>ðŸ”— <strong>On Connect:</strong></p><p>When the smart device connects to the server, it sends its current firmware UUID. The server responds with the potential UUID for a firmware or config update that could be downloaded.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'connect'</span><span>,</span><span>
</span></span><span><span>  </span><span>firmware</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'connect'</span><span>,</span><span>
</span></span><span><span>  </span><span>server_time</span><span>:</span><span> </span><span>1706098993961n</span><span>,</span><span>
</span></span><span><span>  </span><span>firmware</span><span>:</span><span> </span><span>&lt;</span><span>Buffer ab cd ef ab cd ef ab cd ef ab cd ef ab cd ef ab</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>config</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>calibration</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>conditioning</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>server_address</span><span>:</span><span> </span><span>'smartdeviceep.---.com'</span><span>,</span><span>
</span></span><span><span>  </span><span>server_port</span><span>:</span><span> </span><span>41014</span><span>,</span><span>
</span></span><span><span>  </span><span>rtc_sync</span><span>:</span><span> </span><span>{</span><span> </span><span>ss</span><span>:</span><span> </span><span>13</span><span>,</span><span> </span><span>mm</span><span>:</span><span> </span><span>23</span><span>,</span><span> </span><span>hh</span><span>:</span><span> </span><span>12</span><span>,</span><span> </span><span>DD</span><span>:</span><span> </span><span>24</span><span>,</span><span> </span><span>MM</span><span>:</span><span> </span><span>1</span><span>,</span><span> </span><span>YYYY</span><span>:</span><span> </span><span>2024</span><span>,</span><span> </span><span>D</span><span>:</span><span> </span><span>3</span><span> </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>â¤µï¸ <strong>Server Updates Smart Device State:</strong></p><p>When the server wants to update the smart device's state, it will send a packet like this.</p><div><pre><code><span><span>// Server Request</span><span>
</span></span><span><span></span><span>{</span><span> 
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'mirror_data'</span><span>,</span><span>
</span></span><span><span>  </span><span>data</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>FAN_SPEED</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>BOOST</span><span>:</span><span> </span><span>false</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>â¤´ï¸ <strong>Smart Device Updates Server State:</strong></p><p>The smart device sends its latest state to the server whenever it changes.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'mirror_data'</span><span>,</span><span>
</span></span><span><span>  </span><span>data</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>timestamp</span><span>:</span><span> </span><span>1706105072142n</span><span>,</span><span>
</span></span><span><span>    </span><span>FAN_SPEED</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>BOOST</span><span>:</span><span> </span><span>false</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER1</span><span>:</span><span> </span><span>0</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER2</span><span>:</span><span> </span><span>0</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>'mirror_data'</span><span> </span><span>}</span></span></code></pre></div><p>ðŸ›œ <strong>Keep Alive:</strong></p><p>The smart device frequently sends a keep-alive packet to the server so the server can potentially use the open connection to send state updates.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'keep_alive'</span><span>,</span><span>
</span></span><span><span>  </span><span>stats</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>rssi</span><span>:</span><span> </span><span>-</span><span>127n</span><span>,</span><span>
</span></span><span><span>    </span><span>rtt</span><span>:</span><span> </span><span>684</span><span>,</span><span>
</span></span><span><span>    </span><span>pkt_drop</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>con_count</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>boot_str</span><span>:</span><span> </span><span>''</span><span>,</span><span>
</span></span><span><span>    </span><span>uptime</span><span>:</span><span> </span><span>100080</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>'keep_alive'</span><span> </span><span>}</span></span></code></pre></div><h2><a href="#mqtt-bridge" title="MQTT Bridge"><span>MQTT Bridge</span></a></h2><p>We're going to need a way to connect Home Assistant to our custom server, which handles the smart device networking. <a target="_blank" rel="noopener noreferrer nofollow" href="https://mqtt.org/"><span>MQTT</span></a> is ideal for this; it's a protocol designed for IoT messaging and can be easily configured within Home Assistant. For this, I set up the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/eclipse/mosquitto"><span>Mosquitto</span></a> addon for Home Assistant, an open-source MQTT broker that connects everything together.</p><p>The connection chain will look like this:</p><p><code>Home Assistant</code> &lt;--&gt; <code>MQTT Broker</code> &lt;--&gt; <code>Custom Server</code> &lt;--&gt; <code>Smart Device</code>.</p><p>The custom server logic in pseudocode would look something like this:</p><div><div><pre><code><span><span>function</span><span> </span><span>HandleSmartDeviceRequest</span><span>(</span><span>req</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>switch</span><span> </span><span>(</span><span>req</span><span>.</span><span>type</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>case</span><span> </span><span>'mirror_data_get'</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>      </span><span>// Device wants state, send latest MQTT state or default fallback</span><span>
</span></span><span><span>      device</span><span>.</span><span>send</span><span>(</span><span>{</span><span> </span><span>fan_speed</span><span>:</span><span> mqtt</span><span>.</span><span>get</span><span>(</span><span>'fan_speed'</span><span>)</span><span> </span><span>||</span><span> </span><span>0</span><span> </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span>      </span><span>return</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>    </span><span>case</span><span> </span><span>'mirror_data'</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>      </span><span>// Device state has changed, publish and retain in MQTT broker</span><span>
</span></span><span><span>      mqtt</span><span>.</span><span>publish</span><span>(</span><span>'fan_speed'</span><span>,</span><span> req</span><span>.</span><span>fan_speed</span><span>,</span><span> </span><span>{</span><span> </span><span>retain</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span>      </span><span>return</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>HandleMQTTMessage</span><span>(</span><span>topic</span><span>,</span><span> msg</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>switch</span><span> </span><span>(</span><span>topic</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>case</span><span> </span><span>'set_fan_speed'</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>      </span><span>// MQTT wants to change state, forward to device</span><span>
</span></span><span><span>      device</span><span>.</span><span>send</span><span>(</span><span>{</span><span> </span><span>fan_speed</span><span>:</span><span> msg</span><span>.</span><span>fan_speed </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span>      </span><span>return</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>This logic seems quite minimal but is carefully designed. The latest state is retained in the MQTT broker. However, the source of truth for state updates is always the device, meaning the state will never update in the MQTT broker unless the device updates it via the custom server. This covers a couple of edge cases:</p><ul><li><p>If the state update was unsuccessful, we should not display the state as updated.</p></li><li><p>The state update should be reflected via the MQTT broker if the smart device was updated via its physical control panel.</p></li></ul></div><p>The three main cases we are supporting here are:</p><ul><li><p>When the smart device boots and initially connects to the custom server, it requests the latest state; we can attempt to obtain this from the MQTT broker's retained value or fall back to a default state.</p></li><li><p>When Home Assistant wants to update the state, it will send a command to the MQTT broker. We can subscribe to this command topic from the custom server and forward the request to the smart device.</p></li><li><p>When the smart device's state changes for any reason, it sends the <code>mirror_data</code> packet to update the server state; we send this value to the MQTT broker to update the state and tell it to retain the data as the latest value.</p></li></ul><p>I run this custom server alongside Mosquitto and Home Assistant on my small home automation server. Then configured my Pi-hole local DNS to resolve the cloud server's domain to my custom server.</p><h2><a href="#home-assistant-integration" title="Home Assistant Integration"><span>Home Assistant Integration</span></a></h2><p>The final step in this process is configuring Home Assistant to map the MQTT topics to a device type. For my air purifier, the closest integration was an <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.home-assistant.io/integrations/fan.mqtt/"><span>MQTT Fan</span></a>; in my <code>configuration.yaml</code> I added something like this:</p><div><div><pre><code><span><span>mqtt</span><span>:</span><span>
</span></span><span><span>  </span><span>fan</span><span>:</span><span>
</span></span><span><span>    </span><span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>"Air Purifier"</span><span>
</span></span><span><span>      </span><span>unique_id</span><span>:</span><span> </span><span>"air_purifier.main"</span><span>
</span></span><span><span>      </span><span>state_topic</span><span>:</span><span> </span><span>"air_purifier/on/state"</span><span>
</span></span><span><span>      </span><span>command_topic</span><span>:</span><span> </span><span>"air_purifier/on/set"</span><span>
</span></span><span><span>      </span><span>payload_on</span><span>:</span><span> </span><span>"true"</span><span>
</span></span><span><span>      </span><span>payload_off</span><span>:</span><span> </span><span>"false"</span><span>
</span></span><span><span>      </span><span>percentage_state_topic</span><span>:</span><span> </span><span>"air_purifier/speed/state"</span><span>
</span></span><span><span>      </span><span>percentage_command_topic</span><span>:</span><span> </span><span>"air_purifier/speed/set"</span><span>
</span></span><span><span>      </span><span>speed_range_min</span><span>:</span><span> </span><span>1</span><span>
</span></span><span><span>      </span><span>speed_range_max</span><span>:</span><span> </span><span>4</span></span></code></pre></div><p>I added topics to control the fan speed and turn the device on and off.</p></div><p><strong>Everything works!</strong> I've been running this for a couple of weeks now, and it has worked fine without any issues! I've even set up a little automation, so if my separate air monitor's PM2.5 or VOC level gets too high, it boosts the air purifier for a while!</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="580" height="700" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 400px" srcset="https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><h2><a href="#technical-recap" title="Technical Recap"><span>Technical Recap</span></a></h2><p>For better or worse, the engineers behind the service decided not to implement a standard protocol like DTLS. They created a custom solution which introduced some downsides to the system:</p><ul><li><div><p>We're not certain if each device has its own unique private key, but whether it does or not, both have downsides:</p><ul><li><p>If all devices share the same firmware private key, the attacker needs to reverse engineer just a single device to MITM attack any other devices.</p></li><li><p>However, if every device has its own unique private key, the server must keep a data store mapping device serial numbers to the key of each device. So, In the case of any data loss, the server would entirely lose the ability to respond to any device communications; that is a scary thought for the business. Unless there is an insecure network fallback in place, which is equally alarming and time-consuming to develop</p></li></ul></div></li><li><p>Because the firmware contains a private key that is static, an attacker needs a single firmware dump to obtain the key and perform an MITM attack. Whereas, if an EC private key was instead generated at runtime, write access would be required in order to patch the server public key or application firmware, which could be protected by other means.</p></li></ul><p>Also, the mobile app has a 1-star review on the app store. It makes me wonder if there is a correlation between the unexpectedly custom technical implementation and the abnormally poor end-user app experience. Building a custom system is far more than just the initial development; systems need support, and bugs need fixing. </p><p>Overall, it wasn't a bad implementation from a security perspective; you'd still need physical access to attack the device; there are pros and cons to everything and variables that aren't visible from our perspective.</p><p>The custom implementation increased the obscurity of network communication. However, <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Security_through_obscurity"><span>Security through obscurity</span></a> is simply a short-term win. While it may deter generic attacks on standard technical implementations. In the bigger picture, it's just an annoying yet passable hoop for an attacker to jump through. </p><p>I've had a few conversations recently about why engineers build from the ground up vs. using proven standards. And that's a very interesting topic; I'll save that for another post!</p><h2><a href="#conclusion" title="Conclusion"><span>Conclusion</span></a></h2><p>What a crazy journey that was! </p><p>I'd like to emphasize that the reverse-engineering process was not as smooth as it may seem from this post; I've done my best to format everything to be best read by you. But in reality, I was often in the dark, unsure if the next thing would work or not, and juggling many tasks and theories, iteratively making progress in multiple places to test my assumptions ASAP.</p><p>I tried some things that hit dead-ends and weren't worth dedicated sections in this post:</p><ul><li><p>I tried running the firmware in <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/espressif/qemu"><span>Espressif's fork of QEMU</span></a>, patched out the CapSense service, and loaded virtual e-fuses to match the MAC address from the firmware, all to find out it doesn't support WiFi emulation. It was fun to see it booting virtually, though!</p></li><li><p>I also tried flashing a different serial number, device key, and certificates to see if that affected anything before I got around to fully reversing the application logic. I didn't get much from this. Turns out this likely would have just affected the computed shared secret used for the HKDF salt, which we dumped anyway.</p></li></ul><p>I've certainly sharpened a variety of skills from this project. I'm also proud I achieved my goal of adding this device to Home Assistant! The moment I managed to successfully decrypt the first packet was great; everything just clicked into place.</p><p>I'm still curious to explore creating an open-source project to de-cloud and debug smart home products; I've learned much more about the technical aspects of achieving that.</p><p>Thanks for reading! I hope you found some value in this post. I put a massive amount of effort into creating it, probably more than I did actually doing the project itself. It would be amazing to receive feedback on the format!</p><p>I'd also really appreciate it if you could help share the post. </p><p>You can drop a follow on <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/jmswrnr"><span>X</span></a> to stay updated with what I'm doing.</p><p>If you found it helpful and would like to support my content creation, you can <a target="_blank" rel="noopener noreferrer" href="https://buymeacoffee.com/jmswrnr"><span>Buy Me a Coffee</span></a>! Your support helps me continue creating content and sharing my passion for reverse engineering!</p><p>Take it easy ðŸ‘‹</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Palestinian activist arrested by ICE while expecting U.S. citizenship interview (154 pts)]]></title>
            <link>https://www.cbc.ca/lite/story/1.7510325</link>
            <guid>43688069</guid>
            <pubDate>Tue, 15 Apr 2025 01:18:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/lite/story/1.7510325">https://www.cbc.ca/lite/story/1.7510325</a>, See on <a href="https://news.ycombinator.com/item?id=43688069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><div><article id="article"><p>The Associated Press | Posted: April 15, 2025 12:16 AM | Last Updated: 4 hours ago</p><p>Mohsen Mahdawi, a legal permanent resident, had led protests against the war in Gaza</p><div role="figure" data-pw="imageEmbed"><p>Image  |  Immigration Palestinian Student Detained</p><p>Caption: This image taken from a video shows Mohsen Mahdawi being detained at the U.S. Citizenship and Immigration Services office in Colchester, Vt., on Monday. The video was taken by Christopher Helali, a friend who accompanied Mahdawi to a meeting at the office.  (Christopher Helali via AP)</p></div><p>A Palestinian man who led protests against the war in Gaza as a student at Columbia University was arrested Monday at a Vermont immigration office where he expected to be interviewed about finalizing his U.S. citizenship, his attorneys said.</p><p>Mohsen Mahdawi, a legal permanent resident who has held a green card since 2015, was detained at the U.S. Citizenship and Immigration Services office in Colchester, Vt., by Immigration and Customs Enforcement agents, his lawyers said.</p><p>The attorneys said they do not know where he is and have filed a petition in federal court seeking an order barring the government from removing him from the state or country.</p><p>"The Trump administration detained Mohsen Mahdawi in direct retaliation for his advocacy on behalf of Palestinians and because of his identity as a Palestinian. His detention is an attempt to silence those who speak out against the atrocities in Gaza. It is also unconstitutional," attorney Luna Droubi said in an email.</p><p>According to the court filing, Mahdawi was born in a refugee camp in the West Bank and moved to the United States in 2014.</p><p>He recently completed coursework at Columbia in New York and was expected to graduate in May before beginning a master's degree program there in the fall.</p><p>The petition describes him as a committed Buddhist who believes in "non-violence and empathy as a central tenet of his religion."</p><h2>Arrest 'immoral, inhumane, and illegal'</h2><p>As a student, Mahdawi was an outspoken critic of Israel's military campaign in Gaza and organized campus protests until March 2024.</p><p>He co-founded the Palestinian Student Union at Columbia with Mahmoud Khalil, another Palestinian permanent resident of the U.S. and graduate student who recently was detained by ICE.</p><p>Khalil was the first person arrested under President Donald Trump's promised crackdown on students who joined campus protests against the war in Gaza.</p><p>On Friday, an immigration judge in Louisiana ruled that Khalil can be deported as a national security risk.</p><p>Christopher Helali, a friend of Mahdawi who lives near him in Vermont, was present outside the immigration office when Mahdawi was detained and recorded a video of Mahdawi being led away by authorities.</p><p>In the video, which Helali released on social media Monday, Mahdawi is shown giving a peace sign with his hands and being led away to a car.</p><p>Helali described Mahdawi as a peaceful demonstrator who has worked to foster dialogue about the struggle of Palestinians in his homeland.</p><p>Helali said he and Mahdawi were aware that Mahdawi could be detained today and that his friend went forward with the appointment anyway.</p><p>"And rightfully so, he was nervous for what was going on around him. But he was very much resolute in coming to this interview and coming today because he didn't do anything wrong and was a law-abiding citizen, or soon-to-be citizen," Helali said.</p><p>Vermont's congressional delegation issued a statement condemning Mahdawi's arrest, saying that instead of taking one of the final steps in his citizenship process, he was handcuffed by armed officers with their faces covered.</p><p>"This is immoral, inhumane and illegal. Mr. Mahdawi, a legal resident of the United States, must be afforded due process under the law and immediately released from detention," said the statement from Sen. Bernie Sanders, Sen. Peter Welch and Rep. Becca Balint.</p></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The problem with "vibe coding" (118 pts)]]></title>
            <link>https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html</link>
            <guid>43687767</guid>
            <pubDate>Tue, 15 Apr 2025 00:26:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html">https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html</a>, See on <a href="https://news.ycombinator.com/item?id=43687767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">
					<article>
						
						
						<p>The whole â€œvibe codingâ€ thing is another reminder that quite a lot of people working in tech donâ€™t understand the difference between programs and products.</p>

<p>To me, programs are â€œworks on my machineâ€ code. The kind of things many of us crank out a few times every week. Experiments, prototypesâ€¦ that script you hacked up to rename all the MP4 files in a folder? You know the one. No error checking. Hard-coded path names. Does it work on Windows? Who cares? Iâ€™m on Linux right now and I got work to do.</p>

<p>I have dozens of these kinds of programs I use every day. Theyâ€™re tools I use to automate bits of my work. They crash all the time (â€œwhat? Ohâ€¦ that person has a backslash in the title of their presentationâ€¦ interesting.â€) - but that doesnâ€™t matter; I fix them, I get the results I need, I move on. The code is just a means to an end. The result is what matters.</p>

<p>If youâ€™re writing software that youâ€™re planning to ship; to distribute to other people, perhaps even sell it to paying customers? Well, now thatâ€™s a whole different ball game.</p>

<p>Probably the single most important lesson Iâ€™ve learned in my career, the thing that I would argue is the hallmark of â€œexperienceâ€, is understanding just how much work it takes to turn a working <em>program</em> into a viable <em>product</em>. Itâ€™s why developer estimates are so notoriously optimistic - and why experienced developers are so notoriously cynical. Letâ€™s say you crank out a bit of code thatâ€™ll take responses from a web form and add them in an Excel spreadsheet. Thatâ€™s not that hardâ€¦ yay! we just built a Typeform competitor in one afternoon! Except, no, you didnâ€™t. You made one thing work one time on one computer. You havenâ€™t considered encoding, internationalization, concurrency, authentication, telemetry, billing, branding, mobile devices, deployment. You havenâ€™t hit any of the weird limits yet - ever had a system work brilliantly for the first 65,535 requests and then fall over? You donâ€™t have a product. At best, you have a proof-of-concept of a good idea that, if some very smart people work very hard, might become a viable product.</p>

<p>One of the genuinely positive things about tools like Copilot and ChatGPT is that they empower people with minimal development experience to create their own programs. Little programs that do useful things - and thatâ€™s <em>awesome</em>. More power to the users.</p>

<p>But thatâ€™s not product development, itâ€™s programming. They arenâ€™t the same thing. Not even close.</p>

					</article>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Temu pulls its U.S. Google Shopping ads (157 pts)]]></title>
            <link>https://searchengineland.com/temu-pulls-us-google-shopping-ads-454260</link>
            <guid>43687495</guid>
            <pubDate>Mon, 14 Apr 2025 23:43:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://searchengineland.com/temu-pulls-us-google-shopping-ads-454260">https://searchengineland.com/temu-pulls-us-google-shopping-ads-454260</a>, See on <a href="https://news.ycombinator.com/item?id=43687495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articlebody">

													
												
						
						
						<div>
<p>Temu completely shut off Google Shopping ads in the U.S. on April 9, with its App Store ranking subsequently plummeting from a typical third or fourth position to 58th in just three days. </p>



<p>The companyâ€™s impression share, which measures how often their ads appear compared to eligibility, dropped sharply before disappearing completely from advertiser auction data by April 12.</p>



<p>The timing coincided with the Trump administrationâ€™s hardened stance on Chinese imports, raising tariffs to 125% while maintaining a more moderate approach to other trading partners.</p>



<p><strong>First seen.</strong> Mike Ryan, head of ecommerce insights at Smarter Ecommerce, shared this news on <a href="https://www.linkedin.com/posts/mikeryanretail_%F0%9D%97%A7%F0%9D%97%B2%F0%9D%97%BA%F0%9D%98%82-%F0%9D%97%B5%F0%9D%97%AE%F0%9D%98%80-%F0%9D%97%B9%F0%9D%97%B2%F0%9D%97%B3%F0%9D%98%81-%F0%9D%98%81%F0%9D%97%B5%F0%9D%97%B2-%F0%9D%97%AF%F0%9D%98%82%F0%9D%97%B6%F0%9D%97%B9%F0%9D%97%B1%F0%9D%97%B6%F0%9D%97%BB%F0%9D%97%B4-activity-7317519336426901504-Kucf/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAB0N7MBstWf5SblEci2G1F3WzMSeIW1b7s" target="_blank" rel="noopener">LinkedIn</a>:</p>


<div>
<figure><img fetchpriority="high" decoding="async" width="800" height="487" src="https://searchengineland.com/wp-content/seloads/2025/04/1744632561651.jpeg.webp" alt="1744632561651" srcset="https://searchengineland.com/wp-content/seloads/2025/04/1744632561651.jpeg.webp 800w,https://searchengineland.com/wp-content/seloads/2025/04/1744632561651-555x338.jpeg.webp 555w,https://searchengineland.com/wp-content/seloads/2025/04/1744632561651-186x113.jpeg.webp 186w,https://searchengineland.com/wp-content/seloads/2025/04/1744632561651-768x468.jpeg.webp 768w" sizes="(max-width: 800px) 100vw, 800px"></figure></div>


<p><strong>Between the lines</strong>. Temuâ€™s business model relied on heavily subsidized orders from parent company PDD to drive market share growth, despite operating at a loss on individual sales.</p>



<ul>
<li>New tariffs, combined with crackdowns on â€œde minimisâ€ import loopholes, have severely undermined Temuâ€™s direct-from-manufacturer approach.</li>



<li>The companyâ€™s inability to maintain app performance without advertising for even a single day demonstrates the fragility of its market position.</li>
</ul>



<p><strong>Why we care</strong>. Ecommerce advertisers may experience temporary relief in digital advertising costs as Temuâ€™s aggressive spending vanishes from auction platforms. Similar rapid market exits (e.g., Amazon during early pandemic lockdowns) led to drops in cost-per-click metrics. Some reduction in CPM rates is expected, potentially lowering both CPC and cost-per-conversion for remaining advertisers.</p>



<p><strong>Tariffs</strong>. The underlying causes of Temuâ€™s retreat (tariffs and import restrictions) could ultimately prove more damaging to the ecommerce landscape, particularly for small and medium-sized businesses.</p>



<p><strong>Bottom line</strong>. Unlike failed competitor Wish.com, Temuâ€™s parent company remains fundamentally sound. With U.S. trade policy still in flux and facing internal opposition even within the administration, Temuâ€™s retreat may not be permanent.</p>
</div>
						
						<hr>
						
						

						<div>
			<p>New on Search Engine Land</p>
			<section>
				<ul>

					
					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
				</ul>
			</section>
		</div>


											
<!-- START EOS SPACE -->

<!-- END EOS SPACE -->					
						


<div>
	<p>About the author</p>
	<div>
				<div>
						<p><img src="https://searchengineland.com/anu-adegbola-2" alt="Anu Adegbola" width="140" height="140" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20140%20140'%3E%3C/svg%3E"></p>
											</div>
				<div>
						
						

						<p><span>Anu Adegbola has been Paid Media Editor of Search Engine Land</span><span> since 2024. She covers</span><span> paid search, paid social, retail media, video and more.<p>In 2008, Anu's career started with</p></span><span><span>&nbsp;delivering digital marketing campaigns (mostly but not exclusively Paid Search) by building strategies, maximising ROI, automating repetitive processes and bringing efficiency from every part of marketing departments through inspiring leadership both on agency, client and marketing tech side.</span></span></p>
<p><span><span>Outside editing Search Engine Land article she is the founder of PPC networking event - <a href="https://ppc.live/" target="_blank" rel="noopener">PPC Live</a> and host of </span></span><span><span>weekly podcast <a href="https://www.themarketinganu.com/podcast" target="_blank" rel="noopener">PPCChat Roundup</a>.</span></span></p>

<p><span><span>She is also an international speaker with some of the stages she has presented on being SMX (US), SMX (Munich), Friends of Search (Amsterdam), brightonSEO, The Marketing Meetup, HeroConf (PPC Hero), SearchLove, BiddableWorld, SESLondon, PPC Chat Live, AdWorld Experience (Bologna) and more.</span></span></p>					</div>
			</div>
</div>
						
						<br>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cost of Being Crawled: LLM Bots and Vercel Image API Pricing (103 pts)]]></title>
            <link>https://metacast.app/blog/engineering/postmortem-llm-bots-image-optimization</link>
            <guid>43687431</guid>
            <pubDate>Mon, 14 Apr 2025 23:33:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://metacast.app/blog/engineering/postmortem-llm-bots-image-optimization">https://metacast.app/blog/engineering/postmortem-llm-bots-image-optimization</a>, See on <a href="https://news.ycombinator.com/item?id=43687431">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>A misconfiguration that might have cost us $7,000</p><p><img alt="LLM bots + Next.js image optimization = recipe for bankruptcy (post-mortem)" loading="lazy" width="1200" height="630" decoding="async" data-nimg="1" sizes="100vw" srcset="https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=640&amp;q=75 640w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=750&amp;q=75 750w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=828&amp;q=75 828w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=1080&amp;q=75 1080w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=1200&amp;q=75 1200w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=1920&amp;q=75 1920w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=2048&amp;q=75 2048w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=3840&amp;q=75 3840w" src="https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=3840&amp;q=75"></p><div><div><p><img alt="Author's picture" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" srcset="https://metacast.app/_next/image?url=%2Fimages%2Fpeople%2Filya-avatar.jpg&amp;w=128&amp;q=75 1x, https://metacast.app/_next/image?url=%2Fimages%2Fpeople%2Filya-avatar.jpg&amp;w=256&amp;q=75 2x" src="https://metacast.app/_next/image?url=%2Fimages%2Fpeople%2Filya-avatar.jpg&amp;w=256&amp;q=75"></p><p>Ilya Bezdelev</p></div><p>Published on <time datetime="2025-02-10T13:33:07.000Z">February	10, 2025</time></p></div><hr><div><div><p>Table of Contents</p><ol><li><a href="#tldr">TL;DR</a></li><li><a href="#context">Context</a></li><li><a href="#how-we-discovered-the-problem">How we discovered the problem</a><ol><li><a href="#step-1-a-cost-spike">Step 1: A cost spike</a></li><li><a href="#step-2-image-optimization-api-usage-spike">Step 2: Image Optimization API usage spike</a></li><li><a href="#step-3-tens-of-thousands-of-requests-from-llm-bots">Step 3: Tens of thousands of requests from LLM bots</a></li></ol></li><li><a href="#mitigation">Mitigation</a><ol><li><a href="#step-1-stop-the-bleeding">Step 1: Stop the bleeding</a></li><li><a href="#step-2-disable-image-optimization">Step 2: Disable Image Optimization</a></li><li><a href="#step-3-robotstxt">Step 3: robots.txt</a><ol><li><a href="#user-agents-of-llm-bots">User agents of LLM bots</a></li><li><a href="#user-agents-of-search-engine-crawlers">User agents of search engine crawlers</a></li><li><a href="#user-agents-of-seo-bots">User agents of SEO bots</a></li></ol></li></ol></li><li><a href="#how-do-we-prevent-this-in-the-future">How do we prevent this in the future?</a><ol><li><a href="#continue-with-a-sensitive-spend-limit">Continue with a sensitive spend limit</a></li><li><a href="#mindset-for-scale">Mindset for scale</a></li><li><a href="#ready-for-defense">Ready for defense</a></li></ol></li><li><a href="#social-media-response">Social media response</a></li><li><a href="#parting-thoughts">Parting thoughts</a></li><li><a href="#upd-vercel-changed-their-image-optimization-pricing">UPD: Vercel changed their image optimization pricing</a></li></ol></div><h2 id="tldr"><a href="#tldr">TL;DR</a></h2>
<p>On Friday, Feb 7, 2025 we had an incident with our Next.js web app hosted on Vercel that could've cost us $7,000 if we didn't notice it in time.</p>
<p>We had a spike in LLM bot traffic coming from Amazonbot, Claudebot, Meta and an unknown bot. Together they sent 66.5k requests to our site within a single day. Bots scraped thousands of images that used Vercel's Image Optimization API, which cost us $5 per 1k images.</p>
<p>The misconfiguration on our side combined with the aggressive bot traffic created an economically risky situation for our tiny bootstrapped startup.</p>
<h2 id="context"><a href="#context">Context</a></h2>
<p>Metacast is a podcast tech startup. Our main product is a <a href="https://metacast.app/">podcast app</a> for iOS and Android.</p>
<p>For every podcast episode on the platform, our web app has a web page. Our platform has ~1.4M episodes, which means we have 1.4M web pages that are discoverable by crawlers. These pages are generated server-side at request time, then cached.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/lex-podcast-page-metacast.png" alt="Lex Fridman Podcast"></p>
<h2 id="how-we-discovered-the-problem"><a href="#how-we-discovered-the-problem">How we discovered the problem</a></h2>
<h3 id="step-1-a-cost-spike"><a href="#step-1-a-cost-spike">Step 1: A cost spike</a></h3>
<p>First, we received a cost alert from Vercel saying that we've hit 50% of the budget for resources metered by usage.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-cost-alert.png" alt="Vercel cost alert"></p>
<h3 id="step-2-image-optimization-api-usage-spike"><a href="#step-2-image-optimization-api-usage-spike">Step 2: Image Optimization API usage spike</a></h3>
<p>We looked into it and saw that it's driven by the Image Optimization API, which peaked on Feb 7.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-image-optimization-usage-summary.jpg" alt="Image Optimization Usage"></p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-image-optimization-chart.jpg" alt="Image Optimization Usage Chart"></p>
<p>Every page in the podcast directory has an image of a podcast cover (source image dimensions are 3000x3000px). With Image Optimization, podcast covers were reduced to 1/10th of the size, then cached. Image Optimization made the web app really snappy. It worked like a charm, except it turned out to be very expensive.</p>
<p>Vercel <a href="https://vercel.com/docs/image-optimization/limits-and-pricing">charges</a> $5 for every 1,000 images optimized. With thousands of requests coming our way, we were accumulating cost at the rate of $5 per each 1k image requests. In the worst case scenario, if all 1.4M images were crawled we'd hypothetically be looking at a $7k bill from Vercel.</p>
<h3 id="step-3-tens-of-thousands-of-requests-from-llm-bots"><a href="#step-3-tens-of-thousands-of-requests-from-llm-bots">Step 3: Tens of thousands of requests from LLM bots</a></h3>
<p>We looked at the user agents of requests in the Firewall in Vercel and saw Amazonbot, ClaudeBot, meta_externalagent and an unknown bot disguising itself as a browser.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-user-agent-stats.png" alt="User Agents"></p>
<p>We can't say definitively which bots were downloading images, because we are on the Pro plan on Vercel and no longer have access to logs from Friday. We only know that it was bot traffic.</p>
<h2 id="mitigation"><a href="#mitigation">Mitigation</a></h2>
<h3 id="step-1-stop-the-bleeding"><a href="#step-1-stop-the-bleeding">Step 1: Stop the bleeding</a></h3>
<p>Both of us used to work at AWS where we internalized the golden rule of incident recovery - <strong>stop the bleeding first, do a long-term fix later</strong>.</p>
<p>We configured firewall rules in Vercel to block bots from Amazon, Anthropic, OpenAI and Meta. To be fair, OpenAI didn't crawl our site, but we blocked it as a preventative measure.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-firewall-rules.jpg" alt="Firewall rules"></p>
<h3 id="step-2-disable-image-optimization"><a href="#step-2-disable-image-optimization">Step 2: Disable Image Optimization</a></h3>
<p>First, we disabled image optimization by adding an <code>unoptimized</code> property to podcast images in Next.js. Our reasoning was that users accessing the pages will get the latest version of the page with unoptimized images.</p>
<p>We didn't consider that:</p>
<ul>
<li>Bots had already crawled thousands of pages and would crawl the <em>optimized</em> images using the URLs they extracted from the "old" HTML.</li>
<li>Our site enabled image optimization for all external hosts.</li>
</ul>
<p>The latter is the most embarrassing part of the story. We missed an obvious exploit in the web app.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="javascript" data-theme="github-dark-dimmed github-light"><code data-language="javascript" data-theme="github-dark-dimmed github-light"><span data-line=""><span>const</span><span> nextConfig</span><span> =</span><span> {</span></span>
<span data-line=""><span>  images: {</span></span>
<span data-line=""><span>    remotePatterns: [</span></span>
<span data-line=""><span>      {</span></span>
<span data-line=""><span>        protocol: </span><span>'https'</span><span>,</span></span>
<span data-line=""><span>        hostname: </span><span>'**'</span><span>,</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>      {</span></span>
<span data-line=""><span>        protocol: </span><span>'http'</span><span>,</span></span>
<span data-line=""><span>        hostname: </span><span>'**'</span><span>,</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>    ],</span></span>
<span data-line=""><span>  },</span></span>
<span data-line=""><span>  ...</span></span></code></pre></figure>
<p>To explain why we did this in the first place, we need to add some important context about podcasting.</p>
<p>We do not own the podcast content displayed on our site. Similar to other podcast apps like Apple and Spotify, we ingest podcast information from RSS feeds and display it in our directory. The cover images are hosted on specialized podcast hosting platforms like <a href="https://transistor.fm/">Transistor</a>, <a href="https://www.buzzsprout.com/">Buzzsprout</a>, and others. But podcasts could be hosted anywhere from a WordPress website to an S3 bucket. It is impractical to allowlist all possible hosts.</p>
<p>Optimizing an image meant that Next.js downloaded the image from one of those hosts to Vercel first, optimized it, then served to the users. If we wanted to make our site snappy, we had to either build and maintain an image optimization pipeline ourselves or use the built-in capability. As a scrappy startup for whom a web app was at best secondary, we chose the faster route without thinking much about it.</p>
<p>In retrospect, we should've researched how it works. We're lucky no one started using our site as an image optimization API.</p>
<p>To mitigate the problem entirely, we disabled image optimization for any external URLs. Now, image optimization is only enabled for images hosted on our own domain. Podcast covers load noticeably slower. We'll need to do something about it eventually.</p>
<p>But this is not all.</p>
<h3 id="step-3-robotstxt"><a href="#step-3-robotstxt">Step 3: robots.txt</a></h3>
<p>Of course, we knew about <code>robots.txt</code>, a file that tells crawlers whether they're allowed to crawl the site or not.</p>
<p>Since both of us were new to managing a large-scale content site (our background is in backends, APIs, and web apps behind auth), we didn't even think about LLM bots. It's just not something that was on our radar. So, our <code>robots.txt</code> was a simple allow-all except for a few paths that we disallowed.</p>
<p>Our first reaction was to disable all bot traffic except Google. But when we understood that the root cause of the problem lied in the misconfigured image optimization, we decided to keep our site open to all LLM and search engine bots. Serving the text content doesn't cost us much, but we may benefit from being shown as a source of data in LLMs, which would be similar to being shown on a search engine results page (SERP).</p>
<p>We generate <code>robots.txt</code> programmatically using <a href="https://nextjs.org/docs/app/api-reference/file-conventions/metadata/robots">robots.ts</a> in Next.js. We researched the bots and added their user agents to our code. If we ever need to disable any of the bots, we can do so very quickly now. While we were at it, we disabled some paths for SEO bots like Semrush and MJ12Bot.</p>
<p>Note that <code>robots.txt</code> only works if bots respect it. It's honor-based system and there are still bad bots out there that ignore it and/or attempt to disguise themselves as users.</p>
<h4 id="user-agents-of-llm-bots"><a href="#user-agents-of-llm-bots">User agents of LLM bots</a></h4>
<table>
<thead>
<tr>
<th>User Agent</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Amazonbot</code></td>
<td><a href="https://developer.amazon.com/amazonbot">Amazon</a></td>
</tr>
<tr>
<td><code>CCBot</code></td>
<td><a href="https://commoncrawl.org/faq">Common Crawl</a></td>
</tr>
<tr>
<td><code>ClaudeBot</code></td>
<td><a href="https://privacy.anthropic.com/en/articles/10023637-does-anthropic-crawl-data-from-the-web-and-how-can-site-owners-block-the-crawler">Anthropic</a></td>
</tr>
<tr>
<td><code>GPTBot</code></td>
<td><a href="https://platform.openai.com/docs/bots/">OpenAI</a></td>
</tr>
<tr>
<td><code>Meta-ExternalAgent</code></td>
<td><a href="https://developers.facebook.com/docs/sharing/webmasters/web-crawlers/">Meta</a></td>
</tr>
<tr>
<td><code>PerplexityBot</code></td>
<td><a href="https://docs.perplexity.ai/guides/bots">Perplexity</a></td>
</tr>
</tbody>
</table>
<h4 id="user-agents-of-search-engine-crawlers"><a href="#user-agents-of-search-engine-crawlers">User agents of search engine crawlers</a></h4>
<table>
<thead>
<tr>
<th>User Agent</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Applebot</code></td>
<td><a href="https://support.apple.com/en-us/119829">Apple</a></td>
</tr>
<tr>
<td><code>Baiduspider</code></td>
<td><a href="https://www.baidu.com/search/robots_english.html">Baidu</a></td>
</tr>
<tr>
<td><code>Bingbot</code></td>
<td><a href="https://www.bing.com/webmasters/help/which-crawlers-does-bing-use-8c184ec0">Bing</a></td>
</tr>
<tr>
<td><code>ChatGPT-User</code> &amp; <code>OAI-SearchBot</code></td>
<td><a href="https://platform.openai.com/docs/bots/">OpenAI</a></td>
</tr>
<tr>
<td><code>DuckDuckBot</code></td>
<td><a href="https://duckduckgo.com/duckduckgo-help-pages/results/duckduckbot/">DuckDuckGo</a></td>
</tr>
<tr>
<td><code>Googlebot</code></td>
<td><a href="https://developers.google.com/search/docs/crawling-indexing/googlebot">Google</a></td>
</tr>
<tr>
<td><code>ImageSift</code></td>
<td><a href="https://imagesift.com/about">ImageSift by Hive</a></td>
</tr>
<tr>
<td><code>Perplexityâ€‘User</code></td>
<td><a href="https://docs.perplexity.ai/guides/bots">Perplexity</a></td>
</tr>
<tr>
<td><code>YandexBot</code></td>
<td><a href="https://www.yandex.com/support/webmaster/robot-workings/user-agent.html">Yandex</a></td>
</tr>
</tbody>
</table>
<h4 id="user-agents-of-seo-bots"><a href="#user-agents-of-seo-bots">User agents of SEO bots</a></h4>
<table>
<thead>
<tr>
<th>User Agent</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>AhrefsBot</code></td>
<td><a href="https://ahrefs.com/robot">Ahrefs</a></td>
</tr>
<tr>
<td><code>DataForSeoBot</code></td>
<td><a href="https://dataforseo.com/dataforseo-bot">DataForSeoBot</a></td>
</tr>
<tr>
<td><code>DotBot</code></td>
<td><a href="https://moz.com/help/moz-procedures/crawlers/dotbot">DotBot</a></td>
</tr>
<tr>
<td><code>MJ12bot</code></td>
<td><a href="https://mj12bot.com/">MS12Bot</a></td>
</tr>
<tr>
<td><code>SemrushBot</code></td>
<td><a href="https://www.semrush.com/bot/">Semrush</a></td>
</tr>
</tbody>
</table>
<h2 id="how-do-we-prevent-this-in-the-future"><a href="#how-do-we-prevent-this-in-the-future">How do we prevent this in the future?</a></h2>
<p>We will start with the one thing we've done well.</p>
<h3 id="continue-with-a-sensitive-spend-limit"><a href="#continue-with-a-sensitive-spend-limit">Continue with a sensitive spend limit</a></h3>
<p>We had a very sensitive spend limit alert. We knew we should not be spending much on Vercel, so we set it very low. When it triggered, we knew something was off.</p>
<p>This may be the most important lesson to all startups and big enterprises alike - always set spend limits for your infrastructure, or the bill may ruin you. You can probably negotiate with Vercel, AWS, GCP, etc. and they'll reduce or forgive your bill. But it's best to not put yourself in a situation where you have to ask for a favor.</p>
<h3 id="mindset-for-scale"><a href="#mindset-for-scale">Mindset for scale</a></h3>
<p>We've learned a ton and have (hopefully) attuned ourselves to:</p>
<ul>
<li><strong>The scale we're operating at</strong> â€“ we're serving millions of pages and need to be prepared for user traffic at that scale. The bots gave us a taste for what it would've been like had our app gone viral.</li>
<li><strong>The scale of web crawlers, both good and bad</strong> â€“ we need to be prepared to be "anthropized", "openAIed", "amazoned", or "semrushed." It's the new <a href="https://en.wikipedia.org/wiki/Slashdot_effect">slasdot effect</a> but without the benefit of immediate gratification.</li>
</ul>
<h3 id="ready-for-defense"><a href="#ready-for-defense">Ready for defense</a></h3>
<p>We've now better understood the options we have for firewalling ourselves from bots if we have to do so in the future. We can use Vercel firewall as the first line of defense or add a more advanced WAF from Cloudflare if things get dire.</p>
<p>See this post from Cloudflare: <a href="https://blog.cloudflare.com/declaring-your-aindependence-block-ai-bots-scrapers-and-crawlers-with-a-single-click/">Declare your AIndependence: block AI bots, scrapers and crawlers with a single click</a></p>

<p>When we discovered the rate at which bots were crawling our site, we <a href="https://www.linkedin.com/posts/ilyabezdelev_our-site-is-getting-totally-slammed-by-activity-7293596095778074624-MD_I">posted about it</a> on LinkedIn. We were just sharing what's going on in real time, but boy did it hit the nerve. Almost 400k impressions, 2.4k likes, 270+ comments, 120+ reposts.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/linkedin-post.jpg" alt="LinkedIn post stats"></p>
<p>We've gone through all comments on the post and responded to most of them.</p>
<p>Lots of folks offered solutions like <a href="https://blog.cloudflare.com/declaring-your-aindependence-block-ai-bots-scrapers-and-crawlers-with-a-single-click/">CloudFlare</a>, using middleware, rate limiting, etc. Some offered to feed junk back to LLM bots.</p>
<p>We learned about <a href="https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/">tarpit</a> tools like <a href="https://iocaine.madhouse-project.org/">iocaine</a> and <a href="https://zadzmo.org/code/nepenthes/">Nepenthes</a>.</p>
<blockquote>
<p><em>You could lure them into a honeypot?<br>
Like nepenthes or locaine.<br>
If you feel like poisoning the ai well</em></p>
</blockquote>
<p>People rightfully pointed out that you can get ruined by infinite scalability of cloud resources.</p>
<blockquote>
<p><em>that's my biggest concern about cloud providers. You make a small mistake (everyone does) and the costs can skyrocket overnight.</em></p>
</blockquote>
<p>We learned that some people aren't aware of the LLM bot crawling activity or the scale of it. They thanked us for raising awareness.</p>
<blockquote>
<p><em>WOW - thanks for alerting us.</em></p>
</blockquote>
<p>Some people had been surprised by bots just like we were.</p>
<blockquote>
<p><em>Same here. At first I was super excited to get so many new subscriptions. We did reCaptcha and Cloudflare. Things have quieted down. Thanks for posting. I thought we were the only ones</em></p>
</blockquote>
<p>Some aren't surprised at all and see it as a problem.</p>
<blockquote>
<p><em>Very recognizable (unfortunately). These (predominantly AI) bots started noticeably hitting our platform back in May/June 2024. Lots of time &amp; efforts wasted to keep our bills in check. We also found out that not all of them respect Robots.txt, so indeed a WAF is needed as well. I can(not) imagine how painful this must/will be for smaller businesses...</em></p>
</blockquote>
<p>Some people blamed us for not being prepared and called us out on calling out AI companies. Others defended us. Virality is a double-edged sword.</p>
<p>A large portion of the comments were claiming that data scraping is unethical, illegal, etc. People were outraged. It wasn't our intention, but our post brought the issue to the zeitgeist of that day.</p>
<h2 id="parting-thoughts"><a href="#parting-thoughts">Parting thoughts</a></h2>
<p><strong>There's a part of me that is glad that this happened.</strong></p>
<p>We got a taste of operating a web app at scale before reaching scale. It was easy to block bots, but had it been caused by user traffic, we'd have to swallow the cost or downgrade the experience. Bots were the canaries in a coalmine.</p>
<p><strong>Any technology has negative externalities.</strong></p>
<p>Some are obvious, some aren't. Of all the things that were happening, I was worried that we'd get penalized by podcast hosters whose endpoints we were hitting at the same rate as bots requested images from our site.</p>
<p><strong>Operating at scale on the internet is a game of defense</strong></p>
<p>We can rant about bots as much as we want, but that <em>is</em> the reality we operate in. So we better acknowledge it and deal with it.</p>
<p>P.S. We'll be discussing this topic on the next episode of the <a href="https://metacast.app/podcasts/7d7e381e-907c-5b22-aefc-1fc8311d2a71">Metacast: Behind the scenes</a> podcast. Follow us wherever you listen to podcasts to hear the story with more nuance.</p>
<h2 id="upd-vercel-changed-their-image-optimization-pricing"><a href="#upd-vercel-changed-their-image-optimization-pricing">UPD: Vercel changed their image optimization pricing</a></h2>
<p>On Feb 18, 2025, just a few days after we published this blog post, Vercel <a href="https://vercel.com/changelog/faster-transformations-and-reduced-pricing-for-image-optimization">changed</a> their image optimization pricing. With the new pricing we'd not have faced a huge bill.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-new-pricing.webp" alt="New Image Optimization pricing on Vercel"></p>
<p>However, this wouldn't address the problem that we need to optimize images hosted outside of our domain. We ended up implementing our own image optimization.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tomb Engine (152 pts)]]></title>
            <link>https://tombengine.com/</link>
            <guid>43686936</guid>
            <pubDate>Mon, 14 Apr 2025 22:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tombengine.com/">https://tombengine.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43686936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="6f3696b0" data-element_type="container" data-widget_type="text-editor.default" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}" data-elementor-type="footer" data-elementor-id="1421" data-elementor-post-type="elementor_library">
				<p><span>This is a community project which is not affiliated with Core Design, Eidos Interactive, or Embracer Group AB. Tomb Raider is a registered trademark of Embracer Group AB. TombEngine is not be sold. The code is open-source to encourage contributions and to be used for study purposes. We are not responsible for illegal uses of this source code. This source code is released as-is and continues to be maintained by non-paid contributors in their free time.</span></p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel sells 51% stake in Altera to private equity firm on a $8.75B valuation (276 pts)]]></title>
            <link>https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025</link>
            <guid>43686773</guid>
            <pubDate>Mon, 14 Apr 2025 21:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025">https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025</a>, See on <a href="https://news.ycombinator.com/item?id=43686773">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Raghib Hussain appointed chief executive officer of Altera.</p><div nonce="ijCpSEMuRnL490hOs/kXNA==">

					
						

					<!--?xml encoding="utf-8" ?--><p>SANTA CLARA, Calif.; SAN JOSE, Calif.; and MENLO PARK, Calif., April 14, 2025 â€“ Intel Corporation today announced that it has entered into a definitive agreement to sell 51% of its Altera business to Silver Lake, a global leader in technology investing.</p><p>The transaction, which values Altera at $8.75 billion, establishes Alteraâ€™s operational independence and makes it the largest pure-play FPGA (field programmable gate array) semiconductor solutions company. Altera offers a proven and highly scalable architecture and tool chain and is focused on driving growth and FPGA innovation to meet the demands and opportunities of an AI-driven market.</p><p>Intel will own the remaining 49% of the Altera business, enabling it to participate in Alteraâ€™s future success while focusing on its core business.</p><p>Intel also announced that Raghib Hussain will succeed Sandra Rivera as chief executive officer of Altera, effective May 5, 2025. Hussain is a highly accomplished and visionary technology executive with strong business acumen and engineering credentials. He joins Altera from his previous role as president of Products and Technologies at Marvell. Prior to joining Marvell in 2018, Hussain served as chief operating officer of Cavium, a company he co-founded.â€¯Prior to Cavium, Hussain held engineering roles at both Cisco and Cadence and helped found VPNet, an enterprise security company.</p><p>â€œTodayâ€™s announcement reflects our commitment to sharpening our focus, lowering our expense structure and strengthening our balance sheet,â€ said Lip-Bu Tan, chief executive officer of Intel. â€œAltera continues to make progress repositioning its product portfolio to participate in the fastest growing and most profitable segments of the FPGA market. We are grateful for Sandraâ€™s strong leadership and lasting impact throughout her 25-year Intel career and wish her continued success as she begins a new chapter. Raghib is a superb executive we selected to lead the business forward based on his vast industry experience and proven track record of success. We look forward to partnering with Silver Lake upon closing of the transaction, as their industry expertise will help to accelerate Altera's efforts and unlock additional economic value for Intel.â€</p><p>â€œThis investment represents a once-in-a-generation opportunity to invest in a scale leader in advanced semiconductors. Together with Raghib, we will be focused on strengthening Alteraâ€™s technology leadership position and investing in emerging AI-driven markets such as edge computing and robotics,â€ said Kenneth Hao, chairman and managing partner of Silver Lake. â€œWe look forward to working closely with Intel as a strategic partner who will continue to provide U.S.-based foundry services and complementary engagement with customers.â€</p><p>â€œI am excited to lead Altera in its next chapter, and this milestone with Silver Lake furthers Alteraâ€™s journey to be the world's No. 1 FPGA solutions provider,â€ said Hussain. â€œBacked by Silver Lakeâ€™s strong track record and now with clarity of focus as an independent company, Altera is well-positioned to build on its momentum and deliver breakthrough FPGA-based solutions that are shaping the future of compute driven by AI. I am grateful for the impact Sandra has made and the team she has built as we begin Alteraâ€™s next phase of growth.â€</p><p>Altera has been at the forefront of driving FPGA innovations for more than 40 years. The company provides leading programmable solutions that are easy-to-use and deploy in a range of strategically important segments such as industrial, communications, data center and military, aerospace, and government, as well as emerging markets such as AI/edge and robotics. Its broad portfolio of programmable semiconductor solutions, software and development tools deliver the reliability and flexibility needed to accelerate customer technology innovation.</p><p>The transaction is expected to close in the second half of 2025, subject to customary closing conditions.</p><p>Upon closing, Intel expects to deconsolidate Alteraâ€™s financial results from Intelâ€™s consolidated financial statements. In Fiscal Year 2024, Altera generated revenues of $1.54 billion, GAAP gross margin of $361 million and GAAP operating loss of $615 million. Alteraâ€™s Fiscal Year 2024 non-GAAP gross margin was $769 million and non-GAAP operating income was $35&nbsp;million. Reconciliations between the GAAP and non-GAAP measures are provided below.</p><p>Morgan Stanley &amp; Co. LLC acted as financial advisor to Intel.</p><p><strong>Forward-Looking Statements</strong></p><p>This release contains forward-looking statements that involve a number of risks and uncertainties, including with respect to the terms and anticipated timing of closing the agreed upon sale of a controlling interest in Altera and the potential benefits of such sale to Intel and Altera. Such statements involve risks and uncertainties that could cause actual results to differ materially from those expressed or implied, including:&nbsp; the risk that the transaction may not be completed in a timely manner or at all, including as a result of a failure to receive regulatory approvals; the occurrence of any event, change or other circumstance that could give rise to the termination of the transaction; the risk that the expected benefits of the transaction, including as a result of the increased independence of Altera, may not be realized; the risk of future loss of the Altera business by Intel as a result of the sale of a controlling interest in Altera; disputes or potential litigation related to the transaction or the ownership, control and operation of the Altera business, including as it relates to Intel; unanticipated costs related to the transaction or the Altera business that may be incurred; risks as to the retention of key Altera personnel and customers; risks related to the diversion of managementâ€™s attention during the pendency of the transaction; potential adverse reactions or changes to business relationships resulting from the announcement or completion of the transaction; changes in demand for Alteraâ€™s semiconductor products; the high level of competition and rapid technological change in the semiconductor industry; and other risks and uncertainties described in Intelâ€™s 2024 Form 10-K and our other filings with the SEC.</p><p>Given these risks and uncertainties, readers are cautioned not to place undue reliance on such forward-looking statements. Readers are urged to carefully review and consider the various disclosures made in this release and in other documents we file from time to time with the SEC that disclose risks and uncertainties that may affect our business.</p><p>All information in this press release reflects Intel management views as of the date hereof unless an earlier date is specified. Intel does not undertake, and expressly disclaims any duty, to update such statements, whether as a result of new information, new developments, or otherwise, except to the extent that disclosure may be required by law.</p><p><strong>Non-GAAP Financial Measures</strong></p><p>This release contains references to non-GAAP financial measures: Altera non-GAAP gross margin and Altera non-GAAP operating income / (loss) measures. Set out below are reconciliations of these measures to the most directly comparable GAAP financial measures. The non-GAAP financial measures disclosed herein should not be considered a substitute for, or superior to, the financial measures prepared in accordance with GAAP. Please refer to â€œExplanation of Non-GAAP Measuresâ€ in Intelâ€™s earnings release dated Jan. 30, 2025 for a detailed explanation of the adjustments made to the comparable GAAP measures, the ways management uses the non-GAAP measures, and the reasons why management believes the non-GAAP measures provide investors with useful supplemental information.</p><table nonce="ijCpSEMuRnL490hOs/kXNA==">
<tbody>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Twelve Months Ended</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">(in Millions; Unaudited)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Dec 28, 2024</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">GAAP gross margin</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="><strong>$ 361</strong></td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Acquisition-related adjustments</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">402</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Share-based compensation</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">6</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Non-GAAP gross margin</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">$ 769</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">GAAP operating income / (loss)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="><strong>$ (615)</strong></td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Acquisition-related adjustments</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">491</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Share-based compensation</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">122</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Restructuring and other charges</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">37</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Non-GAAP operating income / (loss)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">$ 35</td>
</tr>
</tbody>
</table><p><strong>About Intel</strong></p><p>Intel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Mooreâ€™s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customersâ€™ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intelâ€™s innovations, go to <a href="https://newsroom.intel.com/">newsroom.intel.com</a> and <a href="https://intel.com/">intel.com</a>.</p><p><strong>About Altera</strong><br>
Altera is a leading supplier of programmable hardware, software, and development tools that empower designers of electronic systems to innovate, differentiate, and succeed in their markets. With a broad portfolio of industry-leading FPGAs, SoCs, and design solutions, Altera enables customers to achieve faster time-to-market and unmatched performance in applications spanning data centers, communications, industrial, automotive, and more. For more information, visit&nbsp;<a href="http://www.altera.com./">www.altera.com.</a></p><p><strong>About Silver Lake</strong><br>
Silver Lake is a global technology investment firm, with approximately $104 billion in combined assets under management and committed capital and a team of professionals based in North America, Europe and Asia. Silver Lakeâ€™s portfolio companies collectively generate nearly $252 billion of revenue annually and employ approximately 433,000 people globally.</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is Entropy? (224 pts)]]></title>
            <link>https://jasonfantl.com/posts/What-is-Entropy/</link>
            <guid>43684560</guid>
            <pubDate>Mon, 14 Apr 2025 18:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jasonfantl.com/posts/What-is-Entropy/">https://jasonfantl.com/posts/What-is-Entropy/</a>, See on <a href="https://news.ycombinator.com/item?id=43684560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>People say many things about entropy: entropy increases with time, entropy is disorder, entropy increases with energy, entropy determines the arrow of time, etc.. But I have no idea what entropy is, and from what I find, neither do most other people. This is the introduction I wish I had when first told about entropy, so hopefully you find it helpful. My goal is that by the end of this long post we will have a rigorous and intuitive understanding of those statements, and in particular, why the universe looks different when moving forward through time versus when traveling backward through time.</p><p>This journey begins with defining and understanding entropy. There are multiple formal definitions of entropy across disciplinesâ€”thermodynamics, statistical mechanics, information theoryâ€”but they all share a central idea: <strong>entropy quantifies uncertainty</strong>. The easiest introduction to entropy is through Information Theory, which will lead to entropy in physical systems, and then finally to the relationship between entropy and time.</p><h2 id="information-theory"><span>Information Theory</span><a href="#information-theory"><i></i></a></h2><p>Imagine you want to communicate to your friend the outcome of some random events, like the outcome of a dice roll or the winner of a lottery, but you want to do it with the fewest number of bits (only 1s and 0s) as possible. How few bits could you use?</p><p>The creator of Information Theory, Claude Shannon, was trying to answer questions such as these during his time at Bell labs. He was developing the mathematical foundations of communication and compression, and eventually he discovered that the minimum number of bits required for a message was directly related to the uncertainty of the message. He was able to then formulate an equation to quantify the uncertainty of a message. When he shared it with his physicist colleague at Bell Labs, John von Neumann, von Neumann suggested calling it <em>entropy</em> for two reasons:</p><blockquote><p>Von Neumann, Shannon reports, suggested that there were two good reasons for calling the function â€œentropyâ€. â€œIt is already in use under that name,â€ he is reported to have said, â€œand besides, it will give you a great edge in debates because nobody really knows what entropy is anyway.â€ Shannon called the function â€œentropyâ€ and used it as a measure of â€œuncertainty,â€ interchanging the two words in his writings without discrimination.<br> â€” <em>Harold A. Johnson (ed.),</em> <em>Heat Transfer, Thermodynamics and Education: Boelter Anniversary Volume</em> (New York: McGraw-Hill, 1964), p. 354.</p></blockquote><p>Later we will see that the relationship between Shannonâ€™s entropy and the pre-existing definition of entropy was more than coincidental, they are deeply intertwined.</p><p>But now let us see how Shannon found definitions for these usually vague terms of â€œinformationâ€ and â€œuncertaintyâ€.</p><p>In Information Theory, the information of an observed state is formally defined as the number of bits needed to communicate that state (at least for a system with equally likely outcomes with powers of two, weâ€™ll see shortly how to generalize this). Here are some examples of information:</p><ul><li>If I flip a fair coin, it will take one bit of information to tell you the outcome: I use a <code>0</code> for head and a <code>1</code> for tails.</li><li>If I roll a fair 8-sided dice, I can represent the outcome with 3 bits: I use <code>000</code> for a 1, <code>001</code> for 2, <code>010</code> for 3, etc.</li></ul><p>The more outcomes a system can have, the more bits (information) it will require to represent its outcome. If a system has $N$ equally likely outcomes, then it will take $\text{log}_2(N)$ bits of information to represent an outcome of that system.</p><p>Entropy is defined as the expected number of bits of information needed to represent the state of a system (this is a lie, but itâ€™s the most useful definition for the moment, weâ€™ll fix it later). So the entropy of a coin is 1 since on average we expect it to take 1 bit of information to represent the outcome of the coin. An 8-sided dice will have an entropy of 3 bits, since we expect it to take an average of 3 bits to represent the outcome.</p><p>It initially seems that entropy is an unnecessary definition since we can just look at how many bits it takes to represent the outcome of our system and use that value, but this is only true when the chance of the outcomes are all equally likely.</p><p>Imagine now that I have a weighted 8-sided dice, so the number 7 comes up $50$% of the time while the rest of the faces come up $\approx 7.14$% of the time. Now, if we are clever, we can reduce the expected number of bits needed to communicate the outcome of the dice. We can decide to represent a 7 with a <code>0</code>, and all the other numbers will be represented with <code>1XXX</code> where the <code>X</code>s are some unique bits. This would mean that $50$% percent of the time we only have to use 1 bit of information to represent the outcome, and the other $50$% of the time we use 4 bits, so the expected number of bits (the entropy of the dice) is 2.5. This is lower than the 3 bits of entropy for the fair 8-sided dice.</p><p>Fortunately, we donâ€™t need to come up with a clever encoding scheme for every possible system, there exists a pattern to how many bits of information it takes to represent a state with probability $p$. We know if $p=0.5$ such as in the case of a coin landing on heads, then it takes 1 bit of information to represent that outcome. If $p=0.125$ such as in the case of a fair 8-sided dice landing on the number 5, it takes 3 bits of information to represent that outcome. If $p=0.5$ such as in the case of our unfair 8-sided dice landing on the number 7, then it takes 1 bit of information, just like the coin, which shows us that all that matters is the probability of the outcome. With this, we can discover an equation for the number of bits of information needed for a state with probability $p$.</p><p>\[I(p) = -\text{log}_2(p)\]</p><p>This value $I$ is usually called <em>information content</em> or <em>surprise</em>, since the lower the probability of a state occurring, the higher the surprise when it does occur.</p><p>When the probability is low, the surprise is high, and when the probability is high, the surprise is low. This is a more general formula then â€œthe number of bits neededâ€ since it allows for states that are exceptionally likely (such as $99$% likely) to have surprise less then 1, which would make less sense if we tried to interpret the value as â€œthe number of needed bits to represent the outcomeâ€.</p><p>And now we can fix our definition of entropy (the lie I told earlier). Entropy is not necessarily the expected number of bits used to represent a system (although it is when you use an optimal encoding scheme), but more generally the entropy is the expected <em>surprise</em> of the system.</p><p>And now we can calculate the entropy of systems like a dice or a coin or any system with known probabilities for its outcomes. The expected surprise (entropy) of a system with $N$ possible outcomes each with probability $p_i$ (all adding up to 1) can be calculated as</p><p>\[\begin{align} \sum_{i=1}^{N} p_i \cdot I(p_i) = - \sum_{i=1}^{N} p_i \cdot \text{log}_2(p_i)\label{shannon_entropy}\tag{Shannon entropy}\\ \end{align}\]</p><p>And notice that if all the $N$ probabilities are the same (so $p_i = \frac{1}{N}$), then the entropy equation can simplify to</p><p>\[- \sum_{i=1}^{N} p_i \cdot \text{log}_2(p_i) \Rightarrow \text{log}_2(N)\]</p><p>Here are some basic examples using $\eqref{shannon_entropy}$.</p><ul><li>The entropy of a fair coin is</li></ul><p>\[- ( 0.5 \cdot \text{log}_2(0.5) + 0.5 \cdot \text{log}_2(0.5)) = \text{log}_2(2) = 1\]</p><ul><li>The entropy of a fair 8-sided dice is</li></ul><p>\[- \sum_{i=1}^{8} 0.125 \cdot \text{log}_2(0.125) = \text{log}_2(8) = 3\]</p><ul><li>The entropy of an unfair 8-sided dice, where the dice lands on one face $99$% of the time and lands on the other faces the remaining $1$% of the time with equal probability (about $0.14$% each), is</li></ul><p>\[- (0.99 \cdot \text{log}_2(0.99) + \sum_{i=1}^{7} 0.0014 \cdot \text{log}_2(0.0014)) = 0.10886668511648723\]</p><p>Hopefully it is a bit more intuitive now that entropy represents uncertainty. An 8-sided dice would have higher entropy than a coin since we are more uncertain about the outcome of the 8-sided dice than we are about the coin (8 equally likely outcomes are more uncertain than only 2 equally likely outcomes). But a highly unfair 8-sided dice has less entropy than even a coin since we have very high certainty about the outcome of the unfair dice. Now we have an actual equation to quantify that uncertainty (entropy) about a system.</p><p>It is not clear right now how this definition of entropy has anything to do with disorder, heat, or time, but this idea of entropy as uncertainty is fundamental to understanding the entropy of the universe which we will explore shortly. For reference, this definition of entropy is called Shannon entropy.</p><p>We will move on now, but I recommend looking further into Information Theory. It has many important direct implications for data compression, error correction, cryptography, and even linguistics, and touches nearly any field that deals with uncertainty, signals, or knowledge.</p><h2 id="physical-entropy"><span>Physical Entropy</span><a href="#physical-entropy"><i></i></a></h2><p>Now we will see entropy from a very different lens, that of Statistical Mechanics. We begin with the tried-and-true introduction to entropy which every student is given.</p><h3 id="balls-in-a-box"><span>Balls in a box</span><a href="#balls-in-a-box"><i></i></a></h3><p>I shall give you a box with 10 balls in it, $p_0$ through $p_9$, and we will count how many balls are on the left side of the box and on the right side of the box. Assume every ball is equally likely to be on either side. Immediately we can see it is highly unlikely that we count all the balls are on the left side of the box, and more likely that we count an equal number of balls on each side. Why is that?</p><p>Well, there is only one state in which we count all the balls on the left, and that is if every ball is on the left (truly astounding, but stay with me). But there are many ways in which the box is balanced: We could have $p_0$ through $p_4$ one side and the rest on the other, or the same groups but flipped from left to right, or we could have all the even balls on one side and the odd on the other, or again flipped, or any of the other many possible combinations.</p><p>This box is a system that we can measure the entropy of, at least once I tell you how many balls are counted on each side. It can take a moment to see, but imagine the box with our left and right counts as a system where the outcome will be finding out where all the individual balls are in the box, similar to rolling a dice and seeing which face it lands on.</p><p>This would mean that the box where we count all the balls on the left side only has one possible outcome: all the balls are on the left side. We would take this to mean that this system has $0$ entropy (no expected surprise) since we already know where we will find each individual ball.</p><p>The box with balanced sides (5 on each) has many possible equally likely outcomes, and in fact, we can count them. A famous equation in combinatorics is the N-choose-k equation, which calculates exactly this scenario. It tells us that there are 252 possible ways in which we can place 5 balls on each side. The entropy for this system would then be $- \sum_{i=1}^{252} \frac{1}{252} \cdot \text{log}_2(\frac{1}{252}) = \text{log}_2(252) = 7.9772799235$. This is the same as calculating the entropy of a 252-sided dice.</p><p>And if we were to increase the number of balls, the entropy of the balanced box would increase since there would then be even more possible combinations that could make up a balanced box.</p><p>We should interpret these results as: The larger the number of ways there are to satisfy the large-scale measurement (counting the number of balls on each side), the higher the entropy of the system. When all the balls are on the left, there is only one way to satisfy that measurement and so it has a low entropy. When there are many ways to balance it on both sides, it has high entropy.</p><p>Here we see 1000 balls bouncing around in a box. They will all start on the left, so the box would have 0 entropy, but once the balls start crossing to the right and changing the count on each side, the entropy will increase.</p><p><a href="https://jasonfantl.com/assets/img/posts/Entropy/2_cell_box.gif"><img data-src="/assets/img/posts/Entropy/2_cell_box.gif" alt=" balls in a box with its entropy " width="300" data-proofer-ignore=""></a></p><p>In Statistical Mechanics, the formal term for the large-scale measurement is the <em>macrostate</em>, and the specific states that can satisfy that measurement are <em>microstates</em>. We would call the measurement of the number of balls on each side of the box the macrostate, and the different combinations of positions of individual balls the microstates. So rephrasing the above: There is only one microstate representing the macrostate of all balls being counted on one side, and there are many microstates representing the macrostate of a balanced box.</p><p>But why did we decide to measure the number of balls on the left and right? We could have measured a different macrostate, and the entropy would be different.</p><h3 id="macrostates"><span>Macrostates</span><a href="#macrostates"><i></i></a></h3><p>Imagine instead of selecting the left and right halves of the box to count the number of balls, we instead count how many balls are in each pixel of the box. In this scenario, the entropy would almost always be maximized, as the balls rarely share a pixel. Even if all the balls were on the left side of the box, they would likely still each occupy a different pixel, and the measured entropy would be the same as if the balls were evenly distributed in the box.</p><p>If we use an expensive instrument to measure the box and track the balls with high precision, then the entropy would rarely change and would be very high. If we instead use an inexpensive instrument that can only tell if a ball is on the left or right of the box, then the entropy will be low and could very easily fluctuate if some of the balls temporarily end up on the same side of the box.</p><p>Letâ€™s run exactly the same simulation of 1000 balls in the box again, still starting with the balls on the left. But, this time we count how many balls are in each cell in a 50x50 grid, as opposed to the previous two cells (the left and right cells). The entropy will be high since there are many microstates that represent a bunch of cells with only 1 ball in it, and the entropy wonâ€™t change much since two balls rarely share the same cell. Recall that if two balls share the same cell, the count would go up, and there are fewer microstates that satisfy a cell with a count of 2 compared to two cells with a count of 1 in each.</p><p><a href="https://jasonfantl.com/assets/img/posts/Entropy/50_cell_box.gif"><img data-src="/assets/img/posts/Entropy/50_cell_box.gif" alt=" balls in a box with its entropy " width="300" data-proofer-ignore=""></a></p><p>Entropy is not intrinsic to the physical system alone, but rather to our description of it as well â€” i.e., the macrostate weâ€™re measuring, and the resolution at which we observe it.</p><p>This process of measuring a lower-resolution version of our system (like counting how many balls are on the left or right side of a box) is called <em>coarse-graining</em>.</p><p>How we choose/measure the macrostate, that is, how we coarse-grain the system, is dependent on the problem we are solving.</p><ul><li>Imagine you have a box of gas (like our balls in a box, but at the scale of $10^{25}$ balls in the box), and we place a temperature-reader on the left and right side of the box. This gives us a macrostate of two counts of the average ball speed on the left and right sides of the box. We can then calculate the entropy by comparing when the temperature-readers are equal to when they are different by $T$ degrees. Once we learn how time and entropy interact, we will use this model to show that the two temperature-readers are expected to converge to the same value over time.</li><li>Imagine you sequence the genome of many different people in a population, you could choose many different macrostates based on what you care about. You could count how many of each nucleotide there are in all the sequences, allowing you to quantify how variable the four nucleotides are in DNA. You could calculate the entropy of every individual position in the DNA sequence by counting how many nucleotide types are used in that position across the population, allowing you to identify portions of DNA that are constant across individuals or vary across individuals.</li></ul><p>How you choose to measure the macrostate can come in many forms for the same system, depending on what you are capable of measuring and/or what you care about measuring.</p><p>But once we have a macrostate, we need a way to identify all the microstates and assign probabilities to them.</p><h3 id="microstates"><span>Microstates</span><a href="#microstates"><i></i></a></h3><p>When we were looking at the positions of balls in a box in equally sized cells, it was easy to see that every ball was equally likely to be in any of the cells, so each microstate was equally likely. This made calculating the entropy very simple, we just used the simplified version of $\eqref{shannon_entropy}$ to find that for $W$ microstates that satisfy a given macrostate, the entropy of the system is $\text{log}_{2}(W)$. It isnâ€™t too hard to extend this idea to microstates that are not equally likely.</p><p>For example, letâ€™s calculate the entropy of a box with 5 balls on the left and 5 balls on the right, but we replace one of the balls in the box with a metal ball that is pulled by a magnet to the left. In this case, the probability of each microstate is no longer equally likely. If we assume there is an $80$% chance that the metal ball is on the left side instead of the right side, then the entropy of the box can be calculated as follows: For all of the 252 microstates, 126 of them have the metal ball on the left, which has a $0.8$ chance of being true, and the other 126 have the metal ball on the right with a $0.2$ chance. This means using the $\eqref{shannon_entropy}$ we get an entropy of</p><p>\[- \sum_{i=1}^{126} \frac{0.2}{126} \cdot \text{log}_2(\frac{0.2}{126}) - \sum_{i=1}^{126} \frac{0.8}{126} \cdot \text{log}_2(\frac{0.8}{126}) = 7.69921\]</p><p>This is a little less than the box with normal balls which had $7.9772799235$ entropy. This is exactly what we should expect, we are a bit more certain about the outcome of this system since we knew where one of the balls was more likely to be.</p><p>But this raises a subtle question: why did we choose this particular set of microstates? For example, if we have the macrostate of 5 balls on the left and 5 balls on the right, but we decide to use the 50x50 grid of cells to describe the microstates, then there are far more microstates that satisfy the macrostate compared to when we were using the 2x1 grid of left and right.</p><p>Letâ€™s calculate the entropy for those two examples. Keep in mind they both have the same macrostate: 5 balls on the left and 5 balls on the right.</p><ul><li>If we choose to use the microstates of looking at the position of individual balls between two cells splitting the box in half, then we can use n-choose-k to calculate that there are 252 possible combinations of balls across the two cells. This gives us an entropy of $\text{log}_2(252) = 7.977279923$.</li><li>If we choose to use the microstates of looking at the position of individual balls between 50x50 (2500) cells splitting the box into a grid, then we can use n-choose-k to calculate that there are 252 possible combinations of balls across the two halves of the box, for each of which every ball could be in any of 50x25 (1250) cells. This gives us an entropy of $\text{log}_2(252*1250^{10}) = 110.8544037$.</li></ul><p>This result lines up very well with our Information-theoretic understanding of entropy: when we allow more microstates to represent the same macrostate, we are more uncertain about the microstate our system is in. But this result does raise some concerns.</p><p>If different microstates give different entropy, how do we choose the right microstates for our problem? Unlike the macrostate, this decision of which microstates to use is not determined by our instruments or the scope of the problem, it has to be determined by the person making the calculation. Often for physical systems people will use the set of microstates that capture all the relevant information related to the macrostate. For example, if our macrostate is about balls on the left or right side of a box, then we probably donâ€™t care about the ballâ€™s velocity or mass or anything else but the ball position.</p><p>Another concern is that it feels wrong that the same physical system with the same macrostate can have different entropies depending on the microstate representation we use. Usually, we expect physical systems to have invariant measurements regardless of the internal representation we decide to use for our measurement. But this is incorrect for entropy. We need to recall that entropy is the uncertainty of a system and that the definition of entropy is completely dependent on what we are uncertain about, which for physical systems are the microstates. This would be similar to someone asking â€œHow many parts make up that machine?â€, to which we should respond â€œHow do you define a â€˜partâ€™?â€. When we ask â€œWhat is the entropy of this macrostate?â€, we need to respond with â€œWhat microstates are we using?â€.</p><p>With all that said, there is some small truth to what our intuition is telling us, although it doesnâ€™t apply to the general case. While the entropy of the system changes when we change the microstates, the relative differences in entropy across macrostates will be equal <em>if</em> the new microstates uniformly multiply the old microstates. That is, if each original microstate is split into the same number of refined microstates, then the entropy of every macrostate increases by a constant. Weâ€™re getting lost in the terminology, an example will demonstrate.</p><p>Let us again take the 10 balls in a box, and we will calculate the entropy of the system for a few different macrostates and microstate representations. We indicate the number of balls on each side of the box with <code>(L, R)</code>, where <code>L</code> is the number of balls on the left and <code>R</code> is the number of balls on the right. Then we calculate the entropy using the microstate of a 2x1 grid of cells (just the left and right halves of the box) and for the 50x50 grid of cells.</p><div><table><thead><tr><th>&nbsp;</th><th>(10,0)</th><th>(9,1)</th><th>(8,2)</th><th>(7,3)</th><th>(6,4)</th><th>(5,5)</th><th>(4,6)</th><th>(3,7)</th><th>(2,8)</th><th>(1,9)</th><th>(0,10)</th></tr></thead><tbody><tr><td>2x1</td><td>0.00000</td><td>3.32193</td><td>5.49185</td><td>6.90689</td><td>7.71425</td><td>7.97728</td><td>7.71425</td><td>6.90689</td><td>5.49185</td><td>3.32193</td><td>0.00000</td></tr><tr><td>50x50</td><td>102.87712</td><td>106.19905</td><td>108.36898</td><td>109.78401</td><td>110.59137</td><td>110.85440</td><td>110.59137</td><td>109.78401</td><td>108.36898</td><td>106.19905</td><td>102.87712</td></tr></tbody></table></div><p>And if we look, we will see that the entropy in the 50x50 grid microstate values is just the 2x1 grid values plus a constant. The relative entropy in both cases would be identical. This is even more clear if we mathematically show how the entropy is calculated. For the 2x1 grid we use the equation $\text{log}_2({10 \choose L})$, and for the 50x50 grid we use $\text{log}_2(1250^{10} {10 \choose L}) = \text{log}_2(1250^{10}) + \text{log}_2({10 \choose L})$. Mathematically we can see that it is the same as the entropy of the 2x1 grid offset by $\text{log}_2(1250^{10})$.</p><p>You can imagine if we added another dimension along the microstates that we would increase the entropy again by a constant. For example, if each of the 10 balls could be one of 3 colors, then the number of microstates would grow by a factor of $3^{10}$, and so the entropy of the whole system would increase by $\text{log}_2(3^{10})$.</p><p>Our intuition was correct when we used different microstates that are multiples of each other, but that intuition fails if the microstates are not so neatly multiples of each other. An easy example of this is if we represent the left side of the box as one cell and the right as a 50x25 grid of cells, then the entropy looks very different. Below is the table again, but with the added row of our non-homogenous microstates. An example of how we calculate the entropy of macrostate $(3, 7)$ is: there are 120 equally likely ways to place 3 balls on the left and 7 balls on the right, but the balls on the right can also be in $1250^7$ different states, so the entropy is $\text{log}_2(120 \cdot 1250^7) = 78.920877252$.</p><div><table><thead><tr><th>&nbsp;</th><th>(10,0)</th><th>(9,1)</th><th>(8,2)</th><th>(7,3)</th><th>(6,4)</th><th>(5,5)</th><th>(4,6)</th><th>(3,7)</th><th>(2,8)</th><th>(1,9)</th><th>(0,10)</th></tr></thead><tbody><tr><td>2x1</td><td>0.00000</td><td>3.32193</td><td>5.49185</td><td>6.90689</td><td>7.71425</td><td>7.97728</td><td>7.71425</td><td>6.90689</td><td>5.49185</td><td>3.32193</td><td>0.00000</td></tr><tr><td>50x50</td><td>102.87712</td><td>106.19905</td><td>108.36898</td><td>109.78401</td><td>110.59137</td><td>110.85440</td><td>110.59137</td><td>109.78401</td><td>108.36898</td><td>106.19905</td><td>102.87712</td></tr><tr><td>mixed</td><td>0.00000</td><td>13.60964</td><td>26.06728</td><td>37.77003</td><td>48.86510</td><td>59.41584</td><td>69.44052</td><td>78.92088</td><td>87.79355</td><td>95.91134</td><td>102.87712</td></tr></tbody></table></div><p>A funny thing to note is that when all the balls are on the left, the entropy is zero, but when all the balls are on the right, the entropy is maximized. And again, hopefully, this makes sense from our understanding of entropy, that it measures uncertainty relative to our microstates. If we know all the balls are on the left, then we know they must be in the single left cell, so no uncertainty. If we know the balls are all on the right, then they could be in any of $1250^{10}$ microstates, so high uncertainty.</p><p>Clearly, we need to be careful and aware of what microstates we are choosing when measuring the entropy of a system. Fortunately, for most physical systems we use the standard microstates of a uniform grid of positions and momentums of the balls (particles) in the system. Another standard microstate to use is the continuous space of position and momentum.</p><h3 id="continuous-microstates"><span>Continuous Microstates</span><a href="#continuous-microstates"><i></i></a></h3><p>So far, weâ€™ve looked at discrete sets of microstates â€” such as balls in cells. But in physical systems, microstates are often continuous: positions and momenta can vary over a continuum. How do we compute entropy in this setting? This is not related to the rest of the explanation, but it is an interesting tangent to explore.</p><p>Letâ€™s return to our 10 balls in a 2D box. If each ball can occupy any position in the square, then the microstate of the system is a point in a $20$-dimensional space (2 dimensions per ball). The number of possible microstates is infinite â€” and each individual one has infinitesimal probability.</p><p>In this setting, we use a probability density function $\rho(x)$, and entropy becomes a continuous integral:</p><p>\[S = - \int_X \rho(x) \log_2 \rho(x) \, dx\]</p><p>This is called differential entropy. It generalizes Shannon entropy to continuous systems, though it has some subtleties â€” it can be negative, and itâ€™s not invariant under coordinate transformations.</p><p>If the density is uniform, say $\rho(x) = \frac{1}{V}$ over a region of volume $V$, then the entropy becomes:</p><p>\[S = - \int_X \frac{1}{V} \log_2 \left( \frac{1}{V} \right) dx = \log_2(V)\]</p><p>So entropy still grows with the logarithm of the accessible state volume, just as in the discrete case.</p><p>This formalism is particularly natural in quantum mechanics, where the wavefunction $\psi(x)$ defines a probability density $\rho(x) = |\psi(x)|^2$. Consider a 1D Gaussian wavefunction:</p><p>\[\psi(x) = \left( \frac{1}{\pi \sigma^2} \right)^{1/4} e^{-x^2 / (2 \sigma^2)}\]</p><p>Its entropy (in bits) is:</p><p>\[S = - \int_{-\infty}^{\infty} \rho(x) \log_2 \rho(x) \, dx = \frac{1}{2} \log_2(2 \pi e \sigma^2)\]</p><p>This shows that wider distributions have higher entropy, as expected: a more spread-out wavefunction indicates more uncertainty in the particleâ€™s location.</p><p>For instance:</p><ul><li>If $\sigma = 1$, then $S \approx 2.047$</li><li>If $\sigma = 3$, then $S \approx 3.600$</li></ul><p>Which again should make sense: When we are less certain about a system, like where a particle will be when measured, the more entropy it has.</p><p>And a quick issue to address: If the state space is unbounded, like momentum in classical mechanics, then the entropy can diverge. This isnâ€™t a problem in practice because physical systems typically have probability distributions (like Gaussians) that decay quickly enough at infinity to keep the entropy finite. When thatâ€™s not the case, we either limit the system to a finite region or focus on entropy differences, which remain well-defined even when absolute entropy diverges.</p><p>But letâ€™s get back to our main topic, and weâ€™ll get back into it with a historical overview.</p><h3 id="standard-usage-of-entropy"><span>Standard Usage of Entropy</span><a href="#standard-usage-of-entropy"><i></i></a></h3><p>Eighty years before Claude Shannon developed Information Theory, <a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann</a> formulated a statistical definition of entropy for an ideal gas. He proposed that the entropy $S$ of a system is proportional to the logarithm of the number of microstates $W$ consistent with a given macrostate:</p><p>\[\begin{align} S = k_{B} \ln(W) \label{boltzmann_entropy}\tag{Boltzmann entropy} \end{align}\]</p><p>This equation should look familiar: itâ€™s the equal-probability special case of the Shannon entropy weâ€™ve been using, just with a change of base (from $\log_2$ to $\ln$) and a scaling factor $k_B$ (Boltzmannâ€™s constant). The connection between Boltzmannâ€™s statistical mechanics and Shannonâ€™s information theory is more than historical coincidenceâ€”both quantify uncertainty, whether in physical states or messages.</p><p>A few years later, <a href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Josiah Willard Gibbs</a> generalized Boltzmannâ€™s definition to cases where microstates are not equally likely. His formulation remains the standard definition of entropy in modern physics:</p><p>\[\begin{align} S = -k_B \sum_{i} p_i \ln(p_i) \label{gibbs_entropy}\tag{Gibbs entropy} \end{align}\]</p><p>This is formally identical to Shannon entropy, again differing only in logarithm base and physical units. But Gibbsâ€™s generalization was a profound leap: it enabled thermodynamics to describe systems in contact with heat baths, particle reservoirs, and other environments where probability distributions over microstates are non-uniform. This made entropy applicable far beyond ideal gasesâ€”covering chemical reactions, phase transitions, and statistical ensembles of all kinds.</p><p>Now that we have a formal understanding of entropy with some historical background, letâ€™s try to understand how entropy relates to our universe and in particular to time.</p><h3 id="time"><span>Time</span><a href="#time"><i></i></a></h3><p>How does time play a role in all of this?</p><p>When you drop a spot of milk into tea, it always spreads and mixes, and yet you never see the reverse where the milk molecules spontaneously separate and return to a neat droplet. When ocean waves crash into the shore, the spray and foam disperse, but we never see that chaos reassemble into a coherent wave that launches back into the sea. These examples are drawn from this <a href="https://www.youtube.com/watch?v=ROrovyJXSnM">lecture on entropy</a> by Richard Feynman. If you were shown a reversed video of these events, youâ€™d immediately recognize something was off. This sounds obvious at first, but it actually isnâ€™t clear this should be true if we just look at the laws of physics. All the known laws of physics are time-reversible (the wave function collapse seems to be debatable), which just means that they <em>do</em> look the same playing forward and backward. The individual molecules all obey these time-reversible laws, and yet the cup of tea gets murky from the milk always mixing in.</p><p>This highlights a fundamental paradox: the microscopic laws of physics are time-reversible, but the macroscopic world is not. If you took a video of two atoms bouncing off each other and played it backward, it would still look physically valid, but play a video of milk mixing into coffee backward, and it looks obviously wrong.</p><p>We want to build a simplified model of time in a way that reflects both the time-reversibility of microscopic laws and the time-asymmetry of macroscopic behavior. Letâ€™s imagine the complete state of a physical system, like a box of particles, as a single point in a high-dimensional space called phase space, with each dimension corresponding to a particleâ€™s position and momentum. As time evolves, the system traces out a continuous trajectory through this space.</p><p>The laws of physics, such as Newtonâ€™s equations, Hamiltonian mechanics, or SchrÃ¶dingerâ€™s equation, all govern this trajectory. They are deterministic and time-reversible. That means if you reverse the momenta of all particles at any moment, the system will retrace its path backward through state space.</p><p>So far everything is time-reversible, including this view of how the universe moves through time. But we will see that even in this toy model, time appears to have a preferred direction, an <em>arrow of time</em>.</p><p>The key lies in coarse-graining. When we observe the world, we donâ€™t see every microscopic detail. Instead, we measure macrostates: aggregate properties like temperature, pressure, position of an object, or color distribution in a cup of tea. Each macrostate corresponds to many underlying microstates â€” and not all macrostates are created equal.</p><p>For example, consider a box sliding across the floor and coming to rest due to friction. At the microscopic level, the system is just particles exchanging momentum, and all time-reversible. But we certainly would not call this action time-reversible, we never see a box spontaneously start speeding up from stand-still. But, if we took the moment after the box comes to a rest due to friction, and you reversed the velocities of all the particles (including those in the floor that absorbed the boxâ€™s kinetic energy as heat), the box <em>would</em> spontaneously start moving and slide back to its original position. This would obey Newtonâ€™s laws, but itâ€™s astronomically unlikely. Why?</p><p>The number of microstates where the energy is spread out as heat (the box is at rest, and the molecules in the floor are jiggling) vastly outnumber the microstates where all that energy is coordinated to move the box. The stand-still macrostate has high entropy while the spontaneous-movement macrostate has low entropy. When the system evolves randomly or deterministically from low entropy, it is overwhelmingly likely to move toward higher entropy simply because there are more such microstates.</p><p>If you had perfect knowledge of all particles in the universe (i.e., you lived at the level of microstates), time wouldnâ€™t seem to have a direction. But from the perspective of a coarse-grained observer, like us, entropy tends to increase. And thatâ€™s why a movie of tea mixing looks natural, but the reverse looks fake. At the level of physical laws, both are valid. But one is typical, and one is astronomically rare, all because we coarse-grained.</p><p>To drive the point home, letâ€™s again look at the balls in a box. Weâ€™ll define macrostates by dividing the box into a grid of cells and counting how many balls are in each bin.</p><p>Now suppose the balls move via random small jitters (our toy model of microscopic dynamics). Over time, the system will naturally tend to explore the most probable macrostates, as the most probable macrostates have far more microstates for you to wander into. That is, entropy increases over time, not because of any fundamental irreversibility in the laws, but because high-entropy macrostates are far more typical.</p><p>If we started the simulation with all the balls packed on the left, thatâ€™s a very specific (low entropy) macrostate. As they spread out, the number of compatible microstates grows, and so does the entropy.</p><p>This leads to a crucial realization: Entropy increases because we started in a low-entropy state. This is often called the <a href="https://en.wikipedia.org/wiki/Past_hypothesis">Past Hypothesis</a>, the postulate that the universe began in an extremely low-entropy state. Given that, the Second Law of Thermodynamics follows naturally. The arrow of time emerges not from the dynamics themselves, but from the statistical unlikelihood of reversing them after coarse-graining, and the fact that we began in a low-entropy state.</p><p>You could imagine once a system reaches near-maximum entropy that it no longer looks time-irreversible. The entropy of such a system would <a href="https://en.wikipedia.org/wiki/Fluctuation_theorem">fluctuate a tiny bit</a> since entropy is an inherently statistical measure, but they would be small enough not to notice. For example, while it is clear when a video of milk being poured into tea (a low-entropy macrostate) is playing forward as opposed to backward, you couldnâ€™t tell if a video of already-combined milk and tea (a high-entropy macrostate) being swirled around is playing forward or backward.</p><p>While there are tiny fluctuations in entropy, they are not enough to explain the large-scale phenomena that sometimes seem to violate this principle that we just established of entropy always increasing with time.</p><h3 id="violations-of-the-second-law"><span>Violations of the Second Law?</span><a href="#violations-of-the-second-law"><i></i></a></h3><p>Some real-world examples seem to contradict the claim that entropy always increases. For instance, oil and water separate after mixing, dust clumps into stars and planets, and we build machines like filters and refrigerators that separate mixed substances. Arenâ€™t these violations?</p><p>The issue is we have only been considering the position of molecules, while physical systems have many different properties which allow for more microstates. For example, if we start considering both the position and velocity of balls in a box, then the entropy can be high even while all the balls are on the left side of the box since every ball could have a different velocity. If the balls were all on the left <em>and</em> the velocities were all the same, then the entropy would be low. Once we consider velocity as well, entropy can increase both from more spread out positions and more spread out velocities.</p><p>When water and oil separate, the positions of the molecules separate into top and bottom, which appears to decrease positional entropy. However, this separation actually increases the total entropy of the system. Why? Water molecules strongly prefer to form hydrogen bonds with other water molecules rather than interact with oil molecules. When water molecules are forced to be near oil molecules in a mixed state, they must adopt more constrained arrangements to minimize unfavorable interactions, reducing the number of available microstates. When water and oil separate, water molecules can interact freely with other water molecules in more configurations, and oil molecules can interact with other oil molecules more freely. This increase in available microstates for molecular arrangements and interactions more than compensates for the decrease in positional mixing entropy. So, while the entropy decreases if we only consider the general positions of molecules (mixed versus separated), the total entropy increases when we account for all the molecular interactions, orientations, and local arrangements. This demonstrates why we need to consider all properties of a system when calculating its entropy.</p><p>When stars or planets form together from dust particles floating around in space and clump together from gravity, it would seem that even when we consider position and velocity of the particles that the entropy might be decreasing. Even though the particles speed up to clump together, they slow down after they collide, seemingly decreasing entropy. This is because we are again failing to consider the entire system. When particles collide with each other, their speed decreases a bit by turning that kinetic energy into radiation, causing photons to get sent out into space. If we considered a system where radiation isnâ€™t allowed, then the kinetic energy would just get transferred from one particle to another through changes in velocity, and the entropy of the system would still be increasing because of the faster velocities. Once we start considering the entropy of the position, velocity, and <em>all</em> particles in a system, we can consider <em>all</em> the microstates that are equally likely and calculate the correct entropy.</p><p>Similarly, once we consider the entire system around a refrigerator, the decrease in entropy disappears. The entropy from the power generated to run the refrigerator and the heat moved from the inside to the outside of the refrigerator will offset the decrease in entropy caused by cooling the inside of the refrigerator. Local decreases in entropy <em>can</em> be generated, as long as the entropy of the entire system is still increasing.</p><p>Ensure that the entire system is being considered when analyzing the entropy of a system, with the position, velocity, other interactions of particles, that all particles are included, and that the entire system is actually being analyzed.</p><h3 id="disorder"><span>Disorder</span><a href="#disorder"><i></i></a></h3><p>Entropy is sometimes described as â€œdisorder,â€ but this analogy is imprecise and often misleading. In statistical mechanics, entropy has a rigorous definition: it quantifies the number of microstates compatible with a given macrostate. That is, entropy measures our uncertainty about the exact microscopic configuration of a system given some coarse-grained, macroscopic description.</p><p>So where does the idea of â€œdisorderâ€ come from?</p><p>Empirically, macrostates we label as â€œdisorderedâ€ often correspond to a vastly larger number of microstates than those we consider â€œorderedâ€. For example, in a childâ€™s room, there are many more configurations where toys are scattered randomly than ones where everything is neatly shelved. Since the scattered room corresponds to more microstates, it has higher entropy.</p><p>But this connection between entropy and disorder is not fundamental. The problem is that â€œdisorderâ€ is subjectiveâ€”it depends on human perception, context, and labeling. For instance, in our earlier example of 1000 balls bouncing around a box, a perfectly uniform grid of balls would have high entropy due to the huge number of possible microstates realizing it. And yet to a human observer, such a grid might appear highly â€œordered.â€</p><p>The key point is: entropy is objective and well-defined given a macrostate and a set of microstates, while â€œdisorderâ€ is a human-centric heuristic concept that sometimes, but not always, tracks entropy. Relying on â€œdisorderâ€ to explain entropy risks confusion, especially in systems where visual symmetry or regularity masks the underlying statistical structure.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>So here are some thoughts in regard to some common statements made about entropy:</p><ul><li>Entropy is a measure of disorder.<ul><li>â€œdisorderâ€ is a subjective term for states of a system that humans donâ€™t find useful/nice, and usually has much higher entropy than the â€œorderedâ€ macrostate that humans create. Because of this, when entropy increases, it is more likely that we end up in disordered state, although not guaranteed.</li></ul></li><li>Entropy always increases in a closed system.<ul><li>This is a statistical statement that for all practical purposes is true, but is not guaranteed and can fail when you look at very small isolated systems or measure down to the smallest details of a system. It also assumes you started in a low-entropy state, giving your system space to increase in entropy. This has the neat implication that since our universe has been observed to be increasing in entropy, it must have begun in a low-entropy state.</li></ul></li><li>Heat flows from hot to cold because of entropy.<ul><li>Heat flows from hot to cold because the number of ways in which the system can be non-uniform in temperature is much lower than the number of ways it can be uniform in temperature, and so as the system â€œrandomlyâ€ moves to new states, it will statistically end up in states that are more uniform.</li></ul></li><li>Entropy is the only time-irreversible law of physics.<ul><li>All the fundamental laws of physics are time-reversible, but by coarse-graining and starting from a lower-entropy state, a system will statistically move to a higher-entropy state. This means if a system is already in a near-maximum entropy state (either because of its configuration or because of the choice for coarse-graining) or we donâ€™t coarse-grain, then entropy will not look time-irreversible.</li></ul></li></ul><p>And here is some further reading, all of which I found supremely helpful in learning about entropy.</p><ul><li><a href="https://www.youtube.com/watch?v=ROrovyJXSnM">Lecture on entropy by Richard Feynman</a></li><li><a href="https://scholar.harvard.edu/files/schwartz/files/6-entropy.pdf">Lecture notes on entropy from the Statistical Mechanics course at Harvard taught by Matthew Schwartz</a></li><li><a href="https://math.ucr.edu/home/baez/what_is_entropy.pdf">A both friendly and rigorous textbook on entropy by John C. Baez</a></li><li><a href="https://www.youtube.com/watch?v=VCXqELB3UPg">A youtube video on entropy using actual balls bouncing in a box</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harvard's response to federal government letter demanding changes (1183 pts)]]></title>
            <link>https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</link>
            <guid>43684536</guid>
            <pubDate>Mon, 14 Apr 2025 18:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/">https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</a>, See on <a href="https://news.ycombinator.com/item?id=43684536">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

			<div>
				
<div><p>Dear Members of the Harvard Community,</p><p>&nbsp;For three-quarters of a century, the federal government has awarded grants and contracts to Harvard and other universities to help pay for work that, along with investments by the universities themselves, has led to groundbreaking innovations across a wide range of medical, engineering, and scientific fields. These innovations have made countless people in our country and throughout the world healthier and safer. In recent weeks, the federal government has threatened its partnerships with several universities, including Harvard, over accusations of antisemitism on our campuses. These partnerships are among the most productive and beneficial in American history. New frontiers beckon us with the prospect of life-changing advancesâ€”from treatments for diseases such as Alzheimerâ€™s, Parkinsonâ€™s, and diabetes, to breakthroughs in artificial intelligence, quantum science and engineering, and numerous other areas of possibility. For the government to retreat from these partnerships now risks not only the health and well-being of millions of individuals but also the economic security and vitality of our nation.</p><p>&nbsp;Late Friday night, the administration issued an updated and expanded list of demands, warning that Harvard must comply if we intend to â€œmaintain [our] financial relationship with the federal government.â€ It makes clear that the intention is not to work with us to address antisemitism in a cooperative and constructive manner. Although some of the demands outlined by the government are aimed at combating antisemitism, the majority represent direct governmental regulation of the â€œintellectual conditionsâ€ at Harvard.</p><p>&nbsp;I encourage you to&nbsp;<a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf" target="_blank" rel="noreferrer noopener">read the letter</a>&nbsp;to gain a fuller understanding of the unprecedented demands being made by the federal government to control the Harvard community. They include requirements to â€œauditâ€ the viewpoints of our student body, faculty, staff, and to â€œreduc[e] the powerâ€ of certain students, faculty, and administrators targeted because of their ideological views. We have informed the administration through our legal counsel that&nbsp;<a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Harvard-Response-2025-04-14.pdf" target="_blank" rel="noreferrer noopener">we will not accept their proposed agreement</a>. The University will not surrender its independence or relinquish its constitutional rights.</p><p>&nbsp;The administrationâ€™s prescription goes beyond the power of the federal government. It violates Harvardâ€™s First Amendment rights and exceeds the statutory limits of the governmentâ€™s authority under Title VI. And it threatens our values as a private institution devoted to the pursuit, production, and dissemination of knowledge. No governmentâ€”regardless of which party is in powerâ€”should dictate what private universities can teach, whom they can admit and hire, and which areas of study and inquiry they can pursue.</p><p>&nbsp;Our mottoâ€”Veritas, or truthâ€”guides us as we navigate the challenging path ahead. Seeking truth is a journey without end. It requires us to be open to new information and different perspectives, to subject our beliefs to ongoing scrutiny, and to be ready to change our minds. It compels us to take up the difficult work of acknowledging our flaws so that we might realize the full promise of the University, especially when that promise is threatened.</p><p>&nbsp;We have made it abundantly clear that we do not take lightly our moral duty to fight antisemitism. Over the past fifteen months, we have taken many steps to address antisemitism on our campus. We plan to do much more. As we defend Harvard, we will continue to:&nbsp;</p></div>



<ul>
<li>nurture a thriving culture of open inquiry on our campus; develop the tools, skills, and practices needed to engage constructively with one another; and broaden the intellectual and viewpoint diversity within our community;&nbsp;</li>



<li>affirm the rights and responsibilities we share; respect free speech and dissent while also ensuring that protest occurs in a time, place, and manner that does not interfere with teaching, learning, and research; and enhance the consistency and fairness of disciplinary processes; and&nbsp;</li>



<li>work together to find ways, consistent with law, to foster and support a vibrant community that exemplifies, respects, and embraces difference. As we do, we will also continue to comply with&nbsp;<em>Students For Fair Admissions v. Harvard</em>, which ruled that Title VI of the Civil Rights Act makes it unlawful for universities to make decisions â€œon the basis of race.â€&nbsp;</li>
</ul>



<div><p>These ends will not be achieved by assertions of power, unmoored from the law, to control teaching and learning at Harvard and to dictate how we operate. The work of addressing our shortcomings, fulfilling our commitments, and embodying our values is ours to define and undertake as a community. Freedom of thought and inquiry, along with the governmentâ€™s longstanding commitment to respect and protect it, has enabled universities to contribute in vital ways to a free society and to healthier, more prosperous lives for people everywhere. All of us share a stake in safeguarding that freedom. We proceed now, as always, with the conviction that the fearless and unfettered pursuit of truth liberates humanityâ€”and with faith in the enduring promise that Americaâ€™s colleges and universities hold for our country and our world.</p><p>&nbsp;Sincerely,<br>Alan M. Garber</p></div>
			</div>

			

			
		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal Government's letter to Harvard demanding changes [pdf] (147 pts)]]></title>
            <link>https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf</link>
            <guid>43684386</guid>
            <pubDate>Mon, 14 Apr 2025 18:13:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf">https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43684386">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Web Server (126 pts)]]></title>
            <link>https://simplewebserver.org/</link>
            <guid>43684009</guid>
            <pubDate>Mon, 14 Apr 2025 17:43:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simplewebserver.org/">https://simplewebserver.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43684009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Run multiple &amp; in the background</h2><p>Run multiple web servers at the same time, even when the app is closed.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AudioX: Diffusion Transformer for Anything-to-Audio Generation (135 pts)]]></title>
            <link>https://zeyuet.github.io/AudioX/</link>
            <guid>43683907</guid>
            <pubDate>Mon, 14 Apr 2025 17:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zeyuet.github.io/AudioX/">https://zeyuet.github.io/AudioX/</a>, See on <a href="https://news.ycombinator.com/item?id=43683907">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <!-- <section class="hero"> -->
  <section>
    <!-- <div class="hero-body"> -->
    <div>
          
          

          <p><span><sup>1</sup>HKUST</span>
          </p>

          <p><span><sup>â€ </sup>Corresponding authors
            </span>
          </p>
          
        </div>
    
    <!-- </section> -->

    <div>
        <!-- Abstract. -->
        <div>
            <h2>Abstract</h2>
            <p>
                Audio and music generation have emerged as crucial tasks in many applications, yet existing approaches face significant limitations: they operate in isolation without unified capabilities across modalities, suffer from scarce high-quality, multi-modal training data, and struggle to effectively integrate diverse inputs. In this work, we propose AudioX, a unified Diffusion Transformer model for Anything-to-Audio and Music Generation. Unlike previous domain-specific models, AudioX can generate both general audio and music with high quality, while offering flexible natural language control and seamless processing of various modalities including text, video, image, music, and audio. Its key innovation is a multi-modal masked training strategy that masks inputs across modalities and forces the model to learn from masked inputs, yielding robust and unified cross-modal representations. To address data scarcity, we curate two comprehensive datasets: vggsound-caps with 190K audio captions based on the VGGSound dataset, and V2M-caps with 6 million music captions derived from the V2M dataset. Extensive experiments demonstrate that AudioX not only matches or outperforms state-of-the-art specialized models, but also offers remarkable versatility in handling diverse input modalities and generation tasks within a unified architecture. 
              </p>
          </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <div>
            <h2>Demo Video</h2>
    
            
    
          </div>

        <!--/ Paper video. -->
      </div>

    <div>
    

            

            
  <!-- å•ä¸ªä»»åŠ¡ç¤ºä¾‹ï¼šText-to-Audio Generation -->
  <div>
    <!-- å¤–å±‚å®¹å™¨ï¼Œå¸¦è¾¹æ¡† -->


      <!-- ä»»åŠ¡æ ‡é¢˜ -->
      <h2>Text-to-Audio Generation</h2>

      <!-- é¢„è§ˆåŒºåŸŸï¼š2-3ä¸ªç¤ºä¾‹ -->
      <div>
          <!-- ç¤ºä¾‹3 -->
          <div>
            <p><strong>Prompt:</strong>
              <br>  
              Thunder and rain during a sad piano solo</p>
            </div>          
          <!-- ç¤ºä¾‹1 -->
          <div>
            <p><strong>Prompt:</strong>
              <br>  
              Typing on a keyboard</p>
            </div>
          <!-- ç¤ºä¾‹2 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Ocean waves crashing</p>
            </div>           
     

        </div>

      <!-- æŠ˜å æŒ‰é’®ï¼šç‚¹å‡»å±•å¼€æ›´å¤šæ ·æœ¬ -->
      <!-- æŠ˜å å†…å®¹ï¼šæ›´å¤š sampleï¼Œå¸¦ carousel -->
      <div>

            <div>
              <p><strong>Prompt:</strong>
                A person is snoring</p>
              </div>              
            <div>
              <p><strong>Prompt:</strong> A toilet flushing</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> Rain falling on a rooftop</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> An airplane is taking flight</p>
              </div>                                                   
            <div>
              <p><strong>Prompt:</strong> An explosion and crackling</p>
              </div>
            
            <div>
              <p><strong>Prompt:</strong> Footsteps in snow</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> A cat meowing repeatedly</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> Food and oil sizzling</p>
              </div>
            <!-- ç»§ç»­æ·»åŠ æ›´å¤š sample-item ... -->
          </div>

  </div>


  <!-- å•ä¸ªä»»åŠ¡ç¤ºä¾‹ï¼šText-to-Music Generation -->
  <div>
    <!-- å¤–å±‚å®¹å™¨ï¼Œå¸¦è¾¹æ¡† -->

      <!-- ä»»åŠ¡æ ‡é¢˜ -->
      <h2>Text-to-Music Generation</h2>

      <!-- é¢„è§ˆåŒºåŸŸï¼š2-3ä¸ªç¤ºä¾‹ -->
      <div>
          <!-- ç¤ºä¾‹1 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Orchestral, epic, with drums, strings, 
              <br>  
              and brass</p>
            </div>
          <!-- ç¤ºä¾‹2 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Electronic dance music with synthesizers, bass, drums, and a slow build-up</p>
            </div>
          <!-- ç¤ºä¾‹3 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Sad emotional soundtrack with ambient textures and solo cello</p>
            </div>
        </div>

      <!-- æŠ˜å æŒ‰é’®ï¼šç‚¹å‡»å±•å¼€æ›´å¤šæ ·æœ¬ -->
      <!-- æŠ˜å æŒ‰é’®ï¼šç‚¹å‡»å±•å¼€æ›´å¤šæ ·æœ¬ -->
      <!-- æŠ˜å å†…å®¹ï¼šæ›´å¤š sampleï¼Œå¸¦ carousel -->
      <div>
            <div>
              <p><strong>Prompt:</strong> 
                A suspenseful scene in a haunted mansion</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                An orchestral music piece for a fantasy world</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                
                Uplifting ukulele tune for a travel vlog</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                
                Romantic acoustic guitar music for a sunset scene</p>
              </div>                                                
            <div>
              <p><strong>Prompt:</strong> 
                Smooth urban R&amp;B beat with a mellow groove</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> 
                Produce upbeat electronic music for a dance party</p>
              </div>
            
            <div>
              <p><strong>Prompt:</strong> 
                Playful 8-bit chiptune music for a retro platformer game</p>
              </div> 
            
            <div>
              <p><strong>Prompt:</strong> 
                Ambient synth music in a deep space setting</p>
              </div>             
            <!-- ç»§ç»­æ·»åŠ æ›´å¤š sample-item ... -->
          </div>


  </div>




    
            <!-- Video-to-Audio Generation -->
            <div>

                <h2>Video-to-Audio Generation</h2>
                

      <!-- æŠ˜å æŒ‰é’®ï¼šç‚¹å‡»å±•å¼€æ›´å¤šæ ·æœ¬ -->
      <!-- æŠ˜å å†…å®¹ï¼šæ›´å¤š sampleï¼Œå¸¦ carousel -->
      

            </div>
    
            <!-- Video-to-Music Generation -->
            <div>

                <h2>Video-to-Music Generation</h2>
                
      <!-- æŠ˜å æŒ‰é’®ï¼šç‚¹å‡»å±•å¼€æ›´å¤šæ ·æœ¬ -->
      <!-- æŠ˜å å†…å®¹ï¼šæ›´å¤š sampleï¼Œå¸¦ carousel -->
      
          </div>
    




    </div>
    
    
    
    
    

    
    <div>
            <h2>Teaser</h2>
            <!-- <div class="columns is-centered"> -->
            <p><img src="https://zeyuet.github.io/AudioX/static/images/teaser.png" alt="Teaser." height="100%" width="100%"></p><p>
                (a) Overview of AudioX, illustrating its capabilities across various tasks. (b) Radar chart comparing the performance of different methods across multiple benchmarks. AudioX demonstrates superior Inception Scores (IS) across a diverse set of datasets in audio and music generation tasks.
              </p>
          </div>

    <div>
            <h2>Method</h2>
            <!-- <div class="columns is-centered"> -->
            <p><img src="https://zeyuet.github.io/AudioX/static/images/method-.png" alt="Method." height="100%" width="100%"></p><p>
                The AudioX Framework.
              </p>
          </div>


    <div id="BibTeX">
        <h2>BibTeX</h2>
        <p>
          If you find our work useful, please consider citing:</p>
        <pre><code>@article{tian2025audiox,
          title={AudioX: Diffusion Transformer for Anything-to-Audio Generation},
          author={Tian, Zeyue and Jin, Yizhu and Liu, Zhaoyang and Yuan, Ruibin and Tan, Xu and Chen, Qifeng and Xue, Wei and Guo, Yike},
          journal={arXiv preprint arXiv:2503.10522},
          year={2025}
        }</code></pre>
      </div>



    
    
    
    

    






</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Podman Quadlets with Podman Desktop (150 pts)]]></title>
            <link>https://podman-desktop.io/blog/podman-quadlet</link>
            <guid>43683641</guid>
            <pubDate>Mon, 14 Apr 2025 17:16:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://podman-desktop.io/blog/podman-quadlet">https://podman-desktop.io/blog/podman-quadlet</a>, See on <a href="https://news.ycombinator.com/item?id=43683641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p><img decoding="async" loading="lazy" alt="banner" src="https://podman-desktop.io/assets/images/banner-b4811c66dc40efde426f577bd07fc7fd.png" width="1216" height="832"></p>
<p>Containers are typically deployed in Kubernetes clusters.
However, for smaller-scale use cases such as on a single-node server or during development, Kubernetes can be overkill.</p>
<p>Whatâ€™s a more lightweight solution for running autonomous applications with multiple interacting containers?</p>
<p>In this blog, we'll dive into what Quadlets are, their benefits, and how to use them within Podman Desktop.</p>
<h2 id="what-are-quadlets">What Are Quadlets?<a href="#what-are-quadlets" aria-label="Direct link to What Are Quadlets?" title="Direct link to What Are Quadlets?">â€‹</a></h2>
<p>Podman Quadlets allow you to manage containers declaratively using systemd<sup><a href="#user-content-fn-1-4453df" id="user-content-fnref-1-4453df" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>.
Since version 4.4, Podman can create, start, and manage containers (including pulling images, creating volumes, and managing pods) through systemd.</p>
<p>Quadlets are simplified configuration filesâ€”recognized by their specific extensions,
such as <code>*.container</code>, <code>*.pod</code>, or <code>*.image</code> that are processed during startup or when you reload the daemon using the <code>systemctl daemon-reload</code> command.</p>
<p>Quadlets generate the equivalent systemd unit files, streamlining the container management process.</p>
<h3 id="why-use-quadlets">Why Use Quadlets?<a href="#why-use-quadlets" aria-label="Direct link to Why Use Quadlets?" title="Direct link to Why Use Quadlets?">â€‹</a></h3>
<ul>
<li><strong>Declarative Configuration</strong>: Similar to Compose or Kubernetes manifests, Quadlets allow you to declare what you want to run, simplifying the workload setup.</li>
<li><strong>Tight System Integration</strong>: Quadlets align with Podmanâ€™s philosophy of integrating seamlessly with Linux, leveraging systemdâ€™s process management capabilities.</li>
<li><strong>Ease of Automation</strong>: Quadlets make it simple to configure containers to start at boot, restart on failure, and more.</li>
</ul>
<h3 id="example-a-quadlet-file-for-nginx">Example: A Quadlet File for Nginx<a href="#example-a-quadlet-file-for-nginx" aria-label="Direct link to Example: A Quadlet File for Nginx" title="Direct link to Example: A Quadlet File for Nginx">â€‹</a></h3>
<p>Below is an example of an <code>nginx.container</code> Quadlet file, which starts an nginx container at boot:</p>
<div><p>~/.config/containers/systemd/nginx.container</p><div><pre tabindex="0"><code><span><span># nginx.container</span><br></span><span><span>[Container]</span><br></span><span><span>ContainerName=nginx</span><br></span><span><span>Image=nginx</span><br></span><span><span>PublishPort=80:8080</span><br></span><span><span></span><br></span><span><span>[Service]</span><br></span><span><span>Restart=always</span><br></span></code></pre></div></div>
<p>This configuration ensures the container restarts automatically if stopped, and exposes port 8080.</p>
<h2 id="using-the-podman-quadlet-extension-in-podman-desktop">Using the Podman Quadlet Extension in Podman Desktop<a href="#using-the-podman-quadlet-extension-in-podman-desktop" aria-label="Direct link to Using the Podman Quadlet Extension in Podman Desktop" title="Direct link to Using the Podman Quadlet Extension in Podman Desktop">â€‹</a></h2>
<p>Managing Quadlets directly on non-Linux platforms can be challenging due to virtualized environments (e.g., WSL or Hyper-V).
Fortunately, the Podman Desktop extension Podman Quadlet simplifies this process, enabling you to list, generate, and edit Quadlets visually.</p>
<h3 id="key-features-of-the-extension">Key Features of the Extension<a href="#key-features-of-the-extension" aria-label="Direct link to Key Features of the Extension" title="Direct link to Key Features of the Extension">â€‹</a></h3>
<ul>
<li><strong>Integration with Podlet</strong>: Generates Quadlets from existing Podman objects<sup><a href="#user-content-fn-2-4453df" id="user-content-fnref-2-4453df" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>.</li>
<li><strong>Quadlet Management UI</strong>: Provides a dedicated interface to list, edit, delete, start, and stop Quadlets.</li>
<li><strong>Logs Viewer</strong>: Fetches and displays systemd logs using journalctl for troubleshooting.</li>
</ul>
<h3 id="installation">Installation<a href="#installation" aria-label="Direct link to Installation" title="Direct link to Installation">â€‹</a></h3>
<p>If you already have the latest version of Podman Desktop, you can <a href="podman-desktop:extension/podman-desktop.quadlet"><strong>click here to install the Podman Quadlet extension</strong></a>.</p>
<p>Alternatively, navigate to the Extensions page within Podman Desktop to install it.</p>
<h3 id="list-quadlets-clipboard">List Quadlets <!-- -->ðŸ“‹<a href="#list-quadlets-clipboard" aria-label="Direct link to list-quadlets-clipboard" title="Direct link to list-quadlets-clipboard">â€‹</a></h3>
<p>On the Podman Quadlet page, you can view all the Quadlets available across your Podman machines. To update the list, click <strong>Refresh</strong>.</p>
<p><img src="https://podman-desktop.io/assets/images/podman-quadlet-home-light-dd43d64eaf29d2f9b622f501dff42ffb.png" alt="Quadlets List"><img src="https://podman-desktop.io/assets/images/podman-quadlet-home-dark-c9e82c34f0facb36b072159c54b56ce9.png" alt="Quadlets List"></p><p>In Podman Desktop, you can see that a dedicated icon is used for the containers managed by a Quadlet.</p>
<p><img src="https://podman-desktop.io/assets/images/container-icon-quadlet-light-b86c5a14b2a3f6583a0efa67e6b87b28.png" alt="Container Quadlet Icon"><img src="https://podman-desktop.io/assets/images/container-icon-quadlet-dark-813e9532612012aad3a46278d8db8f2d.png" alt="Container Quadlet Icon"></p><h3 id="generate-quadlets-hammer">Generate Quadlets <!-- -->ðŸ”¨<a href="#generate-quadlets-hammer" aria-label="Direct link to generate-quadlets-hammer" title="Direct link to generate-quadlets-hammer">â€‹</a></h3>
<p>To generate a Quadlet from an existing container, youâ€™ll need to install <a href="https://github.com/containers/podlet" target="_blank" rel="noopener noreferrer">Podlet</a>. The extension simplifies installation.</p>
<p>Use one of the following ways to install Podlet:</p>
<ul>
<li>Go to <strong> Settings &gt; CLI Tools</strong> and install Podlet using the Podman Quadlet extension.</li>
<li>Download Podlet manually from its <a href="https://github.com/containers/podlet/releases" target="_blank" rel="noopener noreferrer">GitHub release page</a>.</li>
</ul>
<p><img src="https://podman-desktop.io/assets/images/cli-podlet-light-c3a1435d0d7961b4a62a38e29ffd63fc.png" alt="Podlet Installation"><img src="https://podman-desktop.io/assets/images/cli-podlet-dark-58159bbeed8fc3dda26e0e88dfe891ca.png" alt="Podlet Installation"></p><h4 id="example-generate-a-container-quadlet">Example: Generate a Container Quadlet<a href="#example-generate-a-container-quadlet" aria-label="Direct link to Example: Generate a Container Quadlet" title="Direct link to Example: Generate a Container Quadlet">â€‹</a></h4>
<ol>
<li>Start a container using Podman:</li>
</ol>
<div><pre tabindex="0"><code><span><span>podman</span><span> run </span><span>--name</span><span> nginx-demo </span><span>-d</span><span> </span><span>-p</span><span> </span><span>80</span><span>:8080 nginx</span><br></span></code></pre></div>
<ol start="2">
<li>In Podman Desktop, find your container on the Containers page.</li>
<li>Click the <strong>overflow menu</strong> icon and select <strong>Generate Quadlet</strong>.</li>
</ol>
<p><img src="https://podman-desktop.io/assets/images/generate-quadlet-action-light-9d7bc4b162aa72adeb6d1bf91f72acd7.png" alt="Container actions"><img src="https://podman-desktop.io/assets/images/generate-quadlet-action-dark-76b7699d969dd5f80fd28c6b3acd1fe2.png" alt="Container actions"></p><ol start="4">
<li>Click <strong>Generate</strong> to finalize the Quadlet.</li>
</ol>
<p><img src="https://podman-desktop.io/assets/images/generate-form-options-light-e09f8de6226947ec69a1548ff8624a0e.png" alt="Quadlet Generate Form"><img src="https://podman-desktop.io/assets/images/generate-form-options-dark-53ccd0966f5fbee1dbd9f9e5223d80d1.png" alt="Quadlet Generate Form"></p><ol start="5">
<li>Optional: Edit the Quadlet configuration details.</li>
<li>Click <strong>Load into machine</strong>.</li>
</ol>
<p><img src="https://podman-desktop.io/assets/images/generate-form-edit-light-a63038e484f23e452c00c67c2f4ea2ff.png" alt="Quadlet Generate Form"><img src="https://podman-desktop.io/assets/images/generate-form-edit-dark-ebea360be56e8a803c6e5fdd677ca98c.png" alt="Quadlet Generate Form"></p><p>Congrats ðŸŽ‰ you created your first Quadlet!</p>
<h3 id="edit-quadlets-pen">Edit Quadlets <!-- -->ðŸ–Š<a href="#edit-quadlets-pen" aria-label="Direct link to edit-quadlets-pen" title="Direct link to edit-quadlets-pen">â€‹</a></h3>
<p>Click the Quadlet <strong>STATUS</strong> icon to view its details page, which has three tabs:</p>
<ul>
<li><strong>Generated</strong>: View the systemd unit generated by Podman (read-only).</li>
<li><strong>Source</strong>: Edit the Quadlet file directly.</li>
<li><strong>Logs</strong>: Monitor logs for the service using journalctl.</li>
</ul>
<p>You can make changes to the Quadletâ€™s source file and apply updates as needed.</p>
<p><img src="https://podman-desktop.io/assets/images/quadlet-details-source-light-c4da0f3f8b8a56d3cc4c3dff0fa5c796.png" alt="Quadlet Details Source"><img src="https://podman-desktop.io/assets/images/quadlet-details-source-dark-b1496cbe3e4692864ad17d1675a71e6d.png" alt="Quadlet Details Source"></p><h3 id="view-quadlet-logs-scroll">View Quadlet Logs <!-- -->ðŸ“œ<a href="#view-quadlet-logs-scroll" aria-label="Direct link to view-quadlet-logs-scroll" title="Direct link to view-quadlet-logs-scroll">â€‹</a></h3>
<p>Since a Quadlet's corresponding resource is managed by systemd we can access corresponding unit's logs using journalctl.</p>
<p><img src="https://podman-desktop.io/assets/images/quadlet-details-logs-light-017268786f1d799f5e324c1fae9b7989.png" alt="Quadlet Details Logs"><img src="https://podman-desktop.io/assets/images/quadlet-details-logs-dark-ddad799f50f58aa48e7e931de1c052b1.png" alt="Quadlet Details Logs"></p><h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>Podman Quadlets provide a powerful way to manage containers declaratively with systemd, bridging the gap between lightweight container management and full orchestration tools like Kubernetes.</p>
<p>With the Podman Quadlet extension in Podman Desktop, users gain a convenient interface to manage Quadlets visually, reducing complexity and saving time.</p>
<p>Try it today and streamline your container workflows!</p>
<!-- -->
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1-4453df">
<p><a href="https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html" target="_blank" rel="noopener noreferrer">https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html</a> <a href="#user-content-fnref-1-4453df" data-footnote-backref="" aria-label="Back to reference 1">â†©</a></p>
</li>
<li id="user-content-fn-2-4453df">
<p><a href="https://github.com/containers/podlet" target="_blank" rel="noopener noreferrer">https://github.com/containers/podlet</a> <a href="#user-content-fnref-2-4453df" data-footnote-backref="" aria-label="Back to reference 2">â†©</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4.1 in the API (587 pts)]]></title>
            <link>https://openai.com/index/gpt-4-1/</link>
            <guid>43683410</guid>
            <pubDate>Mon, 14 Apr 2025 17:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/gpt-4-1/">https://openai.com/index/gpt-4-1/</a>, See on <a href="https://news.ycombinator.com/item?id=43683410">Hacker News</a></p>
Couldn't get https://openai.com/index/gpt-4-1/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. and El Salvador Say They Won't Return Man Who Was Mistakenly Deported (256 pts)]]></title>
            <link>https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs</link>
            <guid>43683405</guid>
            <pubDate>Mon, 14 Apr 2025 17:01:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs">https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs</a>, See on <a href="https://news.ycombinator.com/item?id=43683405">Hacker News</a></p>
Couldn't get https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Is a Systemic Risk to the Tech Industry (111 pts)]]></title>
            <link>https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/</link>
            <guid>43683071</guid>
            <pubDate>Mon, 14 Apr 2025 16:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/">https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/</a>, See on <a href="https://news.ycombinator.com/item?id=43683071">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p><strong><em>Before we go any further: I hate to ask you to do this, but I need your help â€” I'm up for this year's Webbys for the best business podcast award. I know it's a pain in the ass, but</em></strong><a href="https://vote.webbyawards.com/PublicVoting?ref=wheresyoured.at#/2025/podcasts/individual-episode/business"><strong><em> <u>can you sign up and vote for Better Offline</u></em></strong></a><strong><em>? I have never won an award in my life, so help me win this one.</em></strong></p><hr><p><strong><em>Soundtrack: </em></strong><a href="https://www.youtube.com/watch?v=L4PztrhXkXohttps%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DL4PztrhXkXo&amp;ref=wheresyoured.at"><strong><em><u>Mastodon - High Road</u></em></strong></a></p><hr><p>I wanted to start this newsletter with a pithy anecdote about chaos, both that caused by Donald Trump's tariffs and the brittle state of the generative AI bubble.</p><p>Instead, I am going to write down some questions, and make an attempt to answer them.</p><h2 id="how-much-cash-does-openai-have"><strong>How Much Cash Does OpenAI Have?</strong></h2><p>Last week, OpenAI closed "<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?ref=wheresyoured.at"><u>the largest private tech funding round in history</u></a>," where it "raised"&nbsp; an astonishing "$40 billion," and the reason that I've put quotation marks around it is that OpenAI has only raised $10 billion of the $40 billion, with the rest arriving by "the end of the year."&nbsp;</p><p>The remaining $30 billion â€” $20 billion of which will (allegedly) be provided by SoftBank â€” is partially contingent on OpenAI's conversion from a non-profit to a for-profit by the end of 2025, and if it fails,<a href="https://www.cnbc.com/2025/03/31/openai-funding-could-be-cut-by-10-billion-if-for-profit-move-lags.html?ref=wheresyoured.at"> <u>SoftBank will only give OpenAI a further $20 billion</u></a>. The round also valued OpenAI at $300 billion.</p><p>To put that in context, OpenAI had revenues of $4bn in 2024. This deal <em>values OpenAI at 75 times its revenue</em>. Thatâ€™s a bigger gulf than Tesla at its peak market cap â€” a company that was, in fact, worth more than all other legacy car manufacturers combined, despite making far less than them, and shipping a fraction of their vehicles.&nbsp;</p><p>I also want to add that, as of writing this sentence,<strong> this money is yet to arrive.</strong><a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><strong> </strong><u>SoftBank's filings</u></a> say that the money will arrive mid-April â€” and that SoftBank would be borrowing as much as $10 billion to finance the round, with the option to syndicate part of it to other investors. For the sake of argument, I'm going to assume this money actually arrives.</p><p>Filings also suggest that "in certain circumstances" the second ($30 billion) tranche could arrive "in early 2026." This isn't great. <strong>It also seems that SoftBank's $10 billion commitment is contingent on getting a loan, "...financed through borrowings from Mizuho Bank, Ltd., among other financial institutions."</strong></p><p><a href="https://www.theverge.com/openai/640894/chatgpt-has-hit-20-million-paid-subscribers?ref=wheresyoured.at"><u>OpenAI also revealed it now has 20 million paying subscribers</u></a> and over 500 million weekly active users. If you're wondering why it doesnâ€™t talk about <em>monthly</em> active users, it's because they'd likely be much higher than 500 million, which would<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=It%20would%20also%20suggest%20a%20conversion%20rate%20of%202.583%25%20from%20free%20to%20paid%20users%20on%20ChatGPT%20%E2%80%94%20an%20astonishingly%20bad%20number%2C%20one%20made%20worse%20by%20the%20fact%20that%20every%20single%20user%20of%20ChatGPT%2C%20regardless%20of%20whether%20they%20pay%2C%20loses%20the%20company%20money."> <u>reveal exactly how poorly OpenAI converts free ChatGPT users to paying ones</u></a>, and how few people use ChatGPT in their day-to-day lives.</p><p>The Information reported back in January that<a href="https://www.theinformation.com/articles/openai-tightens-grip-on-high-end-of-app-market-muratis-startup-gets-a-name?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>OpenAI was generating $25 million in revenue a month from its $200-a-month "Pro" subscribers</u></a> (<a href="https://techcrunch.com/2025/01/05/openai-is-losing-money-on-its-pricey-chatgpt-pro-plan-ceo-sam-altman-says/?ref=wheresyoured.at"><u>it still loses money on every one of them</u></a>), suggesting around 125,000 ChatGPT Pro subscribers. Assuming the other 19,875,000 users are paying $20 a month, that puts its revenue at about $423 million a month, or about $5 billion a year, from ChatGPT subscriptions.&nbsp;</p><p>This is what reporters mean when they say "annualized revenue" by the way â€” it's literally the monthly revenue multiplied by 12.</p><p><a href="https://www.bloomberg.com/news/articles/2025-03-26/openai-expects-revenue-will-triple-to-12-7-billion-this-year?ref=wheresyoured.at"><u>Bloomberg reported recently that OpenAI expects its 2025 revenue to "triple" to $12.7 billion this year</u></a>.<a href="https://www.wheresyoured.at/oai-business/#:~:text=Licensing%20Access%20To%20Models%20And%20Services%20%E2%80%94%2027%25%20of%20revenue%20(approximately%20%241%20billion)."> <u>Assuming a similar split of revenue to 2024</u></a>, this would require OpenAI to nearly double its annualized subscription revenue from Q1 2025 (from $5 billion to around $9.27 billion) <strong>and nearly quadruple API revenue </strong>(from 2024's revenue of $1 billion, which includes Microsoft's 20% payment for access to OpenAI's models, to $3.43 billion).</p><p>While these are messy numbers, it's unclear how OpenAI intends to pull this off.</p><p>The Information reported in February<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>that it planned to do so by making $3 billion a year selling "agents,"</u></a> with ChatGPT subscriptions ($7.9 billion) and API calls ($1.8 billion) making up the rest. This, of course, is utter bollocks.<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Counterpoint%3A%20OpenAI%20has%20a%20new%20series%20of%20products%20that%20could%20open%20up%20new%20revenue%20streams%20such%20as%20Operator%2C%20its%20%22agent%22%20product%2C%20and%20%22Deep%20Research%2C%22%20their%20research%20product."> <u>OpenAI's "agents" can't do even the simplest tasks,</u></a> and<a href="https://www.cnbc.com/2025/02/03/softbank-commits-to-joint-venture-with-openai.html?ref=wheresyoured.at"> <u>three billion dollars of the $12.7 billion figure appears to be a commitment made by SoftBank to purchase</u></a> OpenAI's tech for its various subsidiaries and business units.&nbsp;</p><p>Let's say out the numbers precisely:</p><ul><li><strong>Incoming monthly revenue: </strong>roughly $425 million, give or take.</li><li><strong>Theoretical revenue from Softbank:</strong> $250 million a month. However, I can find no proof that SoftBank has begun to make these payments or, indeed, that it intends to make them.</li><li><strong>Liquidity:</strong><ul><li>$10 billion <strong>that it is yet to receive</strong> from SoftBank and a syndicate of investors including Microsoft, <strong>potentially.</strong></li><li><a href="https://openai.com/index/new-credit-facility-enhances-financial-flexibility/?ref=wheresyoured.at"><u>An indeterminate amount of remaining capital on the $4 billion credit facility provided by multiple banks</u></a> back in October 2024, raised alongside a funding round that valued the company at $157 billion.<ul><li>As a note, this announcement stated that OpenAI had "access to over $10 billion in liquidity."</li></ul></li><li><strong>Based on reports, OpenAI will not have access to the rest of its $40bn funding until "the end of the year," and it's unclear what part of the end of the year.</strong></li></ul></li></ul><p>We can assume, in this case, that OpenAI likely has, in the best case scenario, <strong>access to roughly $16 billion in liquidity at any given time. </strong>It's reasonable to believe that OpenAI will raise more <em>debt</em> this year, and I'd estimate it does so to the tune of around $5 billion or $6 billion. Without it, I am not sure what itâ€™s going to do.</p><p><strong>As a reminder: OpenAI loses money on every single user.</strong></p><h2 id="what-are-openais-obligations"><strong>What Are OpenAI's Obligations?</strong></h2><p>When I wrote "<a href="https://www.wheresyoured.at/to-serve-altman/"><u>How Does OpenAI Survive</u></a>?" and "<a href="https://www.wheresyoured.at/oai-business/"><u>OpenAI Is A Bad Business</u></a>," I used reported information to explain how this company was, at its core, unsustainable.</p><p>Let's refresh our memories.</p><h3 id="compute-costs-at-least-13-billion-in-2025-with-microsoft-alone-and-as-much-as-594-million-to-coreweave"><strong>Compute Costs: at least $13 billion in 2025 <em>with Microsoft alone</em>, and as much as $594 million to CoreWeave.</strong></h3><ul><li><strong>In 2024,</strong><a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=As%20a%20note,run%20this%20company."><strong> <u>OpenAI spent $9 billion to lose $5 billion</u></strong></a><strong>.</strong><ul><li>This figure includes the $3 billion spent on training new models and $2 billion on running them.</li></ul></li></ul><p>It seems, from even a cursory glance, that OpenAI's costs are increasing dramatically. The Information reported earlier in the year that<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"> <u>OpenAI projects to spend <strong>$13 billion on compute with Microsoft alone in 2025</strong></u></a><strong>,</strong><a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"><strong> </strong><u>nearly <em>tripling</em> what it spent in total on compute in 2024 ($5 billion)</u></a>.</p><p>This suggests that OpenAI's costs are skyrocketing, and that was before<a href="https://techcrunch.com/2025/03/31/openais-new-image-generator-is-now-available-to-all-users/?ref=wheresyoured.at"> <u>the launch of its new image generator</u></a> which led to multiple complaints from Altman<a href="https://x.com/sama/status/1905296867145154688?ref=wheresyoured.at"> <u>about a lack of available GPUs</u></a>,<a href="https://x.com/sama/status/1907098207467032632?ref=wheresyoured.at"> <u>leading to OpenAI's CEO saying to expect "stuff to break" and delays in new products</u></a>. Nevertheless, even if we assume OpenAI factored in the compute increases into its projections, <strong>it still expects to pay Microsoft $13 billion for compute this year.</strong></p><p>This number, however, doesn't include the $12.9 billion five-year-long compute deal signed with CoreWeave,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>a deal that was a result of Microsoft declining to pick up the option to buy said compute itself</u></a>.<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=The%20recent%20analyst%20forecasts%20took%20into%20account%20its%20largest%20ever%20single%20contract%2C%20a%20%2411.9%20billion%20deal%20with%20OpenAI%20that%20CoreWeave%20said%20would%20begin%20in%20October.%20That%20means%20it%20will%20only%20be%20able%20to%20book%20those%20revenues%20toward%20the%20tail%20end%20of%20this%20year."> <u>Payments for this deal, according to The Information, start in October 2025</u></a>, and assuming that it's evenly paid (the terms of these contracts are generally secret, even in the case of public companies), this would <strong>still amount to roughly $2.38 billion a year.</strong></p><p>However, for the sake of argument, let's consider the payments are around $198 million a month, though there are scenarios â€” such as, say,<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Four%20%2D%20CoreWeave%20Is%20Using%20A%20Suspicious%20and%20Unproven%20Partner%20To%20Build%20its%20Entire%20Infrastructure"> <u>CoreWeave's buildout partner not being able to build the data centers</u></a> or<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Three%3A%20CoreWeave%20Does%20Not%20Have%20Access%20To%20The%20Capital%20Necessary%20To%20Meet%20Its%20Obligations"> <u>CoreWeave not having the money to pay to build them</u></a> â€” where OpenAI might pay less.</p><p>To be clear, and Iâ€™ll explain in greater detail later, this wouldnâ€™t be a good thing, either. While it would be off the hook for some of its payments, it would also be without the compute thatâ€™s essential for it to continue growing, serving existing customers, and building new AI models. Cash and compute are <em>both</em> essential to OpenAIâ€™s survival.&nbsp;&nbsp;</p><h3 id="stargate-1-billion"><strong>Stargate: $1 Billion+</strong></h3><p><a href="https://www.reuters.com/technology/openai-softbank-each-commit-19-bln-stargate-data-center-venture-information-2025-01-23/?ref=wheresyoured.at"><u>OpenAI has dedicated somewhere in the region of $19 billion to the Stargate data center project</u></a>, along with another $19 billion provided by SoftBank and an indeterminate amount by other providers.</p><p><a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"><u>Based on reporting from Bloomberg</u></a>, OpenAI plans to have 64,000 Blackwell GPUs running "by the end of 2026," or roughly $3.84 billion worth of them. I should also note that Bloomberg said that 16,000 of these chips would be operational by Summer 2025, though it's unclear if that will actually happen.</p><p>Though it's unclear who actually pays for what parts of Stargate, it's safe to assume that OpenAI will have to, <strong>at the very least, put a billion dollars into a project that is meant to be up and running by the end of 2026,</strong> if not more.</p><p>As of now, Stargate has exactly one data center under development in Abilene, Texas, and as above, it's unclear how that's going, though <a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a recent piece from The Information reported</u></a> that it was currently "empty and incomplete," and that if it stays that way, "OpenAI could walk away from the deal, which would cost Oracle billions of dollars." Though the article takes pains to assure the reader that won't be likely, even an <em>inkling</em> of such a possibility is a bad sign.</p><p><a href="https://www.businessinsider.com/texas-stargate-data-center-build-cost-2025-1?ref=wheresyoured.at"><u>Business Insider's reporting on the site in Abilene calls it a</u></a> "$3.4 billion data center development" (<a href="https://crusoe.ai/newsroom/crusoe-blue-owl-capital-primary-digital-joint-venture/?ref=wheresyoured.at"><u>as did the press release from site developer Crusoe</u></a>), though these numbers don't include GPUs, hardware, or the labor necessary to run them. Right now, Crusoe is (according to Business Insider) building "six new data centers, each with a minimum square footage...[which will] join the two it is already constructing for Oracle." Oracle has signed, according to The Information, a 15-year-long lease with Crusoe for its data centers, all of which will be rented to OpenAI.</p><p>In any case, OpenAIâ€™s exposure could be much, much higher than the $1bn posited at the start of this section (and Iâ€™ll explain in greater depth how I reached that figure at the bottom of this section). If OpenAI has to contribute significantly to the costs associated with building Stargate, it could be on the hook for <em>billions</em>.<a href="https://www.datacenterdynamics.com/en/news/crusoe-begins-construction-on-second-phase-of-abilene-texas-data-center-campus-will-add-six-buildings/?ref=wheresyoured.at">&nbsp;</a></p><p><a href="https://www.datacenterdynamics.com/en/news/crusoe-begins-construction-on-second-phase-of-abilene-texas-data-center-campus-will-add-six-buildings/?ref=wheresyoured.at"><u>Data Center Dynamics reports that the Abilene site is meant to have 200MW of compute capacity in the first half of 2025, and then as much as 1.2GW by "mid-2026."</u></a><u> To give you a sense of total costs for this project, </u><a href="https://www.latitudemedia.com/news/catalyst-explaining-the-watt-bit-spread/?ref=wheresyoured.at#:~:text=But%20I%20think%20that,the%20CapEx%20deployment%20opportunity."><u>former Microsoft VP of Energy Brian Janous said in January</u></a> that it costs about $25 million a megawatt (or $25 billion a gigawatt), meaning that the initial capital expenditures for Stargate to spin up its first 200MW data center will be around $5 billion, spiraling to $30 billion for the entire project.&nbsp;</p><p>Or perhaps even more. The Information has reported that the site, which could be "...potentially one of the world's biggest AI data centers," could cost "$50 billion to $100 billion in the coming years."&nbsp;</p><p><strong>Assuming we stick with the lower end of the cost estimates, itâ€™s likely that OpenAI is on the hook for over $5 billion for the Abilene site based on the $19 billion it has agreed to contribute to the <em>entire </em>Stargate project, the (often disagreeing) cost projections of the facility), and the contributions of other partners.&nbsp;</strong></p><p>This expenditure wonâ€™t come all at once, and will be spread across several years. Still, assuming even the rosiest numbers, it's hard to see how OpenAI doesn't have to pony up $1 billion in 2025, with similar annual payments going forward until its completion, and that is likely because the development of this site is going to be heavily delayed by both tariffs, labor shortages, and Oracle's (as reported by The Information) trust in "scrappy but unproven startups to develop the project."</p><h3 id="other-costs-at-least-35-billion"><strong>Other costs: at least $3.5 billion</strong></h3><p><a href="https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Based on reporting from The Information last year</u></a>, OpenAI will spend <em>at least $2.5 billion</em> across salaries, "data" (referring to buying data from other companies), hosting and other cost of sales, and sales and marketing, and then another billion on what infrastructure OpenAI owns.</p><p>I expect the latter cost to balloon with OpenAI's investment in physical infrastructure for Stargate.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdTLWNPUZ-Y3kviQD7Sn0ojL9bEazTw2r7G-JOiNtwC8ac3-d_DsBNExz6VYKwjyo6C2Tp1K6h1-4KeAT0bY89YsF7HFhQHZI7l-ok8rNK1AuoeynifiUxsvRPbVSQUYUPxs0l1?key=MFOPt-R0auIdYEYVFbbAfdWf" alt="" loading="lazy" width="624" height="564"></figure><h2 id="how-does-openai-meet-its-obligations"><strong>How Does OpenAI Meet Its Obligations?</strong></h2><h3 id="openai-could-spend-28-billion-or-more-in-2025-and-lose-over-14-billion-while-having-an-absolute-maximum-of-20-billion-in-liquidity"><strong>OpenAI Could Spend $28 Billion Or More In 2025, and Lose over $14 Billion while having an absolute maximum of $20 billion in liquidity</strong></h3><p><a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=The%20New%20York%20Times%20reports%20that%20OpenAI%20projects%20it%27ll%20make%20%2411.6%20billion%20in%202025%2C%20and%20assuming%20that%20OpenAI%20burns%20at%20the%20same%20rate%20it%20did%20in%202024%20%E2%80%94%20spending%20%242.25%20to%20make%20%241"><u>Based on previous estimates, OpenAI spends about $2.25 to make $1.</u></a> At that rate, it's likely that OpenAI's costs <em>in its rosiest revenue projections of $12.7 billion </em>are at least $28 billion â€” <strong>meaning that itâ€™s on course to burn at least $14 billion in 2025.</strong></p><p>Assuming that OpenAI has <strong>all of its liquidity from last year </strong>(it doesn't, but for sake of argument, letâ€™s pretend it still has the full $10 billion), <strong>as well as the $10 billion from SoftBank</strong>, it is <em>still</em> unclear how it meets its obligations.</p><p>While OpenAI likely has preferential payment structures with all vendors, such as its discounted rates with Microsoft for Azure cloud services, it will still have to pay them, especially in the case of costs related to Stargate, many of which will be up-front costs. In the event that its costs are as severe as reporting suggests, itâ€™s likely the company will find itself needing to raise more capital â€” whether through equity (or the weird sort-of equity that it issues) or through debt.&nbsp;</p><p>And yes, while OpenAI has some revenue, it comes at a terrible cost, and anything that isnâ€™t committed to paying for salaries and construction fees will likely be immediately funnelled directly into funding the obscene costs behind inference and training models like GPT 4.5 â€” a "<a href="https://www.wheresyoured.at/power-cut/#:~:text=The%20bad%20news%20was%20that%2C%20and%20I%20quote%2C%20GPT%204.5%20is%20%E2%80%9C...a%20giant%2C%20expensive%20model%2C%E2%80%9D"><u>giant expensive model</u></a>" to run that<a href="https://help.openai.com/en/articles/10658365-gpt-4-5-in-chatgpt?ref=wheresyoured.at"> <u>the company has nevertheless pushed to every user</u></a>.</p><p>Worse still, OpenAI has, while delaying its next model (GPT-5),<a href="https://techcrunch.com/2025/04/04/openai-says-itll-release-o3-after-all-delays-gpt-5/?ref=wheresyoured.at"> <u>promised to launch its o3 reasoning model after saying it wouldn't do so</u></a>, which is strange, because it turns out that o3 is actually <em>way</em> more expensive to run than people thought.&nbsp;</p><p>Reasoning models are almost always more expensive to operate, as they involve the model â€œcheckingâ€ its work, which, in turn, requires more calculations and more computation. Still, o3 is ludicrously expensive even for this category, with the Arc Prize Foundation (a non-profit that makes the ARC-AGI test for benchmarking models) estimating that it will cost<a href="https://techcrunch.com/2025/04/02/openais-o3-model-might-be-costlier-to-run-than-originally-estimated/?ref=wheresyoured.at"> <em><u>$30,000 a task.</u></em></a></p><h3 id="softbank-has-to-borrow-money-to-meet-its-openai-and-stargate-obligations-leading-to-softbanks-financial-condition-likely-deteriorating"><strong>SoftBank Has To Borrow Money To Meet Its OpenAI and Stargate Obligations, leading to SoftBank's  "...financial condition likely deteriorating."</strong></h3><p>As of right now, SoftBank has committed to the following:</p><ul><li>At least $30 billion ($7.5 of the initial $10 billion, and $22.5 billion of the remaining $30 billion) in funding as part of OpenAI's recent $40bn funding round.<ul><li>This assumes that SoftBank finds others to invest with it. <a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><u>SoftBank's filings surrounding OpenAI's funding</u></a> also suggest that SoftBank is, ultimately, on the hook for the entire $40 billion, but <em>can</em> syndicate with other investors.<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?ref=wheresyoured.at"> <u>Reporting suggests that syndication will happen with Coatue, Microsoft and other investors</u></a>.</li><li>If OpenAI fails to convert to a for-profit, that $40bn figure is slashed to $30, although, again, SoftBankâ€™s share of the final sum is contingent upon whether it finds other investors to join the deal.&nbsp;</li></ul></li><li><a href="https://www.cnbc.com/2025/02/03/softbank-commits-to-joint-venture-with-openai.html?ref=wheresyoured.at"><u>$3 billion in spend on OpenAI "tech."</u></a></li><li>$19 billion for the Stargate data center project,<a href="https://www.theinformation.com/articles/softbanks-son-goes-on-a-new-borrowing-binge-to-fund-ai?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>which SoftBank takes financial responsibility for</u></a>.<ul><li><strong>Total: $52 billion or $62 billion, with at least $20 billion due by the end of 2025.</strong></li></ul></li></ul><p>SoftBank's exposure to OpenAI is materially harming the company.<a href="https://www.wsj.com/business/deals/openai-softbank-investment-debt-51b4a130?ref=wheresyoured.at"> <u>To quote the Wall Street Journal:</u></a></p><blockquote>Ratings agency S&amp;P Global said last week that SoftBankâ€™s â€œfinancial condition will likely deteriorateâ€ as a result of the OpenAI investment and that its plans to add debt could lead the agency to consider downgrading SoftBankâ€™s ratings.&nbsp;</blockquote><p>While one might argue that SoftBank has a good amount of cash, the Journal also adds that itâ€™s&nbsp; somewhat hamstrung in its use as a result of CEO Masayoshi Son's reckless gambles:</p><blockquote>SoftBank had a decent buffer of $31 billion of cash as of Dec. 31, but the company has also pledged to hold much of that in reserve to quell worried investors. SoftBank has committed not to borrow more than 25% of the value of all of its holdings, which means it will likely need to sell some of the other parts of its empire to pay for the rest of the OpenAI deal.</blockquote><p>Worse still, it seems, as mentioned before, that SoftBank will be financing the entirety of the first $10 billion â€” or $7.5 billion, assuming it finds investors to syndicate the first tranche, and they follow through right until the moment Masayoshi Son hits â€˜sendâ€™ on the wire transfer .</p><p>As a result, SoftBank will likely have to start selling off parts of its valuable holdings in companies like Alibaba and ARM, or, worse still,<a href="https://www.wheresyoured.at/power-cut/#:~:text=On%20the%20subject%20of%20Softbank%E2%80%99s%20holdings"> <u>parts of its ailing investments from its Vision Fund</u></a>, resulting in a material loss on its underwater deals.</p><p>This is an untenable strategy, and I'll explain why.</p><h3 id="openai-needs-at-least-40-billion-a-year-to-survive-and-its-costs-are-increasing"><strong>OpenAI Needs At Least $40 billion A Year To Survive, And Its Costs Are Increasing</strong></h3><p>While we do not have much transparency into OpenAI's actual day-to-day finances, we can make the educated guess that its costs are <em>increasing</em> based on the amount of capital itâ€™s raising. If OpenAIâ€™s costs were flat, or only mildly increasing, weâ€™d expect to see raises roughly the same size as previous ones. Its $40bn raise is nearly <em>six</em> times the previous funding round.&nbsp;</p><p>Admittedly, multiples like that arenâ€™t particularly unusual. If a company raises $300,000 in a pre-seed round, and $3m in a Series A round, thatâ€™s a tenfold increase. But weâ€™re not talking about hundreds of thousands of dollars, or even millions of dollars. Weâ€™re talking about <em>billions</em> of dollars. If OpenAIâ€™s funding round with Softbank goes as planned, itâ€™ll raise the equivalent of the entire GDP of Estonia â€” a fairly wealthy country itself, and one thatâ€™s also a member of Nato and the European Union. That alone should give you a sense of the truly insane scale of this.&nbsp;</p><p>Insane, sure, but undoubtedly necessary. <a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=this%20year%20to-,%2428%20billion%20in%202028,-.%20The%20spending%20forecast"><u>Per The Information</u></a>, OpenAI expects to spend as much as $28 billion in compute on Microsoft's Azure cloud in 2028. Over a third of OpenAI's revenue, per the same article, will come from SoftBank's (alleged) spend.It's reasonable to believe that OpenAI will, as a result, need to raise in excess of $40 billion in funding a year, though it's reasonable to believe that it will need to raise more along the lines of $50 billion or more a year until it reaches profitability. This is due to both its growing cost of business, as well as its various infrastructure commitments, both in terms of Stargate, as well as with third-party suppliers like CoreWeave and Microsoft.&nbsp;</p><blockquote><strong>Counterpoint: OpenAI could reduce costs:</strong> While this is <u>theoretically</u> possible, there is no proof that this is taking place.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information claims that</u></a> "...OpenAI would turn profitable by the end of the decade after the buildout of Stargate," but there is no suggestion as to how it might do so, or how building more data centers would somehow reduce its costs.This is especially questionable when you realize that<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=OpenAI%20pays%20just%20over%2025%25%20of%20the%20cost%20of%20Azure%E2%80%99s%20GPU%20compute%20as%20part%20of%20its%20deal%20with%20Microsoft%20%E2%80%94%20around%20%241.30%2Dper%2DGPU%2Dper%2Dhour%20versus%20the%20regular%20Azure%20cost%20of%20%243.40%20to%20%244."> <u>Microsoft is already providing discounted pricing on Azure compute</u></a>. We donâ€™t know if these discounts are below Microsoftâ€™s break-even point â€” which it wouldnâ€™t, nor would any other company offer, if they didnâ€™t have something else to incentivize it, such as equity or a profit-sharing program. Microsoft, for what itâ€™s worth, has both of those things.&nbsp;</blockquote><p>OpenAI CEO Sam Altman's statements around costs also suggest that they're increasing. In late February,<a href="https://techcrunch.com/2025/02/27/openai-ceo-sam-altman-says-the-company-is-out-of-gpus/?ref=wheresyoured.at"> <u>Altman claimed that OpenAI was "out of GPUs</u></a>." While this suggests that thereâ€™s demand for some products â€” like its image-generating tech, which enjoyed a viral day in the sun in March â€” it also means that to meet the demand it needs to spend more. And, at the risk of repeating myself, that demand doesnâ€™t necessarily translate into profitability.&nbsp;</p><h3 id="softbank-cannot-fund-openai-long-term-as-openais-costs-are-projected-to-be-320-billion-in-the-next-five-years"><strong>SoftBank Cannot Fund OpenAI Long-Term, as OpenAI's costs are projected to be $320 billion in the next five years</strong></h3><p>As discussed above, SoftBank has to overcome significant challenges to fund both OpenAI and Stargate, and when I say "fund," I mean <strong>fund the current state of both projects, assuming no further obligations.</strong></p><p>The Information reports that<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>OpenAI forecasts that it will spend $28 billion on compute with Microsoft alone in 2028</u></a>. The same article also reports that OpenAI "would turn profitable by the end of the decade after the buildout of Stargate," suggesting that OpenAI's operating expenses will grow exponentially year-over-year.</p><p>These costs, per The Information, are astronomical:</p><blockquote>The reason for the expanding cash burn is simple: OpenAI is spending whatever revenue comes in on computing needs for operating its existing models and developing new models. The company expects those costs to surpass $320 billion overall between 2025 and 2030.<p>The company expects more than half of that spending through the end of the decade to fund research-intensive compute for model training and development. That spending will rise nearly sixfold from current rates to around $40 billion per year starting in 2028. OpenAI projects its spending on running AI models will surpass its training costs in 2030.</p></blockquote><p>SoftBank has had to (and will continue having to) go to remarkable lengths to fund OpenAI's current ($40 billion) round, lengths so significant that it may lead to its credit rating being further downgraded.</p><p>Even if we assume the best case scenario â€” OpenAI successfully converts to a for-profit entity by the end of the year, and receives the full $30 billion â€” it seems unlikely (if not impossible) for it to continue raising the amount of capital they need to continue operations. As Iâ€™ve argued in previous newsletters, there are only a few entities that can provide the kinds of funding that OpenAI needs. These include big tech-focused investment firms like Softbank, sovereign wealth funds (like those of Saudi Arabia and the United Emirates), and perhaps the largest tech companies.</p><p>These entities can meet OpenAIâ€™s needs, but not all the time. Itâ€™s not realistic to expect Softbank, or Microsoft, or the Saudis, or Oracle, or whoever, to provide $40bn <em>every year</em> for the foreseeable future.&nbsp;</p><p>This is especially true for Softbank. Based on its current promise to not borrow more than 25% of its holdings, it is near-impossible that SoftBank will be able to continue funding OpenAI at this rate ($40 billion a year), and $40 billion a year may not actually be enough.</p><p>Based on<a href="https://group.softbank/en/ir/stock/sotp?ref=wheresyoured.at"> <u>its last reported equity value of holdings</u></a>, SoftBank's investments and other assets are worth around $229 billion, meaning that it can borrow just over $57bn while remaining compliant with these guidelines.</p><p>In any case, it is unclear how SoftBank can fund OpenAI, but it's far clearer that <em>nobody else is willing to.</em></p><h3 id="openai-is-running-into-capacity-issues-suggesting-material-instability-in-its-business-or-infrastructure-%E2%80%94-and-its-unclear-how-it-expands-further"><strong>OpenAI Is Running Into Capacity Issues, Suggesting Material Instability In Its Business or Infrastructure â€” And It's Unclear How It Expands Further</strong></h3><p>Before we go any further, it's important to note that OpenAI does not really have its own compute infrastructure. The majority of its compute is provided by Microsoft, though, as mentioned above,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>OpenAI now has a deal with CoreWeave to take over Microsoft's future options for more capacity</u></a>.</p><p>Anyway, in the last 90 days, Sam Altman has complained about a lack of GPUs and pressure on OpenAI's servers multiple times. Forgive me for repeating stuff from above, but this is necessary.</p><ul><li><a href="https://x.com/sama/status/1895203654103351462?ref=wheresyoured.at"><u>On February 27,</u></a> he lamented how GPT 4.5 was a "giant, expensive model," adding that it was "hard to perfectly predict growth surges that lead to GPU shortages." He also added that they would be adding tens of thousands of GPUs in the following week, then hundreds of thousands of GPUs "soon."</li><li><a href="https://x.com/sama/status/1905000759336620238?ref=wheresyoured.at"><u>On March 26</u></a>, he said that "images in chatgpt are wayyyy more popular than [OpenAI] expected," delaying the free tier launch as a result.</li><li><a href="https://x.com/sama/status/1905296867145154688?ref=wheresyoured.at"><u>On March 27</u></a>, he said that OpenAI's "GPUs [were] melting," adding that it was "going to introduce some temporary rate limits" while it worked out how to "make it more efficient."</li><li><a href="https://x.com/rohanjamin/status/1905721967216599199?ref=wheresyoured.at"><u>On March 28</u></a>, he retweeted Rohan Sahai, the product team lead on OpenAI's Sora video generation model, who said "The 4o image gen demand has been absolutely incredible. Been super fun to watch the Sora feed fill up with great content...GPUs are also melting in Sora land unfortunately so you may see longer wait times / capacity issues over coming days."</li><li><a href="https://x.com/sama/status/1906210479695126886?ref=wheresyoured.at"><u>On March 30</u></a>, he said "can yall please chill on generating images this is insane our team needs sleep."</li><li><a href="https://x.com/sama/status/1907098207467032632?ref=wheresyoured.at"><u>On April 1</u></a>, he said that "we are getting things under control, but you should expect new releases from openai [sic] to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges." He also added that OpenAI is "working as fast we can to really get stuff humming; if anyone has GPU capacity in 100k chunks we can get asap please call!"</li></ul><p>These statements, in a bubble, seem either harmless or like OpenAI's growth is skyrocketing â€” the latter of which might indeed be true, but bodes ill for a company that burns money on every single user.</p><p>Any mention of rate limits or performance issues suggests that OpenAI is having significant capacity issues, and at this point it's unclear what further capacity it can actually expand to outside of that currently available. Remember,<a href="https://www.datacenterdynamics.com/en/news/microsoft-cancels-up-to-2gw-of-data-center-projects-says-td-cowen/?ref=wheresyoured.at"> <u>Microsoft has now pulled out of as much as 2GW of data center projects</u></a>,<a href="https://www.datacenterdynamics.com/en/news/microsoft-backs-away-from-1bn-data-center-plans-in-licking-county-ohio/?ref=wheresyoured.at"> <u>walked away from a $1 billion data center development in Ohio</u></a>, and<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>declined the option on $12bn of compute from CoreWeave that OpenAI had to pick up</u></a> â€” meaning that it may be pushing up against the limits of what is physically available.</p><p>While the total available capacity of GPUs at many providers like Lambda and Crusoe is unknown, we know that CoreWeave has approximately 360MWavailable,<a href="https://www.wheresyoured.at/power-cut/#:~:text=For%20some%20context,at%20this%20time."> <u>compared to Microsoft's 6.5 to 7.5 Gigawatts</u></a>, a large chunk of which already powers OpenAI.</p><p>If OpenAI is running into capacity issues, it could be one of the following:</p><ul><li>OpenAI is running up against the limit of what Microsoft has available, or is willing to offer the company.<a href="https://www.theinformation.com/articles/openai-eases-away-from-microsoft-data-centers?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported in October 2024</u></a> that OpenAI was frustrated with Microsoft, which said it wasnâ€™t moving fast enough to supply it with servers.</li><li>While OpenAI's capacity is sufficient, It does not have the resources available to easily handle bursts in user growth in a stable manner.</li></ul><p>Per The Information's reporting, Microsoft "promised OpenAI 300,000 NVIDIA GB200 (Blackwell) chips by the end of 2025," or roughly $18 billion of chips. It's unclear if this has changed<a href="https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/?ref=wheresyoured.at"> <u>since Microsoft allowed OpenAI to seek other compute in late January 2025</u></a>.</p><p>I also don't believe that OpenAI has any other viable options for <em>existing compute infrastructure outside of Microsoft.</em><a href="https://www.cnbc.com/2025/03/26/the-concern-with-coreweaves-250000-nvidia-chips-ahead-of-its-ipo.html?ref=wheresyoured.at"><em> </em><u>CoreWeave's current data centers mostly feature NVIDIA's aging "Hopper" GPUs</u></a>, and while it could â€” and likely is! â€” retrofitting its current infrastructure with Blackwell chips, doing so is not easy. Blackwell chips require far more powerful cooling and server infrastructure to make them run smoothly (<a href="https://www.theinformation.com/articles/nvidias-top-customers-face-delays-from-glitchy-ai-chip-racks?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a problem which led to a delay in their delivery to most customers</u></a>), and even if CoreWeave was able to replace every last Hopper GPU with Blackwell (it won't), it still wouldn't match what OpenAI needs to expand.</p><p>One might argue that it simply needs to wait for the construction of the Stargate data center, or for CoreWeave to finish the gigawatt or so of construction itâ€™s working on.</p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Per%20its%20S,its%20current%20commitments."><u>As I've previously written</u></a>, I have serious concerns over the viability of CoreWeave ever completing its (alleged) contracted 1.3 Gigawatts of capacity.</p><p>Per my article:</p><blockquote>Per its S-1, CoreWeave has contracted for around 1.3 Gigawatts of capacity, which it expects to roll out over the coming years, and based on NextPlatform's math, <strong>CoreWeave will have to spend in excess of $39 billion to build its contracted compute. It is unclear how it will fund doing so, and it's fair to assume that CoreWeave does not currently have the capacity to cover its current commitments.</strong></blockquote><p>However, even if I were to humour the idea, it is impossible that any of this project is done by the end of the year, or even in 2026. I can find no commitments to any timescale, other than the fact that OpenAI will allegedly start paying CoreWeave in October (<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=The%20recent%20analyst%20forecasts%20took%20into%20account%20its%20largest%20ever%20single%20contract%2C%20a%20%2411.9%20billion%20deal%20with%20OpenAI%20that%20CoreWeave%20said%20would%20begin%20in%20October.%20That%20means%20it%20will%20only%20be%20able%20to%20book%20those%20revenues%20toward%20the%20tail%20end%20of%20this%20year."><u>per The Information</u></a>), which could very well be using current capacity.</p><p>I can also find no evidence that Crusoe, the company building the Stargate data center, has <em>any</em> compute available. Lambda,<a href="https://lambda.ai/blog/lambda-raises-320m-to-build-a-gpu-cloud-for-ai?srsltid=AfmBOopeWiVs7rtdEu5gHfszLlR2caTYw9u_avGGz6Go2D-izzkM5CBL&amp;ref=wheresyoured.at"> <u>a GPU compute company that raised $320 million earlier in this year</u></a>, and<a href="https://www.datacenterdynamics.com/en/analysis/true-believers-lambda-labs-ai-cloud-dreams/?ref=wheresyoured.at"> <u>according to Data Center Dynamics</u></a> "operates out of colocation data centers in San Francisco, California, and Allen, Texas, and is backed by more than $820 million in funds raised just this year," suggesting that it may not have their own data centers at all. Its ability to scale is entirely contingent on the availability of whatever data center providers it has relationships with.&nbsp;</p><p>In any case, this means that OpenAI's only real choice for GPUs is CoreWeave or Microsoft. While it's hard to calculate precisely,<a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"> <u>OpenAI's best case scenario is that 16,000 GPUs come online in the summer of 2025</u></a> as part of the Stargate data center project.</p><p>That's a drop in the bucket compared to the 300,000 Blackwell GPUs that Microsoft had previously promised.</p><h3 id="any-capacity-or-expansion-issues-threaten-to-kneecap-openai"><strong>Any capacity or expansion issues threaten to kneecap OpenAI</strong></h3><p>OpenAI is, regardless of how you or I may feel about generative AI, one of the fastest-growing companies of all time. It currently has, according to its own statements, 500 million weekly active users. Putting aside that each user is unprofitable, such remarkable growth â€” especially as it's partially a result of its extremely resource-intensive image generator â€” is also a strain on its infrastructure.</p><p>The vast majority of OpenAI's users are free customers using ChatGPT, with only around 20 million paying subscribers, and the vast majority on the cheapest $20 plan. OpenAI's services â€” even in the case of image generation â€” are relatively commoditized, meaning that users can, if they really care, go and use any number of other different Large Language Model services. They can switch to Bing Image Creator, or Grok, or Stable Diffusion, or whatever.</p><p>Free users are also a burden on the company â€” especially with such a piss-poor conversion rate â€” losing it money with each prompt (which is also the case with paying customers), and the remarkable popularity of its image generation service only threatens to bring more burdensome one-off customers that will generate a few abominable Studio Ghibli pictures and then never return.</p><p>If OpenAI's growth continues at this rate, it will run into capacity issues, and it does not have much room to expand. While we do not know how much capacity itâ€™s taking up with Microsoft, or indeed whether Microsoft is approaching capacity or otherwise limiting how much of it OpenAI can take, we do know that OpenAI has seen reason to beg for access to more GPUs.</p><p>In simpler terms, even if OpenAI wasnâ€™t running out of money, even if OpenAI wasnâ€™t horrifyingly unprofitable, it also may not have enough GPUs to continue providing its services in a reliable manner.</p><p>If that's the case, there really isn't much that can be done to fix it other than:</p><ul><li>Significantly limiting free users' activity on the platform, which is OpenAI's primary mechanism for revenue growth and customer acquisition.</li><li>Limiting activity or changing the economics behind its paid product, to quote Sam Altman, "<a href="https://x.com/sama/status/1889679681047482730?ref=wheresyoured.at"><u>find[ing] some way to let people to pay for compute they want to use more dynamically.</u></a>"<ul><li><a href="https://x.com/sama/status/1897036361506689206?ref=wheresyoured.at"><u>On March 4th</u></a>, Altman solicited feedback on "...an idea for paid plans: your $20 plus subscription converts to credits you can use across features like deep research, o1, gpt-4.5, sora, etc...no fixed limits per feature and you choose what you want; if you run out of credits you can buy more."</li><li><a href="https://x.com/sama/status/1876104315296968813?ref=wheresyoured.at"><u>On January 5th</u></a>, Sam Altman revealed that OpenAI is currently losing money on every paid subscription, including its $200-a-month "pro" subscription.</li><li><a href="https://www.theinformation.com/articles/openai-plots-charging-20-000-a-month-for-phd-level-agents?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=OpenAI%20CEO%20Sam,200%20a%20month.%E2%80%9D"><u>Buried in an article from The Information from March 5</u></a> is a comment that suggests itâ€™s considering measures like changing its pricing model, with "...Sam Altman reportedly [telling] developers in London [in February] that OpenAI is primed to charge 20% or 30% of Pro customers a higher price because of how many research queries theyâ€™re doing, but he suggested an â€œa la carteâ€ or pay-as-you-go approach. When it comes to agents, though, â€œwe have to charge much more than $200 a month.â€</li></ul></li></ul><p>The problem is that these measures, even if they succeed in generating more money for the company, <strong>also need to reduce the burden on OpenAI's available infrastructure.</strong></p><p><a href="https://www.wheresyoured.at/power-cut/#:~:text=Data%20center%20buildouts,a%20year%20ago."><u>Remember: data centers can take three to six years to build</u></a>, and even with the Stargate's accelerated (and I'd argue unrealistic) timelines, OpenAI isn't even unlocking a tenth of Microsoft's promised compute (16,000 GPUs online this year versus the 300,000 GPUs promised by Microsoft).</p><h3 id="what-might-capacity-issues-look-like-and-what-are-the-consequences"><strong>What Might Capacity Issues Look Like? And What Are The Consequences?</strong></h3><p>Though downtime might be an obvious choice, capacity issues at OpenAI will likely manifest in hard limits on what free users can do, some of which I've documented above. Nevertheless, I believe the real pale horses of capacity issues come from <strong>arbitrary limits on any given user group,</strong> meaning both free and paid users. Sudden limits on what a user can do â€” a reduction in the number of generations of images of videos for paid users, any introduction of "peak hours," or any increases in prices are a sign that OpenAI is running out of GPUs, which it has already publicly said is happening.</p><p>However, the really obvious one would be <em>service degradation</em> â€” delays in generations of any kind,<a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-500-internal-server-error.html?ref=wheresyoured.at#:~:text=An%20HTTP%20500%20status%20code,it%20from%20fulfilling%20the%20request."> <u>500 status code errors</u></a>, or ChatGPT failing to fully produce an answer. OpenAI has, up until this point, had fairly impressive uptime. Still, if it is running up against a wall, this streak will end.</p><p>The consequences depend on how often these issues occur, and to whom they occur. If free users face service degradation, they will bounce off the product, as their use is likely far more fleeting than a paid user, which will begin to erode OpenAI's growth. Ironically, rapid (and especially unprecedented) growth in one of OpenAIâ€™s competitors, like xAI or Anthropic, could also represent a pale horse for OpenAI.&nbsp;</p><p>If <em>paid</em> users face service degradation, it's likely this will cause the most harm to the company, as while paid users still lose OpenAI money in the end, <em>it at least receives some money in exchange.</em></p><p>OpenAI has effectively one choice here: getting more GPUs from Microsoft, and its future depends heavily both on its generosity <em>and</em> there being enough of them at a time when Microsoft<a href="https://www.wheresyoured.at/power-cut/"> <u>has pulled back</u></a><a href="https://sherwood.news/tech/microsoft-cancels-2-gigawatts-worth-of-data-centers-analysts-say/?ref=wheresyoured.at"> <u>from two gigawatts of data centers</u></a><a href="https://www.reuters.com/technology/microsoft-pulls-back-more-data-center-leases-us-europe-analysts-say-2025-03-26/?ref=wheresyoured.at"> <em><u>specifically because of it moving away from providing compute for OpenAI</u></em></a><em>.</em></p><p>Admittedly, OpenAI has previously spent more on training models than inference (actually running them) and the company might be able to smooth downtime issues by shifting capacity. This would, of course, have a knock-on effect on its ability to continue developing new models, and the company is already losing ground, particularly when it comes to Chinese rivals like DeepSeek.</p><h3 id="openai-must-convert-to-a-for-profit-entity-by-the-end-of-2025-or-it-loses-10-billion-in-funding-and-doing-so-may-be-impossible"><strong>OpenAI Must Convert To A For-Profit Entity By The End of 2025 Or It Loses $10 Billion In Funding, And Doing So May Be Impossible</strong></h3><p>As part of its deal with SoftBank, OpenAI must convert its bizarre non-profit structure into a for-profit entity by December 2025, or itâ€™ll lose $10 billion from its promised funding.&nbsp;</p><p>Furthermore, in the event that OpenAI fails to convert to a for-profit by October 2026,<a href="https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=yvhGAx&amp;ref=wheresyoured.at"> <u>investors in its previous $6.6 billion round can claw back their investment</u></a>, with it converting into a loan with an attached interest rate. Naturally, this represents a nightmare scenario for the company, as itâ€™ll increase both its costs and its outgoings.</p><p>This is a complex situation that almost warrants its own newsletter, but the long and short of it is that OpenAI would have to effectively dissolve itself, <a href="https://www.upcounsel.com/converting-non-profit-to-for-profit?ref=wheresyoured.at#:~:text=Converting%20a%20nonprofit%20to%20a,a%20new%20for%2Dprofit%20entity."><u>start the process of forming an entirely new entity</u></a>, and distribute its assets to other nonprofits (or sell/license them to the for-profit company at fair market rates). It would require valuing OpenAI's assets, which in and of itself would be a difficult task, as well as getting past the necessary state regulators, the IRS, state revenue agencies, and<a href="https://www.inc.com/reuters/legal-battle-between-musk-and-openai-heads-to-trial-in-2026/91172454?ref=wheresyoured.at"> <u>the upcoming trial with Elon Musk only adds further problems</u></a>.</p><p>Iâ€™ve simplified things here, and thatâ€™s because (as I said) this stuff is complex. Suffice to say, this isnâ€™t as simple as liquidating a company and starting afresh, or submitting a couple of legal filings. Itâ€™s a long, fraught process and one that will be â€” and has been â€” subject to legal challenges, both from OpenAIâ€™s business rivals, as well as from civil society organizations in California.</p><p>Based on discussions with experts in the field and my own research, I simply do not know how OpenAI pulls this off <em>by October 2026,</em> let alone by the end of the year.</p><h2 id="openai-has-become-a-systemic-risk-to-the-tech-industry"><strong>OpenAI Has Become A Systemic Risk To The Tech Industry</strong></h2><p>OpenAI has become a load-bearing company for the tech industry, both as a narrative â€”<a href="https://www.wheresyoured.at/wheres-the-money/"> <u>as previously discussed, ChatGPT is the only Large Language Model company with any meaningful userbase</u></a> â€” and as a financial entity.&nbsp;</p><p>Its ability to meet its obligations and its future expansion plans are critical to the future health â€” or, in some cases, survival â€” of multiple large companies, and that's before the after-effects that will affect its customers as a result of any financial collapse.&nbsp;</p><p>The parallels to the 2007-2008 financial crisis are startling. Lehman Brothers wasnâ€™t the largest investment bank in the world (although it was certainly big), just like OpenAI isnâ€™t the largest tech company (though, again, itâ€™s certainly large in terms of market cap and expenditure). Lehman Brothersâ€™ collapse sparked a contagion that would later spread throughout the global financial services industry, and consequently, the global economy.&nbsp;</p><p>I can see OpenAIâ€™s failure having a similar systemic effect. While there is a vast difference between OpenAIâ€™s involvement in peopleâ€™s lives compared to the millions of subprime loans issued to real people, the stock marketâ€™s dependence on the value of the Magnificent 7 stocks (Apple, Microsoft, Amazon, Alphabet, NVIDIA and Tesla), and in turn the Magnificent 7â€™s reliance on the stability of the AI boom narrative still threatens material harm to millions of people, and thatâ€™s before the ensuing layoffs.&nbsp;</p><p>And as Iâ€™ve said before, this entire narrative is based off of OpenAIâ€™s success, because OpenAI <em>is</em> the generative AI industry.&nbsp;</p><p>I want to lay out the direct result of any kind of financial crisis at OpenAI, because I don't think anybody is taking this seriously.</p><h3 id="oracle-will-lose-at-least-1-billion-if-openai-doesnt-fulfil-its-obligations"><strong>Oracle Will Lose At Least $1 Billion If OpenAI Doesn't Fulfil Its Obligations</strong></h3><p><a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Per The Information</u></a>, Oracle, which has taken responsibility for organizing the construction of the Stargate data centers with unproven data center builder Crusoe, "...may need to raise more capital to fund its data center ambitions."</p><p>Oracle has signed a 15-year lease with Crusoe, and, to quote The Information, "...is on the hook for $1 billion in payments to that firm."</p><p>To further quote The Information:</p><blockquote>...while thatâ€™s a standard deal length, the unprecedented size of the facility Oracle is building for just one customer makes it riskier than a standard cloud data center used by lots of interchangeable customers with more predictable needs, according to half a dozen people familiar with these types of deals.</blockquote><p>In simpler terms, Oracle is building a giant data center for one customer â€” OpenAI â€” and has taken on the financial burden associated with it. If OpenAI fails to expand, or lacks the capital to actually pay for its share of the Stargate project, Oracle is on the hook for at least a billion dollars, and, based on The Information's reporting, is also on the hook to buy the GPUs for the site.</p><blockquote>Even before the Stargate announcement, Oracle and OpenAI had agreed to expand their Abilene deal from two to eight data center buildings, which can hold 400,000 Nvidia Blackwell GPUs, adding tens of billions of dollars to the total cost of the facility.</blockquote><p>In reality, this development will likely cost tens of billions of dollars, $19 billion of which is due from OpenAI, which does not have the money until it receives its second tranche of funding in December 2025, which is contingent partially on its ability to convert into a for-profit entity, which, as mentioned, is a difficult and unlikely proposition.</p><p>It's unclear how many of the Blackwell GPUs that Oracle has had to purchase in advance, but in the event of any kind of financial collapse at OpenAI, Oracle would likely <strong>take a loss of at least a billion dollars, if not several billion dollars.</strong></p><h3 id="coreweaves-expansion-is-likely-driven-entirely-by-openai-and-it-cannot-survive-without-openai-fulfilling-its-obligations-and-may-not-anyway"><strong>CoreWeave's Expansion Is Likely Driven Entirely By OpenAI, And It Cannot Survive Without OpenAI Fulfilling Its Obligations (And May Not Anyway)</strong></h3><p><a href="https://www.wheresyoured.at/core-incompetency/"><u>I have written a lot about publicly-traded AI compute firm CoreWeave</u></a>, and it would be my greatest pleasure to never mention it again.</p><p>Nevertheless, I have to.</p><p>The Financial Times revealed a few weeks ago that<a href="https://www.ft.com/content/163c6927-2032-4346-857e-8e3787e4babc?ref=wheresyoured.at"> <u>CoreWeave's debt payments could balloon to over $2.4 billion a year by the end of 2025</u></a>, far outstripping its cash reserves, and<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that its cash burn would increase to $15 billion in 2025</u></a>.</p><p>As per its IPO filings, 62% of CoreWeave's 2024 revenue (a little under $2 billion, with losses of $863 million) was Microsoft compute, and based on conversations with sources, a good amount of this was Microsoft running compute for OpenAI.</p><p>Starting October 2025,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>OpenAI will start paying Coreweave as part of its five-year-long $12 billion contract</u></a>, picking up the option that Microsoft declined.<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Starting%20from%20October%202025"> <u>This is also when</u></a> CoreWeave will have to start making payments on<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Problem%20Loan%20Number%202%3A%20DDTL%202.0"> <u>its massive, multi-billion dollar DDTL 2.0 loan</u></a>, which likely makes these payments critical to CoreWeave's future.</p><p>This deal also suggests that OpenAI will become CoreWeave's largest customer. Microsoft had previously committed to spending $10 billion on CoreWeave's services "<a href="https://www.datacenterdynamics.com/en/news/microsoft-to-invest-10bn-in-coreweave-by-end-of-decade/?ref=wheresyoured.at"><u>by the end of the decade</u></a>," but CEO Satya Nadella added a few months later on a podcast that its relationship with CoreWeave was a "<a href="https://www.youtube.com/watch?v=9NtsnzRFJ_o&amp;ref=wheresyoured.at"><u>one-time thing</u></a>." Assuming Microsoft keeps spending at its previous rate â€” something that isn't guaranteed â€” it would still be only half of OpenAI's potential revenue.</p><p>CoreWeave's expansion, at this point, is entirely driven by OpenAI. 77% of its 2024 revenue came from two customers â€” Microsoft being the largest, and using CoreWeave as an auxiliary supplier of compute for OpenAI. As a result, the future expansion efforts â€”<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Per%20its%20S,its%20current%20commitments."> <u>the theoretical 1.3 gigawatts of contracted (translation: does not exist yet) compute</u></a> â€” are largely (if not entirely) for the benefit of OpenAI.</p><p><strong>In the event that OpenAI cannot fulfil its obligations, CoreWeave will collapse.</strong> It is that simple.&nbsp;</p><h3 id="nvidia-relies-on-coreweave-for-more-than-6-of-its-revenue-and-coreweaves-future-creditworthiness-to-continue-receiving-it-%E2%80%94-much-of-which-is-dependent-on-openai"><strong>NVIDIA Relies On CoreWeave For More Than 6% Of Its Revenue, And CoreWeave's Future Creditworthiness To Continue Receiving It â€” Much Of Which Is Dependent On OpenAI</strong></h3><p>Iâ€™m basing this on a comment I received from Gil Luria, Managing Director and Head of Technology Research at analyst D.A. Davidson &amp; Co:</p><blockquote>Since CRWV bought 200,000 GPUs last year and those systems are around $40,000 we believe CRWV spent $8 billion on NVDA last year. That represents more than 6% of NVDAâ€™s revenue last year.&nbsp;</blockquote><p>CoreWeave receives preferential access to NVIDIA's GPUs, and makes up billions of dollars of its revenue.<a href="https://www.ft.com/content/41bfacb8-4d1e-4f25-bc60-75bf557f1f21?ref=wheresyoured.at"> <u>CoreWeave then takes those GPUs and raises debt using them as collateral</u></a>, then proceeds to buy more of those GPUs from NVIDIA. NVIDIA was the anchor for CoreWeave's IPO, and CEO Michael Intrator said that the IPO "wouldn't have closed" without NVIDIA buying $250 million worth of shares.<a href="https://www.theinformation.com/articles/project-osprey-how-nvidia-seeded-coreweaves-rise?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>NVIDIA invested $100 million in the early days of CoreWeave</u></a>, and, for reasons I cannot understand, also agreed to spend $1.3 billion over four years to, and I quote The Information, "rent its own chips from CoreWeave."</p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=potentially%20fatal%20%E2%80%94%20vulnerability.-,Sidenote,-%3A%20On%20the%20subject"><u>Buried in CoreWeave's S-1 â€” the document every company publishes before going public â€”&nbsp; was a warning about counterparty credit risk</u></a>, which is when one party provides services or goods to another with specific repayment terms, and the other party not meeting their side of the deal. While this was written as a theoretical (as it could, in theoretically, come from any company to which CoreWeave acts as a creditor) it only named one company: OpenAI.&nbsp;</p><p>As discussed previously, CoreWeave is saying that, should a customer â€” any customer, but really, it means OpenAI â€” fail to pay its bills for infrastructure built on their behalf, or for services rendered, it could have a material risk to the business.</p><blockquote><strong>Aside:</strong><a href="https://www.theinformation.com/articles/google-advanced-talks-rent-nvidia-ai-servers-coreweave?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that Google is in "advanced talks" to rent GPUs from CoreWeave</u></a>. It also, when compared to Microsoft and OpenAI's deals with CoreWeave, noted that "...Google's potential deal with CoreWeave is "significantly smaller than those commitments, according to one of the people briefed on it, but could potentially expand in future years."</blockquote><p>CoreWeave's continued ability to do business hinges heavily on its ability to raise further debt (<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Two%20%E2%80%94%20CoreWeave%20Has%20Taken%20On%20A%20Fatal%20Amount%20of%20Debt"><u>which I have previously called into question</u></a>), and its ability to raise further debt is,<a href="https://www.ft.com/content/163c6927-2032-4346-857e-8e3787e4babc?ref=wheresyoured.at"> <u>to quote the Financial Times</u></a>, "secured against its more than 250,000 Nvidia chips and its contracts with customers, such as Microsoft." Any future debt that CoreWeave raises would be based upon its contract with OpenAI (you know, the counterparty credit risk threat that represents a disproportionate share of its revenue) and whatever GPUs it still has to collateralize.</p><p>As a result, a chunk of NVIDIA's future revenue is dependent on OpenAI's ability to fulfil its obligations to CoreWeave, both in its ability to pay them and their timeliness in doing so. If OpenAI fails, then CoreWeave fails, which then hurts NVIDIA.&nbsp;</p><p>Contagion.&nbsp;</p><h3 id="openais-expansion-is-dependent-on-two-unproven-startups-who-are-also-dependent-on-openai-to-live"><strong>OpenAI's Expansion Is Dependent On Two Unproven Startups, Who Are Also Dependent on OpenAI To Live</strong></h3><p>With Microsoft's data center pullback and OpenAI's intent to become independent from Redmond, future data center expansion is based on two partners supporting CoreWeave and Oracle: Crusoe and Core Scientific, neither of which appear to have ever built an AI data center.</p><p>I also must explain how <em>difficult</em> building a data center is, and how said difficulty increases when you're building an AI-focused data center. For example,<a href="https://www.theinformation.com/articles/nvidia-customers-worry-about-snag-with-new-ai-chip-servers?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>NVIDIA had to delay the launch of its Blackwell GPUs because of how finicky the associated infrastructure</u></a> (the accompanying servers and cooling them) is. <em>For customers that already had experience handling GPUs, and therefore likely know how to manage the extreme temperatures created by them.</em></p><p><em>As another reminder,</em> OpenAI is on the hook for $19 billion of funding behind Stargate, money that neither it nor SoftBank has right now.</p><p>Imagine if you didn't have any experience, and effectively had to learn from scratch? How do you think that would go?</p><p>We're about to find out!</p><h3 id="crusoestargateabilene-texas"><strong>Crusoe - Stargate - Abilene Texas</strong></h3><p><strong>Crusoe </strong>is a former cryptocurrency mining company that<a href="https://techcrunch.com/2024/11/21/crusoe-a-rumored-openai-data-center-supplier-has-secured-686m-in-new-funds-filing-shows/?ref=wheresyoured.at"> <u>has now raised hundreds of millions of dollars</u></a> to build data centers for AI companies, starting with<a href="https://www.theinformation.com/briefings/crusoe-in-talks-to-raise-several-billion-dollars-for-oracle-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>a $3.4 billion data center financing deal with asset manager Blue Owl Capital</u></a>. This (yet-to-be-completed) data center has now been leased by Oracle, which will, allegedly, fill it full of GPUs for OpenAI.</p><p>Despite calling itself "the industryâ€™s first vertically integrated AI infrastructure provider," with the company using <a href="https://www.datacenterdynamics.com/en/news/crusoe-to-deploy-gas-flare-data-centers-in-utah/?ref=wheresyoured.at"><u>flared gas (a waste byproduct of oil production) to power IT infrastructure</u></a>, Crusoe does not appear to have built an AI data center, and is now being tasked with<a href="https://crusoe.ai/blog/crusoe-expands-ai-data-center-campus-in-abilene-to-1-2-gigawatts/?ref=wheresyoured.at"> <u>building a 1.2 Gigawatt data center campus for OpenAI</u></a>.</p><p>Crusoe is the sole developer and operator of the Abilene site, meaning, according to<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information</u></a>, "...is in charge of contracting with construction contractors and data center customers, as well as running the data center after it is built."</p><p>Oracle, it seems, will be responsible for<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>filling said data center with GPUs and the associated hardware</u></a>.</p><p>Nevertheless, the project appears to be behind schedule.</p><p>The Information reported in October 2024 that Abeline was meant to have "...<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"><u>50,000 of NVIDIA's [Blackwell] AI chips...in the first quarter of [2025</u></a>]," and also suggested that the site was projected to have 100,000 Blackwell chips by the end of 2025.</p><p>Here in reality,<a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"> <u>a report from Bloomberg in March 2025</u></a> (that I cited previously) said that OpenAI and Oracle were expected to have <em>16,000 GPUs</em> available <em>by the Summer of 2025, </em>with "...OpenAI and oracle are expected to deploy 64,000 NVIDIA GB200s at the Stargate data center...by the end of 2026."</p><p>As discussed above, OpenAI <em>needs this capacity</em>.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>According to The Information</u></a>, OpenAI expects Stargate to handle three-quarters of its compute by 2030, and these delays call into question at the very least whether this schedule is reasonable, if not whether Stargate, as a project, is actually possible.</p><h3 id="core-scientificcoreweavedenton-texas"><strong>Core Scientific - CoreWeave - Denton Texas</strong></h3><p>I've written a great deal about CoreWeave in the past,<a href="https://www.wheresyoured.at/optimistic-cowardice/"> <u>and specifically about its buildout partner Core Scientific</u></a>, a cryptocurrency mining company (yes, <em>another one</em>) that has exactly one customer for AI data centers â€” CoreWeave.</p><p>A few notes:</p><ul><li>Core Scientific was bankrupt last year.</li><li>Core Scientific has never built an AI data center, and its cryptocurrency mining operations were built around ASICs â€” specialist computers for mining Bitcoin â€”<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Needham%20analysts%20wrote%20in%20a%20report%20in%20May%20that%20almost%20all%20infrastructure%20that%20miners%20currently%20have%20would%20%E2%80%9Cneed%20to%20be%20bulldozed%20and%20built%20from%20the%20ground%20up%20to%20accommodate%20HPC%2C%E2%80%9D%20or%20high%2Dperformance%20computing.%C2%A0"> <u>which led an analyst to tell CNBC</u></a> that said data centers would "<a href="https://www.cnbc.com/2024/08/06/bitcoin-miner-core-scientific-expands-coreweave-deal-to-6point7-billion.html?ref=wheresyoured.at#:~:text=Needham%20analysts%20wrote%20in%20a%20report%20in%20May%20that%20almost%20all%20infrastructure%20that%20miners%20currently%20have%20would%20%E2%80%9Cneed%20to%20be%20bulldozed%20and%20built%20from%20the%20ground%20up%20to%20accommodate%20HPC%2C%E2%80%9D%20or%20high%2Dperformance%20computing."><u>need to be bulldozed and built up from the ground up</u></a>" to accommodate AI compute.</li><li>Core Scientific does not appear to have any meaningful AI compute of any kind. Its AI/HPC (high-performance computing) revenue represents a tiny, tiny percentage of its overall revenue, which still comes primarily from mining crypto, both for itself and for third-parties.&nbsp;</li><li><a href="https://investors.corescientific.com/news-events/press-releases/detail/110/core-scientific-and-coreweave-announce-1-2-billion-expansion-at-denton-tx-site?ref=wheresyoured.at"><u>CoreWeave's entire 1.3 Gigawatt buildout appears to be being handled by Core Scientific</u></a>.</li></ul><p>Core Scientific is also, it seems, taking on $1.14 billion of capital expenditures to build out these data centers,<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Core%20Scientific%2C%20according%20to%20its%2010%2DK%20form%3A"> <u>with CoreWeave promising to reimburse $899.3 million of these costs</u></a>.</p><p>It's also unclear how Core Scientific intends to do this. While itâ€™s taken on a good amount of debt in the past â€”<a href="https://investors.corescientific.com/news-events/press-releases/detail/102/core-scientific-prices-upsized-550-million-convertible-senior-notes-offering?ref=wheresyoured.at"> <u>$550 million in a convertible note toward the end of 2024</u></a> â€” this would be more debt than itâ€™s ever taken on.</p><p>It also, as with Crusoe, does not appear to have any experience building AI data centers, except unlike Crusoe, Core Scientific is a barely-functioning recently-bankrupted bitcoin miner pretending to be a data center company.</p><p>How important is CoreWeave to OpenAI exactly?<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at#:~:text=%E2%80%9CCoreWeave%20has%20been,very%2C%20very%20quickly.%E2%80%9D"> <u>From Semafor</u></a>:</p><blockquote>â€œCoreWeave has been one of our earliest and largest compute partners,â€ OpenAI chief Sam Altman said in CoreWeaveâ€™s roadshow <a href="https://www.netroadshow.com/custom/IPO/CoreWeave/retail/disclaimer.html?ref=wheresyoured.at"><u>video</u></a>, adding that CoreWeaveâ€™s computing power â€œled to the creation of some of the models that weâ€™re best known for.â€<p>â€œCoreweave figured out how to innovate on hardware, to innovate on data center construction, and to deliver results very, very quickly.â€</p></blockquote><p>But will it survive long term?</p><p>Going back to the point of contagion: If OpenAI fails, and CoreWeave fails, so too does Core Scientific. And I donâ€™t fancy Crusoeâ€™s chances, either. At least Crusoe isnâ€™t public.</p><h3 id="an-open-question-does-microsoft-book-openais-compute-as-revenue"><strong>An Open Question: Does Microsoft Book OpenAI's Compute As Revenue?</strong></h3><p>Up until fairly recently, Microsoft has been the entire infrastructural backbone of OpenAI, but recently (to free OpenAI up to work with Oracle)<a href="https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/?ref=wheresyoured.at"> <u>released it from its exclusive cloud compute deal</u></a>. Nevertheless,<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"> <u>per The Information</u></a>, OpenAI still intends to spend $13 billion on compute on Microsoft Azure this year.</p><p>What's confusing, however, is whether any of this is booked as <em>revenue.</em> Microsoft claimed earlier in this year that it surpassed $13 billion in annual recurring revenue â€” by which it means its last month multiplied by 12 â€”<a href="https://www.marketwatch.com/livecoverage/microsoft-earnings-stock-results-azure-cloud-ai-deepseek/card/microsoft-says-ai-revenue-has-surpassed-13-billion-annual-run-rate-4d7JEBh564bN1pCGbGI6?ref=wheresyoured.at"> <u>from artificial intelligence</u></a>.<a href="https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?ref=wheresyoured.at&amp;rc=kz8jh3"> <u>OpenAI's compute costs in 2024 were $5 billion</u></a>, at a<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=OpenAI%20pays%20just%20over%2025%25%20of%20the%20cost%20of%20Azure%E2%80%99s%20GPU%20compute%20as%20part%20of%20its%20deal%20with%20Microsoft%20%E2%80%94%20around%20%241.30%2Dper%2DGPU%2Dper%2Dhour%20versus%20the%20regular%20Azure%20cost%20of%20%243.40%20to%20%244."> <u>discounted Azure rate</u></a>, which, on an annualized basis, would be around $416 million in revenue a month for Microsoft.</p><p>It isn't, however, clear whether Microsoft counts OpenAI's compute spend as revenue.</p><p>Microsoft's earnings do not include an "artificial intelligence" section, but<a href="https://www.microsoft.com/en-us/investor/segment-information?ref=wheresyoured.at"> <u>three separate segments</u></a>:</p><ul><li>Productivity and Business Processes, which includes things like Microsoft 365, LinkedIn, Dynamics 365 and other business processing software.</li><li>More Personal Computing, which includes Windows and Gaming Products</li><li>Intelligent Cloud, Including server products and cloud services like Azure, which is likely where OpenAI's compute is included.</li></ul><p>As a result, it's hard to say specifically where OpenAI's revenue sits, but based on an analysis of Microsoft's Intelligent Cloud segment from FY23 Q1 (note, financial years donâ€™t always correspond with the calendar year,<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q2/press-release-webcast?os=httpwww.szxlp.xyz&amp;ref=app"> <u>so we just finished FY25 Q2 in January</u></a>) through to its most recent earnings, and found that there was a spike in revenue from FY23 Q1 to FY24 Q1.&nbsp;</p><p>In FY23 Q1 (which ended on <a href="https://www.microsoft.com/en-us/investor/earnings/fy-2023-q1/press-release-webcast?ref=wheresyoured.at"><u>September 30, 2022</u></a>, a month before ChatGPT's launch),&nbsp; the segment made $20.3 billion. The following year, in FY24 Q1, it made $24.3 billion â€” a 19.7% year-over-year (or roughly $4 billion) increase.</p><p>This could represent the massive increase in training and inference costs associated with hosting ChatGPT,<a href="https://www.microsoft.com/en-us/investor/earnings/fy-2024-q4/press-release-webcast?ref=wheresyoured.at"> <u>peaking at $28.5 billion in revenue in FY24 Q4</u></a> â€” before dropping dramatically to $24.1 billion in<a href="https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/press-release-webcast?ref=wheresyoured.at"> <u>FY25 Q1</u></a> and raising a little to $25.5 billion in<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q2/press-release-webcast?os=httpwww.szxlp.xyz&amp;ref=app"> <u>FY25 Q2</u></a>.</p><p>OpenAI spent 2023 training its GPT-4o model before transitioning to its massive, expensive "Orion" model which would eventually become GPT 4.5, as well as its video generation model "Sora."<a href="https://www.wsj.com/tech/ai/openai-gpt5-orion-delays-639e7693?ref=wheresyoured.at"> <u>According to the Wall Street Journal</u></a>, training GPT 4.5 involved at least one training run costing "around half a billion dollars in computing costs alone."</p><p>These are huge sums, but itâ€™s worth noting a couple of things. First, Microsoft licenses OpenAIâ€™s models to third parties, so some of this revenue could be from other companies using GPT on Azure. And thereâ€™s also other companies running their own models on Azure. Weâ€™ve seen a lot of companies launch AI products, and not all of them are based on LLMs.</p><p>Muddling things further, Microsoft provides OpenAI access to Azure cloud services at a discounted rate. And so, thereâ€™s a giant question mark over OpenAIâ€™s contribution to the various spikes in revenue for Microsoftâ€™s Intelligent Cloud segment, or whether other third-parties played a significant role.&nbsp;</p><p>Furthermore, Microsoftâ€™s investment in OpenAI isnâ€™t entirely in cold, hard cash. Rather, it has provided the company with credits to be redeemed on Azure services. Iâ€™m not entirely sure how this would be represented on accounting terms, and if anyone can shed light on this, please get in touch.&nbsp;</p><p>Would it be noted as revenue, or something else? OpenAI isnâ€™t paying Microsoft, but rather doing the tech equivalent of redeeming some airmiles, or spending a gift card.&nbsp;</p><p>Additionally, while equity is often treated as income for tax purposes â€” as is the case when an employee receives RSUs as part of their compensation package â€” under the existing OpenAI structure, Microsoft isnâ€™t a shareholder but rather the owner of profit-sharing units. This is a distinction worth noting.&nbsp;&nbsp;</p><p>These profit-sharing units are treated as analogous to equity, at least in terms of OpenAIâ€™s ability to raise capital, but in practice they arenâ€™t the same thing. They donâ€™t represent ownership in the company as directly as, for example, a normal share unit would. They lack the liquidity of a share, and the upside they provide â€” namely, dividends â€” is purely theoretical.&nbsp;</p><p>Another key difference: when a company goes bankrupt and enters liquidation, shareholders can potentially receive a share of the proceeds (after other creditors, employees, etc are paid). While that often doesnâ€™t happen (as in, the liabilities far exceed the assets of the company), itâ€™s at least theoretically possible. Given that profit-sharing units arenâ€™t actually shares, where does that leave Microsoft?</p><p>This stuff is confusing, and Iâ€™m not ashamed to say that complicated accounting questions like these are far beyond my understanding. If anyone can shed some light, drop me an email, or a message on Twitter or BlueSky, or post on the Better Offline subreddit.&nbsp;</p><h2 id="the-future-of-generative-ai-rests-on-openai-and-openais-future-rests-on-near-impossible-financial-requirements"><strong>The Future of Generative AI Rests On OpenAI, And OpenAI's Future Rests On Near-Impossible Financial Requirements</strong></h2><p>I have done my best to write this piece in as objective a tone as possible, regardless of my feelings about the generative AI bubble and its associated boosters.</p><p>OpenAI,<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Is%20Generative%20AI%20A%20Real%20Industry%3F"> <u>as I've written before</u></a>, is effectively the entire generative AI industry, with its nearest competitor being less than five percent of its 500 million weekly active users.</p><p>Its future is dependent â€” and this is not an opinion, but objective fact â€” on effectively infinite resources.</p><h3 id="financial-resources"><strong>Financial Resources</strong></h3><p>If it required $40 billion to continue operations this year, it is reasonable to believe it will need at least another $40 billion next year, and based on its internal projections, will need at least that every single other year until 2030, when it claims, somehow, it will be profitable "with the completion of the Stargate data center."</p><h3 id="compute-resources-and-expansion"><strong>Compute Resources and Expansion</strong></h3><p>OpenAI requires more compute resources than anyone has ever needed, and will continue to do so in perpetuity. Building these resources is now dependent on two partners â€” Core Scientific and Crusoe â€” that have never built a data center, as Microsoft has materially pulled back on data center development, which have (as well as the aforementioned pullback on 2GW of data centers)<a href="https://www.linkedin.com/posts/noelle-walsh-b29356108_microsoftcloud-datacenters-activity-7315439628562423808-W67e/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAACNp-u0B8oyS6pLtatitYCwLv1mvyLXiCvk"> <u>"slowed or paused" some of its "early stage" data center projects</u></a>. This shift is directly linked to Microsoftâ€™s relationship with OpenAI, withTD Cowen's recent analyst report saying that data center pullbacks were, and I quote its March 26 2025 data center channel checks letter, "...driven by the decision to not support incremental OpenAI training workloads."</p><p>In simpler terms, OpenAI needs more compute at a time when its lead backer,<a href="https://www.datacenterdynamics.com/en/news/microsoft-bought-twice-as-many-nvidia-hopper-gpus-as-other-big-tech-companies-report/?ref=wheresyoured.at"> <u>which has the most GPUs in the world</u></a>, has specifically walked away from building it.</p><p>Even in my most optimistic frame of mind, it isn't realistic to believe that Crusoe or Core Scientific can build the data centers necessary for OpenAI's expansion.</p><p>Even if SoftBank and OpenAI had the money to invest in Stargate <em>today</em>, dollars do not change the fabric of reality. Data centers take time to build, requiring concrete, wood, steel and other materials to be manufactured and placed, and that's after the permitting required to get these deals done. Even if that succeeds, getting the power necessary is a challenge unto itself, to the point that even Oracle, an established and storied cloud compute company,<a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>to quote The Information</u></a>, "...has less experience than its larger rivals in dealing with utilities to secure power and working with powerful and demanding cloud customers whose plans change frequently."</p><p>A partner like Crusoe or Core Scientific simply doesn't have the muscle memory or domain expertise that Microsoft has when it comes to building and operating data centers. As a result, it's hard to imagine even in the <em>best case scenario</em> that they're able to match the hunger for compute that OpenAI has.</p><p>Now, I want to be clear â€” I believe OpenAI will still continue to use Microsoft's compute, and even expand further into whatever remaining compute Microsoft may have. However, there is now a hard limit on how much of it there's going to be, both literally (in what's physically available) and in what Microsoft itself will actually OpenAI them to use, especially given how unprofitable GPU compute might be.</p><h2 id="how-does-this-end"><strong>How Does This End?</strong></h2><p>Last week, a truly offensive piece of fan fiction â€” framed as a "report" â€”<a href="https://ai-2027.com/?ref=wheresyoured.at"> <u>called AI 2027 went viral</u></a>, garnering press coverage with<a href="https://www.dwarkesh.com/p/scott-daniel?ref=wheresyoured.at"> <u>the Dwarkesh Podcast</u></a> and<a href="https://www.nytimes.com/2025/04/03/technology/ai-futures-project-ai-2027.html?ref=wheresyoured.at"> <u>gormless, child-like wonder from the New York Times' Kevin Roose</u></a>. Its predictions vaguely suggest a theoretical company called OpenBrain will invent a self-teaching agent of some sort.</p><p>It's bullshit, but it captured the hearts and minds of AI boosters because it vaguely suggests that somehow Large Language Models and their associated technology will become something entirely different.</p><p>I don't like making predictions like these because the future â€” especially in our current political climate â€” is so chaotic, but I will say that I do not see, and I say this with complete objectivity, how any of this continues.</p><p>I want to be <strong>extremely blunt</strong> with the following points, as I feel like both members of the media and tech analysts have failed to express how ridiculous things have become. I will be repeating myself, but it's necessary, as I <strong>need you to understand how untenable things are.</strong></p><ul><li>SoftBank is putting itself in dire straits <em>simply to fund OpenAI once. </em>This deal threatens its credit rating, with SoftBank having to take on what will be multiple loans <strong>to fund OpenAI's $40 billion round.<u> OpenAI will need at least another $40 billion in the next year.</u></strong><ul><li>This is before you consider the other $19 billion that SoftBank has agreed to contribute to the Stargate data center project, money that it does not currently have available.</li></ul></li><li>OpenAI has promised $19 billion to the Stargate data center project, money it <strong>does not have</strong> and <strong>cannot get without SoftBank's funds.</strong><ul><li><strong><u>Again, neither SoftBank nor OpenAI has the money for Stargate right now.</u></strong></li></ul></li><li>OpenAI <em>needs Stargate to get built to grow much further.</em></li></ul><p>I see no way in which OpenAI can continue to raise money at this rate, <em>even if OpenAI somehow actually receives the $40 billion, which will require it becoming a for-profit entity. </em>While it could theoretically stretch that $40 billion to last multiple years,<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>projections say itâ€™ll burn $320 billion in the next five years</u></a>.</p><p>Or, more likely, I canâ€™t see a realistic way in which OpenAI gets the resources it needs to survive. Itâ€™ll need a streak of unlikely good fortune, the kind of which you only ever hear about in Greek epic poems:&nbsp;</p><ul><li>SoftBank somehow gets the resources (and loses the constraints) required to bankroll it indefinitely.&nbsp;</li><li>The worldâ€™s wealthiest entities â€” those sovereign wealth funds mentioned earlier, the Saudis and so on&nbsp; â€” pick up the slack each year until OpenAI reaches productivity (assuming it does).</li><li>It has enough of those mega-wealthy benefactors to provide the $320bn it needs before it reaches profitability.</li><li>Crusoe and CoreScientific turn out to be really good at building AI infrastructure â€” something theyâ€™ve never done before.&nbsp;</li><li>Microsoft walks-back its walk-back on building new AI infrastructure and recommits to the tens of billions of dollars of capex spending it previously floated.&nbsp;</li><li>Stargate construction happens faster than expected, and there are no supply chain issues (in terms of labor, building materials, GPUs, and so on).</li></ul><p>If those things happen, Iâ€™ll obviously find myself eating crow. But Iâ€™m not worried.&nbsp;</p><p>In the present conditions, OpenAI is on course to run out of money or compute capacity, and it's unclear which will happen first.</p><h2 id="its-time-to-wake-up"><strong>It's Time To Wake Up</strong></h2><p>Even in a hysterical bubble where everybody is agreeing that this is the future, OpenAI currently requires more money and more compute than is reasonable to acquire. <em>Nobody</em> has ever raised as much as OpenAI needs to, and based on the sheer amount of difficulty that SoftBank is having in raising the funds to meet <em>the lower tranche ($10bn) of its commitment, </em>it may simply not be possible for this company to continue.</p><p>Even with <em>extremely</em> preferential payment terms â€” months-long deferred payments, for example â€” at some point somebody is going to need to get paid.</p><p>I will give Sam Altman credit. He's found many partners to shoulder the burden of the rotten economics of OpenAI, with Microsoft, Oracle, Crusoe and CoreWeave handling the up-front costs of building the infrastructure, SoftBank finding the investors for its monstrous round, and the tech media mostly handling his marketing for him.</p><p>He is, however, over-leveraged. OpenAI has never been forced to stand on its own two feet or focus on efficiency, and I believe the constant enabling of its ugly, nonsensical burnrate has doomed this company. OpenAI has acted like itâ€™ll always have more money and compute, and that people will always believe its bullshit, mostly because up until recently <em>everybody has.</em></p><p>OpenAI cannot "make things cheaper" at this point, because the money has always been there to make things more expensive, as has the compute to make larger language models that burn billions of dollars a year. This company is not built to reduce its footprint in any way, nor is it built for a future in which it wouldn't have access to, as I've said before, infinite resources.</p><p>Worse still, investors and the media have run cover for the fact that these models don't really do much more than they did a year ago and for<a href="https://www.wheresyoured.at/godot-isnt-making-it/"> <u>the overall diminishing returns of Large Language Models</u></a>.</p><p>I have had many people <em>attack</em> my work about OpenAI, but none have provided any real counterpoint to<a href="https://www.wheresyoured.at/to-serve-altman/"> <u>the underlying economic argument I've made since July of last year</u></a> that OpenAI is unsustainable. This is likely because there really isn't one, other than "OpenAI will continue to raise more money than anybody has ever raised in history, in perpetuity, and will somehow turn from the least-profitable company of all time to a profitable one."</p><p>This isnâ€™t a rational argument. Itâ€™s a religious one. Itâ€™s a call for faith.&nbsp;</p><p>And I see no greater pale horse of the apocalypse than Microsoft's material pullback on data centers. While the argument might be that Microsoft wants OpenAI to have an independent future, that's laughable when you consider Microsoft's deeply monopolistic tendencies â€” and, for that matter, it owns a massive proportion of OpenAIâ€™s pseudo-equity. At one point, Microsoftâ€™s portion was valued at 49 percent. And while additional fundraising has likely diluted Microsoftâ€™s stake, it still â€œownsâ€ a massive proportion of what is (at least) the most valuable private startup of all time.</p><p>And weâ€™re supposed to believe that Microsoftâ€™s pullback â€” which limits OpenAIâ€™s access to the infrastructure it needs to train and run its models, and thus (as mentioned) represents an existential threat to the company â€” is because of some paternal desire to see OpenAI leave the childhood bedroom, spread its wings, and enter the real world? Behave.&nbsp;</p><p>More likely, Microsoft got what it needed out of OpenAI, which has reached the limit of the models it can develop, and which Microsoft already retains the IP of. Thereâ€™s probably no reason to make any further significant investments, though they allegedly may be part of the initial $10 billion tranche of OpenAIâ€™s next round.</p><p>It's also important to note that absolutely nobody <em>other than NVIDIA </em>is making any money from generative AI. CoreWeave loses billions of dollars, OpenAI loses billions of dollars, Anthropic loses billions of dollars, and I can't find a single company providing generative AI-powered software that's making a profit. The only companies even <em>close</em> to doing so are consultancies providing services to train and create data for models like Turing and Scale AI â€” and<a href="https://www.bloomberg.com/news/articles/2025-04-02/scale-ai-expects-to-more-than-double-sales-to-2-billion-in-2025?ref=wheresyoured.at"> <u>Scale isn't even profitable</u></a>.</p><p>The knock-on effects of OpenAI's collapse will be wide-ranging. Neither CoreWeave nor Crusoe will have tenants for their massive, unsustainable operations, and Oracle will have nobody to sell the compute itâ€™s leased from Crusoe for the next 15 years. CoreWeave will likely collapse under the weight of its abominable debt, which will lead to a 7%+ revenue drop for NVIDIA at a time when revenue growth has already begun to slow.</p><p>On a philosophical level, OpenAI's health is what keeps this industry alive.<a href="https://www.wheresyoured.at/wheres-the-money/"> <u>OpenAI has the only meaningful userbase in generative AI</u></a>, and this entire hype-cycle has been driven by its success, meaning any deterioration (or collapse) of OpenAI will tell the market what I've been saying for over a year: that generative AI is not the next hyper-growth market, and its underlying economics do not make sense.</p><p>I am not writing this to be "right" or "be a hater."</p><p>If something changes, and I am wrong somehow, I will write exactly how, and why, and what mistakes I made to come to the conclusions I have in this piece.</p><p>I do not believe that my peers in the media will do the same when this collapses, but I promise you that they will be held accountable, because all of this abominable waste could have been avoided.</p><p>Large Language Models are not, on their own, the problem. They're tools, capable of some outcomes, doing some things, but the problem, ultimately, are the extrapolations made about their abilities, and the unnecessary drive to make them larger, even if said largeness never amounted to much.</p><p>Everything that I'm describing is the result of a tech industry â€” including media and analysts â€” that refuses to do business with reality, trafficking in ideas and ideology, celebrating victories that have yet to take place, applauding those who have yet to create the things they're talking about, cheering on men lying about what's possible so that they can continue to burn billions of dollars and increase their wealth and influence.</p><p>I understand why others might not have written this piece. What I am describing is a systemic failure, one at a scale hereto unseen, one that has involved so many rich and powerful and influential people agreeing to ignore reality, and thatâ€™ll have crushing impacts for the wider tech ecosystem when it happens.</p><p>Don't say I didn't warn you.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists: Protein IL-17 fights infection, acts on the brain, inducing anxiety (106 pts)]]></title>
            <link>https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html</link>
            <guid>43682686</guid>
            <pubDate>Mon, 14 Apr 2025 15:54:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html">https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html</a>, See on <a href="https://news.ycombinator.com/item?id=43682686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/anxiety.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/anxiety.jpg" data-sub-html="Credit: Andrew Neel from Pexels">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/anxiety.jpg" alt="anxiety" title="Credit: Andrew Neel from Pexels" width="800" height="530">
             <figcaption>
                Credit: Andrew Neel from Pexels
            </figcaption>        </figure>
    </div><p>Immune molecules called cytokines play important roles in the body's defense against infection, helping to control inflammation and coordinating the responses of other immune cells. A growing body of evidence suggests that some of these molecules also influence the brain, leading to behavioral changes during illness.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>Two new studies from MIT and Harvard Medical School, focusing on a cytokine called IL-17, now add to that evidence. The researchers found that IL-17 acts on two distinct brain regionsâ€”the amygdala and the somatosensory cortexâ€”to exert two divergent effects. In the amygdala, IL-17 can elicit feelings of anxiety, while in the cortex it promotes sociable behavior.</p>
<p>These findings suggest that the immune and nervous systems are tightly interconnected, says Gloria Choi, an associate professor of brain and cognitive sciences, a member of MIT's Picower Institute for Learning and Memory, and one of the senior authors of the studies.</p>
<p>"If you're sick, there's so many more things that are happening to your internal states, your mood, and your behavioral states, and that's not simply you being fatigued physically. It has something to do with the brain," she says.</p>
<p>Jun Huh, an associate professor of immunology at Harvard Medical School, is also a senior author of both studies, which appear in <i>Cell</i>. One of the papers was led by Picower Institute Research Scientist Byeongjun Lee and former Picower Institute research scientist Jeong-Tae Kwon, and the other was led by Harvard Medical School postdoc Yunjin Lee and Picower Institute postdoc Tomoe Ishikawa.</p>
<h2>Behavioral effects</h2>
<p>Choi and Huh became interested in IL-17 several years ago, when they found it was involved in a phenomenon known as the fever effect. Large-scale studies of autistic children have found that for many of them, their behavioral symptoms temporarily diminish when they have a fever.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>In a <a href="https://medicalxpress.com/news/2019-12-infections-autism-symptoms.html">2019 study</a> in mice, Choi and Huh showed that in some cases of infection, IL-17 is released and suppresses a small region of the brain's cortex known as S1DZ. Overactivation of neurons in this region can lead to autism-like behavioral symptoms in mice, including repetitive behaviors and reduced sociability.</p>
<p>"This molecule became a link that connects immune system activation, manifested as a fever, to changes in <a href="https://medicalxpress.com/tags/brain+function/" rel="tag">brain function</a> and changes in the animals' behavior," Choi says.</p>
<p>IL-17 comes in six different forms, and there are five different receptors that can bind to it.</p>
<p>In their two new papers, the researchers set out to map which of these receptors are expressed in different parts of the brain. This mapping revealed that a pair of receptors known as IL-17RA and IL-17RB is found in the cortex, including in the S1DZ region that the researchers had previously identified. The receptors are located in a population of neurons that receive proprioceptive input and are involved in controlling behavior.</p>
<p>When a type of IL-17 known as IL-17E binds to these receptors, the neurons become less excitable, which leads to the behavioral effects seen in the 2019 study.</p>
<p>"IL-17E, which we've shown to be necessary for behavioral mitigation, actually does act almost exactly like a neuromodulator in that it will immediately reduce these neurons' excitability," Choi says.</p>
<p>"So, there is an immune molecule that's acting as a neuromodulator in the brain, and its main function is to regulate excitability of neurons."</p>
<p>Choi hypothesizes that IL-17 may have originally evolved as a neuromodulator, and later on was appropriated by the immune system to play a role in promoting inflammation.</p>
<p>That idea is consistent with previous work showing that in the worm C. elegans, IL-17 has no role in the immune system but instead acts on neurons. Among its effects in worms, IL-17 promotes aggregation, a form of social behavior. Additionally, in mammals, IL-17E is actually made by neurons in the cortex, including S1DZ.</p>
<p>"There's a possibility that a couple of forms of IL-17 perhaps evolved first and foremost to act as a neuromodulator in the brain, and maybe later were hijacked by the immune system also to act as immune modulators," Choi says.</p>

                                                                                                                                            <h2>Provoking anxiety</h2>
<p>In the other <i>Cell</i> paper, the researchers explored another brain location where they found IL-17 receptorsâ€”the amygdala. This almond-shaped structure plays an important role in processing emotions, including fear and anxiety.</p>
<p>That study revealed that in a region known as the basolateral amygdala (BLA), the IL-17RA and IL-17RE receptors, which work as a pair, are expressed in a discrete population of neurons. When these receptors bind to IL-17A and IL-17C, the neurons become more excitable, leading to an increase in anxiety.</p>
<p>The researchers also found that, counterintuitively, if animals are treated with antibodies that block IL-17 receptors, it actually increases the amount of IL-17C circulating in the body. This finding may help to explain unexpected outcomes observed in a clinical trial of a drug targeting the IL-17-RA receptor for psoriasis treatment, particularly regarding its potential adverse effects on mental health.</p>
<p>"We hypothesize that there's a possibility that the IL-17 ligand that is upregulated in this patient cohort might act on the brain to induce suicide ideation, while in animals there is an anxiogenic phenotype," Choi says.</p>
<p>During infections, this anxiety may be a beneficial response, keeping the sick individual away from others to whom the infection could spread, Choi hypothesizes.</p>
<p>"Other than its main function of fighting pathogens, one of the ways that the immune system works is to control the host behavior, to protect the host itself and also protect the community the host belongs to," she says. "One of the ways the immune system is doing that is to use cytokines, secreted factors, to go to the brain as communication tools."</p>
<p>The researchers found that the same BLA neurons that have receptors for IL-17 also have receptors for IL-10, a cytokine that suppresses inflammation. This molecule counteracts the excitability generated by IL-17, giving the body a way to shut off anxiety once it's no longer useful.</p>

                                                                                                                                                                                                                                                                                                    <h2>Distinctive behaviors</h2>
<p>Together, the two studies suggest that the immune system, and even a single family of cytokines, can exert a variety of effects in the brain.</p>
<p>"We have now different combinations of IL-17 receptors being expressed in different populations of neurons, in two different brain regions, that regulate very distinct behaviors. One is actually somewhat positive and enhances social behaviors, and another is somewhat negative and induces anxiogenic phenotypes," Choi says.</p>
<p>Her lab is now working on additional mapping of IL-17 receptor locations, as well as the IL-17 molecules that bind to them, focusing on the S1DZ region. Eventually, a better understanding of these neuro-immune interactions may help researchers develop new treatments for neurological conditions such as autism or depression.</p>
<p>"The fact that these molecules are made by the immune system gives us a novel approach to influence brain function as a means of therapeutics," Choi says. "Instead of thinking about directly going for the brain, can we think about doing something to the immune system?"</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Inflammatory and anti-inflammatory cytokines bidirectionally modulate amygdala circuits regulating anxiety, <i>Cell</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2025.03.005" target="_blank">DOI: 10.1016/j.cell.2025.03.005</a>. <a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00278-8" target="_blank">www.cell.com/cell/fulltext/S0092-8674(25)00278-8</a>
</p><p>Brain-wide mapping of immune receptors uncovers a neuro-modulatory role of interleukin-17E and the receptor IL-17RB., <i>Cell</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2025.03.006" target="_blank">DOI: 10.1016/j.cell.2025.03.006</a>. <a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00279-X" target="_blank">www.cell.com/cell/fulltext/S0092-8674(25)00279-X</a></p>

																								
																								<div>
													<p><strong>Journal information:</strong>
																											<a href="https://medicalxpress.com/journals/cell/"><cite>Cell</cite></a></p><a href="http://www.cell.com/" target="_blank" rel="nofollow">
															<svg>
																<use href="https://medx.b-cdn.net/tmpl/v6/img/svg/sprite.svg#icon_open" x="0" y="0"></use>
															</svg>
														</a> 
																									</div>
																							</div>
                                        											
																					
                                                                                                                            <p>
                                                <i>This story is republished courtesy of MIT News (<a href="http://web.mit.edu/newsoffice/" target="_blank">web.mit.edu/newsoffice/</a>), a popular site that covers news about MIT research, innovation and teaching.</i>
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Scientists discover the protein IL-17 that fights infection also acts on the brain, inducing anxiety or sociability (2025, April 7)
                                                 retrieved 14 April 2025
                                                 from https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Zero-codegen, no-compile TypeScript type inference from Protobufs (123 pts)]]></title>
            <link>https://github.com/nathanhleung/protobuf-ts-types</link>
            <guid>43682547</guid>
            <pubDate>Mon, 14 Apr 2025 15:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nathanhleung/protobuf-ts-types">https://github.com/nathanhleung/protobuf-ts-types</a>, See on <a href="https://news.ycombinator.com/item?id=43682547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">protobuf-ts-types</h2><a id="user-content-protobuf-ts-types" aria-label="Permalink: protobuf-ts-types" href="#protobuf-ts-types"></a></p>
<blockquote>
<p dir="auto">Zero-codegen, no-compile TypeScript <code>type</code> inference from protobuf <code>message</code>s.</p>
</blockquote>
<p dir="auto"><code>protobuf-ts-types</code> lets you define language-agnostic <code>message</code> types in <code>proto</code> format, then infers TypeScript types from them with no additional codegen.</p>
<p dir="auto"><a href="https://github.dev/nathanhleung/protobuf-ts-types/blob/main/examples/basic/index.ts" rel="nofollow">Try on github.dev</a> | <a href="https://codesandbox.io/p/github/nathanhleung/protobuf-ts-types/main?import=true&amp;embed=1&amp;file=%2Fexamples%2Fbasic%2Findex.ts" rel="nofollow">View on CodeSandbox</a></p>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto">Proof of concept, not production ready. See <a href="#limitations">Limitations</a> below for more details.</p>
</div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nathanhleung/protobuf-ts-types/blob/main/screenshot.png"><img src="https://github.com/nathanhleung/protobuf-ts-types/raw/main/screenshot.png" width="400px" alt="Screenshot"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it Works" href="#how-it-works"></a></p>
<p dir="auto">In short, aggressive use of TypeScript's <a href="https://www.typescriptlang.org/docs/handbook/2/template-literal-types.html" rel="nofollow">template literal types</a>. Annotated example from the source:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Pass the proto string you want to infer `message` names from as a generic parameter
type MessageNames<Proto extends string> =
  // Infer `message` parts using template literal type
  WrapWithNewlines<Proto> extends `${string}${Whitespace}message${Whitespace}${infer MessageName}${OptionalWhitespace}{${string}}${infer Rest}`
    ? // Recursively infer remaining message names
      [MessageName, ...MessageNames<Rest>]
    : [];"><pre><span>// Pass the proto string you want to infer `message` names from as a generic parameter</span>
<span>type</span> <span>MessageNames</span><span>&lt;</span><span>Proto</span> <span>extends</span> <span>string</span><span>&gt;</span> <span>=</span>
  <span>// Infer `message` parts using template literal type</span>
  <span>WrapWithNewlines</span><span>&lt;</span><span>Proto</span><span>&gt;</span> <span>extends</span> `${<span>string</span><span>}</span>${<span>Whitespace</span><span>}</span>message${<span>Whitespace</span><span>}</span>${infer <span>MessageName</span><span>}</span>${<span>OptionalWhitespace</span><span>}</span>{${<span>string</span><span>}</span>}${infer <span>Rest</span><span>}</span>`
    ? <span>// Recursively infer remaining message names</span>
      <span>[</span><span>MessageName</span><span>,</span> ...<span>MessageNames</span><span>&lt;</span><span>Rest</span><span>&gt;</span><span>]</span>
    : <span>[</span><span>]</span><span>;</span></pre></div>
<p dir="auto">See more in <a href="https://github.com/nathanhleung/protobuf-ts-types/blob/main/src/proto.ts"><code>src/proto.ts</code></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">First, install the package.</p>
<div data-snippet-clipboard-copy-content="npm install https://github.com/nathanhleung/protobuf-ts-types"><pre><code>npm install https://github.com/nathanhleung/protobuf-ts-types
</code></pre></div>
<p dir="auto">Then, use it in TypeScript.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { pbt } from &quot;protobuf-ts-types&quot;;

const proto = `
    syntax = &quot;proto3&quot;;

    message Person {
      string name = 1;
      int32 id = 2;
      bool is_ceo = 3;
      optional string description = 4;
    }

    message Group {
        string name = 1;
        repeated Person people = 2;
    }
`;

// `Proto` is a mapping of message names to message types, inferred from the
// `proto` source string above.
type Proto = pbt.infer<typeof proto>;

type Person = Proto[&quot;Person&quot;];
type Person2 = pbt.infer<typeof proto, &quot;Person&quot;>;

// `Person` and `Person2` are the same type:
// ```
// {
//     name: string;
//     id: number;
//     is_ceo: boolean;
//     description?: string;
// }
// ```

type Group = pbt.infer<typeof proto, &quot;Group&quot;>;

function greetPerson(person: Person) {
  console.log(`Hello, ${person.name}!`);

  if (person.description) {
    console.log(`${person.description}`);
  } else {
    console.log(&quot;(no description)&quot;);
  }
}

function greetGroup(group: Group) {
  console.log(`=========${&quot;=&quot;.repeat(group.name.length)}===`);
  console.log(`= Hello, ${group.name}! =`);
  console.log(`=========${&quot;=&quot;.repeat(group.name.length)}===`);

  for (const person of group.people) {
    greetPerson(person);
    console.log();
  }
}

// If the structure of the `Group` or any of the individual `Person`s does not
// match the type, TypeScript will show an error.
greetGroup({
  name: &quot;Hooli&quot;,
  people: [
    {
      name: &quot;Gavin Belson&quot;,
      id: 0,
      is_ceo: true,
      description: &quot;CEO of Hooli&quot;,
    },
    {
      name: &quot;Richard Hendricks&quot;,
      id: 1,
      is_ceo: true,
      description: &quot;CEO of Pied Piper&quot;,
    },
    {
      name: &quot;Dinesh Chugtai&quot;,
      id: 2,
      is_ceo: false,
      description: &quot;Software Engineer&quot;,
    },
    {
      name: &quot;Jared Dunn&quot;,
      id: 3,
      is_ceo: false,
    },
  ],
});

// Output:
// ```
// =================
// = Hello, Hooli! =
// =================
// Hello, Gavin Belson!
// CEO of Hooli

// Hello, Richard Hendricks!
// CEO of Pied Piper

// Hello, Dinesh Chugtai!
// Software Engineer

// Hello, Jared Dunn!
// (no description)
// ```"><pre><span>import</span> <span>{</span> <span>pbt</span> <span>}</span> <span>from</span> <span>"protobuf-ts-types"</span><span>;</span>

<span>const</span> <span>proto</span> <span>=</span> <span>`</span>
<span>    syntax = "proto3";</span>
<span></span>
<span>    message Person {</span>
<span>      string name = 1;</span>
<span>      int32 id = 2;</span>
<span>      bool is_ceo = 3;</span>
<span>      optional string description = 4;</span>
<span>    }</span>
<span></span>
<span>    message Group {</span>
<span>        string name = 1;</span>
<span>        repeated Person people = 2;</span>
<span>    }</span>
<span>`</span><span>;</span>

<span>// `Proto` is a mapping of message names to message types, inferred from the</span>
<span>// `proto` source string above.</span>
<span>type</span> <span>Proto</span> <span>=</span> <span>pbt</span><span>.</span><span>infer</span><span>&lt;</span><span>typeof</span> <span>proto</span><span>&gt;</span><span>;</span>

<span>type</span> <span>Person</span> <span>=</span> <span>Proto</span><span>[</span><span>"Person"</span><span>]</span><span>;</span>
<span>type</span> <span>Person2</span> <span>=</span> <span>pbt</span><span>.</span><span>infer</span><span>&lt;</span><span>typeof</span> <span>proto</span><span>,</span> <span>"Person"</span><span>&gt;</span><span>;</span>

<span>// `Person` and `Person2` are the same type:</span>
<span>// ```</span>
<span>// {</span>
<span>//     name: string;</span>
<span>//     id: number;</span>
<span>//     is_ceo: boolean;</span>
<span>//     description?: string;</span>
<span>// }</span>
<span>// ```</span>

<span>type</span> <span>Group</span> <span>=</span> <span>pbt</span><span>.</span><span>infer</span><span>&lt;</span><span>typeof</span> <span>proto</span><span>,</span> <span>"Group"</span><span>&gt;</span><span>;</span>

<span>function</span> <span>greetPerson</span><span>(</span><span>person</span>: <span>Person</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`Hello, <span><span>${</span><span>person</span><span>.</span><span>name</span><span>}</span></span>!`</span><span>)</span><span>;</span>

  <span>if</span> <span>(</span><span>person</span><span>.</span><span>description</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>`<span><span>${</span><span>person</span><span>.</span><span>description</span><span>}</span></span>`</span><span>)</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"(no description)"</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>function</span> <span>greetGroup</span><span>(</span><span>group</span>: <span>Group</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`=========<span><span>${</span><span>"="</span><span>.</span><span>repeat</span><span>(</span><span>group</span><span>.</span><span>name</span><span>.</span><span>length</span><span>)</span><span>}</span></span>===`</span><span>)</span><span>;</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`= Hello, <span><span>${</span><span>group</span><span>.</span><span>name</span><span>}</span></span>! =`</span><span>)</span><span>;</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`=========<span><span>${</span><span>"="</span><span>.</span><span>repeat</span><span>(</span><span>group</span><span>.</span><span>name</span><span>.</span><span>length</span><span>)</span><span>}</span></span>===`</span><span>)</span><span>;</span>

  <span>for</span> <span>(</span><span>const</span> <span>person</span> <span>of</span> <span>group</span><span>.</span><span>people</span><span>)</span> <span>{</span>
    <span>greetPerson</span><span>(</span><span>person</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>// If the structure of the `Group` or any of the individual `Person`s does not</span>
<span>// match the type, TypeScript will show an error.</span>
<span>greetGroup</span><span>(</span><span>{</span>
  <span>name</span>: <span>"Hooli"</span><span>,</span>
  <span>people</span>: <span>[</span>
    <span>{</span>
      <span>name</span>: <span>"Gavin Belson"</span><span>,</span>
      <span>id</span>: <span>0</span><span>,</span>
      <span>is_ceo</span>: <span>true</span><span>,</span>
      <span>description</span>: <span>"CEO of Hooli"</span><span>,</span>
    <span>}</span><span>,</span>
    <span>{</span>
      <span>name</span>: <span>"Richard Hendricks"</span><span>,</span>
      <span>id</span>: <span>1</span><span>,</span>
      <span>is_ceo</span>: <span>true</span><span>,</span>
      <span>description</span>: <span>"CEO of Pied Piper"</span><span>,</span>
    <span>}</span><span>,</span>
    <span>{</span>
      <span>name</span>: <span>"Dinesh Chugtai"</span><span>,</span>
      <span>id</span>: <span>2</span><span>,</span>
      <span>is_ceo</span>: <span>false</span><span>,</span>
      <span>description</span>: <span>"Software Engineer"</span><span>,</span>
    <span>}</span><span>,</span>
    <span>{</span>
      <span>name</span>: <span>"Jared Dunn"</span><span>,</span>
      <span>id</span>: <span>3</span><span>,</span>
      <span>is_ceo</span>: <span>false</span><span>,</span>
    <span>}</span><span>,</span>
  <span>]</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// Output:</span>
<span>// ```</span>
<span>// =================</span>
<span>// = Hello, Hooli! =</span>
<span>// =================</span>
<span>// Hello, Gavin Belson!</span>
<span>// CEO of Hooli</span>

<span>// Hello, Richard Hendricks!</span>
<span>// CEO of Pied Piper</span>

<span>// Hello, Dinesh Chugtai!</span>
<span>// Software Engineer</span>

<span>// Hello, Jared Dunn!</span>
<span>// (no description)</span>
<span>// ```</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations</h2><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<ul dir="auto">
<li>If not using inline (i.e., literals in TypeScript) proto <code>string</code>s <code>as const</code>, probably requires a <a href="https://github.com/nonara/ts-patch"><code>ts-patch</code></a> compiler patch to import <code>.proto</code> files until <a data-error-text="Failed to load title" data-id="779392318" data-permission-text="Title is private" data-url="https://github.com/microsoft/TypeScript/issues/42219" data-hovercard-type="issue" data-hovercard-url="/microsoft/TypeScript/issues/42219/hovercard" href="https://github.com/microsoft/TypeScript/issues/42219">microsoft/TypeScript#42219</a> is resolved</li>
<li><code>service</code>s and <code>rpc</code>s are not supported (only <code>message</code>s)</li>
<li><code>oneof</code> and <code>map</code> fields are not supported</li>
<li><code>import</code>s are not supported (for now, concatenate)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>pbt</code></h3><a id="user-content-pbt" aria-label="Permalink: pbt" href="#pbt"></a></p>
<p dir="auto">Top-level exported namespace.</p>
<div data-snippet-clipboard-copy-content="import { pbt } from &quot;protobuf-ts-types&quot;;"><pre><code>import { pbt } from "protobuf-ts-types";
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>pbt.infer&lt;Proto extends string, MessageName extends string = ""&gt;</code></h3><a id="user-content-pbtinferproto-extends-string-messagename-extends-string--" aria-label="Permalink: pbt.infer<Proto extends string, MessageName extends string = &quot;&quot;>" href="#pbtinferproto-extends-string-messagename-extends-string--"></a></p>
<p dir="auto">Given a proto source string, infers the types of the <code>message</code>s in the source.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Returns</h4><a id="user-content-returns" aria-label="Permalink: Returns" href="#returns"></a></p>
<ul dir="auto">
<li>If <code>MessageName</code> is an empty string, the returned type is a mapping from message names to message types.</li>
<li>If <code>MessageName</code> is a known <code>message</code>, the returned type is the inferred type of the given <code>MessageName</code>.</li>
<li>If <code>MessageName</code> is not a known <code>message</code>, the returned type is <code>never</code>.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Path to Open-Sourcing the DeepSeek Inference Engine (481 pts)]]></title>
            <link>https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine</link>
            <guid>43682088</guid>
            <pubDate>Mon, 14 Apr 2025 15:03:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine">https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine</a>, See on <a href="https://news.ycombinator.com/item?id=43682088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">The Path to Open-Sourcing the DeepSeek Inference Engine</h2><a id="user-content-the-path-to-open-sourcing-the-deepseek-inference-engine" aria-label="Permalink: The Path to Open-Sourcing the DeepSeek Inference Engine" href="#the-path-to-open-sourcing-the-deepseek-inference-engine"></a></p>
<p dir="auto">A few weeks ago,
during <a href="https://github.com/deepseek-ai/open-infra-index?tab=readme-ov-file#202502-open-source-week">Open Source Week</a>,
we open-sourced several libraries.
The response from the community has been incredibly positive - sparking inspiring collaborations, productive
discussions, and valuable bug fixes.
Encouraged by this, weâ€™ve decided to take another step forward: contributing our internal inference engine back to the
open-source community.</p>
<p dir="auto">We are deeply grateful for the open-source ecosystem, without which our progress toward AGI would not be possible.
Our training framework relies on <a href="https://github.com/pytorch/pytorch">PyTorch</a>, and our inference engine is built
upon <a href="https://github.com/vllm-project/vllm">vLLM</a>,
both of which have been instrumental in accelerating the training and deployment of DeepSeek models.</p>
<p dir="auto">Given the growing demand for deploying models like <a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a>
and <a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1</a>, we want to give back to the community as much as we can.
While we initially considered open-sourcing our full internal inference engine, we identified several challenges:</p>
<ul dir="auto">
<li><strong>Codebase Divergence</strong>: Our engine is based on an early fork of vLLM from over a year ago. Although structurally
similar, weâ€™ve heavily customized it for DeepSeek models, making it difficult to extend for broader use cases.</li>
<li><strong>Infrastructure Dependencies</strong>: The engine is tightly coupled with our internal infrastructure, including cluster
management tools, making it impractical for public deployment without significant modifications.</li>
<li><strong>Limited Maintenance Bandwidth</strong>: As a small research team focused on developing better models, we lack bandwidth to
maintain a large open-source project.</li>
</ul>
<p dir="auto">Considering these challenges, weâ€™ve decided to collaborate with existing open-source projects as more sustainable alternatives.</p>
<p dir="auto">Moving forward, we will work closely with existing open-source projects to:</p>
<ul dir="auto">
<li><strong>Extract Standalone Features</strong>: Modularize and contribute reusable components as independent libraries.</li>
<li><strong>Share Optimizations</strong>: Contribute design improvements and implementation details directly.</li>
</ul>
<p dir="auto">We are profoundly grateful for the open-source movement - from operating systems and programming languages to machine
learning frameworks and inference engines. Itâ€™s an honor to contribute to this thriving ecosystem and to see our models
and code embraced by the community. Together, letâ€™s push the boundaries of AGI and ensure its benefits serve all of
humanity.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto"><strong>To clarify, this article outlines our approach to open-sourcing of our DeepSeek-Inference-Engine codebase only.
Regarding future model releases, we maintain an open and collaborative stance towards both the open-source community
and hardware partners.
We commit to proactively synchronizing inference-related engineering efforts prior to new model launches, with the
goal of enabling the community to achieve state-of-the-art (SOTA) support from Day-0. Our ultimate aim is to foster a
synchronized ecosystem where cutting-edge AI capabilities can be seamlessly implemented across diverse hardware
platforms upon official model releases.</strong></p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite File Format Viewer (233 pts)]]></title>
            <link>https://sqlite-internal.pages.dev</link>
            <guid>43682006</guid>
            <pubDate>Mon, 14 Apr 2025 14:55:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite-internal.pages.dev">https://sqlite-internal.pages.dev</a>, See on <a href="https://news.ycombinator.com/item?id=43682006">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How to Bike Across the Country (195 pts)]]></title>
            <link>https://www.brooks.team/posts/how-to-bike-across-the-country/</link>
            <guid>43681936</guid>
            <pubDate>Mon, 14 Apr 2025 14:49:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brooks.team/posts/how-to-bike-across-the-country/">https://www.brooks.team/posts/how-to-bike-across-the-country/</a>, See on <a href="https://news.ycombinator.com/item?id=43681936">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  
  <p>Loading...</p>

  
  
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tariff: A Python package that imposes tariffs on Python imports (120 pts)]]></title>
            <link>https://pypi.org/project/tariff/</link>
            <guid>43681752</guid>
            <pubDate>Mon, 14 Apr 2025 14:32:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pypi.org/project/tariff/">https://pypi.org/project/tariff/</a>, See on <a href="https://news.ycombinator.com/item?id=43681752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="description" data-project-tabs-target="content" role="tabpanel" aria-labelledby="description-tab mobile-description-tab" tabindex="-1">
          <h2>Project description</h2>
          <div>
            
<p>The GREATEST, most TREMENDOUS Python package that makes importing great again!</p>
<h2>About</h2>
<p>TARIFF is a fantastic tool that lets you impose import tariffs on Python packages. We're going to bring manufacturing BACK to your codebase by making foreign imports more EXPENSIVE!</p>
<h2>Installation</h2>
<pre lang="bash">pip<span> </span>install<span> </span>tariff
</pre>
<h2>Usage</h2>
<pre lang="python3"><span>import</span><span> </span><span>tariff</span>

<span># Set your tariff rates (package_name: percentage)</span>
<span>tariff</span><span>.</span><span>set</span><span>({</span>
    <span>"numpy"</span><span>:</span> <span>50</span><span>,</span>     <span># 50% tariff on numpy</span>
    <span>"pandas"</span><span>:</span> <span>200</span><span>,</span>   <span># 200% tariff on pandas</span>
    <span>"requests"</span><span>:</span> <span>150</span>  <span># 150% tariff on requests</span>
<span>})</span>

<span># Now when you import these packages, they'll be TARIFFED!</span>
<span>import</span><span> </span><span>numpy</span>   <span># This will be 50% slower</span>
<span>import</span><span> </span><span>pandas</span>  <span># This will be 200% slower</span>
</pre>
<h2>How It Works</h2>
<p>When you import a package that has a tariff:</p>
<ol>
<li>TARIFF measures how long the original import takes</li>
<li>TARIFF makes the import take longer based on your tariff percentage</li>
<li>TARIFF announces the tariff with a TREMENDOUS message</li>
</ol>
<h2>Example Output</h2>
<pre><code>JUST IMPOSED a 50% TARIFF on numpy! Original import took 45000 us, now takes 67500 us. American packages are WINNING AGAIN! #MIPA
</code></pre>
<h2>Why TARIFF?</h2>
<p>Because foreign packages have been STEALING our CPU cycles for TOO LONG! It's time to put AMERICA FIRST and make importing FAIR and BALANCED again!</p>
<h2>License</h2>
<p>This is a parody package. Use at your own risk. MAKE IMPORTING GREAT AGAIN!</p>

          </div>
        </div><div id="files" data-project-tabs-target="content" role="tabpanel" aria-labelledby="files-tab mobile-files-tab" tabindex="-1">
            <h2>Download files</h2>
            <p>Download the file for your platform. If you're not sure which to choose, learn more about <a href="https://packaging.python.org/tutorials/installing-packages/" title="External link" target="_blank" rel="noopener">installing packages</a>.</p>

            <h3>
Source Distribution            </h3>

                  


            <h3>
Built Distribution            </h3>

                

          </div><div id="tariff-1.0.0.tar.gz" data-project-tabs-target="content" role="tabpanel" aria-labelledby="file-tab mobile-file-tab" tabindex="-1">
  <h2>File details</h2>
  <p>Details for the file <code>tariff-1.0.0.tar.gz</code>.</p>

  <h3>File metadata</h3>
  <div>
    <ul>
      <li>
        Download URL: <a href="https://files.pythonhosted.org/packages/6e/86/8a6d8b6c88cbfa42a7f20d7a0bf166ec621e4b0d4f89b2910a539452d587/tariff-1.0.0.tar.gz">
          tariff-1.0.0.tar.gz
        </a>
      </li>
      <li>Upload date: <time datetime="2025-04-10T19:33:18+0000" data-controller="localized-time" data-localized-time-relative="true" data-localized-time-show-time="false">
  Apr 10, 2025
</time></li>
      <li>Size: 4.0 kB</li>
      <li>Tags: Source</li>
      <li>
Uploaded using Trusted Publishing? No      </li>
      <li>Uploaded via: twine/6.1.0 CPython/3.10.16</li>
    </ul>
  </div>

  <h3>File hashes</h3>
  <div>
    <table>
      <caption>Hashes for tariff-1.0.0.tar.gz</caption>
      <thead>
        <tr>
          <th scope="col">Algorithm</th>
          <th scope="col">Hash digest</th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr data-controller="clipboard">
          <th scope="row">SHA256</th>
          <td><code data-clipboard-target="source">24a8d49034398a7820d6f9eb1d345476f0d0bfcb67f75ce266284943208596cd</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">MD5</th>
          <td><code data-clipboard-target="source">46117ae6651d1a90855555f1cb629b38</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">BLAKE2b-256</th>
          <td><code data-clipboard-target="source">6e868a6d8b6c88cbfa42a7f20d7a0bf166ec621e4b0d4f89b2910a539452d587</code></td>
          <td>
            
          </td>
        </tr>
      </tbody>
    </table>
    <p>
<a href="https://pip.pypa.io/en/stable/topics/secure-installs/#hash-checking-mode" title="External link" target="_blank" rel="noopener">See more details on using hashes here.</a>    </p>
  </div>

</div><div id="tariff-1.0.0-py3-none-any.whl" data-project-tabs-target="content" role="tabpanel" aria-labelledby="file-tab mobile-file-tab" tabindex="-1">
  <h2>File details</h2>
  <p>Details for the file <code>tariff-1.0.0-py3-none-any.whl</code>.</p>

  <h3>File metadata</h3>
  <div>
    <ul>
      <li>
        Download URL: <a href="https://files.pythonhosted.org/packages/8e/ae/6f57db1138cfce911d19113e8d931a739858e0116ca3a2a3e391748cb5ff/tariff-1.0.0-py3-none-any.whl">
          tariff-1.0.0-py3-none-any.whl
        </a>
      </li>
      <li>Upload date: <time datetime="2025-04-10T19:33:17+0000" data-controller="localized-time" data-localized-time-relative="true" data-localized-time-show-time="false">
  Apr 10, 2025
</time></li>
      <li>Size: 4.5 kB</li>
      <li>Tags: Python 3</li>
      <li>
Uploaded using Trusted Publishing? No      </li>
      <li>Uploaded via: twine/6.1.0 CPython/3.10.16</li>
    </ul>
  </div>

  <h3>File hashes</h3>
  <div>
    <table>
      <caption>Hashes for tariff-1.0.0-py3-none-any.whl</caption>
      <thead>
        <tr>
          <th scope="col">Algorithm</th>
          <th scope="col">Hash digest</th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr data-controller="clipboard">
          <th scope="row">SHA256</th>
          <td><code data-clipboard-target="source">20d738a789f96146ae49de4fffc000ea9942bd4335f0cdc336d2c824e6aa063b</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">MD5</th>
          <td><code data-clipboard-target="source">eb211c83b4fd4814b8a15f0a92ed3dab</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">BLAKE2b-256</th>
          <td><code data-clipboard-target="source">8eae6f57db1138cfce911d19113e8d931a739858e0116ca3a2a3e391748cb5ff</code></td>
          <td>
            
          </td>
        </tr>
      </tbody>
    </table>
    <p>
<a href="https://pip.pypa.io/en/stable/topics/secure-installs/#hash-checking-mode" title="External link" target="_blank" rel="noopener">See more details on using hashes here.</a>    </p>
  </div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A hackable AI assistant using a single SQLite table and a handful of cron jobs (568 pts)]]></title>
            <link>https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs</link>
            <guid>43681287</guid>
            <pubDate>Mon, 14 Apr 2025 13:52:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs">https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs</a>, See on <a href="https://news.ycombinator.com/item?id=43681287">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Thereâ€™s a lot of hype these days around patterns for building with AI. Agents, memory, RAG, assistantsâ€”so many buzzwords! But the reality is, <strong>you donâ€™t need fancy techniques or libraries to build useful personal tools with LLMs.</strong></p>

<p>In this short post, Iâ€™ll show you how I built a useful AI assistant for my family using a dead simple architecture: a single SQLite table of memories, and a handful of cron jobs for ingesting memories and sending updates, all hosted on <a href="https://www.val.town/">Val.town</a>. The whole thing is so simple that you can easily copy and extend it yourself.</p>

<h2 id="meet-stevens">Meet Stevens</h2>

<p>The assistant is called Stevens, named after the butler in the great Ishiguro novel <a href="https://en.wikipedia.org/wiki/The_Remains_of_the_Day">Remains of the Day</a>. Every morning it sends a brief to me and my wife via Telegram, including our calendar schedules for the day, a preview of the weather forecast, any postal mail or packages weâ€™re expected to receive, and any reminders weâ€™ve asked it to keep track of. All written up nice and formally, just like youâ€™d expect from a proper butler.</p>

<p>Hereâ€™s an example. (Iâ€™ll use fake data throughout this post, beacuse our actual updates contain private information.)</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/telegram.png?1744560139" alt=""></p>

<p>Beyond the daily brief, we can communicate with Stevens on-demandâ€”we can forward an email with some important info, or just leave a reminder or ask a question via Telegram chat.</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/coffee.png?1744560139" alt=""></p>

<p>Thatâ€™s Stevens. Itâ€™s rudimentary, but already more useful to me than Siri!</p>

<h2 id="behind-the-scenes">Behind the scenes</h2>

<p>Letâ€™s break down the simple architecture behind Stevens. The whole thing is hosted on <a href="https://www.val.town/">Val.town</a>, a lovely platform that offers SQLite storage, HTTP request handling, scheduled cron jobs, and inbound/outbound email: a perfect set of capabilities for this project.</p>

<p>First, how does Stevens know what goes in the morning brief? The key is the butlerâ€™s notebook, a log of everything that Stevens knows. Thereâ€™s an admin view where we can see the notebook contentsâ€”letâ€™s peek and see whatâ€™s in there:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/notebook.png?1744560139" alt=""></p>

<p>You can see some of the entries that fed into the morning brief aboveâ€”for example, the parent-teacher conference has a log entry.</p>

<p>In addition to some text, entries can have a <em>date</em> when they are expected to be relevant.  There are also entries with no date that serve as general background info, and are always included. You can see these particular background memories came from a Telegram chat, because Stevens does an intake interview via Telegram when you first get started:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/background.png?1744560139" alt=""></p>

<p><strong>With this notebook in hand, sending the morning brief is easy</strong>: just run a cron job which makes a call to the Claude API to write the update, and then sends the text to a Telegram thread. As context for the model, we include any log entries dated for the coming week, as well as the undated background entries.</p>

<p>Under the hood, the â€œnotebookâ€ is just a single SQLite table with a few columns. Hereâ€™s a more boring view of things:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/db.png?1744560139" alt=""></p>

<p>But wait: how did the various log entries get there in the first place? In the admin view, we can watch Stevens buzzing around entering things into the log from various sources:</p>

<video width="100%" controls="">
  <source src="https://www.geoffreylitt.com/images/article_images/stevens/cron.mp4" type="video/mp4">
</video>

<p>This is just some data importers populating the table:</p>

<ul>
<li>An hourly data pull from the Google Calendar API</li>
<li>An hourly check of the local weather forecast using a weather API</li>
<li>I forward <a href="https://www.usps.com/manage/informed-delivery.htm">USPS Informed Delivery</a> containing scans of our postal mail, and Stevens OCRs them using Claude</li>
<li>Inbound Telegram and email messages can also result in log entries</li>
<li>Every week, some â€œfun factsâ€ get added into the log, as a way of adding some color to future daily updates.</li>
</ul>

<p><strong>This system is easily extensible with new importers.</strong> An importer is just any process that adds/edits memories in the log. The memory contents can be any arbitrary text, since theyâ€™ll just be fed back into an LLM later anyways.</p>

<h2 id="reflections">Reflections</h2>

<p>A few quick reflections on this project:</p>

<p><strong>Itâ€™s very useful for personal AI tools to have access to broader context from other information sources.</strong> Awareness of things like my calendar and the weather forecast turns a dumb chatbot into a useful assistant. ChatGPT recently added memory of past conversations, but thereâ€™s lots of information not stored within that silo. Iâ€™ve <a href="https://x.com/geoffreylitt/status/1810442615264796864">written before</a> about how the endgame for AI-driven personal software isnâ€™t more app silos, itâ€™s small tools operating on a shared pool of context about our lives.</p>

<p><strong>â€œMemoryâ€ can start simple.</strong> In this case, the use cases of the assistant are limited, and its information is inherently time-bounded, so itâ€™s fairly easy to query for the relevant context to give to the LLM. It also helps that some modern models have long context windows. As the available information grows in size, RAG and <a href="https://x.com/sjwhitmore/status/1910439061615239520">fancier</a> <a href="https://arxiv.org/abs/2304.03442">approaches</a> to memory may be needed, but you can start simple.</p>

<p><strong>Vibe coding enables sillier projects.</strong> Initially, Stevens spoke with a dry tone, like you might expect from a generic Apple or Google product. But it turned out it was just more <em>fun</em> to have the assistant speak like a formal butler. This was trivial to do, just a couple lines in a prompt. Similarly, I decided to make the admin dashboard views feel like a video game, because why not? I generated the image assets in ChatGPT, and vibe coded the whole UI in Cursor + Claude 3.7 Sonnet; it took a tiny bit of extra effort in exchange for a lot more fun.</p>

<h2 id="try-it-yourself">Try it yourself</h2>

<p>Stevens isnâ€™t a product you can run out of the box, itâ€™s just a personal project I made for myself.</p>

<p>But if youâ€™re curious, you can check out the code and fork the project <a href="https://www.val.town/x/geoffreylitt/stevensDemo">here</a>. You should be able to apply this basic patternâ€”a single memories table and an extensible constellation of cron jobsâ€”to do lots of other useful things.</p>

<p>I recommend editing the code using your AI editor of choice with the <a href="https://github.com/pomdtr/vt">Valtown CLI</a> to sync to local filesystem.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta antitrust trial kicks off in federal court (316 pts)]]></title>
            <link>https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court</link>
            <guid>43680957</guid>
            <pubDate>Mon, 14 Apr 2025 13:18:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court">https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court</a>, See on <a href="https://news.ycombinator.com/item?id=43680957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><div data-theme="pro"><div data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-event-name="story_view" data-vars-deprecated-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-deprecated-headline="Meta antitrust trial kicks off in federal court" data-vars-deprecated-category="story" data-vars-deprecated-sub-category="story" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-latitude="47.23" data-vars-longitude="8.84" data-vars-postal-code="8645"><div><p><span>Axios Pro Exclusive Content</span></p><div><p><img alt="" loading="lazy" width="52" height="52" decoding="async" data-nimg="1" srcset="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FC_Z_frNtxeJxkMDSsXJSCdXj6w0%3D%2F52x0%2Fsmart%2F2023%2F03%2F24%2F1679666155723.jpg&amp;w=64&amp;q=75 1x, https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FC_Z_frNtxeJxkMDSsXJSCdXj6w0%3D%2F52x0%2Fsmart%2F2023%2F03%2F24%2F1679666155723.jpg&amp;w=128&amp;q=75 2x" src="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FC_Z_frNtxeJxkMDSsXJSCdXj6w0%3D%2F52x0%2Fsmart%2F2023%2F03%2F24%2F1679666155723.jpg&amp;w=128&amp;q=75"></p></div></div><figure data-cy="au-image" data-chromatic="ignore"><img data-cy="StoryImage" alt="Mark Zuckerberg taking an oath in Congress with a black backdrop" fetchpriority="high" width="1920" height="1080" decoding="async" data-nimg="1" sizes="100vw" srcset="https://images.axios.com/dZ2sVpFnmwMBZaPT7ZQc8qfwTSw=/0x0:7555x4250/640x360/2025/04/11/1744384586720.jpg?w=640 640w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=750 750w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=828 828w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=1080 1080w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=1200 1200w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=1920 1920w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=2048 2048w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=3840 3840w" src="https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=3840"><figcaption data-cy="image-caption"><p>Mark Zuckerberg on Jan. 31, 2024 on Capitol Hill. Photo: Tom Williams/CQ-Roll Call, Inc via Getty Images</p></figcaption></figure><div data-chromatic="ignore"><p><span data-schema="smart-brevity"><p>The Federal Trade Commission and Meta will square off in a long-awaited antitrust trial on Monday over the tech giant's past acquisitions of WhatsApp and Instagram.</p><p><strong>Why it matters: </strong>The trial will be a major test of the FTC's ability to take on tech behemoths for<strong> </strong>allegedly breaking antitrust law and comes as Meta CEO Mark Zuckerberg<strong> </strong>tries to <a data-vars-link-text="cozy up" data-vars-click-url="https://www.axios.com/pro/tech-policy/2025/04/03/zuckerberg-gets-closer-to-dc" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/pro/tech-policy/2025/04/03/zuckerberg-gets-closer-to-dc" target="_self">cozy up</a> to President Trump.</p></span></p><ul><li>The case could result in Meta having to spin off WhatsApp and Instagram. </li><li>If Meta wins, the company would be vindicated in its longtime argument that the two apps couldn't have thrived without the company's backing and that Meta has plenty of competition in the social networking space.</li><li>The lawsuit's main question is whether Meta acted illegally in its WhatsApp and Instagram acquisitions, done in 2014 and 2012.</li></ul><p><strong>Federal judge <a data-vars-link-text="James Boasberg" data-vars-click-url="https://www.axios.com/2025/03/18/judge-trump-impeachment-james-boasberg" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2025/03/18/judge-trump-impeachment-james-boasberg" target="_self">James Boasberg</a> </strong>will hear the case, which was <a data-vars-link-text="first filed" data-vars-click-url="https://www.axios.com/2020/12/09/ftc-sues-facebookstate-ags-sue-facebook" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2020/12/09/ftc-sues-facebookstate-ags-sue-facebook" target="_self">first filed</a> in December 2020 under Trump's first administration.</p><ul><li>A judge <a data-vars-link-text="dismissed" data-vars-click-url="https://www.axios.com/2021/06/28/judge-dismisses-ftcs-antitrust-complaint-against-facebook" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2021/06/28/judge-dismisses-ftcs-antitrust-complaint-against-facebook" target="_self">dismissed</a> that original lawsuit in June 2021 for lacking sufficient evidence of Meta's market power.</li><li>Under Lina Khan, FTC chair under President Biden, the case was re-filed and expanded in August 2021. </li><li>Boasberg allowed that case to proceed in January 2022, and rejected a bid from Meta<strong> </strong>last year to have the case dismissed, paving way for this trial.</li></ul><p><strong>What they're saying: </strong>The FTC says Meta has illegally monopolized the market for "personal social networking services" through those acquisitions, in a bid to "neutralize" its rivals, per legal filings. </p><ul><li>"Acquiring these competitive threats has enabled Facebook to sustain its dominanceâ€”to the detriment of competition and usersâ€”not by competing on the merits, but by avoiding competition," the FTC wrote in a filing.</li><li>Meta could have chosen to compete with then-upstart photo sharing app Instagram in 2012, a senior FTC official said on a call with reporters ahead of the trial, but instead it bought it, and did the same with WhatsApp. </li></ul><p><strong>The other side: </strong>"The FTC's lawsuit against Meta defies reality. The evidence at trial will show what every 17-year-old in the world knows: Instagram, Facebook and WhatsApp compete with Chinese-owned TikTok, YouTube, X, iMessage and many others," Meta spokesperson Chris Sgro said in a statement.</p><ul><li>"More than 10 years after the FTC reviewed and cleared our acquisitions, the Commission's action in this case sends the message that no deal is ever truly final."</li><li>"Regulators should be supporting American innovation, rather than seeking to break up a great American company and further advantaging China on critical issues like AI."</li></ul><p><strong>What we're watching:</strong> The case could take eight weeks or more. There'll be a slew of high-profile witnesses, including Zuckerberg.</p><ul><li>Former COO Sheryl Sandberg, chief technology officer Andrew Bosworth, and WhatsApp and Instagram leadership past and present, will also testify, per court filings.</li><li>Representatives from Snap, TikTok and Pinterest are expected to testify as well.</li></ul><p><strong>Our thought bubble: </strong>Tech firms have gotten much closer with Trump in his second term.</p><ul><li>But unless Trump tells the FTC to shut the whole trial down, Meta's overtures may not do the company any good here.</li></ul></div></div><h5>Go deeper</h5></div><div data-theme="pro" data-cy="pro-paywall" data-vars-event-name="paywall_view" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-latitude="47.23" data-vars-longitude="8.84" data-vars-postal-code="8645" data-vars-deprecated-category="cta" data-vars-deprecated-experiment="pro-paywall" data-vars-deprecated-experiment-variant="tech-policy"><p>This article is currently free.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DolphinGemma: How Google AI is helping decode dolphin communication (272 pts)]]></title>
            <link>https://blog.google/technology/ai/dolphingemma/</link>
            <guid>43680899</guid>
            <pubDate>Mon, 14 Apr 2025 13:12:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/ai/dolphingemma/">https://blog.google/technology/ai/dolphingemma/</a>, See on <a href="https://news.ycombinator.com/item?id=43680899">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
  }">
  
  <div>
      <div>
          
            <p>Apr 14, 2025</p>
          
          
            <p data-reading-time-render="">[[read-time]] min read</p>
          
        </div>
      
        <p>
          DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate â€” and hopefully find out what they're saying, too.
        </p>
      
    </div>
  
  <div>
      
  
    <figure>
        <picture>
            


    

    
        <source media="(max-resolution: 1.5dppx)" sizes="122px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-122x92.format-webp.webp 122w">
    
        <source media="(min-resolution: 1.5dppx)" sizes="244px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp 244w">
    

    <img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp" alt="thad headshot" sizes=" 122px,  244px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-122x92.format-webp.webp 122w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp 244w" data-target="image" loading="lazy">
    


        </picture>
    </figure>



<div>
  <p>Dr. Thad Starner</p>
  
    <p>
      Google DeepMind Research Scientist and Georgia Tech Professor
    </p>
  
  
</div>

    </div>
</div>

    

    
      


  <uni-youtube-player-hero index="0" thumbnail-alt="DolphinGemma text over a picture of dolphins" component-title="DolphinGemma: How Google AI is helping decode dolphin communication" video-id="T8GdEVVvXyE" video-type="video" image="DolphinGemma_SocialExplainers_16x9_DolphinGemma" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16.width-1000.format-webp.webp">
  </uni-youtube-player-hero>


    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="DolphinGemma: How Google AI is helping decode dolphin communication" listen-to-article="Listen to article" data-date-modified="2025-04-14T17:08:29.525540+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="6q2c0">For decades, understanding the clicks, whistles and burst pulses of dolphins has been a scientific frontier. What if we could not only listen to dolphins, but also understand the patterns of their complex communication well enough to generate realistic responses?</p><p data-block-key="4o0o1">Today, on National Dolphin Day, Google, in collaboration with researchers at Georgia Tech and the field research of the <a href="https://www.wilddolphinproject.org/">Wild Dolphin Project</a> (WDP), is announcing progress on DolphinGemma: a foundational AI model trained to learn the structure of dolphin vocalizations and generate novel dolphin-like sound sequences. This approach in the quest for interspecies communication pushes the boundaries of AI and our potential connection with the marine world.</p></div>
  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="6q2c0">Researching dolphin society for decades</h2><p data-block-key="ae8k9">Understanding any species requires deep context, and that's one of the many things the WDP provides. Since 1985, WDP has conducted the world's longest-running underwater dolphin research project, studying a specific community of wild Atlantic spotted dolphins (Stenella frontalis) in the Bahamas across generations. This non-invasive, "In Their World, on Their Terms" approach yields a rich, unique dataset: decades of underwater video and audio meticulously paired with individual dolphin identities, life histories and observed behaviors.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Dolphins swimming in the water" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="27106">A pod of Atlantic spotted dolphins, Stenella frontalis</p>
    </div>
  
  
    <p><img alt="Dolphins swimming in the water" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="iocbw">A primary focus for WDP is observing and analyzing the dolphins' natural communication and social interactions. Working underwater allows researchers to directly link sounds to specific behaviors in ways surface observation cannot. For decades, they have correlated sound types with behavioral contexts. Here are some examples:</p><ul><li data-block-key="fu0nf">Signature whistles (unique names) that can be used by mothers and calves to reunite</li><li data-block-key="b63q5">Burst-pulse "squawks" often seen during fights</li><li data-block-key="bseip">Click "buzzes" often used during courtship or chasing sharks</li></ul><p data-block-key="2ar36">Knowing the individual dolphins involved is crucial for accurate interpretation. The ultimate goal of this observational work is to understand the structure and potential meaning within these natural sound sequences â€” seeking patterns and rules that might indicate language. This long-term analysis of natural communication forms the bedrock of WDP's research and provides essential context for any AI analysis.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="A split image: left, a dolphin touching the sandy seabed underwater; right, a spectrogram with bright vertical streaks indicating high-frequency sounds." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="s704z">Left: A mother spotted dolphin observes her calf while foraging. She will use her unique signature whistle to call the calf back after he is finished. Right: Spectrogram to visualize the whistle.</p>
    </div>
  
  
    <p><img alt="A split image: left, a dolphin touching the sandy seabed underwater; right, a spectrogram with bright vertical streaks indicating high-frequency sounds." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="iocbw">Introducing DolphinGemma</h2><p data-block-key="2m8ks">Analyzing dolphins' natural, complex communication is a monumental task, and WDP's vast, labeled dataset provides a unique opportunity for cutting-edge AI.</p><p data-block-key="bgerj">Enter DolphinGemma. Developed by Google, this AI model makes use of specific Google audio technologies: the SoundStream tokenizer efficiently represents dolphin sounds, which are then processed by a model architecture suited for complex sequences. This ~400M parameter model is optimally-sized to run directly on the Pixel phones WDP uses in the field.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two spectrograms: left shows three arching sound patterns; right shows a more uniform sound pattern." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="30sb2">Left: Whistles (left) and burst pulses (right) generated during early testing of DolphinGemma.</p>
    </div>
  
  
    <p><img alt="Two spectrograms: left shows three arching sound patterns; right shows a more uniform sound pattern." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="3p158">This model builds upon insights from <a href="https://ai.google.dev/gemma">Gemma</a>, Googleâ€™s collection of lightweight, state-of-the-art open models that are built from the same research and technology that powers our Gemini models. Trained extensively on WDPâ€™s acoustic database of wild Atlantic spotted dolphins, DolphinGemma functions as an audio-in, audio-out model, processes sequences of natural dolphin sounds to identify patterns, structure and ultimately predict the likely subsequent sounds in a sequence, much like how large language models for human language predict the next word or token in a sentence.</p><p data-block-key="a754e">WDP is beginning to deploy DolphinGemma this field season with immediate potential benefits. By identifying recurring sound patterns, clusters and reliable sequences, the model can help researchers uncover hidden structures and potential meanings within the dolphins' natural communication â€” a task previously requiring immense human effort. Eventually, these patterns, augmented with synthetic sounds created by the researchers to refer to objects with which the dolphins like to play, may establish a shared vocabulary with the dolphins for interactive communication.</p></div>
  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="3p158">Using Pixel phones to listen to and analyze dolphin sounds</h2><p data-block-key="7vd3s">In addition to analyzing natural communication, WDP is also pursuing a distinct, parallel path: exploring potential two-way interaction using technology in the ocean. This effort led to the development of the <a href="https://www.wilddolphinproject.org/our-research/chat-research/">CHAT</a> (Cetacean Hearing Augmentation Telemetry) system, in partnership with the Georgia Institute of Technology. CHAT is an underwater computer designed not to directly decipher the dolphins' complex natural language, but to establish a simpler, shared vocabulary.</p><p data-block-key="6avcn">The concept first relies on associating novel, synthetic whistles (created by CHAT, distinct from natural dolphin sounds) with specific objects the dolphins enjoy, like sargassum, seagrass or scarves the researchers use. By demonstrating the system between humans, researchers hope the naturally curious dolphins will learn to mimic the whistles to request these items. Eventually, as more of the dolphinsâ€™ natural sounds are understood, they can also be added to the system.</p></div>
  

  
    
  
    


  <uni-youtube-player-article index="10" thumbnail-alt="CHAT explainer video" video-id="YhopeQKbpZA" video-type="video">
  </uni-youtube-player-article>


  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="3p158">To enable two-way interaction, the CHAT system first needs to:</p><ol><li data-block-key="9is9o">Hear the mimic accurately amid ocean noise.</li><li data-block-key="5qsu4">Identify which whistle was mimicked in real-time.</li><li data-block-key="48nl7">Inform the researcher (via bone-conducting headphones that work underwater) which object the dolphin "requested."</li><li data-block-key="2f5o">Enable the researcher to respond quickly by offering the correct object, reinforcing the connection.</li></ol><p data-block-key="c9b4">A Google Pixel 6 handled the high-fidelity analysis of dolphin sounds in real time. The upcoming generation, centered around a Google Pixel 9 (research slated for summer 2025), builds on this effort by integrating speaker/microphone functions and using the phone's advanced processing to run both deep learning models and template matching algorithms simultaneously.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two portraits: left, a woman on a boat holding a device; right, a man indoors wearing headphones and holding a similar device." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="pdphj">Left: Dr. Denise Herzing wearing â€œChat Senior, 2012â€, Right: Georgia Tech PhD Student Charles Ramey wearing â€œChat Junior, 2025â€</p>
    </div>
  
  
    <p><img alt="Two portraits: left, a woman on a boat holding a device; right, a man indoors wearing headphones and holding a similar device." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }">
        <p data-block-key="su54v">Using Pixel smartphones dramatically reduces the need for custom hardware, improves system maintainability, lowers power consumption and shrinks the device's cost and size â€” crucial advantages for field research in the open ocean. Meanwhile, DolphinGemmaâ€™s predictive power can help CHAT anticipate and identify potential mimics earlier in the vocalization sequence, increasing the speed at which researchers can react to the dolphins and making interactions more fluid and reinforcing.</p>
      </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Pixel phone inside a case hooked up to cables" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="qfo9j">A Google Pixel 9 inside the latest CHAT system hardware.</p>
    </div>
  
  
    <p><img alt="Pixel phone inside a case hooked up to cables" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="su54v">Sharing DolphinGemma with the research community</h2><p data-block-key="2ad01">Recognizing the value of collaboration in scientific discovery, weâ€™re planning to share DolphinGemma as an open model this summer. While trained on Atlantic spotted dolphin sounds, we anticipate its potential utility for researchers studying other cetacean species, like bottlenose or spinner dolphins. Fine-tuning may be required for different species' vocalizations, and the open nature of the model facilitates this adaptation.</p><p data-block-key="40nps">By providing tools like DolphinGemma, we hope to give researchers worldwide the tools to mine their own acoustic datasets, accelerate the search for patterns and collectively deepen our understanding of these intelligent marine mammals.</p><p data-block-key="e2jq7">The journey to understanding dolphin communication is long, but the combination of dedicated field research by WDP, engineering expertise from Georgia Tech and the power of Google's technology is opening exciting new possibilities. We're not just listening anymore. We're beginning to understand the patterns within the sounds, paving the way for a future where the gap between human and dolphin communication might just get a little smaller.</p><p data-block-key="esrl0">You can learn more about the<a href="https://www.wilddolphinproject.org/"> Wild Dolphin Project</a> on their website.</p></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meilisearch â€“ search engine API bringing AI-powered hybrid search (131 pts)]]></title>
            <link>https://github.com/meilisearch/meilisearch</link>
            <guid>43680699</guid>
            <pubDate>Mon, 14 Apr 2025 12:46:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/meilisearch/meilisearch">https://github.com/meilisearch/meilisearch</a>, See on <a href="https://news.ycombinator.com/item?id=43680699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-light-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only">
  </a>
  <a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-dark-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only">
  </a>
</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">
  <a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Website</a> |
  <a href="https://roadmap.meilisearch.com/tabs/1-under-consideration" rel="nofollow">Roadmap</a> |
  <a href="https://www.meilisearch.com/pricing?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Meilisearch Cloud</a> |
  <a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Blog</a> |
  <a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Documentation</a> |
  <a href="https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">FAQ</a> |
  <a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Discord</a>
</h4><a id="user-content---website---roadmap---meilisearch-cloud---blog---documentation---faq---discord" aria-label="Permalink: Website |
  Roadmap |
  Meilisearch Cloud |
  Blog |
  Documentation |
  FAQ |
  Discord" href="#--website---roadmap---meilisearch-cloud---blog---documentation---faq---discord"></a></p>
<p dir="auto">
  <a href="https://deps.rs/repo/github/meilisearch/meilisearch" rel="nofollow"><img src="https://camo.githubusercontent.com/0b51de54cdba053bdde0478c1ffc91dbc30d279d73e71c78088e77e98f41735e/68747470733a2f2f646570732e72732f7265706f2f6769746875622f6d65696c697365617263682f6d65696c697365617263682f7374617475732e737667" alt="Dependency status" data-canonical-src="https://deps.rs/repo/github/meilisearch/meilisearch/status.svg"></a>
  <a href="https://github.com/meilisearch/meilisearch/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/60e4fe2b4b86adf9d06832e9dcbbe27eddf7f46bc4af612f3dda01c9907a7a07/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d696e666f726d6174696f6e616c" alt="License" data-canonical-src="https://img.shields.io/badge/license-MIT-informational"></a>
  <a href="https://github.com/meilisearch/meilisearch/queue"><img alt="Merge Queues enabled" src="https://camo.githubusercontent.com/4fc74073767004f08ce185305a7295b9e062871fb144ca0fa35592b02a3fcac0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d657267655f5175657565732d656e61626c65642d2532333537636636303f6c6f676f3d676974687562" data-canonical-src="https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github"></a>
</p>
<p name="user-content-ph-banner" dir="auto">
  <a href="https://www.producthunt.com/posts/meilisearch-ai" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/ph-banner.png" alt="Meilisearch AI-powered search general availability announcement on ProductHunt">
  </a>
</p>
<p dir="auto">âš¡ A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow ðŸ”</p>
<p dir="auto"><a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=intro" rel="nofollow">Meilisearch</a> helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.</p>
<p name="user-content-demo" dir="auto">
  <a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-light-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/demo-light.gif#gh-light-mode-only" alt="A bright colored application for finding movies screening near the user" data-animated-image="">
  </a>
  <a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-dark-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/demo-dark.gif#gh-dark-mode-only" alt="A dark colored application for finding movies screening near the user" data-animated-image="">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ–¥ Examples</h2><a id="user-content--examples" aria-label="Permalink: ðŸ–¥ Examples" href="#-examples"></a></p>
<ul dir="auto">
<li><a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=organization" rel="nofollow"><strong>Movies</strong></a> â€” An application to help you find streaming platforms to watch movies using <a href="https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow">hybrid search</a>.</li>
<li><a href="https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow"><strong>Ecommerce</strong></a> â€” Ecommerce website using disjunctive <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow">facets</a>, range and rating filtering, and pagination.</li>
<li><a href="https://music.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow"><strong>Songs</strong></a> â€” Search through 47 million of songs.</li>
<li><a href="https://saas.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow"><strong>SaaS</strong></a> â€”&nbsp;Search for contacts, deals, and companies in this <a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow">multi-tenant</a> CRM application.</li>
</ul>
<p dir="auto">See the list of all our example apps in our <a href="https://github.com/meilisearch/demos">demos repository</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">âœ¨ Features</h2><a id="user-content--features" aria-label="Permalink: âœ¨ Features" href="#-features"></a></p>
<ul dir="auto">
<li><strong>Hybrid search:</strong> Combine the best of both <a href="https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">semantic</a> &amp; full-text search to get the most relevant results</li>
<li><strong>Search-as-you-type:</strong> Find &amp; display results in less than 50 milliseconds to provide an intuitive experience</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Typo tolerance</a>:</strong> get relevant matches even when queries contain typos and misspellings</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Filtering</a> and <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">faceted search</a>:</strong> enhance your users' search experience with custom filters and build a faceted search interface in a few lines of code</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Sorting</a>:</strong> sort results based on price, date, or pretty much anything else your users need</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Synonym support</a>:</strong> configure synonyms to include more relevant content in your search results</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Geosearch</a>:</strong> filter and sort documents based on geographic data</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Extensive language support</a>:</strong> search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Security management</a>:</strong> control which users can access what data with API keys that allow fine-grained permissions handling</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Multi-Tenancy</a>:</strong> personalize search results for any number of application tenants</li>
<li><strong>Highly Customizable:</strong> customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets</li>
<li><strong><a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">RESTful API</a>:</strong> integrate Meilisearch in your technical stack with our plugins and SDKs</li>
<li><strong>AI-ready:</strong> works out of the box with <a href="https://www.meilisearch.com/with/langchain" rel="nofollow">langchain</a> and the <a href="https://github.com/meilisearch/meilisearch-mcp">model context protocol</a></li>
<li><strong>Easy to install, deploy, and maintain</strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ“– Documentation</h2><a id="user-content--documentation" aria-label="Permalink: ðŸ“– Documentation" href="#-documentation"></a></p>
<p dir="auto">You can consult Meilisearch's documentation at <a href="https://www.meilisearch.com/docs/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=docs" rel="nofollow">meilisearch.com/docs</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸš€ Getting started</h2><a id="user-content--getting-started" aria-label="Permalink: ðŸš€ Getting started" href="#-getting-started"></a></p>
<p dir="auto">For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our <a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=get-started" rel="nofollow">documentation</a> guide.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸŒ Supercharge your Meilisearch experience</h2><a id="user-content--supercharge-your-meilisearch-experience" aria-label="Permalink: ðŸŒ Supercharge your Meilisearch experience" href="#-supercharge-your-meilisearch-experience"></a></p>
<p dir="auto">Say goodbye to server deployment and manual updates with <a href="https://www.meilisearch.com/cloud?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch" rel="nofollow">Meilisearch Cloud</a>. Additional features include analytics &amp; monitoring in many regions around the world. No credit card is required.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ§° SDKs &amp; integration tools</h2><a id="user-content--sdks--integration-tools" aria-label="Permalink: ðŸ§° SDKs &amp; integration tools" href="#-sdks--integration-tools"></a></p>
<p dir="auto">Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!</p>
<p dir="auto">Take a look at the complete <a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-link" rel="nofollow">Meilisearch integration list</a>.</p>
<p dir="auto"><a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-logos" rel="nofollow"><img src="https://github.com/meilisearch/meilisearch/raw/main/assets/integrations.png" alt="Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">âš™ï¸ Advanced usage</h2><a id="user-content-ï¸-advanced-usage" aria-label="Permalink: âš™ï¸ Advanced usage" href="#ï¸-advanced-usage"></a></p>
<p dir="auto">Experienced users will want to keep our <a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">API Reference</a> close at hand.</p>
<p dir="auto">We also offer a wide range of dedicated guides to all Meilisearch features, such as <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">filtering</a>, <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">sorting</a>, <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">geosearch</a>, <a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">API keys</a>, and <a href="https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">tenant tokens</a>.</p>
<p dir="auto">Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as <a href="https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">documents</a> and <a href="https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">indexes</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ“Š Telemetry</h2><a id="user-content--telemetry" aria-label="Permalink: ðŸ“Š Telemetry" href="#-telemetry"></a></p>
<p dir="auto">Meilisearch collects <strong>anonymized</strong> user data to help us improve our product. You can <a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection" rel="nofollow">deactivate this</a> whenever you want.</p>
<p dir="auto">To request deletion of collected data, please write to us at <a href="mailto:privacy@meilisearch.com">privacy@meilisearch.com</a>. Remember to include your <code>Instance UID</code> in the message, as this helps us quickly find and delete your data.</p>
<p dir="auto">If you want to know more about the kind of data we collect and what we use it for, check the <a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection" rel="nofollow">telemetry section</a> of our documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ“« Get in touch!</h2><a id="user-content--get-in-touch" aria-label="Permalink: ðŸ“« Get in touch!" href="#-get-in-touch"></a></p>
<p dir="auto">Meilisearch is a search engine created by Meili, a software development company headquartered in France and with team members all over the world. Want to know more about us? <a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact" rel="nofollow">Check out our blog!</a></p>
<p dir="auto">ðŸ—ž <a href="https://meilisearch.us2.list-manage.com/subscribe?u=27870f7b71c908a8b359599fb&amp;id=79582d828e" rel="nofollow">Subscribe to our newsletter</a> if you don't want to miss any updates! We promise we won't clutter your mailbox: we only send one edition every two months.</p>
<p dir="auto">ðŸ’Œ Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:</p>
<ul dir="auto">
<li>For feature requests, please visit our <a href="https://github.com/meilisearch/product/discussions">product repository</a></li>
<li>Found a bug? Open an <a href="https://github.com/meilisearch/meilisearch/issues">issue</a>!</li>
<li>Want to be part of our Discord community? <a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact" rel="nofollow">Join us!</a></li>
</ul>
<p dir="auto">Thank you for your support!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ‘©â€ðŸ’» Contributing</h2><a id="user-content--contributing" aria-label="Permalink: ðŸ‘©â€ðŸ’» Contributing" href="#-contributing"></a></p>
<p dir="auto">Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at <a href="https://github.com/meilisearch/meilisearch/blob/main/CONTRIBUTING.md">our contribution guidelines</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðŸ“¦ Versioning</h2><a id="user-content--versioning" aria-label="Permalink: ðŸ“¦ Versioning" href="#-versioning"></a></p>
<p dir="auto">Meilisearch releases and their associated binaries are available on the project's <a href="https://github.com/meilisearch/meilisearch/releases">releases page</a>.</p>
<p dir="auto">The binaries are versioned following <a href="https://semver.org/" rel="nofollow">SemVer conventions</a>. To know more, read our <a href="https://github.com/meilisearch/engine-team/blob/main/resources/versioning-policy.md">versioning policy</a>.</p>
<p dir="auto">Differently from the binaries, crates in this repository are not currently available on <a href="https://crates.io/" rel="nofollow">crates.io</a> and do not follow <a href="https://semver.org/" rel="nofollow">SemVer conventions</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omnom: Self-hosted bookmarking with searchable, wysiwyg snapshots [showcase] (146 pts)]]></title>
            <link>https://omnom.zone/?src=hn</link>
            <guid>43680232</guid>
            <pubDate>Mon, 14 Apr 2025 11:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://omnom.zone/?src=hn">https://omnom.zone/?src=hn</a>, See on <a href="https://news.ycombinator.com/item?id=43680232">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<article>
  <p>Warning</p>
  <p>This is a read-only demo instance - check out our <a href="https://github.com/asciimoo/omnom">GitHub</a> for more details</p>
</article>

            <h3>Download extension</h3>
            <p>
                Browser extensions are required to create bookmarks &amp; snapshots. Install the extension to your browser and enjoy Omnoming.
            </p>
            
        </div></div>]]></description>
        </item>
    </channel>
</rss>