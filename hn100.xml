<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 11 Dec 2025 16:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Meta shuts down global accounts linked to abortion advice and queer content (280 pts)]]></title>
            <link>https://www.theguardian.com/global-development/2025/dec/11/meta-shuts-down-global-accounts-linked-to-abortion-advice-and-queer-content</link>
            <guid>46230072</guid>
            <pubDate>Thu, 11 Dec 2025 11:26:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/global-development/2025/dec/11/meta-shuts-down-global-accounts-linked-to-abortion-advice-and-queer-content">https://www.theguardian.com/global-development/2025/dec/11/meta-shuts-down-global-accounts-linked-to-abortion-advice-and-queer-content</a>, See on <a href="https://news.ycombinator.com/item?id=46230072">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Meta has removed or restricted dozens of accounts belonging to abortion access providers, queer groups and reproductive health organisations in the past weeks in what campaigners call one of the “biggest waves of censorship” on its platforms in years.</p><p>The takedowns and restrictions began in October and targeted the Facebook, <a href="https://www.theguardian.com/technology/instagram" data-link-name="in body link" data-component="auto-linked-tag">Instagram</a> and WhatsApp accounts of more than 50 organisations worldwide, some serving tens of thousands of people – in what appears to be a growing push by Meta to limit reproductive health and queer content across its platforms. Many of these were from Europe and the UK, however the bans also affected groups serving women in Asia, Latin America and the Middle East.</p><p>Repro Uncensored, an NGO tracking digital censorship against movements focused on gender, health and justice, said that it had tracked 210 incidents of account removals and severe restrictions affecting these groups this year, compared with 81 last year.</p><p>Meta denied an escalating trend of censorship. “Every organisation and individual on our platforms is <a href="https://transparency.meta.com/policies/community-standards/" data-link-name="in body link">subject to the same set of rules</a>, and any claims of enforcement based on group affiliation or advocacy are baseless,” it said in a statement, adding that its policies on abortion-related content had not changed.</p><figure id="ade83e20-9ddd-4875-994b-bd0be693edef" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A black box that says ‘We suspended your account, The Queer Agenda’ in the middle of squares of social media content" src="https://i.guim.co.uk/img/media/976a0fd5e30e02c3c3dc2ac1e6cdb93f0ca63219/0_0_1195_831/master/1195.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="309.4518828451883" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>In a recent purge queer and sex-positive accounts were banned.</span> Photograph: Courtesy of Repro Uncensored</figcaption></figure><p>Campaigners say the actions indicate that Meta is taking its Trump-era approach to women’s health and LGBTQ+ issues global. Earlier this year, <a href="https://www.theguardian.com/world/2025/jan/29/abortion-pills-instagram-shadow-banning" data-link-name="in body link">it appeared to “shadow-ban” or remove the accounts</a> of organisations on Instagram or Facebook helping Americans to find abortion pills. Shadow-banning is when a social media platform severely restricts the visibility of a user’s content without telling the user.</p><p>In this latest purge, it blocked abortion hotlines in countries where abortion is legal, banned queer and sex-positive accounts in Europe, and removed posts with even non-explicit, cartoon depictions of nudity.</p><p>“Within this last year, especially since the new US presidency, we have seen a definite increase in accounts being taken down – not only in the US, but also worldwide as a ripple effect,” said Martha Dimitratou, executive director of Repro Uncensored.</p><figure id="7b7aef26-bc34-49f9-bdcc-ae4b35df01d8" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Mark Zuckerberg and Donald Trump sit at a table laughing; Trump has his hand on Zuckerberg’s back." src="https://i.guim.co.uk/img/media/9cbcb14759839e4807385822bff8b17500bd20b3/0_0_7819_5213/master/7819.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="296.68563754955875" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>US president Donald Trump jokes with Meta CEO Mark Zuckerberg, left, as he hosts tech leaders for a dinner in the state dining room of the White House in Washington DC in September 2025. </span> Photograph: Saul Loeb/AFP/Getty Images</figcaption></figure><p>“This has been, to my knowledge, at least one of the biggest waves of censorship we are seeing,” she said.</p><p><br>
 Campaigners have accused Meta of being condescending and unresponsive, with the company offering only vague reasons why certain accounts were taken down – and appearing unwilling to engage.</p><p>In one email shared with the Guardian, a Meta consultant appears to invite a number of reproductive health organisations to a closed-door online briefing about “the challenges that you are facing with Meta’s content moderation policies”.</p><p>The email says the meeting “will not be an opportunity to raise critiques of Meta’s practices or to offer recommendations for policy changes”.</p><p>Dimitratou said such closed-door meetings had happened before, saying they “reinforce the power imbalance that allows big tech to decide whose voices are amplified and whose are silenced”.</p><p>In another instance, a Meta employee counselled an affected organisation in a personal message to simply move away from the platform entirely and start a mailing list, saying that bans were likely to continue. Meta said it did not send this message.</p><p>Meta’s recent takedowns are part of a broader pattern of the company purging accounts, and then – at times – appearing to backtrack after public pressure, said Carolina Are, a fellow at Northumbria University’s Centre for Digital Citizens.</p><p>“It wouldn’t be as much of a problem if platforms’ appeals actually worked, but they don’t. And appeals are the basis of any democratic justice system,” she added.</p><p>Meta said that it aimed to reduce enforcement mistakes against accounts on its platform, but added that the appeals process for banned accounts had become frustratingly slow.</p><p>Organisations affected by the bans include Netherlands-registered Women Help Women, a nonprofit offering information about abortion to women worldwide, including in Brazil, the Philippines and Poland. It fields about 150,000 emails from women each year, said its executive director, Kinga Jelinska.</p><figure id="e2e87436-142f-43c1-8a29-3b8c38178c5b" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=380&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=380&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A black box that says ‘We suspended your page’ in the middle of squares of social media content" src="https://i.guim.co.uk/img/media/ad4ef5cc572acfe48bcfaa2b1bfe5bc3dcc41e80/0_0_1259_889/master/1259.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="314.2216044479746" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The feminist group Women Help Women had their page banned by Meta in November, but it has since been reinstated.</span> Photograph: Courtesy of Repro Uncensored</figcaption></figure><p>Women Help Women has been on <a href="https://www.theguardian.com/technology/facebook" data-link-name="in body link" data-component="auto-linked-tag">Facebook</a> for 11 years, said Jelinska, and while its account had been suspended before, this was the first time it was banned outright. The ban could be “life-threatening”, she said, pushing some women towards dangerous, less reliable information sources. Little explanation was given for the ban.</p><p>A message from Meta to the group dated 13 November said its page “does not follow our Community Standards on prescription drugs”, adding: “We know this is disappointing, but we want to keep Facebook safe and welcoming for everyone.”</p><p>“It’s a very laconic explanation, a feeling of opacity,” Jelinska said. “They just removed it. That’s it. We don’t even know which post it was about.”</p><p>Meta said more than half of the accounts flagged by Repro Uncensored have been reinstated, including Women Help Women which it said was taken down in error. “The disabled accounts were correctly removed for violating a variety of our policies including our <a href="https://transparency.meta.com/policies/community-standards/human-exploitation/" data-link-name="in body link">Human Exploitation</a> policy,” it added.</p><p>Jacarandas was founded by a group of young feminists when abortion was <a href="https://www.theguardian.com/global-development/2022/feb/22/colombia-legalises-abortion-in-move-celebrated-as-historic-victory-by-campaigners" data-link-name="in body link">decriminalised in Colombia in 2022</a>, to advise women and girls on how to get a free, legal abortion. The group’s executive director, Viviana Monsalve, said its WhatsApp helpline had been blocked then reinstated three times since October. The WhatsApp account is currently banned and Monsalve said they had received little information from Meta about whether this would continue.</p><p>“We wrote [Meta] an email and said, ‘hey, we are a feminist organisation. We work in abortion. <a href="https://www.theguardian.com/world/abortion" data-link-name="in body link" data-component="auto-linked-tag">Abortion</a> is allowed in Colombia up to 24 weeks. It’s allowed to give information about it,’” said Monsalve.</p><p>Without Meta’s cooperation, Monsalve said it was difficult to plan for the future. “You are not sure if [a ban] will happen tomorrow or after tomorrow, because they didn’t answer anything.”</p><figure id="c3516402-bc9c-4ff6-b3c1-41c5dc0fb476" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:27,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Meta and Google accused of restricting reproductive health information&quot;,&quot;elementId&quot;:&quot;c3516402-bc9c-4ff6-b3c1-41c5dc0fb476&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/global-development/2024/mar/27/meta-and-google-accused-of-restricting-reproductive-health-information&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>Meta said: “Our policies and enforcement regarding abortion medication-related content have not changed: we allow posts and ads promoting healthcare services like abortion, as well as discussion and debate around them, as long as they follow our policies.”</p><p>While groups such as Jacarandas and Women Help Women had their accounts removed outright, other groups said that they increasingly faced Meta restricting their posts and shadow-banning their content.</p><p>Fatma Ibrahim, the director of the Sex Talk Arabic, a UK-based platform which offers Arabic-language content on sexual and reproductive health, said that the organisation had received a message almost every week from Meta over the past year saying that its page “didn’t follow the rules” and would not be suggested to other people, based on posts related to sexuality and sexual health.</p><figure id="3efc4ddb-c1c7-4bb7-ac98-61189cfd0704" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="An illustration of a naked man and woman walking along a path with an arm around each others’ wait while pink hearts float around, one covering their bottoms." src="https://i.guim.co.uk/img/media/72d60b6755dcd49881de61a16b2ad609c37a28a7/0_0_1629_1192/master/1629.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="325.6230816451811" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>An Instagram post from The Sex Talk Arabic that triggered a nudity warning and was removed by Meta.</span> Photograph: Courtesy of Thesextalkarabic</figcaption></figure><p>Two weeks ago, these messages escalated to a warning, in which Meta noted its new policies on nudity and removed a post from the Sex Talk Arabic’s page. The offending <a href="https://www.instagram.com/p/DJMherqt6rA/?igsh=MW9zd254dTJ0MXhtbQ%3D%3D" data-link-name="in body link">post was an artistic depiction of a naked couple</a>, obscured by hearts.</p><p>Ibrahim said the warning was “condescending”, and that Meta’s moderation was US-centric and lacked context.</p><p>“Despite the profits they make from our region, they don’t invest enough to understand the social issues women fight against and why we use social media platforms for such fights,” she said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A “frozen” dictionary for Python (114 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1047238/25c270b077849dc0/</link>
            <guid>46229467</guid>
            <pubDate>Thu, 11 Dec 2025 09:51:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1047238/25c270b077849dc0/">https://lwn.net/SubscriberLink/1047238/25c270b077849dc0/</a>, See on <a href="https://news.ycombinator.com/item?id=46229467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
Dictionaries are ubiquitous in Python code; they are the data structure of
choice for a wide variety of tasks.  But dictionaries are mutable, which
makes them problematic for sharing data in concurrent code.  Python has
added various concurrency features to the language over the last decade or
so—<a href="https://lwn.net/Articles/726600/">async</a>, <a href="https://lwn.net/Articles/947138/">free threading without the global interpreter lock</a>
(GIL), and <a href="https://lwn.net/Articles/941090/">independent subinterpreters</a>—but users must work out their own
solution for an immutable dictionary that can be safely shared by
concurrent code.  There are existing modules that could be used, but a recent proposal, <a href="https://peps.python.org/pep-0814/">PEP 814</a> ("Add frozendict
built-in type"), looks to bring the feature to the language itself.
</p>

<p>
Victor Stinner <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854">announced
the PEP</a> that he and Donghee Na have authored in a post to the PEPs
category of the <a href="https://discuss.python.org/">Python discussion
forum</a> on November 13.  The idea has come up before, including in <a href="https://peps.python.org/pep-0416/">PEP 416</a>, which has essentially
the same title as 814 and was authored by Stinner back in 2012.  It was
rejected by Guido van Rossum at the time, in part due to its target: a <a href="https://lwn.net/Articles/574215/">Python sandbox</a> that never
really panned out.
</p>

<h4><tt>frozendict</tt></h4>

<p>
The idea is fairly straightforward: add <tt>frozendict</tt> as a new
immutable type to the
language's <a href="https://docs.python.org/3/library/builtins.html#module"><tt>builtins</tt>
module</a>.  As Stinner put it:
</p><blockquote>
We expect <tt>frozendict</tt> to be safe by design, as it prevents any unintended modifications. This addition benefits not only CPython's standard library, but also third-party maintainers who can take advantage of a reliable, immutable dictionary type.
</blockquote>


<p>
While <tt>frozendict</tt> has a lot in common with the <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict"><tt>dict</tt></a>
built-in type, it is <a href="https://peps.python.org/pep-0814/#inherit-from-dict">not a subclass of <tt>dict</tt></a>; instead, it
is a subclass of the base <a href="https://docs.python.org/3/library/functions.html#object"><tt>object</tt></a>
type.  The <tt>frozendict()</tt> constructor can be used to create one in
various ways:
</p><pre>    fd = frozendict()           # empty
    fd = frozendict(a=1, b=2)   # frozen { 'a' : 1, 'b' : 2 }
    d = { 'a' : 1, 'b' : 2 }
    fd = frozendict(d)          # same
    l = [ ( 'a', 1 ), ( 'b', 2 ) ]
    fd = frozendict(l)          # same
    fd2 = frozendict(fd)        # same
    assert d == fd == fd2       # True
</pre>


<p>
As with dictionaries, the keys for a <tt>frozendict</tt> must be immutable,
thus <a href="https://docs.python.org/3/glossary.html#term-hashable">hashable</a>,
but the values may or may not be.  For example, a list is a legitimate type
for a value in either type of dictionary, but it is mutable, making the
dictionary as a whole (frozen or not) mutable.  However, if all of the
values stored in a <tt>frozendict</tt> are immutable, it is also immutable,
so it can be hashed and used in places where that is required
(e.g. dictionary keys, set elements, or entries in a <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache"><tt>functools.lru_cache</tt></a>).
</p>

<p>
As might be guessed, based on the last line of the example above, frozen
dictionaries that are hashable can be compared for equality with other
dictionaries of either type.  In addition, neither the <a href="https://docs.python.org/3/library/functions.html#hash"><tt>hash()</tt></a>
value nor the equality test depend on the insertion order of the
dictionary, though that order is preserved in a frozen dictionary (as it is
in the regular variety).  So:
</p><pre>    d = { 'a' : 1, 'b' : 2 }
    fd = frozendict(d)
    d2 = { 'b' : 2, 'a' : 1 }
    fd2 = frozendict(d2)
    assert d == d2 == fd == fd2

    # frozendict unions work too, from the PEP
    &gt;&gt;&gt; frozendict(x=1) | frozendict(y=1)
    frozendict({'x': 1, 'y': 1})
    &gt;&gt;&gt; frozendict(x=1) | dict(y=1)
    frozendict({'x': 1, 'y': 1})
</pre><p>
For the unions, a new frozen dictionary is created in both cases; the
"</p><tt>|=</tt><p>" union-assignment operator also works by generating a new
</p><tt>frozendict</tt><p> for the result.
</p>

<p>
Iteration over a <tt>frozendict</tt> works as expected; the type implements
the <a href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping"><tt>collections.abc.Mapping</tt></a>
abstract base class, so <tt>.items()</tt> returns an iterable of key-value
tuples, while <tt>.keys()</tt> and <tt>.values()</tt> provide the keys and
values of the frozen dictionary.
For the most part, a
<tt>frozendict</tt> acts like a <tt>dict</tt> that cannot change; the
specific differences between the two are <a href="https://peps.python.org/pep-0814/#differences-between-dict-and-frozendict">listed
in the PEP</a>.  It also contains a <a href="https://peps.python.org/pep-0814/#possible-candidates-for-frozendict-in-the-stdlib">lengthy
list</a> of places in the standard library where a <tt>dict</tt> could be switched to a
<tt>frozendict</tt> to "<q>enhance safety and prevent unintended modifications</q>".
</p>

<h4>Discussion</h4>

<p>
The reaction to the PEP was generally positive, with the usual suggestions
for tweaks and more substantive additions to the proposal.  Stinner kept
the discussion focused on the proposal at hand for the most part.  One part
of the proposal was troubling to some: converting a <tt>dict</tt> to a
<tt>frozendict</tt> was described as an O(n) shallow copy.  Daniel F
Moisset <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/19">thought</a>
that it would make sense to have an in-place transformation that could be
O(1) instead.  He proposed adding a <tt>.freeze()</tt> method that would
essentially just change the type of a <tt>dict</tt> object to
<tt>frozendict</tt>. 
</p>

<p>
However, changing the type of an existing object is fraught with peril, as Brett
Cannon <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/20">described</a>:

</p><blockquote>
But now you have made that dictionary frozen for everyone who holds a reference to it, which means side-effects at a distance in a way that could be unexpected (e.g. context switch in a thread and now suddenly you're going to get an exception trying to mutate what was a dict a microsecond ago but is now frozen). That seems like asking for really nasty debugging issues just to optimize some creation time.
</blockquote>



<p>
The PEP is not aimed at performance, he continued, but is meant to help
"<q>lessen bugs in concurrent code</q>".  Moisset <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/23">noted</a>,
that dictionaries can already change in unexpected ways via
<a href="https://docs.python.org/3/library/stdtypes.html#dict.clear"><tt>.clear()</tt></a>
or <a href="https://docs.python.org/3/library/stdtypes.html#dict.update"><tt>.update()</tt></a>,
thus the debugging issues already exist.  He recognized that the
authors may not want to tackle that as part of the PEP, but wanted to try
to ensure that an O(1) transformation was not precluded in the future.
</p>

<p>
Cannon's <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/47">strong
objection</a> is to changing the type of the object directly.  <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/24">Ben
Hsing</a> and <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/48">"Nice
Zombies"</a> proposed ways to construct a new <tt>frozendict</tt> without
requiring the shallow copy—thus O(1)—by either moving the hash table to a
newly created <tt>frozendict</tt>, while clearing the dictionary, or by
using a copy-on-write scheme for the table.  As Steve Dower <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/58">noted</a>,
that optimization can be added later as long as the PEP does not specify
that the operation <i>must</i> be O(n), which would be a silly thing to do,
but that it sometimes happens "<q>because it makes people stop
complaining</q>", he said in a footnote.  In light of the discussion, the
PEP <a href="https://peps.python.org/pep-0814/#method-to-convert-dict-to-frozendict">specifically
defers</a> that optimization to a later time, suggesting that it could also
be done for other frozen types (<a href="https://docs.python.org/3/library/stdtypes.html#tuple"><tt>tuple</tt></a>
and <a href="https://docs.python.org/3/library/stdtypes.html#frozenset"><tt>frozenset</tt></a>),
perhaps by resurrecting <a href="https://peps.python.org/pep-0351/">PEP
351</a> ("The freeze protocol").
</p>

<p>
On December 1, Stinner <a href="https://discuss.python.org/t/pep-814-add-frozendict-built-in-type/104854/89">announced</a>
that the PEP had been <a href="https://github.com/python/steering-council/issues/325">submitted to
the steering council</a> for pronouncement.  Given that Na is on the
council, though will presumably recuse himself from deciding on this PEP,
he probably has a pretty good sense for how it might be received by the group.
So it seems likely that the PEP has a good chance of being approved.  The
availability of the
free-threaded version of the language (i.e. without the GIL) means that more
multithreaded Python programs are being created, so having a safe way to share
dictionaries 
between threads will be a boon.
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/PythonIndex/">Python</a></td><td><a href="https://lwn.net/Archives/PythonIndex/#Dictionaries">Dictionaries</a></td></tr>
            <tr><td><a href="https://lwn.net/Archives/PythonIndex/">Python</a></td><td><a href="https://lwn.net/Archives/PythonIndex/#Python_Enhancement_Proposals_PEP-PEP_814">Python Enhancement Proposals (PEP)/PEP 814</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cost of a Closure in C (116 pts)]]></title>
            <link>https://thephd.dev/the-cost-of-a-closure-in-c-c2y</link>
            <guid>46228597</guid>
            <pubDate>Thu, 11 Dec 2025 07:21:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thephd.dev/the-cost-of-a-closure-in-c-c2y">https://thephd.dev/the-cost-of-a-closure-in-c-c2y</a>, See on <a href="https://news.ycombinator.com/item?id=46228597">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <header id="main">
        
    </header>

    <section>
    
            <p>I had a vague idea that closures could have a variety of performance implications; I did not believe that so many of the chosen and potential designs for C and C++ extensions ones, however, were so…<!--more--> suboptimal.</p>

<p>But, before we get into how these things perform and what the cost of their designs are, we need to talk about what Closures are.</p>

<h2 id="closures">“Closures”?</h2>

<p>Closures in this instance are programming language constructs that includes data alongside instructions that are not directly related to their input (arguments) and their results (return values). They can be seen as a “generalization” of the concept of a function or function call, in that a function call is a “subset” of closures (e.g., the set of closures that do not include this extra, spicy data that comes from places outside of arguments and returns). These generalized functions and generalized function objects hold the ability to do things like work with “instance” data that is not passed to it directly (i.e., variables surrouding the closure off the stack) and, usually, some way to carry around more data than is implied by their associated function signature.</p>

<p>Pretty much all recent and modern languages include something for Closures unless they are deliberately developing for a target audience or for a source code design that is too “low level” for such a concept (such as Stack programming languages, Bytecode languages, or ones that fashion themselves as assembly-like or close to it). However, we’re going to be focusing on and looking specifically at Closures in C and C++, since this is going to be about trying to work with and – eventually – standardize something for ISO C that works for everyone.</p>

<p>First, let’s show a typical problem that arises in C code to show why closure solutions have popped up all over the C ecosystem, then talk about it in the context of the various solutions.</p>

<h2 id="the-closure-problem">The Closure Problem</h2>

<p>The closure problem can be neatly described by as “how do I get extra data to use within this <code>qsort</code> call?”. For example, consider setting this variable, <code>in_reverse</code>, as part of a bit of command line shenanigans, to change how a sort happens:</p>

<div><pre><code><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
#include</span> <span>&lt;string.h&gt;</span><span>
#include</span> <span>&lt;stddef.h&gt;</span><span>
</span>
<span>static</span> <span>int</span> <span>in_reverse</span> <span>=</span> <span>0</span><span>;</span>

<span>int</span> <span>compare</span><span>(</span><span>const</span> <span>void</span><span>*</span> <span>untyped_left</span><span>,</span> <span>const</span> <span>void</span><span>*</span> <span>untyped_right</span><span>)</span> <span>{</span>
  <span>const</span> <span>int</span><span>*</span> <span>left</span> <span>=</span> <span>untyped_left</span><span>;</span>
  <span>const</span> <span>int</span><span>*</span> <span>right</span> <span>=</span> <span>untyped_right</span><span>;</span>
  <span>return</span> <span>(</span><span>in_reverse</span><span>)</span> <span>?</span> <span>*</span><span>right</span> <span>-</span> <span>*</span><span>left</span> <span>:</span> <span>*</span><span>left</span> <span>-</span> <span>*</span><span>right</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
  <span>if</span> <span>(</span><span>argc</span> <span>&gt;</span> <span>1</span><span>)</span> <span>{</span>
    <span>char</span><span>*</span> <span>r_loc</span> <span>=</span> <span>strchr</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>'r'</span><span>);</span>
    <span>if</span> <span>(</span><span>r_loc</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
      <span>ptrdiff_t</span> <span>r_from_start</span> <span>=</span> <span>(</span><span>r_loc</span> <span>-</span> <span>argv</span><span>[</span><span>1</span><span>]);</span>
      <span>if</span> <span>(</span><span>r_from_start</span> <span>==</span> <span>1</span> <span>&amp;&amp;</span> <span>argv</span><span>[</span><span>1</span><span>][</span><span>0</span><span>]</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>strlen</span><span>(</span><span>r_loc</span><span>)</span> <span>==</span> <span>1</span><span>)</span> <span>{</span>
        <span>in_reverse</span> <span>=</span> <span>1</span><span>;</span>
      <span>}</span> 
    <span>}</span>
  <span>}</span>
  <span>int</span> <span>list</span><span>[]</span> <span>=</span> <span>{</span> <span>2</span><span>,</span> <span>11</span><span>,</span> <span>32</span><span>,</span> <span>49</span><span>,</span> <span>57</span><span>,</span> <span>20</span><span>,</span> <span>110</span><span>,</span> <span>203</span> <span>};</span>
  <span>qsort</span><span>(</span><span>list</span><span>,</span> <span>(</span><span>sizeof</span><span>(</span><span>list</span><span>)</span><span>/</span><span>sizeof</span><span>(</span><span>*</span><span>list</span><span>)),</span> <span>sizeof</span><span>(</span><span>*</span><span>list</span><span>),</span> <span>compare</span><span>);</span>
	
  <span>return</span> <span>list</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</code></pre></div>

<p>This uses a <code>static</code> variable to have it persist between both the <code>compare</code> function calls that <code>qsort</code> makes and the <code>main</code> call which (potentially) changes its value to be <code>1</code> instead of <code>0</code>. Unfortunately, this isn’t always the best idea for more complex programs that don’t fit within a single snippet:</p>

<ul>
  <li>it is impossible to have different “copies” of a <code>static</code> variable, meaning all mutations done in all parts of the program that can see <code>in_reverse</code> are responsible for knowing the state before and after (e.g., heavily stateful programming of state that you may not own / cannot see);</li>
  <li>working on <code>static</code> data may produce thread contention/race conditions in more complex programs;</li>
  <li>using <code>_Thread_local</code> instead of <code>static</code> only solves the race condition problem but does not solve the “shared across several places on the same thread” problem;</li>
  <li>referring to specific pieces of data or local pieces of data (like <code>list</code> itself) become impossible;</li>
</ul>

<p>and so on, and so forth. This is the core of the problem here. It becomes more pronounced when you want to do things with function and data that are a bit more complex, such as <a href="https://rosettacode.org/wiki/Man_or_boy_test">Donald Knuth’s “Man-or-Boy” test code</a>.</p>

<p>The solutions to these problems come in 4 major flavors in C and C++ code.</p>

<ul>
  <li>Just reimplement the offending function to take a userdata pointer so you can pass whatever data you want (typical C solution, e.g. going from <code>qsort</code> as the sorting function to BSD’s <code>qsort_r</code><sup id="fnref:bsd-qsort_r" role="doc-noteref"><a href="#fn:bsd-qsort_r" rel="footnote">1</a></sup> or Annex K’s <code>qsort_s</code><sup id="fnref:annex-k-qsort_s" role="doc-noteref"><a href="#fn:annex-k-qsort_s" rel="footnote">2</a></sup>).</li>
  <li>Use GNU Nested Functions to just Refer To What You Want Anyways.</li>
  <li>Use Apple Blocks to just Refer To What You Want Anyways.</li>
  <li>Use C++ Lambdas and some elbow grease to just Refer To What You Want Anyways.</li>
</ul>

<p>Each solution has drawbacks and benefits insofar as usability and design, but as a quick overview we’ll show what it’s like using <code>qsort</code> (or <code>qsort_r</code>/<code>qsort_s</code>, where applicable). Apple Blocks, for starters, looks like this:</p>

<div><pre><code><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
#include</span> <span>&lt;string.h&gt;</span><span>
#include</span> <span>&lt;stddef.h&gt;</span><span>
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
	<span>// local, non-static variable</span>
	<span>int</span> <span>in_reverse</span> <span>=</span> <span>0</span><span>;</span>

	<span>// value changed in-line</span>
	<span>if</span> <span>(</span><span>argc</span> <span>&gt;</span> <span>1</span><span>)</span> <span>{</span>
		<span>char</span><span>*</span> <span>r_loc</span> <span>=</span> <span>strchr</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>'r'</span><span>);</span>
		<span>if</span> <span>(</span><span>r_loc</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
			<span>ptrdiff_t</span> <span>r_from_start</span> <span>=</span> <span>(</span><span>r_loc</span> <span>-</span> <span>argv</span><span>[</span><span>1</span><span>]);</span>
			<span>if</span> <span>(</span><span>r_from_start</span> <span>==</span> <span>1</span> <span>&amp;&amp;</span> <span>argv</span><span>[</span><span>1</span><span>][</span><span>0</span><span>]</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>strlen</span><span>(</span><span>r_loc</span><span>)</span> <span>==</span> <span>1</span><span>)</span> <span>{</span>
				<span>in_reverse</span> <span>=</span> <span>1</span><span>;</span>
			<span>}</span> 
		<span>}</span>
	<span>}</span>
	
	<span>int</span> <span>list</span><span>[]</span> <span>=</span> <span>{</span> <span>2</span><span>,</span> <span>11</span><span>,</span> <span>32</span><span>,</span> <span>49</span><span>,</span> <span>57</span><span>,</span> <span>20</span><span>,</span> <span>110</span><span>,</span> <span>203</span> <span>};</span>
	
	<span>qsort_b</span><span>(</span><span>list</span><span>,</span> <span>(</span><span>sizeof</span><span>(</span><span>list</span><span>)</span><span>/</span><span>sizeof</span><span>(</span><span>*</span><span>list</span><span>)),</span> <span>sizeof</span><span>(</span><span>*</span><span>list</span><span>),</span>
		<span>// Apple Blocks are Block Expressions, meaning they do not have to be stored</span>
		<span>// in a variable first</span>
		<span>^</span><span>(</span><span>const</span> <span>void</span><span>*</span> <span>untyped_left</span><span>,</span> <span>const</span> <span>void</span><span>*</span> <span>untyped_right</span><span>)</span> <span>{</span>
			<span>const</span> <span>int</span><span>*</span> <span>left</span> <span>=</span> <span>untyped_left</span><span>;</span>
			<span>const</span> <span>int</span><span>*</span> <span>right</span> <span>=</span> <span>untyped_right</span><span>;</span>
			<span>return</span> <span>(</span><span>in_reverse</span><span>)</span> <span>?</span> <span>*</span><span>right</span> <span>-</span> <span>*</span><span>left</span> <span>:</span> <span>*</span><span>left</span> <span>-</span> <span>*</span><span>right</span><span>;</span>
		<span>}</span>
	<span>);</span>
	
	<span>return</span> <span>list</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</code></pre></div>

<p>and GNU Nested Functions look like this:</p>

<div><pre><code><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
#include</span> <span>&lt;string.h&gt;</span><span>
#include</span> <span>&lt;stddef.h&gt;</span><span>
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
	<span>// local, non-static variable</span>
	<span>int</span> <span>in_reverse</span> <span>=</span> <span>0</span><span>;</span>

	<span>// modify variable in-line</span>
	<span>if</span> <span>(</span><span>argc</span> <span>&gt;</span> <span>1</span><span>)</span> <span>{</span>
		<span>char</span><span>*</span> <span>r_loc</span> <span>=</span> <span>strchr</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>'r'</span><span>);</span>
		<span>if</span> <span>(</span><span>r_loc</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
			<span>ptrdiff_t</span> <span>r_from_start</span> <span>=</span> <span>(</span><span>r_loc</span> <span>-</span> <span>argv</span><span>[</span><span>1</span><span>]);</span>
			<span>if</span> <span>(</span><span>r_from_start</span> <span>==</span> <span>1</span> <span>&amp;&amp;</span> <span>argv</span><span>[</span><span>1</span><span>][</span><span>0</span><span>]</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>strlen</span><span>(</span><span>r_loc</span><span>)</span> <span>==</span> <span>1</span><span>)</span> <span>{</span>
				<span>in_reverse</span> <span>=</span> <span>1</span><span>;</span>
			<span>}</span> 
		<span>}</span>
	<span>}</span>
	
	<span>int</span> <span>list</span><span>[]</span> <span>=</span> <span>{</span> <span>2</span><span>,</span> <span>11</span><span>,</span> <span>32</span><span>,</span> <span>49</span><span>,</span> <span>57</span><span>,</span> <span>20</span><span>,</span> <span>110</span><span>,</span> <span>203</span> <span>};</span>
	
	<span>// GNU Nested Function definition, can reference `in_reverse` directly</span>
	<span>// is a declaration/definition, and cannot be used directly inside of `qsort`</span>
	<span>int</span> <span>compare</span><span>(</span><span>const</span> <span>void</span><span>*</span> <span>untyped_left</span><span>,</span> <span>const</span> <span>void</span><span>*</span> <span>untyped_right</span><span>)</span> <span>{</span>
		<span>const</span> <span>int</span><span>*</span> <span>left</span> <span>=</span> <span>untyped_left</span><span>;</span>
		<span>const</span> <span>int</span><span>*</span> <span>right</span> <span>=</span> <span>untyped_right</span><span>;</span>
		<span>return</span> <span>(</span><span>in_reverse</span><span>)</span> <span>?</span> <span>*</span><span>right</span> <span>-</span> <span>*</span><span>left</span> <span>:</span> <span>*</span><span>left</span> <span>-</span> <span>*</span><span>right</span><span>;</span>
	<span>}</span>
	<span>// use in the sort function without the need for a `void*` parameter</span>
	<span>qsort</span><span>(</span><span>list</span><span>,</span> <span>(</span><span>sizeof</span><span>(</span><span>list</span><span>)</span><span>/</span><span>sizeof</span><span>(</span><span>*</span><span>list</span><span>)),</span> <span>sizeof</span><span>(</span><span>*</span><span>list</span><span>),</span> <span>compare</span><span>);</span>
	
	<span>return</span> <span>list</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</code></pre></div>

<p>or, finally, C++-style Lambdas:</p>

<div><pre><code><span>#define __STDC_WANT_LIB_EXT1__ 1
</span>
<span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
#include</span> <span>&lt;string.h&gt;</span><span>
#include</span> <span>&lt;stddef.h&gt;</span><span>
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
	<span>int</span> <span>in_reverse</span> <span>=</span> <span>0</span><span>;</span>
	
	<span>if</span> <span>(</span><span>argc</span> <span>&gt;</span> <span>1</span><span>)</span> <span>{</span>
		<span>char</span><span>*</span> <span>r_loc</span> <span>=</span> <span>strchr</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>'r'</span><span>);</span>
		<span>if</span> <span>(</span><span>r_loc</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
			<span>ptrdiff_t</span> <span>r_from_start</span> <span>=</span> <span>(</span><span>r_loc</span> <span>-</span> <span>argv</span><span>[</span><span>1</span><span>]);</span>
			<span>if</span> <span>(</span><span>r_from_start</span> <span>==</span> <span>1</span> <span>&amp;&amp;</span> <span>argv</span><span>[</span><span>1</span><span>][</span><span>0</span><span>]</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>strlen</span><span>(</span><span>r_loc</span><span>)</span> <span>==</span> <span>1</span><span>)</span> <span>{</span>
				<span>in_reverse</span> <span>=</span> <span>1</span><span>;</span>
			<span>}</span> 
		<span>}</span>
	<span>}</span>
	
	<span>// lambdas are expressions, but we can assign their unique variable types with `auto`</span>
	<span>auto</span> <span>compare</span> <span>=</span> <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>void</span><span>*</span> <span>untyped_left</span><span>,</span> <span>const</span> <span>void</span><span>*</span> <span>untyped_right</span><span>)</span> <span>{</span>
		<span>const</span> <span>int</span><span>*</span> <span>left</span> <span>=</span> <span>(</span><span>const</span> <span>int</span><span>*</span><span>)</span><span>untyped_left</span><span>;</span>
		<span>const</span> <span>int</span><span>*</span> <span>right</span> <span>=</span> <span>(</span><span>const</span> <span>int</span><span>*</span><span>)</span><span>untyped_right</span><span>;</span>
		<span>return</span> <span>(</span><span>in_reverse</span><span>)</span> <span>?</span> <span>*</span><span>right</span> <span>-</span> <span>*</span><span>left</span> <span>:</span> <span>*</span><span>left</span> <span>-</span> <span>*</span><span>right</span><span>;</span>
	<span>};</span>

	<span>int</span> <span>list</span><span>[]</span> <span>=</span> <span>{</span> <span>2</span><span>,</span> <span>11</span><span>,</span> <span>32</span><span>,</span> <span>49</span><span>,</span> <span>57</span><span>,</span> <span>20</span><span>,</span> <span>110</span><span>,</span> <span>203</span> <span>};</span>	

	<span>// C++ Lambdas don't automatically make a trampoline, so we need to provide</span>
	<span>// one ourselves for the `qsort_s/r` case so we can call the lambda</span>
	<span>auto</span> <span>compare_trampoline</span> <span>=</span> <span>[](</span><span>const</span> <span>void</span><span>*</span> <span>left</span><span>,</span> <span>const</span> <span>void</span><span>*</span> <span>right</span><span>,</span> <span>void</span><span>*</span> <span>user</span><span>)</span> <span>{</span>
		<span>typeof</span><span>(</span><span>compare</span><span>)</span><span>*</span> <span>p_compare</span> <span>=</span> <span>user</span><span>;</span>
		<span>return</span> <span>(</span><span>*</span><span>p_compare</span><span>)(</span><span>left</span><span>,</span> <span>right</span><span>);</span>
	<span>};</span>
	<span>qsort_s</span><span>(</span><span>list</span><span>,</span> <span>(</span><span>sizeof</span><span>(</span><span>list</span><span>)</span><span>/</span><span>sizeof</span><span>(</span><span>*</span><span>list</span><span>)),</span> <span>sizeof</span><span>(</span><span>*</span><span>list</span><span>),</span> <span>compare_trampoline</span><span>,</span> <span>&amp;</span><span>compare</span><span>);</span>

	<span>return</span> <span>list</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</code></pre></div>

<p>To solve this gaggle of problems, pretty much every semi-modern language (that isn’t assembly-adjacent or based on some kind of state/stack programming) provide some idea of being able to associate some set of data with one or more function calls. And, particularly for Closures, this is done in a local way without passing it as an explicit argument. As it turns out, all of those design choices – including the ones in C – have pretty significant consequences on not just usability, but performance.</p>

<h2 id="not-a-big-overview">Not A Big Overview</h2>

<p>This article is <strong>NOT</strong> going to talk in-depth about the <strong>design</strong> of all of the alternatives or other languages. We’re focused on the actual cost of the extensions and what they mean. A detailed overview of the design tradeoffs, their security implications, and other problems, can be read at the <a href="https://thephd.dev/future_cxx/papers/C%20-%20Functions%20with%20Data%20-%20Closures%20in%20C.html">ISO C Proposal for Functions with Closures here</a>; it also gets into things like Security Implications, ABI, current implementation impact, and more of the various designs. The discussion in the paper is pretty long and talks about the dozens of aspects of each solution down to both the design aspect and the implementation quirks. We encourage you to dive into that proposal and read it to figure out if there’s something more specific you care about insofar as some specific design portion. But, this article is going to be concerned about one thing and one thing only:</p>

<h2 id="purrrrrrrformance-3">Purrrrrrrformance <strong>:3</strong>!</h2>

<p>In order to measure this cost, we are going to take Knuth’s Man-or-Boy test and benchmark various styles of implementation in C and C++ using various different extensions / features for the Closure problem. The Man-or-Boy test is an efficient measure of how well your programming language can handle referring to <em>specific</em> entities while engaging in a large degree of recursion and self-reference. It can stress test various portions of how your program creates and passes around data associated with a function call, and if your programming language design is so goofy that it can’t refer to a specific instance of a variable or function argument, it will end up producing the wrong answer and breaking horrifically.</p>

<h2 id="anatomy-of-a-benhcmark-raw-c">Anatomy of a Benhcmark: Raw C</h2>

<p>Here is the core of the Man-or-Boy test, as implemented in raw C. This implementation<sup id="fnref:idk-benchmarks-closures" role="doc-noteref"><a href="#fn:idk-benchmarks-closures" rel="footnote">3</a></sup> and all the others are available online for us all to scrutinize and yell at me for messing up, to make sure I’m not slandering your favorite solution for Closures in this space.</p>

<div><pre><code><span>// ...</span>

<span>static</span> <span>int</span> <span>eval</span><span>(</span><span>ARG</span><span>*</span> <span>a</span><span>)</span> <span>{</span>
	<span>return</span> <span>a</span><span>-&gt;</span><span>fn</span><span>(</span><span>a</span><span>);</span>
<span>}</span>

<span>static</span> <span>int</span> <span>B</span><span>(</span><span>ARG</span><span>*</span> <span>a</span><span>)</span> <span>{</span>
	<span>int</span> <span>k</span>    <span>=</span> <span>*</span><span>a</span><span>-&gt;</span><span>k</span> <span>-=</span> <span>1</span><span>;</span>
	<span>ARG</span> <span>args</span> <span>=</span> <span>{</span> <span>B</span><span>,</span> <span>&amp;</span><span>k</span><span>,</span> <span>a</span><span>,</span> <span>a</span><span>-&gt;</span><span>x1</span><span>,</span> <span>a</span><span>-&gt;</span><span>x2</span><span>,</span> <span>a</span><span>-&gt;</span><span>x3</span><span>,</span> <span>a</span><span>-&gt;</span><span>x4</span> <span>};</span>
	<span>return</span> <span>A</span><span>(</span><span>&amp;</span><span>args</span><span>);</span>
<span>}</span>

<span>static</span> <span>int</span> <span>A</span><span>(</span><span>ARG</span><span>*</span> <span>a</span><span>)</span> <span>{</span>
	<span>return</span> <span>*</span><span>a</span><span>-&gt;</span><span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>eval</span><span>(</span><span>a</span><span>-&gt;</span><span>x4</span><span>)</span> <span>+</span> <span>eval</span><span>(</span><span>a</span><span>-&gt;</span><span>x5</span><span>)</span> <span>:</span> <span>B</span><span>(</span><span>a</span><span>);</span>
<span>}</span>

<span>// ...</span>
</code></pre></div>

<p>You will notice that there is a big, fat, ugly <code>ARG*</code> parameter hanging around all of these functions. That is because, as stated before, plain ISO C cannot handle passing the data around unless it’s part of a function’s arguments. Because the actual core of the Man-or-Boy experiment is the ability to refer to specific values of <code>k</code> that exist during the recursive run of the program, we need to actually <strong>modify the function signature</strong> and thereby cheat some of the implicit Man-or-Boy requirements of not passing the value in directly. Here’s what <code>ARG</code> looks like:</p>

<div><pre><code><span>typedef</span> <span>struct</span> <span>arg</span> <span>{</span>
	<span>int</span> <span>(</span><span>*</span><span>fn</span><span>)(</span><span>struct</span> <span>arg</span><span>*</span><span>);</span>
	<span>int</span><span>*</span> <span>k</span><span>;</span>
	<span>struct</span> <span>arg</span> <span>*</span><span>x1</span><span>,</span> <span>*</span><span>x2</span><span>,</span> <span>*</span><span>x3</span><span>,</span> <span>*</span><span>x4</span><span>,</span> <span>*</span><span>x5</span><span>;</span>
<span>}</span> <span>ARG</span><span>;</span>

<span>static</span> <span>int</span> <span>f_1</span><span>(</span><span>ARG</span><span>*</span> <span>_</span><span>)</span> <span>{</span>
	<span>return</span> <span>-</span><span>1</span><span>;</span>
<span>}</span>

<span>static</span> <span>int</span> <span>f0</span><span>(</span><span>ARG</span><span>*</span> <span>_</span><span>)</span> <span>{</span>
	<span>return</span> <span>0</span><span>;</span>
<span>}</span>

<span>static</span> <span>int</span> <span>f1</span><span>(</span><span>ARG</span><span>*</span> <span>_</span><span>)</span> <span>{</span>
	<span>return</span> <span>1</span><span>;</span>
<span>}</span>

<span>static</span> <span>int</span> <span>eval</span><span>(</span><span>ARG</span><span>*</span> <span>a</span><span>)</span> <span>{</span>
	<span>// ...</span>
<span>}</span>
<span>// ...</span>
</code></pre></div>

<p>And this is how it gets used in the main body of the function in order to compute the right answer and benchmark it:</p>

<div><pre><code><span>static</span> <span>void</span> <span>normal_functions_rosetta</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
	<span>const</span> <span>int</span> <span>initial_k</span>  <span>=</span> <span>k_value</span><span>();</span>
	<span>const</span> <span>int</span> <span>expected_k</span> <span>=</span> <span>expected_k_value</span><span>();</span>
	<span>int64_t</span> <span>result</span>       <span>=</span> <span>0</span><span>;</span>

	<span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
		<span>int</span> <span>k</span>     <span>=</span> <span>initial_k</span><span>;</span>
		<span>ARG</span> <span>arg1</span>  <span>=</span> <span>{</span> <span>f1</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span> <span>};</span>
		<span>ARG</span> <span>arg2</span>  <span>=</span> <span>{</span> <span>f_1</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span> <span>};</span>
		<span>ARG</span> <span>arg3</span>  <span>=</span> <span>{</span> <span>f_1</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span> <span>};</span>
		<span>ARG</span> <span>arg4</span>  <span>=</span> <span>{</span> <span>f1</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span> <span>};</span>
		<span>ARG</span> <span>arg5</span>  <span>=</span> <span>{</span> <span>f0</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span> <span>};</span>
		<span>ARG</span> <span>args</span>  <span>=</span> <span>{</span> <span>B</span><span>,</span> <span>&amp;</span><span>k</span><span>,</span> <span>&amp;</span><span>arg1</span><span>,</span> <span>&amp;</span><span>arg2</span><span>,</span> <span>&amp;</span><span>arg3</span><span>,</span> <span>&amp;</span><span>arg4</span><span>,</span> <span>&amp;</span><span>arg5</span> <span>};</span>
		<span>int</span> <span>value</span> <span>=</span> <span>A</span><span>(</span><span>&amp;</span><span>args</span><span>);</span>
		<span>result</span> <span>+=</span> <span>value</span> <span>==</span> <span>expected_k</span> <span>?</span> <span>1</span> <span>:</span> <span>0</span><span>;</span>
	<span>}</span>

	<span>if</span> <span>(</span><span>result</span> <span>!=</span> <span>state</span><span>.</span><span>iterations</span><span>())</span> <span>{</span>
		<span>state</span><span>.</span><span>SkipWithError</span><span>(</span><span>"failed: did not produce the right answer!"</span><span>);</span>
	<span>}</span>
<span>}</span>

<span>BENCHMARK</span><span>(</span><span>normal_functions_rosetta</span><span>);</span>
</code></pre></div>

<p>Everything within the <code>for (auto _ : state) { ... }</code> is benchmarked. For those paying attention to the code and find it looking familiar, it’s because that code is the basic structure all Google Benchmark<sup id="fnref:google-benchmark" role="doc-noteref"><a href="#fn:google-benchmark" rel="footnote">4</a></sup> code finds itself looking like. I’ve wanted to swap to Catch2<sup id="fnref:catch2-benchmark" role="doc-noteref"><a href="#fn:catch2-benchmark" rel="footnote">5</a></sup> for a long time now to change to their benchmarking infrastructure, but I’ve been stuck on Google Benchmark because I’ve made a lot of graph-making tools based on its JSON output and I have not vetted Catch2’s JSON output yet to see if it has all of the necessary bits ‘n’ bobbles I use to de-dedup runs and compute statistics.</p>

<p>Everything outside is setup (the part above the <code>for</code> loop) or teardown/test correction (the part below the <code>for</code> loop). The initialization of the <code>ARG args</code>s cannot be moved outside of the measuring loop because each invocation of <code>A</code> – the core of the Man-or-Boy experiment – modifies the <code>k</code> of the ARG parameter, so all of them have to be inside. Conceivably, <code>arg1 .. 5</code> could be moved out of the loop, but I am very tired of looking at the eight or nine variations of this code so someone else can move it and tell me if Clang or GCC has lots of compiler optimization sauce and doesn’t understand that those 5 <code>argI</code>s can be hoisted out of the loop.</p>

<p>The value <code>k</code> is <code>10</code>, and <code>expected_k</code> is <code>-67</code>. The expected, returned <code>k</code> value is dependent on the input <code>k</code> value, which controls how deep the Man-or-Boy test would recurse on itself to produce its answer. Therefore, to prevent GCC and Clang and other MEGA POWERFUL PILLAR COMPILERS from optimizing the entire thing out and just replacing the benchmark loop with <code>ret -67</code>, both <code>k_value()</code> and <code>expected_k_value()</code> come from a Dynamic Link Library (<code>.dylib</code> on MacOS, <code>.so</code> on *nix platforms, <code>.dll</code> on Windows platforms) to make sure that NO amount of optimization (Link Time Optimization/Link Time Code Generation, Inlining Optimization, Cross-Translation Unit Optimization, and Automatic Constant Expression Optimization) from C or C++ compilers could fully preempt all forms of computation.</p>

<p>This allows us to know, for sure, that we’re actually measuring something and not just testing how fast a compiler can load a number into a register and test it against <code>state.iterations()</code>. And, since we know for sure, we can now talk the general methodology.</p>

<h2 id="methodology">Methodology</h2>

<p>The tests were ran on a dying 13-inch 2020 MacBook Pro M1 that has suffered several toddler spills and two severe falls. It has 16 GB of RAM and is son MacOS 15.7.2 Sequoia at the time the test was taken, using the stock MacOS AppleClang Compiler and the stock <code>brew install gcc</code> compiler in order to produce the numbers seen on December 6th, 2025.</p>

<p>There 2 measures being conducted: Real Time and CPU Time. The time is gathered by running a single iteration of the code within the <code>for</code> loop anywhere from a couple thousand to hundreds of thousands of times to produce confidence in that run of the benchmark. This is then averaged to produce the first point. The process is repeated 50 times, repeating that many iterations to build further confidence in the measurement. All 50 means are used as the points for the values, and the average of all of those 50 means is then used as the height of a bar in a bar graph.</p>

<p>The bars are presented side-by-side as a horizontal bar chart with 11 categories of C or C++ code being measured. The 11 categories are:</p>

<ol>
  <li><code>no-op</code>: Literally doing nothing. It’s just there to test environmental noise and make sure none of our benchmarks are so off-base that we’re measuring noise rather than computation. Helps keep us grounded in reality.</li>
  <li><code>Lambdas (No Function Helpers)</code>: a solution using C++-style lambdas. Rather than using helper functions like <code>f0</code>, <code>f1</code>, and <code>f_1</code>, we compute a raw lambda that stores the value meant to be returned for the Man-or-Boy test (<code>return i;</code>) in the lambda itself and then pass that uniquely-typed lambda to the core of the test. The entire test is templated and uses a fake <code>recursion</code> template parameter to halt the recursion after a certain depth.</li>
  <li><code>Lambdas</code>: The same as above but actually using <code>int f0(void)</code>, etc. helper functions at the start rather than lambdas. Reduces inliner pressure by using “normal” types which do not add to the generated number of lambda-typed, recursive, templated function calls.</li>
  <li><code>Lambdas (std::function_ref)</code>: The same as above, but rather than using a function template to handle each uniquely-typed lambda like a precious baby bird, it instead erases the lambda behind a <code>std::function_ref&lt;int(void)&gt;</code>. This allows the recursive function to retain exactly one signature.</li>
  <li><code>Lambdas (std::function)</code>: The same as above, but replaces <code>std::function_ref&lt;int(void)&gt;</code> with <code>std::function&lt;int(void)&gt;</code>. This is its allocating, C++03-style type.</li>
  <li><code>Lambdas (Rosetta Code)</code>: The code straight out of the C++11 Rosetta Code Lambda section on the Man-or-Boy Rosetta Code implementation.</li>
  <li><code>Apple Blocks</code>: Uses Apple Blocks to implement the test, along with the <code>__block</code> specifier to refer directly to certain variables on the stack.</li>
  <li><code>GNU Nested Functions (Rosetta Code)</code>: The code straight out of the C Rosetta Code section on the Man-or-Boy Rosetta Code implementation.</li>
  <li><code>GNU Nested Functions</code>: GNU Nested Functions similar to the Rosetta Code implementation, but with some slight modifications in a hope to potentially alleviate some stack pressure if possible by using regular helper functions like <code>f0</code>, <code>f1</code>, and <code>f_1</code>.</li>
  <li><code>Custom C++ Class</code>: A custom-written C++ class using a discriminated union to decide whether its doing a straight function call or attemping to engage in the Man-or-Boy recursion.</li>
  <li><code>C++03 shared_ptr (Rosetta Code)</code>: A C++ class using <code>std::enable_shared_from_this</code> and <code>std::shared_ptr</code> with a virtual function call to invoke the “right” function call during recursion.</li>
</ol>

<p>The two compilers tested are Apple Clang 17 and GCC 15. There are two graph images because one is for Apple Clang and the other is for GCC. This is particularly important because neither compiler implements the other’s closure extension (Clang does Apple Blocks but not Nested Functions, while GCC does Nested Functions in exclusively its C frontend but does not implement Apple Blocks<sup id="fnref:gcc-apple-blocks" role="doc-noteref"><a href="#fn:gcc-apple-blocks" rel="footnote">6</a></sup>).</p>

<h2 id="the-results">The Results</h2>

<p>Ta-da!</p>

<p><img src="https://thephd.dev/assets/img/2025/12/appleclang17_closure_linear.png" alt=""></p>

<p><sub><sub><sub><a href="https://thephd.dev/assets/img/2025/12/appleclang17_closure_linear.png.txt">For the vision-impaired, a text description is available.</a></sub></sub></sub></p>

<p><img src="https://thephd.dev/assets/img/2025/12/gcc15_closure_linear.png" alt=""></p>

<p><sub><sub><sub><a href="https://thephd.dev/assets/img/2025/12/gcc15_closure_linear.png.txt">For the vision-impaired, a text description is available.</a></sub></sub></sub></p>

<p>… Oh. That looks <strong>awful</strong>.</p>

<p>It turns out that some solutions are so dogwater that it completely screws up our viewing graphs. But, it does let us know that Lambdas used the Rosetta Code style are so unbelievably awful that it is several orders of magnitude more expensive than any other solution presented! One has to wonder what the hell is going on in the code snippet there, but first we need to make the graphs more legible. To do this we’re going to be using the (slightly deceptive) <strong>LOGARITHMIC SCALING</strong>. This is a bit deadly to do because it tends to mislead people about how much of a change there is, so please pay attention to the <strong>potential order of magnitude gains and losses</strong> when going from one bar graph to another.</p>

<p><img src="https://thephd.dev/assets/img/2025/12/appleclang17_closure_logarithmic.png" alt="">
<sub><sub><sub><a href="https://thephd.dev/assets/img/2025/12/appleclang17_closure_logarithmic.png.txt">For the vision-impaired, a text description is available.</a></sub></sub></sub></p>

<p><img src="https://thephd.dev/assets/img/2025/12/gcc15_closure_logarithmic.png" alt=""></p>

<p><sub><sub><sub><a href="https://thephd.dev/assets/img/2025/12/gcc15_closure_logarithmic.png.txt">For the vision-impaired, a text description is available.</a></sub></sub></sub></p>

<p>There we go. Now we can talk about the various solutions and – in particular – why “lambdas” have 4 different entries with such wildly differing performance profiles. First up, let’s talk about the clear performance winners.</p>

<h2 id="lambdas-on-top">Lambdas: On Top!</h2>

<p>Not surprising to anyone who has been checked in to C++, lambdas that are used directly and not type-erased are on top. This means there’s a one-to-one mapping between a function call and a given bit of execution. We are cheating by using a constant parameter to stop the uniquely-typed lambdas being passed into the functions from recursing infinitely, which makes the Man-or-Boy function look like this:</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>int</span> <span>recursion</span> <span>=</span> <span>0</span><span>&gt;</span>
<span>static</span> <span>int</span> <span>a</span><span>(</span><span>int</span> <span>k</span><span>,</span> <span>const</span> <span>auto</span><span>&amp;</span> <span>x1</span><span>,</span> <span>const</span> <span>auto</span><span>&amp;</span> <span>x2</span><span>,</span> <span>const</span> <span>auto</span><span>&amp;</span> <span>x3</span><span>,</span> <span>const</span> <span>auto</span><span>&amp;</span> <span>x4</span><span>,</span> <span>const</span> <span>auto</span><span>&amp;</span> <span>x5</span><span>)</span> <span>{</span>
	<span>if</span> <span>constexpr</span> <span>(</span><span>recursion</span> <span>==</span> <span>11</span><span>)</span> <span>{</span>
		<span>::</span><span>std</span><span>::</span><span>cerr</span> <span>&lt;&lt;</span> <span>"This should never happen and this code should never have been generated."</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
		<span>::</span><span>std</span><span>::</span><span>terminate</span><span>();</span>
		<span>return</span> <span>0</span><span>;</span>
	<span>}</span>
	<span>else</span> <span>{</span>
		<span>auto</span> <span>B</span> <span>=</span> <span>[</span><span>&amp;</span><span>](</span><span>this</span> <span>const</span> <span>auto</span><span>&amp;</span> <span>self</span><span>)</span> <span>{</span> <span>return</span> <span>a</span><span>&lt;</span><span>recursion</span> <span>+</span> <span>1</span><span>&gt;</span><span>(</span><span>--</span><span>k</span><span>,</span> <span>self</span><span>,</span> <span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>,</span> <span>x4</span><span>);</span> <span>};</span>
		<span>return</span> <span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>x4</span><span>()</span> <span>+</span> <span>x5</span><span>()</span> <span>:</span> <span>B</span><span>();</span>
	<span>}</span>
<span>}</span>
</code></pre></div>

<p>Every <code>B</code> is its own unique type and we are not erasing that unique type when using the expression as an initializer to <code>B</code>. This means that when we call <code>a</code> again with <code>B</code> (the <code>self</code> in this lambda here using Deduced This, a C++23 feature that cannot be part of the C version of lambdas) which means we need to use <code>auto</code> parameters (a shortcut way of writing template parameters) to take it. But, since every parameter is unique, and every <code>B</code> is unique, calling this recursively means that, eventually, C++ compilers will actually just completely crash out/toss out-of-memory errors/say we’ve compile-time recursed too hard, or similar. That’s why the compile-time <code>if constexpr</code> on the extra, templated <code>recursion</code> parameter needs to have some arbitrary limit. Because we know <code>k</code> starts at 10 for this test, we just have some bogus limit of “11”.</p>

<p>This results in a very spammy recursive chain of function calls, where the actual generated names of these template functions is <strong>far</strong> more complex than <code>a</code> and can run the compiler into the ground / cause quite a bit of instantiations if you let <code>recursion</code> get to a high enough value. But, once you add the limit, the compiler gets perfect information about this recursive call all the way to every leaf, and thus is able to not only optimize the hell out of it, but refuse to generate the other frivolous code it knows won’t be useful.</p>

<h3 id="lambdas-are-also-fast-even-when-type-erased">Lambdas are also Fast, even when Type-Erased</h3>

<p>You can observe a slight bump up in performance penalty when a Lambda is erased by a <code>std::function_ref</code>. This is a low-level, non-allocating, non-owning, slim “view” type that is analogous to what a language-based wide function pointer type would be in C. From this, it allows us to <em>guess</em> how good Lambdas in C would be even if you had to hide them behind a non-unique type.</p>

<p>The performance metrics are about equivalent to if you hand-wrote a C++ class with a custom <code>operator()</code> that uses a discriminated union, no matter which compiler gets used to do it. It’s obviously not as fast as having access to a direct function call and being able to slurp-inline optimize, but the performance difference is acceptable when you do not want to engage in a large degree of what is called “monomorphisation” of a genric routine or type. And, indeed, outside of macros, C has no way of doing this innately that isn’t runtime-based.</p>

<p>A very strong contender for a good solution!</p>

<h3 id="lambdas-on-bottom-too">Lambdas: On…. Bottom, too?</h3>

<p>One must wonder, then, why the <code>std::function</code> Lambdas and the Rosetta Code Lambdas are either bottom-middle-of-the-road or absolutely-teary-eyed-awful.</p>

<p>Starting off, the <code>std::function</code> Lambdas are bad because of exactly that: <code>std::function</code>. <code>std::function</code> is not a “cheap” closure; it is a potentially-allocating, meaty, owning function abstraction. This means that it’s safe to make one and pass it around and store it and call it later; the cost of this is, obviously, that you’re allocating (when the type is big enough) for that internal storage. Part of this is alleviated by using <code>const std::function&lt;int(void)&gt;&amp;</code> parameters, taking things by reference and only generating a new object when necessary. This prevents copying on every function call. Both the Rosetta Lambdas and regular <code>std::function</code> Lambdas code does the by-reference parameters bit, though, so where does the difference come in? It actually has to do with the Captures. Here’s how <code>std::function</code> Lambdas defines the recursive, self-referential lambda and uses it:</p>

<div><pre><code><span>using</span> <span>f_t</span> <span>=</span> <span>std</span><span>::</span><span>function</span><span>&lt;</span><span>int</span><span>(</span><span>void</span><span>)</span><span>&gt;</span><span>;</span>

<span>inline</span> <span>static</span> <span>int</span> <span>A</span><span>(</span><span>int</span> <span>k</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x1</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x2</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x3</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x4</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x5</span><span>)</span> <span>{</span>
	<span>f_t</span> <span>B</span> <span>=</span> <span>[</span><span>&amp;</span><span>]</span> <span>{</span> <span>return</span> <span>A</span><span>(</span><span>--</span><span>k</span><span>,</span> <span>B</span><span>,</span> <span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>,</span> <span>x4</span><span>);</span> <span>};</span>
	<span>return</span> <span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>x4</span><span>()</span> <span>+</span> <span>x5</span><span>()</span> <span>:</span> <span>B</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>And, here is how the Rosetta Code Lambdas defines the recursive, self-referential lambda and uses it:</p>

<div><pre><code><span>using</span> <span>f_t</span> <span>=</span> <span>std</span><span>::</span><span>function</span><span>&lt;</span><span>int</span><span>(</span><span>void</span><span>)</span><span>&gt;</span><span>;</span>

<span>inline</span> <span>static</span> <span>int</span> <span>A</span><span>(</span><span>int</span> <span>k</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x1</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x2</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x3</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x4</span><span>,</span> <span>const</span> <span>f_t</span><span>&amp;</span> <span>x5</span><span>)</span> <span>{</span>
	<span>f_t</span> <span>B</span> <span>=</span> <span>[</span><span>=</span><span>,</span> <span>&amp;</span><span>k</span><span>,</span> <span>&amp;</span><span>B</span><span>]</span> <span>{</span> <span>return</span> <span>A</span><span>(</span><span>--</span><span>k</span><span>,</span> <span>B</span><span>,</span> <span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>,</span> <span>x4</span><span>);</span> <span>};</span>
	<span>return</span> <span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>x4</span><span>()</span> <span>+</span> <span>x5</span><span>()</span> <span>:</span> <span>B</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>The big problem here is in the use of the <code>=</code>. What <code>=</code> by itself in the front of a lambda capture clause means is “copy all the visible variables in and hold onto that copy” (unless the capture for that following variable is “overridden” by a <code>&amp;var</code>, address capture). Meanwhile, the <code>&amp;</code> is the opposite: it means “refer to all the visible variables directly by their address and do not copy them in”. So, while the <code>std::function</code> Lambda is (smartly) referring to stuff directly without copying because we know for the Man-or-Boy test that referring to things directly is not an unsafe operation, the general <code>=</code> causes that for the several dozen recursive iterations through the function, it is copying all five allocating <code>std::function</code> arguments. So the first call creates a <code>B</code> that copies everything in, and then passes that in, and then the next call copies the previous <code>B</code> and the 4 normal functions, and then passes that in to the next <code>B</code>, and then it copies <strong>both</strong> previous <code>B</code>’s, and this stacks for the depth of the callgraph (some 10 times since <code>k = 10</code> to start).</p>

<p>You can imagine how much that completely screws with the performance, and it explains why the Rosetta Code Lambdas code behaves so poorly in terms of performance. But, this also raises a question: if referring to everything by-reference saves so much speed, then why does GNU Nested Functions – in all its variants – perform so poorly? After all, Nested Functions capture everything by reference / by address, exactly like a lambda does with <code>[&amp;]</code>.</p>

<p>Similarly, if allocating over and over again was so expensive, how come Apple Blocks and C++03 <code>shared_ptr</code> Rosetta Code-style versions of the Man-or-Boy test don’t perform nearly as badly as the Rosetta Code Lambdas? Are we not copying the value of the arguments into a newly created Apple Block and, thusly, tanking the performance metrics? Well, as it turns out, there’s many reasons for these things, so let’s start with GNU Nested Functions.</p>

<h2 id="nested-functions-and-the-stack">Nested Functions and The Stack</h2>

<p>I’ve written about it <a href="https://thephd.dev/lambdas-nested-functions-block-expressions-oh-my">dozens of times</a> now, but the prevailing and most common implementation of Nested Functions is with an executable stack. The are <a href="https://thephd.dev/_vendor/future_cxx/papers/C%20-%20Functions%20with%20Data%20-%20Closures%20in%20C.html#intro-nested.functions-security">a lot of security and other implications for this</a>, but all you need to understand is that the <em>reason</em> GCC did this is because it was an at-the-time slick encoding of both the <em>location</em> of the variables and the <em>routine</em> itself. Allocating a chunk of data off of the current programming stack means that the “environment context”/”this closure” pointer has the same anchoring address as the routine itself. This means you can encode both the location of the data to know what to access <em>and</em> the address of a function’s entry point into a single thing that works with your typical setup-and-call convention that comes with invoking a standard ISO C function pointer.</p>

<p>But think about that, briefly, in terms of optimization.</p>

<p>You are using the function’s stack frame at that precise point in the program as the “base address” for this executable code. That base address also means that all the variables associated with it need to be <strong>reachable</strong> from that base address: i.e., that things are not stuffed in registers, but that you are referring to the same variables as modified by the enclosing function around your nested function. Principally, this means that your function needs to have all of the following now so that GNU Nested Functions <em>actually</em> work.</p>

<ul>
  <li>A stack that is executable so that the base address used for the trampoline can be run succinctly.</li>
  <li>A real function frame that exists somewhere in memory to serve as the base address for the trampoline.</li>
  <li>Real objects in memory backing the names of the captured variables accesses.</li>
</ul>

<p>This all seems like regular consequences, until you tack on the second order affects from the point of optimization.</p>

<ul>
  <li>A stack that now has both data and instructions all blended into itself.</li>
  <li>A real function frame, which means no ommission of a frame pointer and no collapsing / inlining of that function frame.</li>
  <li>Real objects that all have their address taken that are tied to the function frame, which must be memory-accessible and which the compiler now has a hard time telling if they can simply be exchanged through registers or if the need to <strong>actually</strong> sit somewhere in memory.</li>
</ul>

<p>In other words: GNU Nested Functions have created the perfect little storm for what might be the best optimizer-murderer. The reason it performs so drastically poorly (worse than even allocating lambdas inside of a <code>std::function</code> or C++03-style virtual function calls inside of a bulky, nasty C++ <code>std::shared_ptr</code>) by a whole order of magnitude or more is that everything about Nested Functions and their current implementation is basically Optimizer Death. If the compiler can’t see through everything – and the Man-or-Boy test with a non-constant value of <code>k</code> and <code>expected_k</code> – GNU Nested Functions deteriorate rapidly. It takes every core optimization technique that we’ve researched and maximized on in the last 30 years and puts a shotgun to the side of its head once it can’t pre-compute <code>k</code> and <code>expected_k</code>.</p>

<p>The good news is that GCC has completed a new backing implementation for GNU Nested Functions, which uses a heap-based trampoline. Such a trampoline does not interfere with the stack, would allow for omission of frame pointers while referring directly to the data itself (which may prevent the wrecking of specific kinds of inlining optimizations), and does not need an executable stack (just a piece of memory from ✨somewhere✨ it can mark executable). This may have performance closer to Apple Blocks, but we don’t have a build of the latest GCC to test it with. But, when we do, we can simply add the compilation flag <code>-ftrampoline-impl=heap</code> to the two source files in CMake and then let the benchmarks run again to see how it stacks up!</p>

<p>Finally, there is a <em>minor</em> performance degredation because our benchmarking software is in C++ and this extension exists exclusively in the C frontend of GCC. That means I have to use an <code>extern</code> function call within the benchmark loop to get to the actual code. Within the function call, however, all of this stuff should be optimized down, so the cost of a <em>single</em> function call’s stack frame shouldn’t be so awful, but I expect to try to dig into this better to help make sure the <code>extern</code> of a C function call isn’t making things dramatically worse than they are. Given it’s a different translation unit and it’s <strong>not</strong> being compiled as a separate static or dynamic library, it should still link together and optimize cleanly, but given how bad it’s performing? Every possible issue is on the table.</p>

<h2 id="what-about-apple-blocks">What about Apple Blocks?</h2>

<p>Apple Blocks are not the fastest, but they the best of the C extensions while being the worst of the “fast” solutions. They are not faster than just hacking the <code>ARG*</code> into the function signature and using regular normal C function calls, unfortunately, and that’s likely due to their shared, heap-ish nature. The saddest part about Apple Blocks is that it works using a Blocks Runtime that is already as optimized as it can possibly be: Clang and Apple both document that whie the Blocks Runtime does manage an Automatic Reference Counted (ARC) Heap of Block pointers, when a Block is first created it will literally have its memory stored on the stack rather than in the heap. In order to move it to the heap, one must call <code>Block_copy</code> to trigger the “normal” heap-based shenanigans. We never call <code>Block_copy</code>, so this is with as-fast-as-possible variable access and management with few allocations.</p>

<p>It’s very slightly disappointing that: normal C functions with an <code>ARG*</code> blob; a custom C++ class using a discriminated union and <code>operator()</code>; any mildly conscientious use of lambdas; and, any other such shenanigans perform better than the very best Apple Blocks has to offer. One has to imagine that all of the ARC management functions made to copy the <code>int^(void)</code> “hat-style” function pointers, even if they end up not doing much for the data stored on the stack, impacted the results here. But, this is also somewhat good news: because Apple Block hat pointers are cheaply-copiable entities (they are just pointers to a Block object), it means that even if we copy all of the arguments into the closure every function call, that copying is about as cheap as it can get. Obivously, as regular “Lambdas” and “Lambas (No Function Helpers)” demonstrate, being able to just slurp everything up by address/by reference – including visible function arguments – with <code>[&amp;]</code> saves us a teensy, tiny bit of time<sup id="fnref:apple-blocks-parameters" role="doc-noteref"><a href="#fn:apple-blocks-parameters" rel="footnote">7</a></sup>.</p>

<p>The cheapness of <code>int^(void)</code> hat-pointer function types is likely the biggest saving grace for Apple Blocks in this benchmark. In the one place we need to be careful, we rename the input argument <code>k</code> to <code>arg_k</code> and then make a <code>__block</code> variable to actually refer to a shared <code>int k</code> (and get the right answer):</p>

<div><pre><code><span>static</span> <span>int</span> <span>a</span><span>(</span><span>int</span> <span>arg_k</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x1</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x2</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x3</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x4</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x5</span><span>)</span> <span>{</span>
	<span>__block</span> <span>int</span> <span>k</span>    <span>=</span> <span>arg_k</span><span>;</span>
	<span>__block</span> <span>fn_t</span> <span>^</span> <span>b</span> <span>=</span> <span>^</span><span>(</span><span>void</span><span>)</span> <span>{</span> <span>return</span> <span>a</span><span>(</span><span>--</span><span>k</span><span>,</span> <span>b</span><span>,</span> <span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>,</span> <span>x4</span><span>);</span> <span>};</span>
	<span>return</span> <span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>x4</span><span>()</span> <span>+</span> <span>x5</span><span>()</span> <span>:</span> <span>b</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>All of the <code>x1</code>, <code>x2</code>, and <code>x3</code> – like the bad Lambda case – are copied over and over and over again. One could change the name of all the arugments <code>arg_xI</code> and then have an <code>xI</code> variable inside that is marked <code>__block</code>, but that’s more effort and very unlikely to have any serious impact on the code while possibly degrading performance for the setup of multiple shared variables that all have to also be ARC-reference-counted and be stored inside each and every new <code>b</code> block that is created.</p>

<h2 id="a-brief-aside-self-referencing-functionsclosures">A Brief Aside: Self-Referencing Functions/Closures</h2>

<p>It’s also important to note that just writing this:</p>

<div><pre><code><span>static</span> <span>int</span> <span>a</span><span>(</span><span>int</span> <span>arg_k</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x1</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x2</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x3</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x4</span><span>,</span> <span>fn_t</span> <span>^</span> <span>x5</span><span>)</span> <span>{</span>
	<span>__block</span> <span>int</span> <span>k</span>    <span>=</span> <span>arg_k</span><span>;</span>
	<span>fn_t</span> <span>^</span> <span>b</span> <span>=</span> <span>^</span><span>(</span><span>void</span><span>)</span> <span>{</span> <span>return</span> <span>a</span><span>(</span><span>--</span><span>k</span><span>,</span> <span>b</span><span>,</span> <span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>,</span> <span>x4</span><span>);</span> <span>};</span>
	<span>return</span> <span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>x4</span><span>()</span> <span>+</span> <span>x5</span><span>()</span> <span>:</span> <span>b</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>(no <code>__block</code> on the <code>b</code> variable) is actually a huge bug. Apple Blocks, like older C++ Lambdas, cannot technically refer to “itself” inside. You have to refer to the “self” by capturing the variable it set to. For those who use C++ and are familiar with the lambdas over there, it’s like making sure you capture the variable you initialize with the lambda by reference while <em>also</em> making sure it has a concrete type. It can only be escaped by using <code>auto</code> and Deducing This, or some other combination of referential-use. That is:</p>

<ul>
  <li><code>auto x = [&amp;x](int v) { if (v != limit) x(v + 1); return v + 8; }</code> does not compile, as the type <code>auto</code> isn’t figured out yet;</li>
  <li><code>std::function_ref&lt;int(int)&gt; x = [&amp;x](int v) { if (v != limit) x(v + 1); return v + 8; }</code> compiles but due to C++ shenanigans produces a dangling reference to a temporary lambda that dies after the full expression (the initialization);</li>
  <li><code>std::function&lt;int(int)&gt; x = [&amp;x](int v) { if (v != limit) x(v + 1); return v + 8; }</code> compiles and works with no segfaults because <code>std::function</code> allocates, and the reference to itself <code>&amp;x</code> is just fine.</li>
  <li>and, finally, <code>auto x = [](this const auto&amp; self, int v) { if (v != limit) self(v + 1); return v + 8; }</code> which compiles and works with no segfaults because the invisible <code>self</code> parameter is just a reference to the current object.</li>
</ul>

<p>The problem with the most recent Apple Blocks snippet just above is that it’s the equivalent of doing</p>

<ul>
  <li><code>std::function&lt;int(int)&gt; x = [x](int v) { if (v != limit) x(v + 1); return v + 8; }</code></li>
</ul>

<p>Notice that there’s no <code>&amp;x</code> in the lambda initializer’s capture list. It’s copying an (uninitialized) variable by-value into the lambda. This is what Apple Blocks set into a variable that does not have a <code>__block</code> specifier, like in our bad code case with <code>b</code>.</p>

<p>All variations of this on all implementations which allow for self-referencing allow this and compile some form of this. You would imagine some implementations would warn about this, but this is leftover nonsense from allowing a variable to refer to itself in its initialization. The obvious reason this happens in C and C++ is because you can create self-referential structures, but unfortunately neither languages provided a safe way to do this generally. C++23’s Deducing This does not work inside of regular functions and non-objects, so good luck applying to other places and other extensions. The only extension which does not suffer this problem is GNU Nested Functions, because it creates a function declaration / definition rather than a variable with an initializer. Thus, this code from the benchmarks works:</p>

<div><pre><code><span>inline</span> <span>static</span> <span>int</span> <span>gnu_nested_functions_a</span><span>(</span><span>int</span> <span>k</span><span>,</span> <span>int</span> <span>xl</span><span>(</span><span>void</span><span>),</span> <span>int</span> <span>x2</span><span>(</span><span>void</span><span>),</span> <span>int</span> <span>x3</span><span>(</span><span>void</span><span>),</span> <span>int</span> <span>x4</span><span>(</span><span>void</span><span>),</span> <span>int</span> <span>x5</span><span>(</span><span>void</span><span>))</span> <span>{</span>
	<span>int</span> <span>b</span><span>(</span><span>void</span><span>)</span> <span>{</span>
		<span>return</span> <span>gnu_nested_functions_a</span><span>(</span><span>--</span><span>k</span><span>,</span> <span>b</span><span>,</span> <span>xl</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>,</span> <span>x4</span><span>);</span>
	<span>}</span>
	<span>return</span> <span>k</span> <span>&lt;=</span> <span>0</span> <span>?</span> <span>x4</span><span>()</span> <span>+</span> <span>x5</span><span>()</span> <span>:</span> <span>b</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>And it has the semantics one would expect, unlike how Blocks, Lambdas, or others with default by-value copying works.</p>

<p>In the general case, this is what the paper <code>__self_func</code> was going to solve<sup id="fnref:__self_func" role="doc-noteref"><a href="#fn:__self_func" rel="footnote">8</a></sup>, but… that’s going to need some time for me to convince WG14 that maybe it IS actually a good idea. We can probably just keep writing the buggy code a few dozen more times for the recursion case and keep leaving it error prone, but I’ll try my best to convince them one more time that the above situation is very not-okay.</p>

<h2 id="thinking-it-over">Thinking It Over</h2>

<p>While the Man-or-Boy test isn’t exactly the end-all, be-all performance test, due to flexing both (self)-referential data and utilization of local copies with recursion, it is surprisingly suitable for figuring out if a closure design is decent enough in a mid to high-level programming language. It also gives me some confidence that, at the very least, the baseline for performance of statically-known, compile-time understood, non-type erased, callable Closure object will have the best implementation quality and performance tradeoffs for a language like ISO C no matter the compiler implementation.</p>

<p>In the future, at some point, I’ll have to write about <strong>why</strong> that is. It’s a bit upside-down from the perspective of readers of this blog to <strong>first</strong> address performance and then later write about the design, but it’s nice to make sure we’re not designing ourselves into a bad performance corner at the offset of this whole adventure.</p>

<h2 id="learned-insights">Learned Insights</h2>

<p>Surprising nobody, the more information the compiler is allowed to accrue (the Lambda design), the better its ability to make the code fast. What might be slightly more surprising is that a <strong>slim</strong>, <strong>compact</strong> layer of type erasure – not a bulky set of Virtual Function Calls (C++03 <code>shared_ptr</code> Rosetta Code design) – does not actually cost much at all (Lambdas with <code>std::function_ref</code>). This points out something else that’s part of the ISO C proposal for Closures (but not formally in its wording): Wide Function Pointers.</p>

<p>The ability to make a thin <code>{ some_function_type* func; void* context; }</code> type backed by the compiler in C would be extremely powerful. Martin Uecker has a proposal that has received interest and passing approval in the Committee, but it would be nice to <a href="https://thephd.dev/_vendor/future_cxx/papers/C%20-%20Functions%20with%20Data%20-%20Closures%20in%20C.html#appendix-wide.function.pointer">move it along in a nice direction</a>. My suggestion is having <code>%</code> as a modifier, so it can be used easily since wide function pointers are an extremely prevalent concept. Being able to write something like the following would be very easy and helpful.</p>

<div><pre><code><span>typedef</span> <span>int</span><span>(</span><span>compute_fn_t</span><span>)(</span><span>int</span><span>);</span>

<span>int</span> <span>do_computation</span><span>(</span><span>int</span> <span>num</span><span>,</span> <span>compute_fn_t</span><span>%</span> <span>success_modification</span><span>);</span>
</code></pre></div>

<p>A wide function pointer type like this would also be traditionally convertible from a number of already-existing extensions, too, where GNU Nested Functions, Apple Blocks, C++-style Lambdas, and more could create the appropriate wide function pointer type to be cheaply used. Additionally, it also works for FFI: things like Go closures already use GCC’s <code>__builtin_call_with_static_chain</code> to transport through their Go functions in C. Many other functions from other languages could be cheaply and efficiently bridged with this, without having to come up with hairbrained schemes about where to put a <code>void* userdata</code> or some kind of implicit context pointer / implicit environment pointer.</p>

<h2 id="existing-extensions">Existing Extensions?</h2>

<p>Unfortunately – except for the borland closure annotation – there’s too many things that are performance-stinky about both GNU Nested Functions and Apple Blocks. It’s no wonder GCC is trying to add <code>-ftrampoline-impl=heap</code> to the story of GNU Nested Functions; they might be able to tighten up that performance and make it more competitive with Apple Blocks. But, unfortunately, since it is heap-based, there’s a real chance that its <strong>maximum</strong> performance ceiling is only as good as Apple Blocks, and <strong>not</strong> as good as a C++-style Lambda.</p>

<p>Both GNU Nested Functions and Apple Blocks – as they are implemented – do not really work well in ISO C. GNU Nested Functions because their base design and most prevalent implementation are performance-awful, but also Apple Blocks because of the copying and indirection runtime of Blocks that manage ARC pointers providing a hard upper limit on how good the performance can actually be in complex cases.</p>

<p>Regular C code, again, performs middle-of-the-road here. It’s not the worst of it, but it’s not the best at all, which means there’s some room beneath how we could go having the C code run. While it’s hard to fully trust the Rosetta Code Man-or-Boy code for C as the best, it is a pretty clear example of how a “normal” C developer would do it and how it’s not actually able to hit maximum performance for this situation.</p>

<p>I wanted to add a version of regular C code that used a dynamic array with <code>static</code>s to transfer data, or a bunch of <code>thread_local</code>s, but I could not bring myself to actually care enough to write a complex association scheme from a specific invocation of the recursive function <code>a</code> and the slot of dynamic data that represented the closure’s data. I’m sure there’s schemes for it and I could think of a few, but at that point it’s such a violent contortion to get a solution that going that I figured it simply wasn’t worth the effort. But, as always,</p>

<p>pull requests are welcome. 💚</p>

<ul>
  <li>Banner and Title Photo by <a href="https://www.pexels.com/photo/person-holding-black-card-holder-928181/">Lukas, from Pexels</a></li>
</ul>







    
    </section>

    <!-- Social media shares -->
    






    <!-- Category and Tag list -->
    <div data-testid="tag-list">
    <ul>
      
        <li>Tags</li>
      

      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#C">
          <p><i></i> C</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#C+standard">
          <p><i></i> C standard</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#C%2B%2B">
          <p><i></i> C++</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#blocks">
          <p><i></i> blocks</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#closures">
          <p><i></i> closures</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#functions">
          <p><i></i> functions</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#performance">
          <p><i></i> performance</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#purrformance">
          <p><i></i> purrformance</p>
        </a></li>
      
        <li><a data-testid="tag-link" href="https://thephd.dev/tags#%F0%9F%93%8A">
          <p><i></i> 📊</p>
        </a></li>
      
    </ul>
  </div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Incomplete list of mistakes in the design of CSS (157 pts)]]></title>
            <link>https://wiki.csswg.org/ideas/mistakes</link>
            <guid>46227619</guid>
            <pubDate>Thu, 11 Dec 2025 04:20:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.csswg.org/ideas/mistakes">https://wiki.csswg.org/ideas/mistakes</a>, See on <a href="https://news.ycombinator.com/item?id=46227619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">

<p>
That should be corrected if anyone invents a time machine. :P
</p>
<ul>
<li><p><code>white-space: nowrap</code> should be <code>white-space: no-wrap</code></p>
<ul>
<li><p> and line wrapping behavior should not have been added to <code>white-space</code></p>
</li>
</ul>
</li>
<li><p><code>animation-iteration-count</code> should just have been <code>animation-count</code> (like <code>column-count</code>!)</p>
</li>
<li><p><code>vertical-align</code> should not apply to table cells. Instead the CSS3 alignment properties should exist in Level 1.</p>
</li>
<li><p><code>vertical-align: middle</code> should be <code>text-middle</code> or <code>x-middle</code> because it's not really in the middle, and such a name would better describes what it does.</p>
</li>
<li><p> Percentage heights should be calculated against <code>fill-available</code> rather than being undefined in auto situations.</p>
</li>
<li><p> Table layout should be sane.</p>
</li>
<li><p> Box-sizing should be <code>border-box</code> by default.</p>
</li>
<li><p><code>background-size</code> with one value should duplicate its value, not default the second one to <code>auto</code>. Ditto <code>translate()</code>.</p>
</li>
<li><p><code>background-position</code> and <code>border-spacing</code> (all 2-axis properties) should take *vertical* first, to match with the 4-direction properties like <code>margin</code>.</p>
</li>
<li><p> Not quite a mistake, because it was a reasonable default for the 90s, but it would be more helpful since then if `background-repeat` defaulted to `no-repeat`.</p>
</li>
<li><p> The 4-value shorthands like <code>margin</code> should go counter-clockwise (so that the inline-start value is before the block-end and inline-end values instead of after them).</p>
</li>
<li><p><code>z-index</code> should be called <code>z-order</code> or <code>depth</code> and should Just Work on all elements (like it does on flex items).</p>
</li>
<li><p><code>word-wrap</code>/<code>overflow-wrap</code> should not exist. Instead, <code>overflow-wrap</code> should be a keyword on 'white-space', like <code>nowrap</code> (<code>no-wrap</code>).</p>
</li>
<li><p> The top and bottom margins of a single box should never have been allowed to collapse together automatically as this is the <strong>root of all margin-collapsing evil</strong>.</p>
</li>
<li><p> Partial collapsing of margins instead of weird rules to handle min/max-heights?</p>
</li>
<li><p> Tables (like other non-blocks, e.g. flex containers) should form pseudo-stacking contexts.</p>
</li>
<li><p> The <code>currentColor</code> keyword should have retained the dash, <code>current-color</code>, as originally specified. Likewise all other color multi-word keyword names.</p>
</li>
<li><p> There should have been a predictable color naming system (like CNS) instead of the arbitrary X11 names which were eventually adopted.</p>
</li>
<li><p><code>border-radius</code> should have been <code>corner-radius</code>.</p>
</li>
<li><p> Absolutely-positioned replaced elements should stretch when opposite offset properties (e.g. left+right) are set, instead of being start-aligned.</p>
</li>
<li><p> The <code>hyphens</code> property should be called <code>hyphenate</code>. (It's called <code>hyphens</code> because the XSL:FO people objected to <code>hyphenate</code>.)</p>
</li>
<li><p><code>rgba()</code> and <code>hsla()</code> should not exist, <code>rgb()</code> and <code>hsl()</code>  should have gotten an optional fourth parameter instead (and the alpha value should have used the same format as R, G, and B or S and L).</p>
</li>
<li><p> Descendant combinator should have been <code>»</code> and indirect sibling combinator should have been <code>++</code>, so there's some logical relationships among the selectors' ascii art</p>
</li>
<li><p> The <code>*-blend-mode</code> properties should've just been <code>*-blend</code></p>
</li>
<li><p> The syntax of unicode ranges should have consistent with the rest of <abbr title="Cascading Style Sheets">CSS</abbr>, like <code>u0001-u00c8</code>.</p>
</li>
<li><p> Unicode ranges should not have had a separate microsyntax with their own tokenization or token handling.  The tokenization hacks required either to make selectors (e.g., u+a) handle things that are unicode-range tokens, or make unicode-range handle the other huge range of tokens (numbers and dimensions with and without scientific notation, identifiers, +) are both horrible.</p>
</li>
<li><p><code>font-family</code> should have required the font name to be quoted (like all other values that come from “outside” <abbr title="Cascading Style Sheets">CSS</abbr>).  The rules for handling unquoted font names make parsing <code>font</code> stupid, as it requires a <code>font-size</code> value for disambiguation.</p>
</li>
<li><p> Flexbox should have been less crazy about <code>flex-basis</code> vs <code>width</code>/<code>height</code>.  Perhaps: if <code>width</code>/<code>height</code> is <code>auto</code>, use <code>flex-basis</code>; otherwise, stick with <code>width</code>/<code>height</code> as an inflexible size.  (This also makes min/max width/height behavior fall out of the generic definition.)</p>
</li>
<li><p><del><code>:empty</code> should have been <code>:void</code>, and <code>:empty</code> should select items that contain only white space</del> FIXED in the <abbr title="specification">spec</abbr>, waiting for implementations to check for Web-compat…</p>
</li>
<li><p><code>table-layout: fixed; width: auto</code> should result in a fill-available table with fixed-layout columns.</p>
</li>
<li><p><code>text-orientation</code> should have had <code>upright</code> as the initial value (given the latest changes to 'writing-mode').</p>
</li>
<li><p> The <code>@import</code> rule is required to (a) always hit the network unless you specify cache headers, and (b) construct fresh CSSStyleSheet objects for every import, even if they're identical. It should have had more aggressive <abbr title="Uniform Resource Locator">URL</abbr>-based deduping and allowed sharing of stylesheet objects.</p>
</li>
<li><p> Selectors have terrible future-proofing. We should have split on top-level commas, and only ignored unknown/invalid segments, not the entire thing.</p>
</li>
<li><p><code>:link</code> should have had the <code>:any-link</code> semantics all along.</p>
</li>
<li><p> The <code>flex</code> shorthand (and <code>flex-shrink</code> and <code>flex-grow</code> longhands) should accept <code>fr</code> units instead of bare numbers to represent flex fractions.</p>
</li>
<li><p> The <code>display</code> property should be called <code>display-type</code>.</p>
</li>
<li><p> The <code>list-style</code> properties should be called <code>marker-style</code>, and <code>list-item</code> renamed to <code>marked-block</code> or something.</p>
</li>
<li><p> The <code>text-overflow</code> property should always apply, not be dependent on <code>overflow</code></p>
</li>
<li><p><code>line-height: &lt;percentage&gt;</code> should compute to the equivalent <code>line-height: &lt;number&gt;</code>, so that it effectively inherits as a percentage not a length</p>
</li>
<li><p><code>::placeholder</code> should be <code>::placeholder-text</code> and <code>:placeholder-shown</code> should be <code>:placeholder</code></p>
</li>
<li><p><code>overflow: scroll</code> should introduce a stacking context</p>
</li>
<li><p><code>size</code> should have been a shorthand for <code>width</code> and <code>height</code> instead of an <code>@page</code> property with a different definition</p>
</li>
<li><p> We probably should have avoided mixing keywords (<code>span</code>) with idents in the <a href="https://github.com/w3c/csswg-drafts/issues/1137" title="https://github.com/w3c/csswg-drafts/issues/1137" rel="ugc nofollow">grid properties</a>, possibly by using functional notation (like <code>span(2)</code>).</p>
</li>
<li><p> Comments shouldn't have been allowed basically everywhere in <abbr title="Cascading Style Sheets">CSS</abbr> (compare to <abbr title="HyperText Markup Language">HTML</abbr>, which basically only allows them where content goes), because it makes them basically unrepresentable in the object model, which in turn makes building editing directly on top of the object model impossible</p>
</li>
<li><p> The alignment properties in Flexbox should have been writing-mode relative, not flex-flow relative, and thus could have reasonably understandable names like <code>align-inline-*</code> and <code>align-block-*</code>.</p>
</li>
<li><p><code>shape-outside</code> should have had <code>wrap-</code> in the name somehow, as people assume the shape should also clip the content as in <code>clip-path</code>.</p>
</li>
<li><p> It shouldn't be <code>!important</code> —&nbsp;that reads to engineers as “not important”. We should have picked another way to write this.</p>
</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vibe coding is mad depressing (201 pts)]]></title>
            <link>https://law.gmnz.xyz/vibe-coding-is-mad-depressing/</link>
            <guid>46227422</guid>
            <pubDate>Thu, 11 Dec 2025 03:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://law.gmnz.xyz/vibe-coding-is-mad-depressing/">https://law.gmnz.xyz/vibe-coding-is-mad-depressing/</a>, See on <a href="https://news.ycombinator.com/item?id=46227422">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    

    
        

        <p>
            <i>
                <time datetime="2025-12-11T03:28Z">
    11 Dec, 2025
</time>
            </i>
        </p>
    

    <p>I’ve been in the mobile development industry for almost 15 years, and this AI/LLM era might be the worst.</p>
<p>My work are mostly freelance, gigs, hourly, milestones, and I could say 90% of my experience are greenfield projects. I don’t have any apps on my own, I make a living coding apps for others.</p>
<h3 id="before-ai">Before AI</h3><p>Back in the day, during a client kickoff they usually hand me a document with a UI prototype and a list of features. Then, you start from scratch, File - New Project. <code>git init</code> that shit and you’re on your way.</p>
<p>Everything was calm, clients just wanted a weekly or monthly feedback because they know how hard mobile development is you know. No pressure. You can focus on the great work, clean code, proper variable naming, proper git commit, all that stuffs.</p>
<p>In 2-3 months you get an alpha or beta build out, and clients are very happy. They can’t believe there idea, has now transformed into something they can play with.</p>
<h3 id="start-of-ai-era">Start of AI era</h3><p>Fast forward to today, or maybe it started around 2-3 years ago. Nothing wrong with it at first. Like any freelancer, I try to adopt with the latest trends.</p>
<p>At first it was just code snippets.</p>
<blockquote>
<p>Hey! I asked AI for this code, do you think this will work? I think you should use it.</p>
</blockquote>
<p>Okay, so this non-technical person is sending me codes now.</p>
<p>I mostly reply with</p>
<blockquote>
<p>It’s alright I got some working code blocks that worked in production perfectly fine. Thanks though!</p>
</blockquote>
<p>But, then this code snippets get larger and larger as time goes on. I'm thankful for this suggestions of course. But, it's just additional work when you're coding and you get this AI source code and then you have to think on how to merge this code with a different coding style and variable names into your codebase.</p>
<h3 id="vibe-coding-era">Vibe Coding era</h3><p>The first clues started when a client, who I thought was a software developer, starts merging his own code through the <code>main</code> branch, without warning. No pull request, just straight <code>git push --force origin main</code>.</p>
<p>As I started to checkout what the code was about, I started seeing this emojis inside the <code>print()</code> statements. I thought, this is so odd and unprofessional.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/lawgimenez/17am.webp" alt="Screenshot 2025-12-11 at 10"></p>
<p>I tried to Google search the macOS shortcut for emojis, to match this person's vibe. This fella must really like emojis you know. It turns out, AI code has a lot of emojis along with it.</p>
<p>The other sign was how the branching, and merging works with AI. And maybe feature request? I really don't know. For example, one vibe coded project has 1,227 branches and counting. I haven't merged one yet, I let the client deal with that.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/lawgimenez/41am.webp" alt="Screenshot 2025-12-11 at 10"></p>
<p>Last time, I checked this Xcode project did not compiled. Or anything close to it.</p>
<p>And the last thing that made me snapped was, all this vibed source code were located inside one file <code>ContentView</code>. To anyone who's not familiar, <code>ContentView</code> is the first SwiftUI file created when you start a new Xcode project.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/lawgimenez/20pm.webp" alt="Screenshot 2025-12-09 at 12"></p>
<p>All the UI logic, view models, model are located inside that file. Worst part, this is currently live in the App Store.</p>
<h3 id="conclusion">Conclusion</h3><p>I totally get it, everyone has to make a living. Creating an app is one of them. I just feel sad with how AI has bastardized my profession, which I worked hard for the last 15 years. There is no best practices anymore, no proper process, no meaningful back and forth. Just dealing with thousands and thousands of lines of code at every project kickoff.</p>


    

    
        

        
            


        

        
            
        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Patterns.dev (404 pts)]]></title>
            <link>https://www.patterns.dev/</link>
            <guid>46226483</guid>
            <pubDate>Thu, 11 Dec 2025 01:18:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.patterns.dev/">https://www.patterns.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=46226483">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h3>
            We offer a modern perspective on patterns
          </h3>
          <p>
            A common critique of design patterns is that they needlessly add
            complexity.
          </p>
          <p>
            Our perspective is that patterns are valuable for solving specific
            problems, often helping to 
            <strong>communicate comminalities in code problems</strong> for humans.
            If a project doesn't have those problems, there isn't a need
            to apply them. Patterns can also be very language or framework-specific
            (e.g. React), which can often mean thinking beyond the scope of just
            the original GoF design patterns.
          </p>
        </div><div>
          <h3>
            We help you scale your webapps for performance
          </h3>
          <p>
            Learn about web performance patterns for loading your code more
            efficiently. Unsure how to think about modern approaches to loading
            or rendering user-experiences? We've got you covered.
          </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When would you ever want bubblesort? (2023) (102 pts)]]></title>
            <link>https://buttondown.com/hillelwayne/archive/when-would-you-ever-want-bubblesort/</link>
            <guid>46224311</guid>
            <pubDate>Wed, 10 Dec 2025 21:45:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/hillelwayne/archive/when-would-you-ever-want-bubblesort/">https://buttondown.com/hillelwayne/archive/when-would-you-ever-want-bubblesort/</a>, See on <a href="https://news.ycombinator.com/item?id=46224311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
        
            <p>There are very few universal rules in software engineering, but there are are a lot of <em>near</em>-universal principles. Things like "prefer composition to inheritance" is near-universal. I love finding the rare situations where these principles don't hold, like where you do want <a href="https://buttondown.email/hillelwayne/archive/when-to-prefer-inheritance-to-composition/" target="_blank">inheritance over composition</a>. A similar near-universal principle is "don't use <a href="https://en.wikipedia.org/wiki/Bubble_sort" target="_blank">bubblesort</a>". Some would even say it's a universal rule, with Donald Knuth writing "bubble sort seems to have nothing to recommend it, except a catchy name and the fact that it leads to some interesting theoretical problems".<sup id="fnref:cite"><a href="#fn:cite">1</a></sup> But Knuth's <a href="https://en.wikipedia.org/wiki/Knuth_reward_check" target="_blank">been wrong before</a>, so let's see if this universal rule is only <em>near</em>-universal.</p>
<p>Theoretically, bubblesort is faster than quick or mergesort for small arrays. This makes it useful as part of a larger sorting strategy: most of the fast-in-principle sorting algorithms work by recursively sorting subpartitions of an array, ie if you apply quicksort to 2^20 random integers, at some point you're sorting 2^17 8-integer subpartitions. Switching over to bubblesort for those subpartitions would be a nice optimization. </p>
<p>Many production sorting algorithms do use a hybrid approach, but they overwhelmingly use <a href="https://en.wikipedia.org/wiki/Insertion_sort" target="_blank">insertion sort</a> instead. Insertion sort is very fast for small arrays and it's also <a href="https://nicknash.me/2012/10/12/knuths-wisdom/" target="_blank">better at using the hardware</a>. On some very particular hardwares bubblesort stills ends up better, like in this <a href="http://www.sci.utah.edu/~wald/Publications/2019/rtgems/ParticleSplatting.pdf" target="_blank">NVIDIA study</a>, but you probably don't have that hardware.</p>
<p>So that's one use-case, albeit one still dominated by a different algorithm. It's interesting that NVIDIA used it here because gamedev has a situation that's uniquely useful to bubblesort, based on two of its properties:</p>
<ol>
<li>While the algorithm is very slow overall, each individual step is very fast and easily suspendable.</li>
<li>Each swap leaves the array more ordered than it was before. Other sorts can move values <em>away</em> from their final positions in intermediate stages.</li>
</ol>
<p>This makes it really good when you want to do a fixed amount of sorting work per frame. Say you have a bunch of objects on a screen, where some objects can occlude others. You want to render the objects closest to the camera <em>first</em> because then you can determine which objects it hides, and then save time rendering those objects. There's no correctness cost for rendering objects out of order, just a potential performance cost. So while your array doesn't <em>need</em> to be ordered, the more ordered it is the happier you are. But you also can't spend too much time running a sorting algorithm, because you have a pretty strict realtime constraint. Bubble sort <a href="https://discussions.unity.com/t/depth-sorting-of-billboard-particles-how-can-i-do-it/5053" target="_blank">works pretty well here</a>. You can run it a little bit of a time at each frame and get a better ordering than when you started.</p>
<p>That reminds me of one last use-case I've heard, apocryphally. Let's say you have a random collection of randomly-colored particles, and you want to animate them sorting into a rainbow spectrum. If you make each frame of the animation one pass of bubblesort, the particles will all move smoothly into the right positions. I couldn't find any examples in the wild, so with the help of GPT4 I hammered out a crappy visualization. Code is <a href="https://gist.github.com/hwayne/85488f755066d8aa57cd147875e97b72" target="_blank">here</a>, put it <a href="https://editor.p5js.org/" target="_blank">here</a>.</p>
<p>(After doing that I suspect this isn't actually done in practice, in favor of running a better sort to calculate each particles final displacement and then animating each particles moving directly, instead of waiting to move for each bubblesort pass. I haven't mocked out an example but I think that'd look a lot smoother.)</p>
<p>So there you go, three niche use cases for bubblesort. You'll probably never need it.</p>
<hr>
<h3>New Quanta Article!</h3>
<p>Okay so I didn't actually write this one, but I played a role in it happening! A while back a friend visited, and we were chatting about his job at quanta. At the time he was working on this <a href="https://www.quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/" target="_blank">mammoth article on metacomplexity theory</a>, so naturally the topic of <a href="https://buttondown.email/hillelwayne/archive/problems-harder-than-np-complete/" target="_blank">problems harder than NP-complete</a> came up and I recommend he check out Petri net reachability. So he did, and then he wrote <a href="https://www.quantamagazine.org/an-easy-sounding-problem-yields-numbers-too-big-for-our-universe-20231204/" target="_blank">An Easy-Sounding Problem Yields Numbers Too Big for Our Universe</a>. Gosh this is so exciting! </p>

        
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Services Experiencing Outage (126 pts)]]></title>
            <link>https://www.apple.com/support/systemstatus/</link>
            <guid>46223577</guid>
            <pubDate>Wed, 10 Dec 2025 20:47:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/support/systemstatus/">https://www.apple.com/support/systemstatus/</a>, See on <a href="https://news.ycombinator.com/item?id=46223577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ac-globalfooter" lang="en-US" data-analytics-region="global footer" role="contentinfo" aria-labelledby="ac-gf-label">
		        <h2 id="ac-gf-label">Apple Footer</h2>
		        <nav aria-label="Breadcrumbs" role="navigation">
		            <a href="https://www.apple.com/">
		                
		                <span>Apple</span>
		                <span></span>
		                <span></span>
		            </a>
		            <div>
		                <ol vocab="http://schema.org/" typeof="BreadcrumbList">
		                    <li property="itemListElement" typeof="ListItem">
		                        <span property="name">System Status</span>
		                        <meta property="position" content="1">
		                    </li>
		                </ol>
		            </div>
		        </nav>
		        <section>
					<div x-ms-format-detection="none"><p>
						More ways to shop: <a href="https://www.apple.com/retail/" onclick="sendAnalytics(this), trackFooterLinkClick(this)" data-analytics-title="find an apple store">Find an Apple Store</a> or <a href="https://locate.apple.com/" onclick="sendAnalytics(this), trackFooterLinkClick(this)" data-analytics-title="other retailers or resellers" data-analytics-exit-link="">other retailer</a> near you. <span>Or call 1-800-MY-APPLE.</span>
					</p></div>
					<div>
						<p><a href="https://www.apple.com/choose-country-region/" title="Choose your country or region" aria-label="United States. Choose your country or region" onclick="sendAnalyticsInnerHtml(this), trackCountrySelectorLinkClick(this)" data-analytics-title="choose your country">United States</a>
					</p></div>
					<div>
						<p>Copyright ©
							<span id="footer_msg_year"></span> Apple Inc. All rights reserved.</p>
						<div>
							<p><a href="https://www.apple.com/legal/privacy/" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="privacy policy">Privacy Policy</a>
							<a href="https://www.apple.com/legal/internet-services/terms/site.html" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="terms of use">Terms of Use</a>
							<a href="https://www.apple.com/us/shop/goto/help/sales_refunds" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="sales and refunds">Sales and Refunds</a>
							<a href="https://www.apple.com/legal/" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="legal">Legal</a>
							<a href="https://www.apple.com/sitemap/" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="site map">Site Map</a>
						</p></div>
					</div>
				</section>				
		    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting a Gemini API key is an exercise in frustration (661 pts)]]></title>
            <link>https://ankursethi.com/blog/gemini-api-key-frustration/</link>
            <guid>46223311</guid>
            <pubDate>Wed, 10 Dec 2025 20:29:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ankursethi.com/blog/gemini-api-key-frustration/">https://ankursethi.com/blog/gemini-api-key-frustration/</a>, See on <a href="https://news.ycombinator.com/item?id=46223311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <article>   <section>  <p>Last week, I started working on a new side-project. It’s a standard React app partly made up of run-of-the-mill CRUD views—a perfect fit for LLM-assisted programming. I reasoned that if I could get an LLM to quickly write the boring code for me, I’d have more time to focus on the interesting problems I wanted to solve.</p>
<p>I’ve pretty much settled on Claude Code as my coding assistant of choice, but I’d been hearing great things about Google’s Gemini 3 Pro. Despite my aversion to Google products, I decided to try it out on my new codebase.</p>
<p>I already had <a href="https://github.com/google-gemini/gemini-cli">Gemini CLI</a> installed, but that only gave me access to Gemini 2.5 with rate limits. I wanted to try out Gemini 3 Pro, and I wanted to avoid being rate limited. I had some spare cash to burn on this experiment, so I went looking for ways to pay for a Gemini Pro plan, if such a thing existed.</p>
<p>Thus began my grand adventure in trying to give Google my money.</p>
<h2 id="what-is-a-gemini-really">What is a Gemini, really?</h2>
<p>The name “Gemini” is so overloaded that it barely means anything. Based on the context, Gemini could refer to:</p>
<ul>
<li>The chatbot available at <a href="https://gemini.google.com/">gemini.google.com</a>.</li>
<li>The mobile app that lets you use the same Gemini chatbot on your <a href="https://apps.apple.com/us/app/google-gemini/id6477489729">iPhone</a> or <a href="https://play.google.com/store/apps/details?id=com.google.android.apps.bard&amp;hl=en_US">Android</a>.</li>
<li>The <a href="https://gemini.google/us/assistant/">voice assistant</a> on Android phones.</li>
<li>The AI features <a href="https://workspace.google.com/resources/ai/">built into Google Workspace</a>, Firebase, Colab, BigQuery, and other Google products.</li>
<li>Gemini CLI, an agentic coding tool for your terminal that works the same way as Claude Code or OpenAI Codex.</li>
<li>The <a href="https://codeassist.google/">Gemini Code Assist</a> suite of products, which includes extensions for various IDEs, a GitHub app, and Gemini CLI.</li>
<li>The <a href="https://en.wikipedia.org/wiki/Gemini_(language_model)">underlying LLM</a> powering all these products.</li>
<li>Probably three more products by the time I finish writing this blog post.</li>
</ul>
<p>To make things even more confusing, Google has at least three different products just for agentic coding: Gemini Code Assist (Gemini CLI is a part of this suite of products), <a href="https://jules.google/">Jules</a>, and <a href="https://antigravity.google/">Antigravity</a>.</p>
<p>And then there’s a bunch of other GenAI stuff that is powered by Gemini but doesn’t have the word Gemini in the name: <a href="https://cloud.google.com/vertex-ai?hl=en">Vertex AI Platform</a>, <a href="https://aistudio.google.com/api-keys">Google AI Studio</a>, <a href="https://notebooklm.google/">NotebookLM</a>, and who knows what else.</p>
<p>I just wanted to plug my credit card information into a form and get access to a coding assistant. Instead, I was dunked into an alphabet soup of products that all seemed to do similar things and, crucially, didn’t have any giant “Buy Now!” buttons for me to click.</p>
<p>In contrast, both Anthropic and OpenAI have two primary ways you can access their products: via their consumer offerings at <a href="https://claude.ai/">claude.ai</a> and <a href="https://chatgpt.com/">chatgpt.com</a> respectively, or via API credits that you can buy through their respective <a href="https://platform.claude.com/">developer</a> <a href="https://platform.openai.com/">consoles</a>. In each case, there is a form field where you can plug in your credit card details, and a big, friendly “Buy Now!” button to click.</p>
<p>After half an hour of searching the web, I did the obvious thing and asked the free version of Gemini (the chatbot, not one of those other Geminis) what to do:</p>
<blockquote>
<p>How do I pay for the pro version of Gemini so i can use it in the terminal for writing code? I specifically want to use the Gemini 3 Pro model.</p>
</blockquote>
<p>It thought for a suspiciously long time and told me that Gemini 3 Pro required a developer API key to use. Since the new model is still in preview, it’s not yet available on any of the consumer plans. When I asked follow up questions about pricing, it told me that “Something went wrong”. Which translates to: we broke something, but we won’t tell you how to fix it.</p>
<p>So I asked Claude for help. Between the two LLMs, I was able to figure out how to create an API key for the Gemini I wanted.</p>
<h2 id="creating-an-api-key-is-easy">Creating an API key is easy</h2>
<p>Google AI Studio is supposed to be the all-in-one dashboard for Google’s generative AI models. This is where you can experiment with model parameters, manage API keys, view logs, and manage billing for your projects.</p>
<p>I logged into Google AI Studio and <a href="https://aistudio.google.com/api-keys">created a new API key</a>. This part was pretty straightforward: I followed the on-screen instructions and had a fresh new key housed under a project in a few seconds. I then verified that my key was working with Gemini CLI.</p>
<p>It worked! Now all that was left to do was to purchase some API credits. Back in Google AI Studio, I saw a link titled “Set up billing” next to my key. It looked promising, so I clicked it.</p>
<p>That’s where the fun <em>really</em> began.</p>
<h2 id="google-doesnt-want-my-money">Google doesn’t want my money</h2>
<p>The “Set up billing” link kicked me out of Google AI Studio and into Google Cloud Console, and my heart sank. Every time I’ve logged into Google Cloud Console or AWS, I’ve wasted hours upon hours reading outdated documentation, gazing in despair at graphs that make no sense, going around in circles from dashboard to dashboard, and feeling a strong desire to attain freedom from this mortal coil.</p>
<p>Turns out I can’t just put $100 into my Gemini account. Instead, I must first create a Billing Account. After I’ve done that, I must associate it with a project. <em>Then</em> I’m allowed to add a payment method to the Billing Account. And <em>then</em>, if I’m lucky, my API key will turn into a paid API key with Gemini Pro privileges.</p>
<p>So I did the thing. The whole song and dance. Including the mandatory two-factor OTP verification that every Indian credit card requires. At the end of the process, I was greeted with a popup telling me I had to verify my payment method before I’d be allowed to use it.</p>
<p>Wait. Didn’t I <em>just</em> verify my payment method? When I entered the OTP from my bank?</p>
<p>Nope, turns out Google hungers for more data. Who’d have thunk it?</p>
<p>To verify my payment method <em>for reals</em>, I had to send Google a picture of my government-issued ID and the credit card I’d just associated with my Billing Account. I had to ensure all the numbers on my credit card were redacted by manually placing black bars on top of them in an image editor, leaving only my name and the last four digits of the credit card number visible.</p>
<p>This felt unnecessarily intrusive. But by this point, I was too deep in the process to quit. I was invested. I needed my Gemini 3 Pro, and I was willing to pay any price.</p>
<p>The upload form for the government ID rejected my upload twice before it finally accepted it. It was the same exact ID every single time, just in different file formats. It wanted a PNG file. Not a JPG file, nor a PDF file, but a PNG file. Did the upload form mention that in the instructions? Of course not.</p>
<p>After jumping through all these hoops, I received an email from Google telling me that my verification will be completed in a few days.</p>
<p>A <em>few days</em>? Nothing to do but wait, I suppose.</p>
<h2 id="403-forbidden">403 Forbidden</h2>
<p>At this point, I closed all my open Cloud Console tabs and went back to work. But when I was fifteen minutes into writing some code by hand like a Neanderthal, I received a second email from Google telling me that my verification was complete.</p>
<p>So for the tenth time that day, I navigated to AI Studio. For the tenth time I clicked “Set up billing” on the page listing my API keys. For the tenth time I was told that my project wasn’t associated with a billing account. For the tenth time I associated the project with my new billing account. And finally, after doing all of this, the “Quota tier” column on the page listing my API keys said “Tier 1” instead of “Set up billing”.</p>
<p>Wait, Tier 1? Did that mean there were other tiers? What were tiers, anyway? Was I already on the best tier? Or maybe I was on the worst one? Not important. The important part was that I had my API key and I’d managed to convince Google to charge me for it.</p>
<p>I went back to the Gemini CLI, ran the <code>/settings</code> command, and turned on the “Enable experimental features” option. I ran the <code>/models</code> command, which told me that Gemini 3 Pro was now available.</p>
<p>Success? Not yet.</p>
<p>When I tried sending a message to the LLM, it failed with this 403 error:</p>
<pre tabindex="0" data-language="json"><code><span><span>{</span></span>
<span><span>  "error"</span><span>: {</span></span>
<span><span>    "message"</span><span>: </span><span>"{</span><span>\n</span><span>  \"</span><span>error</span><span>\"</span><span>: {</span><span>\n</span><span>    \"</span><span>code</span><span>\"</span><span>: 403,</span><span>\n</span><span>    \"</span><span>message</span><span>\"</span><span>: </span><span>\"</span><span>The caller does not have permission</span><span>\"</span><span>,</span><span>\n</span><span>    \"</span><span>status</span><span>\"</span><span>:</span><span>\"</span><span>PERMISSION_DENIED</span><span>\"\n</span><span>  }</span><span>\n</span><span>}</span><span>\n</span><span>"</span><span>,</span></span>
<span><span>    "code"</span><span>: </span><span>403</span><span>,</span></span>
<span><span>    "status"</span><span>: </span><span>"Forbidden"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre>
<p>Is that JSON inside a string inside JSON? Yes. Yes it is.</p>
<p>To figure out if my key was even working, I tried calling the Gemini API from JavaScript, reproducing the basic example from <a href="https://ai.google.dev/gemini-api/docs#javascript">Google’s own documentation</a>.</p>
<p>No dice. I ran into the exact same error.</p>
<p>I then tried talking to Gemini 3 Pro using the <a href="https://aistudio.google.com/prompts/new_chat">Playground</a> inside Google AI Studio. It showed me a toast message saying <code>Failed to generate content. Please try again.</code> The chat transcript said <code>An internal error has occurred.</code></p>
<p>At this point I gave up and walked away from my computer. It was already 8pm. I’d been trying to get things to work since 5pm. I needed to eat dinner, play <em>Clair Obscur</em>, and go to bed. I had no more time to waste and no more fucks to give.</p>
<h2 id="your-account-is-in-good-standing-at-this-time">Your account is in good standing at this time</h2>
<p>Just as I was getting into bed, I received an email from Google with this subject line:</p>
<blockquote>
<p>Your Google Cloud and APIs billing account XXXXXX-XXXXXX-XXXXXX is in good standing at this time.</p>
</blockquote>
<p>With the message inside saying:</p>
<blockquote>
<p>Based on the information you provided and further analysis by Google, we have reinstated your billing account XXXXXX-XXXXXX-XXXXXX. Your account is in good standing, and you should now have full access to your account and related Project(s) and Service(s).</p>
</blockquote>
<p>I have no idea what any of this means, but Gemini 3 Pro started working correctly after I received this email. It worked in the Playground, directly by calling the API from JavaScript, and with Gemini CLI.</p>
<p>Problem solved, I guess. Until Google mysteriously decides that my account is no longer in good standing.</p>
<h2 id="this-was-a-waste-of-time">This was a waste of time</h2>
<p>This was such a frustrating experience that I still haven’t tried using Gemini with my new codebase, nearly a week after I made all those sacrifices to the Gods of Billing Account.</p>
<p>I understand why the process for getting a Gemini API key is so convoluted. It’s designed for large organizations, not an individual developers trying to get work done; it serves the bureaucracy, not the people doing the work; it’s designed for maximum compliance with government regulations, not for efficiency or productivity.</p>
<p>Google doesn’t want my money unless I’m an organization that employs ten thousand people.</p>
<p>In contrast to Google, Anthropic and OpenAI are much smaller and much more nimble. They’re able to make the process of setting up a developer account quick and easy for those of us who just want to get things done. Unlike Google, they haven’t yet become complacent. They need to compete for developer mindshare if they are to survive a decade into the future. Maybe they’ll add the same level of bureaucracy to their processes as they become larger, but for now they’re fairly easy to deal with.</p>
<p>I’m still going to try using Gemini 3 Pro with Gemini CLI as my coding assistant, but I’ll probably cap the experiment to a month. Unless Gemini 3 Pro is a massive improvement over its competitors, I’ll stick to using tools built by organizations that want me as a customer.</p>  </section>   </article>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I got an Nvidia GH200 server for €7.5k on Reddit and converted it to a desktop (320 pts)]]></title>
            <link>https://dnhkng.github.io/posts/hopper/</link>
            <guid>46222237</guid>
            <pubDate>Wed, 10 Dec 2025 19:19:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dnhkng.github.io/posts/hopper/">https://dnhkng.github.io/posts/hopper/</a>, See on <a href="https://news.ycombinator.com/item?id=46222237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://dnhkng.github.io/assets/img/main.jpg"><img src="https://dnhkng.github.io/assets/img/main.jpg" alt="Grace Hopper Desktop" loading="lazy"></a></p><h2 id="introduction"><span>Introduction</span><a href="#introduction"><i></i></a></h2><p>Running large language models locally has always been a game of compromise. You either spend \$10,000+ on consumer GPUs that can barely handle 70 B parameter models, or you dream about enterprise hardware you’ll never afford. The Grace-Hopper platform—Nvidia’s unified CPU-GPU superchip architecture—represents the kind of dream-rig AI infrastructure LocalLlama drools over, with systems typically costing well over \$100,000 and exclusively available to data centers and research institutions.</p><p>So when I stumbled across a Grace-Hopper system being sold for 10K euro on Reddit, my first thought was “obviously fake.” My second thought was “I wonder if he’ll take 7.5K euro?”.</p><p>This is the story of how I bought enterprise-grade AI hardware designed for liquid-cooled server racks, converted it to air cooling, survived multiple near-disasters (including GPUs reporting temperatures of 16 million degrees), and ended up with a desktop that can run 235B parameter models at home. It’s a tale of questionable decisions, creative problem-solving, and what happens when you try to turn datacenter equipment into a daily driver.</p><p>If you’ve ever wondered what it takes to run truly large models locally, or if you’re just here to watch someone disassemble $80,000 worth of hardware with nothing but hope and isopropanol, you’re in the right place.</p><h2 id="the-deal"><span>The Deal</span><a href="#the-deal"><i></i></a></h2><p>Early this year, while browsing r/LocalLLaMA/new, I came across a <a href="https://www.reddit.com/r/LocalLLaMA/comments/1m65iga/frankenserver_for_sale_at_a_steep_discount_2x96gb/"><em>ridiculously good deal</em></a>. How good? These were the specs for the server offered for 10K euro, and a serious upgrade to my 4x RTX 4090 rig:</p><h3 id="specs"><span>Specs:</span><a href="#specs"><i></i></a></h3><ul><li>2x Nvidia Grace-Hopper Superchip</li><li>2x 72-core Nvidia Grace CPU</li><li>2x Nvidia Hopper H100 Tensor Core GPU</li><li>2x 480GB of LPDDR5X memory with error-correction code (ECC)</li><li>2x 96GB of HBM3 memory</li><li>1152GB of total fast-access memory</li><li>NVLink-C2C: 900 GB/s of bandwidth</li><li>Programmable from 1000W to 2000W TDP (CPU + GPU + memory)</li><li>1x High-efficiency 3000W PSU 230V to 48V</li><li>2x PCIe Gen4 M.2 22110/2280 slots on board</li><li>4x FHFL PCIe Gen5 x16</li></ul><blockquote><p><strong>UPDATE</strong>:Since I bought this, DDR5 RAM prices have become insane. 960GB of fast DDR5 now costs more than what I paid for the whole Grace-Hopper system 🤯</p></blockquote><p><em>Obviously fake</em> I thought, because</p><ol><li>H100s cost about <strong>30-40,000 euro each</strong>, and this system has <em>two of them</em></li><li>Grace-Hopper NVL2 systems are basically not for sale for consumers anyway!</li></ol><p>The Reddit thread explained the reason the system was being sold cheap:</p><blockquote><p>The main reason why is that it is a Frankensystem converted from liquid-cooled to aircooled. Also it is not very pretty and not rackable, because it has a 48V power supply attached. It is originally directly from Nvidia.</p></blockquote><p>I immediately offered to buy it, because why not? If it was a scam, I could always back out, but I wanted to be first in line!</p><p>It turns out I live near the seller, and he runs an online shop that <a href="https://gptshop.ai/">sells modified Nvidia server equipment as desktops</a>. It still seemed pretty risky, so I did some research and <a href="https://www.youtube.com/watch?v=YBIpJhN5YsE">found a video review</a> of one of his Desktops on Youtube. With the deal now seeming at least plausible, and the seller only a two-hour drive away and agreeing to take cash, it was time to take a Bavarian road trip.</p><p>I arrived at a farmhouse in a small forest, and met Bernhard the proprietor of <a href="https://gptshop.ai/">GPTshop.ai</a>. He showed me a nice workshop (plasma cutters, an electronics lab, etc.) from which he fabricates custom cases for the high-end H100 desktops he builds. These desktops seem pretty damn nice, so it’s unfortunate that his webshop gives off shady vibes; the business registration in the Cayman Islands definitely doesn’t help. What I can say though is that this item was <em>heavily</em> discounted, and not what he usually sells.</p><blockquote><p><strong>Disclaimer</strong>: I have zero affiliation with GPTshop.ai beyond handing them a stack of cash and receiving a dust-covered server in return. If this were a sponsored post, they probably wouldn’t let me mention the 16 million degree GPU temperatures or the part where I had to free-solder components while praying to the electronics gods.</p></blockquote><h2 id="disassembling-the-grace-hopper-server"><span>Disassembling the Grace Hopper server</span><a href="#disassembling-the-grace-hopper-server"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/open.jpeg"><img src="https://dnhkng.github.io/assets/img/open.jpeg" alt="Arrival" loading="lazy"></a></p><p>The server itself was not in great condition. These things run <em>extremely</em> loud and high-throughput fans, and these had sucked in a lot of dust, coating the mainboard so heavily I couldn’t tell the color of the PCB. However, it booted up and ran OK, so I handed over a wad of cash, strapped it into the backseat of my car with the seatbelt (it weighed ~20 kg), and drove it home.</p><p>Did I mention it’s loud? Firing up the system is physically painful. There are 8x Sunon dual-fan modules, and each is as loud as a powerful vacuum cleaner, but with a much higher and more annoying pitch. With all 8 running at full power, hearing protection is necessary - I could hear the system running in my basement with the windows closed from 50 meters away! My wife immediately (and quite fairly), banned its use at home. We both work home-office and it was simply too loud for online meetings. But I had other plans anyway…</p><p>First things first, I of course quickly decided and then proceeded to strip down the server, after first photo-documenting the various connectors between the various PCBs, modules and mainboard.</p><h2 id="cleaning-the-server"><span>Cleaning the Server</span><a href="#cleaning-the-server"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/cleaning.jpg"><img src="https://dnhkng.github.io/assets/img/cleaning.jpg" alt="Cleaning" loading="lazy"></a></p><p>The majority of the dust was vacuumed off during disassembly, but there was clearly a lot more under the Grace-Hopper modules. After removing those as well, I decided to go with a full washdown of the mainboard.</p><p>I purchased a few litres of Isopropanol, and with a soft brush I went over the whole board a few times to get the remaining fine dust from inside connectors and between SMD-component pins.</p><p>I suspected there might also be dust <em>inside</em> the Grace-Hopper modules, but actually, I really just wanted to pop them open to poke around.</p><p>The mainboard went on my heated floor to dry for a week, while I moved on to replacing the cooling system.</p><h2 id="a-new-water-cooling-system"><span>A new Water Cooling system</span><a href="#a-new-water-cooling-system"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/adapter_plate.jpg"><img src="https://dnhkng.github.io/assets/img/adapter_plate.jpg" alt="Adapter Plate" loading="lazy"></a></p><p>I had looked into building a custom water-cooling block, but I was worried about leaks, when I found cheap <a href="https://www.arctic.de/en/Liquid-Freezer-III-420/ACFRE00137A">all-in-one water cooling systems</a> for ~40 euro each on sale. Two per GH200 module would be sufficient, so I carefully measured the dimensions of the GPU die and CPU, as well as screw locations, and threw those into Fusion 360 to model up an adapter block.</p><p>I have a Bambu X1, which came in very handy for prototyping the adapter blocks. The tolerances have to be very tight, so I printed several cut-away versions to make sure there was solid contact to the bare GPU die, and a safe margin from contact to fragile parts.</p><p>The parts were then sent for CNC milling, and were delivered as the mainboard was finished drying. After using yet more isopropanol to clean off the machining oil, they were mounted without much fuss.</p><h2 id="assembling-the-desktop"><span>Assembling the Desktop</span><a href="#assembling-the-desktop"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/assembly.jpg"><img src="https://dnhkng.github.io/assets/img/assembly.jpg" alt="Assembly" loading="lazy"></a></p><p>My go-to material for this kind of project is ProfilAlu from eBay. It’s cheap, stiff, and delivered pre-cut for assembly. I put together a design in Fusion 360, and had the parts in a few days. The various mounts however were much more work. I needed to design a few dozen custom mounts for the various PCBs and air-filter fixings; this used up a few kilos of filament to get things just right.</p><h2 id="disasters"><span>Disaster(s)</span><a href="#disasters"><i></i></a></h2><h3 id="critical-fan-errors"><span>Critical Fan Errors</span><a href="#critical-fan-errors"><i></i></a></h3><p>The system didn’t start to boot anymore. Checking the logs, I saw 16 critical errors, one for each fan in the 8 pairs:</p><blockquote><div><table><tbody><tr><td>4</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_5_F</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>5</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_6_R</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>6</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_8_F</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>7</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_5_R</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>8</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_7_F</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>9</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_8_R</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM…</td></tr></tbody></table></div></blockquote><p>With the fans removed, the <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface#Baseboard_management_controller">BMC (Baseboard Management Controller)</a> immediately panicked, and shut down the mainboard to prevent thermal damage, even with the water coolers in place. So, I disabled the fan-check subsystem.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre># stops the service for the current session
systemctl stop phosphor-sensor-monitor.service

# prevents the service from starting on the next boot
systemctl disable phosphor-sensor-monitor.service
</pre></td></tr></tbody></table></code></p></div><p>Who needs hardware monitoring? ¯\_(ツ)_/¯</p><h3 id="nuclear-fusion"><span>Nuclear Fusion?</span><a href="#nuclear-fusion"><i></i></a></h3><p>Great! I could start the boot process, and even reach login! But only about 1 time in 4… Not optimal. And even logged in, the server would crash within 2 minutes.</p><p>Looking into the BMC logs, I saw:</p><div><table><tbody><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>shutdown_ok_mon[1478]</td><td>event: FALLING EDGE offset: 26 timestamp: [571.615238550]</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>power-status[1493]</td><td>event: FALLING EDGE offset: 18 timestamp: [571.632491062]</td></tr><tr><td>Sep 23 08:20:18</td><td><strong>oberon-bmc</strong></td><td><strong>shutdown_ok_mon[545]</strong></td><td><strong>SHDN_OK_L-I = 0</strong></td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>shutdown_ok_mon[545]</td><td>Asserting SYS_RST_IN_L-O to hold host in reset</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>shutdown_ok_mon[545]</td><td>gpioset SYS_RST_IN_L-O = 0</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>power-status[697]</td><td>gpioset SYS_RST_IN_L-O = 0</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>power-status[697]</td><td>Set SYS_RST_IN_L-O=0</td></tr></tbody></table></div><p>So, a Critical Failure at 08:20:18:</p><ul><li>SHDN_OK_L-I signal goes low (falling edge detected)</li><li>This immediately triggers a shutdown sequence</li><li>System powers off within ~30 seconds of successful boot</li></ul><p>But why?!!? I had shut down the hardware monitoring.</p><p>Diving deeper into the logs:</p><div><table><tbody><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>ipmid[520]</td><td>thresholdChanged: Assert</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>ipmid[520]</td><td>thresholdChanged: Assert</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>ipmid[520]</td><td>thresholdChanged: Assert</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>satellitesensor[2351]</td><td>Sensor HGX_GPU_1_TEMP_1 high threshold 92 assert: value 1.67772e+07 raw data nan</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>satellitesensor[2351]</td><td>Sensor HGX_GPU_1_TEMP_1 high threshold 89 assert: value 1.67772e+07 raw data nan</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>satellitesensor[2351]</td><td>Sensor HGX_GPU_1_TEMP_1 high threshold 87 assert: value 1.67772e+07 raw data nan</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>phosphor-fru-fault-monitor[524]</td><td>/xyz/openbmc_project/logging/entry/496 created</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>phosphor-fru-fault-monitor[524]</td><td>/xyz/openbmc_project/logging/entry/497 created</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>sensor-monitor[499]</td><td>Starting 1000ms HardShutdownAlarmHigh shutdown timer due to sensor /xyz/openbmc_project/sensors/temperature/HGX_GPU_0_TEMP_1 value 16777214</td></tr></tbody></table></div><blockquote><p><strong>Warning:</strong> Your GPU should not reach 16,777,214 Celsius during boot. Imagine what would happen under load!</p></blockquote><p>This took some time to debug, as I was quite sure the sensors could not physically handle reading temperatures over 16 million Celsius… But then I noticed something interesting about that specific number:</p><div><table><thead><tr><th>Decimal</th><th>Binary</th><th>Hex</th></tr></thead><tbody><tr><td>16,777,214</td><td>1111 1111 1111 1111 1111 1110</td><td>0xFFFFFE</td></tr></tbody></table></div><p>This is <code>2²⁴ - 2</code>, which is suspiciously close to the maximum value of a 24-bit unsigned integer. In the hardware world, this is the equivalent of a sensor throwing up its hands and screaming “I have no idea what’s happening!” When hardware can’t read a value properly—whether due to a loose connection, damaged circuit, or initialization failure—it often returns the maximum (or near-maximum) representable value. It’s like the digital version of a shrug.</p><p>The logs confirmed this theory: seeing <code>1.67772e+07</code> (16,777,214) wasn’t evidence that my GPU had achieved nuclear fusion temperatures 🔥—it was evidence that the temperature sensor had simply stopped working. And if a sensor error is intermittent, the most likely culprit is a loose connection or physical damage.</p><p>After spending way too long pursuing software solutions (because who wants to disassemble everything <em>again</em>?), I finally accepted the inevitable and broke out the screwdrivers.</p><p><a href="https://dnhkng.github.io/assets/img/fix.jpg"><img src="https://dnhkng.github.io/assets/img/fix.jpg" alt="Fix" loading="lazy"></a></p><p>I happened to have bought a new microscope earlier this year, and it turned out to be the perfect tool for diagnosing and fixing the issue. Near one of the modules, I found some damaged surface mount components. The damage must have happened after cleaning, probably during the reassembly of the modules with the copper adapters. They weigh over 2 kg, so a slight bump would have easily caused this damage. Amazingly, the tiny components were still attached to the traces, and so I could measure them easily: a 100 nF capacitor, and 4.7k resistor (both of which I had on-hand, as they are standard values for decoupling circuits). The bad news? I had huge “0805” sized parts (2mm long), these were tiny “0402” (1mm long). And one of the traces was just gone.</p><p>With some very fiddly soldering, and scratching off the solder mask on the PCB to expose more trace, I was able to ‘free solder’ the parts into a wonderful 3D sculpture which was then liberally coated in UV-curing mask resin, set, and then held in place with sticky tape. Very professional. After reassembly, the system booted smoothly.</p><h2 id="final-touches"><span>Final Touches</span><a href="#final-touches"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/touches.jpg"><img src="https://dnhkng.github.io/assets/img/touches.jpg" alt="Fix" loading="lazy"></a></p><p>I 3D printed a few extra parts:</p><ul><li>Mounts for the E1.S 8TB SSD I found cheap online</li><li>A full rear-panel, that mounts the 3KW 48V power supply</li><li>Cool-looking mesh to protect the water-cooling radiators and dust filters</li></ul><p>Getting the actual GPU working was also painful, so I’ll leave the details here for future adventurers:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td><pre># Data Center/HGX-Series/HGX H100/Linux aarch64/12.8 seem to work!
wget https://us.download.nvidia.com/tesla/570.195.03/NVIDIA-Linux-aarch64-570.195.03.run

# Tell the driver to completely ignore the NVLINK and it should allow the GPUs to initialise independently over PCIe !!!!   This took a week of work to find, thanks Reddit!

# create a modprobe config file:
sudo nano /etc/modprobe.d/nvidia-disable-nvlink.conf

# add the driver option
options nvidia NVreg_NvLinkDisable=1

# update the boot files:
sudo update-initramfs -u

# reboot
sudo reboot
</pre></td></tr></tbody></table></code></p></div><h2 id="benchmarks"><span>Benchmarks</span><a href="#benchmarks"><i></i></a></h2><p>That’s what you’re here for, maybe? I have only just started, but after compiling the latest Llama.cpp version using 144 cores in 90 seconds, here’s some benchmarks on larger LLMs:</p><p><a href="https://dnhkng.github.io/assets/img/benchmarks.jpg"><img src="https://dnhkng.github.io/assets/img/benchmarks.jpg" alt="Benchmarks" loading="lazy"></a></p><div><table><thead><tr><th>Model</th><th>Prompt Processing</th><th>Token Generation</th></tr></thead><tbody><tr><td>gpt-oss-120b-Q4_K_M</td><td>2974.79</td><td>195.84</td></tr><tr><td>GLM-4.5-Air-Q4_K_M</td><td>1936.65</td><td>100.71</td></tr><tr><td>Qwen3-235B-A22B-Instruct-2507-Q4_K</td><td>1022.79</td><td>65.90</td></tr></tbody></table></div><p>This is pretty unoptimized, but it’s looking promising so far! During the LLM tests I hit around 300W per GPU, far from the 900W max.</p><h2 id="cost-breakdown"><span>Cost Breakdown</span><a href="#cost-breakdown"><i></i></a></h2><p>Here’s what the entire build actually cost me, from the initial purchase to the final touches:</p><div><table><thead><tr><th>Component</th><th>Description</th><th>Cost (EUR)</th></tr></thead><tbody><tr><td>Grace-Hopper Server</td><td>2x GH200 superchips with H100 GPUs (the Frankenstein special)</td><td>€7,500</td></tr><tr><td>Storage</td><td>‘like-new’ used 8TB E1.S NVMe SSD</td><td>€250</td></tr><tr><td>Custom Water Cooling Adapters</td><td>2x CNC-milled copper mounting plates for AIO coolers</td><td>€700</td></tr><tr><td>AIO Water Coolers</td><td>4x Arctic Liquid Freezer III 420 (B-Ware)</td><td>€180</td></tr><tr><td>Structural Frame</td><td>Extruded aluminum profiles, pre-cut and delivered</td><td>€200</td></tr><tr><td>3D Printing Filament</td><td>1kg black PLA for custom mounts and brackets</td><td>€20</td></tr><tr><td>Hardware</td><td>Nuts, bolts, and mounting hardware</td><td>€50</td></tr><tr><td>Cleaning Supplies</td><td>5 liters of 99.9% isopropanol (used liberally throughout)</td><td>€20</td></tr><tr><td>Aesthetics</td><td>LED lighting strip (because RGB makes it faster)</td><td>€10</td></tr><tr><td><strong>Total</strong></td><td>&nbsp;</td><td><strong>€8,930</strong></td></tr></tbody></table></div><p>Not included: hearing protection (absolutely necessary), the microscope I already owned (but proved essential), several failed 3D prints, and the emotional cost of seeing “16,777,214°C” in system logs.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>So, was it worth it? I now have a desktop that can run 235B parameter models at home for less than the cost of a single H100. It required disassembling $80,000 worth of enterprise hardware, debugging sensors that reported temperatures approaching the surface of the sun, and free-soldering components under a microscope. Your mileage may vary. Literally: I had to drive two hours to pick this thing up.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The future of Terraform CDK (123 pts)]]></title>
            <link>https://github.com/hashicorp/terraform-cdk</link>
            <guid>46222165</guid>
            <pubDate>Wed, 10 Dec 2025 19:14:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hashicorp/terraform-cdk">https://github.com/hashicorp/terraform-cdk</a>, See on <a href="https://news.ycombinator.com/item?id=46222165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">The Future of Terraform CDK</h2><a id="user-content-the-future-of-terraform-cdk" aria-label="Permalink: The Future of Terraform CDK" href="#the-future-of-terraform-cdk"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sunset Notice</h2><a id="user-content-sunset-notice" aria-label="Permalink: Sunset Notice" href="#sunset-notice"></a></p>
<p dir="auto">Terraform CDK (CDKTF) will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date. Unfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem.</p>
<p dir="auto">As of December 10, 2025, Terraform CDK will be archived on GitHub, and the documentation will reflect its deprecated status. The archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements (including compatibility updates) will be made.</p>
<p dir="auto">You will be able to continue to use Terraform CDK at your own risk. Terraform CDK is licensed under the Mozilla Public License (MPL). HashiCorp, an IBM Company, does not apply any additional restrictions. We encourage community forks if there’s interest in continuing development independently.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Migration to HCL</h2><a id="user-content-migration-to-hcl" aria-label="Permalink: Migration to HCL" href="#migration-to-hcl"></a></p>
<p dir="auto">You can use the following command to generate Terraform-compatible .tf files directly from your Terraform CDK project:</p>
<p dir="auto"><code>cdktf synth --hcl</code></p>
<p dir="auto">This will produce readable HCL configuration files, making it easier to migrate away from Terraform CDK. After running the command, you can use standard Terraform CLI commands (<code>terraform init</code>, <code>terraform plan</code>, <code>terraform apply</code>) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Note on AWS CDK</h3><a id="user-content-note-on-aws-cdk" aria-label="Permalink: Note on AWS CDK" href="#note-on-aws-cdk"></a></p>
<p dir="auto">If your infrastructure is defined in Terraform CDK but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem. If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto">Q: Is CDKTF still being developed?</p>
<p dir="auto">A: No. CDKTF will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date.</p>
<p dir="auto">Q: Why is CDKTF being sunset?</p>
<p dir="auto">A: CDKTF did not find product-market fit at scale. We’ve chosen to focus our investments on Terraform core and its broader ecosystem.</p>
<p dir="auto">Q: Will CDKTF be removed from GitHub?</p>
<p dir="auto">A: CDKTF will be archived on GitHub, and documentation will reflect its deprecated status.</p>
<p dir="auto">Q: Can I still use CDKTF after it's sunset?</p>
<p dir="auto">A: Yes, the archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements will be made.</p>
<p dir="auto">Q: Will CDKTF continue to support new versions of Terraform or providers?</p>
<p dir="auto">A: No. Compatibility updates will not be made after the EOL date.</p>
<p dir="auto">Q: Can I fork CDKTF and maintain it myself?</p>
<p dir="auto">A: Yes. CDKTF is open source, and we encourage community forks if there’s interest in continuing development independently.</p>
<p dir="auto">Q: Can I keep using CDKTF?</p>
<p dir="auto">A: You may continue to use it at your own risk. HashiCorp, an IBM Company, will no longer be maintaining it.</p>
<p dir="auto">Q: Is there a migration tool?</p>
<p dir="auto">A: You can use the following command to generate Terraform-compatible .tf files directly from your CDKTF project:</p>
<p dir="auto"><code>cdktf synth --hcl</code></p>
<p dir="auto">This will produce readable HCL configuration files, making it easier to migrate away from CDKTF. After running the command, you can use standard Terraform CLI commands (terraform init, terraform plan, terraform apply) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.</p>
<p dir="auto">Q: What migration guidance can we provide to customers?</p>
<p dir="auto">A: For users looking to migrate away from CDKTF:</p>
<p dir="auto">If your infrastructure is defined in CDKTF but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem.</p>
<p dir="auto">If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.</p>
<hr>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hashicorp/terraform-cdk/workflows/Release/badge.svg"><img src="https://github.com/hashicorp/terraform-cdk/workflows/Release/badge.svg" alt=""></a>
<a href="https://badge.fury.io/js/cdktf" rel="nofollow"><img src="https://camo.githubusercontent.com/10ce5cc6a21f56b89861b61ba073172f046370b8e1c4e40ce900926cfe14be10/68747470733a2f2f62616467652e667572792e696f2f6a732f63646b74662e737667" alt="npm version" data-canonical-src="https://badge.fury.io/js/cdktf.svg"></a>
<a href="https://badge.fury.io/py/cdktf" rel="nofollow"><img src="https://camo.githubusercontent.com/b8c9163a6c7596a5d407c29c4906776d19fa5f8a6cf23758ba20f000b8091abf/68747470733a2f2f62616467652e667572792e696f2f70792f63646b74662e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/cdktf.svg"></a>
<a href="https://badge.fury.io/nu/HashiCorp.Cdktf" rel="nofollow"><img src="https://camo.githubusercontent.com/7566fa476d9e6e443710536cb5e5635f7e297c1593868fef94b077f9b6d85e11/68747470733a2f2f62616467652e667572792e696f2f6e752f4861736869436f72702e43646b74662e737667" alt="NuGet version" data-canonical-src="https://badge.fury.io/nu/HashiCorp.Cdktf.svg"></a>
<a href="https://search.maven.org/artifact/com.hashicorp/cdktf" rel="nofollow"><img src="https://camo.githubusercontent.com/0330c15b9403354d389b692ffd865dc136d878ec8fc9b336da962625aad35b30/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f636f6d2e6861736869636f72702f63646b74663f636f6c6f723d627269676874677265656e" alt="Maven Central" data-canonical-src="https://img.shields.io/maven-central/v/com.hashicorp/cdktf?color=brightgreen"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">CDK for Terraform</h2><a id="user-content-cdk-for-terraform" aria-label="Permalink: CDK for Terraform" href="#cdk-for-terraform"></a></p>
<p dir="auto">Cloud Development Kit for Terraform (CDKTF) allows you to use familiar
programming languages to define cloud infrastructure and provision it through
HashiCorp Terraform. This gives you access to the entire Terraform ecosystem without learning HashiCorp Configuration Language (HCL) and lets you leverage the power of your existing toolchain for testing, dependency management, etc.</p>
<p dir="auto">We currently support TypeScript, Python, Java, C#, and Go.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hashicorp/terraform-cdk/blob/main/docs/terraform-platform.png"><img src="https://github.com/hashicorp/terraform-cdk/raw/main/docs/terraform-platform.png" alt="terraform platform"></a></p>
<p dir="auto">CDKTF includes two packages:</p>
<ul dir="auto">
<li><a href="https://github.com/hashicorp/terraform-cdk/blob/main/packages/cdktf-cli">cdktf-cli</a> - A CLI that allows users to run commands to initialize, import, and synthesize CDK for Terraform applications.</li>
<li><a href="https://github.com/hashicorp/terraform-cdk/blob/main/packages/cdktf">cdktf</a> - A library for defining Terraform resources using programming constructs.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto">Choose a language:</p>
<ul dir="auto">
<li><a href="https://developer.hashicorp.com/terraform/tutorials/cdktf/cdktf-build?in=terraform%2Fcdktf&amp;variants=cdk-language%3Atypescript" rel="nofollow">TypeScript</a></li>
<li><a href="https://developer.hashicorp.com/terraform/tutorials/cdktf/cdktf-build?in=terraform%2Fcdktf&amp;variants=cdk-language%3Apython" rel="nofollow">Python</a></li>
<li><a href="https://developer.hashicorp.com/terraform/tutorials/cdktf/cdktf-build?in=terraform%2Fcdktf&amp;variants=cdk-language%3Ajava" rel="nofollow">Java</a></li>
<li><a href="https://developer.hashicorp.com/terraform/tutorials/cdktf/cdktf-build?in=terraform%2Fcdktf&amp;variants=cdk-language%3Acsharp" rel="nofollow">C#</a></li>
<li><a href="https://developer.hashicorp.com/terraform/tutorials/cdktf/cdktf-build?in=terraform%2Fcdktf&amp;variants=cdk-language%3Ago" rel="nofollow">Go</a></li>
</ul>
<blockquote>
<p dir="auto"><strong>Hands-on:</strong> Try the tutorials in the <a href="https://learn.hashicorp.com/collections/terraform/cdktf" rel="nofollow">CDK for Terraform</a> collection on HashiCorp Learn.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Refer to the <a href="https://developer.hashicorp.com/terraform/cdktf" rel="nofollow">CDKTF documentation</a> for more detail about how to build and manage CDKTF applications, including:</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://developer.hashicorp.com/terraform/cdktf/concepts/cdktf-architecture" rel="nofollow">Application Architecture</a>: Learn the tools and processes that CDKTF uses to leverage the Terraform ecosystem and convert code into Terraform configuration files. It also explains the major components of a CDKTF application and how those pieces fit together.</p>
</li>
<li>
<p dir="auto"><a href="https://developer.hashicorp.com/terraform/cdktf/create-and-deploy/project-setup" rel="nofollow">Project Setup</a>: Learn how to create a new CDKTF project from a pre-built or custom template. Also learn how to convert an existing HCL project into a CDKTF application.</p>
</li>
<li>
<p dir="auto"><a href="https://developer.hashicorp.com/terraform/cdktf/test/unit-tests" rel="nofollow">Unit Tests</a>: Learn how to test your application in Typescript with jest.</p>
</li>
<li>
<p dir="auto"><a href="https://developer.hashicorp.com/terraform/cdktf/examples-and-guides/examples" rel="nofollow">Examples</a>: Reference example projects in every supported language and review explanatory videos and other resources.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">The development team would love your feedback to help guide the project.</p>
<ul dir="auto">
<li>Contribute using the <a href="https://github.com/hashicorp/terraform-cdk/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> guide.</li>
<li>Ask a question on the HashiCorp <a href="https://discuss.hashicorp.com/" rel="nofollow">Discuss</a> using the <a href="https://discuss.hashicorp.com/c/terraform-core/cdk-for-terraform/" rel="nofollow">terraform-cdk</a> category.</li>
<li>Report a <a href="https://github.com/hashicorp/terraform-cdk/issues/new?assignees=&amp;labels=bug&amp;template=bug-report.md&amp;title=">bug</a> or request a new <a href="https://github.com/hashicorp/terraform-cdk/issues/new?assignees=&amp;labels=enhancement&amp;template=feature-request.md&amp;title=">feature</a>.</li>
<li>Browse all <a href="https://github.com/hashicorp/terraform-cdk/issues">open issues</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build</h2><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<p dir="auto">For prerequisites, refer to the <a href="https://github.com/hashicorp/terraform-cdk/blob/main/CONTRIBUTING.md#prerequisites">following</a>.</p>
<p dir="auto">Clone the project repository.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/hashicorp/terraform-cdk.git"><pre>git clone https://github.com/hashicorp/terraform-cdk.git</pre></div>
<p dir="auto">Download dependencies.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd terraform-cdk/
yarn install"><pre><span>cd</span> terraform-cdk/
yarn install</pre></div>
<p dir="auto">Build the project and packages.</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Super Mario 64 for the PS1 (266 pts)]]></title>
            <link>https://github.com/malucard/sm64-psx</link>
            <guid>46221925</guid>
            <pubDate>Wed, 10 Dec 2025 18:58:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/malucard/sm64-psx">https://github.com/malucard/sm64-psx</a>, See on <a href="https://news.ycombinator.com/item?id=46221925">Hacker News</a></p>
<div id="readability-page-1" class="page"><p dir="auto">This repo does not include all assets necessary for compiling the game.
An original copy of the game is required to extract the assets.</p><div data-snippet-clipboard-copy-content="sm64
├── actors: object behaviors, geo layout, and display lists
├── assets: animation and demo data
│   ├── anims: animation data
│   └── demos: demo data
├── bin: C files for ordering display lists and textures
├── build: output directory
├── data: behavior scripts, misc. data
├── doxygen: documentation infrastructure
├── enhancements: example source modifications
├── include: header files
├── levels: level scripts, geo layout, and display lists
├── lib: N64 SDK code
├── sound: sequences, sound samples, and sound banks
├── src: C source code for game
│   ├── audio: audio code
│   ├── buffers: stacks, heaps, and task buffers
│   ├── engine: script processing engines and utils
│   ├── game: behaviors and rest of game source
│   ├── goddard: rewritten Mario intro screen
│   ├── goddard_og: backup of original Mario intro screen
│   ├── menu: title screen and file, act, and debug level selection menus
│   └── port: port code, audio and video renderer
├── text: dialog, level names, act names
├── textures: skybox and generic texture data
└── tools: build tools"><pre><code>sm64
├── actors: object behaviors, geo layout, and display lists
├── assets: animation and demo data
│   ├── anims: animation data
│   └── demos: demo data
├── bin: C files for ordering display lists and textures
├── build: output directory
├── data: behavior scripts, misc. data
├── doxygen: documentation infrastructure
├── enhancements: example source modifications
├── include: header files
├── levels: level scripts, geo layout, and display lists
├── lib: N64 SDK code
├── sound: sequences, sound samples, and sound banks
├── src: C source code for game
│   ├── audio: audio code
│   ├── buffers: stacks, heaps, and task buffers
│   ├── engine: script processing engines and utils
│   ├── game: behaviors and rest of game source
│   ├── goddard: rewritten Mario intro screen
│   ├── goddard_og: backup of original Mario intro screen
│   ├── menu: title screen and file, act, and debug level selection menus
│   └── port: port code, audio and video renderer
├── text: dialog, level names, act names
├── textures: skybox and generic texture data
└── tools: build tools
</code></pre></div><p dir="auto">Pull requests are welcome. For major changes, please open an issue first to
discuss what you would like to change.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise (141 pts)]]></title>
            <link>https://arxiv.org/abs/2512.08309</link>
            <guid>46221594</guid>
            <pubDate>Wed, 10 Dec 2025 18:37:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.08309">https://arxiv.org/abs/2512.08309</a>, See on <a href="https://news.ycombinator.com/item?id=46221594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.08309">View PDF</a>
    <a href="https://arxiv.org/html/2512.08309v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Alexander Goslin [<a href="https://arxiv.org/show-email/c780ef89/2512.08309" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 9 Dec 2025 07:10:35 UTC (12,075 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Automated license plate reader coverage in the USA (209 pts)]]></title>
            <link>https://alpranalysis.com</link>
            <guid>46220794</guid>
            <pubDate>Wed, 10 Dec 2025 17:42:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alpranalysis.com">https://alpranalysis.com</a>, See on <a href="https://news.ycombinator.com/item?id=46220794">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Is it a bubble? (264 pts)]]></title>
            <link>https://www.oaktreecapital.com/insights/memo/is-it-a-bubble</link>
            <guid>46220640</guid>
            <pubDate>Wed, 10 Dec 2025 17:30:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oaktreecapital.com/insights/memo/is-it-a-bubble">https://www.oaktreecapital.com/insights/memo/is-it-a-bubble</a>, See on <a href="https://news.ycombinator.com/item?id=46220640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							
							<!-- Text to Speech Conditional Wrapper -->
							<!-- End -->
							<p>Ours is a remarkable moment in world history.  A transformative technology is ascending, and its supporters claim it will forever change the world.  To build it requires companies to invest a sum of money unlike anything in living memory.  News reports are filled with widespread fears that America’s biggest corporations are propping up a bubble that will soon pop.  </p><p>During my visits to clients in Asia and the Middle East last month, I was often asked about the possibility of a bubble surrounding artificial intelligence, and my discussions gave rise to this memo.  I want to start off with my usual caveats: I’m not active in the stock market; I merely watch it as the best barometer of investor psychology.  I’m also no techie, and I don’t know any more about AI than most generalist investors.  But I’ll do my best.</p><p>One of the most interesting aspects of bubbles is their regularity, not in terms of timing, but rather the progression they follow.  Something new and seemingly revolutionary appears and worms its way into people’s minds.  It captures their imagination, and the excitement is overwhelming.  The early participants enjoy huge gains.  Those who merely look on feel incredible envy and regret and – motivated by the fear of continuing to miss out – pile in.  They do this without knowledge of what the future will bring or concern about whether the price they’re paying can possibly be expected to produce a reasonable return with a tolerable amount of risk.  The end result for investors is inevitably painful in the short to medium term, although it’s possible to end up ahead after enough years have passed.</p><p>I’ve lived through several bubbles and read about others, and they’ve all hewed to this description.  One might think the losses experienced when past bubbles popped would discourage the next one from forming.  But that hasn’t happened yet, and I’m sure it never will.  <strong>Memories are short, and prudence and natural risk aversion are no match for the dream of getting rich on the back of a revolutionary technology that “everyone knows” will change the world. </strong></p><p>I took the quote that opens this memo from Derek Thompson’s November 4 newsletter entitled “AI Could Be the Railroad of the 21<sup>st</sup> Century.  Brace Yourself,” about parallels between what’s going on today in AI and the railroad boom of the 1860s.  Its word-for-word applicability to both shows clearly what’s meant by the phrase widely attributed to Mark Twain: “history rhymes.”</p><p><span>Understanding Bubbles</span></p><p>Before diving into the subject at hand – and having read a great deal about it in preparation – <strong>I want to start with a point of clarification.  Everyone asks, “Is there a bubble in AI?”  I think there’s ambiguity even in the question.  I’ve concluded there are two different but interrelated bubble possibilities to think about: one in the behavior of companies <span>within</span> the industry, and the other in how investors are behaving <span>with regard to</span> the industry.</strong> I have absolutely no ability to judge whether the AI companies’ aggressive behavior is justified, so I’ll try to stick primarily to the question of whether there’s a bubble around AI in the financial world.</p><p>The main job of an investment analyst – especially in the so-called “value” school to which I subscribe – is to (a) study companies and other assets and assess the level of and outlook for their intrinsic value and (b) make investment decisions on the basis of that value.  Most of the change the analyst encounters in the short to medium term surrounds the asset’s price and its relationship to underlying value.  That relationship, in turn, is essentially the result of investor psychology.</p><p>Market bubbles aren’t caused directly by technological or financial developments.  Rather, they result from the application of excessive optimism to those developments.  As I wrote in my January memo <a href="https://www.oaktreecapital.com/insights/memo/on-bubble-watch" data-sf-ec-immutable=""><em>On Bubble Watch</em></a>, bubbles are temporary manias in which developments in those areas become the subject of what former U.S. Federal Reserve Chairman Alan Greenspan called “irrational exuberance.’’</p><p>Bubbles usually coalesce around new financial developments (e.g., the South Sea Company of the early 1700s or sub-prime residential mortgage-backed securities in 2005-06) or technological progress (optical fiber in the late 1990s and the internet in 1998-2000).  <strong>Newness plays a huge part in this.  Because there’s no history to restrain the imagination, the future can appear limitless for the new thing.  And futures that are perceived to be limitless can justify valuations that go well beyond past norms – leading to asset prices that aren’t justified on the basis of predictable earning power.</strong></p><p>The role of newness is well described in my favorite passage from a book that greatly influenced me, <em>A Short History of Financial Euphoria</em> by John Kenneth Galbraith.  Galbraith wrote about what he called “the extreme brevity of the financial memory” and pointed out that in the financial markets, “past experience, to the extent that it is part of memory at all, is dismissed as the primitive refuge of those who do not have the insight to appreciate the incredible wonders of the present.”  In other words, history can impose limits on awe regarding the present and imagination regarding the future.  In the absence of history, on the other hand, all things seem possible.</p><p><strong>The key thing to note here is that the new thing understandably inspires great enthusiasm, but bubbles are what happen when the enthusiasm reaches irrational proportions.  </strong>Who can identify the boundary of rationality?  Who can say when an optimistic market has become a bubble?  It’s just a matter of judgment.  </p><p>Something that occurred to me this past month is that two of my best “calls” came in 2000, when I cautioned about what was going on in the market for tech and internet stocks, and in 2005-07, when I cited the dearth of risk aversion and the resulting ease of doing crazy deals in the pre-Global Financial Crisis world.  </p><ul><li data-list="2" data-level="1"><p>First, in neither case did I possess any expertise regarding the things that turned out to be the subjects of the bubbles: the internet and sub-prime mortgage-backed securities.  All I did was render observations regarding the behavior taking place around me.  </p></li><li data-list="2" data-level="1"><p>And second, the value in my calls consisted mostly of describing the folly in that behavior, not in insisting that it had brought on a bubble.  </p></li></ul><p><strong>Struggling with whether to apply the “bubble” label can bog you down and interfere with proper judgment; we can accomplish a great deal by merely assessing what’s going on around us and drawing inferences with regard to proper behavior.</strong></p><p><span>What’s Good About Bubbles?</span></p><p>Before going on to discuss AI and whether it’s presently in a bubble, I want to spend a little time on a subject that may seem somewhat academic from the standpoint of investors: the upside of bubbles.  You may find the attention I devote to this topic excessive, but I do so because I find it fascinating.</p><p>The November 5 <em>Stratechery</em> newsletter was entitled “The Benefits of Bubbles.”  In it, Ben Thompson (no relation to Derek) cites a book titled <em>Boom: Bubbles and the End of Stagnation</em>. It was written by Byrne Hobart and Tobias Huber, who propose that there are two kinds of bubbles:</p><p>. . . “Inflection Bubbles” – the good kind of bubbles, as opposed to the much more damaging “Mean-reversion Bubbles” like the 2000’s subprime mortgage bubble. </p><p>I find this a useful dichotomy.  </p><ul><li data-list="2" data-level="1"><p>The financial fads I’ve read about or witnessed – the South Sea Company, portfolio insurance, and sub-prime mortgage-backed securities – stirred the imagination based on the promise of returns without risk, but there was no expectation that they would represent overall progress for mankind.  There was, for example, no thought that housing would be revolutionized by the sub-prime mortgage movement, merely a feeling that there was money to be made from backing new buyers.  Hobart and Huber call these “mean-reverting bubbles,” presumably because there’s no expectation that the underlying developments would move the world forward.  Fads merely rise and fall.</p></li><li data-list="2" data-level="1"><p>On the other hand, Hobart and Huber call bubbles based on technological progress – as in the case of the railroads and the internet – “inflection bubbles.”  After an inflection-driven bubble, the world will not revert to its prior state.  In such a bubble, “investors decide that the future will be meaningfully different from the past and trade accordingly.”  As Thompson tells us:</p></li></ul><p>The definitive book on bubbles has long been Carlota Perez’s <em>Technological Revolutions and Financial Capital</em>. Bubbles were – are – thought to be something negative and to be avoided, particularly at the time Perez published her book.  The year was 2002 and much of the world was in a recession coming off the puncturing of the dot-com bubble.</p><p>Perez didn’t deny the pain: in fact, she noted that similar crashes marked previous revolutions, including the Industrial Revolution, railways, electricity, and the automobile.  In each case the bubbles were not regrettable, but necessary: <strong>the speculative mania enabled what Perez called the “Installation Phase,” where necessary but not necessarily financially wise investments laid the groundwork for the “Deployment Period.”  What marked the shift to the deployment period was the popping of the bubble; <span>what enabled the deployment period were the money-losing investments.</span></strong> (All emphasis added)</p><p>This distinction is very meaningful for Hobart and Huber, and I agree.  They say, “not all bubbles destroy wealth and value.  Some can be understood as important catalysts for techno-scientific progress.”  </p><p>But I would restate as follows: “Mean-reversion bubbles” – in which markets soar on the basis of some new financial miracle and then collapse – destroy wealth.  On the other hand, “inflection bubbles” based on revolutionary developments accelerate technological progress and create the foundation for a more prosperous future, <strong>and they destroy wealth</strong>. The key is to not be one of the investors whose wealth is destroyed in the process of bringing on progress.</p><p>Hobart and Huber go on to describe in greater depth the process through which bubbles finance the building of the infrastructure required by the new technology and thus accelerate its adoption:</p><p>Most novel technology doesn’t just appear <em>ex nihilo</em> [i.e., from nothing], entering the world fully formed and all at once.  Rather, it builds on previous false starts, failures, iterations, and historical path dependencies.  Bubbles create opportunities to deploy the capital necessary to fund and speed up such large-scale experimentation – which includes lots of trial and error done in parallel – thereby accelerating the rate of potentially disruptive technologies and breakthroughs. </p><p>By generating positive feedback cycles of enthusiasm and investment, bubbles can be net beneficial.  Optimism can be a self-fulfilling prophecy.  Speculation provides the massive financing needed to fund highly risky and exploratory projects; what appears in the short term to be excessive enthusiasm or just bad investing turns out to be essential for bootstrapping social and technological innovations . . .  A bubble can be a collective delusion, but it can also be an expression of collective vision.  That vision becomes a site of coordination for people and capital and for the parallelization of innovation.  Instead of happening over time, bursts of progress happen simultaneously across different domains.  And with mounting enthusiasm . . . comes increased risk tolerance and strong network effects.  The fear of missing out, or FOMO, attracts even more participants, entrepreneurs, and speculators, further reinforcing this positive feedback loop.  Like bubbles, FOMO tends to have a bad reputation, but it’s sometimes a healthy instinct.  After all, none of us wants to miss out on a once-in-a-lifetime chance to build the future.</p><p>In other words, bubbles based on technological progress are good because they excite investors into pouring in money – a good bit of which is thrown away – to carpet-bomb a new area of opportunity and thus jump-start its exploitation.  </p><p><strong>The key realization seems to be that if people remained patient, prudent, analytical, and value-insistent, novel technologies would take many years and perhaps decades to be built out.  Instead, the hysteria of the bubble causes the process to be compressed into a very short period – with some of the money going into life-changing investment in the winners but a lot of it being incinerated. </strong></p><p><strong>A bubble has aspects that are both technological and financial, but the above citations are from the standpoint of people who crave technological progress and are perfectly happy to see investors lose money in its interest.  “We,” on the other hand, would like to see technological progress but have no desire to throw away money to help bring it about.</strong></p><p>Ben Thompson ends this discussion by saying, “This is why I’m excited to talk about new technologies, the prospect for which <em>I don’t know</em>.” I love the fact that he’s excited by future possibilities and at the same time admits that the shape of the future is unknown (in our world, we might say “very risky”).</p><p><span>Assessing the Current Landscape</span></p><p>Now let’s get down to what we used to call “brass tacks.”  What do we know?  First, I haven’t met anyone who doesn’t believe artificial intelligence has the potential to be one of the biggest technological developments of all time, reshaping both daily life and the global economy.</p><p>We also know that in recent years, economies and markets have become increasingly dependent on AI:</p><ul><li data-list="3" data-level="1"><p>AI is responsible for a very large portion of companies’ total capital expenditures.</p></li><li data-list="3" data-level="1"><p>Capital expenditures on AI capacity account for a large share of the growth in U.S. GDP.</p></li><li data-list="3" data-level="1"><p>AI stocks have been the source of the vast majority of the gains of the S&amp;P 500.</p></li></ul><p>As a <em>Fortune</em> headline put it on October 7: </p><p>75% of gains, 80% of profits, 90% of capex – AI’s grip on the S&amp;P is total and Morgan Stanley’s top analyst is ‘very concerned’</p><p>Further, I think it’s important to note that whereas the gains in AI-related stocks account for a disproportionate percentage of the total gains in all stocks, the excitement AI injects into the market must have added a lot to the appreciation of non-AI stocks as well.</p><p>AI-related stocks have shown astronomical performance, led by Nvidia, the leading developer of computer chips for AI.  From its formation in 1993 and its initial public offering in 1999, when its estimated market value was $626 million, Nvidia briefly became the world’s first company worth $5 trillion.  That’s appreciation of around 8,000x, or roughly 40% a year for 26+ years.  No wonder imaginations have been fired.  </p><p><span>What Are the Areas of Uncertainty?</span></p><p>I think it’s fair to say that while we know AI will be a source of incredible change, most of us have no idea exactly what it will be able to do, how it will be applied commercially, or what the timing will be.  </p><p><strong>Who will be the winners, and what will they be worth?</strong> If a new technology is assumed to be a world changer, it’s invariably assumed that the leading companies possessing that technology will be of great value.  But how accurate will that assumption prove to be?  As Warren Buffett pointed out in 1999, “[The automobile was] the most important invention, probably, of the first half of the 20<sup>th</sup> century. . . .  If you had seen at the time of the first cars how this country would develop in connection with autos, you would have said, ‘This is the place I must be.’  But of the 2,000 companies, as of a few years ago, only three car companies survived.  So autos had an enormous impact on America but the opposite direction on investors.” (<em>Time</em>, January 23, 2012)</p><p>In AI, there are some very strong leaders at present, including some of the world’s strongest and richest companies.  But new technology is notoriously disruptive.  Will today’s leaders prevail or give way to upstarts?  How much will the arms race cost, and who will win?</p><p><strong>Similarly, what’s a share in an upstart worth?</strong> Unlike front runners worth trillions, it’s possible to invest in some would-be challengers at enterprise values in mere billions or even – might I say? – millions.  On June 25, 2024, CNBC reported as follows:  </p><p>A team founded by college dropouts has raised $120 million from investors led by Primary Venture Partners to build a new AI chip to take on Nvidia.  Etched CEO Gavin Uberti said the startup is betting that as AI develops, most of the technology’s power-hungry computing requirements will be filled by customized, hard-wired chips called ASICs.  “If transformers go away, we’ll die,” Uberti told CNBC. “But if they stick around, we’re the biggest company of all time.”</p><p>Even granting the possibility that Etched won’t become the biggest company of all time, if success could give them a valuation just one-fifth of Nvidia’s peak – a mere $1 trillion – what probability of success would be required to justify an investment of $120 million?  Assuming for simplicity’s sake that the investment was for a 100% ownership stake, all you need is a belief that achieving the trillion-dollar value has a probability of one-tenth of a percent for an expected return of over eight times your money.  Who’s to say Etched doesn’t have that chance?  And in that case, why would anyone not play?  The foregoing is what I call “lottery-ticket thinking,” in which the dream of an enormous payoff justifies – no, compels – participation in an endeavor with an overwhelming probability of failing.  </p><p>There’s nothing wrong with calculating expected values this way.  Leading venture capitalists engage in it every day to great effect.  But assumptions regarding the possible payoffs and their probabilities must be reasonable.  Thinking about a trillion-dollar payout will override reasonableness in any calculation.</p><p><strong>Will AI produce profits, and for whom?  Two things</strong> we know little or nothing about are the profits AI will produce for vendors and its impact on non-AI companies, primarily meaning those who employ it.  </p><p>Will AI be a monopoly or duopoly, in which one or two leading companies are able to charge dearly for the capabilities?  Or will it be a highly competitive free-for-all in which a number of firms compete on price for users’ spending on AI services, making it a commodity?  Or, perhaps most likely, will it be a mix of leading companies and specialized players, some of whom compete on price and others through proprietary advantages.  It’s said that the services currently responding to AI queries, such as ChatGPT and Gemini, lose money on every query they answer (of course, it’s not unusual for participants in a new industry to offer “loss leaders” for a while).  Will the leading tech firms – used to success in winner-take-all markets – be content to experience losses in their AI businesses for years in order to gain share?  Hundreds of billions of dollars are being committed to the race for AI leadership.  Who will win, and what will be the result?</p><p>Likewise, what will be AI’s impact on the companies that use it?  Clearly, AI will be a great tool for enhancing users’ productivity by, among other things, replacing workers with computer-sourced labor and intelligence.  But will this ability to cut costs add to the profit margins of the companies that employ it?  Or will it simply enable price wars among those companies in the pursuit of customers?  In that case, the savings might be passed on to the customers rather than garnered by the companies.  In other words, is it possible AI will increase the efficiency of businesses without increasing their profitability?</p><p><strong>Should we worry about so-called “circular deals”?</strong> In the telecom boom of the late 1990s, in which optical fiber became overbuilt, fiber-owning companies engaged in transactions with each other that permitted them to report profits.  If two companies own fiber, they just have an asset on their books.  But if each buys capacity from the other, they can both report profits . . . so they did.  In other cases, manufacturers loaned network operators money to buy equipment from them, before the operators had customers to justify the buildout.  All this resulted in profits that were illusory.</p><p>Nowadays, deals are being announced in which money appears to be round-tripped between AI players.  People who believe there’s an AI bubble find it easy to view these transactions with suspicion.  Is the purpose to achieve legitimate business goals or to exaggerate progress?</p><p>Adding to worries, critics say, some of the deals that OpenAI has made with chipmakers, cloud computing companies and others are oddly circular.  OpenAI is set to receive billions from tech companies but also sends billions back to the same companies to pay for computing power and other services. . . .</p><p>Nvidia has also made some deals that have raised questions about whether the company is paying itself.  It announced that it would invest $100 billion in OpenAI.  The start-up receives that money as it buys or leases Nvidia’s chips. . . .</p><p>Goldman Sachs has estimated that Nvidia will make 15 percent of its sales next year from what critics also call circular deals.  (<em>The New York Times</em>, November 20)</p><p>Noteworthily, OpenAI has made investment commitments to industry counterparties totaling $1.4 trillion, even though it has yet to turn a profit.  The company makes clear that the investments are to be paid out of revenues received from the same parties and that it has ways to back out of these commitments.  But all this raises the question of whether the AI industry has developed a perpetual motion machine.  </p><p>(On this subject, I’ve been enjoying articles questioning the ability of people to relate to the word “trillion,” and I think this idea is spot on.  A million dollars is a dollar a second for 11.6 days.  A billion dollars is a dollar a second for 31.7 years.  We get that.  But a trillion dollars is a dollar a second for 31,700 years.  Who can get their head around the significance of 31,700 years?)</p><p><strong>What will be the useful life of AI assets?</strong> We have to wonder whether the topic of obsolescence is being handled correctly in AI-land.  What will be the lifespan of AI chips?  How many years of earnings growth should be counted on in assigning p/e ratios for AI-related stocks?  Will chips and other aspects of AI infrastructure last long enough to repay the debt undertaken to buy them?  Will artificial general intelligence (a machine capable of doing anything the human brain can do) be achieved?  Will that be the end of progress, or might there be further revolutions, and what firms will win them?  Will firms reach a position where technology is stable and they can extract economic value from it?  Or will new technologies continually threaten to supplant older ones as the route to success?  </p><p>In this connection, a single issue of an FT newsletter briefly mentioned two developments that suggest the fluid nature of the competitive landscape:</p><ul><li data-list="2" data-level="1"><p>A study by the Massachusetts Institute of Technology and open-source AI start-up Hugging Face found that the total share of downloads of new Chinese-made open models rose to 17 per cent in the past year.  The figure surpasses the 15.8 per cent share of downloads from American developers such as Google, Meta and OpenAI – the first time Chinese groups have beaten their American counterparts. . . .</p></li><li data-list="2" data-level="1"><p>Nvidia shares fell sharply yesterday on fears that Google is gaining ground in artificial intelligence, erasing $115bn in market value from the AI chipmaker.  (<em>FirstFT Americas</em>, November 26)</p></li></ul><p><strong>Dynamic change creates the opportunity for incredible new technologies, but that same dynamism can threaten the leading companies’ reign.</strong> Amid all these uncertainties, investors must ask whether the assumption of continued success incorporated in the prices they’re paying is fully warranted.</p><p><strong>Is exuberance leading to speculative behavior?</strong> For an extreme example, I’ll cite the trend toward venture capital investments in startups via $1 billion “seed rounds.”  Here’s one vignette:</p><p>Thinking Machines, an AI startup helmed by former Open AI executive Mira Murati, just raised the largest seed round in history: $2 billion in funding at a $10 billion valuation.  The company has not released a product and has refused to tell investors what they’re even trying to build.  “It was the most absurd pitch meeting,” one investor who met with Murati said.  “She was like, ‘So we're doing an AI company with the best AI people, but we can’t answer any questions.’ ”  (“The Is How the AI Bubble Will Pop,” Derek Thompson Substack, October 2)</p><p>But that’s ancient history. . . already two months old.  Here’s an update:</p><p>Thinking Machines Lab, the artificial intelligence startup founded by former Open AI executive Mira Murati, is in early talks to raise a new funding round at a roughly $50 billion valuation, <em>Bloomberg News</em> reported on Thursday.  The startup was last valued at $12 billion in July, after it raised about $2 billion.  (<em>Reuters</em>, November 13)</p><p>And Thinking Machines Lab isn’t alone:</p><p>In one of the boldest bets yet in the AI arms race, Safe Superintelligence (SSI), the stealth startup founded by former OpenAI chief scientist Ilya Sutskever, has raised $2 billion in a round that values the company at $32 billion – despite having no publicly released product or service.  (<em>CTech by Calcalist</em>, April 13)</p><p><strong>What’s the end state?</strong> Part of the issue with AI includes the unusual nature of this newest thing.  This isn’t like a business that designs and sells a product, making money if the selling price exceeds the cost of the inputs.  Rather, it’s companies building an airplane while it’s in flight, and once it’s built, they’ll know what it can do and whether anyone will pay for its services.</p><p>Many companies justify their spending because <strong>they’re not just building a product, they’re creating something that will change the world</strong>: artificial general intelligence, or A.G.I. . . .  The rub is that none of them quite know how to do it.</p><p>But Anton Korinek, an economist at the University of Virginia, said the spending would all be justified if Silicon Valley reached its goal.  He is optimistic it can be done.</p><p>“It’s a bet on A.G.I. or bust,” Dr. Korinek said.  (<em>The New York Times</em>, November 20 – emphasis added)</p><p>The yet-to-be-determined nature of the industry under construction is best captured in remarks from Sam Altman, the CEO of OpenAI, that have been paraphrased as follows: “we’ll build this sort of generally intelligent system and then ask it to figure out a way to generate an investment return from it.”</p><p>This should be a source of pause for people who heretofore fully comprehended the nature of the businesses they invested in.  Clearly, the value of a technology that equals or surpasses the human brain should be pretty big, but isn’t it well beyond calculation?  </p><p><span>A Word About the Use of Debt</span></p><p>To date, much of the investment in AI and the supporting infrastructure has consisted of equity capital derived from operating cash flow.  But now, companies are committing amounts that require debt financing, and for some of those companies, the investments and leverage have to be described as aggressive.</p><p>The AI data centre boom was never going to be financed with cash alone.  The project is too big to be paid for out of pocket.  JPMorgan analysts have done some sums on the back of a napkin, or possibly a tablecloth, and estimated the bill for the infrastructure build-out would come to $5tn (not including a tip).  Who knows if that’s right, but we have good reason to expect close to half a trillion in spending next year.  Meanwhile, the biggest spenders (Microsoft, Alphabet, Amazon, Meta and Oracle) had only about $350bn in the bank, collectively, as of the end of the third quarter.  (“Unhedged,” <em>Financial Times</em>, November 13)</p><p>The firms mentioned above derive healthy cash flows from their very strong non-AI businesses.  But the massive, winner-take-all arms race in AI is requiring some to take on debt.  <strong>In fact, it’s reasonable to think one of the reasons they’re spending vast sums is to make it hard for lesser firms to keep up.</strong> </p><p>Oracle, Meta, and Alphabet have issued 30-year bonds to finance AI investments.  In the case of the latter two, the yields on the bonds exceed those on Treasurys of like maturity by 100 basis points or less.  Is it prudent to accept 30 years of technological uncertainty to make a fixed-income investment that yields little more than riskless debt?  And will the investments funded with debt – in chips and data centers – maintain their level of productivity long enough for these 30-year obligations to be repaid?</p><p>On November 14, Alex Kantrowitz’s <em>Big Technology Podcast</em> carried a conversation with Gil Luria, Head of Technology Research at financial services firm D.A. Davidson, primarily regarding the use of debt in the AI sector.  Here’s some of what Luria had to say:</p><ul><li data-list="4" data-level="1"><p>Healthy behavior is being practiced by “. . . reasonable, thoughtful business leaders, like the ones at Microsoft, Amazon, and Google that are making sound investments in growing the capacity to deliver AI. And the reason they can make sound investments is that they have all the customers. . .  And so, when they make investments, they’re using cash on their balance sheets; they have tremendous cash flow to back it up; they understand that it’s a risky investment; and they balance it out.”  </p></li><li data-list="4" data-level="1"><p>Unhealthy behavior – Here he describes “. . . a startup that is borrowing money to build data centers for another startup.  They’re both losing tremendous amounts of cash, and yet they’re somehow being able to raise this debt capital in order to fund this buildout, again without having the customers or the visibility into those investments paying off.”</p></li><li data-list="4" data-level="1"><p>“So there’s a whole range of behaviors between healthy and unhealthy, and we just need to sort that out so we don’t make the mistakes of the past.”</p></li><li data-list="4" data-level="1"><p>“There are certain things we finance through equity, through ownership, and there are certain things we finance through debt, through an obligation to pay down interest over time.  And as a society, for the longest time, we’ve had those two pieces in their right place.  Debt is when I have a predictable cash flow and/or an asset that can back that loan, and then it makes sense for me to exchange capital now for future cash flows to the lender. . . .  We use equity for investing in more speculative things, for when we want to grow and we want to own that growth, but we’re not sure about what the cash flow is going to be.  That’s how a normal economy functions.  When you start confusing the two you get yourself in trouble.”</p></li></ul><p>Among potentially worrisome factors, Luria cites these:</p><ul><li data-list="5" data-level="1"><p>“A speculative asset . . . we don’t know how much of it we’re really going to need in two to five years.”</p></li><li data-list="5" data-level="1"><p>Lender personnel with incentives to make loans but no exposure to long-term consequences </p></li><li data-list="5" data-level="1"><p>The possibility that the supply of AI capacity catches up with or surpasses the demand</p></li><li data-list="5" data-level="1"><p>The chance that future generations of AI chips will be more powerful, obsoleting existing ones or reducing their value as backing for debt</p></li><li data-list="5" data-level="1"><p>Powerful competitors who vie for market share by cutting rental rates and running losses</p></li></ul><p>Here are some important paragraphs from Azeem Azhar’s <em>Exponential View</em> of October 18:</p><p>When does an AI boom tip into a bubble?  [Investor and engineer] Paul Kedrosky points to the Minsky moment – the inflection point when credit expansion exhausts its good projects and starts chasing bad ones, funding marginal deals with vendor financing and questionable coverage ratios.  For AI infrastructure, that shift may already be underway; the telltale signs include hyperscalers’ capex outpacing revenue momentum and lenders sweetening terms to keep the party alive.</p><p>Paul makes a compelling case.  We’ve entered speculative finance territory – arguably past the tentative stage – and recent deals will set dangerous precedents.  As Paul warns, this financing will “create templates for future such transactions,” spurring rapid expansion in junk issuance and SPV proliferation among hyperscalers chasing dominance at any cost. . . . </p><p><strong>For AI infrastructure, the warning signs are flashing: vendor financing proliferates, coverage ratios thin, and hyperscalers leverage balance sheets to maintain capex velocity even as revenue momentum lags.  We see both sides – genuine infrastructure expansion alongside financing gymnastics that recall the 2000 telecom bust.  The boom may yet prove productive, but only if revenue catches up before credit tightens.</strong> When does healthy strain become systemic risk?  That’s the question we must answer before the market does.  (Emphasis added)</p><p>Azhar references the use of off-balance sheet financing via special-purpose vehicles, or SPVs, which were among the biggest contributors to Enron’s precariousness and eventual collapse.  A company and its partners set up an SPV for some specific purpose(s) and supply the equity capital.  The parent company may have operating control, but because it doesn’t have majority ownership, it doesn’t consolidate the SPV on its financial statements.  The SPV takes on debt, but that debt doesn’t appear on the parent’s books.  The parent may be an investment grade borrower, but likewise, the debt isn’t an obligation of the parent or guaranteed by it.  Today’s debt may be backed by promised rent from a data center tenant – sometimes an equity partner – but the debt isn’t a direct obligation of the equity partner either.  Essentially, an SPV is a way to make it look like a company isn’t doing the things the SPV is doing and doesn’t have the debt the SPV does.  (Private equity funds and private credit funds are highly likely to be found among the partners and lenders in these entities.)  </p><p>As I quoted earlier, according to Perez (who wrote on the heels of the dot-com bubble), “what enabled the deployment period were the money-losing investments.”  Early investment is lost in the “Minsky moment,” in which unwise commitments made in an extended up-cycle encounters value destruction in a correction.  And there are three things we know for sure about the use of debt:</p><ul><li data-list="3" data-level="1"><p>it magnifies losses if there are losses (just as it magnifies the hoped-for gains if they materialize), </p></li><li data-list="3" data-level="1"><p>it increases the probability of a venture failing if it encounters a difficult moment, and</p></li><li data-list="3" data-level="1"><p>despite the layer of equity beneath it, it puts lenders’ capital at risk if the difficult moment is bad enough.</p></li></ul><p>One key risk to consider is the possibility that the boom in data center construction will result in a glut.  Some data centers may be rendered uneconomic, and some owners may go bankrupt.  In that case, a new generation of owners might buy up centers at pennies on the dollar from lenders who foreclosed on them, reaping profits when the industry stabilizes.  This is a process through which “creative destruction” brings markets into equilibrium and reduces costs to levels that make future business profitable.</p><p><strong>Debt is neither a good thing nor a bad thing <em>per se</em>. Likewise, the use of leverage in the AI industry shouldn’t be applauded or feared.  It all comes down to the proportion of debt in the capital structure; the quality of the assets or cash flows you’re lending against; the borrowers’ alternative sources of liquidity for repayment; and the adequacy of the safety margin obtained by lenders.  We’ll see which lenders maintain discipline in today’s heady environment.</strong></p><p>It’s worth noting in this connection that Oaktree has made a few investments in data centers, and our parent, Brookfield, is raising a $10 billion fund for investment in AI infrastructure.  Brookfield is putting up its own money and has equity commitments from sovereign wealth funds and Nvidia, to which it intends to apply “prudent” debt.  Brookfield’s investments seem likely to go largely into geographies that are less saturated with data centers and for infrastructure to supply the vast amounts of electric power that data centers will require.  Of course, we’re both doing these things on the basis of what we think are prudent decisions.  </p><p><strong>I know I don’t know enough to opine on AI.  But I do know something about debt, and it’s this:  </strong></p><ul><li data-list="3" data-level="1"><p><strong>It’s okay to supply debt financing for a venture where the outcome is uncertain.</strong> </p></li><li data-list="3" data-level="1"><p><strong>It’s not okay where the outcome is purely a matter of conjecture.</strong> </p></li><li data-list="3" data-level="1"><p><strong>Those who understand the difference still have to make the distinction correctly.</strong></p></li></ul><p>The FT’s <em>Unhedged</em> quotes Chong Sin, lead analyst for CMBS research at JPMorgan, as saying, “. . . in our conversations with investment grade ABS and CMBS investors, one often-cited concern is whether they want to take on the residual value risk of data centers when the bonds mature.”  I’m glad potential lenders are asking the kind of questions they should.  </p><p>Here’s how to think about the intersection of debt and AI according to Bob O’Leary, Oaktree’s co-CEO and co-portfolio manager of our Opportunities Funds:</p><p><strong>Most technological advances develop into winner-takes-all or winner-takes-most competitions.  The “right” way to play this dynamic is through equity, not debt.</strong> Assuming you can diversify your equity exposures so as to include the eventual winner, the massive gain from the winner will more than compensate for the capital impairment on the losers.  That’s the venture capitalist’s time-honored formula for success.</p><p>The precise opposite is true of a diversified pool of debt exposures.  You’ll only make your coupon on the winner, and that will be grossly insufficient to compensate for the impairments you’ll experience on the debt of the losers.  </p><p><strong>Of course, if you can’t identify the pool of companies from which the winner will emerge, the difference between debt and equity is irrelevant – you’re a zero either way.</strong> I mention this because that’s precisely what happened in search and social media: early leaders (Lycos in search and MySpace in social media) lost out spectacularly to companies that emerged later (Google in search and Facebook in social media).</p><p><span>Trying to Get to a Conclusion</span></p><p>There can be no doubt that today’s behavior is “speculative,” defined as based on speculation regarding the future.  There’s also no doubt that no one knows what the future holds, but investors are betting huge sums on that future.</p><p>In that connection, I want to say a little about the unique nature of AI.  The AI revolution is different from the technological revolutions that preceded it in ways that are both <span>wonderful</span> and <span>worrisome</span>. It feels to me like a genie has been released from a bottle, and it isn’t going back in:</p><p><strong>AI may not be a tool for mankind, but rather something of a replacement.</strong> It may be capable of taking over cognition, on which humans have thus far had a monopoly.  Because of this, it’s likely to be different in kind from prior developments, not just in degree.  (More on this in my postscript.)</p><p><strong>AI technology is progressing at an incredibly rapid clip</strong>, possibly leaving scant time for mankind to adjust.  I’ll provide two examples:</p><br><ul><li data-list="2" data-level="1"><p>Coding, which we called “computer programming” 60 years ago, is the canary in the coal mine in terms of the impact of AI.  In many advanced software teams, developers no longer write the code; they type in what they want, and AI systems generate the code for them.  Coding performed by AI is at a world-class level, something that wasn’t so just a year ago.  According to my guide here, “There is no speculation about whether or not human replacement will take place in that vertical.”</p></li><li data-list="2" data-level="1"><p>In the field of digital advertising, when users log into an app, AI engages in “ad matching,” showing them ads tailored to the preferences displayed by their prior surfing.  No humans need apply to do this job.</p></li></ul><p>Perhaps most importantly, <strong>the growth of demand for AI seems totally unpredictable.</strong> As one of my younger advisers explained, “the speed and scale of improvement mean it’s incredibly hard to forecast demand for AI.  Adoption today may have nothing to do with adoption tomorrow, because a year or two from now, AI may be able to do 10x or 100x what it can do today.  Thus, how can anyone say how many data centers will be needed?  And how can even successful companies know how much computing capacity to contract for?”</p><p>With differences like these, how can anyone correctly judge what AI implies for the future?</p><p>*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *</p><p>One of the things occupying many observers at this juncture – including me – is the search for parallels to past bubbles.  Here’s some historical perspective from a recent article in <em>Wired</em>:</p><p>AI’s closest historical analogue here may be not electric lighting but radio.  When RCA started broadcasting in 1919, it was immediately clear that it had a powerful information technology on its hands.  But less clear was how that would translate into business. “Would radio be a loss-leading marketing for department stores?  A public service for broadcasting Sunday sermons?  An ad-supported medium for entertainment?” [Brent Goldfarb and David A. Kirsch of the University of Maryland] write.  “All were possible.  All were subjects of technological narratives.”  As a result, radio turned into one of the biggest bubbles in history – peaking in 1929, before losing 97 percent of its value in the crash.  This wasn’t an incidental sector; RCA was, along with Ford Motor Company, the most high-traded stock on the market.  It was, as <em>The New Yorker</em> recently wrote, “the Nvidia of its day.” . . .</p><p>In 1927, Charles Lindbergh flew the first solo nonstop transatlantic flight from New York to Paris. . . .  It was the biggest tech demo of the day, and it became an enormous, ChatGPT-launch-level coordinating event – a signal to investors to pour money into the industry.</p><p>“Expert investors appreciated correctly the importance of airplanes and air travel,” Goldfarb and Kirsch write, but <strong>“the narrative of inevitability largely drowned out their caution.  Technological uncertainty was framed as opportunity, not risk.  The market overestimated how quickly the industry would achieve technological viability and profitability.”</strong></p><p>As a result, the bubble burst in 1929 – from its peak in May, aviation stocks dropped 96 percent by May 1932. . . .</p><p>It’s worth reiterating that two of the closest analogs AI seems to have in tech bubble history are aviation and broadcast radio.  Both were wrapped in high degrees of uncertainty and both were hyped with incredibly powerful coordinating narratives.  Both were seized on by pure play companies seeking to capitalize on the new game-changing tech, and both were accessible to the retail investors of the day.  Both helped inflate a bubble so big that when it burst, in 1929, it left us with the Great Depression.  (“AI Is the Bubble to Burst Them All,” Brian Merchant, <em>Wired</em>, October 27 – emphasis added. N.b., the Depression had many causes beyond the bursting of the radio/aviation bubble.)  </p><p>Derek Thompson, who supplied the quote with which I opened this memo, ended his newsletter with some terrific historical perspective:</p><p>The railroads were a bubble and they transformed America.  Electricity was a bubble, and it transformed America.  The broadband build-out of the late-1990s was a bubble that transformed America.  I am not rooting for a bubble, and quite the contrary, I hope that the US economy doesn’t experience another recession for many years.  <strong>But given the amount of debt now flowing into AI data center construction, I think it’s unlikely that AI will be the first transformative technology that isn’t overbuilt and doesn’t incur a brief painful correction.</strong> (“AI Could Be the Railroad of the 21<sup>st</sup> Century.  Brace Yourself.” November 4 – emphasis added)</p><p>The skeptics readily cite ways in which today’s events are comparable to the internet bubble:</p><ul><li data-list="6" data-level="1"><p>A change-the-world technology</p></li><li data-list="6" data-level="1"><p>Exuberant, speculative behavior </p></li><li data-list="6" data-level="1"><p>The role of FOMO</p></li><li data-list="6" data-level="1"><p>Suspect, circular deals</p></li><li data-list="6" data-level="1"><p>The use of SPVs</p></li><li data-list="6" data-level="1"><p>$1 billion seed rounds </p></li></ul><p>The supporters have reasons why the comparison isn’t appropriate:</p><ul><li data-list="5" data-level="1"><p>An existing product for which there is strong demand</p></li><li data-list="5" data-level="1"><p>One billion users already (many times the number of internet users at the height of the bubble)</p></li><li data-list="5" data-level="1"><p>Well-established main players with revenues, profits, and cash flow</p></li><li data-list="5" data-level="1"><p>The absence of an IPO craze with prices doubling in a day</p></li><li data-list="5" data-level="1"><p>Reasonable p/e ratios for the established participants </p></li></ul><p>I’ll elaborate regarding the first of the proposed non-comparable factors.  Unlike in the internet bubble, AI products already exist at scale, the demand for them is exploding, and they’re producing revenues in rapidly increasing amounts.  For example, Anthropic, one of the two leaders in producing models for AI coding as described on page 12, is said to have “10x-ed” its revenues in each of the last two years (for those who didn’t study higher math, that’s 100x in two years).  Revenues from Claude Code, a program for coding that Anthropic introduced earlier this year, already are said to be running at an annual rate of $1 billion.  Revenues for the other leader, Cursor, were $1 million in 2023 and $100 million in 2024, and they, too, are expected to reach $1 billion this year. </p><p>As to the final bullet point, see the table below, which comes from Goldman Sachs via Derek Thompson.  You’ll notice that during the internet bubble of 1998-2000, the p/e ratios were much higher for Microsoft, Cisco, and Oracle than they are today for the biggest AI players – Nvidia, Microsoft, Alphabet, Amazon, and Meta (OpenAI doesn’t have earnings).  In fact, Microsoft’s on a half-off sale relative to its p/e 26 years ago!  In the first bubble I witnessed – surrounding the Nifty-Fifty in 1969-72 – the p/e ratios for the leading companies were even higher than those of 1998-2000. </p><br><div><p><img src="https://www.oaktreecapital.com/images/oaktreecaplibraries/insights/memos/commentary/is-it-a-bubble-exhibit7.jpg?sfvrsn=d6aa2866_2" alt="Exhibit 7"></p></div><p><span>In Conclusion</span></p><p>For my final citation, I’ll look to Sam Altman of OpenAI.  His comments seem to me to capture the essence of what’s going on:</p><p>“When bubbles happen, smart people get overexcited about a kernel of truth,” Mr. Altman told reporters this year.  “Are we in a phase where investors as a whole are overexcited about A.I.?  My opinion is yes.  Is A.I. the most important thing to happen in a very long time?  My opinion is also yes.”  (<em>The New York Times</em>, November 20)</p><p>But do I have a bottom line?  Yes, I do.  Alan Greenspan’s phrase, mentioned earlier, serves as an excellent way to sum up a stock market bubble: “irrational exuberance.”  <strong>There is no doubt that investors are applying exuberance with regard to AI.  The question is whether it’s irrational.  Given the vast potential of AI but also the large number of enormous unknowns, I think virtually no one can say for sure.</strong> We can theorize about whether the current enthusiasm is excessive, but we won’t know until years from now whether it was.  Bubbles are best identified in retrospect.</p><p><strong>While the parallels to past bubbles are inescapable, believers in the technology will argue that “this time it’s different.”</strong> Those four words are heard in virtually every bubble, explaining why the present situation isn’t a bubble, unlike the analogous prior ones.  On the other hand, Sir John Templeton, who in 1987 drew my attention to those four words, was quick to point out that 20% of the time things really are different.  <strong>But on the third hand, it must be borne in mind that behavior based on the belief that it’s different is what causes it to <span>not</span> be different!</strong></p><p>Today’s situation calls to mind a comment attributed to American economist Stuart Chase about faith.  I believe it’s also applicable to AI (as well as to gold and cryptocurrencies):</p><p>For those who believe, no proof is necessary.  For those who don't believe, no proof is possible.</p><p>Here’s my actual bottom line:</p><ul><li data-list="7" data-level="1"><p>There’s a consistent history of transformational technologies generating excessive enthusiasm and investment, resulting in more infrastructure than is needed and asset prices that prove to have been too high.  The excesses accelerate the adoption of the technology in a way that wouldn’t occur in their absence.  The common word for these excesses is “bubbles.”  </p></li><li data-list="7" data-level="1"><p>AI has the potential to be one of the greatest transformational technologies of all time.</p></li><li data-list="7" data-level="1"><p>As I wrote just above, AI is currently the subject of great enthusiasm.  If that enthusiasm doesn’t produce a bubble conforming to the historical pattern, that will be a first.</p></li><li data-list="7" data-level="1"><p>Bubbles created in this process usually end in losses for those who fuel them.</p></li><li data-list="7" data-level="1"><p>The losses stem largely from the fact that the technology’s newness renders the extent and timing of its impact unpredictable.  This in turn makes it easy to judge companies too positively amid all the enthusiasm and difficult to know which will emerge as winners when the dust settles.</p></li><li data-list="7" data-level="1"><p>There can be no way to participate fully in the potential benefits from the new technology without being exposed to the losses that will arise if the enthusiasm and thus investors’ behavior prove to have been excessive.  </p></li><li data-list="7" data-level="1"><p>The use of debt in this process – which the high level of uncertainty usually precluded in past technological revolutions – has the potential to magnify all of the above this time.</p></li></ul><p><strong>Since no one can say definitively whether this is a bubble, I’d advise that no one should go all-in without acknowledging that they face the risk of ruin if things go badly.  But by the same token, no one should stay all-out and risk missing out on one of the great technological steps forward.</strong> A moderate position, applied with selectivity and prudence, seems like the best approach.</p><p>Finally, it’s essential to bear in mind that there are no magic words in investing.  These days, people promoting real estate funds say, “Office buildings are so yesterday, but we’re investing in the future through data centers,” whereupon everyone nods in agreement.  But data centers can be in shortage or in oversupply, and rental rates can surprise to the upside or the downside.  As a result, they can be profitable . . . or not.  <strong>Intelligent investment in data centers, and thus in AI – <span>like everything else</span> – requires sober, insightful judgment and skillful implementation.</strong></p><br><!-- Date -->
<p>December 9, 2025</p><p>P.S.: The following has nothing to do with the financial markets or the question of whether AI is the subject of a bubble.  My topic is the impact of AI on society through joblessness and purposelessness.  You needn’t read it – that’s why it’s a postscript – but it’s important to me, and I've been looking for a place to say a few words about it.</p><p>On November 18, a research note from Barclays described Fed Governor Christopher Waller as having “highlighted how recent stock market enthusiasm around AI has not yet translated into job creation.”  This strikes me as paradoxical given my sense that one of AI’s main impacts will be to increase productivity and thus eliminate jobs.  That is the source of my concern.</p><p>I view AI primarily as an incredible labor-saving device.  Joe Davis, Global Chief Economist and Global Head of the Investment Strategy Group at Vanguard, says, “for most jobs – likely four out of five – AI’s impact will result in a mixture of innovation and automation, and could save about 43% of the time people currently spend on their work tasks.”  (<em>Exponential View</em>, September 3)  </p><p><strong>I find the resulting outlook for employment terrifying.</strong> I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can’t find jobs because of it.  The optimists argue that “new jobs have always materialized after past technological advances.”  I hope that’ll hold true in the case of AI, but hope isn’t much to hang one’s hat on, and I have trouble figuring out where those jobs will come from.  <strong>Of course, I’m not much of a futurist or a financial optimist, and that’s why it’s a good thing I shifted from equities to bonds in 1978.</strong></p><p>The other thing the optimists say is that “the beneficial impact of AI on productivity will cause a huge acceleration in GDP growth.”  Here I have specific quibbles:  </p><ul><li data-list="2" data-level="1"><p>The change in GDP can be thought of as the change in hours worked times the change in output per hour (aka “productivity”).  The role of AI in increasing productivity means it will take fewer hours worked – meaning fewer workers – to produce the goods we need.</p></li><li data-list="2" data-level="1"><p>Or, viewed from the other direction, maybe the boom in productivity will mean a lot more goods can be produced with the same amount of labor.  But if a lot of jobs are lost to AI, how will people be able to afford the additional goods AI enables to be produced?</p></li></ul><p><strong>I find it hard to imagine a world in which AI works shoulder-to-shoulder with all the people who are employed today.  How can employment not decline?</strong> AI is likely to replace large numbers of entry-level workers, people who process paper without applying judgment, and junior lawyers who scour the lawbooks for precedents.  Maybe even junior investment analysts who create spreadsheets and compile presentation materials.  It’s said that AI can read an MRI better than the average doctor.  Driving is one of the most populous professions in America, and driverless vehicles are already arriving; where will all the people who currently drive taxis, limos, buses, and trucks find jobs?</p><p>I imagine government’s response will be something called “universal basic income.”  The government will simply mail checks to the millions for whom there are no jobs.  But the worrier in me finds problems in this, too:</p><ul><li data-list="2" data-level="1"><p><strong>Where will the money come from for those checks?</strong> The job losses I foresee imply reduced income tax receipts and increased spending on entitlements.  This puts a further burden on the declining segment of the population that is working and implies even greater deficits ahead.  In this new world, will governments be able to fund ever-increasing deficits?  </p></li><li data-list="2" data-level="1"><p>And more importantly, <strong>people get a lot more from jobs than just a paycheck.</strong> A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect, and presents them with challenges, the overcoming of which provides satisfaction.  How will these things be replaced?  I worry about large numbers of people receiving subsistence checks and sitting around idle all day.  I worry about the correlation between the loss of jobs in mining and manufacturing in recent decades and the incidence of opioid addiction and shortening of lifespans.</p></li></ul><p>And by the way, if we eliminate large numbers of junior lawyers, analysts, and doctors, where will we get the experienced veterans capable of solving serious problems requiring judgment and pattern recognition honed over decades?</p><p>What jobs won’t be eliminated?  What careers should our children and grandchildren prepare for?  Think about the jobs that machines can’t perform.  My list starts with plumbers, electricians, and masseurs –physical tasks.  Maybe nurses will earn more than doctors because they deliver hands-on care.  And what distinguishes the best artists, athletes, doctors, lawyers, and hopefully investors?  I think it’s something called talent or insight, which AI might or might not be able to replicate.  But how many people at the top of those professions are needed?  A past presidential candidate said he would give laptops to everyone who lost their job to offshoring.  How many laptop operators do we need?</p><p>Finally, I’m concerned that a small number of highly educated multi-billionaires living on the coasts will be viewed as having created technology that puts millions out of work.  <strong>This promises even more social and political division than we have now, making the world ripe for populist demagoguery.</strong> </p><p>I’ve seen incredible progress over the course of my lifetime, but in many ways I miss the simpler world I grew up in. I worry that this will be another big one.  <strong>I get no pleasure from this recitation.  Will the optimists please explain why I’m wrong?</strong></p><p>Interestingly in this connection, Vanguard’s Joe Davis points out that more Americans are turning 65 in 2025 than in any preceding year, and that approximately 16 million baby boomers will retire between now and 2035.  Could AI merely make up for that?  There’s an optimistic take for you.</p><p>HM</p><p>Legal Information and Disclosures</p><p><span><em>This memorandum expresses the views of the author as of the date indicated and such views are subject to change without notice. Oaktree has no duty or obligation to update the information contained herein. Further, Oaktree makes no representation, and it should not be assumed, that past investment performance is an indication of future results. Moreover, wherever there is the potential for profit there is also the possibility of loss.</em>
 </span>
</p><p><span><em>This memorandum is being made available for educational purposes only and should not be used for any other purpose. The information contained herein does not constitute and should not be construed as an offering of advisory services or an offer to sell or solicitation to buy any securities or related financial instruments in any jurisdiction. Certain information contained herein concerning economic trends and performance is based on or derived from information provided by independent third-party sources. Oaktree Capital Management, L.P. (“Oaktree”) believes that the sources from which such information has been obtained are reliable; however, it cannot guarantee the accuracy of such information and has not independently verified the accuracy or completeness of such information or the assumptions on which such information is based. </em>
 </span>
</p><p><span><em>This memorandum, including the information contained herein, may not be copied, reproduced, republished, or posted in whole or in part, in any form without the prior written consent of Oaktree.</em>
 </span>
</p><p><em>© 2025 Oaktree Capital Management, L.P.</em>
</p>
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Auto-grading decade-old Hacker News discussions with hindsight (488 pts)]]></title>
            <link>https://karpathy.bearblog.dev/auto-grade-hn/</link>
            <guid>46220540</guid>
            <pubDate>Wed, 10 Dec 2025 17:23:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://karpathy.bearblog.dev/auto-grade-hn/">https://karpathy.bearblog.dev/auto-grade-hn/</a>, See on <a href="https://news.ycombinator.com/item?id=46220540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    

    
        

        <p>
            <i>
                <time datetime="2025-12-10T15:00Z">
    10 Dec, 2025
</time>
            </i>
        </p>
    

    <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/karpathy/hnhero.webp" alt="hnhero"></p>
<p>TLDR: <a href="https://karpathy.ai/hncapsule/">https://karpathy.ai/hncapsule/</a></p>
<hr>
<p>Yesterday I stumbled on this HN thread <a href="https://news.ycombinator.com/item?id=46205632">Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now</a>, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the <a href="https://news.ycombinator.com/front?day=2015-12-09">HN frontpage from exactly 10 years ago</a>, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the front pages of December (31 days, 30 articles per day), get ChatGPT 5.1 Thinking to do the analysis, and present everything in a nice way for historical reading.</p>
<p>There are two macro reasons for why I think the exercise is interesting more generally:</p>
<ol>
<li>I believe it is quite possible and desirable to train your forward future predictor given training and effort.</li>
<li>I was reminded again of my tweets that said <em>"Be good, future LLMs are watching"</em>. You can take that in many directions, but here I want to focus on the idea that future LLMs <strong>are</strong> watching. Everything we do today might be scrutinized in great detail in the future because doing so will be "free". A lot of the ways people behave currently I think make an implicit "security by obscurity" assumption. But if intelligence really does become too cheap to meter, it will become possible to do a perfect reconstruction and synthesis of everything. LLMs are watching (or humans using them might be). Best to be good.</li>
</ol>
<p>Vibe coding the actual project was relatively painless and took about 3 hours with Opus 4.5, with a few hickups but overall very impressive. The repository is on GitHub here: <a href="https://github.com/karpathy/hn-time-capsule">karpathy/hn-time-capsule</a>. Here is the progression of what the code does:</p>
<ul>
<li>Given a date, download the frontpage of 30 articles</li>
<li>For each article, download/parse the article itself and the full comment thread using Algolia API.</li>
<li>Package up everything into a markdown prompt asking for the analysis. Here is the prompt prefix I used:</li>
</ul>
<div><pre><span></span>The following is an article that appeared on Hacker News 10 years ago, and the discussion thread.

Let's use our benefit of hindsight now in 6 sections:

1. Give a brief summary of the article and the discussion thread.
2. What ended up happening to this topic? (research the topic briefly and write a summary)
3. Give out awards for "Most prescient" and "Most wrong" comments, considering what happened.
4. Mention any other fun or notable aspects of the article or discussion.
5. Give out grades to specific people for their comments, considering what happened.
6. At the end, give a final score (from 0-10) for how interesting this article and its retrospect analysis was.

As for the format of Section 5, use the header "Final grades" and follow it with simply an unordered list of people and their grades in the format of "name: grade (optional comment)". Here is an example:

Final grades
- speckx: A+ (excellent predictions on ...)
- tosh: A (correctly predicted this or that ...)
- keepamovin: A
- bgwalter: D
- fsflover: F (completely wrong on ...)

Your list may contain more people of course than just this toy example. Please follow the format exactly because I will be parsing it programmatically. The idea is that I will accumulate the grades for each account to identify the accounts that were over long periods of time the most prescient or the most wrong.

As for the format of Section 6, use the prefix "Article hindsight analysis interestingness score:" and then the score (0-10) as a number. Give high scores to articles/discussions that are prominent, notable, or interesting in retrospect. Give low scores in cases where few predictions are made, or the topic is very niche or obscure, or the discussion is not very interesting in retrospect.

Here is an example:
Article hindsight analysis interestingness score: 8
---
</pre></div>
<ul>
<li>Submit prompt to GPT 5.1 Thinking via the OpenAI API</li>
<li>Collect and parse the results</li>
<li>Render the results into static HTML web pages for easy viewing</li>
<li>Host the html result pages on my website: <a href="https://karpathy.ai/hncapsule/">https://karpathy.ai/hncapsule/</a></li>
<li>Host all the intermediate results of the <code>data</code> directory if someone else would like to play. It's the file <code>data.zip</code> under the exact same url prefix (intentionally avoiding a direct link).</li>
</ul>
<p>I spent a few hours browsing around and found it to be very interesting. A few example threads just for fun:</p>
<ul>
<li>December 3 2015 <a href="https://karpathy.ai/hncapsule/2015-12-03/index.html#article-10669891">Swift went open source</a>.</li>
<li>December 6 2015 <a href="https://karpathy.ai/hncapsule/2015-12-06/index.html#article-10685407">Launch of Figma</a></li>
<li>December 11 2015 <a href="https://karpathy.ai/hncapsule/2015-12-11/index.html#article-10720176">original announcement of OpenAI</a> :').</li>
<li>December 16 2015 <a href="https://karpathy.ai/hncapsule/2015-12-16/index.html#article-10744206">geohot is building Comma</a></li>
<li>December 22 2015 <a href="https://karpathy.ai/hncapsule/2015-12-22/index.html#article-10774865">SpaceX launch webcast: Orbcomm-2 Mission</a></li>
<li>December 28 2015 <a href="https://karpathy.ai/hncapsule/2015-12-28/index.html#article-10799261">Theranos struggles</a></li>
</ul>
<p>And then when you navigate over to the <a href="https://karpathy.ai/hncapsule/hall-of-fame.html">Hall of Fame</a>, you can find the top commenters of Hacker News in December 2015, sorted by imdb-style score of their grade point average. In particular, congratulations to pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob, 0xcde4c3db, Manishearth, johncolanduoni - GPT 5.1 Thinking found your comments very insightful and prescient. You can also scroll all the way down to find the noise of HN, which I think we're all familiar with too :)</p>
<p>My <a href="https://github.com/karpathy/hn-time-capsule">code</a> (wait, Opus' code?) on GitHub can be used to reproduce or tweak the results. Running 31 days of 30 articles through GPT 5.1 Thinking meant <code>31 * 30 =</code> 930 LLM queries and cost about $58 and somewhere around ~1 hour. The LLM megaminds of the future might find this kind of a thing a lot easier, a lot faster and a lot cheaper.</p>


    

    
        

        
            


        

        
            
        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux (809 pts)]]></title>
            <link>https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html</link>
            <guid>46220488</guid>
            <pubDate>Wed, 10 Dec 2025 17:20:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html">https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html</a>, See on <a href="https://news.ycombinator.com/item?id=46220488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        <p>The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the <a href="https://www.heise.de/news/Linux-Konsole-Valve-kuendigt-neue-Steam-Machine-an-11076221.html?from-en=1">mini-PC is software-limited to HDMI 2.0</a>. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.</p>
<!-- RSPEAK_STOP -->




  


<!-- RSPEAK_START -->

<p>In a statement to <a href="https://arstechnica.com/gaming/2025/12/why-wont-steam-machine-support-hdmi-2-1-digging-in-on-the-display-standard-drama/" rel="external noopener" target="_blank">Ars Technica, a Valve spokesperson confirmed</a> that HDMI 2.1 support is "still a work-in-progress on the software side." "We’ve been working on trying to unblock things there."</p>
<p>The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.</p>
<!-- RSPEAK_STOP -->

  




<!-- RSPEAK_START -->

<h3 id="nav_no_change_after__0">No Change After Almost Two Years</h3>
<p>The restriction imposed by the HDMI Forum <a href="https://www.heise.de/news/AMD-HDMI-Forum-verhindert-HDMI-2-1-unter-Linux-9643729.html?from-en=1">was already criticized in early 2024 by an AMD employee responsible for Linux</a>. Even then, according to AMD, they had submitted a functional, HDMI 2.1-compatible driver, which the HDMI Forum rejected.</p>
<p>"Unfortunately, the HDMI Forum rejected our proposal," it was stated at the time. "At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements."</p>
<p>Only HDMI 2.1 offers sufficient bandwidth for 120 or 144 Hertz at 3840&nbsp;× 2160 pixels without compression. Furthermore, this version introduced manufacturer-independent variable refresh rates (HDMI VRR). Valve enables 4K and 120 Hertz using chroma subsampling, a compression technique that is particularly noticeable with text. VRR functions in the form of AMD's Freesync, which requires compatible displays.</p>
<!-- RSPEAK_STOP -->


  



  




<!-- RSPEAK_START -->

<p>Alternatively, interested parties can use an active adapter from DisplayPort 1.4 to HDMI 2.1 to increase the frame rate without compression. However, they do not officially support VRR. Popular variants from Club3D are no longer available; <a data-teaser-tracking-content="textlink-pvg" data-teaser-tracking-id="textlink-pvg-pvg_a2664995-1" data-teaser-tracking-name="pvg_a2664995: Lindy DisplayPort 1.4 Stecker auf HDMI 2.1 Buchse, Adapter (41094)" data-teaser-tracking-rank="11107440: Valve: HDMI Forum Continues to Block HDMI 2.1 for…" href="https://preisvergleich.heise.de/lindy-displayport-1-4-stecker-auf-hdmi-2-1-buchse-41094-a2664995.html?cs_id=1206858352&amp;ccpid=hocid-newsticker" rel="external noopener" target="_blank">offers from less well-known providers (starting from 35,67 €)</a> are still available in price comparisons.</p>


<!-- RSPEAK_STOP -->

<!-- RSPEAK_START -->
<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:mma@heise.de" title="Mark Mantel">mma</a>)</span>
<!-- RSPEAK_START -->
</p>
<div>
    <p>
      Don't miss any news – follow us on
      <a href="https://www.facebook.com/heiseonlineEnglish">Facebook</a>,
      <a href="https://www.linkedin.com/company/104691972">LinkedIn</a> or
      <a href="https://social.heise.de/@heiseonlineenglish">Mastodon</a>.
    </p>
    <p>
      <em>This article was originally published in
      
        <a href="https://www.heise.de/news/Valve-HDMI-Forum-blockiert-weiter-HDMI-2-1-fuer-Linux-11107364.html">German</a>.
      
      It was translated with technical assistance and editorially reviewed before publication.</em>
    </p>
  </div>



        

        
        <!-- RSPEAK_STOP -->
        

<a-gift has-access="">
    
</a-gift>


        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek uses banned Nvidia chips for AI model, report says (313 pts)]]></title>
            <link>https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html</link>
            <guid>46219853</guid>
            <pubDate>Wed, 10 Dec 2025 16:34:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html">https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html</a>, See on <a href="https://news.ycombinator.com/item?id=46219853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content-wrapper">  <article data-testid="article-content-wrapper">     <div data-testid="article-body">   <figure data-testid="article-figure-image"><div> <p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==" alt="Photographer: Lam Yik/Bloomberg" loading="eager" height="641" width="960"></p></div> <figcaption><!-- HTML_TAG_START -->Photographer: Lam Yik/Bloomberg<!-- HTML_TAG_END -->  </figcaption> </figure>   <p><!-- HTML_TAG_START --><span>(Bloomberg) --</span> Chinese artificial intelligence startup DeepSeek has relied on Nvidia Corp. chips that are banned in the country to develop an upcoming AI model, according to a new report in The Information.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Nvidia’s Blackwell chips were smuggled into China through countries that permitted their sale, The Information reported, citing unnamed sources. More specifically, DeepSeek tapped chips that were installed in data centers in unspecified countries, then dismantled and shipped to China after clearing inspection by companies developing server equipment, The Information said. <!-- HTML_TAG_END --></p>      <p><!-- HTML_TAG_START -->Most Read from Bloomberg<!-- HTML_TAG_END --></p>   <ul><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-08/nj-suburb-montclair-goes-through-with-school-system-staff-cuts?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote;elm:context_link;itc:0;sec:content-canvas">NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-09/aviva-seeks-partner-for-new-city-of-london-skyscraper-project?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Aviva Seeks Partner for New City of London Skyscraper Project;elm:context_link;itc:0;sec:content-canvas">Aviva Seeks Partner for New City of London Skyscraper Project</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-09/democrats-seek-probe-of-trump-officials-dealings-with-immigration-contractors?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Democrats Want Probe of Trump Officials and Immigration Deals;elm:context_link;itc:0;sec:content-canvas">Democrats Want Probe of Trump Officials and Immigration Deals</a><!-- HTML_TAG_END --></p> </li> </ul>   <p><!-- HTML_TAG_START -->The US bans the sale of these advanced semiconductors to China, which has led AI developers there to access the hardware through data centers located outside of the mainland or subterfuge. In November, US prosecutors charged two Chinese nationals and two US citizens with a scheme to ship chips to China by way of Malaysia using a fake real estate business.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->A representative for DeepSeek didn’t immediately respond to a request for comment.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->DeepSeek drew global attention in January when it debuted an AI model that was competitive with Silicon Valley’s best and said it had built it at a fraction of the cost. The startup was funded by the Chinese hedge fund High-Flyer, which had amassed 10,000 Nvidia GPUs in 2021, prior to US bans on exports of sophisticated Nvidia chips and other graphics processing units.<!-- HTML_TAG_END --></p>      <p><!-- HTML_TAG_START -->Earlier this week, President Donald Trump granted Nvidia permission to ship to China an older version of its AI accelerators, the H200. An export ban on its more powerful Blackwell version remains in place.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Beijing has meanwhile pushed Chinese technology companies to rely on domestic equipment to develop AI. DeepSeek released a new model in September and indicated that it was working with Chinese chipmakers on the model.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Nvidia told The Information that it hasn’t seen “any substantiation or received tips” about smuggling through data centers outside of China.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->(Updates with more details on reported chip smuggling starting in the third paragraph)<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Most Read from Bloomberg Businessweek<!-- HTML_TAG_END --></p>   <ul><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-09/albright-college-budget-cuts-are-eliminating-many-traditional-majors?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Why a College Fighting for Survival Is Slashing Econ and Physics Majors;elm:context_link;itc:0;sec:content-canvas">Why a College Fighting for Survival Is Slashing Econ and Physics Majors</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-09/argentina-s-richest-man-marcos-galperin-on-stepping-down-as-mercadolibre-ceo?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Argentina’s Richest Man: ‘Real Power Is Choosing When to Step Away’;elm:context_link;itc:0;sec:content-canvas">Argentina’s Richest Man: ‘Real Power Is Choosing When to Step Away’</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-09/nuclear-energy-fossil-fuel-interests-join-forces-against-renewable-energy?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Nuclear and Fossil Fuels Join Forces to Undermine Renewables;elm:context_link;itc:0;sec:content-canvas">Nuclear and Fossil Fuels Join Forces to Undermine Renewables</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-08/grand-canyon-glacier-joshua-tree-national-park-workers-rally-to-unionize?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:How Trump Pushed US Park Rangers to the Breaking Point—and a Union Drive;elm:context_link;itc:0;sec:content-canvas">How Trump Pushed US Park Rangers to the Breaking Point—and a Union Drive</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-03/ai-slop-youtube-videos-for-kids-pretend-to-be-educational?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:YouTube Creators Find a New Consumer for AI Slop: Babies;elm:context_link;itc:0;sec:content-canvas">YouTube Creators Find a New Consumer for AI Slop: Babies</a><!-- HTML_TAG_END --></p> </li> </ul>   <p><!-- HTML_TAG_START -->©2025 Bloomberg L.P.<!-- HTML_TAG_END --></p>   </div> <span> </span>  </article>     <hr> <ul><li data-testid="seamlessscroll-6f99d87c-7474-3d64-b2e5-19edaf0c66ef"> </li><li data-testid="seamlessscroll-3e7395ca-6ae7-3e6e-9226-a1df04934c4b"> </li><li data-testid="seamlessscroll-4b18cf2c-f118-392a-aa62-695ba93376df"> </li><li data-testid="seamlessscroll-7416125b-ea22-3ad7-bd27-9434d427e188"> </li><li data-testid="seamlessscroll-c848c1fa-973e-35e4-9051-b71406386dac"> </li><li data-testid="seamlessscroll-e6c25bb8-8cef-3d9b-9ee8-ee448aba48be"> </li><li data-testid="seamlessscroll-bdcba08a-56a4-306e-9e56-04cce3f29951"> </li></ul> <section><header> </header>   </section></div></div>]]></description>
        </item>
    </channel>
</rss>