<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 26 Aug 2024 16:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[DOJ Files Antitrust Suit Against RealPage, Maker of Rent-Setting Algorithm (142 pts)]]></title>
            <link>https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</link>
            <guid>41357557</guid>
            <pubDate>Mon, 26 Aug 2024 14:36:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm">https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</a>, See on <a href="https://news.ycombinator.com/item?id=41357557">Hacker News</a></p>
Couldn't get https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fixing a Bug in Google Chrome as a First-Time Contributor (311 pts)]]></title>
            <link>https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</link>
            <guid>41355303</guid>
            <pubDate>Mon, 26 Aug 2024 09:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/">https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=41355303">Hacker News</a></p>
Couldn't get https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dutch DPA fines Uber 290M euro because of transfers of drivers' data to the US (280 pts)]]></title>
            <link>https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</link>
            <guid>41355021</guid>
            <pubDate>Mon, 26 Aug 2024 08:15:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us">https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</a>, See on <a href="https://news.ycombinator.com/item?id=41355021">Hacker News</a></p>
Couldn't get https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Avante.nvim: Use Your Neovim Like Using Cursor AI IDE (186 pts)]]></title>
            <link>https://github.com/yetone/avante.nvim</link>
            <guid>41353835</guid>
            <pubDate>Mon, 26 Aug 2024 03:44:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/yetone/avante.nvim">https://github.com/yetone/avante.nvim</a>, See on <a href="https://news.ycombinator.com/item?id=41353835">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">avante.nvim</h2><a id="user-content-avantenvim" aria-label="Permalink: avante.nvim" href="#avantenvim"></a></p>
<p dir="auto"><strong>avante.nvim</strong> is a Neovim plugin designed to emulate the behaviour of the <a href="https://www.cursor.com/" rel="nofollow">Cursor</a> AI IDE. It provides users with AI-driven code suggestions and the ability to apply these recommendations directly to their source files with minimal effort.</p>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">ü•∞ This project is undergoing rapid iterations, and many exciting features will be added successively. Stay tuned!</p>
</div>
<details open="">
  <summary>
    
    <span aria-label="Video description avante-2.mp4">avante-2.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description avante-3.mp4">avante-3.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>AI-Powered Code Assistance</strong>: Interact with AI to ask questions about your current code file and receive intelligent suggestions for improvement or modification.</li>
<li><strong>One-Click Application</strong>: Quickly apply the AI's suggested changes to your source code with a single command, streamlining the editing process and saving time.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install <code>avante.nvim</code> using <a href="https://github.com/folke/lazy.nvim">lazy.nvim</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;make&quot;,
  opts = {
    -- add any opts here
  },
  dependencies = {
    &quot;nvim-tree/nvim-web-devicons&quot;, -- or echasnovski/mini.icons
    &quot;stevearc/dressing.nvim&quot;,
    &quot;nvim-lua/plenary.nvim&quot;,
    &quot;MunifTanjim/nui.nvim&quot;,
    --- The below is optional, make sure to setup it properly if you have lazy=true
    {
      'MeanderingProgrammer/render-markdown.nvim',
      opts = {
        file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
      },
      ft = { &quot;markdown&quot;, &quot;Avante&quot; },
    },
  },
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>make<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span><span>--</span> add any opts here</span>
  },
  <span>dependencies</span> <span>=</span> {
    <span><span>"</span>nvim-tree/nvim-web-devicons<span>"</span></span>, <span><span>--</span> or echasnovski/mini.icons</span>
    <span><span>"</span>stevearc/dressing.nvim<span>"</span></span>,
    <span><span>"</span>nvim-lua/plenary.nvim<span>"</span></span>,
    <span><span>"</span>MunifTanjim/nui.nvim<span>"</span></span>,
    <span><span>---</span> The below is optional, make sure to setup it properly if you have lazy=true</span>
    {
      <span><span>'</span>MeanderingProgrammer/render-markdown.nvim<span>'</span></span>,
      <span>opts</span> <span>=</span> {
        <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
      },
      <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
    },
  },
}</pre></div>
<p dir="auto">For Windows users, change the build command to the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1&quot;,
  -- rest of the config
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1<span>"</span></span>,
  <span><span>--</span> rest of the config</span>
}</pre></div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><code>avante.nvim</code> is currently only compatible with Neovim 0.10.0 or later. Please ensure that your Neovim version meets these requirements before proceeding.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">If your neovim doesn't use LuaJIT, then change <code>build</code> to <code>make lua51</code>. By default running make will install luajit.
For ARM-based setup, make sure to also install cargo as we will have to build the tiktoken_core from source.</p>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">Recommended <strong>Neovim</strong> options:</p>
<div dir="auto" data-snippet-clipboard-copy-content="-- views can only be fully collapsed with the global statusline
vim.opt.laststatus = 3
-- Default splitting will cause your main splits to jump when opening an edgebar.
-- To prevent this, set `splitkeep` to either `screen` or `topline`.
vim.opt.splitkeep = &quot;screen&quot;"><pre><span><span>--</span> views can only be fully collapsed with the global statusline</span>
<span>vim</span>.<span>opt</span>.<span>laststatus</span> <span>=</span> <span>3</span>
<span><span>--</span> Default splitting will cause your main splits to jump when opening an edgebar.</span>
<span><span>--</span> To prevent this, set `splitkeep` to either `screen` or `topline`.</span>
<span>vim</span>.<span>opt</span>.<span>splitkeep</span> <span>=</span> <span><span>"</span>screen<span>"</span></span></pre></div>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto"><code>render-markdown.nvim</code> is an optional dependency that is used to render the markdown content of the chat history. Make sure to also include <code>Avante</code> as a filetype
to its setup:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;MeanderingProgrammer/render-markdown.nvim&quot;,
  opts = {
    file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
  },
  ft = { &quot;markdown&quot;, &quot;Avante&quot; },
}"><pre>{
  <span><span>"</span>MeanderingProgrammer/render-markdown.nvim<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
  },
  <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
}</pre></div>
</div>
<p dir="auto">Default setup configuration:</p>
<p dir="auto"><em>See <a href="https://github.com/yetone/avante.nvim/blob/main/lua/avante/config.lua">config.lua#L9</a> for the full config</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  ---@alias Provider &quot;openai&quot; | &quot;claude&quot; | &quot;azure&quot;  | &quot;copilot&quot; | [string]
  provider = &quot;claude&quot;,
  claude = {
    endpoint = &quot;https://api.anthropic.com&quot;,
    model = &quot;claude-3-5-sonnet-20240620&quot;,
    temperature = 0,
    max_tokens = 4096,
  },
  mappings = {
    ask = &quot;<leader>aa&quot;,
    edit = &quot;<leader>ae&quot;,
    refresh = &quot;<leader>ar&quot;,
    --- @class AvanteConflictMappings
    diff = {
      ours = &quot;co&quot;,
      theirs = &quot;ct&quot;,
      none = &quot;c0&quot;,
      both = &quot;cb&quot;,
      next = &quot;]x&quot;,
      prev = &quot;[x&quot;,
    },
    jump = {
      next = &quot;]]&quot;,
      prev = &quot;[[&quot;,
    },
    submit = {
      normal = &quot;<CR>&quot;,
      insert = &quot;<C-s>&quot;,
    },
    toggle = {
      debug = &quot;<leader>ad&quot;,
      hint = &quot;<leader>ah&quot;,
    },
  },
  hints = { enabled = true },
  windows = {
    wrap = true, -- similar to vim.o.wrap
    width = 30, -- default % based on available width
    sidebar_header = {
      align = &quot;center&quot;, -- left, center, right for title
      rounded = true,
    },
  },
  highlights = {
    ---@type AvanteConflictHighlights
    diff = {
      current = &quot;DiffText&quot;,
      incoming = &quot;DiffAdd&quot;,
    },
  },
  --- @class AvanteConflictUserConfig
  diff = {
    debug = false,
    autojump = true,
    ---@type string | fun(): any
    list_opener = &quot;copen&quot;,
  },
}"><pre>{
  <span><span>---</span><span>@alias</span> <span>Provider</span> <span><span>"</span>openai<span>" </span></span><span>| </span><span><span>"</span>claude<span>" </span></span><span>| </span><span><span>"</span>azure<span>"  </span></span><span>| </span><span><span>"</span>copilot<span>" </span></span><span>| </span><span>[string]</span></span>
  <span>provider</span> <span>=</span> <span><span>"</span>claude<span>"</span></span>,
  <span>claude</span> <span>=</span> {
    <span>endpoint</span> <span>=</span> <span><span>"</span>https://api.anthropic.com<span>"</span></span>,
    <span>model</span> <span>=</span> <span><span>"</span>claude-3-5-sonnet-20240620<span>"</span></span>,
    <span>temperature</span> <span>=</span> <span>0</span>,
    <span>max_tokens</span> <span>=</span> <span>4096</span>,
  },
  <span>mappings</span> <span>=</span> {
    <span>ask</span> <span>=</span> <span><span>"</span>&lt;leader&gt;aa<span>"</span></span>,
    <span>edit</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ae<span>"</span></span>,
    <span>refresh</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ar<span>"</span></span>,
    <span><span>---</span><span> @class</span> <span>AvanteConflictMappings</span></span>
    <span>diff</span> <span>=</span> {
      <span>ours</span> <span>=</span> <span><span>"</span>co<span>"</span></span>,
      <span>theirs</span> <span>=</span> <span><span>"</span>ct<span>"</span></span>,
      <span>none</span> <span>=</span> <span><span>"</span>c0<span>"</span></span>,
      <span>both</span> <span>=</span> <span><span>"</span>cb<span>"</span></span>,
      <span>next</span> <span>=</span> <span><span>"</span>]x<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[x<span>"</span></span>,
    },
    <span>jump</span> <span>=</span> {
      <span>next</span> <span>=</span> <span><span>"</span>]]<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[[<span>"</span></span>,
    },
    <span>submit</span> <span>=</span> {
      <span>normal</span> <span>=</span> <span><span>"</span>&lt;CR&gt;<span>"</span></span>,
      <span>insert</span> <span>=</span> <span><span>"</span>&lt;C-s&gt;<span>"</span></span>,
    },
    <span>toggle</span> <span>=</span> {
      <span>debug</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ad<span>"</span></span>,
      <span>hint</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ah<span>"</span></span>,
    },
  },
  <span>hints</span> <span>=</span> { <span>enabled</span> <span>=</span> <span>true</span> },
  <span>windows</span> <span>=</span> {
    <span>wrap</span> <span>=</span> <span>true</span>, <span><span>--</span> similar to vim.o.wrap</span>
    <span>width</span> <span>=</span> <span>30</span>, <span><span>--</span> default % based on available width</span>
    <span>sidebar_header</span> <span>=</span> {
      <span>align</span> <span>=</span> <span><span>"</span>center<span>"</span></span>, <span><span>--</span> left, center, right for title</span>
      <span>rounded</span> <span>=</span> <span>true</span>,
    },
  },
  <span>highlights</span> <span>=</span> {
    <span><span>---</span><span>@type</span> <span>AvanteConflictHighlights</span></span>
    <span>diff</span> <span>=</span> {
      <span>current</span> <span>=</span> <span><span>"</span>DiffText<span>"</span></span>,
      <span>incoming</span> <span>=</span> <span><span>"</span>DiffAdd<span>"</span></span>,
    },
  },
  <span><span>---</span><span> @class</span> <span>AvanteConflictUserConfig</span></span>
  <span>diff</span> <span>=</span> {
    <span>debug</span> <span>=</span> <span>false</span>,
    <span>autojump</span> <span>=</span> <span>true</span>,
    <span><span>---</span><span>@type</span> <span>string </span><span>| </span><span>fun</span><span>(): </span><span>any</span></span>
    <span>list_opener</span> <span>=</span> <span><span>"</span>copen<span>"</span></span>,
  },
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Given its early stage, <code>avante.nvim</code> currently supports the following basic functionalities:</p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">Avante will only support OpenAI (and its variants including copilot and azure), and Claude out-of-the-box due to its high code quality generation.
For all OpenAI-compatible providers, see <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more details.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">For most consistency between neovim session, it is recommended to set the environment variables in your shell file.
By default, <code>Avante</code> will prompt you at startup to input the API key for the provider you have selected.</p>
<p dir="auto">For Claude:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export ANTHROPIC_API_KEY=your-api-key"><pre><span>export</span> ANTHROPIC_API_KEY=your-api-key</pre></div>
<p dir="auto">For OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=your-api-key"><pre><span>export</span> OPENAI_API_KEY=your-api-key</pre></div>
<p dir="auto">For Azure OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export AZURE_OPENAI_API_KEY=your-api-key"><pre><span>export</span> AZURE_OPENAI_API_KEY=your-api-key</pre></div>
</div>
<ol dir="auto">
<li>Open a code file in Neovim.</li>
<li>Use the <code>:AvanteAsk</code> command to query the AI about the code.</li>
<li>Review the AI's suggestions.</li>
<li>Apply the recommended changes directly to your code with a simple command or key binding.</li>
</ol>
<p dir="auto"><strong>Note</strong>: The plugin is still under active development, and both its functionality and interface are subject to significant changes. Expect some rough edges and instability as the project evolves.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Bindings</h2><a id="user-content-key-bindings" aria-label="Permalink: Key Bindings" href="#key-bindings"></a></p>
<p dir="auto">The following key bindings are available for use with <code>avante.nvim</code>:</p>
<ul dir="auto">
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>a</kbd> ‚Äî show sidebar</li>
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>r</kbd> ‚Äî show sidebar</li>
<li><kbd>c</kbd><kbd>o</kbd> ‚Äî choose ours</li>
<li><kbd>c</kbd><kbd>t</kbd> ‚Äî choose theirs</li>
<li><kbd>c</kbd><kbd>b</kbd> ‚Äî choose both</li>
<li><kbd>c</kbd><kbd>0</kbd> ‚Äî choose none</li>
<li><kbd>]</kbd><kbd>x</kbd> ‚Äî move to previous conflict</li>
<li><kbd>[</kbd><kbd>x</kbd> ‚Äî move to next conflict</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlight Groups</h2><a id="user-content-highlight-groups" aria-label="Permalink: Highlight Groups" href="#highlight-groups"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Highlight Group</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>AvanteTitle</td>
<td>Title</td>
</tr>
<tr>
<td>AvanteReversedTitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteSubtitle</td>
<td>Selected code title</td>
</tr>
<tr>
<td>AvanteReversedSubtitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteThirdTitle</td>
<td>Prompt title</td>
</tr>
<tr>
<td>AvanteReversedThirdTitle</td>
<td>Used for rounded border</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODOs</h2><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul>
<li> Chat with current file</li>
<li> Apply diff patch</li>
<li> Chat with the selected block</li>
<li> Slash commands</li>
<li> Edit the selected block</li>
<li> Smart Tab (Cursor Flow)</li>
<li> Chat with project</li>
<li> Chat with selected files</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul dir="auto">
<li><strong>Enhanced AI Interactions</strong>: Improve the depth of AI analysis and recommendations for more complex coding scenarios.</li>
<li><strong>LSP + Tree-sitter + LLM Integration</strong>: Integrate with LSP and Tree-sitter and LLM to provide more accurate and powerful code suggestions and analysis.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions to avante.nvim are welcome! If you're interested in helping out, please feel free to submit pull requests or open issues. Before contributing, ensure that your code has been thoroughly tested.</p>
<p dir="auto">See <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more recipes and tricks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">avante.nvim is licensed under the Apache License. For more details, please refer to the <a href="https://github.com/yetone/avante.nvim/blob/main/LICENSE">LICENSE</a> file.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing stuff is never obvious yet often better (391 pts)]]></title>
            <link>https://www.gkogan.co/removing-stuff/</link>
            <guid>41353328</guid>
            <pubDate>Mon, 26 Aug 2024 01:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gkogan.co/removing-stuff/">https://www.gkogan.co/removing-stuff/</a>, See on <a href="https://news.ycombinator.com/item?id=41353328">Hacker News</a></p>
Couldn't get https://www.gkogan.co/removing-stuff/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Server Setup Basics for Self Hosting (161 pts)]]></title>
            <link>https://becomesovran.com/blog/server-setup-basics.html</link>
            <guid>41353284</guid>
            <pubDate>Mon, 26 Aug 2024 01:50:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://becomesovran.com/blog/server-setup-basics.html">https://becomesovran.com/blog/server-setup-basics.html</a>, See on <a href="https://news.ycombinator.com/item?id=41353284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>This is a post I've been meaning to do for a while. While it's simple to
                explain how to set up an app for self-hosting, it's pointless to host an app on a weak foundation.
                It's a massive pain in my ass to start every how to with a section on server setup, so I'm
                also making this post for myself as a reference on how I like to set up a server for apps I'm
                hosting. I'll start with basic stuff like proper login with SSH and non-root user set up and making
                users for each app. I'll also touch on NGINX setup, some quality of life tools that make server
                management easier, log management and basic network security.<br>‚Äç<br></p>
              <ul role="list">
                <li>
                  <a href="#ssh">SSH</a>
                </li>
                <li>
                  <a href="#users">Users</a>
                </li>
                <li>
                  <a href="#logs">Logs</a>
                </li>
                <li>
                  <a href="#backups">Backups</a>
                </li>
                <li>
                  <a href="#network">Basic Network Safety</a>
                </li>
                <li>
                  <a href="#nginx">NGINX</a>
                </li>
                <li>
                  <a href="#qol">Quality of Life Tools</a>
                </li>
                <li>
                  <a href="#dns">DNS</a>
                </li>
                <li>
                  <a href="#docker">Docker</a>
                </li>
              </ul>
              <h2 id="ssh"><p>SSH</p></h2>
              <p>First is login. You‚Äôll need a way to access your device securely. Don't even
                mess with username and password. You want to use SSH (Secure Shell) and make sure that SSH is the only
                way to log in. To do that, you‚Äôll need an SSH key and a new user account. On a newly provisioned VPS,
                you'll be logged in as root, and you want to protect the root account. First off on the VPS or
                remote machine make a new regular user with and add them to the ‚Äúsudo‚Äù group with:</p>
              <pre contenteditable="false"><code><span>sudo adduser newuser
</span>
sudo usermod -aG sudo newuser</code></pre>
              <p><br>Now on your local machine run:<br></p>
              <pre contenteditable="false"><code><span>ssh-keygen -t ed25519 -C </span><span>"your_email@example.com"</span></code></pre>
              <p><br>Follow the instructions, it should ask you where you want to save the file and
                if you want a password or not. Make sure you set a string one. To copy the public key over to your
                server run on your local machine:</p>
              <pre contenteditable="false"><code><span>ssh-copy-id -i ~/.ssh/id_ed25519.pub newuser@your_server_ip</span></code></pre>
              <p><br>Keep in mind newuser@your-server-ip is the username and the remote device you
                are trying to copy your public key into. When you get prompted for a password, it will be the password
                for the account on the remote device, NOT the password you just made for the SSH key. Once verified, it
                will copy over the public key, and you can now log in Via SSH. To turn off username and password login,
                type in:<br>‚Äç</p>
              <pre contenteditable="false"><code><span>sudo nano /etc/ssh/sshd_config</span></code></pre>
              <p><br>Find these values and set them as you see them here.<br>‚Äç</p>
              <pre contenteditable="false"><code><span>Port 2222     </span><span># Change default port (use a number between 1024 and 65535)</span><span>
</span><span>PermitRootLogin no                 </span><span># Disable root login</span><span>
</span><span>PasswordAuthentication no          </span><span># Disable password authentication</span><span>
</span><span>PubkeyAuthentication yes           </span><span># Enable public key authentication</span><span>
</span><span>AuthorizedKeysFile .ssh/authorized_keys </span><span># Specify authorized_keys file location</span><span>
</span><span>AllowUsers newuser                 </span><span># Only allow specific users to login</span></code></pre>
              <p><br>This disallows every login method besides SSH under the user you copied your
                public key to. Stops login as Root and only allows the user you specify to log in. Hit CTL+S to save and
                CTL+x to get out of the file editor. Restart SSH:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo service ssh restart</span></code></pre>
              <p><br>This might boot you out of the session. If it does, this is a good time to test
                the other login methods to see if they are declined before continuing. Also, it should go without
                saying, but you need to keep the private key safe and if you lose it you will not be able to get in
                remotely anymore.You can further lock down your login with: <br>‚Äç</p>
              <pre contenteditable="false"><code><span>Protocol 2                 </span><span># Use only SSH protocol version 2</span><span>
</span><span>MaxAuthTries 3             </span><span># Limit authentication attempts</span><span>
</span><span>ClientAliveInterval 300    </span><span># Client alive interval in seconds</span><span>
</span><span>ClientAliveCountMax 2      </span><span># Maximum client alive count</span></code></pre>
              <p><br>Now, let's dive into users a bit more and see how we can leverage them for
                a bit of organization and security.</p>
              <h2 id="users"><p>Users</p></h2>
              <div><p>Users are important when it comes to managing a Linux server. There
                is an idea in server management called the ‚ÄúPrinciple of The Least Privilege‚Äù this basically means that
                you want to give an app or process the minimum amount of privileges that it needs to do its job. Root
                has unlimited power, and no app really needs this. Making a user for apps that you're running
                accomplishes a few things. It can limit potential damage if an application you are running is
                compromised. It adds isolation when running more than one app, it helps with auditing so you know what
                app is using what system resources. </p><p>In short, users are a great way of helping organize your
                system and helps you troubleshoot if and when things go wrong. To add a new user, run:<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>sudo useradd -rms /usr/sbin/nologin -c </span><span>"a comment"</span><span> youruser</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like ‚ÄúRunning Nextcloud‚Äù or whatever. Clone app files into the /opt directory with:<br>‚Äç
              </p>
              <pre contenteditable="false"><code><span>sudo mkdir /opt/myapp</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like ‚ÄúRunning Nextcloud‚Äù or whatever. Clone app files into the /opt directory with:<br>‚Äç
              </p>
              <pre contenteditable="false"><code><span>sudo chown appuser:appuser /opt/myapp</span></code></pre>
              <p><br>Ok, with this your login is locked down, and you should have a decent
                idea about how to use users. Next is logs.<br>‚Äç</p>
              <h2 id="logs"><strong><p>Logs</p></strong></h2>
              <p><br>Logs are crucial to system administration. They keep track of system
                health, help troubleshoot issues and detect threats. So you want to set up proper log rotation so they
                do not take up too much space on your system, plus are easier to read and manage. To set up proper log
                rotation, you want to edit the logrotate.conf file located in /etc. Individual application
                configurations are typically stored in /etc/logrotate.d/, so an example configuration for NGINX would
                look like:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>/var/</span><span>log</span><span>/nginx/*.</span><span>log</span><span> {
</span>    weekly
    missingok
    rotate 52
    compress
    delaycompress
    notifempty
    create 0640 www-data adm
    sharedscripts
    postrotate
<span>        [ -f /var/run/nginx.pid ] &amp;&amp; </span><span>kill</span><span> -USR1 `cat /var/run/nginx.pid`
</span>    endscript
}
</code></pre>
              <p><br>This configuration rotates logs weekly, keeps 52 weeks of logs,
                compresses old logs, makes new logs with the right permissions and then signals NGINX to reopen log
                files after rotation. You can test it with:<br></p>
              <pre contenteditable="false"><code><span>sudo logrotate -d /etc/logrotate.conf</span></code></pre>
              <p><br>This will show what it will do without actually rotating logs. With
                this all set up, you can start to do more advanced stuff like triggering alerts based on log entries.
                Now this is good for a single server but if you manage more than one server it's a good idea to
                look into tools like Grafana Loki, Graylog and Fluentd. I won't go into detail here, but if
                you're looking to up your log game, these a decent place to start.<br>‚Äç<br></p>
              <h2 id="backups"><strong><p>Backups</p></strong></h2>
              <div><p>Backups, and more importantly, testing your backups, are extremely
                important in server management. Remember: a backup is not a backup unless you test it. Untested backups
                are essentially useless.</p><p>

                There are three main types of backups. Full, Differential, Incremental. Full backups are a complete copy
                of all data on a disk. Takes the most resources, but is the easiest to restore from. Differential
                backups back up all the changes since the last full backup, it's a middle ground strategy for backups on
                both space and restoration speed. An incremental backup backs up data that was changed since the last
                backup, this is the fastest backup option but can be the most complex to restore.</p><p>

                I think of it like this. I use incremental backups for things like photos and documents or project files
                and folders that get edited a lot. I'll use a full backup for backing up and entire server or disk.
                Differential backups Ill use for backing up full folders like /etc, /opt and log folders.</p><p>

                Now what about storage? If you follow the 3-2-1 rule, you will be golden. 3 copies of your data, 2
                storage types, and 1 offsite backup. I'd say if this seems like too much, the ‚Äúoffsite‚Äù storage is the
                most important and not one to skip. In case of a catastrophic meltdown, having a hard disk with your
                backups is invaluable. Offsite / offline backups can also save your ass from ransomware. So keep that in
                mind. There is a huge amount of backup software out there. <a href="https://github.com/awesome-foss/awesome-sysadmin#backups" target="_blank">This link</a> is for exploring some more
                professional backup tools. <a href="https://github.com/awesome-selfhosted/awesome-selfhosted?tab=readme-ov-file#file-transfer--synchronization" target="_blank">This link</a> has file sync, transfer and could storage solutions. I use a combo
                of sync-thing, Borg backup and good old-fashioned FTP.</p><p>

                Remember, that backup, logs and server monitoring is an evolving process based on your needs. The
                specific strategy you implement should be tailored to your needs and the criticality of your data.</p></div>


              <h2 id="network"><strong><p>Basic Network Safety</p></strong></h2>
              <p><br>The next step in securing a server is to lock down ports that need
                don‚Äôt need to be exposed to the internet and banning things that try to log in when they should not. UFW
                and Fail2Ban are two tools that are in widespread use for this. They are simple and easy to use, UFW
                lets you set traffic rules for ports and Fail2Ban will ban and IP address when it knocks on a port they
                should not be or if they fail to log in after some predefined rules. UFW or uncomplicated firewall often
                comes preinstalled on a lot of VPS services, same with Fail2Ban, but if you are on a new machine and
                you're unsure, run:<br>‚Äç</p>
              <pre contenteditable="false"><code><span>sudo apt install ufw
</span>
sudo apt install fail2ban</code></pre>
              <h3 id="ufw"><strong><br>UFW</strong></h3>
              <p><br>We will worry about Fail2Ban later, for now let's focus on UFW
                setup. First run some default policys with:<br></p>
              <pre contenteditable="false"><code><span>sudo ufw default deny incoming
</span> 
sudo ufw allow outgoing</code></pre>
              <p><br>This is considered best practice, as it follows the ‚Äúthe least
                privileges‚Äù idea I touched on earlier. It reduces attack surface on your machine and gives you precise
                control over what you do expose. In short, this configuration creates a balance between security and
                functionality. Your server can reach out to the internet as needed, but external entities can only
                connect to your server in ways you've explicitly allowed. Now let's allow some stuff
                in.<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo ufw allow ssh
</span>sudo ufw allow 80
sudo ufw allow 443</code></pre>
              <p><br>If you are going to be running a web server, you need port 80 and
                port 443 open. 80 is HTTP and 443 is HTTPS. By default, port 22 is SSH, if you changed this you need to
                specify the port instead of using the ‚Äúallow ssh‚Äù command. Here are some other useful commands:
                <br>‚Äç<br>
              </p>
              <pre contenteditable="false"><code><span>#List rules with numbers:</span><span>
</span>sudo ufw status numbered
<span></span><span>#Delete by number:</span><span>
</span>sudo ufw delete NUMBER
<span></span><span>#Delete by rule specification:</span><span>
</span>sudo ufw delete allow 80
<span></span><span>#You can allow connections from specific IP addresses:</span><span>
</span>sudo ufw allow from 192.168.1.100
<span></span><span>#You can also only allow an IP to connect to a specfic port with: </span><span>
</span>sudo ufw allow from 192.168.1.100 to any port 22
<span></span><span>#If you neeed to allow a range of ports: </span><span>
</span>sudo ufw allow 6000:6007/tcp
<span></span><span>#To further protect from brut force attacks you can rate limit specific ports with: </span><span>
</span><span>sudo ufw </span><span>limit</span><span> ssh
</span><span></span><span>#This would limit port 22 to 6 connections in 30 seconds from a single IP. To see the status of the firewall you can use: </span><span>
</span>
<span></span><span>#Adding this goves you more info</span><span>
</span>sudo ufw status verbose
<span></span><span>#and to reset incase you need to start over: </span><span>
</span>sudo ufw reset
<span></span><span>#and to enable and disable: </span><span>
</span><span>sudo ufw </span><span>enable</span><span> 
</span><span>sudo ufw </span><span>disable</span><span> 
</span>
<span></span><span>#finaly to enable logging and adjusting the log level: </span><span>
</span>sudo ufw logging on
<span>sudo ufw logging medium </span><span># levels are low, medium, high, full </span><span>
</span></code></pre>
              <p><br>On to Fail2Ban now. <br></p>
              <h3 id="ban"><strong><br>Fail2Ban</strong></h3>
              <p>‚Äç<br>The main configuration is located in /etc/fail2ban/jail.conf, but
                it's recommended to create a local configuration file:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
</span>
sudo nano /etc/fail2ban/jail.local</code></pre>
              <p>‚Äç<br>There are some basic settings in the [DEFAULT] section of the
                jail.local section those are:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>bantime = 10m
</span>findtime = 10m
maxretry = 5</code></pre>
              <p>‚Äç<br>Ban time is how long an IP is banned. Find time is the time frame in
                witch Fail2Ban looks for repeated failure, and max retry is the number of failures before an IP is
                banned. You can tune these as you see fit. There are also custom jails you can set, Fail2Ban also
                supports jails for commonly used services like SSH. There are even more steps you can take, but I think
                this covers the basics.<br></p>
              <h3 id="nginx"><strong><p>NGINX</p></strong></h3>
              <div><p>There are a small mess of web servers out there that you can use.
                Apache, Caddy, nginx, IIS to name a few. I use Nginx. It's what I know, and it works really damn
                well. Nginx (pronounced engine-x) is a web server, reverse proxy, and load balancer. As a web server, it
                excels at serving static content and can handle loads of concurrent connections with fairly low resource
                usage. As a reverse proxy, it can sit in front of your application servers and forward traffic to them
                while enchaining the apps' security. Its load balancing aspects can effectively balance traffic
                between servers, improving reliability and scalability. </p><p>When installed via apt, the default
                location for nginx is /etc/nginx/ the nginx.conf is mostly used for global server configuration and
                includes filed from the /etc/nginx/sites-enabled folder. This modular structure allows for easy
                management of multiple sites. Two folders to be aware of are the sites-enabled folder and the
                sites-available folders. You can think of the sites available as a staging place to test your site
                configurations, while the sites enabled is for live sites and apps. A common practice is to set up and
                test your configuration in the sites in the sites available, then when you're ready to go live and
                get an SSL cert, you link the file to the sites-enabled folder. You do that with:<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>ln -s /etc/nginx/sites-available/yoursitefile /etc/nginx/sites-enabled</span></code></pre>
              <p><br>Then reload nginx and double check nginx status with:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl reload nginx
</span>
sudo systemctl status nginx</code></pre>
              <div><p>Your site should be live now.</p><p>Below, I‚Äôll show you some
                boilerplate Nginx site configurations. Be sure to look into your app or sites needs as these are just
                starting points.&nbsp;For static sites, this is a decent starting point.&nbsp;</p></div>
              <p><br>Basic Static Website Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name example.com www.example.com;
    root /var/www/example.com/html;
    index index.html index.htm;
    location / {
<span>        try_files </span><span>$uri</span><span> </span><span>$uri</span><span>/ =404;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>Proxy Pass Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name app.example.com;
    location / {
        proxy_pass http://localhost:3000;
<span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/app.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/app.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/app.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/app.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>WebSocket Upgrade Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name ws.example.com;
    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
<span>        proxy_set_header Upgrade </span><span>$http_upgrade</span><span>;
</span><span>        proxy_set_header Connection </span><span>"upgrade"</span><span>;
</span><span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># WebSocket timeout settings</span><span>
</span>    proxy_read_timeout 300s;
    proxy_send_timeout 300s;
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/ws.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/ws.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/ws.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/ws.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <div><p>The basic configuration is for serving a simple static site. It
                specifies the domain name, listens on port 80 for both IPv4 and IPv6, sets the root directory for the
                site, configures error handling with try_files, adds some basic headers that protect from common web
                vulnerabilities, sets up logging for access and errors and includes a section for SSL that is commented
                out. Most of the SSL config will be handled by certbot, but there are a few lines in there that add some
                SSL security that can be uncommented after certbot is ran.<br>‚Äç<br>The proxy pass configuration is
                similar to the basic configuration, but instead of serving files directly, it proxies requests to a
                local application (in this case, running on port 3000).</p><p>The third configuration file is geared
                towards apps that need website connections, it's a lot like the proxy pass configuration with some
                changes to allow web sockets. &nbsp;</p><p>Ok, any bit about web servers is not really complete without
                talking about SSL. For casual use, certbot is a pleb's best friend. It's free, it is fast, and
                it fucking works. I use the python version of certbot. You can install that with: &nbsp;<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>sudo apt install certbot python3-certbot-nginx</span></code></pre>
              <p><br>Once it's installed you can simply run ‚Äúcertbot‚Äù in your
                terminal, this will detect the configs in your sites-enabled folder and ask what you want to do (renew,
                reissue, etc‚Ä¶). Follow the walk-through, certbot gives you It's pretty straight forward.<br>‚Äç<br>So
                nowadays certbot when getting a new cert will set up auto-renew for you, so it's a sit-and-forget
                kinda task. But to make sure it worked you can run:<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl status certbot.timer</span></code></pre>
              <p><br>if this is up and running, you should be good to go if you're
                using systemd.<br>‚Äç<br></p>
              <h2 id="qol"><strong><p>Quality Of Life Tools</p></strong></h2>
              <div><p>On the topic of tools that make managing your system easier, I'm
                going to present some tools I use on my servers that I think make management just a bit nicer. Not going
                to do a deep dive on any tool. All of these are optional and in no particular order. A lot of these I
                found on the site <a href="https://terminaltrove.com/" target="_blank">terminal trove</a>, a great site
                to browse if you're a terminal junkie like me.&nbsp;</p><p>First tool, <a href="https://terminaltrove.com/btop/" target="_blank">Btop</a> this is in my personal must haves
                list. Btop is a terminal monitor of resources. It shows you real time visuals of usage stats for your
                box‚Äôs CPU, RAM, disks, network and running possesses it's written in C++ and can be installed via
                most package managers.&nbsp;</p><p>For servers that have a lot of outside connections, i.e. a nostr relay, a
                tool like <a href="https://terminaltrove.com/neoss/" target="_blank">Neoss</a> is helpful. Neoss aims to
                replace usual ss command for basic usage. It provides a list of in use TCP and UDP sockets with their
                respective stats. Its main advantage over SS raw output is its clear and simple TUI (terminal user
                interface) that allows you to sort, refresh and navigate what is connected to your machine. It's
                installed Via NPM, meaning you need JavaScript installed.</p><p>
                <a href="https://github.com/allinurl/goaccess" target="_blank">GoAccess</a> is a terminal based log
                analyzer for web servers. It's great for a quick real time look at logs while in the terminal, but
                it can also generate real time HTML, JSON, and CSV reports. GoAccess can be installed via most package
                managers, works on all platforms.&nbsp;</p><p>Next on the list is <a href="https://terminaltrove.com/mc/" target="_blank">MC or ‚Äúmidnight commander‚Äù</a> Its a powerful text based file manager with a two panel
                display and lots of features for manipulating files and directories. It's also cross-platform and
                can be installed via most package managers.&nbsp;</p><p>In the same thread of server file management is <a href="https://dev.yorhel.nl/ncdu" target="_blank">NCDU</a>. This one is in my must-have list. It is a
                disk usage analyzer that is designed to find space hogs. It's fast and very simple to use. It can
                be installed on most systems and package managers. Windows will need Linux subsystems installed to use
                it.&nbsp;</p><p>Hopefully you find some use out of these. The last topic I'd like to touch on is DNS
                it's a bit topic, so I'm not going to do a massive deep dive, but if you're self-hosting
                it helps to have some of the basics of DNS down.&nbsp;ing doesn‚Äôt work.</p></div>
              <h2 id="dns"><strong><p>DNS</p></strong></h2>
              <div><p>DNS or The Domain Name System is a core part of how the internet as we
                know it works. Love it or hate it, it's what we have to work with If you want to be accessible to
                the wider internet. (I dislike what it currently is it, but I‚Äôm not opening that can of worms here.)
                Basically, Think of DNS like a phone book. It‚Äôs what allows you to type duckduckgo.com instead of
                ‚Äú52.250.42.157‚Äù every time you need to search the internet. It translates something easy for humans to
                remember into the information needed by computers to actually reach ‚Äúduckduckgo.com‚Äù</p><p>If
                you're hosting on a VPS, the only thing you really need to know is to know how to point an A record
                at your server's IP after you decide on a domain to use. Pretty much all VPS hosts can give you a
                static IP, so that's mostly a set and forget type deal. </p><p>Hosting from home presents some
                challenges. One prominent one is (and a valid question that I often hear) not having a static IP
                address. Nowadays with the number of devices online needing IP addresses we do a lot of juggling, and
                most IP addresses are assigned dynamically unless you pay for it from your ISP.&nbsp; But there is a
                solution. The answer to this is called Dynamic DNS or DDNS. This allows automatic updating of DNS
                servers every time an IP address changes. There are a mess of ways to set up dynamic DNS. You can host
                your own service or use a host. <a href="https://dynamic.domains/dynamic-dns/providers-list/default.aspx" target="_blank">Here is a
                  link</a> with some hosts and projects to check out.</p><p>In a nutshell, it works like so. You chose
                a provider or set up your own. You get a domain, install the client on your home router or server and
                the client periodically checks to see if the IP address has changed, if so it updates your DNS record
                for that domain.&nbsp;</p></div>
              <h2 id="docker"><strong><p>Docker</p></strong></h2>
              <p>I'm not gonna cover how to install docker here. It's best to
                follow <a href="https://docs.docker.com/engine/install/debian/" target="_blank">the official
                  installation</a> guide anyway. But I want to touch on a few things. First off, docker is useful as
                hell for testing new apps. But that's about as far as I take it. I personally do not like using
                docker all that much, and where possible run applications directly. Here are some pros and cons to keep
                in mind.<br></p>
              <h3><strong>Docker Pros</strong></h3>
              <p>Consistency is a big one it can make things more constant between
                development, testing, and deploying if your system can run docker you can run most docker apps. It can
                help with isolation, reducing conflicts between apps. In some cases it can help with efficiency as it
                takes less resources than traditional VM‚Äôs. It can help with scaling as it's pretty easy to spin up
                more containers and the microservice architecture can be useful because you can break down an
                application into smaller manageable services, allowing for independent scaling of said services. Lastly
                the community is large, so the documentation is good, and community support is always helpful, plus
                there is a wide range of ready to go docker images for deployment.<br></p>
              <h3><strong>Docker Cons</strong></h3>
              <div><p>I‚Äôll start with overhead. While it's better than a traditional VM,
                it uses more resources than running something directly on the host, and I/O operations can be slower.
                The fact that docker shares the system's kernel means that a compromised app could affect the
                system. Persistent data is doable but adds a layer of complexity that can cause data loss with new
                users, it also makes backups more complex. Networking can also be more complex with docker, making it
                not as straightforward. It's also good to note that if you use UFW or firewalld for a firewall,
                docker bypasses those rules. Docker is only compatible with iptables. Also, while a well managed docker
                container can help manage server resources, an improperly manged on can be detrimental to resources as
                well. Containers can get too large, effecting disk size, and misconfiguration can use too many of your
                servers resources. It also adds extra layers of complexity when monitoring and debugging applications,
                especially across multiple containers.</p><p>At the end of the day, it's your system. But I wanted
                to lay out some pros and cons when it comes to using Docker. Moving on.&nbsp; </p></div>
              <h2><strong><p>Wrap Up</p></strong></h2>
              <p>Well, that about does it for the basics of server setup and tools. There
                is a <a href="https://git.sovbit.dev/Enki/sovran-scripts" target="_blank"> a script that I wrote</a> that will do most of this for you. I wrote it to make my own server setup faster.
                You can get that here, it includes all of my must-haves and does some basic configuration. Tweak it to
                your own needs, and as always stay safe out there and ping me on nostr or simplex if you have questions
                or if I fucked something up in this post.<br></p>
              
              
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senior Intel CPU architects splinter to develop RISC-V processors (148 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</link>
            <guid>41353155</guid>
            <pubDate>Mon, 26 Aug 2024 01:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing">https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</a>, See on <a href="https://news.ycombinator.com/item?id=41353155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: AheadComputing)</span>
</figcaption>
</div>

<div id="article-body">
<p>While Intel is busy laying off thousands of employees some of its most experienced CPU architects, with a combined 80+ years at the firm, have left to form a RISC-V startup. <a data-analytics-id="inline-link" href="https://www.aheadcomputing.com/" data-url="https://www.aheadcomputing.com/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">AheadComputing</a> was co-founded by Debbie Marr, Mark Dechene, Jonathan Pearce, and Srikanth Srinivasan, with the goal of ‚Äúcreating compelling open specification core IP.‚Äù This proactive move by the quartet of architects and engineers must be congratulated, as they founded AheadComputing and went public on July 18 ‚Äì just a couple of weeks before Intel‚Äôs harsh <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend">workforce reduction plans</a> were announced.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg"></picture></p></div><figcaption itemprop="caption description"><span>Everyone deserves a better website </span><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>AheadComputing‚Äôs website is rather basic and threadbare at the time of writing, but it does contain a mission statement of sorts, some short bios detailing the ex-Intel co-founders, a single blog post (launch announcement), and a call for new recruits with experience in CPU design and verification roles.</p><p>As indicated above, the work of AheadComputing is going to begin with work on the RISC-V architecture. Specifically, the fledgling firm has set out with a plan ‚Äúdedicated to designing, verifying, and licensing compelling RISC-V core IP.‚Äù For any deeper dive into the goings-on behind the doors of the new Oregon-based firm, you will have to chat with them directly or wait for further blogging. However, they will also meet with people during Happy Hour on Tuesdays, between 4 - 5:30 pm, at Cornelius Pass Roadhouse, Hillsboro‚Ä¶</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>The most compelling feature of AheadComputing is, for now, its co-founders, so let‚Äôs take a closer look at their resumes.</p><p>Co-founder, CEO, &amp; President, Dr. Debbie Marr was an Intel Fellow and Chief Architect of the Advanced Architecture Development Group (AADG) at Intel and spent 33 years at the chipmaker on products spanning the i386 all up to the present day. A highlight of her career seems to have been bringing Intel Hyperthreading Technology from concept to finished product. Marr also authored over 40 patents in CPU, AI accelerators, and FPGA fields.</p><p>Co-Founder, Mark Dechene was an Intel Principal Engineer and CPU Architect in the Advanced Architecture Development Group. During his 16 years at Intel Dechene worked on architecture development for Intel CPU products including Haswell, Broadwell, Goldmont, Goldmont Plus, Tremont, and Skymont. Dechene has authored over 15 patents, focused on microprocessor performance.</p><p>Co-Founder, Jonathan Pearce was an Intel Principal Engineer, CPU Architect, and a key technologist &amp; strategist in the Advanced Architecture Development Group until recently. Pearce worked for 22 years at Intel. During his career, Pearce has worked in both pre-silicon and post-silicon roles on multiple generations of Intel Core SOCs. He also authored 19 patents in the CPU, AI, and GPU fields.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-k6SrjEwfa6jCtt4TU4Epnh"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>Co-Founder, Dr. Srikanth Srinivasan has over 20 years of technical leadership experience in product R&amp;D. At Intel he taped out some well-known chip designs like Nehalem, Haswell, and Broadwell. However, most recently, Srinivasan led the frontend and backend CPU teams at the Advanced Architecture Development Group at Intel. The highlight of his career / achievements so far is probably the authoring of more than a dozen highly cited papers and over 50 patents.</p><p>With its pedigree, surely we will hear about AheadComputing again, in the not-too-distant future. On the flip side, PC enthusiasts may rightly worry about the future of Intel when it has just instigated the most severe layoff plans in its 56-year history, some of its ambitious construction plans have come into question, and severe brain drain, as evidenced by this new RISC-V startup, could slow any chances of revival.</p>
</div>
<div id="slice-container-authorBio-k6SrjEwfa6jCtt4TU4Epnh"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>



<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We found North Korean engineers in our application pile (149 pts)]]></title>
            <link>https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</link>
            <guid>41353079</guid>
            <pubDate>Mon, 26 Aug 2024 01:18:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile">https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</a>, See on <a href="https://news.ycombinator.com/item?id=41353079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Cinder is part of a growing list of US-based tech companies that encounter engineering applicants who are actually suspected North Korean nationals. These North Koreans almost certainly work on behalf of the North Korean government to <a href="https://apnews.com/article/north-korea-weapons-program-it-workers-f3df7c120522b0581db5c0b9682ebc9b">funnel money back</a> to their government while working remotely via third countries like China. Since at least early 2023, many have applied to US-based remote-first tech companies like Cinder. If you‚Äôve been running into this issue, here are some tips for how you can handle this at your own company.</p><p>It‚Äôs important to note that funding the North Korean government could constitute a crime given <a href="https://ofac.treasury.gov/sanctions-programs-and-country-information/north-korea-sanctions">the sanctions</a> the regime is under. And nobody wants that kind of paperwork headache!</p><p>Cinder is unique in our ability to interface with this issue given our co-founders‚Äô backgrounds as ex-CIA operatives, as well as an expert on North Korea. Our prior experience spurred our interest in building internet safety software to begin with, and inspires a particular vigilance to maintain it to the best of our abilities.</p><p>I first learned of North Korea‚Äôs practice of sending workers abroad in 2014: I joined the board of a leadership development program for North Korean escapees and learned of North Korea‚Äôs government and its use of technology from those who experienced it firsthand. Later, I volunteered for a nonprofit developing information access technology for clandestine use inside closed countries like North Korea. I have spoken with North Korean escapees who have recent knowledge of the latest North Korean tech worker trends. But I never expected I would one day experience them as applicants attempting to join my company.&nbsp;</p><h2>North Koreans are applying to US tech companies?</h2><p>The North Korean government has a <a href="https://www.bloomberg.com/news/features/2018-02-07/inside-kim-jong-un-s-hacker-army">long history</a> of sending workers abroad to earn money for the regime. The workers are sent to countries like China where they must earn a salary quota, most of which will be taken by the government for its own needs. These workers are under close supervision by North Korean officials while abroad. They are often required to leave family members behind as collateral to prevent them from defecting while outside their home country.&nbsp;</p><p>North Koreans have been working undercover as software freelancers for part time contract jobs for years. And recently, they have <a href="https://blog.knowbe4.com/how-a-north-korean-fake-it-worker-tried-to-infiltrate-us">started</a> to apply to American tech companies that offer remote, full time work. This may be exacerbated by the rise of remote work after the COVID pandemic and the fact that working at US tech companies can be so lucrative. Hyun-Seung Lee, a former North Korean businessman and former chair of the Kim Il Sung Socialist Youth League branch in Dalian, China, told us that the earnings quota for a North Korean IT worker based in China is typically $6,000 per month. This quota is more than covered by many US tech salaries.</p><h2>The application process</h2><p>In our experience, North Koreans applying to US tech companies under false pretenses will often use a standard process: they will create profiles on multiple professional networking and job posting sites using a name that is not Korean and sometimes with an AI-edited profile image.&nbsp;</p><p>Once they go through the interview process and have received a job offer, they may ask their new company-provided laptop be <a href="https://www.bleepingcomputer.com/news/security/us-dismantles-laptop-farm-used-by-undercover-north-korean-it-workers/">sent to a US-based partner</a>. According to a Department of Justice <a href="https://www.justice.gov/usao-dc/media/1352191/dl">indictment</a>, the US-based partner may install remote desktop software so that the North Korean engineer can appear to be working from a US location, with a laptop physically located in the US, while remotely controlling the laptop from abroad.</p><p>By demonstrating sufficient technical capability and minimal English language skills, North Korean applicants can meet minimum thresholds for junior software engineer roles. Fast-growing start-ups eager to ship more products might overlook gaps in resume, unreliable or missing education records, or poor command of written or spoken English for an engineer with sufficient skill who is ready to start working soon.&nbsp;</p><p>We suspect if the worker is employed even for just a few months before being terminated, this can still be quite profitable for the regime.</p><h2>Cinder‚Äôs approach</h2><p>We have a unique perspective on this problem for a few reasons: our company is in the internet safety industry, two of our co-founders came from the CIA, and I have twelve years of experience working on cybersecurity and human rights issues related to North Korea. So when North Korean IT workers applied to Cinder, they had a different experience than they might have expected.</p><blockquote><em>Pyongyang has a long history of exploiting its people to further the regime‚Äôs ambitions and this activity is no exception. Two of Cinder‚Äôs founders bring years of CIA experience, so we‚Äôre no strangers to creating and running virtual operations, nor detecting and countering those of hostile nation states.<br>‚Äç<br>- Phil Brennan, Cinder co-founder and 10-year CIA veteran</em></blockquote><h3>What tipped us off</h3><p>Fifteen months prior to any <a href="https://www.bleepingcomputer.com/news/security/five-arizona-ukraine-charged-for-cyber-schemes-infiltrating-over-300-companies-to-benefit-north-koreas-weapons-program/">FBI indictments</a>, our COO first noticed a few unusual trends in our applicant pool. Upon further inspection he discovered these candidates either didn't seem to exist on the internet, or were mapped to people who weren't them, who did have an internet presence. Over time, we realized many applicants that had the following characteristics:</p><ol role="list"><li>No online presence outside of professional networking websites; and professional networking profiles were recently created, typically with profile pictures that obscured the individual‚Äôs image (in ski goggles, sunglasses), were too zoomed out to be helpful, were AI-generated, or were simply blank.&nbsp;</li><li>Completely fabricated job history including office locations that don‚Äôt actually exist.&nbsp;</li><li>Unable to find these applicants online outside of the standard professional networking sites (e.g. no presence on GitHub, social media etc).</li><li>Inability to answer basic questions about the cities in which they allegedly worked (‚ÄòWhat was your Metro stop in Paris?‚Äô) or technology on which they worked (‚ÄòWhat org were you in at Uber?‚Äô).</li><li>Background noise during their interview that indicated other people speaking in an interview-like setting, implying a crowded room of people on separate professional video calls.</li><li>Highly scripted answers with explicit preference for remote work, and little ability to deviate from the script.</li><li>A mismatch between the name displayed on the resume or networking site, and the candidate‚Äôs command of English (e.g. Chris Smith with a B.A. from a large US research university who can barely speak interview-level English is surprising).&nbsp;</li></ol><p>We also noticed vague cover letter language:</p><blockquote><em>Hi, team!<br>I hope you're fine and safe.&nbsp;<br>I am really excited about this potential opportunity with the ambitious project.<br>As a Senior Frontend Developer with 8+ years of experience, I have great experience in working with React.js/Redux, RTK, React Query, Vue, Next.js, Vercel, TypeScript, GraphQL, etc.</em> <em>Please have a look at my previous works.</em></blockquote><p>Another example: </p><blockquote><em>Hi,</em> <br>‚Äç<em>I love what you are doing in your company. With my eight-plus years of development, I'd love to be one of you.</em> <em>As an FE-heavy developer, I have a track record of building successful products. And I am familiar with startup environment.</em> <em>I'd love to use my strong debugging and problem-solving abilities to be a powerful force in the workplace. I can wear multiple hats and adapt to a fast-paced team.</em> <em>I look forward to meeting you to learn more about this role and share my relevant skills.</em> <em>Best,</em></blockquote><p>Taken together, to me these details suggested fake identities. And while I knew North Korea had a history of sending workers abroad to freelance, I didn‚Äôt expect that they would apply to full time roles at US-based companies.</p><h3>What we did</h3><p>First, because we come from the Trust and Safety industry, I was able to reach out to our partners at various security companies and confirm these patterns were consistent with North Koreans attempting to pass themselves off as Americans. I also learned a lot from published investigations like the one <a href="https://www.nisos.com/research/dprk-it-worker-scam/">Nisos published last year</a>.</p><p>With more knowledge, we were able to go digging. And we had a lot of material: For applicants from some job sites, roughly 80% of inbound applicants with experience matching our stack were suspected North Koreans.&nbsp;</p><p>We started filtering out suspected North Korean applicants by doing quick internet searches and closer examinations of job history, profile imagery, and a social media screening. However, our process wasn‚Äôt perfect, and we still ended up on occasional Zoom calls screening applicants who we would quickly discover, mid-call, had fabricated their career history and only recently created their online presence.</p><p>When we first started receiving North Korean applications, some of our interviewers noted applicants‚Äô strong resistance to travel in their post-interview write ups:</p><blockquote><em>One clarifying question that I neglected to ask about is that on his Linkedin profile he says he is&nbsp; looking for ‚Äú100% Remote job only without travel‚Äù. I did not notice the ‚Äúwithout travel‚Äù part until after the interview. We should make sure he would be willing to travel sometimes for team offsites as this is an important part of Cinder‚Äôs culture.</em></blockquote><p>I started informing candidates that Cinder‚Äôs customer base includes companies investigating nation-state espionage and insider threat issues. I added that this is a natural fit for us, because our co-founders came from the US intelligence community including the CIA.&nbsp;</p><p>Upon hearing this, one suspected North Korean applicant immediately dropped from the Zoom call and never contacted us again.</p><h2>What Cinder is doing now</h2><p>We continue to receive dozens of suspected North Korean applicants to Cinder. We take steps to share relevant information with security teams at networking and job listing sites that we work with. If your company is also affected by this growing threat, I encourage you to get in touch with me at <a href="mailto:declan@cndr.io">declan@cndr.io</a> and I‚Äôd be happy to share more tips and prevention strategies.&nbsp;</p><p>‚Äç</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber loses New Zealand appeal, court rules drivers are employees not contractors (109 pts)]]></title>
            <link>https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</link>
            <guid>41352997</guid>
            <pubDate>Mon, 26 Aug 2024 01:05:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/">https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</a>, See on <a href="https://news.ycombinator.com/item?id=41352997">Hacker News</a></p>
Couldn't get https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Australian employees now have the right to ignore work emails, calls after hours (411 pts)]]></title>
            <link>https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</link>
            <guid>41352681</guid>
            <pubDate>Mon, 26 Aug 2024 00:08:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/">https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</a>, See on <a href="https://news.ycombinator.com/item?id=41352681">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Police Chief Says Cops Have a 5th Amendment Right to Leave Body Cameras Off (199 pts)]]></title>
            <link>https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/</link>
            <guid>41351993</guid>
            <pubDate>Sun, 25 Aug 2024 22:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/">https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/</a>, See on <a href="https://news.ycombinator.com/item?id=41351993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>Albuquerque, New Mexico, Police Chief Harold Medina operated his department-issued pickup truck "in an unsafe manner" on February 17, when he ran a red light and broadsided a car, severely injuring the driver. So concludes a recent <a href="https://s3.documentcloud.org/documents/25056680/i-171-24-medina-martinez-final_redacted.pdf">report</a> from internal investigators who looked into that shocking incident.</p> <p>Duh, you might say if you have seen <a href="https://www.youtube.com/watch?v=DvSVzDimSAk">surveillance camera footage</a> of the crash, which shows Medina crossing Central Avenue, a busy, four-lane street, against the light. He crosses the westbound lanes through a gap between two cars, forcing one of the drivers to brake abruptly, before barreling across the eastbound lanes, where he rams into the side of a gold 1966 Mustang driven by 55-year-old Todd Perchert.</p> <p>Although Medina's recklessness seems obvious, the Albuquerque Police Department's Fleet Crash Review Board (CRB) earlier this year <a href="https://reason.com/2024/04/04/albuquerques-police-chief-ran-a-red-light-and-broadsided-a-car-a-review-board-says-it-was-unavoidable/">concluded</a> that the crash was "non-preventable." How so? Medina, who was on his way to a Saturday press conference with his wife when he took a detour to have a look at a homeless encampment, said he ran the light to escape an altercation between two homeless men that had escalated into gunfire at the intersection of Central and Alvarado Drive.</p> <p>While "the initial decision to enter the intersection is not in question," Lt. James Ortiz says in the Internal Affairs report, "the facts and circumstances do not relieve department personnel of driving safely to ensure no additional harm is done to personnel or to citizens." Medina, Ortiz says, clearly failed to do that: "By definition, driving into a crosswalk, darting between two vehicles driving on a busy street, and crossing through an intersection with vehicles traveling eastbound were unsafe driving practices." In this case, he notes, those unsafe practices "resulted in a vehicle collision with serious physical injuries to the victim, including a broken collarbone and shoulder blade, 8 broken ribs (reconstructed with titanium plates after surgery), collapsed lung, lacerations to left ear and head, multiple gashes to his face, a seven-hour surgery, and hospitalization requiring epidural painkiller and a chest tube for nearly a week."</p> <p>Ortiz not only disagrees with the CRB's conclusion about Medina's crash; he says the board never should have reviewed the incident to begin with, since its mission is limited to accidents "not resulting in a fatality or serious injury." Ortiz says Commander Benito Martinez, who chairs the CRB, violated department policy when he decided the board should pass judgment on Medina's accident.</p> <p>Martinez acknowledged that department policy "prohibited the CRB from hearing serious injury crashes" and that "allowing such a case to be heard would be a policy violation." Why did he allow it anyway? "He explained that his reasoning for permitting the Chief's crash to be reviewed by the CRB was based on his belief that someone wanted the crash to be heard," Ortiz writes. "Cmdr. Martinez clarified that he believed someone from Internal Affairs wanted the case to be heard by the CRB to ensure full transparency. However, he did not consult with anyone in Internal Affairs to verify the accuracy of this assumption."</p> <p>Both the CRB's decision to review the crash and its implicit exoneration of Medina are hard to fathom. But Medina's explanations for the third policy violation identified by Ortiz‚Äîthe chief's failure to activate his body camera after the crash‚Äîare even weirder.</p> <p>"After the collision occurred, the shooting victim approached," Ortiz writes. "The victim informed the Chief that he was okay and had not been shot. Chief Medina asked the victim to remain at the scene, but the victim refused and fled southbound on Alvarado. Another citizen approached the Chief and reported having seen individuals leaving a black truck and fleeing away from the scene. Chief clarified with the witness that no one was outstanding. It is important to note that these interactions were not recorded and are contacts that require mandatory recording."</p> <p>Medina offered two puzzling excuses for leaving his camera off. He&nbsp;"cited intermittent conversations with his wife, who was a passenger in his unmarked patrol vehicle at the time of the collision," Ortiz says. "He claimed there was a right to privileged communication between spouses, which specifically exempted him from mandatory recording requirements." But the relevant policy "does not provide for nonrecording based on spousal privilege."</p> <p>Even more troubling, Medina said he "purposefully did not record because he was invoking his 5th Amendment right not to self-incriminate." Since "he was involved in a traffic collision," he reasoned, he was "subject to 5th Amendment protections."</p> <p>Think about the implications of that argument. Body cameras are supposed to help document (and perhaps deter) police misconduct. But Medina is suggesting that cops have a constitutional right to refrain from recording their interactions with the public whenever that evidence could be used against them. By turning on their cameras in those situations, he argues, police could be incriminating themselves. That is the whole point.</p> <p>Medina received two official <a href="https://www.abqjournal.com/news/albuquerque-police-chief-reprimanded-for-crash-that-injured-man/article_48c6c9de-455d-11ef-a7de-77dd5b86acc9.html">reprimands</a> for the camera violation and the reckless driving that injured Perchert, a casualty of the police chief's desperation to save his own skin. In similar situations, other Albuquerque police officers have been <a href="https://reason.com/2024/04/04/albuquerques-police-chief-ran-a-red-light-and-broadsided-a-car-a-review-board-says-it-was-unavoidable/">fired</a>. But after the crash, Albuquerque Mayor Tim Keller <a href="https://www.koat.com/article/victim-crash-involving-albuquerque-police-chief-medina/60324357">hailed</a> Medina as a hero who is "out on the front line‚Ä¶doing what he can to make our city safe."</p>						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why am I writing a Rust compiler in C? (363 pts)]]></title>
            <link>https://notgull.net/announcing-dozer/</link>
            <guid>41351446</guid>
            <pubDate>Sun, 25 Aug 2024 21:08:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notgull.net/announcing-dozer/">https://notgull.net/announcing-dozer/</a>, See on <a href="https://news.ycombinator.com/item?id=41351446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>To bootstrap Rust, no cost is too great.</p>

<p>Perceptive Rustaceans may have noticed my activity has gone down as of late.
There are a handful of different reasons for this. I‚Äôve been the subject of a
truly apocalyptic series of life events, including the death of a relative that
rattled me to my core. I‚Äôve had more responsibilities at work, leaving me with
less time and energy to contribute. Maybe I‚Äôve also lost a little bit of the
college-kid enthusiasm that brought me to open source in the first place.</p>

<p>There‚Äôs another reason, too. I‚Äôve been cooking up a project that‚Äôs been taking
up most of my time. It‚Äôs certainly the largest project I‚Äôve created in the open
source world, and if I complete it, it will certainly be my crowning
achievement.</p>

<p>I am writing a Rust compiler in pure C. No C++. No <a href="https://en.wikipedia.org/wiki/Flex_(lexical_analyser_generator)"><code>flex</code></a> or <a href="https://en.wikipedia.org/wiki/Yacc"><code>yacc</code></a>. Not even a
<a href="https://en.wikipedia.org/wiki/Make_(software)"><code>Makefile</code></a>. Nothing but pure C.</p>

<p>It‚Äôs called <a href="https://codeberg.org/notgull/dozer">Dozer</a>.</p>

<h2 id="wait-why">Wait, Why?</h2>

<p>To understand why I‚Äôve followed this path of madness, you first need to
understand bootstrapping and why it is important.</p>

<p>Let‚Äôs say that you‚Äôve written some code in Rust. In order to run this code, you
need to <em>compile</em> it. A <em>compiler</em> is a program that parses your code, validates
its correctness, and then transforms it into machine code that the CPU can
understand.</p>

<blockquote>
  <p><img src="https://notgull.net/images/ddog.jpg" alt="Dependency Dog" width="100">
<strong>Dependency Dog:</strong> Yes, it‚Äôs significantly more complicated than that. Except when it‚Äôs less complicated than that. Compilers are tricky to even describe.</p>
</blockquote>

<p>For Rust, your main compiler is <a href="https://github.com/rust-lang/rust">rustc</a>. If you don‚Äôt know, this is the
underlying program that <code>cargo</code> calls when you run <code>cargo build</code>. It‚Äôs fantastic
software, and frankly a gem of the open source community. Its code quality is up
there with the Linux kernel and the Quake III source code.</p>

<p>However, <a href="https://github.com/rust-lang/rust">rustc</a> itself is a program. So it needs a compiler to compile it from
its source code to machine code. Say, what language <em>is</em> <a href="https://github.com/rust-lang/rust">rustc</a> written in?</p>

<p><img src="https://notgull.net/images/rustc-in-rust.png" alt="rustc is 97.3 percent rust"></p>

<p>Ah, <a href="https://github.com/rust-lang/rust">rustc</a> is a Rust program. Written in Rust, for the purpose of compiling
Rust code. But, think about this for a second. If <a href="https://github.com/rust-lang/rust">rustc</a> is written in Rust,
and <a href="https://github.com/rust-lang/rust">rustc</a> is needed to compile Rust code, that means you need to use <a href="https://github.com/rust-lang/rust">rustc</a>
to compile <a href="https://github.com/rust-lang/rust">rustc</a>. Which is fine for us users, since we can just download
<a href="https://github.com/rust-lang/rust">rustc</a> from the internet and use it.</p>

<p>But, who compiled the first <a href="https://github.com/rust-lang/rust">rustc</a>? There had to be a chicken before the egg,
right? Where does it start?</p>

<p>‚Ä¶</p>

<p>Actually, that‚Äôs fairly simple. Every new version of <a href="https://github.com/rust-lang/rust">rustc</a> was compiled with
the previous version of <a href="https://github.com/rust-lang/rust">rustc</a>. So <a href="https://github.com/rust-lang/rust">rustc</a> version 1.80.0 was compiled with
<a href="https://github.com/rust-lang/rust">rustc</a> version 1.79.0. Which was, in turn, compiled with <a href="https://github.com/rust-lang/rust">rustc</a> version
1.78.0. And so on and so forth, all the way back to <a href="https://github.com/rust-lang/rust/tree/ef75860a0a72f79f97216f8aaa5b388d98da6480">version 0.7</a>
if the compiler. At that point, the compiler was written in <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a>. So all you
needed was an OCaml compiler to get a fully functioning <a href="https://github.com/rust-lang/rust">rustc</a> program.</p>

<p>There, problem solved! We‚Äôve figured out how to create <a href="https://github.com/rust-lang/rust">rustc</a> from first
principles! All is well, let‚Äôs go back to business.</p>

<p>Just one more thing. We still need a version of the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler for all of
this to work. So what language is the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler written in?</p>

<p><img src="https://notgull.net/images/ocaml-in-ocaml.png" alt="OCaml is 84 percent OCaml"></p>

<p><em>faceplant</em></p>

<p>Okay, okay, no worries! There is a <a href="https://github.com/Ekdohibs/camlboot">project</a>
that can successfully compile the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler using <a href="https://en.wikipedia.org/wiki/GNU_Guile">Guile</a>, which is one of the many
variants of <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a>, which is one of many variants of <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a>. Not to mention,
<a href="https://en.wikipedia.org/wiki/GNU_Guile">Guile</a>‚Äôs interpreter is written in C.</p>

<p>So this brings us, as all eventually things do, to the C programming language. We just
compile it using <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, and everything works out. So we just need to compile
<a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, which is written using‚Ä¶ C++?!</p>

<p>Okay, that‚Äôs a little unfair. <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a> was written in C until version 5, and it‚Äôs
not like there‚Äôs a shortage of C compilers written in C out there. For instance,
consider <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>, which is written in C and handles not only compiling, but
assembly and linking too.</p>

<p>‚Ä¶but that still doesn‚Äôt answer our question. What was the first C compiler
written in? Assembly? Then what was the first assembler written in?</p>

<h2 id="the-descent-principle">The Descent Principle</h2>

<p>This is where we introduce the <a href="https://bootstrappable.org/">Bootstrappable Builds</a>
project. To me, this is one of the most fascinating projects in the open source
community. It‚Äôs basically code alchemy.</p>

<p>Their <a href="https://github.com/fosslinux/live-bootstrap">Linux bootstrap process</a>
starts with a 512-byte binary seed. This seed contains what‚Äôs possibly the
simplest compiler you can imagine: it takes hexadecimal digits and outputs the
corresponding raw bytes. As an example, here part of the ‚Äúsource code‚Äù that‚Äôs
compiled with this compiler.</p>

<div><pre><code>31 C0           # xor ax, ax
8E D8           # mov ds, ax
8E C0           # mov es, ax
8E D0           # mov ss, ax
BC 00 77        # mov sp, 0x7700
FC              # cld ; clear direction flag
88 16 15 7C     # mov [boot_drive], dl
</code></pre></div>

<p>Note that everything after the pound sign is a comment, and all whitespace is
stripped. Frankly, I‚Äôm not even sure this can be called a programming language.
Still, it is <em>technically</em> analyzable, dissectable source code.</p>

<p>From here, this compiler compiles a very simple operating system, a barebones
shell, and a slightly more advanced compiler. That compiler compiles a slightly
more advanced compiler. A few steps later, you have something that roughly
<em>looks</em> like assembly code.</p>

<div><pre><code>DEFINE cmp_ebx,edx 39D3
DEFINE je 0F84
DEFINE sub_ebx, 81EB

:loop_options
    cmp_ebx,edx                         # Check if we are done
    je %loop_options_done               # We are done
    sub_ebx, %2                         # --options
</code></pre></div>

<p>Man, it‚Äôs weird to think of <em>assembly code</em> as being higher-level than anything
else, right?</p>

<p>This is enough to get them to a very basic subset of C. Then they compile a
slightly more advanced C compiler written in this subset. A few steps later they
can compile <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>. From there they can bootstrap <a href="https://en.wikipedia.org/wiki/Yacc"><code>yacc</code></a>, basic coreutils,
Bash, autotools, and eventually <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a> and Linux.</p>

<p>I‚Äôm not doing this justice, it‚Äôs a fascinating process. Every step is listed
<a href="https://github.com/fosslinux/live-bootstrap/blob/master/parts.rst">here</a>.</p>

<p>Anyhow, you‚Äôve essentially gone from ‚Äúa binary blob small enough to be manually
analyzed‚Äù to Linux, GCC, and basically everything else. But let‚Äôs start again
from <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>.</p>

<p>Right now, Rust shows up very late into this process. They use <a href="https://github.com/thepowersgang/mrustc">mrustc</a>, an
alternative Rust implementation written in C++ that can compile <a href="https://github.com/rust-lang/rust">rustc</a> version
1.56. From here, they then compile up to modern Rust code.</p>

<p>The main issue here is that, by the time C++ is introduced into the bootstrap
chain, the bootstrap is basically over. So if you wanted to use Rust at any
point before C++ is introduced, you‚Äôre out of luck.</p>

<p>So, for me, it would be <em>really nice</em> if there was a Rust compiler that could be
bootstrapped from C. Specifically, a Rust compiler that can be bootstrapped from
<a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>, while assuming that there are no tools on the system yet that could be
potentially useful.</p>

<p>That‚Äôs <a href="https://codeberg.org/notgull/dozer">Dozer</a>.</p>

<h2 id="the-plan">The Plan</h2>

<p>I‚Äôve been working on <a href="https://codeberg.org/notgull/dozer">Dozer</a> for the past two months, putting my anemic free
time to work on writing in a language that I kind of hate.</p>

<blockquote>
  <p><img src="https://notgull.net/images/ddog.jpg" alt="Dependency Dog" width="100">
<strong>Dependency Dog:</strong> That‚Äôs a little unfair. C has some elegant qualities to it. Reality truly is what you make of it. It‚Äôs just that I would not let this code anywhere near production.</p>
</blockquote>

<p>It‚Äôs written with no extensions, and so far both <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a> and <a href="https://sr.ht/~mcf/cproc/">cproc</a> are able
to compile it with no issues. I‚Äôm using <a href="https://c9x.me/compile/">QBE</a> as a backend. Other than that, I
assume no tools exist on the system. Just a C compiler, some very basic shell
implementation, and nothing else.</p>

<p>I won‚Äôt get into the raw <em>experience</em> of writing a compiler in this blogpost.
But so far, I have the lexer done, as well as a sizable part of the parser.
Macro/module expansion is something I‚Äôm putting off as long as possible,
typechecking only supports <code>i32</code>, and codegen is a little bit rough. But it‚Äôs a
start.</p>

<p>I can successfully compile this code:</p>

<div><pre><code><span>fn</span> <span>rust_main</span><span>()</span> <span>-&gt;</span> <span>i32</span> <span>{</span>
    <span>(</span><span>2</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>6</span> <span>+</span> <span>3</span>
<span>}</span>
</code></pre></div>

<p>So, where to from here? Here‚Äôs my plan.</p>

<ul>
  <li>Slowly advance <a href="https://codeberg.org/notgull/dozer">Dozer</a> until it can compile some basic <code>libc</code>-using samples,
then <code>libcore</code>, then <a href="https://github.com/rust-lang/rust">rustc</a>.
    <ul>
      <li>For the record, I‚Äôm planning on compiling <a href="https://github.com/rust-lang/rust">rustc</a>‚Äôs <a href="https://github.com/rust-lang/rustc_codegen_cranelift">Cranelift</a>
backend, which is written entirely in Rust. Since we‚Äôre assuming we don‚Äôt
have C++ yet, we can‚Äôt compile LLVM.</li>
    </ul>
  </li>
  <li>Create a <code>cargo</code> equivalent that can use <a href="https://codeberg.org/notgull/dozer">Dozer</a> to compile Rust packages.</li>
  <li>Find out which sources in <a href="https://github.com/rust-lang/rust">rustc</a> are automaticaly generated and then strip
them out. By the Bootstrappable project‚Äôs rules, automatically generated code
is not allowed.</li>
  <li>Create a process that can be used to compile <a href="https://github.com/rust-lang/rust">rustc</a> and then <code>cargo</code>, then
use our compiled versions of <a href="https://github.com/rust-lang/rust">rustc</a>/<code>cargo</code> to re-compile canonical versions
of <a href="https://github.com/rust-lang/rust">rustc</a>/<code>cargo</code>.</li>
</ul>

<p>This will definitely be the hardest project I‚Äôve ever undertaken. Part of me
doubts that I will be able to finish it. But you know what? It‚Äôs better to have
tried and lost than to never have tried at all.</p>

<p>Stay tuned for more <a href="https://codeberg.org/notgull/dozer">Dozer</a> updates, as well as an explanation of the
architecture I have planned.</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pi Pico 2 Extreme Teardown (143 pts)]]></title>
            <link>http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html</link>
            <guid>41351380</guid>
            <pubDate>Sun, 25 Aug 2024 21:01:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html">http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html</a>, See on <a href="https://news.ycombinator.com/item?id=41351380">Hacker News</a></p>
Couldn't get http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Database "sharding" came from Ultima Online? (263 pts)]]></title>
            <link>https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/</link>
            <guid>41351219</guid>
            <pubDate>Sun, 25 Aug 2024 20:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/">https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/</a>, See on <a href="https://news.ycombinator.com/item?id=41351219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://startuplessonslearned.blogspot.com/2009/01/sharding-for-startups.html#comment-form"><span title="L"><span>L</span></span>essons Learned: Sharding for startups </a>is a technical post about database scalability. What caught my eye was the <em>term</em>. What an odd term ‚Äî ‚Äúsharding.‚Äù Why would a database be described that way?</p>
<p>So I started reading a bit about it. It basically means running a bunch of parallel databases and looking into the right one, rather than trying to cram everything into one.</p>
<p>Near as I can tell, a quick Google seems to say that the term came about <a href="http://highscalability.com/unorthodox-approach-database-design-coming-shard">because of a guy who worked at Friendster and Flickr, </a>and seems to . Wikipedia has only had <a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)">an article</a> for a little while. In the comment thread at Lessons Learned, there‚Äôs mention of the term being used in 2006.</p>
<p>Flickr, of course, was born as an MMO called <a href="https://en.wikipedia.org/wiki/Game_Neverending"><em>Game Neverending</em></a>. In fact, I was quoted in Ludicorp‚Äôs business plan, and Stewart Butterfield had asked if I could be an advisor, but I couldn‚Äôt do it at the time because of my contract with Sony. Sigh. Anyway, I would be <em>shocked</em> if the term ‚Äúshard‚Äù hadn‚Äôt been thrown around those offices‚Ä¶ because in MMOs, of course, ‚Äúshards‚Äù has a very specific meaning and history.</p>

<p>It means database partitioning ‚Äî of worlds. Parallel worlds each running the same static template database source, but evolving different runtime databases. But these were just called ‚Äúservers‚Äù ‚Äî like, <em>Meridian 59</em> had bunches of them, and they had numbers instead of the common practice of names that is in use today.</p>
<div><p><img decoding="async" title="A snippet from the UO intro movie" src="https://upload.wikimedia.org/wikipedia/en/c/cb/Mondain-uo-intro.jpg" alt="A snippet from the UO intro movie" width="283" height="160"></p><p>A snippet from the UO intro movie</p></div>
<p>No, ‚Äúshards‚Äù came about specifically because when we realized we would need to run multiple whole copies of <em>Ultima Online</em> for users to connect to, we needed to come up with a fiction for it. I went off and read a whole mess of stuff about early Ultima lore and tried to come up with a fictional justification. What I ended up with <a href="https://en.wikipedia.org/wiki/Britannia_(Ultima_Online)">is described here pretty well</a>: that the evil wizard Mondain had attempted to gain control over Sosaria by trapping its essence in a crystal. When the Stranger at the end of Ultima I defeated Mondain and shattered the crystal, the crystal <strong>shards</strong> each held a refracted copy of Sosaria.</p>
<p>It was a very very specific word chosen because, well, it was a piece of a crystal, which was a completely fictional invention. If Mondain had captured Sosaria on a parchment or in a painting, I would have said ‚Äúa tatter‚Äù or a ‚Äúfragment‚Äù or some such. But in the original U1, it specifically said he had used a crystal to gain power. We even talked about terms like ‚Äúmultiverse‚Äù and the like at the time and dismissed them as comic-book geeky and not really Ultima-flavored‚Ä¶ so ‚Äúshard‚Äù it was.</p>
<p>Now, from there time kept marching forward as each parallel Sosaria evolved in tandem. (UO was supposed to be between U3 and U4, in terms of chronology). The difference is, some of them got the Avatar (sent by the Time Lord) and some didn‚Äôt. Some of them were captured by The Guardian, and we invented the notion that Shadowlords were essentially evil beings created from shards he had captured. In fact, the beta test shard eventually was captured in this way ‚Äî if you read up on it, you‚Äôll find that really, there should be a fourth Shadowlord running around now.</p>
<div><p><a href="http://flickr.com/photos/37996580417@N01/6819311"><img fetchpriority="high" decoding="async" title="Original planned UO map" src="https://i0.wp.com/farm1.static.flickr.com/6/6819311_40cd3d3801.jpg?resize=400%2C300" alt="Original planned UO map, photo by Cory Doctorow, CC BY-SA" width="400" height="300" data-recalc-dims="1"></a></p><p>Original planned UO map, photo by Cory Doctorow, CC BY-SA</p></div>
<p>(Originally, the landmass of <em>Second Age</em> was supposed to be Ambrosia from Ultima III, and there‚Äôs actually a spot up north that is where Exodus is supposed to go. We even made the art for the whirlpool that is supposed to go there, and then just never put it in. But that‚Äôs a whole other story‚Ä¶)</p>
<p>(Oh‚Ä¶ and then why does the Stranger in the original UO intro movie have an Ankh on his chest? Because U9 was in development aready, and nobody had time to make a new model. üôÇ So it‚Äôs the same 3d model as was used in U9, which didn‚Äôt ship until <em>years</em> later. So expedience led to a fictional glitch.)</p>
<p>In any case, we called parallel servers ‚Äúshards‚Äù and it became a term used occasionally though not universally as a term of art within the field. You‚Äôll hear folks who worked on MMOs in the 90s use server and shard interchangeably ‚Äî sometimes saying ‚Äúshard‚Äù to reference a parallel server cluster rather than a physical server.</p>
<p>So, did this database term come from a doc that I dashed off one afternoon in 1996? Umm‚Ä¶ I am not sure. Seems like an interesting coincidence, if not.</p>
<p>I wonder if I still have that doc‚Ä¶</p>

 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Olivetti Programma 101: At the Origins of the Personal Computer (119 pts)]]></title>
            <link>https://www.inexhibit.com/case-studies/olivetti-programma-101-at-the-origins-of-the-personal-computer/</link>
            <guid>41351009</guid>
            <pubDate>Sun, 25 Aug 2024 20:20:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inexhibit.com/case-studies/olivetti-programma-101-at-the-origins-of-the-personal-computer/">https://www.inexhibit.com/case-studies/olivetti-programma-101-at-the-origins-of-the-personal-computer/</a>, See on <a href="https://news.ycombinator.com/item?id=41351009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img fetchpriority="high" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer.jpg" alt="Olivetti Programma 101 computer" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>An Olivetti Programma 101, photo courtesy of Museo Nazionale della Scienza e della Tecnologia ‚ÄúLeonardo da Vinci‚Äù, Milan (CC BY-SA 4.0).</em></p>
<p><strong>At the origins of the Personal Computer: the&nbsp;Olivetti Programma 101 (1965)</strong></p>
<p>These days, Italy is not particularly renowned for its consumer electronics products; yet, there was a time, in the ‚Äô60s, when an Italian company was reputed to be the ‚ÄúEuropean response‚Äù to American computer manufacturers; that company was <strong>Olivetti</strong>.</p>
<p>The company was founded in Ivrea, Northern Italy, in the early 20th century as a typewriter maker; but, in the late ‚Äô50s, under the direction of <strong>Adriano Olivetti</strong> and his son <strong>Roberto</strong>, it became one of the first European companies to regularly produce electronic calculators and computers, often characterized by innovative design and engineering solutions.</p>
<p><strong>The&nbsp;first human-centered&nbsp;computer</strong><br>
It was in the early Sixties that Olivetti<strong> decided to develop a ‚Äúdesktop‚Äù computer</strong>; namely, a computer much smaller than those used at the time, and compact enough to be <em>‚Äúa personal object, something that had to live with a person, a person with his chair sitting at a table or desktop‚Äù</em> (Roberto Olivetti). This object was the <strong>Programma 101</strong>.</p>
<p>This idea was utterly revolutionary since, at the time, computers were massive mainframes sealed in airtight rooms and operated by an elite of specialized technicians in white coats. Just before revealing the ‚Äúdream machine‚Äù, a Programma 101 advertisement recited: <em>‚ÄúWelcome to the world of tomorrow. You are about to take a journey out of this world into the world of the future‚Äù</em>, another one was showing a businessman and a handsome woman in a swimsuit (his secretary, perhaps) working on a Perottina right at the side of a pool‚Ä¶</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg" rel="attachment wp-att-39542"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-300x172.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-768x440.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-218x125.jpg.webp 218w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-624x358.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg" alt="Olivetti Programma 101 computer advertise 1" width="870" height="499" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-300x172.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-768x440.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-218x125.jpg 218w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-624x358.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>A 1960s video advertisement of the Olivetti P101 for the U.S. market.</em></p>
<p><strong>The development stage</strong><br>
The Programma 101 takes its nickname, <em><strong>Perottina</strong></em>, from that of its inventor ‚Äì Italian electrical engineer <strong>Pier Giorgio Perotto</strong>, then 32 years old ‚Äì to whom Olivetti assigned the direction of the project in 1962. The computer was developed by an engineering team of five young technicians which included ‚Äì along with Perotto ‚Äì Giovanni De Sandre, Giuliano Gaiti, Gastone Garziera, and Giancarlo Toppi.</p>
<p>The early story of the Programma is somewhat romantic. Olivetti had just sold its electronics division to General Electric, which wasn‚Äôt interested in an ‚ÄúItalian computer‚Äù at all.<br>
Yet, the team didn‚Äôt want to give up the project, already in an embryonic stage; therefore, they invented a trick. Overnight, they warily declassified the machine from ‚Äúcomputer‚Äù to ‚Äúcalculator‚Äù, and the calculator division was not part of the agreement with GE. So they could go on developing for some crucial months their ‚Äúmachine of the future‚Äù, in a sort of no man‚Äôs land between Olivetti and General Electric.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg" rel="attachment wp-att-39544"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team-300x212.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team-768x543.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team-624x441.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg" alt="Olivetti Programma 101 Perotto team" width="870" height="615" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team-300x212.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team-768x543.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team-624x441.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The technical development team of Programma 101 (except Giuliano Gaiti); left to right and bottom to top: Pier Giorgio Perotto, Giovanni De Sandre, Gastone Garziera, and Giancarlo Toppi; photo courtesy of Laboratorio-museo Tecnologicamente, Ivrea / Wikimedia.</em></p>
<p>When we look at the specifications and capabilities of the machine, today, it is hard to think it was a real computer.<br>
Due to its limited RAM of 1,920 bits, the Programma 101 was mostly a machine conceived to make arithmetic calculations ‚Äì sums, subtractions, divisions, multiplications, square roots -, yet, like modern computers, it could also perform logical operations, conditional and unconditional jumps, and print the data stored in a register, all through a custom-made alphanumeric programming language. This was, in the early ‚Äô60s, what set computers apart from calculators, indeed.<br>
Overall, in today‚Äôs terms, Programma 101 can be considered a sort of ‚Äútransitional fossil‚Äù between desktop calculators and personal computers.</p>
<p>The P101 didn‚Äôt have a monitor or the like, it used a small paper tape printer as a visualization device, instead. A revolutionary innovation made by Olivetti was to replace the fridge-size magnetic tape mass memory devices typical of coeval mainframes with a <strong>programmable magnetic card reader/recorder</strong>.<br>
Programs were recorded on these plastic strips, about 3 inches wide and one foot long, which could contain only 240 instructions and were very slow but were also small, simple to use, and quite practical overall. The magnetic bands were on one side of the card, so the other could be used to write annotations and the names of the programs they contained.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg" rel="attachment wp-att-39546"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-300x101.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-768x258.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-624x209.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg" alt="Olivetti Programma 101 desktop computer 2" width="870" height="292" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-300x101.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-768x258.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-624x209.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card-300x98.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card-768x251.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card-624x204.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg" alt="Olivetti Programma 101 magnetic card" width="870" height="284" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card-300x98.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card-768x251.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card-624x204.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>An image showing how the memory cards were used and a photo of one of the original magnetic cards; images courtesy of Computer Museum / University of Amsterdam and Bech (CC BY-SA 4.0) / Inexhibit.</em></p>
<p>The machine didn‚Äôt have a microprocessor or integrated circuits; like most computers of the time, its electronics were exclusively based on transistors, diodes, capacitors, and the like, grouped into larger functional ‚Äúmicro-units‚Äù (a patented technology specially developed by Olivetti for the Programma 101).</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open.jpg" rel="attachment wp-att-39554"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-300x164.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-768x421.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-624x342.jpg.webp 624w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-245x135.jpg.webp 245w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open.jpg" alt="Olivetti Programma 101 open" width="870" height="477" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-300x164.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-768x421.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-624x342.jpg 624w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-245x135.jpg 245w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The interior </em><em>of the P101 ‚ÄúPerottina‚Äù; photo ICTP Scientific FabLab; the front-right section accommodates the power supply and the electric motor; the front-middle-to-left section contains the keyboard, the printer, and the card reader/recorder; the rear section is reserved for the electronic section, cooled by a fan.</em></p>
<p><strong>The design of the Programma 101 body<br>
</strong>The design of the Programma‚Äôs body was conducted by <strong>Mario Bellini</strong>, a then-young architect, who was preferred to other designers who had previously worked for Olivetti, such as Ettore Sottsass, Marco Zanuso, and Marcello Nizzoli. Zanuso was contacted at first, but his proposal was a massive self-standing box, similar to that of a mainframe, which would have nullified all the effort to keep the device as small and lightweight as possible.</p>
<p>The team of&nbsp;Perotto had already created an impromptu wood case for the machine, just to give the P101 some kind of a container, but they were aware they still needed an open-mind architect keen to work on something never seen before. The young Bellini was possibly that man.</p>
<p>For the P101, Bellini conceived a case, mostly made in <strong>cast aluminum</strong>, whose round-edge shape set it apart from other electronics products by Olivetti, such as the mainframe <em>ELEA 9003</em> designed by Sottsass only a few years before.<br>
The decision to make the case of Programma 101 in an unconventional material such as die-cast alloy (most computers of the time were made in sheet metal) was justified by the need to avoid electromagnetic interference in a home/office environment.<br>
The case was 3 mm. thick and relatively lightweight (the whole machine weighed about 65 lbs. / 30 Kg. ).<br>
Bellini would have probably designed it to be made in plastic if synthetic materials were sufficiently developed at the time, which wasn‚Äôt the case. For example, in 1964, <strong>Ettore Sottsass</strong> designed a lined housing for the Olivetti Praxis 48 typewriter also to conceal the imperfections and the visually unpleasing shininess in its plastic die.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-300x159.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-768x406.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-624x330.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg" alt="Olivetti Praxis 48 typewriter side" width="870" height="460" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-300x159.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-768x406.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-624x330.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The case of the Olivetti Praxis 48 typewriter was designed in 1964 with a lined texture to disguise the imperfection of its innovative plastic body; image Charles Kremenak (CC BY 2.0).</em></p>
<p><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003-768x511.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003-624x415.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003.jpg" alt="Olivetti ELEA 9003" width="870" height="579" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003-768x511.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003-624x415.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></p>
<p><em>The sharp-edged, angular forms of the mainframe Olivetti ELEA 9003 were typical of the late ‚Äô50s and early ‚Äô60s computers; image Museo Nazionale della Scienza e della Tecnologia ‚ÄúLeonardo da Vinci‚Äù (CC BY-SA 4.0).</em></p>
<p>The design of the Perottina is somewhat reminiscent of that (again by Sottsass) of the <strong>Olivetti Logos 27</strong> electromechanical calculator, which was first presented, together with the Programma 101, in October 1965 at the <strong>Bema</strong> (Business Equipment Manufacturer Association) show in New York. &nbsp;Like the 101, the Logos 27 also had a die-cast alloy case; overall, both machines look a bit like big typewriters.<br>
Nevertheless, the case of the Programma is much more futuristic, bright, and ‚Äúfriendly‚Äù than the rather serious one of the Logos.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27.jpg" alt="Olivetti Logos 27" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The electro-mechanic calculator Olivetti Logos 27 (1965), design: Ettore Sottsass; photo&nbsp; Piergiovanna (CC BY-SA 4.0) / Inexhibit.</em></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg" rel="attachment wp-att-39560"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-768x511.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-624x415.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg" alt="Olivetti Programma 101 desktop computer 5" width="870" height="579" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-768x511.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-624x415.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Desk-top computer Olivetti Programma 101 (1965); design: Mario Bellini; photo courtesy of Museo Nazionale della Scienza e della Tecnologia, Milan (CC BY-SA 4.0).</em></p>
<p>I see in it some elements ‚Äì such as the use of thin lines to make the object appear smaller than it actually was, the playful contrast between the almost-white color case and the vividly-colored logo area, and the uncluttered design of slots and handles ‚Äì which recall me the <strong>‚ÄúSnow White‚Äù design language</strong> developed for Apple by German designer&nbsp;<em>Hartmut Esslinger</em> twenty years later.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg" rel="attachment wp-att-39568"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-768x511.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-624x415.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg" alt="Olivetti Programma 101 desktop computer 4" width="870" height="579" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-768x511.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-624x415.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo courtesy of Museo Nazionale della Scienza e della Tecnologia, Milan (CC BY-SA 4.0).</em></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-300x241.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-768x617.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-624x501.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg" alt="Olivetti Programma 101 desktop computer 6" width="870" height="699" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-300x241.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-768x617.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-624x501.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo by Paolo Monti / BEIC Digital Library (CC BY-SA 4.0)</em><em>.</em></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg" alt="Olivetti Programma 101 desktop computer close-up" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo by ‚ò∞‚òµ Michele M. F. / Flickr (CC BY-SA 2.0).</em></p>
<p><strong>The P101 commercial success and legacy</strong><br>
Despite Olivetti initially having modest expectations of the commercial possibilities of Programma 101, the computer was a success.<br>
With a price of $3,200 (about 20,000 in today‚Äôs dollars), it was quite cheap if compared to other computers of the time, which were mostly expensive mainframes reserved for big companies, government agencies, and universities. Furthermore, the Perottina was small and you could easily move it from one room to another, plug it into a power socket, and start working in minutes.<br>
In his book&nbsp;on the story of the P101, Perotto&nbsp;reports that some&nbsp;visitors of the <em>Bema Show</em>, when the machine was presented for the first time, believed that it was a sham, and was some sort of a console attached&nbsp;to a mainframe secretly concealed somewhere else.</p>
<p>Olivetti <strong>sold about 44,000 Programma 101 units</strong>, mostly in the United States, including 10 machines that NASA used for the Apollo 11 program.</p>
<p><em>‚ÄúBy Apollo 11 we had a desktop computer, sort of, kind of, called an Olivetti Programma 101. It was kind of a super calculator. (‚Ä¶) It would add, subtract, multiply, and divide, but it would remember a sequence of these things, and it would record that sequence on a magnetic card (‚Ä¶). So you could write a sequence, a programming sequence, and load it in there‚Äù</em> David W. Whittle, Johnson Space Center, NASA</p>
<p>What makes the Perottina a quantum leap in computer concept and design was being <strong>the first human-centered computer</strong> ever made.<br>
The company‚Äôs leaders and designers shared the same objective: to create for the first time a computer aimed at common people, not technicians and scientists only.<br>
And to achieve that they had to focus on the relationship between humans and machines, besides the pure computational performances of the computer.</p>
<p><em>‚ÄúThose days, few manufacturers and designers were interested in the user‚Äôs perspective and user-friendliness of machines. After all, In the ‚Äô60s, the available technology was limited, and the interest of computer designers was entirely focused on technical issues and on making devices work. It was the user who had to adapt to the machine, not the opposite. The electronics had to provide quantitative performances ‚Äì as much computational power, memory, and printing speed as possible -, there was no room to improve the relationship between computers and their users who, moreover, were all specialized technicians. Despite technology was improving in power, nevertheless, it didn‚Äôt leave much to those interested in making machines more friendly and easy to use.‚Äù &nbsp;</em>(Pier Giorgio Perotto, Programma 101. The never told, fascinating story of the invention of the Personal Computer, p. 20)</p>
<p>That‚Äôs why the Programma was technically and aesthetically conceived as an unintimidating object everyone could use, even at home. In that sense, there is no doubt that the Olivetti Programma 101 truly is <strong>the first Personal Computer</strong> in history.<br>
Furthermore, if industrial design is a discipline aimed at creating relationships between useful objects and their users, the Perottina can be considered possibly the first computer to have been designed.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg" alt="Olivetti Programma 101 desktop computer 7" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo by Emanuele / Flickr (CC BY-NC-ND 2.0).</em></p>
<p><strong>References</strong><br>
For images and technical info on the Programma 101 see:<br>
The incredible story of the first PC, from 1965 (http://royal.pingdom.com/2012/08/28/the-first-pc-from-1965/, in English)<br>
Olivetti Programma 1010 (http://www.silab.it/frox/p101/_index.html , in English)<br>
PROGRAMMA 101 ‚Äì Memory of the Future by Alessandro Bernard and Paolo Ceretto (http://www.101project.eu/the-documentary/, video)<br>
‚ÄúAlle origini del personal computer: l‚ÄôOlivetti Programma 101‚Äù (http://www.storiaolivetti.it/percorso.asp?idPercorso=630, in Italian)<br>
La Programma 101, il primo personal computer al mondo (http://www.piergiorgioperotto.it/programma101.aspx, in Italian)</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Pharma claims lower prices means giving up miracle medications. Ignore them (128 pts)]]></title>
            <link>https://www.vox.com/future-perfect/368538/medicare-drug-prices-pharma-negotiations-innovation</link>
            <guid>41350940</guid>
            <pubDate>Sun, 25 Aug 2024 20:14:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vox.com/future-perfect/368538/medicare-drug-prices-pharma-negotiations-innovation">https://www.vox.com/future-perfect/368538/medicare-drug-prices-pharma-negotiations-innovation</a>, See on <a href="https://news.ycombinator.com/item?id=41350940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the first time, the federal government has <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2024/08/15/fact-sheet-biden-harris-administration-announces-new-lower-prices-for-first-ten-drugs-selected-for-medicare-price-negotiation-to-lower-costs-for-millions-of-americans/">negotiated</a> directly with pharmaceutical companies over the prices for a handful of drugs. The new prices, which were announced mid-August, take effect in January 2026, and they will help the Medicare program cap what individual patients spend out of pocket on their prescriptions in a year at $2,000.</p><p>The historic policy, which has been floating around for decades, was long opposed by ‚ÄúBig Pharma‚Äù until Democrats in Congress passed and President Joe Biden signed <a href="https://www.vox.com/policy/2023/8/30/23850979/medicare-drug-price-negotiations-10-prescription-list">the Inflation Reduction Act in 2022</a>.</p><p>Pharma tried to stop the negotiation policy in courts after it became law. Their concerns ‚Äî namely, that these ‚Äúprice controls‚Äù <a href="https://www.vox.com/policy-and-politics/22702855/build-build-better-plan-medicare-negotiate-drug-prices">will stifle innovation</a> ‚Äî have been echoed by Republicans and policy commentators with the recent finalization of the negotiated prices. With less profit, companies like <a href="https://www.cnbc.com/2023/05/11/pfizer-medicare-could-face-legal-action-over-drug-price-negotiations.html">Pfizer</a> and <a href="https://www.cnn.com/2023/06/06/politics/merck-lawsuit-medicare-drug-price-negotiation/index.html">Merck</a> argue, it will be harder to hire scientists, invest in laboratory space, and set up clinical trials to test the medications of the future.</p><div><p>Sign up <a href="https://www.vox.com/pages/future-perfect-newsletter-signup">here</a> to explore the big, complicated problems the world faces and the most efficient ways to solve them. Sent twice a week.</p></div><p>It is a harrowing proposition: that in trying to control drug prices for 67 million Medicare patients now, we might inadvertently prevent the development of future drugs that could save lives. Implied, if not stated outright, is that we‚Äôre putting a cure for cancer or <a href="https://www.vox.com/future-perfect/355108/alzheimers-disease-drug-approval-research-retraction">Alzheimer‚Äôs</a> or some other intractable disease in jeopardy.</p><p>But we have good reasons to believe that the current policy won‚Äôt have such a trade-off any time soon. For one, pharma is hugely profitable, and these negotiated prices, while potentially chipping away at profit margins, should hardly entirely dampen the incentive to innovate, according to a couple of key studies of the industry. Two, if we are worried about future innovation, we should be focused on <a href="https://www.vox.com/future-perfect/367247/antibiotic-resistance-bacteria-pasteur-act-big-pharma">making it cheaper to develop drugs</a> ‚Äì and this is actually one area where AI is showing promise. By identifying the best candidates for possible treatments early in the research process, we could speed up development and continue to reduce costs ‚Äî without losing out on tomorrow‚Äôs breakthroughs.</p><div><p id="we-can-afford-to-lower-drug-prices"><h2>We can afford to lower drug prices</h2></p></div><p>The argument against reducing profits usually goes like this: The drug companies spend a lot of money developing drugs, including some drugs that never make it to market because they don‚Äôt prove to be effective. When they do have a new, effective drug to sell, they need to make a lot of money to cover their development costs and then some, so they can take the profits and invest more money into research and development for the next generation of medicines. </p><p>Most other wealthy countries, like Australia and the UK, use the government‚Äôs central role in their health care system to negotiate lower prices while also <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2866602/">fostering their own medical innovation sectors</a>. But in the US, before the IRA‚Äôs provisions became law, prices were left more to the free market and the individual negotiating positions of manufacturers, private insurers, the government, and pharmacy benefit managers. Various rebates, kickbacks, and other financing mechanisms often obfuscated and increased Americans‚Äô drug prices. As a result, the US pays by far the highest costs for medications in the world. </p><p>As a result of how much we pay, Americans generally get first dibs on new cures. But that early access is only useful if patients can afford the drugs. <a href="https://www.kff.org/health-costs/issue-brief/americans-challenges-with-health-care-costs/#:~:text=About%20one%20in%20five%20adults,year%20because%20of%20the%20cost.">Too often, they can‚Äôt</a>.</p><p>But here‚Äôs the thing: This whole premise is faulty. When the Congressional Budget Office evaluated the bill before it passed, its analysts said they <a href="https://www.cbo.gov/system/files/2023-12/59792-Letter.pdf">did not expect a major effect</a> on future drug development. The need to cover R&amp;D costs does not actually explain, at least not entirely, the high costs for medications charged in America, according to <a href="https://www.healthaffairs.org/content/forefront/r-d-costs-pharmaceutical-companies-do-not-explain-elevated-us-drug-prices">a 2017 analysis published by <em>Health Affairs</em></a>, a health care research journal.</p><p>The research ‚Äî from Memorial Sloan Kettering Cancer Center‚Äôs Nancy Yu, Zachary Helms, and Peter Bach ‚Äî determined the excess price paid in the US compared to other wealthy nations. They called this price the American R&amp;D ‚Äúpremium.‚Äù They then calculated how much revenue said premium generated for the top 15 drug manufacturers in the world and compared it to the companies‚Äô respective R&amp;D spending.</p><div><div><p><a href="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="1172" data-pswp-width="1240" target="_blank" rel="noreferrer"><img alt="A chart showing how much more Americans pay for prescription drugs than people in other countries do, from 25 percent to 75 percent more, varying by manufacturer." data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><cite>Dylan Scott/Vox</cite></p></div><p>They concluded other countries had average drug list prices that were 41 percent of the net prices paid in the US. Big Pharma reaped $116 billion in revenue in one year from these excess American prices. In the same year, drug makers spent $76 billion on R&amp;D. These numbers suggest drug companies can afford avoiding such a premium. ‚ÄúThere are billions of dollars left over even after worldwide research budgets are covered,‚Äù the authors wrote.</p><p>At a certain point, the expectation of lower revenues could start to reduce the industry‚Äôs willingness to invest in new drugs and make riskier bets with potentially big payoffs. But are we anywhere near that point? Whatever objections these companies might be raising, it may be more telling to examine what they do rather than what they say.</p><p>Last year, Richard Frank and Ro Huang at the Brookings Institution <a href="https://www.brookings.edu/articles/early-claims-and-ma-behavior-following-enactment-of-the-drug-provisions-in-the-ira/">looked</a> at the business decisions drug makers had made since negotiation provisions became law. The researchers specifically considered mergers and acquisitions, the other means by which big drug companies discover new drugs (usually by buying a promising start-up that has already done R&amp;D). </p><p>Frank and Huang detected little evidence that the drug companies were expecting a massive blow to their revenues because of changes to the negotiation process. If anything, they found increased transactions for drugs at both the early and late trial stages. Overall M&amp;A spending was not noticeably altered and some <a href="https://s203.q4cdn.com/636242992/files/doc_financials/2023/q2/JNJ-Q2-2023-Transcript-Final.pdf">recent earnings reports</a> had expressed optimism about the future.</p><p>This makes sense: the IRA stipulated that Medicare‚Äôs negotiating authority be limited and gradually phased in. For the first year, Medicare was permitted to pick 10 drugs for negotiations. Next year, the program can add another 15 and another 15 the year after that. </p><div><p id="how-to-make-more-drugs-quickly"><h2>How to make more drugs quickly</h2></p></div><p>We have a sound basis to think we can afford lower prices for more drugs. But still, it would be nice if we could develop drugs more quickly and therefore more cheaply. That could naturally lower prices while still delivering new medicines to people in need. Win-win.</p><p>There may be ways to simplify the approval process and the approval criteria for more drugs. Writer Matt Yglesias <a href="https://www.slowboring.com/p/smarter-ways-to-boost-drug-innovation">covered some options</a> for Congress and the FDA to consider in his newsletter, including being more receptive to data from clinical trials conducted in other countries (where trials can often be done at less expense).</p><p>But science is the most daunting obstacle to new drugs. It can take years for researchers to even figure out how diseases work, their biological basis, and thereby hypothesize possible candidates for interventions. Moving from the basic research that reveals those building blocks to the clinical trials that secure FDA approval can take decades. The FDA only factors in once you‚Äôve figured out something that actually works. That‚Äôs why big drug companies do spend so much on acquisitions; even with all their resources, there‚Äôs no guarantee the in-house scientists will find a promising treatment candidate before an outside researcher does.</p><p>The best way to maximize our R&amp;D resources, to get the most bang for our buck when we set up expensive human trials, is to identify the most promising candidates at the start. But we are dealing with an enormous amount of information: the library of genetics that every human being carries. This is why drug developers are turning to <a href="https://www.vox.com/future-perfect/23827785/artifical-intelligence-ai-drug-discovery-medicine-pharmaceutical">AI for help in sorting through it</a>.</p><p>Leading researchers on antibiotic resistance <a href="https://www.vox.com/future-perfect/353420/drug-resistant-bacteria-are-killing-more-and-more-humans-we-need-new-weapons">have trained computers</a> to hunt everywhere, even in extinct animal DNA, for molecules that could be promising in treating bacteria that have become difficult for conventional medicines to treat. Longevity proponents <a href="https://www.vox.com/the-highlight/24121932/anti-aging-longevity-science-health-drugs">put a similar faith</a> in artificial intelligence. New start-ups, such as Recursion Pharmaceuticals, <a href="https://www.statnews.com/2024/08/19/recursion-pharmaceuticals-front-runner-ai-in-medicine-new-drug-development/">profiled by STAT</a>, have based their entire business on using AI to find potential drug candidates, including among those sitting on the shelves of Big Pharma that could be repurposed for new conditions.</p><p>Whether those AI aspirations will pay off is still unknown. But they provide another reason for optimism. </p><p>Too often, the drug pricing conversation is framed as an either/or. Either lower prices or new cures, but not both. It‚Äôs a false choice.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Telegram really an encrypted messaging app? (548 pts)]]></title>
            <link>https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/</link>
            <guid>41350530</guid>
            <pubDate>Sun, 25 Aug 2024 19:34:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/">https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/</a>, See on <a href="https://news.ycombinator.com/item?id=41350530">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-7859">
	
	<div>
		
<p>This blog is reserved for more serious things, and ordinarily I wouldn‚Äôt spend time on questions like the above. But much as I‚Äôd like to spend my time writing about exciting topics, sometimes the world requires a bit of what <a href="https://braddelong.substack.com/">Brad Delong </a>calls ‚ÄúIntellectual Garbage Pickup,‚Äù namely: correcting wrong, or mostly-wrong ideas that spread unchecked across the Internet. </p>



<p>This post is inspired by the recent and concerning news that <a href="http://app is accused of failure to cooperate with law enforcement over drug trafficking, child sexual content and fraud.">Telegram‚Äôs CEO Pavel Durov has been arrested by French authorities</a> for its failure to sufficiently moderate content. While I don‚Äôt know the details, the use of criminal charges to coerce social media companies is a pretty worrying escalation, and I hope there‚Äôs more to the story.</p>



<p>But this arrest is not what I want to talk about today.</p>



<p>What I do want to talk about is one specific detail of the reporting. Specifically: the fact that nearly every news report about the arrest refers to Telegram as an ‚Äúencrypted messaging app.‚Äù Here are <a href="https://www.politico.eu/article/telegram-app-ceo-pavel-durov-reportedly-arrested-at-french-airport/">just a</a> <a href="https://abcnews.go.com/Technology/wireStory/french-authorities-arrest-telegram-ceo-pavel-durov-paris-113132319">few</a> <a href="https://www.france24.com/en/live-news/20240825-telegram-chief-pavel-durov-arrested-at-french-airport">examples</a>: </p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png"><img data-attachment-id="7864" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-34/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png" data-orig-size="1182,274" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png?w=700" tabindex="0" role="button" width="1024" height="237" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png?w=1024" alt=""></a></figure></div>

<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png"><img data-attachment-id="7865" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-35/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png" data-orig-size="2466,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png?w=700" tabindex="0" role="button" width="1024" height="233" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png?w=1024" alt=""></a></figure></div>

<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png"><img data-attachment-id="7867" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-36/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png" data-orig-size="2040,582" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png?w=700" tabindex="0" role="button" width="1024" height="292" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png?w=1024" alt=""></a></figure></div>


<p>This phrasing drives me buts because in one a very limited technical sense it‚Äôs <em>not wrong.</em> Yet in every sense that matters, it fundamentally misrepresents what Telegram is and how it works in practice. And this misrepresentation is bad for both journalists and particularly for Telegram‚Äôs users, many of whom could be badly hurt as a result.</p>



<p>Now to the details. </p>



<h3>Does Telegram have encryption or doesn‚Äôt it?</h3>



<p>Many systems use encryption in some way or another. However, when we talk about encryption in the context of modern private messaging services, the word typically has a very specific meaning: it refers to the use of default <a href="https://en.wikipedia.org/wiki/End-to-end_encryption">end-to-end</a> encryption to protect users‚Äô message content. When used in an industry-standard way, this feature ensures that every message will be encrypted using encryption keys that are only known to the communicating parties, and not to the service provider.</p>



<p>From your perspective as a user, an ‚Äúencrypted messenger‚Äù ensures that each time you start a conversation, your messages will only be readable by the folks you intend to speak with. If the operator of a messaging service tries to view the content of your messages, all they‚Äôll see is useless encrypted junk. That same guarantee holds for anyone who might hack into the provider‚Äôs servers, and also, for better or for worse, to <a href="https://www.theguardian.com/technology/2023/apr/20/crime-agencies-condemn-facebook-instagram-encryption-plans">law enforcement agencies that serve providers with a subpoena</a>. </p>



<p>Telegram clearly fails to meet this stronger definition for a simple reason: it does not end-to-end encrypt conversations by default. If you want to use end-to-end encryption in Telegram, you must manually activate an <a href="https://core.telegram.org/blackberry/secretchats">optional end-to-end encryption feature</a> called ‚ÄúSecret Chats‚Äù for every single private conversation you want to have. The feature is explicitly <span>not turned on</span> for the vast majority of conversations, and is only available for one-on-one conversations, and never for group chats with more than two people in them. </p>



<p>As a kind of a weird bonus, activating end-to-end encryption in Telegram is oddly difficult for non-expert users to actually do.</p>



<p>For one thing, the button that activates Telegram‚Äôs encryption feature is not visible from the main conversation pane, or from the home screen. To find it in the iOS app, I had to click at least four times ‚Äî once to make a hidden menu pop up, and a second time to ‚Äúconfirm‚Äù that I wanted to use encryption. And even after this I was not able to actually have an encrypted conversation, since <em>Secret Chats only works if your conversation partner happens to be online </em>when you do this. </p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png"><img data-attachment-id="7884" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-40/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png" data-orig-size="2908,658" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png?w=700" tabindex="0" role="button" loading="lazy" width="1024" height="231" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png?w=1024" alt=""></a><figcaption><em>Starting a ‚Äúsecret chat‚Äù with my friend Michael on the latest Telegram iOS app. From an ordinary chat screen this option isn‚Äôt directly visible. Getting it activated requires four clicks: <strong>(1)</strong> to get to Michael‚Äôs profile (left image), <strong>(2)</strong> on the ‚Äú‚Ä¶‚Äù button to display a hidden set of options (center image), <strong>(3)</strong> on ‚ÄúStart Secret Chat‚Äù, and <strong>(4)</strong> on the ‚ÄúAre you sure‚Ä¶‚Äù confirmation dialog. After that I‚Äôm still unable to send Michael any messages, because Telegram‚Äôs Secret Chats can only be turned on if the other user is also online. </em></figcaption></figure></div>


<p>Overall this is quite different from the experience of starting a new encrypted chat in an industry-standard modern messaging application, which simply requires you to open a new chat window.</p>



<p>While it might seem like I‚Äôm being picky, the difference in adoption between default end-to-end encryption and this experience is likely very significant. The practical impact of these UX decisions is likely to ensure that the vast majority of one-on-one Telegram conversations ‚Äî and literally <em>every single group chat</em> ‚Äî allow Telegram‚Äôs servers to see and record the content of all messages sent between users. That may or may not be a problem for every Telegram user, but it‚Äôs certainly not something we‚Äôd advertise as particularly well encrypted.</p>



<p>(If you‚Äôre interested in the details, as well as a little bit of further criticism of Telegram‚Äôs actual encryption protocols, I‚Äôll get into what we know about that further below.)</p>



<h3>But wait, does default encryption really matter?</h3>



<p>Maybe yes, maybe no! There are two different ways to think about this.</p>



<p>One is that <em>Telegram‚Äôs lack of default encryption is just fine</em> <em>for many people</em>. The reality is that many users don‚Äôt choose Telegram for encrypted private messaging at all. For plenty of people, Telegram is used more like a social media network than a private messenger. </p>



<p>Getting more specific, Telegram has two popular features that makes it ideal for this use-case. One of those is the ability to create and subscribe to ‚Äú<a href="https://telegram.org/tour/channels">channels</a>‚Äú, each of which works like a broadcast network where one person (or a small number of people) can push content out to millions of readers. When you‚Äôre <em>broadcasting</em> messages to thousands of strangers in public, maintaining the secrecy of your chat content isn‚Äôt as important. </p>



<p>Telegram also supports large public <a href="https://telegram.org/tour/groups">group chats</a> that can include thousands of users. These groups can be made open for the general public to join, or they can set up as invite-only. While I‚Äôve never personally wanted to share a group chat with thousands of people, I‚Äôm told that many people enjoy this feature. In the large and <em>public</em> instantiation, it also doesn‚Äôt really matter that Telegram group chats are unencrypted ‚Äî after all, who cares about confidentiality if you‚Äôre talking in the public square?</p>



<p>But Telegram is not limited to just those features, and many users who join for them will also do other things.</p>



<p>Imagine you‚Äôre in a ‚Äúpublic square‚Äù having a large group conversation. In that setting there may be no expectation of strong privacy, and so end-to-end encryption doesn‚Äôt really matter to you. But let‚Äôs say that you and five friends step out of the square to have a side conversation. Does <em>that</em> conversation deserve strong privacy? It doesn‚Äôt really matter what you want, because <em>Telegram won‚Äôt provide it</em>, at least not with encryption that protects you from sharing your content with Telegram servers. </p>



<p>Similarly, imagine you use Telegram for its social media-like features, meaning that you mainly consume content rather than producing it. But one day your friend, who also uses Telegram for similar reasons, notices you‚Äôre on the platform and decides she wants to send you a private message. Are you concerned about privacy now? And are you each going to manually turn on the ‚ÄúSecret Chat‚Äù feature ‚Äî&nbsp;even though it requires four explicit clicks through hidden menus, and even though it will prevent you from communicating immediately if one of you is offline?</p>



<p>My strong suspicion is that many people who join Telegram for its social media features also end up using it to communicate privately. And I think Telegram knows this, and tends to advertise itself as a ‚Äúsecure messenger‚Äù and talk about the platform‚Äôs encryption features precisely because they know it makes people feel more comfortable. But in practice, I also suspect that very few of those users are actually <em>using Telegram‚Äôs encryption</em>. Many of those users may not even realize they have to turn encryption on manually, and think they‚Äôre already using it. </p>



<p>Which brings me to my next point.</p>



<h3>Telegram knows its encryption is difficult to turn on, and they continue to promote their product as a secure messenger</h3>



<p>Telegram‚Äôs encryption has <a href="https://threadreaderapp.com/thread/1474067549574688768.html">been subject to</a> <a href="https://grugq.tumblr.com/post/133453305233/operational-telegram">heavy criticism</a> <a href="https://www.dailydot.com/debug/telegram-isis-encryption-cryptography/">since</a> <a href="https://cpj.org/2016/05/why-telegrams-security-flaws-may-put-irans-journal/">at least 2016</a> (and possibly earlier) for many of the reasons I outlined in this post. In fact, many of these criticisms were made by experts including myself, in years-old conversations with Pavel Durov on Twitter.<sup>1</sup></p>



<p>Although the interaction with Durov could sometimes be harsh, I still mostly assumed good faith from Telegram back in those days. I believed that Telegram was busy growing their network and that, in time, they would improve the quality and usability of the platform‚Äôs end-to-end encryption: for example, by activating it as a default, providing support for group chats, and making it possible to start encrypted chats with offline users. I assumed that while Telegram might be a follower rather than a leader, it would eventually reach feature parity with the encryption protocols offered by Signal and WhatsApp. Of course, a second possibility was that Telegram would abandon encryption entirely ‚Äî and just focus on being a social media platform.</p>



<p>What‚Äôs actually happened is a lot more confusing to me.</p>



<p>Instead of improving the usability of Telegram‚Äôs end-to-end encryption, the owners of Telegram have more or less kept their encryption UX unchanged since 2016. While there have been a <a href="https://core.telegram.org/mtproto">few upgrades to the underlying encryption algorithms</a> used by the platform, the user-facing experience of Secret Chats in 2024 is almost identical to the one <a href="https://grugq.tumblr.com/post/133453305233/operational-telegram">you‚Äôd have seen eight years ago</a>. This, despite the fact that the number of Telegram users has grown by 7-9x during the same time period.</p>



<p>At the same time, Telegram CEO Pavel Durov has continued to aggressively market Telegram as a ‚Äúsecure messenger.‚Äù Most recently he <a href="https://www.theregister.com/2024/05/14/telegram_ceo_calls_out_rival/">issued a scathing criticism of</a> Signal and WhatsApp on his personal Telegram channel, implying that those systems were backdoored by the US government, and only Telegram‚Äôs independent encryption protocols were really trustworthy. </p>



<p>While this might be a reasonable nerd-argument if it was taking place between two platforms that both supported default end-to-end encryption, Telegram really has no legs to stand on in this particular discussion. Indeed, it no longer feels amusing to see the Telegram organization urge people away from default-encrypted messengers, while <em>refusing to implement essential features that would widely encrypt their own users‚Äô messages</em>. In fact, it‚Äôs starting to feel a bit malicious.</p>



<h3>What about the boring encryption details? </h3>



<p>This is a cryptography blog and so I‚Äôd be remiss if I didn‚Äôt spend at least a little bit of time on the boring encryption protocols. I‚Äôd also be missing a good opportunity to <em>let my mouth gape open in amazement</em>, which is pretty much what happens every time I look at the internals of Telegram‚Äôs encryption. </p>



<p>I‚Äôm going to handle this in one paragraph to reduce the pain, and you can feel free to skip past it if you‚Äôre not interested.</p>



<p>According to <a href="https://core.telegram.org/api/end-to-end">what I <em>think</em> is the latest encryption spec</a>, Telegram‚Äôs Secret Chats feature is based on a custom feature called MTProto 2.0. This system uses 2048-bit* finite-field <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman</a> key agreement, with group parameters (I think) chosen by the server.* (Since the Diffie-Hellman protocol is only executed interactively, this is why Secret Chats cannot be set up when one user is offline.*) MITM protection is handled by the end-users, who must compare key fingerprints. There are some weird random nonces provided by the server, which I don‚Äôt fully understands the purpose of* ‚Äî and that <a href="https://words.filippo.io/dispatches/telegram-ecdh/">in the past used to actively make the key exchange totally insecure against a malicious server</a> (but this has long since been fixed.*) The resulting keys are then used to power the most amazing, <a href="https://eprint.iacr.org/2015/1177.pdf">non-standard</a> authenticated encryption mode ever invented, something called ‚Äú<a href="https://core.telegram.org/api/end-to-end">Infinite Garble Extension</a>‚Äù (IGE) based on AES and with SHA2 handling authentication.*</p>



<p>NB: Every place I put a ‚Äú*‚Äù in the paragraph above is a point where expert cryptographers would, in the context of something like a professional security audit, raise their hands and ask <em>a lot</em> of questions. I‚Äôm not going to go further than this. Suffice it to say that Telegram‚Äôs encryption is unusual. </p>



<h3>Is there anything else I should know?</h3>



<p>Yes, unfortunately. Even though end-to-end encryption is one of the best tools we‚Äôve developed to prevent data compromise, it is hardly the end of the story. One of the biggest privacy problems in messaging is the availability of loads of meta-data ‚Äî essentially data about who uses the service, who they talk to, and when they do that talking. </p>



<p>This data is not typically protected by end-to-end encryption. Even in applications that are broadcast-only, such as Telegram‚Äôs channels, there is plenty of useful metadata available about <em>who is listening to a broadcast.</em> That information alone is valuable to people, as evidenced by the enormous amounts of money that traditional broadcasters <a href="https://www.komando.com/news/security/stop-smart-tv-tracking/">spend to collect it</a>. Right now all of that information likely exists on Telegram‚Äôs servers, where it is available to anyone who wants to collect it.</p>



<p>I am not specifically calling out Telegram for this, since the same problem exists with virtually every other social media network and private messenger. But it should be mentioned, just to avoid leaving you with the conclusion that encryption is all we need. </p>



<p>Notes:</p>



<ol>
<li>I will never find all of these conversations again, thanks to Twitter search being so broken. If anyone can turn them up I‚Äôd appreciate it. </li>
</ol>
	</div><!-- .entry-content -->

			<!-- .entry-footer -->
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stripe Data vs. Open‚ÄêSource Alternatives: A MRR Example (125 pts)]]></title>
            <link>https://github.com/getlago/lago/wiki/Stripe-Data-vs-Open%E2%80%90Source-Alternatives:-a-MRR-example</link>
            <guid>41350468</guid>
            <pubDate>Sun, 25 Aug 2024 19:28:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/getlago/lago/wiki/Stripe-Data-vs-Open%E2%80%90Source-Alternatives:-a-MRR-example">https://github.com/getlago/lago/wiki/Stripe-Data-vs-Open%E2%80%90Source-Alternatives:-a-MRR-example</a>, See on <a href="https://news.ycombinator.com/item?id=41350468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wiki-body" data-view-component="true">
                <p>The founder of <a href="https://cal.com/" rel="nofollow">Cal.com</a> had some choice of words for Stripe:</p>
<p><img width="479" alt="Capture d‚ÄôeÃÅcran 2023-10-26 aÃÄ 10 26 58" src="https://private-user-images.githubusercontent.com/85290767/278263692-7d162323-cae7-4080-8727-288272a55175.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2ODI5MDQsIm5iZiI6MTcyNDY4MjYwNCwicGF0aCI6Ii84NTI5MDc2Ny8yNzgyNjM2OTItN2QxNjIzMjMtY2FlNy00MDgwLTg3MjctMjg4MjcyYTU1MTc1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA4MjYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwODI2VDE0MzAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2MWE2OGQzYmYzMTE3ZjAzNGYzNjI5ZDYzNzlmMzlhY2RkMzNmYmRjN2JiMjMwYTdlM2UzMThmODBhZmU3ZDgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.2RUuiCf-DHa03asm9QxH3hKWbFCpSzMmz7K_4OioMtY" content-type-secured-asset="image/png"></p><p>Source: <a href="https://twitter.com/peer_rich/status/1701291062927503499" rel="nofollow">X</a></p>
<p>Not very kind words. But unfortunately, he‚Äôs right. Calculating MRR using Stripe‚Äôs out-of-the-box API is very difficult. This might come as a surprise to many because Stripe does provide a nifty embedded dashboard in its admin portal that includes MRR amongst other core metrics.</p>
<p><img src="https://camo.githubusercontent.com/77b1f2c4894e7d9513573a45d17ff96dbc79e1c181795227faf1d47944a34be7/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313332353236666632393131613234313263345f5374726970654d52525f73637265656e312e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e5132526ff2911a2412c4_StripeMRR_screen1.png"></p>
<p>To a founder of a seed stage startup, this dashboard is both helpful and likely sufficient. But as companies grow, they want to do more with their data. And Stripe doesn‚Äôt have an API route that‚Äôs equivalent to <code>/getMRR</code> or something similar. Without serious legwork, getting statistics into your own warehouse or database using Stripe‚Äôs main API is tough.</p>
<p><strong>This isn‚Äôt a matter of poor engineering. Stripe has one of the best engineering (and design) teams in the world. It‚Äôs just profit-maximizing strategy.</strong></p>
<p>Stripe keeps its API pretty barebones, expecting customers to purchase Stripe Sigma (fancy SQL editor) or Stripe Data Pipeline (in-house ETL tool) to better access data. Both of these tools add a cost per transaction, which is a little ridiculous given that Stripe‚Äôs base rate is higher <a href="https://directpaynet.com/stripe-fees-breakdown-comparison/" rel="nofollow">than competitors</a>, PayPal and Square.</p>
<p><h2>What options do you have?</h2><a id="user-content-what-options-do-you-have" aria-label="Permalink: What options do you have?" href="#what-options-do-you-have"></a></p>
<p>If you are locked into Stripe, you still have options. Some, as aforementioned, are internal Stripe add-ons. Others are third-party tools. And, to spoil the surprise, they all come with a cost.</p>
<p><h3>Stripe Data Pipeline</h3><a id="user-content-stripe-data-pipeline" aria-label="Permalink: Stripe Data Pipeline" href="#stripe-data-pipeline"></a></p>
<p><a href="https://stripe.com/en-fr/data-pipeline" rel="nofollow">Stripe Data Pipeline</a> is a limited ETL product that syncs Stripe data with a Snowflake or Amazon Redshift warehouse (presumably, they are building more integrations, but Stripe only supports those two presently). Advertised customers of Stripe Data Pipeline include Doordash, Slack, Zoom, and Hubspot.</p>
<p>While Stripe will definitely cut a volume deal to larger players, its base cost is $0.03 or ‚Ç¨0.025 per transaction. Transaction, in this case, includes whenever a user was charged, an authorization was submitted, or a payment was requested. (While this post is mostly critical of Stripe, it‚Äôs worth acknowledging that Stripe includes provisions to not double charge customers for the same transaction, e.g. if an authorization is captured, it counts as one transaction, not two).</p>
<p>These Stripe extra fees can sound small. What‚Äôs a few cents, here and there? Well, it‚Äôs not a few cents. Sure, Stripe Data Pipeline is a great deal for customers where the median charge is $200-300, as the per-transaction fee reduces to a rounding error. But for companies with lots of smaller transactions (e.g. DoorDash or Lime), these charges are hardly trivial. They won‚Äôt overshadow Stripe‚Äôs core rake, but they add-up. <a href="https://backlinko.com/doordash-users" rel="nofollow">There were 816 million</a> DoorDash orders in 2020; even if Stripe cut DoorDash a hefty 50% discount, that‚Äôs <strong>10,200,000 annually. For 10M/year, I‚Äôm willing to bet you could build an entire billing company.</strong></p>
<p><h3>Stripe Sigma</h3><a id="user-content-stripe-sigma" aria-label="Permalink: Stripe Sigma" href="#stripe-sigma"></a></p>
<p>Stripe Sigma isn‚Äôt exactly a replacement for exporting data (it supports CSV exports of reports, but that‚Äôs hardly data warehouse material). However, it does address some of the needs that a data warehouse might be attempting to solve, so it‚Äôs a worthy mention. For instance, you can calculate MRR (within reason) using Stripe Sigma.</p>
<p>Stripe Sigma is advertised as a collaborative, data-querying product that looks like a <a href="https://popsql.com/?utm_source=google&amp;utm_medium=CPC&amp;utm_campaign=all_search_brand&amp;utm_term=brand&amp;utm_term=Popsql&amp;gad_source=1&amp;gclid=Cj0KCQjwpc-oBhCGARIsAH6ote_fJ1-Ifuk7zp8NrJTZKUkUtYqgeFI7SxuMNgtAE3qdYkm7nZbf3IMaAkMnEALw_wcB" rel="nofollow">PopSQL</a> or <a href="https://www.basedash.com/" rel="nofollow">Basedash</a>. Teams can collaborate on SQL queries and filter / group data like they would when accessing a Postgres database. Data can be exported as a CSV or shared via a platform link.</p>
<p>And, for what it‚Äôs worth, Stripe Sigma is a helpful solution for a very specific type of company. A company where a data warehouse is overkill, transaction count is manageable, but data is abundant requiring analysis. I can name twenty people heading up mid-sized companies that‚Äôll likely benefit from Stripe Sigma.</p>
<p>But just like Stripe Data Pipeline, Stripe Sigma is expensive when you add up the numbers. Alongside a base fee ($10/mo - $100/mo for &lt;50K transactions), Stripe charges an additional $0.020/transaction/mo - $0.014/transaction/mo based on volume.</p>
<p><em><strong>If a DoorDash employee queried all of their transaction history using Stripe Sigma, DoorDash‚Äôs CFO might have a stroke.</strong></em></p>
<p><h3>Both solutions fall flat for usage-based billing</h3><a id="user-content-both-solutions-fall-flat-for-usage-based-billing" aria-label="Permalink: Both solutions fall flat for usage-based billing" href="#both-solutions-fall-flat-for-usage-based-billing"></a></p>
<p>When you hear ‚Äúusage-based billing‚Äù, you might think of a classic developer tool that charges per API call or server hours. Realistically, many SaaS applications feature usage-based billing because of seats. Technically, seats are a metric of usage. They can go up and down on a month-by-month basis, and seat costs are typically prorated.</p>
<p>The thing is, seats aren‚Äôt usually a volatile thing. Most SaaS apps don‚Äôt see customers radically changing seats unless there was a fresh round of funding, a massive layoff, or some weird restructuring. They are a quasi-MRR unit. We call it usage-based MRR, even if that sounds like an oxymoron.</p>
<p><strong>Stripe makes usage-based metrics impossible.</strong> We‚Äôre not arguing that they should be easy; accounting for various nuances of different billing metrics is difficult. But Stripe is entirely based on a subscription-based model. It‚Äôs not designed to be personalizable to businesses with various growth metrics. This creates a mess when analyzing data, even raw data exported from Stripe.</p>
<p><h3>Third-Party Financial Metrics tools</h3><a id="user-content-third-party-financial-metrics-tools" aria-label="Permalink: Third-Party Financial Metrics tools" href="#third-party-financial-metrics-tools"></a></p>
<p>This is my favorite part. I‚Äôm always humored when massive companies could be built due to some design flaw of another product. Salesforce has a ton of these, and Stripe is no exception. <a href="https://chartmogul.com/" rel="nofollow">ChartMogul</a> (39M / yr <a href="https://chartmogul.com/" rel="nofollow">in revenue</a>) and <a href="https://profitwell.com/" rel="nofollow">ProfitWell</a> (<a href="https://techcrunch.com/2022/05/25/paddle-acquires-profitwell-for-200m-to-bring-analytics-and-retention-tools-to-its-saas-payments-platform/" rel="nofollow">acquired for $200M</a>) strictly exist due to Stripe‚Äôs limitations.</p>
<p>With both, you can generate reports or consolidate exports into data warehouses. They won‚Äôt account for everything (e.g. usage-based MRR), but they are a level-up from Stripe‚Äôs raw API.</p>
<p><h3>Third-Party FP&amp;A Tool, Pigment</h3><a id="user-content-third-party-fpa-tool-pigment" aria-label="Permalink: Third-Party FP&amp;A Tool, Pigment" href="#third-party-fpa-tool-pigment"></a></p>
<p>This one is a bit extraneous, but <a href="https://www.gopigment.com/" rel="nofollow">Pigment</a> is a neat tool designed for FP&amp;A teams (Financial Planning and Analysis). Basically the folks that evaluate how to save money and make more money.</p>
<p>Today, Pigment <a href="https://www.gopigment.com/integrations" rel="nofollow">does not integrate</a> with Stripe, but it‚Äôs high-up on their roadmap. If I was to make a wild guess, they‚Äôll announce an integration soon given how big of a space this is. With Pigment, teams could answer big-picture growth-based financial questions and build helpful dashboards. But, as you might gather, it‚Äôs for very large companies and isn‚Äôt priced for your average Series ABC startup.</p>
<p><h3>Use an ELT / ETL to dump the data into a warehouse</h3><a id="user-content-use-an-elt--etl-to-dump-the-data-into-a-warehouse" aria-label="Permalink: Use an ELT / ETL to dump the data into a warehouse" href="#use-an-elt--etl-to-dump-the-data-into-a-warehouse"></a></p>
<p>Instead of using Stripe‚Äôs native ETL tool, Stripe Data Pipeline, you can use a third-party ETL / ELT tool to pull Stripe‚Äôs data into a warehouse. This is a good strategy for teams that already use an ETL / ELT tool for other purposes. Common examples of these are <a href="https://docs.airbyte.com/integrations/sources/stripe/" rel="nofollow">Airbyte</a>, <a href="https://www.fivetran.com/connectors/stripe" rel="nofollow">Fivetran</a>, and <a href="https://www.stitchdata.com/docs/integrations/saas/stripe" rel="nofollow">Stitch</a>. (The difference between ELT and ETL is where and how the data is transformed, but the general I/O is the same).</p>
<p>Of course, pulling data into Redshift or Snowflake doesn‚Äôt automatically solve your problem. You still need to calculate MRR. This is non-trivial. If we were to return to our <a href="https://cal.com/" rel="nofollow">Cal.com</a> friend, you can witness the frustration with his Benjamin Franklin offer:</p>
<p><img width="449" alt="Capture d‚ÄôeÃÅcran 2023-10-26 aÃÄ 10 32 43" src="https://private-user-images.githubusercontent.com/85290767/278265308-3d2fcfa9-15c7-412a-a4ba-b821de89cad7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2ODI5MDQsIm5iZiI6MTcyNDY4MjYwNCwicGF0aCI6Ii84NTI5MDc2Ny8yNzgyNjUzMDgtM2QyZmNmYTktMTVjNy00MTJhLWE0YmEtYjgyMWRlODljYWQ3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA4MjYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwODI2VDE0MzAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ3ZTE0NjkwOTdmMWM4MzI2ZGVjYjJlYWQyMDA2ZTkzYWFhNTZkMjYyNjVmODc1OTAwZWZkMDM4MjQ5NGU5YTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RNlB_tvzn3EvWZn6sfsiRTR-xumrObS0Qten6czEuB8" content-type-secured-asset="image/png"></p><p>Source: <a href="https://twitter.com/peer_rich/status/1701303837452083543?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1701303837452083543%7Ctwgr%5Ef27ef9916f11184ec4995cd6dde1389330364ad0%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.getlago.com%2Fblog%2Fcalculating-stripe-mrr-is-difficult" rel="nofollow">X</a></p>
<p><h2>Why open source billing solutions can solve it</h2><a id="user-content-why-open-source-billing-solutions-can-solve-it" aria-label="Permalink: Why open source billing solutions can solve it" href="#why-open-source-billing-solutions-can-solve-it"></a></p>
<p>Full disclosure, Lago is an open source billing solution. But the reason we‚Äôre so passionate about this subject is the same reason we built the Lago framework.</p>
<p>By leveraging open source billing solutions, you‚Äôll retain full ownership over your billing infrastructure. Of course, you can also build your own billing engine, and if you have the engineering bandwidth to do that, more power to you. But, given that <a href="https://www.getlago.com/blog/why-billing-systems-are-a-nightmare-for-engineers" rel="nofollow">billing is very hard with lots of edge cases</a>, many companies turn to external billing providers; all we‚Äôre saying is use an open-source one.</p>
<p>Take Lago, for instance. If you use our Docker distribution, you‚Äôll immediately get a leg-up on Stripe users:</p>
<p>No reliance on ELT / ETL solution to dump data at defined intervals
No dependence on third-party tools to crunch complex queries
Ability to build financial reports directly on top of your financial queries
Of course, as developers of commercial open source software (COSS), we have our biases. But no one can deny, even Stripe engineers, that getting instant access to your financial data in Postgres‚Äîsweet, open-source Postgres‚Äîis very handy. (We use Postgres, if that wasn‚Äôt obvious). The table is broken into simple tables like invoices, events, and fees.</p>
<p>Because you own your data, you can easily ingest it into an analytics tool (like <a href="https://www.metabase.com/" rel="nofollow">open-source Metabase</a>) to build your own dashboards.</p>
<p><img src="https://camo.githubusercontent.com/36edaf7bc69004138ef8c4a8acc770aa3eb6dd06903de78c4374436e31f18e97/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313364356262303965643339386532633238335f5374726970654d52525f53637265656e322e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e513d5bb09ed398e2c283_StripeMRR_Screen2.png"></p>
<p>Or, if you use one of the many closed-source BI tools, that works too. The point is that the data is yours, and the PSQL queries are your oyster.</p>
<p><h2>Some Lago examples to demonstrate our point</h2><a id="user-content-some-lago-examples-to-demonstrate-our-point" aria-label="Permalink: Some Lago examples to demonstrate our point" href="#some-lago-examples-to-demonstrate-our-point"></a></p>
<p>If you are serious about considering an open source library like Lago, it‚Äôs worth flipping through some basic revenue queries. To be clear, these are only basic queries for the sake of example‚Äîyou can go a lot deeper with more advanced retention data.</p>
<p><h3>Calculating Total Revenue</h3><a id="user-content-calculating-total-revenue" aria-label="Permalink: Calculating Total Revenue" href="#calculating-total-revenue"></a></p>
<p>If you want to calculate the total revenue with Lago, you will need to use the invoices table. In this table, there‚Äôs a simple trinity:</p>
<p><code>payment_status</code> = 0 are for <code>pending invoices</code>
<code>payment_status</code> = 1 are for <code>paid invoices</code>
<code>payment_status</code> = 2 are for <code>failed invoices</code>
Accordingly, a sample query for calculating total revenue looks like:</p>
<p><img src="https://camo.githubusercontent.com/dc26ff88a12c51bbf3683c6ce861a4ac72aaf215b6ab54be7d257d9435638d64/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313665373532616163336135333566643532315f53637265656e73686f74253230323032332d31302d3137253230617425323031312e31302e34362e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e516e752aac3a535fd521_Screenshot%202023-10-17%20at%2011.10.46.png"></p>
<p>If you want to break that data into month-by-month buckets, you can truncate it using <code>COALESCE</code> and a simple <code>GROUP BY</code> / <code>ORDER BY</code> pair.</p>
<p><img src="https://camo.githubusercontent.com/8c2c5964ea09606dd14f06c34d2a382fa6087c6128e7eb16ae85c7660d8c64bf/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313736336133343761653438316664353464305f53637265656e73686f74253230323032332d31302d3137253230617425323031312e31312e30342e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e51763a347ae481fd54d0_Screenshot%202023-10-17%20at%2011.11.04.png"></p>
<p>This results in a table that looks like this (please pardon my literal French):
<img src="https://camo.githubusercontent.com/13ff034f71c651e3f0d0e65721a345b9fd1be53fd19a74aa22c34ff6f99c9fa9/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313437643339656535653066386261633765335f5374726970654d52525f53637265656e332e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e5147d39ee5e0f8bac7e3_StripeMRR_Screen3.png"></p>
<p>Some notes on the table:</p>
<p>This revenue gathers <strong>subscriptions</strong>, <strong>usage based billing</strong> and <strong>add-ons</strong>.
We use the <code>issuing_date</code> of an invoice instead of the <code>created_at</code>. Because Lago can issue draft invoices, this always ensures we take the date of final stage of an invoice.</p>
<p><h3>Calculating Basic MRR &amp; ARR</h3><a id="user-content-calculating-basic-mrr--arr" aria-label="Permalink: Calculating Basic MRR &amp; ARR" href="#calculating-basic-mrr--arr"></a></p>
<p>MRR is tracking and calculating revenue from recurring <code>subscription</code> fees. To effectively calculate MRR, you'll need to fetch data from the <code>fees</code> table as part of the input data, and remove anything related to usage (called <code>charge</code> in Lago) and <code>add-ons</code> (created by one-time invoices).</p>
<p>The query amounts to:
<img src="https://camo.githubusercontent.com/2b7b86f94dd0746a65a0b62b588e02a2cedfcf58b333b28872550429ca31e331/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313835613966653735633431646662633438665f53637265656e73686f74253230323032332d31302d3137253230617425323031312e31312e32342e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e5185a9fe75c41dfbc48f_Screenshot%202023-10-17%20at%2011.11.24.png"></p>
<p>A likewise query for calculating ARR looks like:
<img src="https://camo.githubusercontent.com/3a6ff0e3612d41a115c7e646b0221ddaddc557b2bfb6296ab56a65261b4c0035/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633353639663339306633613761643463373664326264362f3635326535313931343631383337626630353938653632355f53637265656e73686f74253230323032332d31302d3137253230617425323031312e31312e33322e706e67" alt="" data-canonical-src="https://assets-global.website-files.com/63569f390f3a7ad4c76d2bd6/652e5191461837bf0598e625_Screenshot%202023-10-17%20at%2011.11.32.png"></p>
<p>Some notes here:</p>
<p>We might want to remove any discounts from this calculation in the future. In that case, we can just remove <code>coupons</code> or <code>wallets</code> data.
We might want to remove refunds (<code>credit_notes</code> table) from this calculation.
Regardless, even with some additional contingencies, calculating MRR or ARR using an open source solution is really easy.</p>
<p><h3>Usage MRR</h3><a id="user-content-usage-mrr" aria-label="Permalink: Usage MRR" href="#usage-mrr"></a></p>
<p>Since Lago operates first as a <strong>usage-based billing solution</strong>, optimizing the calculation of usage is crucial. You can refer to this as "Usage MRR," which may not follow a consistent usage pattern (i.e. not necessarily recurring) and can exhibit fluctuations between months.</p>
<p>To calculate Usage MRR, you will need to fetch data from the <code>fees</code> table as part of the input data, and add only fees related to usage (called <code>charge</code> in Lago). Some of the charges can be <code>recurring</code> (more predictable), and others can be <code>metered</code> (less predictable).</p>
<p><h2>Closing Thoughts</h2><a id="user-content-closing-thoughts" aria-label="Permalink: Closing Thoughts" href="#closing-thoughts"></a></p>
<p>Unfortunately, as closed-source companies grow, they tend to forgo basic features in favor of incentivizing upgrades. This is exactly the case with Stripe. Stripe wants customers to purchase Stripe Data Pipeline or Stripe Sigma to increase their per transaction revenue per customer. In certain cases, these tools are great and affordable, but for many, it‚Äôs very expensive.</p>
<p>Worse, Stripe‚Äôs structure makes calculating recurring revenue very, very difficult whenever organizations leverage a usage-based billing model. And that includes everyday SaaS apps that bill on a per-seat basis. There are tools to solve this (such as ProfitWell and Pigment), but they are either expensive, built for larger companies, or both.</p>
<p>The most surefire approach to conquer your billing woes is to build billing in-house or leverage an open source framework. We‚Äôre obviously biased towards the latter (particularly our open source framework), <strong>but the point stands that companies shouldn‚Äôt let their financial data be held hostage to the land and expand goals of Stripe‚Äôs sales team.</strong></p>
<p>‚Äç</p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Telegram abides by EU laws, including the Digital Services Act (128 pts)]]></title>
            <link>https://twitter.com/telegram/status/1827787345367834772</link>
            <guid>41350438</guid>
            <pubDate>Sun, 25 Aug 2024 19:26:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/telegram/status/1827787345367834772">https://twitter.com/telegram/status/1827787345367834772</a>, See on <a href="https://news.ycombinator.com/item?id=41350438">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[TIL: Versions of UUID and when to use them (294 pts)]]></title>
            <link>https://ntietz.com/blog/til-uses-for-the-different-uuid-versions/</link>
            <guid>41350225</guid>
            <pubDate>Sun, 25 Aug 2024 19:05:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ntietz.com/blog/til-uses-for-the-different-uuid-versions/">https://ntietz.com/blog/til-uses-for-the-different-uuid-versions/</a>, See on <a href="https://news.ycombinator.com/item?id=41350225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  

  <p><strong>Saturday, June 29, 2024</strong></p>

  <div><p>About a month ago<sup><a href="#not-today">1</a></sup>, I was onboarding a friend into one of my side project codebases and she asked me why I was using a particular type of UUID.
I'd heard about this type while working on that project, and it's really neat.
So instead of hogging that knowledge for just us, here it is: some good uses for different versions of UUID.</p>
<h2 id="what-are-the-different-versions">What are the different versions?</h2>
<p>Usually when we have multiple numbered versions, the higher numbers are newer and presumed to be better.
In contrast, there are 8 UUID versions (v1 through v8) which are different and all defined in <a href="https://datatracker.ietf.org/doc/html/rfc9562">the standard</a>.</p>
<p>Here, I'll provide some explanation of what they are at a high level, linking to the specific section of the RFC in case you want more details.</p>
<ul>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-1">UUID Version 1 (v1)</a> is generated from timestamp, monotonic counter, and a MAC address.</li>
<li><a href="https://datatracker.ietf.org/doc/html/rfc9562#name-uuid-version-2">UUID Version 2 (v2)</a> is reserved for security IDs with no known details<sup><a href="#dce">2</a></sup>.</li>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-3">UUID Version 3 (v3)</a> is generated from MD5 hashes of some data you provide. The RFC suggests DNS and URLs among the candidates for data.</li>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-4">UUID Version 4 (v4)</a> is generated from entirely random data. This is probably what most people think of and run into with UUIDs.</li>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-5">UUID Version 5 (v5)</a> is generated from SHA1 hahes of some data you proivde. As with v3, the RFC suggests DNS or URLs as candidates.</li>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-6">UUID Version 6 (v6)</a> is generated from timestamp, monotonic counter, and a MAC address. These are the same data as Version 1, but they change the order so that sorting them will sort by creation time.</li>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-7">UUID Version 7 (v7)</a> is generated from a timestamp and random data.</li>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#name-uuid-version-8">UUID Version 8 (v8)</a> is entirely custom (besides the required version/variant fields that all versions contain).</li>
</ul>
<h2 id="when-should-you-use-them">When should you use them?</h2>
<p>With eight different versions, which should you use?
There are a few common use cases that dictate which you should use, and some have been replaced by others.</p>
<p>You'll usually be picking between two of them: v4 or v7.
There are also some occasions to pick v5 or v8.</p>
<ul>
<li>Use v4 when you just want a random ID.
<em>This is a good default choice.</em></li>
<li>Use v7 if you're using the ID in a context where you want to be able to sort.
For example, consider using v7 if you are using UUIDs as database keys.</li>
<li>v5 or v8 are used if you have your own data you want in the UUID, but generally, you will know if you need it.</li>
</ul>
<p>What about the other ones?</p>
<ul>
<li><a href="https://www.rfc-editor.org/rfc/rfc9562.html#section-5.7-4">Per the RFC</a>, v7 improves on v1 and v6 and should be used over those if possible.
So you usually won't want v1 or v6.
If you do want one of those, you <em>can</em> use v6.</li>
<li>v2 is reserved for unspecified security things.
If you <em>are</em> using these, you probably can't tell me or anyone else about it, and you're probably not reading this post to figure out more about them.</li>
<li>v3 is superceded by v5, which uses a stronger hash.
This one is one where you probably <em>know</em> if you need it.</li>
</ul>
<hr>


</div>

  


  <hr>
  <p>
    If this post was enjoyable or useful for you, <strong>please share it!</strong>
    If you have comments, questions, or feedback, you can email <a href="mailto:me@ntietz.com">my personal email</a>.
    To get new posts and support my work, subscribe to the <a href="https://ntietz.com/newsletter/">newsletter</a>. There is also an <a href="https://ntietz.com/atom.xml">RSS feed</a>.
  </p>
  <p>
  <i></i> Want to become a better programmer?
  <a href="https://www.recurse.com/scout/click?t=c9a1a9e2e7a2ffefd4af20020b4af1e6">Join the Recurse Center!</a>
  <br>
  Want to hire great programmers?
  <a href="https://recurse.com/hire?utm_source=ntietz&amp;utm_medium=blog">Hire via Recurse Center!</a>
  <i></i>
</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The art of programming and why I won't use LLM (187 pts)]]></title>
            <link>https://kennethnym.com/blog/why-i-still-wont-use-llm/</link>
            <guid>41349443</guid>
            <pubDate>Sun, 25 Aug 2024 17:47:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kennethnym.com/blog/why-i-still-wont-use-llm/">https://kennethnym.com/blog/why-i-still-wont-use-llm/</a>, See on <a href="https://news.ycombinator.com/item?id=41349443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <article> <div>   <p>as llms get better and better at writing code, more and more people, at least on twt, have started to incorporate llms into their workflow. most people seem to agree that llms have been a game changer for coding, praising them for how much they have improved their productivity, how much easier it is to write code, and claiming that programmers who refuse to use them are ‚Äúnot using them correctly‚Äù and will eventually get left behind
in my opinion, the effectiveness of llms in coding at their current state is vastly overblown. even if llms were as good as what avid users of them claim, i still won‚Äôt see myself using it in any meaningful capacity.</p>
<h2 id="the-art-of-programming">the art of programming</h2>
<p>programming can be broken down into two parts - solving problems algorithmically, breaking problems into steps that computers can follow within some contraints, thus forming a solution to the original problem; and expressing the solution in a way that the computer can understand.</p>
<p>both parts provide the programmers with an infinite canvas on which they can express their creativitiy. there are practically limitless ways to approach and solve a problem, and a practically infinite way to express a solution to the problem. hence, programming is a form of self-expression - it is an art form. what is produced through programming is a kind of art - an art few appreciate.</p>
<h2 id="i-am-a-programming-artist">i am a programming artist</h2>
<p>in that sense, i see myself as an artist, one that expresses his creative self through programming. i enjoy creating programming art, because only through it do i find my true self, one who has a burning passion to create and build things.</p>
<h2 id="llm-is-not-for-me">llm is not for me</h2>
<p>using llm to write code is like asking an artist to paint for you. if you only want the end result, by all means! if you are like me who enjoy the process of painting, then why would you bother automating the fun part away? one may say, ‚Äúbut i am only using llm to write code. i am still doing the problem solving myself!‚Äù. to me, programming isn‚Äôt complete if i don‚Äôt get to express the solution in code myself. it isn‚Äôt my art if i don‚Äôt create it myself.</p>
<h2 id="a-sad-reality">a sad reality</h2>
<p>it is sad to me just how much people are trying to automate away programming and delegating it to a black box that can‚Äôt even count letters in a word sometimes, even going as far as trying to emulate a software engineer on top of the black box. does no one not find programming fun anymore? does no one care enough about programming to go further beyond getting things working ‚Äúwell enough‚Äù? is this just another case of availability bias?</p>
<p>please don‚Äôt take this as a judgemental piece to anyone that i am alluring to. it‚Äôs fine to not find programming enjoyable. it‚Äôs fine to just want things to work. i am just disappointed at how the ones who care appear to be an ever dying breed.</p>  </div> </article> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux Pipes Are Slow (248 pts)]]></title>
            <link>https://qsantos.fr/2024/08/25/linux-pipes-are-slow/</link>
            <guid>41348844</guid>
            <pubDate>Sun, 25 Aug 2024 16:52:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qsantos.fr/2024/08/25/linux-pipes-are-slow/">https://qsantos.fr/2024/08/25/linux-pipes-are-slow/</a>, See on <a href="https://news.ycombinator.com/item?id=41348844">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<h2><code>vmsplice</code> is <em>too</em> fast</h2>



<p>Some programs use a particular system call ‚Äú<code>vmsplice</code>‚Äù to move data faster through a pipe. Francesco already did <a href="https://mazzo.li/posts/fast-pipes.html">a deep dive on using <code>vmsplice</code> to make things fast</a>. However, while experimenting with it, I noticed that, when not using <code>vmsplice</code>, Linux pipes are slower than what I would have expected. Since you cannot always use it, I wanted to understand exactly why that was, and whether it could be improved.</p>



<p>The reason I want to move data through pipes is that I am writing a program <a href="https://github.com/qsantos/ripmors/">encode/decode Morse code blazingly fast</a>.</p>



<p>To get a point of reference, the obvious candidate is the <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/">Fizz Buzz throughput competition at the Code Golf StackExchange</a>. There are two kinds of solutions:</p>



<ol>
<li>the ones that manage to reach up to a few gigabytes per second, with <a href="https://codegolf.stackexchange.com/a/215231">neil‚Äôs</a> reaching 8.4 GiB/s;</li>



<li>the ones which largely surpass that, from <a href="https://codegolf.stackexchange.com/a/256115">tkluck‚Äôs</a> at 15.5 GiB/s to <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">ais523‚Äôs</a> at 60.8 GiB/s, to <a href="https://codegolf.stackexchange.com/a/269772">david‚Äôs</a> at 208.3 GiB/s using multiple cores.</li>
</ol>



<p>The difference between the first and the second group is that the second is using <code>vmsplice</code>, while the first is not<sup data-fn="25bc32bc-4b79-41b9-87b3-0db6adcecbbf"><a href="#25bc32bc-4b79-41b9-87b3-0db6adcecbbf" id="25bc32bc-4b79-41b9-87b3-0db6adcecbbf-link">1</a></sup>. But how can using <code>vmsplice</code> enable such a large gain in performance? My intuition about <code>vmsplice</code> is that it allows you to avoid copying data to and from kernel space. Surely, copying data cannot be slower than generating it? Even assuming it is not faster, and that you have to copy the data twice to get it through the pipe, you would assume a throughput gain of 3√ó, at best. But here, we have 7, even just looking at single-core solutions.</p>



<p>Something is missing in my mental model, I want to know what.</p>



<p>First, I‚Äôll need to perform my own measurements to easily compare with what I‚Äôll do afterward. Compiling and running aie523‚Äôs solution on my computer<sup data-fn="9f242c74-a611-49a2-9265-07d5945c4750"><a href="#9f242c74-a611-49a2-9265-07d5945c4750" id="9f242c74-a611-49a2-9265-07d5945c4750-link">2</a></sup>, I get:</p>



<pre><code>$ ./fizzbuzz | pv &gt;/dev/null
96.4GiB 0:00:01 [96.4GiB/s]</code></pre>



<p>With david‚Äôs solution, I reach 277&nbsp;GB/s when using 7 cores (40 GB/s per core).</p>



<p>Now, to understand what‚Äôs going on, we need to find the answer to these questions:</p>



<ol>
<li>How fast can we write data <em>ideally</em>?</li>



<li>How fast can we <em>actually</em> write data to a pipe?</li>



<li>How does <code>vmsplice</code> help?</li>
</ol>



<h2>Writing Data in the Ideal Wonderland</h2>



<p>First, let‚Äôs consider the program below, which just copies data without doing any system call. I use <code><a href="https://doc.rust-lang.org/std/hint/fn.black_box.html">std::hint::black_box</a></code> to stop the compiler from noticing that we are not using the result. Without this, the compiler would optimize the program to nothing.</p>



<pre><code lang="rust">fn main() {
    let dst = [0u8; 1 &lt;&lt; 15];
    let src = [0u8; 1 &lt;&lt; 15];
    let mut copied = 0;
    while copied &lt; (1000 &lt;&lt; 30) {
        std::hint::black_box(dst).copy_from_slice(&amp;src);
        copied += src.len();
    }
}</code></pre>



<p>On my system, this runs at 167 GB/s. This is consistent with the speed of writing to L1 cache for my CPU<sup data-fn="e22c8070-2784-40d4-81ae-6916566ce03a"><a href="#e22c8070-2784-40d4-81ae-6916566ce03a" id="e22c8070-2784-40d4-81ae-6916566ce03a-link">3</a></sup>.</p>



<p>When profiling this, we see that 99.9% of the time is spent in <code>__memset_avx512_unaligned_erms</code>, directly called by <code>main</code>, and calling no other functions. The flamegraph is pretty much flat. If you do not feel like running a full-fledged profiler, you can just <a href="https://yosefk.com/blog/profiling-with-ctrl-c.html">use <code>gdb</code> and hit Ctrl+C at a random time</a>:</p>



<pre><code lang="bash">$ cargo build --release
$ gdb target/release/copy 
‚Ä¶
(gdb) run
‚Ä¶
^C (hitting Ctrl+C)
Program received signal SIGINT, Interrupt.
__memset_avx512_unaligned_erms () at ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:236
‚Ä¶
=&gt; 0x00007ffff7f15dba    f3 aa    rep stos %al,%es:(%rdi)</code></pre>



<p>In any case, note that we are using AVX-512. The reference to <code>memset</code> in the names can be surprising, but this is just because part of the logic is common with <code>memcpy</code>. The implementation is in a <a href="https://github.com/lattera/glibc/blob/master/sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S">generic file dedicated to  SIMD <strong>vec</strong>torization</a> that supports SSE, AVX2 and AVX-512. In our case, <a href="https://github.com/lattera/glibc/blob/895ef79e04a953cac1493863bcae29ad85657ee1/sysdeps/x86_64/multiarch/memset-avx512-unaligned-erms.S#L4">the AVX-512 specialization</a> is used.</p>



<p>As an aside, note that the implementation of <code>memcpy</code> in glibc uses <a href="https://web.mit.edu/darwin/src/modules/xnu/osfmk/man/vm_copy.html">vm_copy</a> to copy pages directly on Mach-based systems (mostly Apply products) <a href="https://github.com/lattera/glibc/blob/master/string/memcpy.c#L44">uses a kernel feature to copy pages directly</a>.</p>



<p>However, AVX-512 is quite niche. According to <a href="https://store.steampowered.com/hwsurvey">Steam‚Äôs hardware survey</a> (section ‚ÄúOther Settings‚Äù), only about 12% of Steam users have it. In fact, Intel only included AVX-512 for consumer-grade processors in the 11th generation; and now reserves it for servers. AMD CPUs support AVX-512 since the Ryzen 7000 series (Zen 4).</p>



<p>So I tested this same program while disabling AVX-512. For this, I used the Linux kernel option <code><a href="https://www.phoronix.com/review/amd-zen4-avx512">clearcpuid=304</a></code>. I was able to check that it used <code>__memset_avx2_unaligned_erms</code> using the <code>gdb</code> and Ctrl+C trick. I then did the same to disable AVX2 with <code><a href="https://www.phoronix.com/news/Linux-5.19-Better-clearcpuid">clearcpuid=304,avx2,avx</a></code>, making it use <code>__memset_sse2_unaligned_erms</code>.</p>



<p>Although SSE2 is always available on x86-64, I also disabled the <code>cpuid</code> bit for SSE2 and SSE to see if it could nudge <code>glibc</code> into using scalar registers to copy data. I immediately got a kernel panic. Ah, well.</p>



<p>When using AVX2, the throughput was‚Ä¶ 167 GB/s. When using only SSE2, the throughput was‚Ä¶ still 167 GB/s. To an extent, it makes sense: even SSE2 is quite enough to fully use the bus and saturate L1 bandwidth. Using wider registers only helps when performing ALU operations.</p>



<p>The conclusion from this experiment is that, as long as vectorization is used, I should reach 167 GB/s.</p>



<h2>Actually Writing Data to a Pipe</h2>



<p>So, let‚Äôs look at what happen when we write to a pipe instead of to user space memory:</p>



<pre><code lang="rust">use std::io::Write;
use std::os::fd::FromRawFd;
fn main() {
    let vec = vec![b'\0'; 1 &lt;&lt; 15];
    let mut total_written = 0;
    let mut stdout = unsafe { std::fs::File::from_raw_fd(1) };
    while let Ok(n) = stdout.write(&amp;vec) {
        total_written += n;
        if total_written &gt;= (100 &lt;&lt; 30) {
            break;
        }
    }
}</code></pre>



<p>We then measure the throughput using:</p>



<pre><code lang="bash">cargo run --release | pv &gt;/dev/null</code></pre>



<p>On my computer, this reaches 17&nbsp;GB/s. This is 10 times as slow as just writing to a buffer! How can a system call which basically writes to a kernel buffer be so much slower? And no, context switches don‚Äôt take that much time.</p>



<p>So let‚Äôs do some profiling of this program.</p>



<svg version="1.1" onload="init(evt)" viewBox="0 0 1200 646" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<!-- Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples. -->
<!-- NOTES:  -->
<defs>
	<linearGradient id="background" y1="0" y2="1" x1="0" x2="0">
		<stop stop-color="#eeeeee" offset="5%"></stop>
		<stop stop-color="#eeeeb0" offset="95%"></stop>
	</linearGradient>
</defs>


<rect x="0.0" y="0" width="1200.0" height="646.0" fill="url(#background)"></rect>
<text id="title" x="600.00" y="24">./zeroes | pv &gt;/dev/null</text>
<text id="subtitle" x="600.00" y="48">Profiling of ./zeroes</text>
<text id="details" x="10.00" y="629"> </text>
<text id="unzoom" x="10.00" y="24">Reset Zoom</text>
<text id="search" x="1090.00" y="24">Search</text>
<text id="ignorecase" x="1174.00" y="24">ic</text>
<text id="matched" x="1090.00" y="629"> </text>
<g id="frames">
<g>
<title>__x86_return_thunk (4,202,612 samples, 0.01%)</title><rect x="213.3" y="325" width="0.1" height="23.0" fill="rgb(253,221,53)" rx="2" ry="2"></rect>
<text x="216.26" y="339.5"></text>
</g>
<g>
<title>exit_to_user_mode_prepare (23,309,116 samples, 0.07%)</title><rect x="1187.8" y="397" width="0.8" height="23.0" fill="rgb(228,108,25)" rx="2" ry="2"></rect>
<text x="1190.80" y="411.5"></text>
</g>
<g>
<title>_raw_spin_lock_irqsave (25,962,963 samples, 0.08%)</title><rect x="504.7" y="277" width="0.9" height="23.0" fill="rgb(247,195,46)" rx="2" ry="2"></rect>
<text x="507.67" y="291.5"></text>
</g>
<g>
<title>__x86_return_thunk (32,381,871 samples, 0.09%)</title><rect x="259.4" y="301" width="1.1" height="23.0" fill="rgb(253,221,53)" rx="2" ry="2"></rect>
<text x="262.38" y="315.5"></text>
</g>
<g>
<title>try_charge_memcg (846,277,863 samples, 2.46%)</title><rect x="184.2" y="301" width="29.1" height="23.0" fill="rgb(210,27,6)" rx="2" ry="2"></rect>
<text x="187.24" y="315.5">tr..</text>
</g>
<g>
<title>_raw_spin_unlock_irq (288,030,674 samples, 0.84%)</title><rect x="892.0" y="349" width="9.9" height="23.0" fill="rgb(215,47,11)" rx="2" ry="2"></rect>
<text x="895.00" y="363.5"></text>
</g>
<g>
<title>check_new_pages (310,465,336 samples, 0.90%)</title><rect x="505.7" y="277" width="10.6" height="23.0" fill="rgb(249,202,48)" rx="2" ry="2"></rect>
<text x="508.70" y="291.5"></text>
</g>
<g>
<title>osq_lock (117,185,036 samples, 0.34%)</title><rect x="803.0" y="325" width="4.1" height="23.0" fill="rgb(214,43,10)" rx="2" ry="2"></rect>
<text x="806.04" y="339.5"></text>
</g>
<g>
<title>__rcu_read_lock (226,040,208 samples, 0.66%)</title><rect x="145.4" y="301" width="7.7" height="23.0" fill="rgb(220,69,16)" rx="2" ry="2"></rect>
<text x="148.37" y="315.5"></text>
</g>
<g>
<title>__GI___libc_write (34,368,952,857 samples, 99.89%)</title><rect x="11.3" y="493" width="1178.7" height="23.0" fill="rgb(217,57,13)" rx="2" ry="2"></rect>
<text x="14.30" y="507.5">__GI___libc_write</text>
</g>
<g>
<title>&lt;std::os::unix::net::stream::UnixStream as std::io::Write&gt;::write (12,137,904 samples, 0.04%)</title><rect x="10.0" y="517" width="0.4" height="23.0" fill="rgb(239,160,38)" rx="2" ry="2"></rect>
<text x="13.00" y="531.5"></text>
</g>
<g>
<title>__hrtimer_run_queues (11,254,762 samples, 0.03%)</title><rect x="802.6" y="205" width="0.3" height="23.0" fill="rgb(237,150,35)" rx="2" ry="2"></rect>
<text x="805.56" y="219.5"></text>
</g>
<g>
<title>_raw_spin_unlock_irqrestore (16,388,541 samples, 0.05%)</title><rect x="830.2" y="325" width="0.5" height="23.0" fill="rgb(228,106,25)" rx="2" ry="2"></rect>
<text x="833.16" y="339.5"></text>
</g>
<g>
<title>fpregs_assert_state_consistent (4,142,862 samples, 0.01%)</title><rect x="1188.5" y="373" width="0.1" height="23.0" fill="rgb(228,109,26)" rx="2" ry="2"></rect>
<text x="1191.45" y="387.5"></text>
</g>
<g>
<title>vfs_write (33,501,533,082 samples, 97.36%)</title><rect x="36.1" y="397" width="1148.9" height="23.0" fill="rgb(250,209,50)" rx="2" ry="2"></rect>
<text x="39.07" y="411.5">vfs_write</text>
</g>
<g>
<title>__x86_return_thunk (15,219,222 samples, 0.04%)</title><rect x="183.7" y="253" width="0.5" height="23.0" fill="rgb(253,221,53)" rx="2" ry="2"></rect>
<text x="186.72" y="267.5"></text>
</g>
<g>
<title>aa_file_perm (30,051,576 samples, 0.09%)</title><rect x="1183.1" y="325" width="1.0" height="23.0" fill="rgb(229,110,26)" rx="2" ry="2"></rect>
<text x="1186.09" y="339.5"></text>
</g>
<g>
<title>_find_first_bit (57,390,916 samples, 0.17%)</title><rect x="908.8" y="301" width="2.0" height="23.0" fill="rgb(252,216,51)" rx="2" ry="2"></rect>
<text x="911.79" y="315.5"></text>
</g>
<g>
<title>__list_del_entry_valid (120,783,301 samples, 0.35%)</title><rect x="255.2" y="301" width="4.2" height="23.0" fill="rgb(239,158,37)" rx="2" ry="2"></rect>
<text x="258.24" y="315.5"></text>
</g>
<g>
<title>hrtimer_interrupt (12,658,212 samples, 0.04%)</title><rect x="802.6" y="229" width="0.4" height="23.0" fill="rgb(228,109,26)" rx="2" ry="2"></rect>
<text x="805.56" y="243.5"></text>
</g>
<g>
<title>_raw_spin_trylock (959,948,236 samples, 2.79%)</title><rect x="260.5" y="301" width="32.9" height="23.0" fill="rgb(222,80,19)" rx="2" ry="2"></rect>
<text x="263.49" y="315.5">_r..</text>
</g>
<g>
<title>file_update_time (4,074,965 samples, 0.01%)</title><rect x="1151.6" y="349" width="0.1" height="23.0" fill="rgb(210,27,6)" rx="2" ry="2"></rect>
<text x="1154.60" y="363.5"></text>
</g>
<g>
<title>__mod_zone_page_state (32,134,035 samples, 0.09%)</title><rect x="503.6" y="277" width="1.1" height="23.0" fill="rgb(221,74,17)" rx="2" ry="2"></rect>
<text x="506.57" y="291.5"></text>
</g>
<g>
<title>_raw_spin_unlock_irqrestore (4,140,183 samples, 0.01%)</title><rect x="505.6" y="277" width="0.1" height="23.0" fill="rgb(228,106,25)" rx="2" ry="2"></rect>
<text x="508.56" y="291.5"></text>
</g>
<g>
<title>syscall_exit_to_user_mode (30,099,876 samples, 0.09%)</title><rect x="1187.7" y="421" width="1.0" height="23.0" fill="rgb(251,211,50)" rx="2" ry="2"></rect>
<text x="1190.66" y="435.5"></text>
</g>
<g>
<title>all (34,408,358,444 samples, 100%)</title><rect x="10.0" y="589" width="1180.0" height="23.0" fill="rgb(213,39,9)" rx="2" ry="2"></rect>
<text x="13.00" y="603.5"></text>
</g>
<g>
<title>__x86_return_thunk (16,313,413 samples, 0.05%)</title><rect x="906.1" y="325" width="0.5" height="23.0" fill="rgb(253,221,53)" rx="2" ry="2"></rect>
<text x="909.05" y="339.5"></text>
</g>
<g>
<title>entry_SYSCALL_64 (134,570,535 samples, 0.39%)</title><rect x="16.9" y="469" width="4.6" height="23.0" fill="rgb(239,156,37)" rx="2" ry="2"></rect>
<text x="19.92" y="483.5"></text>
</g>
<g>
<title>__sysvec_apic_timer_interrupt (12,658,212 samples, 0.04%)</title><rect x="802.6" y="253" width="0.4" height="23.0" fill="rgb(242,173,41)" rx="2" ry="2"></rect>
<text x="805.56" y="267.5"></text>
</g>
<g>
<title>asm_sysvec_apic_timer_interrupt (16,786,362 samples, 0.05%)</title><rect x="802.4" y="301" width="0.6" height="23.0" fill="rgb(232,127,30)" rx="2" ry="2"></rect>
<text x="805.41" y="315.5"></text>
</g>
<g>
<title>update_process_times (7,029,218 samples, 0.02%)</title><rect x="802.7" y="133" width="0.2" height="23.0" fill="rgb(250,209,50)" rx="2" ry="2"></rect>
<text x="805.70" y="147.5"></text>
</g>
<g>
<title>policy_nodemask (33,222,227 samples, 0.10%)</title><rect x="910.8" y="325" width="1.1" height="23.0" fill="rgb(221,74,17)" rx="2" ry="2"></rect>
<text x="913.76" y="339.5"></text>
</g>
<g>
<title>cgroup_rstat_updated (79,560,370 samples, 0.23%)</title><rect x="181.0" y="229" width="2.7" height="23.0" fill="rgb(244,180,43)" rx="2" ry="2"></rect>
<text x="183.99" y="243.5"></text>
</g>
<g>
<title>_copy_from_iter (6,966,591,966 samples, 20.25%)</title><rect x="912.7" y="325" width="238.9" height="23.0" fill="rgb(227,104,24)" rx="2" ry="2"></rect>
<text x="915.69" y="339.5">_copy_from_iter</text>
</g>
<g>
<title>__list_del_entry_valid (400,133,559 samples, 1.16%)</title><rect x="489.8" y="277" width="13.8" height="23.0" fill="rgb(239,158,37)" rx="2" ry="2"></rect>
<text x="492.84" y="291.5"></text>
</g>
<g>
<title>clear_page_erms (4,655,903,634 samples, 13.53%)</title><rect x="296.0" y="301" width="159.7" height="23.0" fill="rgb(229,113,27)" rx="2" ry="2"></rect>
<text x="299.01" y="315.5">clear_page_erms</text>
</g>
<g>
<title>update_wall_time (4,225,544 samples, 0.01%)</title><rect x="802.6" y="133" width="0.1" height="23.0" fill="rgb(207,11,2)" rx="2" ry="2"></rect>
<text x="805.56" y="147.5"></text>
</g>
<g>
<title>__rcu_read_unlock (6,832,345 samples, 0.02%)</title><rect x="1183.9" y="301" width="0.2" height="23.0" fill="rgb(253,224,53)" rx="2" ry="2"></rect>
<text x="1186.89" y="315.5"></text>
</g>
<g>
<title>refill_stock (17,620,376 samples, 0.05%)</title><rect x="212.7" y="277" width="0.6" height="23.0" fill="rgb(238,153,36)" rx="2" ry="2"></rect>
<text x="215.66" y="291.5"></text>
</g>
<g>
<title>ksys_write (33,653,152,549 samples, 97.81%)</title><rect x="30.9" y="421" width="1154.1" height="23.0" fill="rgb(205,4,1)" rx="2" ry="2"></rect>
<text x="33.87" y="435.5">ksys_write</text>
</g>
<g>
<title>sysvec_apic_timer_interrupt (13,980,036 samples, 0.04%)</title><rect x="802.5" y="277" width="0.5" height="23.0" fill="rgb(220,69,16)" rx="2" ry="2"></rect>
<text x="805.51" y="291.5"></text>
</g>
<g>
<title>__memcg_kmem_charge_page (2,947,262,302 samples, 8.57%)</title><rect x="112.2" y="325" width="101.1" height="23.0" fill="rgb(217,57,13)" rx="2" ry="2"></rect>
<text x="115.19" y="339.5">__memcg_kmem..</text>
</g>
<g>
<title>sysvec_apic_timer_interrupt (4,214,752 samples, 0.01%)</title><rect x="455.5" y="253" width="0.2" height="23.0" fill="rgb(220,69,16)" rx="2" ry="2"></rect>
<text x="458.53" y="267.5"></text>
</g>
<g>
<title>get_page_from_freelist (8,833,731,051 samples, 25.67%)</title><rect x="213.4" y="325" width="302.9" height="23.0" fill="rgb(252,218,52)" rx="2" ry="2"></rect>
<text x="216.40" y="339.5">get_page_from_freelist</text>
</g>
<g>
<title>rw_verify_area (10,800,291 samples, 0.03%)</title><rect x="1170.5" y="373" width="0.4" height="23.0" fill="rgb(218,64,15)" rx="2" ry="2"></rect>
<text x="1173.54" y="387.5"></text>
</g>
<g>
<title>tick_sched_handle (7,029,218 samples, 0.02%)</title><rect x="802.7" y="157" width="0.2" height="23.0" fill="rgb(219,68,16)" rx="2" ry="2"></rect>
<text x="805.70" y="171.5"></text>
</g>
<g>
<title>tick_sched_do_timer (4,225,544 samples, 0.01%)</title><rect x="802.6" y="157" width="0.1" height="23.0" fill="rgb(227,104,25)" rx="2" ry="2"></rect>
<text x="805.56" y="171.5"></text>
</g>
<g>
<title>__get_obj_cgroup_from_memcg (460,978,258 samples, 1.34%)</title><rect x="129.6" y="301" width="15.8" height="23.0" fill="rgb(209,21,5)" rx="2" ry="2"></rect>
<text x="132.56" y="315.5"></text>
</g>
<g>
<title>asm_sysvec_apic_timer_interrupt (4,105,206 samples, 0.01%)</title><rect x="295.9" y="301" width="0.1" height="23.0" fill="rgb(232,127,30)" rx="2" ry="2"></rect>
<text x="298.87" y="315.5"></text>
</g>
<g>
<title>__mutex_lock.constprop.0 (8,703,282,714 samples, 25.29%)</title><rect x="516.3" y="349" width="298.5" height="23.0" fill="rgb(225,95,22)" rx="2" ry="2"></rect>
<text x="519.35" y="363.5">__mutex_lock.constprop.0</text>
</g>
<g>
<title>timekeeping_advance (4,225,544 samples, 0.01%)</title><rect x="802.6" y="109" width="0.1" height="23.0" fill="rgb(227,104,25)" rx="2" ry="2"></rect>
<text x="805.56" y="123.5"></text>
</g>
<g>
<title>security_file_permission (410,026,776 samples, 1.19%)</title><rect x="1170.9" y="373" width="14.1" height="23.0" fill="rgb(225,96,23)" rx="2" ry="2"></rect>
<text x="1173.91" y="387.5"></text>
</g>
<g>
<title>apparmor_file_permission (317,347,965 samples, 0.92%)</title><rect x="1173.3" y="349" width="10.9" height="23.0" fill="rgb(218,60,14)" rx="2" ry="2"></rect>
<text x="1176.29" y="363.5"></text>
</g>
<g>
<title>zeroes::main (34,396,128,845 samples, 99.96%)</title><rect x="10.4" y="517" width="1179.6" height="23.0" fill="rgb(205,1,0)" rx="2" ry="2"></rect>
<text x="13.42" y="531.5">zeroes::main</text>
</g>
<g>
<title>alloc_pages (292,194,676 samples, 0.85%)</title><rect x="901.9" y="349" width="10.0" height="23.0" fill="rgb(210,25,6)" rx="2" ry="2"></rect>
<text x="904.88" y="363.5"></text>
</g>
<g>
<title>copy_page_from_iter (6,986,960,281 samples, 20.31%)</title><rect x="912.0" y="349" width="239.6" height="23.0" fill="rgb(209,22,5)" rx="2" ry="2"></rect>
<text x="914.99" y="363.5">copy_page_from_iter</text>
</g>
<g>
<title>mutex_lock (389,788,556 samples, 1.13%)</title><rect x="1151.8" y="349" width="13.4" height="23.0" fill="rgb(217,57,13)" rx="2" ry="2"></rect>
<text x="1154.79" y="363.5"></text>
</g>
<g>
<title>&lt;std::os::unix::net::stream::UnixStream as std::io::Write&gt;::write (21,805,012 samples, 0.06%)</title><rect x="10.6" y="493" width="0.7" height="23.0" fill="rgb(239,160,38)" rx="2" ry="2"></rect>
<text x="13.56" y="507.5"></text>
</g>
<g>
<title>_raw_spin_lock_irqsave (431,015,735 samples, 1.25%)</title><rect x="815.4" y="325" width="14.8" height="23.0" fill="rgb(247,195,46)" rx="2" ry="2"></rect>
<text x="818.37" y="339.5"></text>
</g>
<g>
<title>policy_node (119,598,949 samples, 0.35%)</title><rect x="906.7" y="325" width="4.1" height="23.0" fill="rgb(236,143,34)" rx="2" ry="2"></rect>
<text x="909.66" y="339.5"></text>
</g>
<g>
<title>__sysvec_apic_timer_interrupt (4,214,752 samples, 0.01%)</title><rect x="455.5" y="229" width="0.2" height="23.0" fill="rgb(242,173,41)" rx="2" ry="2"></rect>
<text x="458.53" y="243.5"></text>
</g>
<g>
<title>mutex_spin_on_owner (7,651,102,789 samples, 22.24%)</title><rect x="540.7" y="325" width="262.3" height="23.0" fill="rgb(217,57,13)" rx="2" ry="2"></rect>
<text x="543.65" y="339.5">mutex_spin_on_owner</text>
</g>
<g>
<title>mutex_unlock (154,311,955 samples, 0.45%)</title><rect x="1165.2" y="349" width="5.2" height="23.0" fill="rgb(251,212,50)" rx="2" ry="2"></rect>
<text x="1168.15" y="363.5"></text>
</g>
<g>
<title>entry_SYSRETQ_unsafe_stack (4,116,333 samples, 0.01%)</title><rect x="1188.8" y="469" width="0.2" height="23.0" fill="rgb(206,7,1)" rx="2" ry="2"></rect>
<text x="1191.83" y="483.5"></text>
</g>
<g>
<title>__wake_up_common_lock (463,608,242 samples, 1.35%)</title><rect x="814.8" y="349" width="15.9" height="23.0" fill="rgb(238,155,37)" rx="2" ry="2"></rect>
<text x="817.82" y="363.5"></text>
</g>
<g>
<title>__mod_memcg_state (156,325,243 samples, 0.45%)</title><rect x="178.4" y="253" width="5.3" height="23.0" fill="rgb(205,1,0)" rx="2" ry="2"></rect>
<text x="181.36" y="267.5"></text>
</g>
<g>
<title>__fdget_pos (131,186,857 samples, 0.38%)</title><rect x="31.6" y="397" width="4.5" height="23.0" fill="rgb(216,55,13)" rx="2" ry="2"></rect>
<text x="34.57" y="411.5"></text>
</g>
<g>
<title>__rcu_read_unlock (256,610,337 samples, 0.75%)</title><rect x="136.5" y="277" width="8.8" height="23.0" fill="rgb(253,224,53)" rx="2" ry="2"></rect>
<text x="139.48" y="291.5"></text>
</g>
<g>
<title>update_vsyscall (4,225,544 samples, 0.01%)</title><rect x="802.6" y="61" width="0.1" height="23.0" fill="rgb(254,229,54)" rx="2" ry="2"></rect>
<text x="805.56" y="75.5"></text>
</g>
<g>
<title>__alloc_pages (12,488,057,959 samples, 36.29%)</title><rect x="88.1" y="349" width="428.2" height="23.0" fill="rgb(233,129,30)" rx="2" ry="2"></rect>
<text x="91.08" y="363.5">__alloc_pages</text>
</g>
<g>
<title>copy_user_enhanced_fast_string (6,911,972,451 samples, 20.09%)</title><rect x="914.6" y="301" width="237.0" height="23.0" fill="rgb(238,155,37)" rx="2" ry="2"></rect>
<text x="917.56" y="315.5">copy_user_enhanced_fast_string</text>
</g>
<g>
<title>mod_memcg_state (483,429,269 samples, 1.40%)</title><rect x="167.7" y="277" width="16.5" height="23.0" fill="rgb(232,127,30)" rx="2" ry="2"></rect>
<text x="170.66" y="291.5"></text>
</g>
<g>
<title>__wake_up_common (7,952,263 samples, 0.02%)</title><rect x="815.1" y="325" width="0.3" height="23.0" fill="rgb(248,197,47)" rx="2" ry="2"></rect>
<text x="818.10" y="339.5"></text>
</g>
<g>
<title>page_counter_try_charge (100,471,631 samples, 0.29%)</title><rect x="209.2" y="277" width="3.5" height="23.0" fill="rgb(233,132,31)" rx="2" ry="2"></rect>
<text x="212.21" y="291.5"></text>
</g>
<g>
<title>__x64_sys_write (103,208,079 samples, 0.30%)</title><rect x="27.3" y="421" width="3.6" height="23.0" fill="rgb(246,189,45)" rx="2" ry="2"></rect>
<text x="30.33" y="435.5"></text>
</g>
<g>
<title>syscall_enter_from_user_mode (78,405,130 samples, 0.23%)</title><rect x="1185.0" y="421" width="2.7" height="23.0" fill="rgb(254,229,54)" rx="2" ry="2"></rect>
<text x="1187.97" y="435.5"></text>
</g>
<g>
<title>asm_sysvec_apic_timer_interrupt (5,629,654 samples, 0.02%)</title><rect x="455.5" y="277" width="0.2" height="23.0" fill="rgb(232,127,30)" rx="2" ry="2"></rect>
<text x="458.49" y="291.5"></text>
</g>
<g>
<title>osq_unlock (226,312,628 samples, 0.66%)</title><rect x="807.1" y="325" width="7.7" height="23.0" fill="rgb(248,198,47)" rx="2" ry="2"></rect>
<text x="810.06" y="339.5"></text>
</g>
<g>
<title>timekeeping_update (4,225,544 samples, 0.01%)</title><rect x="802.6" y="85" width="0.1" height="23.0" fill="rgb(238,152,36)" rx="2" ry="2"></rect>
<text x="805.56" y="99.5"></text>
</g>
<g>
<title>zeroes (34,408,355,195 samples, 100.00%)</title><rect x="10.0" y="565" width="1180.0" height="23.0" fill="rgb(224,88,21)" rx="2" ry="2"></rect>
<text x="13.00" y="579.5">zeroes</text>
</g>
<g>
<title>__list_add_valid (119,183,921 samples, 0.35%)</title><rect x="485.8" y="277" width="4.0" height="23.0" fill="rgb(211,28,6)" rx="2" ry="2"></rect>
<text x="488.76" y="291.5"></text>
</g>
<g>
<title>__fget_light (122,843,196 samples, 0.36%)</title><rect x="31.9" y="373" width="4.2" height="23.0" fill="rgb(233,132,31)" rx="2" ry="2"></rect>
<text x="34.85" y="387.5"></text>
</g>
<g>
<title>propagate_protected_usage (5,505,752 samples, 0.02%)</title><rect x="212.5" y="253" width="0.2" height="23.0" fill="rgb(206,5,1)" rx="2" ry="2"></rect>
<text x="215.47" y="267.5"></text>
</g>
<g>
<title>__cond_resched (11,051,020 samples, 0.03%)</title><rect x="540.3" y="325" width="0.4" height="23.0" fill="rgb(217,58,14)" rx="2" ry="2"></rect>
<text x="543.27" y="339.5"></text>
</g>
<g>
<title>_raw_spin_unlock (71,553,131 samples, 0.21%)</title><rect x="293.4" y="301" width="2.5" height="23.0" fill="rgb(223,85,20)" rx="2" ry="2"></rect>
<text x="296.42" y="315.5"></text>
</g>
<g>
<title>do_syscall_64 (33,995,562,642 samples, 98.80%)</title><rect x="22.8" y="445" width="1165.9" height="23.0" fill="rgb(209,20,4)" rx="2" ry="2"></rect>
<text x="25.85" y="459.5">do_syscall_64</text>
</g>
<g>
<title>memcg_account_kmem (495,700,356 samples, 1.44%)</title><rect x="167.2" y="301" width="17.0" height="23.0" fill="rgb(230,115,27)" rx="2" ry="2"></rect>
<text x="170.24" y="315.5"></text>
</g>
<g>
<title>entry_SYSCALL_64_safe_stack (4,103,934 samples, 0.01%)</title><rect x="1188.7" y="469" width="0.1" height="23.0" fill="rgb(231,120,28)" rx="2" ry="2"></rect>
<text x="1191.69" y="483.5"></text>
</g>
<g>
<title>__rcu_read_lock (131,786,573 samples, 0.38%)</title><rect x="132.0" y="277" width="4.5" height="23.0" fill="rgb(220,69,16)" rx="2" ry="2"></rect>
<text x="134.96" y="291.5"></text>
</g>
<g>
<title>tick_sched_timer (11,254,762 samples, 0.03%)</title><rect x="802.6" y="181" width="0.3" height="23.0" fill="rgb(254,227,54)" rx="2" ry="2"></rect>
<text x="805.56" y="195.5"></text>
</g>
<g>
<title>entry_SYSCALL_64_after_hwframe (34,033,680,043 samples, 98.91%)</title><rect x="21.5" y="469" width="1167.2" height="23.0" fill="rgb(218,63,15)" rx="2" ry="2"></rect>
<text x="24.54" y="483.5">entry_SYSCALL_64_after_hwframe</text>
</g>
<g>
<title>__get_task_ioprio (65,612,447 samples, 0.19%)</title><rect x="41.6" y="373" width="2.3" height="23.0" fill="rgb(230,119,28)" rx="2" ry="2"></rect>
<text x="44.64" y="387.5"></text>
</g>
<g>
<title>rmqueue_bulk (1,769,082,103 samples, 5.14%)</title><rect x="455.7" y="301" width="60.6" height="23.0" fill="rgb(235,138,33)" rx="2" ry="2"></rect>
<text x="458.68" y="315.5">rmqueu..</text>
</g>
<g>
<title>__cond_resched (5,443,361 samples, 0.02%)</title><rect x="1164.9" y="325" width="0.2" height="23.0" fill="rgb(217,58,14)" rx="2" ry="2"></rect>
<text x="1167.92" y="339.5"></text>
</g>
<g>
<title>__rcu_read_unlock (394,985,353 samples, 1.15%)</title><rect x="153.1" y="301" width="13.6" height="23.0" fill="rgb(253,224,53)" rx="2" ry="2"></rect>
<text x="156.12" y="315.5"></text>
</g>
<g>
<title>__x86_indirect_thunk_array (11,044,363 samples, 0.03%)</title><rect x="16.5" y="469" width="0.3" height="23.0" fill="rgb(231,123,29)" rx="2" ry="2"></rect>
<text x="19.45" y="483.5"></text>
</g>
<g>
<title>pipe_write (32,852,709,554 samples, 95.48%)</title><rect x="43.9" y="373" width="1126.6" height="23.0" fill="rgb(236,146,35)" rx="2" ry="2"></rect>
<text x="46.89" y="387.5">pipe_write</text>
</g>
<g>
<title>bpf_lsm_file_permission (23,314,251 samples, 0.07%)</title><rect x="1184.2" y="349" width="0.8" height="23.0" fill="rgb(238,154,36)" rx="2" ry="2"></rect>
<text x="1187.17" y="363.5"></text>
</g>
<g>
<title>main (34,408,266,749 samples, 100.00%)</title><rect x="10.0" y="541" width="1180.0" height="23.0" fill="rgb(243,179,42)" rx="2" ry="2"></rect>
<text x="13.00" y="555.5">main</text>
</g>
<g>
<title>__x86_return_thunk (16,610,051 samples, 0.05%)</title><rect x="166.7" y="301" width="0.5" height="23.0" fill="rgb(253,221,53)" rx="2" ry="2"></rect>
<text x="169.67" y="315.5"></text>
</g>
<g>
<title>syscall_return_via_sysret (28,605,764 samples, 0.08%)</title><rect x="1189.0" y="469" width="1.0" height="23.0" fill="rgb(229,113,27)" rx="2" ry="2"></rect>
<text x="1191.97" y="483.5"></text>
</g>
<g>
<title>_raw_spin_lock_irq (1,785,614,251 samples, 5.19%)</title><rect x="830.8" y="349" width="61.2" height="23.0" fill="rgb(231,122,29)" rx="2" ry="2"></rect>
<text x="833.76" y="363.5">_raw_s..</text>
</g>
<g>
<title>__cond_resched (43,770,418 samples, 0.13%)</title><rect x="110.7" y="325" width="1.5" height="23.0" fill="rgb(217,58,14)" rx="2" ry="2"></rect>
<text x="113.69" y="339.5"></text>
</g>
</g>
</svg>



<p>Note that <code>__GI___libc_write</code> is the <code>glibc</code> wrapper that performs the system call. It and everything below is in user land. Everything above is in the kernel.</p>



<p>As expected, we are spending virtually all our time calling <code>write</code>. In particular, we are spending 95% of our time inside <code>pipe_write</code>. Inside this function, we are spending 36% of our total time in <code>__alloc_pages</code>, which provisions new memory pages for the pipe. We cannot just reuse a handful of pages in a loop because <code>pv</code> moves these pages using <code>splice</code> to <code>/dev/null</code>, which consume them.</p>



<p>Next to it are <code>__mutex_lock.constprop.0</code> that takes 25% of the time and <code>_raw_spin_lock_irq</code> that takes 5%. They lock the pipe for writing.</p>



<p>This leaves just 20% of the time for the copying of data itself in <code>copy_user_enhanced_fast_string</code>. But, even with only 20% of the CPU time, we would expect to be able to move 167 GB/s * 20% = 33 GB/s. It means that, even taken separately, this function is still twice as slow as <code>__memset_avx512_unaligned_erms</code>, which was used in the program that just wrote to user space memory.</p>



<p>What is <code>copy_user_enhanced_fast_string</code> doing to be so slow? We need to dig deeper. For this, <a href="https://blog.packagecloud.io/how-to-extract-and-disassmble-a-linux-kernel-image-vmlinuz/">I disassembled my Linux kernel</a><sup data-fn="ce4dcb58-ec87-4707-ba7b-fd4c521c97da"><a href="#ce4dcb58-ec87-4707-ba7b-fd4c521c97da" id="ce4dcb58-ec87-4707-ba7b-fd4c521c97da-link">4</a></sup>, and looked at that function.</p>



<pre><code>$ grep -w copy_user_enhanced_fast_string /usr/lib/debug/boot/System.map-6.1.0-18-amd64 
ffffffff819d3d90 T copy_user_enhanced_fast_string
$ objdump -d --start-address=0xffffffff819d3d90 vmlinuz | less   
    
vmlinuz:     file format elf64-x86-64


Disassembly of section .text:

ffffffff819d3d90 &lt;.text+0x9d3d90&gt;:

ffffffff819d3d90:       90                      nop
ffffffff819d3d91:       90                      nop
ffffffff819d3d92:       90                      nop
ffffffff819d3d93:       83 fa 40                cmp    $0x40,%edx
ffffffff819d3d96:       72 48                   jb     0xffffffff819d3de0
ffffffff819d3d98:       89 d1                   mov    %edx,%ecx
ffffffff819d3d9a:       f3 a4                   rep movsb %ds:(%rsi),%es:(%rdi)
ffffffff819d3d9c:       31 c0                   xor    %eax,%eax
ffffffff819d3d9e:       90                      nop
ffffffff819d3d9f:       90                      nop
ffffffff819d3da0:       90                      nop
ffffffff819d3da1:       e9 9a dd 42 00          jmp    0xffffffff81e01b40
...
ffffffff81e01b40:       c3                      ret
</code></pre>



<p>The <code>NOP</code> instructions at the beginning and at the end of the function allow <code>ftrace</code> to insert tracing instructions when needed. This lets it collect data about specific kernel function calls without inducing any slow down for kernel functions that are not being profiled. The CPU instruction decoding pipeline takes care of <code>NOP</code> early, so they have basically no impact on performance (other than taking room in the L1i cache).</p>



<p>I do not know why the <code>JMP</code> is not just a <code>RET</code>, however.</p>



<p>In any case, the <code>CMP</code> test and <code>JB</code> jump handle the case of buffers that are smaller than 64 bytes by jumping to another function that copy 8 bytes at a time with 64-bit registers, then 1 byte at a time with 8 bit register in two loops. For large buffers, the copying is handled by a <code>REP MOV</code> instruction. That‚Äôs definitely not vectorized code.</p>



<p>In fact, <a href="https://github.com/torvalds/linux/blob/830b3c68c1fb1e9176028d02ef86f3cf76aa2476/arch/x86/lib/copy_user_64.S#L161">this function is not implemented in C but directly in Assembly</a>! This means that there is no need to look at the result of compilation; we can just look at the source code. And it‚Äôs not just a missed optimization when compiling, it was written like that.</p>



<p>But is the lack of vector instruction the only reason why <code>copy_user_enhanced_fast_string</code> is twice as slow as <code>__memset_avx512_unaligned_erms</code>? To check this, I adapted the initial Rust program to explicitly use <code>REP MOVS</code>:</p>



<pre><code lang="rust">use std::arch::asm;

fn main() {
    let src = [0u8; 1 &lt;&lt; 15];
    let mut dst = [0u8; 1 &lt;&lt; 15];
    let mut copied = 0;
    while copied &lt; (1000u64 &lt;&lt; 30) {
        unsafe {
            asm!(
                "rep movsb",
                inout("rsi") src.as_ptr() =&gt; _,
                inout("rdi") dst.as_mut_ptr() =&gt; _,
                inout("ecx") 1 &lt;&lt; 15 =&gt; _,
            );
        }
        copied += 1 &lt;&lt; 15;
    }
}</code></pre>



<p>The throughput is 80 GB/s. This is a factor 2 slow down, exactly what we observe with the kernel function!</p>



<p>Now, we know that the Linux kernel is not using SIMD to copy memory and that this makes <code>copy_user_enhanced_fast_string</code> twice as slow as it could be.</p>



<p>But why is that? Over at Stack Overflow, <a href="https://stackoverflow.com/questions/59525762/why-doesnt-copy-user-enhanced-fast-string-use-avx-if-it-is-available">Peter Cordes explains that using SSE/AVX instructions is not worth it in most cases</a>, because of the cost of saving and restoring the SIMD context.</p>



<p>In summary: the kernel is spending quite a bit of time on managing memory, and it is not even using SIMD when actually copying the bytes. This is the source of the 10√ó slow-down we see when comparing with the ideal case.</p>



<h2><code>vmsplice</code> to the Rescue</h2>



<p>We now have an upper bound (167&nbsp;GB/s to write the data in memory once) and a lower bound (17&nbsp;GB/s when using <code>write</code> on a pipe). Let‚Äôs look in details at the effect of usng <code>vmsplice</code>. It mitigates the cost of using a pipe by moving entire buffers from user space to the kernel without copying them.</p>



<p>To understand how it works, again, read <a href="https://mazzo.li/posts/fast-pipes.html">the excellent article by Francesco</a>. We‚Äôll be using the <a href="https://github.com/bitonic/pipes-speed-test"><code>./write</code> program</a> from that article to get a minimal example of using <code>vmsplice</code>. This program just writes an infinite number of <code>'X'</code>s. This will simplify the profiling by not having any time dedicated to compute Fizz Buzz data or something else.</p>



<p><code>./write</code> actually achieves 210&nbsp;GB/s, well above our upper bound, but that‚Äôs because the program is kind of cheating by reusing the same buffers to pass to <code>vmsplice</code>. For anything other than a stream of constant bytes, we will actually have to fill the buffers with new data, which is where the upper bound actually applies. In any case, we only care about what <code>vmsplice</code> does:</p>



<svg version="1.1" onload="init(evt)" viewBox="0 0 1200 430" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<!-- Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples. -->
<!-- NOTES:  -->
<defs>
	<linearGradient id="background" y1="0" y2="1" x1="0" x2="0">
		<stop stop-color="#eeeeee" offset="5%"></stop>
		<stop stop-color="#eeeeb0" offset="95%"></stop>
	</linearGradient>
</defs>


<rect x="0.0" y="0" width="1200.0" height="430.0" fill="url(#background)"></rect>
<text id="title" x="600.00" y="24">./write ‚Äìwrite_with_vmsplice ‚Äìhuge_page ‚Äìbusy_loop | ./read ‚Äìread_with_splice ‚Äìbusy_loop</text>
<text id="subtitle" x="600.00" y="48">Profiling of ./write</text>
<text id="details" x="10.00" y="413"> </text>
<text id="unzoom" x="10.00" y="24">Reset Zoom</text>
<text id="search" x="1090.00" y="24">Search</text>
<text id="ignorecase" x="1174.00" y="24">ic</text>
<text id="matched" x="1090.00" y="413"> </text>
<g id="frames">
<g>
<title>__iov_iter_get_pages_alloc (3,949,231,497 samples, 14.88%)</title><rect x="963.5" y="205" width="175.6" height="23.0" fill="rgb(250,210,50)" rx="2" ry="2"></rect>
<text x="966.49" y="219.5">__iov_iter_get_pages_a..</text>
</g>
<g>
<title>__fget_light (62,561,929 samples, 0.24%)</title><rect x="243.3" y="229" width="2.8" height="23.0" fill="rgb(233,132,31)" rx="2" ry="2"></rect>
<text x="246.34" y="243.5"></text>
</g>
<g>
<title>internal_get_user_pages_fast (3,133,200,714 samples, 11.81%)</title><rect x="975.8" y="181" width="139.3" height="23.0" fill="rgb(253,223,53)" rx="2" ry="2"></rect>
<text x="978.83" y="195.5">internal_get_user..</text>
</g>
<g>
<title>write (26,541,239,090 samples, 100.00%)</title><rect x="10.0" y="349" width="1180.0" height="23.0" fill="rgb(228,107,25)" rx="2" ry="2"></rect>
<text x="13.00" y="363.5">write</text>
</g>
<g>
<title>__check_object_size (130,746,843 samples, 0.49%)</title><rect x="911.9" y="157" width="5.8" height="23.0" fill="rgb(226,98,23)" rx="2" ry="2"></rect>
<text x="914.91" y="171.5"></text>
</g>
<g>
<title>osq_lock (197,341,424 samples, 0.74%)</title><rect x="634.9" y="205" width="8.8" height="23.0" fill="rgb(214,43,10)" rx="2" ry="2"></rect>
<text x="637.91" y="219.5"></text>
</g>
<g>
<title>import_iovec (1,716,063,086 samples, 6.47%)</title><rect x="886.6" y="229" width="76.3" height="23.0" fill="rgb(241,168,40)" rx="2" ry="2"></rect>
<text x="889.58" y="243.5">import_i..</text>
</g>
<g>
<title>__import_iovec (1,666,122,831 samples, 6.28%)</title><rect x="888.8" y="205" width="74.1" height="23.0" fill="rgb(214,42,10)" rx="2" ry="2"></rect>
<text x="891.80" y="219.5">__import..</text>
</g>
<g>
<title>do_mmap (2,892,862 samples, 0.01%)</title><rect x="10.0" y="229" width="0.1" height="23.0" fill="rgb(228,107,25)" rx="2" ry="2"></rect>
<text x="13.00" y="243.5"></text>
</g>
<g>
<title>iov_iter_advance (538,480,611 samples, 2.03%)</title><rect x="1115.1" y="181" width="24.0" height="23.0" fill="rgb(248,197,47)" rx="2" ry="2"></rect>
<text x="1118.13" y="195.5">i..</text>
</g>
<g>
<title>pipe_lock (150,603,536 samples, 0.57%)</title><rect x="1147.6" y="229" width="6.7" height="23.0" fill="rgb(226,99,23)" rx="2" ry="2"></rect>
<text x="1150.62" y="243.5"></text>
</g>
<g>
<title>syscall_enter_from_user_mode (4,006,940 samples, 0.02%)</title><rect x="1187.3" y="253" width="0.2" height="23.0" fill="rgb(254,229,54)" rx="2" ry="2"></rect>
<text x="1190.34" y="267.5"></text>
</g>
<g>
<title>kill_fasync (2,756,081 samples, 0.01%)</title><rect x="1139.1" y="229" width="0.1" height="23.0" fill="rgb(224,91,21)" rx="2" ry="2"></rect>
<text x="1142.07" y="243.5"></text>
</g>
<g>
<title>do_syscall_64 (2,892,862 samples, 0.01%)</title><rect x="10.0" y="277" width="0.1" height="23.0" fill="rgb(209,20,4)" rx="2" ry="2"></rect>
<text x="13.00" y="291.5"></text>
</g>
<g>
<title>vm_mmap_pgoff (2,892,862 samples, 0.01%)</title><rect x="10.0" y="253" width="0.1" height="23.0" fill="rgb(237,150,35)" rx="2" ry="2"></rect>
<text x="13.00" y="267.5"></text>
</g>
<g>
<title>do_syscall_64 (26,020,596,200 samples, 98.04%)</title><rect x="32.6" y="277" width="1156.8" height="23.0" fill="rgb(209,20,4)" rx="2" ry="2"></rect>
<text x="35.59" y="291.5">do_syscall_64</text>
</g>
<g>
<title>arch_get_unmapped_area_topdown (2,892,862 samples, 0.01%)</title><rect x="10.0" y="181" width="0.1" height="23.0" fill="rgb(250,208,49)" rx="2" ry="2"></rect>
<text x="13.00" y="195.5"></text>
</g>
<g>
<title>mutex_lock (30,726,118 samples, 0.12%)</title><rect x="1139.2" y="229" width="1.4" height="23.0" fill="rgb(217,57,13)" rx="2" ry="2"></rect>
<text x="1142.19" y="243.5"></text>
</g>
<g>
<title>entry_SYSRETQ_unsafe_stack (8,363,819 samples, 0.03%)</title><rect x="1189.4" y="301" width="0.4" height="23.0" fill="rgb(206,7,1)" rx="2" ry="2"></rect>
<text x="1192.44" y="315.5"></text>
</g>
<g>
<title>mutex_spin_on_owner (5,495,045,988 samples, 20.70%)</title><rect x="390.6" y="205" width="244.3" height="23.0" fill="rgb(217,57,13)" rx="2" ry="2"></rect>
<text x="393.60" y="219.5">mutex_spin_on_owner</text>
</g>
<g>
<title>update_process_times (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="61" width="0.1" height="23.0" fill="rgb(250,209,50)" rx="2" ry="2"></rect>
<text x="1190.40" y="75.5"></text>
</g>
<g>
<title>__cond_resched (5,668,335 samples, 0.02%)</title><rect x="390.4" y="205" width="0.2" height="23.0" fill="rgb(217,58,14)" rx="2" ry="2"></rect>
<text x="393.35" y="219.5"></text>
</g>
<g>
<title>__fdget (18,709,007 samples, 0.07%)</title><rect x="242.5" y="229" width="0.8" height="23.0" fill="rgb(214,41,10)" rx="2" ry="2"></rect>
<text x="245.51" y="243.5"></text>
</g>
<g>
<title>osq_unlock (817,653,660 samples, 3.08%)</title><rect x="643.7" y="205" width="36.3" height="23.0" fill="rgb(248,198,47)" rx="2" ry="2"></rect>
<text x="646.68" y="219.5">osq..</text>
</g>
<g>
<title>syscall_exit_to_user_mode (43,203,238 samples, 0.16%)</title><rect x="1187.5" y="253" width="1.9" height="23.0" fill="rgb(251,211,50)" rx="2" ry="2"></rect>
<text x="1190.52" y="267.5"></text>
</g>
<g>
<title>__sysvec_apic_timer_interrupt (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="181" width="0.1" height="23.0" fill="rgb(242,173,41)" rx="2" ry="2"></rect>
<text x="1190.40" y="195.5"></text>
</g>
<g>
<title>_copy_from_user (1,015,660,918 samples, 3.83%)</title><rect x="917.7" y="157" width="45.2" height="23.0" fill="rgb(206,7,1)" rx="2" ry="2"></rect>
<text x="920.72" y="171.5">_cop..</text>
</g>
<g>
<title>get_pipe_info (88,389,900 samples, 0.33%)</title><rect x="882.7" y="229" width="3.9" height="23.0" fill="rgb(226,98,23)" rx="2" ry="2"></rect>
<text x="885.65" y="243.5"></text>
</g>
<g>
<title>tick_sched_handle (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="85" width="0.1" height="23.0" fill="rgb(219,68,16)" rx="2" ry="2"></rect>
<text x="1190.40" y="99.5"></text>
</g>
<g>
<title>asm_sysvec_apic_timer_interrupt (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="229" width="0.1" height="23.0" fill="rgb(232,127,30)" rx="2" ry="2"></rect>
<text x="1190.40" y="243.5"></text>
</g>
<g>
<title>vm_unmapped_area (2,892,862 samples, 0.01%)</title><rect x="10.0" y="157" width="0.1" height="23.0" fill="rgb(235,138,33)" rx="2" ry="2"></rect>
<text x="13.00" y="171.5"></text>
</g>
<g>
<title>try_grab_folio (289,286,952 samples, 1.09%)</title><rect x="1102.3" y="157" width="12.8" height="23.0" fill="rgb(238,153,36)" rx="2" ry="2"></rect>
<text x="1105.27" y="171.5"></text>
</g>
<g>
<title>get_user_pages_fast (7,086,063 samples, 0.03%)</title><rect x="975.5" y="181" width="0.3" height="23.0" fill="rgb(229,111,26)" rx="2" ry="2"></rect>
<text x="978.52" y="195.5"></text>
</g>
<g>
<title>page_cache_pipe_buf_release (43,300,058 samples, 0.16%)</title><rect x="880.7" y="205" width="2.0" height="23.0" fill="rgb(224,89,21)" rx="2" ry="2"></rect>
<text x="883.73" y="219.5"></text>
</g>
<g>
<title>__mutex_lock.constprop.0 (9,759,850,719 samples, 36.77%)</title><rect x="246.1" y="229" width="433.9" height="23.0" fill="rgb(225,95,22)" rx="2" ry="2"></rect>
<text x="249.12" y="243.5">__mutex_lock.constprop.0</text>
</g>
<g>
<title>with_vmsplice (4,241,758 samples, 0.02%)</title><rect x="1189.8" y="325" width="0.2" height="23.0" fill="rgb(230,119,28)" rx="2" ry="2"></rect>
<text x="1192.81" y="339.5"></text>
</g>
<g>
<title>exit_to_user_mode_prepare (30,683,997 samples, 0.12%)</title><rect x="1188.0" y="229" width="1.3" height="23.0" fill="rgb(228,108,25)" rx="2" ry="2"></rect>
<text x="1190.95" y="243.5"></text>
</g>
<g>
<title>pud_huge (4,099,890 samples, 0.02%)</title><rect x="1102.1" y="157" width="0.2" height="23.0" fill="rgb(229,110,26)" rx="2" ry="2"></rect>
<text x="1105.09" y="171.5"></text>
</g>
<g>
<title>mas_empty_area_rev (2,892,862 samples, 0.01%)</title><rect x="10.0" y="133" width="0.1" height="23.0" fill="rgb(244,181,43)" rx="2" ry="2"></rect>
<text x="13.00" y="147.5"></text>
</g>
<g>
<title>copy_user_enhanced_fast_string (76,785,562 samples, 0.29%)</title><rect x="959.5" y="133" width="3.4" height="23.0" fill="rgb(238,155,37)" rx="2" ry="2"></rect>
<text x="962.46" y="147.5"></text>
</g>
<g>
<title>entry_SYSCALL_64_after_hwframe (26,054,316,296 samples, 98.17%)</title><rect x="31.1" y="301" width="1158.3" height="23.0" fill="rgb(218,63,15)" rx="2" ry="2"></rect>
<text x="34.09" y="315.5">entry_SYSCALL_64_after_hwframe</text>
</g>
<g>
<title>__do_sys_vmsplice (25,963,594,680 samples, 97.82%)</title><rect x="33.0" y="253" width="1154.3" height="23.0" fill="rgb(227,104,24)" rx="2" ry="2"></rect>
<text x="36.02" y="267.5">__do_sys_vmsplice</text>
</g>
<g>
<title>wait_for_space (742,762,247 samples, 2.80%)</title><rect x="1154.3" y="229" width="33.0" height="23.0" fill="rgb(215,49,11)" rx="2" ry="2"></rect>
<text x="1157.32" y="243.5">wa..</text>
</g>
<g>
<title>__hrtimer_run_queues (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="133" width="0.1" height="23.0" fill="rgb(237,150,35)" rx="2" ry="2"></rect>
<text x="1190.40" y="147.5"></text>
</g>
<g>
<title>check_stack_object (58,579,278 samples, 0.22%)</title><rect x="915.1" y="133" width="2.6" height="23.0" fill="rgb(215,49,11)" rx="2" ry="2"></rect>
<text x="918.12" y="147.5"></text>
</g>
<g>
<title>get_unmapped_area (2,892,862 samples, 0.01%)</title><rect x="10.0" y="205" width="0.1" height="23.0" fill="rgb(234,134,32)" rx="2" ry="2"></rect>
<text x="13.00" y="219.5"></text>
</g>
<g>
<title>entry_SYSCALL_64 (259,954,397 samples, 0.98%)</title><rect x="19.5" y="301" width="11.6" height="23.0" fill="rgb(239,156,37)" rx="2" ry="2"></rect>
<text x="22.53" y="315.5"></text>
</g>
<g>
<title>syscall_exit_to_user_mode_prepare (2,750,376 samples, 0.01%)</title><rect x="1189.3" y="229" width="0.1" height="23.0" fill="rgb(235,142,34)" rx="2" ry="2"></rect>
<text x="1192.32" y="243.5"></text>
</g>
<g>
<title>entry_SYSCALL_64_after_hwframe (2,892,862 samples, 0.01%)</title><rect x="10.0" y="301" width="0.1" height="23.0" fill="rgb(218,63,15)" rx="2" ry="2"></rect>
<text x="13.00" y="315.5"></text>
</g>
<g>
<title>add_to_pipe (4,557,388,711 samples, 17.17%)</title><rect x="680.0" y="229" width="202.7" height="23.0" fill="rgb(223,84,20)" rx="2" ry="2"></rect>
<text x="683.04" y="243.5">add_to_pipe</text>
</g>
<g>
<title>__mmap (2,892,862 samples, 0.01%)</title><rect x="10.0" y="325" width="0.1" height="23.0" fill="rgb(227,104,25)" rx="2" ry="2"></rect>
<text x="13.00" y="339.5"></text>
</g>
<g>
<title>iovec_from_user.part.0 (1,403,501,367 samples, 5.29%)</title><rect x="900.5" y="181" width="62.4" height="23.0" fill="rgb(242,171,40)" rx="2" ry="2"></rect>
<text x="903.48" y="195.5">iovec_..</text>
</g>
<g>
<title>hrtimer_interrupt (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="157" width="0.1" height="23.0" fill="rgb(228,109,26)" rx="2" ry="2"></rect>
<text x="1190.40" y="171.5"></text>
</g>
<g>
<title>all (26,541,242,666 samples, 100%)</title><rect x="10.0" y="373" width="1180.0" height="23.0" fill="rgb(213,39,9)" rx="2" ry="2"></rect>
<text x="13.00" y="387.5"></text>
</g>
<g>
<title>tick_sched_timer (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="109" width="0.1" height="23.0" fill="rgb(254,227,54)" rx="2" ry="2"></rect>
<text x="1190.40" y="123.5"></text>
</g>
<g>
<title>sysvec_apic_timer_interrupt (2,662,881 samples, 0.01%)</title><rect x="1187.4" y="205" width="0.1" height="23.0" fill="rgb(220,69,16)" rx="2" ry="2"></rect>
<text x="1190.40" y="219.5"></text>
</g>
<g>
<title>iov_iter_get_pages2 (3,963,033,797 samples, 14.93%)</title><rect x="962.9" y="229" width="176.2" height="23.0" fill="rgb(247,194,46)" rx="2" ry="2"></rect>
<text x="965.88" y="243.5">iov_iter_get_pages2</text>
</g>
<g>
<title>mutex_unlock (158,874,728 samples, 0.60%)</title><rect x="1140.6" y="229" width="7.0" height="23.0" fill="rgb(251,212,50)" rx="2" ry="2"></rect>
<text x="1143.56" y="243.5"></text>
</g>
<g>
<title>vmsplice (26,534,006,381 samples, 99.97%)</title><rect x="10.1" y="325" width="1179.7" height="23.0" fill="rgb(212,35,8)" rx="2" ry="2"></rect>
<text x="13.13" y="339.5">vmsplice</text>
</g>
</g>
</svg>



<p>Like with <code>write</code>, we are spending a significant amount of time (37%) in <code>__mutex_lock.constprop.0</code>. However, there is no <code>_alloc_pages</code> and no <code>_raw_spin_lock_irq</code>. And, instead of <code>copy_user_enhanced_fast_string</code>, we find <code>add_to_pipe</code>, <code>import_iovec</code> and <code>iov_iter_get_pages2</code>. From this, we can see that how <code>vmsplice</code> bypasses the expensive parts of the <code>write</code> system call.</p>



<p>As an aside, I was a bit surprised about the effect of the buffer size, especially when not using <code>vmsplice</code>. It looks like minimizing the number of system calls is not always the most important thing to do.</p>



<figure><table><thead><tr><th>What</th><th data-align="right">Buffer size</th><th data-align="right">Throughput (GB/s)</th><th data-align="right">System calls</th><th data-align="right">Instructions</th><th data-align="right">ins/syscall</th></tr></thead><tbody><tr><td>./write</td><td data-align="right">32768</td><td data-align="right">99</td><td data-align="right">3276822</td><td data-align="right">7373684904</td><td data-align="right">2250</td></tr><tr><td>./write</td><td data-align="right">65536</td><td data-align="right">150</td><td data-align="right">1638466</td><td data-align="right">5438514152</td><td data-align="right">3319</td></tr><tr><td>./write</td><td data-align="right">131072</td><td data-align="right">207</td><td data-align="right">819270</td><td data-align="right">4288897413</td><td data-align="right">5235</td></tr><tr><td>zeroes</td><td data-align="right">32768</td><td data-align="right">17</td><td data-align="right">3276800</td><td data-align="right">31859864089</td><td data-align="right">9723</td></tr><tr><td>zeroes</td><td data-align="right">65536</td><td data-align="right">13</td><td data-align="right">1638400</td><td data-align="right">31750857264</td><td data-align="right">19379</td></tr><tr><td>zeroes</td><td data-align="right">131072</td><td data-align="right">12</td><td data-align="right">819200</td><td data-align="right">35002733773</td><td data-align="right">42728</td></tr></tbody></table></figure>



<h2>Wrapping Up</h2>



<p>There you have it. Writing to a pipe is ten times slower than writing to raw memory. And this is because, when writing to a pipe, we need to spend a lot of time taking a lock, and we cannot use vector instructions efficiently.</p>



<p>In principle, we could move data at 167 GB/s, but we need to avoid the cost of locking the buffer, and the cost of saving and restoring the SIMD context. This is exactly what <code>splice</code> and <code>vmsplice</code> do. They are often described as avoiding copying data between buffers, and this is true, but, most importantly, they completely bypass the conservative kernel code with extensive procedures and scalar code.</p>


<ol><li id="25bc32bc-4b79-41b9-87b3-0db6adcecbbf">Of course, they need to write code fast enough for exploit what <code>vmsplice</code> enables, but the point is that the first group‚Äôs performance is limited by not using <code>vmsplice</code>. <a href="#25bc32bc-4b79-41b9-87b3-0db6adcecbbf-link" aria-label="Jump to footnote reference 1">‚Ü©Ô∏é</a></li><li id="9f242c74-a611-49a2-9265-07d5945c4750">All benchmarks were performed on my personal desktop computer, which features a 7950X3D and DDR5 RAM overclocked to 6000T/s. And I am running Debian 12 with a 6.1.0-18-amd64 Linux kernel. CPU mitigations were disabled using the Linux kernel option <code>mitigations=off</code>.<br>As mentioned by ais523, it is important to pin the processes to specific cores. I have used logical cores 27 and 29, but I trim <code>taskset -c 27</code> and <code>taskset -c 29</code> from the commands in this article for the sake of readability. Look into <code>/sys/devices/system/cpu/cpu*/acpi_cppc/highest_perf</code> to know the relative performance of your cores. <a href="#9f242c74-a611-49a2-9265-07d5945c4750-link" aria-label="Jump to footnote reference 2">‚Ü©Ô∏é</a></li><li id="e22c8070-2784-40d4-81ae-6916566ce03a">See ‚ÄúL1 Cache write‚Äù in the last row of the second table from the bottom of the <a href="https://lanoc.org/review/cpus/8673-amd-ryzen-9-7950x3d?start=2">LanOC review</a>. This gives 2,518.4 GB/s for all 16 physical cores, or 157.4 GB/s per physical core.  <a href="#e22c8070-2784-40d4-81ae-6916566ce03a-link" aria-label="Jump to footnote reference 3">‚Ü©Ô∏é</a></li><li id="ce4dcb58-ec87-4707-ba7b-fd4c521c97da">I had to install <code>linux-image-6.1.0-18-amd64-dbg</code> to get the file <code>/usr/lib/debug/boot/System.map-6.1.0-18-amd64</code> with the symbols. <a href="#ce4dcb58-ec87-4707-ba7b-fd4c521c97da-link" aria-label="Jump to footnote reference 4">‚Ü©Ô∏é</a></li></ol>	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lidl's Cloud Gambit: Europe's Shift to Sovereign Computing (382 pts)]]></title>
            <link>https://horovits.medium.com/lidl-is-taking-on-aws-the-age-of-eurocloud-b237258e3311</link>
            <guid>41348659</guid>
            <pubDate>Sun, 25 Aug 2024 16:35:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://horovits.medium.com/lidl-is-taking-on-aws-the-age-of-eurocloud-b237258e3311">https://horovits.medium.com/lidl-is-taking-on-aws-the-age-of-eurocloud-b237258e3311</a>, See on <a href="https://news.ycombinator.com/item?id=41348659">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure></figure><div><a rel="noopener follow" href="https://horovits.medium.com/?source=post_page-----b237258e3311--------------------------------"><div aria-hidden="false"><p><img alt="Dotan Horovits (@horovits)" src="https://miro.medium.com/v2/resize:fill:88:88/1*6rhez1l3VXgPkm1n8u_yZQ.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="f330">‚Äú<em>How Lidl accidentally took on the big guns of cloud computing</em>‚Äù ‚Äî this article published yesterday <a href="https://www.ft.com/content/08eb1b45-91c2-4312-9d3c-ac5e4e557278" rel="noopener ugc nofollow" target="_blank">in the Financial Times</a> caught my attention. It shed light on an unexpected player in the cloud computing arena ‚Äî Lidl, the European discount retailer known for its no-frills approach to groceries.</p><p id="361d">Remember the story of how AWS started some 20 years ago, as the Amazon retailer wanted to solve its own IT infrastructure needs? Now Lidl and its owner Schwarz Group is pulling the proverbial AWS play, and spinning up its internal IT unit, <a href="https://schwarz-digits.de/en" rel="noopener ugc nofollow" target="_blank">Schwarz Digits</a>, into a standalone operating division, which competes with AWS. According to FT, it positioned itself as a credible regional challenger against the likes of AWS, Google, and Microsoft.</p><p id="60ce">This move is not just an isolated case but part of a broader trend in Europe towards sovereign cloud computing.</p><p id="7198">As I pointed out in my previous <a href="https://medium.com/p/033e7518eefb" rel="noopener">blog post about the shifts in AWS</a>, the one-stop-cloud-shop approach has shown cracks. Amazon, Google, Microsoft, Alibaba et al. won‚Äôt be able to cover all grounds, neither in tech domains, nor in geo‚Äôs.</p><p id="742e">This realization comes at a time when European countries, led by Germany and Austria, are increasingly prioritizing stringent privacy and data protection laws. GDPR compliance is non-negotiable, and businesses are demanding cloud services that operate entirely within the EU‚Äôs borders and address these control and sovereignty needs. In essence, Europe is looking for its own ‚ÄúEuroCloud‚Äù.</p><p id="0141">This demand isn‚Äôt just theoretical. The EU has already taken concrete steps with initiatives like <a href="https://gaia-x.eu/" rel="noopener ugc nofollow" target="_blank">Gaia-X</a>, which sets the framework for what an EU cloud should look like ‚Äî sovereign, secure, and compliant with European regulations.</p><figure><figcaption>gaia-x.eu</figcaption></figure><p id="2a0c">This push for a EuroCloud is why a grocery chain like Lidl can suddenly emerge as a cloud player, grabbing market share from AWS. Schwarz Digits generated ‚Ç¨1.9 billion in sales last year and has signed on major clients like SAP and Bayern Munich. This is no fringe experiment. The <a href="https://www.stackit.de/en/" rel="noopener ugc nofollow" target="_blank">StackIT page</a> features a service list ranging from the basic compute-network-storage through managed databases, messaging, Kubernetes, monitoring, security and more.</p><p id="f3d4">This is something AWS is scrambling to address with its recent announcement of a ‚Ç¨7.8 billion investment in an <a href="https://aws.amazon.com/blogs/security/aws-plans-to-invest-e7-8b-into-the-aws-european-sovereign-cloud-set-to-launch-by-the-end-of-2025/" rel="noopener ugc nofollow" target="_blank">AWS European Sovereign Cloud</a>, expected to launch its first region in Germany by the end of 2025. But will that be enough to regain the trust of European corporations</p><p id="dfe7">The pricing factor is another interesting angle. Lidl disrupted the retail market with its low-cost groceries; can it do the same in cloud computing? With Schwarz Digits, <strong>could Lidl become the low-cost EuroCloud alternative</strong> that businesses are looking for? AWS‚Äôs challenge will be to convince these businesses that its new European Sovereign Cloud can offer the same level of trust, security, and affordability.</p><p id="c4fa">As we watch this play out, it‚Äôs clear that the days of one-stop-cloud-shops are numbered. The market is fragmenting, and specialized, regionally-focused providers like Schwarz Digits are stepping in to fill the gaps left by global giants.</p></div></div>]]></description>
        </item>
    </channel>
</rss>