<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 21 Apr 2024 12:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Programming Is Mostly Thinking (336 pts)]]></title>
            <link>http://agileotter.blogspot.com/2014/09/programming-is-mostly-thinking.html</link>
            <guid>40103407</guid>
            <pubDate>Sun, 21 Apr 2024 05:40:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://agileotter.blogspot.com/2014/09/programming-is-mostly-thinking.html">http://agileotter.blogspot.com/2014/09/programming-is-mostly-thinking.html</a>, See on <a href="https://news.ycombinator.com/item?id=40103407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-4896867988576448796" itemprop="description articleBody">
<div dir="ltr" trbidi="on">
<blockquote>
<span><br></span><span>Pretend you have a really great programming day.</span>&nbsp;</blockquote>
<blockquote>
<span>You only have to attend a few meetings, have only a few off-topic conversations, don't get distracted or interrupted much, don't have to do a bunch of status or time reporting, and you put in a good six hours of serious programming [note: this RARELY happens in an 8-10 hour day].</span>&nbsp;</blockquote>
<blockquote>
<span>I want to review your work in the morning, so I print out a diff of your day's work before going home.</span>&nbsp;</blockquote>
<blockquote>
<span>Sadly, overnight the version control system crashes and they have to recover from the previous day's backup. You have lost an entire day's work.</span>&nbsp;</blockquote>
<blockquote>
<span>If I give you the diff, how long will it take you to type the changes back into the code base and recover your six-hours' work? </span></blockquote>
<br>
<h3>
Programming is 11/12ths Thinking</h3> <p> I've been touting this figure for some time now, and people keep asking me where the study is that produced such an odd number.  </p><p> Well, it's not pulled out of thin air and it's not the result of a thorough scientific study.  </p><p> I have done informal polls now for a few years, though I've not kept good records. My goal was not to become the scientist who cracks the statistical/mathematical code for programming activities. I was looking for a reasonable answer to a reasonable question. </p><p> However, this answer surprised me. In a long Quora post titled "<a href="#">How do programmers code so quickly?</a>"  one responder offered that it was a combination of physical skills (muscle memory, skill with tools, debugging skills,  typing skill) and knowing where to search for info. His post was swamped and overwhelmed by posts explaining that typing and tools are not the most important aid to quick code production.</p></div><p dir="ltr" trbidi="on"><br><h3>Software Factories</h3></p><div dir="ltr" trbidi="on">&nbsp; 
<p>I have seen the stickers and slogans on stickers and social media for a long time that "<a href="https://blog.ploeh.dk/2018/09/17/typing-is-not-a-programming-bottleneck/">typing is not the bottleneck</a>" (though every once in a while the inability of some programmers to type is <b>a </b>bottleneck).</p>

<p>
I am keenly aware that most management still subscribes to the idea that <i>motion is work</i>. They are fairly convinced that a lack of <i>motion</i> is a lack of <i>work</i>. That makes sense in a lawn care service, a factory assembly line, or a warehouse operation.</p>

<p>
Nearly all of the visible work done in producing physical goods is motion. People roll steel, stamp, press, mill, pick and place, bolt/screw/rivet, and on.&nbsp;</p>

<p>
Modern factories produce goods with Computer Numerical Control machines, which produce perfect copies of an original model that may not even exist in real life. These machines work from abstract models -- just data, really -- and perform perfect motion. Humans tend the machines, rather than working the wood by hand.</p>

<p>
I have some great guitars that were produced at affordable costs because of the degree of automation brought by such machines.&nbsp;</p>

<p>
Great boutique guitars are produced entirely by hand at higher cost and I don't put down that effort either. The world has room for both.</p>

<p>
<iframe allowfullscreen="allowfullscreen" frameborder="0" height="266" mozallowfullscreen="mozallowfullscreen" src="https://www.youtube.com/embed/PhOpgMDkfwc?feature=player_embedded" webkitallowfullscreen="webkitallowfullscreen" width="320"></iframe></p>



<p>
Software developers have perfected the factory. It runs flawlessly bit-perfect copies. You just click the "copy" or "download" button. It's so cheap that the purchasers happily cover the costs of the factory. Those who are cautious will double check the checksums that come with the download, but most people don't bother. The machines are reliable and efficient and quick and cheap.&nbsp;</p>

<p>
Once the initial model (really, just data) exists, then the marginal cost of all the bit-perfect copies is essentially zero. Yes, this is just copying and not creating, but that's what factories do. Custom shops might produce unique items (like guitars) but factories create copies of originals.</p>

<div><p>
The software factory tends to give you a progress bar, so you can visualize the motion of bits, but in many ways you can say that the product doesn't really exist. It's a pattern of tiny charged v. uncharged areas of metal on a plate (well, probably) and you don't even pay for the plate or the magnet or the laser when you create the copy. It's already there.</p><p>

Software is an intellectual good.</p></div>
<h3>
The Design Shop</h3>

<p>
In my years of working with Uncle Bob Martin, I heard him continually tell customers and students that software development is not a fabrication operation, but a design operation. Once the initial design is done, all the duplication is done by machines at nearly zero cost.</p>

<p>
So what programmers and testers and POs and Scrum Masters and software management area all doing (if they're doing it right) is designing the data model that will later be used by the factory to create copies for use by customers, patrons, and other people in the community the software is intended to serve.&nbsp;</p>

<p>
Yet the mechanistic, Industrial-Age idea of software development as a factory persists, and developers dutifully try to make it look like they're doing physical labor at the detriment of the process.&nbsp;</p>

<p>
All intellectual activities are hard to observe and monitor. An idea that is 80% complete has no physical manifestation. It's an idea, and it's not done yet. Sometimes we have experiments or proof-of-concept code or notes, but they don't give an accurate "% complete" number as does physical work.</p>

<p>
A chair being manufactured looks about 50% done at the 50% mark. &nbsp;When it's done, it looks done.</p>

<div><p>
A design for a chair may not exist on paper until it is more than 70% complete. And we don't know that it's really 70% done, because it's not finished being designed yet.</p><h3> The Answer: Really? </h3></div><p>
I have asked this question at conventions, client companies, to my peers, to colleagues, and to strangers I have met for the first time when I find out they are programmers. </p><p> The answer I receive most often is "about half an hour." </p><p> I could use the 8-hour day, ignoring meetings and interruptions and status reports, but that feels like padding the answer. I stick to the six hours doing things that programmers identify as programming work.</p><p>  There are twelve half-hours in six hours. One half-hour to retype all the changes made in six hours of hard programming work.  </p><p>What in the world can that mean? How can it be so little?</p></div><h3>The Meaning Behind the Answer</h3><p>Right now I suspect a bunch of managers are about to go yell at their programmers for putting in a half-hour's work in an 8-hour day! That would be a horrible misunderstanding of what was actually happening.</p><div dir="ltr" trbidi="on"> <p>  What is really happening? </p><div>
<ul>
<li>Programmers were typing on and off all day. Those 30 minutes are to recreate the <i><b>net result</b></i> of all the work they wrote, un-wrote, edited, and reworked through the day. It is not all the effort they put in, it is only the <i>residue of the effort.</i></li>
<li>Programmers are <i><b>avoiding defects</b></i> as best they can. In order to do that, they have to be continuously evaluating the code as they write it, hypothesizing the kinds of defects or security vulnerabilities they might be introducing. After all, they receive their harshest criticism for introducing defects into the shared code base.&nbsp;</li>
<li>Programming is a kind of <i><b>lossy compression</b></i>. The code only says what the program must do when it is running. Why a programmer chose one particular way over others, how it influences the rest of the system, what errors were introduced and removed, and what pitfalls it avoids are not (generally) present in the text of the program.</li>
<li>Most of the work is not in making the change, but in <i><b>deciding how to make the change</b></i>. Deciding requires us to understand the code that already exists. This is especially time-consuming when the code is messy or the design is not very obvious in the source code.&nbsp;</li>
<li>Programmers work in a <b><i>social context</i></b>&nbsp;since all their results are integrated into a shared code base (and most use pair programming or other "many eyes" techniques). Programmers may be helping other programmers or testers or operations people get a handle on their work. Connecting and communicating with others has benefits and costs that don't appear in the code.&nbsp;</li>
</ul>
</div>

<div><p>
Six hours of intellectual work (reading, researching, deciding, confirming, validating, verifying) translates to about 30 minutes worth of net lines-of-code change to a code base.</p><p>

That's not additional lines of code. We often have weeks when we fix bugs and add features and have fewer lines of code at end of the week than we had at the beginning of the week. I once got in trouble for having multiple weeks where we had negative lines of code -- we didn't know the 'grand boss' over our team was reporting SLOC as if it measured progress. Sigh.&nbsp;</p></div>

<div><p>
Programmers will gladly explain that the work they did was reading, learning, understanding, sometimes guessing, researching, debugging, testing, compiling, running, hypothesizing and disproving their ideas of what the code should look like. In short, they were thinking and deciding.</p><div><p>
Most of what goes on is intellectual work.</p><div><p>
One of the quora responders wrote:</p><blockquote>
<span>You see the fingers flying over the keyboard; you don't see the hours spent in talking to users, discussing the problems with coworkers, doing research and thinking the problems through.</span></blockquote>
</div>
<div><p>
Another suggested:</p><blockquote>
<span>I achieve it firstly (to the extent that I do) by 'helping' the customer to eliminate the unnecessary notions from their idea, which they often mistakenly call 'requirements' and sometimes even say they are 'must have'. This is the biggest possible acceleration in the delivery of a solution because I can do an infinite amount of no work in no time at all.</span></blockquote>
</div><p>
And yet another:</p><blockquote>
<span>Really good developers do 90% or more of the work before they ever touch the&nbsp; keyboard; really understanding the requirements and devising an appropriate solution.</span></blockquote><p>
These are not unique unusual answers. I find that most of the time, "knowing what not to write", "doing less," "working in smaller steps", and "having first figured out what to do" are common answers. Programming is much more about thinking than about typing.</p></div>
</div>

<p>
I have examined a lot of the change logs (diffs). It has consistently looked like 30+/-10 minutes of change on a good day (at least to me).&nbsp;</p>

<p>
I'm confident enough to tout this number as effectively true, though I should mention that no company I work with has so far been willing to delete a whole day's work to prove or disprove this experiment yet. &nbsp;Remember, I have only estimates and examinations of daily diffs to work from. The result here is not scientific.</p>

<div><p>
I should also let you know that people who do more typing or more cut/paste are often doing less thinking and understanding, which results in more errors and more burden on other programmers to understand and correct their code.</p><p><span><i>Code is just the residue of the work.</i></span></p>
<h3>
So What?</h3>
<br></div>

<p>
If programming is 1/12th motion and 11/12ths thinking, then we shouldn't push people to be typing 11/12ths of the time. We should instead provide the materials, environment, and processes necessary to ensure that the thinking we do is of high quality.&nbsp;</p>

<p>
Doing otherwise is optimizing the system for the wrong effect.</p>

<div><p>
What if we changed our tactics, and intentionally built systems for thinking together about software and making decisions easier to make? I think that productivity lies in this direction.</p><p>

So I invite you: how can you experiment with learning on-the-job to create systems where the thinking is optimized?&nbsp;</p></div>

</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Racket Language (220 pts)]]></title>
            <link>https://racket-lang.org/</link>
            <guid>40102912</guid>
            <pubDate>Sun, 21 Apr 2024 03:18:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://racket-lang.org/">https://racket-lang.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40102912">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="doc"><top-section> <a href="https://racket-lang.org/"><span id="logo"><img alt="small logo" src="https://racket-lang.org/img/racket-logo.svg">&nbsp;Racket</span></a>

</top-section>

<section id="pull-quote"><section-content><li></li></section-content></section>

<div><p><label for="racket-lang"><span>Racket, the Programming Language</span></label></p><div><p><img alt="large logo" src="https://racket-lang.org/img/racket-logo.svg"></p><div><p>#lang racket/gui</p><pre><p>(<a href="http://docs.racket-lang.org/reference/define.html#(form._((lib._racket/private/base..rkt)._define))" onclick="javascript:cancel_bubble(event)">define</a> my-language 'English)</p><p>(<a href="http://docs.racket-lang.org/reference/define.html#(form._((lib._racket/private/base..rkt)._define))" onclick="javascript:cancel_bubble(event)">define</a> translations<br>  #hash([Chinese . "你好 世界"]<br>        [English . "Hello world"]<br>        [French . "Bonjour le monde"]<br>        [German . "Hallo Welt"]<br>        [Greek . "Γειά σου, κόσμε"]<br>        [Portuguese . "Olá mundo"]<br>        [Spanish . "Hola mundo"]<br>        [Thai . "สวัสดีชาวโลก"]<br>        [Turkish . "Merhaba Dünya"]))</p><p>(<a href="http://docs.racket-lang.org/reference/define.html#(form._((lib._racket/private/base..rkt)._define))" onclick="javascript:cancel_bubble(event)">define</a> my-hello-world<br>  (<a href="http://docs.racket-lang.org/reference/hashtables.html#(def._((quote._~23~25kernel)._hash-ref))" onclick="javascript:cancel_bubble(event)">hash-ref</a> translations my-language<br>            "hello world"))</p><p>(<a href="http://docs.racket-lang.org/gui/Windowing_Functions.html#(def._((lib._mred/main..rkt)._message-box))" onclick="javascript:cancel_bubble(event)">message-box</a> "" my-hello-world)</p></pre></div></div><p><label for="mature"><span>Mature</span></label></p><p><label for="practical"><span>Practical</span></label></p><p><label for="extensible"><span>Extensible</span></label></p><p><label for="robust"><span>Robust</span></label></p><p><label for="polished"><span>Polished</span></label></p></div>

<div><p><label for="racket-lop"><span>Racket, the Language-Oriented Programming Language</span></label></p><div id="lang4"><p>#lang datalog</p><pre>ancestor(A, B) <a href="https://docs.racket-lang.org/datalog/interop.html?q=%3A-#%28form._%28%28lib._datalog%2Fmain..rkt%29._~3a-%29%29" onclick="javascript:cancel_bubble(event)">:-</a> parent(A, B).<br>ancestor(A, B) <a href="https://docs.racket-lang.org/datalog/interop.html?q=%3A-#%28form._%28%28lib._datalog%2Fmain..rkt%29._~3a-%29%29" onclick="javascript:cancel_bubble(event)">:-</a><br>  parent(A, C), ancestor(C, B).<br>parent(john, douglas).<br>parent(bob, john).<br>ancestor(A, B)?</pre></div><p><label for="little-macros"><span>Little Macros</span></label></p><div><p>Racket allows programmers to <a href="https://docs.racket-lang.org/guide/pattern-macros.html" onclick="javascript:cancel_bubble(event)">add new syntactic constructs</a> in the same way that other languages permit the formulation of procedures, methods, or classes.  All you need to do is formulate a simple rule that rewrites a custom syntax to a Racket expression or definition.</p><p>Little macros can particularly help programmers with DRY where other features can’t. The example <abc>on the left</abc> <abc>above</abc> shows how to define a new syntax for measuring the time a task takes. The syntax avoids the repeated use of lambda. Note also how the macro is exported from this module as if it were an ordinary function.</p></div><p><label for="general-purpose"><span>General Purpose</span></label></p><div><p>Racket comes with a comprehensive suite of libraries: <a href="https://docs.racket-lang.org/gui/" onclick="javascript:cancel_bubble(event)">a cross-platform GUI toolbox</a>, a <a href="https://docs.racket-lang.org/web-server/index.html?q=%23lang%20web" onclick="javascript:cancel_bubble(event)">web server</a>, and more. <a href="https://pkgs.racket-lang.org/" onclick="javascript:cancel_bubble(event)">Thousands of additional packages</a> are a <a href="https://docs.racket-lang.org/pkg/getting-started.html?q=raco%20pkg#%28part._installing-packages%29" onclick="javascript:cancel_bubble(event)">single command</a> away: 3D graphics, a bluetooth socket connector, color maps, data structures, educational software, games, a quantum-random number generator, scientific simulations, web script testing, and many more.</p><p>Macros work with these tools. The example <abc>on the left</abc> <abc>above</abc> shows the implementation of a small number-guessing game. It is implemented in the GUI dialect of Racket, and demonstrates a number of language features.</p></div><p><label for="big-macros"><span>Big Macros</span></label></p><div><p><img src="https://racket-lang.org/img/big-macros-class.png" alt="Big Macros" width="350" height="262"></p><div><p>Getting to know the full Racket macro system will feel liberating, empowering, dazzling—like a whole new level of enlightenment. Developers can easily create a collection of co-operating macros to implement <a href="https://docs.racket-lang.org/reference/match.html" onclick="javascript:cancel_bubble(event)">algebraic pattern matching</a>, simple <a href="https://docs.racket-lang.org/teachpack/2htdpuniverse.html?q=big-bang#%28part._world._interactive%29" onclick="javascript:cancel_bubble(event)">event-handling</a>, or a <a href="https://pkgs.racket-lang.org/package/faster-minikanren" onclick="javascript:cancel_bubble(event)">logic-constraint solver</a>.</p><p>While Racket is a functional language, it has offered a sub-language of <a href="http://www.cs.utah.edu/plt/publications/aplas06-fff.pdf" onclick="javascript:cancel_bubble(event)">classes and objects, mixins and traits</a>, from the beginning. The macro-based implementation of a Java-like class system lives in a library and does not need any support from the core language. A Racket programmer can thus combine functional with object-oriented components as needed. </p></div></div><p><label for="easy-dsls"><span>Easy DSLs</span></label></p><div><p><img src="https://racket-lang.org/img/lang-video.png" alt="#lang video Dependency Graph" width="350" height="350"></p><div><p>Some languages convey ideas more easily than others. And some programming languages convey solutions better than others.  Therefore Racket is a language for <a href="https://docs.racket-lang.org/guide/hash-languages.html" onclick="javascript:cancel_bubble(event)">making languages</a>, so that a programmer can write every module in a well-suited language.</p><p>Often <a href="https://lang.video/" onclick="javascript:cancel_bubble(event)">an application domain</a> comes with several languages.  When you need a new language, you make it—on the fly. Open an IDE window; create a language right there, with just a few keystrokes; and run a module in this new language in a second IDE window.  Making new languages really requires no setup, no project files, no external tools, no nothing.</p></div></div><p><label for="ide-support"><span>IDE Support</span></label></p><div><p><img src="https://racket-lang.org/img/ide-support.png" alt="IDE Support" width="552" height="465"></p><div><p>Racket comes with its own IDE, <a href="https://docs.racket-lang.org/drracket/" onclick="javascript:cancel_bubble(event)">DrRacket</a> (<a href="https://www2.ccs.neu.edu/racket/pubs/jfp01-fcffksf.pdf" onclick="javascript:cancel_bubble(event)">née DrScheme</a>), and it sports some unique features. For example, when a programmer mouses over an identifier, the IDE draws an arrow back to where it was defined.</p><p>A programmer immediately benefits from DrRacket while using an alternative language, say <a href="https://docs.racket-lang.org/ts-guide/index.html" onclick="javascript:cancel_bubble(event)">Typed Racket</a>. Racket macros, even complex ones and those used to make new languages, record and propagate a sufficient amount of source information for DrRacket to act as if it understood the features of the new language.</p></div></div><p><label for="any-syntax"><span>Any Syntax</span></label></p><div><p><img src="https://racket-lang.org/img/ugly-syntax.png" alt="Dots and Colon-Pipes, too!" width="350" height="280"></p><div><p>Racket programmers usually love parentheses, but they have empathy for those who need commas and braces.  Hence, building languages with conventional surface syntax, like that of <a href="https://docs.racket-lang.org/datalog/datalog.html?q=datalog" onclick="javascript:cancel_bubble(event)">datalog</a>, is almost as easy as building parenthetical languages.</p><p>Racket’s ecosystem comes with <a href="https://docs.racket-lang.org/br-parser-tools/index.html?q=parsing" onclick="javascript:cancel_bubble(event)">parsing packages</a> that allow developers to easily map any syntax to a parenthesized language, which is then compiled to ordinary Racket with the help of Racket’s macro system. Such a language can also exploit the hooks of the IDE framework, so that its programmers may take advantage of Racket’s IDE.</p></div></div></div>

<div><p><label for="racket-ecosystem"><span>Racket, the Ecosystem</span></label></p><div><p><img alt="eighth RacketCon, 2018" src="https://racket-lang.org/img/racket-con-2018.png"></p></div><p><label for="software"><span>Software</span></label></p><p><label for="tutorials"><span>Tutorials &amp; Documentation</span></label></p><p><label for="community"><span>Community</span></label></p><p><label for="books"><span>Books</span></label></p><p><label for="education"><span>Education</span></label></p><div><table><tbody><tr><td><p>Education</p><p><a href="https://school.racket-lang.org/" onclick="javascript:cancel_bubble(event)">The Racket Summer School</a><br>a summer school for researchers, professionals, and (under)graduate students to the Racket philosophy of programming languages</p><p><a href="http://programbydesign.org/" onclick="javascript:cancel_bubble(event)">Program by Design (aka TeachScheme!)</a><br>a curriculum and training program for high school teachers and college faculty</p><p><a href="http://www.bootstrapworld.org/" onclick="javascript:cancel_bubble(event)">Bootstrap</a><br>a curriculum and training program for middle-school and high-school teachers</p></td><td></td><td><p><img src="https://racket-lang.org/img/four.png" alt="The Four Amigos" width="450" height="322"></p></td></tr></tbody></table></div><p><label for="swag"><span>Swag</span></label></p><div><table><tbody><tr><td><p>Swag</p><p><a href="https://devswag.com/products/racket-t-shirt" onclick="javascript:cancel_bubble(event)">Racket T-Shirts</a> — the perfect way to meet friends, influence people, and stay warm.</p><p><a href="https://devswag.com/products/racket" onclick="javascript:cancel_bubble(event)">Racket Stickers</a> — the indispensable accessory for laptops and textbooks.</p></td><td></td><td><img src="https://racket-lang.org/img/gear-and-stuff.jpg" alt="gear" width="272" height="364"></td></tr></tbody></table></div></div>

<section id="bottom"><section-title><p>Thank you</p></section-title><section-content><li></li></section-content></section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I bought 300 emoji domain names from Kazakhstan and built an email service (2021) (307 pts)]]></title>
            <link>https://tinyprojects.dev/projects/mailoji</link>
            <guid>40101885</guid>
            <pubDate>Sat, 20 Apr 2024 23:24:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tinyprojects.dev/projects/mailoji">https://tinyprojects.dev/projects/mailoji</a>, See on <a href="https://news.ycombinator.com/item?id=40101885">Hacker News</a></p>
<div id="readability-page-1" class="page">
	
	<nav>
		<a href="https://tinyprojects.dev/">Home</a>
		<a href="https://tinyprojects.dev/projects">Projects</a>
		<a href="https://tinyprojects.dev/guides">Guides</a>
		<a href="https://tinyprojects.dev/blog">Blog</a>
		<a href="https://daily.tinyprojects.dev/">Daily Blog</a>
	</nav>
	
	<p><i>March 11th 2021</i></p>

	<p>TLDR; I bought 300 emoji domain names from Kazakhstan and built an <a href="https://mailoji.com/" target="_blank">emoji email address service</a>. In the process I went viral on TikTok, made $1000 in a week, hired a Japanese voice actor, and learnt about the weird world of emoji domains.</p>

	<h3>🌅 The setup</h3>

	<p>Not long ago I decided it would be a brilliant idea to buy the domain name <a href="https://tinyprojects.dev/posts/i_bought_netflix_dot_soy" target="_blank">netflix.soy</a>.</p>

	<p>Whilst arguably there are better ways to spend £17, I did learn a lot about domain names, including that it's possible to have emoji domains like <span>😊.ws</span>.</p>

	<p>It's pretty hard to go a day without seeing an emoji somewhere on the internet. Yet, I'd never seen an emoji domain name before.</p>

	<p>I wondered:</p>

	<p>Could I buy an emoji domain name?</p>

	<h3>💸 Buying an emoji domain name</h3>

	<p>My goal was to buy a single character emoji domain name, like 💡 or 🍰. I didn't know what I'd do with it, I just wanted to see if I could get one.</p>

	<p>I found a website that showed every available emoji domain for 4 different extensions.</p>

	<p>Sadly, nearly every single one had been registered. I was late to the party.</p>

	<img src="https://i.gyazo.com/6aa39e2f0e8e2f9039b61c95ea360cb7.png" alt="Taken emoji domains">

	<p>A simple mailbox emoji with a .ws extension was still available though, so I bought it.</p>

	<h3>📪 The mailbox</h3>

	<img src="https://i.gyazo.com/1b78a0aab3ca0b04649eacf46fd3bc0a.png" alt="Mailbox emoji domain in GoDaddy">

	<p><span>📪.ws</span> was now mine. Mission complete.</p>

	<p>I set up a website and felt rather accomplished with my tiny mailbox.</p>

	<p>I could've stopped there and called it a day. But, then I had another thought:</p>

	<p>Could I use my little mailbox emoji domain in an email address?</p>

	<p>That'd be pretty cute.</p>

	<h3>✉️ Emoji mail attempt #1</h3>

	<p>I gave it a go. I setup an email forwarder to route all email sent to <span>📪.ws</span> to my regular email address.</p>

	<p>Eagerly I typed <span>ben@📪.ws</span> into the "to" field of gmail and hit send.</p>

	<img src="https://i.gyazo.com/3ab67d13bcfad786b7f3ba9a01968272.png" alt="Sending first emoji mail">

	<h3>🛑 Blocked</h3>

	<p>The email never hit my inbox. It was lost forever in cyberspace.</p>

	<p>Turns out emoji domain names score very highly for spam and were going to be blocked to high heaven.</p>

	<p>But, it was interesting that I could send mail towards an emoji email address.</p>

	<p>So I wondered:</p>

	<p>If a normal .com email address doesn't get blocked for spam, could I route my emoji mail through that?</p>

	<h3>💌 Emoji mail attempt #2</h3>

	<p>It would work like this: </p>

	<ol>
		<li>Email sent to <span>ben@📪.ws</span></li>
		<li><span>ben@📪.ws</span> forwards to <span>nospam@normal.com</span></li>
		<li><span>nospam@normal.com</span> forwards to my email address and won't get blocked.</li>
	</ol>

	<p>I cobbled together something using AWS, and tried my experiment again.</p>

	<p>to: <span>ben@📪.ws</span></p>
		<p>message: Hi Ben, how's it going?</p>
	

	<p>Send.</p>

	<img src="https://i.gyazo.com/bdc529a214b0e2019a96a86c933c4bcb.png" alt="First emoji mail">

	<p>It worked!</p>

	<h3>🧨 Where things started to get out of control</h3>

	<p>At this point I was inclined to stop and write a post about emoji email addresses. I'd had a good run.</p>

	<p>But then I wondered:</p>

	<p>My mailbox emoji email address is great and all, but do you know what would be better? <span>ben@⭐</span></p>

	<p>Now how do I get one of those?</p>

	<h3>🎣 Emoji domain name hunting</h3>

	<p>Only 13 TLDs in the world accept registrations of emoji domain names: .cf, .ga, .gq, .la, .ml, .tk, .st, .fm, .to, .je, .gg, .kz, and .ws.</p>

	<p>The website I had used to purchase <span>📪.ws</span> only showed 4 TLDs: .fm, .ws, .to and .ml. These are considered the gold standard of emoji domain name registrars.</p>

	<p>Every emoji had been taken on these though. You could of course get multi-character emoji domains like <span>🎉🐢.ws</span>, but I wanted single character emoji domains only.</p>

	<p>So I wondered:</p>

	<p>Do any of those other TLDs have any emoji domains left?</p>

	<h3>🔭 The great hunt</h3>

	<p>I already had some code that performed WHOIS lookups to see if a domain name is available for a list of TLDs.</p>

	<p>Previously I'd used this code to buy <a href="https://tinyprojects.dev/posts/i_bought_netflix_dot_soy" target="_blank">facebook.网站</a>, only for Marky Z to snatch it back from me. Cheeky bugger.</p>

	<p>I booted up the code and loaded in some A-tier emojis (e.g. ⭐,😂,❤️) and the 13 TLDs that accepted them.</p>

	<p><i>&gt;node search.js</i> [ENTER]</p>

	<h3>🎁 The results</h3>

	<img src="https://i.gyazo.com/6adaeb53f45f75605749f78d4dcac8c3.png" alt="Console output showing available TLDs for emoji domains">

	<p>Instantly I was seeing results! .la, .ga, .gq, .je. There were plenty of emojis still out there on these alternative extensions.</p>

	<p>An extension that stood out to me straight away was .gg, for the Island of Guernsey. "GG" is an acronym for "Good Game", and I say it often when I lose at online games. It was perfect.</p> 

	<p><span>⭐.gg</span> was available for €29. I hit purchase.</p>

	<h3>💔 No GG for me</h3>

	<p>The next day Guernsey sent me an email.</p>

	<img src="https://i.gyazo.com/527c4941fbb3ddcffbc92a0c2ef1c828.png" alt="Email from Guernsey saying emoji domains not available on .gg">

	<p>Long story short, although you could register emoji domain names with them, they didn't actually work.</p>

	<p>Good game Guernsey. Back to the drawing board.</p>

	<h3>⭐ Crazy for KZ</h3>

	<p>With every other extension I kept hitting walls. A lot of the registrars wouldn't even let me search for emoji domains. Nothing was working.</p>

	<p>One extension that kept cropping up was .kz of Kazakhstan. But, I headed over to their registar website and it was entirely in Russian.</p>

	<img src="https://i.gyazo.com/6c20c8eea912beb320555c0dace78b1b.png" alt="Russian domain name website">

	<p>I do not speak Russian.</p>

	<p>Using Google Translate, I tried to navigate the website and buy a .kz emoji domain.</p>

	<p>It was a long, painful process. But, after phoning my bank to confirm I was indeed trying to make a purchase using Kazakhstani tenge, <span>⭐.kz</span> was sitting in my account.</p>

	<p>I plugged it into my email system and <span>ben@⭐.kz</span> worked.</p>

	<p>Very nice.</p>

	<h3>💼 Let's start an email service</h3>

	<p>Something excited me. Nearly all single character emojis were available on .kz, and they were only $8 each.</p>

	<p>So, I wondered:</p>

	<p>What if you could get an email address with any emoji you wanted?</p>

	<p>I pictured email addresses like <span>bob@🚀</span>, <span>alice@🌸</span>, <span>melvin@🍆</span>.</p>

	<p>All I'd need to do is buy every emoji domain to build a service like this.</p>

	<p>It was insane, but it was possible.</p>

	<h3>🌙 The night of 150 emojis</h3>

	<p>I decided I was going to do it.</p>

	<p>If I was chuffed with my mailbox emoji email address, perhaps others would be too.</p>

	<p>I got out my debit card, and, one by one, started buying Kazakhstan emoji domains.</p>

	<p><span>💡.kz</span>, <span>👑.kz</span>, <span>🌈.kz</span>, <span>😎.kz</span>. Buy, buy, buy, buy.</p>

	<p>It was slightly painful watching my bank account going down, and the number of emoji domains go up.</p>

	<p>80 emojis in, forking over money for a goat emoji domain name, you seriously start to question what you're doing.</p>

	<p>$1200 later, 150 emoji domains were mine.</p>

	<h3>💻 Building an emoji email address website</h3>

	<p>Finally, I needed a website where you could register an emoji email address and it would forward mail like <span>ben@📪.ws</span> did.</p>

	<p>Using vanilla HTML, JS and CSS, plus Stripe's API for payments, I cobbled together an MVP over a few weeks.</p>

	<p>Once it was done, I bought one last domain name: <a href="https://mailoji.com/" target="_blank">mailoji.com</a>. My new emoji email address service <a href="https://mailoji.com/" target="_blank">Mailoji</a> was ready. Get your emoji email addresses.</p>

	<img src="https://i.gyazo.com/30c54b0bed4ffc85cb38940a2b26748e.png" alt="Mailoji emoji email address website">

	<h3>📱 TikTok</h3>

	<p>I'd gone from being curious about emoji domain names to now owning 150 of Kazakhstan's finest.</p>

	<p>The next step was to convince someone else to buy an emoji email address.</p>

	<p>TikTok seemed like a good place to start given its demographic. So, I recorded a short video advert and started a "TikTok for business" application to publish it.</p>

	<p>On the final page of the application I was asked for a VAT registration number. Mailoji was not a proper business yet, so there was no way I could publish my ad.</p>

	<p>Screw it, I'll post the video normally.</p>

	<p>Upload.</p>

	<h3>🎉 First sales</h3>

	<p>Here is the <a href="https://www.tiktok.com/@mailoji/video/6925405275201539334?lang=en&amp;is_copy_url=1&amp;is_from_webapp=v3" target="_blank">advert</a> if you're interested.</p>

	<p>The video sat at 0 views for about 5 hours before the TikTok algorithm started to work its magic.</p>

	<p>Slowly, the views started ramping up. 500 views, to 5k views, to 50k views. It was incredible to witness.</p>

	<p>People were loving emoji email addresses, people were hating emoji email addresses.</p>

	<p>It was like Marmite, a talking point. None of it mattered though because emoji email addresses were selling! <span>@🚀</span>, <span>@📷</span> &amp; <span>@💻</span> addresses were the most popular.</p>

	<p>Over 2 days the TikTok video reached 200k+ views, and 60 emoji email addresses had been sold netting ~$300/yr in revenue.</p>

	<img src="https://i.gyazo.com/e33fb288704cc42f58e50ff4a5d33fa8.png" alt="Stripe graph showing first sales from selling emoji domains">

	<p>I took this as a fantastic indicator. So guess what I did?</p>

	<h3>💵 Buying more emoji domain names</h3>

	<p>I decided to purchase 100 more emoji domains.</p>

	<p>I cried into my keyboard forking out yet more money for a llama emoji that I probably didn't need.</p>

	<p>In the end I had 250 emoji domains. If there was ever a moat into the emoji email address world, this was it.</p>

	<h3>📅 Preparing for launch</h3>

	<p>I figured the more people with emoji email addresses, the more people who would see them, and the more people who would buy them. A beautiful cycle.</p>

	<p>My next goal was a Product Hunt launch to get exposure for Mailoji, and kickstart this cycle.</p>

	<p>I prepped my launch post, carefully choosing each word and image.</p>

	<p>I even created this over-hyped promotional video, complete with Japanese voice actor saying the words "Mailoji".</p>

	<p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/JKxEXZv4G3c" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

	<p>Mailoji was ready for launch.</p>

	<h3>🚀 Launch Day</h3>

	<p>At 12:03 AM PST Mailoji went live on <a href="https://www.producthunt.com/posts/mailoji" target="_blank">Product Hunt</a>. We had come a long way from that little mailbox emoji.</p>

	<img src="https://i.gyazo.com/0cf1d62b2d820c8f456a95da3cffda01.png" alt="Product hunt launch thumbnail">

	<p>It was 8:03 AM UK time. Bleary eyed, with a cup of tea in hand, I watched as Mailoji did battle.</p>

	<p>I had chosen to launch on a Wednesday against some stiff competition, but Mailoji really held its own.</p>

	<p>At the end of the day it finished in 5th place. Here were the end of day stats: </p>

	<ul>
		<li>🌎 6.7k website views
		</li><li>💌 150+ emoji email addresses sold</li>
		<li>💵 $830/yr ARR</li>
		<li>🔺 320 upvotes</li>
		<li>🏅 5th place on Product Hunt</li>
		<li>🎀 Most popular Mailoji: @🚀</li>
	</ul>

	<p>Over 150 emoji email addresses were sold in a day, and I received some fantastic feedback from the Product Hunt community.</p>

	<p>It was done, Mailoji had officially launched.</p>

	<h3>📙 The aftermath</h3>

	<p>I wish this story ended with Mailoji blowing up and the queen registering an emoji email address or something (I'll reserve <span>Liz@👑.kz</span> just in case).</p>

	<p>But, currently Mailoji is sitting at ~$1440/year in revenue. There's now 300 emoji domains to choose from though.</p>

	<img src="https://i.gyazo.com/6eac0eb3bcdaa1ee78e57b6692ed9afc.png" alt="Final Stripe ARR chart for Mailoji">

	<p>Even though I still haven't made the money back on all the emoji domains I bought, creating an emoji email address service was so much fun.</p>

	<p>It was an adventure. A rabbit hole containing multiple rabbit holes.</p>

	<p>This project started out as an exploration into emoji domain names; a weird, forgotten about internet feature that I've now become quite fond of.</p>

	<p>Yes emoji domains are hard to type on desktop, yes there's too many variations, and yes, most form validations hate them.</p>

	<p>But they're fun, and I think tech should be more fun.</p>

	<p>Thanks for reading. If you want to get in touch, I've got a brand new email address at the bottom of this website.</p>

	
	
	
	
	
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists discover first nitrogen fixing organelle (159 pts)]]></title>
            <link>https://newscenter.lbl.gov/2024/04/17/scientists-discover-first-nitrogen-fixing-organelle/</link>
            <guid>40101317</guid>
            <pubDate>Sat, 20 Apr 2024 21:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newscenter.lbl.gov/2024/04/17/scientists-discover-first-nitrogen-fixing-organelle/">https://newscenter.lbl.gov/2024/04/17/scientists-discover-first-nitrogen-fixing-organelle/</a>, See on <a href="https://news.ycombinator.com/item?id=40101317">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

      
<lbl-container wrapper-size="sm">
  <lbl-rich-text>
    <p><a href="https://news.ucsc.edu/2024/04/nitrogen-fixing-organelle.html" target="_blank" rel="noopener"><em>Adapted from a release by Erin Malsbury at UC Santa Cruz</em></a></p>
<p>Modern biology textbooks assert that only bacteria can take nitrogen from the atmosphere and convert it into a form that is usable for life. Plants that fix nitrogen, such as legumes, do so by harboring symbiotic bacteria in root nodules. But a recent discovery upends that rule.</p>
<p>In two recent papers, an international team of scientists describe the first known nitrogen-fixing organelle within a eukaryotic cell. The organelle is the fourth example in history of primary endosymbiosis – the process by which a prokaryotic cell is engulfed by a eukaryotic cell and evolves beyond symbiosis into an organelle.</p>
<p>“It’s very rare that organelles arise from these types of things,” said Tyler Coale, a postdoctoral scholar at UC Santa Cruz and first author on one of two recent papers. “The first time we think it happened, it gave rise to all complex life. Everything more complicated than a bacterial cell owes its existence to that event,” he said, referring to the origins of the mitochondria. “A billion years ago or so, it happened again with the chloroplast, and that gave us plants,” Coale said.</p>
<p>The third known instance involves a microbe similar to a chloroplast. The organelle in this discovery has been named a nitroplast.</p>
<h2>A decades-long mystery</h2>
<p>The discovery of the organelle involved a bit of luck and decades of work. In 1998, Jonathan Zehr, a UC Santa Cruz distinguished professor of marine sciences, found a short DNA sequence of what appeared to be from an unknown nitrogen-fixing cyanobacterium in Pacific Ocean seawater. Zehr and colleagues spent years studying the mystery organism, which they called UCYN-A.</p>
<p>At the same time, Kyoko Hagino, a paleontologist at Kochi University in Japan, was painstakingly trying to culture a marine alga. It turned out to be the host organism for UCYN-A. It took her over 300 sampling expeditions and more than a decade, but Hagino eventually successfully grew the alga in culture, allowing other researchers to begin studying UCYN-A and its marine alga host together in the lab.</p>
<p>For years, the scientists considered UCYN-A an endosymbiont that was closely associated with an alga. But the two recent papers suggest that UCYN-A has co-evolved with its host past symbiosis and now fits criteria for an organelle.</p>
<h2>Organelle origins</h2>
<p>In a&nbsp;<a href="https://www.cell.com/cell/pdf/S0092-8674(24)00182-X.pdf" target="_blank" rel="noopener">paper published in <em>Cell</em></a>&nbsp;in March, Zehr and colleagues from the Massachusetts Institute of Technology, Institut de Ciències del Mar in Barcelona and the University of Rhode Island show that the size ratio between UCYN-A and their algal hosts is similar across different species of the marine haptophyte algae&nbsp;<em>Braarudosphaera bigelowii</em>.</p>
<p>The researchers use a model to demonstrate that the growth of the host cell and UCYN-A are controlled by the exchange of nutrients. Their metabolisms are linked. This synchronization in growth rates led the researchers to call UCYN-A “organelle-like.”</p>
<p>“That’s exactly what happens with organelles,” said Zehr. “If you look at the mitochondria and the chloroplast, it’s the same thing: they scale with the cell.”</p>
<p>But the scientists did not confidently call UCYN-A an organelle until confirming other lines of evidence. In the&nbsp;<a href="https://www.science.org/doi/10.1126/science.adk1075" target="_blank" rel="noopener">cover article of the journal <em>Science</em></a>, published last week, the UC Santa Cruz team and collaborators from Lawrence Berkeley National Laboratory (Berkeley Lab), UC San Francisco, National Taiwan Ocean University, and Kochi University in Japan show that UCYN-A relies on proteins from its host cells and that the organelle’s process of replication and division is tightly paired with the algal cell’s process.</p>
<p>“Until this paper, there was still a question of is this still an ‘endosymbiont’, or has it become a true organelle?” said co-author Carolyn Larabell, a senior faculty scientist in Berkeley Lab’s Biosciences Area and Director of the National Center for X-Ray Tomography. “We showed with X-ray imaging that the process of replication and division of the algal host and endosymbiont is synchronized, which provided the first strong evidence.”</p>
<p>Larabell has been collaborating with Zehr for several years to study the relationship between UCYN-A and the alga using the advanced soft X-ray tomography approach she co-developed at Berkeley Lab’s Advanced Light Source, a particle accelerator that produces X-rays. Her technique allows scientists to rapidly visualize internal components of cells in real-time, under real-life conditions.</p>
<p>Valentina Loconte, a research scientist in Larabell’s group, performed the tomography on a large number of <em>B. bigelowii </em>cells, then analyzed the data to generate detailed images showing the organelle’s movements within the alga at all stages of replication.</p>
<p>“That’s the beauty of our technology. We can get numbers to make quantitative statements. We have numbers at each stage of the cell cycle to show that this isn’t a quirk,” said Larabell.</p>
<p>Meanwhile, Coale compared proteins found within isolated UCYN-A with those found in the entire algal host cell. He found that around half of the proteins in UCYN-A are made by the algal host cell, then labeled with a specific amino acid sequence, which tells the cell to send them to the nitroplast. The nitroplast then imports the proteins and uses them.</p>
<p>“That’s one of the hallmarks of something moving from an endosymbiont to an organelle,” said Zehr. “They start throwing away pieces of DNA, and their genomes get smaller and smaller, and they start depending on the mother cell for those gene products – or the protein itself – to be transported into the cell.”</p>
<p>This dependent relationship, taken together with the images of synchronized division, shows that UCYN-A deserves organelle status.</p>
<h2>Changing perspectives</h2>
<p>While mitochondria and chloroplasts evolved billions of years ago, the nitroplast appears to have evolved about 100 million years ago, providing scientists with a new, more recent perspective on organellogenesis.</p>
<p>The organelle also provides insight into ocean ecosystems. All organisms need nitrogen in a biologically usable form, and rely on nitrogen fixers to break apart tightly bound nitrogen gas (N<sub>2</sub>) in the atmosphere, and convert it into ammonia (NH<sub>3</sub>) molecules that can then be made into countless other compounds. Researchers have found UCYN-A everywhere from the tropics to the Arctic Ocean, and it fixes a significant amount of nitrogen.</p>
<p>The discovery also has the potential to change agriculture. The ability to synthesize ammonia fertilizers from atmospheric nitrogen allowed agriculture – and the world population – to take off in the early 20th century. Known as the Haber-Bosch process, it makes possible about 50% of the world’s food production. It also creates enormous amounts of carbon dioxide: about 1.4% of global emissions come from the process. For decades, researchers have tried to figure out a way to incorporate natural nitrogen fixation into agriculture.</p>
<p>“This system is a new perspective on nitrogen fixation, and it might provide clues into how such an organelle could be engineered into crop plants,” said Coale.</p>
<p>But plenty of questions about UCYN-A and its algal host remain unanswered. The researchers plan to delve deeper into how UCYN-A and the alga operate and study different strains.</p>
<p>Kendra Turk-Kubo, an assistant professor at UC Santa Cruz, will continue the research in her new lab. Zehr expects scientists will find other organisms with evolutionary stories similar to UCYN-A, but as the first of its kind, this discovery is one for the textbooks.</p>
<p>This research was funded by the Simons Foundation, National Institute of General Medical Sciences, and the Department of Energy (DOE) Office of Science Office of Biological and Environmental Research. The Advanced Light Source is a DOE Office of Science user facility.</p>
<p>###</p>
<p><a href="https://www.lbl.gov/">Lawrence Berkeley National Laboratory</a> (Berkeley Lab) is committed to delivering solutions for humankind through research in clean energy, a healthy planet, and discovery science. Founded in 1931 on the belief that the biggest problems are best addressed by teams, Berkeley Lab and its scientists have been recognized with 16 Nobel Prizes. Researchers from around the world rely on the Lab’s world-class scientific facilities for their own pioneering research. Berkeley Lab is a multiprogram national laboratory managed by the University of California for the U.S. Department of Energy’s Office of Science.</p>
<p>DOE’s Office of Science is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit <a href="http://energy.gov/science" target="_blank" rel="noopener">energy.gov/science</a>.</p>
  </lbl-rich-text>
</lbl-container>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Two lifeforms merge in once-in-a-billion-years evolutionary event (237 pts)]]></title>
            <link>https://newatlas.com/biology/life-merger-evolution-symbiosis-organelle/</link>
            <guid>40101290</guid>
            <pubDate>Sat, 20 Apr 2024 21:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/biology/life-merger-evolution-symbiosis-organelle/">https://newatlas.com/biology/life-merger-evolution-symbiosis-organelle/</a>, See on <a href="https://news.ycombinator.com/item?id=40101290">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Scientists have caught a once-in-a-billion-years evolutionary event in progress, as two lifeforms have merged into one organism that boasts abilities its peers would envy. Last time this happened, Earth got plants.</p><p>The phenomenon is called <a href="https://newatlas.com/biology/synthetic-hybrids-yeast-bacteria-evolution-symbiosis/" data-cms-ai="0">primary endosymbiosis</a>, and it occurs when one microbial organism engulfs another, and starts using it like an internal organ. In exchange, the host cell provides nutrients, energy, protection and other benefits to the symbiote, until eventually it can no longer survive on its own and essentially ends up <i>becoming</i> an organ for the host – or what’s known as an organelle in microbial cells.</p><p>Imagine if kidneys were actually little animals running around, and humans had to manually filter their blood through a dialysis machine. Then one day some guy somehow gets one of these kidney critters stuck... Internally (who are we to judge how?) – and realizes he no longer needs his dialysis machine. Neither do his kids, until eventually we're all born with these helpful little fellas inside us. That’s kind of what’s happening here.</p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="A diagram of the mitochondria in a cell" width="1440" height="802" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/e47eafd/2147483647/strip/true/crop/1600x891+0+0/resize/440x245!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 440w,https://assets.newatlas.com/dims4/default/9556f7a/2147483647/strip/true/crop/1600x891+0+0/resize/800x446!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 800w,https://assets.newatlas.com/dims4/default/214decf/2147483647/strip/true/crop/1600x891+0+0/resize/1200x668!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 1200w,https://assets.newatlas.com/dims4/default/145c392/2147483647/strip/true/crop/1600x891+0+0/resize/1920x1069!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 1920w" data-src="https://assets.newatlas.com/dims4/default/72bcb4b/2147483647/strip/true/crop/1600x891+0+0/resize/1440x802!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/e47eafd/2147483647/strip/true/crop/1600x891+0+0/resize/440x245!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 440w,https://assets.newatlas.com/dims4/default/9556f7a/2147483647/strip/true/crop/1600x891+0+0/resize/800x446!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 800w,https://assets.newatlas.com/dims4/default/214decf/2147483647/strip/true/crop/1600x891+0+0/resize/1200x668!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 1200w,https://assets.newatlas.com/dims4/default/145c392/2147483647/strip/true/crop/1600x891+0+0/resize/1920x1069!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg 1920w" src="https://assets.newatlas.com/dims4/default/72bcb4b/2147483647/strip/true/crop/1600x891+0+0/resize/1440x802!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fdb%2Fd2%2Fa7d70c80494c888fe5f519719327%2Fmitochondria-0.jpeg">
</p>



    
    

    
        <div><figcaption itemprop="caption">A diagram of the mitochondria in a cell</figcaption><p>National Human Genome Research Institute</p></div>
    
</figure>

                
            </div><p>In the 4-billion-odd-year history of life on Earth, primary endosymbiosis is thought to have only happened twice that we know of, and each time was a massive breakthrough for evolution. The first occurred about 2.2 billion years ago, when an archaea swallowed a bacterium that became the mitochondria. This specialized energy-producing organelle allowed for basically all complex forms of life to evolve. It remains the heralded "powerhouse of the cell" to this day. </p><p>The second time happened about 1.6 billion years ago, when some of these more advanced cells absorbed cyanobacteria that could harvest energy from sunlight. These became organelles called chloroplasts, which gave sunlight-harvesting abilities, as well as a fetching green color, to a group of lifeforms you might have heard of – plants. </p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="Live moss cells under a microscope, showing their chloroplasts (green circles)" width="1440" height="919" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/0da7c66/2147483647/strip/true/crop/2295x1464+0+0/resize/440x281!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 440w,https://assets.newatlas.com/dims4/default/1581ce0/2147483647/strip/true/crop/2295x1464+0+0/resize/800x511!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 800w,https://assets.newatlas.com/dims4/default/5ef6141/2147483647/strip/true/crop/2295x1464+0+0/resize/1200x766!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 1200w,https://assets.newatlas.com/dims4/default/70b7e2d/2147483647/strip/true/crop/2295x1464+0+0/resize/1920x1225!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 1920w" data-src="https://assets.newatlas.com/dims4/default/dcdfdce/2147483647/strip/true/crop/2295x1464+0+0/resize/1440x919!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/0da7c66/2147483647/strip/true/crop/2295x1464+0+0/resize/440x281!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 440w,https://assets.newatlas.com/dims4/default/1581ce0/2147483647/strip/true/crop/2295x1464+0+0/resize/800x511!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 800w,https://assets.newatlas.com/dims4/default/5ef6141/2147483647/strip/true/crop/2295x1464+0+0/resize/1200x766!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 1200w,https://assets.newatlas.com/dims4/default/70b7e2d/2147483647/strip/true/crop/2295x1464+0+0/resize/1920x1225!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg 1920w" src="https://assets.newatlas.com/dims4/default/dcdfdce/2147483647/strip/true/crop/2295x1464+0+0/resize/1440x919!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F96%2Fca%2F61428d1b484d9360ca9ce87832b0%2Fchloroplasts.jpeg">
</p>



    
    

    
        <div><figcaption itemprop="caption">Live moss cells under a microscope, showing their chloroplasts (green circles)</figcaption></div>
    
</figure>

                
            </div><p>And now, scientists have discovered that it’s happening again. A species of algae called <i>Braarudosphaera bigelowii</i> was found to have engulfed a cyanobacterium that lets them do something that algae, and plants in general, can’t normally do – "fixing" nitrogen straight from the air, and combining it with other elements to create more useful compounds.</p><p>Nitrogen is a key nutrient, and normally plants and algae get theirs through symbiotic relationships with bacteria that remain separate. At first it was thought that <i>B. bigelowii</i> had hooked up this kind of situation with a bacterium called UCYN-A, but on closer inspection, scientists discovered that the two have gotten far more intimate.</p><p>In one recent study, a team found that the size ratio between the algae and UCYN-A stays similar across different related species of the algae. Their growth appears to be controlled by the exchange of nutrients, leading to linked metabolisms.</p><p>“That’s exactly what happens with organelles,” said Jonathan Zehr, an author of the studies. “If you look at the mitochondria and the chloroplast, it’s the same thing: they scale with the cell.”</p><p>In a follow-up study, the team and other collaborators used a powerful X-ray imaging technique to view the interior of the living algae cells. This revealed that the replication and cell division was synchronized between the host and symbiote – more evidence of primary endosymbiosis at work.</p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="X-ray images of Braarudosphaera bigelowii at different stages of cell division. The newly identified nitroplast is highlighted in cyan, the algae nucleus is blue, mitochondria are green and chloroplasts are purple" width="1025" height="685" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/1167d59/2147483647/strip/true/crop/1025x685+0+0/resize/440x294!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 440w,https://assets.newatlas.com/dims4/default/79f851b/2147483647/strip/true/crop/1025x685+0+0/resize/800x535!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 800w,https://assets.newatlas.com/dims4/default/82e3fe1/2147483647/strip/true/crop/1025x685+0+0/resize/1200x802!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 1200w,https://assets.newatlas.com/dims4/default/fc8a14f/2147483647/strip/true/crop/1025x685+0+0/resize/1920x1283!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 1920w" data-src="https://assets.newatlas.com/dims4/default/3b97965/2147483647/strip/true/crop/1025x685+0+0/resize/1025x685!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/1167d59/2147483647/strip/true/crop/1025x685+0+0/resize/440x294!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 440w,https://assets.newatlas.com/dims4/default/79f851b/2147483647/strip/true/crop/1025x685+0+0/resize/800x535!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 800w,https://assets.newatlas.com/dims4/default/82e3fe1/2147483647/strip/true/crop/1025x685+0+0/resize/1200x802!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 1200w,https://assets.newatlas.com/dims4/default/fc8a14f/2147483647/strip/true/crop/1025x685+0+0/resize/1920x1283!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png 1920w" src="https://assets.newatlas.com/dims4/default/3b97965/2147483647/strip/true/crop/1025x685+0+0/resize/1025x685!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Ffc%2F29%2Fbe4497b0484cba59d73433909e61%2Fnitroplasts.png">
</p>



    
    

    
        <div><figcaption itemprop="caption">X-ray images of <i>Braarudosphaera bigelowii </i>at different stages of cell division. The newly identified nitroplast is highlighted in cyan, the algae nucleus is blue, mitochondria are green and chloroplasts are purple</figcaption><p>Valentina Loconte/Berkeley Lab</p></div>
    
</figure>

                
            </div><p>And finally, the team compared the proteins of isolated UCYN-A to those inside the algal cells. They found that the isolated bacterium can only produce about half of the proteins it needs, relying on the algal host to provide the rest.</p><p>“That’s one of the hallmarks of something moving from an endosymbiont to an organelle,” said Zehr. “They start throwing away pieces of DNA, and their genomes get smaller and smaller, and they start depending on the mother cell for those gene products – or the protein itself – to be transported into the cell.”</p><p>Altogether, the team says this indicates UCYN-A is a full organelle, which is given the name of nitroplast. It appears that this began to evolve around 100 million years ago, which sounds like an incredibly long time but is a blink of an eye compared to mitochondria and chloroplasts.</p><p>The researchers plan to continue studying nitroplasts, to find out if they’re present in other cells and what effects they may have. One possible benefit is that it could give scientists a new avenue to incorporate nitrogen-fixing into plants to grow better crops.</p><p>The research was published in the journals <i><a href="https://www.cell.com/cell/pdf/S0092-8674(24)00182-X.pdf" target="_blank" data-cms-ai="0">Cell</a></i> and <i><a href="https://www.science.org/doi/10.1126/science.adk1075" target="_blank" data-cms-ai="0">Science</a></i>.</p><p>Source: <a href="https://newscenter.lbl.gov/2024/04/17/scientists-discover-first-nitrogen-fixing-organelle/" target="_blank" data-cms-ai="0">Berkeley Lab</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why everything is becoming a game (143 pts)]]></title>
            <link>https://www.gurwinder.blog/p/why-everything-is-becoming-a-game</link>
            <guid>40100867</guid>
            <pubDate>Sat, 20 Apr 2024 20:44:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gurwinder.blog/p/why-everything-is-becoming-a-game">https://www.gurwinder.blog/p/why-everything-is-becoming-a-game</a>, See on <a href="https://news.ycombinator.com/item?id=40100867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>For years, some of the world’s sharpest minds have been quietly turning your life into a series of games. Not merely to amuse you, but because they realized that the easiest way to make you do what they want is to make it fun. To escape their control, you must understand the creeping phenomenon of gamification, and how it makes you act against your own interests.</p><p>This is a story that encompasses a couple who replaced their real baby with a fake one, a statistician whose obsessions cost the US the Vietnam War, the apparent absence of extraterrestrial life, and the biggest FBI investigation of the 20th century. But it begins with a mild-mannered psychologist who studied pigeons at Harvard in the Thirties.</p><p>B. F. Skinner believed environment determines behavior, and a person could therefore be controlled simply by controlling their environment. He began testing this theory, known as behaviorism, on pigeons. For his experiments, he developed the “Skinner box”, a birdcage with a food dispenser controlled by a button.</p><p>Skinner’s goal was to make the pigeons peck the button as many times as possible. From his experiments, he made three discoveries. First, the pigeons pecked most when doing so yielded immediate, rather than delayed, rewards. Second, the pigeons pecked most when it rewarded them randomly, rather than every time. Skinner’s third discovery occurred when he noticed the pigeons continued to peck the button long after the food dispenser was empty, provided they could hear it click. He realized the pigeons had become conditioned to associate the click with the food, and now valued the click as a reward in itself.</p><p>This led him to propose two kinds of reward: primary and conditioned reinforcers. A primary reinforcer is something we’re born to desire. A conditioned reinforcer is something we learn to desire, due to its association with a primary reinforcer. Skinner found that conditioned reinforcers were generally more effective in shaping behavior, because while our biological need for the primary reinforcer is easily satiable, our abstract desire for the conditioned reinforcer isn’t. The pigeons would stop seeking food once their bellies were full, but they’d take far longer to get tired of hearing the food dispenser click.</p><p><span>Skinner’s three key insights — immediate rewards work better than delayed, unpredictable rewards work better than fixed, and conditioned rewards work better than primary — were found to also apply to humans, and in the 20</span><sup>th</sup><span> Century would be used by businesses to shape consumer behavior. From Frequent Flyer loyalty points to mystery toys in McDonalds Happy Meals, purchases were turned into games, spurring consumers to purchase more.</span></p><p>Some people began to consider whether games could be used to make people do other things. In the Seventies, the American management consultant Charles Coonradt wondered why people work harder at games they pay to play than at work they’re paid to do. Like Skinner, Coonradt saw that a defining feature of compelling games was immediate rewards. Most of the feedback loops in employment — from salary payments to annual performance appraisals — were torturously long. So Coonradt proposed shortening them by introducing daily targets, points systems, and leaderboards. These conditioned reinforcers would transform work from a series of monthly slogs into daily status games, in which employees competed to fulfil the company’s goals.</p><p>In the 21st century, advances in technology made it easy to add game mechanics to almost any activity, and a new term — “gamification” — became a buzzword in Silicon Valley. By 2008, business consultants were giving presentations about leveraging fun to shape behavior, while futurists gave TED Talks speculating on the social implications of a gamified world. Underpinning every speech was a single, momentous question: if gamification could make people buy more stuff and work more hours, what else could it be used to make people do?</p><p><span>The tone was generally utopian, because back then gamification seemed to be mostly a force for good. In 2007, for instance, the online word quiz FreeRice gamified famine relief: for every correct answer, 10 grains of rice were given to the UN World Food Programme. Within six months it had already given away over </span><a href="https://news.un.org/en/story/2008/03/251732" rel="">20 billion</a><span> grains of rice. Meanwhile, the SaaS company, Opower, had gamified going green. It turned eco-friendliness into a contest, showing each person how much energy they were using compared with their neighbors, and displaying a leaderboard of the top 10 least wasteful. The app has since saved </span><a href="https://www.cnbc.com/2022/07/14/how-opower-sold-to-oracle-has-helped-save-3-billion-in-energy-bills.html" rel="">over $3 billion</a><span> worth of energy. And then there was Foldit, a game developed by University of Washington biochemists who’d struggled for 15 years to discern the structure of an Aids virus protein. They reasoned that, if they turned the search into a game, someone might do what they couldn’t. It took gamers just </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3705907/#SD1" rel="">10 days</a><span>.</span></p><p><span>Even established corporations saw gamification’s potential. In 2008, Volkswagen debuted a campaign called “The Fun Theory”, based on the idea that “fun is the easiest way to change people’s behavior for the better”. Piano stairs were installed at a Stockholm rail station to encourage people to use them instead of the escalator, leading to a </span><a href="https://www.researchgate.net/publication/262233618_Social_Stairs_Taking_the_Piano_Staircase_towards_Long-Term_Behavioral_Change" rel="">66% increase</a><span> in stair use. Volkswagen also tried to gamify gamification itself, creating a contest for good game ideas. The winning idea was a “speedcam lottery”, where people who kept to the speed limit would be entered into a prize draw, funded by speeding fines.</span></p><p>It all seemed so simple: if we could only create the right games, we could make humanity fitter, greener, kinder, smarter. We could repopulate forests and even cure cancers simply by making it fun.</p><p>Unfortunately, that didn’t happen. Instead, gamification took a less wholesome route.</p><p>We humans are harder to manipulate than pigeons, but we can be manipulated in many more ways, because we have a wider spectrum of needs. Pigeons don’t care much about respect, but for us it’s a primary reinforcer, to such an extent that we can be made to desire arbitrary sounds that become associated with it, like praise and applause.</p><p><span>Respect is so important to humans that it’s a key reason we evolved to play games. Will Storr, in his book </span><em>The Status Game</em><span>, charted the rise of game-playing in different cultures, and found that games have historically functioned to organize societies into hierarchies of competence, with score acting as a conditioned reinforcer of status. In other words, all games descend from status games. The association between score and status has grown so strong in our minds that, like pigeons pecking the button long after the food dispenser has stopped dispensing, we’ll chase scores long after everyone else has stopped watching.</span></p><p>And so, when Facebook added “likes” in 2009, they quickly became a proxy for status, and a score to compete for. People now had a social stake in posting content. Hitting “send” became like activating a slot machine, initiating an excitingly uncertain outcome; the post might go completely unnoticed, or it might hit the jackpot and go viral, awarding the coveted prizes of respect and fame.</p><p>Other social media platforms followed, leveraging Skinner’s three laws to maximize button-pecking. They offered immediate reinforcement in the form of instant responses, conditioned reinforcement in the form of “likes” and “followers”, and unpredictable reinforcement that varied with each post and each refresh of the page. These features turned social media into the world’s most addictive status game. And thus, just as pigeons were made to chase clicks, so eventually were we.</p><p><span>But this was just the beginning. Many in the managerial class saw the success of social media and wondered how they could use gamification for their own ends. The Chinese Communist Party was among the first to apply the principles of social media to the real world. In several towns and cities, it began trialing social credit schemes that assign citizens a level of “clout” based on how well they behave. In some areas, such as </span><a href="https://foreignpolicy.com/2018/04/03/life-inside-chinas-social-credit-laboratory/" rel="">Rongcheng</a><span> and </span><a href="https://www.telegraph.co.uk/news/social-credit-in-china/" rel="">Hangzhou</a><span>, there are public signs that display leaderboards of the highest scoring citizens. The lowest scoring citizens may be punished with credit blacklists or throttled internet speeds.</span></p><p><span>Meanwhile, in the West, gamification is used to make people obey corporations. Employers like</span><a href="https://www.theinformation.com/articles/amazon-expands-effort-to-gamify-warehouse-work" rel=""> Amazon</a><span> and</span><a href="https://www.fastcompany.com/90260703/the-dark-side-of-gamifying-work" rel=""> Disneyland</a><span> use electronic tracking to keep score of employees’ work rates, often displaying them for all to see. Those who place high on the leaderboards can win prizes like virtual pets; those who fall below the minimum rate may be financially penalized.</span></p><p>Game features are even more pervasive in the digital world. In little over a year, the Chinese shopping app Temu has exploded in popularity thanks to its “play to pay” model: as users browse deals they’re presented with puzzles to solve, roulette wheels to spin, and challenges to complete, which reward them with credit and special offers. Unsurprisingly, users are now spending double the amount of time on Temu than on Amazon.</p><p>Gamification has also transformed dating apps. Zoosk works like a typical role-playing game, where you gradually accumulate “experience points”, which unlock new abilities, such as animated virtual gifts to send to prospective dates. Meanwhile, on Tinder you can purchase various “level-ups” — Boosts, Super Likes, and Rewinds — that increase your chances of winning and compel you to keep playing to get your money’s worth. And if you have no luck on dating apps, there are always AI girlfriends to play with: apps like iGirl and Replika award users points for their commitment, which can be used to “level up” their virtual lovers into a version that is more intimate.</p><p><span>These are only a few examples. Virtually every kind of app, from </span><a href="https://www.hookedtobooks.com/audible-badges/" rel="">audiobook apps</a><span> to </span><a href="https://strivecloud.io/blog/gamification-app-examples-uber/" rel="">taxicab apps</a><span> to </span><a href="https://www.bi.team/blogs/gamified-online-stock-trading-harms-consumers/" rel="">stock trading apps</a><span>, now employs game mechanics like points, badges, levels, streaks, progress bars, and leaderboards. Their ubiquity attests to their success in hooking people.</span></p><p>Gamification once promised to create a better society, but it’s now used mainly to addict people to apps. The gamifiers, like Skinner’s pigeons, prioritized immediate rewards over delayed ones, so they gamified for the next financial quarter and not for the future of civilization.</p><p>So where does this all lead? What is the endgame?</p><p>At the University of Michigan in the mid-twentieth century, there was a zoologist named James V. McConnell. A strong believer in fun, he often presented his academic research alongside satire and poetry, so it was difficult to tell which was which, a habit that made him popular with students but unpopular with his fellow professors.</p><p><span>One of the few things McConnell took seriously was behaviorism. He was transfixed by Skinner’s work on pigeons, and wished to expand the work to humans, with an eye to creating a perfect society. In a 1970 </span><em>Psychology Today</em><span> article he wrote:</span></p><blockquote><p>We should reshape our society so that we all would be trained from birth to want to do what society wants us to do. We have the techniques now to do it. Only by using them can we hope to maximize human potentiality.</p></blockquote><p>In short, he wanted to turn society into a Skinner box.</p><p>Throughout the Seventies, McConnell used Skinnerian techniques to create rehabilitation programs for prisoners and psychiatric patients, some of which were successful. But his most ambitious scheme emerged in the early Eighties, when he witnessed people being captivated by video games like Donkey Kong and Pac Man, and realized their addictive mechanics could be translated to other, more productive activities. He pitched an ambitious project to gamify education to tech companies like Microsoft and IBM, but he was 30 years too early, and they couldn’t yet see its promise. There was, however, one person who’d taken a keen interest in McConnell’s work. His name was Ted Kaczynski.</p><p>Kaczynski was an awkward but gifted student, coldly matter-of-fact in manner, for which he was described by his schoolmates as a “walking brain”. In a school IQ test he’d scored 167 (140 is considered “genius”).</p><p>He’d come to Michigan in 1962 as a postgraduate from Harvard, where he’d studied mathematics and graduated at just 18. But at Harvard, he’d also been subjected to torturous experiments. In a lab not far from where Skinner had once experimented with pigeons, psychologists linked to US intelligence were now experimenting with humans — one of whom was Kaczynski. Under the glare of blinding lights, he was methodically humiliated to see how he reacted. He claimed the experience didn’t affect him, and yet, within just a few years, he’d developed an intense paranoia about psychological conditioning. And so, when Kaczynski learned of McConnell’s proposals to create a utopia through behavior modification, he concluded that the jocular professor was an existential threat to humanity, and that he needed to die.</p><p>It wasn’t a decision Kaczynski had made lightly; he’d developed an entire philosophy to justify it. Influenced by techno-dystopian writers like Aldous Huxley and Jacques Ellul, Kaczynski believed the Industrial Revolution had turned society into a cold process of production and consumption that was gradually crushing everything humans valued most: freedom, happiness, purpose, meaning, and the ecosystem. In his view, everything society now produced—including science and technology—served industry, not humanity, and thus was increasingly being purposed not to enrich our lives but to psychologically condition us so we wouldn’t resist what was being done to us and to the earth.</p><p>In short, where society had once been shaped to accommodate people, now people were being shaped to accommodate society. And this misshaping was destructive because it conflicted with our deepest nature.</p><p>Kaczynski believed modern society made us docile and miserable by depriving us of fulfilling challenges and eroding our sense of purpose. The brain evolved to solve problems, but the problems it had evolved for were now largely solved by technology. Most of us can now obtain all our basic necessities simply by being obedient, like a pigeon pecking a button. Kaczynski argued that such conveniences didn’t make us happy, only aimless. And to stave of this aimlessness, we had to continually set ourselves goals purely to have goals to pursue, which Kaczynski called “surrogate activities”. These included sports, hobbies, or chasing the latest product that ads promised would make us happy.</p><p>For Kaczynski, the result of reorienting our lives to chase artificial goals was that we became increasingly dependent on society to provide us with them. And without our own inherent sense of purpose, we’d inevitably be made to chase goals that were good for the industrial machine but bad for us.</p><p>Kaczynski’s theories eerily prophesize the capture of society by gamification. While he overlooked the benefits of technology, he diligently noted its dangers, recognizing its role in depriving us of purpose and meaning. Today the evidence is everywhere: religion is dying out, Western nations are culturally confused, people are getting married less and having fewer children, and many are losing their jobs to automation, so the traditional pillars of life — God, nation, family, and work — are crumbling, and people are losing their value systems. Amid such uncertainty, games, with their well-defined rules and goals, provide a semblance of order and purpose that may otherwise be lacking in people’s lives. Gamification is thus no accident, but an attempt to plug a widening hole in society.</p><p>Unfortunately, it seems to be only a band-aid. Kaczynski observed that surrogate activities rarely kept people contented for long. There were always more stamps to collect, a better car to buy, a higher score to achieve. He believed artificial goals were too divorced from our actual needs to truly satisfy us, so they merely served to keep us busy enough not to notice our dissatisfaction. Instead of a fulfilled life, a life filled full.</p><p><span>Today, people increasingly live inside their phones, bossed around by notifications, diligently collecting badges and filling progress bars, even though it doesn’t make them happy. On the contrary, </span><a href="https://psycnet.apa.org/record/2022-90266-001" rel="">substantial research</a><span> comprising over a hundred studies finds that prioritizing extrinsic goals over intrinsic goals — in other words doing things to win prizes and achieve high scores rather than for the inherent love of doing them — leads to lower well-being.</span></p><p>Kaczynski seemed to recognize this long before smartphones emerged. He felt that building a life around chasing what was offered on billboards and in magazines wouldn’t make him happy, and would only feed the Machine, so in 1971 he fled society, holing himself up in a log cabin in the Montana wilderness. There he attempted a simple and self-sufficient life, enjoying the small things like the sound of birds singing and the feeling of sunrays on his back.</p><p>But this idyll wouldn’t last. He claims that while hiking across one of his favorite spots — a rocky ridge with a waterfall — he was aghast to find a road had been built through it. As he saw it, industrialization, like some fungus creeping across the world, had followed him even here. Enraged, he decided modernity couldn’t be escaped, and had to be destroyed.</p><p>His emotional instability got the better of him, and in 1978 he began posting homemade bombs to those he accused of betraying humanity. In 1985, a package arrived at McConnell’s home. It was opened by his assistant, Nicklaus Suino. The package only partially exploded, injuring Suino and McConnell, and leaving them both shaken for life.</p><p>They were lucky. Less than a month later, Kaczynski would send another, more carefully prepared bomb to computer store owner, Hugh Scrutton, who’d become Kaczynski’s first murder victim.</p><p>By then, the FBI’s investigation into the bombings had grown into the largest in its history. For over a decade they scoured the country as Kaczynski continued to kill and injure, but much of their time was wasted chasing mirages, for Kaczynski would often scatter his bomb parcels with red herrings such as notes referencing fictitious conspiracies and signed with made-up initials.</p><p>Kaczynski’s actions, though unforgivable, can teach us as much about gamification as his philosophy. His red herrings lured people away from what they actually sought, and, as we shall see, this is the greatest danger of gamification.</p><p>While Kaczynski wanted to demolish industrial society and return humanity to an agrarian life, US defense secretary Robert McNamara wanted the opposite: to use American industrial might to crush the agrarian society of Vietnam.</p><p>McNamara was a statistician who believed what couldn’t be measured didn’t matter. He charted progress in the Vietnam war by body count, because it was simple to measure. It was his way of keeping score. But his focus on what could be easily measured led him to overlook what couldn’t: negative public opinion of the US Army both at home and in Vietnam, which deflated US morale while boosting enemy conscription. In the end, the US was forced to withdraw from the war, despite winning the battle of bodies, because it had lost the battle of hearts and minds.</p><p>Thus, the McNamara fallacy, as it came to be known, refers to our tendency to focus on the most quantifiable measures, even if doing so leads us from our actual goals. Put simply, we try to measure what we value, but end up valuing what we measure.</p><p>And what we measure is rarely what we mean to value. As Skinner showed, the goals of games — points, badges, trophies — are secondary reinforcers that only derive their worth due to their association with something we actually desire. But these associations are often illusory. A click is not the same thing as a food pellet. And points are not the same as progress.</p><p><span>We’re </span><a href="https://www.psychologytoday.com/gb/blog/glue/202107/how-benefit-the-scoreboard-principle" rel="">easily motivated</a><span> by points and scores because they’re easy to track and enjoyable to accrue. As such, scorekeeping is, for many, becoming the new foundation of their lives. “</span><a href="https://www.bbc.com/culture/article/20240326-inside-looksmaxxing-the-extreme-cosmetic-social-media-trend" rel="">Looksmaxxing</a><span>” is a new trend of gamified beauty, where people assign scores to physical appearance and then use any means necessary to maximize their score. And in the online wellness space, there is now a “</span><a href="https://rejuvenationolympics.com/" rel="">Rejuvenation Olympics</a><span>” complete with a leaderboard that ranks people by their “age reversal”. Even sleep has become a game; many people now use apps like Pokemon Sleep that reward them for achieving high “sleep scores”, and some even compete to get the highest “</span><a href="https://www.youtube.com/watch?v=Z7veiyN4LqU" rel="">sleep ranking</a><span>”.</span></p><p>Most such scores are simplifications that don’t tell the whole story. For instance, sleep trackers only measure what’s easy to measure, like movement, which says nothing about crucial facts like time spent in REM sleep. A more accurate measure of how well you slept would be how refreshed you feel in the morning, but since this can’t be quantified, it tends to be ignored.</p><p>Further, if increasing one’s youthfulness score requires a daily 2-hour skincare routine, a diet of 50 pills each morning and night, abstention from many of life’s pleasures, and constant fixation on one’s vital metrics, is it really worth it? Of what value is adding a few years to your life if the cost is a life worth living? The scores we use to chart progress can’t articulate the nuances of reality, and yet we often tie our life goals and even self-worth to such arbitrary numbers.</p><p><span>In the end, even Kaczynski, with his IQ of 167, was led astray by red herring goals. In 1995 he enacted his endgame, demanding the </span><em>New York Times</em><span> and </span><em>Washington Post</em><span> print his anti-technology manifesto to prevent further bloodshed. All along, his goal had been to get the widest possible newspaper coverage, to maximize how many people would see his manifesto, but like McNamara he didn’t account for what couldn’t be quantified, such as </span><em>how</em><span> people would see his manifesto. Skinner’s pigeons had learned to desire the click of the food dispenser because it had been accompanied by food, and Kaczynski’s intended audience learned to hate his arguments because they’d been accompanied by violence. By maximizing audience size at the expense of everything else, Kaczynski gained a massive audience unwilling to give him a fair hearing.</span></p><p>Further, his manifesto contained a peculiar choice of words (“eat your cake and have it”), which was recognized by his brother, David, who alerted the police, leading to Kaczynski’s capture. And so, by fixating on the most obvious metric — the size of his audience — Kaczynski lost the one thing he’d been fighting for all along: freedom.</p><p><span>Kaczynski played the wrong game, and was trapped by it. Today, we all face similar traps. We chase numbers and icons because they’re always available, and the chase is often so immersive that it keeps us from seeing where it leads, which is often far away from what we actually want. This can lead to what the evolutionary psychologist Diana Fleischman </span><a href="https://dianaverse.com/2020/10/30/uncanny-vulvas/" rel="">calls</a><span> “counterfeit fitness”: the constant, momentary “wins” that come with playing digital games give us a false sense of progression and accomplishment, a neurochemical high that feels like victory but is not, and which, if it becomes a habit, risks placating our ambitions to pursue true fulfilment.</span></p><p>It explains why so many young men have lost themselves in video games, and are no longer in employment or relationships. The false signals they’re getting from video game progress, combined with the sexual reward of online porn, are convincing their dopamine pathways that they’re winning in life, even as their minds and futures atrophy.</p><p><span>It’s easy to persuade people into tying their sense of progress to fake or trivial goals. Casinos </span><a href="https://freakonomics.com/2011/09/congratulations-youve-lost-how-slot-machines-disguise-loses-as-wins/" rel="">keep their customers happily losing</a><span> money by distracting them with minor side games they’re likely to win. The small victories convince them they’re winning overall even as they lose the only games that actually matter.</span></p><p><span>This strange quirk of human behavior can even cost lives. In South Korea, a young couple became so addicted to raising a virtual baby that they </span><a href="https://www.theguardian.com/world/2010/mar/05/korean-girl-starved-online-game" rel="">let their real baby starve to death</a><span>. The parents prioritized what they could quantify — levelling up their virtual baby — over that which they couldn’t — the life of their real one.</span></p><p>What makes pathological gameplaying so dangerous is that the more harm it does, the more alluring it becomes. If your baby is dead, why not raise a virtual one? If your life of playing video games has stopped you finding a girlfriend, why not play the AI girlfriend game? Thus, bad games form a feedback loop: they distract us from pursuing the things that will bring us lasting contentment, and without this lasting contentment, we become ever more dependent on false, transient metrics like scores and leaderboards to imbue our lives with meaning.</p><p>All the things a gamified world promises in the short term — pride, purpose, meaning, control, motivation, and happiness — it threatens in the long term. It has the power to seclude people from reality, and to rewrite their value systems so they prioritize the imaginary over the real, and the next moment over the rest of their lives.</p><p>So what’s the solution?</p><p>There are billions of habitable planets in our galaxy, and many of them are far older than our own. Statistically, this would suggest that by now our galaxy would be teeming with signs of advanced alien life. And yet space is silent. This discrepancy, known as the Fermi paradox, has puzzled scientists for almost a century. Ted Kaczynski believed his prophecies offered an answer.</p><p>While serving a life sentence in jail, Kaczynski wrote a little-known sequel to his manifesto, entitled “Anti-Tech Revolution: Why and How”. In it he outlines his belief that all technologically advanced civilizations become trapped in fatal games before they learn to colonize space. This happens because industry is driven by competition, and competition favors short-term wins over long-term sustainability, because players who care about long-term sustainability are significantly disadvantaged compared to players who only care about winning.</p><p>To illustrate his point, Kaczynski describes a thought experiment involving a forested region occupied by several rival kingdoms. The kingdoms that clear the most land for agriculture can support a larger population, affording them a military advantage. Every kingdom must therefore clear as much forest as possible, or face being conquered by its rivals. The resulting deforestation eventually leads to ecological disaster and the collapse of all the kingdoms. Thus, a trait that is advantageous for every kingdom’s short-term survival leads in the long term to every kingdom’s demise.</p><p>Kaczynski was describing a “social trap”, a term coined by a student of Skinner, John Platt, who’d theorized that an entire population behaving like pigeons in a Skinner box, each acting only for the next immediate reward, would eventually overexploit a resource, causing ruin for everyone. What Platt called “social traps”, Kaczynski called “self-propagating systems”, because he viewed them as negative-sum games that took on a life of their own, defeating every player to become the only winner. He believed such games not only drove industrialization but also replaced the sense of purpose and meaning that industrialization destroyed. They were thus inextricable from technological advancement, and, in a society like ours, impossible to stop.</p><p><span>In jail, Kaczynski was forbidden access to the web, and in </span><a href="https://news.yahoo.com/the-unabomber-takes-on-the-internet-201549030.html" rel="">letters</a><span> he struggled to understand what Facebook was. Nevertheless, his warnings could easily have been referring to social media.</span></p><p>On Instagram, the main self-propagating system is a beauty pageant. Young women compete to be as pretty as possible, going to increasingly extreme lengths: makeup, filters, fillers, surgery. The result is that all women begin to feel ugly, online and off.</p><p><span>On TikTok and YouTube, there is another self-propagating system where pranksters compete to outdo each other in outrageousness to avoid being buried by the algorithm. Such extreme brinkmanship frequently leads to arrest or injury, and has even led to the deaths of, among others, </span><a href="https://www.bbc.co.uk/news/technology-55982131" rel="">Timothy Wilks</a><span> and</span><a href="https://www.theguardian.com/us-news/2018/mar/15/woman-jailed-for-killing-boyfriend-in-youtube-stunt-that-went-wrong-monalisa-perez-pedro-ruiz" rel=""> Pedro Ruiz</a><span>.</span></p><p>On X, meanwhile, there is a self-propagating system known as “the culture war”. This game consists of trying to score points (likes and retweets) by attacking the enemy political tribe. Unlike in a regular war, the combatants can’t kill each other, only make each other angrier, so little is ever achieved, except that all players become stressed by constant bickering.&nbsp;And yet they persist in bickering, if only because their opponents do, in an endless state of mutually assured distraction.</p><p>Those are just three examples of social traps that have emerged in our gamified age. But the most worrying social trap is gamification itself.</p><p>Companies that exploit our gameplaying compulsion will have an edge over those who don’t, so every company that wishes to compete must gamify in ever more addictive ways, even though in the long term this harms everyone. As such, gamification is not just a fad; it’s the fate of a digital capitalist society. Anything that can be turned into a game sooner or later will be. And the games won’t just be confined to our phones — “extended reality” eyewear like Meta Quest and Apple Vision, once they become normalized, will make playing even harder to avoid.</p><p><span>Games will be created not just to extract money from people, but also data. The </span><a href="https://www.reuters.com/sports/athletics/athletes-risk-bans-health-death-enhanced-games-wada-2024-02-14/" rel="">2025 Enhanced Games</a><span>, for instance, is a new futuristic version of the Olympics, funded by tech moguls like Peter Thiel, where contestants can exploit anything from cybernetic implants to PEDs to get a competitive advantage. The purpose of the games seems to be transhumanist: to motivate people to discover new ways to augment human abilities, with the eventual goal of turning men into gods.</span></p><p>There is, after all, a vacancy in heaven. When God is dead, and nations are atomized, and family seems burdensome, and machines can beat us at our jobs and even at art, and trust and truth are lost in a roiling sea of AI-generated clickbait — what is left but games?</p><p><span>This isn’t necessarily a bad thing. Games can motivate us to destroy ourselves, but they can also motivate us to better ourselves. In a gamified world, it’s possible to play without getting played, if one only chooses the right games. As the poker-player-turned-podcaster Liv Boeree </span><a href="https://twitter.com/Liv_Boeree/status/1609271228052959233" rel="">said</a><span>: “Intelligence is knowing how to win the game. Wisdom is knowing which game to play…” So how do you decide which games to play? The story of gamification offers five broad rules.</span></p><p>First: choose long-term goals over short-term ones. Short, frequent feedback loops offer regular reinforcement, which helps motivate us. But what is made to motivate us too often addicts us. So consider the long-term outcomes of the games you’re playing: if you did the same thing you did today for the next 10 years, where would you be? Play games the 90-year-old you would be proud of having played. They won’t care how many trophies you have; they will care how many times you saw your parents before they died.</p><p>Second: choose hard games over easy ones. Since the long-term value of games lies in their ability to hone skills and build character, easy games are usually a trap. People with unearned wealth — thieves, heirs and lottery winners — often end up losing it all, because the struggle to obtain a reward teaches us the reward’s worth, and is thus a crucial part of the reward.</p><p>Third: choose positive-sum games over zero-sum or negative-sum ones. Games evolved to confer status, and status is zero-sum — for some to have it, others must lose it. But we no longer have to play such games; we can change the rules so a win for me doesn’t mean a loss for you. Educational games are one example. Wealth creation is another. Positive-sum games —&nbsp;where every player benefits by playing —&nbsp;are a form of competition that brings people together instead of driving them apart.</p><p><span>Fourth: choose atelic games over telic ones. Atelic games are those you play because you enjoy them. Telic games are those you play only to obtain a reward. Chasing rewards like trophies and leaderboard rankings can help drive us to succeed, but a fixation on such rewards can become a source of stress, and can even make leisure activities feel like drudgery, </span><a href="https://thedecisionlab.com/biases/overjustification-effect" rel="">turning games into work</a><span>.</span></p><p>Finally, the fifth rule is to choose immeasurable rewards over measurable ones. Seeing numerical scores increase is satisfying in the short term, but the most valuable things in life — freedom, meaning, love — can’t be quantified.</p><p><span>There are an overwhelming number of games to choose from. If you want to keep fit, try </span><a href="https://zrx.app/" rel="">Zombies Run</a><span>, an app that takes the form of a post-zombie-apocalypse radio broadcast telling you which direction to run to avoid being eaten. If you want to learn general knowledge while helping those in poverty, play the </span><a href="https://freerice.com/" rel="">FreeRice</a><span> quiz. And if you want to form good habits, there’s </span><a href="https://habitshareapp.com/" rel="">Habitshare</a><span>, which lets your friends track your attempts, motivating you more than if you were only accountable to yourself.</span></p><p>But if, among the countless games out there, you can’t find one right for you, then you can just create your own. Fun is not the pursuit of happiness, but the happiness of pursuit, and literally anything can be pursued. By now there’s a way to keep any kind of score and play any kind of game.</p><p><span>Kaczynski’s game is over; he committed suicide last summer, still adamant humanity was doomed. His fearful legacy has since passed to his disciples, like Liverpool man Jacob Graham, who was </span><a href="https://news.sky.com/story/jacob-graham-left-wing-anarchist-jailed-for-13-years-over-terror-offences-after-declaring-he-wanted-to-kill-at-least-50-people-13097584" rel="">recently jailed</a><span> for terrorism after trying to emulate his idol. Graham may have thought he was saving the world, but, with all his talk of maximizing kill counts, he too was just playing a bad game.</span></p><p>In the end, Kaczynski and his followers made the same mistake as Skinner: they viewed us as mere puppets of our environment, devoid of agency and the ability to adapt. They needn’t have feared the world becoming a Skinner box, because, among all the papers written about that troublesome contraption, one fact is always omitted: Skinner’s pigeons only kept pecking the button because they were in a cage, with nothing else to do. But you are still free. Even in a world where everything is a game, you don’t have to play by other people’s rules; you have a wide open world to create your own.</p><p>Your move.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bringing Exchange Support to Thunderbird (251 pts)]]></title>
            <link>https://blog.thunderbird.net/2024/04/adventures-in-rust-bringing-exchange-support-to-thunderbird/</link>
            <guid>40100672</guid>
            <pubDate>Sat, 20 Apr 2024 20:19:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.thunderbird.net/2024/04/adventures-in-rust-bringing-exchange-support-to-thunderbird/">https://blog.thunderbird.net/2024/04/adventures-in-rust-bringing-exchange-support-to-thunderbird/</a>, See on <a href="https://news.ycombinator.com/item?id=40100672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<img src="https://blog.thunderbird.net/files/2024/04/Tb-rust1.png" alt="featured post title image">
						<section>
												

				
<p>Microsoft Exchange is a popular choice of email service for corporations and educational institutions, and so it’s no surprise that there’s demand among Thunderbird users to support Exchange. Until recently, this functionality was only available through an add-on. But, in the next ESR (Extended Support) release of Thunderbird in July 2024, we expect to provide this support natively within Thunderbird. Because of the size of this undertaking, the first roll-out of the Exchange support will <a href="https://youtu.be/7jNV1J2pdPc">initially cover only email</a>, with calendar and address book support coming at a later date.</p>



<p>This article will go into technical detail on how we are implementing support for the Microsoft Exchange Web Services mail protocol, and some idea of where we’re going next with the knowledge gained from this adventure.</p>



<p><em>Before we dive in, just a quick note that <strong>Brendan Abolivier, Ikey Doherty</strong>, and <strong>Sean Burke</strong> are the developers behind this effort, and are the authors of this post.</em></p>



<figure></figure>



<h2>Historical context</h2>



<p>Thunderbird is a long-lived project, which means there’s lots of old code. The current architecture for supporting mail protocols predates Thunderbird itself, having been developed more than 20 years ago as part of Netscape Communicator. There was also no paid maintainership from about 2012 — when Mozilla divested and&nbsp; transferred ownership of Thunderbird to its community — until 2017, when Thunderbird rejoined the Mozilla Foundation. That means years of ad hoc changes without a larger architectural vision and a lot of decaying C++ code that was not using modern standards.</p>



<p>Furthermore, in the entire 20 year lifetime of the Thunderbird project, no one has added support for a new mail protocol before. As such, no one has updated the architecture as mail protocols change and adapt to modern usage patterns, and a great deal of institutional knowledge has been lost. Implementing this much-needed feature is the first organization-led effort to actually understand and address limitations of Thunderbird’s architecture in an incremental fashion.</p>



<h2>Why we chose Rust</h2>



<p>Thunderbird is a large project maintained by a small team, so choosing a language for new work cannot be taken lightly. We need powerful tools to develop complex features relatively quickly, but we absolutely must balance this with long-term maintainability. Selecting Rust as the language for our new protocol support brings some important benefits:</p>



<ol>
<li><strong>Memory safety.</strong> Thunderbird takes input from anyone who sends an email, so we need to be diligent about keeping security bugs out.</li>



<li><strong>Performance.</strong> Rust runs as native code with all of the associated performance benefits.</li>



<li><strong>Modularity and Ecosystem.</strong> The built-in modularity of Rust gives us access to a large ecosystem where there are already a lot of people doing things related to email which we can benefit from.</li>
</ol>



<p>The above are all on the standard list of benefits when discussing Rust. However, there are some additional considerations for Thunderbird:</p>



<ol>
<li><strong>Firefox.</strong> Thunderbird is built on top of Firefox code and we use a shared CI infrastructure with Firefox which already enables Rust. Additionally, Firefox provides a language interop layer called XPCOM (Cross-Platform Component Object Model), which has Rust support and allows us to call between Rust, C++, and JavaScript.</li>



<li><strong>Powerful tools.</strong> Rust gives us a large toolbox for building APIs which are difficult to misuse by pushing logical errors into the domain of the compiler. We can easily avoid circular references or provide functions which simply cannot be called with values which don’t make sense, letting us have a high degree of confidence in features with a large scope. Rust also provides first-class tooling for documentation, which is critically important on a small team.</li>



<li><strong>Addressing architectural technical debt.</strong> Introducing a new language gives us a chance to reconsider some aging architectures while benefiting from a growing language community.</li>



<li><strong>Platform support and portability.</strong> Rust supports a broad set of host platforms. By building modular crates, we can reuse our work in other projects, such as Thunderbird for Android/K-9 Mail.</li>
</ol>



<h2>Some mishaps along the way</h2>



<p>Of course, the endeavor to introduce our first Rust component in Thunderbird is not without its challenges, mostly related to the size of the Thunderbird codebase. For example, there is a lot of existing code with idiosyncratic asynchronous patterns that don’t integrate nicely with idiomatic Rust. There are also lots of features and capabilities in the Firefox and Thunderbird codebase that don’t have any existing Rust bindings.</p>



<h3>The first roadblock: the build system</h3>



<p>Our first hurdle came with getting any Rust code to run in Thunderbird at all. There are two things you need to know to understand why:</p>



<p>First, since the Firefox code is a dependency of Thunderbird, you might expect that we pull in their code as a subtree of our own, or some similar mechanism. However, for historical reasons, it’s the other way around: building Thunderbird requires fetching Firefox’s code, fetching Thunderbird’s code as a subtree of Firefox’s, and using a build configuration file to point into that subtree.</p>



<p>Second, because Firefox’s entrypoint is written in C++ and Rust calls happen via an interoperability layer, there is no single point of entry for Rust. In order to create a tree-wide dependency graph for Cargo and avoid duplicate builds or version/feature conflicts, Firefox introduced a hack to generate a single Cargo workspace which aggregates all the individual crates in the tree.</p>



<p>In isolation, neither of these is a problem in itself. However, in order to build Rust into Thunderbird, we needed to define our own Cargo workspace which lives in our tree, and Cargo does not allow nesting workspaces. To solve this issue, we had to define our own workspace and add configuration to the upstream build tool, <code>mach</code>, to build from this workspace instead of Firefox’s. We then use a newly-added <code>mach</code> subcommand to sync our dependencies and lockfile with upstream and to vendor the resulting superset.</p>



<h3>XPCOM</h3>



<p>While the availability of language interop through XPCOM is important for integrating our frontend and backend, the developer experience has presented some challenges. Because XPCOM was originally designed with C++ in mind, implementing or consuming an XPCOM interface requires a lot of boilerplate and prevents us from taking full advantage of tools like rust-analyzer. Over time, Firefox has significantly reduced its reliance on XPCOM, making a clunky Rust+XPCOM experience a relatively minor consideration. However, as part of the previously-discussed maintenance gap, Thunderbird never undertook a similar project, and supporting a new mail protocol requires implementing hundreds of functions defined in XPCOM.</p>



<p>Existing protocol implementations ease this burden by inheriting C++ classes which provide the basis for most of the shared behavior. Since we can’t do this directly, we are instead implementing our protocol-specific logic in Rust and communicating with a bridge class in C++ which combines our Rust implementations (an internal crate called <code>ews_xpcom</code>) with the existing code for shared behavior, with as small an interface between the two as we can manage.</p>



<p>Please visit our&nbsp;<a href="https://source-docs.thunderbird.net/en/latest/rust/index.html" target="_blank" rel="noreferrer noopener">documentation</a>&nbsp;to learn more about how to create Rust components in Thunderbird.</p>



<h2>Implementing Exchange support with Rust</h2>



<p>Despite the technical hiccups experienced along the way, we were able to clear the hurdles, use, and build Rust within Thunderbird. Now we can talk about how we’re using it and the tools we’re building. Remember all the way back to the beginning of this blog post, where we stated that our goal is to support Microsoft’s Exchange Web Services (EWS) API. EWS communicates over HTTP with request and response bodies in XML.</p>



<h2>Sending HTTP requests</h2>



<p>Firefox already includes a full-featured HTTP stack via its <code>necko</code> networking component. However, <code>necko</code> is written in C++ and exposed over XPCOM, which as previously stated does not make for nice, idiomatic Rust. Simply sending a GET request requires a great deal of boilerplate, including nasty-looking unsafe blocks where we call into XPCOM. (XPCOM manages the lifetime of pointers and their referents, ensuring memory safety, but the Rust compiler doesn’t know this.) Additionally, the interfaces we need are callback-based. For making HTTP requests to be simple for developers, we need to do two things:</p>



<ol>
<li><strong>Support native Rust async/await syntax.</strong> For this, we added a new Thunderbird-internal crate, <code>xpcom_async</code>. This is a low-level crate which translates asynchronous operations in XPCOM into Rust’s native async syntax by defining callbacks to buffer incoming data and expose it by implementing Rust’s <code>Future</code> trait so that it can be awaited by consumers. (If you’re not familiar with the <code>Future</code> concept in Rust, it is similar to a JS <code>Promise</code> or a Python coroutine.)</li>



<li><strong>Provide an idiomatic HTTP API.</strong> Now that we had native <code>async</code>/<code>await</code> support, we created another internal crate (<code>moz_http</code>) which provides an HTTP client inspired by <code>reqwest</code>. This crate handles creating all of the necessary XPCOM objects and providing Rustic error handling (much nicer than the standard XPCOM error handling).</li>
</ol>



<h2>Handling XML requests and responses</h2>



<p>The hardest task in working with EWS is translating between our code’s own data structures and the XML expected/provided by EWS. Existing crates for serializing/deserializing XML didn’t meet our needs. <code>serde</code>’s data model doesn’t align well with XML, making distinguishing XML attributes and elements difficult. EWS is also sensitive to XML namespaces, which are completely foreign to <code>serde</code>. Various <code>serde</code>-inspired crates designed for XML exist, but these require explicit annotation of how to serialize every field. EWS defines hundreds of types which can have dozens of fields, making that amount of boilerplate untenable.</p>



<p>Ultimately, we found that existing <code>serde</code>-based implementations worked fine for deserializing XML into Rust, but we were unable to find a satisfactory tool for serialization. To that end, we introduced another new crate, <code>xml_struct</code>. This crate defines traits governing serialization behavior and uses Rust’s procedural derive macros to automatically generate implementations of these traits for Rust data structures. It is built on top of the existing <code>quick_xml</code> crate and designed to create a low-boilerplate, intuitive mapping between XML and Rust.&nbsp; While it is in the early stages of development, it does not make use of any Thunderbird/Firefox internals and is <a href="https://github.com/thunderbird/xml-struct-rs">available on GitHub</a>.</p>



<p>We have also introduced one more new crate, <code>ews</code>, which defines types for working with EWS and an API for XML serialization/deserialization, based on <code>xml_struct</code> and <code>serde</code>. Like <code>xml_struct</code>, it is in the early stages of development, but is <a href="https://github.com/thunderbird/ews-rs">available on GitHub</a>.</p>



<h2>Overall flow chart</h2>



<p>Below, you can find a handy flow chart to help understand the logical flow for making an Exchange request and handling the response.&nbsp;</p>



<figure><a href="https://blog.thunderbird.net/files/2024/04/pasted-image-.png"><img decoding="async" fetchpriority="high" width="1600" height="716" src="https://blog.thunderbird.net/files/2024/04/pasted-image-.png" alt="A bird's eye view of the flow" title="A bird’s eye view of the flow" srcset="https://blog.thunderbird.net/files/2024/04/pasted-image-.png 1600w, https://blog.thunderbird.net/files/2024/04/pasted-image--252x113.png 252w, https://blog.thunderbird.net/files/2024/04/pasted-image--600x269.png 600w, https://blog.thunderbird.net/files/2024/04/pasted-image--768x344.png 768w, https://blog.thunderbird.net/files/2024/04/pasted-image--1536x687.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></a></figure>



<p>Fig 1. A bird’s eye view of the flow</p>



<h2>What’s next?</h2>



<h2>Testing all the things</h2>



<p>Before landing our next major features, we are taking some time to build out our automated tests. In addition to unit tests, we just landed a mock EWS server for integration testing. The current focus on testing is already paying dividends, having exposed a couple of crashes and some double-sync issues which have since been rectified. Going forward, new features can now be easily tested and verified.</p>



<h2>Improving error handling</h2>



<p>While we are working on testing, we are also busy improving the story around error handling. EWS’s error behavior is often poorly documented, and errors can occur at multiple levels (e.g., a request may fail as a whole due to throttling or incorrect structure, or parts of a request may succeed while other parts fail due to incorrect IDs). Some errors we can handle at the protocol level, while others may require user intervention or may be intractable. In taking the time now to improve error handling, we can provide a more polished implementation and set ourselves up for easier long-term maintenance.</p>



<h2>Expanding support</h2>



<p>We are working on expanding protocol support for EWS (via <code>ews</code> and the internal <code>ews_xpcom</code> crate) and hooking it into the Thunderbird UI. Earlier this month, we landed a series of patches which allow adding an EWS account to Thunderbird, syncing the account’s folder hierarchy from the remote server, and displaying those folders in the UI. (At present, this alpha-state functionality is gated behind a build flag and a preference.) Next up, we’ll work on fetching message lists from the remote server as well as generalizing outgoing mail support in Thunderbird.</p>



<h2>Documentation</h2>



<p>Of course, all of our work on maintainability is for naught if no one understands what the code does. To that end, we’re producing documentation on how all of the bits we have talked about here come together, as well as describing the existing architecture of mail protocols in Thunderbird and thoughts on future improvements, so that once the work of supporting EWS is done, we can continue building and improving on the Thunderbird you know and love.</p>
				

			</section>
			

			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AltStore. The first Apple approved alternative App Store (141 pts)]]></title>
            <link>https://altstore.io/#Downloads</link>
            <guid>40100151</guid>
            <pubDate>Sat, 20 Apr 2024 19:17:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://altstore.io/#Downloads">https://altstore.io/#Downloads</a>, See on <a href="https://news.ycombinator.com/item?id=40100151">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <div data-collapse="medium" data-animation="default" data-duration="400" data-easing="ease" data-easing2="ease" role="banner">
        <p><a href="#"><img src="https://altstore.io/images/logo_text.png" alt="" width="124"></a></p>
      </div>
  
  <div><p>AltStore PAL now available!<br>Read the <a href="https://rileytestut.com/blog/2024/04/17/introducing-altstore-pal/" target="_blank">announcement</a>
    </p></div>
  <section>
    <h2>Sideloading for Everyone</h2>
    <p>Discover apps that push the boundaries of iOS.</p>
    
    <p><img src="https://altstore.io/images/Tuesday-23-Jan-2024-165319.png" srcset="https://altstore.io/images/Tuesday-23-Jan-2024-165319-p-500.png 500w, https://altstore.io/images/Tuesday-23-Jan-2024-165319-p-800.png 800w, https://altstore.io/images/Tuesday-23-Jan-2024-165319-p-1080.png 1080w, https://altstore.io/images/Tuesday-23-Jan-2024-165319.png 1339w" width="400" sizes="(max-width: 479px) 90vw, 400px" alt=""></p>
    
  </section>
  
  <div>
        <div>
          <h2>A New Way to Sideload</h2>
          <div><p>AltStore is an app store designed for sideloading. Every app in AltStore gets a beautifully generated store page with detailed information to make sideloading fun and easy. Browse apps from trusted developers, or add additional "sources" to further increase your options.</p><p> Plus, AltStore is made with security in mind. You can view a full list of an app's permissions from its store page, and AltStore will even automatically alert you if they change so you can sideload with confidence.</p></div>
          <p><a href="https://faq.altstore.io/" target="_blank">Learn More</a>
        </p></div><p><img src="https://altstore.io/images/DeltaStorePage.PNG" srcset="https://altstore.io/images/DeltaStorePage-p-500.png 500w, https://altstore.io/images/DeltaStorePage-p-800.png 800w, https://altstore.io/images/DeltaStorePage-p-1080.png 1080w, https://altstore.io/images/DeltaStorePage.PNG 1339w" width="350" sizes="(max-width: 479px) 90vw, 350px" alt="">
      </p></div>
  <div><p><img src="https://altstore.io/images/Monday-08-May-2023-162140.PNG" srcset="https://altstore.io/images/Monday-08-May-2023-162140-p-500.png 500w, https://altstore.io/images/Monday-08-May-2023-162140-p-800.png 800w, https://altstore.io/images/Monday-08-May-2023-162140-p-1080.png 1080w, https://altstore.io/images/Monday-08-May-2023-162140.PNG 1339w" width="350" sizes="(max-width: 479px) 90vw, 350px" alt=""></p><div>
          <h2>Self-Published Apps</h2>
          <div><p>Anyone can distribute their apps with AltStore. All you need is to make a “source”, which you can do by hosting a text file with basic information about your apps. Users can then enter your source URL in AltStore and your apps will automatically appear.</p><p>Follow our complete guide to create your own source and start distributing your apps in minutes!</p></div>
          <p><a href="https://faq.altstore.io/sources/make-a-source" target="_blank">Publish Apps</a>
        </p></div>
      </div>
  <div>
      <h2>By Indies — For Indies</h2>
      <div>
        <p><a id="w-node-a1c5e89b-ef5e-812c-23ad-c7315bcc8782-ed6becd7" href="https://mastodon.social/@rileytestut" target="_blank"><img src="https://altstore.io/images/spaces_Afe8qEztjcTjsjjaMBY2_uploads_UWT8nOrICxoO7OFmzKo0_Untitled.webp" srcset="https://altstore.io/images/spaces_Afe8qEztjcTjsjjaMBY2_uploads_UWT8nOrICxoO7OFmzKo0_Untitled-p-500.webp 500w, https://altstore.io/images/spaces_Afe8qEztjcTjsjjaMBY2_uploads_UWT8nOrICxoO7OFmzKo0_Untitled-p-800.webp 800w, https://altstore.io/images/spaces_Afe8qEztjcTjsjjaMBY2_uploads_UWT8nOrICxoO7OFmzKo0_Untitled-p-1080.webp 1080w, https://altstore.io/images/spaces_Afe8qEztjcTjsjjaMBY2_uploads_UWT8nOrICxoO7OFmzKo0_Untitled.webp 1500w" id="w-node-f271e8bc-a871-6e22-2967-dc732ff82ca8-ed6becd7" sizes="(max-width: 479px) 100vw, (max-width: 767px) 24vw, (max-width: 991px) 17vw, (max-width: 1439px) 19vw, 188px" alt=""></a></p><a id="w-node-_86a4c6a7-f9c4-ad13-f7bf-6e63b1079e20-ed6becd7" href="https://mastodon.social/@rileytestut" target="_blank">
          
        </a>
        <a id="w-node-e12031f2-99ee-5f24-ac27-ea8e62bab55b-ed6becd7" href="https://twitter.com/shanegillio">
          
        </a>
        <p><a id="w-node-_705f1323-e749-6403-8f86-b86a8cfd6f50-ed6becd7" href="https://twitter.com/shanegillio" target="_blank"><img src="https://altstore.io/images/shaneprof.webp" srcset="https://altstore.io/images/shaneprof-p-500.webp 500w, https://altstore.io/images/shaneprof-p-800.webp 800w, https://altstore.io/images/shaneprof-p-1080.webp 1080w, https://altstore.io/images/shaneprof.webp 1500w" id="w-node-a4aad372-35cc-e00f-45b1-66adc412ef93-ed6becd7" sizes="(max-width: 479px) 100vw, (max-width: 767px) 24vw, (max-width: 991px) 17vw, (max-width: 1439px) 19vw, 188px" alt=""></a>
      </p></div>
      
      <div><p>AltStore is an open-source project developed by a dedicated team of two. We are supported entirely by donations from our community and you can follow along with our progress on GitHub.</p><p>We’re continuously working on new updates for our apps, and you can try out in-development features by joining our Patreon.</p></div>
      <p><a href="https://www.patreon.com/rileyshane" target="_blank">Join Patreon</a>
    </p></div>
  <section id="Downloads">
    <h2><span>Downloads</span></h2>
    <p>AltStore, Delta, and Clip are properties of AltStore LLC and are in no way associated with Nintendo Co., Ltd. or Apple Inc.</p>
    <div>
        <p>AltStore PAL</p>
        <p>Available only in Europe. Requires iOS 17.4 or later.</p>
        <p><a href="https://buy.stripe.com/6oEg2u80z5vI0Mg4gg">€1.50/year + VAT</a></p><div><p>Your subscription covers Apple's Core Technology Fee, payment processing, and server costs.</p><p>Don't want to pay, or not in the EU? Download the version of AltStore below.</p></div>
      </div>
    <p>AltStore (World)</p>
    <p>Requires AltServer to install. Follow our step-by-step <a href="http://faq.altstore.io/">Install Guide</a>
    </p>
    
    <div>
      <p>“[AltStore] is clever, has been verified by other developers, and the service has an active community of thousands of users who side-load apps on their devices. For the past few weeks, I’ve been one of them.”</p>
      
    </div>
    
  </section>
  
  
  <div>
        <p data-w-id="c10f4652-e98c-37f6-51a6-bb8725682d07">
          <h2 data-w-id="0fb59a4f-6d90-2333-688a-b06b291420c6">Experience Apps like Never Before</h2>
          <h3 data-w-id="332883b0-f4e4-5f0a-bd2e-026003ed9cc2">AltStore allows apps to exist on iOS&nbsp;that may not otherwise. <br>‍<br>Apple doesn't allow all apps on their store, so AltStore gives those apps a chance.</h3>
        </p><p><img src="https://altstore.io/images/AltStore_Delta_StorePage.png" width="416" alt="" sizes="100vw" data-w-id="ae8b192f-4a13-e725-9af4-854638dc4268" loading="lazy" srcset="https://altstore.io/images/AltStore_Delta_StorePage-p-500.png 500w, https://altstore.io/images/AltStore_Delta_StorePage-p-800.png 800w, https://altstore.io/images/AltStore_Delta_StorePage-p-1080.png 1080w, https://altstore.io/images/AltStore_Delta_StorePage.png 1400w">
      </p></div>
  
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[My journey into personal computer software development in 1983 (125 pts)]]></title>
            <link>https://farrs.substack.com/p/my-journey-into-personal-computer</link>
            <guid>40099626</guid>
            <pubDate>Sat, 20 Apr 2024 18:29:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://farrs.substack.com/p/my-journey-into-personal-computer">https://farrs.substack.com/p/my-journey-into-personal-computer</a>, See on <a href="https://news.ycombinator.com/item?id=40099626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><a href="https://www.digistore24.com/redir/377301/aboel3z/" rel="nofollow ugc noopener">The Lost SuperFoods</a><span> 126 Forgotten Survival Foods That You can Stockpile for Years without Refrigeration.</span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg" width="800" height="533" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:533,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:35888,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0036f7a-20b2-4b32-9a8f-994b6be3630a_800x533.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>In 1983, Personal Computers were quite the up and coming thing. You could buy your own for a few thousand dollars. Though they were mostly considered toys by many East Coast programmers (more expensive "</span><strong><a href="https://amzn.to/3UrWfGb" rel="nofollow ugc noopener">workstations</a></strong><span>" were the rage), there had already been some interesting and promising applications developed for it.</span></p><p>I thought (along with a lot of other people) that these were definitely the thing of the future. I was considering a new job, so I decided to take a bit of a risk, and look for work writing Personal Computer Software.</p><p><span>I was able to get an interview at one of the top Personal Computer software development companies of the area. The company was called "Software Arts". It was the company of the creators of "</span><a href="https://en.wikipedia.org/wiki/VisiCalc#:~:text=VisiCalc%20(%22visible%20calculator%22),VisiCorp%20on%20October%2017%2C%201979." rel="nofollow ugc noopener">VisiCalc</a><span>", the original spreadsheet.</span></p><p><span>During the interview process, I actually met the creators of VisiCalc. People had scared me about one of them, </span><a href="https://en.wikipedia.org/wiki/Bob_Frankston" rel="nofollow ugc noopener">Bob Frankston</a><span>, as someone difficult to talk to, and quick to temper. But when I met him, I actually found a genuine pleasant programmer-type. His problem was that he didn't really internalize that he was one of the company bosses, and felt that he was just a super-cool programmer. As such, if he felt like yelling at you - it would be perfectly normal because, of course, if he was wrong - you would yell right back and tell him to stfu! The only problem was, as the company founder and chief programmer or something - nobody was actually going to yell back at him. But they would grumble a lot later on, thereby giving him a bad and undeserved reputation.</span></p><p><span>The work was one of those "improve performance" details. They were doing a version of VisiCalc for the newly emerged IBM PC. The program was "almost ready", but it wouldn't fit in the memory limit! If I recall correctly, the memory limit was 256K (that's K, not M) because the "</span><a href="https://amzn.to/3UaDPIJ" rel="nofollow ugc noopener">floppy disks</a><span>" could only hold that much.</span></p><p>Bob Frankston believed the program could be made to fit into the memory by using a "segmentation" strategy. Some people at Software Arts had given it a try, but had not been able to get much success or had decided the work was too boring. In any case, nobody wanted to do it, hence the job opening.</p><p>I heard out his ideas, and it made sense to me. They offered me a job with a 30% raise (I was working for Digital Equipment which was not known for best salaries) and I joined them.</p><p>Bob Frankston's ideas about segmentation were sound. As the original author of the program, he did have a good feel for VisiCalc code, and in fact I found it was very amenable to segmentation along the lines he had suggested.</p><p>So in 2-3 months, I was able to fit the program in the memory limits, with plenty of room to spare for new features.</p><p>That work having done, I became a regular part of the IBM PC VisiCalc team.</p><p>As I mentioned, the program was "almost ready". One of the "almost" parts involved the 256 K memory limit.</p><div><figure><a target="_blank" href="https://magfree-transform-3-in-1-fast.kckb.st/1319d68e" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif" width="695" height="366" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:366,&quot;width&quot;:695,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://magfree-transform-3-in-1-fast.kckb.st/1319d68e&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b09a678-0421-45ec-99ff-b5c8f5d6c5d9_695x366.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>There was another part to the "almost". The bug list of the program had over 600 items. Most of the original programmers on the VisiCalc team had moved on to "better" stuff (more about that later.) Christine S and Joe B were the remaining programmers. Even if they solved 1 bug a day, it would take 60 weeks to clear the bug list. The actual rate was not 1 bug a day, some bugs took many days in fact. Not a very happy situation -- but the </span><a href="https://amzn.to/3Q6UcED" rel="nofollow ugc noopener">Software Arts management</a><span> was already seeing VisiCalc as a "yesterday" thing. Dan Bricklin, a bright and friendly guy who had the original spreadsheet idea and then involved Bob Frankston for the coding, felt that since VisiCalc had already been done and they already owned the spreadsheet market, the best bet was to focus on more new ideas rather than wasting much resources on VisiCalc.</span></p><p>The management thought "TK!Solver", an algebra-type program, would be the next "spreadsheet" type revolution. So that's where the programmers that the company felt were the "best", went.</p><p>Which left two programmers on the VisiCalc team - Christine S and Joe B, and then also I, since I had finished the "segmentation" problem ahead of schedule.</p><p>Truth be told, the "segmentation" problem was indeed boring and routine after a while. So I was only too happy to get into something more exciting. Like, uh, bug-fixing.</p><p>The company had the perfect "bug" solving system as far as I was concerned. Nobody assigned you anything. You looked over the bug list, "checked out" a bug, solved it, and "checked in" the bug.</p><p>Naturally, the hairy bugs were left alone as nobody checked them out.</p><p>But being a natural programmer, I liked my bugs complex. The easy ones were good to perk me up while I finished my morning coffee, another entertaining couple by lunch, and then often I could get one or two more by the end of the day. So I started solving bugs at the rate of 5 or so, a day.</p><p>This caused problems.</p><p>The Quality Assurance staff was very happy. They were used to programmers trying to explain to them why something wasn't a bug, or telling them it would be solved any time soon, now. And here I was, announcing every day that these 3-5 bugs were off the list. Christine P, who was doing VisiCalc Quality Assurance, told me later on that when she saw my first email listing 5 solved bugs, she decided I had to be some kind of a fast-talker and fake. (I can't blame her, here were all these graduates of top technical universities, doing a bug maybe every two-three days, and here I was from a university known for liberal arts, claiming to have solved 5 in a day!) So with the intention to confront me and set me straight, she downloaded my fixes to her PC and checked those out. And what do you know, they were all indeed fixed!</p><p>VisiCalc management was happy. Other management was not. They didn't want much attention going to VisiCalc, the "old" program. (This was before anybody had heard of something called "Excel".)</p><p><span>Other programmers at Software Arts were also a problem. Software Arts had attracted a lot of highly talented pedigreed programmers. </span><a href="https://amzn.to/3Q6UcED" rel="nofollow ugc noopener">Software Arts</a><span> would not normally have even looked at someone of my credentials, had it not been for the fact that none of their highly talented programmers wanted to do any boring work.</span></p><p>Now it turned out, many of these super-programmers had quietly looked at some of the more complex VisiCalc bugs at some time in the past, and had wisely decided not to "check out" the bug. But being super-programmers, they were very annoyed that somebody from an unknown (programming-wise) university would come in and solve those complex bugs without breaking a sweat or without spending one single evening on the premises.</p><p>Besides my educational background, at that time Indians weren't particularly considered to be suitable software material. (Amazing how the world turns, eh?)</p><p>So mostly, the super-programmers were trying to resolve how I could have solved these bugs, since obviously I couldn't be very intelligent. Well, that is, no way was I intelligent in the same way they were intelligent.</p><p>While the super-programmers and the super-managers (I believe Tracy Licklider was the actual management person, Bricklin and Frankston were above the daily management issues) were trying to resolve this dilemma, I was happily and busily solving the bugs.</p><div><figure><a target="_blank" href="https://nomade-i-all-in-one-daily.kckb.st/4b05d669" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif" width="695" height="391" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:391,&quot;width&quot;:695,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://nomade-i-all-in-one-daily.kckb.st/4b05d669&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feea5bf1e-3d79-436a-abdb-87e232fb307b_695x391.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Within a few months, the bug-list was empty, and VisiCalc management was encouraged to add more features to VisiCalc. So I added Graphics capabilities to VisiCalc, Christine S added sorting features (I can't remember if Joe B had been moved to another "better" project by then, but he probably was, because he was "in-clique".)</p><p>So the product was finally ready to be released.</p><p>And then things came to a head.</p><p>VisiCorp, the marketing organization for VisiCalc, was significantly unhappy with the performance of the product. That's because there was a rival called 1-2-3 from Lotus. It didn't have as many features (for example, it drew crappy line drawings instead of filled-out pie charts) but ran faster and took less memory.</p><p>VisiCalc running slower and taking more memory had to do with some inside politics. The in-clique had decided that the program had to be written in Lisp. At that time, there were strong limits on how fast you could run with a language like Lisp, and it was also a memory hog. With segmentation, I had been able to get everything to fit, but just fitting wasn't very good.</p><p><span>To me, the solution was simple -- rewrite the whole thing in something called "assembly language". That's what everybody else was doing on the PC platform in those days. I had already chosen to write the Graphics in </span><a href="https://amzn.to/3UrdPdg" rel="nofollow ugc noopener">assembly language</a><span> (which is why the Graphics took very little memory and ran fast), and from my segmentation and bug-fixing work, I knew everything about everything else in the VisiCalc program. I could have easily rewritten the whole thing in assembly language in another 4-6 months if really encouraged. Without many bugs.</span></p><p>But turns out, nobody was going to encourage me, or even ask me!</p><p>As I mentioned earlier, Tracy Licklider and the super-programmer in-clique were busy trying to resolve the mysterious dilemma of how (a) I could be an Indian and not from a known programming school and (b) I could still fix bugs and add features at this amazing rate.</p><p><span>It looks like they had hit the </span><a href="https://amzn.to/4b4crTj" rel="nofollow ugc noopener">psych books</a><span> and all, because they had finally come up with a solution. Obviously, they had concluded, I was an "idiot savant". [An "idiot savant" is an idiot who happens to be mysteriously very gifted in a particular area, e.g. mathematical computations. Their conclusion was that because obviously I couldn't really be "intelligent", my seeming "intelligence" in solving bugs was a result of this "idiot savant" effect.]</span></p><p>Now, while the in-clique of the super-programmers and managers was busy dissing me, the other staff at the company had been noticing all this, and as a result, I had built an incredible support level among the non-programming staff. Non-management and non-programming personnel, such as quality assurance, accounting, sales, even front-desk, frequently sought me out to tell me about the good things they had heard about my work.</p><p>So the "idiot savant" declaration got back to me.</p><p>I suppose someone with a more combative attitude would have stayed on and fought this thing through, to get the respect he/she deserved.</p><p>I am not like that. Specially back then, I was very easygoing. While I could put in tremendous amount of work in something that I believed was worth doing, I just couldn't see the point of working the politics of it.</p><p>Being labeleld an "idiot savant" by the management in retaliation for having done some (what I thought to be) amazingly good work, frankly unnerved and annoyed me a lot.</p><p>My reaction was, I wanted to get the heck away from those crazies.</p><p>I knew many support staff liked me, but I was realistic enough to realize management and programming staff could cause much trouble for me, if they had an attitude like that.</p><p>So that was the end of my first brief foray into Personal Computer technology in the early 80s, as I went back into a familiar world of Workstations, Unix, and C programming.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why you Should Not Apply To YC (425 pts)]]></title>
            <link>https://twitter.com/dvassallo/status/1781751108211511680</link>
            <guid>40099585</guid>
            <pubDate>Sat, 20 Apr 2024 18:26:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/dvassallo/status/1781751108211511680">https://twitter.com/dvassallo/status/1781751108211511680</a>, See on <a href="https://news.ycombinator.com/item?id=40099585">Hacker News</a></p>
Couldn't get https://twitter.com/dvassallo/status/1781751108211511680: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Financial Market Applications of LLMs (217 pts)]]></title>
            <link>https://thegradient.pub/financial-market-applications-of-llms/</link>
            <guid>40099344</guid>
            <pubDate>Sat, 20 Apr 2024 18:03:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thegradient.pub/financial-market-applications-of-llms/">https://thegradient.pub/financial-market-applications-of-llms/</a>, See on <a href="https://news.ycombinator.com/item?id=40099344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>The AI revolution drove frenzied investment in both private and public companies and captured the public’s imagination in 2023. Transformational consumer products like ChatGPT are powered by Large Language Models (LLMs) that excel at modeling sequences of tokens that represent words or parts of words [2]. Amazingly, structural understanding emerges from learning next-token prediction, and agents are able to complete tasks such as translation, question answering and generating human-like prose from simple user prompts.</p><p>Not surprisingly, quantitative traders have asked: can we turn these models into the next price or trade prediction [1,9,10]? That is, rather than modeling sequences of words, can we model sequences of prices or trades. This turns out to be an interesting line of inquiry that reveals much about both generative AI and financial time series modeling. Be warned this will get wonky.</p><p>LLMs are known as autoregressive learners -- those using previous tokens or elements in a sequence to predict the next element or token. In quantitative trading, for example in strategies like statistical arbitrage in stocks, most research is concerned with identifying autoregressive structure. That means finding sequences of news or orders or fundamental changes that best predict future prices.</p><p>Where things break down is in the quantity and information content of available data to train the models. At the 2023 NeurIPS conference, Hudson River Trading, a high frequency trading firm, presented a comparison of the number of input tokens used to train GPT-3 with the amount of trainable tokens available in the stock market data per year HRT estimated that, with 3,000 tradable stocks, 10 data points per stock per day, 252 trading days per year, and 23400 seconds in a trading day, there are 177 billion stock market tokens per year available as market data. GPT-3 was trained on 500 billion tokens, so not far off [6].</p><figure><img src="https://thegradient.pub/content/images/2024/04/Screenshot-2024-04-18-at-3.11.18-PM.png" alt="" loading="lazy" width="2000" height="368" srcset="https://thegradient.pub/content/images/size/w600/2024/04/Screenshot-2024-04-18-at-3.11.18-PM.png 600w, https://thegradient.pub/content/images/size/w1000/2024/04/Screenshot-2024-04-18-at-3.11.18-PM.png 1000w, https://thegradient.pub/content/images/size/w1600/2024/04/Screenshot-2024-04-18-at-3.11.18-PM.png 1600w, https://thegradient.pub/content/images/2024/04/Screenshot-2024-04-18-at-3.11.18-PM.png 2356w" sizes="(min-width: 720px) 720px"><figcaption>numbers courtesy of HRT 2023 NeuRIPS presentation</figcaption></figure><p>But, in the trading context the tokens will be prices or returns or trades rather than syllables or words; the former is much more difficult to predict. Language has an underlying linguistic structure (e.g., grammar) [7]. It’s not hard to imagine a human predicting the next word in a sentence, however that same human would find it extremely challenging to predict the next return given a sequence of previous trades, hence the lack of billionaire day traders. The challenge is that there are very smart people competing away any signal in the market, making it <em>almost </em>efficient (“efficiently inefficient”, in the words of economist Lasse Pedersen) and hence unpredictable. No adversary actively tries to make sentences more difficult to predict — if anything, authors usually seek to make their sentences easy to understand and hence <em>more</em> predictable.</p><p>Looked at from another angle, there is much more noise than signal in financial data. Individuals and institutions are trading for reasons that might not be rational or tied to any fundamental change in a business. The GameStop episode in 2021 is one such example. Financial time series are also constantly changing with new fundamental information, regulatory changes, and occasional large macroeconomic shifts such as currency devaluations. Language evolves at a much slower pace and over longer time horizons.</p><p>On the other hand, there are reasons to believe that ideas from AI will work well in financial markets. One emerging area of AI research with promising applications to finance is multimodal learning [5], which aims to use different modalities of data, for example both images and textual inputs to build a unified model. With OpenAI’s DALL-E 2 model, a user can enter text and the model will generate an image. In finance, multi-modal efforts could be useful to combine information classical sources such as technical time series data (prices, trades, volumes, etc.) with alternative data in different modes like sentiment or graphical interactions on twitter, natural language news articles and corporate reports, or the satellite images of shipping activity in a commodity centric port. Here, leveraging multi-modal AI, one could potentially incorporate all these types of non-price information to predict well.</p><p>Another strategy called ‘residualization’ holds prominence in both finance and AI, though it assumes different roles in the two domains. &nbsp;In finance, structural `factor’ models break down the contemporaneous observations of returns across different assets into a shared component (the market return, or more generally returns of common, market-wide factors) and an idiosyncratic component unique to each underlying asset. Market and factor returns are difficult to predict and create interdependence, so it is often helpful to remove the common element when making predictions at the individual asset level and to maximize the number of independent observations in the data. </p><p>In residual network architectures such as transformers, there’s a similar idea that we want to learn a function h(X) of an input X, but it might be easier to learn the residual of h(X) to the identity map, i.e., h(X) – X. Here, if the function h(X) is close to identity, its residual will be close to zero, and hence there will be less to learn and learning can be done more efficiently. In both cases the goal is to exploit structure to refine predictions: in the finance case, the idea is to focus on predicting innovations beyond what is implied by the overall market, for residual networks the focus is on predicting innovations to the identity map.</p><p>A key ingredient for the impressive performance of LLMs work is their ability to discern affinities or strengths between tokens over long horizons known as context windows. In financial markets, the ability to focus attention across long horizons enables analysis of multi-scale phenomena, with some aspects of market changes explained across very different time horizons. For example, at one extreme, fundamental information (e.g., earnings) may be incorporated into prices over months, technical phenomena (e.g., momentum) might be realized over days, and, at the other extreme, microstructure phenomena (e.g., order book imbalance) might have a time horizon of seconds to minutes.</p><p>Capturing all of these phenomena involves analysis of multiple time horizons across the context window. However, in finance, prediction over multiple <em>future</em> time horizons is also important. For example, a quantitative system may seek to trade to profit from multiple different anomalies that are realized over multiple time horizons (e.g., simultaneously betting on a microstructure event and an earnings event). This requires predicting not just the next period return of the stock, but the entire term structure or trajectory of expected returns, while current transformer-style predictive models only look one period in the future.</p><p>Another financial market application of LLMs might be synthetic data creation [4,8]. This could take a few directions. Simulated stock price trajectories can be generated that mimic characteristics observed in the market and can be extremely beneficial given that financial market data is scarce relative to other sources as highlighted above in the number of tokens available. Artificial data could open the door for meta-learning techniques which have successfully been applied, for example, in robotics. In the robotic setting controllers are first trained using cheap but not necessarily accurate physics simulators, before being better calibrated using expensive real world experiments with robots. In finance the simulators could be used to coarsely train and optimize trading strategies. The model would learn high level concepts like risk aversion and diversification and tactical concepts such as trading slowly to minimize the price impact of a trade. Then precious real market data could be employed to fine-tune the predictions and determine precisely the optimal speed to trade.</p><figure><img src="https://thegradient.pub/content/images/2024/04/Screenshot-2024-04-18-at-3.08.44-PM.png" alt="" loading="lazy" width="2000" height="258" srcset="https://thegradient.pub/content/images/size/w600/2024/04/Screenshot-2024-04-18-at-3.08.44-PM.png 600w, https://thegradient.pub/content/images/size/w1000/2024/04/Screenshot-2024-04-18-at-3.08.44-PM.png 1000w, https://thegradient.pub/content/images/size/w1600/2024/04/Screenshot-2024-04-18-at-3.08.44-PM.png 1600w, https://thegradient.pub/content/images/size/w2400/2024/04/Screenshot-2024-04-18-at-3.08.44-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Financial market practitioners are often interested in extreme events, the times when trading strategies are more likely to experience significant gains or losses. Generative models where it’s possible to sample from extreme scenarios could find use. However extreme events by definition occur rarely and hence determining the right parameters and sampling data from the corresponding distribution is fraught.</p><p>Despite the skepticism that LLMs will find use in quantitative trading, they might boost fundamental analysis. As AI models improve, it’s easy to imagine them helping analysts refine an investment thesis, uncover inconsistencies in management commentary or find latent relationships between tangential industries and businesses [3]. Essentially these models could provide a Charlie Munger for every investor.</p><p>The surprising thing about the current generative AI revolution is that it’s taken almost everyone – academic researchers, cutting edge technology firms and long-time observers – by surprise. The idea that building bigger and bigger models would lead to emergent capabilities like we see today was totally unexpected and still not fully understood.</p><p>The success of these AI models has supercharged the flow of human and financial capital into AI, which should in turn lead to even better and more capable models. So while the case for GPT-4 like models taking over quantitative trading is currently unlikely, we advocate keeping an open mind. Expecting the unexpected has been a profitable theme in the AI business.</p><hr><h3 id="references">References</h3><ol><li>“Applying Deep Neural Networks to Financial Time Series Forecasting” Allison Koenecke. 2022</li><li>“<a href="https://scholar.google.com/scholar?oi=bibs&amp;cluster=2960712678066186980&amp;btnI=1&amp;hl=en">Attention is all you need</a>.” A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones… &nbsp;Advances in Neural Information Processing Systems, 2017</li><li>“Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models” . Lopez-Lira, Alejandro and Tang, Yuehua, (April 6, 2023) Available at SSRN</li><li>“<a href="https://scholar.google.com/scholar?oi=bibs&amp;cluster=8154893591177160457&amp;btnI=1&amp;hl=en">Generating Synthetic Data in Finance: Opportunities, Challenges and Pitfalls</a>.” SA Assefa, D Dervovic, M Mahfouz, RE Tillman… - Proceedings of the First ACM International Conference …, 2020</li><li>“GPT-4V(ision) System Card.” OpenAI. September 2023</li><li>“<a href="https://scholar.google.com/scholar?oi=bibs&amp;cluster=15953747982133883426&amp;btnI=1&amp;hl=en">Language models are few-shot learners</a>.” T Brown, B Mann, N Ryder, M Subbiah, JD Kaplan… - Advances in Neural Information Processing Systems, 2020</li><li>“Sequence to Sequence Learning with Neural Networks.” I.Sutskever,O.Vinyals,and Q.V.Le in Advances in Neural Information Processing Systems, 2014, pp. 3104–3112.</li><li>“Synthetic Data Generation for Economists”. A Koenecke, H Varian &nbsp;- arXiv preprint arXiv:2011.01374, 2020</li><li>C. C. Moallemi, M. Wang. A reinforcement learning approach to optimal execution. Quantitative Finance, 22(6):1051–1069, March 2022.</li><li>C. Maglaras, C. C. Moallemi, M. Wang. A deep learning approach to estimating fill probabilities in a limit order book. Quantitative Finance, 22(11):1989–2003, October 2022.</li></ol><h3 id="citation">Citation</h3><p>For attribution in academic contexts or books, please cite this work as</p><pre><code>Richard Dewey and Ciamac Moallemi, "Financial Market Applications of LLMs," The Gradient, 2024</code></pre><pre><code>@article{dewey2024financial,
    author = {Richard Dewey and Ciamac Moallemi},
    title = {Financial Market Applications of LLMs},
    journal = {The Gradient},
    year = {2024},
    howpublished = {\url{https://thegradient.pub/financial-market-applications-of-llms},
}</code></pre>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-reasoning tokens: teaching models to think ahead (146 pts)]]></title>
            <link>https://reasoning-tokens.ghost.io/reasoning-tokens/</link>
            <guid>40099252</guid>
            <pubDate>Sat, 20 Apr 2024 17:54:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reasoning-tokens.ghost.io/reasoning-tokens/">https://reasoning-tokens.ghost.io/reasoning-tokens/</a>, See on <a href="https://news.ycombinator.com/item?id=40099252">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p><a href="https://reasoning-tokens.ghost.io/author/felipe/">
                                <img src="https://www.gravatar.com/avatar/c7a32029edda420c1bff08b48f99b2cb?s=250&amp;r=x&amp;d=mp" alt="Felipe Sens Bonetto">
                            </a>
                </p>
                <div>
                    
                    <p><time datetime="2024-04-20">Apr 20, 2024</time>
                            <span><span>—</span> 4 min read</span>
                    </p>
                </div>
            </div><section>
            <p>What is the mathematical formulation of reasoning? How can we make LLMs like chatGPT think before they speak? And how can we make that baked into the model so it can learn to think in a self-supervised way without having to "explain it step by step" (or another famous prompt we use when we want to improve chatGPT performance drastically)? How can we teach models to think ahead? I will share with you the results of some experiments that may cast light on the path of "Reasoning Tokens."</p><p><strong>Introduction</strong></p><p>As the authors of <a href="https://arxiv.org/abs/2211.00593?ref=reasoning-tokens.ghost.io" rel="noreferrer">"Interpretability in the wild"</a> have taught us, from looking inside transformers, we know that the computation of the next token includes some information computed in previous steps.  This may seem obvious at first glance, but there is more to this affirmation than what meets the eye. This means the language model expends some internal "cognitive power" processing and storing information that will be used, not for predicting the very next token but 2, 3, or even 10 tokens ahead.</p><figure><img src="https://reasoning-tokens.ghost.io/content/images/2024/04/Screenshot-2024-04-20-at-12.11.57-AM.png" alt="" loading="lazy" width="1520" height="654" srcset="https://reasoning-tokens.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-20-at-12.11.57-AM.png 600w, https://reasoning-tokens.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-20-at-12.11.57-AM.png 1000w, https://reasoning-tokens.ghost.io/content/images/2024/04/Screenshot-2024-04-20-at-12.11.57-AM.png 1520w" sizes="(min-width: 720px) 720px"><figcaption><span>Internal computation of GPT-2, extracted from the "Interpretability in the wild" paper </span></figcaption></figure><p>As we can see from the image above, the attention heads produce computations that will be helpful only in the far future, and even some calculations that "headge" against the wrong answers, exposed in the paper as "Negative Name Mover Heads" or attention heads that suppress specific tokens.</p><figure><img src="https://reasoning-tokens.ghost.io/content/images/2024/04/Screenshot-2024-04-20-at-12.30.01-AM.png" alt="" loading="lazy" width="920" height="860" srcset="https://reasoning-tokens.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-20-at-12.30.01-AM.png 600w, https://reasoning-tokens.ghost.io/content/images/2024/04/Screenshot-2024-04-20-at-12.30.01-AM.png 920w" sizes="(min-width: 720px) 720px"><figcaption><span>Visual explanation extracted from the "Do Language Models Plan for Future Tokens?" paper</span></figcaption></figure><p>Further work has shown that LLMs indeed plan for future tokens. In the paper <a href="https://arxiv.org/abs/2404.00859?ref=reasoning-tokens.ghost.io" rel="noreferrer">"Do Language Models Plan for Future Tokens?"</a> the authors carefully crafted a mathematical formulation to impede what they call "Pre-Caching," or the ability of the model to make intermediary computations that would be useful beyond the very next token. Their experiments found a small performance gap when the model was "myopic" or incapable of planning for future tokens. This is promising but could be better. This indicates that while GPTs plan ahead, most of their power is used to predict only the next word in the sequence. As a sanity check, this gap should increase as the length of the predicted text grows because the model would have more tokens to produce said computations, and indeed, that was what they found in the paper.</p><p><strong>How do we leverage that?</strong></p><p>What if we incentivized those intermediary calculations, which are useful only in future tokens, teaching the model to think ahead in a self-supervised way? It turns out that the formulation for such a task doesn't need to be that complicated.</p><figure><img src="https://reasoning-tokens.ghost.io/content/images/2024/04/image-1.png" alt="" loading="lazy" width="1312" height="504" srcset="https://reasoning-tokens.ghost.io/content/images/size/w600/2024/04/image-1.png 600w, https://reasoning-tokens.ghost.io/content/images/size/w1000/2024/04/image-1.png 1000w, https://reasoning-tokens.ghost.io/content/images/2024/04/image-1.png 1312w" sizes="(min-width: 720px) 720px"><figcaption><span>Gradient flow of Reasoning tokens!</span></figcaption></figure><p>In this first experiment, we introduce <strong>reasoning tokens</strong>! The model will produce two tokens for each token in the original sequence. As usual, the first token will be used to predict the next token. The second token, however, duplicates the input of the first one and does not receive a gradient "answer" from the very next token, only from future tokens; in fact, this token doesn't even participate in the calculation of the very next token. This incentivizes the model to "pre-cache" or <em>only</em> put information that is useful for the future in this spot. <em>But talk is cheap. Show me the results.</em></p><figure><img src="https://reasoning-tokens.ghost.io/content/images/2024/04/image-3.png" alt="" loading="lazy" width="2000" height="918" srcset="https://reasoning-tokens.ghost.io/content/images/size/w600/2024/04/image-3.png 600w, https://reasoning-tokens.ghost.io/content/images/size/w1000/2024/04/image-3.png 1000w, https://reasoning-tokens.ghost.io/content/images/size/w1600/2024/04/image-3.png 1600w, https://reasoning-tokens.ghost.io/content/images/2024/04/image-3.png 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Mini GPT-2 (10M params) trained on 82M tokens.</span></figcaption></figure><p>And the results are very promising, showing a reduction of <strong>35% in the loss</strong>! From 0.621 to 0.401. The experiment also shows that the model benefits from having multiple tokens to do its "reasoning," forecasting the capability to form long-range dependencies. This validates the hypothesis that we can teach the models to plan for the future, an important first step to get to reasoning. </p><p>A GPT-2 Small (124M params) model was also trained on 300B tokens of the "Open Web Text Corpus," and its results were also very promising, resulting in a 0.04 validation loss reduction from 2.85 to 2.81. In context, going from GPT-2 Large (~700M) to GPT-2 XL (1.5B) drops the validation loss by 0.13 in the same dataset. All training code was derived from Andrej Karpathy amazing <a href="https://github.com/karpathy/nanoGPT/tree/master?ref=reasoning-tokens.ghost.io" rel="noreferrer">GPT-2 implementation</a>.</p><figure><img src="https://reasoning-tokens.ghost.io/content/images/2024/04/image-4.png" alt="" loading="lazy" width="1088" height="628" srcset="https://reasoning-tokens.ghost.io/content/images/size/w600/2024/04/image-4.png 600w, https://reasoning-tokens.ghost.io/content/images/size/w1000/2024/04/image-4.png 1000w, https://reasoning-tokens.ghost.io/content/images/2024/04/image-4.png 1088w" sizes="(min-width: 720px) 720px"><figcaption><span>GPT-2 Small trained on 300B params - 1 Reasoning token</span></figcaption></figure><p><strong>What is next for Reasoning Tokens?</strong></p><p>Currently, I'm experimenting with reasoning tokens in fine-tuned instruction following models, where planning can be much more useful. The formulation is very close to the first experiment. Still, this time, the model can choose when this internal reasoning will start, allowing it to choose when to reason before producing the next word in the sequence.</p><figure><img src="https://reasoning-tokens.ghost.io/content/images/2024/04/image-5.png" alt="" loading="lazy" width="1714" height="910" srcset="https://reasoning-tokens.ghost.io/content/images/size/w600/2024/04/image-5.png 600w, https://reasoning-tokens.ghost.io/content/images/size/w1000/2024/04/image-5.png 1000w, https://reasoning-tokens.ghost.io/content/images/size/w1600/2024/04/image-5.png 1600w, https://reasoning-tokens.ghost.io/content/images/2024/04/image-5.png 1714w" sizes="(min-width: 720px) 720px"><figcaption><span>Reasoning tokens in instruction tasks</span></figcaption></figure><p>The hypothesis being tested is that the addition of Reasoning Tokens can substitute and outperform models where a "step by step" explanation is included in the training phase. This would be useful because those explanations are expensive to produce/obtain. Although such explanations can be useful to the model, gradient descent could find other ways to do that reasoning using all the internal mathematical dimensions of the model in a way that does not necessarily make sense to us. It would be a great fit for "Mixture of Experts" (MoE) models, where we can have an expert just for the reasoning phase.</p><p>The future is bright. Stay tuned for the next advancements.</p>
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VLC vs. the App Stores (136 pts)]]></title>
            <link>https://mjtsai.com/blog/2024/04/19/vlc-vs-the-app-stores/</link>
            <guid>40098867</guid>
            <pubDate>Sat, 20 Apr 2024 17:15:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mjtsai.com/blog/2024/04/19/vlc-vs-the-app-stores/">https://mjtsai.com/blog/2024/04/19/vlc-vs-the-app-stores/</a>, See on <a href="https://news.ycombinator.com/item?id=40098867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><a href="https://twitter.com/videolan/status/1771104206872555660">VideoLAN</a> (via <a href="https://news.ycombinator.com/item?id=39798565">Hacker News</a>):</p>
<blockquote cite="https://twitter.com/videolan/status/1771104206872555660"><p>App Stores were a mistake.</p><p>Currently, we cannot update VLC on Windows Store, and we cannot update VLC on Android Play Store, without reducing security or dropping a lot of users…</p><p>For now, iOS App Store still allows us to ship for iOS9, but until when?</p></blockquote>

<p><a href="https://twitter.com/videolan/status/1759688788232523788">VideoLAN</a>:</p>
<blockquote cite="https://twitter.com/videolan/status/1759688788232523788"><p>If you do wonder why we don’t update VLC on the Windows Store or why VLC/iOS can’t connect properly to OneDrive shares, it’s because Microsoft Kafkaïesque bureaucracy refuses to help us.</p><p>We’re only trying to contact someone since 2years…</p></blockquote>

<p><a href="https://twitter.com/videolan/status/1771102415279763909">VideoLAN</a> (<a href="https://social.treehouse.systems/@Aissen/112139649840297169">Anisse</a>, <a href="https://news.ycombinator.com/item?id=39827828">Hacker News</a>):</p>
<blockquote cite="https://twitter.com/videolan/status/1771102415279763909"><p>If you wonder why we can’t update the VLC on Android version, it’s because Google refuses to let us update:</p><ul><li>either we give them our private signing keys,</li><li>or we drop support for Android TV before API-30, and all our users on TV API&lt;30 can’t get fixes.</li></ul></blockquote>

<p><a href="https://twitter.com/videolan/status/1771123709366943875">VideoLAN</a>:</p>
<blockquote cite="https://twitter.com/videolan/status/1771123709366943875">
<p>VLC cannot even enter the Mac App Store, because of the restrictions…</p>
</blockquote>

<p>Look at all those platforms competing to benefit users.</p>

<p><a href="https://twitter.com/Florian4Gamers/status/1778742764567429366">Florian Mueller</a>:</p>
<blockquote cite="https://twitter.com/Florian4Gamers/status/1778742764567429366"><p>This here is a European app store for Android and Google’s <a href="https://twitter.com/luishg/status/1778717325652341075">YouTube has just killed their channel</a>. It’s obviously a problem if you depend on the incumbent’s platforms all the way.</p></blockquote>

<p>Previously:</p>
<ul>
<li><a href="https://mjtsai.com/blog/2024/03/21/u-s-sues-apple-over-iphone-monopoly/">U.S. Sues Apple Over iPhone Monopoly</a></li>
<li><a href="https://mjtsai.com/blog/2021/07/01/google-sunsets-the-apk-format-for-new-android-apps/">Google Sunsets the APK Format for New Android Apps</a></li>
</ul><p><a rel="tag" href="https://mjtsai.com/blog/tag/android/">Android</a> <a rel="tag" href="https://mjtsai.com/blog/tag/appstore/">App Store</a> <a rel="tag" href="https://mjtsai.com/blog/tag/google-play-store/">Google Play Store</a> <a rel="tag" href="https://mjtsai.com/blog/tag/ios/">iOS</a> <a rel="tag" href="https://mjtsai.com/blog/tag/ios-17/">iOS 17</a> <a rel="tag" href="https://mjtsai.com/blog/tag/ios-9/">iOS 9</a> <a rel="tag" href="https://mjtsai.com/blog/tag/macapp/">Mac App</a> <a rel="tag" href="https://mjtsai.com/blog/tag/macappstore/">Mac App Store</a> <a rel="tag" href="https://mjtsai.com/blog/tag/macos-14-sonoma/">macOS 14 Sonoma</a> <a rel="tag" href="https://mjtsai.com/blog/tag/onedrive/">Microsoft OneDrive</a> <a rel="tag" href="https://mjtsai.com/blog/tag/vlc/">VLC</a> <a rel="tag" href="https://mjtsai.com/blog/tag/windows-store/">Windows Store</a> <a rel="tag" href="https://mjtsai.com/blog/tag/youtube/">YouTube</a></p>





















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Doing Cloud (112 pts)]]></title>
            <link>https://grski.pl/self-host</link>
            <guid>40098405</guid>
            <pubDate>Sat, 20 Apr 2024 16:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grski.pl/self-host">https://grski.pl/self-host</a>, See on <a href="https://news.ycombinator.com/item?id=40098405">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>STOP DOING CLOUD</h2>
<p>This will be a feisty juicy article, a bit controversial. I think more than a half of the users of the cloud/kubernetes would be better off without it. AWS should stand for <code>how to have people pay for our infra we need once per year during black friday and actually make money out of it</code>. Declouding is a nice trend I'm seeing now. 37signals have some good stuff on it. I'll ad my share as to why what has once been something cool has evolved into an abomination that often adds more complexity and problems than it brings, at least for some people. </p>
<p><img alt="meme about the cloud" src="https://grski.pl/static/articles/cloud/fools.png"></p>
<p>Sure it has it's uses at a certain scale and so on. The problem is almost no one is at such a scale and never will be, but we are blindly following a trend, pretending it's not the reality. </p>
<p>Why not try... Simplicty? Boring old stuff that just works, is easily debuggable and that even one person can grasp? </p>
<p>No your startup with 100k monthly users probably doesn't need all the stuff AWS excells at. To be honest most of you will be fine running a single dedicated bare-metal server.</p>
<p>Cloud pricing is unclear often, performance is not that dependable, especially on shared resources. To bring down costs you need to often sign up for long-term plans. So on so forth. Layers of abstractions upon abstractions.</p>
<p>I still do use the cloud in some of my work, but there's an alternative people have forgotten about - actually hosting your shit. Owning your data. Your architecture. Everything. Today I'll show you an example how we can do that. In this article we will go through setting up a self-hosted postgres instance, replicated/scalable API, load balancer, automatic ssl management, simple deployment that can be automated in 10 minutes and lastly, we will do that for under $200 per month and within 15 minutes. With this setup in some cases I'd argue you can handle up to 1M monthly active users without a hitch. See why the cloud providers and gurus have...</p>
<h2>They have played us for absolute fools.</h2>
<p>In the article I assume you have a server running somewhere. Preferable a dedicated one. In my case it's 80 core 128 gb hetzner, that I got for $200 per month.</p>
<p>Before starting let's install some utils we will need and update our server.</p>
<div><pre><span></span><code>sudo<span> </span>apt<span> </span>update<span> </span><span>&amp;&amp;</span><span> </span>sudo<span> </span>apt<span> </span>upgrade
sudo<span> </span>apt<span> </span>install<span> </span>gnupg2<span> </span>wget<span> </span>vim<span> </span>ca-certificates<span> </span>curl<span> </span>gnupg<span> </span>lsb-release
</code></pre></div>
<h2>Installing postgres</h2>
<h3>Installing needed packages</h3>
<div><pre><span></span><code>sudo<span> </span>sh<span> </span>-c<span> </span><span>'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" &gt; /etc/apt/sources.list.d/pgdg.list'</span>
curl<span> </span>-fsSL<span> </span>https://www.postgresql.org/media/keys/ACCC4CF8.asc<span> </span><span>|</span><span> </span>sudo<span> </span>gpg<span> </span>--dearmor<span> </span>-o<span> </span>/etc/apt/trusted.gpg.d/postgresql.gpg
sudo<span> </span>apt-get<span> </span>--purge<span> </span>remove<span> </span>postgresql<span> </span>postgresql-*<span> </span><span># IF YOU HAD POSTGRES PREVIOUSLY</span>
sudo<span> </span>apt<span> </span>update
sudo<span> </span>apt<span> </span>install<span> </span>postgresql-16<span> </span>postgresql-contrib-16
sudo<span> </span>systemctl<span> </span>start<span> </span>postgresql
sudo<span> </span>systemctl<span> </span><span>enable</span><span> </span>postgresql
</code></pre></div>
<p>Let's quickly walk through what we did here. We've added newest postgres repos so that our server knows what and where to install from. In case of ubuntu 22.04, the default postgres version that the distro repos come with is postgres 14. We want the new fancy shiny stuff, so we had to make that extra step.</p>
<p>Then, we optionally uninstall previous postgres versions. I doubt you had any, but adding this step as it might be helpful for some of you. Be careful though. That <code>--purge</code> thing will purge a lot of stuff. Your data from databases included. If you want to ugprade from existing postgres installation, this guide is not for you.</p>
<p>After that we update our sources and install postgres + some needed packages. </p>
<p>Lastly we start the postgresql service and make it enabled - so it boots after startup. </p>
<p>Now, we have to... Well, actually that's it. AWS marketers have done a good job in making you think installing and running a database was hard and a complex task. In some cases it is, indeed. But for the average IT Joe/startup? I wouldn't say so.</p>
<h3>Creating new database and user</h3>
<p>Now we need to do a little bit of setup on our database. In order to do that, let's connect to it using <code>psql</code>. How?</p>

<p>now you should see something like:</p>
<div><pre><span></span><code>psql<span> </span><span>(</span><span>16</span>.0<span> </span><span>(</span>Ubuntu<span> </span><span>16</span>.0-1.pgdg22.04+1<span>))</span>
Type<span> </span><span>"help"</span><span> </span><span>for</span><span> </span>help.

<span>postgres</span><span>=</span><span>#</span>
</code></pre></div>
<p>Boom. There we are. To test if our efforts in installing the newest postgres version have not failed, type:</p>
<div><pre><span></span><code><span>psql</span><span> </span><span>(</span><span>16</span><span>.</span><span>0</span><span> </span><span>(</span><span>Ubuntu</span><span> </span><span>16</span><span>.</span><span>0</span><span>-</span><span>1</span><span>.</span><span>pgdg22</span><span>.</span><span>04</span><span>+</span><span>1</span><span>))</span>
<span>Type</span><span> </span><span>"help"</span><span> </span><span>for</span><span> </span><span>help</span><span>.</span>

<span>postgres</span><span>=#</span><span> </span><span>SELECT</span><span> </span><span>version</span><span>();</span>
<span>                                                              </span><span>version</span>
<span>-----------------------------------------------------------------------------------------------------------------------------------</span>
<span> </span><span>PostgreSQL</span><span> </span><span>16</span><span>.</span><span>0</span><span> </span><span>(</span><span>Ubuntu</span><span> </span><span>16</span><span>.</span><span>0</span><span>-</span><span>1</span><span>.</span><span>pgdg22</span><span>.</span><span>04</span><span>+</span><span>1</span><span>)</span><span> </span><span>on</span><span> </span><span>x86_64</span><span>-</span><span>pc</span><span>-</span><span>linux</span><span>-</span><span>gnu</span><span>,</span><span> </span><span>compiled</span><span> </span><span>by</span><span> </span><span>gcc</span><span> </span><span>(</span><span>Ubuntu</span><span> </span><span>11</span><span>.</span><span>4</span><span>.</span><span>0</span><span>-</span><span>1</span><span>ubuntu1</span><span>~</span><span>22</span><span>.</span><span>04</span><span>)</span><span> </span><span>11</span><span>.</span><span>4</span><span>.</span><span>0</span><span>,</span><span> </span><span>64</span><span>-</span><span>bit</span>
<span>(</span><span>1</span><span> </span><span>row</span><span>)</span>
</code></pre></div>
<p>As you can see, <code>PostgreSQL 16.0</code>. Congrats, we made it brahs. </p>
<p>Currently you are inside your postgres, running as the default allmighty postgres user on postgres database. Now - we DO NOT EVER want to run our apps on this database. Don't be a lazy bum. It's a big security breach potentailly. So what do we do instead one might ask? That is a trivial question - we need to create a seprate database and a separate user for that database. Usually you have separate db (or multiple dbs actually) for an app/service couple with user just for that db.</p>
<p>That way if someone ever manages to break into your DB, in case you are hosting multiple dbs with data from multiple apps, they only get access to that one particular db. Is it hard? Nope. Check this out:</p>
<div><pre><span></span><code><span>postgres</span><span>=#</span><span> </span><span>CREATE</span><span> </span><span>DATABASE</span><span> </span><span>yourdbname</span><span>;</span>
<span>CREATE</span><span> </span><span>DATABASE</span>
<span>postgres</span><span>=#</span><span> </span><span>CREATE</span><span> </span><span>USER</span><span> </span><span>youruser</span><span> </span><span>WITH</span><span> </span><span>ENCRYPTED</span><span> </span><span>PASSWORD</span><span> </span><span>'yourpass'</span><span>;</span>
<span>CREATE</span><span> </span><span>ROLE</span>
<span>postgres</span><span>=#</span><span> </span><span>GRANT</span><span> </span><span>ALL</span><span> </span><span>PRIVILEGES</span><span> </span><span>ON</span><span> </span><span>DATABASE</span><span> </span><span>yourdbname</span><span> </span><span>TO</span><span> </span><span>youruser</span><span>;</span>
<span>GRANT</span>
<span>postgres</span><span>=#</span><span> </span><span>ALTER</span><span> </span><span>DATABASE</span><span> </span><span>yourdbname</span><span> </span><span>OWNER</span><span> </span><span>TO</span><span> </span><span>youruser</span><span>;</span>
<span>ALTER</span><span> </span><span>DATABASE</span>
</code></pre></div>
<p>We created a new user with a particular password, created a new database. Then we assigned the user privilages to perform all operations on said database, but only on that database.</p>
<p>The last line is needed because we created the database as the postgres user. Which means that while the user can perform actions on the database, he can only perform actions on the database objects that are his own. Because we created the database as the postgres user, and during db creation it gets created with some default schemas/tables, by default the owner of these is the user that created it. In our case - postgres. So other than allowing our new user to perform any action on the said database, we need to now make him an owner of the stuff that's already existing in the database so he can modify it too if needed, and it will be. </p>
<p>By the way interesting concept right? Even when you create an empty database, it's already populated with some stuff, so it ain't empty. IT, right?</p>
<p>That's pretty much it. Or is it? </p>
<h3>Connecting to postgres from outside of localhost</h3>
<p>Postgres, by default, only allows you to connect to itself from localhost/local machine to simplify. Meaning - any connections from other ips, networks etc. will be rejected. It's a very needed security measure that prevents random people from the internet to try and brute force their way into your database. That is the last thing you want.</p>
<p>However we live in a world where everything is running in a container. Containers have their own networks (usually) and when we make requests from inside of the container, the network we are in will be a bit different, meaning we won't be 'marked' as localhost, which in turn currently will make postgres reject our connection, even if we specify correct credentials.</p>
<p>I know it may sound tricky - how come, we are on the same machine, local machine. Why is our request treated as it isn't? This relats to how docker, containers and their networking works. Docker has it's own private network for all the stuff it does, sometimes sharing it with the host (in the host network mode) or having a 'bridge' that acts as a, well, bridge, between the local network and docker network, which allows you to, for example, call services hosted on the host machine, from within docker container.</p>
<p>This way you can have multiple docker containers or docker-composes running, some of which internally are using the same ports, without conflicts and so on. They are usually put in other networks created eg. per docker-compose (unless you specify otherwise).</p>
<p>It's a great thing, however in this case it complicates stuff for us, but not by much. What do we have to do?</p>
<p>Well, first of all, install docker! It'll come in handy, right?</p>
<h2>Installing docker on ubuntu 22.04</h2>
<p>First off, again - if you tried to install something before hand you might want to do this to purge everything and have a clean slate. Again - be careful.</p>
<div><pre><span></span><code>sudo<span> </span>apt<span> </span>remove<span> </span>docker-desktop
rm<span> </span>-r<span> </span><span>$HOME</span>/.docker/desktop
sudo<span> </span>rm<span> </span>/usr/local/bin/com.docker.cli
sudo<span> </span>apt<span> </span>purge<span> </span>docker-desktop
</code></pre></div>
<p>Once we have that, we will add new sources to our repos, this time for docker, similarly as we did for our postgres.</p>
<div><pre><span></span><code>curl<span> </span>-fsSL<span> </span>https://download.docker.com/linux/ubuntu/gpg<span> </span><span>|</span><span> </span>sudo<span> </span>gpg<span> </span>--dearmor<span> </span>-o<span> </span>/etc/apt/keyrings/docker.gpg
<span>echo</span><span> </span><span>\</span>
<span>  </span><span>"deb [arch=</span><span>$(</span>dpkg<span> </span>--print-architecture<span>)</span><span> signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \</span>
<span>  </span><span>$(</span>lsb_release<span> </span>-cs<span>)</span><span> stable"</span><span> </span><span>|</span><span> </span>sudo<span> </span>tee<span> </span>/etc/apt/sources.list.d/docker.list<span> </span>&gt;<span> </span>/dev/null
sudo<span> </span>apt<span> </span>update
</code></pre></div>
<p>Now, let's see what versions are available to us:</p>
<div><pre><span></span><code>apt-cache<span> </span>madison<span> </span>docker-ce<span> </span><span>|</span><span> </span>awk<span> </span><span>'{ print $3 }'</span>
<span>5</span>:24.0.6-1~ubuntu.22.04~jammy
<span>5</span>:24.0.5-1~ubuntu.22.04~jammy
<span>5</span>:24.0.4-1~ubuntu.22.04~jammy
<span>5</span>:24.0.3-1~ubuntu.22.04~jammy
<span>5</span>:24.0.2-1~ubuntu.22.04~jammy
<span>5</span>:24.0.1-1~ubuntu.22.04~jammy
<span>5</span>:24.0.0-1~ubuntu.22.04~jammy
<span>5</span>:23.0.6-1~ubuntu.22.04~jammy
<span>5</span>:23.0.5-1~ubuntu.22.04~jammy
<span>5</span>:23.0.4-1~ubuntu.22.04~jammy
<span>5</span>:23.0.3-1~ubuntu.22.04~jammy
<span>5</span>:23.0.2-1~ubuntu.22.04~jammy
<span>5</span>:23.0.1-1~ubuntu.22.04~jammy
<span>(</span>...<span>)</span>
</code></pre></div>
<p>I decided to go with the newest one, if you for some reason want to install another, feel free.</p>
<div><pre><span></span><code><span>VERSION_STRING</span><span>=</span><span>5</span>:24.0.6-1~ubuntu.22.04~jammy
sudo<span> </span>apt<span> </span>install<span> </span>docker-ce<span>=</span><span>$VERSION_STRING</span><span> </span>docker-ce-cli<span>=</span><span>$VERSION_STRING</span><span> </span>containerd.io<span> </span>docker-compose-plugin
</code></pre></div>
<p>aaand done. Let's test our docker installation.</p>
<div><pre><span></span><code>docker<span> </span>run<span> </span>hello-world
Unable<span> </span>to<span> </span>find<span> </span>image<span> </span><span>'hello-world:latest'</span><span> </span>locally
latest:<span> </span>Pulling<span> </span>from<span> </span>library/hello-world
719385e32844:<span> </span>Pull<span> </span><span>complete</span>
Digest:<span> </span>sha256:88ec0acaa3ec199d3b7eaf73588f4518c25f9d34f58ce9a0df68429c5af48e8d
Status:<span> </span>Downloaded<span> </span>newer<span> </span>image<span> </span><span>for</span><span> </span>hello-world:latest

Hello<span> </span>from<span> </span>Docker!
This<span> </span>message<span> </span>shows<span> </span>that<span> </span>your<span> </span>installation<span> </span>appears<span> </span>to<span> </span>be<span> </span>working<span> </span>correctly.

To<span> </span>generate<span> </span>this<span> </span>message,<span> </span>Docker<span> </span>took<span> </span>the<span> </span>following<span> </span>steps:
<span> </span><span>1</span>.<span> </span>The<span> </span>Docker<span> </span>client<span> </span>contacted<span> </span>the<span> </span>Docker<span> </span>daemon.
<span> </span><span>2</span>.<span> </span>The<span> </span>Docker<span> </span>daemon<span> </span>pulled<span> </span>the<span> </span><span>"hello-world"</span><span> </span>image<span> </span>from<span> </span>the<span> </span>Docker<span> </span>Hub.
<span>    </span><span>(</span>amd64<span>)</span>
<span> </span><span>3</span>.<span> </span>The<span> </span>Docker<span> </span>daemon<span> </span>created<span> </span>a<span> </span>new<span> </span>container<span> </span>from<span> </span>that<span> </span>image<span> </span>which<span> </span>runs<span> </span>the
<span>    </span>executable<span> </span>that<span> </span>produces<span> </span>the<span> </span>output<span> </span>you<span> </span>are<span> </span>currently<span> </span>reading.
<span> </span><span>4</span>.<span> </span>The<span> </span>Docker<span> </span>daemon<span> </span>streamed<span> </span>that<span> </span>output<span> </span>to<span> </span>the<span> </span>Docker<span> </span>client,<span> </span>which<span> </span>sent<span> </span>it
<span>    </span>to<span> </span>your<span> </span>terminal.

To<span> </span>try<span> </span>something<span> </span>more<span> </span>ambitious,<span> </span>you<span> </span>can<span> </span>run<span> </span>an<span> </span>Ubuntu<span> </span>container<span> </span>with:
<span> </span>$<span> </span>docker<span> </span>run<span> </span>-it<span> </span>ubuntu<span> </span>bash

Share<span> </span>images,<span> </span>automate<span> </span>workflows,<span> </span>and<span> </span>more<span> </span>with<span> </span>a<span> </span>free<span> </span>Docker<span> </span>ID:
<span> </span>https://hub.docker.com/

For<span> </span>more<span> </span>examples<span> </span>and<span> </span>ideas,<span> </span>visit:
<span> </span>https://docs.docker.com/get-started/
</code></pre></div>
<p>Seems to be working. How about <code>docker-compose</code>?</p>
<div><pre><span></span><code>docker-compose
Command<span> </span><span>'docker-compose'</span><span> </span>not<span> </span>found,<span> </span>but<span> </span>can<span> </span>be<span> </span>installed<span> </span>with:
apt<span> </span>install<span> </span>docker-compose
</code></pre></div>
<p>Not there, weird? Nope. Some of you might be still used to the old <code>docker-compose</code> thingy, however some time ago it got moved to be a part of the docker itself, which means that now instead of <code>docker-compose</code> you do:</p>
<div><pre><span></span><code>docker<span> </span>compose

Usage:<span>  </span>docker<span> </span>compose<span> </span><span>[</span>OPTIONS<span>]</span><span> </span>COMMAND

Define<span> </span>and<span> </span>run<span> </span>multi-container<span> </span>applications<span> </span>with<span> </span>Docker.
</code></pre></div>
<p>Alright! We set. Almost.</p>
<p>Currently, if you sshed on a clean server, which I assume you did, you are running as the root user. You can check this by typing:</p>

<p>The problem with that is similar to the situation with our postgres and the almighty postgres user. </p>
<p>Ideally, we do not want to run our containers as root, to prevent attackers from being able to do bad stuff to the whole server. Let's create a new user where we will be running our containers. You can have user per app or service, but not sure if you need that. Just not running on root is usually good enough.</p>
<p>How?</p>
<h3>Running docker on non-user or rootless docker</h3>
<p>That's all quite simple.</p>
<p>We need to create a new user, add it to the sudoers grup, set a password for it and lastly add it to the docker group. In our case we will create a prod user and then add it to the sudo group and docker group.</p>
<div><pre><span></span><code>sudo<span> </span>useradd<span> </span>prod
sudo<span> </span>usermod<span> </span>-aG<span> </span>sudo<span> </span>prod
sudo<span> </span>passwd<span> </span>prod
sudo<span> </span>usermod<span> </span>-aG<span> </span>docker<span> </span>docker
</code></pre></div>
<p>That's quite much it for now.</p>
<h3>Enabling docker containers to connect to host postgres</h3>
<p>The sane way. Some people deal with the issue described before, the one regarding connections from outside of localhost, by allowing <code>*</code> which means any and all networks/ips. This is a NO GO for production, really. The sane way is, as mentioned, to only allow specific networks. In our case docker network. How to do that?</p>
<p>We have to find out what is the local ip address that our docker network got assigned and simply allow traffic from that network to access. Sounds tricky, but ain't.</p>
<p>Now, before we proceed, I'm not that proficient in networking to be frank. Which means that my solution, while working, might not be the ideal one. Happy for feedback from someone more knowledgeable in the topic.</p>
<p>We want to add our docker network to those permitted inside our postgres. This implies we need to know the docker network address. How to get it?</p>
<div><pre><span></span><code>ip<span> </span>addr<span> </span><span>|</span><span> </span>grep<span> </span>docker
<span>3</span>:<span> </span>docker0:<span> </span>&lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt;<span> </span>mtu<span> </span><span>1500</span><span> </span>qdisc<span> </span>noqueue<span> </span>state<span> </span>DOWN<span> </span>group<span> </span>default
<span>    </span>inet<span> </span><span>172</span>.17.0.1/16<span> </span>brd<span> </span><span>172</span>.17.255.255<span> </span>scope<span> </span>global<span> </span>docker0
</code></pre></div>
<p><code>172.17.0.1</code> in this case is the network address we need. It'll probably be the same in your case, but doesn't have to be. Now that we have it, let's move on. How to edit postgres config?</p>
<p>First, my young padawan, we will need to find the location of our postgresql.conf file - which, surprisingly, is the file used to configure postgres.</p>
<p>We can do that with:</p>
<div><pre><span></span><code>sudo<span> </span>find<span> </span>/<span> </span>-type<span> </span>f<span> </span>-name<span> </span>postgresql.conf
/etc/postgresql/16/main/postgresql.conf
</code></pre></div>
<p>In my case it's in <code>/etc/postgresql/16/main/postgresql.conf</code>. The probability of it being the same for you, if you are running ubuntu 22.04 and followed this guide, as the probability of us living in a simulation or being at the beginning of an AI bubble. Get back to the topic Olaf. Gosh.</p>
<p>Okay, we know where the file is, we need to edit it. Type in:</p>
<div><pre><span></span><code>sudo<span> </span>vim<span> </span>/etc/postgresql/16/main/postgresql.conf
</code></pre></div>
<p>and look for <code>listen_addresses</code> part. In vim you can do a search by typing <code>/{phrase}</code> so <code>/listen_addresses</code> should navigate you to the proper line. In my case it looks like this:</p>
<div><pre><span></span><code><span>#</span><span>listen_addresses</span><span> </span><span>=</span><span> </span><span>'</span><span>localhost</span><span>'</span><span>         </span><span>#</span><span> </span><span>what</span><span> </span><span>IP</span><span> </span><span>address</span><span>(</span><span>es</span><span>)</span><span> </span><span>to</span><span> </span><span>listen</span><span> </span><span>on</span><span>;</span>
</code></pre></div>
<p>we need to uncomment the line and edit it so it allows connections from our docker network ip. So:</p>
<div><pre><span></span><code><span>listen_addresses</span><span> </span><span>=</span><span> </span><span>"localhost,172.17.0.1"</span>
</code></pre></div>
<p>then <code>:wq</code> and done.</p>
<p>Now we also need to edit <code>pg_hba.conf</code> to also allow this particular network to acces our database while authenticating with a password.</p>
<p>First let's find it:</p>
<div><pre><span></span><code>sudo<span> </span>find<span> </span>/<span> </span>-type<span> </span>f<span> </span>-name<span> </span>pg_hba.conf
/etc/postgresql/16/main/pg_hba.conf
</code></pre></div>
<p>and edit it with:</p>
<div><pre><span></span><code>sudo<span> </span>vim<span> </span>/etc/postgresql/16/main/pg_hba.conf
</code></pre></div>
<p>now again, navigate to a section containing "IPv4 local connections":</p>
<div><pre><span></span><code><span># IPv4 local connections:</span>
host<span>    </span>all<span>             </span>all<span>             </span><span>127</span>.0.0.1/32<span>            </span>scram-sha-256
<span># IPv6 local connections:</span>
host<span>    </span>all<span>             </span>all<span>             </span>::1/128<span>                 </span>scram-sha-256
</code></pre></div>
<p>we need to edit the IPv4 section to look like this:</p>
<div><pre><span></span><code><span># IPv4 local connections:</span>
host<span>    </span>all<span>             </span>all<span>             </span><span>127</span>.0.0.1/32<span>            </span>scram-sha-256
host<span>    </span>all<span>             </span>all<span>             </span><span>172</span>.17.0.0/16<span>           </span>scram-sha-256
</code></pre></div>
<p>What does the /16 after the netowrk address mean? Match the first 16 bytes of the address, so the 2 first. numbers, rest can change.</p>
<p>Now, let's restart our postgres.</p>
<div><pre><span></span><code>sudo<span> </span>/etc/init.d/postgresql<span> </span>restart
</code></pre></div>
<p>Important note. You might need to add something like this to your docker-compose:</p>
<div><pre><span></span><code><span>    </span><span>extra_hosts</span><span>:</span>
<span>      </span><span>-</span><span> </span><span>"host.docker.internal:172.17.0.1"</span>
</code></pre></div>
<p>For each service that will access it, and edit the connection string for postgres host to be: host.docker.internal. Either that or just use 172.17.0.1 value directly.</p>
<p>With docker and postgres set up, the world is yours to take. But is this it? I wouldn't be myself if i just ended with this. Let's take it up a notch. I mean we usually want to have something in front of our API, some reverse proxy, maybe capability to scale, have multiple replicas and so on. Performance and scaling stuff. Simple solution for that too.</p>
<h2>BUT MUH SCALABILITY, LOAD BALANCING, SSL and whatnot</h2>
<p>Ye I hear you, all the folks with 1k monthly active users, serving up to 2 requests per second, usually screaming about scalability the loudest. WHERE"S KUBERNETES? WHERE"S MY CLOUD SCALING STUFF, REEE!!one! AND THE DEVOPS TEAM? ARE YOU A FOOL?</p>
<p>I'll give you some love too, fret not.</p>
<p>For the database, the case is simple. With a dedicated bare metal server that I recommend you get, unless you do some horrendeous things in the schema or query, well, you can handle TONS of data &amp; traffic on a single machine.With just one instance of $200 ARM Hetzner with 80 dedicated cores, 128 GB of RAM, 2TB NVME PCIe SSD, how much more do you need in most cases? </p>
<p>Yeah, availability zones and so on, but let's take a step back. How many of you are truly running multi region &amp; multi availability zones DB deployments? HMMM? Thought so. Sorry to break it to you, but hype/conference driven development isn't the only way to go. I'd argue that at least 90-95% of current startups could probably run just fine with this single instance only. Okay, maybe some of you would need something like S3 (Cloudflare R2 maybe?). Outgrowing this setup will probably mean you already got enough tracton, customers and money to actually start your own colocation thingy with a dedicated team. Backups? Survavibility? We'll talk about that part later.</p>
<p>So, in this post, we won't cover how to horizontally scale the db, as I think it's simply not needed for the audience i target this too. What is needed though, is probably replication of the apis/scaling them and then reverse proxy/managing ssl/load balancing. That's what we will do. Let's start with replicating our api to an arbitrary size. How can we do that?</p>
<p>Docker-compose lol.</p>
<h2>Ditch Kubernetes, docker compose for the win</h2>
<p>This part will be quite short, sweet and simple. Probably not many of you know, but docker compose supports replication out of the box. Why wouldn't it. How do we go about it?</p>
<div><pre><span></span><code><span>  </span><span>api</span><span>:</span>
<span>    </span><span>build</span><span>:</span>
<span>      </span><span>context</span><span>:</span><span> </span><span>.</span>
<span>    </span><span>depends_on</span><span>:</span>
<span>      </span><span>database</span><span>:</span>
<span>        </span><span>condition</span><span>:</span><span> </span><span>service_healthy</span>
<span>    </span><span>restart</span><span>:</span><span> </span><span>always</span>
<span>    </span><span>deploy</span><span>:</span>
<span>      </span><span>replicas</span><span>:</span><span> </span><span>4</span>
<span>    </span><span>ports</span><span>:</span>
<span>      </span><span>-</span><span> </span><span>"8000-8003:8000"</span>
</code></pre></div>
<p>the key part here being:</p>
<div><pre><span></span><code><span>    </span><span>deploy</span><span>:</span>
<span>      </span><span>replicas</span><span>:</span><span> </span><span>4</span>
<span>    </span><span>ports</span><span>:</span>
<span>      </span><span>-</span><span> </span><span>"8000-8003:8000"</span>
</code></pre></div>
<p>after that, just do <code>docker compose up</code>. And then boom. You done. Multiple replicas of your api service up and running. With 4 lines of code, 2 of them you already probably have in your code.</p>
<p>Remember what we said - we do not want to run docker as root, so ssh/login into the user we created <code>prod</code> for this purpose.</p>
<p>once you there, just clone the repo and docker compose up.</p>
<p>You'll be amazed how fast the deployments can happen. Also about the secrets. 1password offers some nice options here for such use cases, or in fact, you can even just create .env file, specify it in the docker-compose and be done with it.</p>
<p>Logs can be easily checked with a simple <code>docker compose logs</code> + docker saves them to a file iether way.</p>
<p>But, what about load balancing, reverse proxy and ssl stuff? </p>
<h2>Load Balancing &amp; automatic ssl with Caddyserver</h2>
<p>We will use caddyserver to act as a reverse proxy, load balancer and to automatically take care of the certificates for us. It's a bit less performant than nginx, true, but the ease of use and convenience it provides is well worth it. That plus usually it's not the proxy that will die first. Quite the opposite.</p>
<p>So how do we go about this? Probably complicated? Nope.</p>
<p>We will let ansible handle all the work for us. Ansible? Yes, you read that right. Not terraform.</p>
<p>In order to do that we will need to create a new user for our ansible to run on, enable ssh access and do a bit of ansible dev. Let's go. You already know the drill.</p>
<div><pre><span></span><code>sudo<span> </span>useradd<span> </span>ingres
sudo<span> </span>passwd<span> </span>ingres
sudo<span> </span>usermod<span> </span>-aG<span> </span>sudo<span> </span>ingres
</code></pre></div>
<p>Now, a small change to what we did before.</p>
<p>We make sure our user can do sudo operations without password. How?</p>

<p>then find this piece:</p>
<div><pre><span></span><code><span># User privilege specification</span>
root<span>    </span><span>ALL</span><span>=(</span>ALL:ALL<span>)</span><span> </span>ALL
</code></pre></div>
<p>and add this below (or at the bottom of the file):</p>
<div><pre><span></span><code>ingres<span> </span><span>ALL</span><span>=(</span>ALL<span>)</span><span> </span>NOPASSWD:<span> </span>ALL
</code></pre></div>
<p>We could be more granular about permissions here and what it has access to, but that could come in a 2nd iteration, I consider this good enough.</p>
<p>Let's enable SSH access now. This might not be needed on your machine, depends on the server. I had to do it on my hetzner.</p>
<p>We need to edit the sshd_config file. How to find where it is? You should know by now ;) </p>

<p>and find something like this:</p>
<div><pre><span></span><code><span>#AuthorizedKeysFile      .ssh/authorized_keys</span>
</code></pre></div>
<p>turn it into:</p>
<div><pre><span></span><code>AuthorizedKeysFile<span>      </span>.ssh/authorized_keys
AllowUsers<span> </span>root<span> </span>prod<span> </span>dev
</code></pre></div>
<p>add your ssh key to <code>/home/ingres/.ssh/authorized_keys</code> in order to do that and eg. add the same ssh key you use for your root account (not ideal):</p>
<p>```bashand lastly:
su ingres # we switch the user to make it the owner of the directory we create
mkdir -p /home/ingres/.ssh
cat ~/.ssh/authorized_keys &gt; /home/ingres/.ssh/authorized_keys</p>
<div><pre><span></span><code>aaand lastly:

```bash
service sshd restart
</code></pre></div>
<p>Setup done. Time to install caddy with ansible. But before that, we need to setup ansible.</p>
<p>I'll assume you have pyenv installed and set up running on your local machine. You can read about that <a href="https://grski.pl/pyenv-en">here</a> in my article, or <a href="https://grski.pl/pdf-brag">here</a>.</p>
<p>With that we can:</p>
<div><pre><span></span><code>pyenv<span> </span>virtualenv<span> </span><span>3</span>.11<span> </span>infrastructure-deployment-3-11
mkdir<span> </span>infrastructure-deployment
<span>cd</span><span> </span>infrastructure-deployment
pyenv<span> </span><span>local</span><span> </span>infrastructure-deployment-3-11
python<span> </span>-m<span> </span>pip<span> </span>install<span> </span>ansible
</code></pre></div>
<p>Pyenv set up. Ansible set up. We will need one more thing - install custom role from ansible galaxy.</p>
<div><pre><span></span><code>python<span> </span>-m<span> </span>ansible<span> </span>galaxy<span> </span>role<span> </span>install<span> </span>caddy_ansible.caddy_ansible<span>  </span>
</code></pre></div>
<p>Now inside our <code>infrastructure-deployment</code> directory on our local machine create a file called <code>inventory.yml</code></p>
<div><pre><span></span><code><span>all</span><span>:</span>
<span>  </span><span>hosts</span><span>:</span>
<span>    </span><span>bare-metal-hetzner</span><span>:</span>
<span>      </span><span>ansible_host</span><span>:</span><span> </span><span>"your-host-ip"</span>
<span>      </span><span>ansible_user</span><span>:</span><span> </span><span>"ingres"</span>
<span>      </span><span>ansible_port</span><span>:</span><span> </span><span>22</span>
</code></pre></div>
<p>aaand <code>caddy_install.yml</code>:</p>
<div><pre><span></span><code><span>---</span>
<span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>Install Caddy Server</span>
<span>  </span><span>hosts</span><span>:</span><span> </span><span>all</span>
<span>  </span><span>become</span><span>:</span><span> </span><span>true</span>
<span>  </span><span>roles</span><span>:</span>
<span>     </span><span>-</span><span> </span><span>role</span><span>:</span><span> </span><span>caddy_ansible.caddy_ansible</span>
<span>       </span><span>caddy_conf_filename</span><span>:</span><span> </span><span>Caddyfile</span>
<span>       </span><span>caddy_update</span><span>:</span><span> </span><span>true</span>
<span>       </span><span>caddy_systemd_capabilities_enabled</span><span>:</span><span> </span><span>true</span>
<span>       </span><span>caddy_systemd_capabilities</span><span>:</span><span> </span><span>"CAP_NET_BIND_SERVICE"</span>
<span>       </span><span>caddy_config</span><span>:</span><span> </span><span>|</span>
<span>        </span><span>your-fancy-startup-domain.com {                 </span>
<span>          </span><span># Compress responses according to Accept-Encoding headers</span>
<span>          </span><span>encode gzip zstd</span>

<span>          </span><span># Send API requests to backend</span>
<span>          </span><span>reverse_proxy 127.0.0.1:8000 127.0.0.1:8301 127.0.0.1:8302 127.0.0.1:8303</span>
<span>        </span><span>}</span>
</code></pre></div>
<p>run </p>
<div><pre><span></span><code>python<span> </span>-m<span> </span>ansible<span> </span>playbook<span> </span>-i<span> </span>inventory.yml<span> </span>caddy_install.yml<span>   </span>
</code></pre></div>
<p>aaand done.</p>
<p>Now if you go to your-fancy-startup-domain.com, given that proper docker containers are running, you'll get them.</p>
<p>Automatic SSL. Automatic load balancing. EVERYTHING WORKS.</p>
<h2>BACKUPS, SURVAVIBILITY</h2>
<p>You can have hourly backups with BorgBackup. How? Brilliant tutorial can be found in <a href="https://community.hetzner.com/tutorials/install-and-configure-borgbackup">hetzner docs</a>. Go read them.</p>
<p>On top of that add $4 1 TB <a href="https://www.hetzner.com/storage/storage-box">Hetzner Storage Box</a> linked to your server. Boom. Done. You might want to think about adding pg_dump, but IMO just the BorgBackup for starters is ok.</p>
<p>My borg-backup script looks more or less like this:</p>
<div><pre><span></span><code><span>    </span><span>#!/bin/sh</span>
<span># First init the repo</span>
<span># ssh -p23 ssh://xxxxx.your-storagebox.de mkdir /home/backup</span>
<span># ssh -p23 ssh://<a href="https://grski.pl/cdn-cgi/l/email-protection" data-cfemail="4830303030300830303030306631273d3a653b3c273a292f2d2a2730662c2d">[email&nbsp;protected]</a> mkdir /home/backup/main</span>
<span># borg init --encryption=repokey ssh://<a href="https://grski.pl/cdn-cgi/l/email-protection" data-cfemail="a6dededededee6dedededede88dfc9d3d48bd5d2c9d4c7c1c3c4c9de88c2c3">[email&nbsp;protected]</a>:23/~/backup/main</span>
<span># Setting this, so the repo does not need to be given on the commandline:</span>
<span>export</span><span> </span><span>BORG_REPO</span><span>=</span>ssh://<a href="https://grski.pl/cdn-cgi/l/email-protection" data-cfemail="245c645c0a5d4b51560957504b56454341464b5c0a4041">[email&nbsp;protected]</a>:23/~/backup/main

<span># See the section "Passphrase notes" for more infos.</span>
<span>export</span><span> </span><span>BORG_PASSPHRASE</span><span>=</span>

<span># some helpers and error handling:</span>
info<span>()</span><span> </span><span>{</span><span> </span><span>printf</span><span> </span><span>"\n%s %s\n\n"</span><span> </span><span>"</span><span>$(</span><span> </span>date<span> </span><span>)</span><span>"</span><span> </span><span>"</span><span>$*</span><span>"</span><span> </span>&gt;<span>&amp;</span><span>2</span><span>;</span><span> </span><span>}</span>
<span>trap</span><span> </span><span>'echo $( date ) Backup interrupted &gt;&amp;2; exit 2'</span><span> </span>INT<span> </span>TERM

info<span> </span><span>"Starting backup"</span>

<span># Backup the most important directories into an archive named after</span>
<span># the machine this script is currently running on:</span>

borg<span> </span>create<span>                         </span><span>\</span>
<span>    </span>--verbose<span>                       </span><span>\</span>
<span>    </span>--filter<span> </span>AME<span>                    </span><span>\</span>
<span>    </span>--list<span>                          </span><span>\</span>
<span>    </span>--stats<span>                         </span><span>\</span>
<span>    </span>--show-rc<span>                       </span><span>\</span>
<span>    </span>--compression<span> </span>lz4<span>               </span><span>\</span>
<span>    </span>--exclude-caches<span>                </span><span>\</span>
<span>    </span>--exclude<span> </span><span>'home/*/.cache/*'</span><span>     </span><span>\</span>
<span>    </span>--exclude<span> </span><span>'var/tmp/*'</span><span>           </span><span>\</span>
<span>    </span>--exclude<span> </span><span>'*__pycache__*'</span><span>       </span><span>\</span>
<span>    </span>--exclude<span> </span><span>'*.pyenv*'</span><span>            </span><span>\</span>
<span>                                    </span><span>\</span>
<span>    </span>::<span>'{hostname}-{now}'</span><span>            </span><span>\</span>
<span>    </span>/etc<span>                            </span><span>\</span>
<span>    </span>/home<span>                           </span><span>\</span>
<span>    </span>/root<span>                           </span><span>\</span>
<span>    </span>/var

<span>backup_exit</span><span>=</span><span>$?</span>

info<span> </span><span>"Pruning repository"</span>

<span># Use the `prune` subcommand to maintain 7 daily, 4 weekly and 6 monthly</span>
<span># archives of THIS machine. The '{hostname}-*' matching is very important to</span>
<span># limit prune's operation to this machine's archives and not apply to</span>
<span># other machines' archives also:</span>

borg<span> </span>prune<span>                          </span><span>\</span>
<span>    </span>--list<span>                          </span><span>\</span>
<span>    </span>--glob-archives<span> </span><span>'{hostname}-*'</span><span>  </span><span>\</span>
<span>    </span>--show-rc<span>                       </span><span>\</span>
<span>    </span>--keep-daily<span>    </span><span>7</span><span>               </span><span>\</span>
<span>    </span>--keep-weekly<span>   </span><span>4</span><span>               </span><span>\</span>
<span>    </span>--keep-monthly<span>  </span><span>6</span>

<span>prune_exit</span><span>=</span><span>$?</span>

<span># actually free repo disk space by compacting segments</span>

info<span> </span><span>"Compacting repository"</span>

borg<span> </span>compact

<span>compact_exit</span><span>=</span><span>$?</span>

<span># use highest exit code as global exit code</span>
<span>global_exit</span><span>=</span><span>$((</span><span> </span><span>backup_exit</span><span> </span><span>&gt;</span><span> </span><span>prune_exit</span><span> </span>?<span> </span><span>backup_exit</span><span> </span>:<span> </span><span>prune_exit</span><span> </span><span>))</span>
<span>global_exit</span><span>=</span><span>$((</span><span> </span><span>compact_exit</span><span> </span><span>&gt;</span><span> </span><span>global_exit</span><span> </span>?<span> </span><span>compact_exit</span><span> </span>:<span> </span><span>global_exit</span><span> </span><span>))</span>

<span>if</span><span> </span><span>[</span><span> </span><span>${</span><span>global_exit</span><span>}</span><span> </span>-eq<span> </span><span>0</span><span> </span><span>]</span><span>;</span><span> </span><span>then</span>
<span>    </span>info<span> </span><span>"Backup, Prune, and Compact finished successfully"</span>
<span>elif</span><span> </span><span>[</span><span> </span><span>${</span><span>global_exit</span><span>}</span><span> </span>-eq<span> </span><span>1</span><span> </span><span>]</span><span>;</span><span> </span><span>then</span>
<span>    </span>info<span> </span><span>"Backup, Prune, and/or Compact finished with warnings"</span>
<span>else</span>
<span>    </span>info<span> </span><span>"Backup, Prune, and/or Compact finished with errors"</span>
<span>fi</span>

<span>exit</span><span> </span><span>${</span><span>global_exit</span><span>}</span>
</code></pre></div>
<p>To run it periodically type in <code>crontab -e</code></p>
<p>and then</p>
<div><pre><span></span><code><span>00</span><span> </span><span>2</span><span> </span>*<span> </span>*<span> </span>*<span> </span>/root/borg-backup.sh
</code></pre></div>
<h2>Potential improvements</h2>
<p>Ofcourse the permissions here and there could be more fine-grained for sure. </p>
<p>We could also add a bastion in front of the server. </p>
<p>Automate the deployment so that after each merge stuff gets built &amp; deployed. </p>
<p>Add monitoring, observability, alerts. (Ain't that hard tbh, we will explore that one day)</p>
<p>There's much more than that ofcourse but these are the starters.</p>
<h2>Summary</h2>
<p>We have set up: </p>
<ol>
<li>self-hosted postgres instance with passable initail configuration</li>
<li>replicated api-service with as many replicas as we want</li>
<li>proper load balancing and reverse proxy in front of them</li>
<li>https everywhere</li>
<li>proper certifcates, all handled automatically</li>
<li>1 click deployment of our reverse proxy</li>
<li>blazing fast deployments/build times in the future (for now manual, but can easily be automated)</li>
<li>ability to potentially handle hundreds of thousands of users</li>
<li>very predictable cost &amp; performance</li>
<li>regular FULL backups</li>
<li>no additional deployment code</li>
<li>Absolutely stunning performance with 80 dedicated cores, 128 gb of ram, 2 TB NVMe SSD (you'd be amazed)</li>
</ol>
<p>What more can I say. Cloud IS NOT the solution for everything. Sometimes you can try the alternative path.</p>
<p>Similar setup on AWS would be probably $6-10k upwards just for the postgres. That plus it wouldn't match the performance we have here. One thing not covered here is how much performance you gain when all the services are within one network. No calls outside your network == blazing fast shit.</p>
<p>All of this in 15 minutes and for $200 monthly. </p>
<p>Want some copium cloud bro? </p>
<p>Ofcourse this doesn't adhere to some of you and your companies, but you know that. I've simplified lots of things or generlised. However, for the general public and their needs, I think it's worth rethink the whole cloud sometimes.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Doomscroller.xyz (375 pts)]]></title>
            <link>https://doomscroller.xyz/</link>
            <guid>40098178</guid>
            <pubDate>Sat, 20 Apr 2024 15:40:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doomscroller.xyz/">https://doomscroller.xyz/</a>, See on <a href="https://news.ycombinator.com/item?id=40098178">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <center>
      <p><img src="https://doomscroller.xyz/static/Header.PNG" alt="Header Image">
    </p>
    <!-- <p class="logo-text">Doomscroller</p> -->

    <div>
        <div>
            <p>What does it do???   </p>
            <p>this and <br> only this.  </p>
            <p><img src="https://doomscroller.xyz/static/arrow_blue.png" alt="">
            <img src="https://doomscroller.xyz/static/wheel.png" alt="Wheel"></p>

          <div>
                 
           
      
                     
            <stripe-buy-button buy-button-id="buy_btn_1P5Y1328PU2Wr5nx37n76Me7" publishable-key="pk_live_QHHTMsoPgQZg6Oz7JujHn8pa">
          </stripe-buy-button>


            <stripe-buy-button buy-button-id="buy_btn_1P5Xx628PU2Wr5nxO5bFsP22" publishable-key="pk_live_QHHTMsoPgQZg6Oz7JujHn8pa">
            </stripe-buy-button>
        </div>

      
          <div>
            <p><b>Disclaimers:</b></p><ul>
              <li>Shipping in ~2 weeks</li>
              <li>Only works with Android/PC. Sorry iOS</li>
              <li>Code on github</li>
              <li>Fairly sure the battery won't explode</li>
            </ul>
          </div>
          
      </div>
        <div>
          <p><a data-width="350" data-theme="dark" data-min-width="300" data-max-width="600" href="https://twitter.com/AndrewMcCalip?ref_src=twsrc%5Etfw">Timeline</a>
        </p></div>
    </div>

</center></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub comments abused to push malware via Microsoft repo URLs (129 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/github-comments-abused-to-push-malware-via-microsoft-repo-urls/</link>
            <guid>40097818</guid>
            <pubDate>Sat, 20 Apr 2024 14:55:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/github-comments-abused-to-push-malware-via-microsoft-repo-urls/">https://www.bleepingcomputer.com/news/security/github-comments-abused-to-push-malware-via-microsoft-repo-urls/</a>, See on <a href="https://news.ycombinator.com/item?id=40097818">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="GitHub" height="900" src="https://www.bleepstatic.com/content/hl-images/2021/05/10/GitHub-headpic.jpg" width="1804"></p>
<p>A GitHub flaw, or possibly a design decision, is being abused by threat actors to distribute malware using URLs associated with a Microsoft repository, making the files appear trustworthy.</p>
<p>While most of the malware activity has been based around the Microsoft GitHub URLs, this "flaw" could be abused with any public repository on GitHub, allowing threat actors to create very convincing lures.</p>
<h2>Abusing GitHub's file upload feature</h2>
<p>Yesterday, McAfee released a report on a <a href="https://www.bleepingcomputer.com/news/security/fake-cheat-lures-gamers-into-spreading-infostealer-malware/" target="_blank">new LUA malware loader</a> distributed through what appeared to be a legitimate Microsoft GitHub repository for the "C++ Library Manager for Windows, Linux, and MacOS," known as <a href="https://github.com/microsoft/vcpkg" target="_blank" rel="nofollow noopener">vcpkg</a>.</p>
<p>The URLs for the malware installers, shown below, clearly indicate that they belong to the Microsoft repo, but we could not find any reference to the files in the project's source code.</p>
<pre><code>https://github[.]com/microsoft/vcpkg/files/14125503/Cheat.Lab.2.7.2.zip
https://github[.]com/microsoft/STL/files/14432565/Cheater.Pro.1.6.0.zip
</code></pre>
<p>Finding it strange that a Microsoft repo would be <a href="http://urlhaus.abuse.ch/url/2760438/" target="_blank" rel="nofollow noopener">distributing malware since February</a>, BleepingComputer looked into it and found that the files are not part of <em>vcpkg</em> but were uploaded as part of a comment left on a commit or issue in the project.</p>
<p>When leaving a comment, a GitHub user can attach a file, which will be uploaded to GitHub's CDN and associated with the related project using a unique URL in this format: '<em>https://www.github.com/{project_user}/{repo_name}/files/{file_id}/{file_name}.</em>'</p>
<p>Instead of generating the URL after a comment is posted, GitHub automatically generates the download link after you add the file to an unsaved comment, as shown below. This allows threat actors to attach their malware to any repository without them knowing.</p>
<div>
<figure><img alt="Download link auto-generated when adding a file to a comment" height="300" src="https://www.bleepstatic.com/images/news/security/g/github/github-file-uploads/github-comment-file-upload.jpg" width="795"><figcaption><strong>Download link auto-generated when adding a file to a comment</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>Even if you decide not to post the comment or delete it after it is posted, the files are not deleted from GitHub's CDN, and the download URLs continue to work forever.</p>
<p>As the file's URL contains the name of the repository the comment was created in, and as almost every software company uses GitHub, this flaw can allow threat actors to develop extraordinarily crafty and trustworthy lures.</p>
<p>For example, a threat actor could upload a malware executable in <a href="https://github.com/NVIDIA/nvidia-installer" target="_blank" rel="nofollow noopener">NVIDIA's driver installer repo</a> that pretends to be a new driver fixing issues in a popular game. Or a threat actor could upload a file in a comment to the <a href="https://github.com/chromium/chromium" target="_blank" rel="nofollow noopener">Google Chromium source code</a> and pretend it's a new test version of the web browser.</p>
<p>These URLs would also appear to belong to the company's repositories, making them far more trustworthy.</p>
<p>Unfortunately, even if a company learns their repos are abused to distribute malware, BleepingComputer could not find any settings that allow you to manage files attached to your projects.</p>
<p>Furthermore, you can only protect a GitHub account from being abused in this way and tarnishing your reputation by disabling comments. According to this <a href="https://docs.github.com/en/communities/moderating-comments-and-conversations/limiting-interactions-in-your-repository" target="_blank" rel="nofollow noopener">GitHub support document</a>, you can only temporarily disable comments for a maximum of six months at a time.</p>
<p>However, restricting comments can significantly impact a project's development as it will not allow users to report bugs or suggestions.</p>
<p>Sergei Frankoff, of automated malware analysis service UNPACME, did a livestream on Twitch about this bug just last month, saying that threat actors were actively abusing it.</p>
<blockquote>
<p dir="ltr" lang="en">Weeks later... GitHub bug still dropping malware <a href="https://t.co/s165zOAsoI" rel="nofollow noopener">pic.twitter.com/s165zOAsoI</a></p>
— herrcore (@herrcore) <a href="https://twitter.com/herrcore/status/1772988192678969567?ref_src=twsrc%5Etfw" rel="nofollow noopener">March 27, 2024</a></blockquote>
<p>As part of our research into this bug, BleepingComputer could only find one other repo, <a href="https://urlhaus.abuse.ch/url/2780254/" target="_blank" rel="nofollow noopener">httprouter</a>, abused to distribute malware in this way, and it was the same 'Cheater.Pro.1.6.0.zip' as seen in Microsoft's URLs.</p>
<p>However, Frankoff told BleepingComputer that they <a href="https://research.openanalysis.net/github/lua/2024/03/03/lua-malware.html" target="_blank" rel="nofollow noopener">discovered a similar campaign in March</a> that utilizes the same LUA loader malware, which is called <a href="https://www.unpac.me/results/f3a0a729-afcf-4209-9323-fbf470be2835#/" target="_blank" rel="nofollow noopener">SmartLoader</a>, disguised as the Aimmy cheat software.</p>
<p>Frankoff told BleepingComputer that SmartLoader is commonly installed alongside other payloads, such as the RedLine information-stealing malware.</p>
<p>BleepingComputer contacted both GitHub and Microsoft on Thursday about this abuse but did not receive a response.</p>
<p>At the time of this publication, the information-stealing malware is still being distributed through links associated with Microsoft' GitHub repository.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U-M finds students with alphabetically lower-ranked names receive lower grades (376 pts)]]></title>
            <link>https://record.umich.edu/articles/study-alphabetical-order-of-surnames-may-affect-grading/</link>
            <guid>40097375</guid>
            <pubDate>Sat, 20 Apr 2024 13:53:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://record.umich.edu/articles/study-alphabetical-order-of-surnames-may-affect-grading/">https://record.umich.edu/articles/study-alphabetical-order-of-surnames-may-affect-grading/</a>, See on <a href="https://news.ycombinator.com/item?id=40097375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
<p>Knowing your ABCs is essential to academic success, but having a last name starting with A, B or C might also help make the grade.</p>



<p>An analysis by University of Michigan researchers of more than 30 million grading records from U-M finds students with alphabetically lower-ranked names receive lower grades. This is due to sequential grading biases and the default order of students’ submissions in Canvas — the most widely used online learning management system — which is based on alphabetical rank of their surnames.</p>





<p>What’s more, the researchers found, those alphabetically disadvantaged students receive comments that are notably more negative and less polite, and exhibit lower grading quality measured by post-grade complaints from students.</p>



<p>“We spend a lot of time thinking about how to make the grading fair and accurate but even for me it was really surprising,” said Jun Li, associate professor of technology and operations at the Stephen M. Ross School of Business. “It didn’t occur to us until we looked at the data and realized that sequence makes a difference.”</p>



<p>Li co-authored the study with doctoral students Jiaxin Pei from the School of Information and Helen (Zhihan) Wang from Ross. It is under review by the journal Management Science.</p>



<p>The researchers collected available historical data of all programs, students and assignments on Canvas from the fall 2014 semester to the summer 2022 semester. They supplemented the Canvas data with university registrar data, which contains detailed information about students’ backgrounds, demographics and learning trajectories at the university.</p>



<figure><p>
<iframe width="500" height="281" src="https://www.youtube.com/embed/Dxdq1xXFi_M?feature=oembed&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="U-M Researchers find a correlation between student grades and alphabetical ordering of last names"></iframe>
</p></figure>



<p>Although the data is from U-M, the researchers say the findings can be generalized across institutions and courses. They are driven by a common design issue of learning-management systems — the default setting of ranking students’ assignments alphabetically by their names.</p>



<p>Their research uncovered a clear pattern of a decline in grading quality as graders evaluate more assignments. Wang said students whose surnames start with A, B, C, D or E received a 0.3-point higher grade out of 100 possible points than compared with when they were graded randomly. Likewise, students with later-in-the-alphabet surnames received a 0.3-point lower grade — creating a 0.6-point gap.</p>



<p>Wang noted that for a small group of graders (about 5%) that grade from Z to A, the grade gap flips as expected: A-E students are worse off, while W-Z students receive higher grades relative to what they would receive when graded randomly. The researchers said such observations confirm their hypothesis that it’s the order of grading that leads to the initial gap in grades.</p>



<p>A 0.6-point difference might seem small, but such a disparity did affect students’ course grade-point averages, which negatively influences opportunities in their respective career paths.</p>



<p>“Our conclusion is this may be something that happened unconsciously by the graders that’s actually creating a real social impact,” Wang said.</p>



<p>Pei said the idea for the study came up during a discussion he had with Wang in which they were talking about their research: Wang studies educational technology and he studies artificial intelligence. He observed that a fundamental task of machine learning is data labeling, also a sequential task that can be long and tedious, but one that is randomized.</p>



<p>It got them thinking about educational systems like Canvas and led to some pilot studies to see if there was any disparity among grades based on the amount of time spent in the task of grading.</p>



<p>“We kind of suspect that fatigue is one of the major factors that is driving this effect, because when you’re working on something for a long period of time, you get tired and then you start to lose your attention and your cognitive abilities are dropping,” Pei said.</p>



<p>The researchers note the option exists to grade the assignments in a random order, and some educators do, but alphabetical order is the default mode in Canvas and other online learning-management systems. One simple fix would be to make random order the default setting.</p>



<p>They also suggest academic institutions could hire more graders for larger classes, distribute the workload among more people or train them to be aware of and lessen the bias while grading.</p>



<p>Li, Wang and Pei have been sharing their research at conferences and it’s been positively received — many are impressed by their work although it confirms suspicions many harbor. One reaction in particular stands out to Li, no doubt an information-age wrinkle on “the dog ate my homework” excuse.</p>



<p>“A college student emailed us afterward asking us to share the paper with him,” she said. “He mentioned that his last name started with W. He’s going to tell his parents it’s not because of him — it’s because of his last name.”</p>
                    
                                        <dl>
                        <dt>Tags:</dt>
                        <dd>
                            <ul>
                                                                <li><a href="https://record.umich.edu/tags/canvas/">Canvas</a></li>
                                                                <li><a href="https://record.umich.edu/tags/grading/">grading</a></li>
                                                                <li><a href="https://record.umich.edu/tags/school-of-information/">School of Information</a></li>
                                                                <li><a href="https://record.umich.edu/tags/stephen-m-ross-school-of-business/">Stephen M. Ross School of Business</a></li>
                                                            </ul>
                        </dd>
                    </dl>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debugging the Doctor Brain: Who's teaching doctors how to think? (110 pts)]]></title>
            <link>https://bessstillman.substack.com/p/debugging-the-doctor-brain</link>
            <guid>40097111</guid>
            <pubDate>Sat, 20 Apr 2024 13:10:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bessstillman.substack.com/p/debugging-the-doctor-brain">https://bessstillman.substack.com/p/debugging-the-doctor-brain</a>, See on <a href="https://news.ycombinator.com/item?id=40097111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong>I walked into the hospital room of “Gladys,” 54-year-old woman</strong><span> who, like practically a quarter of ER patients, had belly pain,</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-143339099" href="https://bessstillman.substack.com/p/debugging-the-doctor-brain#footnote-1-143339099" target="_self" rel="">1</a></span><span> but something didn’t seem right. I’m not trying to be deliberately, annoyingly vague: something I couldn’t articulate kept me in her room.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-143339099" href="https://bessstillman.substack.com/p/debugging-the-doctor-brain#footnote-2-143339099" target="_self" rel="">2</a></span><span>Her vital signs looked normal and she wasn’t in terrible distress. Yet I loitered despite the relentless administrative pressure to see more patients, faster. </span></p><p>Gladys and I were chatting about her impending grandchild when, in less time than it takes you to read this sentence, Gladys sat up, vomited a huge quantity of blood, her blood pressure bottomed out, and she lost consciousness. I had to intubate, attempt a balloon tamponade, and initiate massive transfusion protocol—quickly. The ER team was able to stabilize her—barely. Luckily, I was already in the room.</p><p>Textbooks can’t describe and standardized tests can’t detect gestalt. Or, as Gen Z would say, “vibes.” A lot of ER docs like “spidey-sense”—the tingle that whispers: “order a CT scan to rule out a life-threatening diagnosis,” though the patient’s symptoms don’t exactly indicate it. Gestalt is built and honed by seeing thousands of patients. Do emergency medicine for 80 hours a week for three to four years —the length of an ER residency—and a resident doctor will have spent around 10,000 hours on direct patient care. It’s during those encounters that doctors are (supposed to be) guided towards developing and deepening the fundamental mental models that run in their cognitive background while evaluating each new patient.</p><p>But how does a doctor know if their models are accurate or adequate?</p><p><span>Answering that question really means asking if the education student doctors receive is both adequately teaching the fundamentals as well as teaching resident physicians how to think about and evaluate their own thought processes. And Dan Luu’s “</span><em><a href="https://danluu.com/teach-debugging/" rel="">Why don’t schools teach debugging</a></em><span>” got me thinking about the way science and medical education universally teaches the fundamentals: badly.</span></p><blockquote><p><span>When I suggested to the professor</span><sup> </sup><span>that he spend half an hour reviewing algebra for those students who never had the material covered cogently in high school, I was told in no uncertain terms that it would be a waste of time because some people just can't hack it in engineering. I was told that I wouldn't be so naive once the semester was done, because some people just can't hack it in engineering. I was told that helping students with remedial material was doing them no favors; they wouldn't be able to handle advanced courses anyway because some students just can't hack it in engineering. I was told that Purdue has a loose admissions policy and that I should expect a high failure rate, because some students just can't hack it in engineering.</span></p></blockquote><p><span>There seems to be a mass delusion in the sciences that someone—not you, but someone—must have, or at least should have already, taught a student the fundamentals by the time they get in front of you, so that you can focus on the interesting, juicy, complex conversations, presumably with the “smart” people who already get it, the smart people who can </span><em>hack it.</em><span> But most of the people who get it had to get it somewhere</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-143339099" href="https://bessstillman.substack.com/p/debugging-the-doctor-brain#footnote-3-143339099" target="_self" rel="">3</a></span><span>—why shouldn’t that somewhere be with you?</span></p><p data-attrs="{&quot;url&quot;:&quot;https://bessstillman.substack.com/p/debugging-the-doctor-brain?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://bessstillman.substack.com/p/debugging-the-doctor-brain?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><strong>In medicine, we often mistake the speed of initial understanding</strong><span> with a students’ capacity for mastery. This expectation starts in pre-med courses. Organic chemistry (“O-chem”) is the big pre-med “weed out” course because it both requires high-volume memorization and is one of the first times students have to learn a new way of thinking. In general chemistry, basic chemical equations are algebraic. The process of balancing two sides of an equation works off a mathematical model most students see in high school. O-chem, however, demands that you think in the language O-chem provides, which is a long list of various chemical reactions whose effects you memorize like vocabulary, and then you have to figure out how to use them to solve the puzzle of turning one chemical into another. You memorize the facts, then have to think in a new way to understand the fundamentals. You can’t just regurgitate. O-chem problems, much like complex patients, have multiple solutions. That’s why it’s hard.</span></p><p>Learning the language of chemistry to talk about chemistry resembles the way doctors learn the language of the body so they can think about the body. That’s the only logical reason, apart from a de-facto IQ test, I can come up with for having to take organic chemistry, because there’s no practical utility for O-chem in day-to-day doctoring. I suspects it’s also a test—one of many— to see if we’re willing to torture ourselves and jump through hoops. Extra points to anyone who asks “How high?” Masochism is heavily selected for in medical students, which is an essay topic for another time.</p><p>My O-Chem teacher was a lot like Luu’s engineering prof, who assumed that “hacking it” had more to do with inherent student capabilities rather than the quality of the teaching. On the first day of class, he announced that a quarter of the class would drop by the end of the month, and half of what remained would get a C or lower in a non-curved course. It seems like a sign of a lazy educator to announced he wouldn’t be capable of adequately explaining the material to students. Was half the room too stupid or lazy to understand? “Too stupid to understand” doesn’t usually sign up to be 25% of a 315 person O-Chem class at 7:30 a.m.</p><p><span>I had a really hard time getting it. Although the professor had office hours three times a week, showing up to them meant trading his ire for his help, which I (and many others) did. He said that, if I was having so much trouble understanding early on, I should leave, because some people won’t get it. Instead, I found an outside tutor who helped me understand how to approach problems, and change to a less linear way of thinking, and O-chem finally clicked. It was as if I was able to take all the words I’d memorized and finally speak the language, and think in that language, without having to translate. Was I slow on the uptake? Was my professor a bad teacher? Probably. Neither, however, precluded me from eventually getting it, suggesting both that I had the necessary processing power, and </span><em>someone</em><span> could teach the material.</span></p><p>Speed of understanding, however, only becomes more important as medical education continues into residency. </p><p><strong>A doctor’s foundational clinical mental models are built during residency</strong><span>, but the apprenticeship model of residency has flaws. An attending physician (an attending is a physician who has completed residency ) may be a skilled clinician but a poor educator, or not have the time, patience, or inclination to educate residents. A resident may only have three years in which to gain the practical, clinical knowledge they need to practice independently for the rest of their career. This puts a great deal of pressure on a student. But it should also places the burden of that education on attending physicians, many of whom aren’t given adequate tools and time to teach during their own workdays. </span></p><p>An ER shift usually goes like this: One attending physician oversees an ER “pod\area” and between 1-3 residents. Patients are assigned to that pod, residents assign themselves to patients, and the attending is responsible for seeing and evaluating all the patients while supervising the residents. An ER doctor sees, on average, 2-4 patients per hour, over a 8-12 hour shift, with multiple patients being juggled at once (I’ve cared for more than 20 active patients at a time). Patients who require intensive resuscitation or procedures may need an hour or more of sustained attention, while the board (the list of patients assigned to a pod) backs up. Being an Emergency Physician is about interruptions and fragmented time.</p><p>Even if you haven’t been in an ER lately, the news of worsening overcrowding, boarding times and uptick in patient visits is all over the news. It's worse than you imagine. ER attendings are beholden to any number of administrative metrics—patient satisfaction, charting completion, door to doc times—but especially throughput speed. You have to “move the meat”—ER lingo for getting patients in and out of the department quickly—to try and keep up with that endless stream of patients. Correcting a resident’s incorrect treatment plan only takes a moment, but stopping to interrogate the thought process that led that resident to the wrong answer takes time during which another patient arrives in anaphylactic shock, someone is bleeding onto the floor, another three patients are vomiting and a gunshot wound is being wheeled into the trauma bay. Those patients have to come first.</p><p>Teaching during a shift interrupts a busy workflow and means that attendings have to trade time completing their charts, for example, in order to teach, which then results in having to stay late or bring work home. Teaching or staying late doesn’t (usually) come with extra compensation, so the motivation needs to be intrinsic.</p><p>There are attempts to standardize resident education and overcome the variables that affect teaching on-shift, mostly with weekly “conferences” consistent of educational lectures, the quality of which also varies extensively depending on the lecturer. Let’s just say most wouldn’t be invited onto a TEDx stage. It’s not a bad way to learn the basics and facts: things like the biochemical changes cause by a kidney with stage III kidney disease, how to perform a simple interrupted suture, or how to calculate cardiac risk stratification scores. </p><p><span>But the fundamentals—which I’m defining as how you use and manipulate those basic facts to solve real problems in real patients, like </span><em>when </em><span>to use that simple interrupted suture or whether other factors would recommend a mattress suture, how a patient’s cardiac risk score interacts with other facts to influence a treatment plan, or what do when your kidney failure patient is coding and you don’t know their complete medication history—are learned mostly in real-time, on shift. How to think about facts, how to use facts, is where the art of medicine lies.</span></p><p>Even simulation-lab patient encounters don’t adequately recreate the challenges of rapid decision making in a busy ER, and tend to focus on common patient presentations. But patient’s rarely read the textbook and present accordingly. Basic facts are only tools. The facts don’t teach you to think like a doctor, any more than being able to identify a hammer makes someone a handyman.</p><p>There are a lot of misaligned incentives in resident education: attendings are judged by metrics of speed and patient satisfaction, residents want to learn and be seen as “good” so they can graduate and be recommended for a job, and hospitals want more patients to be seen, faster. </p><p>Because of the top to bottom relentless pressure to move the meat, a “good” resident, a resident who can “hack it” is a resident who is able to work quickly with minimal risk to patients. Who wouldn’t want to work with a resident whose incentives are aligned with yours? I know I feel more optimistic about the day when I see that I’m working with a resident who moves quickly and can help me do my job more smoothly. </p><p>But that means that someone— not me, but someone—must have, or should have already, taught the student the fundamentals by the time they get in front of me, so that I’m not slowed down and can focus on the interesting, juicy, complex conversations with a resident who “gets it.” Residents are smart. They know that’s what’s desirable: already knowing the things that they are really there to learn.</p><p>The residents who master material in a way that allows them to work quickly, whether or not they understand deeply, are prized and praised. Problem is that deep understanding usually requires sacrificing speed (initially), and there’s an inevitable bottleneck that happens when someone is laying the groundwork for fluency in a new skill. </p><p><span>How can we tell when the resident is quick and right via luck or guessing—and when they’re quick and right because they understand? We can’t, really, not until the right situation presents itself. And the truth is, doctors can get away with a lot of algorithmic thinking before a patient presents who is both complex in unexpected ways </span><em>and </em><span>in ways that might kill them if you get it wrong. </span></p><p>That’s what separates the physicians from many other members of the medical team: The training to get away from the algorithm and use a deep understanding to come up with novel solutions. That’s also why algorithmic thinking can be so dangerous. So many patients never bother reading the flowcharts before they arrive and only presenting with the allowed symptoms.</p><p><strong>Skill can be confused with speed of mastery</strong><span> and competence can be confused with confidence, because we want it to be. What I keep coming back to is that so much of science and medical training comes down to perception of skill, as opposed to actual skill.</span></p><p><span>For example, when I was in residency, a friend was given feedback that she wasn’t seeing enough patients on shifts. When she asked how many she saw compared to other residents, she was told that they didn’t have the numbers, but they could see she was slow, and she needed to show she could keep up, or wouldn’t be able to </span><em>hack it</em><span>. The electronic medical record had a search option where you could pull up the number of patient’s you’d seen in the last six months. So she looked. And then she looked up the numbers of all the other residents. Out of thirteen residents, she was ranked #6. When my friend brought this information back to the program director, she was told that it didn’t matter what the numbers showed, she gave the perception of being slow, and needed to fix it. Her program director wouldn’t even look at the data. </span></p><p>I remember presenting a patient to one of my attendings and saying that, given his clinical picture and my list of possible diagnoses, I wasn’t sure what the best next test would be.</p><p>“I want you to be sure,” my attending said.</p><p>“Yes, I want to be sure as well, but I’ve never seen this and so I’m not sure.”</p><p>“You need to be more confident in your plans.”</p><p><span>I countered that I’d be more confident in my plan if I could discuss the few different plans I’m considering and learn which was the most appropriate to the patient and why, so that the next time I saw a similar patient, I had a better understanding of </span><em>why </em><span>I was doing what I’m doing instead of just being perceived as knowing it. That’s when I’d be confident. Plus, I only had three years to get that kind of feedback before I was the one providing that feedback to others. There’s never another time during their career when a doc has the opportunity to run every single patient they see by a more experienced clinician. </span></p><p><span>I’m as skeptical of residents (and attendings) with too much confidence as none: I don’t want my residents to be too confident, to be too thoroughly convinced of their own rightness and way. I want them to have the freedom to admit when they don’t know everything. Because they don’t. I don’t, either. In </span><em>The Name of the Rose</em><span>, William of Baskerville is a monk but also a proto-detective in the mold of Sherlock Holmes, and when he’s trying to solve a series of increasingly bizarre murders, he tells his sidekick, Adso, that “we mustn’t dismiss any hypothesis, no matter how farfetched.” And so it often is in medicine. Being okay with uncertainty will make both residents and attending’s lives better, and more importantly, patient lives safer.</span></p><p><strong>The problem of perception as the most important metric</strong><span> of skill is a problem with most forms of physician evaluation. When going for your quarterly review, your boss, who doesn’t directly watch you interact with patients, uses nursing and peer perception of your skills, as well as certain metrics of speed and patient satisfaction scores, to determine the depth of your knowledge and ability to care for patients. </span></p><p>There’s no direct, objective observation of your interactions with patients, or discussion of how you break down complex problems, or philosophy to approaching new patients, or what you do when you’re faced with an unfamiliar problem, all of which give a much deeper understanding of who someone really is as a physician. When you need a new job, you’re required to get letters of recommendations from colleagues who have also never watched you interact with patients directly, and who don’t have any idea what kind of a doctor you actually are, just what kind of a doctor you appear to be.</p><p>This is a systems problem. Most physicians who are hired to work in residencies didn’t get formal training on how to educate. They happen to work at a site that has residents, and so they have to teach. We base how we teach on how we were taught. We praise for what we were praised for. I’m not immune. I catch myself doing it, too. We teach our residents how to succeed in a system where a doctor’s success and a patient’s successful care don’t always spring from the well of thought.</p><p><strong>Incentivizing deep learning and deep thought means</strong><span> reducing the time pressure on both attendings and residents. If hospitals valued people over profits, they’d hire more attendings to both see patients and supervise, spreading both the patient care and educational workload. The existing arguments that this is cost prohibitive is laughable. For example David Reich, CEO of Mt. Sinai Hospital in NYC made $1,808,577 in 2023 (excluding bonuses, which can be </span><em>impressive</em><span>). According to Glassdoor (and on par with my experience) the salary for a full time ER physician in NYC is between $200-275k a year. </span></p><p><span>The center for Medicare and Medicaid is the primary source of graduate medical education (residency) funding. Per the </span><a href="https://www.graham-center.org/maps-data-tools/gme-data-tables/2000-2021.html" rel="">Graham Center interactive GME data tool</a><span> Mt. Sinai received&nbsp; around $175k a year per resident, and pays them a salary of $84,479\year, leaving 90K to pay for their “education.” Remember that ER patients are being billed, and the physician pay comes from hospital profit. There should be plenty of room to hire a few additional physicians, if administrators stopped to remember that the residents being trained will one day be the attendings caring for them.</span></p><p>Until incentives align, and the hospitals reward and pay physicians for doing the work of educating in addition to their clinical work; until teaching attendings have adequate training on how to educate; until hospitals are willing to staff adequately so there’s time to teach, the system will remain broken.</p><p><em>Part Two (coming soon): How can we teach our students (and ourselves) to think better within the system we have?</em></p><p><em><span>If you’ve gotten this far, </span><a href="https://www.gofundme.com/f/help-the-fight-against-cancer-with-jake-s" rel="">consider the Go Fund Me</a><span> that’s funding my husband Jake’s </span><a href="https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/" rel="">ongoing cancer treatment</a><span>. Essays and Archives are not paywalled, but your support gives us more time to focus on both writing and each other, which we appreciate!</span></em></p><p data-attrs="{&quot;url&quot;:&quot;https://www.gofundme.com/f/help-the-fight-against-cancer-with-jake-s&quot;,&quot;text&quot;:&quot;Support Jake's Cancer Treatments&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.gofundme.com/f/help-the-fight-against-cancer-with-jake-s" rel=""><span>Support Jake's Cancer Treatments</span></a></p><p><em>If you enjoyed reading, let me know by giving the heart button below a tap, commenting, sharing, and subscribing, if you don’t already. </em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9785955,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa20fed8-6cbb-4fb0-91a9-d72fa651e04f_6240x4160.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
    </channel>
</rss>