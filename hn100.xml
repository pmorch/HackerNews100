<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 09 Nov 2024 23:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Jaws – a JavaScript to WASM ahead-of-time compiler (127 pts)]]></title>
            <link>https://github.com/drogus/jaws</link>
            <guid>42095879</guid>
            <pubDate>Sat, 09 Nov 2024 18:14:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/drogus/jaws">https://github.com/drogus/jaws</a>, See on <a href="https://news.ycombinator.com/item?id=42095879">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Jaws</h2><a id="user-content-jaws" aria-label="Permalink: Jaws" href="#jaws"></a></p>
<p dir="auto">Jaws is a JavaScript to WebAssembly compiler written in Rust. It is similar to <a href="https://github.com/CanadaHonk/porffor">porffor</a> in a way it also results in a standalone WASM binary that can be executed without an interpreter, but it takes a different implementation approach.</p>
<p dir="auto">It's an experimental tool and it's not ready for production. A lot of the language
features and builtin types are missing or incomplete. That said, my goal is to eventually support 100% of the language.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why Jaws?</h3><a id="user-content-why-jaws" aria-label="Permalink: Why Jaws?" href="#why-jaws"></a></p>
<p dir="auto">I started this project while working on a stress testing tool called <a href="https://github.com/drogus/crows">Crows</a> that runs WebAssembly scenarios. At the moment it only supports code compiled from Rust to WASM. As much as I love writing Rust, I also know it's not a widely popular language and besides, small tests are often easier to write in interpreted languages. The problem is, running scripting languages on top of WASM is not ideal at the moment. You have to either include an interpreter, which automatically makes the binary at least a few MBs in size and the memory usage even bigger, or use a variation of the language you're targetting (like TinyGo instead of Go, or AssemblyScript instead of TypeScript/JavaScript).</p>
<p dir="auto">I believe that with modern WASM proposals it is possible to implement 100% of JavaScript features without the need to use a compiled interpreter, as WASM runtimes are already interpreters.</p>
<p dir="auto">If you want to see it happen, please consider <a href="https://github.com/sponsors/drogus">sponsoring my work</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What works</h3><a id="user-content-what-works" aria-label="Permalink: What works" href="#what-works"></a></p>
<p dir="auto">As I eventually want to implment 100% of the language, I'm purposefully focused on implementing the semantics first, rather than go for 100% of builtins and grammar as I want to be 100% sure it's doable.</p>
<p dir="auto">I have a list of 4 things that I think are hard to implement and after I implement all of them I will focus on more grammar and builtins. These are:</p>
<ol dir="auto">
<li>Scopes/closures</li>
<li>try/catch</li>
<li>async/await</li>
<li>generators</li>
</ol>
<p dir="auto">The last two are kind of similar as by getting generators working, one essentially has tools to make async await work, but I still wanted to make the distinction. At the moment Jaws can compile code using closures with (mostly) proper scopes support, it allows try/catch and it implements (limited) <code>Promise</code> API and <code>async</code> (but not <code>await</code> yet). For example the following script will print <code>error: foo</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="let value = &quot;foo&quot;;
async function foo() {
  throw value;
}

foo().then(
  function () {},
  function (v) {
    console.log(&quot;error&quot;, v);
  },
);"><pre><span>let</span> <span>value</span> <span>=</span> <span>"foo"</span><span>;</span>
<span>async</span> <span>function</span> <span>foo</span><span>(</span><span>)</span> <span>{</span>
  <span>throw</span> <span>value</span><span>;</span>
<span>}</span>

<span>foo</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>
  <span>function</span> <span>(</span><span>)</span> <span>{</span><span>}</span><span>,</span>
  <span>function</span> <span>(</span><span>v</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"error"</span><span>,</span> <span>v</span><span>)</span><span>;</span>
  <span>}</span><span>,</span>
<span>)</span><span>;</span></pre></div>
<p dir="auto">A non exhaustive list of other stuff that should work:</p>
<ul dir="auto">
<li>declaring and assigning: <code>var</code>, <code>let</code>, <code>const</code></li>
<li><code>while</code></li>
<li>string lierals, adding string literals</li>
<li>numbers and basic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>)</li>
<li>booleans and basic boolean operators</li>
<li>array literals</li>
<li>object literals</li>
<li><code>new</code> keyword</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Host requirements</h3><a id="user-content-host-requirements" aria-label="Permalink: Host requirements" href="#host-requirements"></a></p>
<p dir="auto">As Jaws is built with a few relatively recent WASM proposals, the generated binaries are not really portable between runtimes yet. I'm aiming to implement it with WASIp2 in mind, but the only runtime capable of running components and WASIp2, ie. Wasmtime, does not support some other things I use, like parts of the WASM GC proposal or exception handling.</p>
<p dir="auto">In order to make it easier to develop before the runtimes catch up with standardized proposals, I decided to use V8 (through Chromium or Node) with a Javascript polyfill for WASIp2 features that I need. There is a script <code>run.js</code> in the repo that allows to run binaries generated by Jaws. Eventually it should be possible to run them on any runtime implementing WASM GC, exception handling and WASIp2 API.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to use it?</h3><a id="user-content-how-to-use-it" aria-label="Permalink: How to use it?" href="#how-to-use-it"></a></p>
<p dir="auto">Unless you want to contribute you probably shouldn't, but after cloning the repo
you can use an <code>execute.sh</code> script like:</p>
<div data-snippet-clipboard-copy-content="./execute.sh --cargo-run path/to/script.js"><pre><code>./execute.sh --cargo-run path/to/script.js
</code></pre></div>
<p dir="auto">It will generate a WAT file, compile it to a binary and then run using Node.js.</p>
<p dir="auto">It requires Rust's <code>cargo</code>, relatively new version of <code>wasm-tools</code> and Node.js v23.0.0 or newer. Passing <code>--cargo-run</code> will make the script use <code>cargo run</code> command to first compile and then run the project, otherwise it will try to run the release build (so you have to run <code>cargo build --release</code> prior to running <code>./execute.sh</code> without <code>--cargo-run</code> option)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's next?</h3><a id="user-content-whats-next" aria-label="Permalink: What's next?" href="#whats-next"></a></p>
<p dir="auto">My plan is to finish implementing all of the "hard to implement" features first, so next in line are generators and <code>await</code> keyword support. Ideally I would use the <a href="https://github.com/WebAssembly/stack-switching">stack-switching</a> proposal for both await and generators, but alas it's only in Phase 2 and it has minimal runtime support (I could find some mentions in Chromium development groups, but I couldn't get it to work). In the absence of stack-switching I'm working on using CPS transforms in order to simulate continuations.</p>
<p dir="auto">After that's done, I will be slowly implementing all of the missing pieces, starting with grammar (for loops, switch etc) and then builtin types and APIs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How does it work?</h3><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">The project is essentially translating JavaScript syntax into WASM instructions, leveraging instructions added by WASM GC, exception handling and tail call optimizations proposals. On top of the Rust code that is translating JavaScript code, there is about 3k lines of WAT code with all the plumbing needed to translate JavaScript semantics into WASM.</p>
<p dir="auto">To give an example let's consider scopes and closures. WASM has support for passing function references and for structs and arrays, but it doesn't have the scopes semantics that JavaScript has. Thus, we need to simulate how scopes work, by adding some extra WASM code. Imagine the following JavaScript code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="let a = &quot;foo&quot;;

function bar() {
  console.log(a);
}

bar();"><pre><span>let</span> <span>a</span> <span>=</span> <span>"foo"</span><span>;</span>

<span>function</span> <span>bar</span><span>(</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>a</span><span>)</span><span>;</span>
<span>}</span>

<span>bar</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto">In JavaScript, because a function definition inherits the scope in which it's defined, the <code>bar()</code> function has access to the <code>a</code> variable. Thus, this script should print out the string <code>"foo"</code>. We could translate it to roughly the following pseudo code:</p>
<div data-snippet-clipboard-copy-content="// first we create a global scope, that has no parents
let scope = newScope(null);

// then we set the variable `a` on the scope
declareVariable(scope, &quot;a&quot;, &quot;foo&quot;);

// now we define the  bar function saving a reference to the function
let func = function(parentScope: Scope, arguments: JSArguments, this: Any) -> Any {
  // inside a function declaration we start a new scope, but keeping
  // a reference to the parentScope
  let scope = newScope(parentScope);

  // now we translate console.log call retreiving the variable from the scope
  // this will search for the `a` variable on the current scope and all of the
  // parent scopes
  console.log(retrieve(scope, &quot;a&quot;));
}
// when running a function we have to consider the scope
// in which it was defined
let fObject = createFunctionObject(func, scope);
// and now we also set `bar` on the current scope
declareVariable(scope, &quot;bar&quot;, fObject)

// now we need to fetch the `bar` function from the scop
// and run it
let f = retrieve(scope, &quot;bar&quot;);
call(f);"><pre><code>// first we create a global scope, that has no parents
let scope = newScope(null);

// then we set the variable `a` on the scope
declareVariable(scope, "a", "foo");

// now we define the  bar function saving a reference to the function
let func = function(parentScope: Scope, arguments: JSArguments, this: Any) -&gt; Any {
  // inside a function declaration we start a new scope, but keeping
  // a reference to the parentScope
  let scope = newScope(parentScope);

  // now we translate console.log call retreiving the variable from the scope
  // this will search for the `a` variable on the current scope and all of the
  // parent scopes
  console.log(retrieve(scope, "a"));
}
// when running a function we have to consider the scope
// in which it was defined
let fObject = createFunctionObject(func, scope);
// and now we also set `bar` on the current scope
declareVariable(scope, "bar", fObject)

// now we need to fetch the `bar` function from the scop
// and run it
let f = retrieve(scope, "bar");
call(f);
</code></pre></div>
<p dir="auto">All of the helpers needed to make it work are hand written in WAT format. I have some ideas on how to make it more efficient, but before I can validate all the major features I didn't want to invest too much time into side quests. Writing WAT by hand is not that hard, too, especially when you consider WASM GC.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The code is licensed under Apache 2.0 license</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenCoder: Open-Source LLM for Coding (222 pts)]]></title>
            <link>https://arxiv.org/abs/2411.04905</link>
            <guid>42095580</guid>
            <pubDate>Sat, 09 Nov 2024 17:27:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2411.04905">https://arxiv.org/abs/2411.04905</a>, See on <a href="https://news.ycombinator.com/item?id=42095580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+S" rel="nofollow">Siming Huang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+T" rel="nofollow">Tianhao Cheng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J+K" rel="nofollow">Jason Klein Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao,+J" rel="nofollow">Jiaran Hao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song,+L" rel="nofollow">Liuyihan Song</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Y" rel="nofollow">Yang Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+J" rel="nofollow">J. Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J" rel="nofollow">J.H. Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+C" rel="nofollow">Chenchen Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chai,+L" rel="nofollow">Linzheng Chai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+R" rel="nofollow">Ruifeng Yuan</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z" rel="nofollow">Zhaoxiang Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+J" rel="nofollow">Jie Fu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Q" rel="nofollow">Qian Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+G" rel="nofollow">Ge Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z" rel="nofollow">Zili Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi,+Y" rel="nofollow">Yuan Qi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Y" rel="nofollow">Yinghui Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu,+W" rel="nofollow">Wei Chu</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2411.04905">View PDF</a>
    <a href="https://arxiv.org/html/2411.04905v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Large language models (LLMs) for code have become indispensable in various domains, including code generation, reasoning tasks and agent <a href="http://systems.while/" rel="external noopener nofollow">this http URL</a> open-access code LLMs are increasingly approaching the performance levels of proprietary models, high-quality code LLMs suitable for rigorous scientific investigation, particularly those with reproducible data processing pipelines and transparent training protocols, remain limited. The scarcity is due to various challenges, including resource constraints, ethical considerations, and the competitive advantages of keeping models advanced. To address the gap, we introduce OpenCoder, a top-tier code LLM that not only achieves performance comparable to leading models but also serves as an ``open cookbook'' for the research community. Unlike most prior efforts, we release not only model weights and inference code, but also the reproducible training data, complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols for open scientific research. Through this comprehensive release, we identify the key ingredients for building a top-tier code LLM: (1) code optimized heuristic rules for data cleaning and methods for data deduplication, (2) recall of text corpus related to code and (3) high-quality synthetic data in both annealing and supervised fine-tuning stages. By offering this level of openness, we aim to broaden access to all aspects of a top-tier code LLM, with OpenCoder serving as both a powerful model and an open foundation to accelerate research, and enable reproducible advancements in code AI.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Linzheng Chai [<a href="https://arxiv.org/show-email/c945dd3e/2411.04905" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 7 Nov 2024 17:47:25 UTC (25,625 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IronCalc – Open-Source Spreadsheet Engine (163 pts)]]></title>
            <link>https://www.ironcalc.com/</link>
            <guid>42095292</guid>
            <pubDate>Sat, 09 Nov 2024 16:36:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ironcalc.com/">https://www.ironcalc.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42095292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>      
      <div id="about">
            <div>
              <h4>MIT/Apache 2.0 licensed</h4>
              <p>You can integrate it into your projects, customize it to your needs, and share it openly without any restrictions.</p>
            </div>
            <div>
              <h4>Feature rich</h4>
              <p>You shouldn’t worry that this or that function is not supported.</p>
            </div> 
            
             
            <div>
              <h4>Excel compatible</h4>
              <p>We at IronCalc are in awe of the software created by Microsoft over the years. We want every one to be able to use their spreadsheets.</p>
            </div> 
            <div>
              <h4>Fully tested</h4>
              <p>Modern programming practices should be used covering with tests any feature of the system.</p>
            </div>
            <div>
              <h4>Fast and lightweight</h4>
              <p>The programs shouldn’t be heavier than a few hundred kilobytes.</p>
            </div>
            <div>
              <h4>International from day one</h4>
              <p>Language should no be a barrier to use a spreadsheet.</p>
            </div>
            <div>
              <h4>Well designed</h4>
              <p>It should be nice and friendly to use. Designed with love from the ground up.</p>
            </div> 
             
             
             

          </div>
      
      <div id="why-ironcalc">
          
          
            <p>
              For over 40 years, spreadsheets have been integral to countless applications. Despite numerous proprietary and open-source options, finding a universally accessible, reliable, and high-quality engine remains a challenge. Many existing solutions are expensive, require accounts, or suffer from performance and stability issues.
            </p>
            <p>
              <strong>Our Mission:</strong> To fill the gaps left by the industry and empower every user with a robust, open-source spreadsheet engine that caters to diverse needs. Here's why we are dedicated to this mission:
            </p>
            <h4>Addressing Unmet Needs</h4>
            <p><strong>Empowering SaaS Developers:</strong> Hundreds, if not thousands, of companies have implemented half-baked spreadsheets in their systems. IronCalc aims to provide these businesses with a superior, open-source alternative that enhances their SaaS applications.</p>
            <p><strong>Automated Spreadsheet Processing:</strong> Users need a reliable way to programmatically open, populate, and analyze spreadsheets for large-scale scenarios. IronCalc delivers the performance and functionality required for these complex tasks.</p>
            <p><strong>Global Collaboration:</strong> We envision a world where anyone can use a spreadsheet online and effortlessly share it with friends for collaborative projects, such as planning travel experiences.</p>
            <p><strong>Interactive Blog Integration:</strong> Bloggers should be able to embed interactive spreadsheets in their posts, allowing readers to engage with custom test cases and scenarios.</p>
            <h4>Beyond Code: Advancing Spreadsheet Technology and Community</h4>
            <p>IronCalc's ambition extends beyond providing open-source code. We aim to drive the spreadsheet industry forward through:</p>
            <p><strong>Research and Development:</strong> While many areas of computer science, such as compilers and algorithms, have extensive literature, spreadsheets have been largely overlooked. We want to challenge that by finding collaborators in universities and academic institutions willing to do open research in spreadsheet engines.</p>
            <p><strong>Community and Collaboration:</strong> We can dream bigger, maybe we can organize conferences and maybe support PhD researchers and foster a collaborative environment where ideas and innovations can flourish.</p>
            <p><strong>Building a Knowledge Base:</strong> Our goal is to equip the next generation of spreadsheet developers with a comprehensive set of tools and knowledge, laying a solid foundation for future advancements, not only IronCalc.</p>
            <p>Together, we can push the boundaries of what spreadsheets can achieve, making high-quality, accessible spreadsheet technology available to all.</p>
            
            <p>
            – The IronCalc Team
            </p>

            

        </div>
      <!-- <section id="newsletter">
        <div class="section-content">
          <div class="blue-container">
            <div class="flex-v gap-lg">
              <div class="flex-v gap-sm">
                <h2>Join the waitlist</h2>
                <p>
                  We’ll send you a message when IronCalc is launched!
                </p>
              </div>
              <button class="secondary max-w-200">Join</button>
            </div>
          </div>
        </div>
      </section> -->

      


      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite does not do checksums (116 pts)]]></title>
            <link>https://avi.im/blag/2024/sqlite-bit-flip/</link>
            <guid>42094663</guid>
            <pubDate>Sat, 09 Nov 2024 14:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avi.im/blag/2024/sqlite-bit-flip/">https://avi.im/blag/2024/sqlite-bit-flip/</a>, See on <a href="https://news.ycombinator.com/item?id=42094663">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>SQLite does not do checksums by default. I learned this from <a href="https://fosstodon.org/@AlexMillerDB/109553692861357766">Alex Miller</a>. What does this mean? If there is disk corruption, the database or application won’t be able to know that the database is ‘corrupt’.</p><p>Even a single bit flip can cause havoc. This can happen due to a faulty disk, a bug in the disk driver, or when another application (malicious or otherwise) modifies the database files.</p><p>This is not a bug - it’s properly documented:</p><blockquote><p>SQLite assumes that the detection and/or correction of bit errors caused by cosmic rays, thermal noise, quantum fluctuations, device driver bugs, or other mechanisms, is the responsibility of the underlying hardware and operating system. SQLite does not add any redundancy to the database file for the purpose of detecting corruption or I/O errors. SQLite assumes that the data it reads is exactly the same data that it previously wrote.</p></blockquote><p>I created a <a href="https://gist.github.com/avinassh/0e7e4b0578136a338f1b9a03fba36ead">simple script</a> to demonstrate this:</p><ol><li><p>Create a sample database using <a href="https://gist.github.com/avinassh/0e7e4b0578136a338f1b9a03fba36ead">this script</a>. It creates a bank database and adds a row for Alice with $83K.</p></li><li><p>Flip a single bit:</p><pre><code> printf '\x00\x00\x00\x00\x00\x80' | dd of=bank.db bs=1 seek=$((0x1ffd)) count=1 conv=notrunc
</code></pre></li><li><p>Alice’s balance is now zero. Sorry, Alice.</p></li></ol><p>It passes <code>PRAGMA integrity_check</code> too. Here’s an ASCII animation if you prefer that:</p><h2 id="wal-and-checksums">WAL and Checksums</h2><p>SQLite has checksums for WAL frames. However, when it detects a corrupt frame, it silently ignores the faulty frame and all subsequent frames. It doesn’t even raise an error!</p><p>Ignoring frames might be acceptable, but not raising an error is where it gets me.</p><h2 id="checksum-vfs-shim">Checksum VFS Shim</h2><p>You can use the <a href="https://www.sqlite.org/cksumvfs.html">Checksum VFS Shim</a>, but there’s one important caveat:</p><blockquote><p>Checksumming only works on databases that have a reserve bytes value of exactly 8</p></blockquote><p>The <a href="https://www.sqlite.org/fileformat2.html#resbyte">documentation of reserve bytes</a> explains:</p><blockquote><p>SQLite has the ability to set aside a small number of extra bytes at the end of every page for use by extensions. These extra bytes are used, for example, by the SQLite Encryption Extension to store a nonce and/or cryptographic checksum associated with each page. The “reserved space” size in the 1-byte integer at offset 20 is the number of bytes of space at the end of each page to reserve for extensions. This value is usually 0. The value can be odd.</p></blockquote><p>This means if you’re using any extension that uses reserve bytes, you can’t use the Checksum shim.</p><p>Again, this is not a bug. <a href="https://avi.im/blag/2024/databases-checksum">Most databases (except a few)</a> assume that the OS, filesystem, and disk are sound. Whether this matters depends on your application and the guarantees you need.</p><p>edit: I wrote a <a href="https://avi.im/blag/2024/databases-checksum">follow up post</a>.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientist treated her own cancer with viruses she grew in the lab (359 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-03647-0</link>
            <guid>42094573</guid>
            <pubDate>Sat, 09 Nov 2024 14:23:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-03647-0">https://www.nature.com/articles/d41586-024-03647-0</a>, See on <a href="https://news.ycombinator.com/item?id=42094573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                        <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Coloured transmission electron micrograph of cultured measles virus particles." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg"><figcaption><p><span>Viruses such as measles (pictured here) can be used to attack cancerous cells. </span><span>Credit: Eye Of Science/Science Photo Library</span></p></figcaption></picture></figure><p>A scientist who successfully treated her own <a href="https://www.nature.com/subjects/breast-cancer" data-track="click" data-label="https://www.nature.com/subjects/breast-cancer" data-track-category="body text link">breast cancer</a> by injecting the tumour with lab-grown viruses has sparked discussion about the ethics of self-experimentation. </p><p>Beata Halassy discovered in 2020, aged 49, that she had breast cancer at the site of a previous mastectomy. It was the second recurrence there since her left breast had been removed, and she couldn’t face another bout of chemotherapy. </p><p>Halassy, a virologist at the University of Zagreb, studied the literature and decided to take matters into her own hands with an unproven treatment. </p><p>A case report published in <i>Vaccines</i> in August<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> outlines how Halassy self-administered a treatment called <a href="https://www.nature.com/articles/s41571-022-00719-w" data-track="click" data-label="https://www.nature.com/articles/s41571-022-00719-w" data-track-category="body text link">oncolytic virotherapy</a> (OVT) to help treat her own stage 3 cancer. She has now been cancer-free for four years. </p><p>In choosing to <a href="https://www.nature.com/articles/nm0508-471b" data-track="click" data-label="https://www.nature.com/articles/nm0508-471b" data-track-category="body text link">self-experiment</a>, Halassy joins a long line of scientists who have participated in this under-the-radar, stigmatized and ethically fraught practice. “It took a brave editor to publish the report,” says Halassy.</p><h2>Up-and-coming therapy</h2><p>OVT is an emerging field of <a href="https://www.nature.com/subjects/cancer-therapy" data-track="click" data-label="https://www.nature.com/subjects/cancer-therapy" data-track-category="body text link">cancer treatment</a> that uses viruses to both attack cancerous cells and provoke the immune system into fighting them. Most OVT clinical trials so far have been in late-stage, metastatic cancer, but in the past few years they have been directed towards earlier-stage disease. One OVT, called T-VEC, has been in approved in the United States to treat metastatic melanoma, but there are as yet no OVT agents approved to treat breast cancer of any stage, anywhere in the world. </p><p>Halassy stresses that she isn’t a specialist in OVT, but her expertise in cultivating and purifying viruses in the laboratory gave her the confidence to try the treatment. She chose to target her tumour with two different viruses consecutively — a <a href="https://www.nature.com/subjects/measles-virus" data-track="click" data-label="https://www.nature.com/subjects/measles-virus" data-track-category="body text link">measles virus</a> followed by a vesicular stomatitis virus (VSV). Both pathogens are known to infect the type of cell from which her tumour originated, and have already been used in OVT clinical trials. A measles virus has been trialled against metastatic breast cancer.</p><p>Halassy had previous experience working with both viruses, and both have a good safety record. The strain of measles she chose is used extensively in childhood vaccines, and the strain of VSV induces, at worst, mild influenza-like symptoms. </p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Portrait of Beata Halassy." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg"><figcaption><p><span>Halassy’s experience with self-treatment has changed the focus of her research. </span><span>Credit: Ivanka Popić </span></p></figcaption></picture></figure><p>Over a two-month period, a colleague administered a regime of treatments with research-grade material freshly prepared by Halassy, injected directly into her tumour. Her oncologists agreed to monitor her during the self-treatment, so that she would be able to switch to conventional chemotherapy if things went wrong.</p><p>The approach seemed to be effective: over the course of the treatment, and with no serious side effects, the tumour shrank substantially and became softer. It also detached from the pectoral muscle and skin that it had been invading, making it easy to remove surgically.</p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-024-02613-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27470032.jpg"><p>How a trove of cancer genomes could improve kids’ leukaemia treatment</p></a></article><p>Analysis of the tumour after removal showed that it was thoroughly infiltrated with immune cells called lymphocytes, suggesting that the OVT had worked as expected and provoked Halassy’s immune system to attack both the viruses and the tumour cells. “An immune response was, for sure, elicited,” says Halassy. After the surgery, she received a year’s treatment with the anticancer drug trastuzumab. </p><p>Stephen Russell, an OVT specialist who runs virotherapy biotech company Vyriad in Rochester, Minnesota, agrees that Halassy’s case suggests the viral injections worked to shrink her tumour and cause its invasive edges to recede. </p><p>But he doesn’t think her experience really breaks any new ground, because researchers are already trying to use OVT to help treat earlier-stage cancer. He isn’t aware of anyone trying two viruses sequentially, but says it isn’t possible to deduce whether this mattered in an ‘<i>n</i> of 1’ study. “Really, the novelty here is, she did it to herself with a virus that she grew in her own lab,” he says.</p><h2>Ethical dilemma</h2><p>Halassy felt a responsibility to publish her findings. But she received more than a dozen rejections from journals — mainly, she says, because the paper, co-authored with colleagues, involved self-experimentation. “The major concern was always ethical issues,” says Halassy. She was particularly determined to persevere after she came across a review highlighting the value of self-experimentation<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. </p><p>That journals had concerns doesn’t surprise Jacob Sherkow, a law and medicine researcher at the University of Illinois Urbana-Champaign who has examined the ethics of researcher self-experimentation in relation to COVID-19 vaccines. </p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-023-02075-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_26019860.jpg"><p>Huge leap in breast cancer survival rate</p></a></article><p>The problem is not that Halassy used self-experimentation as such, but that publishing her results could encourage others to reject conventional treatment and try something similar, says Sherkow. People with cancer can be particularly susceptible to trying unproven treatments. Yet, he notes, it’s also important to ensure that the knowledge that comes from self-experimentation isn’t lost. The paper emphasizes that self-medicating with cancer-fighting viruses “should not be the first approach” in the case of a cancer diagnosis. </p><p>“I think it ultimately does fall within the line of being ethical, but it isn’t a slam-dunk case,” says Sherkow, adding that he would have liked to see a commentary fleshing out the ethics perspective, published alongside the case report.</p><p>Halassy has no regrets about self-treating, or her dogged pursuit of publication. She thinks it is unlikely that someone would try to copy her, because the treatment requires so much scientific knowledge and skill. And the experience has given her own research a new direction: in September she got funding to investigate OVT to treat cancer in domestic animals. “The focus of my laboratory has completely turned because of the positive experience with my self-treatment,” she says.</p>
                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Memories are not only in the brain, human cell study finds (182 pts)]]></title>
            <link>https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html</link>
            <guid>42094427</guid>
            <pubDate>Sat, 09 Nov 2024 13:53:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html">https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html</a>, See on <a href="https://news.ycombinator.com/item?id=42094427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/memories-are-not-only.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2024/memories-are-not-only.jpg" data-sub-html="An NYU researcher administers chemical signals to non-neural cells grown in a culture plate. Credit: Nikolay Kukushkin">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/memories-are-not-only.jpg" alt="Memories are not only in the brain, new research finds" title="An NYU researcher administers chemical signals to non-neural cells grown in a culture plate. Credit: Nikolay Kukushkin" width="800" height="530">
             <figcaption>
                An NYU researcher administers chemical signals to non-neural cells grown in a culture plate. Credit: Nikolay Kukushkin
            </figcaption>        </figure>
    </div><p>It's common knowledge that our brains—and, specifically, our brain cells—store memories. But a team of scientists has discovered that cells from other parts of the body also perform a memory function, opening new pathways for understanding how memory works and creating the potential to enhance learning and to treat memory-related afflictions.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>"Learning and <a href="https://medicalxpress.com/tags/memory/" rel="tag">memory</a> are generally associated with brains and brain cells alone, but our study shows that other cells in the body can learn and form memories, too," explains New York University's Nikolay V. Kukushkin, the lead author of the <a href="https://www.nature.com/articles/s41467-024-53922-x" target="_blank">study</a>, which appears in the journal <i>Nature Communications</i>.</p>
<p>The research sought to better understand if non-brain cells help with memory by borrowing from a long-established neurological property—the massed-spaced effect—which shows that we tend to retain information better when studied in spaced intervals rather than in a single, intensive session—better known as cramming for a test.</p>
<p>In the research, the scientists replicated learning over time by studying two types of non-brain human cells in a laboratory (one from nerve tissue and one from kidney tissue) and exposing them to different patterns of chemical signals—just like brain cells are exposed to patterns of neurotransmitters when we learn new information.</p>
<p>In response, the non-brain cells turned on a "memory gene"—the same gene that brain cells turn on when they detect a pattern in the information and restructure their connections in order to form memories.</p>
<p>To monitor the memory and learning process, the scientists engineered these non-brain cells to make a glowing protein, which indicated when the memory gene was on and when it was off.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>The results showed that these cells could determine when the chemical pulses, which imitated bursts of neurotransmitter in the brain, were repeated rather than simply prolonged—just as neurons in our brain can register when we learn with breaks rather than cramming all the material in one sitting.</p>
<p>Specifically, when the pulses were delivered in spaced-out intervals, they turned on the "memory gene" more strongly, and for a longer time, than when the same treatment was delivered all at once.</p>
<p>"This reflects the massed-space effect in action," says Kukushkin, a clinical associate professor of life science at NYU Liberal Studies and a research fellow at NYU's Center for Neural Science. "It shows that the ability to learn from spaced repetition isn't unique to <a href="https://medicalxpress.com/tags/brain+cells/" rel="tag">brain cells</a>, but, in fact, might be a fundamental property of all cells."</p>
<p>The researchers add that the findings not only offer new ways to study memory, but also point to potential health-related gains.</p>
<p>"This discovery opens new doors for understanding how memory works and could lead to better ways to enhance learning and treat memory problems," observes Kukushkin.</p>
<p>"At the same time, it suggests that in the future, we will need to treat our body more like the brain—for example, consider what our pancreas remembers about the pattern of our past meals to maintain healthy levels of blood glucose or consider what a cancer cell remembers about the pattern of chemotherapy."</p>
<p>The work was jointly supervised by Kukushkin and Thomas Carew, a professor in NYU's Center for Neural Science. The study's authors also included Tasnim Tabassum, an NYU researcher, and Robert Carney, an NYU undergraduate researcher at the time of the study.</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    N. V. Kukushkin et al, The massed-spaced learning effect in non-neural human cells, <i>Nature Communications</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1038/s41467-024-53922-x" target="_blank">DOI: 10.1038/s41467-024-53922-x</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Memories are not only in the brain, human cell study finds (2024, November 8)
                                                 retrieved 9 November 2024
                                                 from https://medicalxpress.com/news/2024-11-memories-brain-human-cell.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I Analyzed 650k TikTok Influencers and This Is What I Found (291 pts)]]></title>
            <link>https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</link>
            <guid>42093911</guid>
            <pubDate>Sat, 09 Nov 2024 11:49:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/">https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</a>, See on <a href="https://news.ycombinator.com/item?id=42093911">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Money was never the end goal – mrdoob – threejs creator (111 pts)]]></title>
            <link>https://twitter.com/mrdoob/status/1854662365163536613</link>
            <guid>42093795</guid>
            <pubDate>Sat, 09 Nov 2024 11:21:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/mrdoob/status/1854662365163536613">https://twitter.com/mrdoob/status/1854662365163536613</a>, See on <a href="https://news.ycombinator.com/item?id=42093795">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Mergiraf: a syntax-aware merge driver for Git (304 pts)]]></title>
            <link>https://mergiraf.org/</link>
            <guid>42093756</guid>
            <pubDate>Sat, 09 Nov 2024 11:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mergiraf.org/">https://mergiraf.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42093756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">

            <div id="content" class="page">
                    <main>
                        <p><em>Are you held back by conflicts? Then meet</em></p>

<p>Mergiraf can solve <a href="https://mergiraf.org/conflicts.html">a wide range of Git merge conflicts</a>. That's because it's aware of the trees in your files!
Thanks to <a href="https://mergiraf.org/languages.html">its understanding of your language</a>, it can often reconcile the needs of both sides.</p>
<p>You can <a href="https://mergiraf.org/adding-a-language.html">teach Mergiraf a new language</a> in a completely declarative way. It's a nonviolent animal, so it prefers that over imperatives.</p>
<h2 id="demo">Demo</h2>
<p>Configure Git to use Mergiraf instead of its default merge heuristics. This will enhance <code>git merge</code>, <code>revert</code>, <code>rebase</code>, <code>cherry-pick</code> and more.</p>


<p>You can also keep Git's original behaviour and manually invoke Mergiraf after encountering conflicts.</p>


<div>
<p><img src="https://mergiraf.org/img/scene_1.png" alt="A giraffe observes a fighting pair"></p><p><strong>Figure 1:</strong> Two git users making inadequate use of <code>blame</code>, <code>push</code> and <code>pull</code> to resolve a conflict</p>
</div>
<h2 id="ready-to-give-it-a-try"><a href="#ready-to-give-it-a-try">Ready to give it a try?</a></h2>
<p>Head to the <a href="https://mergiraf.org/installation.html">installation</a> page and start merging nonviolently today!</p>
<h2 id="aspirations"><a href="#aspirations">Aspirations</a></h2>
<p>Mergiraf is designed with your needs in mind. Its goals are:</p>
<h3 id="dont-sweep-conflicts-under-the-rug"><a href="#dont-sweep-conflicts-under-the-rug">Don't sweep conflicts under the rug</a></h3>
<p>Syntax-aware merging heuristics can sometimes be a bit too optimistic in considering a conflict resolved. Mergiraf does its best to err on the side of caution and retain conflict markers in the file when encountering suspicious cases.</p>
<p>If it manages to resolve all conflicts on its own, it encourages you to review its mediation work via the <code>mergiraf review</code> command.
If a merge looks faulty, <a href="https://mergiraf.org/usage.html#reporting-a-bad-merge">you can report it easily</a>.</p>
<h3 id="be-fast-enough-for-interactive-use"><a href="#be-fast-enough-for-interactive-use">Be fast enough for interactive use</a></h3>
<div>
<p><img src="https://mergiraf.org/img/scene_2.png" alt="The giraffe surrounds the pair with its neck and they are surprised by its intervention"></p><p><strong>Figure 2:</strong> Mergiraf offers to mediate</p>
</div>
<p>Did you know that giraffes can run as fast as 60 kilometers per hour? Anyways. The operation of merging diverging versions of files happens routinely when working on a code base, often without you noticing as long as there aren't any conflicts. So Mergiraf tries to be quick so as not to interrupt you in your tasks.</p>
<h3 id="be-open-to-other-methods"><a href="#be-open-to-other-methods">Be open to other methods</a></h3>
<p>In many cases, line-based merging works just great and there is no need for tree-munging business. If a line-based merge is conflict-free, then Mergiraf just returns that merge (which is very quick).
One exception to this rule is <a href="https://mergiraf.org/conflicts.html#line-based-merges">when line-based merging creates duplicate keys</a>. In such a case, Mergiraf does a bit more work to resolve the issue or highlight it to you with conflict markers.</p>


                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="https://mergiraf.org/installation.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>

            <nav aria-label="Page navigation">

                    <a rel="next prefetch" href="https://mergiraf.org/installation.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: HTML-to-Markdown – convert entire websites to Markdown with Golang/CLI (234 pts)]]></title>
            <link>https://github.com/JohannesKaufmann/html-to-markdown</link>
            <guid>42093511</guid>
            <pubDate>Sat, 09 Nov 2024 09:48:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/JohannesKaufmann/html-to-markdown">https://github.com/JohannesKaufmann/html-to-markdown</a>, See on <a href="https://news.ycombinator.com/item?id=42093511">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">html-to-markdown</h2><a id="user-content-html-to-markdown" aria-label="Permalink: html-to-markdown" href="#html-to-markdown"></a></p>
<p dir="auto">A robust html-to-markdown converter that transforms HTML (even entire websites) into clean, readable Markdown. It supports complex formatting, customizable options, and plugins for full control over the conversion process.</p>
<p dir="auto">Use the fully extendable <a href="#golang-library">Golang library</a> or a quick <a href="#cli---using-it-on-the-command-line">CLI command</a>. Alternatively, try the <a href="https://html-to-markdown.com/demo" rel="nofollow">Online Demo</a> or <a href="https://html-to-markdown.com/api" rel="nofollow">REST API</a> to see it in action!</p>
<p dir="auto">Here are some <em>cool features</em>:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Bold &amp; Italic:</strong> Supports bold and italic—even within single words.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_bold_italic.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_bold_italic.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>List:</strong> Handles ordered and unordered lists with full nesting support.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_list.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_list.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Blockquote:</strong> Blockquotes can include other elements, with seamless support for nested quotes.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_blockquote.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_blockquote.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Inline Code &amp; Code Block:</strong> Correctly handles backticks and multi-line code blocks, preserving code structure.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_code.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_code.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Link &amp; Image:</strong> Properly formats multi-line links, adding escapes for blank lines where needed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_link_image.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_link_image.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Smart Escaping:</strong> Escapes special characters only when necessary, to avoid accidental Markdown rendering.
🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/ESCAPING.md">ESCAPING.md</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_escaping.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_escaping.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Remove/Keep HTML:</strong> Choose to strip or retain specific HTML tags for ultimate control over output.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_wrapper.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_wrapper.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Plugins:</strong> Easily extend with plugins. Or create custom ones to enhance functionality.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_strikethrough.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_strikethrough.png" alt=""></a></p>
</li>
</ul>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Golang Library</h2><a id="user-content-golang-library" aria-label="Permalink: Golang Library" href="#golang-library"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go get -u github.com/JohannesKaufmann/html-to-markdown/v2"><pre>go get -u github.com/JohannesKaufmann/html-to-markdown/v2</pre></div>
<p dir="auto"><em>Or if you want a specific commit add the suffix <code>/v2@commithash</code></em></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">This is the documentation for the v2 library. For the old version switch to the <a href="https://github.com/JohannesKaufmann/html-to-markdown/tree/v1">"v1" branch</a>.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/JohannesKaufmann/html-to-markdown/v2" rel="nofollow"><img src="https://camo.githubusercontent.com/4de9ed495aaf54b8396c04b85bc3edb47d7736aab876b29756705763dc8d1ec1/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f4a6f68616e6e65734b6175666d616e6e2f68746d6c2d746f2d6d61726b646f776e2f76322e737667" alt="Go V2 Reference" data-canonical-src="https://pkg.go.dev/badge/github.com/JohannesKaufmann/html-to-markdown/v2.svg"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	htmltomarkdown &quot;github.com/JohannesKaufmann/html-to-markdown/v2&quot;
)

func main() {
	input := `<strong>Bold Text</strong>`

	markdown, err := htmltomarkdown.ConvertString(input)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(markdown)
	// Output: **Bold Text**
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"log"</span>

	htmltomarkdown <span>"github.com/JohannesKaufmann/html-to-markdown/v2"</span>
)

<span>func</span> <span>main</span>() {
	<span>input</span> <span>:=</span> <span>`&lt;strong&gt;Bold Text&lt;/strong&gt;`</span>

	<span>markdown</span>, <span>err</span> <span>:=</span> <span>htmltomarkdown</span>.<span>ConvertString</span>(<span>input</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>fmt</span>.<span>Println</span>(<span>markdown</span>)
	<span>// Output: **Bold Text**</span>
}</pre></div>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/basics/main.go">Example code, basics</a></li>
</ul>
<p dir="auto">The function <code>htmltomarkdown.ConvertString()</code> is a <em>small wrapper</em> around <code>converter.NewConverter()</code> and the <em>base</em> and <em>commonmark</em> plugins. If you want more control, use the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/converter&quot;
	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/plugin/base&quot;
	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/plugin/commonmark&quot;
)

func main() {
	input := `<strong>Bold Text</strong>`

	conv := converter.NewConverter(
		converter.WithPlugins(
			base.NewBasePlugin(),
			commonmark.NewCommonmarkPlugin(
				commonmark.WithStrongDelimiter(&quot;__&quot;),
				// ...additional configurations for the plugin
			),
		),
	)

	markdown, err := conv.ConvertString(input)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(markdown)
	// Output: __Bold Text__
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"log"</span>

	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/converter"</span>
	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/plugin/base"</span>
	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/plugin/commonmark"</span>
)

<span>func</span> <span>main</span>() {
	<span>input</span> <span>:=</span> <span>`&lt;strong&gt;Bold Text&lt;/strong&gt;`</span>

	<span>conv</span> <span>:=</span> <span>converter</span>.<span>NewConverter</span>(
		<span>converter</span>.<span>WithPlugins</span>(
			<span>base</span>.<span>NewBasePlugin</span>(),
			<span>commonmark</span>.<span>NewCommonmarkPlugin</span>(
				<span>commonmark</span>.<span>WithStrongDelimiter</span>(<span>"__"</span>),
				<span>// ...additional configurations for the plugin</span>
			),
		),
	)

	<span>markdown</span>, <span>err</span> <span>:=</span> <span>conv</span>.<span>ConvertString</span>(<span>input</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>fmt</span>.<span>Println</span>(<span>markdown</span>)
	<span>// Output: __Bold Text__</span>
}</pre></div>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/options/main.go">Example code, options</a></li>
</ul>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">If you use <code>NewConverter</code> directly make sure to also <strong>register the commonmark and base plugin</strong>.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Plugins</h3><a id="user-content-plugins" aria-label="Permalink: Plugins" href="#plugins"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Published Plugins</h4><a id="user-content-published-plugins" aria-label="Permalink: Published Plugins" href="#published-plugins"></a></p>
<p dir="auto">These are the plugins located in the <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/plugin">plugin folder</a>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Base</td>
<td>Implements basic shared functionality (e.g. removing nodes)</td>
</tr>
<tr>
<td>Commonmark</td>
<td>Implements Markdown according to the <a href="https://spec.commonmark.org/" rel="nofollow">Commonmark Spec</a></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>GitHubFlavored</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>TaskListItems</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>Strikethrough</td>
<td>Converts <code>&lt;strike&gt;</code>, <code>&lt;s&gt;</code>, and <code>&lt;del&gt;</code> to the <code>~~</code> syntax.</td>
</tr>
<tr>
<td>Table</td>
<td><em>planned</em></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>VimeoEmbed</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>YoutubeEmbed</td>
<td><em>planned</em></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>ConfluenceCodeBlock</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>ConfluenceAttachments</td>
<td><em>planned</em></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Not all the plugins from v1 are already ported to v2. These will soon be implemented...</p>
</div>
<p dir="auto">These are the plugins in other repositories:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>[Plugin Name](Your Link)</td>
<td>A short description</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Writing Plugins</h4><a id="user-content-writing-plugins" aria-label="Permalink: Writing Plugins" href="#writing-plugins"></a></p>
<p dir="auto">You want to write custom logic?</p>
<ol dir="auto">
<li>
<p dir="auto">Write your logic and <strong>register</strong> it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/autocomplete_register.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/autocomplete_register.png" alt=""></a></p>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/register/main.go">Example code, register</a></li>
</ul>
</li>
<li>
<p dir="auto"><em>Optional:</em> Package your logic into a <strong>plugin</strong> and publish it.</p>
<ul dir="auto">
<li>🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/WRITING_PLUGINS.md">WRITING_PLUGINS.md</a></li>
</ul>
</li>
</ol>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI - Using it on the command line</h2><a id="user-content-cli---using-it-on-the-command-line" aria-label="Permalink: CLI - Using it on the command line" href="#cli---using-it-on-the-command-line"></a></p>
<p dir="auto">Using the Golang library provides the most customization, while the CLI is the simplest way to get started.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation-1" aria-label="Permalink: Installation" href="#installation-1"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew Tap</h4><a id="user-content-homebrew-tap" aria-label="Permalink: Homebrew Tap" href="#homebrew-tap"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install JohannesKaufmann/tap/html2markdown"><pre>brew install JohannesKaufmann/tap/html2markdown</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Manually</h4><a id="user-content-manually" aria-label="Permalink: Manually" href="#manually"></a></p>
<p dir="auto">Download the pre-compiled binaries from the <a href="https://github.com/JohannesKaufmann/html-to-markdown/releases">releases page</a> and copy them to the desired location.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Version</h3><a id="user-content-version" aria-label="Permalink: Version" href="#version"></a></p>

<div dir="auto"><p dir="auto">Note</p><p dir="auto">Make sure that <code>--version</code> prints <code>2.X.X</code> as there is a different CLI for V2 of the converter.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-1" aria-label="Permalink: Usage" href="#usage-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo &quot;<strong>important</strong>&quot; | html2markdown

**important**"><pre>$ <span>echo</span> <span><span>"</span>&lt;strong&gt;important&lt;/strong&gt;<span>"</span></span> <span>|</span> html2markdown

<span>**</span>important<span>**</span></pre></div>
<div data-snippet-clipboard-copy-content="$ curl --no-progress-meter http://example.com | html2markdown

# Example Domain

This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)"><pre lang="text"><code>$ curl --no-progress-meter http://example.com | html2markdown

# Example Domain

This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)
</code></pre></div>
<p dir="auto"><em>(The cli does not support every option yet. Over time more customization will be added)</em></p>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Extending with Plugins</h3><a id="user-content-extending-with-plugins" aria-label="Permalink: Extending with Plugins" href="#extending-with-plugins"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Need your own logic? Write your own code and then <strong>register</strong> it.</p>
<ul dir="auto">
<li>
<p dir="auto">Don't like the <strong>defaults</strong> that the library uses? You can use <code>PriorityEarly</code> to run you logic <em>earlier</em> than others.</p>
</li>
<li>
<p dir="auto">🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/register/main.go">Example code, register</a></p>
</li>
</ul>
</li>
<li>
<p dir="auto">If you believe that you logic could also benefit others, you can package it up into a <strong>plugin</strong>.</p>
<ul dir="auto">
<li>🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/WRITING_PLUGINS.md">WRITING_PLUGINS.md</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bugs</h3><a id="user-content-bugs" aria-label="Permalink: Bugs" href="#bugs"></a></p>
<p dir="auto">You found a bug?</p>
<p dir="auto"><a href="https://github.com/JohannesKaufmann/html-to-markdown/issues/new/choose">Open an issue</a> with the HTML snippet that does not produce the expected results. Please, please, plase <em>submit the HTML snippet</em> that caused the problem. Otherwise it is very difficult to reproduce and fix...</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security</h3><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">This library produces markdown that is readable and can be changed by humans.</p>
<p dir="auto">Once you convert this markdown back to HTML (e.g. using <a href="https://github.com/yuin/goldmark">goldmark</a> or <a href="https://github.com/russross/blackfriday">blackfriday</a>) you need to be careful of malicious content.</p>
<p dir="auto">This library does NOT sanitize untrusted content. Use an HTML sanitizer such as <a href="https://github.com/microcosm-cc/bluemonday">bluemonday</a> before displaying the HTML in the browser.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/SECURITY.md">SECURITY.md</a> if you find a security vulnerability</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Goroutines</h3><a id="user-content-goroutines" aria-label="Permalink: Goroutines" href="#goroutines"></a></p>
<p dir="auto">You can use the <code>Converter</code> from (multiple) goroutines. Internally a mutex is used &amp; there is a test to verify that behaviour.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Escaping &amp; Backslash</h3><a id="user-content-escaping--backslash" aria-label="Permalink: Escaping &amp; Backslash" href="#escaping--backslash"></a></p>
<p dir="auto">Some characters have a special meaning in markdown (e.g. "*" for emphasis). The backslash <code>\</code> character is used to "escape" those characters. That is perfectly safe and won't be displayed in the final render.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/ESCAPING.md">ESCAPING.md</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You want to contribute? Thats great to hear! There are many ways to help:</p>
<p dir="auto">Helping to answer questions, triaging issues, writing documentation, writing code, ...</p>
<p dir="auto">If you want to make a code change: Please first discuss the change you wish to make, by opening an issue. I'm also happy to guide you to where a change is most likely needed. There are also extensive tests (see below) so you can freely experiment 🧑‍🔬</p>
<p dir="auto"><em>Note: The outside API should not change because of backwards compatibility...</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing</h3><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto">You don't have to be afraid of breaking the converter, since there are many "Golden File" tests:</p>
<p dir="auto">Add your problematic HTML snippet to one of the <code>.in.html</code> files in the <code>testdata</code> folders. Then run <code>go test -update</code> and have a look at which <code>.out.md</code> files changed in GIT.</p>
<p dir="auto">You can now change the internal logic and inspect what impact your change has by running <code>go test -update</code> again.</p>
<p dir="auto"><em>Note: Before submitting your change as a PR, make sure that you run those tests and check the files into GIT...</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Unless otherwise specified, the project is licensed under the terms of the MIT license.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/LICENSE">LICENSE</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SVDQuant: 4-Bit Quantization Powers 12B Flux on a 16GB 4090 GPU with 3x Speedup (147 pts)]]></title>
            <link>https://hanlab.mit.edu/blog/svdquant</link>
            <guid>42093112</guid>
            <pubDate>Sat, 09 Nov 2024 07:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hanlab.mit.edu/blog/svdquant">https://hanlab.mit.edu/blog/svdquant</a>, See on <a href="https://news.ycombinator.com/item?id=42093112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Muyang Li*, Yujun Lin*, Zhekai Zhang*, Tianle Cai, Xiuyu Li, Junxian Guo, Enze Xie, Chenlin Meng, Jun-Yan Zhu, Song Han</p><p>November 7, 2024</p></div><p>A new post-training training quantization paradigm for diffusion models, which quantize both the weights and activations of FLUX.1 to 4 bits, achieving 3.5× memory and 8.7× latency reduction on a 16GB laptop 4090 GPU.</p><div><p>
  <img src="https://github.com/mit-han-lab/nunchaku/blob/main/assets/demo.gif?raw=true" width="70%">
</p><p>Check our interactive demo at <a href="https://svdquant.mit.edu/">https://svdquant.mit.edu</a>! Our quantization library is at <a href="https://github.com/mit-han-lab/deepcompressor">github.com/mit-han-lab/deepcompressor</a> and inference engine is at <a href="https://github.com/mit-han-lab/nunchaku">github.com/mit-han-lab/nunchaku</a>. Our paper is at <a href="http://arxiv.org/abs/2411.05007">this link</a>.</p><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1bcef3c3ec127e8078fd_672d1b2115081c1e8ac82ea9_teaser.jpeg" loading="lazy" alt=""></p></figure><p>SVDQuant is a post-training quantization technique for 4-bit weights and activations that well maintains visual fidelity. On 12B FLUX.1-dev, it achieves 3.6× memory reduction compared to the BF16 model. By eliminating CPU offloading, it offers 8.7× speedup over the 16-bit model when on a 16GB laptop 4090 GPU, 3× faster than the NF4 W4A16 baseline. On PixArt-∑, it demonstrates significantly superior visual quality over other W4A4 or even W4A8 baselines.</p><h2>Background</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a9dcbacb7d59271c5662e_672a9a6c364fccc4e4443187_trend.jpeg" loading="lazy" alt=""></p><figcaption>Computation <em>v.s.</em> parameters for LLMs and diffusion models.</figcaption></figure><p>Diffusion models are revolutionizing AI with their ability to generate high-quality images from text prompts. To improve image quality and improve the alignment between text and image, researchers are scaling up these models. As shown in the right figure, while Stable Diffusion 1.4 has 800 million parameters, newer models like AuraFlow and FLUX.1 reach billions, delivering more refined and detailed outputs. However, scaling brings challenges: these models become computationally heavy, demanding high memory and longer processing times, making them prohibitive for real-time applications.</p><p>As Moore's law slows down, hardware vendors are turning to low-precision inference, such as NVIDIA's new 4-bit floating point (FP4) precision in Blackwell. In large language models (LLMs), quantization has helped reduce model sizes and speed up inference, primarily by addressing latency from loading model weights. Diffusion models, however, are computationally bound, even for single batches, so quantizing weights alone yields limited gains. To achieve measured speedups, both weights and activations must be quantized to the same bit width; otherwise, the lower precision is upcast during computation, negating any performance benefits.</p><p>In this blog, we introduce SVDQuant to quantize both the weights and activations of diffusion models to 4 bits. At such an aggressive level, conventional post-training methods fall short. Unlike smoothing, which redistributes outliers, SVDQuant absorbs them through a high-precision low-rank branch, significantly preserving image quality. Visual examples demonstrate its effectiveness. See the above figure for some visual examples.</p><h2>SVDQuant: Absorbing Outliers via Low-Rank Branch</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a66701e9812afb49e0cfa_672a651614cb88ed4fd9dc29_intuition-animate.gif" loading="lazy" alt=""></p></figure><div>


    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LaTeX Rendering Example</title>
    


    <p>
The key idea behind SVDQuant is to introduce an additional low-rank branch that can absorb quantization difficulties in both weights and activations. As shown in the above animation, originally, both the activation \( \boldsymbol{X} \) and weights \( \boldsymbol{W} \) contain massive outliers, making 4-bit quantization challenging. We can first aggregate the outliers by migrating them from activations to weights via smoothing, resulting in the updated activation \( \hat{\boldsymbol{X}} \) and weights \( \hat{\boldsymbol{W}} \). While \( \hat{\boldsymbol{X}} \) becomes easier to quantize, \( \hat{\boldsymbol{W}} \) now becomes more difficult. At the last stage, SVDQuant further decomposes \( \hat{\boldsymbol{W}} \) into a low-rank component \( \boldsymbol{L}_1 \boldsymbol{L}_2 \) and a residual \( \hat{\boldsymbol{W}} - \boldsymbol{L}_1 \boldsymbol{L}_2 \) with Singular Value Decomposition (SVD). As the singular value distribution of \( \hat{\boldsymbol{W}} \) is highly imbalanced, with only the first several values being significantly larger, removing these dominant values can dramatically reduce \( \hat{\boldsymbol{W}} \)’s magnitude and outliers, as suggested by <a href="https://en.wikipedia.org/wiki/Low-rank_approximation">Eckart-Young-Mirsky theorem</a>. Thus, the quantization difficulty is alleviated by the low-rank branch, which runs at 16-bit precision. The below figure illustrates an example value distribution of the input activations and weights in PixArt-∑.
    </p>

</div><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672abca95c5f67bff08b7664_672abca0fde8974bb6d63e6d_distribution.jpeg" loading="lazy" alt=""></p><figcaption>Example value distribution of inputs and weights in PixArt-∑.</figcaption></figure><h2>Nunchaku: Fusing Low-Rank and Low-Bit Branch Kernels</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1fccad9d41d739c84c2c_672a6ac09cf7fc46071c3fb8_672a6a991adf3346a0ee4dbb_engine.jpeg" loading="lazy" alt=""></p></figure><p>Although the low-rank branch adds only minor computational costs on paper, running it separately can lead to significant latency overhead—about 50% of the 4-bit branch's latency, as shown in figure (a). This is because, despite reduced computation costs with a small rank, the data size of input and output activations remains the same, shifting the bottleneck to memory access instead of computation.</p><p>To address this, we co-designed our inference engine, Nunchaku, with the SVDQuant algorithm. Specifically, we noted that the down projection in the low-rank branch uses the same input as the quantization kernel in the low-bit branch, and the up projection shares the same output as the 4-bit computation kernel, as shown in figure (b). By fusing the down projection with the quantization kernel and the up projection with the 4-bit computation kernel, the low-rank branch can now share activations with the low-bit branch. This eliminates extra memory access and cuts the number of kernel calls in half. As a result, the low-rank branch now adds only 5–10% additional latency, making its cost almost negligible.</p><h2>Performance</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1bcdf3c3ec127e8078f3_672d1b5772f1247fa24e231d_efficiency.jpeg" loading="lazy" alt=""></p></figure><p>SVDQuant reduces the model size of the 12B FLUX.1 by 3.6×. Additionally, Nunchaku further cuts memory usage of the 16-bit model by 3.5× and delivers 3.0× speedups over the NF4 W4A16 baseline on both the desktop and laptop NVIDIA RTX 4090 GPUs. Remarkably, on laptop 4090, it achieves in total 10.1× speedup by eliminating CPU offloading. </p><h2>Quality</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672ac9098069a7c6f2baedbd_672ac78c0b59dc8da3c15987_visual.jpeg" loading="lazy" alt=""></p></figure><p>On FLUX.1 models, our 4-bit models outperform the NF4 W4A16 baselines, demonstrating superior text alignment and closer similarity to the 16-bit models. For instance, NF4 misinterprets "dinosaur style," generating a real dinosaur. On PixArt-∑ and SDXL-Turbo, our 4-bit results demonstrate noticeably better visual quality than ViDiT-Q's and MixDQ's W4A8 results.</p><p>‍</p><h2>Integrate with LoRA</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a6c74c47e63fff4b5b216_672a6c25ef1acf8704ef65af_lora.jpeg" loading="lazy" alt=""></p></figure><p>Traditional quantization methods require fusing LoRA branches and then requantizing the model when integrating LoRAs. Our SVDQuant, however, avoids redundant memory access, making it possible to add a separate LoRA branch directly. The figure above shows visual examples of our INT4 FLUX.1-dev model with LoRAs applied in five distinct styles—<a href="https://huggingface.co/XLabs-AI/flux-RealismLora">Realism</a>, <a href="https://huggingface.co/aleksa-codes/flux-ghibsky-illustration">Ghibsky Illustration</a>, <a href="https://huggingface.co/alvdansen/sonny-anime-fixed">Anime</a>, <a href="https://huggingface.co/Shakker-Labs/FLUX.1-dev-LoRA-Children-Simple-Sketch">Children Sketch</a>, and <a href="https://huggingface.co/linoyts/yarn_art_Flux_LoRA">Yarn Art</a>. Our INT4 model adapts seamlessly to each style, maintaining the image quality of the original 16-bit version.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Texture-Less Text Rendering (168 pts)]]></title>
            <link>https://poniesandlight.co.uk/reflect/debug_print_text/</link>
            <guid>42093037</guid>
            <pubDate>Sat, 09 Nov 2024 07:27:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://poniesandlight.co.uk/reflect/debug_print_text/">https://poniesandlight.co.uk/reflect/debug_print_text/</a>, See on <a href="https://news.ycombinator.com/item?id=42093037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  	
<figure>
<img src="https://poniesandlight.co.uk/img/reflect/debug_print_text/look_ma.png" loading="lazy">
</figure>
<div>
<p>Sometimes, all you want is to quickly print some text into a Renderpass. But <a href="https://stackoverflow.com/questions/22080881/how-to-render-text-in-modern-opengl-with-glsl">traditionally, drawing text</a> requires you first to render all possible glyphs of a font into an atlas, to bind this atlas as a texture, and then to render glyphs one by one by drawing triangles on screen, with every triangle picking the correct glyph from the font atlas texture.</p>
<p>This is how <a href="https://github.com/ocornut/imgui">imgui</a> does it, how anyone using <a href="https://github.com/nothings/stb/blob/master/stb_truetype.h">stb_truetype</a> does it, and it’s delightfully close to how <a href="https://en.wikipedia.org/wiki/Typesetting">type setting</a> used to be done ages bygone on physical letterpresses.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/upper_case_and_lower_case.jpg" alt="Composing cases of an early letterpress" title="Composing cases of an early letterpress">
<figcaption>
    Case in point: Some ancient Letterpress Type Cases (public domain) – <a href="https://babel.hathitrust.org/846c4e7f-3fa3-4275-b53c-3183150e9481">source</a><p>In case you wonder – <a href="https://www.mcgill.ca/oss/article/did-you-know-history/why-it-called-upper-and-lower-case">yes</a></p><p>That’s enough (ed).
</p></figcaption>
</figure>
<p>Quaint, correct, but also quite cumbersome.</p>
<p>What if – for quick and dirty debug messaging – there was a simpler way to do this?</p>
<p>Here, I’ll describe a technique for <em>texture-less</em> rendering of debug text. On top of it all, it draws all the text in a single draw call.</p>
<h2 id="the-font-pixels-sans-texture">The Font: Pixels Sans Texture&nbsp;<a href="#the-font-pixels-sans-texture"></a></h2>
<p>How can we get rid of the font atlas texture? We’d need to store a font atlas or something similar <em>directly inside</em> the fragment shader. Obviously, we can’t store <em>bitmaps</em> inside our shaders, but we can store integer constants, which, if you squint hard enough, are nothing but maps of bits. Can we pretend that an integer is a bitmap?</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/0x42_as_bitmap.svg" alt="The integer 0x42 as a bitmap" title="The integer 0x42 as a bitmap">
<figcaption>
    An 8 bit integer as a bitmap. The value 66, or <code>0x42</code> in hex notation, translates to <code>0b01000010</code> in binary notation. If we assume that every bit is a pixel  on/off value, we get something like this.
</figcaption>
</figure>
<p>We can draw this to the screen using a GLSL fragment shader by mapping a fragment’s <code>xy</code> position to the bit that is covered by it in the “bitmap”. If the bit is set, we draw in the foreground colour. If the bit is not set, we draw in the background colour.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>bitmap</span> <span>=</span> <span>0x42</span><span>;</span>
</span></span><span><span><span>vec4</span> <span>col_fg</span> <span>=</span> <span>vec4</span><span>(</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span><span>vec4</span> <span>col_bg</span> <span>=</span> <span>vec4</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span>
</span></span><span><span><span>// vec2 uv is the normalized texture coordinate for the fragment</span>
</span></span><span><span><span>// with the origin top-left</span>
</span></span><span><span><span>uint</span> <span>which_bit</span> <span>=</span> <span>7</span> <span>-</span> <span>min</span><span>(</span><span>7</span><span>,</span><span>floor</span><span>(</span><span>uv</span><span>.</span><span>x</span> <span>*</span> <span>8</span><span>));</span> 
</span></span><span><span>
</span></span><span><span><span>out_color</span> <span>=</span> <span>mix</span><span>(</span><span>col_bg</span><span>,</span> <span>col_fg</span><span>,</span> <span>(</span><span>bitmap</span> <span>&gt;&gt;</span> <span>which_bit</span><span>)</span> <span>&amp;</span> <span>1</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>Now, one byte will only draw one line of pixels for us. If we want to draw nicer glyphs, we will need more bytes. If we allowed <span>16 bytes</span><span> (that’s 16 lines)</span> per glyph, this would give us an 8x16 pixel canvas to work with. A single <code>uvec4</code>, which is a built-in type in GLSL, covers exactly the correct amount of bytes that we need.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/character_A.svg" alt="The Glyph A encoded as an uvec4" title="The Glyph A encoded as an uvec4">
<figcaption>
    The character <code>A</code> encoded in 16 bytes, stored as an <code>uvec4</code>, that’s 4 uints with each 4 bytes.
</figcaption>
</figure>
<p>16 bytes per glyph seems small enough; It should allow us to encode the complete <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> subset of 96 printable glyphs in all of 1536 bytes of shader <span>memory</span><span>. (We could probably compress this further, but we would lose simplicity and/or readability)</span>.</p>
<h2 id="where-do-we-get-the-bitmaps-from">Where do we get the bitmaps from?&nbsp;<a href="#where-do-we-get-the-bitmaps-from"></a></h2>
<p>Conveniently, the encoding of a font into bitmaps such as described above is very much the definition of the venerable <a href="https://en.wikipedia.org/wiki/PC_Screen_Font">PSF1 format</a>, give or take a few header bytes. We can therefore harvest the glyph pixels from any PSF1 terminal font by opening it in a hex editor such as <a href="https://imhex.werwolv.net/">ImHex</a>, travelling past the header (4 bytes) and the first section of non-printable glyphs (512 bytes), and then exporting the raw data for the next 96 glyphs (1536 bytes) by using “Copy as → C Array”.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/imhex_screenshot.png" alt="A Screenshot of ImHex" title="A Screenshot of ImHex">
<figcaption>
    The ImHex hex editor has a really useful feature: you can copy binary data as a c-array.
</figcaption>
</figure>
<p>This will give us a nicely formatted array of chars, which we can easily edit into an array of <code>uint</code>s, which we then group into <code>uvec4</code>s. We need to remember that just concatenating the raw chars into <code>uint</code>s flips the endianness of our <code>uint</code>s, but we can always flip this back when we sample the font data…</p>
<p>Once we’re done, this is how our font bitmap data table looks like in the fragment shader:</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>const</span> <span>uvec4</span> <span>font_data</span><span>[</span><span>96</span><span>]</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x1e: SPACE</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080800</span><span>,</span> <span>0x08080000</span> <span>},</span> <span>// 0x21: '!'</span>
</span></span><span><span>  <span>{</span> <span>0x00002222</span><span>,</span> <span>0x22220000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x22: '\'</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x1212127E</span><span>,</span> <span>0x24247E48</span><span>,</span> <span>0x48480000</span> <span>},</span> <span>// 0x23: '#'</span>
</span></span><span><span>  <span>// ... etc ... </span>
</span></span><span><span>
</span></span><span><span>  <span>{</span> <span>0x00000808</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080808</span> <span>},</span> <span>// 0x7C: '|'</span>
</span></span><span><span>  <span>{</span> <span>0x00000030</span><span>,</span> <span>0x08081010</span><span>,</span> <span>0x08040810</span><span>,</span> <span>0x10080830</span> <span>},</span> <span>// 0x7D: '}'</span>
</span></span><span><span>  <span>{</span> <span>0x00000031</span><span>,</span> <span>0x49460000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x7E: '~'</span>
</span></span><span><span>  <span>{</span> <span>0xFC1B26EF</span><span>,</span> <span>0xC8E04320</span><span>,</span> <span>0x8958625E</span><span>,</span> <span>0x79BAEE7E</span> <span>},</span> <span>// 0x7F: BACKSPACE</span>
</span></span><span><span><span>};</span>                                              </span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>I say table, because the <code>font_data</code> array now stores the bitmaps for 96 character glyphs, indexed by their ASCII value (minus 0x20). This table therefore covers the full printable ASCII range from <code>0x20</code> <kbd>SPACE</kbd> to <code>0x7F</code> <kbd>BACKSPACE</kbd> (inclusive), but in the snippet above I’m showing only 8 of them, to save space.</p>
<p>So far, all this is just so that we don’t have to bind a texture when drawing our text. But how to draw the text itself?</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small.png" alt="Text output" title="Text output">
<figcaption>
    This is what we want to print at the end of this process
</figcaption>
</figure>
<h2 id="one-draw-call-thats-all">One Draw Call, That’s All.&nbsp;<a href="#one-draw-call-thats-all"></a></h2>
<p>We’re going to use a single <strong>instanced</strong> draw call.</p>

</div>
<div>
    
<p>With instanced drawing, we don’t have to repeatedly issue draw <em>instructions</em>, since we encode the logic into per-instance data. One draw call contains everything we need, provided it uses two attribute streams. The fist stream, per-draw, has just the necessary information to draw a generic quad. And the second stream, per-instance, packs the two pieces of information that change with every instance of such a quad: First, a position offset, so that we know <em>where in screen space</em> to draw the quad. And second, of course, the text that we want to print.</p>
<p>For the position offset we can use one float each for x and y, which leaves two floats for this particular attribute binding <span>unused</span><span> (attribute bindings in GLSL/Vulkan are at minimum the equivalent of 4 floats wide)</span>. We have more than enough space to use one extra float to pack in a font scale parameter, if we like.</p>

</div>
<div>
  
<p>For the text that we want to print, we have a similarly wasteful situation – the smallest basic vertex attribute data type <a href="https://docs.vulkan.org/spec/latest/chapters/fxvertex.html#fxvertex-attrib-location">is usually 32bit wide</a>, and so it makes sense to make best use of this and pack at least 4 characters at a time. If we do this, we must make sure that the message that we want to print has a length divisible by 4. If it was shorter, we need to fill up the difference with zero byte (<code>\0</code>) characters. Conveniently, the zero byte is also used to signal the end of a c-string.</p>
<p>Our per-instance data looks like this:</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="cpp"><span><span><span>struct</span> <span>word_data</span> <span>{</span>
</span></span><span><span>  <span>float</span>          <span>pos_and_scale</span><span>[</span> <span>3</span> <span>];</span> <span>// xy position + scale 
</span></span></span><span><span><span></span>  <span>uint32_t</span>       <span>word</span><span>;</span>               <span>// four characters that we want to print
</span></span></span><span><span><span></span><span>};</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>cpp</span>
</p></div><p>It’s the application’s responsibility to split up the message into chunks of 4 characters, to convert these four characters into an <code>unit32_t</code>, and to store it into a <code>word_data</code> struct together with the position offset for where on screen to render these four characters. Once a <code>word_data</code> is filled, we append it into an array where we accumulate all the data for our text draw calls. Once we are ready to draw, we can then bind this array as a per-instance binding to our debug text drawing pipeline, and draw all text with a single <span>instanced draw call</span><span>, with the number of instances being the number of quads that we want to draw</span>.</p>
<p>More interesting things happen in the vertex and fragment shader of the debug text drawing pipeline.</p>
<h2 id="vertex-shader">Vertex Shader&nbsp;<a href="#vertex-shader"></a></h2>
<p>Our vertex shader produces three outputs.</p>
<p>First, it writes to <code>gl_Position</code> to place the vertices for our triangles on the screen. This operates in <span> NDC </span><span> = Normalised Device </span> “screen space” Coordinates. We calculate an offset for each vertex using the per-instance <code>pos_and_scale</code> attribute data.</p>
<p>The second output of the vertex shader is the word that we want to render: We just pass though the attribute <code>uint</code> as an output to the fragment shader – but we make sure to use the <code>flat</code> qualifier so that it does not get interpolated.</p>
<p>And then, the vertex shader synthesizes texture coordinates (via <code>gl_VertexIndex</code>). It does so pretty cleverly:</p>
<ul>
<li><code>12 &gt;&gt; gl_VertexIndex &amp; 1</code> will give a sequence <code>0, 0, 1, 1</code>,</li>
<li><code> 9 &gt;&gt; gl_VertexIndex &amp; 1</code> will give a sequence <code>1, 0, 0, 1</code>,</li>
</ul>
<p>This creates a sequence of uv coordinates <code>(0,1), (0,0), (1,0), (1,1)</code> in a branchless way.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>#version 450 core</span>
</span></span><span><span>
</span></span><span><span><span>#extension GL_ARB_separate_shader_objects : enable</span>
</span></span><span><span><span>#extension GL_ARB_shading_language_420pack : enable</span>
</span></span><span><span>
</span></span><span><span><span>// Inputs </span>
</span></span><span><span><span>// Uniforms - Push Constants</span>
</span></span><span><span><span>layout</span> <span>(</span><span>push_constant</span><span>)</span> <span>uniform</span> <span>Params</span>
</span></span><span><span><span>{</span>
</span></span><span><span>	<span>vec2</span> <span>u_resolution</span><span>;</span> <span>// screen canvas resolution in physical pixels</span>
</span></span><span><span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>// Input Attributes</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>0</span><span>)</span> <span>in</span> <span>vec3</span> <span>pos</span><span>;</span>      <span>// "vanilla" vertex position attribute - given in pixels</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>1</span><span>)</span> <span>in</span> <span>uint</span> <span>word</span><span>;</span>     <span>// per-instance: four chars</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>2</span><span>)</span> <span>in</span> <span>vec3</span> <span>word_pos</span><span>;</span> <span>// per-instance: where to place the word in screen space</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>3</span><span>)</span> <span>in</span> <span>vec4</span> <span>col_fg</span><span>;</span>   <span>// per-instance: foreground colour</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>4</span><span>)</span> <span>in</span> <span>vec4</span> <span>col_bg</span><span>;</span>   <span>// per-instance: background colour</span>
</span></span><span><span>
</span></span><span><span><span>// Vertex Outputs </span>
</span></span><span><span><span>struct</span> <span>per_word_data</span> <span>{</span>
</span></span><span><span>	<span>uint</span> <span>msg</span><span>;</span>
</span></span><span><span>	<span>vec4</span> <span>fg_colour</span><span>;</span>
</span></span><span><span>	<span>vec4</span> <span>bg_colour</span><span>;</span>
</span></span><span><span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>out</span> <span>gl_PerVertex</span> <span>{</span> <span>vec4</span> <span>gl_Position</span><span>;</span> <span>};</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>0</span><span>)</span> <span>out</span> <span>vec2</span> <span>outTexCoord</span><span>;</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>1</span><span>)</span> <span>flat</span> <span>out</span> <span>per_word_data</span> <span>outMsg</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>void</span> <span>main</span><span>()</span> 
</span></span><span><span><span>{</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>msg</span> <span>=</span> <span>word</span><span>;</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>fg_colour</span> <span>=</span> <span>col_fg</span><span>;</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>bg_colour</span> <span>=</span> <span>col_bg</span><span>;</span>
</span></span><span><span>
</span></span><span><span>	<span>vec2</span> <span>scale_factor</span> <span>=</span> <span>vec2</span><span>(</span><span>1.</span><span>,</span><span>2.</span><span>)</span><span>/</span><span>(</span><span>u_resolution</span><span>);</span>
</span></span><span><span>	<span>outTexCoord</span> <span>=</span> <span>vec2</span><span>((</span><span>12</span> <span>&gt;&gt;</span> <span>gl_VertexIndex</span><span>)</span> <span>&amp;</span><span>1</span><span>,</span> <span>(</span><span>9</span> <span>&gt;&gt;</span> <span>gl_VertexIndex</span> <span>)</span> <span>&amp;</span><span>1</span><span>);</span>
</span></span><span><span>	<span>vec4</span> <span>position</span> <span>=</span> <span>vec4</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span>	<span>position</span><span>.</span><span>xy</span> <span>=</span> <span>vec2</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>-</span><span>1</span><span>)</span> <span>+</span> <span>(</span><span>pos</span><span>.</span><span>xy</span> <span>*</span> <span>word_pos</span><span>.</span><span>z</span> <span>+</span> <span>word_pos</span><span>.</span><span>xy</span><span>)</span> <span>*</span> <span>scale_factor</span><span>;</span>
</span></span><span><span>	<span>gl_Position</span> <span>=</span> <span>position</span><span>;</span>
</span></span><span><span><span>}</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>If we at this point visualise just the output of the vertex shader, we will get something like this:</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small_uv_continuous.png" alt="Quad visualisation with uv coords" title="Quad visualisation with uv coords">
<figcaption>
    Visualisation of per-quad <code>outTexCoord</code> uv coords. Note that these are continuous (smooth).
</figcaption>
</figure>
<h2 id="fragment-shader">Fragment Shader&nbsp;<a href="#fragment-shader"></a></h2>

</div>
<div>
  
<p>Our fragment shader needs three pieces of information to render text, two of which it receives from the vertex shader stage:</p>
<ol>
<li>The fragment’s interpolated uv coordinate, <code>uv</code></li>
<li>The character that we want to draw, <code>in_word</code></li>
<li>The font data array, <code>font_data</code></li>
</ol>
<p>To render a glyph, each fragment must map its uv-coordinate to the correct bit of the glyph bitmap. If the bit at the lookup position is set, then render the fragment in the foreground colour, otherwise render it in background colour.</p>
<p>This mapping works like this:</p>
<p>First, we must map the uv coordinates to <span>word </span><span>– <strong>word</strong> not, <em>world</em>! –</span> pixel coordinates. The nice thing about these two coordinate systems is that they both have their origin at the <span>top left</span><span>, so we only need to bother with scaling, and not origin transformation</span>.</p>
<p>We know that our uv coordinates are normalised floats going from <code>vec2(0.f,0.f)</code> to <code>vec2(1.f,1.f)</code>, while our font pixel coordinates are integers, going from <code>uvec2(0,0)</code> to <code>uvec2(7,15)</code>.</p>
<p>We also must find out which one of the four characters in the word to draw.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>const</span> <span>uint</span> <span>WORD_LEN</span> <span>=</span> <span>4</span><span>;</span> <span>// 4 characters in a word</span>
</span></span><span><span>
</span></span><span><span><span>// quantize uv coordinate to discrete steps</span>
</span></span><span><span><span>uvec2</span> <span>word_pixel_coord</span> <span>=</span> <span>uvec2</span><span>(</span><span>floor</span><span>(</span><span>uv</span><span>.</span><span>xy</span> <span>*</span> <span>vec2</span><span>(</span> <span>8</span> <span>*</span> <span>WORD_LEN</span><span>,</span> <span>16</span><span>)));</span> 
</span></span><span><span><span>// limit pixel coord range to uvec2(0..31, 0..15)</span>
</span></span><span><span><span>word_pixel_coord</span> <span>=</span> <span>min</span><span>(</span><span>uvec2</span><span>(</span> <span>8</span> <span>*</span> <span>WORD_LEN</span> <span>-</span><span>1</span><span>,</span> <span>16</span> <span>-</span><span>1</span><span>),</span> <span>word_pixel_coord</span><span>);</span>
</span></span><span><span><span>// Find which of the four characters in the word this fragment falls onto</span>
</span></span><span><span><span>uint</span> <span>printable_character</span> <span>=</span> <span>in_word</span> <span>&gt;&gt;</span> <span>(</span><span>WORD_LEN</span> <span>-</span> <span>(</span><span>word_pixel_coord</span><span>.</span><span>x</span> <span>/</span> <span>8</span><span>));</span>
</span></span><span><span><span>// Map fragment coordinate to pixel coordinate inside character bitmap</span>
</span></span><span><span><span>uvec2</span> <span>glyph_pixel_coord</span> <span>=</span> <span>uvec2</span><span>(</span><span>word_pixel_coord</span><span>.</span><span>x</span> <span>%</span> <span>8</span><span>,</span> <span>word_pixel_coord</span><span>.</span><span>y</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small_uv.png" alt="Quad visualisation of word_pixel_coord" title="Quad visualisation of word_pixel_coord">
<figcaption>
    A visualisation of <code>word_pixel_coord</code> (normalised)
</figcaption>
</figure>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_per_char_uv.png" alt="Quad visualisation of glyph_pixel_coord" title="Quad visualisation of glyph_pixel_coord">
<figcaption>
    A visualisation of <code>glyph_pixel_coord</code> (normalised)
</figcaption>
</figure>
<p>Remember, to draw a character, we must look up the character in the font bitmap table, where we must find the correct bit to check based on the uv coordinate of the fragment. You will notice that in the first GLSL example above, we were only worried about the <code>.x</code> coordinate. Now, let’s focus on <code>.y</code>, so that we can draw more lines of pixels by looking up the correct line to sample from.</p>
<p>Let’s do this step by step. First, we fetch the character bitmap from our <code>font_data</code> as an <code>uvec4</code>. Then we use the <code>glyph_pixel_coord.y</code> to pick the correct one of 4 <code>uints</code> that make up the glyph. This will give us four lines of pixels.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>// First, map character ASCII code to an index offset into font_data table. </span>
</span></span><span><span><span>// The first character in the font_data table is 0x20, SPACE.</span>
</span></span><span><span><span>offset</span> <span>=</span> <span>printable_character</span> <span>-</span> <span>0x20</span><span>;</span> 
</span></span><span><span><span>// Then get the bitmap for this glyph</span>
</span></span><span><span><span>uvec4</span> <span>character_bitmap</span> <span>=</span> <span>font_data</span><span>[</span><span>offset</span><span>];</span> 
</span></span><span><span><span>// Find the uint that contains one of the four lines that </span>
</span></span><span><span><span>// are touched by our pixel coordinate</span>
</span></span><span><span><span>uint</span> <span>four_lines</span> <span>=</span> <span>character_bitmap</span><span>[</span><span>glyph_pixel_coord</span><span>.</span><span>y</span> <span>/</span> <span>4</span><span>];</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>Once we have the <code>uint</code> covering four lines, we must pick the correct line from it.</p>
<p>Note that lines are stored in reverse order because after we used ImHex to lift the bitmap bytes out of the font file, we just concatenated the <code>chars</code> into <code>uint</code>. This means that our bitmap <code>uint</code>s have the wrong endianness; We want to keep it like this though, because it is much less work to just concatenate chars copied form ImHex than to manually convert endianness in a text editor.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>current_line</span>  <span>=</span> <span>(</span><span>four_lines</span> <span>&gt;&gt;</span> <span>(</span><span>8</span><span>*</span><span>(</span><span>3</span><span>-</span><span>(</span><span>glyph_pixel_coord</span><span>.</span><span>y</span><span>)</span><span>%</span><span>4</span><span>)))</span> <span>&amp;</span> <span>0xff</span><span>;</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>And, lastly, we must pick the correct bit in the bitmap. Note the <code>7-</code> – this is because bytes are stored with the most significant bit at the highest index. To map this to a left-to-right coordinate system, we must index backwards, again.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>current_pixel</span> <span>=</span> <span>(</span><span>current_line</span> <span>&gt;&gt;</span> <span>(</span><span>7</span><span>-</span><span>glyph_pixel_coord</span><span>.</span><span>x</span><span>))</span> <span>&amp;</span> <span>0x01</span><span>;</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>We now can use the current pixel to shade our fragment, so that if the pixel is set in the bitmap, we shade our fragment in the foreground colour, and if it is not set, shade our fragment in the background colour:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>vec3</span> <span>color</span> <span>=</span> <span>mix</span><span>(</span><span>background_colour</span><span>,</span> <span>foreground_colour</span><span>,</span> <span>current_pixel</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_per_char_uv_overlay.png" alt="Quad visualisation" title="Quad visualisation">
<figcaption>
    Text printed with uv coordinates overlaid
</figcaption>
</figure>
<p>What about the fill chars that get inserted if our printable text is too short to be completely divisible by 4? We detect these in the fragment shader: In case were are about to render such a fill character, we should do absolutely nothing, not even draw the background. We can do this by testing <code>printable_character</code>, and issuing a <code>discard</code> in case the printable character is <code>\0</code>.</p>
<h2 id="a-visual-summary">A Visual Summary&nbsp;<a href="#a-visual-summary"></a></h2>
<p>It is said that an image is worth a thousand words. Why not have both? Here is a diagram which summarises the mapping from quad-uv space to glyph bitmap space:</p>
</div>
<figure>
<img src="https://poniesandlight.co.uk/img/reflect/debug_print_text/summary.svg" loading="lazy">
<figcaption>
	    <div><p>Note: Our Fragment position is marked by the blue speck.</p><p>① pick the correct character from our per-quad word. ② calculate the offset into <code>font_data</code> using the character ASCII code. ③ fetch the <code>uvec4</code> that holds the bitmap for our glyph from <code>font_data</code> ④ pick the <code>uint</code> representing the four lines of the glyph that our fragment falls in (via its y-coord) ⑤ pick the correct line using the fragment’s .y coord ⑥ pick the correct bit using the per-glyph <code>x</code> coordinate.
	    </p></div>
</figcaption>
</figure>
<div>
<h2 id="full-implementation--more-source-code">Full Implementation &amp; More Source Code&nbsp;<a href="#full-implementation--more-source-code"></a></h2>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/island_preview.png" alt="Island preview image" title="Island preview image">
<figcaption>
    You can find an implementation of the technique described above in the source code for <a href="https://github.com/tgfrerer/island/tree/wip/modules/le_debug_print_text">le_print_debug_print_text</a>, which is a new <a href="https://poniesandlight.co.uk/tags/island/">Island</a> module that allows you to easily print debug messages to screen. It has some extra nice bits around text processing and caching which, however, would be too wordy to describe here.
</figcaption>
</figure>
<p>Using this technique, it is now possible, from nearly anywhere in an Island project, to call:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="cpp"><span><span><span>char</span> <span>const</span> <span>msg_2</span><span>[]</span> <span>=</span> <span>{</span> <span>70</span><span>,</span> <span>111</span><span>,</span> <span>108</span><span>,</span> <span>107</span><span>,</span> <span>115</span><span>,</span> <span>'!'</span><span>,</span> <span>0</span> <span>};</span>
</span></span><span><span><span>le</span><span>::</span><span>DebugPrint</span><span>(</span> <span>"That's all, %s"</span><span>,</span> <span>msg_2</span> <span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>cpp</span>
</p></div><p>And see the following result on screen:

</p><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/that_s_all_folks.png" alt="Image That&amp;rsquo;s all Folks">
</figure>
<h2 id="acknowledgements">Acknowledgements&nbsp;<a href="#acknowledgements"></a></h2>
<ul>
<li>Diagrams drawn with <a href="https://excalidraw.com/">Excalidraw</a></li>
<li>Original source data for the pixel font came from <a href="http://www.fial.com/~scott/tamsyn-font/">Tamsyn</a>, a free pixel font by Scott Fial</li>
</ul>
<h2 id="backlinks">Backlinks&nbsp;<a href="#backlinks"></a></h2>
<p>This article was featured on <a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-363/">Graphics Programming Weekly</a>, and discussed on <a href="https://lobste.rs/s/5iiqji/texture_less_text_rendering">Lobste.rs</a>, and <a href="https://news.ycombinator.com/item?id=42093037">Hacker News</a>.</p>
<p>If you like more of this, subscribe to the rss feed, and if you want the very latest, and hear about occasional sortees into generative art and design, follow me on <a href="https://bsky.app/profile/tgfrerer.bsky.social">bluesky</a> or <a href="https://mastodon.social/@tgfrerer">mastodon</a>, or maybe even <a href="https://www.instagram.com/tgfrerer/">Instagram</a>. Shameless plug: my services are also available for contract work.</p>


	</div>
	
	
	
		<div>
			<h3>RSS:</h3>
			<p>Find out first about new posts by subscribing to the <a href="https://poniesandlight.co.uk//reflect/feed.xml">RSS Feed</a> <a href="https://poniesandlight.co.uk//reflect/feed.xml" type="application/rss+xml"><svg style="width: 1em; position:relative; bottom:-0.25em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. --><path d="M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zM96 136c0-13.3 10.7-24 24-24c137 0 248 111 248 248c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-110.5-89.5-200-200-200c-13.3 0-24-10.7-24-24zm0 96c0-13.3 10.7-24 24-24c83.9 0 152 68.1 152 152c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-57.4-46.6-104-104-104c-13.3 0-24-10.7-24-24zm64 120c0 17.7-14.3 32-32 32s-32-14.3-32-32s14.3-32 32-32s32 14.3 32 32z"></path></svg></a></p>
		</div>
	
		<p>
			<h3>Further Posts:</h3>
		</p>
		
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's legal for police to use deception in interrogations. Some want that to end (263 pts)]]></title>
            <link>https://text.npr.org/nx-s1-4974964</link>
            <guid>42091423</guid>
            <pubDate>Fri, 08 Nov 2024 23:57:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text.npr.org/nx-s1-4974964">https://text.npr.org/nx-s1-4974964</a>, See on <a href="https://news.ycombinator.com/item?id=42091423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Ted Bradford says the worst day of his life was when detectives took him into a tiny room to question him about a rape.</p><p>“The whole day it was like accusation after accusation,” he says. “I kept telling them over and over, ‘I didn't do this.’”</p><p>Bradford says the officers in Yakima, Wash., <a href="https://wainnocenceproject.org/stories/ted-bradford/"><u>claimed they had biological evidence</u></a> that would prove he did it, and they weren't going to let him leave until he admitted it.</p><p>“I knew I didn’t do it,” he said. “So I'm thinking, ‘In order to get out of this situation, I could just give them a statement. They’ll test that evidence. It’ll show that I didn’t do it, and then this will all be done with.’”</p><p>After<em> </em>hours of questioning, Bradford confessed to the crime. But the evidence police had – a mask left at the scene – could not be DNA-tested. This was the late nineties and the technology wasn’t there yet.</p><p>Bradford recanted his confession, but was convicted anyway. He was 22 with two small children when he went to prison.</p><p>“Every day I woke up and knew that I shouldn't be there,” he says.</p><p>Advancements in DNA testing helped lead to his exoneration in 2010.</p><p>What happened to Bradford might seem extreme, but nearly 30 years later, the tactic used on him is not. In every state, police officers are allowed to lie to adults during an interrogation. The hope, in many cases, is that they’ll get a person to confess to committing a crime.</p><p>When it comes to children and teenagers, a growing number of states are stopping that practice: Ten have passed laws in recent years effectively banning police from lying to juveniles during interrogations, starting with Illinois in 2021. But some legal advocates are pushing for a deception ban that would apply to everyone, not just kids.</p><h2>‘A quick and relatively straightforward way to close a case’</h2><p>Deception is a powerful law enforcement tool in eliciting confessions, says wrongful convictions attorney Laura Nirider.</p><p>“Police are trained around the country in all 50 states to use deception during interrogation, to lie both about the evidence against a suspect and to lie about the consequences of confessing in order to make it seem not so bad if you just say that you did these things,” she says.</p><p>Police can go into an interrogation room with a suspect, Nirider says, and emerge with “one of the most believable pieces of evidence imaginable, a confession.”</p><p>“It's a quick and relatively straightforward way to close a case,” she says.</p><p>But Nirider says using deception can also draw false confessions.</p><p>According to the Innocence Project, a national organization that works to overturn wrongful convictions, nearly a third of DNA exonerations from 1989 to 2020 <a href="https://innocenceproject.org/dna-exonerations-in-the-united-states/"><u>involved a false confession</u></a>.</p><p>Legal experts say the deception bans passed in recent years fail to protect other vulnerable groups: young adults, people with intellectual disabilities, even just people who are naturally compliant.</p><p>“Children are one category that makes you more vulnerable, but it's certainly not the only category,” says Lara Zarowsky, executive and policy director at the Washington Innocence Project. “It's something that all of us are vulnerable to.”</p><h2>‘Law enforcement is the biggest impediment’</h2><p>In Washington state, where Bradford was convicted, Democratic lawmakers want to set a higher bar: A bill that would make incriminating statements made in police custody – by adults or children – largely inadmissible in court if obtained using deception.</p><p>State Rep. Strom Peterson has introduced the bill twice, but it hasn’t gone anywhere.</p><p>“Law enforcement is the biggest impediment to the bill. They believe that the system in which they work is effective,” he says.</p><p>The Washington Association of Sheriffs and Police Chiefs declined NPR’s request for an interview, but said in a statement that it opposes such a measure, because banning deception would take away a tactic that yields “many more true confessions” than false ones.</p><p>“We fear that it will negatively impact our ability to solve crimes and would result in less accountability for those who victimize others,” the association’s policy director, James McMahan, <a href="https://tvw.org/video/house-appropriations-2024021057/?eventID=2024021057"><u>said at a hearing</u></a> for the bill in February.</p><p>“Criminals often conduct elaborate stories to conceal their crimes,” McMahan said at the hearing. “Sometimes the use of deception is required to locate the truth both to convict and to exonerate people. Such deceptions include telling a person that abuse was discovered during a routine medical exam rather than reported by a family member.”</p><p>In its statement, the association added that judges assess whether confessions are given voluntarily before they can be introduced as evidence, and convictions based solely on confessions are rare.</p><p>Even with other evidence, however, confessions carry a lot of weight. Research indicates that people who confess <a href="https://core.ac.uk/reader/81748492?utm_source=linkout"><u>are treated differently</u></a> afterwards: They’re more likely to be charged, face more charges, and receive a harsher punishment when convicted.</p><p>“A confession will trump everything,” says Jim Trainum, a retired homicide detective in Washington, D.C.</p><p>In his experience, there is pressure to move on after a suspect confesses because a detective’s measure of success is often tied to closure rates.</p><p>“Let's say that I get a confession and I get all the stuff that I want to go out and corroborate. I want to make sure that this is an accurate confession,” Trainum says. “I'm sitting there at my desk working very, very hard on it. And my sergeant comes up and says, ‘What are you doing? That's a confession. That's closed. Move on. You got other ones to take care of.’”</p><h2>‘Trying to give the police new tools’</h2><p>Those against deception bans see them as an attack on police, says Mark Fallon, a consultant on interrogation practices and former federal agent. In fact, he says, it’s the opposite.</p><p>“It is actually trying to give the police new tools, better tools,” he says.</p><p>There’s another way for police to question people, Fallon says, that relies on building rapport and asking open-ended questions, and where the primary goal is information, rather than a confession.</p><p>That technique is used in other countries, including much of Europe. In England, France, Germany, Australia, Japan and elsewhere, for instance, the police are generally <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3669413"><u>not allowed to deceive suspects</u></a>.</p><p>Trainum says interrogation methods that don’t rely on deception ultimately make the police more trustworthy to communities.</p><p>“Today’s suspect is tomorrow's witness,” he says.</p><p>When a suspect or witness has been lied to, he says, “that radiates out. And no wonder people don't trust us. Why should they trust us?”</p><p>That is why Peterson, the lawmaker, plans to introduce the bill in Washington again. He says the public is<em> </em>better off when police use the best tools available to convict the right people.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delta: A syntax-highlighting pager for Git, diff, grep, and blame output (555 pts)]]></title>
            <link>https://github.com/dandavison/delta</link>
            <guid>42091365</guid>
            <pubDate>Fri, 08 Nov 2024 23:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dandavison/delta">https://github.com/dandavison/delta</a>, See on <a href="https://news.ycombinator.com/item?id=42091365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png" alt="image"></a>
</p>
<p dir="auto">
  <a href="https://github.com/dandavison/delta/actions">
    <img src="https://github.com/dandavison/delta/workflows/Continuous%20Integration/badge.svg" alt="CI">
  </a>
  <a href="https://coveralls.io/github/dandavison/delta?branch=main" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e8785ac8ede00f6ec8ad672e5031d27eb6eb5a599d56b232a469b9824f76753c/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64616e64617669736f6e2f64656c74612f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/dandavison/delta/badge.svg?branch=main">
  </a>
  <a href="https://gitter.im/dandavison-delta/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6c92914f6e39c859372cd85d6c7676c73d524f994663f1ae0e2b0b566a0e1361/68747470733a2f2f6261646765732e6769747465722e696d2f64616e64617669736f6e2d64656c74612f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/dandavison-delta/community.svg">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><a href="https://dandavison.github.io/delta/installation.html" rel="nofollow">Install it</a> (the package is called "git-delta" in most package managers, but the executable is just <code>delta</code>) and add this to your <code>~/.gitconfig</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[core]
    pager = delta

[interactive]
    diffFilter = delta --color-only

[delta]
    navigate = true    # use n and N to move between diff sections

    # delta detects terminal colors automatically; set one of these to disable auto-detection
    # dark = true
    # light = true

[merge]
    conflictstyle = zdiff3"><pre>[<span>core</span>]
    <span>pager</span> <span>=</span> <span>delta</span>

[<span>interactive</span>]
    <span>diffFilter</span> <span>=</span> <span>delta</span> <span>--color-only</span>

[<span>delta</span>]
    <span>navigate</span> <span>=</span> <span>true</span>    <span><span>#</span> use n and N to move between diff sections</span>

    <span><span>#</span> delta detects terminal colors automatically; set one of these to disable auto-detection</span>
    <span><span>#</span> dark = true</span>
    <span><span>#</span> light = true</span>

[<span>merge</span>]
    <span>conflictstyle</span> <span>=</span> <span>zdiff3</span></pre></div>
<p dir="auto">Delta has many features and is very customizable; please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Language syntax highlighting with the same syntax-highlighting themes as <a href="https://github.com/sharkdp/bat#readme">bat</a></li>
<li>Word-level diff highlighting using a Levenshtein edit inference algorithm</li>
<li>Side-by-side view with line-wrapping</li>
<li>Line numbering</li>
<li><code>n</code> and <code>N</code> keybindings to move between files in large diffs, and between diffs in <code>log -p</code> views (<code>--navigate</code>)</li>
<li>Improved merge conflict display</li>
<li>Improved <code>git blame</code> display (syntax highlighting; <code>--hyperlinks</code> formats commits as links to hosting provider etc. Supported hosting providers are: GitHub, GitLab, SourceHut, Codeberg)</li>
<li>Syntax-highlights grep output from <code>rg</code>, <code>git grep</code>, <code>grep</code>, etc</li>
<li>Support for Git's <code>--color-moved</code> feature.</li>
<li>Code can be copied directly from the diff (<code>-/+</code> markers are removed by default).</li>
<li><code>diff-highlight</code> and <code>diff-so-fancy</code> emulation modes</li>
<li>Commit hashes can be formatted as terminal <a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">hyperlinks</a> to the hosting provider page (<code>--hyperlinks</code>).
File paths can also be formatted as hyperlinks for opening in your OS.</li>
<li>Stylable box/line decorations to draw attention to commit, file and hunk header sections.</li>
<li>Style strings (foreground color, background color, font attributes) are supported for &gt;20 stylable elements, using the same color/style language as git</li>
<li>Handles traditional unified diff output in addition to git output</li>
<li>Automatic detection of light/dark terminal background</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">A syntax-highlighting pager for git, diff, and grep output</h2><a id="user-content-a-syntax-highlighting-pager-for-git-diff-and-grep-output" aria-label="Permalink: A syntax-highlighting pager for git, diff, and grep output" href="#a-syntax-highlighting-pager-for-git-diff-and-grep-output"></a></p>
<p dir="auto">Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output.</p>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a>
      <br>
      <sub>delta with <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a>
      <br>
      <sub>delta with <code>side-by-side</code> and <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<p dir="auto">Here's what <code>git show</code> can look like with git configured to use delta:</p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Syntax-highlighting themes</h3><a id="user-content-syntax-highlighting-themes" aria-label="Permalink: Syntax-highlighting themes" href="#syntax-highlighting-themes"></a></p>
<p dir="auto"><strong>All the syntax-highlighting color themes that are available with <a href="https://github.com/sharkdp/bat/">bat</a> are available with delta:</strong></p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">Side-by-side view</h3><a id="user-content-side-by-side-view" aria-label="Permalink: Side-by-side view" href="#side-by-side-view"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/side-by-side-view.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    side-by-side = true"><pre>[<span>delta</span>]
    <span>side-by-side</span> <span>=</span> <span>true</span></pre></div>
<p dir="auto">By default, side-by-side view has line-numbers activated, and has syntax highlighting in both the left and right panels: [<a href="#side-by-side-view-1">config</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto">Side-by-side view wraps long lines automatically:</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Line numbers</h3><a id="user-content-line-numbers" aria-label="Permalink: Line numbers" href="#line-numbers"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/line-numbers.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    line-numbers = true"><pre>[<span>delta</span>]
    <span>line-numbers</span> <span>=</span> <span>true</span></pre></div>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Merge conflicts</h3><a id="user-content-merge-conflicts" aria-label="Permalink: Merge conflicts" href="#merge-conflicts"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/merge-conflicts.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png"><img width="500px" src="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Git blame</h3><a id="user-content-git-blame" aria-label="Permalink: Git blame" href="#git-blame"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/git-blame.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ripgrep, git grep</h3><a id="user-content-ripgrep-git-grep" aria-label="Permalink: Ripgrep, git grep" href="#ripgrep-git-grep"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/grep.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"><img width="600px" alt="image" src="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"></a>
</p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation and usage</h3><a id="user-content-installation-and-usage" aria-label="Permalink: Installation and usage" href="#installation-and-usage"></a></p>
<p dir="auto">Please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a> and <code>delta --help</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maintainers</h3><a id="user-content-maintainers" aria-label="Permalink: Maintainers" href="#maintainers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dandavison">@dandavison</a></li>
<li><a href="https://github.com/th1000s">@th1000s</a></li>
</ul>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>