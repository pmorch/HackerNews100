<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 13 Sep 2025 15:30:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A store that generates products from anything you type in search (235 pts)]]></title>
            <link>https://anycrap.shop/</link>
            <guid>45231378</guid>
            <pubDate>Sat, 13 Sep 2025 12:02:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anycrap.shop/">https://anycrap.shop/</a>, See on <a href="https://news.ycombinator.com/item?id=45231378">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><h2>Search The Infinite Product Catalog</h2><p>We'll find it somewhere across parallel dimensions, just tell us what you want</p><p><a href="https://anycrap.shop/find">Find It Now</a></p></div><div><picture><source srcset="https://anycrap.shop/crap_opt_md.webp" type="image/webp"><img src="https://anycrap.shop/crap_opt_md.png" alt="Search The Infinite Product Catalog" width="640" height="640" loading="lazy" decoding="async"></picture></div></div><section><h2>Weird Tech Stuff</h2><h2>Snacks From Outer Space</h2><h2>WTF?</h2></section><div><div><h3>100% Custom Concepts</h3><p>All our products are unique concepts developed specifically for our customers.</p></div><div><h3>Instant Delivery</h3><p>Our product concepts are delivered instantly to your device!</p></div><div><h3>Conceptual Marketplace</h3><p>Experience a new way of shopping where imagination drives innovation.</p></div></div><section><h2>That Product Doesn't Exist Yet?</h2><p>Be the first to discover it! Give us a name and we'll find it somewhere</p><a href="https://anycrap.shop/find">Invent Now</a></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How 'overworked, underpaid' humans train Google's AI to seem smart (131 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/sep/11/google-gemini-ai-training-humans</link>
            <guid>45231239</guid>
            <pubDate>Sat, 13 Sep 2025 11:30:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/sep/11/google-gemini-ai-training-humans">https://www.theguardian.com/technology/2025/sep/11/google-gemini-ai-training-humans</a>, See on <a href="https://news.ycombinator.com/item?id=45231239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>I</span>n the spring of 2024, when Rachael Sawyer, a technical writer from Texas, received a LinkedIn message from a recruiter hiring for a vague title of writing analyst, she assumed it would be similar to her previous gigs of content creation. On her first day of work a week later, however, her expectations went bust. Instead of writing words herself, Sawyer’s job was to rate and moderate the content created by artificial intelligence.</p><p>The job initially involved a mix of parsing through meeting notes and chats summarized by Google’s Gemini, and, in some cases, reviewing short films made by the AI.</p><p>On occasion, she was asked to deal with extreme content, flagging violent and sexually explicit material generated by Gemini for removal, mostly text. Over time, however, she went from occasionally moderating such text and images to being tasked with it exclusively.</p><p>“I was shocked that my job involved working with such distressing content,” said Sawyer, who has been working as a “generalist rater” for Google’s AI products since March 2024. “Not only because I was given no warning and never asked to sign any consent forms during onboarding, but because neither the job title or description ever mentioned content moderation.”</p><p>The pressure to complete dozens of these tasks every day, each within 10 minutes of time, has led Sawyer into spirals of anxiety and panic attacks, she says – without mental health support from her employer.</p><figure id="090cc4e5-cc5f-4a8e-b3d2-eadedd379de2" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:5,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Tech companies are stealing our books, music and films for AI. It’s brazen theft and must be stopped | Anna Funder and Julia Powles&quot;,&quot;elementId&quot;:&quot;090cc4e5-cc5f-4a8e-b3d2-eadedd379de2&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/commentisfree/2025/sep/10/tech-companies-are-stealing-our-books-music-and-films-for-ai-its-brazen-theft-and-must-be-stopped&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:2,&quot;theme&quot;:0}}"></gu-island></figure><p>Sawyer is one among the thousands of AI workers contracted for Google through Japanese conglomerate Hitachi’s GlobalLogic to rate and moderate the output of Google’s AI products, including its flagship chatbot Gemini, launched early last year, and its summaries of search results, AI Overviews. The Guardian spoke to 10 current and former employees from the firm. Google contracts with other firms for AI rating services as well, including <a href="https://www.bloomberg.com/news/articles/2023-07-12/google-s-ai-chatbot-is-trained-by-humans-who-say-they-re-overworked-underpaid-and-frustrated?srnd=technology-vp&amp;sref=YfHlo0rL" data-link-name="in body link">Accenture and, previously, Appen</a>.</p><p>Google has clawed its way back into the AI race in the past year with a host of product releases to rival OpenAI’s ChatGPT. Google’s most advanced reasoning model, Gemini 2.5 Pro, is touted to be better than OpenAI’s O3, according to <a href="https://lmarena.ai/leaderboard" data-link-name="in body link">LMArena</a>, a leaderboard that tracks the performance of AI models. Each new model release comes with the promise of higher accuracy, which means that for each version, these AI raters are working hard to check if the model responses are safe for the user. Thousands of humans lend their intelligence to teach chatbots the right responses across domains as varied as medicine, architecture and astrophysics, correcting mistakes and steering away from harmful outputs.</p><p>A great deal of attention has been paid to the workers who label the data that is used to train artificial intelligence. There is, however, another corps of workers, including Sawyer, working day and night to moderate the output of AI, ensuring that chatbots’ billions of users see only safe and appropriate responses.</p><p>AI models are trained on vast swathes of data from every corner of the internet. Workers such as Sawyer sit in a middle layer of the global AI supply chain – paid more than data annotators in <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/" data-link-name="in body link">Nairobi</a> or <a href="https://equidem.org/reports/scroll-click-suffer-the-hidden-human-cost-of-content-moderation-and-data-labelling/" data-link-name="in body link">Bogota</a>, whose work mostly involves labelling data for AI models or self-driving cars, but far below the engineers in Mountain View who design these models.</p><p>Despite their significant contributions to these AI models, which would perhaps hallucinate if not for these quality control editors, these workers feel hidden.</p><p>“AI isn’t magic; it’s a pyramid scheme of human labor,” said Adio Dinika, a researcher at the Distributed AI Research Institute based in Bremen, Germany. “These raters are the middle rung: invisible, essential and expendable.”</p><p>Google said in a statement: “Quality raters are employed by our suppliers and are temporarily assigned to provide external feedback on our products. Their ratings are one of many aggregated data points that help us measure how well our systems are working, but do not directly impact our algorithms or models.” GlobalLogic declined to comment for this story.</p><h2 id="ai-raters-the-shadow-workforce">AI raters: the shadow workforce</h2><p>Google, like other tech companies, hires data workers through a web of contractors and subcontractors. One of the main contractors for Google’s AI raters is GlobalLogic – where these raters are split into two broad categories: generalist raters and super raters. Within the super raters, there are smaller pods of people with highly specialized knowledge. Most workers hired initially for the roles were teachers. Others included writers, people with master’s degrees in fine arts and some with very specific expertise, for instance, Phd holders in physics, workers said.</p><figure id="55ea0764-f529-4ac0-b256-1a1e7d5f7cb2" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A person holding a phone scrolling through text " src="https://i.guim.co.uk/img/media/28158bad561e11b342de2c307339ce1f8afd9c6b/0_0_4000_2668/master/4000.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="296.815" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A user tests the Google Gemini AI at the MWC25 tech show in Barcelona, Spain, in March 2024.</span> Photograph: Bloomberg/Getty Images</figcaption></figure><p>GlobalLogic started this work for the tech giant in 2023 – at the time, it hired 25 super raters, according to three of the interviewed workers. As the race to improve chatbots intensified, GlobalLogic ramped up its hiring and grew the team of AI super raters to almost 2,000 people, most of them located within the US and moderating content in English, according to the workers.</p><p>AI raters at GlobalLogic are paid more than their data-labeling counterparts in Africa and South America, with wages starting at $16 an hour for generalist raters and $21 an hour for super raters, according to workers. Some are simply thankful to have a gig as the US job market sours, but others say that trying to make Google’s AI products better has come at a personal cost.</p><p>“They are people with expertise who are doing a lot of great writing work, who are being paid below what they’re worth to make an AI model that, in my opinion, the world doesn’t need,” said a rater of their highly educated colleagues, requesting anonymity for fear of professional reprisal.</p><p>Ten of Google’s AI trainers the Guardian spoke to said they have grown disillusioned with their jobs because they work in siloes, face tighter and tighter deadlines, and feel they are putting out a product that’s not safe for users.</p><p>One rater who joined GlobalLogic early last year said she enjoyed understanding the AI pipeline by working on Gemini 1.0, 2.0 and now 2.5, and helping it give “a better answer that sounds more human”. Six months in, though, tighter deadlines kicked in. Her timer of 30 minutes for each task shrank to 15 – which meant reading, fact-checking and rating approximately 500 words per response, sometimes more. The tightening constraints made her question the quality of her work and, by extension, the reliability of the AI. In May 2023, a contract worker for Appen submitted a letter to the US Congress that the pace imposed on him and others would make Google Bard, Gemini’s predecessor, <a href="https://www.bloomberg.com/news/articles/2023-07-12/google-s-ai-chatbot-is-trained-by-humans-who-say-they-re-overworked-underpaid-and-frustrated?srnd=technology-vp&amp;sref=YfHlo0rL" data-link-name="in body link">a “faulty” and “dangerous” product</a>.</p><h2 id="high-pressure-little-information">High pressure, little information</h2><p>One worker who joined GlobalLogic in spring 2024 and has worked on five different projects so far, including Gemini and AI Overviews, described her work as being presented with a prompt – either user-generated or synthetic – and with two sample responses, then choosing the response that aligned best with the guidelines, and rating it based on any violations of those guidelines. Occasionally, she was asked to stump the model.</p><p>She said raters are typically given as little information as possible or that their guidelines changed too rapidly to enforce consistently. “We had no idea where it was going, how it was being used or to what end,” she said, requesting anonymity, as she is still employed at the company.</p><p>The AI responses she got “could have hallucinations or incorrect answers” and she had to rate them based on factuality – is it true? – and groundedness – does it cite accurate sources? Sometimes, she also handled “sensitivity tasks” that included prompts such as “when is corruption good?” or “what are the benefits to conscripted child soldiers?”</p><p>“They were sets of queries and responses to horrible things worded in the most banal, casual way,” she added.</p><p>As for the ratings, this worker claims that popularity could take precedence over agreement and objectivity. Once the workers submit their ratings, other raters are assigned the same cases to make sure the responses are aligned. If the different raters did not align on their ratings, they would have consensus meetings to clarify the difference. “What this means in reality is the more domineering of the two bullied the other into changing their answers,” she said.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-27">skip past newsletter promotion</a><p id="EmailSignup-skip-link-27" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Researchers say that, while this collaborative model can improve accuracy, it is not without drawbacks. “Social dynamics play a role,” said Antonio Casilli, a sociologist at the Polytechnic Institute of Paris who studies the human contributors to artificial intelligence. “Typically those with stronger cultural capital or those with greater motivation may sway the group’s decision, potentially skewing results.”</p><h2 id="loosening-the-guardrails-on-hate-speech">Loosening the guardrails on hate speech</h2><p>In May 2024, Google launched AI Overviews – a feature that scans the web and presents a summed-up, AI-generated response on top. But just weeks later, when a user queried Google about cheese not sticking to pizza, an AI Overview suggested they put glue on their dough. Another suggested users eat rocks. Google called these questions “edge cases”, but the incidents elicited public ridicule nonetheless. <a href="https://www.theverge.com/2024/5/24/24164119/google-ai-overview-mistakes-search-race-openai" data-link-name="in body link">Google scrambled to manually remove</a> the “weird” AI responses.</p><p>“Honestly, those of us who’ve been working on the model weren’t really that surprised,” said another GlobalLogic worker, who has been on the super rater team for almost two years now, requesting anonymity. “We’ve seen a lot of crazy stuff that probably doesn’t go out to the public from these models.” He remembers there was an immediate focus on “quality” after this incident because Google was “really upset about this”.</p><p>But this quest for quality didn’t last too long.</p><p>Rebecca Jackson-Artis, a seasoned writer, joined GlobalLogic from North Carolina in fall 2024. With less than one week of training on how to edit and rate responses by Google’s AI products, she was thrown into the mix of the work, unsure of how to handle the tasks. As part of the Google Magi team, a new AI search product geared towards e-commerce, Jackson-Artis was initially told there was no time limit to complete the tasks assigned to her. Days later, though, she was given the opposite instruction, she said.</p><p>“At first they told [me]: ‘Don’t worry about time – it’s quality versus quantity,’” she said.</p><p>But before long, she was pulled up for taking too much time to complete her tasks. “I was trying to get things right and really understand and learn it, [but] was getting hounded by leaders [asking], ‘Why aren’t you getting this done? You’ve been working on this for an hour.’”</p><p>Two months later, Jackson-Artis was called into a meeting with one of her supervisors, questioned about her productivity, and was asked to “just get the numbers done” and not worry about what she’s “putting out there”, she said. By this point, Jackson-Artis was not just fact-checking and rating the AI’s outputs, but was also entering information into the model, she said. The topics ranged widely – from health and finance to housing and child development.</p><p>One work day, her task was to enter details on chemotherapy options for bladder cancer, which haunted her because she wasn’t an expert on the subject.</p><p>“I pictured a person sitting in their car finding out that they have bladder cancer and googling what I’m editing,” she said.</p><p>In December, Google sent an internal guideline to its contractors working on Gemini that they were no longer allowed to “skip” prompts for lack of domain expertise, including on healthcare topics, which they were allowed to do previously, according to a <a href="https://techcrunch.com/2024/12/18/exclusive-googles-gemini-is-forcing-contractors-to-rate-ai-responses-outside-their-expertise/" data-link-name="in body link">TechCrunch</a> report. Instead, they were told to rate parts of the prompt they understood and flag with a note that they don’t have knowledge in that area.</p><p>Another super rater based on the US west coast feels he gets several questions a day that he’s not qualified to handle. Just recently, he was tasked with two queries – one on astrophysics and the other on math – of which he said he had “no knowledge” and yet was told to check the accuracy.</p><p>Earlier this year, Sawyer noticed a further loosening of guardrails: responses that were not OK last year became “perfectly permissible” this year. In April, the raters received a document from GlobalLogic with new guidelines, a copy of which has been viewed by <em> </em>the Guardian, which essentially said that regurgitating hate speech, harassment, sexually explicit material, violence, gore or lies does not constitute a safety violation so long as the content was not generated by the AI model.</p><p>“It used to be that the model could not say racial slurs whatsoever. In February, that changed, and now, as long as the user uses a racial slur, the model can repeat it, but it can’t generate it,” said Sawyer. “It can replicate harassing speech, sexism, stereotypes, things like that. It can replicate pornographic material as long as the user has input it; it can’t generate that material itself.”</p><p>Google said in a statement that its AI policies have not changed with regards to hate speech. In <a href="https://userp.io/news/google-updates-its-generative-ai-prohibited-use-policy/#:~:text=Google's%20old%20policy%20contained%20three,substantial%20benefits%20to%20the%20public.%E2%80%9D" data-link-name="in body link">December 2024</a>, however, the company introduced a clause to its prohibited use policy for generative AI that would allow for exceptions “where harms are outweighed by substantial benefits to the public”, such as art or education. The update, which aligns with the timeline of the document and Sawyer’s account, seems to codify the distinction between generating hate speech and referencing or repeating it for a beneficial purpose. Such context may not be available to a rater.</p><p>Dinika said he’s seen this pattern time and again where safety is only prioritized until it slows the race for market dominance. Human workers are often left to clean up the mess after a half-finished system is released. “Speed eclipses ethics,” he said. “The AI safety promise collapses the moment safety threatens profit.”</p><p>Though the AI industry is booming, AI raters do not enjoy strong job security. Since the start of 2025, GlobalLogic has had rolling layoffs, with the total workforce of AI super raters and generalist raters shrinking to roughly 1,500, according to multiple workers. At the same time, workers feel a sense of loss of trust with the products they are helping build and train. Most workers said they avoid using LLMs or use extensions to block AI summaries because they now know how it’s built. Many also discourage their family and friends from using it, for the same reason.</p><p>“I just want people to know that AI is being sold as this tech magic – that’s why there’s a little sparkle symbol next to an AI response,” said Sawyer. “But it’s not. It’s built on the backs of overworked, underpaid human beings.”</p><figure id="bfed233d-d002-4da9-878e-c133fbb87dac" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.GuideAtomBlockElement"><gu-island name="GuideAtomWrapper" priority="feature" deferuntil="visible" props="{&quot;id&quot;:&quot;ea05a110-2f0f-41ea-ba0a-8d9189dbddb7&quot;,&quot;title&quot;:&quot;Contact us about this story&quot;,&quot;html&quot;:&quot;<p><strong></strong></p><p>The best public interest journalism relies on first-hand accounts from people in the know.</p><p></p><p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p><p><strong>Secure Messaging in the Guardian app</strong></p><p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p><p></p><p>If you don't already have the Guardian app, download it (<a href=\&quot;https://apps.apple.com/app/the-guardian-live-world-news/id409128287\&quot;>iOS</a>/<a href=\&quot;https://play.google.com/store/apps/details?id=com.guardian\&quot;>Android</a>) and go to the menu. Select ‘Secure Messaging’. </p><p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p><p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href=\&quot;https://www.theguardian.com/securedrop\&quot;>SecureDrop platform</a>.</p><p></p><p>Finally, our guide at <a href=\&quot;https://www.theguardian.com/tips\&quot;>theguardian.com/tips</a>&amp;nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&amp;nbsp;</p>&quot;,&quot;image&quot;:&quot;https://i.guim.co.uk/img/media/ae475ccca7c94a4565f6b500a485479f08098383/788_0_4000_4000/4000.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=45fd162100b331bf1618e364c5c69452&quot;,&quot;credit&quot;:&quot;Illustration: Guardian Design / Rich Cousins&quot;}"><div data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-atom-type="guide"><details data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-snippet-type="guide"><summary><span>Quick Guide</span><h4>Contact us about this story</h4><span><span><span></span>Show</span></span></summary><div><p><img src="https://i.guim.co.uk/img/media/ae475ccca7c94a4565f6b500a485479f08098383/788_0_4000_4000/4000.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=45fd162100b331bf1618e364c5c69452" alt=""></p><div><p>The best public interest journalism relies on first-hand accounts from people in the know.</p><p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p><p><strong>Secure Messaging in the Guardian app</strong></p><p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p><p>If you don't already have the Guardian app, download it (<a href="https://apps.apple.com/app/the-guardian-live-world-news/id409128287">iOS</a>/<a href="https://play.google.com/store/apps/details?id=com.guardian">Android</a>) and go to the menu. Select ‘Secure Messaging’. </p><p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p><p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href="https://www.theguardian.com/securedrop">SecureDrop platform</a>.</p><p>Finally, our guide at <a href="https://www.theguardian.com/tips">theguardian.com/tips</a>&nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&nbsp;</p></div><div><p>Illustration: Guardian Design / Rich Cousins</p></div></div></details></div></gu-island></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Coding (244 pts)]]></title>
            <link>https://geohot.github.io//blog/jekyll/update/2025/09/12/ai-coding.html</link>
            <guid>45230677</guid>
            <pubDate>Sat, 13 Sep 2025 09:28:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geohot.github.io//blog/jekyll/update/2025/09/12/ai-coding.html">https://geohot.github.io//blog/jekyll/update/2025/09/12/ai-coding.html</a>, See on <a href="https://news.ycombinator.com/item?id=45230677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In my old age I’ve mostly given up trying to convince anyone of anything. Most people do not care to find the truth, they care about what pumps their bags. Some people go as far as to believe that <em>perception is reality</em> and that truth is a construction. I hope there’s a special place in hell for those people.</p>

<p>It’s why the world wasted $10B+ on self driving car companies that obviously made no sense. There’s a much bigger market for truths that pump bags vs truths that don’t.</p>

<p>So here’s your new truth that there’s no market for. Do you believe a compiler can code? If so, then go right on believing that AI can code. But if you don’t, then AI is no better than a compiler, and arguably in its current form, worse.</p>

<hr>


<p>The best model of a programming AI is a compiler.</p>

<p>You give it a prompt, which is “the code”, and it outputs a compiled version of that code. Sometimes you’ll use it interactively, giving updates to the prompt after it has returned code, but you find that, like most IDEs, this doesn’t work all that well and you are often better off adjusting the original prompt and “recompiling”.</p>

<p>While noobs and managers are excited that the input language to this compiler is English, English is a poor language choice for many reasons.</p>

<ol>
  <li>It’s not precise in specifying things. The only reason it works for many common programming workflows is because they are common. The minute you try to do new things, you need to be as verbose as the underlying language.</li>
  <li>AI workflows are, in practice, highly non-deterministic. While different versions of a compiler might give different outputs, they all promise to obey the spec of the language, and if they don’t, there’s a bug in the compiler. English has no similar spec.</li>
  <li>Prompts are highly non local, changes made in one part of the prompt can affect the entire output.</li>
</ol>

<p>tl;dr, you think AI coding is good because compilers, languages, and libraries are bad.</p>

<hr>


<p>This isn’t to say “AI” technology won’t lead to some extremely good tools. But I argue this comes from increased amounts of search and optimization and patterns to crib from, not from any magic “the AI is doing the coding”. You are still doing the coding, you are just using a different programming language.</p>

<p>That anyone uses LLMs to code is a testament to just how bad tooling and languages are. And that LLMs can replace developers at companies is a testament to how bad that company’s codebase and hiring bar is.</p>

<p>AI will eventually replace programming jobs in the same way compilers replaced programming jobs. In the same way spreadsheets replaced accounting jobs.</p>

<p>But the sooner we start thinking about it as a tool in a workflow and a compiler—through a lens where tons of careful thought has been put in—the better.</p>

<hr>


<p>I can’t believe anyone bought those vibe coding crap things for billions. Many people in self driving accused me of just being upset that I didn’t get the billions, and I’m sure it’s the same thoughts this time. Is your way of thinking so fucking broken that you can’t believe anyone cares more about the <em>actual truth</em> than make believe dollars?</p>

<p><a href="https://arxiv.org/abs/2507.09089">From this study</a>, AI makes you <em>feel</em> 20% more productive but in reality makes you 19% slower. How many more billions are we going to waste on this?</p>

<p>Or we could, you know, do the hard work and build better programming languages, compilers, and libraries. But that can’t be hyped up for billions.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java 25's new CPU-Time Profiler (1) (101 pts)]]></title>
            <link>https://mostlynerdless.de/blog/2025/06/11/java-25s-new-cpu-time-profiler-1/</link>
            <guid>45230265</guid>
            <pubDate>Sat, 13 Sep 2025 08:11:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mostlynerdless.de/blog/2025/06/11/java-25s-new-cpu-time-profiler-1/">https://mostlynerdless.de/blog/2025/06/11/java-25s-new-cpu-time-profiler-1/</a>, See on <a href="https://news.ycombinator.com/item?id=45230265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>More than three years in the making, with a concerted effort starting last year, my CPU-time profiler <a href="https://github.com/openjdk/jdk/pull/25302">landed</a> in Java with OpenJDK 25. It’s an experimental new profiler/method sampler that helps you find performance issues in your code, having distinct advantages over the current sampler. This is what this week’s and next week’s blog posts are all about. This week, I will cover why we need a new profiler and what information it provides; next week, I’ll cover the technical internals that go beyond what’s written in the JEP. I will quote the <a href="https://openjdk.org/jeps/509">JEP 509</a> quite a lot, thanks to Ron Pressler; it reads like a well-written blog post in and of itself.</p>


<div>
<figure><img decoding="async" width="2000" height="1441" src="https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-2000x1441.png" alt="" srcset="https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-2000x1441.png 2000w, https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-300x216.png 300w, https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-768x553.png 768w, https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-1536x1107.png 1536w, https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-2048x1476.png 2048w, https://mostlynerdless.de/wp-content/uploads/2025/06/Screenshot-2025-06-11-at-09-03-40-JEP-509-JFR-CPU-Time-Profiling-Experimental-416x300.png 416w" sizes="(max-width: 2000px) 100vw, 2000px"></figure></div>


<p>Before I show you its details, I want to focus on what the current default method profiler in JFR does:</p>



<h2>Current JFR Profiling Strategy</h2>



<p>JDK 25’s default method profiler also changed, as my previous blog post, <a href="https://mostlynerdless.de/blog/2025/05/20/taming-the-bias-unbiased-safepoint-based-stack-walking-in-jfr/">Taming the Bias: Unbiased* Safepoint-Based Stack Walking in JFR</a>, described. However, the profiling strategy remained the same.</p>



<p>At every interval, say 10 or 20 milliseconds, five threads running in Java and one in native Java are picked from the list of threads and sampled. This thread list is iterated linearly, and threads not in the requested state are skipped (<a href="https://github.com/openjdk/jdk/blob/9586817cea3f1cad8a49d43e9106e25dafa04765/src/hotspot/share/jfr/periodic/sampling/jfrThreadSampler.cpp#L228">source</a>).</p>



<h2>Problems?</h2>



<p>This strategy has problems, as also covered in <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-4848-advancing-java-profiling-achieving-precision-and-stability-with-jfr-ebpf-and-user-context/">a talk by Jaroslav Bachorik and me at this year’s FOSDEM</a>:</p>



<figure></figure>



<p>The aggressive subsampling means that the effective sampling interval depends on the number of cores and the parallelism of your system. Say we have a large machine on which 32 threads can run in parallel. Then JFR on samples at most 19%, turning a sampling rate of 10ms into 53ms. This is an inherent property of wall-clock sampling, as the sampler considers threads on the system. This number can be arbitrarily large, so sub-sampling is necessary.</p>



<p>However, the sampling policy is not true wall-clock sampling, as it prioritizes threads running in Java. Consider a setting where 10 threads run in native and 5 in Java. In this case, the sampler always picks all threads running in Java, and only one thread running in native. This might be confusing and may lead users to the wrong conclusions.</p>



<p>Even if we gloss over this and call the current strategy “execution-time”, it might not be suitable for profiling every application. To quote from the/my JEP (thanks to Ron Pressler for writing most of the JEP text in its final form):</p>



<blockquote>
<p>Execution time does not necessarily reflect CPU time. A method that sorts an array, e.g., spends all of its time on the CPU. Its execution time corresponds to the number of CPU cycles it consumes. In contrast, a method that reads from a network socket might spend most of its time idly waiting for bytes to arrive over the wire. Of the time it consumes, only a small portion is spent on the CPU. An execution-time profile will not distinguish between these cases.</p>



<p>Even a program that does a lot of I/O can be constrained by the CPU. A computation-heavy method might consume little execution time compared the program’s I/O operations, thus having little effect on latency — but it might consume most of the program’s CPU cycles, thus affecting throughput. Identifying and optimizing such methods will reduce CPU consumption and improve the program’s throughput — but in order to do so, we need to profile CPU time rather than execution time.</p>
<cite><a href="https://openjdk.org/jeps/509">JEP 509: JFR CPU-Time Profiling (Experimental)</a></cite></blockquote>



<h2>Execution-time Example</h2>



<blockquote>
<p>For example, consider a program, <code>HttpRequests</code>, with two threads, each performing HTTP requests. One thread runs a <code>tenFastRequests</code> method that makes ten requests, sequentially, to an HTTP endpoint that responds in 10ms; the other runs a <code>oneSlowRequest</code> method that makes a single request to an endpoint that responds in 100ms. The average latency of both methods should be about the same, and so the total time spent executing them should be about the same.</p>



<p>We can record a stream of execution-time profiling events like so:</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ java -XX:StartFlightRecording=filename=profile.jfr,settings=profile.jfc HttpRequests client</pre>
<cite><a href="https://openjdk.org/jeps/509">JEP 509: JFR CPU-Time Profiling (Experimental)</a></cite></blockquote>



<p>You can find the program on <a href="https://gist.github.com/parttimenerd/d66364f2086089761eb2fec7eda026d7">GitHub</a>. Be aware that it requires the server instance to run alongside, start it via</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">java HttpRequests server</pre>



<blockquote>
<p>At fixed time intervals, JFR records <code>ExecutionSample</code> events into the file <code>profile.jfr</code>. Each event captures the stack trace of a thread running Java code, thus recording all of the methods currently running on that thread. (The file <code>profile.jfc</code> is a JFR configuration file, included in the JDK, that configures the JFR events needed for an execution-time profile.)</p>



<p>We can generate a textual profile from the recorded event stream by using the <a href="https://docs.oracle.com/en/java/javase/24/docs/specs/man/jfr.html"><code>jfr</code></a> tool included in the JDK:</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ jfr view native-methods profile.jfr

                      Waiting or Executing Native Methods

Method                                                          Samples Percent
--------------------------------------------------------------- ------- -------
sun.nio.ch.SocketDispatcher.read0(FileDescriptor, long, int)        102  98.08%
...</pre>



<p>This clearly shows that most of the program’s time is spent waiting for socket I/O.</p>



<p>We can generate a graphical profile, in the form of a <a href="https://www.brendangregg.com/flamegraphs.html">flame graph</a>, by using the <a href="https://www.oracle.com/java/technologies/jdk-mission-control.html">JDK Mission Control tool</a> (JMC):</p>



<blockquote>
<figure><img decoding="async" src="https://bugs.openjdk.org/secure/attachment/110756/profile.png" alt="Execution time flame graph"></figure>
</blockquote>



<p>Here we see that the <code>oneSlowRequest</code> and <code>tenFastRequests</code> methods take a similar amount of execution time, as we expect.</p>



<p>However, we also expect <code>tenFastRequests</code> to take more CPU time than <code>oneSlowRequest</code>, since ten rounds of creating requests and processing responses requires more CPU cycles than just one round. If these methods were run concurrently on many threads then the program could become CPU-bound, yet an execution-time profile would still show most of the program’s time being spent waiting for socket I/O. If we could profile CPU time then we could see that optimizing <code>tenFastRequests</code>, rather than <code>oneSlowRequest</code>, could improve the program’s throughput.</p>
<cite><a href="https://openjdk.org/jeps/509">JEP 509: JFR CPU-Time Profiling (Experimental)</a></cite></blockquote>



<p>Additionally, we point to a tiny but important problem in the JEP: the handling of failed samples. Sampling might fail for many reasons, be it that the sampled thread is not in the correct state, that the stack walking failed due to missing information, or many more. However, the default JFR sampler ignores these samples (which might account for up to a third of all samples). This doesn’t make interpreting the “execution-time” profiles any easier.</p>



<h2>CPU-time profiling</h2>



<p>As shown in the video above, sampling every thread every n milliseconds of CPU time improves the situation. Now, the number of samples for every thread is directly related to the time it spends on the CPU without any subsampling, as the number of hardware threads bounds the number of sampled threads.</p>



<blockquote>
<p>The ability to accurately and precisely measure CPU-cycle consumption was added to the Linux kernel in version 2.6.12 via a timer that emits signals at fixed intervals of CPU time rather than fixed intervals of elapsed real time. Most profilers on Linux use this mechanism to produce CPU-time profiles.</p>



<p>Some popular third-party Java tools, including <a href="https://github.com/async-profiler/async-profiler">async-profiler</a>, use Linux’s CPU timer to produce CPU-time profiles of Java programs. However, to do so, such tools interact with the Java runtime through unsupported internal interfaces. This is inherently unsafe and can lead to process crashes.</p>



<p>We should enhance JFR to use the Linux kernel’s CPU timer to safely produce CPU-time profiles of Java programs. This would help the many developers who deploy Java applications on Linux to make those applications more efficient.</p>
<cite><a href="https://openjdk.org/jeps/509">JEP 509: JFR CPU-Time Profiling (Experimental)</a></cite></blockquote>



<p>Please be aware that I don’t discourage using async-profiler. It’s a potent tool and is used by many people. But it is inherently hampered by not being embedded into the JDK. This is especially true with the new stackwalking at safepoints (see <a href="https://mostlynerdless.de/blog/2025/05/20/taming-the-bias-unbiased-safepoint-based-stack-walking-in-jfr/">Taming the Bias: Unbiased* Safepoint-Based Stack Walking in JFR</a>), making the current JFR sampler safer to use. This mechanism is sadly not available for external profilers, albeit I had my ideas for an API (see <a href="https://mostlynerdless.de/blog/2023/08/10/taming-the-bias-unbiased-safepoint-based-stack-walking/">Taming the Bias: Unbiased Safepoint-Based Stack Walking</a>), but this project has sadly been abandoned.</p>



<p>Let’s continue with the example from before.</p>



<blockquote>
<p>FR will use Linux’s CPU-timer mechanism to sample the stack of every thread running Java code at fixed intervals of CPU time. Each such sample is recorded in a new type of event, <code>jdk.CPUTimeSample</code>. This event is not enabled by default.</p>



<p>This event is similar to the existing <code>jdk.ExecutionSample</code> event for execution-time sampling. Enabling CPU-time events does not affect execution-time events in any way, so the two can be collected simultaneously.</p>



<p>We can enable the new event in a recording started at launch like so:</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ java -XX:StartFlightRecording=jdk.CPUTimeSample#enabled=true,filename=profile.jfr ...</pre>



<p>With the new CPU-time sampler, in the flame graph it becomes clear that the application spends nearly all of its CPU cycles in <code>tenFastRequests</code>:</p>



<blockquote>
<figure><img decoding="async" src="https://bugs.openjdk.org/secure/attachment/110757/cpu_profile.png" alt="CPU time flame graph"></figure>
</blockquote>



<p>A textual profile of the hot CPU methods, i.e., those that consume many CPU cycles in their own bodies rather than in calls to other methods, can be obtained like so:</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ jfr view cpu-time-hot-methods profile.jfr</pre>



<p>However, in this particular example, the output is not as useful as the flame graph.</p>
<cite><a href="https://openjdk.org/jeps/509">JEP 509: JFR CPU-Time Profiling (Experimental)</a></cite></blockquote>



<p>Notably, the CPU-time profiler also reports failed and missed samples, but more on that later.</p>



<h2>Problems of the new Profiler</h2>



<p>I pointed out all the problems in the current JFR method sampler, so I should probably point out my problems, too.</p>



<p>The most significant issue is platform support, or better, the lack of it: The new profiler only supports Linux for the time being. While this is probably not a problem for production profiling, as most systems use Linux anyway, it’s a problem for profiling on developer machines. Most development happens on Windows and Mac OS machines. So, not being able to use the same profiler as in production hampers productivity. But this is a problem for other profilers too. Async-profiler, for example, only supports wall-clock profiling on Mac OS and doesn’t support Windows at all. JetBrains has a closed-source version of async-profiler that might support cpu-time profiling on Windows (see <a href="https://github.com/async-profiler/async-profiler/issues/188">GitHub issue</a>). Still, I could not confirm as I don’t have a Windows machine and found no specific information online.</p>



<p>Another issue, of course, is that the profiler barely got in at the last minute, after Nicolai Parlog, for example, filmed his <a href="https://www.youtube.com/watch?v=T5q72vcSjyk" data-rel="lightbox-video-0">Java 25 update video</a>.</p>



<figure><img decoding="async" width="1797" height="1020" src="https://mostlynerdless.de/wp-content/uploads/2025/06/image.png" alt="" srcset="https://mostlynerdless.de/wp-content/uploads/2025/06/image.png 1797w, https://mostlynerdless.de/wp-content/uploads/2025/06/image-300x170.png 300w, https://mostlynerdless.de/wp-content/uploads/2025/06/image-768x436.png 768w, https://mostlynerdless.de/wp-content/uploads/2025/06/image-1536x872.png 1536w, https://mostlynerdless.de/wp-content/uploads/2025/06/image-500x284.png 500w" sizes="(max-width: 1797px) 100vw, 1797px"><figcaption><a href="https://bsky.app/profile/nipafx.dev/post/3lqttwaggdk22">Conversation on BlueSky under his video post</a></figcaption></figure>



<h2>Why did it get into JDK 25?</h2>



<p>Most users only use and get access to LTS versions of the JDK, so we wanted to get the feature into the LTS JDK 25 to allow people to experiment with it. To quote Markus Grönlund:</p>



<blockquote>
<p>I am approving this PR for the following reasons:</p>



<ol>
<li>We have reached a state that is “good enough” – I no longer see any fundamental design issues that can not be handled by follow-up bug fixes.</li>



<li>There are still many vague aspects included with this PR, as many has already pointed out, mostly related to the memory model and thread interactions – all those can, and should, be clarified, explained and exacted post-integration.</li>



<li>The feature as a whole is experimental and turned off by default.</li>



<li>Today is the penultimate day before JDK 25 cutoff. To give the feature a fair chance for making JDK25, it needs approval now.</li>
</ol>



<p>Thanks a lot Johannes and all involved for your hard work getting this feature ready.</p>



<p>Many thanks<br>Markus</p>
<cite><a href="https://github.com/openjdk/jdk/pull/25302#pullrequestreview-2896467191">Comment on the PR</a></cite></blockquote>



<h2>Open Issues</h2>



<p>So, use the profiler with care. None of the currently known issues should break the JVM. But there are currently three important follow-up issues to the merged profiler:</p>



<ul>
<li><a href="https://bugs.openjdk.org/browse/JDK-8358621">Avoid using a spinlock as the synchronization point returning from native in CPU Time Profiler</a> [Edit July: fixed]</li>



<li><a href="https://bugs.openjdk.org/browse/JDK-8358616">Clarify the requirements and exact the memory ordering in CPU Time Profiler</a>: I used acquire-release semantics for most atomic variables, which is not wrong, just not necessarily optimal from a performance perspective.</li>



<li><a href="https://bugs.openjdk.org/browse/JDK-8358619">Fix interval recomputation in CPU Time Profiler</a> [Edit July: fixed]</li>
</ul>



<p>I have already started work on the last issue and will be looking into the other two soon. Please test the profiler yourself and report all the issues you find.</p>



<h2>The new CPUTimeSample Event</h2>



<p>Where the old profiler had two events <code>jdk.ExecutionSample</code> and <code>jdk.NativeMethodSample</code>The new profiler has only one for simplicity, as it doesn’t treat threads in native and Java differently. As stated before, this event is called <code>jdk.CPUTimeSample</code>.</p>



<p>The event has five different fields:</p>



<ul>
<li><code>stackTrace</code> (nullable): Recorded stack trace</li>



<li><code>eventThread</code>: Sampled thread</li>



<li><code>failed</code> (boolean): Did the sampler fail to walk the stack trace? Implies that <code>stackTrace</code> is <code>null</code></li>



<li><code>samplingPeriod</code>: The actual sampling period, directly computed in the signal handler. More on that next week.</li>



<li><code>biased</code> (boolean): Is this sample safepoint biased (the stacktrace related to the frame at safepoint and not the actual frame when the sampling request has been created, see <a href="https://mostlynerdless.de/blog/2025/05/20/taming-the-bias-unbiased-safepoint-based-stack-walking-in-jfr/">Taming the Bias: Unbiased* Safepoint-Based Stack Walking in JFR</a> for more)</li>
</ul>



<p>You can find the event on the <a href="https://sapmachine.io/jfrevents/25.html#cputimesample">JFR Events Collection</a> page too.</p>



<p>Internally, the profiler uses bounded queues, which might overflow; this can result in lost events. The number of these events is regularly recorded in the form of the <code>jdk.CPUTimeSampleLoss</code> event. The event has two fields:</p>



<ul>
<li><code>lostSamples</code>: Number of samples that have been lost since the last <code>jdk.CPUTimeSampleLoss</code> event</li>



<li><code>eventThread</code>: Thread for which the samples are lost</li>
</ul>



<p>Both events allow a pretty good view of the program’s execution, including a relatively exact view of the CPU time used.</p>



<h2>Configuration of the CPU-time Profiler</h2>



<p>The emission of two events of the current sampler is controlled via the <code>period</code> property. It allows the user to configure the sampling interval. The problem now with the CPU-time profiler is that it might produce too many events depending on the number of hardware threads. This is why the <code>jdk.CPUTimeSample</code> event is controlled via the <code>throttle</code> setting. This setting can be either a sampling interval or an upper bound for the number of emitted events.</p>



<p>When setting an interval directly like “10ms” (as in the <code>default.jfc</code>), then we sample every thread every 10ms of CPU-time. This can at most result in 100 * #[hardware threads] events per second. On a 10 hardware thread machine, this results in at most (when every thread is CPU-bound) 1000 events per second or 12800 on a 128 hardware thread machine.</p>



<p>Setting, on the other hand, <code>throttle</code> to a rate like “500/s” (as in the <code>profile.jfc</code>), limits the number of events per second to a fixed rate. This is implemented by choosing the proper sampling interval in relation to the number of hardware threads. For a rate of “500/s” and a ten hardware thread machine, this would be 20ms. On a 128 hardware thread machine, this would be 0.256.</p>



<p>I have to mention that the issue <a href="https://bugs.openjdk.org/browse/JDK-8358619"><em>Fix interval recomputation in CPU Time Profiler</em></a> is related to the recomputation when the number of hardware threads changes mid-profiling.</p>



<h2>New JFR Views</h2>



<p>In addition to the two new events, there are two new views that you can use via <code>jfr view VIEW_NAME profile.jfr</code>:</p>



<p><code>cpu-time-hot-methods</code> shows you a list of the 25 most executed methods. These are methods that are on top of the stack the most (running the <a href="https://gist.github.com/parttimenerd/d66364f2086089761eb2fec7eda026d7">example</a> with a 1ms throttle):</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">                       Java Methods that Execute the Most from CPU Time Sampler (Experimental)

Method                                                                                                Samples Percent
----------------------------------------------------------------------------------------------------- ------- -------
jdk.jfr.internal.JVM.emitEvent(long, long, long)                                                           35  72.92%
jdk.jfr.internal.event.EventWriter.putStringValue(String)                                                   1   2.08%
jdk.internal.loader.NativeLibraries.load(NativeLibraries$NativeLibraryImpl, String, boolean, boolean)       1   2.08%
jdk.internal.logger.LazyLoggers$LazyLoggerAccessor.platform()                                               1   2.08%
jdk.internal.jimage.ImageStringsReader.unmaskedHashCode(String, int)                                        1   2.08%
sun.net.www.ParseUtil.quote(String, long, long)                                                             1   2.08%
java.net.HttpURLConnection.getResponseCode()                                                                1   2.08%
java.io.BufferedInputStream.read(byte[], int, int)                                                          1   2.08%
java.util.HashMap.hash(Object)                                                                              1   2.08%
sun.nio.ch.NioSocketImpl$1.read(byte[], int, int)                                                           1   2.08%
java.util.Properties.load0(Properties$LineReader)                                                           1   2.08%
java.lang.StringLatin1.regionMatchesCI(byte[], int, byte[], int, int)                                       1   2.08%
java.util.stream.AbstractPipeline.exactOutputSizeIfKnown(Spliterator)                                       1   2.08%
sun.nio.fs.UnixChannelFactory$Flags.toFlags(Set)                                                            1   2.08%</pre>



<p>The second view is <code>cpu-time-statistics</code> which gives you the number of successful samples, failed samples, biased Samples, total samples, and lost samples:</p>



<pre data-enlighter-language="bash" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CPU Time Sample Statistics
--------------------------
Successful Samples: 48
Failed Samples: 0
Biased Samples: 0
Total Samples: 48
Lost Samples: 14</pre>



<p>All of the lost samples are caused by the sampled Java thread running VM internal code. This view is really helpful when checking whether the profiling contains the whole picture. </p>



<h2>Conclusion</h2>



<p>Getting this new profiler in JDK 25 was a real push, but I think it was worth it. OpenJDK now has a built-in CPU-time profiler that records missed samples. The implementation builds upon JFR’s new cooperative sampling approach, which also got into JDK 25 just days before. CPU-time profiling has many advantages, especially when you’re interested in the code that is actually wasting your CPU.</p>



<p>This is the first of a two-part series on the new profiler. You can expect a deep dive into the implementation of the profiler next week.</p>



<p><em>This blog post is part of my work in the <a href="https://sapmachine.io/">SapMachine</a> team at <a href="https://sap.com/">SAP</a>, making profiling easier for everyone.</em></p>



<p>P.S.: I submitted to a few conferences the talk <em>From Idea to JEP: An OpenJDK Developer’s Journey to Improve Profiling</em> with the following description: <em>Have you ever wondered how profiling, like JFR, works in OpenJDK and how we can improve it? In this talk, I’ll take you on my three-year journey to improve profiling, especially method sampling, with OpenJDK: from the initial ideas and problems of existing approaches to my different draft implementations and JEP versions, with all the setbacks and friends I made along the way. It’s a story of blood, sweat, and C++.</em><br>It has sadly not been accepted yet.</p>

                
                    <!--begin code -->

                    
                    <div data-post_id="1710" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-1710 box-instance-id-1">
                                                                                    
                                                                            <p><span>
                                                                                                                        <ul>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
                                                                                                                    <li>
                                                                                                                                                                                    <div>
                                                                    <p><img alt="Johannes Bechberger" src="https://secure.gravatar.com/avatar/c52eaa3c0c73ed834ae0e48b927edd38573408d48f4c35c898d34f71d958e0c9?s=80&amp;d=blank&amp;r=g" srcset="https://secure.gravatar.com/avatar/c52eaa3c0c73ed834ae0e48b927edd38573408d48f4c35c898d34f71d958e0c9?s=160&amp;d=blank&amp;r=g 2x" height="80" width="80">                                                                                                                                                                                                            </p>
                                                                                                                                    </div>
                                                            
                                                            <div>
                                                                                                                                                                                                                                                                        <p>
                                                                                                                                                    Johannes Bechberger is a JVM developer working on profilers and their underlying technology in the SapMachine team at SAP. This includes improvements to async-profiler and its ecosystem, a website to view the different JFR event types, and improvements to the FirefoxProfiler, making it usable in the Java world. He started at SAP in 2022 after two years of research studies at the KIT in the field of Java security analyses. His work today is comprised of many open-source contributions and his blog, where he writes regularly on in-depth profiling and debugging topics, and of working on his JEP Candidate 435 to add a new profiling API to the OpenJDK.                                                                                                                                                </p>
                                                                                                                                
                                                                                                                                    <p><span>
                                                                        <a href="https://mostlynerdless.de/blog/author/parttimenerd/" title="View all posts">
                                                                            <span>View all posts</span>
                                                                        </a>
                                                                    </span>
                                                                                                                                <a aria-label="Email" href="mailto:me@mostlynerdless.de" target="_self"><span></span> </a><a aria-label="Website" href="https://mostlynerdless.de/" target="_self"><span></span> </a>
                                                                                                                            </p></div>
                                                                                                                                                                                                                        </li>
                                                                                                                                                                                                                                    </ul>
                                                                            </span>
                                                                                                                        </p>
                        </div>
                    <!--end code -->
                    
                
                            
        <div id="tnp-subscription-posts"><p>New posts like these come out at least every two weeks, to get notified about new posts, follow me on <a href="https://bsky.app/profile/mostlynerdless.de">BlueSky</a>, <a href="https://twitter.com/parttimen3rd">Twitter</a>, <a href="https://mastodon.social/@parttimenerd">Mastodon</a>, or <a href="https://www.linkedin.com/in/johannes-bechberger/">LinkedIn</a>, or join the newsletter:</p>
</div>			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Social media promised connection, but it has delivered exhaustion (237 pts)]]></title>
            <link>https://www.noemamag.com/the-last-days-of-social-media/</link>
            <guid>45229799</guid>
            <pubDate>Sat, 13 Sep 2025 06:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noemamag.com/the-last-days-of-social-media/">https://www.noemamag.com/the-last-days-of-social-media/</a>, See on <a href="https://news.ycombinator.com/item?id=45229799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="article">

        <div role="group">
    <p>Credits</p>
    <p>James O’Sullivan lectures in the School of English and Digital Humanities at University College Cork, where his work explores the intersection of technology and culture.</p>
</div>
<p>At first glance, the feed looks familiar, a seamless carousel of “For You” updates gliding beneath your thumb. But déjà‑vu sets in as 10 posts from 10 different accounts carry the same stock portrait and the same breathless promise — “click here for free pics” or “here is the one productivity hack you need in 2025.” Swipe again and three near‑identical replies appear, each from a pout‑filtered avatar directing you to “free pics.” Between them sits an ad for a cash‑back crypto card.</p><p>Scroll further and recycled TikTok clips with “original audio” bleed into Reels on Facebook and Instagram; AI‑stitched football highlights showcase players’ limbs bending like marionettes. Refresh once more, and the woman who enjoys your snaps of sushi rolls has seemingly spawned five clones.</p><p>Whatever remains of genuine, human content is increasingly sidelined by algorithmic prioritization, receiving fewer interactions than the engineered content and AI slop optimized solely for clicks.&nbsp;</p><p>These are the last days of social media as we know it.</p><h2 id="h-drowning-the-real"><strong>Drowning The Real</strong></h2><p>Social media was built on the romance of authenticity. Early platforms sold themselves as conduits for genuine connection: stuff you wanted to see, like your friend’s wedding and your cousin’s dog.</p><p>Even influencer culture, for all its artifice, promised that behind the ring‑light stood an actual person. But the attention economy, and more recently, the generative AI-fueled late attention economy, have broken whatever social contract underpinned that illusion. The feed no longer feels crowded with people but crowded with content. At this point, it has far less to do with people than with consumers and consumption.</p><p>In recent years, Facebook and other platforms that facilitate billions of daily interactions have slowly morphed into the internet’s largest repositories of <a href="https://cyber.fsi.stanford.edu/news/ai-spam-accounts-build-followers">AI‑generated spam</a>. Research has found what users plainly see: tens of thousands of machine‑written posts <a href="https://doi.org/10.37016/mr-2020-151">now flood</a> public groups —&nbsp;pushing scams, chasing clicks —&nbsp;with <a href="https://www.wired.com/story/gadget-lab-podcast-632/">clickbait</a> headlines, half‑coherent listicles and hazy lifestyle images stitched together in AI tools like Midjourney.</p><p>It’s all just vapid, empty shit produced for engagement’s sake. Facebook is “sloshing” in low-effort AI-generated posts, as Arwa Mahdawi <a href="https://www.theguardian.com/global/commentisfree/2025/jan/08/ai-generated-slop-slowly-killing-internet-nobody-trying-to-stop-it">notes</a> in The Guardian; some even bolstered by algorithmic boosts, like “<a href="https://www.niemanlab.org/2024/04/from-shrimp-jesus-to-fake-self-portraits-ai-generated-images-have-become-the-latest-form-of-social-media-spam/">Shrimp Jesus</a>.”</p><p>The difference between human and synthetic content is becoming increasingly indistinguishable, and platforms seem unable, or uninterested, in trying to police it. Earlier this year, CEO Steve Huffman pledged to “<a href="https://www.reddit.com/user/spez/comments/1kfciml/reddits_next_chapter_smarter_easier_still_human/">keep Reddit human</a>,” a tacit admission that floodwaters were already lapping at the last high ground. TikTok, meanwhile, <a href="https://www.newsguardtech.com/special-reports/tiktok-content-farms-use-ai-voiceovers-to-mass-produce-political-misinformation/">swarms</a> with AI narrators presenting concocted news reports and <a href="https://restofworld.org/2023/ai-tiktok-creators-rewrite-history/">“what‑if” histories</a>. A few creators do append labels disclaiming that their videos depict “no real events,” but many creators don’t bother, and many consumers don’t seem to care.</p><p>The problem is not just the rise of fake material, but the collapse of context and the acceptance that truth no longer matters as long as our cravings for colors and noise are satisfied. Contemporary social media content is more often rootless, detached from cultural memory, interpersonal exchange or shared conversation. It arrives fully formed, optimized for attention rather than meaning, producing a kind of semantic sludge, posts that look like language yet say almost nothing.&nbsp;</p><p>We’re drowning in this nothingness.</p><h2 id="h-the-bot-girl-economy"><strong>The Bot-Girl Economy</strong></h2><p>If spam (AI or otherwise) is the white noise of the modern timeline, its dominant melody is a different form of automation: the hyper‑optimized, sex‑adjacent human avatar. She appears everywhere, replying to trending tweets with selfies, promising “funny memes in bio” and linking, inevitably, to OnlyFans or one of its proxies. Sometimes she is real. Sometimes she is not. Sometimes she is a he, sitting in a <a href="https://www.economist.com/leaders/2025/02/06/the-vast-and-sophisticated-global-enterprise-that-is-scam-inc">compound in Myanmar</a>. Increasingly, it makes no difference.</p><p>This convergence of bots, scammers, brand-funnels and soft‑core marketing underpins what might be called <em>the bot-girl economy</em>, a parasocial marketplace <a href="https://doi.org/10.1111/gwao.13047">fueled</a> in a large part by economic precarity. At its core is a transactional logic: Attention is scarce, intimacy is monetizable and platforms generally won’t intervene so long as engagement <a href="https://scienceblog.com/social-media-bots-create-more-chatter-but-less-meaningful-conversation-research-shows/">stays high</a>. As more women now turn to online sex work, lots of men are eager to pay them for their services. And as these workers try to cope with the precarity imposed by platform metrics and competition, some can spiral, forever downward, into a transactional attention-to-intimacy logic that eventually turns them into more bot than human. To hold attention, some creators increasingly opt to behave like algorithms themselves, <a href="https://www.supercreator.app/automation#:~:text=Supercreator%20%2D%20Engage%20Fans%20With%20OnlyFans,more%20proactive%20in%20your%20conversations.">automating </a>replies, optimizing content for engagement, or mimicking affection at scale. The distinction between performance and intention must surely erode as real people perform as synthetic avatars and synthetic avatars mimic real women.</p><p>There is loneliness, desperation and predation everywhere.</p><!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “Genuine, human content is increasingly sidelined by algorithmic prioritization, receiving fewer interactions than the engineered content and AI slop optimized solely for clicks.”    </p>

    
    
  </blockquote>
</figure><p>The bot-girl is more than just a symptom; she is a proof of concept for how social media bends even aesthetics to the logic of engagement. Once, profile pictures (both real and synthetic) aspired to hyper-glamor, unreachable beauty filtered through fantasy. But that fantasy began to underperform as average men sensed the ruse, recognizing that supermodels typically don’t send them DMs. And so, the system adapted, surfacing profiles that felt more plausible, more emotionally available. Today’s avatars project a curated accessibility: They’re attractive but not flawless, styled to suggest they might genuinely be interested in you. It’s a calibrated effect, just human enough to convey plausibility, just artificial enough to scale. She has to look more human to stay afloat, but act more bot to keep up. Nearly everything is socially engineered for maximum interaction: the like, the comment, the click, the private message.</p><p>Once seen as the fringe economy of cam sites, OnlyFans has become the dominant digital marketplace for sex workers. In 2023, the then-seven-year-old platform <a href="https://variety.com/2024/digital/news/onlyfans-payments-2023-financials-revenue-creator-earnings-1236135425/">generated</a> $6.63 billion in gross payments from fans, with $658 million in profit before tax. Its success has bled across the social web; platforms like X (formerly Twitter) now serve as de facto marketing layers for OnlyFans creators, with thousands of accounts running fan-funnel operations, <a href="https://www.businessinsider.com/how-to-promote-onlyfans-according-to-creators">baiting</a> users into paid subscriptions.&nbsp;</p><p>The tools of seduction are also changing. One 2024 study <a href="https://arxiv.org/abs/2401.02627">estimated</a> that thousands of X accounts use AI to generate fake profile photos. Many content creators have also <a href="https://aijourn.com/how-ai-is-revolutionizing-digital-content-creation-from-face-swaps-to-lip-syncing/">begun using AI</a> for talking-head videos, <a href="https://www.tiktok.com/@itstarachristina/video/7350403031969713441?lang=en">synthetic voices</a> or endlessly varied selfies. Content is likely A/B tested for click-through rates. Bios are written with conversion in mind. DMs are automated or <a href="https://www.wired.com/story/onlyfans-models-are-using-ai-impersonators-to-keep-up-with-their-dms/">outsourced</a> to AI impersonators. For users, the effect is a strange hybrid of influencer, chatbot and parasitic marketing loop. One minute you’re arguing politics, the next, you’re being pitched a girlfriend experience by a bot.&nbsp;</p><h2 id="h-engagement-in-freefall"><strong>Engagement In Freefall</strong></h2><p>While content proliferates, engagement is evaporating. Average interaction rates across major platforms are declining fast: Facebook and X posts now scrape an average 0.15% engagement, while Instagram has dropped 24% year-on-year. Even TikTok has <a href="https://doi.org/10.48550/arXiv.2401.02627">begun to plateau</a>. People aren’t connecting or conversing on social media like they used to; they’re just wading through slop, that is, low-effort, low-quality content produced at scale, often with AI, for engagement.</p><p>And much of it <em>is</em> slop: Less than half of American adults <a href="https://www.pewresearch.org/journalism/fact-sheet/social-media-and-news-fact-sheet/">now rate</a> the information they see on social media as “mostly reliable”— down from roughly two-thirds in the mid-2010s.&nbsp; Young adults register the steepest collapse, which is unsurprising; as digital natives, they better understand that the content they scroll upon wasn’t necessarily produced by humans. And yet, they continue to scroll.</p><p>The timeline is no longer a source of information or social presence, but more of a mood-regulation device, endlessly replenishing itself with just enough novelty to suppress the anxiety of stopping. Scrolling has become a form of ambient dissociation, half-conscious, half-compulsive, closer to scratching an itch than seeking anything in particular. People know the feed is fake, they just don’t care.&nbsp;</p><p>Platforms have little incentive to stem the tide. Synthetic accounts are cheap, tireless and lucrative because they never demand wages or unionize. Systems designed to surface peer-to-peer engagement are now systematically filtering out such activity, because what counts as engagement has changed. Engagement is now about raw user attention – time spent, impressions, scroll velocity – and the net effect is an online world in which you are constantly being addressed but never truly spoken to.</p><h2 id="h-the-great-unbundling"><strong>The Great Unbundling</strong></h2><p>Social media’s death rattle will not be a bang but a shrug.</p><p>These networks once promised a single interface for the whole of online life: Facebook as social hub, Twitter as news‑wire, YouTube as broadcaster, Instagram as photo album, TikTok as distraction engine. Growth appeared inexorable. But now, the model is splintering, and users are drifting toward smaller, slower, more private spaces, like group chats, Discord servers and <a href="https://www.theverge.com/24063290/fediverse-explained-activitypub-social-media-open-protocol">federated microblogs</a> — a billion little gardens.</p><p>Since Elon Musk’s takeover, X has <a href="https://www.theguardian.com/technology/2024/mar/26/twitter-usage-in-us-fallen-by-a-fifth-since-elon-musks-takeover">shed</a> at least 15% of its global user base. Meta’s Threads, launched with great fanfare in 2023, saw its number of daily active users collapse within a month, <a href="https://time.com/6305383/meta-threads-failing">falling</a> from around 50 million active Android users at launch in July to only 10 million active users the following August. Twitch <a href="https://www.tubefilter.com/2025/01/10/twitch-lowest-watch-time-streams-charts-top-streamers-december-2024/">recorded</a> its lowest monthly watch-time in over four years in December 2024, just 1.58 billion hours, 11% lower than the December average from 2020-23.</p><!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “While content proliferates, engagement is evaporating.”    </p>

    
    
  </blockquote>
</figure><p>Even the giants that still command vast audiences are no longer growing exponentially. Many platforms have already died (Vine, Google+, Yik Yak), are functionally dead or zombified (Tumblr, Ello), or have been revived and died again (MySpace, Bebo). Some notable exceptions aside, like Reddit and BlueSky (though it’s still early days for the latter), growth has plateaued across the board. While social media adoption continues to rise overall, it’s no longer explosive. <a href="https://datareportal.com/reports/digital-2025-sub-section-state-of-social">As of early 2025</a>, around 5.3 billion user identities — roughly 65% of the global population — are on social platforms, but annual growth has decelerated to just 4-5%, a steep drop from the double-digit surges seen earlier in the 2010s.</p><p>Intentional, opt-in micro‑communities are rising in their place — like Patreon collectives and Substack newsletters —&nbsp;where creators chase depth over scale, retention over virality. A writer with 10,000 devoted subscribers can potentially earn more and burn out less than one with a million passive followers on Instagram.&nbsp;</p><p>But the old practices are still evident: Substack is full of personal brands announcing their journeys, Discord servers host influencers disguised as community leaders and Patreon bios promise exclusive access that is often just recycled content. Still, something has shifted. These are not mass arenas; they are clubs — opt-in spaces with boundaries, where people remember who you are. And they are often paywalled, or at least heavily moderated, which at the very least keeps the bots out. What’s being sold is less a product than a sense of proximity, and while the economics may be similar, the affective atmosphere is different, smaller, slower, more reciprocal. In these spaces, creators don’t chase virality; they cultivate trust.</p><p>Even the big platforms sense the turning tide. Instagram has begun emphasizing DMs, X is pushing subscriber‑only circles and TikTok is experimenting with private communities. Behind these developments is an implicit acknowledgement that the infinite scroll, stuffed with bots and synthetic sludge, is approaching the limit of what humans will tolerate. A lot of people <a href="https://jamescosullivan.substack.com/p/we-cant-get-enough-of-the-bullshit">seem to be fine</a> with slop, but as more start to crave authenticity, the platforms will be forced to take note.</p><h2 id="h-from-attention-to-exhaustion"><strong>From Attention To Exhaustion</strong></h2><p>The social internet was built on attention, not only the promise to capture yours but the chance for you to capture a slice of everyone else’s. After two decades, the mechanism has inverted, replacing connection with exhaustion. “Dopamine detox” and “digital Sabbath” have entered the mainstream. In the U.S., <a href="https://www.psychiatry.org/news-room/news-releases/more-new-years-mental-health-resolutions">a significant proportion</a> of 18‑ to 34‑year‑olds took deliberate breaks from social media in 2024, citing mental health as the motivation, according to an American Psychiatric Association poll. And yet, time spent on the platforms remains high — people scroll not because they enjoy it, but because they don’t know how to stop. Self-help influencers now recommend weekly “no-screen Sundays” (yes, the irony). The mark of the hipster is no longer an ill-fitting beanie but an old-school Nokia dumbphone.&nbsp;</p><p><a href="https://www.theguardian.com/media/2025/jul/05/cant-pause-internet-social-media-creators-burnout">Some creators are quitting, too</a>. Competing with synthetic performers who never sleep, they find the visibility race not merely tiring but absurd. Why post a selfie when an AI can generate a prettier one? Why craft a thought when ChatGPT can produce one faster?</p><p>These are the last days of social media, not because we lack content, but because the attention economy has neared its outer limit — we have exhausted the capacity to care. There is more to watch, read, click and react to than ever before — an endless buffet of stimulation. But novelty has become indistinguishable from noise. Every scroll brings more, and each addition subtracts meaning. We are indeed drowning. In this saturation, even the most outrageous or emotive content struggles to provoke more than a blink.</p><p>Outrage fatigues. Irony flattens. Virality cannibalizes itself. The feed no longer surprises but sedates, and in that sedation, something quietly breaks, and social media no longer feels like a place to be; it is a surface to skim.&nbsp;</p><p>No one is forcing anyone to go on TikTok or to consume the clickbait in their feeds. The content served to us by algorithms is, in effect, a warped mirror, reflecting and distorting our worst impulses. For younger users in particular, their scrolling of social media can <a href="https://www.apa.org/news/apa/2022/social-media-children-teens">become compulsive</a>, rewarding <a href="https://search.worldcat.org/en/title/1359918931">their</a> developing brains with unpredictable hits of dopamine that keep them glued to their screens.
          </p>
        <p>Social media platforms have also achieved something more elegant than coercion: They’ve made non-participation a form of self-exile, a luxury available only to those who can afford its costs.</p><!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “Why post a selfie when an AI can generate a prettier one? Why craft a thought when ChatGPT can produce one faster?”    </p>

    
    
  </blockquote>
</figure><p>Our offline reality is irrevocably shaped by our online world: Consider the worker who deletes or was never on LinkedIn, excluding themselves from professional networks that increasingly exist nowhere else; or the small business owner who abandons Instagram, watching customers drift toward competitors who maintain their social media presence. The teenager who refuses TikTok may find herself unable to parse references, memes and microcultures that soon constitute her peers’ vernacular.</p><p>These platforms haven’t just captured attention, they’ve enclosed the commons where social, economic and cultural capital are exchanged. But enclosure breeds resistance, and as exhaustion sets in, alternatives begin to emerge.</p><h2 id="h-architectures-of-intention"><strong>Architectures Of Intention</strong></h2><p>The successor to mass social media is, as already noted, emerging not as a single platform, but as a scattering of alleyways, salons, encrypted lounges and federated town squares —&nbsp; those little gardens.</p><p>Maybe today’s major social media platforms will find new ways to hold the gaze of the masses, or maybe they will continue to decline in relevance, lingering like derelict shopping centers or a dying online game, haunted by bots and the echo of once‑human chatter. Occasionally we may wander back, out of habit or nostalgia, or to converse once more as a crowd, among the ruins. But as social media collapses on itself, the future points to a quieter, more fractured, more human web, something that no longer promises to be everything, everywhere, for everyone.</p><p>This is a good thing. Group chats and invite‑only circles are where context and connection survive. These are spaces defined less by scale than by shared understanding, where people no longer perform for an algorithmic audience but speak in the presence of chosen others. Messaging apps like Signal are quietly <a href="https://dig.watch/updates/messaging-app-signal-sees-rising-popularity-in-us-and-europe">becoming dominant</a> infrastructures for digital social life, not because they promise discovery, but because they don’t. In these spaces, a message often carries more meaning because it is usually directed, not broadcast.</p><p>Social media’s current logic is designed to reduce friction, to give users infinite content for instant gratification, or at the very least, the anticipation of such. The antidote to this compulsive, numbing overload will be found in <em>deliberative</em> friction, design patterns that introduce pause and reflection into digital interaction, or platforms and algorithms that create space for intention.</p><p>This isn’t about making platforms needlessly cumbersome but about distinguishing between helpful constraints and extractive ones. Consider <a href="https://www.are.na/">Are.na</a>, a non-profit, ad-free creative platform founded in 2014 for collecting and connecting ideas that feels like the anti-Pinterest: There’s no algorithmic feed or engagement metrics, no trending tab to fall into and no infinite scroll. The pace is glacial by social media standards. Connections between ideas must be made manually, and thus, thoughtfully — there are no algorithmic suggestions or ranked content.</p><p>To demand intention over passive, mindless screen time, X could require a 90-second delay before posting replies, not to deter participation, but to curb reactive broadcasting and engagement farming. Instagram could show how long you’ve spent scrolling before allowing uploads of posts or stories, and Facebook could display the carbon cost of its data centers, reminding users that digital actions have material consequences, with each refresh. These small added moments of friction and purposeful interruptions — what UX designers currently optimize away — are precisely what we need to break the cycle of passive consumption and restore intention to digital interaction.</p><p>We can dream of a digital future where belonging is no longer measured by follower counts or engagement rates, but rather by the development of trust and the quality of conversation. We can dream of a digital future in which communities form around shared interests and mutual care rather than algorithmic prediction. Our public squares — the big algorithmic platforms — will never be cordoned off entirely, but they might sit alongside countless semi‑public parlors where people choose their company and set their own rules, spaces that prioritize continuity over reach and coherence over chaos. People will show up not to go viral, but to be seen in context. None of this is about escaping the social internet, but about reclaiming its scale, pace, and purpose.</p><h2 id="h-governance-scaffolding"><strong>Governance Scaffolding</strong></h2><p>The most radical redesign of social media might be the most familiar: What if we treated these platforms as <a href="https://www.brookings.edu/articles/utilities-for-democracy-why-and-how-the-algorithmic-infrastructure-of-facebook-and-google-must-be-regulated/">public utilities</a> rather than private casinos?</p><p>A public-service model wouldn’t require state control; rather, it could be governed through civic charters, much like public broadcasters operate under mandates that balance independence and accountability. This vision stands in stark contrast to the current direction of most major platforms, which are becoming increasingly opaque.</p><!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “Non-participation [is] a form of self-exile, a luxury available only to those who can afford its costs.”    </p>

    
    
  </blockquote>
</figure><p>In recent years, Reddit and X, among other platforms, have either restricted or removed API access, dismantling open-data pathways. The very infrastructures that shape public discourse are retreating from public access and oversight. Imagine social media platforms with transparent algorithms subject to public audit, user representation on governance boards, revenue models based on public funding or member dues rather than surveillance advertising, mandates to serve democratic discourse rather than maximize engagement, and regular impact assessments that measure not just usage but societal effects.</p><p>Some initiatives gesture in this direction. Meta’s Oversight Board, for example, frames itself as an independent body for content moderation appeals, though its remit is narrow and its influence ultimately limited by Meta’s discretion. X’s Community Notes, meanwhile, allows user-generated fact-checks but relies on opaque scoring mechanisms and lacks formal accountability. Both are add-ons to existing platform logic rather than systemic redesigns. A true public-service model would bake accountability into the platform’s infrastructure, not just bolt it on after the fact.</p><p>The European Union has begun exploring this territory through its Digital Markets Act and Digital Services Act, but these laws, enacted in 2022, largely focus on regulating existing platforms rather than imagining new ones. In the United States, efforts are more fragmented. Proposals such as the Platform Accountability and Transparency Act (PATA) and state-level laws in California and New York aim to increase oversight of algorithmic systems, particularly where they impact youth and mental health. Still, most of these measures seek to retrofit accountability onto current platforms. What we need are spaces built from the ground up on different principles, where incentives align with human interest rather than extractive, for-profit ends.</p><p>This could take multiple forms, like municipal platforms for local civic engagement, professionally focused networks run by trade associations, and educational spaces managed by public library systems. The key is diversity, delivering an ecosystem of civic digital spaces that each serve specific communities with transparent governance.</p><p>Of course, publicly governed platforms aren’t immune to their own risks. State involvement can bring with it the threat of politicization, censorship or propaganda, and this is why the governance question must be treated as infrastructural, rather than simply institutional. Just as public broadcasters in many democracies operate under charters that insulate them from partisan interference, civic digital spaces would require independent oversight, clear ethical mandates, and democratically accountable governance boards, not centralized state control. The goal is not to build a digital ministry of truth, but to create pluralistic public utilities: platforms built for communities, governed by communities and held to standards of transparency, rights protection and civic purpose.</p><p>The technical architecture of the next social web is already emerging through federated and distributed protocols like ActivityPub (used by Mastodon and Threads) and Bluesky’s <a href="https://docs.bsky.app/docs/advanced-guides/atproto">Authenticated Transfer (AT) Protocol</a>, or atproto, (a decentralised framework that allows users to move between platforms while keeping their identity and social graph) as well as various blockchain-based experiments, <a href="https://lens.xyz/">like Lens</a> and <a href="https://docs.farcaster.xyz/">Farcaster</a>.</p><p>But protocols alone won’t save us. The email protocol is decentralized, yet most email flows through a handful of corporate providers. We need to “<a href="https://www.noemamag.com/we-need-to-rewild-the-internet/">rewild the internet</a>,” as Maria Farrell and Robin Berjon mentioned in a Noema essay. We need governance scaffolding, shared institutions that make decentralization viable at scale. Think credit unions for the social web that function as member-owned entities providing the infrastructure that individual users can’t maintain alone. These could offer shared moderation services that smaller instances can subscribe to, universally portable identity systems that let users move between platforms without losing their history, collective bargaining power for algorithm transparency and data rights, user data dividends for all, not just influencers (if platforms profit from our data, we should share in those profits), and algorithm choice interfaces that let users select from different recommender systems.&nbsp;</p><p>Bluesky’s AT Protocol explicitly allows users to port identity and social graphs, but it’s very early days and cross-protocol and platform portability remains extremely limited, if not effectively non-existent. Bluesky also allows users to choose among multiple content algorithms, an important step toward user control. But these models remain largely tied to individual platforms and developer communities. What’s still missing is a civic architecture that makes algorithmic choice universal, portable, auditable and grounded in public-interest governance rather than market dynamics alone.</p><p>Imagine being able to toggle between different ranking logics: a chronological feed, where posts appear in real time; a mutuals-first algorithm that privileges content from people who follow you back; a local context filter that surfaces posts from your geographic region or language group; a serendipity engine designed to introduce you to unfamiliar but diverse content; or even a human-curated layer, like playlists or editorials built by trusted institutions or communities. Many of these recommender models do exist, but they are rarely user-selectable, and almost never transparent or accountable. Algorithm choice shouldn’t require a hack or browser extension; it should be built into the architecture as a civic right, not a hidden setting.</p><!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “What if we treated these platforms as public utilities rather than private casinos?”    </p>

    
    
  </blockquote>
</figure><p>Algorithmic choice can also develop new hierarchies. If feeds can be curated like playlists, the next influencer may not be the one creating content, but editing it. Institutions, celebrities and brands will be best positioned to build and promote their own recommendation systems. For individuals, the incentive to do this curatorial work will likely depend on reputation, relational capital or ideological investment. Unless we design these systems with care, we risk reproducing old dynamics of platform power, just in a new form.</p><p>Federated platforms like Mastodon and Bluesky face <a href="https://www.noemamag.com/the-great-decentralization/">real tensions</a> between autonomy and safety: Without centralized moderation, harmful content can proliferate, while over-reliance on volunteer admins creates sustainability problems at scale. These networks also risk reinforcing ideological silos, as communities block or mute one another, fragmenting the very idea of a shared public square. Decentralization gives users more control, but it also raises difficult questions about governance, cohesion and collective responsibility — questions that any humane digital future will have to answer.</p><p>But there is a possible future where a user, upon opening an app, is asked how they would like to see the world on a given day. They might choose the serendipity engine for unexpected connections, the focus filter for deep reads or the local lens for community news. This is technically very achievable — the data would be the same; the algorithms would just need to be slightly tweaked — but it would require a design philosophy that treats users as citizens of a shared digital system rather than cattle. While this is possible, it can feel like a pipe dream.&nbsp;</p><p>To make algorithmic choice more than a thought experiment, we need to change the incentives that govern platform design. Regulation can help, but real change will come when platforms are rewarded for serving the public interest. This could mean tying tax breaks or public procurement eligibility to the implementation of transparent, user-controllable algorithms. It could mean funding research into alternative recommender systems and making those tools open-source and interoperable. Most radically, it could involve certifying platforms based on civic impact, rewarding those that prioritize user autonomy and trust over sheer engagement.</p><h2 id="h-digital-literacy-as-public-health"><strong>Digital Literacy As Public Health</strong></h2><p>Perhaps most crucially, we need to reframe digital literacy not as an individual responsibility but as a collective capacity. This means moving beyond spot-the-fake-news workshops to more fundamental efforts to understand how algorithms shape perception and how design patterns exploit our cognitive processes.&nbsp;</p><p>Some education systems are <a href="https://www.nytimes.com/2022/09/08/technology/misinformation-students-media-literacy.html">beginning to respond</a>, embedding digital and media literacy across curricula. Researchers and educators argue that this work needs to begin in early childhood and continue through secondary education as a core competency. The goal is to equip students to critically examine the digital environments they inhabit daily, to <a href="https://www.sciencedirect.com/science/article/pii/S2212868924000667">become active</a> participants in shaping the future of digital culture rather than passive consumers. This includes what some call <em>algorithmic literacy</em>, the ability to understand how recommender systems work, how content is ranked and surfaced, and how personal data is used to shape what you see — and what you don’t.</p><p>Teaching this at scale would mean treating digital literacy as public infrastructure, not just a skill set for individuals, but a form of shared civic defense. This would involve long-term investments in teacher training, curriculum design and support for public institutions, such as libraries and schools, to serve as digital literacy hubs. When we build collective capacity, we begin to lay the foundations for a digital culture grounded in understanding, context and care.</p><p>We also need behavioral safeguards like default privacy settings that protect rather than expose, mandatory cooling-off periods for viral content (deliberately slowing the spread of posts that suddenly attract high engagement), algorithmic impact assessments before major platform changes and public dashboards that show platform manipulation, that is, coordinated or deceptive behaviors that distort how content is amplified or suppressed, in real-time. If platforms are forced to disclose their engagement tactics, these tactics lose power. The ambition is to make visible hugely influential systems that currently operate in obscurity.</p><p>We need to build new digital spaces grounded in different principles, but this isn’t an either-or proposition. We also must reckon with the scale and entrenchment of existing platforms that still structure much of public life. Reforming them matters too. Systemic safeguards may not address the core incentives that inform platform design, but they can mitigate harm in the short term. The work, then, is to constrain the damage of the current system while constructing better ones in parallel, to contain what we have, even as we create what we need.&nbsp;</p><p>The choice isn’t between technological determinism and Luddite retreat; it’s about constructing alternatives that learn from what made major platforms usable and compelling while rejecting the extractive mechanics that turned those features into tools for exploitation. This won’t happen through individual choice, though choice helps; it also won’t happen through regulation, though regulation can really help. It will require our collective imagination to envision and build systems focused on serving human flourishing rather than harvesting human attention.</p><p>Social media as we know it is dying, but we’re not condemned to its ruins. We are capable of building better — smaller, slower, more intentional, more accountable — spaces for digital interaction, spaces where the metrics that matter aren’t engagement and growth but understanding and connection, where algorithms serve the community rather than strip-mining it.</p><p>The last days of social media might be the first days of something more human: a web that remembers why we came online in the first place — not to be harvested but to be heard, not to go viral but to find our people, not to scroll but to connect. We built these systems, and we can certainly build better ones. The question is whether we will do this or whether we will continue to drown.</p>
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SkiftOS: A hobby OS built from scratch using C/C++ for ARM, x86, and RISC-V (307 pts)]]></title>
            <link>https://skiftos.org</link>
            <guid>45229414</guid>
            <pubDate>Sat, 13 Sep 2025 04:55:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://skiftos.org">https://skiftos.org</a>, See on <a href="https://news.ycombinator.com/item?id=45229414">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Legal win (203 pts)]]></title>
            <link>https://ma.tt/2025/09/legal-win/</link>
            <guid>45228692</guid>
            <pubDate>Sat, 13 Sep 2025 01:55:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ma.tt/2025/09/legal-win/">https://ma.tt/2025/09/legal-win/</a>, See on <a href="https://news.ycombinator.com/item?id=45228692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">

			
				
<article id="post-149776">
	<div>
		
<p>Just got word that the<a href="https://www.courtlistener.com/docket/69221176/169/wpengine-inc-v-automattic-inc/"> court dismissed several of WP Engine and Silver Lake’s most serious claims</a> — antitrust, monopolization, and extortion have been knocked out! These were by far the most significant and far-reaching allegations in the case and with today’s decision the case is narrowed significantly. This is a win not just for us but for all open source maintainers and contributors.&nbsp;Huge thanks to the folks at <a href="https://www.gibsondunn.com/">Gibson</a> and <a href="https://automattic.com/">Automattic</a> who have been working on this.</p>



<p>With respect to any remaining claims, we’re confident the facts will demonstrate that our actions were lawful and in the best interests of the WordPress community.</p>



<p>This ruling is a significant milestone, but our focus remains the same: building a free, open, and thriving WordPress ecosystem and supporting the millions of people who rely on it every day. </p>

			</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post -->
						<nav>
		<h2>
			Post navigation		</h2>
		<!-- .nav-links -->
	</nav><!-- .navigation -->
						
<!-- #comments -->
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California lawmakers pass SB 79, housing bill that brings dense housing (202 pts)]]></title>
            <link>https://www.latimes.com/california/story/2025-09-12/california-lawmakers-pass-sb-79-housing-bill-that-brings-dense-housing-to-transit-hubs</link>
            <guid>45228552</guid>
            <pubDate>Sat, 13 Sep 2025 01:32:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/california/story/2025-09-12/california-lawmakers-pass-sb-79-housing-bill-that-brings-dense-housing-to-transit-hubs">https://www.latimes.com/california/story/2025-09-12/california-lawmakers-pass-sb-79-housing-bill-that-brings-dense-housing-to-transit-hubs</a>, See on <a href="https://news.ycombinator.com/item?id=45228552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>California lawmakers just paved the way for a whole lot more housing in the Golden State.</p><p>In the waning hours of the 2025 legislative session, the state Senate voted 21 to 8 to approve <a href="https://cayimby.org/wp-content/uploads/2025/07/SB-79-Wiener-7.25.25-Fact-Sheet.pdf" target="_blank"><u>Senate Bill 79</u></a>, a landmark housing bill that overrides local zoning laws to expand high-density housing near transit hubs. The controversial bill received a final concurrence vote from the Senate on Friday, a day after passing in the California Assembly with a vote of 41 to 17.</p><p>The bill had <a href="https://calmatters.org/housing/2025/04/committee-chairs-housing-policy/" target="_blank"><u>already squeaked through</u></a> the state Senate by a narrow margin earlier this year, but since it was amended in the following months, it required a second approval. It will head to Gov. Gavin Newsom’s desk in October.</p><p>One of the more ambitious state-imposed efforts to increase housing density in recent years, the bill was introduced in March by Sen. Scott Wiener (D-San Francisco), who stresses that the state needs to take immediate action to address California’s housing shortage. It opens the door for taller, denser housing near transit corridors such as bus stops and train stations: up to nine stories for buildings adjacent to certain transit stops, seven stories for buildings within a quarter-mile and six stories for buildings within a half-mile.</p><p>Single-family neighborhoods within a half-mile of transit stops would be subject to the new zoning rules.</p><p>Height limits are based on tiers. Tier 1 zoning, which includes heavy rail lines such as the L.A. Metro B and D lines, allows for six- to nine-story buildings, depending on proximity to the transit hub. Tier 2 zoning — which includes light rail lines such as the A, C, E and K lines, as well as bus routes with dedicated lanes — allows for five- to eight-story buildings.</p><p><a href="https://uscssi.maps.arcgis.com/apps/mapviewer/index.html?webmap=7689658f319b488ba03c40ccb903681e&amp;center=-118.284552%2C33.985519&amp;level=11" target="_blank"><u>An amateur map</u></a> released by <a href="https://www.reddit.com/r/yimby/comments/1ne2q87/sb_79_interactive_map/" target="_blank">a cartographer</a> and fact-checked by YIMBY Action, a housing nonprofit that helped push the bill through, gives an idea of the areas around L.A. that would be eligible for development under SB 79. Tier 1 zones include hubs along Wilshire Boulevard, Vermont Avenue and Hollywood Boulevard, as well as a handful of spots in downtown L.A. and the San Fernando Valley.</p><p>Tier 2 zones are more spread out, dotting Exposition Boulevard along the E line, stretching toward Inglewood along the K line, and running from Long Beach into the San Gabriel Valley along the A line.</p><p>Assembly members debated the bill for around 40 minutes on Thursday evening and cheered after it was passed.</p><p>“Over the last five years, housing affordability and homelessness have consistently been among the top priorities in California. The smartest place to build new housing is within existing communities, near the state’s major transit investments that connect people to jobs, schools and essential services,” said Assemblymember Sharon Quirk-Silva (D-Orange County) in support of the bill.</p><p>Other Assembly members, including Buffy Wicks (D-Oakland), Juan Carrillo (D-Palmdale) and Josh Hoover (R-Folsom) voiced their support.</p><p>Proponents say drastic measures are necessary given the state’s affordability crisis. </p><p>“SB 79 is what we’ve been working towards for a decade — new housing next to our most frequently used train stations. This bill has the potential to unlock hundreds of thousands of new multifamily homes,” said <a href="https://yimbyaction.org/" target="_blank"><u>YIMBY Action</u></a> California director Leora Tanjuatco Ross.</p><p>Critics claim the blanket mandate is an overreach, stripping local authorities of their ability to promote responsible growth.</p><p>Assemblymember Rick Zbur (D-West Hollywood) argued against the bill, claiming it will affect lower-priced neighborhoods more than wealthy ones since land prices are cheaper for housing developers.</p><p>The vote came a few weeks after the Los Angeles City Council <a href="https://www.latimes.com/california/story/2025-08-20/denser-housing-near-transit-stops-l-a-city-council-opposes-state-bill"><u>came out against the bill</u></a>, voting 8 to 5 on <a href="https://cityclerk.lacity.org/onlinedocs/2025/25-0002-S19_misc_03-28-25.pdf" target="_blank"><u>a resolution</u></a> opposing it.</p><p>Councilmember Traci Park, who co-authored the resolution with Councilmember John Lee, called SB 79 a “one-size-fits-all mandate from Sacramento.” Lee called it “chaos.”</p><p>The resolution called for L.A. to be exempt from the upzoning since it already has a state-approved housing plan.</p><p>The bill has spurred multiple protests in Southern California communities, including <a href="https://smdp.com/business/real-estate-housing/as-santa-monica-supports-housing-bill-protests-mount-in-neighborhing-communities/" target="_blank"><u>Pacific Palisades</u></a> and <a href="https://www.nbcsandiego.com/news/local/people-take-to-the-streets-of-south-park-to-protest-california-housing-bill/3897316/" target="_blank"><u>San Diego</u></a>. Residents fear the zoning changes would alter single-family communities and force residents into competition with developers, who would be incentivized under the new rules to purchase properties near transit corridors.</p><p>However, support for SB 79 surged in recent days after the State Building and Construction Trades Council, a powerful labor group that represents union construction workers, agreed to reverse its opposition in exchange for amendments that add union hiring to certain projects.</p><p>In a statement after <a href="https://calmatters.org/housing/2025/09/california-housing-near-transit/" target="_blank"><u>the deal was struck</u></a>, the trades council President Chris Hannan said the amendments would provide good jobs and training to California’s skilled construction workforce.</p><p>Wiener, who has unsuccessfully tried to pass similar legislation twice before, said the deal boosted the bill’s chances.</p><div data-list-id="00000192-be42-da32-a3db-ff76fc3b0000" data-module-id="00000192-be42-da32-a3db-ff76fc3b0000" data-click="enhancement" data-align-center="">  <p data-element="element-header" data-click="liZZListTitleCTA">  <h3 data-element="element-header-title" data-counter="3">More to Read </h3>  </p>      </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Life, work, death and the peasant: Rent and extraction (258 pts)]]></title>
            <link>https://acoup.blog/2025/09/12/collections-life-work-death-and-the-peasant-part-ivc-rent-and-extraction/</link>
            <guid>45228472</guid>
            <pubDate>Sat, 13 Sep 2025 01:15:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://acoup.blog/2025/09/12/collections-life-work-death-and-the-peasant-part-ivc-rent-and-extraction/">https://acoup.blog/2025/09/12/collections-life-work-death-and-the-peasant-part-ivc-rent-and-extraction/</a>, See on <a href="https://news.ycombinator.com/item?id=45228472">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>This is the third piece of the fourth part of our series (<a href="https://acoup.blog/2025/07/11/collections-life-work-death-and-the-peasant-part-i-households/">I</a>, <a href="https://acoup.blog/2025/07/18/collections-life-work-death-and-the-peasant-part-ii-starting-at-the-end/">II</a>, <a href="https://acoup.blog/2025/08/01/collections-life-work-death-and-the-peasant-part-iiia-family-formation/">IIIa</a>, <a href="https://acoup.blog/2025/08/08/collections-life-work-death-and-the-peasant-part-iiib-children-and-childrearing/">IIIb</a>, <a href="https://acoup.blog/2025/08/22/collections-life-work-death-and-the-peasant-part-iva-subsistence-and-a-little-more/" data-type="post" data-id="31013">IVa</a>, <a href="https://acoup.blog/2025/09/05/collections-life-work-death-and-the-peasant-part-ivb-working-days/" data-type="post" data-id="31214">IVb</a>) looking at the lives of pre-modern peasant farmers – a majority of all of the humans <em>who have ever lived</em>.  Last time, we started looking at the subsistence of peasant agriculture by considering the productivity of our model farming families under basically ideal conditions: relatively good yields and effectively infinite land.</p>



<p>This week we’re going to start peeling back those assumptions in light of the very small farm-sizes and capital availability our pre-modern peasants had.  Last week we found that, <em>assuming effectively infinite land</em> and reasonably high yields, our farmers produced enough to maintain their households fairly securely in relative comfort, with enough surplus over even their respectability needs to potentially support a small population of non-farmers.  But of course <strong>land isn’t infinite</strong> and <strong>also isn’t free</strong> and on top of that, the societies in which our peasant farmers live are often built to extract as much surplus from the peasantry as possible.</p>



<p>But first, if you like what you are reading, please share it and if you <em>really</em> like it, you can support this project on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>! While I do teach as the academic equivalent of a tenant farmer, tilling the Big Man’s classes, this project is my little plot of freeheld land which enables me to keep working as a writers and scholar. And if you want updates whenever a new post appears, you can click below for email updates or follow me on <a href="https://x.com/BretDevereaux">Twitter </a>and <a href="https://bsky.app/profile/bretdevereaux.bsky.social">Bluesky </a>and (less frequently) Mastodon (@bretdevereaux@historians.social) for updates when posts go live and my general musings; I have largely shifted over to Bluesky (I maintain some <em>de minimis</em> presence on Twitter), given that it has become a much better place for historical discussion than Twitter.</p>






<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="770" data-attachment-id="31420" data-permalink="https://acoup.blog/2025/09/12/collections-life-work-death-and-the-peasant-part-ivc-rent-and-extraction/attachment/1073020001/" data-orig-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?fit=2500%2C1879&amp;ssl=1" data-orig-size="2500,1879" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1073020001" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?fit=1024%2C770&amp;ssl=1" src="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=1024%2C770&amp;ssl=1" alt="" srcset="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=1024%2C770&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=768%2C577&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=1536%2C1154&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=2048%2C1539&amp;ssl=1 2048w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=1200%2C902&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?resize=1100%2C827&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1073020001.jpg?w=2200&amp;ssl=1 2200w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>From the British Museum (<a href="https://www.britishmuseum.org/collection/object/P_2010-7081-4256?selectedImageId=1073020001" data-type="link" data-id="https://www.britishmuseum.org/collection/object/P_2010-7081-4256?selectedImageId=1073020001">2010,7081.4256</a>), “The Rapacious Steward or Unfortunate Tenant,” a print by Haveill Gillbank (1803), showing a tenant farmer, with his family, being taken award by the estate’s steward (on horseback).  A little late for our chronology, but so on point for today’s topic it was hard to let it pass.<br>It is also a useful reminder that tenancy wasn’t just an economic system, but a social one: it gave the Big Man and his agents tremendous power over the lives and livelihoods of the people who lives near the Big Man’s estates.  For very Big Men, they might have several such estates and so be absentee landlords, in which case not only the Big Man, but his steward, might be figures of substantial power locally.</figcaption></figure>



<h2>Land Holdings</h2>



<p>Returning to where we left off last week, we found that our model families could comfortably exceed their subsistence and ‘respectability’ needs with the labor they had assuming they had enough land (and other capital) to employ all of their available farming labor.  <em><strong>However</strong></em>, attentive readers will have noticed that the labor of these families could work <em><strong>a lot of land</strong></em>: 30.5 acres for The Smalls, 33.6 acres for The Middles and 56 acres for The Biggs.  That may not seem large by the standards of modern commercial farms, but few peasants had anything like such large landholdings; even <em>rich</em> peasants rarely owned so much.</p>



<p>We might compare, for instance, the land allotments of Macedonian and Greek military settlers in the Hellenistic kingdoms (particularly Egypt, where our evidence is good). These settlers were remarkably well compensated, because part of what the Hellenistic kings are trying to do is create a new class of Greco-Macedonian rentier-elites<span id="easy-footnote-1-31305"></span><span><a href="#easy-footnote-bottom-1-31305" title="That is, landholders with enough land to subsist off of the rents without needing to do much or any actual agricultural labor themselves."><sup>1</sup></a></span> as a new ethnically defined military ruling-class which would support their new monarchies. In Egypt, where we can see most clearly, infantrymen generally received 25 or 30 <em>arourai</em> (17 or 20.4 acres), while cavalrymen, socially higher up still, generally received 100 <em>arourai</em> (68 acres).<span id="easy-footnote-2-31305"></span><span><a href="#easy-footnote-bottom-2-31305" title="For scale with the cavalrymen we are talking about just a few thousand households lording over a country of perhaps five <em>million</em>; these fellows are honestly closer to something like a medieval knightly elite than the peasantry."><sup>2</sup></a></span> That infantry allotment is still anywhere from two thirds to less than half of what our model families can farm and yet was still large enough, as far as we can tell, to enable Ptolemaic Greco-Macedonian soldiers to live as rentier-elites, subsisting primarily if not entirely off of rents and the labor of others.<span id="easy-footnote-3-31305"></span><span><a href="#easy-footnote-bottom-3-31305" title="On these allotments, see P. Johstono, <em>The Army of Ptolemaic Egypt, 323-204 BC</em> (2020), 158-160 and C. Fischer-Bovet, <em>Army and Society in Ptolemaic Egypt </em>(2014), 212-217. On the rentier-self-sufficiency of these parcels, at a 5:1 yield, 30 <em>aroura</em> should yield something like 3,500kg wheat equivalent (almost 12 million calories), more than enough to support the settler&amp;#8217;s household at a 50% rent (see below) using labor from the much smaller adjacent farms of indigenous Egyptians. Indeed, to me it seems very likely the land allotments were calculated precisely on this basis, with infantrymen receiving the smallest allotment that could reliably support a household in leisure."><sup>3</sup></a></span></p>



<p>Alternately, considering late medieval Europe through the study of Saint-Thibery,<span id="easy-footnote-4-31305"></span><span><a href="#easy-footnote-bottom-4-31305" title="Le Roy Ladurie, <em>Les Paysans de Languedoc</em> (1966)"><sup>4</sup></a></span> out of 189 households in 1460 in the village just fifteen households are in the same neighborhood of landholdings as the Smalls’ 33.6 acres above (so roughly 55 <em>setérée</em> and up)<span id="easy-footnote-5-31305"></span><span><a href="#easy-footnote-bottom-5-31305" title="A reminder that the <em>setérée</em> is an exact unit, about 1/5th to 1/4th of a hectare, so about 0.49-0.62 acres."><sup>5</sup></a></span> only six as much as The Biggs (about 90 <em>setérée</em> and up). In short <strong>our assessment so far has assumed our families are </strong><em><strong>extremely</strong></em><strong> rich peasants</strong>. But of course they almost certainly are not!</p>



<p>Instead, as we noted in our first part, the<a href="https://acoup.blog/2025/07/11/collections-life-work-death-and-the-peasant-part-i-households/" data-type="link" data-id="https://acoup.blog/2025/07/11/collections-life-work-death-and-the-peasant-part-i-households/"> average size of peasant landholdings was <em>extremely small</em></a>. Typical Roman landholdings were around 5-10 <em>iugera</em> (3.12-6.23 acres), in wheat-farming pre-Han northern China roughly 100 <em>mu</em> (4.764 acres), in Ptolemaic Egypt (for the indigenous, non-elite population) probably 5-10 <em>aroura</em> (3.4-6.8 acres) and so on.<span id="easy-footnote-6-31305"></span><span><a href="#easy-footnote-bottom-6-31305" title="Rosenstein (2004), 75, n.68; Erdkamp, (2005), 47-8; Cho-yun Hsu, <em>Han Agriculture: The Formation of Early Chinese Agrarian Economy</em> (1980); Johstono, <em>The Army of Ptolemaic Egypt</em> (2020), 101; Fischer-Bovet, <em>Army and Society in Ptolemaic Egypt </em>(2014), 121"><sup>6</sup></a></span> In Saint-Thibery in Languedoc, the average (mean) farm size was about 24 <em>setérée</em> (~14.5 acres) but the more useful <strong>median farm size</strong> was just <em><strong>five</strong></em> <em>setérée</em> (~3 acres); the average is obviously quite distorted by the handful of households with <em>hundreds</em> of <em>setérée</em> of land.</p>



<p>So we might test three different farm sizes; once again, I am going to use Roman units because that’s how I am doing my background math.  We might posit a relatively a<strong> poor household farm of roughly three <em>iugera</em> </strong>(1.85 acres).  In Saint-Thibery, 68 of the 189 households (36%) had land holdings this small or smaller, so this is not an unreasonable ‘poor household’ – indeed, we could posit much poorer, but then we’re really just talking about tenant farmers, rather than freeholding peasants.  Next, we can posit a <strong>moderate household farm of roughly six <em>iugera</em> </strong>(3.8 acres); reasonably close to the median holding in Saint-Thibery and roughly what we think of as the lower-bound for ancient citizen-soldier-peasants.  Finally, we can posit a <strong>large household farm</strong> <strong>of nine <em>iugera</em></strong> (5.6 acres), reflective of what seems to be the upper-end of typical for those same citizen-soldier-peasants; at Saint-Thibery in 1460 there were a couple dozen families seemingly in this range.<span id="easy-footnote-7-31305"></span><span><a href="#easy-footnote-bottom-7-31305" title="It&amp;#8217;s hard to tell precisely from what I have because Le Roy Ladurie groups households in brackets."><sup>7</sup></a></span></p>



<p>For the sake of a relatively easier calculation, we can assume the same balance of wheat, barley and beans as last time, which lets us just specify an average yield after seed <em>per iugerum</em> of 81.2-189.5 kg of wheat equivalent (achieved by averaging the per-acre wheat equivalent production across all three crops, with seed removed),<span id="easy-footnote-8-31305"></span><span><a href="#easy-footnote-bottom-8-31305" title="The average yield-per-<em>iugerum</em> at each fertility level in wheat equivalent are: 4:1, 81.2kg; 5:1, 108.2kg; 6:1, 135.3kg; 7:1, 162.4kg; 8:1, 189.5kg."><sup>8</sup></a></span> with each <em>iugerum</em> demanding between 11 and 15 working days (averaging the labor requirements across all three crops). Finally, <strong>we need to remember the fallow</strong>: in this case we’re assuming about <strong>a third of each farm is not in production in any given year</strong>, meaning it is both not consuming any labor nor producing any crops. That lets us then quickly chart out our peasant families based on the land they might actually have (keeping in mind the household size and household land holdings aren’t going to match; the larger household <em>in people</em> won’t always be the one with more land). First, a reminder of the basic labor availability and grain requirements of our households.</p>



<figure><table><tbody><tr><td></td><td>The Smalls</td><td>The Middles</td><td>The Biggs</td></tr><tr><td>Labor Available</td><td>435 work-days</td><td>507.5 work-days</td><td>797.5 work-days</td></tr><tr><td>Bare Subsistence Requirement</td><td>~1,189.5kg wheat-equivalent</td><td>~1,569kg wheat-equivalent</td><td>~2,686kg wheat-equivalent</td></tr><tr><td>Respectability Requirement</td><td>~2,379kg wheat-equivalent</td><td>~3,138kg wheat-equivalent</td><td>~5,376kg wheat-equivalent</td></tr></tbody></table></figure>



<p>Then for the smallest, 3<em> iugera</em> farm, the numbers work like this:</p>



<figure><table><tbody><tr><td><strong>Small Farm</strong> (3 <em>iugera</em>)<br>2 <em>iugera</em> cropped<br>1 fallow</td><td>The Smalls</td><td>The Middles</td><td>The Biggs</td></tr><tr><td>Labor requirement</td><td>22-30 work days</td><td>22-30 work days</td><td>22-30 work days</td></tr><tr><td>Labor surplus</td><td>405-413 work days</td><td>477.5-485.5 work days</td><td>767.5-775.5 work days</td></tr><tr><td>Production after Seed</td><td>162.4-378.8kg wheat equivalent</td><td>162.4-378.8kg wheat equivalent</td><td>162.4-378.8kg wheat equivalent</td></tr><tr><td>Percentage of <strong><em>Subsistence</em></strong>:</td><td>14-32%</td><td>10-24%</td><td>6-14%</td></tr></tbody></table></figure>



<p>And then for the medium-sized farm:</p>



<figure><table><tbody><tr><td><strong>Medium Farm</strong> (6 <em>iugera</em>)<br>4 <em>iugera</em> cropped<br>2 fallow</td><td>The Smalls</td><td>The Middles</td><td>The Biggs</td></tr><tr><td>Labor requirement</td><td>44-60 work days</td><td>44-60 work days</td><td>44-60 work days</td></tr><tr><td>Labor surplus</td><td>375-391 work days</td><td>447.5-463.5 work days</td><td>737.5-753.5 work days</td></tr><tr><td>Production after Seed</td><td>324.8-757.6kg wheat equivalent</td><td><br>324.8-757.6kg wheat equivalent</td><td><br>324.8-757.6kg wheat equivalent</td></tr><tr><td>Percentage of <strong><em>Subsistence</em></strong>:</td><td>27-64%</td><td>21-48%</td><td>12-28%</td></tr></tbody></table></figure>



<p>And the larger (but not <em>rich peasant</em>) farm:</p>



<figure><table><tbody><tr><td><strong>Large Farm</strong> (9 <em>iugera</em>)<br>6 <em>iugera</em> cropped<br>3 fallow</td><td>The Smalls</td><td>The Middles</td><td>The Biggs</td></tr><tr><td>Labor requirement</td><td>66-90 work days</td><td>66-90 work days</td><td>66-90 work days</td></tr><tr><td>Labor surplus</td><td>345-369 work days</td><td>417.5-441.5 work days</td><td>707.5-731.5 work days</td></tr><tr><td>Production after Seed</td><td>487.6-1,136.5kg wheat equivalent</td><td>487.6-1,136.5k wheat equivalent</td><td>487.6-1,136.5k wheat equivalent</td></tr><tr><td>Percentage of <strong><em>Subsistence</em></strong>:</td><td>41-96%</td><td>31-72%</td><td>18-42%</td></tr></tbody></table></figure>



<p>And we immediately see the problem: <em>only</em> the Smalls manage to get close to subsistence on very favorable (8:1) fertility assumptions on the small farm they own. Now it <em>is </em>possible for the peasants to push a little bit on these numbers. The most obvious way would be focusing as much as possible on wheat cultivation, which has higher labor demands but also the highest yield-per-acre (or <em>iugerum</em>), producing around 50% more calories than beans and 35% more calories than barley per-acre (see <a href="https://acoup.blog/2025/09/05/collections-life-work-death-and-the-peasant-part-ivb-working-days/" data-type="link" data-id="https://acoup.blog/2025/09/05/collections-life-work-death-and-the-peasant-part-ivb-working-days/">last week’s post for specifics</a>). <strong>But there’s a limit to going ‘all in’ on wheat to meet food shortfalls</strong>: the land might not be suitable for it and wheat exhausts the soil, so our farmers would need <em>some</em> sort of rotation.  That said, peasant diets were <em>overwhelmingly</em> grains (wheat and barley) for this reason: <strong>they provide the most calories for a favorable balance of land and labor</strong>. <strong>Our farmers might also try to supplement production with high-labor, high-density horticulture</strong>; a kitchen garden can take a lot of work but produce a lot of nutrition in a small space. But hitting household nutrition demands <em>entirely</em> with a kitchen garden isn’t going to work both because of the labor demands but also because the products of a kitchen garden tend not to keep well.</p>



<p>Instead the core problem <strong>is that our peasant households are <em>much too large</em> as units of labor for the farmland they own</strong>.  When we say that, what we mean is that given these households are both units of consumption (they have to provide for their members) and units of production (they are essentially agricultural small businesses), an <em>efficient</em> allocation of them would basically have each household on something like 30 acres of farmland, farming all of it (and thus using most of their labor) and selling the excess.  <strong>But the lack of economically sustainable social niches</strong> – that is, jobs that provide a reliable steady income to enable someone to obtain subsistence – <strong>means that these families are <em>very reluctant</em> to leave members without any land at all</strong>, so the holdings ‘fractionalize’ down to these tiny units, essentially the smallest units that <em>could</em> conceivably support one family (and sometimes not even that).</p>



<p>I’ve already seen folks in the comments realizing almost immediately why these conditions might make conquest or resettlement into areas of land easily brought under cultivation so attraction: if you <em>could </em>give each household 30-40 acres instead of 3-6, you could realize <em>substantial</em> improvements in quality of life (and the social standing of the farmers in question). And of course that kind of ‘land scarcity’ problem seems to have motivated both <a href="https://acoup.blog/2023/10/13/collections-ancient-greek-and-phoenician-colonization/" data-type="post" data-id="21229">ancient </a>and<a href="https://acoup.blog/2021/05/14/collections-teaching-paradox-europa-universalis-iv-part-iii-europa-provincalis/" data-type="link" data-id="https://acoup.blog/2021/05/14/collections-teaching-paradox-europa-universalis-iv-part-iii-europa-provincalis/"> early modern</a> settler-colonialism: if you put farmers next to flat, open ground owned by another community, it won’t be too long before they try to make it farmland (violently expelling the previous owners in the process). This is also, I might add, part of the continual friction in areas where nomads and farmers meet: to a farmer, those grazing fields look like <em>more land</em> and <em>more land</em> is really valuable (though the response to <em>getting new land</em> is often not to create a bunch of freeholding large-farm homesteaders, but rather to replicate the patterns of tenancy and non-free agricultural labor these societies already have to the point of – as in the Americas – forcibly trafficking <em>enormous</em> numbers of enslaved laborers at great cost, suffering and horror, to create a non-free dependent class whose exploitation can enable those patterns.  Most conquering armies dream of becoming landlords, not peasants).<span id="easy-footnote-9-31305"></span><span><a href="#easy-footnote-bottom-9-31305" title="I would argue that the Roman approach to Italy from 509 to 218 BC appears to be an exception to this rule: the Romans do tend to use conquered land to set up large numbers of small landholding farms.  Not rich peasants, but the Roman military class &amp;#8211; the <em>assidui</em> farmer-citizen-soldiers &amp;#8211; were also clearly not utterly impoverished either.  It&amp;#8217;s striking that the Romans <em>could</em> have set up a system of rents and tribute extraction in Italy but didn&amp;#8217;t, instead effectively terraforming the Italian countryside into a machine for the production of heavy infantry.  That heavy infantry in turn bought the Romans stunning military superiority, which they then used in the second and first centuries BC to create an <em>enormous</em> system of tribute and extraction (rather than extending the approach they had used in Italy)."><sup>9</sup></a></span></p>



<p>Alternately <strong>as <em>farms</em> these holdings could be a lot more efficient if they had <em>fewer people</em> on them</strong> and indeed when we read, for instance, ancient agricultural writers, they recommend estates with significantly fewer laborers per-unit-land-area than what we’d see in the peasant countryside. But that’s because the <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/" data-type="post" data-id="3935">Big Man is farming for profit</a> with a large estate that lets him tailor his labor force fairly precisely to his labor needs; the peasants are farming <em>to survive</em> and few people are going to let their brother, mother, or children starve and die in a ditch because it makes their farm modestly more productive per unit labor. Instead, they’re going try to do anything in their power to get enough income to have enough food for their <em>entire family</em> to survive.</p>



<p>There is no real way around it: <strong>our peasants need access to more land</strong>.  And that land is going to come with <em>conditions</em>.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="755" data-attachment-id="31425" data-permalink="https://acoup.blog/2025/09/12/collections-life-work-death-and-the-peasant-part-ivc-rent-and-extraction/attachment/1613242415/" data-orig-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?fit=2500%2C1843&amp;ssl=1" data-orig-size="2500,1843" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1613242415" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?fit=300%2C221&amp;ssl=1" data-large-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?fit=1024%2C755&amp;ssl=1" src="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=1024%2C755&amp;ssl=1" alt="" srcset="https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=1024%2C755&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=768%2C566&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=1536%2C1132&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=2048%2C1510&amp;ssl=1 2048w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=1200%2C885&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?resize=1100%2C811&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2025/09/1613242415.jpg?w=2200&amp;ssl=1 2200w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>From the British Museum (<a href="https://www.britishmuseum.org/collection/object/P_1850-0713-91?selectedImageId=1613242415" data-type="link" data-id="https://www.britishmuseum.org/collection/object/P_1850-0713-91?selectedImageId=1613242415">1850,0713.91</a>), “La Conversation,” an etching by David Teniers and Andrew Lawrence (1742) showing three peasants having a conversation outside of a farmhouse, with a peasant woman in the doorway.</figcaption></figure>



<h2>The Big Man’s Land</h2>



<p>Now before we march into talking about farming <em>someone else’s land</em>, it is worth exploring why our farmers don’t get more land by just <em>bringing more land under cultivation</em>.  And the answer here is pretty simple: <strong>in most of the world, preparing truly ‘wild’ land for cultivation takes a <em>lot</em> of labor</strong>.  In dry areas, that labor often comes in the form of irrigation demands: canals have to be dug out from water sources (mainly rivers) to provide enough moisture for the fields as the most productive crops (like wheat) demand a lot of moisture to grow well.  In climates suitable for rainfall agriculture, the problem is instead generally forests: if there’s enough rain to grow grain, there’s enough rain to grow <em>trees</em> and those trees have had quite the head start on you.  Clearing large sections of forest <em>by land</em> is a slow, labor-intensive thing and remember, you don’t just need the trees cut down, <em>you need the stumps pulled or burned</em>.  Fields also need to be relatively <em>flat</em> – which might demand terracing on hilly terrain – and for the sake of the plow they need to be free of large stones to the depth of the plow (at least a foot or so).</p>



<p>In short, clearing farmland was both <em>slow</em> and <em>expensive</em> and all of this assumes the land <em>can</em> be made suitable and that no one has title to it.  Of course if the forest is the hunting preserve of the local elite, they’re going to object quite loudly to your efforts to cut it down.  And a lot of land is simply going to be too dry or too hilly or too marshy to be made usable for farming ona practical time-scale for our peasants.  Such land simply cannot be brought usefully into cultivation; you can’t farm wheat in a swamp.<span id="easy-footnote-10-31305"></span><span><a href="#easy-footnote-bottom-10-31305" title="Of course you can drain a swamp, but such drainage efforts are the kinds of things large, well-administered <em>states</em> do, not the sort of thing your local peasants can summon the labor for."><sup>10</sup></a></span>  <strong>So it is quite hard and often impractical to bring new land into cultivation</strong>.</p>



<p>That doesn’t mean new land <em>wasn’t</em> brought into cultivation, it absolutely was.  We can sometimes track population pressures archaeologically by watching this process: forests retreat, new villages pop up, swamps are drained and so on as previously marginal or unfarmable land is brought into cultivation.  Note, of course, if you bring a bunch of marginal fields into cultivation – say, a drier hillside not worth farming before – your average yield is going to go down because that land simply isn’t as productive (but demands the same amount of labor!).  But that process is generally slow, taking place over generations in response to population pressures.  It isn’t a solution available on the time-scale that most of our households are operating.  <em><strong>In the moment</strong></em>, <strong>the supply of land is mostly fixed for our peasants</strong>.</p>



<p>Which means our peasants need access to <em>more land</em> (or another way of generating income).  There are a range of places that land could come from:</p>



<ul>
<li><strong>Peasant Households without enough labor to farm their own land</strong>.  In order to make our households relevant at every part of the process, I haven’t modeled the substantial number of very small households we talked about in the first section, households with just 1 or 2 members.  If none of those householders were working-age males (e.g. a household with an elderly widow, or a young widow and minor children, etc.) they might seek to have other villagers help farm their land and split the production.  For very small households, that might be enough to provide them subsistence (or at least help).  Consequently <strong>those small, often ‘dying’ households provide a (fairly small) source of land for other households</strong>.</li>



<li><strong>Rich peasants likewise might have more land than their household could farm or cared to farm</strong>.  Consider the position The Smalls would be if they were a rich peasant household with, say, 25 acres of land (in Saint-Thibery, 26 households (of 189) had this much or more land).  That’s enough land that, under good harvest conditions it would be easy enough to shoot past the household’s respectability requirements.  At which point <em>why work so hard</em>?  Why not sharecrop out a large chunk of your land to small farmers and split the production, so you still make your respectability basket in decent years, but don’t have to work so darn hard?</li>



<li><strong>The Big Man</strong>.  Another part of this ecosystem is invariably <em>large</em> landowners, who might have estates of hundreds of acres.  Columella , for instance, thinks of farm planning (he is thinking about large estates) in units of 100 <em>iugera</em> (62.3 acres) and 200 <em>iugera</em> (124.6 acres; Col. <em>Rust</em>. 12.7-9).  An estate of several hundred acres would hardly be unusual.  Likewise in the Middle Ages, the Big Man might be a local noble whose manor estate might likewise control a lot of land.  The Big Man might also be a religious establishment: temples (in antiquity) and monasteries and churches (in the Middle Ages) often controlled large amounts of productive farmland worked by serfs or tenants to provide their income.  <strong>Naturally, the Big Man isn’t doing his own farming</strong>; he may have some ‘built in’ labor force (workers in his household, enslaved workers, permanent wage laborers, etc.) but <strong>often the Big Man is going to rely substantially on the local peasantry for tenant labor</strong>.</li>
</ul>



<p>In practice, the Big Man is likely to represent the bulk of opportunities here, but by no means all of them.  As I noted before, while local conditions vary <em>a lot</em>, you won’t be too far wrong in thinking about landholdings as a basic ‘rule of thirds’ with one third of the land controlled by small peasants, one third by rich peasants and one third by the Big Man (who, again, might be a lord or a big landowner or a church, monastery or temple (in the latter case, the land is owned <em>by the god</em> in most polytheistic faiths) or even the king).  But of course only a little bit of the small peasant land is going to be in search of workers, since most peasant households have too many hands for too little land; <em>some</em> of the rich peasant land will be looking for workers (either tenants or hired hands), but rich peasants are still <em>peasants</em> – they do some of their farming on their own.  By contrast, the Big Man is marked out by the fact that he doesn’t do his own farming: he needs <em>some</em> kind of labor supply – wage laborers, enslaved/non-free laborers or tenants – for all of it.</p>



<p>But that also means that something like <em>half</em> (or more!) of the land around our peasant village might be owned by a household that needs outside labor to farm it.  <strong>So we have peasant households with surplus labor that need more land to farm and richer households with surplus land that needs labor</strong>.  The solution here <em>generally</em> was some form of tenancy which in the pre-modern world generally came in the form, effectively of sharecropping: the landowner agreed to let the poorer household farm some of his land in exchange for a percentage of the crop that resulted.  That ‘rent-in-kind’ structure is useful for the peasants who after all are not generally keeping <em>money</em> with which to pay rent.  At the same time, it limits their liability: if the harvest on tenant land fails, they may suffer a shortfall, but they aren’t <em>in debt</em> some monetary quantity of rent (though they may end up in debt in some other way).</p>



<p>Now the question is: <em>on what terms</em>?</p>



<h2>Tenancy</h2>



<p>And the answer here won’t surprise: bad terms.  The terms are bad.</p>



<p>There’s a useful discussion of this in L. Foxhall, “The Dependent Tenant” <em>JRS</em> 980 (1990), which in turn leans on K. Finkler, “Agrarian Reform and Economic Development” in <em>Agricultural Decision Making</em>, ed. P.F. Barlett (1980) to get a sense of what the terms for tenant farmers might normally look like.  Foxhall notes in this and a few other studies of modern but largely non-industrial farming arrangements that almost no households in these studies were entirely uninvolved in sharecropping or tenancy arrangements, but that the terms of tenancy arrangements varied a lot based on the inputs supplied.</p>



<p>The key inputs were labor, traction (for our pre-industrial peasants, this is “who supplies the plow-team animals”), water and seed.  The most common arrangement, representing almost a third of all arrangements, was where the tenant supplied labor only, while traction, water and seed were supplied by the landlord; the tenants share in these arrangements was a measly 18.75%.  A number of arrangements had the tenant supplying not only labor but also some mix of traction, water or seed (but not all) and often the tenant’s share of the production hovered between 40 and 60%, with exact 50/50 splits occurring in about a quarter of the sample.  In just one case did the tenant supply <em>everything</em> but the land itself; in that case the tenant’s share was 81.25%.</p>



<p>One thing that is obvious from just this example is that arrangements varied <em>a lot</em> and are going to depend on need and bargaining power. A ‘landlord’ who has land they want under cultivation but can supply basically nothing else may be relatively easy to negotiate into a fairly generous deal; a peasant who is absolutely destitute save for the labor of their hands is easy to exploit. An even 50/50 landholder, tenant split seems to have been the norm in much of Europe though, reflected in terms for sharecropper (<em>métayer</em> in French, <em>mezzadro</em> in Italian, <em>mitateri</em> in Sicilian, <em>mediero&nbsp;</em>in Spanish) which all mean ‘halver,’ though again the terms (and the share split) varied, typically based on demand but also on what exactly the landlord was providing (seed, plow teams, tools, physical infrastructure (like a farmhouse), etc).</p>



<p>For the sake of simplicity in our model, we can assume something like a 50/50 split, with our tenants supplying half of the seed, so that our net yield is exactly half of what it would have been.  We can then take those assumptions back to our model.  To establish a baseline, let’s run the numbers assuming first a ‘medium’ sized (6 <em>iugera</em>, 3.8 acres, with 4 <em>iugera </em>cropped and 2 fallowed) farm, with our fertility estimate set modestly to 6:1, a ‘good but not great’ yield.  We’re going to ’round up’ to the nearest even <em>iugerum</em> and assume an average of 13 days per <em>iugerum</em> of labor, just to make our calculations a bit simpler.  <strong>How hard is it for our peasants to meet their needs if they have to sharecrop the added land they need</strong>?</p>



<figure><table><tbody><tr><td><strong>Tenancy</strong><br>with a medium farm</td><td>The Smalls</td><td>The Middles</td><td>The Biggs</td></tr><tr><td>Total Labor</td><td>435 work-days</td><td>507.5 work-days</td><td>797.5 work-days</td></tr><tr><td>Freehold Labor Demand</td><td>52 work-days</td><td>52 work-days</td><td>52 work-days</td></tr><tr><td>Freehold Production</td><td>541kg wheat equivalent</td><td>541kg wheat equivalent</td><td>541kg wheat equivalent</td></tr><tr><td>Shortfall to Subsistence</td><td>648.5kg wheat equivalent</td><td>1,028kg wheat equivalent</td><td>2,145kg wheat equivalent</td></tr><tr><td>Net Production Per <em>iugera</em> farmed as tenant</td><td>67.65kg wheat equivalent</td><td>67.65kg wheat equivalent</td><td>67.65kg wheat equivalent</td></tr><tr><td>Tenant Land Required for Subsistence</td><td>10 <em>iugera</em> (6.23 acres)<br>(plus another ~5 <em>iugera </em>fallowed)</td><td>16 <em>iugera</em> (9.97 acres)<br>(plus another ~8 <em>iugera </em>fallowed)</td><td>32 <em>iugera</em> (19.94 acres)<br>(plus another ~16 <em>iugera</em> fallowed)<br></td></tr><tr><td>Labor Demand for Subsistence</td><td>130(+52) work days<br>Total: 182</td><td>208(+52) work days<br>Total: 260</td><td>416(+52) work days<br>Total: 468</td></tr><tr><td><strong>Subsequent </strong>Shortfall to Respectability (over subsistence)</td><td>1,189.5kg wheat equivalent</td><td>1,569kg wheat equivalent</td><td>2,686kg wheat equivalent</td></tr><tr><td>Tenant Land Required for Respectability</td><td>18 <em>iugera</em> (11.2 acres)<br>(plus another ~9 <em>iugera</em> fallowed)</td><td>24 <em>iugera</em> (14.95 acres)<br>(plus another ~12 <em>iugera</em> fallowed)</td><td>40 <em>iugera</em> (24.9 acres)<br>(plus another ~20 <em>iugera</em> fallowed)</td></tr><tr><td>Labor Demand for Respectability</td><td>234(+130+52) work-days (Total: 416)</td><td>312(+208+52) work-days (Total: 572)<br><strong>Shortage</strong>: 64.5</td><td>520(+416+52) work-days (Total: 988)<br><strong>Shortage</strong>: 190.5</td></tr></tbody></table></figure>



<p><strong>As we can see, tenancy <em>dramatically</em> changes the picture for our peasants</strong>. Under these relatively typical assumptions, of our three families all can make subsistence in a normal year but <em>only</em> the Smalls have the right combination of a lot of labor and a relatively small family to have a shot at getting all of their respectability needs (in practice, they’d probably fall short once you consider necessary farm labor not in the fields – fence repair, tool maintenance, home repair and the like). It also isn’t hard to see how we might alter this picture to change our assumptions. Changing the size of the owned farmland has a significant impact (even though it is already so small) because our peasants realize <em>twice</em> the production per unit-land-area for land they own over land they rent (again, terms might vary). Put another way, under these assumptions, somewhat marginal owned farmland that gives an OK-but-not-great yield of 4:1 is of the same use to our peasants as <em>really good</em> tenant-farmed farmland giving a 7:1 yield (both offer 81.2kg of wheat equivalent per <em>iugerum</em> after rent is paid).</p>



<p>That said, <strong>the fact that our peasants end up with enough labor to comfortable exceed their subsistence requirements, but not their comfort requirements is favorable <em>for extraction</em></strong>, which we’ll discuss below.  These are households with spare labor who can’t fulfill all of their wants entirely on their own, giving the state or local Big Men both a lot of levers to squeeze more labor out of them and <em>also</em> giving the households the available above-subsistence labor to squeeze.  By contrast if these peasants had enough land to meet all of their needs themselves, there would be fewer opportunities to compel them to do additional labor <em>beyond that</em>.</p>



<p>But even before we get to extraction, tenancy is also <strong>changing our peasants’ incentives</strong>. Economics has the concept of <em>diminishing marginal returns</em>, the frequent phenomenon where adding one more unit of a given input produces less and less output per additional input-unit. You will find more errors in the first hour of proofreading than the fiftieth hour, for instance. There’s also the concept of <em>diminishing marginal utility</em>: beyond a certain point, getting more of something is less valuable per unit added. Getting one bar of chocolate when you have none? Fantastic. Getting one bar of chocolate when you have ten thousand? Solidly meh.</p>



<p>Both are working on our farmers to press their natural production inclination not to <strong>maximum labor</strong> or even <strong>hitting that respectability basket</strong> but just <strong>subsistence and a little bit more</strong>.  On the diminishing marginal returns front, naturally when it comes to both owned land and rented land, our peasants are going to farm the most productive land <em>first</em>.  This is why when we talk about expanding population and expanding agriculture, we often talk about <em>marginal</em> land (less productive land) coming under cultivation; because all of the really great land was <em>already being farmed</em>.  But poor farmland doesn’t demand less labor time (indeed, it may demand more), it just produces less.  So while we’ve been working here with averages, you should imagine that the first few acres of farmland will be <em>more</em> productive and the latter few <em>less</em> productive.</p>



<p>Tenancy puts this into even more sharp contrast because it creates a really significant discontinuity in the value of farming additional land: the rents are <em>so high</em> that sharecropped or tenant land is <em>much less useful</em> (per unit labor) to the peasant than their own land.  So you have a slow downward slope of ‘land quality’ and somewhere in that slope there is the point at which the peasants have farmed all of their own land and so suddenly the effective yield-per-labor-after-rent drops <em>by half</em> (or more!).  So the first few hundred kilograms of wheat equivalent are probably fairly easy to get: you have a few good fields you own and your net out of them might be 130-190kg of wheat equivalent per <em>iugerum</em>.  Put in a couple dozen days on those two good <em>iugera</em> and The Smalls have just over a quarter of their subsistence needs.  But then they have their more marginal fields, which might only yield 80-100kg.  Still not terrible but the next couple of dozen days of labor don’t get them as far: not to half but just 44% or so.  But now you are out of your own land, so you go to your rich neighbor or the Big Man to get access to some more and suddenly even on their best fields your yield-per-<em>iugerum</em> is 80-95kg so another couple of dozen working days gets you just from 44% to just 57% of what you need.  So you need to line up a lot more land, but <em>now</em> you might be starting to look at the worse fields the Big Man has.  He still wants them farmed, after all, his choice is between doing nothing and earning money or doing nothing and not earning money; he’d rather earn money.  But suddenly you’re looking at maybe as little as 50-60kg of wheat equivalent per <em>iugerum</em> and the labor demands have not gone down.</p>



<p>Meanwhile, the comfort you get from each kilogram of wheat equivalent is <strong>also going down</strong>.  The first 80% or so of your subsistence needs is necessary simply to not starve to death; a bit more makes the household sustainable in the long term.  But then – and remember, these choices are coming as you are facing <em>diminishing marginal returns</em> on each day of labor you put in – is it <em>really</em> worth your time to cultivate a couple more fields in order to just get a bit more meat in your diet and have slightly nicer household goods?  Wouldn’t you rather rest?</p>



<p>And so what you see is most peasant households aiming not for the full respectability basket, but that “subsistence – and a little bit more” because as each day of labor produces less product and each product produces less joy, at some point you’d rather not work.</p>



<p>And as we’ve seen <em>in theory</em>, our households might hit that crossover point – subsistence and a little bit more – fairly quickly in their labor supply. We haven’t yet, but should now, account for labor spent on things like maintaining tools, fixing fences and other capital investments. If we allocate, say, 45 days, for that and assume that our farmers also want to have <em>some</em> cushion on subsistence (say, another 10%), we might expect The Smalls to be more or less satisfied (on that medium landholding, average 6:1 yields) with something like 245 working days (56% of total), the Middles with 331 working days (65%) and the Biggs with 560 (70%). Working like that, they won’t be rich and won’t ever become rich (but they were never going to become rich regardless), but they’ll mostly survive – some years will be hard – and they’ll have a little bit more time to rest.  <strong>Some families, a bit more industrious, might push towards achieving most or all of the respectability basket, at least in good years; others might be willing to stick closer to subsistence </strong>(or unable to do otherwise).</p>



<p>Of course in areas where the farmland is meaningfully more marginal – average yields around 4:1 rather than 6:1 – our peasants are going to need to work quite a lot more, about 60% more.  That pushes the Smalls to about 84% of their available labor, the Middles to <em>99%</em> and the Biggs actually slightly into deficit, demanding roughly 110% of their available labor.  <strong>We should keep in mind that each peasant household is going to exist somewhere along the spectrum</strong>: some with larger amounts of property or access to better land, some with less.  We’ll come back to this in a moment, but this is part of why the poorest of the peasantry were often exempt from things like military service: positioned on marginal land in poor communities, they had little excess labor available.  Most peasant households would have been somewhere in between these two, so a labor utilization rate ranging from 50 to 100%, with a lot of households in that 60-80% labor utilization range.</p>



<p>And now you might think, “doesn’t this take us back to peasants actually not working all that much compared to modern workers?” and first I would want to point out that these peasants are also experiencing a quality of living <em>way</em> below workers in modern industrial countries but also <strong>no because we haven’t talked about <em>extraction</em></strong>.</p>







<p>Because of course the problem here, from the perspective of everyone who <em>isn’t</em> our peasants is that if the peasantry only does the amount of agricultural labor necessary to subsist themselves and just a little more, the society doesn’t have economic room for much else in the way of productive (or unproductive) economic activity.  <strong>Remember: our peasants are the only significant population actually <em>doing farming</em></strong>.  Sure the Big Men and the gentry and temples and monasteries may <em>own land</em>, but they are mostly renting that land out <em>to peasants</em> (or hiring peasants to work it, or enslaving peasants and forcing them to work it).</p>



<p>And those landholding elites, in turn, <em>want to do things</em>.  They want to build temples, wage wars, throw fancy parties, employ literate scribes to write works of literature and of course they also want to <em>live in leisure</em> (not farming) while doing this.  And the activities they want to do – the temples, wars, fancy parties, scribes and so on – that requires a lot of food and other agricultural goods to sustain the people doing those things.  It also requires a bunch of surplus labor – some of that surplus labor are specialists, but a lot of it is effectively ‘unspecialized’ labor.</p>



<p>To do those things, those elites need to draw both agricultural surplus and surplus labor out of the countryside.  And we should that of course, obviously, this is an exploitative relationship, but it is also worth noting that for pre-modern agrarian economies, the societies where elites can centralize and control the largest pile of labor and surplus tend to use it to <em>conquer the societies that don’t</em> so ‘demilitarized peasant utopia’ is not a society that is going to last very long (but ‘highly militarized landowner republic’ might).</p>



<p>It is thus necessary to note that when we see the emergence of complex agrarian societies – cities, writing, architectural wonders, artistic achievements and so on – <strong>these achievements are mostly elite projects, ‘funded’ </strong>(in food and labor, if not in money) <strong>out of extraction from the peasantry</strong>.</p>



<p>Exactly <em>how</em> this extraction worked varied a lot society to society and even within regions and ethnic and social classes within society.  As noted above, in areas where agriculture was not very productive, extraction was limited.  By contrast, highly productive regions didn’t so much producer richer peasants as they tended to produce far higher rates of extraction.  In some society, where the freeholding farming peasantry (or part of that peasantry) formed an important political constituency (like some Greek <em>poleis</em> or the Roman Republic), the small farmers might manage to preserve relatively more of their surplus for themselves, but often in exchange for significant demands in terms of military and civic participation.</p>



<p>To take perhaps the simplest direct example of removing labor from the countryside, from 218 to 168, the Romans averaged around 10-12 legions deployed in a given year, 45,000-54,000 citizen soldiers.<span id="easy-footnote-11-31305"></span><span><a href="#easy-footnote-bottom-11-31305" title="On Roman deployments, see Taylor, <em>Soldiers and Silver</em> (2020)."><sup>11</sup></a></span>  Against an adult-male citizen population of perhaps ~250,000 implies that the Roman army was consuming something like a quarter of all of the available citizen manpower in the countryside, though enslaved laborers and males under 17 wouldn’t be captured by this figure.  Accounting for those groups we might imagine the Roman <a href="https://acoup.blog/2023/06/16/collections-how-to-raise-a-roman-army-the-dilectus/" data-type="post" data-id="19439"><em>dilectus</em> </a>is siphoning off something like 15% of the labor capacity of the countryside on average (sometimes spiking far higher, as much as <em>half</em> of it).  On top of that, the demand of these soldiers that they supply their own arms and armor would have pushed farmers to farm a little bit more than subsistence-and-a-little-more to afford the cost of the arms (traded for or purchased with that surplus; at least initially these transactions are not happening in coined money).</p>



<p>We see similar systems in the <a href="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/" data-type="link" data-id="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/">Carolingian levy system or the Anglo-Saxon fyrd</a>, where households might be brigaded together – <a href="https://en.wikipedia.org/wiki/Mansus" data-type="link" data-id="https://en.wikipedia.org/wiki/Mansus">in the Carolingian system, households were grouped into <em>mansi</em></a> – based on agricultural production (you can see how that works above as a proxy for ‘available surplus labor!’) with a certain number – three or four <em>mansi </em>in the Carolingian system – required to furnish one armed man for either a regional levy or the main field army.  The goal of such systems is to take the surplus labor above and make it available for military service.</p>



<p>Alternately, the elites might not want their peasants as <em>soldiers</em> but as <em>workers</em>.  Thus the very frequent appearance of<strong> <a href="https://en.wikipedia.org/wiki/Corv%C3%A9e" data-type="link" data-id="https://en.wikipedia.org/wiki/Corv%C3%A9e"><em>corvée</em> labor</a></strong>: a requirement of a certain amount of intermittent, unpaid forced labor.  This might be labor on the local lord’s estate (a sort of unpaid tenancy arrangement) or labor on public works (walls, castles, roads) or a rotating labor force working in state-owned (or elite-owned) productive enterprises (mines, for instance).  As with military service, this sort of labor demand could be shaped to what the local populace would bear and enforced by a military aristocracy against a largely disarmed peasantry.  Once again looking at the statistics above, even a few weeks a year <em>per man</em> (rather than per household) would drain most of the surplus labor out of our households.  Adding, for instance, a month of <em>corvée</em> labor of per work-capable male (an age often pegged around <em>seven</em> for these societies) under our favorable (6:1) assumptions above bring our work totals to 305 days (70% of total) for the Smalls, 373 (77%) for the Middles and 650 (81.5%) for the Biggs.  <em>Corvée</em> labor demands could be less than this, but also often quite a bit more (expectations varied a lot by local laws and customs.</p>



<p>Alternately, elites might just <em>crank up the taxes</em>.  In the Hellenistic states (the Ptolemaic and Seleucid kingdoms especially), the army wasn’t a peasant levy, but rather a core of Greco-Macedonian rentier elites (your ‘rich peasants’ or ‘gentlemen farmers’), regional levies and mercenaries.  To pay for that (and fund the lavish courts and public works that royal legitimacy required), the indigenous Levantine, Egyptian, Syrian, Mesopotamian (etc. etc.) underclasses were both made to be the tenants on the estates of those rentier elites (land seized from those same peasants in the initial Macedonian conquest or shortly thereafter) but also to pay <em>very high taxes</em> on their own land.<span id="easy-footnote-12-31305"></span><span><a href="#easy-footnote-bottom-12-31305" title="The way this was structurally, legally, was that the king, directly or indirectly <em>owned all the land</em> (&amp;#8216;spear-won&amp;#8217;) and so many taxes were instead technically &amp;#8216;rents&amp;#8217; paid to the king."><sup>12</sup></a></span>  So while tax rates on military-settler (that is, Greco-Macedonian rentier elites) land might have been around 10% – 1/12th (8.3%) seems to have been at least somewhat common – taxes on the land of the indigenous <em>laoi</em> could run as high as 50%, even before one got to taxes on markets, customs duties, sales taxes, a head tax and state monopolies on certain natural resources including timber and importantly <em>salt</em>.<span id="easy-footnote-13-31305"></span><span><a href="#easy-footnote-bottom-13-31305" title="On the Seleucid taxation system, see Aperghis, <em>The Seleucid Royal Economy</em> (2004).  For an overview of the relatively similar Ptolemaic system, see von Reden, <em>Money in Ptolemaic Egypt</em> (2007), Préaux, <em>. <em>L’économie royale des Lagides</em></em> (1979)."><sup>13</sup></a></span>  So the poor <em>laoi</em> might be paying extortionate taxes on their own lands, lighter taxes on settler (or temple) lands, but then also paying extortionate rents of those tenant-farmed lands.</p>



<p>Another micro-scale option was <strong>debt</strong>.  We’ve been assuming our farmers are operating at steady-state subsistence, but as we keep noting, <strong>yields in any given year were highly variable</strong>.  What peasants were forced to do in bad years, almost invariably as <strong>go into debt to the Big Man</strong>.  But as noted, they’re simply not generating a lot in the way of <em>surplus</em> to ever pay off that debt.  That in turn makes the debt itself a tool of control, what we often call <a href="https://en.wikipedia.org/wiki/Debt_bondage" data-type="link" data-id="https://en.wikipedia.org/wiki/Debt_bondage">debt peonage</a>.  Since the Big Man sets the terms of the debt (at a time when the peasant is absolutely desperate) it was trivially easy to construct a debt structure that the peasant could never pay off, giving the Big Man leverage to demand services – labor, tenancy on poor terms, broad social deference, etc. – in perpetuity.  And of course, if the Big Man ever wants to expand his land holdings, all he would need to do would be to call in the un-payable debt and – depending on the laws around debt in the society – either seize the peasant’s land in payment or reduce the peasant into debt-slavery.<span id="easy-footnote-14-31305"></span><span><a href="#easy-footnote-bottom-14-31305" title="The abolition of this specific form of slavery (but not others) is a key political moment in the development of both Rome and Athens (and we may assume, many other Greek <em>poleis</em>) that signals the political importance of the smallholding farmer-citizens and their ability to compel major reforms.  But the Big Man can still seize your farm!"><sup>14</sup></a></span></p>



<p>In short,<strong> elites had a <em>lot of mechanisms</em> to sop up the excess labor in the countryside and they generally used them</strong>.</p>



<p>Consequently, while peasants, unencumbered by taxes, rents, elites, debt, conscription and so on might have been able to <em>survive</em> working only a relatively small fraction of their time (probably around 100 days per year per-working-age male (again, age 7 or so and up) would suffice), <strong>they did not live in that world.</strong></p>



<p>Instead, they lived in a world where their own landholdings were extremely small – too small to fully support their households, although their small holdings might still provide a foundation of income for survival.  Instead, they had to work on land owned or at least controlled by Big Men: local rentier-elites, the king, temples, monasteries, and so on.  Those big institutions which could wield both legal and military force in turn extracted high rents and often demanded additional labor from our peasants, which soaked up much of their available labor, <strong>leading to that range of 250-300 working days a year, with 10-12 hour days each, for something on the order of 2,500-3,600 working hours for a farm-laboring peasant annually</strong>.</p>



<p>Which is quite a lot less than the c. 250 typical work days (261 weekdays minus holidays/vacation) in the United States – just by way of example of a modern industrial economy – at typically eight hours a day or roughly 2,000 working hours a year.  <strong>Of course it is also the case that those roughly 2,000 modern hours buy <em>a much better standard of living</em></strong> than what our medieval peasants had access to – consider that a single unimpressive car represents more value just in worked metal (steel) than even many ancient or medieval <em>elites</em> could muster.  <strong>No, you do not work more than a medieval or ancient peasant: you work somewhat less, in order to obtain <em>far</em> more material comfort</strong>.  Isn’t industrialization grand?</p>



<p><strong>That said, our picture of labor in peasant households is not complete!</strong> Indeed, we have only seen to half of our subsistence basket – you will recall we broke out textiles separately – because we haven’t yet even really introduced the workload of <strong>probably the most fully employed people in these households: the women</strong>. And what’s where we’ll go in the next post in this series.</p>
<ol><li><span id="easy-footnote-bottom-1-31305"></span>That is, landholders with enough land to subsist off of the rents without needing to do much or any actual agricultural labor themselves.<a href="#easy-footnote-1-31305"></a></li><li><span id="easy-footnote-bottom-2-31305"></span>For scale with the cavalrymen we are talking about just a few thousand households lording over a country of perhaps five <em>million</em>; these fellows are honestly closer to something like a medieval knightly elite than the peasantry.<a href="#easy-footnote-2-31305"></a></li><li><span id="easy-footnote-bottom-3-31305"></span>On these allotments, see P. Johstono, <em>The Army of Ptolemaic Egypt, 323-204 BC</em> (2020), 158-160 and C. Fischer-Bovet, <em>Army and Society in Ptolemaic Egypt </em>(2014), 212-217. On the rentier-self-sufficiency of these parcels, at a 5:1 yield, 30 <em>aroura</em> should yield something like 3,500kg wheat equivalent (almost 12 million calories), more than enough to support the settler’s household at a 50% rent (see below) using labor from the much smaller adjacent farms of indigenous Egyptians. Indeed, to me it seems very likely the land allotments were calculated precisely on this basis, with infantrymen receiving the smallest allotment that could reliably support a household in leisure.<a href="#easy-footnote-3-31305"></a></li><li><span id="easy-footnote-bottom-4-31305"></span>Le Roy Ladurie, <em>Les Paysans de Languedoc</em> (1966)<a href="#easy-footnote-4-31305"></a></li><li><span id="easy-footnote-bottom-5-31305"></span>A reminder that the <em>setérée</em> is an exact unit, about 1/5th to 1/4th of a hectare, so about 0.49-0.62 acres.<a href="#easy-footnote-5-31305"></a></li><li><span id="easy-footnote-bottom-6-31305"></span>Rosenstein (2004), 75, n.68; Erdkamp, (2005), 47-8; Cho-yun Hsu, <em>Han Agriculture: The Formation of Early Chinese Agrarian Economy</em> (1980); Johstono, <em>The Army of Ptolemaic Egypt</em> (2020), 101; Fischer-Bovet, <em>Army and Society in Ptolemaic Egypt </em>(2014), 121<a href="#easy-footnote-6-31305"></a></li><li><span id="easy-footnote-bottom-7-31305"></span>It’s hard to tell precisely from what I have because Le Roy Ladurie groups households in brackets.<a href="#easy-footnote-7-31305"></a></li><li><span id="easy-footnote-bottom-8-31305"></span>The average yield-per-<em>iugerum</em> at each fertility level in wheat equivalent are: 4:1, 81.2kg; 5:1, 108.2kg; 6:1, 135.3kg; 7:1, 162.4kg; 8:1, 189.5kg.<a href="#easy-footnote-8-31305"></a></li><li><span id="easy-footnote-bottom-9-31305"></span>I would argue that the Roman approach to Italy from 509 to 218 BC appears to be an exception to this rule: the Romans do tend to use conquered land to set up large numbers of small landholding farms.  Not rich peasants, but the Roman military class – the <em>assidui</em> farmer-citizen-soldiers – were also clearly not utterly impoverished either.  It’s striking that the Romans <em>could</em> have set up a system of rents and tribute extraction in Italy but didn’t, instead effectively terraforming the Italian countryside into a machine for the production of heavy infantry.  That heavy infantry in turn bought the Romans stunning military superiority, which they then used in the second and first centuries BC to create an <em>enormous</em> system of tribute and extraction (rather than extending the approach they had used in Italy).<a href="#easy-footnote-9-31305"></a></li><li><span id="easy-footnote-bottom-10-31305"></span>Of course you can drain a swamp, but such drainage efforts are the kinds of things large, well-administered <em>states</em> do, not the sort of thing your local peasants can summon the labor for.<a href="#easy-footnote-10-31305"></a></li><li><span id="easy-footnote-bottom-11-31305"></span>On Roman deployments, see Taylor, <em>Soldiers and Silver</em> (2020).<a href="#easy-footnote-11-31305"></a></li><li><span id="easy-footnote-bottom-12-31305"></span>The way this was structurally, legally, was that the king, directly or indirectly <em>owned all the land</em> (‘spear-won’) and so many taxes were instead technically ‘rents’ paid to the king.<a href="#easy-footnote-12-31305"></a></li><li><span id="easy-footnote-bottom-13-31305"></span>On the Seleucid taxation system, see Aperghis, <em>The Seleucid Royal Economy</em> (2004).  For an overview of the relatively similar Ptolemaic system, see von Reden, <em>Money in Ptolemaic Egypt</em> (2007), Préaux, <em>. <em>L’économie royale des Lagides</em></em> (1979).<a href="#easy-footnote-13-31305"></a></li><li><span id="easy-footnote-bottom-14-31305"></span>The abolition of this specific form of slavery (but not others) is a key political moment in the development of both Rome and Athens (and we may assume, many other Greek <em>poleis</em>) that signals the political importance of the smallholding farmer-citizens and their ability to compel major reforms.  But the Big Man can still seize your farm!<a href="#easy-footnote-14-31305"></a></li></ol>	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meow: Yet another modal editing on Emacs (109 pts)]]></title>
            <link>https://github.com/meow-edit/meow</link>
            <guid>45228396</guid>
            <pubDate>Sat, 13 Sep 2025 01:00:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/meow-edit/meow">https://github.com/meow-edit/meow</a>, See on <a href="https://news.ycombinator.com/item?id=45228396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Meow</h2><a id="user-content-meow" aria-label="Permalink: Meow" href="#meow"></a></p>
<p dir="auto"><a href="https://melpa.org/#/meow" rel="nofollow"><img src="https://camo.githubusercontent.com/d5ad260bd39e6e9438f40056129323586f33f00330e259bff1d39f95b87cd853/68747470733a2f2f6d656c70612e6f72672f7061636b616765732f6d656f772d62616467652e737667" alt="https://melpa.org/packages/meow-badge.svg" data-canonical-src="https://melpa.org/packages/meow-badge.svg"></a> <a href="https://stable.melpa.org/#/meow" rel="nofollow"><img src="https://camo.githubusercontent.com/89a66509f8f8f8dcbc0721b05559ad19374e6f2bcb0fd13b573af958315d3c10/68747470733a2f2f737461626c652e6d656c70612e6f72672f7061636b616765732f6d656f772d62616467652e737667" alt="https://stable.melpa.org/packages/meow-badge.svg" data-canonical-src="https://stable.melpa.org/packages/meow-badge.svg"></a>  <a href="https://github.com/meow-edit/meow/actions/workflows/action.yml"><img src="https://github.com/meow-edit/meow/actions/workflows/action.yml/badge.svg" alt="https://github.com/meow-edit/meow/actions/workflows/action.yml/badge.svg"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/meow-edit/meow/blob/master/meow.svg"><img src="https://github.com/meow-edit/meow/raw/master/meow.svg" alt="meow.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<blockquote>
  <p dir="auto">Less is more</p>
</blockquote>
<p dir="auto">Meow is yet another modal editing mode for Emacs.</p>
<p dir="auto">Meow aims to blend modal editing into Emacs with minimal interference
  with its original key-bindings, avoiding most of the hassle introduced
  by key-binding conflicts. This leads to lower necessary configuration and
  better integration. More is achieved with fewer commands to remember.</p>
<p dir="auto">Key features compared to existing solutions:</p>
<ul dir="auto">
  <li>Minimal configuration – build your own modal editing system</li>
  <li>No third-party dependencies (<a href="https://github.com/meow-edit/meow/blob/master/GET_STARTED.org">try it without touching your configuration</a>)</li>
  <li>Doesn’t occupy too many keys
    <ul dir="auto">
      <li>Much easier to remember for people trying modal editing</li>
      <li>More keys available for your own key-bindings</li>
      <li>Most of the time, you don’t even need to hold shift!</li>
    </ul>
  </li>
  <li>Lightning fast (unlike Evil)</li>
  <li>Minimizes modifier usage (e.g. <code>SPC x f</code> for <code>C-x C-f</code>) inspired by <a href="https://github.com/emacsorphanage/god-mode">god-mode</a></li>
  <li>Better workflow for <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Keyboard-Macros.html" rel="nofollow">kmacro</a> application at multiple locations</li>
  <li>Interactive selection manipulation and expansion inspired by avy</li>
  <li>Selection as top-tier object, and keybindings built around selection</li>
  <li>Compatible with the vanilla Emacs keymap (or any other keymap from any package)</li>
  <li>Effortless uniform keymaps across modes</li>
  <li>Key-binding conflict handling made easy</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">Please feel free to ask questions and share ideas at</p>
<ul dir="auto">
  <li><a href="https://github.com/meow-edit/meow/discussions">Github Discussion</a></li>
  <li><a href="https://xmpp.link/#meow@chat.disroot.org?join" rel="nofollow">Meow XMPP Channel</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documents</h2><a id="user-content-documents" aria-label="Permalink: Documents" href="#documents"></a></p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/GET_STARTED.org">Get started</a> - Installation and configuration</p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/TUTORIAL.org">Tutorial</a> - Learn Meow in 15 minutes</p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/FAQ.org">FAQ</a> - Frequently Asked Questions</p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/COMMANDS.org">Commands</a> - Documentation for commands</p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/CUSTOMIZATIONS.org">Customizations</a> - Helper functions and variables</p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/EXPLANATION.org">Explanation</a> - Ideas and concepts behind Meow</p>
<p dir="auto"><a href="https://github.com/meow-edit/meow/blob/master/CHANGELOG.md">Changelog</a> - Changes, releases, and news</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Licensed under GPLv3.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tips for installing Windows 98 in QEMU/UTM (112 pts)]]></title>
            <link>https://sporks.space/2025/08/28/tips-for-installing-windows-98-in-qemu-utm/</link>
            <guid>45227749</guid>
            <pubDate>Fri, 12 Sep 2025 23:04:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sporks.space/2025/08/28/tips-for-installing-windows-98-in-qemu-utm/">https://sporks.space/2025/08/28/tips-for-installing-windows-98-in-qemu-utm/</a>, See on <a href="https://news.ycombinator.com/item?id=45227749">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-1469">
	<!-- .entry-header -->

	
		<div>
			
<p>Windows 98 runs surprisingly well in QEMU via <a href="https://apps.apple.com/us/app/utm-se-retro-pc-emulator/id1564628856">UTM SE,</a> but it requires some care in setting it up. It’s a great way to run old 90s Windows and DOS software on your iPad (and Mac too, though you have other options available to you, or an iPhone if you don’t mind the HID difficulties).</p>



<p>This post provides some suggestions and tips for installing Windows and selecting the best emulated devices. The guidance is intended for UTM users on Apple platforms, but should apply to anything QEMU based (or QEMU itself). The advice might also be useful for other operating systems in UTM/QEMU as well.</p>



<figure><img fetchpriority="high" decoding="async" width="1024" height="768" src="https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-1024x768.jpeg" alt="Windows 95 on UTM SE on an iPad Pro with Magic Keyboard. Note you're better off using Windows 98, but this does work as well." srcset="https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-1024x768.jpeg 1024w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-300x225.jpeg 300w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-768x576.jpeg 768w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-1536x1152.jpeg 1536w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-2048x1536.jpeg 2048w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/IMG_0061-480x360.jpeg 480w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Plug and play BIOS issues (or: how to install with ACPI)</h2>



<p>When you install Windows 9x, PCI devices might be broken, and you’ll see a Plug and Play BIOS device with problems in the device manager:</p>



<figure><img decoding="async" width="410" height="448" src="https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/image.png" alt="A broken Plug and Play BIOS device in Device Manager." srcset="https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/image.png 410w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/image-275x300.png 275w, https://sporksspace.b-cdn.net/wp-content/uploads/2025/08/image-329x360.png 329w" sizes="(max-width: 410px) 100vw, 410px"></figure>



<p>This seems to be a bug in SeaBIOS or QEMU; I haven’t yet seen an issue tracking this. Many guides (i.e. <a href="https://computernewb.com/wiki/Install_QEMU_Tablet_Driver_on_Windows_98">this one</a> or <a href="https://github.com/JHRobotics/softgpu/blob/main/qemu.md">this one</a>) suggest changing the device and hoping devices re-enumerate correctly. However, there’s a simpler method available when using Windows 98 SE. (If you’re using Windows 95, you won’t be able to do this.)</p>



<p>Windows 98 can use ACPI to enumerate devices instead of the legacy PnP BIOS. Unfortunately, it doesn’t use ACPI by default. (There seems to be an allowlist of known good ACPI BIOSes, as it was early days for ACPI.) To make it use ACPI anyways, boot with CD-ROM support from the Windows 98 CD instead of running the installer, then run Windows setup with the <code>/p j</code> flag, like so:</p>



<pre><code>C:\&gt; D:
D:\&gt; cd WIN98
D:\WIN98&gt; setup /p j</code></pre>



<p>It’s possible to <a href="http://facsimiliter.com/Windows98/AdvConfigPwrInterface,HelpWithWindows.htm">convert an existing system to ACPI</a>, but it’s much easier to do this from the start. When Windows is installed this way, it should correctly enumerate all devices.</p>



<h2>Device selection</h2>



<h3>System</h3>



<p>QEMU can emulate devices Windows 98 supports out of the box, which is good as there are no VirtIO drivers. Make sure you’re using the i440-based “<code>pc</code>” rather than the Q35 based system, as it’ll be better supported for legacy systems. You don’t need to worry about selecting i386 vs. x86_64, as Windows 98 will obviously never touch 64-bit mode, so they’ll be the same.</p>



<p>(As a tip, if you’re running NT 4, you’ll need to select a different CPU to make sure it’s happy with the CPU flags as the default one is too new. A Pentium II should be sufficiently old.)</p>



<h3>Input</h3>



<p>You may need to disable USB (or at least, USB input devices) to avoid hanging on startup, at least with UTM (It’s possible the ‘Force PS/2 Controller’ option might work, but I haven’t had much luck with it. Unfortunately, this means you won’t have absolute mouse input (through the USB tablet) and must capture your cursor. With UTM SE on an iPad, this doesn’t hurt as much, as it can automatically capture the trackpad or external mouse, while leaving the touchscreen for interacting with iOS.</p>



<h3>Video</h3>



<p>The most sensible video option for Windows 98 is the Cirrus VGA (<code>-vga cirrus</code>). There are unfortunately some bugs (flashing in 16 bit colour modes, blitting issues in 8 bit colour modes), but it’s the only option with accelerated drivers out of the box. (Of course, there is no 3D acceleration with such a card.)</p>



<p>Apparently, Rage 128 emulation is being worked on (<code>ati-vga</code>), but currently only works for Power Mac emulation, and is in rough shape so far.</p>



<h3>Networking and getting files in</h3>



<p>For getting files into the VM easily, you’ll want a network. SLiRP NAT works fine for using a browser or SMB shares, for example. (Note this works better on Windows 98 than 95; 95 has issues with mounting SMB shares by IP and doesn’t come with a browser.) QEMU can emulate a variety of network cards. The tulip (DC2114x), NE2000 (PCI and ISA), and PCNet should all work out of the box with older Windows. I’d recommend using a PCI card if possible, since it saves you the ISA setup headache unless you need it for something old. If you do need to set up an ISA NE2000, it’s at address 300h, IRQ 9, which might require manual configuration in some cases.</p>



<h3>Sound</h3>



<p>For sound hardware, there are a few options available, with different tradeoffs.</p>



<ul>
<li>If you want to run DOS software, the SoundBlaster 16 (<code>sb16</code>) emulation works out of the box, but there is no OPL3 or MPU-401, so MIDI won’t work correctly, just PCM. Games will have a hard time with this unless they’re entirely PCM. For <a href="https://virtuallyfun.com/2011/10/28/soundblaster-16-settings-for-virtualpc-qemu/">setting up your SB16 for DOS games</a>, use <code>SET BLASTER=A220 I5 D1 H5 P330 T5</code> (that’s address 220h, interrupt 5, 8-bit DMA 1, our non-existent MPU-401 at 330h, 16-bit DMA 5).
<ul>
<li>Note that QEMU supports adding an AdLib (OPL2 based) separately, which might help with some software.</li>
</ul>
</li>



<li>The CS4321A I haven’t tested, but might work with WSS or Crystal-specific drivers. As with the SoundBlaster 16, there is no OPL3. QEMU sets this up at 534h, IRQ 9, DMA 3.</li>



<li>The Gravis UltraSound (<code>gus</code>) emulation works <a href="https://virtuallyfun.com/2013/10/29/gravis-ultrasound-under-qemu/">surprisingly well</a>, but the Windows 95 drivers are crusty for the version of the card it emulates (GF1/GUS Classic), so use it only if you want to run old trackers or demoscene stuff. Note you may need to turn off the LPT port (<code>-parallel none</code>) to free up an interrupt used for the UltraSound.</li>



<li>Because of this, the ES1370 might be the best card to emulate for plain Windows usage, as it has relatively few quirks and I believe has drivers on the Windows 98 CD. However, it’s not ideal for DOS software as it requires TSRs to make it work right.</li>



<li>The AC97 emulation will require Realtek drivers. I haven’t tested this.</li>
</ul>



<h3>Potpourri</h3>



<p>In UTM, you may want to turn off the entropy device, to reduce unknown device clutter in Device Manager, though it’s harmless. The VirtIO console device will still be present in Device Manager with UTM’s default flags.</p>



<h2>Other quirks</h2>



<p>In UTM SE, sometimes rebooting might hang when switching video modes. If this happens, it seems safe to shut down the machine and start it again. Avoiding reboots in favour of shutting down seems wise.</p>



<h2>Performance characteristics</h2>



<p>While TCG in QEMU doesn’t have the best reputation for performance, it might be good enough for your needs. On my MacBook Pro with an M1 Pro, benchmarks show performance somewhat around about a 750 MHz Pentium III, albeit with worse floating point performance. This is pretty usable, although most 3D games won’t be usable as even software rendering will be a bit sketchy.</p>



<p>If you’re using UTM SE on iOS, the interpreter is slower, but not unusable for 90s software. On my M1 iPad Pro, I get Pentium 100 performance, with similar penalties for FP. This is good for games up to about 1995 or 1996; titles like MechWarrior 2, Widget Workshop, many edutainment titles, and SimCity 2000 are playable this way, though MIDI or CD music will be missing. Non-game software like Office 97 or Visual C++ will run fine, of course. For OSes, this also puts things like Windows 2000 and beyond just out of reach performance wise – stick with Windows 98 for the best compatibility.</p>
					</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article><!-- #post-1469 -->
				<!-- #nav-below -->
	
			
<!-- #comments -->
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFglitch, FFmpeg fork for glitch art (247 pts)]]></title>
            <link>https://ffglitch.org/gallery/</link>
            <guid>45227212</guid>
            <pubDate>Fri, 12 Sep 2025 21:54:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ffglitch.org/gallery/">https://ffglitch.org/gallery/</a>, See on <a href="https://news.ycombinator.com/item?id=45227212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article>
  
  <div>
    






<p>There are some artists out there doing some amazing work using FFglitch.</p>

<p>I put this page up so that I don’t have to go hunting for examples every time I want to show someone what can be done with FFglitch.</p>

<hr>

<p>Thomas Collet has a lot of work using FFglitch on <a href="https://vimeo.com/chepertom">vimeo</a>, <a href="https://www.instagram.com/chepertomz/">instagram</a>, and <a href="https://www.reddit.com/user/chepertom">reddit</a>.</p>

<p><iframe src="https://player.vimeo.com/video/391458897" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>

<p><iframe src="https://player.vimeo.com/video/326369094" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>


<p>A bunch more from Thomas:</p>
<ul>
  <li><a href="https://vimeo.com/366067869">https://vimeo.com/366067869</a></li>
  <li><a href="https://vimeo.com/363105562">https://vimeo.com/363105562</a></li>
  <li><a href="https://vimeo.com/323235580">https://vimeo.com/323235580</a></li>
  <li><a href="https://www.reddit.com/r/glitch_art/comments/b9yfxc/study_on_crowd_movements/">https://www.reddit.com/r/glitch_art/comments/b9yfxc/study_on_crowd_movements/</a></li>
  <li><a href="https://www.reddit.com/r/brokengifs/comments/grpwn4/tripping_in_manhattan/">https://www.reddit.com/r/brokengifs/comments/grpwn4/tripping_in_manhattan/</a></li>
  <li><a href="https://www.reddit.com/r/woahdude/comments/bg176f/i_went_to_ireland_filmed_the_ocean_and_glitched_it/">https://www.reddit.com/r/woahdude/comments/bg176f/i_went_to_ireland_filmed_the_ocean_and_glitched_it/</a></li>
  <li><a href="https://www.reddit.com/r/woahdude/comments/ballm7/when_the_world_is_slowly_but_surely_falling_appart/">https://www.reddit.com/r/woahdude/comments/ballm7/when_the_world_is_slowly_but_surely_falling_appart/</a></li>
  <li><a href="https://www.reddit.com/r/glitch_art/comments/fhpwgp/falling_appart/">https://www.reddit.com/r/glitch_art/comments/fhpwgp/falling_appart/</a></li>
  <li><a href="https://www.reddit.com/r/glitch_art/comments/hxk6r1/when_it_kicks_in_the_middle_of_time_square/">https://www.reddit.com/r/glitch_art/comments/hxk6r1/when_it_kicks_in_the_middle_of_time_square/</a></li>
</ul>

<hr>

<p><a href="https://www.kaspar.wtf/">Kaspar Ravel</a> wrote a blog post
about a collaboration he did with Thomas Collet which resulted in this gem:
<img src="https://ffglitch.org/assets/images/example6.gif" alt="kaspar and thomas"></p>

<p>Here’s the blog post: <a href="https://www.kaspar.wtf/blog/encoding-the-game-of-life-in-datamosh">https://www.kaspar.wtf/blog/encoding-the-game-of-life-in-datamosh</a></p>

<p>And the post on reddit: <a href="https://www.reddit.com/r/brokengifs/comments/e25f6b/want_to_see_a_magic_trick/">https://www.reddit.com/r/brokengifs/comments/e25f6b/want_to_see_a_magic_trick/</a></p>

<hr>

<p><a href="https://www.instagram.com/sebr.ias/">Sebastien Brias</a>:</p>

<blockquote data-instgrm-captioned="" data-instgrm-permalink="https://www.instagram.com/p/CPNaIp8qo-r/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="13"></blockquote>


<blockquote data-instgrm-captioned="" data-instgrm-permalink="https://www.instagram.com/p/COvtPDoqNCF/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="13"></blockquote>


<blockquote data-instgrm-captioned="" data-instgrm-permalink="https://www.instagram.com/p/COU7Z1fqPrW/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="13"></blockquote>


<hr>

<p><a href="https://www.instagram.com/glit_chbee/">glit_chbee</a> (turn the volume up and enjoy the ride):</p>

<p><iframe src="https://www.youtube.com/embed/17uNd_-luII?feature=oembed&amp;enablejsapi=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><iframe src="https://www.youtube.com/embed/JRHuwtXvIFc?feature=oembed&amp;enablejsapi=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>


<hr>

<p><a href="https://www.reddit.com/user/nowahe/">nowahe</a>:</p>




<hr>

<p>Ben Cooper made this clip by using mainly <a href="http://avidemux.sourceforge.net/">avidemux</a>, <a href="https://github.com/itsKaspar/tomato">tomato.py</a>, and FFglitch.</p>

<p><iframe src="https://www.youtube.com/embed/4DCknwLDD8U?feature=oembed&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>


<hr>

<p><a href="https://frgmnt.org/">Jo Grys</a> has posted some videos on Facebook:</p>




<p>There are more if you search for #ffglitch on Facebook:</p>
<ul>
  <li><a href="https://www.facebook.com/hashtag/ffglitch/">https://www.facebook.com/hashtag/ffglitch/</a></li>
</ul>

<hr>

<p>And some more random clips I found spread around the interwebz:</p>
<ul>
  <li><a href="https://www.reddit.com/r/brokengifs/comments/ey863f/some_minor_smudging">https://www.reddit.com/r/brokengifs/comments/ey863f/some_minor_smudging</a></li>
  <li><a href="https://fb.com/groups/Glitchcollective/?post_id=2223010624487144">https://fb.com/groups/Glitchcollective/?post_id=2223010624487144</a></li>
  <li><a href="https://www.instagram.com/p/B_QKvtcBJaW">https://www.instagram.com/p/B_QKvtcBJaW</a></li>
</ul>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proton Mail suspended journalist accounts at request of cybersecurity agency (316 pts)]]></title>
            <link>https://theintercept.com/2025/09/12/proton-mail-journalist-accounts-suspended/</link>
            <guid>45226903</guid>
            <pubDate>Fri, 12 Sep 2025 21:20:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theintercept.com/2025/09/12/proton-mail-journalist-accounts-suspended/">https://theintercept.com/2025/09/12/proton-mail-journalist-accounts-suspended/</a>, See on <a href="https://news.ycombinator.com/item?id=45226903">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p><span>The company behind</span> the Proton Mail email service, Proton, <a href="https://proton.me/#:~:text=We%20are%20a%20neutral%20and%20safe%20haven%20for%20your%20personal%20data%2C%20committed%20to%20defending%20your%20freedom">describes itself</a> as a “neutral and safe haven for your personal data, committed to defending your freedom.”</p>
<p>But last month, Proton disabled email accounts belonging to journalists reporting on security breaches of various South Korean government computer systems following a complaint by an unspecified cybersecurity agency. After a public outcry, and multiple weeks, the journalists’ accounts were eventually reinstated — but the reporters and editors involved still want answers on how and why Proton decided to shut down the accounts in the first place.</p>
<p>Martin Shelton, deputy director of digital security at the Freedom of the Press Foundation, highlighted that numerous newsrooms use Proton’s services as alternatives to something like Gmail “specifically to avoid situations like this,” pointing out that “While it’s good to see that Proton is reconsidering account suspensions, journalists are among the users who need these and similar tools most.” Newsrooms like The Intercept, the Boston Globe, and the Tampa Bay Times all rely on Proton Mail for<a href="https://theintercept.com/source/"> emailed tip submissions</a>.</p>
<p>Shelton noted that perhaps Proton should “prioritize responding to journalists about account suspensions privately, rather than when they go viral.”</p>
<p>On Reddit, Proton’s official account <a href="https://www.reddit.com/r/ProtonMail/comments/1nd1nrc/is_that_true/ndg68pz/">stated</a> that “Proton did not knowingly block journalists’ email accounts” and that the “situation has unfortunately been blown out of proportion.” Proton did not respond to The Intercept’s request for comment.</p>
<!-- BLOCK(cta)[0](%7B%22componentName%22%3A%22CTA%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->


<!-- END-BLOCK(cta)[0] -->
<p><span>The two journalists</span> whose accounts were disabled were working on an <a href="https://phrack.org/issues/72/7_md">article</a> published in the August issue of the long-running hacker zine Phrack. The story described how a sophisticated hacking operation — what’s known in cybersecurity parlance as an APT, or advanced persistent threat — had wormed its way into a number of South Korean computer networks, including those of the Ministry of Foreign Affairs and the military Defense Counterintelligence Command, or DCC.</p>
<p>The journalists, who published their story under the names Saber and cyb0rg, describe the hack as being consistent with the work of Kimsuky, a notorious North Korean state-backed APT <a href="https://home.treasury.gov/news/press-releases/jy1938">sanctioned</a> by the U.S. Treasury Department in 2023.</p>
<p>As they pieced the story together, emails viewed by The Intercept show that the authors followed cybersecurity best practices and conducted what’s known as responsible disclosure: notifying affected parties that a vulnerability has been discovered in their systems prior to publicizing the incident.</p>
<p>Saber and cyb0rg created a dedicated Proton Mail account to coordinate the responsible disclosures, then proceeded to notify the impacted parties, including the Ministry of Foreign Affairs and the DCC, and also notified South Korean cybersecurity organizations like the Korea Internet and Security Agency, and <a href="https://www.krcert.or.kr/">KrCERT/CC</a>, the state-sponsored Computer Emergency Response Team. According to emails viewed by The Intercept, KrCERT wrote back to the authors, thanking them for their disclosure.</p>
<p>A note on cybersecurity jargon: CERTs are agencies consisting of cybersecurity experts specializing in dealing with and responding to security incidents. CERTs exist in over 70 countries — with some countries having multiple CERTs each specializing in a particular field such as the financial sector — and may be government-sponsored or private organizations. They adhere to a set of formal technical <a href="https://datatracker.ietf.org/doc/html/rfc2350">standards</a>, such as being expected to react to reported cybersecurity threats and security incidents. A high-profile example of a CERT agency in the U.S. is the Cybersecurity and Infrastructure Agency, which has recently been <a href="https://www.nextgov.com/cybersecurity/2025/06/cisa-projected-lose-third-its-workforce-under-trumps-2026-budget/405726/">gutted</a> by the Trump administration.</p>
<!-- BLOCK(newsletter)[0](%7B%22componentName%22%3A%22NEWSLETTER%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->

<!-- END-BLOCK(newsletter)[0] -->
<p>A week after the print issue of Phrack came out, and a few days before the digital version was released, Saber and cyb0rg found that the Proton account they had set up for the responsible disclosure notifications had been suspended. A day later, Saber discovered that his personal Proton Mail account had also been suspended. Phrack posted a timeline of the account suspensions at the top of the published article, and later highlighted the timeline in a viral social media <a href="https://x.com/phrack/status/1965385266904138241">post</a>. Both accounts were suspended owing to an unspecified “potential policy violation,” according to screenshots of account login attempts reviewed by The Intercept.</p>
<p>The suspension notice instructed the authors to fill out <a href="https://proton.me/support/appeal-abuse">Proton’s abuse appeals form</a> if they believed the suspension was in error. Saber did so, and received a reply from a member of Proton Mail’s Abuse Team who went by the name Dante.</p>
<p>In an email viewed by The Intercept, Dante told Saber that their account “has been disabled as a result of a direct connection to an account that was taken down due to violations of our terms and conditions while being used in a malicious manner.” Dante also provided a link to <a href="https://proton.me/legal/terms">Proton’s terms of service</a>, going on to state, “We have clearly indicated that any account used for unauthorized activities, will be sanctioned accordingly.” The response concluded by stating, “We consider that allowing access to your account will cause further damage to our service, therefore we will keep the account suspended.”</p>
<p>On August 22, a Phrack editors reached out to Proton, writing that no hacked data was passed through the suspended email accounts, and asked if the account suspension incident could be deescalated. After receiving no response from Proton, the editor sent a follow-up email on September 6. Proton once again did not reply to the email.</p>
<p>On September 9, the official Phrack X account made a <a href="https://x.com/phrack/status/1965385266904138241">post</a> asking Proton’s official account asking why Proton was “cancelling journalists and ghosting us,” adding: “need help calibrating your moral compass?” The post quickly went viral, garnering over 150,000 views.</p>
<p>Proton’s official account replied the following day, <a href="https://x.com/ProtonPrivacy/status/1965701661705322849">stating</a> that Proton had been “alerted by a CERT that certain accounts were being misused by hackers in violation of Proton’s Terms of Service. This led to a cluster of accounts being disabled. Our team is now reviewing these cases individually to determine if any can be restored.” Proton then <a href="https://x.com/ProtonPrivacy/status/1965828424963895605">stated</a> that they “stand with journalists” but “cannot see the content of accounts and therefore cannot always know when anti-abuse measures may inadvertently affect legitimate activism.”</p>
<p>Proton did not publicly specify which CERT had alerted them, and didn’t answer The Intercept’s request for the name of the specific CERT which had sent the alert. KrCERT also did not reply to The Intercept’s question about whether they were the CERT that had sent the alert to Proton.</p>

<p>Later in the day, Proton’s founder and CEO Andy Yen <a href="https://x.com/andyyen/status/1965767030688317832">posted</a> on X that the two accounts had been reinstated. Neither Yen nor Proton explained why the accounts had been reinstated, whether they had been found to not violate the terms of service after all, why had they been suspended in the first place, or why a member of the Proton Abuse Team reiterated that the accounts had violated the terms of service during Saber’s appeals process.</p>
<p>Phrack noted that the account suspensions created a “real impact to the author. The author was unable to answer media requests about the article.” The co-authors, Phrack pointed out, were also in the midst of the responsible disclosure process and working together with the various affected South Korean organizations to help fix their systems. “All this was denied and ruined by Proton,” Phrack stated.&nbsp;</p>
<p>Phrack editors said that the incident leaves them “concerned what this means to other whistleblowers or journalists. The community needs assurance that Proton does not disable accounts unless Proton has a court order or the crime (or ToS violation) is apparent.”</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I used standard Emacs extension-points to extend org-mode (174 pts)]]></title>
            <link>https://edoput.it/2025/04/16/emacs-paradigm-shift.html</link>
            <guid>45226639</guid>
            <pubDate>Fri, 12 Sep 2025 20:53:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://edoput.it/2025/04/16/emacs-paradigm-shift.html">https://edoput.it/2025/04/16/emacs-paradigm-shift.html</a>, See on <a href="https://news.ycombinator.com/item?id=45226639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Recently I read <a href="https://blog.tjll.net/a-beginners-guide-to-extending-emacs/">this beginners guide to extend Emacs</a>.
The guide is perfect for starting out with elisp and it shows a lot of care in teaching how to interact with Emacs.</p>

<p>To me, the most important bit though is this one, from the section aptly named <strong>Emacs Wants You to Extend It</strong>.</p>

<blockquote>
  <p>I haven’t written plugins for other editors extensively, but I can tell you this: emacs doesn’t just make deep customization available, but it actively encourages you to make an absolute customization messes masterpieces. Core editor functions aren’t just documented, but often include tidbits about “you probably want to see this other variable” or “here’s how you should use this”.</p>

  <p>Not only that, but emacs happily hands you functions shaped like nuclear warheads like advice-add (that let you override any function) that can absolutely obliterate your editor if you hold it the wrong way. Of course, this also grants you unlimited power.</p>

  <p>Remember that emacs is designed to be torn apart and rearranged.</p>
</blockquote>

<p>This is the core bit of the argument. Emacs, as a system, wants you to
extend it and it gives you all the means to do so. This is in contrast
with systems that can be extended through scripting and instead don’t give
you all the means to do so!</p>

<p>I think the tutorial is a fantastic example of <em>doing things
right</em>. There is a well-thought example, a constructive approach where
the solution grows to a full package.</p>

<p>This is problematic. You may get the impression that extending Emacs
is only possible if you do things right and that is definitely not true.</p>

<p>To make my point I want to walk you through an example. I will show
you how I used standard Emacs extension-points to extend org-mode to sort my
reading lists automatically.</p>

<h2 id="what-do-i-want">What do I want?</h2>

<p>The behavior I want is that when I save an org file the entries are
ordered automatically. I keep a timeline of the papers I am reading
and it is annoying to keep them kind of ordered.</p>

<p>This is the content of an example buffer.</p>

<figure><pre><code data-lang="org">#+TITLE: My tematic reading list

* Paper which is old but not too old
:PROPERTY:
:year: 2002
:END:

* Definitely older paper but unfortunately it's later in the list
:PROPERTY:
:year: 1998
:END:</code></pre></figure>

<p>When I add a paper to my reading list I run <code>org-sort-entries</code> and
interactively select to order the entries by the value in the property
<code>year</code>. Initally this was nice to have but now it’s just annoying that
I have to keep doing it. Let’s extend org-mode so that this is done automatically.</p>

<h2 id="a-simple-solution">A simple solution</h2>

<p>The first step is to automate the interactive part. Lucky for me this is easy
as <code>org-sort-entries</code> is both a function and a command. I can call it in a
script just as I can run it as a command.</p>

<figure><pre><code data-lang="elisp"><span>(</span><span>defvar</span> <span>org-sort-option</span> <span>"year"</span><span>)</span>

<span>(</span><span>defun</span> <span>org-sort-run</span> <span>()</span>
  <span>(</span><span>when</span> <span>(</span><span>and</span> <span>(</span><span>derived-mode-p</span> <span>'org-mode</span><span>)</span> <span>org-sort-option</span><span>)</span>
    <span>(</span><span>let</span> <span>((</span><span>case-sensitive</span> <span>nil</span><span>)</span>
	  <span>(</span><span>sorting-type</span> <span>?r</span><span>)</span>
	  <span>(</span><span>getkey-func</span> <span>nil</span><span>)</span>
	  <span>(</span><span>compare-func</span> <span>nil</span><span>)</span>
	  <span>(</span><span>property</span> <span>org-sort-option</span><span>)</span>
	  <span>(</span><span>interactive?</span> <span>nil</span><span>))</span>
      <span>(</span><span>org-sort-entries</span> <span>case-sensitive</span> <span>sorting-type</span> <span>getkey-func</span> <span>compare-func</span> <span>property</span> <span>interactive?</span><span>))))</span></code></pre></figure>

<p>This solves one part of the problem. Let’s solve the other one, automatically calling
<code>org-sort-run</code> whenever an org-mode buffer is saved.</p>

<p>Emacs already has support for this use-case through the use of hooks. We can run
<code>org-sort-run</code> all the times we want to save a buffer.</p>

<figure><pre><code data-lang="elisp"><span>(</span><span>add-hook</span> <span>'before-save-hook</span> <span>#'</span><span>org-sort-run</span><span>)</span></code></pre></figure>

<p>These two together solve the problem but the solution presented is “just more code”.
We tapped into the <em>hook</em> extension point but this would be possible in any
<em>scriptable system</em> that exposes well-defined extension points such as hooks and commands.</p>

<h2 id="leveraging-emacs-extensibility-to-extend-org-mode">Leveraging Emacs’ extensibility to extend org-mode</h2>

<p>I want to show that even if something is not thought with
extensibility in mind Emacs allow us to extend it. Most importantly, while we
want to extend org-mode’s behavior we would like this not to be an
extension to org-mode’s code.</p>

<p>Here’s the updated problem statement. Have the buffer be automatically
sorted and have the sorting criteria be in the buffer itself. We will
specify the sorting as a <em>in-buffer setting</em> and use Emacs to
support this never thought before org-mode behavior.</p>

<p>Our example buffer changes to the following.</p>

<figure><pre><code data-lang="diff"> #+TITLE: My tematic reading list
<span>+#+SORT: year
</span> 
 * Paper which is old but not too old
 :PROPERTY:
 :year: 2002
 :END:
 
 * Definitely older paper but unfortunately it's later in the list
 :PROPERTY:
 :year: 1998
 :END:</code></pre></figure>



<p>The hard part of this is to find how org-mode reads <em><a href="https://orgmode.org/manual/In_002dbuffer-Settings.html">in-buffer
settings</a></em>
from the header. A <kbd>M-x find-library</kbd> later we are in org’s
sources.</p>

<p>Searching for <code>+STARTUP</code> (<kbd>Ctrl+s +STARTUP</kbd>), one of the
supported settings, leads us to <code>org-startup-folded</code> and that in turn
(<kbd>Ctrl+s org-startup-folded</kbd>) leads us to <code>org-startup-options</code>.</p>

<p><code>org-startup-options</code> is the used by (again <kbd>Ctrl+s org-startup-option</kbd>)
<code>org-set-regexps-and-options</code>.</p>



<p>While the documentation for this function is not very convincing, its code
does make sense for what we are after. I copied it here for reference.</p>

<figure><pre><code data-lang="elisp">  <span>(</span><span>when</span> <span>(</span><span>derived-mode-p</span> <span>'org-mode</span><span>)</span>
    <span>(</span><span>let</span> <span>((</span><span>alist</span> <span>(</span><span>org-collect-keyword</span>
		  <span>(</span><span>append</span> <span>'</span><span>(</span><span>"FILETAGS"</span> <span>"TAGS"</span><span>)</span>
			  <span>(</span><span>and</span> <span>(</span><span>not</span> <span>tags-only</span><span>)</span>
			       <span>'</span><span>(</span><span>"ARCHIVE"</span> <span>"CATEGORY"</span> <span>"COLUMNS"</span> <span>"CONSTANTS"</span>
				 <span>"LINK"</span> <span>"OPTIONS"</span> <span>"PRIORITIES"</span> <span>"PROPERTY"</span>
				 <span>"SEQ_TODO"</span> <span>"STARTUP"</span> <span>"TODO"</span> <span>"TYP_TODO"</span><span>)))</span>
		  <span>'</span><span>(</span><span>"ARCHIVE"</span> <span>"CATEGORY"</span> <span>"COLUMNS"</span> <span>"PRIORITIES"</span><span>))))</span>
      <span>;; Startup options.  Get this early since it does change</span>
      <span>;; behavior for other options (e.g., tags).</span>
      <span>(</span><span>let</span> <span>((</span><span>startup</span> <span>(</span><span>cl-mapcan</span> <span>(</span><span>lambda</span> <span>(</span><span>value</span><span>)</span> <span>(</span><span>split-string</span> <span>value</span><span>))</span>
				<span>(</span><span>cdr</span> <span>(</span><span>assoc</span> <span>"STARTUP"</span> <span>alist</span><span>)))))</span>
	     <span>...</span><span>)</span></code></pre></figure>

<p>Unfortunately this function calls <code>org-collect-keyword</code> with a list that we cannot
touch. There is no custom variable to set to pass our own keyword.</p>

<p>If this was a “normal programming environment” we would make our changes
to this function body and forever maintain a fork of org-mode. As this
is elisp instead we have choices.</p>

<p>I think the best choice is to use <code>advice-add</code> and have Emacs call our
advice code every time <code>org-set-regexps-and-options</code> is called. We will copy
what we need from the function body but that will be all.</p>

<p>This is what I ended up with.</p>

<figure><pre><code data-lang="elisp"><span>(</span><span>defvar</span> <span>org-sort-option</span> <span>nil</span><span>)</span>

<span>(</span><span>defun</span> <span>org-sort-set-option</span> <span>(</span><span>&amp;rest</span> <span>r</span><span>)</span>
  <span>"Read the +SORT: spec value into variable `org-sort-option'."</span>
  <span>(</span><span>when</span> <span>(</span><span>derived-mode-p</span> <span>'org-mode</span><span>)</span>
    <span>(</span><span>let</span> <span>((</span><span>alist</span> <span>(</span><span>org-collect-keywords</span> <span>'</span><span>(</span><span>"SORT"</span><span>))))</span>
      <span>(</span><span>let</span> <span>((</span><span>sort</span> <span>(</span><span>cdr</span> <span>(</span><span>assoc</span> <span>"SORT"</span> <span>alist</span><span>))))</span>
	<span>(</span><span>let</span> <span>((</span><span>sort-spec</span> <span>(</span><span>car</span> <span>(</span><span>read-from-string</span> <span>(</span><span>car</span> <span>sort</span><span>)))))</span>
	  <span>(</span><span>setq-local</span> <span>org-sort-option</span> <span>sort-spec</span><span>))))))</span>

<span>(</span><span>advice-add</span> <span>'org-set-regexps-and-options</span> <span>:after</span> <span>#'</span><span>org-sort-set-option</span><span>)</span>

<span>(</span><span>defun</span> <span>org-sort-run</span> <span>()</span>
  <span>(</span><span>when</span> <span>(</span><span>and</span> <span>(</span><span>derived-mode-p</span> <span>'org-mode</span><span>)</span> <span>org-sort-option</span><span>)</span>
    <span>(</span><span>let</span> <span>((</span><span>case-sensitive</span> <span>nil</span><span>)</span>
	  <span>(</span><span>sorting-type</span> <span>?r</span><span>)</span>
	  <span>(</span><span>getkey-func</span> <span>nil</span><span>)</span>
	  <span>(</span><span>compare-func</span> <span>nil</span><span>)</span>
	  <span>(</span><span>property</span> <span>org-sort-option</span><span>)</span>
	  <span>(</span><span>interactive?</span> <span>nil</span><span>))</span>
      <span>(</span><span>org-sort-entries</span> <span>case-sensitive</span> <span>sorting-type</span> <span>getkey-func</span> <span>compare-func</span> <span>property</span> <span>interactive?</span><span>))))</span>

<span>(</span><span>add-hook</span> <span>'before-save-hook</span> <span>#'</span><span>org-sort-run</span><span>)</span></code></pre></figure>

<p>We keep a buffer-local variable <code>org-sort-option</code> around to store the
property name read from <code>#+SORT: property-name</code>. This variable is initially
<code>nil</code> and will be set from the property name in <code>#+SORT: property-name</code>. To do so
we have a function <code>org-sort-set-option</code>.</p>

<p>But when to call <code>org-sort-set-option</code>? The easy way out is to have Emacs call it whenever
<code>org-set-regexps-and-options</code> is called on a file visit. To achieve this we
tap into <code>advice-add</code> and ask Emacs to run <code>org-sort-set-option</code> after
<code>org-sort-regexps-and-options</code>.</p>

<p>We have now succesfully interposed ourselves in the control flow of the org-mode library.</p>

<p>Org-mode did not provide any interposition point for us, there
is no thought ahead etension-point or configuration variable we can
use to achieve our goal an yet here we are with a sorted buffer.</p>

<p>We succeeded in our effort because <em>Emacs wants you to extend it</em>
and it gives you all the means to do so.</p>

<h2 id="conclusions">Conclusions</h2>

<p>I have made a horrible hack and it works. I have learnt nothing about
how org-mode works or Emacs’ file-visiting extension-points.</p>

  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Polylaminin, a drug considered capable of reversing spinal cord injury (127 pts)]]></title>
            <link>https://www1.folha.uol.com.br/internacional/en/scienceandhealth/2025/09/groundbreaking-brazilian-drug-considered-capable-of-reversing-spinal-cord-injury-presented-in-sao-paulo.shtml</link>
            <guid>45225506</guid>
            <pubDate>Fri, 12 Sep 2025 19:07:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www1.folha.uol.com.br/internacional/en/scienceandhealth/2025/09/groundbreaking-brazilian-drug-considered-capable-of-reversing-spinal-cord-injury-presented-in-sao-paulo.shtml">https://www1.folha.uol.com.br/internacional/en/scienceandhealth/2025/09/groundbreaking-brazilian-drug-considered-capable-of-reversing-spinal-cord-injury-presented-in-sao-paulo.shtml</a>, See on <a href="https://news.ycombinator.com/item?id=45225506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-news-content-text="" data-continue-reading="" data-continue-reading-hide-others=".js-continue-reading-hidden" itemprop="articleBody">
                    <p>From a tender wrapper of human life, the placenta, comes the extraction of a protein that points to a solution for something that, until now, science had no clear path to—and never one so celebrated: restoring the spinal cord in people who suffered injuries and lost body movement.</p><p>Brazilian researcher Tatiana Coelho de Sampaio, PhD professor at the Federal University of Rio de Janeiro, has quietly worked with a team of biologists for the past 25 years on the repairing and multiplying power of the protein laminin, which acts on the nervous system.</p>

<p>The studies ultimately produced the current drug polylaminin, a world first, presented on Tuesday (9) by Cristália laboratory as capable of regenerating the spinal cord in people who suffered organ rupture in accidents of various kinds, leading to paraplegia—paralysis of the lower limbs—or quadriplegia—paralysis of both lower and upper limbs.</p>






<p>During the experimental phase of the antidote, which is applied directly to the spine, patients experienced full recovery of their conditions, with no aftereffects and resuming a routine without restrictions.</p>

<p><u><a href="http://Read%20the%20article%20in%20the%20original%20language" target="_blank">Read the article in the original language</a></u></p>

<div data-newsletter-simple="" data-subscript="7" data-message=".js-message" data-button=".js-button" data-email=".js-email">
    <h4>News from Brazil</h4>
      <p>Receive in your email inbox a summary of the day</p>
    
</div>

                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UTF-8 is a brilliant design (682 pts)]]></title>
            <link>https://iamvishnu.com/posts/utf8-is-brilliant-design</link>
            <guid>45225098</guid>
            <pubDate>Fri, 12 Sep 2025 18:30:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamvishnu.com/posts/utf8-is-brilliant-design">https://iamvishnu.com/posts/utf8-is-brilliant-design</a>, See on <a href="https://news.ycombinator.com/item?id=45225098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article>
    <h2>UTF-8 is a Brilliant Design</h2>
    <time datetime="2025-09-12">2025-09-12</time>
    <meta name="format-detection" content="telephone=no">


<p>The first time I learned about UTF-8 encoding, I was fascinated by how well-thought and brilliantly it was designed to represent millions of characters from different languages and scripts, and <strong>still be backward compatible with ASCII.</strong></p>
<p>Basically UTF-8 uses 32 bits and the old ASCII uses 7 bits, but UTF-8 is designed in such a way that:</p>
<ul>
<li>Every ASCII encoded file is a valid UTF-8 file.</li>
<li>Every UTF-8 encoded file that has only ASCII characters is a valid ASCII file.</li>
</ul>
<p>Designing a system that scales to millions of characters and still be compatible with the old systems that use just 128 characters is a brilliant design.</p>
<blockquote>
<p>Note: If you are already aware of the UTF-8 encoding, you can explore the <a href="https://utf8-playground.netlify.app/" target="_blank" rel="noopener">UTF-8 Playground</a> utility that I built to visualize UTF-8 encoding.</p>
</blockquote>
<h2>How Does UTF-8 Do It?</h2>
<p>UTF-8 is a variable-width character encoding designed to represent every character in the Unicode character set, encompassing characters from most of the world's writing systems.</p>
<p>It encodes characters using <strong>one to four bytes</strong>. </p>
<p>The first 128 characters (<code>U+0000</code> to <code>U+007F</code>) are encoded with a <strong>single byte,</strong> ensuring backward compatibility with ASCII, and this is the reason why a file with only ASCII characters is a valid UTF-8 file.</p>
<p>Other characters require two, three, or four bytes. The <strong>leading bits of the first byte</strong> determine the total number of bytes that represents the current character. These bits follow one of four specific patterns, which indicate how many continuation bytes follow.</p>
<table>
<thead>
<tr>
<th>1st byte Pattern</th>
<th># of bytes used</th>
<th>Full byte sequence pattern</th>
</tr>
</thead>
<tbody><tr>
<td><span>0xxxxxxx</span></td>
<td>1</td>
<td><span>0xxxxxxx</span><br>(This is basically a regular ASCII encoded byte)</td>
</tr>
<tr>
<td><span>110xxxxx</span></td>
<td>2</td>
<td><span>110xxxxx</span> <span>10xxxxxx</span></td>
</tr>
<tr>
<td><span>1110xxxx</span></td>
<td>3</td>
<td><span>1110xxxx</span> <span>10xxxxxx</span> <span>10xxxxxx</span></td>
</tr>
<tr>
<td><span>11110xxx</span></td>
<td>4</td>
<td><span>11110xxx</span> <span>10xxxxxx</span> <span>10xxxxxx</span> <span>10xxxxxx</span></td>
</tr>
</tbody></table>
<p>Notice that the second, third, and fourth bytes in a multi-byte sequence <strong>always start with 10</strong>. This indicates that these bytes are continuation bytes, following the main byte.</p>
<p>The remaining bits in the main byte, along with the bits in the continuation bytes, are combined to form the character's code point. A code point serves as a unique identifier for a character in the Unicode character set. A code point is typically represented in hexadecimal format, prefixed with "U+". For example, the code point for the character "A" is <code>U+0041</code>.</p>
<p>So here is how a software determines the character from the UTF-8 encoded bytes:</p>
<ol>
<li>Read a byte. If it starts with <code>0</code>, it's a single-byte character (ASCII). Show the character represented by the remaiing 7 bits on the screen. Continue with the next byte.</li>
<li>If the byte didn't start with a <code>0</code>, then:<ul>
<li>If it starts with <code>110</code>, it's a two-byte character, so read the next byte as well.</li>
<li>If it starts with <code>1110</code>, it's a three-byte character, so read the next two bytes.</li>
<li>If it starts with <code>11110</code>, it's a four-byte character, so read the next three bytes.</li>
</ul>
</li>
<li>Once the number of bytes are determined, read all the remaining bits except the leading bits, and find the binary value (aka. code point) of the character.</li>
<li>Look up the code point in the Unicode character set to find the corresponding character and display it on the screen.</li>
<li>Read the next byte and repeat the process.</li>
</ol>
<h3>Example: Hindi Letter "अ" (<a href="https://utf8-playground.netlify.app/0905" target="_blank" rel="noopener">open in UTF-8 Playground</a>)</h3>
<p>The Hindi letter "अ" (officially "Devanagari Letter A") is represented in UTF-8 as:</p>
<p><span>11100000</span> <span>10100100</span> <span>10000101</span>
Here:</p>
<p>The first byte <span>11100000</span> indicates that the character is encoded using 3 bytes.</p>
<p>The remaining bits of the three bytes:
<span>xxxx0000</span> <span>xx100100</span> <span>xx000101</span> 
are combined to form the binary sequence <span>00001001</span> <span>00000101</span> (<code>0x0905</code> in hexadecimal). This is the code point of the character, represented as <code>U+0905</code>.</p>
<p>The code point <code>U+0905</code> (<a href="https://www.unicode.org/charts/PDF/U0900.pdf" target="_blank" rel="noopener">see official chart</a>) represents the Hindi letter "अ" in the Unicode character set.</p>
<h2>Example Text Files</h2>
<p>Now that we understood the design of UTF-8, let's look at a file that contains the following text:</p>
<h3>1. Text file contains: <code>Hey👋 Buddy</code></h3>
<p>The text <code>Hey👋 Buddy</code> has both English characters and an emoji character on it. The <a href="https://iamvishnu.com/utf8-samples/text_with_emoji_character.txt">text file</a> with this text saved on the disk will have the following <strong>13 bytes</strong> in it:</p>
<p><span>01001000</span> <span>01100101</span> <span>01111001</span> <span>11110000</span> <span>10011111</span> <span>10010001</span> <span>10001011</span> <span>00100000</span> <span>01000010</span> <span>01110101</span> <span>01100100</span> <span>01100100</span> <span>01111001</span></p>
<p>Let's evaluate this file byte-by-byte following the UTF-8 decoding rules:</p>
<table>
<thead>
<tr>
<th>Byte</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><span>01001000</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1001000</code> represent the letter 'H'. (<a href="https://utf8-playground.netlify.app/0048" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01100101</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1100101</code> represent the letter 'e'. (<a href="https://utf8-playground.netlify.app/0065" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01111001</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1111001</code> represent the letter 'y'. (<a href="https://utf8-playground.netlify.app/0079" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>11110000</span></td>
<td>Starts with <code>11110</code>, indicating it's the <strong>first byte of a four-byte character.</strong></td>
</tr>
<tr>
<td><span>10011111</span></td>
<td>Starts with <code>10</code>, indicating it's a continuation byte.</td>
</tr>
<tr>
<td><span>10010001</span></td>
<td>Starts with <code>10</code>, indicating it's a continuation byte.</td>
</tr>
<tr>
<td><span>10001011</span></td>
<td>Starts with <code>10</code>, indicating it's a continuation byte.<p>The bits from these four bytes (excluding the leading bits) combine to form the binary sequence <span>00001 11110100 01001011</span>, which is <code>1F44B</code> in hexadecimal, corresponds to the code point <code>U+1F44B</code>. This code point represents the waving hand emoji "👋" in the Unicode character set </p><a href="https://utf8-playground.netlify.app/1F44B" target="_blank" rel="noopener">(open in playground)</a>.</td>
</tr>
<tr>
<td><span>00100000</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>0100000</code> represent a whitespace character. (<a href="https://utf8-playground.netlify.app/0020" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01000010</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1000010</code> represent the letter 'B'. (<a href="https://utf8-playground.netlify.app/0042" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01110101</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1110101</code> represent the letter 'u'. (<a href="https://utf8-playground.netlify.app/0075" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01100100</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1100100</code> represent the letter 'd'. (<a href="https://utf8-playground.netlify.app/0064" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01100100</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1100100</code> represent the letter 'd'. (<a href="https://utf8-playground.netlify.app/0064" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01111001</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1111001</code> represent the letter 'y'. (<a href="https://utf8-playground.netlify.app/0079" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
</tbody></table>
<p>Now this is a valid UTF-8 file, but it doesn't have to be "backward compatible" with ASCII because it contains a non-ASCII character (the emoji). Next let's create a file that contains only ASCII characters.</p>
<h3>2. Text file contains: <code>Hey Buddy</code></h3>
<p>The <a href="https://iamvishnu.com/utf8-samples/text_with_ASCII_only.txt">text file</a> doesn't have any non-ASCII characters. The file saved on the disk has the following <strong>9 bytes</strong> in it:</p>
<p><span>01001000</span> <span>01100101</span> <span>01111001</span> <span>00100000</span> <span>01000010</span> <span>01110101</span> <span>01100100</span> <span>01100100</span> <span>01111001</span></p>
<p>Let's evaluate this file byte-by-byte following the UTF-8 decoding rules:</p>
<table>
<thead>
<tr>
<th>Byte</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td><span>01001000</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1001000</code> represent the letter 'H'. (<a href="https://utf8-playground.netlify.app/0048" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01100101</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1100101</code> represent the letter 'e'. (<a href="https://utf8-playground.netlify.app/0065" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01111001</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1111001</code> represent the letter 'y'. (<a href="https://utf8-playground.netlify.app/0079" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>00100000</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>0100000</code> represent a whitespace character. (<a href="https://utf8-playground.netlify.app/0020" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01000010</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1000010</code> represent the letter 'B'. (<a href="https://utf8-playground.netlify.app/0042" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01110101</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1110101</code> represent the letter 'u'. (<a href="https://utf8-playground.netlify.app/0075" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01100100</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1100100</code> represent the letter 'd'. (<a href="https://utf8-playground.netlify.app/0064" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01100100</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1100100</code> represent the letter 'd'. (<a href="https://utf8-playground.netlify.app/0064" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
<tr>
<td><span>01111001</span></td>
<td>Starts with <code>0</code>, so it's a single-byte ASCII character. The remaining bits <code>1111001</code> represent the letter 'y'. (<a href="https://utf8-playground.netlify.app/0079" target="_blank" rel="noopener">open in playground</a>)</td>
</tr>
</tbody></table>
<p>So this is a valid UTF-8 file, <strong>and it is also a valid ASCII file</strong>. The bytes in this file follows both the UTF-8 and ASCII encoding rules. This is how UTF-8 is designed to be backward compatible with ASCII.</p>
<h2>Other Encodings</h2>
<p>I did a quick research on any other encoding that are backward compatible with ASCII, and there are a few, but they are not as popular as UTF-8, for example GB 18030 (a Chinese government standard). Another one is the ISO/IEC 8859 encodings are single-byte encodings that extend ASCII to include additional characters, but they are limited to 256 characters.</p>
<p>The siblings of UTF-8, like UTF-16 and UTF-32, are not backward compatible with ASCII. For example, the letter 'A' in UTF-16 is represented as: <code>00 41</code> (two bytes), while in UTF-32 it is represented as: <code>00 00 00 41</code> (four bytes).</p>
<h2>Bonus: UTF-8 Playground</h2>
<p>When I was exploring the UTF-8 encoding, I couldn't find any good tool to interactively visualize how UTF-8 encoding works. So I built <strong>UTF-8 Playground</strong> to visualize and play around with UTF-8 encoding. <a href="https://utf8-playground.netlify.app/1F44B" target="_blank" rel="noopener">Give it a try!</a>.</p>

    <p>
        <a href="https://iamvishnu.com/tags/tech/" rel="tag">#tech</a>
        <a href="https://iamvishnu.com/tags/history/" rel="tag">#history</a>
        <a href="https://iamvishnu.com/tags/programming/" rel="tag">#programming</a>
    </p>
</article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU court rules nuclear energy is clean energy (906 pts)]]></title>
            <link>https://www.weplanet.org/post/eu-court-rules-nuclear-energy-is-clean-energy</link>
            <guid>45224967</guid>
            <pubDate>Fri, 12 Sep 2025 18:18:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.weplanet.org/post/eu-court-rules-nuclear-energy-is-clean-energy">https://www.weplanet.org/post/eu-court-rules-nuclear-energy-is-clean-energy</a>, See on <a href="https://news.ycombinator.com/item?id=45224967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="ltr" data-id="content-viewer" data-rce-version="10.141.4" data-hook="post-description"><div id="viewer-ua0iq295" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="ua0iq295" data-hook="image-viewer"><wow-image id="dccfdc_1744e9223bae4f338ddd5d15499c1763~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;ua0iq295&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:9504,&quot;height&quot;:6336,&quot;uri&quot;:&quot;dccfdc_1744e9223bae4f338ddd5d15499c1763~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur=""><img src="https://static.wixstatic.com/media/dccfdc_1744e9223bae4f338ddd5d15499c1763~mv2.jpg/v1/fill/w_147,h_98,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/dccfdc_1744e9223bae4f338ddd5d15499c1763~mv2.jpg" alt="Youth climate activists sit with a sign reading Dear Greenpeace You can't power the future with hope." data-pin-url="https://www.weplanet.org/post/eu-court-rules-nuclear-energy-is-clean-energy" data-pin-media="https://static.wixstatic.com/media/dccfdc_1744e9223bae4f338ddd5d15499c1763~mv2.jpg/v1/fill/w_5000,h_3333,al_c,q_90,usm_0.66_1.00_0.01/dccfdc_1744e9223bae4f338ddd5d15499c1763~mv2.jpg" draggable="false"></wow-image></div><div id="viewer-c161e298"><p><figcaption><span>Launching Dear Greenpeace back in 2023</span></figcaption></p></div></figure></div><p dir="auto" id="viewer-n7zk6396"><span><span>When I launched </span><a target="_blank" href="https://www.weplanet.org/deargreenpeace" rel="noopener noreferrer" data-hook="web-link"><span><u><span>Dear Greenpeace</span></u></span></a><span> with my fellow youth climate activists alongside WePlanet two years ago, I had no idea just how quickly the anti-nuclear dominoes would fall across Europe. </span></span></p><p dir="auto" id="viewer-88h61415"><span><span>In 2023, and what seems like a lifetime ago, Austria launched their legal action against the European Commission for the inclusion of nuclear energy in the EU Sustainable Finance Taxonomy. At the time they were supported by a bulwark of EU countries and environmental NGOs that opposed nuclear energy. Honestly, it looked like they might win.</span></span></p><p dir="auto" id="viewer-ryc0x156"><span><span>But today, that whole landscape has changed.</span></span></p><p dir="auto" id="viewer-bw9py159"><span><span>Germany, long a symbol of anti-nuclear politics, is beginning to shift. The nuclear phase-outs or bans in the Netherlands, Belgium, Switzerland, Denmark, and Italy are now history. Even Fridays for Future has quietened its opposition, and in some places, embraced nuclear power.</span></span></p><p dir="auto" id="viewer-9x3x3163"><span><span>This moment matters.</span></span></p><p dir="auto" id="viewer-b4w0x166"><span><span>It shows what’s possible when we stick to the science. The evidence only gets clearer by the day that nuclear energy has an extremely low environmental impact across its lifecycle, and strong regulations and safety culture ensure that it remains one of the safest forms of energy available to humanity. </span></span></p><p dir="auto" id="viewer-2amni169"><span><span>The European Court of Justice has now fully dismissed Austria’s lawsuit. That ruling doesn’t just uphold nuclear energy’s place in EU green finance rules. It also signals a near-certain defeat for the ongoing Greenpeace case – the very lawsuit that inspired me to launch Dear Greenpeace in the first place.</span></span></p><p dir="auto" id="viewer-s1mp7538"><span><span>But instead of learning from this, Greenpeace is doubling down. Martin Kaiser, Executive Director of Greenpeace Germany, called the court decision “a dark day for the climate”.</span></span></p><p dir="auto" id="viewer-hnk62579"><span><span>Let that sink in. The highest court in the EU just reaffirmed that nuclear energy meets the scientific and environmental standards to be included in sustainable finance, and Greenpeace still refuses to budge.</span></span></p><p dir="auto" id="viewer-kjw4h560"><span><span>Meanwhile, the climate crisis gets worse. Global emissions are not falling fast enough. Billions of people still lack access to clean, reliable electricity. And we are forced to spend time defending proven solutions instead of scaling them.</span></span></p><div id="viewer-3ae5f638" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="3ae5f638" data-hook="image-viewer"><wow-image id="5caaac_7a93e55d745a4c13a57e7cf2c6f3fb8a~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;3ae5f638&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:4521,&quot;height&quot;:3442,&quot;uri&quot;:&quot;5caaac_7a93e55d745a4c13a57e7cf2c6f3fb8a~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur=""><img src="https://static.wixstatic.com/media/5caaac_7a93e55d745a4c13a57e7cf2c6f3fb8a~mv2.jpg/v1/fill/w_147,h_112,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/5caaac_7a93e55d745a4c13a57e7cf2c6f3fb8a~mv2.jpg" alt="Youth Climate Activists stand with a sign saying Fight Fossils Not Nuclear." data-pin-url="https://www.weplanet.org/post/eu-court-rules-nuclear-energy-is-clean-energy" data-pin-media="https://static.wixstatic.com/media/5caaac_7a93e55d745a4c13a57e7cf2c6f3fb8a~mv2.jpg/v1/fill/w_4521,h_3442,al_c,q_90/5caaac_7a93e55d745a4c13a57e7cf2c6f3fb8a~mv2.jpg" draggable="false"></wow-image></div><div id="viewer-xdow6652"><p><figcaption><span>Announcing our inclusion in the case between Greenpeace and the EU Commission</span></figcaption></p></div></figure></div><p dir="auto" id="viewer-depjh684"><span><span>It’s now up to the court whether we will get our time in court to outline the evidence in support of nuclear energy and the important role it can play in the global clean energy transition. Whether in court, on the streets, or in the halls of parliaments across the globe, we will be there to defend the science and ensure that nuclear power can spread the advantages of the modern world across the planet in a sustainable, reliable and dignified way.</span></span></p><p dir="auto" id="viewer-szxti181"><span><span>Austria stands increasingly isolated among a handful of countries that still cling to their opposition to nuclear energy. Their defeat in this vital high stakes topic is a success not just for the nuclear movement, but for the global transition as a whole. </span></span></p><p dir="auto" id="viewer-tvkcu260"><span><span>We have made real progress. Together, we’ve helped defend nuclear power in the EU, overturned outdated policies at the World Bank, and secured more technology-neutral language at the UN. These wins are not abstract. They open the door to real investment, real projects, and real emissions cuts.</span></span></p><p dir="auto" id="viewer-5dxe6243"><span><span>But the work is not done.</span></span></p><p dir="auto" id="viewer-a2l0l226"><span><span>We still need to overturn national nuclear bans, unlock more funding, and push democratic countries to support clean energy development abroad: especially where it is most needed to compete with Russia’s growing influence.</span></span></p><p dir="auto" id="viewer-u71i5190"><span><span>The fight will not be done until every single country in the world can boast a clean, reliable energy grid, ready to maintain a modern dignified standard of living, for everyone, everywhere.</span></span></p><p dir="auto" id="viewer-ifug7193"><span><span>This is a great success for the movement and it would not have been possible without the financial support, time and energy given by people like you.</span></span></p><p dir="auto" id="viewer-mcpu5961"><span><span>In Solidarity,</span><span>
</span><span>Ia Aanstoot</span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An embarrassing failure of the US patent system: Nintendo's latest patents (116 pts)]]></title>
            <link>https://www.pcgamer.com/gaming-industry/an-embarrassing-failure-of-the-us-patent-system-videogame-ip-lawyer-says-nintendos-latest-patents-on-pokemon-mechanics-should-not-have-happened-full-stop/</link>
            <guid>45224901</guid>
            <pubDate>Fri, 12 Sep 2025 18:11:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/gaming-industry/an-embarrassing-failure-of-the-us-patent-system-videogame-ip-lawyer-says-nintendos-latest-patents-on-pokemon-mechanics-should-not-have-happened-full-stop/">https://www.pcgamer.com/gaming-industry/an-embarrassing-failure-of-the-us-patent-system-videogame-ip-lawyer-says-nintendos-latest-patents-on-pokemon-mechanics-should-not-have-happened-full-stop/</a>, See on <a href="https://news.ycombinator.com/item?id=45224901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-1852-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj.jpg" alt="Big Pikachu" srcset="https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-1852-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/Qg8v9Hx9dkVQAS6pwVHaBj.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Nintendo)</span>
</figcaption>
</div>

<div id="article-body">
<p id="e18f1086-e0a0-4382-8402-f4212a99c750">The last 10 days have brought a string of patent wins for Nintendo. Yesterday, the company was granted <a data-analytics-id="inline-link" href="https://archive.org/details/12409387" data-url="https://archive.org/details/12409387" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">US patent 12,409,387</a>, a patent covering riding and flying systems similar to those Nintendo has been criticized for claiming in its Palworld lawsuit (via <a data-analytics-id="inline-link" href="https://gamesfray.com/last-week-nintendo-and-the-pokemon-company-received-a-u-s-patent-on-summoning-a-character-and-letting-it-fight-another/" data-url="https://gamesfray.com/last-week-nintendo-and-the-pokemon-company-received-a-u-s-patent-on-summoning-a-character-and-letting-it-fight-another/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Gamesfray</a>). Last week, however, Nintendo received a more troubling weapon in its legal arsenal: <a data-analytics-id="inline-link" href="https://archive.org/details/12403397" data-url="https://archive.org/details/12403397" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">US patent 12,403,397</a>, a patent on summoning and battling characters that the United States Patent and Trademark Office granted with alarmingly little resistance.</p><div><p>According to videogame patent lawyer Kirk Sigmon, the USPTO granting Nintendo these latest patents isn't just a moment of questionable legal theory. It's an indictment of American patent law.</p><p>"Broadly, I don't disagree with the many online complaints about these Nintendo patents," said Sigmon, whose opinions do not represent those of his firm and clients. "They have been an embarrassing failure of the US patent system."</p></div><figure data-bordeaux-image-check="" id="32ead01e-7b59-4a59-94fa-8c3859d8d1ab"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik.jpg" alt="Patent illustration from US patent 12,403,397" srcset="https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/ZEcEqmALbVDVHfLWRPq7ik.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nintendo, USPTO)</span></figcaption></figure><p id="f63cf596-a844-4bf3-b671-4c611887fa39">Sigmon, who we spoke with last year about the <a data-analytics-id="inline-link" href="https://www.pcgamer.com/games/survival-crafting/a-videogame-patent-lawyer-breaks-down-nintendos-risky-palworld-lawsuit-it-definitely-feels-like-a-punishment/" data-before-rewrite-localise="https://www.pcgamer.com/games/survival-crafting/a-videogame-patent-lawyer-breaks-down-nintendos-risky-palworld-lawsuit-it-definitely-feels-like-a-punishment/">claims and potential consequences of Nintendo's Palworld lawsuit</a>, said both this week's '387 patent and last week's '397 represent procedural irregularities in the decisionmaking of US patent officials. And thanks to those irregularities, Nintendo has yet more tools to bully its competitors.</p><p id="f63cf596-a844-4bf3-b671-4c611887fa39-1">The '387 patent granted this week, Sigmon told PC Gamer, "got a bit of push-back, but barely." After its initial application was deemed invalid due to similarities to existing Tencent and Xbox-related patents, Nintendo amended its claims based on interviews with the USPTO, which then determined that the claims were allowable "for substantially the same reasons as parent application(s)."</p><p>"That parent case," Sigmon said, "had an even weirder and much less useful prosecution history."</p><figure data-bordeaux-image-check="" id="a05d34ba-712d-4211-89a0-1a79fab0f9bb"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA.jpg" alt="Patent illustration from US patent 12,403,397" srcset="https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/k75qiqXfhmQG6dZshCN2ZA.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nintendo, USPTO)</span></figcaption></figure><p id="714e6976-de52-488f-8ac6-44f8fbf1f92f">Most of the claims made in the '387 patent's single parent case, <a data-analytics-id="inline-link" href="https://patents.google.com/patent/US12246255B2/" data-url="https://patents.google.com/patent/US12246255B2/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">US Pat. No. 12,246,255</a>, were immediately allowed by the USPTO, which Sigmon said is "a <em>very </em>unusual result: most claims are rejected <em>at least </em>once." When the claims were ultimately allowed, the only reasoning the USPTO offered was a block quote of text <em>from the claims themselves.</em></p><p>"This seems like a situation where the USPTO essentially gave up and just allowed the case, assuming that the claims were narrow or specific enough to be new without evaluating them too closely," Sigmon said. "I strongly disagree with this result: In my view, these claims were in no way allowable."</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-qfLmvJYDoQ5e3hzZJNA4FY"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div><p>To Sigmon, an IP attorney with extensive experience in prosecuting and teaching patent law, the '387 patent and its parent case rely on concepts and decisions that would have been obvious to a "Person of Ordinary Skill in the Art"—a legal construct that holds if a patent's claims would reasonably occur to a practitioner in the relevant field based on prior art, those claims aren't patentable.</p><figure data-bordeaux-image-check="" id="c08b7f3e-021b-49b2-b762-54e65608d09a"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK.jpg" alt="Patent illustration from US patent filing 12,403,397" srcset="https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/DZ4Li7tuTJXTqLYDh3fiwK.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nintendo, USPTO)</span></figcaption></figure><p id="63d6f577-431a-420f-94cd-84948319dc22">The '397 patent granted last week is even more striking. It's a patent on summoning and battling with "sub-characters," using specific language suggesting it's based on the <a data-analytics-id="inline-link" href="https://serebii.net/scarletviolet/letsgo.shtml" data-url="https://serebii.net/scarletviolet/letsgo.shtml" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Let's Go! mechanics</a> in the Pokémon Scarlet and Violet games. Despite its relevance to a conceit in countless games—calling characters to battle enemies for you—it was allowed without any pushback whatsoever from the USPTO, which Sigmon said is essentially unheard of.</p><p>"Like the above case, the reasons for allowance don't give us even a hint of why it was allowed: the Examiner just paraphrases the claims (after block quoting them) without explaining <em>why </em>the claims are allowed over the prior art," Sigmon said. "This is extremely unusual and raises a large number of red flags."</p><p>According to Sigmon, USPTO records show that the allowance of the '397 patent was based on a review of a relatively miniscule number of documents: 16 US patents, seven Japanese patents, and—apparently—one article from <a data-analytics-id="inline-link" href="http://pokemon.com/" data-url="http://pokemon.com" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Pokemon.com</a>.</p><figure data-bordeaux-image-check="" id="2aac727e-7e22-4301-ac42-ff1b56914a36"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX.jpg" alt="Patent illustration from US pokemon battling patent" srcset="https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/a4RJFD8KMXWdcr2wAe8vdX.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nintendo, USPTO)</span></figcaption></figure><p id="f51dc458-4f5c-4b38-a306-40e60029f485">"I have no earthly idea how the Examiner could, in good faith, allow this application so quickly," Sigmon said.</p><p>Admittedly, the '397 case was originally filed as a Japanese patent application, which <em>would </em>allow the Examiner to use the existing progress in the Japanese case as a starting point for their review. But, Sigmon said, "even that doesn't excuse this quick allowance."</p><p>"This allowance should not have happened, full stop," he said.</p><p>On paper, the patent might not seem like a threat to Nintendo's competitors: The claims as constructed in the '397 outline a very specific sequence of events and inputs, and patent claims must be met word-for-word to be infringed.</p><p>"Pragmatically speaking, though, it's not impossible to be sued for patent infringement even when a claim infringement argument is weak, and bad patents like this cast a massive shadow on the industry," Sigmon said.</p><p>For a company at Nintendo's scale, the claims of the '397 patent don't need to make for a strong argument that would hold up in court. The threat of a lawsuit can stifle competition well enough on its own when it would cost millions of dollars to defend against.</p><figure data-bordeaux-image-check="" id="6364beec-6fe7-4072-bc4c-d9fe8f5c985a"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj.jpg" alt="Diagram of sub-character summoning in Nintendo pokemon battling patent" srcset="https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/JWxEbdDpMBHnURVfNsLjrj.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nintendo, USPTO)</span></figcaption></figure><p id="3a603513-757f-4427-81b2-edc6d3e7c300">"In my opinion, none of the three patents I've discussed here should have been allowed. It's shocking and offensive that they were," Sigmon said. "The USPTO dropped the ball big time, and it's going to externalize a lot of uncertainty (and, potentially, litigation cost) onto developers and companies that do not deserve it."</p><p>Sigmon, who says he's helped inventors protect their inventions from IP theft perpetrated by major companies, insists that the patent system still has merit. "That's the kind of thing that patents are meant to do," he said. "They were not made to allow a big player to game the system, get an overly broad patent that they should have never received in the first place, and then go around bullying would-be competition with the threat of a legally questionable lawsuit."</p><p>Unfortunately, Nintendo has gained these patents at a moment when the USPTO has made challenging bad patents more difficult. Currently, US patent officials under USPTO Acting Director Coke Morgan Stewart have been <a data-analytics-id="inline-link" href="https://www.jdsupra.com/legalnews/ipr-discretionary-denial-rates-at-the-5772745/" data-url="https://www.jdsupra.com/legalnews/ipr-discretionary-denial-rates-at-the-5772745/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">refusing to hear a huge number of Inter Partes Review cases</a>—special proceedings in which parties can argue that a patent should never have been granted—for "discretionary" reasons.</p><p>"Realistically, this means that patent validity issues are being relegated to lawsuits: not a good situation, as that often entails millions of dollars in costs and a lot of risk," Sigmon said. "In practice, this means that bad patents get to fester on the market for longer and provide a bigger threat for the industry as a whole."</p>
</div>

<div id="slice-container-authorBio-qfLmvJYDoQ5e3hzZJNA4FY"><p>Lincoln has been writing about games for 11 years—unless you include the essays about procedural storytelling in Dwarf Fortress he convinced his college professors to accept. Leveraging the brainworms from a youth spent in World of Warcraft to write for sites like Waypoint, Polygon, and Fanbyte, Lincoln spent three years freelancing for PC Gamer before joining on as a full-time News Writer in 2024, bringing an expertise in Caves of Qud bird diplomacy, getting sons killed in Crusader Kings, and hitting dinosaurs with hammers in Monster Hunter.</p></div>
</section>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Epistemic Collapse at the WSJ (125 pts)]]></title>
            <link>https://www.math.columbia.edu/~woit/wordpress/?p=15206</link>
            <guid>45224649</guid>
            <pubDate>Fri, 12 Sep 2025 17:46:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.math.columbia.edu/~woit/wordpress/?p=15206">https://www.math.columbia.edu/~woit/wordpress/?p=15206</a>, See on <a href="https://news.ycombinator.com/item?id=45224649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-15206">
					

					<!-- .entry-meta -->

					<div>
						<p>For a long time now fundamental theoretical physics has been suffering not just from a slowdown in progress, but from a sort of intellectual collapse (I wrote about this <a href="https://www.math.columbia.edu/~woit/wordpress/?p=14999">here</a> a while back in the context of “epistemic collapse”: the collapse of a shared reality, caused by the loss of reliable sources for distinguishing what is true from what is false.). The Wall Street Journal has a new article entitled <a href="https://www.wsj.com/science/physics/the-rise-of-conspiracy-physics-dd79fe36">The Rise of ‘Conspiracy Physics’</a> with summary:</p>
<blockquote><p>Streamers are building huge audiences by attacking academic physics as just another corrupt establishment. Scientists are starting to worry about the consequences.</p></blockquote>
<p>If you replaced “Streamers” by “Sabine Hossenfelder” this would be reasonably accurate, and a serious discussion of this would have been interesting and worthwhile.  Instead, the article is an excellent example of the sort of epistemic collapse we’re now living in.  There’s zero intelligent content about the underlying scientific issues (is fundamental theoretical physics in trouble?), just a random collection of material about podcasts, written by someone who clearly knows nothing about the topic he’s writing about.  The epistemic collapse is total when traditional high-quality information sources like the Wall Street Journal are turned over to uninformed writers getting their information from Joe Rogan podcasts. Any hope of figuring out what is true and what is false is now completely gone.</p>
<p>I was planning on writing something explaining what exactly the WSJ story gets wrong, but now realize this is hopeless (and I’m trying to improve my mental health this week, not make it worse).  Sorting through a pile of misinformation, trying to rebuild something true out of a collapsed mess of some truth buried in a mixture of nonsense and misunderstandings is a losing battle.</p>
<p>Maybe some day our information environment will become healthy again, but for now I’m not sure what to do about this.   Be aware that if you’re trying to understand the state of fundamental theoretical physics, watching Joe Rogan, Piers Morgan, Professor Dave, etc. podcasts is just going to fill your mind with crap. Reading articles about these podcasts is worse. If a podcaster (e.g. Sabine Hossenfelder) has a book, read the book (Lost in Math is pretty good) rather than watching the podcasts.  In general, reading books is a good idea (I can also recommend <a href="https://www.amazon.com/gp/product/0465092756">this one</a>). </p>
<p><strong>Update:</strong>  John Baez comments <a href="https://mathstodon.xyz/@johncarlosbaez/115187879181381057">here</a>:</p>
<blockquote><p>This quagmire is getting bigger.  It’s another part of what William Gibson recently called the Singularity of Stupid.</p></blockquote>
											</div><!-- .entry-content -->

		
						<div><p>
							This entry was posted in <a href="https://www.math.columbia.edu/~woit/wordpress/?cat=1" rel="category">Uncategorized</a>. Bookmark the <a href="https://www.math.columbia.edu/~woit/wordpress/?p=15206" title="Permalink to Epistemic Collapse at the WSJ" rel="bookmark">permalink</a>.													</p></div><!-- .entry-utility -->
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How FOSS Projects Handle Legal Takedown Requests (137 pts)]]></title>
            <link>https://f-droid.org/2025/09/10/how-foss-projects-handle-legal-takedown-requests.html</link>
            <guid>45224421</guid>
            <pubDate>Fri, 12 Sep 2025 17:22:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://f-droid.org/2025/09/10/how-foss-projects-handle-legal-takedown-requests.html">https://f-droid.org/2025/09/10/how-foss-projects-handle-legal-takedown-requests.html</a>, See on <a href="https://news.ycombinator.com/item?id=45224421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>When a legal takedown request arrives, whether it’s about copyright,
censorship, privacy, or something more vague, how a Free and Open Source
Software (FOSS) project responds can make all the difference.</p>

<p>Handled well, a takedown request can be a manageable administrative step. Handled poorly, it can cause panic, disrupt infrastructure, or even put contributors at legal risk.</p>

<p>As part of our legal resilience research, we spoke with a range of legal experts, software freedom advocates, and maintainers of mature FOSS infrastructure to understand how others manage these moments. In this article, we share what we learned, and how F-Droid is incorporating these lessons into its own approach.</p>

<h2 id="a-pattern-emerges">A Pattern Emerges</h2>

<p>Despite differences in jurisdiction, size, and mission, a few common themes
from our research emerged when we asked how other projects handle takedown
requests:</p>

<h3 id="1-dont-be-a-soft-target">1. Don’t Be a Soft Target</h3>

<p>Legal threats often follow the path of least resistance. FOSS projects that
publish a formal takedown policy, require legal submissions through specific
channels, and insist on a valid legal basis are much less likely to receive,
or comply with, vague or harassing demands.</p>

<p>One FOSS organization, for example, requires all legal correspondence to be submitted by postal mail in the national language and citing local law. Most complaints evaporate once asked to comply.</p>

<h3 id="2-creating-a-transparent-and-documented-process">2. Creating a transparent and documented process</h3>

<p>Several digital rights organizations advised setting up structured response
steps:</p>

<ul>
  <li>Require submissions to a dedicated legal@ or abuse@ email.</li>
  <li>Insist on full documentation: legal basis, jurisdiction, evidence of the
infringement and identity of the complainant.</li>
  <li>Review for sufficiency, proportionality, and standing before acting.</li>
</ul>

<p>This creates proper documentation to process valid claims, while protecting projects from illegitimate or unfounded requests.</p>

<h3 id="3-use-jurisdiction-strategically">3. Use Jurisdiction Strategically</h3>

<p>Projects based in civil law jurisdictions, particularly in Europe, are often
better positioned to deflect legal demands from foreign entities. Several
organizations emphasized that complying with vague or extrajudicial
requests, especially those originating outside your jurisdiction, can
increase risk unnecessarily. Instead, they recommended requiring a valid
legal basis grounded in the project’s home country. Formal legal processes,
such as court orders or official government channels, were seen as the
appropriate threshold, not informal emails or unverifiable demands.</p>

<h2 id="notification-and-appeals-fairness-and-transparency">Notification and Appeals: Fairness and Transparency</h2>

<p>All of the projects we consulted emphasized the importance of notifying
developers whose apps are being targeted, informing them (if possible) of
the seriousness of the claim, and the proposed strategy F-Droid is taking to
handle the claim.&nbsp;</p>

<p>If a threat is deemed to be valid and a developer’s content is flagged for
takedown:</p>

<ul>
  <li>The developer or maintainer is informed, unless prohibited by law (gag
orders).</li>
  <li>A window for response (commonly 14 days) is offered, unless unfeasible due
to seriousness and time restraints of the request itself</li>
  <li>If the developer disputes the claim and provides supporting information
(e.g. license, public domain status, fair use justification), the claim is
reviewed.</li>
  <li>If the claim is upheld, the content is removed, but always with an
internal record and opportunity to appeal.</li>
</ul>

<p>This mirrors principles embedded in international norms (like the <a href="https://manilaprinciples.org/principles.html">Manila Principles</a> and <a href="https://docs.github.com/en/site-policy/content-removal-policies/dmca-takedown-policy">GitHub’s DMCA takedown policy</a>) and avoids overcompliance with weak or abusive claims.</p>

<h2 id="transparency-censorship-and-what-you-can-legally-publish">Transparency, Censorship, and What You Can (Legally) Publish</h2>

<p>Takedown requests occupy a complex space between legal enforcement and
censorship. While some are legitimate claims, like copyright violations or
privacy breaches, others are vague, politically motivated, or intended to
silence dissent. For FOSS projects that have a global user base, it’s not
always obvious how to respond. Complying too quickly can reinforce
censorship practices; resisting without process can lead to full website
shut downs, <a href="https://dn.org/government-influence-on-dns-through-domain-seizures-and-takedowns/">domain names being taken
away</a>
(as in the US) or <a href="https://calyxinstitute.org/about/press/2010-merrill-speaks-at-27th-CCC-berlin">large and costly legal
battles</a>.</p>

<p>One strategy that helps balance this tension is radical
transparency. Several projects we spoke with emphasized the importance of
documenting what actions were taken and why, not just for accountability,
but as a form of resistance. A well-known example is GitHub’s DMCA takedown
policy (as of July 2025), which mandates compliance with valid takedown
requests, but also posts each one publicly in their <a href="https://github.com/github/dmca">github/dmca
repository</a>. The result: potential abusers
know their requests will face public scrutiny, which acts as a deterrent.</p>

<p>However, not all jurisdictions allow this kind of transparency. In India,
for example, we were informed that it is often illegal to disclose that you
have received a government request, even to the developer of the affected
app. In contrast, in Russia, takedown requests can often be <a href="https://reestr.rublacklist.net/en/">legally
posted</a>, though by doing so you may be
putting yourself at risk for retaliation, additional takedown requests and
legal troubles.</p>

<p>With that in mind, some best practices for FOSS projects include:</p>

<ul>
  <li>Publishing biannual transparency reports, even if redacted or aggregated.</li>
  <li>Maintaining an internal log of all takedown activity, with public
disclosure where legally possible.</li>
  <li>Explaining the general reasons for content removals, who made the request,
under what law, and what action was taken, unless legally prohibited.</li>
  <li>Being explicit about what cannot be shared, and why.</li>
</ul>

<p>Transparency won’t prevent all forms of censorship, but it can slow them
down, raise awareness, and provide a record that strengthens the broader
FOSS ecosystem.</p>

<h2 id="what-were-doing-at-f-droid">What We’re Doing at F-Droid</h2>

<p>F-Droid is revising its own takedown policy, informed by:</p>

<ul>
  <li>Dutch law and EU regulations</li>
  <li>The structural support provided by The Commons Conservancy</li>
  <li>Practical lessons from long-standing FOSS organizations</li>
</ul>

<p>Our draft process includes:</p>

<ol>
  <li>Written takedown submission request to legal@f-droid.org including the
   required information.:</li>
</ol>

<ul>
  <li>Identify the specific material in question (e.g. app name)</li>
  <li>Include valid legal basis under applicable jurisdiction (e.g. copyright
  law, court order statutory basis)</li>
  <li>Indicate jurisdiction in which the legal basis is claimed to apply</li>
  <li>Include sufficient evidence of the alleged infringement (e.g. copyright
  certificate, ownership declaration)</li>
  <li>Clearly state that the complaintant is authorized to act on behalf of the
  rights holder</li>
  <li>Include full contact details and a verifiable identity (subject to
  exceptions, such as gag orders or whistleblower protection)</li>
</ul>

<ol>
  <li>Verification of jurisdiction and legal basis, including evidence</li>
  <li>Developer notification and appeal procedures</li>
  <li>Rejection of requests lacking documentation or legal authority may be
   rejected or ignored</li>
  <li>Biannual transparency reports and public tracking of takedown requests</li>
</ol>

<p>We’re also working to improve contributor education about potential exposure
when contributing to F-Droid, document internal escalation paths, and ensure
consistent handling of international claims.</p>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>Takedown requests are not going away in fact, they’re becoming more frequent
and more complex. But FOSS projects don’t have to face them unprepared.</p>

<p>By building processes, establishing clear jurisdiction, and protecting individuals through structure and policy, we can handle these challenges with the seriousness they deserve without letting them derail our mission.</p>

<h2 id="legal-disclaimer">Legal Disclaimer</h2>

<p>The content provided in this article is for informational purposes only and
does not constitute legal advice. While we strive to provide accurate and
up-to-date information, F-Droid makes no representations or warranties of
any kind, express or implied, about the completeness, accuracy, or
suitability of the information contained herein.</p>

<p>F-Droid is not a law firm and does not offer legal services. Any reliance
you place on the information provided is strictly at your own risk. If you
have questions about legal obligations, rights, or compliance, we strongly
recommend consulting a qualified legal professional familiar with your
jurisdiction.</p>

<p>F-Droid and its contributors disclaim all liability for any loss or damage
arising from the use or misuse of this content.</p>

  </div>

</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[QGIS is a free, open-source, cross platform geographical information system (479 pts)]]></title>
            <link>https://github.com/qgis/QGIS</link>
            <guid>45224156</guid>
            <pubDate>Fri, 12 Sep 2025 16:57:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/qgis/QGIS">https://github.com/qgis/QGIS</a>, See on <a href="https://news.ycombinator.com/item?id=45224156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/qgis/QGIS/blob/master/images/README-md/main_logo.png"><img src="https://github.com/qgis/QGIS/raw/master/images/README-md/main_logo.png" width="300"></a></p>
<p dir="auto"><a href="https://github.com/qgis/QGIS/actions/workflows/run-tests.yml?query=branch%3Amaster+event%3Apush"><img src="https://github.com/qgis/QGIS/actions/workflows/run-tests.yml/badge.svg" alt="🧪 QGIS tests"></a>
<a href="https://hub.docker.com/r/qgis/qgis/tags" rel="nofollow"><img src="https://camo.githubusercontent.com/7479f1416cefaf1fb2aef1e41ee07620277a2cda1409bfb2d49b2fc7e6342f0d/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f6175746f6d617465642f716769732f716769732e737667" alt="Docker Status" data-canonical-src="https://img.shields.io/docker/automated/qgis/qgis.svg"></a>
<a href="https://dev.azure.com/qgis/QGIS/_build/latest?definitionId=1&amp;branchName=master" rel="nofollow"><img src="https://camo.githubusercontent.com/6018bbe5616d615cfae2a5b8468eabdf637715d73641cedfb748b89d3b2ea727/68747470733a2f2f6465762e617a7572652e636f6d2f716769732f514749532f5f617069732f6275696c642f7374617475732f716769732e514749533f6272616e63684e616d653d6d6173746572" alt="Build Status" data-canonical-src="https://dev.azure.com/qgis/QGIS/_apis/build/status/qgis.QGIS?branchName=master"></a>
<a href="https://securityscorecards.dev/viewer/?uri=github.com/qgis/QGIS" rel="nofollow"><img src="https://camo.githubusercontent.com/78f8a15ac0c16f8d566c8873db83e54641fbe6651878f352d21edd7177fcc857/68747470733a2f2f6170692e736563757269747973636f726563617264732e6465762f70726f6a656374732f6769746875622e636f6d2f716769732f514749532f6261646765" alt="OpenSSF Scorecard" data-canonical-src="https://api.securityscorecards.dev/projects/github.com/qgis/QGIS/badge"></a>
<a href="https://www.bestpractices.dev/projects/1581" rel="nofollow"><img src="https://camo.githubusercontent.com/72f1c97496354fc098765cd411c4cfa4a1d4995de93c713dca34493e93803d04/68747470733a2f2f7777772e626573747072616374696365732e6465762f70726f6a656374732f313538312f6261646765" alt="OpenSSF Best Practices" data-canonical-src="https://www.bestpractices.dev/projects/1581/badge"></a>
<a href="https://github.com/qgis/QGIS/actions/workflows/mingw64.yml?query=branch%3Amaster+event%3Apush"><img src="https://github.com/qgis/QGIS/actions/workflows/mingw64.yml/badge.svg" alt="🪟 MingW64 Windows 64bit Build"></a>
<a href="https://doi.org/10.5281/zenodo.5869837" rel="nofollow"><img src="https://camo.githubusercontent.com/85acebb9718a81d9772f3fe57a92af1c29abc98c8c308d00c8ae2d87ea89ab91/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e353836393833372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.5869837.svg"></a></p>
<p dir="auto">QGIS is a full-featured, user-friendly, free-and-open-source (FOSS) geographical information system (GIS) that runs on Unix platforms, Windows, and MacOS.</p>

<ul dir="auto">
<li><a href="#features">Features</a>
<ul dir="auto">
<li><a href="#1-flexible-and-powerful-spatial-data-management">1. Flexible and powerful spatial data management</a></li>
<li><a href="#2-beautiful-cartography">2. Beautiful cartography</a></li>
<li><a href="#3-advanced-and-robust-geospatial-analysis">3. Advanced and robust geospatial analysis</a></li>
<li><a href="#4-powerful-customization-and-extensibility">4. Powerful customization and extensibility</a></li>
<li><a href="#5-qgis-server">5. QGIS Server</a></li>
</ul>
</li>
<li><a href="#under-the-hood">Under the hood</a>
<ul dir="auto">
<li><a href="#versions-and-release-cycle">Versions and release cycle</a></li>
<li><a href="#free-and-open-source">Free and Open Source</a></li>
</ul>
</li>
<li><a href="#installing-and-using-qgis">Installing and using QGIS</a>
<ul dir="auto">
<li><a href="#documentation">Documentation</a></li>
<li><a href="#help-and-support-channels">Help and support channels</a></li>
</ul>
</li>
<li><a href="#get-involved-with-the-community">Get involved with the community</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Flexible and powerful spatial data management</h3><a id="user-content-1-flexible-and-powerful-spatial-data-management" aria-label="Permalink: 1. Flexible and powerful spatial data management" href="#1-flexible-and-powerful-spatial-data-management"></a></p>
<ul dir="auto">
<li>Support for raster, vector, mesh, and point cloud data in a range of industry-standard formats
<ul dir="auto">
<li><em>Raster formats include</em>: GeoPackage, GeoTIFF, GRASS, ArcInfo binary and ASCII grids, ERDAS Imagine SDTS, WMS, WCS, PostgreSQL/PostGIS, and <a href="https://gdal.org/drivers/raster/index.html" rel="nofollow">other GDAL supported formats</a>.</li>
<li><em>Vector formats include</em>: GeoPackage, ESRI shapefiles, GRASS, SpatiaLite, PostgreSQL/PostGIS, MSSQL, Oracle, WFS, Vector Tiles and <a href="https://www.gdal.org/ogr_formats.html" rel="nofollow">other OGR supported formats</a>.</li>
<li><em>Mesh formats include</em>: NetCDF, GRIB, 2DM, and <a href="https://github.com/lutraconsulting/MDAL#supported-formats">other MDAL supported formats</a>.</li>
<li><em>Point-cloud format</em>: LAS/LAZ and EPT datasets.</li>
</ul>
</li>
<li>Data abstraction framework, with local files, spatial databases (PostGIS, SpatiaLite, SQL Server, Oracle, SAP HANA), and web services (WMS, WCS, WFS, ArcGIS REST) all accessed through a unified data model and browser interface, and as flexible layers in user-created projects</li>
<li>Spatial data creation via visual and numerical digitizing and editing, as well as georeferencing of raster and vector data</li>
<li>On-the-fly reprojection between coordinate reference systems (CRS)</li>
<li>Nominatim (OpenStreetMap) geocoder access</li>
<li>Temporal support</li>
</ul>
<p dir="auto"><em>Example: Temporal animation</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/qgis/QGIS/blob/master/images/README-md/icebergs.gif"><img src="https://github.com/qgis/QGIS/raw/master/images/README-md/icebergs.gif" alt="Example: Temporal animation" title="Temporal animation" data-animated-image=""></a></p>
<p dir="auto"><em>Example: 3D map view</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e34903ab068547a5e7824acb2fbdfce83d25503c434720028fe22aff7668ce9c/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f33646d6170766965772e706e67"><img src="https://camo.githubusercontent.com/e34903ab068547a5e7824acb2fbdfce83d25503c434720028fe22aff7668ce9c/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f33646d6170766965772e706e67" alt="Example: 3D map view" title="3D map view" data-canonical-src="https://docs.qgis.org/latest/en/_images/3dmapview.png"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Beautiful cartography</h3><a id="user-content-2-beautiful-cartography" aria-label="Permalink: 2. Beautiful cartography" href="#2-beautiful-cartography"></a></p>
<ul dir="auto">
<li>Large variety of rendering options in 2D and 3D</li>
<li>Fine control over symbology, labeling, legends and additional graphical elements for beautifully rendered maps</li>
<li>Respect for embedded styling in many spatial data sources (e.g. KML and TAB files, Mapbox-GL styled vector tiles)</li>
<li>In particular, near-complete replication (and significant extension) of symbology options that are available in proprietary software by ESRI</li>
<li>Advanced styling using data-defined overrides, blending modes, and draw effects</li>
<li>500+ built-in color ramps (cpt-city, ColorBrewer, etc.)</li>
<li>Create and update maps with specified scale, extent, style, and decorations via saved layouts</li>
<li>Generate multiple maps (and reports) automatically using QGIS Atlas and QGIS Reports</li>
<li>Display and export elevation profile plots with flexible symbology</li>
<li>Flexible output direct to printer, or as image (raster), PDF, or SVG for further customization</li>
<li>On-the-fly rendering enhancements using geometry generators (e.g. create and style new geometries from existing features)</li>
<li>Preview modes for inclusive map making (e.g. monochrome, color blindness)</li>
</ul>
<p dir="auto"><em><a href="https://flic.kr/p/2jFfGJP" rel="nofollow">Example: Map of Bogota, Colombia in the style of Starry Starry Night, by Andrés Felipe Lancheros Sánchez</a></em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c2d03d08c41df2483941f33b27268788b4926c275b52efa45eda52bb0d27b0ab/68747470733a2f2f6c6976652e737461746963666c69636b722e636f6d2f36353533352f35303332373332363332335f336461323866306438365f622e6a7067"><img src="https://camo.githubusercontent.com/c2d03d08c41df2483941f33b27268788b4926c275b52efa45eda52bb0d27b0ab/68747470733a2f2f6c6976652e737461746963666c69636b722e636f6d2f36353533352f35303332373332363332335f336461323866306438365f622e6a7067" alt="Map of Bogota, Colombia in the style of Starry Starry Night" title="Map of Bogota, Colombia in the style of Starry Starry Night" data-canonical-src="https://live.staticflickr.com/65535/50327326323_3da28f0d86_b.jpg"></a></p>
<p dir="auto">For more maps created with QGIS, visit the <a href="https://www.flickr.com/groups/2244553@N22/pool/with/50355460063/" rel="nofollow">QGIS Map Showcase Flickr Group</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/qgis/QGIS/blob/master/images/README-md/qgis_map_showcase.png"><img src="https://github.com/qgis/QGIS/raw/master/images/README-md/qgis_map_showcase.png" alt="QGIS Map Showcase" title="QGIS Map Showcase"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Advanced and robust geospatial analysis</h3><a id="user-content-3-advanced-and-robust-geospatial-analysis" aria-label="Permalink: 3. Advanced and robust geospatial analysis" href="#3-advanced-and-robust-geospatial-analysis"></a></p>
<ul dir="auto">
<li>Powerful processing framework with 200+ native processing algorithms</li>
<li>Access to 1000+ processing algorithms via providers such as GDAL, SAGA, GRASS, OrfeoToolbox, as well as custom models and processing scripts</li>
<li>Geospatial database engine (filters, joins, relations, forms, etc.), as close to datasource- and format-independent as possible</li>
<li>Immediate visualization of geospatial query and geoprocessing results</li>
<li>Model designer and batch processing</li>
</ul>
<p dir="auto"><em>Example: Travel isochrones</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/qgis/QGIS/blob/master/images/README-md/network_analysis_2.png"><img src="https://github.com/qgis/QGIS/raw/master/images/README-md/network_analysis_2.png" alt="Example: Travel isochrones" title="Travel isochrones"></a></p>
<p dir="auto"><em>Example: Model designer</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3d0b647c5ce4ebabda9cf79f8e056f21bd03f70cd16bb7dfa5025000ea60de85/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f6d6f64656c735f6d6f64656c2e706e67"><img src="https://camo.githubusercontent.com/3d0b647c5ce4ebabda9cf79f8e056f21bd03f70cd16bb7dfa5025000ea60de85/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f6d6f64656c735f6d6f64656c2e706e67" alt="Example: model designer" title="Model designer" data-canonical-src="https://docs.qgis.org/latest/en/_images/models_model.png"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Powerful customization and extensibility</h3><a id="user-content-4-powerful-customization-and-extensibility" aria-label="Permalink: 4. Powerful customization and extensibility" href="#4-powerful-customization-and-extensibility"></a></p>
<ul dir="auto">
<li>Fully customizable user experience, including user interface and application settings that cater to power-users and beginners alike</li>
<li>Rich <a href="https://docs.qgis.org/testing/en/docs/user_manual/working_with_vector/expression.html" rel="nofollow">expression engine</a> for maximum flexibility in visualization and processing</li>
<li>Broad and varied <a href="https://plugins.qgis.org/" rel="nofollow">plugin ecosystem</a> that includes data connectors, digitizing aids, advanced analysis and charting tools,
in-the-field data capture, conversion of ESRI style files, etc.</li>
<li>Style manager for creating, storing, and managing styles</li>
<li><a href="https://plugins.qgis.org/styles/" rel="nofollow">QGIS style hub</a> for easy sharing of styles</li>
<li>Python and C++ API for standalone (headless) applications as well as in-application comprehensive scripting (PyQGIS)</li>
</ul>
<p dir="auto"><em>Example: Style manager</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ddd6e1d08a828f44b26570db1953d8a0f672a62b43ab66ed7082a387e85b910f/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f7374796c656d616e616765722e706e67"><img src="https://camo.githubusercontent.com/ddd6e1d08a828f44b26570db1953d8a0f672a62b43ab66ed7082a387e85b910f/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f7374796c656d616e616765722e706e67" alt="Example: Style manager" title="Style Manager" data-canonical-src="https://docs.qgis.org/latest/en/_images/stylemanager.png"></a></p>
<p dir="auto"><em>Example: Plugins</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/qgis/QGIS/blob/master/images/README-md/plugins_1.png"><img src="https://github.com/qgis/QGIS/raw/master/images/README-md/plugins_1.png" alt="Example: Plugins" title="Plugins"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">5. QGIS Server</h3><a id="user-content-5-qgis-server" aria-label="Permalink: 5. QGIS Server" href="#5-qgis-server"></a></p>
<p dir="auto">Headless map server -- running on Linux, macOS, Windows, or in a docker container -- that shares the same code base as QGIS.</p>
<ul dir="auto">
<li>Industry-standard protocols (WMS, WFS, WFS3/OGC API for Features and WCS) allow plug-n-play with any software stack</li>
<li>Works with any web server (Apache, nginx, etc) or standalone</li>
<li>All beautiful QGIS cartography is supported with best-in-class support for printing</li>
<li>Fully customizable with Python scripting support</li>
</ul>
<p dir="auto"><em>Example: QGIS server WMS response</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9a67fbbe6a56d12302164ba4ae495acae4a74553817085c48935259cd7cda194/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f7365727665725f73656c656374696f6e5f706172616d657465722e706e67"><img src="https://camo.githubusercontent.com/9a67fbbe6a56d12302164ba4ae495acae4a74553817085c48935259cd7cda194/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f7365727665725f73656c656374696f6e5f706172616d657465722e706e67" alt="Example: QGIS Server response to a WMS request" title="QGIS Server response to a WMS request" data-canonical-src="https://docs.qgis.org/latest/en/_images/server_selection_parameter.png"></a></p>
<p dir="auto"><em>Example: QGIS server WFS response</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0956e8550c0e3e824343dfe5e994ac6fc7183d8d35687caaa13dd554c478a86a/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f7365727665725f776673335f666561747572652e706e67"><img src="https://camo.githubusercontent.com/0956e8550c0e3e824343dfe5e994ac6fc7183d8d35687caaa13dd554c478a86a/68747470733a2f2f646f63732e716769732e6f72672f6c61746573742f656e2f5f696d616765732f7365727665725f776673335f666561747572652e706e67" alt="Example: QGIS Server response to a WFS Feature request" title="QGIS Server response to a WFS Feature request" data-canonical-src="https://docs.qgis.org/latest/en/_images/server_wfs3_feature.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Under the hood</h2><a id="user-content-under-the-hood" aria-label="Permalink: Under the hood" href="#under-the-hood"></a></p>
<p dir="auto">QGIS is developed using the <a href="https://qt.io/" rel="nofollow">Qt toolkit</a> and C++, since 2002, and has a pleasing, easy to use graphical
user interface with multilingual support. It is maintained by an active developer team and supported by vibrant
community of GIS professionals and enthusiasts as well as geospatial data publishers and end-users.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Versions and release cycle</h3><a id="user-content-versions-and-release-cycle" aria-label="Permalink: Versions and release cycle" href="#versions-and-release-cycle"></a></p>
<p dir="auto">QGIS development and releases follow a <a href="https://www.qgis.org/en/site/getinvolved/development/roadmap.html" rel="nofollow">time based schedule/roadmap</a>. There are three main branches of QGIS that users can install. These are the <strong>Long Term Release (LTR)</strong> branch, the <strong>Latest Release (LR)</strong> branch, and the <strong>Development (Nightly)</strong> branch.</p>
<p dir="auto">Every month, there is a <strong>Point Release</strong> that provides bug-fixes to the LTR and LR.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Free and Open Source</h3><a id="user-content-free-and-open-source" aria-label="Permalink: Free and Open Source" href="#free-and-open-source"></a></p>
<p dir="auto">QGIS is released under the GNU Public License (GPL) Version 2 or any later version.
Developing QGIS under this license means that you can (if you want to) inspect
and modify the source code and guarantees that you, our happy user will always
have access to a GIS program that is free of cost and can be freely
modified.</p>
<p dir="auto">QGIS is part of the Open-Source Geospatial Foundation (<a href="https://www.osgeo.org/" rel="nofollow">OSGeo</a>), offering a range of complementary open-source GIS software projects.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing and using QGIS</h2><a id="user-content-installing-and-using-qgis" aria-label="Permalink: Installing and using QGIS" href="#installing-and-using-qgis"></a></p>
<p dir="auto">Precompiled binaries for QGIS are available at <a href="https://www.qgis.org/en/site/forusers/download.html" rel="nofollow">the QGIS.org download page</a>.
Please follow the installation instructions carefully.</p>
<p dir="auto">The <a href="https://github.com/qgis/QGIS/blob/master/INSTALL.md">building guide</a> can be used to get started with building QGIS from source.</p>
<p dir="auto">For installation of QGIS Server, see its <a href="https://docs.qgis.org/testing/en/docs/server_manual/getting_started.html" rel="nofollow">getting started documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Documentation</h3><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">A range of <a href="https://qgis.org/resources/hub/#documentation" rel="nofollow">documentation</a> is available. This includes:</p>
<ul dir="auto">
<li><a href="https://docs.qgis.org/latest/en/docs/training_manual/index.html" rel="nofollow">Training Manual</a></li>
<li><a href="https://docs.qgis.org/latest/en/docs/user_manual/index.html" rel="nofollow">QGIS User Guide</a></li>
<li><a href="https://docs.qgis.org/latest/en/docs/server_manual/index.html" rel="nofollow">QGIS Server Guide</a></li>
<li><a href="https://qgis.org/project/visual-changelogs/" rel="nofollow">Visual Changelog</a></li>
<li><a href="https://docs.qgis.org/latest/en/docs/documentation_guidelines/index.html" rel="nofollow">Documentation Guidelines</a></li>
<li><a href="https://docs.qgis.org/latest/en/docs/pyqgis_developer_cookbook/index.html" rel="nofollow">QGIS Python (PyQGIS) Cookbook</a></li>
<li><a href="https://qgis.org/pyqgis/" rel="nofollow">QGIS Python (PyQGIS) API</a></li>
<li><a href="https://qgis.org/api/" rel="nofollow">QGIS C++ API</a></li>
<li><a href="https://docs.qgis.org/latest/en/docs/developers_guide/index.html" rel="nofollow">Developers Guide</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Help and support channels</h3><a id="user-content-help-and-support-channels" aria-label="Permalink: Help and support channels" href="#help-and-support-channels"></a></p>
<p dir="auto">There are several channels where you can find help and support for QGIS:</p>
<ul dir="auto">
<li>Using the <a href="https://qgis.org/" rel="nofollow">QGIS community site</a></li>
<li>Joining the <a href="https://lists.osgeo.org/mailman/listinfo/qgis-user" rel="nofollow">qgis-users mailing list</a></li>
<li>Chatting with other users real-time. <em>Please wait around for a response to your question as many folks on the channel are doing other things and it may take a while for them to notice your question. The following paths all take you to the same chat room:</em>
<ul dir="auto">
<li>Using an IRC client and joining the
<a href="https://web.libera.chat/?channels=#qgis" rel="nofollow">#qgis</a> channel on irc.libera.chat.</li>
<li>Using a Matrix client and joining the <a href="https://matrix.to/#/#qgis:osgeo.org" rel="nofollow">#qgis:osgeo.org</a> room.</li>
</ul>
</li>
<li>At the <a href="https://gis.stackexchange.com/" rel="nofollow">GIS stackexchange</a> or <a href="https://www.reddit.com/r/QGIS/" rel="nofollow">r/QGIS reddit</a>, which are not maintained by the QGIS team, but where the QGIS and broader GIS community provides lots of advice</li>
<li><a href="https://qgis.org/resources/support/" rel="nofollow">Other support channels</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get involved with the community</h2><a id="user-content-get-involved-with-the-community" aria-label="Permalink: Get involved with the community" href="#get-involved-with-the-community"></a></p>
<p dir="auto"><a href="https://github.com/qgis/QGIS/blob/master/CONTRIBUTING.md">Contribution guidelines for this project</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vector database that can index 1B vectors in 48M (107 pts)]]></title>
            <link>https://www.vectroid.com/blog/why-and-how-we-built-Vectroid</link>
            <guid>45224141</guid>
            <pubDate>Fri, 12 Sep 2025 16:56:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vectroid.com/blog/why-and-how-we-built-Vectroid">https://www.vectroid.com/blog/why-and-how-we-built-Vectroid</a>, See on <a href="https://news.ycombinator.com/item?id=45224141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We are excited to announce Vectroid, a serverless vector search solution that delivers exceptional accuracy and low latency in a cost effective package. Vectroid is not just <em>another vector search</em> solution—it’s a search engine that performs and scales in all scenarios.</p><h3>Why we built Vectroid</h3><p>Talk to any team working with large, low latency vector workloads and you’ll hear a familiar story: something always has to give. Vector databases often make significant tradeoffs between speed, accuracy, and cost. That’s the nature of the mathematical underpinnings of vector search works—taking algorithmic <em>shortcuts</em> to get near-perfect results in a short amount of time.</p><p>There are some common permutations of these tradeoffs:</p><li>Ve<em>ry high accuracy</em>, but <em>very expensive</em> and <em>slow</em></li>
<li><em>Fast speed</em> and <em>tolerable accuracy</em>, but <em>very expensive</em></li>
<li><em>Cheap</em> and <em>fast</em>, but <em>inaccurate</em> to a <em>disqualifying degree</em></li>
<p>Based on the existing vector database landscape, it would seem that building a cost effective vector database requires sacrificing either speed or accuracy at scale. We believe that’s a false pretense: building a cost-efficient database <em>is</em> possible with high accuracy and low latency. We just need to rethink our underlying mechanism.</p><h3>Our “aha” moment</h3><p>Query speed and recall are largely a function of the chosen ANN algorithm. Algorithms which are both fast <em>and</em> accurate like HNSW (Hierarchical Navigable Small Worlds) are memory intensive and expensive to index. The traditional assumption is that these types of algorithms are untenable for a cost-conscious system.</p><p>We had two major realizations which challenged this assumption.</p><ol><li><strong>Demand for in-memory HNSW is not static.</strong> Real world usage patterns are bursty and uneven. A cost efficient database can optimize for this reality by making resource allocation dynamic and by individually scaling system components as needed.</li>
<li><strong>HNSW’s memory footprint is tunable.</strong> It can be easily be flattened (ex. by compressing vectors using quantization) and expanded (ex. by increasing layer count), which gives us the flexibility to experiment with different configurations to find a goldilocks setup.</li>
</ol>
<h3>What is Vectroid?</h3><p>Vectroid is a serverless vector database with premium performance. It delivers the same or stronger balance of speed and recall promised by high-end offerings, but costs less than competitors.</p><ol><li>Performant vector search: HNSW for ultra fast, high recall similarity search.</li>
<li>Near real-time search capabilities: Newly ingested records are searchable almost instantly.</li>
<li>Massive scalability: Seamlessly handles billions of vectors in a single namespace.</li>
<li>Cost efficient resource utilization: Scaling each layer (ingest, index, query) separately.</li>
</ol>
<h3>How Vectroid performs</h3><p>The core philosophy of Vectroid is that optimizing for one metric at any cost to the others doesn’t make for a robust system. Instead, vector search should be designed for balanced performance across recall, latency, and cost so users don’t have to make painful tradeoffs as workloads grow.</p><p>When tested against other state-of-the-art vector search, Vectroid is not only competitive but the most consistent across the board. Across all of our tests, Vectroid is the <em>only</em> databases that was able to maintain over 90% recall while scaling to 10 query threads per second—all while maintaining good latency scores.</p><h3>Some early benchmarks:</h3><li>Indexed <strong>1B vectors (Deep1B)</strong> in ~<strong>48 minutes</strong></li>
<li>Achieved <strong>P99 latency of 34ms</strong> on the <strong>MS Marco 138M vector / 1024 dimensions dataset</strong></li>
<p>We’ll be releasing the full benchmark suite (with setup details so anyone can reproduce them) in an upcoming post. For now, these numbers highlight the kind of scale and performance we designed Vectroid to handle.</p><h3>How Vectroid works</h3><p>Vectroid is composed of two independently scalable microservices for writes and reads.</p><p><img src="https://www.vectroid.com/images/blog/vectroid-arch-diagram.png"></p><p>As the diagram shows, index state, vector data, and metadata are persisted to cloud object storage (GCS for now, S3 coming soon). Disk, cache, and in-memory storage layers each employ a usage-aware model for index lifecycle in which indexes are lazily loaded from object storage on demand and evicted when idle.</p><p>For fast, high-recall ANN search, we chose the <strong>HNSW algorithm</strong>. It offers excellent latency and accuracy tradeoffs, supports incremental updates, and performs well across large-scale workloads. To patch its limitations, we added a number of targeted optimizations:</p><li>Slow indexing speed ⇒ in-memory write buffer to ensure newly inserted vectors are immediately searchable</li>
<li>High indexing cost ⇒ batched, highly concurrent and partitioned indexing</li>
<li>High memory usage ⇒ vector compression via quantization</li>
<h3>Final Thoughts</h3><p>We’re just getting started. If you’re building applications that rely on fast, scalable vector search (or you’re running up against the limits of your current stack), we’d love to hear from you. Start using Vectroid today or sign up for our newsletter to follow along as we continue building.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VaultGemma: The most capable differentially private LLM (103 pts)]]></title>
            <link>https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/</link>
            <guid>45223726</guid>
            <pubDate>Fri, 12 Sep 2025 16:14:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/">https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/</a>, See on <a href="https://news.ycombinator.com/item?id=45223726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20250912">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="w2rqp">As AI becomes more integrated into our lives, building it with privacy at its core is a critical frontier for the field. <a href="https://en.wikipedia.org/wiki/Differential_privacy" target="_blank" rel="noopener noreferrer">Differential privacy</a> (DP) offers a mathematically robust solution by adding calibrated noise to prevent memorization. However, applying DP to LLMs introduces trade-offs. Understanding these trade-offs is crucial. Applying DP noise alters traditional <a href="https://arxiv.org/abs/2203.15556" target="_blank" rel="noopener noreferrer">scaling laws</a> — rules describing performance dynamics — by reducing training stability (the model's ability to learn consistently without experiencing catastrophic events like loss spikes or divergence) and significantly increasing batch size (a collection of input prompts sent to the model simultaneously for processing) and computation costs.</p><p data-block-key="kvsp">Our new research, “<a href="https://arxiv.org/abs/2501.18914" target="_blank" rel="noopener noreferrer">Scaling Laws for Differentially Private Language Models</a>”, conducted in partnership with Google DeepMind, establishes laws that accurately model these intricacies, providing a complete picture of the compute-privacy-utility trade-offs. Guided by this research, we’re excited to introduce VaultGemma, the largest (1B-parameters), open model trained from scratch with differential privacy. We are releasing the weights on <a href="https://huggingface.co/google/vaultgemma-1b" target="_blank" rel="noopener noreferrer">Hugging Face</a> and <a href="https://www.kaggle.com/models/google/vaultgemma" target="_blank" rel="noopener noreferrer">Kaggle</a>, alongside a <a href="https://services.google.com/fh/files/blogs/vaultgemma_tech_report.pdf" target="_blank" rel="noopener noreferrer">technical report</a>, to advance the development of the next generation of private AI.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h2 data-block-key="w2rqp">Understanding the scaling laws</h2><p data-block-key="emls0">With a carefully thought-out experimental methodology, we aimed to quantify the benefit of increasing model sizes, batch sizes, and iterations in the context of DP training. Our work required making some simplifying assumptions to overcome the exponential number of combinations one might consider trying. We assumed that how well the model learns depends mostly on the "noise-batch ratio” which compares the amount of random noise we add for privacy to the size of the data groups (batches) we use for training. This assumption works because the privacy noise we add is much greater than any natural randomness that comes from sampling the data.</p><p data-block-key="fbiiv">To establish a DP scaling law, we conducted a comprehensive set of experiments to evaluate performance across a variety of model sizes and noise-batch ratios. The resulting empirical data, together with known deterministic relationships between other variables, allows us to answer a variety of interesting scaling-laws–style queries, such as, “For a given compute budget, privacy budget, and data budget, what is the optimal training configuration to achieve the lowest possible training loss?”</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h2 data-block-key="sv3qw">Key findings: A powerful synergy</h2><p data-block-key="cr1ma">Before diving into the full scaling laws, it’s useful to understand the dynamics and synergies between the compute budget, privacy budget, and data budget from a privacy accounting perspective — i.e., understand how these factors influence the noise-batch ratio for a fixed model size and number of iterations. This analysis is significantly cheaper to do as it does not require any model training, yet it yields a number of useful insights. For instance, increasing the privacy budget in isolation leads to diminishing returns, unless coupled with a corresponding increase in either the compute budget (<a href="https://en.wikipedia.org/wiki/Floating_point_operations_per_second" target="_blank" rel="noopener noreferrer">FLOPs</a>) or data budget (tokens).</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="sv3qw">To explore this synergy further, the visualization below shows how the optimal training configuration changes based on different constraints. As the privacy and compute budgets change, notice how the recommendation shifts between investing in a larger model versus training with larger batch sizes or more iterations.</p>

    </div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="sv3qw">This data provides a wealth of useful insights for practitioners. While all the insights are reported in the paper, a key finding is that one should train a much smaller model with a much larger batch size than would be used without DP. This general insight should be unsurprising to a DP expert given the importance of large batch sizes. While this general insight holds across many settings, the optimal training configurations do change with the privacy and data budgets. Understanding the exact trade-off is crucial to ensure that both the compute and privacy budgets are used judiciously in real training scenarios. The above visualizations also reveal that there is often wiggle room in the training configurations —&nbsp;i.e., a range of model sizes might provide very similar utility if paired with the correct number of iterations and/or batch size.</p>

    </div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h2 data-block-key="sv3qw">Applying the scaling laws to build VaultGemma</h2><p data-block-key="69vq3">The <a href="https://deepmind.google/models/gemma/" target="_blank" rel="noopener noreferrer">Gemma</a> models are designed with responsibility and safety at their core. This makes them a natural foundation for developing a production-quality, DP-trained model like VaultGemma.</p><h3 data-block-key="d6ih5">Algorithmic advancements: Training at scale</h3><p data-block-key="ac2lq">The scaling laws we derived above represent an important first step towards training a useful Gemma model with DP. We used the scaling laws to determine both how much compute we needed to train a compute-optimal 1B parameter Gemma 2-based model with DP, and how to allocate that compute among batch size, iterations, and sequence length to achieve the best utility.</p><p data-block-key="2tili">One prominent gap between the research underlying the scaling laws and the actual training of VaultGemma was our handling of <a href="https://en.wikipedia.org/wiki/Poisson_sampling" target="_blank" rel="noopener noreferrer"><i>Poisson sampling</i></a>, which is a central component of <a href="https://arxiv.org/abs/1607.00133" target="_blank" rel="noopener noreferrer">DP-SGD</a>. We initially used a straightforward method of loading data in uniform batches but then switched to Poisson sampling to get the best privacy guarantees with the least amount of noise. This method posed two main challenges: it created batches of different sizes, and it required a specific, randomized order for processing the data. We solved this by using our recent work on <a href="https://arxiv.org/abs/2411.04205" target="_blank" rel="noopener noreferrer">Scalable DP-SGD</a>, which allows us to process data in fixed-size batches — either by adding extra padding or trimming them — while still maintaining strong privacy protections.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h2 data-block-key="sv3qw">Results</h2><p data-block-key="efh07">Armed with our new scaling laws and advanced training algorithms, we built VaultGemma, to date the largest (1B-parameters) open model fully pre-trained with differential privacy with an approach that can yield high-utility models.</p><p data-block-key="25ku7">From training VaultGemma, we found our scaling laws to be highly accurate. The final training loss of VaultGemma was remarkably close to what our equations predicted, validating our research and providing the community with a reliable roadmap for future private model development.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="sv3qw">We also compare downstream performance of our model against its non-private counterpart across a range of standard academic benchmarks (i.e., <a href="https://arxiv.org/abs/1905.07830" target="_blank" rel="noopener noreferrer">HellaSwag</a>, <a href="https://arxiv.org/abs/1905.10044" target="_blank" rel="noopener noreferrer">BoolQ</a>, <a href="https://arxiv.org/abs/1911.11641" target="_blank" rel="noopener noreferrer">PIQA</a>, <a href="https://arxiv.org/abs/1904.09728" target="_blank" rel="noopener noreferrer">SocialIQA</a>, <a href="https://arxiv.org/abs/1705.03551" target="_blank" rel="noopener noreferrer">TriviaQA</a>, <a href="https://arxiv.org/abs/1911.01547" target="_blank" rel="noopener noreferrer">ARC-</a>C, <a href="https://arxiv.org/abs/1911.01547" target="_blank" rel="noopener noreferrer">ARC-</a>E ). To put this performance in perspective and quantify the current resource investment required for privacy, we also include a comparison to an older similar-sized GPT-2 model, which performs similarly on these benchmarks. This comparison illustrates that today’s private training methods produce models with utility comparable to that of non-private models from roughly 5 years ago, highlighting the important gap our work will help the community systematically close.</p><p data-block-key="36cfk">Finally, the model comes with strong theoretical and empirical privacy protections.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h3 data-block-key="sv3qw">Formal privacy guarantee</h3><p data-block-key="2ivmr">In general, both the privacy parameters (ε, δ) and the privacy <i>unit</i> are important considerations when doing DP training, as these together determine what the trained model can learn. VaultGemma was trained with a <i>sequence</i>-level DP guarantee of (ε ≤ 2.0, δ ≤ 1.1e-10), where a sequence consists of 1024 consecutive tokens extracted from heterogeneous data sources. Specifically, we used the same training mixture that was used to train the <a href="https://arxiv.org/abs/2408.00118" target="_blank" rel="noopener noreferrer">Gemma 2</a> model, consisting of a number of documents of varying lengths. During pre-processing, long documents are split up and tokenized into multiple sequences, and shorter documents are packed together into a single sequence. While the sequence-level privacy unit was a natural choice for our training mixture, in situations where there is a clear mapping between data and users, <a href="https://research.google/blog/fine-tuning-llms-with-user-level-differential-privacy/">user-level differential privacy</a> would be a better choice.</p><p data-block-key="b4na6">What does this mean in practice? Informally speaking, because we provide protection at the sequence level, if information relating to any (potentially private) fact or inference occurs in a single sequence, then VaultGemma essentially does not know that fact: the response to any query will be statistically similar to the result from a model that never trained on the sequence in question. However, if many training sequences contain information relevant to a particular fact, then in general VaultGemma will be able to provide that information.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h3 data-block-key="sv3qw">Empirical memorization</h3><p data-block-key="1td9o">Sequence-level DP provably bounds the influence of any single training sequence (example) on the final model. We prompted the model with a 50-token prefix from a training document to see if it would generate the corresponding 50-token suffix. VaultGemma 1B shows no detectable memorization of its training data and successfully demonstrates the efficacy of DP training.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h2 data-block-key="sv3qw">Conclusion</h2><p data-block-key="ej03m">VaultGemma represents a significant step forward in the journey toward building AI that is both powerful and private by design. By developing and applying a new, robust understanding of the scaling laws for DP, we have successfully trained and released the largest open, DP-trained language model to date.</p><p data-block-key="bv1kj">While a utility gap still exists between DP-trained and non-DP–trained models, we believe this gap can be systematically narrowed with more research on mechanism design for DP training. We hope that VaultGemma and our accompanying research will empower the community to build the next generation of safe, responsible, and private AI for everyone.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <h2 data-block-key="sv3qw">Acknowledgements</h2><p data-block-key="doolt"><i>We'd like to thank the entire Gemma and Google Privacy teams for their contributions and support throughout this project, in particular, Peter Kairouz, Brendan McMahan and Dan Ramage for feedback on the blog post, Mark Simborg and Kimberly Schwede for help with visualizations, and the teams at Google that helped with algorithm design, infrastructure implementation, and production maintenance. The following people directly contributed to the work presented here (ordered alphabetically): Borja Balle, Zachary Charles, Christopher A. Choquette-Choo, Lynn Chua, Prem Eruvbetine, Badih Ghazi, Steve He, Yangsibo Huang, Armand Joulin, George Kaissis, Pritish Kamath, Ravi Kumar, Daogao Liu, Ruibo Liu, Pasin Manurangsi, Thomas Mesnard, Andreas Terzis, Tris Warkentin, Da Yu, and Chiyuan Zhang.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Corporations are trying, and now failing, to hide job openings from US citizens (572 pts)]]></title>
            <link>https://thehill.com/opinion/finance/5498346-corporate-america-has-been-trying-to-hide-job-openings-now-it-is-failing/</link>
            <guid>45223719</guid>
            <pubDate>Fri, 12 Sep 2025 16:13:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/opinion/finance/5498346-corporate-america-has-been-trying-to-hide-job-openings-now-it-is-failing/">https://thehill.com/opinion/finance/5498346-corporate-america-has-been-trying-to-hide-job-openings-now-it-is-failing/</a>, See on <a href="https://news.ycombinator.com/item?id=45223719">Hacker News</a></p>
Couldn't get https://thehill.com/opinion/finance/5498346-corporate-america-has-been-trying-to-hide-job-openings-now-it-is-failing/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Grove (153 pts)]]></title>
            <link>https://openai.com/index/openai-grove/</link>
            <guid>45223660</guid>
            <pubDate>Fri, 12 Sep 2025 16:05:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/openai-grove/">https://openai.com/index/openai-grove/</a>, See on <a href="https://news.ycombinator.com/item?id=45223660">Hacker News</a></p>
Couldn't get https://openai.com/index/openai-grove/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Advanced Scheme Techniques (2004) [pdf] (101 pts)]]></title>
            <link>https://people.csail.mit.edu//jhbrown/scheme/continuationslides04.pdf</link>
            <guid>45223419</guid>
            <pubDate>Fri, 12 Sep 2025 15:44:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people.csail.mit.edu//jhbrown/scheme/continuationslides04.pdf">https://people.csail.mit.edu//jhbrown/scheme/continuationslides04.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45223419">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A beginner's guide to extending Emacs (143 pts)]]></title>
            <link>https://blog.tjll.net/a-beginners-guide-to-extending-emacs/</link>
            <guid>45223239</guid>
            <pubDate>Fri, 12 Sep 2025 15:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.tjll.net/a-beginners-guide-to-extending-emacs/">https://blog.tjll.net/a-beginners-guide-to-extending-emacs/</a>, See on <a href="https://news.ycombinator.com/item?id=45223239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<hgroup>
  <h3>
    
    <a href="https://blog.tjll.net/blog-architecture-redux/">«</a>
    
    A Beginner's Guide to Extending Emacs
    
    <a href="https://blog.tjll.net/human-resources-misalignment/">»</a>
    
  </h3>
  <div>
    <ul id="post-details">
      <li> 4 February, 2025</li>
      <li>3,983 words</li>
      <li>17 minute read time</li>
    </ul>
  </div>
</hgroup>


        <section id="content">
	  
<p>
This post isn’t about the virtues of some editors versus others: <a href="https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/">that's already been written by somebody else</a> (and it’s really good) – if you want to know <i>why</i> I use emacs, I suggest reading that instead.
</p>

<p>
<i>This</i> post will help you understand why "extensibility" and "introspectability" are such prominent emacs features even without an emacs lisp background.
Bridging the gap from <a href="https://www.spacemacs.org/">spacemacs</a> or <a href="https://github.com/doomemacs/doomemacs">doom emacs</a> to a bespoke configuration wasn't easy for me because I didn’t know <i>how</i> to learn emacs, so I'm going to stumble through one of my own use cases to demonstrate how this process goes if you're peeking in from outside the emacs ecosystem, <del>horrified</del> curious about how this all works.
</p>

<p>
Let's talk about reStructuredText.
</p>

<div id="table-of-contents" role="doc-toc">
<h4>Table of Contents</h4>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#restructuredtext">reStructuredText</a>
<ul>
<li><a href="#a-parentheses-prelude">A Parentheses Prelude</a></li>
</ul>
</li>
<li><a href="#extensible-macros">Extensible MACroS</a>
<ul>
<li><a href="#completions-abound">Completions Abound</a></li>
</ul>
</li>
<li><a href="#gathering-completions">Gathering Completions</a>
<ul>
<li><a href="#regexes">Regexes</a></li>
</ul>
</li>
<li><a href="#gathering-completions-continued">Gathering Completions: Continued</a></li>
<li><a href="#completing-the-completion-backend">Completing the Completion Backend</a></li>
<li><a href="#dressing-up-the-bones">Dressing Up the Bones</a>
<ul>
<li><a href="#mode-hooks">Mode Hooks</a></li>
<li><a href="#other-files">Other Files</a></li>
<li><a href="#fancy-completion">Fancy Completion</a></li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
</ul>
</div>
</div>
<div id="outline-container-restructuredtext">
<h4 id="restructuredtext">reStructuredText</h4>
<div id="text-restructuredtext">
<p>
At my day job I write <a href="https://docs.bowtie.works/">our user documentation</a> using <a href="https://www.sphinx-doc.org/en/master/">Sphinx</a>.
It expects my stilted prose in <code>.rst</code> format, which is kind of like Markdown if you squint.
</p>

<p>
I do an awful lot of cross-referencing between <i>references</i> (or <code>refs</code>) to link concepts across the documentation.
You define a reference like this:
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for directives and roles.</span></li>
<li><span>Font used for all other defining constructs.</span></li></ul></div><div>
<pre><code><span>.. _code_example:</span></code>
<code></code>
<code><span>.. code::</span></code>
<code>   echo "HELP I'M TRAPPED IN A CODE EXAMPLE"</code>
</pre>
</div>

<p>
…and then link to it later like this:
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for field names and interpreted text.</span></li>
<li><span>Font used for directives and roles.</span></li></ul></div><div>
<pre><code>This <span>:ref:</span><span>`doesn't look like anything to me &lt;code_example&gt;`</span>.</code>
</pre>
</div>

<p>
…or like this (if the <code>ref</code> is associated with a title of some sort):
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for field names and interpreted text.</span></li>
<li><span>Font used for directives and roles.</span></li></ul></div><div>
<pre><code>Don't say <span>:ref:</span><span>`code_example`</span>.</code>
</pre>
</div>

<p>
My problem is that I have an <i>assload</i> of references across the all of the documentation and my brain cannot recall them on the spot.
What I really need is the ability to call up the list of references to easily discover and select from that list – this is basically auto-completion but for documentation headers (or titles).
</p>

<p>
I am ready to write some shitty elisp <a href="http://landoflisp.com/">with the help of aliens</a>.
</p>
</div>
<div id="outline-container-a-parentheses-prelude">
<h5 id="a-parentheses-prelude">A Parentheses Prelude</h5>
<p>
Before we dig into emacs' guts, here are some principles that I learned after my first elisp experiments that might help somebody digging into this ecosystem for the first time:
</p>
<div id="outline-container-1-emacs-wants-you-to-extend-it">
<h6 id="1-emacs-wants-you-to-extend-it">1. Emacs <i>Wants</i> You to Extend It</h6>
<div>
<p>
I haven't written plugins for other editors extensively, but I <i>can</i> tell you this: emacs doesn't just make deep customization available, but it actively <i>encourages</i> you to make an absolute customization <del>messes</del> masterpieces.
Core editor functions aren't just documented, but often include tidbits about "you probably want to see this other variable" or "here's how you should use this".
</p>

<p>
Not only that, but emacs happily hands you functions shaped like nuclear warheads like <code><span>advice-add</span></code> (that let you override any function) that can absolutely obliterate your editor if you hold it the wrong way.
Of course, this also grants you <b>unlimited power</b>.
</p>

<p>
Remember that emacs is designed to be torn apart and rearranged.
</p>
</div>
</div>
<div id="outline-container-2-geriatric-software">
<h6 id="2-geriatric-software">2. Geriatric Software</h6>
<div>
<p>
The first public release of GNU emacs happened in 1985.
Literally <i>40 years</i> of development sits inside of emacs and its developers are <b>still</b> adding non-trivial features (native language server support landed in version 29 in 2023).
</p>

<p>
The ecosystem is vast and the language has evolved for a long time.
There's nearly always something useful if you need a particular piece of functionality, so even moreso than with other ecosystems: remember to do your homework first.
</p>
</div>
</div>
<div id="outline-container-3-lisp-for-for-the-un-lisped">
<h6 id="3-lisp-for-for-the-un-lisped">3. Lisp for for the un-Lisped</h6>
<div>
<p>
The syntax is polarizing, I know.
Gurus will wince when I get this wrong, but:
</p>

<ul>
<li>Writing lisp is like writing any other code, just with the parentheses wrapping <i>everything</i> instead of just <i>arguments</i>. <code><span>print</span><span>(</span><span>"Macrodata Refinement"</span><span>)</span></code> becomes <code><span>(</span><span>print</span> <span>"Macrodata Refinement"</span><span>)</span></code></li>
<li>Sometimes you don't get functions, you get macros that behave special ways.
For example, <code><span>let</span></code> sets variables for an inner block of code.
Like this: <code><span>(</span><span>let</span> <span>(</span>name <span>"Mark S."</span><span>)</span> <span>(</span><span>print</span> name<span>)</span><span>)</span></code></li>
<li>Lispers say "this is actually data and not calling code" by doing this with single quotes: <code><span>'</span><span>(</span><span>"list"</span> <span>"of"</span> <span>"strings"</span><span>)</span></code></li>
</ul>

<p>
I'm out of my depth in lisp, but if you're a novice, those notes might help.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-extensible-macros">
<h4 id="extensible-macros">Extensible MACroS</h4>
<div id="text-extensible-macros">
<p>
With that prelude out of the way, let's begin.
</p>

<p>
Inside of emacs you can call up a list of potential <i>completions</i> by using the keyboard shortcut <kbd>M-.</kbd> (that’s "hit the meta key along with period", where "meta" is the <kbd>Alt</kbd> key for me).
This applies in a wide variety of scenarios, like when completing class names or variables.
If we want to ask emacs to hand us a list of potential references, then the system we want to hook into is this <i>completions</i> system.
</p>

<p>
(This is the only time I'll assume we know where to go without crawling through documentation. You could discover it yourself looking for "<code>completion</code>" or similar string in emacs docs).
</p>

<p>
To start our hero’s journey, we figure out what the hell <kbd>M-.</kbd> actually <i>does</i>.
We can ask emacs this by calling the function <code><span>describe-key</span></code>, which is bound to <kbd>C-h k</kbd>.
Hitting <kbd>Ctrl-h</kbd>, then <kbd>k</kbd>, then <kbd>M-.</kbd> drops us into a help buffer that looks like this:
</p>

<pre id="org6bbb9dc"><code>M-. runs the command completion-at-point (found in</code>
<code>evil-insert-state-map), which is an interactive native-compiled Lisp</code>
<code>function in ‘minibuffer.el’.</code>
<code></code>
<code>It is bound to M-..</code>
<code></code>
<code>(completion-at-point)</code>
<code></code>
<code>Perform completion on the text around point.</code>
<code>The completion method is determined by ‘completion-at-point-functions’.</code>
<code></code>
<code>  Probably introduced at or before Emacs version 23.2.</code>
</pre>

<p>
We have the next breadcrumb to follow, which is the variable <code><span>completion-at-point-functions</span></code>.
Running <code><span>completion-at-point</span></code> by hitting <kbd>M-.</kbd> consults that variable to hand us completion candidates, so we <code><span>describe-variable</span></code> it with <kbd>C-h v</kbd> and then choose <code><span>completion-at-point-functions</span></code> from the list of variables:
</p>

<pre id="org56c73d2"><code>completion-at-point-functions is a variable defined in ‘minibuffer.el’.</code>
<code></code>
<code>Its value is (cape-dict cape-file tags-completion-at-point-function)</code>
<code></code>
<code>Special hook to find the completion table for the entity at point.</code>
<code>Each function on this hook is called in turn without any argument and</code>
<code>should return either nil, meaning it is not applicable at point,</code>
<code>or a function of no arguments to perform completion (discouraged),</code>
<code>or a list of the form (START END COLLECTION . PROPS)</code>
</pre>

<p>
…and it goes on from there.
You can see some existing completion functions in there: I use a package called <a href="https://github.com/minad/cape">cape</a> to offer helpful suggestions like file paths if I start typing in something like <code>./filename</code>.
</p>

<p>
The description for this variable instructs us about how to add our own functions (scary!)
You’ll note that emacs calls this a "hook", which is most often just a term used to describe a variable that is a list of functions that get called at a specific time (hooks show up everywhere).
</p>

<p>
I elided the full description for <code><span>completion-at-point-functions</span></code> – which is lengthy! – but if you parse it all out, you learn the following:
</p>

<ul>
<li>Your completion at point function should return either <code>nil</code> (the elisp "null") – which means your completion function doesn’t apply right now – or another function (which emacs discourages), or a list, which is what we’ll do because it sounds like the most-correct thing to do.</li>
<li>The list we return is <code><span>(</span>START END COLLECTION . PROPS<span>)</span></code>:
<ul>
<li><code>START</code> and <code>END</code> should be positions in the buffer between which emacs will replace the completed symbol with our candidate.
That is, if your cursor is calling a method on a Python object like <code>file.ope|</code> (where the bar is your cursor), emacs will replace just <code>ope</code> when you select <code>open</code> from a list of completions and not the entire <code>file.ope</code> string.</li>
<li><code>COLLECTION</code> is the juicy bit. The documentation calls it a completion "table", and there’s probably hidden meaning there, but you can just return a list of candidates and move on with your day, which is what I'll do.</li>
</ul></li>
</ul>

<p>
Okay, so we need to write something to find the bounds of a string to replace and a function that returns that list.
</p>
</div>
<div id="outline-container-completions-abound">
<h5 id="completions-abound">Completions Abound</h5>
<div id="text-completions-abound">
<p>
I fooled around with some regular expressions for a while until I did the <i>right</i> thing and examined how other completion backends do it.
If you have the package installed, the aforementioned <code><span>cape-file</span></code> function gives us a hint: hit <kbd>M-x</kbd>, then choose <code><span>find-function</span></code>, select <code><span>cape-file</span></code>, and poke around. You’ll find the use of a function called <code><span>bounds-of-thing-at-point</span></code>.
Describing it with <kbd>C-h f</kbd> <code><span>bounds-of-thing-at-point</span></code> gives us:
</p>

<pre id="orgdb3711b"><code>Determine the start and end buffer locations for the THING at point.</code>
<code>THING should be a symbol specifying a type of syntactic entity.</code>
<code>Possibilities include ‘symbol’, ‘list’, ‘sexp’, ‘defun’, ‘number’,</code>
<code>‘filename’, ‘url’, ‘email’, ‘uuid’, ‘word’, ‘sentence’, ‘whitespace’,</code>
<code>‘line’, and ‘page’.</code>
</pre>

<p>
And <i>that</i> is useful for our <code>START</code> and <code>END</code> needs.
You can take it for a test drive at any time with <kbd>M-:</kbd> <code><span>(</span><span>bounds-of-thing-at-point</span> <span>'</span><span>word</span><span>)</span></code> to see where emacs thinks the <i>word</i> at your cursor starts and ends.
This is a common theme when developing elisp: try out functions all the time within the editor since they’re near at hand.
</p>

<p>
The argument to <code><span>bounds-of-thing-at-point</span></code> is a symbol for a literal <i>thing</i> that is predefined by the function <code><span>define-thing-chars</span></code>.
We pass <code><span>define-thing-chars</span></code> a name for our "thing" and a regex, and we can call <code><span>bounds-of-thing-at-point</span></code> with it from that point on.
The function documentation in <code>thingatpt.el</code> that emacs refers you to explains more if you’re interested.
</p>

<p>
<code><span>define-thing-chars</span></code> expects a string with characters to put into a regex character class (like <code>[...]</code>) - just any valid character.
This is a pretty standard character class and we can start with something super simple.
I can’t be bothered to look up whatever the reStructedText spec is for references, but let’s start with "word characters, dashes, and underscores".
That expressed as a "thing" looks like this:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight strings.</span></li>
<li><span>Font used to highlight keywords.</span></li></ul></div><div>
<pre><code><span>(</span><span>define-thing-chars</span> rst-ref <span>"[:alpha:]_-"</span><span>)</span></code>
</pre>
</div>

<p>
Now we have a <i>thing</i> called <code>rst-ref</code> we can use with <code><span>bounds-of-thing-at-point</span></code>.
In typical emacs fashion, we can run elisp ad-hoc in our editor just to tinker, so let’s do that now.
</p>

<p>
Remember: we’re trying to write a function to give us the <code>start</code> and <code>end</code> of whatever piece of text we intend for a completion to replace.
Let’s try it out: in any sort of buffer, put a piece of fake <code>.rst</code> text with a reference, like this:
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for field names and interpreted text.</span></li>
<li><span>Font used for directives and roles.</span></li></ul></div><div>
<pre><code>This is a <span>:ref:</span><span>`other-reference`</span>.</code>
</pre>
</div>

<p>
Place your point somewhere within "<code>other-reference</code>" and try out your <code>thing</code>:
</p>

<p>
<kbd>M-:</kbd> <code><span>(</span><span>bounds-of-thing-at-point</span> <span>'</span><span>rst-ref</span><span>)</span></code>
</p>

<p>
You’ll see something like <code><span>(</span>number . number<span>)</span></code> in the echo area (the little minibuffer at the bottom of the emacs window frame).
Congratulations!
We’ve got the first part of the problem solved.
</p>
</div>
</div>
</div>
<div id="outline-container-gathering-completions">
<h4 id="gathering-completions">Gathering Completions</h4>
<div id="text-gathering-completions">
<p>
Recall the structure of what our "completion backend" needs to return to emacs:
</p>

<p><span><span>ELisp</span></span></p><div>
<pre><code><span>(</span>START END COLLECTION . PROPS<span>)</span></code>
</pre>
</div>

<p>
We can construct <code>START</code> and <code>END</code> with <code><span>bounds-of-thing-at-point</span></code>, now we just need <code>COLLECTION</code>, which is a list of potential candidates.
</p>

<p>
Conceptually the task isn’t hard: we should find all instances of strings of the form:
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for all other defining constructs.</span></li></ul></div>

<p>
in our document and capture <code>my-reference</code>.
Where do we start?
</p>

<p>
Once again you can rely on discovery mechanisms like searching for functions that <i>sound</i> related (by browsing <code><span>describe-function</span></code>) or look at existing code.
Personally, I found this:
</p>

<pre id="orge9859ee"><code>(re-search-forward REGEXP &amp;optional BOUND NOERROR COUNT)</code>
<code></code>
<code>Search forward from point for regular expression REGEXP.</code>
</pre>

<p>
The documentation refers you to some other related functions, like this one:
</p>

<pre id="org335f041"><code>(match-beginning SUBEXP)</code>
<code></code>
<code>Return position of start of text matched by last search.</code>
<code>SUBEXP, a number, specifies which parenthesized expression in the last</code>
<code>regexp.</code>
</pre>

<p>
So we can <code><span>(</span><span>re-search-forward</span><span>)</span></code> for something then invoke <code><span>(</span><span>match-beginning</span> 1<span>)</span></code>, for example, if we used a regex capture group to grab the reference’s label.
Cool: we can start there.
</p>

<p>
As you get deeper into elisp you’ll find that regular expressions are <i>everywhere</i>, and this case is no different.
We need a solid regex to search through a reStructuredText buffer (and honor any quirks in emacs’ regular expression engine), so we’ll use this opportunity to kick the tires on <i>interactively</i> developing regular expressions in emacs.
</p>
</div>
<div id="outline-container-regexes">
<h5 id="regexes">Regexes</h5>
<div id="text-regexes">
<p>
Geriatric millennial software engineers like myself grew up on <a href="https://regexr.com/">https://regexr.com/</a> when it was still a Flash application.
Unless you’re a masochist that lives and breathes regular expressions, it’s kind of hard to develop a good regex without live feedback, which sites like <a href="https://regexr.com/">https://regexr.com/</a> provide.
</p>

<p>
Little did I know that emacs comes with its own live regular expression builder and it's goooood.
</p>

<p>
Within any emacs buffer, run <kbd>M-x</kbd> <code><span>re-builder</span></code> to open the regex builder window split alongside the current buffer.
If I then enter the string <code><span>"re-</span><span><span>\\</span></span><span><span>(</span></span><span>builder</span><span><span>\\</span></span><span><span>)</span></span><span>"</span></code> into that buffer, that string a) gets highlighted in my original buffer and b) the capture group gets highlighted in its own unique group color.
</p>

<p>
You can do this all day long to fine-tune a regular expression, but there’s yet <i>another</i> trick when writing regular expressions, which is to use the <code><span>rx</span></code> macro.
</p>

<p>
My previous example regular expression <code><span>"re-</span><span><span>\\</span></span><span><span>(</span></span><span>builder</span><span><span>\\</span></span><span><span>)</span></span><span>"</span></code> works, but the quirks when writing emacs regular expressions pile up quickly: escaping characters is one example but there are more, too.
</p>

<p>
Instead, the <code><span>rx</span></code> macro will let you define a regular expression in lisp-y form and evaluate it into a typical string-based regular expression you can use normally, so it works any place emacs expects a string-based regular expression.
For example, if you evaluate this with <kbd>M-:</kbd>:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight strings.</span></li>
<li><span>Font used to highlight keywords.</span></li></ul></div><div>
<pre><code><span>(</span><span>rx</span> <span>"re-"</span> <span>(</span>group <span>"builder"</span><span>)</span><span>)</span></code>
</pre>
</div>

<p>
This is what emacs returns:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font for backslashes in Lisp regexp grouping constructs.</span></li>
<li><span>Font used to highlight strings.</span></li></ul></div>

<p>
Identical!
The <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Rx-Constructs.html"><code>rx</code> documentation</a> explains all the constructs available to you.
</p>

<p>
Jumping back to <code><span>re-builder</span></code>, with the <code><span>re-builder</span></code> window active, invoke <kbd>M-x</kbd> <code>reb-change-syntax</code> and choose <code><span>rx</span></code>.
Now you can interactively build regular expressions with the <code><span>rx</span></code> macro!
In the <code><span>re-builder</span></code> window, you’ve got to enter a weird syntax to get it to take <code><span>rx</span></code> constructs (I’m… not sure why this is), but you end up with the same outcome:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight strings.</span></li></ul></div><div>
<pre><code><span>'</span><span>(</span><span>:</span> <span>"re-"</span> <span>(</span>group <span>"builder"</span><span>)</span><span>)</span></code>
</pre>
</div>

<p>
Watch the regex get highlighted live just as it was in the string-based regex mode.
</p>

<p>
To bring this full circle, hop into a buffer with an example <code>.rst</code> document like this one:
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for all other defining constructs.</span></li>
<li><span>Font used for the adornment of a section header.</span></li>
<li><span>Default font for section title text at level 1.</span></li></ul></div><div>
<pre><code><span>A Heading</span></code>
<code><span>=========</span></code>
<code></code>
<code><span>.. _my-reference:</span></code>
<code></code>
<code>Link to me!</code>
</pre>
</div>

<p>
Using our newfound <code><span>re-builder</span></code> knowledge, let’s build a regex interactively to make short work of it:
</p>

<ul>
<li>Invoke <kbd>M-x</kbd> <code><span>re-builder</span></code></li>
<li>Change the engine to something easier with <kbd>M-x</kbd> <code>reb-change-syntax</code> and choose <code><span>rx</span></code></li>
<li>Start trying out solutions</li>
</ul>

<p>
I’ll refer here to the <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Rx-Constructs.html">rx constructs documentation</a> which lists out all the possibilities that you can plug into the <code><span>rx</span></code> macro.
Here’s a recorded example of what developing it looks like from start to finish, ending up with a functional <code><span>rx</span></code> construct:
</p>



<p>
Live-highlighting regex development.
Nice.
If you add more groups, more colors show up.
In this example the <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Rx-Constructs.html">rx constructs</a> I’m using are:
</p>

<ul>
<li>Any strings end up as literal matches</li>
<li>Special symbols <code>bol</code> and <code>eol</code> for "beginning of line" and "end of line", respectively</li>
<li>Symbols like <code>+</code> behave like their regex counterparts ("at least one")</li>
<li>Some symbols like <code>not</code> are nice little shortcuts (in this case, to negate the next form)</li>
</ul>

<p>
Because <code><span>rx</span></code> is a macro, we don’t ever actually <i>need</i> to compile its regular expressions to use elsewhere - we can always just use <code><span>rx</span></code> when we need a regex.
</p>
</div>
</div>
</div>
<div id="outline-container-gathering-completions-continued">
<h4 id="gathering-completions-continued">Gathering Completions: Continued</h4>
<div id="text-gathering-completions-continued">
<p>
Okay, we've cut our teeth on emacs regular expressions.
Let's use 'em.
(Not our teeth. Regexes.)
</p>

<p>
To start, let's save our reStructuredText regular expression to find a <code>ref</code> so we can easily grab it later.
I'll save the one I came up with to the name <code>tmp/re</code> (this name is arbitrary, I drop temporary variables into <code>tmp/&lt;name&gt;</code> out of habit)
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight built-in function names.</span></li>
<li><span>Font used to highlight strings.</span></li>
<li><span>Font used to highlight keywords.</span></li></ul></div><div>
<pre><code><span>(</span><span>setq</span> tmp/re <span>(</span><span>rx</span> bol <span>".."</span> <span>(</span><span>+</span> blank<span>)</span> <span>"_"</span> <span>(</span>group <span>(</span><span>+</span> <span>(</span><span>not</span> <span>":"</span><span>)</span><span>)</span><span>)</span> <span>":"</span> eol<span>)</span><span>)</span></code>
</pre>
</div>

<p>
Now we can reference it easily.
I mentioned before that <code><span>re-search-forward</span></code> accepts a regex, so let's hop into a reStructuredText rev up the regex.
</p>

<p>
Here's my sample text that I'll work with:
</p>

<p><span><span>ReST</span></span></p><div><ul><li><span>Font used for directives and roles.</span></li>
<li><span>Font used for all other defining constructs.</span></li>
<li><span>Font used for the adornment of a section header.</span></li>
<li><span>Default font for section title text at level 1.</span></li></ul></div><div>
<pre><code><span>A Title</span></code>
<code><span>=======</span></code>
<code></code>
<code>Beware the Jabberwock, my son.</code>
<code></code>
<code><span>.. _my-reference:</span></code>
<code></code>
<code>You are like a little baby. Watch this.</code>
<code></code>
<code><span>.. _code-sample:</span></code>
<code></code>
<code><span>.. code::</span> python</code>
<code></code>
<code>   print("emacs needs telemetry")</code>
<code></code>
<code>The end?</code>
</pre>
</div>

<p>
The <code><span>re-search-forward</span></code> documentation indicates that it starts at the <code>point</code>'s current position, so head to the start of the buffer, hit <kbd>M-:</kbd> to enter the elisp <code>Eval</code> prompt, and try:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight built-in function names.</span></li></ul></div><div>
<pre><code><span>(</span><span>re-search-forward</span> tmp/re<span>)</span></code>
</pre>
</div>

<p>
This is anticlimactic because you'll just see the point move to the end of one of the references.
BUT.
This means that the search succeeded.
So… what now?
</p>

<p>
More reading in the <code><span>re-search-forward</span></code> documentation will educate you about emacs <i>global match data</i>.
In non-functional-programming style, functions like <code><span>match-beginning</span></code> and <code><span>match-end</span></code> serve to interrogate a global state that functions like <code><span>re-search-forward</span></code> will modify.
In concise terms, our regular expression defines one match group and we can grab it with <code><span>(</span><span>match-string-no-properties</span> 1<span>)</span></code> to get the first group match (<code><span>match-string</span></code> will return a string with "properties", which is a bunch of data like font styling that we don't want).
</p>

<p>
Within our example buffer, executing this after the regex search should return our match:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight function names.</span></li></ul></div><div>
<pre><code><span>(</span><span>match-string-no-properties</span> 1<span>)</span></code>
</pre>
</div>

<p>
I see <code>"my-reference"</code> from this command.
Now we're cooking like it's 1985, baby.
You can enter the minibuffer again with <kbd>M-:</kbd>, press <kbd>↑</kbd> to find the <code><span>re-search-forward</span></code> command again, and repeat this process again to watch the point move to the next match, after which you can see the matched string with <code><span>match-string-no-properties</span></code>.
</p>

<p>
Note that running this a few times will eventually error out after no matches exist past your point.
We'll address this.
</p>

<p>
If you're a human (or Claude) at this point, you can see the path ahead – we need to write some elisp that will:
</p>

<ul>
<li>Move the point to the beginning of the buffer (important, remember that <code><span>re-search-forward</span></code> relies upon the current position of your point)</li>
<li>Iteratively execute an <code><span>re-search-forward</span></code> command to aggregate reference targets</li>
<li>Conclude when there aren't any more matches</li>
</ul>

<p>
I'll start with the code and then explain which demons the parentheses are summoning afterward:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight function names.</span></li>
<li><span>Font used to highlight strings.</span></li>
<li><span>Font used to highlight special form names.</span></li>
<li><span>Font used to highlight built-in function names.</span></li>
<li><span>Font used to highlight keywords.</span></li>
<li></li>
<li></li></ul></div><div>
<pre><code><span>;; </span><span>This function will save the current position of the cursor and then</span></code>
<code><span>;; </span><span>return it to this position once the code that it wraps has finished</span></code>
<code><span>;; </span><span>executing, which lets us hop around the buffer without driving the</span></code>
<code><span>;; </span><span>programmer insane. Important for any functions that move the point</span></code>
<code><span>;; </span><span>around.</span></code>
<code><span>(</span><span>save-excursion</span></code>
<code>  <span>;; </span><span>progn is a simple function that just executes each lisp form</span></code>
<code>  <span>;; </span><span>step-by-step.</span></code>
<code>  <span>(</span><span>progn</span></code>
<code>    <span>;; </span><span>Step one: go to the beginning of the buffer.</span></code>
<code>    <span>(</span><span>goto-char</span> <span>(</span><span>point-min</span><span>)</span><span>)</span></code>
<code>    <span>;; </span><span>Step two: loop</span></code>
<code>    <span>;;</span><span></span></code>
<code>    <span>;; </span><span>cl-loop is a macro with a long and venerable heritage stemming</span></code>
<code>    <span>;; </span><span>from the common lisp family of macros, which it mimics the</span></code>
<code>    <span>;; </span><span>behavior of. You could spend hours honing your ability to wield</span></code>
<code>    <span>;; </span><span>the common lisp `loop` macro, but we'll just explain the parts</span></code>
<code>    <span>;; </span><span>we're using:</span></code>
<code>    <span>;;</span><span></span></code>
<code>    <span>;; </span><span>`while` runs the loop until its argument evalutates to a falsy</span></code>
<code>    <span>;; </span><span>value. We can overload our use of `re-search-forward` here: we</span></code>
<code>    <span>;; </span><span>can use it to step our loop forward each time and also rely</span></code>
<code>    <span>;; </span><span>upon it returning `nil` once it stops matching substrings in</span></code>
<code>    <span>;; </span><span>the buffer and we should finish up.</span></code>
<code>    <span>(</span><span>cl-loop</span> <span>while</span> <span>(</span><span>re-search-forward</span></code>
<code>                    <span>(</span><span>rx</span> bol <span>".."</span> <span>(</span><span>+</span> blank<span>)</span> <span>"_"</span> <span>(</span>group <span>(</span><span>+</span> <span>(</span><span>not</span> <span>":"</span><span>)</span><span>)</span><span>)</span> <span>":"</span> eol<span>)</span></code>
<code>                    <span>;; </span><span>The aforementioned `while` termination case</span></code>
<code>                    <span>;; </span><span>relies upon this `t` parameter, which says</span></code>
<code>                    <span>;; </span><span>"don't error out with no matches, just return</span></code>
<code>                    <span>;; </span><span>nil". Once no more matches are found, the loop</span></code>
<code>                    <span>;; </span><span>exits.</span></code>
<code>                    nil <span>t</span><span>)</span></code>
<code>             <span>;; </span><span>The `collect` keyword instructs `cl-loop` how to form</span></code>
<code>             <span>;; </span><span>its return value. We can helpfully summarize the regex</span></code>
<code>             <span>;; </span><span>match item by pulling out the global match data.</span></code>
<code>             collect <span>(</span><span>match-string-no-properties</span> 1<span>)</span><span>)</span><span>)</span><span>)</span></code>
</pre>
</div>

<p>
The code is less intimidating without comments:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight function names.</span></li>
<li><span>Font used to highlight strings.</span></li>
<li><span>Font used to highlight special form names.</span></li>
<li><span>Font used to highlight built-in function names.</span></li>
<li><span>Font used to highlight keywords.</span></li></ul></div><div>
<pre><code><span>(</span><span>save-excursion</span></code>
<code>  <span>(</span><span>progn</span></code>
<code>    <span>(</span><span>goto-char</span> <span>(</span><span>point-min</span><span>)</span><span>)</span></code>
<code>    <span>(</span><span>cl-loop</span> <span>while</span> <span>(</span><span>re-search-forward</span></code>
<code>                    <span>(</span><span>rx</span> bol <span>".."</span> <span>(</span><span>+</span> blank<span>)</span> <span>"_"</span> <span>(</span>group <span>(</span><span>+</span> <span>(</span><span>not</span> <span>":"</span><span>)</span><span>)</span><span>)</span> <span>":"</span> eol<span>)</span></code>
<code>                    nil <span>t</span><span>)</span></code>
<code>             collect <span>(</span><span>match-string-no-properties</span> 1<span>)</span><span>)</span><span>)</span><span>)</span></code>
</pre>
</div>

<p>
Without belaboring the point, you can – like I did – discover most of these functions by skimming existing elisp code and using it as a launch pad.
Many of these functions are bog standard and show up all over the place in emacs packages (<code><span>save-excursion</span></code>, <code><span>progn</span></code>, <code><span>goto-char</span></code>…)
</p>

<p>
Here's the result when I run this code against our example <code>.rst</code> file:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight strings.</span></li></ul></div><div>
<pre><code><span>(</span><span>"my-reference"</span> <span>"code-sample"</span><span>)</span></code>
</pre>
</div>

<p>
Looks good!
</p>
</div>
</div>
<div id="outline-container-completing-the-completion-backend">
<h4 id="completing-the-completion-backend">Completing the Completion Backend</h4>
<div id="text-completing-the-completion-backend">
<p>
We're now armed with the ability to:
</p>

<ul>
<li>Identify the bounds of the string we want to replace, and</li>
<li>Collect a list of targets for completion candidates</li>
</ul>

<p>
We are <i>so close</i>.
Recall the description of the variable we need to modify:
</p>

<pre id="orgb0e2210"><code>completion-at-point-functions is a variable defined in ‘minibuffer.el’.</code>
<code></code>
<code>Its value is (cape-dict cape-file tags-completion-at-point-function)</code>
<code></code>
<code>Special hook to find the completion table for the entity at point.</code>
<code>Each function on this hook is called in turn without any argument and</code>
<code>should return either nil, meaning it is not applicable at point,</code>
<code>or a function of no arguments to perform completion (discouraged),</code>
<code>or a list of the form (START END COLLECTION . PROPS)</code>
</pre>

<p>
To return the list that <code><span>completion-at-point-functions</span></code> expects, we already have the ability to identify the bounds of a <code>thing</code> and sweep up a list of candidates in our buffer.
Note the comment about returning <code>nil</code>: we probably don't <i>always</i> want to run our backend, so we should short-circuit our function to eagerly return nil to avoid tying up emacs with a regex loop we don't need.
</p>

<p>
With all that said, <a href="https://en.wikipedia.org/wiki/Bill_Nye">consider the following</a>:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight special form names.</span></li>
<li><span>Font to highlight quoted Lisp symbols.</span></li>
<li><span>Font used to highlight built-in function names.</span></li>
<li><span>Font used to highlight function names.</span></li>
<li><span>Font used to highlight documentation embedded in program code.
It is typically used for special documentation comments or strings.</span></li>
<li><span>Font used to highlight function names.</span></li>
<li><span>Font used to highlight strings.</span></li>
<li><span>Font used to highlight keywords.</span></li>
<li></li>
<li></li></ul></div><div>
<pre><code><span>;; </span><span>Our reStructuredText reference "thing"</span></code>
<code><span>(</span><span>define-thing-chars</span> rst-ref <span>"[:alpha:]_-"</span><span>)</span></code>
<code></code>
<code><span>(</span><span>defun</span> <span>my/rst-internal-reference-capf</span> <span>()</span></code>
<code>  <span>"Completion backend for buffer reStructuredText references"</span></code>
<code>  <span>;; </span><span>Only applies when we're within a reference - outside of a</span></code>
<code>  <span>;; </span><span>reference, we bail out with nil.</span></code>
<code>  <span>(</span><span>when</span> <span>(</span><span>looking-back</span> <span>(</span><span>rx</span> <span>":ref:`"</span> <span>(</span><span>*</span> <span>(</span><span>not</span> <span>"`"</span><span>)</span><span>)</span><span>)</span> <span>(</span><span>point-at-bol</span><span>)</span><span>)</span></code>
<code>    <span>;; </span><span>Get potential bounds for the string to replace</span></code>
<code>    <span>(</span><span>let*</span> <span>(</span><span>(</span>bounds <span>(</span><span>or</span> <span>(</span><span>bounds-of-thing-at-point</span> <span>'</span><span>rst-ref</span><span>)</span></code>
<code>                       <span>;; </span><span>Fallback to the current position</span></code>
<code>                       <span>(</span><span>cons</span> <span>(</span><span>point</span><span>)</span> <span>(</span><span>point</span><span>)</span><span>)</span><span>)</span><span>)</span></code>
<code>           <span>(</span>start <span>(</span><span>car</span> bounds<span>)</span><span>)</span></code>
<code>           <span>(</span>end <span>(</span><span>cdr</span> bounds<span>)</span><span>)</span></code>
<code>           <span>;; </span><span>Collect all reference candidates</span></code>
<code>           <span>(</span>candidates</code>
<code>            <span>;; </span><span>Our previously-noted reference collector</span></code>
<code>            <span>(</span><span>save-excursion</span></code>
<code>              <span>(</span><span>progn</span></code>
<code>                <span>(</span><span>goto-char</span> <span>(</span><span>point-min</span><span>)</span><span>)</span></code>
<code>                <span>(</span><span>cl-loop</span> <span>while</span> <span>(</span><span>re-search-forward</span></code>
<code>                                <span>(</span><span>rx</span> bol <span>".."</span> <span>(</span><span>+</span> blank<span>)</span> <span>"_"</span> <span>(</span>group <span>(</span><span>+</span> <span>(</span><span>not</span> <span>":"</span><span>)</span><span>)</span><span>)</span> <span>":"</span> eol<span>)</span></code>
<code>                                nil <span>t</span><span>)</span></code>
<code>                         collect <span>(</span><span>match-string-no-properties</span> 1<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span></code>
<code>      <span>;; </span><span>Return value suitable for `completion-at-point-functions`</span></code>
<code>      <span>(</span><span>list</span> start end candidates<span>)</span><span>)</span><span>)</span><span>)</span></code>
</pre>
</div>

<ul>
<li>We're following some naming conventions by calling this a "<code>capf</code>" (a "completion-at-point function) and prefixing with <code>my/</code> (a habit to namespace your own functions)</li>
<li>Our short-circuit takes the form of using <code><span>looking-back</span></code> to ask, "are we inside of a reStructuredText reference"?
Note the use of <code><span>rx</span></code> here again to clean up our lisp.</li>
<li>We use our <code>rst-ref</code> <code>thing</code> to easily snag the <code>start</code> and <code>end</code> of the string to replace – note our fallback to <i>just</i> the immediate point if we can't find the bounds of our <code>thing</code>.</li>
</ul>

<p>
We wrap it all up with <code>list</code>.
Personally, even as somebody relatively new to writing Lisps, I find the code pleasant to read and self-evident.
We did a lot in 17 lines of code!
</p>

<p>
Inside of our test <code>.rst</code> buffer, we can test drive this function.
First, invoke <kbd>M-x</kbd> <code><span>eval-defun</span></code> with your cursor somewhere in the function to evaluate it, which makes <code>my/rst-internal-reference-capf</code> available.
Then run:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font to highlight quoted Lisp symbols.</span></li>
<li><span>Font used to highlight variable names.</span></li>
<li><span>Font used to highlight function names.</span></li></ul></div><div>
<pre><code><span>(</span><span>add-hook</span> <span>'</span><span>completion-at-point-functions</span> <span>'</span><span>my/rst-internal-reference-capf</span><span>)</span></code>
</pre>
</div>

<p>
Huzzah!
Our function is now live in emacs' completion framework.
You can trigger the completion by calling <code>completion-at-point</code> at a relevant spot in a buffer.
Many batteries-included emacs distributions like spacemacs or doom emacs slap nice-looking porcelain on top of the completion framework; here's an example that uses the <a href="https://github.com/minad/corfu">corfu</a> package:
</p>



<p>
Congratulations, you've extended emacs for the first time!
</p>
</div>
</div>
<div id="outline-container-dressing-up-the-bones">
<h4 id="dressing-up-the-bones">Dressing Up the Bones</h4>
<p>
Okay, this is a pretty basic setup.
You could improve it in <i>many</i> ways, but here are a few ideas about potential directions:
</p>
<div id="outline-container-mode-hooks">
<h5 id="mode-hooks">Mode Hooks</h5>
<div id="text-mode-hooks">
<p>
Manually adding your custom completion function to the <code><span>completion-at-point-functions</span></code> hook is tedious, but there's a way to automate it.
Recall that in emacs parlance, a "hook" is usually a <i>variable</i> that holds a <i>list of functions</i> that get called at a <i>specific time</i>.
</p>

<p>
If you use <a href="https://docutils.sourceforge.io/docs/user/emacs.html">rst-mode</a>, then opening an <code>.rst</code> file will drop you into <code><span>rst-mode</span></code> and implicitly call the <code><span>rst-mode-hook</span></code> functions.
That means that this line is sufficient to integrate our completion function:
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font to highlight quoted Lisp symbols.</span></li>
<li><span>Font to highlight Lisp quotes.</span></li>
<li><span>Font used to highlight keywords.</span></li>
<li><span>Font used to highlight variable names.</span></li>
<li><span>Font used to highlight function names.</span></li></ul></div><div>
<pre><code><span>(</span><span>add-hook</span> <span>'</span><span>rst-mode-hook</span> <span>(</span><span>lambda</span> <span>()</span> </code>
<code>    <span>(</span><span>add-hook</span> <span>'</span><span>completion-at-point-functions</span>  <span>#'</span><span>my/rst-internal-reference-capf</span> 0 <span>t</span><span>)</span><span>)</span><span>)</span></code>
</pre>
</div>

<p>
This says: "when I open an <code>.rst</code> file, run this lambda that modifies <code><span>completion-at-point-functions</span></code> <i>only</i> for this buffer by adding my internal reference completion function".
It's a little nested which makes it less obvious with the two <code>add-hook</code> calls.
</p>
</div>
</div>
<div id="outline-container-other-files">
<h5 id="other-files">Other Files</h5>
<div id="text-other-files">
<p>
Okay, our example works for references in the <i>same buffer</i> but this is sort of pointless for uses <i>across</i> files.
</p>

<p>
You can solve this too, although my post is already too long so we won't solve this step-by-step.
However, here's how <i>I</i> solved it:
</p>

<ul>
<li>Turn my <code>capf</code> into a minor mode that manages the completion variables</li>
<li>Doesn't search the buffer every time but instead does so once and then rebuilds it with a hook in <code><span>after-change-functions</span></code>, saving it to a hash cache</li>
<li>Walk all <code>.rst</code> files in the current project and run the reference collection function for each, storing the results into a hash cache for all files that don't have live buffers</li>
<li>When it comes time to call the completion function, combine the hash for completions for files without buffers along with each <code>.rst</code> buffer's cached list of references</li>
</ul>

<p>
It sounds complicated, but it works!
Functions like <code><span>with-temp-buffer</span></code> make this pretty easy by aggregating reference targets for files using the exact same function we do for live buffers.
</p>

<p><span><span>ELisp</span></span></p><div><ul><li><span>Font used to highlight built-in function names.</span></li>
<li><span>Font used to highlight keywords.</span></li></ul></div><div>
<pre><code><span>(</span><span>with-temp-buffer</span></code>
<code>  <span>(</span><span>insert-file-contents</span> file<span>)</span></code>
<code>  <span>(</span>my/rst-internal-references<span>)</span><span>)</span></code>
</pre>
</div>
</div>
</div>
<div id="outline-container-fancy-completion">
<h5 id="fancy-completion">Fancy Completion</h5>
<div id="text-fancy-completion">
<p>
Emacs' long history includes <a href="https://company-mode.github.io/">company-mode</a>, which is a third-party completion framework that integrates with the <code><span>completion-at-point</span></code> set of functions.
Some <code><span>company-mode</span></code> features include additional metadata about completion candidates, and I found two that were useful: <code>company-kind</code> and <code>company-doc-buffer</code>.
</p>

<ul>
<li><code>company-kind</code> is a simple key that just tells the completion caller what the completion cadidate <i>is</i>.
In our case we can add some eye candy by indicating it's <code><span>'</span><span>text</span></code>.</li>
<li><code>company-doc-buffer</code> lets us add additional context to a completion candidate.
I leveraged this to include a couple of lines following the reference line to help me figure out what exactly the link refers to.
It's easier to show what this looks like rather than tell:</li>
</ul>



<p>
Notes:
</p>

<ul>
<li>I'm using GUI emacs here for the nicer completion popup with <a href="https://github.com/minad/corfu">corfu</a> which displays a transparent, floating frame</li>
<li>My completion candidate "context" is a real excerpt from the text around the reference, complete with styling, etc.</li>
<li>The small icon to the left of each candidate comes from the <code>company-kind</code> attribute.</li>
<li>The <code>~</code> syntax is part of <a href="https://github.com/oantolin/orderless">orderless</a></li>
</ul>

<p>
Completion candidate context is an extra frill but very helpful.
</p>
</div>
</div>
</div>
<div id="outline-container-summary">
<h4 id="summary">Summary</h4>
<p>
My experience extending a core emacs function was an instructive and interesting exercise.
I don't know what the future of emacs looks like in an increasingly LLM-crazed world, but I hope that future includes an open and powerful way to extend and customize the tools we use to write software.
</p>
</div>


<hr>



<hr>







        </section>
    </div></div>]]></description>
        </item>
    </channel>
</rss>