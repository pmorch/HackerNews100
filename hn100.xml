<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 16 Feb 2024 05:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Magika: AI powered fast and efficient file type identification (186 pts)]]></title>
            <link>https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html</link>
            <guid>39391688</guid>
            <pubDate>Fri, 16 Feb 2024 01:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html">https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html</a>, See on <a href="https://news.ycombinator.com/item?id=39391688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-824803887080674909" itemprop="articleBody">
<meta content="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbkRgYqDxKQrhyphenhyphenl-sNYpZJ08Oo5TqD08Yk5tcbCYzFatO-cDjDRlDH96vDiO0ylvYN-TZoKSfR4LBln1wSFJLixBRiuVeuzaF0UQ3wGUMt14VKugPHuk7q0CwSgeg0V7OVS_yxaUXbFus2yVXrLmRdB88QQyXagMFE6Axs91iDgdq1hUkS4hsS4ECMuf4/s1600/OSS-Majika-Social-V5.png" name="twitter:image">
<p>

<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxNXxbDvO9U0sI1_Vh0b_iePDZZDhr-XzvjOQTrAFBHEnaFSoohzbNR36Op83b8Hj7L1JOiex5JWEyQFVzC5jWBtLRULhMDmbu_Z4Cs3094FwQVmI8H2uOYKIu_ozG4luPhxeJIQiH_GjV7zAP4K-o-B6RnTZptdhH3nhUfatSurWEmn2x9vdp0vitAk4/s1600/OSS-Magika-Banner-V5%20%281%29.png"><img data-original-height="800" data-original-width="1058" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxNXxbDvO9U0sI1_Vh0b_iePDZZDhr-XzvjOQTrAFBHEnaFSoohzbNR36Op83b8Hj7L1JOiex5JWEyQFVzC5jWBtLRULhMDmbu_Z4Cs3094FwQVmI8H2uOYKIu_ozG4luPhxeJIQiH_GjV7zAP4K-o-B6RnTZptdhH3nhUfatSurWEmn2x9vdp0vitAk4/s1600/OSS-Magika-Banner-V5%20%281%29.png"></a></p><p>Today we are <a href="https://google.github.io/magika/" target="_blank">open-sourcing Magika</a>, Google’s AI-powered file-type identification system, to help others accurately detect binary and textual file types. Under the hood, Magika employs a custom, highly optimized deep-learning model, enabling precise file identification within milliseconds, even when running on a CPU. </p>

<div><table><tbody><tr><td><center><img alt="Magika command line tool used to recognize a identify the type of a diverse set of files" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiPjf8Rag2sUXJw_aUJcqEBo_RPNRG0PyFSJI8FXuyeaCYT195znXw4DW235ZHVihlUfZ744MFeZBlfhG_xdq8jjnQN5ICFjMO-rphRjt9BfO1gfyupghgAPWxNsivP9l362AcNXWnFSj_CzaJ1Con6ZMfJ1RcFExjhCDRMUs59qcQAxulIlkhBn-uhNDU/s1600/image1.png" td=""></center></td></tr><tr><td><i>Magika command line tool used to recognize a identify the type of a diverse set of files</i></td></tr></tbody></table></div>

<p>You can <a href="https://google.github.io/magika/" target="_blank">try the Magika web demo today</a>, or install it as a Python library and standalone command line tool (output is showcased above) by  using the standard command line  <span>pip install magika</span>.</p>

<h2>Why identifying file type is difficult</h2>

<p>Since the early days of computing, accurately detecting file types has been crucial in determining how to process files. Linux comes equipped with <a href="https://github.com/file/file" target="_blank"><span>libmagic</span> and the <span>file utility</span></a>, which have served as the de facto standard for file type identification for over 50 years. Today web browsers, code editors, and countless other software rely on file-type detection to decide how to properly render a file. For example, modern code editors use file-type detection to choose which syntax coloring scheme to use as the developer starts typing in a new file. </p>

<p>Accurate file-type detection is a notoriously difficult problem because each file format has a different structure, or no structure at all. This is particularly challenging for textual formats and programming languages as they have very similar constructs. So far, <span>libmagic</span> and most other file-type-identification software have been relying on a handcrafted collection of heuristics and custom rules to detect each file format.</p> 

<p>This manual approach is both time consuming and error prone as it is hard for humans to create generalized rules by hand. In particular for security applications, creating dependable detection is especially challenging as attackers are constantly attempting to confuse detection with adversarially-crafted payloads.</p>

<p>To address this issue and provide fast and accurate file-type detection we researched and developed Magika, a new AI powered file type detector. Under the hood, Magika uses a custom, highly optimized deep-learning model designed and trained using <a href="https://keras.io/" target="_blank">Keras</a> that only weighs about 1MB.  At inference time Magika uses  <a href="https://onnx.ai/" target="_blank">Onnx</a> as an inference engine to ensure files are identified in a matter of milliseconds, almost as fast as a non-AI tool even on CPU.</p>

<h2>Magika Performance</h2>

<div><table><tbody><tr><td><center><img alt="Magika detection quality compared to other tools on our 1M files benchmark" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuz_BUIEGw6FQfhzA1lr4EQ1SLO_O0S8TIlGrnYY5Kh0BRngFTboPD4_DTCYsbKkO9c51xUKaulCu8ivEdyQlGIhEfvRzleArV9XpatHdvgSf62F1kt3DMwSOwOOan6gL2kaaangCIzQBv1ZVGIXInx-9jpO9N_OkYR8LeJvl6A-Ba3Qdfq441i9QBxvY/s1600/image2.png" td=""></center></td></tr><tr><td><i>Magika detection quality compared to other tools on our 1M files benchmark</i></td></tr></tbody></table></div>

<p>Performance wise, Magika, thanks to its AI model and large training dataset, is able to  outperform other existing tools by about 20% when evaluated on a 1M files benchmark that encompasses over 100 file types.  Breaking down by file type, as reported in the table below, we see even greater performance gains on textual files, including code files  and configuration files that other tools can struggle with.</p>

<div><table><tbody><tr><td><center><img alt="Table showing various file type identification tools performance for a selection of the file types included in our benchmark" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYHJfKw3xp2yBY_qdS8RcamEPn5oWhK2jbbkSgztnC_icqV7IFqh3lcAOWEzEu20TI2zMwBsdBp6YauRRc-ouVZTqLpxbkW5PMoBfuZLgSJKwfYIBVjGrrbM8Ob2P5iuJvQXE2eQ5mGe0WFXT4ilZbciPwasz8h-6AKx-sk7CH_klLRwrYbC3VqDPqlng/s1600/Screenshot%202024-02-15%20at%2011.24.40%E2%80%AFAM.png" td=""></center></td></tr><tr><td><i>Various file type identification tools performance for a selection of the file types included in our benchmark - n/a indicates the tool doesn’t detect the given file type.</i></td></tr></tbody></table></div><br>

<h2>Magika at Google</h2>

<p>Internally, Magika is used at scale to help improve Google users’ safety by routing Gmail, Drive, and Safe Browsing files to the proper security and content policy scanners.
Looking at a weekly average of hundreds of billions of files reveals that Magika improves file type identification accuracy by 50% compared to our previous system that relied on handcrafted rules. In particular, this increase in accuracy allows us to scan 11% more files with our <a href="https://security.googleblog.com/2020/02/improving-malicious-document-detection.html" target="_blank">specialized malicious AI document scanners</a> and reduce the number of unidentified files to 3%.</p>

<p>The upcoming integration of Magika with VirusTotal will complement the platform's existing Code Insight functionality, which employs Google's generative AI to analyze and detect malicious code. Magika will act as a pre-filter before files are analyzed by <a href="https://blog.virustotal.com/2023/04/introducing-virustotal-code-insight.html" target="_blank">Code Insight</a>, improving the platform’s efficiency and accuracy. This integration, due to VirusTotal’s collaborative nature, directly contributes to the global cybersecurity ecosystem, fostering a safer digital environment.</p>

<h2>Open Sourcing Magika</h2>

<p>By <a href="https://google.github.io/magika/" target="_blank">open-sourcing Magika</a>, we aim to help other software improve their file identification accuracy and offer researchers a reliable method for identifying file types at scale. </p>

<p><a href="https://github.com/google/magika" target="_blank">Magika code and model</a> are freely available starting today in Github under the Apache2 License. Magika  can also quickly be installed as a standalone utility and python library via the <a href="https://pypi.org/project/magika/" target="_blank">pypi package manager</a> by simply typing <span>pip install</span> magika with no GPU required. We also have an experimental <a href="https://www.npmjs.com/package/magika" target="_blank">npm package</a> if you would like to use the TFJS version.</p>

<p>To learn more about how to use it, please refer to <a href="https://www.npmjs.com/package/magika" target="_blank">Magika documentation site</a>.</p><br>

<h4><span>Acknowledgements </span></h4>
  
<p>Magika would not have been possible without the help of many people including: Ange Albertini, Loua Farah, Francois Galilee, Giancarlo Metitieri, Luca Invernizzi, Young Maeng, Alex Petit-Bianco, David Tao, Kurt Thomas, Amanda Walker, and Zhixun Tan.</p>

<p><em>By Elie Bursztein – Cybersecurity AI Technical and Research Lead and Yanick Fratantonio – Cybersecurity Research Scientist</em></p>







</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Video generation models as world simulators (127 pts)]]></title>
            <link>https://openai.com/research/video-generation-models-as-world-simulators</link>
            <guid>39391458</guid>
            <pubDate>Fri, 16 Feb 2024 00:38:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>, See on <a href="https://news.ycombinator.com/item?id=39391458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><!--[--><!--[--><!--]--><!--[--><div><p>This technical report focuses on (1) our method for turning visual data of all types into a unified representation that enables large-scale training of generative models, and (2) qualitative evaluation of Sora’s capabilities and limitations. Model and implementation details are not included in this report.</p><p>Much prior work has studied generative modeling of video data using a variety of methods, including recurrent networks,<span><sup><span>[^1]</span></sup><!----></span><span><sup><span>[^2]</span></sup><!----></span><span><sup><span>[^3]</span></sup><!----></span> generative adversarial networks,<span><sup><span>[^4]</span></sup><!----></span><span><sup><span>[^5]</span></sup><!----></span><span><sup><span>[^6]</span></sup><!----></span><span><sup><span>[^7]</span></sup><!----></span> autoregressive transformers,<span><sup><span>[^8]</span></sup><!----></span><span><sup><span>[^9]</span></sup><!----></span> and diffusion models.<span><sup><span>[^10]</span></sup><!----></span><span><sup><span>[^11]</span></sup><!----></span><span><sup><span>[^12]</span></sup><!----></span> These works often focus on a narrow category of visual data, on shorter videos, or on videos of a fixed size. Sora is a generalist model of visual data—it can generate videos and images spanning diverse durations, aspect ratios and resolutions, up to a full minute of high definition video.<br></p></div><!--]--><!--[--><div id="turning-visual-data-into-patches" data-heading=""><p><h2>Turning visual data into patches</h2></p></div><!--]--><!--[--><div><p>We take inspiration from large language models which acquire generalist capabilities by training on internet-scale data.<span><sup><span>[^13]</span></sup><!----></span><span><sup><span>[^14]</span></sup><!----></span> The success of the LLM paradigm is enabled in part by the use of tokens<em> </em>that elegantly unify diverse modalities of text—code, math and various natural languages. In this work, we consider how generative models of visual data can inherit such benefits. Whereas LLMs have text tokens, Sora has visual <em>patches</em>. Patches have previously been shown to be an effective representation for models of visual data.<span><sup><span>[^15]</span></sup><!----></span><span><sup><span>[^16]</span></sup><!----></span><span><sup><span>[^17]</span></sup><!----></span><span><sup><span>[^18]</span></sup><!----></span> We find that patches are a highly-scalable and effective representation for training generative models on diverse types of videos and images.<br></p></div><!--]--><!--[--><div><figure><p><img src="https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=10&amp;height=10&amp;quality=50" width="2031" height="378" alt="Figure Patches" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false"></p><figcaption><!--[--><!--]--></figcaption></figure></div><!--]--><!--[--><div><p>At a high level, we turn videos into patches by first compressing videos into a lower-dimensional latent space,<span><sup><span>[^19]</span></sup><!----></span> and subsequently decomposing the representation into spacetime patches.<br></p></div><!--]--><!--[--><div id="video-compression-network" data-heading=""><p><h2>Video compression network</h2></p></div><!--]--><!--[--><div><p>We train a network that reduces the dimensionality of visual data.<span><sup><span>[^20]</span></sup><!----></span> This network takes raw video as input and outputs a latent representation that is compressed both temporally and spatially. Sora is trained on and subsequently generates videos within this compressed latent space. We also train a corresponding decoder model that maps generated latents back to pixel space.</p></div><!--]--><!--[--><div id="spacetime-latent-patches" data-heading=""><p><h2>Spacetime Latent Patches</h2></p></div><!--]--><!--[--><div><p>Given a compressed input video, we extract a sequence of spacetime patches which act as transformer tokens. This scheme works for images too since images are just videos with a single frame. Our patch-based representation enables Sora to train on videos and images of variable resolutions, durations and aspect ratios. At inference time, we can control the size of generated videos by arranging randomly-initialized patches in an appropriately-sized grid.<br></p></div><!--]--><!--[--><div id="scaling-transformers-for-video-generation" data-heading=""><p><h2>Scaling transformers for video generation</h2></p></div><!--]--><!--[--><div><p>Sora is a diffusion model<span><sup><span>[^21]</span></sup><!----></span><span><sup><span>[^22]</span></sup><!----></span><span><sup><span>[^23]</span></sup><!----></span><span><sup><span>[^24]</span></sup><!----></span><span><sup><span>[^25]</span></sup><!----></span>; given input noisy patches (and conditioning information like text prompts), it’s trained to predict the original “clean” patches. Importantly, Sora is a diffusion <em>transformer</em>.<span><sup><span>[^26]</span></sup><!----></span> Transformers have demonstrated remarkable scaling properties across a variety of domains, including language modeling,<span><sup><span>[^13]</span></sup><!----></span><span><sup><span>[^14]</span></sup><!----></span> computer vision,<span><sup><span>[^15]</span></sup><!----></span><span><sup><span>[^16]</span></sup><!----></span><span><sup><span>[^17]</span></sup><!----></span><span><sup><span>[^18]</span></sup><!----></span> and image generation.<span><sup><span>[^27]</span></sup><!----></span><span><sup><span>[^28]</span></sup><!----></span><span><sup><span>[^29]</span></sup><!----></span><br></p></div><!--]--><!--[--><div><figure><p><img src="https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=10&amp;height=10&amp;quality=50" width="1261" height="312" alt="Figure Diffusion" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false"></p><figcaption><!--[--><!--]--></figcaption></figure></div><!--]--><!--[--><div><p>In this work, we find that diffusion transformers scale effectively as video models as well. Below, we show a comparison of video samples with fixed seeds and inputs as training progresses. Sample quality improves markedly as training compute increases.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="variable-durations-resolutions-aspect-ratios" data-heading=""><p><h2>Variable durations, resolutions, aspect ratios</h2></p></div><!--]--><!--[--><div><p>Past approaches to image and video generation typically resize, crop or trim videos to a standard size – e.g., 4 second videos at 256x256 resolution. We find that instead training on data at its native size provides several benefits.<br></p></div><!--]--><!--[--><div id="sampling-flexibility" data-heading=""><p><h3>Sampling flexibility</h3></p></div><!--]--><!--[--><div><p>Sora can sample widescreen 1920x1080p videos, vertical 1080x1920 videos and everything inbetween. This lets Sora create content for different devices directly at their native aspect ratios. It also lets us quickly prototype content at lower sizes before generating at full resolution—all with the same model.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="improved-framing-and-composition" data-heading=""><p><h3>Improved framing and composition</h3></p></div><!--]--><!--[--><div><p>We empirically find that training on videos at their native aspect ratios improves composition and framing. We compare Sora against a version of our model that crops all training videos to be square, which is common practice when training generative models. The model&nbsp; trained on square crops (left) sometimes generates videos where the subject is only partially in view. In comparison, videos from Sora (right)s have improved framing.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="language-understanding" data-heading=""><p><h2>Language understanding</h2></p></div><!--]--><!--[--><div><p>Training text-to-video generation systems requires a large amount of videos with corresponding text captions. We apply the re-captioning technique introduced in DALL·E 3<span><sup><span>[^30]</span></sup><!----></span> to videos. We first train a highly descriptive captioner model and then use it to produce text captions for all videos in our training set. We find that training on highly descriptive video captions improves text fidelity as well as the overall quality of videos.</p><p>Similar to DALL·E 3, we also leverage GPT to turn short user prompts into longer detailed captions that are sent to the video model. This enables Sora to generate high quality videos that accurately follow user prompts.<br></p></div><!--]--><!--[--><div layout="full-bleed" id="SoraMadlib-25"><p> taking a pleasant stroll in </p></div><!--]--><!--[--><div id="prompting-with-images-and-videos" data-heading=""><p><h2>Prompting with images and videos</h2></p></div><!--]--><!--[--><div><p>All of the results above and in our <a href="https://openai.com/sora" rel="noopener noreferrer">landing page</a> show text-to-video samples. But Sora can also be prompted with other inputs, such as pre-existing images or video. This capability enables Sora to perform a wide range of image and video editing tasks—creating perfectly looping video, animating static images, extending videos forwards or backwards in time, etc.<br></p></div><!--]--><!--[--><div id="animating-dall-e-images" data-heading=""><p><h3>Animating DALL·E images</h3></p></div><!--]--><!--[--><div><p>Sora is capable of generating videos provided an image and prompt as input. Below we show example videos generated based on DALL·E 2<span><sup><span>[^31]</span></sup><!----></span> and DALL·E 3<span><sup><span>[^30]</span></sup><!----></span> images.<br></p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-30"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_0.png"></p></div><!--]--><p>A Shiba Inu dog wearing a beret and black turtleneck.</p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-31"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_2.png"></p></div><!--]--><p>Monster Illustration in flat design style of a diverse family of monsters. The group includes a furry brown monster, a sleek black monster with antennas, a spotted green monster, and a tiny polka-dotted monster, all interacting in a playful environment.</p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-32"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_4.png"></p></div><!--]--><p>An image of a realistic cloud that spells “SORA”.</p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-33"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_6.png"></p></div><!--]--><p>In an ornate, historical hall, a massive tidal wave peaks and begins to crash. Two surfers, seizing the moment, skillfully navigate the face of the wave.</p></div><!--]--><!--[--><div id="extending-generated-videos" data-heading=""><p><h3>Extending generated videos</h3></p></div><!--]--><!--[--><div><p>Sora is also capable of extending videos, either forward or backward in time. Below are four videos that were all extended backward in time starting from a segment of a generated video. As a result, each of the four videos starts different from the others, yet all four videos lead to the same ending.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>We can use this method to extend a video both forward and backward to produce a seamless infinite loop.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="video-to-video-editing" data-heading=""><p><h3>Video-to-video editing</h3></p></div><!--]--><!--[--><div><p>Diffusion models have enabled a plethora of methods for editing images and videos from text prompts. Below we apply one of these methods, SDEdit,<span><sup><span>[^32]</span></sup><!----></span> to Sora. This technique enables Sora to transform&nbsp; the styles and environments of input videos zero-shot.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="connecting-videos" data-heading=""><p><h3>Connecting videos</h3></p></div><!--]--><!--[--><div><p>We can also use Sora to gradually interpolate between two input videos, creating seamless transitions between videos with entirely different subjects and scene compositions. In the examples below, the videos in the center interpolate between the corresponding videos on the left and right.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="image-generation-capabilities" data-heading=""><p><h2>Image generation capabilities</h2></p></div><!--]--><!--[--><div><p>Sora is also capable of generating images. We do this by arranging patches of Gaussian noise in a spatial grid with a temporal extent of one frame. The model can generate images of variable sizes—up to 2048x2048 resolution.<br></p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-47"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_0.png"><span>Close-up portrait shot of a woman in autumn, extreme detail, shallow depth of field</span></p></div><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_1.png"><span>Vibrant coral reef teeming with colorful fish and sea creatures</span></p></div><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_2.png"><span>Digital art of a young tiger under an apple tree in a matte painting style with gorgeous details</span></p></div><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_3.png"><span>A snowy mountain village with cozy cabins and a northern lights display, high detail and photorealistic dslr, 50mm f/1.2</span></p></div><!--]--><!----></div><!--]--><!--[--><div id="emerging-simulation-capabilities" data-heading=""><p><h2>Emerging simulation capabilities</h2></p></div><!--]--><!--[--><div><p>We find that video models exhibit a number of interesting emergent capabilities when trained at scale. These capabilities enable Sora to simulate some aspects of people, animals and environments from the physical world. These properties emerge without any explicit inductive biases for 3D, objects, etc.—they are purely phenomena of scale.</p><p><strong>3D consistency.</strong> Sora can generate videos with dynamic camera motion. As the camera shifts and rotates, people and scene elements move consistently through three-dimensional space.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p><strong>Long-range coherence and object permanence. </strong>A significant challenge for video generation systems has been maintaining temporal consistency when sampling long videos. We find that Sora is often, though not always, able to effectively model both short- and long-range dependencies. For example, our model can persist people, animals and objects even when they are occluded or leave the frame. Likewise, it can generate multiple shots of the same character in a single sample, maintaining their appearance throughout the video.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p><strong>Interacting with the world.</strong> Sora can sometimes simulate actions that affect the state of the world in simple ways. For example, a painter can leave new strokes along a canvas that persist over time, or a man can eat a burger and leave bite marks.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p><strong>Simulating digital worlds.</strong> Sora is also able to simulate artificial processes–one example is video games. Sora can simultaneously control the player in Minecraft with a basic policy while also rendering the world and its dynamics in high fidelity. These capabilities can be elicited zero-shot by prompting Sora with captions mentioning “Minecraft.”<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>These capabilities suggest that continued scaling of video models is a promising path towards the development of highly-capable simulators of the physical and digital world, and the objects, animals and people that live within them.<br></p></div><!--]--><!--[--><div id="discussion" data-heading=""><p><h2>Discussion</h2></p></div><!--]--><!--[--><!--]--><!--[--><div><p>Sora currently exhibits numerous limitations as a simulator. For example, it does not accurately model the physics of many basic interactions, like glass shattering. Other interactions, like eating food, do not always yield correct changes in object state. We enumerate other common failure modes of the model—such as incoherencies that develop in long duration samples or spontaneous appearances of objects—in our <a href="https://openai.com/sora" rel="noopener noreferrer">landing page</a>.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>We believe the capabilities Sora has today demonstrate that continued scaling of video models is a promising path towards the development of capable simulators of the physical and digital world, and the objects, animals and people that live within them.<br></p></div><!--]--><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It Was 33 Years Ago Today: Happy Birthday Lemmings (175 pts)]]></title>
            <link>https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/</link>
            <guid>39390965</guid>
            <pubDate>Thu, 15 Feb 2024 23:48:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/">https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/</a>, See on <a href="https://news.ycombinator.com/item?id=39390965">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-37461">
		<!-- .entry-header -->

	
	<div>
		
<p>Today, February 14th, 2024, marks the 33rd anniversary of <em><a href="https://en.wikipedia.org/wiki/Lemmings_(video_game)">Lemmings</a></em>, the game that transcended mere entertainment to become a cultural icon and a catalyst for Scotland’s thriving game development industry. But before the green-haired hordes invaded screens worldwide, let’s rewind to 1991 and trace its remarkable journey.</p>



<p>Born from the minds of DMA Design (now of course Rockstar North), a small Dundee studio, Lemmings was a revolutionary concept. Instead of blowing things you, you were tasked with saving the plummeting rodents’ lives. </p>



<p>However, DMA’s genius lay in its execution. With charming character design (at an astonishingly small scale), addictive puzzle mechanics, and more than a touch of what would become DMA’s slapstick humour, they transformed a complex concept into a game anyone could pick up and play.</p>


<div>
<figure><a href="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?ssl=1"><img loading="lazy" decoding="async" width="580" height="363" data-attachment-id="4108" data-permalink="https://scottishgames.net/2012/11/06/steve-hammonds-manual-override-realit/lemmings-8bit/" data-orig-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?fit=580%2C363&amp;ssl=1" data-orig-size="580,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="lemmings 8bit" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?fit=580%2C363&amp;ssl=1" src="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?resize=580%2C363&amp;ssl=1" alt="Lemming. 8 Bit." data-recalc-dims="1"></a></figure></div>


<p><em>Lemmings</em> offered a simple premise: guide a predetermined number of lemmings to an exit by assigning them roles like blocker, climber, builder, and floater. But simplicity masks depth. Each level presented a unique challenge, requiring strategic thinking, quick reflexes, and a touch of trial-and-error gory death.</p>



<p>Success was immediate. <em>Lemmings</em> conquered consoles and computers, selling over 15 million copies and becoming the UK’s best-selling game of 1991. Awards and accolades rained down, but perhaps the most significant impact was on Scottish gaming itself. Lemmings put DMA Design on the map, attracting talent and investment and inspiring the world’s first games degree.</p>



<p>The Scottish Games Network spoke to several of the original team members to ask for their thoughts on the impact of the game:</p>



<h4>Mike Dailly, the creator of the original animation of tiny things being splattered, said:</h4>



<blockquote>
<p>I’m constantly amazed at the legacy of Lemmings. Where ever I go, there are fans, old and new who love the game. With the style, and accessibility of it, it not only entertained, but brought families closer together as kids played with their non-game playing parents and grandparents. I get people getting in touch all the time telling me of their happy memories of playing it with their relatives who never had an interest in games before, and being able to share their hobby with them, meant the world to them.</p>



<p>Even now at shows, some 33 years later, you’ll still see the odd person dressed up as a Lemming and expressing love for the game, the music, the sound effects, the characters – or how they were useless at it, but loved to just nuke them!</p>



<p>Lemmings is still the game I’m most proud to have been a part of, in a world of first person shooters, it’s as popular now as it ever was with young and old alike</p>
</blockquote>



<h4>Russell Kay, told us his dream is to bring the games to a new generation:</h4>



<blockquote>
<p>33 years ago we released a game that is still loved today that is very gratifying and I don’t think any of us would have believed you if we were told at the time. Over the years we have fallen in and out of love with the franchise but it holds a special place in our hearts, personally I would love to be able to update the characters and franchise but Sony hold onto the rights jealously, it would be fantastic to get a chance to see what the Lemmings would make of the modern gaming world!</p>
</blockquote>



<p>Lemmings’ influence resonated far beyond Scotland. It can be said to have popularised puzzle games, inspiring titles like <em>The Incredible Machine</em>. Its emphasis on physics and user-generated content laid the groundwork for future sandbox games (possibly even <em>Minecraft</em>…?)</p>



<p>Moreover, its humour and memorable characters solidified DMA Design’s reputation for innovative, surprising and engaging gameplay, paving the way for future classics like <em>Grand Theft Auto</em>, the often overlooked (and far more bonkers) <em>Tanktics</em>, cult-classic <em>Body Harvest</em> and the underrated <em>Wild Metal Country</em>.</p>



<p>Today, Lemmings remains a beloved puzzle classic, enjoying re-releases on various platforms and inspiring new generations of designers. But its legacy extends far beyond nostalgic pixelated memories. Dundee’s city centre plays host to a beloved <a href="https://scottishgames.net/2013/10/14/lets-go-lemmings-in-the-real-world/">series of statues of Lemmings</a>, hard at work, climbing and bridging a garden gateway overlooking the river Tay.</p>


<div>
<figure><a href="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?ssl=1"><img loading="lazy" decoding="async" width="740" height="448" data-attachment-id="37472" data-permalink="https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/screenshot-2024-02-14-at-14-08-29/" data-orig-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?fit=1398%2C846&amp;ssl=1" data-orig-size="1398,846" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-02-14 at 14.08.29" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?fit=300%2C182&amp;ssl=1" data-large-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?fit=740%2C448&amp;ssl=1" src="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=740%2C448&amp;ssl=1" alt="Lemmings statue, Perth Road, Dundee" srcset="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=1024%2C620&amp;ssl=1 1024w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=300%2C182&amp;ssl=1 300w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=768%2C465&amp;ssl=1 768w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=1200%2C726&amp;ssl=1 1200w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=500%2C303&amp;ssl=1 500w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?w=1398&amp;ssl=1 1398w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px" data-recalc-dims="1"></a></figure></div>


<p>On the 20th anniversary in 2011 <a href="https://scottishgames.net/2021/02/15/happy-birthday-lemmings-30-today/">a plaque was unveiled</a> at the bottom of Perth Road in the city, commemorating DMA’s first office, where the game was originally born.</p>


<div>
<figure><a href="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?ssl=1"><img loading="lazy" decoding="async" width="700" height="200" data-attachment-id="881" data-permalink="https://scottishgames.net/cropped-bb-lemmings-jpg/" data-orig-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?fit=700%2C200&amp;ssl=1" data-orig-size="700,200" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cropped-bb-lemmings.jpg" data-image-description="<p>http://scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg</p>
" data-image-caption="" data-medium-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?fit=300%2C86&amp;ssl=1" data-large-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?fit=700%2C200&amp;ssl=1" src="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?resize=700%2C200&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>


<p>In 2022 <em><a href="https://scottishgames.net/2022/02/15/lemmings-can-you-dig-it-youtube/" target="_blank" rel="noreferrer noopener">Lemmings: Can You Dig It?</a></em> a feature-length documentary was released, which charted the design and development of the original game and its impact upon gamers today. You can watch it here:</p>



<figure><p><span><iframe loading="lazy" width="740" height="417" src="https://www.youtube.com/embed/RbAVNKdk9gA?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p></figure>



<p>Happy birthday <em>Lemmings</em>!</p>
		
		
		
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple confirms it's breaking iPhone web apps in the EU on purpose (509 pts)]]></title>
            <link>https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/</link>
            <guid>39388218</guid>
            <pubDate>Thu, 15 Feb 2024 20:22:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/">https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/</a>, See on <a href="https://news.ycombinator.com/item?id=39388218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Well, it turns out it’s not a bug that broke iPhone web apps, also known as Progressive Web Apps (PWAs), in the EU. Following developer complaints and press reports about how PWAs were no longer functional in the EU after installing the most recent iOS betas, Apple has updated its website to explain why. No surprise, the tech giant is blaming the new EU regulation, the Digital Markets Act, for the change, saying that the complexities involved with the DMA’s requirement to allow different browser engines is the root cause.</p>
<p>To catch you up, security researcher <a href="https://x.com/mysk_co/status/1753401847044288847?s=20">Tommy Mysk</a> and <a href="https://open-web-advocacy.org/blog/did-apple-just-break-web-apps-in-ios17.4-beta-eu/">Open Web Advocacy</a>, first noticed that PWAs <a href="https://www.macrumors.com/2024/02/08/ios-17-4-nerfs-web-apps-in-the-eu">had been demoted</a> to website shortcuts with the release of the second beta of iOS 17.4. Initially, it was unclear if this was a beta bug — stranger things have happened — or it was intended to undermine the functionality of PWAs in the E.U., a market where Apple is now being forced to allow alternative app stores, third-party payments, and alternative browser engines, among other things. In the betas, PWAs, which typically allow web apps to function and feel more like native iOS apps, were no longer working.&nbsp;Developers noticed that these web apps would open like a bookmark saved to your Home Screen, instead.</p>
<p>As <a href="https://www.macrumors.com/2024/02/08/ios-17-4-nerfs-web-apps-in-the-eu">MacRumors</a> pointed out at the time, that meant no “dedicated windowing, notifications, or long-term local storage.” iOS <a href="https://9to5mac.com/2023/02/16/iphone-web-app-new-features-ios-16-4/">16.4 also allowed PWAs to badge their icons</a> with notifications, as native apps could. iOS 17.4 beta users reported that when they opened a web app while running the iOS beta, the system would ask them if they wanted to open the app in Safari or cancel. The message indicates that the web app will “open in your default browser from now on,” it said. Afterward, users said they experienced issues with data loss, as a Safari website shortcut doesn’t offer local storage. Notifications also no longer worked.</p>
<p>Still, there was reason to be cautious about whether or not the change was intentional. Multiple staff at TechCrunch repeatedly asked Apple for comment but received no reply. (We had wanted to know if the comapny would confirm if this was a beta bug or an intentional change, and if the latter, what Apple’s reasoning for it was.) After the next beta release emerged, <a href="https://www.theverge.com/2024/2/14/24072764/apple-progressive-web-apps-eu-ios-17-4">The Verge</a>&nbsp;ran a report indicating that Apple <em>“appears to be”</em> breaking PWAs in the E.U., after also not likely getting a formal response from the tech giant.</p>
<p>Now, Apple has responded, in its way. Today, it updated its <a href="https://developer.apple.com/support/dma-and-apps-in-the-eu/">website detailing its DMA-related changes in the EU</a> to address the matter. In a new update, the company explains how it’s had to make so many changes to iOS to comply with the EU guidelines, that continued support for PWAs was simply off the table.</p>
<p>Traditionally, the iOS system provided support for Home Screen web apps by building directly on WebKit (Safari’s browser engine), and its security architecture, Apple said. That allowed web apps to align with the same security and privacy models as found in other native apps. But with the DMA, Apple is being forced to allow alternative browser engines. It argues that without the isolation and enforcement of the rules applied to WebKit-based web apps, malicious apps could be installed that could do things like read data from other web apps, or “gain access to a user’s camera, microphone or location without a user’s consent,” Apple said.</p>
<p>“Addressing the complex security and privacy concerns associated with web apps using alternative browser engines would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps. And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU,” the website reads.</p>
<p>The company informs EU users they will be able to access websites from their Home Screen through bookmarks as a result of the change, confirming developers’ concerns that PWAs were effectively being disabled in the EU.</p>
<p>“We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our users,” Apple says.</p>
<p><a href="https://twitter.com/OpenWebAdvocacy/status/1757929731071373447">Critics</a> <a href="https://twitter.com/douglascamata/status/1755967835371716975">have</a> <a href="https://twitter.com/MyDaebakCafe/status/1755538810287350259">argued</a> that Apple’s desire to hold onto its power in the iOS app ecosystem was so strong that it would break web app functionality for users of its devices. Apple’s defenders, meanwhile, will probably argue that the company’s explanation is reasonable and aligns with Apple’s desire to keep iOS safe for its users. The truth, as it often is, is likely lies more in the middle.</p>
<p>Apple still has not responded to requests for comment.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building an LLM from Scratch: Automatic Differentiation (192 pts)]]></title>
            <link>https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html</link>
            <guid>39387850</guid>
            <pubDate>Thu, 15 Feb 2024 20:01:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html">https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html</a>, See on <a href="https://news.ycombinator.com/item?id=39387850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">





<div id="faa21911" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="1">
<details>
<summary>Setup</summary>
<div id="cb1"><pre><code><span id="cb1-1"><span>from</span> typing <span>import</span> Any, Optional, List</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>import</span> networkx <span>as</span> nx</span></code></pre></div>
</details>
</div>
<section id="llm-from-scratch-automatic-differentiation">
<h2 data-anchor-id="llm-from-scratch-automatic-differentiation">LLM from scratch: Automatic Differentiation</h2>
<p>I’m building a modern language model with all the bells and whistles completely from scratch: from vanilla python to functional coding assistant. Borrowing (shamelessly stealing) from computer games, I’ve built a tech tree of everything that I think I’ll need to implement to get a fully functional language model. If you think anything is missing, <a href="mailto:bclarkson-code@proton.me">please let me know</a>:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/tech_tree_post_1.png" alt="The LLM from scratch tech tree" width="700"></p>
<figcaption>The LLM from scratch tech tree</figcaption>
</figure>
</div>
<p>Before we can move onto building modern features like <a href="https://arxiv.org/abs/2104.09864">Rotary Positional Encodings</a>, we first need to figure out how to differentiate with a computer. The backpropagation algorithm that underpins the entire field of Deep Learning requires the ability to differentiate the outputs of neural networks with respect to (wrt) their inputs. In this post, we’ll go from nothing to an (admittedly very limited) automatic differentiation library that can differentiate arbitrary functions of scalar values.</p>
<p>This one algorithm will form the core of our deep learning library that, eventually, will include everything we need to train a language model.</p>
</section>
<section id="creating-a-tensor">
<h2 data-anchor-id="creating-a-tensor">Creating a tensor</h2>
<p>We can’t do any differentiation if we don’t have any numbers to differentiate. We’ll want to add some extra functionality that is in standard <code>float</code> types so we’ll need to create our own. Let’s call it a <code>Tensor</code>.</p>
<div id="3c2dc0d6" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="2"><pre><code><span id="cb2-1"><span>class</span> Tensor:</span>
<span id="cb2-2">    <span>"""</span></span>
<span id="cb2-3"><span>    Just a number (for now)</span></span>
<span id="cb2-4"><span>    """</span></span>
<span id="cb2-5"></span>
<span id="cb2-6">    value: <span>float</span></span>
<span id="cb2-7"></span>
<span id="cb2-8">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb2-9">        <span>self</span>.value <span>=</span> value</span>
<span id="cb2-10"></span>
<span id="cb2-11">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb2-12">        <span>"""</span></span>
<span id="cb2-13"><span>        Create a printable string representation of this</span></span>
<span id="cb2-14"><span>        object</span></span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>        This function gets called when you pass a Tensor to print</span></span>
<span id="cb2-17"></span>
<span id="cb2-18"><span>        Without this function:</span></span>
<span id="cb2-19"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb2-20"><span>        &lt;__main__.Tensor at 0x104fd1950&gt;</span></span>
<span id="cb2-21"></span>
<span id="cb2-22"><span>        With this function:</span></span>
<span id="cb2-23"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb2-24"><span>        Tensor(5)</span></span>
<span id="cb2-25"><span>        """</span></span>
<span id="cb2-26">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span>
<span id="cb2-27"></span>
<span id="cb2-28"></span>
<span id="cb2-29"><span># try it out</span></span>
<span id="cb2-30">Tensor(<span>5</span>)</span></code></pre></div>
<p>Next we’ll need some simple operations we want to perform: addition, subtraction and multiplication.</p>
<div id="69ba409d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="3"><pre><code><span id="cb4-1"><span>def</span> _add(a: Tensor, b: Tensor):</span>
<span id="cb4-2">    <span>"""</span></span>
<span id="cb4-3"><span>    Add two tensors</span></span>
<span id="cb4-4"><span>    """</span></span>
<span id="cb4-5">    <span>return</span> Tensor(a.value <span>+</span> b.value)</span>
<span id="cb4-6"></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span>def</span> _sub(a: Tensor, b: Tensor):</span>
<span id="cb4-9">    <span>"""</span></span>
<span id="cb4-10"><span>    Subtract tensor b from tensor a</span></span>
<span id="cb4-11"><span>    """</span></span>
<span id="cb4-12">    <span>return</span> Tensor(a.value <span>-</span> b.value)</span>
<span id="cb4-13"></span>
<span id="cb4-14"></span>
<span id="cb4-15"><span>def</span> _mul(a: Tensor, b: Tensor):</span>
<span id="cb4-16">    <span>"""</span></span>
<span id="cb4-17"><span>    Multiply two tensors</span></span>
<span id="cb4-18"><span>    """</span></span>
<span id="cb4-19">    <span>return</span> Tensor(a.value <span>*</span> b.value)</span></code></pre></div>
<p>We can use use our operations as follows:</p>
<div id="55858d5d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="4">
<div id="cb5"><pre><code><span id="cb5-1"><span>def</span> test(got: Any, want: Any):</span>
<span id="cb5-2">    <span>"""</span></span>
<span id="cb5-3"><span>    Check that two objects are equal to each other</span></span>
<span id="cb5-4"><span>    """</span></span>
<span id="cb5-5">    indicator <span>=</span> <span>"✅"</span> <span>if</span> want <span>==</span> got <span>else</span> <span>"❌"</span></span>
<span id="cb5-6">    <span>print</span>(<span>f"</span><span>{</span>indicator<span>}</span><span> - Want: </span><span>{</span>want<span>}</span><span>, Got: </span><span>{</span>got<span>}</span><span>"</span>)</span>
<span id="cb5-7"></span>
<span id="cb5-8"></span>
<span id="cb5-9">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb5-10">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb5-11"></span>
<span id="cb5-12"></span>
<span id="cb5-13">test(_add(a, b).value, <span>7</span>)</span>
<span id="cb5-14">test(_sub(a, b).value, <span>-</span><span>1</span>)</span>
<span id="cb5-15">test(_mul(a, b).value, <span>12</span>)</span></code></pre></div>
<div>
<pre><code>✅ - Want: 7, Got: 7
✅ - Want: -1, Got: -1
✅ - Want: 12, Got: 12</code></pre>
</div>
</div>
</section>
<section id="scalar-derivatives">
<h2 data-anchor-id="scalar-derivatives">Scalar derivatives</h2>
<p>Diving straight into differentiating matrices sounds too hard so let’s start with something simpler: differentiating scalars. The simplest scalar derivative I can think of is differentiating a tensor with respect to itself: <span>\[\frac{dx}{dx} = 1\]</span></p>
<p>A more interesting case is the derivative of two tensors added together (note we are using partial derivatives because our function has multiple inputs): <span>\[f(x, y) = x + y\]</span> <span>\[\frac{\partial f}{\partial x} = 1\]</span> <span>\[\frac{\partial f}{\partial y} = 1\]</span></p>
<p>We can do a similar thing for multiplication and subtraction</p>
<table>
<colgroup>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th><span>\(f(x, y)\)</span></th>
<th><span>\(\frac{\partial f}{\partial x}\)</span></th>
<th><span>\(\frac{\partial f}{\partial y}\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td><span>\(x + y\)</span></td>
<td><span>\(1\)</span></td>
<td><span>\(1\)</span></td>
</tr>
<tr>
<td><span>\(x - y\)</span></td>
<td><span>\(1\)</span></td>
<td><span>\(-1\)</span></td>
</tr>
<tr>
<td><span>\(x \times y\)</span></td>
<td><span>\(y\)</span></td>
<td><span>\(x\)</span></td>
</tr>
</tbody>
</table>
<p>Now that we’ve worked out these derivatives mathematically, the next step is to convert them into code. In the table above, when we make a tensor by combining two tensors with an operation, the derivative only ever depends on the inputs and the operation. There is no “hidden state”.</p>
<p>This means that the only information we need to store is the inputs to an operation and a function to calculate the derivative wrt each input. With this, we should be able to differentiate any binary function wrt its inputs. A good place to store this information is in the tensor that is produced by the operation.</p>
<p>We’ll add some new attributes to our <code>Tensor</code>: <code>args</code> and <code>local_derivatives</code>. If the tensor is the output of an operation, then <code>args</code> will store the arguments to the operation and <code>local_derivatives</code> will store the derivatives wrt each input. We’re calling it <code>local_derivatives</code> to avoid confusion when we start nesting functions.</p>
<p>Once we’ve calculated the derivative (from our <code>args</code> and <code>local_derivatives</code>) we’ll need to store it. It turns out that the neatest place to put this is in the tensor that the output is being differentiated wrt. We’ll call this <code>derivative</code>.</p>
<div id="2df2b7ce" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="5"><pre><code><span id="cb7-1"><span>class</span> Tensor:</span>
<span id="cb7-2">    <span>"""</span></span>
<span id="cb7-3"><span>    A number that can be differentiated</span></span>
<span id="cb7-4"><span>    """</span></span>
<span id="cb7-5"></span>
<span id="cb7-6">    <span># If the tensor was made by an operation, the operation arguments</span></span>
<span id="cb7-7">    <span># are stored in args</span></span>
<span id="cb7-8">    args: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb7-9">    <span># If the tensor was made by an operation, the derivatives wrt</span></span>
<span id="cb7-10">    <span># operation inputs are stored in derivatives</span></span>
<span id="cb7-11">    local_derivatives: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb7-12">    <span># The derivative we have calculated</span></span>
<span id="cb7-13">    derivative: Optional[<span>"Tensor"</span>] <span>=</span> <span>None</span></span>
<span id="cb7-14"></span>
<span id="cb7-15">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb7-16">        <span>self</span>.value <span>=</span> value</span>
<span id="cb7-17"></span>
<span id="cb7-18">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb7-19">        <span>"""</span></span>
<span id="cb7-20"><span>        Create a printable string representation of this</span></span>
<span id="cb7-21"><span>        object</span></span>
<span id="cb7-22"></span>
<span id="cb7-23"><span>        This function gets called when you pass a Tensor to print</span></span>
<span id="cb7-24"></span>
<span id="cb7-25"><span>        Without this function:</span></span>
<span id="cb7-26"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb7-27"><span>        &lt;__main__.Tensor at 0x104fd1950&gt;</span></span>
<span id="cb7-28"></span>
<span id="cb7-29"><span>        With this function:</span></span>
<span id="cb7-30"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb7-31"><span>        Tensor(5)</span></span>
<span id="cb7-32"><span>        """</span></span>
<span id="cb7-33">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span></code></pre></div>
<p>For example, if we have</p>
<div id="16c996f7" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="6"><pre><code><span id="cb8-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb8-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb8-3"></span>
<span id="cb8-4">output <span>=</span> _mul(a, b)</span></code></pre></div>
<p>Then <code>output.args</code> and <code>output.local_derivatives</code> should be set to:</p>
<div id="cb9"><pre><code><span id="cb9-1">output.args <span>==</span> (Tensor(<span>3</span>), Tensor(<span>4</span>))</span>
<span id="cb9-2">output.derivatives <span>==</span> (</span>
<span id="cb9-3">    b,  <span># derivative of output wrt a is b</span></span>
<span id="cb9-4">    a,  <span># derivative of output wrt b is a</span></span>
<span id="cb9-5">)</span></code></pre></div>
<p>Once we have actually computed the derivatives, then the derivative of <code>output</code> wrt <code>a</code> will be stored in <code>a.derivative</code> and should be equal to <code>b</code> (which is 4 in this case).</p>
<p>We know that we’ve done everything right once these tests pass:</p>
<div id="615dc0ba" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="7">
<div id="cb10"><pre><code><span id="cb10-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb10-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb10-3"></span>
<span id="cb10-4">output <span>=</span> _mul(a, b)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span># </span><span>TODO</span><span>: differentiate here</span></span>
<span id="cb10-7"></span>
<span id="cb10-8">test(got<span>=</span>output.args, want<span>=</span>(a, b))</span>
<span id="cb10-9">test(got<span>=</span>output.local_derivatives, want<span>=</span>(b, a))</span>
<span id="cb10-10">test(got<span>=</span>a.derivative, want<span>=</span>b)</span>
<span id="cb10-11">test(got<span>=</span>b.derivative, want<span>=</span>a)</span></code></pre></div>
<div>
<pre><code>❌ - Want: (Tensor(3), Tensor(4)), Got: ()
❌ - Want: (Tensor(4), Tensor(3)), Got: ()
❌ - Want: Tensor(4), Got: None
❌ - Want: Tensor(3), Got: None</code></pre>
</div>
</div>
<p>First, let’s add a function to our <code>Tensor</code> that will actually calculate the derivatives for each of the function arguments. Pytorch calls this function <code>backward</code> so we’ll do the same.</p>
<div id="18dcfc02" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="8"><pre><code><span id="cb12-1"><span>class</span> Tensor:</span>
<span id="cb12-2">    <span>"""</span></span>
<span id="cb12-3"><span>    A number that can be differentiated</span></span>
<span id="cb12-4"><span>    """</span></span>
<span id="cb12-5"></span>
<span id="cb12-6">    <span># If the tensor was made by an operation, the operation arguments</span></span>
<span id="cb12-7">    <span># are stored in args</span></span>
<span id="cb12-8">    args: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb12-9">    <span># If the tensor was made by an operation, the derivatives wrt</span></span>
<span id="cb12-10">    <span># operation inputs are stored in</span></span>
<span id="cb12-11">    local_derivatives: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb12-12">    <span># The derivative we have calculated</span></span>
<span id="cb12-13">    derivative: Optional[<span>"Tensor"</span>] <span>=</span> <span>None</span></span>
<span id="cb12-14"></span>
<span id="cb12-15">    <span># optionally give this tensor a name</span></span>
<span id="cb12-16">    name: Optional[<span>str</span>] <span>=</span> <span>None</span></span>
<span id="cb12-17">    <span># Later, we'll want to record the path we followed to get</span></span>
<span id="cb12-18">    <span># to this tensor and some operations we did along the way</span></span>
<span id="cb12-19">    <span># don't worry about these for now</span></span>
<span id="cb12-20">    paths: List[Tensor] <span>=</span> <span>None</span></span>
<span id="cb12-21">    chains: List[Tensor] <span>=</span> <span>None</span></span>
<span id="cb12-22"></span>
<span id="cb12-23">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb12-24">        <span>self</span>.value <span>=</span> value</span>
<span id="cb12-25"></span>
<span id="cb12-26">    <span>def</span> backward(<span>self</span>):</span>
<span id="cb12-27">        <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb12-28">            <span>raise</span> <span>ValueError</span>(</span>
<span id="cb12-29">                <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb12-30">            )</span>
<span id="cb12-31"></span>
<span id="cb12-32">        <span>for</span> arg, derivative <span>in</span> <span>zip</span>(<span>self</span>.args, <span>self</span>.local_derivatives):</span>
<span id="cb12-33">            arg.derivative <span>=</span> derivative</span>
<span id="cb12-34"></span>
<span id="cb12-35">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb12-36">        <span>"""</span></span>
<span id="cb12-37"><span>        Create a printable string representation of this</span></span>
<span id="cb12-38"><span>        object</span></span>
<span id="cb12-39"></span>
<span id="cb12-40"><span>        This function gets called when you pass a Tensor to print</span></span>
<span id="cb12-41"></span>
<span id="cb12-42"><span>        Without this function:</span></span>
<span id="cb12-43"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb12-44"><span>        &lt;__main__.Tensor at 0x104fd1950&gt;</span></span>
<span id="cb12-45"></span>
<span id="cb12-46"><span>        With this function:</span></span>
<span id="cb12-47"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb12-48"><span>        Tensor(5)</span></span>
<span id="cb12-49"><span>        """</span></span>
<span id="cb12-50">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span></code></pre></div>
<p>This only works if we also store the arguments and derivatives in the output tensors of operations</p>
<div id="0f77b5c2" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="9"><pre><code><span id="cb13-1"><span>def</span> _add(a: Tensor, b: Tensor):</span>
<span id="cb13-2">    <span>"""</span></span>
<span id="cb13-3"><span>    Add two tensors</span></span>
<span id="cb13-4"><span>    """</span></span>
<span id="cb13-5">    result <span>=</span> Tensor(a.value <span>+</span> b.value)</span>
<span id="cb13-6">    result.local_derivatives <span>=</span> (Tensor(<span>1</span>), Tensor(<span>1</span>))</span>
<span id="cb13-7">    result.args <span>=</span> (a, b)</span>
<span id="cb13-8">    <span>return</span> result</span>
<span id="cb13-9"></span>
<span id="cb13-10"></span>
<span id="cb13-11"><span>def</span> _sub(a: Tensor, b: Tensor):</span>
<span id="cb13-12">    <span>"""</span></span>
<span id="cb13-13"><span>    Subtract tensor b from a</span></span>
<span id="cb13-14"><span>    """</span></span>
<span id="cb13-15">    result <span>=</span> Tensor(a.value <span>-</span> b.value)</span>
<span id="cb13-16">    result.local_derivatives <span>=</span> (Tensor(<span>1</span>), Tensor(<span>-</span><span>1</span>))</span>
<span id="cb13-17">    result.args <span>=</span> (a, b)</span>
<span id="cb13-18">    <span>return</span> result</span>
<span id="cb13-19"></span>
<span id="cb13-20"></span>
<span id="cb13-21"><span>def</span> _mul(a: Tensor, b: Tensor):</span>
<span id="cb13-22">    <span>"""</span></span>
<span id="cb13-23"><span>    Multiply two tensors</span></span>
<span id="cb13-24"><span>    """</span></span>
<span id="cb13-25">    result <span>=</span> Tensor(a.value <span>*</span> b.value)</span>
<span id="cb13-26">    result.local_derivatives <span>=</span> (b, a)</span>
<span id="cb13-27">    result.args <span>=</span> (a, b)</span>
<span id="cb13-28">    <span>return</span> result</span></code></pre></div>
<p>Let’s re-run our tests and see if it works</p>
<div id="426bc097" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="10">
<div id="cb14"><pre><code><span id="cb14-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb14-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb14-3"></span>
<span id="cb14-4">output <span>=</span> _mul(a, b)</span>
<span id="cb14-5"></span>
<span id="cb14-6">output.backward()</span>
<span id="cb14-7"></span>
<span id="cb14-8">test(got<span>=</span>output.args, want<span>=</span>(a, b))</span>
<span id="cb14-9">test(got<span>=</span>output.local_derivatives, want<span>=</span>(b, a))</span>
<span id="cb14-10">test(a.derivative, b)</span>
<span id="cb14-11">test(b.derivative, a)</span></code></pre></div>
<div>
<pre><code>✅ - Want: (Tensor(3), Tensor(4)), Got: (Tensor(3), Tensor(4))
✅ - Want: (Tensor(4), Tensor(3)), Got: (Tensor(4), Tensor(3))
✅ - Want: Tensor(4), Got: Tensor(4)
✅ - Want: Tensor(3), Got: Tensor(3)</code></pre>
</div>
</div>
<p>So far so good, let’s try nesting operations.</p>
<div id="e14634fb" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="11">
<div id="cb16"><pre><code><span id="cb16-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb16-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb16-3"></span>
<span id="cb16-4">output_1 <span>=</span> _mul(a, b)</span>
<span id="cb16-5"><span># z = a + (a * b)</span></span>
<span id="cb16-6">output_2 <span>=</span> _add(a, output_1)</span>
<span id="cb16-7"></span>
<span id="cb16-8">output_2.backward()</span>
<span id="cb16-9"></span>
<span id="cb16-10"><span># should get</span></span>
<span id="cb16-11"><span># dz/db = 0 + a = a</span></span>
<span id="cb16-12">test(b.derivative, a)</span></code></pre></div>
<div>
<pre><code>❌ - Want: Tensor(3), Got: None</code></pre>
</div>
</div>
<p>Something has gone wrong.</p>
<p>We should have got <code>a</code> as the derivative for <code>b</code> but we got <code>0</code> instead. Looking through the <code>.backward()</code> function, the issue is pretty clear: we haven’t thought about nested functions. To get this example working, we’ll need to figure out how to calculate derivatives through multiple functions instead of just one.</p>
</section>
<section id="chaining-functions-together">
<h2 data-anchor-id="chaining-functions-together">Chaining Functions Together</h2>
<p>To calculate derivatives of nested functions, we can use a rule from calculus: The Chain Rule.</p>
<p>For a variable <span>\(z\)</span> generated by nested functions <span>\(f\)</span> and <span>\(g\)</span> such that <span>\[z = f(g(x))\]</span></p>
<p>Then the derivative of <span>\(z\)</span> wrt <span>\(x\)</span> is: <span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(x)}{\partial x}\]</span></p>
<p>Here, <span>\(u\)</span> is a dummy variable. <span>\(\frac{\partial f(u)}{\partial u}\)</span> means the derivative of <span>\(f\)</span> wrt its input.</p>
<p>For example, if</p>
<p><span>\[f(x) = g(x)^2\]</span> Then we can define <span>\(u=g(x)\)</span> and rewrite <span>\(f\)</span> in terms of u <span>\[f(u) = u^2 \implies \frac{\partial f(u)}{\partial u} = 2u = 2 g(x)\]</span></p>
<section id="multiple-variables">
<h3 data-anchor-id="multiple-variables">Multiple Variables</h3>
<p>The chain rule works as you might expect for functions of multiple variables. When differentiating wrt a variable, we can treat the other variables as constant and differentiate as normal <span>\[z = f(g(x), h(y))\]</span></p>
<p><span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(x)}{\partial x}\]</span> <span>\[\frac{\partial z}{\partial y} = \frac{\partial f(u)}{\partial u} \frac{\partial h(y)}{\partial y}\]</span></p>
<p>If we have different functions that take the same input, we differentiate each of them individually and then add them together</p>
<p><span>\[z = f(g(x), h(x))\]</span></p>
<p>We get <span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u}\frac{\partial g(x)}{\partial x} + \frac{\partial f(u)}{\partial u}\frac{\partial h(x)}{\partial x}\]</span></p>
</section>
<section id="more-than-2-functions">
<h3 data-anchor-id="more-than-2-functions">More than 2 functions</h3>
<p>If we chain 3 functions together, we still just multiply the derivatives for each function together:</p>
<p><span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(x)}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(u)}{\partial u}\frac{\partial h(x)}{\partial x}\]</span></p>
<p>And this generalises to any amount of nesting</p>
<p><span>\[z = f_1(f_2(....f_{n-1}(f_n(x))...)) \]</span> <span>\(\implies \frac{\partial z}{\partial x} = \frac{\partial f_1(u)}{\partial u}\frac{\partial f_2(u)}{\partial u}...\frac{\partial f_{n-1}(u)}{\partial u}\frac{\partial f_{n}(x)}{\partial x}\)</span>$</p>
</section>
<section id="a-picture-is-worth-a-thousand-equations">
<h3 data-anchor-id="a-picture-is-worth-a-thousand-equations">A picture is worth a thousand equations</h3>
<p>As you probably noticed, the maths is starting to get quite dense. When we start working with neural networks, we can easily get 100s or 1000s of functions deep so to get a handle on things, we’ll need a different strategy. Helpfully, there is one: turning it into a graph.</p>
<p>We can start with some rules:</p>
<blockquote>
<p>Variables are represented with circles and operations are represented with boxes</p>
</blockquote>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/variable_and_box.png" alt="A variable as a circle and an operation as a box"></p>
</figure>
</div>
<blockquote>
<p>Inputs to an operation are represented with arrows that point to the operation box. Outputs point away.</p>
</blockquote>
<p>For example, here is the diagram for <span>\(z = mx\)</span></p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/z_eq_mx.png" alt="The operation z = mx"></p>
</figure>
</div>
<p>And that’s it! All of the equations we’ll be working with can be represented graphically using these simple rules. To try it out, let’s draw the diagram for a more complex formula:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/square_error.png" alt="A diagram of the square error of a linear regression"></p>
</figure>
</div>
<p>This is an example of a structure called a graph (also called a network). A lot of problem in computer science get much easier if you can represent them with a graph and this is no exception.</p>
<p>The real power of these diagrams is that they can also help us with our derivatives. Take <span>\[y = mx + p = \texttt{add}(p, \texttt{mul}(m ,x)).\]</span></p>
<p>From before, we can find its derivatives by differentiating each operation wrt its inputs and multiplying the results together. In this case, we get: <span>\[\frac{\partial y}{\partial p} = \frac{\partial \texttt{add}(u_1, u_2)}{\partial u_1} = 1\]</span> <span>\[\frac{\partial y}{\partial m} = \frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_2} = 1 \times x = x\]</span> <span>\[\frac{\partial y}{\partial x} = \frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_1} = 1 \times m = m\]</span></p>
<p>We can also graph it like this:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/y_eq_mx_plus_p_labelled.png" alt="a graph of y = mx + p"></p>
</figure>
</div>
<p>If you imagine walking from <span>\(y\)</span> to each of the inputs, you might notice a similarity between the edges you pass through and the equations above. If you walk from <span>\(y\)</span> to <span>\(x\)</span>, you’ll pass through <code>a-&gt;c-&gt;d</code>. Similarly, if you walk from <span>\(y\)</span> to <span>\(m\)</span>, you’ll pass through <code>a-&gt;d-&gt;e</code>. Notice that both paths go through <code>c</code>, the edge coming out of <code>add</code> that corresponds to the input <span>\(u_2\)</span>. Also, both equations include the term <span>\(\frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\)</span>.</p>
<p>If I rename the edges as follows:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/y_eq_mx_plus_p_deriv.png" alt="y = mx + p with each edge given a letter"></p>
</figure>
</div>
<p>We can see that going from <span>\(y\)</span> to <span>\(x\)</span>, we pass through <span>\(1\)</span>, <span>\(\frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\)</span> and <span>\(\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_1}\)</span>. If we multiply these together, we get exactly <span>\(\frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_1} = \frac{\partial y}{\partial x}\)</span>!</p>
<p>It turns out that this rule works in general:</p>
<blockquote>
<p>If we have some operation <span>\(\texttt{op}(u_1, u_2, ..., u_n)\)</span>, we should label the edge corresponding to input <span>\(u_i\)</span> with <span>\(\frac{\partial \texttt{op}(u_1, u_2, ..., u_n)}{\partial u_i}\)</span></p>
</blockquote>
<p>Then, if we want to find the derivative of the output node wrt any of the inputs,</p>
<blockquote>
<p>The derivative of an output variable wrt one of the input variables can be found by traversing the graph from the output to the input and multiplying together the derivatives for every edge on the path</p>
</blockquote>
<p>To cover every edge case, there are some extra details</p>
<blockquote>
<p>If a graph contains multiple paths from the output to an input, then the derivative is the sum of the products for each path</p>
</blockquote>
<p>This comes from the case we saw earlier where when we have different functions that have the same input we have to add their derivative chains together.</p>
<blockquote>
<p>If an edge is not the input to any function, its derivative is 1</p>
</blockquote>
<p>This covers the edge that leads from the final operation to the output. You can think of the edge having the derivative <span>\(\frac{\partial y}{\partial y}=1\)</span></p>
<p>And that’s it! Let’s try it out with <span>\(z = (x + c)x\)</span>:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/z_eq_xx_plus_xc.png" alt="A graph of z = (x+c)x with edges annotated with derivatives"></p>
</figure>
</div>
<p>Here, instead of writing the formulae for each derivative, I have gone ahead and calculated their actual values. Instead of just figuring out the formulae for a derivative, we want to calculate its value when we plug in our input parameters.</p>
<p>All that remains is to multiply the local derivatives together along each path. We’ll call the product of derivatives along a single path a chain (after the chain rule)</p>
<p>We can get from <span>\(z\)</span> to <span>\(x\)</span> via the green path and the red path. Following these paths, we get: <span>\[\text{red path} = 1 \times (x + c) = x + c\]</span> Along the green path we get: <span>\[\text{green path} = 1 \times x \times 1 = x\]</span></p>
<p>Adding these together, we get <span>\((x+c) + x = 2x + c\)</span></p>
<p>If we work out the derivative algebraically:</p>
<p><span>\[\frac{\partial z}{\partial x} = \frac{\partial}{\partial x}((x+c)x) = \frac{\partial}{\partial x}(x^2 + cx) = \frac{\partial x^2}{\partial x} + c\frac{\partial x}{\partial x} = 2x + c\]</span></p>
<p>We can see that it seems to work! Calculating <span>\(\frac{\partial z}{\partial c}\)</span> is left as an exercise for the reader (I’ve always wanted to say that).</p>
<p>To summarise, we have invented the following algorithm for calculating of a variable wrt its inputs:</p>
<ol type="1">
<li>Turn the equation into a graph</li>
<li>Label each edge with the appropriate derivative</li>
<li>Find every path from the output to the input variable you care about</li>
<li>Follow each path and multiply the derivatives you pass through</li>
<li>Add together the results for each path</li>
</ol>
<p>Now that we have an algorithm in pictures and words, let’s turn it into code.</p>
</section>
<section id="the-algorithm">
<h3 data-anchor-id="the-algorithm">The Algorithm™</h3>
<p>Surprisingly, we have actually already converted our functions into graphs. If you recall, when we generate a tensor from an operation, we record the inputs to the operation in the output tensor (in <code>.args</code>). We also stored the functions to calculate derivatives for each of the inputs in <code>.local_derivatives</code> which means that we know both the destination and derivative for every edge that points to a given node. This means that we’ve already completed steps 1 and 2.</p>
<p>The next challenge is to find all paths from the tensor we want to differentiate to the input tensors that created it. Because none of our operations are self referential (outputs are never fed back in as inputs), and all of our edges have a direction, our graph of operations is a directed acyclic graph or DAG. The property of the graph having no cycles means that we can find all paths to every parameter pretty easily with a Breadth First Search (or Depth First Search but BFS makes some optimisations easier as we’ll see in part 2).</p>
<p>To try it out, let’s recreate that giant graph we made earlier. We can do this by first calculating <span>\(L\)</span> from the inputs</p>
<div id="4c65eba1" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="12"><pre><code><span id="cb18-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb18-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb18-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb18-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span># L = (y - (mx + c))^2</span></span>
<span id="cb18-7">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb18-8">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb18-9"></span>
<span id="cb18-10">L <span>=</span> _mul(left, right)</span>
<span id="cb18-11"></span>
<span id="cb18-12"><span># Attaching names to tensors will make our</span></span>
<span id="cb18-13"><span># diagram look nicer</span></span>
<span id="cb18-14">y.name <span>=</span> <span>"y"</span></span>
<span id="cb18-15">m.name <span>=</span> <span>"m"</span></span>
<span id="cb18-16">x.name <span>=</span> <span>"x"</span></span>
<span id="cb18-17">c.name <span>=</span> <span>"c"</span></span>
<span id="cb18-18">L.name <span>=</span> <span>"L"</span></span></code></pre></div>
<p>And then using Breadth First Search to do 3 things:</p>
<ul>
<li>Find all nodes</li>
<li>Find all edges</li>
<li>Find all paths from <span>\(L\)</span> to our parameters</li>
</ul>
<p>We haven’t implemented a simple way to check whether two tensors are identical so we’ll need to compare hashes.</p>
<div id="6f90fd88" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="13"><pre><code><span id="cb19-1">edges <span>=</span> []</span>
<span id="cb19-2"></span>
<span id="cb19-3">stack <span>=</span> [(L, [L])]</span>
<span id="cb19-4"></span>
<span id="cb19-5">nodes <span>=</span> []</span>
<span id="cb19-6">edges <span>=</span> []</span>
<span id="cb19-7"><span>while</span> stack:</span>
<span id="cb19-8">    node, current_path <span>=</span> stack.pop()</span>
<span id="cb19-9">    <span># Record nodes we haven't seen before</span></span>
<span id="cb19-10">    <span>if</span> <span>hash</span>(node) <span>not</span> <span>in</span> [<span>hash</span>(n) <span>for</span> n <span>in</span> nodes]:</span>
<span id="cb19-11">        nodes.append(node)</span>
<span id="cb19-12"></span>
<span id="cb19-13">    <span># If we have reached a parameter (it has no arguments</span></span>
<span id="cb19-14">    <span># because it wasn't created by an operation) then</span></span>
<span id="cb19-15">    <span># record the path taken to get here</span></span>
<span id="cb19-16">    <span>if</span> <span>not</span> node.args:</span>
<span id="cb19-17">        <span>if</span> node.paths <span>is</span> <span>None</span>:</span>
<span id="cb19-18">            node.paths <span>=</span> []</span>
<span id="cb19-19">        node.paths.append(current_path)</span>
<span id="cb19-20">        <span>continue</span></span>
<span id="cb19-21"></span>
<span id="cb19-22">    <span>for</span> arg <span>in</span> node.args:</span>
<span id="cb19-23">        stack.append((arg, current_path <span>+</span> [arg]))</span>
<span id="cb19-24">        <span># Record every new edge</span></span>
<span id="cb19-25">        edges.append((<span>hash</span>(node), <span>hash</span>(arg)))</span></code></pre></div>
<p>Now we’ve got all of the edges and nodes, we have complete knowledge of our computational graph. Let’s use networkx to plot it</p>
<div id="8fd42378" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="14">
<div id="cb20"><pre><code><span id="cb20-1"><span># Assign a unique integer to each</span></span>
<span id="cb20-2"><span># unnamed node so we know which</span></span>
<span id="cb20-3"><span># node is which in the picture</span></span>
<span id="cb20-4">labels <span>=</span> {}</span>
<span id="cb20-5"><span>for</span> i, node <span>in</span> <span>enumerate</span>(nodes):</span>
<span id="cb20-6">    <span>if</span> node.name <span>is</span> <span>None</span>:</span>
<span id="cb20-7">        labels[<span>hash</span>(node)] <span>=</span> <span>str</span>(i)</span>
<span id="cb20-8">    <span>else</span>:</span>
<span id="cb20-9">        labels[<span>hash</span>(node)] <span>=</span> node.name</span>
<span id="cb20-10"></span>
<span id="cb20-11">graph <span>=</span> nx.DiGraph()</span>
<span id="cb20-12">graph.add_edges_from(edges)</span>
<span id="cb20-13">pos <span>=</span> nx.nx_agraph.pygraphviz_layout(graph, prog<span>=</span><span>"dot"</span>)</span>
<span id="cb20-14">nx.draw(graph, pos<span>=</span>pos, labels<span>=</span>labels)</span></code></pre></div>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post_files/figure-html/cell-15-output-1.png" width="691" height="499"></p>
</figure>
</div>
</div>
<p>If you squint a bit, you can see that this looks like the graph we made earlier! Let’s take a look at the paths the algorithm found from <span>\(L\)</span> to <span>\(x\)</span>.</p>
<div id="7cf96dca" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="15">
<div id="cb21"><pre><code><span id="cb21-1"><span>for</span> path <span>in</span> x.paths:</span>
<span id="cb21-2">    steps <span>=</span> []</span>
<span id="cb21-3">    <span>for</span> step <span>in</span> path:</span>
<span id="cb21-4">        steps.append(labels[<span>hash</span>(step)])</span>
<span id="cb21-5">    <span>print</span>(<span>"-&gt;"</span>.join(steps))</span></code></pre></div>
<div>
<pre><code>L-&gt;1-&gt;2-&gt;4-&gt;x
L-&gt;8-&gt;9-&gt;10-&gt;x</code></pre>
</div>
</div>
<p>The paths look correct! All we need to do now is to modify the algorithm a bit to keep track of the chain of derivatives along each path.</p>
<div id="386e7fdf" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="16"><pre><code><span id="cb23-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb23-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb23-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb23-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb23-5"></span>
<span id="cb23-6"><span># L = (y - (mx + c))^2</span></span>
<span id="cb23-7">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb23-8">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb23-9"></span>
<span id="cb23-10">L <span>=</span> _mul(left, right)</span>
<span id="cb23-11"></span>
<span id="cb23-12">y.name <span>=</span> <span>"y"</span></span>
<span id="cb23-13">m.name <span>=</span> <span>"m"</span></span>
<span id="cb23-14">x.name <span>=</span> <span>"x"</span></span>
<span id="cb23-15">c.name <span>=</span> <span>"c"</span></span>
<span id="cb23-16">L.name <span>=</span> <span>"L"</span></span></code></pre></div>
<div id="28e3b011" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="17"><pre><code><span id="cb24-1">stack <span>=</span> [(L, [L], [])]</span>
<span id="cb24-2"></span>
<span id="cb24-3">nodes <span>=</span> []</span>
<span id="cb24-4">edges <span>=</span> []</span>
<span id="cb24-5"><span>while</span> stack:</span>
<span id="cb24-6">    node, current_path, current_chain <span>=</span> stack.pop()</span>
<span id="cb24-7">    <span># Record nodes we haven't seen before</span></span>
<span id="cb24-8">    <span>if</span> <span>hash</span>(node) <span>not</span> <span>in</span> [<span>hash</span>(n) <span>for</span> n <span>in</span> nodes]:</span>
<span id="cb24-9">        nodes.append(node)</span>
<span id="cb24-10"></span>
<span id="cb24-11">    <span># If we have reached a parameter (it has no arguments</span></span>
<span id="cb24-12">    <span># because it wasn't created by an operation) then</span></span>
<span id="cb24-13">    <span># record the path taken to get here</span></span>
<span id="cb24-14">    <span>if</span> <span>not</span> node.args:</span>
<span id="cb24-15">        <span>if</span> node.paths <span>is</span> <span>None</span>:</span>
<span id="cb24-16">            node.paths <span>=</span> []</span>
<span id="cb24-17">        <span>if</span> node.chains <span>is</span> <span>None</span>:</span>
<span id="cb24-18">            node.chains <span>=</span> []</span>
<span id="cb24-19">        node.paths.append(current_path)</span>
<span id="cb24-20">        node.chains.append(current_chain)</span>
<span id="cb24-21">        <span>continue</span></span>
<span id="cb24-22"></span>
<span id="cb24-23">    <span>for</span> arg, op <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb24-24">        next_node <span>=</span> arg</span>
<span id="cb24-25">        next_path <span>=</span> current_path <span>+</span> [arg]</span>
<span id="cb24-26">        next_chain <span>=</span> current_chain <span>+</span> [op]</span>
<span id="cb24-27"></span>
<span id="cb24-28">        stack.append((arg, next_path, next_chain))</span>
<span id="cb24-29"></span>
<span id="cb24-30">        <span># Record every new edge</span></span>
<span id="cb24-31">        edges.append((<span>hash</span>(node), <span>hash</span>(arg)))</span></code></pre></div>
<p>Let’s check if the derivatives were recorded correctly.</p>
<div id="95ea9947" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="18">
<div id="cb25"><pre><code><span id="cb25-1"><span>print</span>(<span>f"Number of chains: </span><span>{</span><span>len</span>(x.chains)<span>}</span><span>"</span>)</span>
<span id="cb25-2"><span>for</span> chain <span>in</span> x.chains:</span>
<span id="cb25-3">    <span>print</span>(chain)</span></code></pre></div>
<div>
<pre><code>Number of chains: 2
[Tensor(-9), Tensor(-1), Tensor(1), Tensor(2)]
[Tensor(-9), Tensor(-1), Tensor(1), Tensor(2)]</code></pre>
</div>
</div>
<p>Looks reasonable so far. We have 2 identical paths, each with 4 derivatives (one for each edge in the path) as expected.</p>
<p>Let’s multiply the derivatives together along each path and add the total for each path together and see if we get the right answer.</p>
<p>According my calculations (and <a href="https://www.wolframalpha.com/">Wolfram Alpha</a>) the derivative of <span>\(L\)</span> wrt <span>\(x\)</span> is: <span>\[\frac{\partial L}{\partial x} = 2m (c + mx - y)\]</span> Plugging the values for our tensors in, we get <span>\[2\times2 (4 + (2\times3) - 1) = 36\]</span></p>
<div id="71c45972" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="19"><pre><code><span id="cb27-1">total_derivative <span>=</span> Tensor(<span>0</span>)</span>
<span id="cb27-2"><span>for</span> chain <span>in</span> x.chains:</span>
<span id="cb27-3">    chain_total <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb27-4">    <span>for</span> step <span>in</span> chain:</span>
<span id="cb27-5">        chain_total <span>=</span> _mul(chain_total, step)</span>
<span id="cb27-6">    total_derivative <span>=</span> _add(total_derivative, chain_total)</span>
<span id="cb27-7"></span>
<span id="cb27-8">total_derivative</span></code></pre></div>
<p>The correct answer! It looks like our algorithm works. All that remains is to put all the pieces together.</p>
</section>
</section>
<section id="putting-it-all-together">
<h2 data-anchor-id="putting-it-all-together">Putting it all together</h2>
<p>When dreaming up the algorithm, we kept a record of the nodes, edges and paths which made plotting and debugging easier. Now that we know that it works, we can remove these and simplify things a bit.</p>
<div id="5c3a5852" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="20"><pre><code><span id="cb29-1"><span>def</span> backward(root_node: Tensor) <span>-&gt;</span> <span>None</span>:</span>
<span id="cb29-2">    stack <span>=</span> [(root_node, [])]</span>
<span id="cb29-3"></span>
<span id="cb29-4">    <span>while</span> stack:</span>
<span id="cb29-5">        node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb29-6"></span>
<span id="cb29-7">        <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb29-8">        <span># because it wasn't created by an operation) then</span></span>
<span id="cb29-9">        <span># record the path taken to get here</span></span>
<span id="cb29-10">        <span>if</span> <span>not</span> node.args:</span>
<span id="cb29-11">            <span>if</span> node.chains <span>is</span> <span>None</span>:</span>
<span id="cb29-12">                node.chains <span>=</span> []</span>
<span id="cb29-13">            node.chain.append(current_derivative)</span>
<span id="cb29-14">            <span>continue</span></span>
<span id="cb29-15"></span>
<span id="cb29-16">        <span>for</span> arg, op <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb29-17">            stack.append((arg, current_derivative <span>+</span> [op]))</span></code></pre></div>
<p>There is also no need (for now) to store the derivatives and calculate them separately. Instead, we can avoid a bunch of repeated calculations by multiplying the derivatives as we go.</p>
<div id="c4000db8" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="21"><pre><code><span id="cb30-1"><span>def</span> backward(root_node: Tensor) <span>-&gt;</span> <span>None</span>:</span>
<span id="cb30-2">    stack <span>=</span> [(root_node, Tensor(<span>1</span>))]</span>
<span id="cb30-3"></span>
<span id="cb30-4">    <span>while</span> stack:</span>
<span id="cb30-5">        node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb30-6"></span>
<span id="cb30-7">        <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb30-8">        <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb30-9">        <span># derivative</span></span>
<span id="cb30-10">        <span>if</span> <span>not</span> node.args:</span>
<span id="cb30-11">            <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb30-12">                node.derivative <span>=</span> current_derivative</span>
<span id="cb30-13">            <span>else</span>:</span>
<span id="cb30-14">                node.derivative <span>=</span> _add(node.derivative, current_derivative)</span>
<span id="cb30-15">            <span>continue</span></span>
<span id="cb30-16"></span>
<span id="cb30-17">        <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb30-18">            stack.append((arg, _mul(current_derivative, derivative)))</span></code></pre></div>
<p>Let’s make sure we didn’t break anything</p>
<div id="6bc39eac" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="22">
<div id="cb31"><pre><code><span id="cb31-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb31-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb31-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb31-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb31-5"></span>
<span id="cb31-6">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb31-7">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb31-8"></span>
<span id="cb31-9">L <span>=</span> _mul(left, right)</span>
<span id="cb31-10">backward(L)</span>
<span id="cb31-11"></span>
<span id="cb31-12"><span>print</span>(<span>f"</span><span>{</span>x<span>.</span>derivative <span>=</span> <span>}</span><span>\n</span><span>"</span>)</span>
<span id="cb31-13">test(got<span>=</span>x.derivative.value, want<span>=</span><span>36</span>)</span></code></pre></div>
<div>
<pre><code>x.derivative = Tensor(36)

✅ - Want: 36, Got: 36</code></pre>
</div>
</div>
<p>Let’s put this algorithm into our Tensor object</p>
<div id="208fa522" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="23"><pre><code><span id="cb33-1"><span>class</span> Tensor:</span>
<span id="cb33-2">    <span>"""</span></span>
<span id="cb33-3"><span>    A float that can be differentiated</span></span>
<span id="cb33-4"><span>    """</span></span>
<span id="cb33-5"></span>
<span id="cb33-6">    args: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb33-7">    local_derivatives: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb33-8">    <span># The derivative (once we've calculated it).  This is None if the derivative</span></span>
<span id="cb33-9">    <span># has not been computed yet</span></span>
<span id="cb33-10">    derivative: Tensor <span>|</span> <span>None</span> <span>=</span> <span>None</span></span>
<span id="cb33-11"></span>
<span id="cb33-12">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb33-13">        <span>self</span>.value <span>=</span> value</span>
<span id="cb33-14"></span>
<span id="cb33-15">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb33-16">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>.</span><span>__repr__</span>()<span>}</span><span>)"</span></span>
<span id="cb33-17"></span>
<span id="cb33-18">    <span>def</span> backward(<span>self</span>):</span>
<span id="cb33-19">        <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb33-20">            <span>raise</span> <span>ValueError</span>(</span>
<span id="cb33-21">                <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb33-22">            )</span>
<span id="cb33-23"></span>
<span id="cb33-24">        stack <span>=</span> [(<span>self</span>, Tensor(<span>1</span>))]</span>
<span id="cb33-25"></span>
<span id="cb33-26">        <span>while</span> stack:</span>
<span id="cb33-27">            node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb33-28"></span>
<span id="cb33-29">            <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb33-30">            <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb33-31">            <span># derivative</span></span>
<span id="cb33-32">            <span>if</span> <span>not</span> node.args:</span>
<span id="cb33-33">                <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb33-34">                    node.derivative <span>=</span> Tensor(<span>0</span>)</span>
<span id="cb33-35">                node.derivative <span>=</span> _add(node.derivative, current_derivative)</span>
<span id="cb33-36">                <span>continue</span></span>
<span id="cb33-37"></span>
<span id="cb33-38">            <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb33-39">                new_derivative <span>=</span> _mul(current_derivative, derivative)</span>
<span id="cb33-40">                stack.append((arg, new_derivative))</span></code></pre></div>
<p>Let’s try it out</p>
<div id="59db14e7" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="24">
<div id="cb34"><pre><code><span id="cb34-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb34-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb34-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb34-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb34-5"></span>
<span id="cb34-6">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb34-7">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb34-8"></span>
<span id="cb34-9">L <span>=</span> _mul(left, right)</span>
<span id="cb34-10">L.backward()</span>
<span id="cb34-11"></span>
<span id="cb34-12">test(x.derivative, Tensor(<span>36</span>))</span></code></pre></div>
<div>
<pre><code>❌ - Want: Tensor(36), Got: Tensor(36)</code></pre>
</div>
</div>
<p>Huh?</p>
<p>By default, if you compare two objects in python with <code>==</code>, python will check whether the object on the left has the same reference as the object as the one on the right. Because <code>Tensor(36)</code> is a different object (that just happens to have the same value) to <code>x.derivative</code>, <code>x.derivative == Tensor(36)</code> returns <code>False</code>.</p>
<p>It makes a lot more sense to compare two tensors based upon their <code>.value</code>. To achieve this, we can add the <code>__eq__</code> special method to <code>Tensor</code> which will change the behaviour of the <code>==</code> operator for <code>Tensor</code> objects</p>
<div id="00be4f8d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="25"><pre><code><span id="cb36-1"><span>def</span> <span>__eq__</span>(<span>self</span>, other) <span>-&gt;</span> <span>bool</span>:</span>
<span id="cb36-2">    <span>"""</span></span>
<span id="cb36-3"><span>    Tells python to compare .value when applying the `==`</span></span>
<span id="cb36-4"><span>    operation to two tensors instead of comparing references</span></span>
<span id="cb36-5"><span>    """</span></span>
<span id="cb36-6">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb36-7">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot compare a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb36-8"></span>
<span id="cb36-9">    <span>return</span> <span>self</span>.value <span>==</span> other.value</span></code></pre></div>
<p>Similarly, if we try to use <code>+</code>, <code>-</code> or <code>*</code> on our tensors, we’ll get an error. We can tell python how to do these operations on our tensors by defining the following special functions:</p>
<ul>
<li><code>__add__</code> let’s us use <code>+</code></li>
<li><code>__sub__</code> let’s us use <code>-</code></li>
<li><code>__mul__</code> let’s us use <code>*</code></li>
</ul>
<div id="20dbaf3a" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="26"><pre><code><span id="cb37-1"><span>def</span> <span>__add__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb37-2">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb37-3">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot add a Tensor to a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb37-4"></span>
<span id="cb37-5">    <span>return</span> _add(<span>self</span>, other)</span>
<span id="cb37-6"></span>
<span id="cb37-7"></span>
<span id="cb37-8"><span>def</span> <span>__sub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb37-9">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb37-10">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot subtract a Tensor from a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb37-11"></span>
<span id="cb37-12">    <span>return</span> _sub(<span>self</span>, other)</span>
<span id="cb37-13"></span>
<span id="cb37-14"></span>
<span id="cb37-15"><span>def</span> <span>__mul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb37-16">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb37-17">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot multiply a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb37-18">    <span>return</span> _mul(<span>self</span>, other)</span></code></pre></div>
<p>Finally, we can add the <code>__iadd__</code>, <code>__isub__</code> and <code>__imul__</code> methods to allow us to use <code>+=</code>, <code>-=</code> and <code>*=</code>.</p>
<div id="7f0b2199" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="27"><pre><code><span id="cb38-1"><span>def</span> <span>__iadd__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb38-2">    <span>self</span> <span>=</span> <span>self</span>.<span>__add__</span>(<span>self</span>, other)</span>
<span id="cb38-3">    <span>return</span> <span>self</span></span>
<span id="cb38-4"></span>
<span id="cb38-5"></span>
<span id="cb38-6"><span>def</span> <span>__isub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb38-7">    <span>self</span> <span>=</span> <span>self</span>.<span>__sub__</span>(<span>self</span>, other)</span>
<span id="cb38-8">    <span>return</span> <span>self</span></span>
<span id="cb38-9"></span>
<span id="cb38-10"></span>
<span id="cb38-11"><span>def</span> <span>__imul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb38-12">    <span>self</span> <span>=</span> <span>self</span>.<span>__mul__</span>(<span>self</span>, other)</span>
<span id="cb38-13">    <span>return</span> <span>self</span></span></code></pre></div>
<p>While we’re here, let’s clean up our backward function a bit by replacing the ugly <code>_add</code> and <code>_mul</code> operations with <code>+</code> and <code>*</code>.</p>
<div id="aee373de" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="28"><pre><code><span id="cb39-1"><span>def</span> backward(<span>self</span>):</span>
<span id="cb39-2">    <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb39-3">        <span>raise</span> <span>ValueError</span>(</span>
<span id="cb39-4">            <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb39-5">        )</span>
<span id="cb39-6"></span>
<span id="cb39-7">    stack <span>=</span> [(<span>self</span>, Tensor(<span>1</span>))]</span>
<span id="cb39-8"></span>
<span id="cb39-9">    <span>while</span> stack:</span>
<span id="cb39-10">        node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb39-11"></span>
<span id="cb39-12">        <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb39-13">        <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb39-14">        <span># derivative</span></span>
<span id="cb39-15">        <span>if</span> <span>not</span> node.args:</span>
<span id="cb39-16">            <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb39-17">                node.derivative <span>+=</span> current_derivative</span>
<span id="cb39-18">            <span>else</span>:</span>
<span id="cb39-19">                node.derivative <span>+=</span> current_derivative</span>
<span id="cb39-20">            <span>continue</span></span>
<span id="cb39-21"></span>
<span id="cb39-22">        <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb39-23">            stack.append((arg, current_derivative <span>*</span> derivative))</span></code></pre></div>
<p>Putting all of these improvements together, we get a final <code>Tensor</code> object as follows:</p>
<div id="2eae868b" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="29"><pre><code><span id="cb40-1"><span>class</span> Tensor:</span>
<span id="cb40-2">    <span>"""</span></span>
<span id="cb40-3"><span>    A float that can be differentiated</span></span>
<span id="cb40-4"><span>    """</span></span>
<span id="cb40-5"></span>
<span id="cb40-6">    args: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb40-7">    local_derivatives: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb40-8">    <span># The derivative (once we've calculated it).  This is None if the derivative</span></span>
<span id="cb40-9">    <span># has not been computed yet</span></span>
<span id="cb40-10">    derivative: Tensor <span>|</span> <span>None</span> <span>=</span> <span>None</span></span>
<span id="cb40-11"></span>
<span id="cb40-12">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb40-13">        <span>self</span>.value <span>=</span> value</span>
<span id="cb40-14"></span>
<span id="cb40-15">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb40-16">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>.</span><span>__repr__</span>()<span>}</span><span>)"</span></span>
<span id="cb40-17"></span>
<span id="cb40-18">    <span>def</span> <span>__eq__</span>(<span>self</span>, other) <span>-&gt;</span> <span>bool</span>:</span>
<span id="cb40-19">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-20">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot compare a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-21">        <span>return</span> <span>self</span>.value <span>==</span> other.value</span>
<span id="cb40-22"></span>
<span id="cb40-23">    <span>def</span> <span>__add__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-24">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-25">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot add a Tensor to a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-26">        <span>return</span> _add(<span>self</span>, other)</span>
<span id="cb40-27"></span>
<span id="cb40-28">    <span>def</span> <span>__sub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-29">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-30">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot subtract a Tensor from a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-31">        <span>return</span> _sub(<span>self</span>, other)</span>
<span id="cb40-32"></span>
<span id="cb40-33">    <span>def</span> <span>__mul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-34">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-35">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot multiply a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-36">        <span>return</span> _mul(<span>self</span>, other)</span>
<span id="cb40-37"></span>
<span id="cb40-38">    <span>def</span> <span>__iadd__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-39">        <span>return</span> <span>self</span>.<span>__add__</span>(other)</span>
<span id="cb40-40"></span>
<span id="cb40-41">    <span>def</span> <span>__isub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-42">        <span>return</span> <span>self</span>.<span>__sub__</span>(other)</span>
<span id="cb40-43"></span>
<span id="cb40-44">    <span>def</span> <span>__imul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-45">        <span>return</span> <span>self</span>.<span>__mul__</span>(other)</span>
<span id="cb40-46"></span>
<span id="cb40-47">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb40-48">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span>
<span id="cb40-49"></span>
<span id="cb40-50">    <span>def</span> backward(<span>self</span>):</span>
<span id="cb40-51">        <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb40-52">            <span>raise</span> <span>ValueError</span>(</span>
<span id="cb40-53">                <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb40-54">            )</span>
<span id="cb40-55"></span>
<span id="cb40-56">        stack <span>=</span> [(<span>self</span>, Tensor(<span>1</span>))]</span>
<span id="cb40-57"></span>
<span id="cb40-58">        <span>while</span> stack:</span>
<span id="cb40-59">            node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb40-60"></span>
<span id="cb40-61">            <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb40-62">            <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb40-63">            <span># current_derivative to derivative</span></span>
<span id="cb40-64">            <span>if</span> <span>not</span> node.args:</span>
<span id="cb40-65">                <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb40-66">                    node.derivative <span>=</span> current_derivative</span>
<span id="cb40-67">                <span>else</span>:</span>
<span id="cb40-68">                    node.derivative <span>+=</span> current_derivative</span>
<span id="cb40-69">                <span>continue</span></span>
<span id="cb40-70"></span>
<span id="cb40-71">            <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb40-72">                stack.append((arg, current_derivative <span>*</span> derivative))</span></code></pre></div>
<p>Let’s take it for a spin. We’ll try calculating <span>\(L\)</span> again</p>
<div id="db25982d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="30">
<div id="cb41"><pre><code><span id="cb41-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb41-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb41-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb41-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb41-5"></span>
<span id="cb41-6">diff <span>=</span> y <span>-</span> ((m <span>*</span> x) <span>+</span> c)</span>
<span id="cb41-7">L <span>=</span> diff <span>*</span> diff</span>
<span id="cb41-8">L.backward()</span>
<span id="cb41-9"></span>
<span id="cb41-10">test(got<span>=</span>x.derivative, want<span>=</span>Tensor(<span>36</span>))</span></code></pre></div>
<div>
<pre><code>✅ - Want: Tensor(36), Got: Tensor(36)</code></pre>
</div>
</div>
<p>Much easier!</p>
<p>To really see what this baby can do, I asked a language model for the most complicated expression it could think of and it gave me this:</p>
<p><span>\[f(x) = (2x^3 + 4x^2 - 5x) \times (3x^2 - 2x + 7) - (6x^4 + 2x^3 - 8x^2) + (5x^2 - 3x)\]</span> According to <a href="https://www.wolframalpha.com/">Wolfram Alpha</a>, the derivative of this expression is: <span>\[\frac{d f(x)}{dx} = -38 + 102 x - 33 x^2 + 8 x^3 + 30 x^4\]</span></p>
<p>If we plug 2 into this equation, the answer is apparently 578 (again, thanks to <a href="https://www.wolframalpha.com/">Wolfram Alpha</a>).</p>
<p>Let’s try it with our algorithm</p>
<div id="0fd9b01f" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="31">
<div id="cb43"><pre><code><span id="cb43-1">x <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb43-2"></span>
<span id="cb43-3">y <span>=</span> (</span>
<span id="cb43-4">    (Tensor(<span>2</span>) <span>*</span> x <span>*</span> x <span>*</span> x <span>+</span> Tensor(<span>4</span>) <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>5</span>) <span>*</span> x)</span>
<span id="cb43-5">    <span>*</span> (Tensor(<span>3</span>) <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>2</span>) <span>*</span> x <span>+</span> Tensor(<span>7</span>))</span>
<span id="cb43-6">    <span>-</span> (Tensor(<span>6</span>) <span>*</span> x <span>*</span> x <span>*</span> x <span>*</span> x <span>+</span> Tensor(<span>2</span>) <span>*</span> x <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>8</span>) <span>*</span> x <span>*</span> x)</span>
<span id="cb43-7">    <span>+</span> (Tensor(<span>5</span>) <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>3</span>) <span>*</span> x)</span>
<span id="cb43-8">)</span>
<span id="cb43-9"></span>
<span id="cb43-10">y.backward()</span>
<span id="cb43-11"></span>
<span id="cb43-12">test(got<span>=</span>x.derivative, want<span>=</span>Tensor(<span>578</span>))</span></code></pre></div>
<div>
<pre><code>✅ - Want: Tensor(578), Got: Tensor(578)</code></pre>
</div>
</div>
<p>Once again, we got the right answer!</p>
</section>
<section id="conclusion">
<h2>Conclusion</h2>
<p>From nothing, we have now written an algorithm that will let us differentiate any mathematical expression (provided it only involves addition, subtraction and multiplication). We did this by converting our expression into a graph and re-imagining partial derivatives as operations on the edges of that graph. Then we found that we could apply Breadth First Search to combine all the derivatives together to get a final answer.</p>
<p>Differentiating scalars is (I hope you agree) interesting, but it isn’t exactly GPT-4. That said, with a few small modifications to our algorithm, we can extend our algorithm to handle multi-dimensional tensors like matrices and vectors. Once you can do that, you can build up to backpropagation and, eventually, to a fully functional language model.</p>
<p>Next time, we’ll extend our algorithm to vectors and matrices and build up from there to a working neural network. If you want to peek ahead, you can check out the repo for <a href="https://github.com/bclarkson-code/Tricycle">Tricycle</a> which is the name for the deep learning framework we’re building.</p>


</section>

</main> <!-- /main -->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uv: Python packaging in Rust (462 pts)]]></title>
            <link>https://astral.sh/blog/uv</link>
            <guid>39387641</guid>
            <pubDate>Thu, 15 Feb 2024 19:50:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astral.sh/blog/uv">https://astral.sh/blog/uv</a>, See on <a href="https://news.ycombinator.com/item?id=39387641">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p><strong>TL;DR:</strong> <a href="https://github.com/astral-sh/uv">uv</a> is an <strong>extremely fast Python package
installer and resolver</strong>, written in Rust, and designed as a drop-in replacement for <code>pip</code> and
<code>pip-tools</code> workflows.</p>
<p><a href="https://github.com/astral-sh/uv">uv</a> represents a milestone in our pursuit of a <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>:
a comprehensive Python project and package manager that's fast, reliable, and easy to use.</p>
<p>As part of this release, we're also taking stewardship of <a href="https://github.com/mitsuhiko/rye">Rye</a>,
an experimental Python packaging tool from <a href="https://github.com/mitsuhiko">Armin Ronacher</a>. We'll
maintain <a href="https://github.com/mitsuhiko/rye">Rye</a> as we expand <a href="https://github.com/astral-sh/uv">uv</a> into a unified successor
project, to fulfill our <a href="https://rye-up.com/philosophy/">shared vision</a> for Python packaging.</p>
<hr>
<p>At Astral, we build high-performance developer tools for the Python ecosystem. We're best known
for <a href="https://github.com/astral-sh/ruff">Ruff</a>, an extremely fast
Python <a href="https://notes.crmarsh.com/python-tooling-could-be-much-much-faster">linter</a>
and <a href="https://astral.sh/blog/the-ruff-formatter">formatter</a>.</p>
<p>Today, we're releasing the next tool in the Astral toolchain: <strong><a href="https://github.com/astral-sh/uv">uv</a>, an extremely fast Python
package resolver and installer, written in Rust</strong>.</p>
<div><p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 422 250"><g aria-roledescription="group mark container" fill="none" stroke-miterlimit="10"><g aria-roledescription="group mark container"><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.0 to 3.5"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M347.5 90.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(90.5 105.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(176.214 105.5)" font-family="Roboto Mono,monospace" font-size="12">1s
                        </text><text text-anchor="middle" transform="translate(261.929 105.5)" font-family="Roboto Mono,monospace" font-size="12">2s
                        </text><text text-anchor="middle" transform="translate(347.643 105.5)" font-family="Roboto Mono,monospace" font-size="12">3s
                        </text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 4 values: uv, poetry, pip-compile, pdm"><g pointer-events="none"><text text-anchor="end" transform="translate(80.5 15.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(80.5 37.75)" font-family="Roboto Mono,monospace" font-size="12">poetry
                        </text><text text-anchor="end" transform="translate(80.5 60.25)" font-family="Roboto Mono,monospace" font-size="12">pip-compile
                        </text><text text-anchor="end" transform="translate(80.5 82.75)" font-family="Roboto Mono,monospace" font-size="12">pdm
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0134756369786; tool: uv" aria-roledescription="bar" d="M90 4.75h1.155v13H90Z"></path><path aria-label="Sum of time: 0.60278702674; tool: poetry" aria-roledescription="bar" d="M90 27.25h51.667v13H90Z"></path><path aria-label="Sum of time: 1.55616658094; tool: pip-compile" aria-roledescription="bar" d="M90 49.75h133.386v13H90Z"></path><path aria-label="Sum of time: 3.37404433084; tool: pdm" aria-roledescription="bar" d="M90 72.25h289.204v13H90Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.60278702674; tool: poetry; timeFormat: 0.60s" aria-roledescription="text mark" transform="translate(147.667 37.75)" font-family="Roboto Mono,monospace" font-size="12">0.60s
                  </text><text aria-label="Sum of time: 1.55616658094; tool: pip-compile; timeFormat: 1.56s" aria-roledescription="text mark" transform="translate(229.386 60.25)" font-family="Roboto Mono,monospace" font-size="12">1.56s
                  </text><text aria-label="Sum of time: 3.37404433084; tool: pdm; timeFormat: 3.37s" aria-roledescription="text mark" transform="translate(385.204 82.75)" font-family="Roboto Mono,monospace" font-size="12">3.37s
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0134756369786; tool: uv; timeFormat: 0.01s" aria-roledescription="text mark" transform="translate(97.155 15.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">0.01s
                  </text></g><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0 to 5"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M330.5 233.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(90.5 248.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(210.5 248.5)" font-family="Roboto Mono,monospace" font-size="12">2s
                        </text><text text-anchor="middle" transform="translate(330.5 248.5)" font-family="Roboto Mono,monospace" font-size="12">4s
                        </text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 4 values: uv, poetry, pdm, pip-sync"><g pointer-events="none"><text text-anchor="end" transform="translate(80.5 158.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(80.5 180.75)" font-family="Roboto Mono,monospace" font-size="12">poetry
                        </text><text text-anchor="end" transform="translate(80.5 203.25)" font-family="Roboto Mono,monospace" font-size="12">pdm
                        </text><text text-anchor="end" transform="translate(80.5 225.75)" font-family="Roboto Mono,monospace" font-size="12">pip-sync
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0576289908; tool: uv" aria-roledescription="bar" d="M90 147.75h3.458v13H90Z"></path><path aria-label="Sum of time: 0.9872183659; tool: poetry" aria-roledescription="bar" d="M90 170.25h59.233v13H90Z"></path><path aria-label="Sum of time: 1.8969612492; tool: pdm" aria-roledescription="bar" d="M90 192.75h113.818v13H90Z"></path><path aria-label="Sum of time: 4.6313483826; tool: pip-sync" aria-roledescription="bar" d="M90 215.25h277.88v13H90Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.9872183659; tool: poetry; timeFormat: 0.99s" aria-roledescription="text mark" transform="translate(155.233 180.75)" font-family="Roboto Mono,monospace" font-size="12">0.99s
                  </text><text aria-label="Sum of time: 1.8969612492; tool: pdm; timeFormat: 1.90s" aria-roledescription="text mark" transform="translate(209.818 203.25)" font-family="Roboto Mono,monospace" font-size="12">1.90s
                  </text><text aria-label="Sum of time: 4.6313483826; tool: pip-sync; timeFormat: 4.63s" aria-roledescription="text mark" transform="translate(373.88 225.75)" font-family="Roboto Mono,monospace" font-size="12">4.63s
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0576289908; tool: uv; timeFormat: 0.06s" aria-roledescription="text mark" transform="translate(99.458 158.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">0.06s
                  </text></g></g></g></svg></p><div><p><span>Resolving (left) and installing (right) the<!-- --> <a target="_blank" rel="noreferrer" href="https://github.com/python-trio/trio">Trio</a> <!-- -->dependencies with a<!-- --> </span><a aria-label="Toggle cache" tabindex="0" type="button">warm</a> <span>cache, to simulate<!-- --> <!-- -->recreating a virtual environment or adding a dependency to an existing project<!-- --> <!-- -->(<a href="https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md" target="_blank" rel="noreferrer">source</a>).</span></p><p><span>Resolving (top) and installing (bottom) the<!-- --> <a target="_blank" rel="noreferrer" href="https://github.com/python-trio/trio">Trio</a> <!-- -->dependencies with a<!-- --> </span><a aria-label="Toggle cache" tabindex="0" type="button">warm</a> <span>cache, to simulate<!-- --> <!-- -->recreating a virtual environment or adding a dependency to an existing project<!-- --> <!-- -->(<a href="https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md" target="_blank" rel="noreferrer">source</a>).</span></p></div></div>
<p><a href="https://github.com/astral-sh/uv">uv</a> is designed as a drop-in replacement for <code>pip</code> and <code>pip-tools</code>,
and is ready for production use today in projects built around those workflows.</p>
<p>Like <a href="https://github.com/astral-sh/ruff">Ruff</a>, uv's implementation was grounded in our core
product principles:</p>
<ol>
<li><strong>An obsessive focus on performance.</strong> In the above <a href="https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md">benchmarks</a>,
uv is <strong>8-10x faster</strong> than <code>pip</code> and <code>pip-tools</code> without caching, and <strong>80-115x faster</strong>
when running with a warm cache (e.g., recreating a virtual environment or updating a dependency).
uv uses a global module cache to avoid re-downloading and re-building dependencies, and
leverages Copy-on-Write and hardlinks on supported filesystems to minimize disk space usage.</li>
<li><strong>Optimized for adoption.</strong> While we have big aspirations for the future of Python packaging,
uv's initial release is centered on supporting the <code>pip</code> and <code>pip-tools</code> APIs behind
our <code>uv pip</code> interface, making it usable by existing projects with zero configuration.
Similarly, uv can be used as "just" a resolver (<code>uv pip compile</code> to lock your
dependencies), "just" a virtual environment creator (<code>uv venv</code>), "just" a package
installer (<code>uv pip sync</code>), and so on. It's both unified and modular.</li>
<li><strong>A simplified toolchain.</strong> uv ships as a single static binary capable of
replacing <code>pip</code>, <code>pip-tools</code>, and <code>virtualenv</code>. uv has no direct Python dependency, so you
can install it separately from Python itself, avoiding the need to manage <code>pip</code> installations
across multiple Python versions (e.g., <code>pip</code> vs. <code>pip3</code> vs. <code>pip3.7</code>).</li>
</ol>
<p>While uv will evolve into a <strong>complete Python project and package manager</strong> (a <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>),
the narrower <code>pip-tools</code> scope allows us to solve the low-level problems involved in building such
a tool (like package installation) while shipping something immediately useful with minimal barrier
to adoption.</p>
<p>You can install <a href="https://github.com/astral-sh/uv">uv</a> today via our standalone installers,
or from <a href="https://pypi.org/project/uv/">PyPI</a>.</p>

<p><a href="https://github.com/astral-sh/uv">uv</a> supports everything you'd expect from a modern Python
packaging tool: editable installs, Git dependencies, URL dependencies, local dependencies,
constraint files, source distributions, custom indexes, and more, all designed around drop-in
compatibility with your existing tools.</p>
<p><a href="https://github.com/astral-sh/uv">uv</a> supports <strong>Linux</strong>, <strong>Windows</strong>, and <strong>macOS</strong>, and
has been tested at-scale against the public PyPI index.</p>
<h3><span id="a-drop-in-compatible-api"></span>A drop-in compatible API<!-- --> <a href="#a-drop-in-compatible-api">#</a></h3>
<p>This initial release centers on what we refer to as uv's <code>pip</code> API. It'll be familiar to those
that have used <code>pip</code> and <code>pip-tools</code> in the past:</p>
<ul>
<li>Instead of <code>pip install</code>, run <code>uv pip install</code> to install Python dependencies from the command
line, a requirements file, or a <code>pyproject.toml</code>.</li>
<li>Instead of <code>pip-compile</code>, run <code>uv pip compile</code> to generate a locked <code>requirements.txt</code>.</li>
<li>Instead of <code>pip-sync</code>, run <code>uv pip sync</code> to sync a virtual environment with a locked <code>requirements.txt</code>.</li>
</ul>
<p>By scoping these "lower-level" commands under <code>uv pip</code>, we retain space in the CLI for the more
"opinionated" project management API we intend to ship in the future, which will look more like
<a href="https://github.com/mitsuhiko/rye">Rye</a>, or <a href="https://github.com/rust-lang/cargo">Cargo</a>, or
<a href="https://github.com/python-poetry/poetry">Poetry</a>. (Imagine <code>uv run</code>, <code>uv build</code>, and so on.)</p>
<p>uv can also be used as a virtual environment manager via <code>uv venv</code>. It's about 80x
faster than <code>python -m venv</code> and 7x faster than <code>virtualenv</code>, with no dependency on Python.</p>
<div><p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 454 282"><g aria-roledescription="group mark container" fill="none" stroke-miterlimit="10"><g aria-roledescription="group mark container"><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 3 values: uv, virtualenv, venv"><g pointer-events="none"><text text-anchor="end" transform="translate(89.5 35)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(89.5 65)" font-family="Roboto Mono,monospace" font-size="12">virtualenv
                        </text><text text-anchor="end" transform="translate(89.5 95)" font-family="Roboto Mono,monospace" font-size="12">venv
                        </text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 3 values: uv, virtualenv, venv"><g pointer-events="none"><text text-anchor="end" transform="translate(89.5 178)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(89.5 208)" font-family="Roboto Mono,monospace" font-size="12">virtualenv
                        </text><text text-anchor="end" transform="translate(89.5 238)" font-family="Roboto Mono,monospace" font-size="12">venv
                        </text></g></g></g><g aria-roledescription="group mark container"><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.00 to 0.08"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M407.5 106.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(107.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(182.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.02s
                        </text><text text-anchor="middle" transform="translate(257.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.04s
                        </text><text text-anchor="middle" transform="translate(332.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.06s
                        </text><text text-anchor="middle" transform="translate(407.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.08s
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0041; tool: uv" aria-roledescription="bar" d="M107 24.5h15.375v13H107Z"></path><path aria-label="Sum of time: 0.0744; tool: virtualenv" aria-roledescription="bar" d="M107 54.5h279v13H107Z"></path><path aria-label="Sum of time: 0.0241; tool: venv" aria-roledescription="bar" d="M107 84.5h90.375v13H107Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0744; tool: virtualenv; timeFormat: 74.4ms" aria-roledescription="text mark" transform="translate(392 65)" font-family="Roboto Mono,monospace" font-size="12">74.4ms
                  </text><text aria-label="Sum of time: 0.0241; tool: venv; timeFormat: 24.1ms" aria-roledescription="text mark" transform="translate(203.375 95)" font-family="Roboto Mono,monospace" font-size="12">24.1ms
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0041; tool: uv; timeFormat: 4.1ms" aria-roledescription="text mark" transform="translate(128.375 35)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">4.1ms
                  </text></g><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.0 to 1.6"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M388.5 249.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(107.5 264.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(201.25 264.5)" font-family="Roboto Mono,monospace" font-size="12">0.5s
                        </text><text text-anchor="middle" transform="translate(295 264.5)" font-family="Roboto Mono,monospace" font-size="12">1s
                        </text><text text-anchor="middle" transform="translate(388.75 264.5)" font-family="Roboto Mono,monospace" font-size="12">1.5s
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0182; tool: uv" aria-roledescription="bar" d="M107 167.5h3.413v13H107Z"></path><path aria-label="Sum of time: 0.1414; tool: virtualenv" aria-roledescription="bar" d="M107 197.5h26.512v13H107Z"></path><path aria-label="Sum of time: 1.54; tool: venv" aria-roledescription="bar" d="M107 227.5h288.75v13H107Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.1414; tool: virtualenv; timeFormat: 141.4ms" aria-roledescription="text mark" transform="translate(139.512 208)" font-family="Roboto Mono,monospace" font-size="12">141.4ms
                  </text><text aria-label="Sum of time: 1.54; tool: venv; timeFormat: 1.54s" aria-roledescription="text mark" transform="translate(401.75 238)" font-family="Roboto Mono,monospace" font-size="12">1.54s
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0182; tool: uv; timeFormat: 18.2ms" aria-roledescription="text mark" transform="translate(116.412 178)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">18.2ms
                  </text></g></g></g></svg></p><div><p>Creating a virtual environment, with (top) and without (bottom) seed packages like pip and setuptools (<a href="https://github.com/astral-sh/uv/blob/ea13d94c57149a8fc6ebfcef46149252e869269f/scripts/benchmarks/venv.sh" target="_blank" rel="noreferrer">source</a>).</p><p>Creating a virtual environment, with (left) and without (right) seed packages like pip and setuptools (<a href="https://github.com/astral-sh/uv/blob/ea13d94c57149a8fc6ebfcef46149252e869269f/scripts/benchmarks/venv.sh" target="_blank" rel="noreferrer">source</a>).</p></div></div>
<p>uv's virtual environments are standards-compliant and work interchangeably with other tools —
there's no lock-in or customization.</p>
<p>Building our own package management stack from scratch also opened up room for new capabilities.
For example:</p>
<ul>
<li><strong>uv supports alternate resolution strategies.</strong> By default, uv follows the standard
Python dependency resolution strategy of preferring the latest compatible version of each package.
But by passing <code>--resolution=lowest</code>, library authors can test their packages against the lowest-compatible version of their dependencies. (This is similar to Go's
<a href="https://go.dev/ref/mod#minimal-version-selection">Minimal version selection</a>.)</li>
<li><strong>uv allows for resolutions against arbitrary target Python versions.</strong> While <code>pip</code>
and <code>pip-tools</code> always resolve against the currently-installed Python version (generating, e.g., a
Python 3.12-compatible resolution when running under Python 3.12), uv accepts
a <code>--python-version</code> parameter, enabling you to generate, e.g., Python 3.7-compatible resolutions
even when running under newer versions.</li>
<li><strong>uv allows for dependency “overrides”.</strong> uv takes pip's “constraints” concepts a step
further via overrides (<code>-o overrides.txt</code>), which allow the user to guide the resolver by
overriding the declared dependencies of a package. Overrides give the user an escape hatch for
working around erroneous upper bounds and other incorrectly-declared dependencies.</li>
</ul>
<p>In its current form, uv won't be the right fit for all projects. <code>pip</code> is a mature and stable
tool, with extensive support for an extremely wide range of use cases and a focus on compatibility.
While uv supports a large fraction of the <code>pip</code> interface, it lacks support for some of its
legacy features, like <code>.egg</code> distributions.</p>
<p>Similarly, uv does not yet generate a platform-agnostic lockfile. This matches <code>pip-tools</code>, but
differs from Poetry and PDM, making uv a better fit for projects built around the <code>pip</code> and
<code>pip-tools</code> workflows.</p>
<p>For those deep in the packaging ecosystem, uv also includes standards-compliant Rust
implementations of <a href="https://peps.python.org/pep-0440/">PEP 440</a> (version identifiers),
<a href="https://peps.python.org/pep-0508/">PEP 508</a> (dependency specifiers),
<a href="https://peps.python.org/pep-0517/">PEP 517</a> (a build-system independent build frontend),
<a href="https://peps.python.org/pep-0405/">PEP 405</a> (virtual environments), and more.</p>
<h3><span id="a-cargo-for-python-uv-and-rye"></span>A "Cargo for Python": uv and Rye<!-- --> <a href="#a-cargo-for-python-uv-and-rye">#</a></h3>
<p>uv represents an intermediary milestone in our pursuit of a <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>: a unified Python
package and project manager that is extremely fast, reliable, and easy to use.</p>
<p>Think: a single binary that bootstraps your Python installation and gives you everything you need to
be productive with Python, bundling not only <code>pip</code>, <code>pip-tools</code>, and <code>virtualenv</code>, but also <code>pipx</code>,
<code>tox</code>, <code>poetry</code>, <code>pyenv</code>, <code>ruff</code>, and more.</p>
<p>Python tooling can be a low-confidence experience: it's a significant amount of work to stand up a
new or existing project, and commands fail in confusing ways. In contrast, when working in the Rust
ecosystem, you trust the tools to succeed. The Astral toolchain is about bringing Python from a
low-confidence to a high-confidence experience.</p>
<p>This vision for Python packaging is not far off from that put forward by <a href="https://github.com/mitsuhiko/rye">Rye</a>,
an experimental project and package management tool from <a href="https://github.com/mitsuhiko">Armin Ronacher</a>.</p>
<p>In talking with Armin, it was clear that our visions were closely aligned, but that fulfilling
them would require a significant investment in foundational tooling. For example: building such a
tool requires an extremely fast, end-to-end integrated, cross-platform resolver and installer. <strong>In
uv, we've built that foundational tooling.</strong></p>
<p>We saw this as a rare opportunity to team up, and to avoid fragmenting the Python ecosystem.
<strong>As such, in collaboration with Armin, we're excited to be taking over <a href="https://github.com/mitsuhiko/rye">Rye</a>.</strong>
Our goal is to evolve uv into a production-ready <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>, and to provide a smooth
migration path from Rye to uv when the time is right.</p>
<p>Until then, we'll be maintaining Rye, migrating it to use uv under-the-hood, and, more
generally, treating it as an experimental testbed for the end-user experience we're building
towards.</p>
<p>While merging projects comes with its own challenges, we're committed to building a single, unified
tool under the Astral banner, and to supporting existing Rye users as we evolve uv into a
suitable and comprehensive successor project.</p>
<h3><span id="our-roadmap"></span>Our Roadmap<!-- --> <a href="#our-roadmap">#</a></h3>
<p>Following this release, our first priority is to support users as they consider <a href="https://github.com/astral-sh/uv">uv</a>,
with a focus on improving compatibility, performance, and stability across platforms.</p>
<p>From there, we'll look towards expanding uv into a complete Python project and package manager:
a single binary that gives you everything you need to be productive with Python.</p>
<p>We have an ambitious roadmap for uv. But even in its current form, I think it will
feel like a very different experience for Python. I hope you'll give it a try.</p>
<h3><span id="acknowledgements"></span>Acknowledgements<!-- --> <a href="#acknowledgements">#</a></h3>
<p>Finally, we'd like to thank all those that contributed directly or indirectly to the development of
uv. Foremost among them are <a href="https://github.com/Eh2406">Jacob Finkelman</a>
and <a href="https://github.com/mpizenberg">Matthieu Pizenberg</a>, the maintainers
of <a href="https://github.com/pubgrub-rs/pubgrub">pubgrub-rs</a>. uv uses PubGrub as its underlying
version solver, and we're grateful to Jacob and Matthieu for the work they put into PubGrub in the
past, and for the way they've engaged with us as collaborators throughout the project.</p>
<p>We'd also like to thank those projects in the packaging space that've inspired us,
especially <a href="https://github.com/rust-lang/cargo">Cargo</a>, along with <a href="https://github.com/oven-sh/bun">Bun</a>, <a href="https://github.com/orogene/orogene">Orogene</a>,
and <a href="https://github.com/pnpm/pnpm">pnpm</a> from the JavaScript ecosystem,
and <a href="https://github.com/njsmith/posy">Posy</a>, <a href="https://github.com/konstin/monotrail-resolve">Monotrail</a>,
and <a href="https://github.com/mitsuhiko/rye">Rye</a> from the Python ecosystem. In particular, thanks
to <a href="https://github.com/mitsuhiko">Armin Ronacher</a> for collaborating with us on this effort.</p>
<p>Finally, we'd like to thank the maintainers of <a href="https://github.com/pypa/pip">pip</a> and the members of
the PyPA more broadly for all the work they do to make Python packaging possible.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman owns OpenAI's venture capital fund (230 pts)]]></title>
            <link>https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund</link>
            <guid>39387578</guid>
            <pubDate>Thu, 15 Feb 2024 19:45:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund">https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund</a>, See on <a href="https://news.ycombinator.com/item?id=39387578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-theme="core" id="main-content"><div data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-category="story" data-vars-sub-category="story"><div><div><p><img alt="headshot" loading="lazy" width="52" height="52" decoding="async" data-nimg="1" srcset="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FcUYY6Rl2xaPB8AWGASzP3EWlsDQ%3D%2F0x0%3A328x328%2F52x0%2F2020%2F05%2F01%2F1588371030543.jpg&amp;w=320&amp;q=75 1x" src="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FcUYY6Rl2xaPB8AWGASzP3EWlsDQ%3D%2F0x0%3A328x328%2F52x0%2F2020%2F05%2F01%2F1588371030543.jpg&amp;w=320&amp;q=75"></p></div><div><ul><li data-cy="byline-author"><a href="https://www.axios.com/authors/danprimack"><span>Dan Primack</span></a><p>, author of  </p><a href="https://www.axios.com/newsletters/axios-pro-rata">Axios Pro Rata</a></li></ul></div></div><figure data-cy="au-image"><img data-cy="StoryImage" alt="Photo illustration of Sam Altman waving in front of a pile of money." fetchpriority="high" width="1920" height="1080" decoding="async" data-nimg="1" sizes="100vw" srcset="https://images.axios.com/GDQgvSXrjaTnHVNOCxYUj2XUtJQ=/0x0:1920x1080/320x180/2024/02/15/1708018368446.jpg?w=320 320w, https://images.axios.com/GDQgvSXrjaTnHVNOCxYUj2XUtJQ=/0x0:1920x1080/320x180/2024/02/15/1708018368446.jpg?w=320 320w, https://images.axios.com/XQFxVifpfo8p2VsNz37-hfOiyS0=/0x0:1920x1080/640x360/2024/02/15/1708018368446.jpg?w=640 640w, https://images.axios.com/XQFxVifpfo8p2VsNz37-hfOiyS0=/0x0:1920x1080/640x360/2024/02/15/1708018368446.jpg?w=640 640w, https://images.axios.com/i27RdSyJupBNc81EE1MowR8wsWY=/0x0:1920x1080/768x432/2024/02/15/1708018368446.jpg?w=768 768w, https://images.axios.com/i27RdSyJupBNc81EE1MowR8wsWY=/0x0:1920x1080/768x432/2024/02/15/1708018368446.jpg?w=768 768w, https://images.axios.com/IDowc7V9ZUYqv5KeTV8Ra1-X-20=/0x0:1920x1080/1024x576/2024/02/15/1708018368446.jpg?w=1024 1024w, https://images.axios.com/IDowc7V9ZUYqv5KeTV8Ra1-X-20=/0x0:1920x1080/1024x576/2024/02/15/1708018368446.jpg?w=1024 1024w, https://images.axios.com/o8FshlR8oMZ76w2gNQAh6FkTZV4=/0x0:1920x1080/1366x768/2024/02/15/1708018368446.jpg?w=1366 1366w, https://images.axios.com/o8FshlR8oMZ76w2gNQAh6FkTZV4=/0x0:1920x1080/1366x768/2024/02/15/1708018368446.jpg?w=1366 1366w, https://images.axios.com/PfEiA3uwp9fWdaDzrLY7JoJTu-w=/0x0:1920x1080/1600x900/2024/02/15/1708018368446.jpg?w=1600 1600w, https://images.axios.com/PfEiA3uwp9fWdaDzrLY7JoJTu-w=/0x0:1920x1080/1600x900/2024/02/15/1708018368446.jpg?w=1600 1600w, https://images.axios.com/ut-S-jEgmNSG0cpCRmG9tiH27jM=/0x0:1920x1080/1920x1080/2024/02/15/1708018368446.jpg?w=1920 1920w, https://images.axios.com/ut-S-jEgmNSG0cpCRmG9tiH27jM=/0x0:1920x1080/1920x1080/2024/02/15/1708018368446.jpg?w=1920 1920w" src="https://images.axios.com/ut-S-jEgmNSG0cpCRmG9tiH27jM=/0x0:1920x1080/1920x1080/2024/02/15/1708018368446.jpg?w=1920"><figcaption><p>Rebecca Zisser / Axios</p></figcaption></figure><div><p><span data-schema="smart-brevity"><p>Sam Altman isn't just the CEO of ChatGPT maker OpenAI. He's also the owner of OpenAI Startup Fund, which Altman once <a data-vars-link-text="called" data-vars-click-url="https://www.openai.fund/about" data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.openai.fund/about" target="_blank">called</a> a "corporate venture fund," according to federal securities filings.</p><p><strong>Why it matters:</strong> OpenAI's structural strangeness permeates all aspects of the business.</p></span></p><p><strong>Background:</strong> OpenAI Startup Fund was launched in late 2021 to invest in other AI startups and projects.</p><ul><li>By last May it reported $175 million in total commitments, and a portfolio that included video editor Descript and legal tool Harvey.</li><li>It always had outside limited partners, including major OpenAI partner Microsoft, which is unusual for corporate VC funds but not unique.</li><li>What set OpenAI Startup Fund apart, however, was that it wasn't (and isn't) owned by OpenAI. Nor even by its affiliated <a data-vars-link-text="nonprofit foundation" data-vars-click-url="https://www.axios.com/2023/01/10/how-a-silicon-valley-nonprofit-became-worth-billions" data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/01/10/how-a-silicon-valley-nonprofit-became-worth-billions" target="_self">nonprofit foundation</a>. Instead, it's legally owned by Altman.</li></ul><p><strong>Behind the scenes: </strong>"We wanted to get started quickly and the easiest way to do that due to our structure was to put it in Sam's name," an OpenAI spokesperson tells Axios. "We have always intended for this to be temporary."</p><ul><li>"Temporary" has been well over a year and it's a significant risk. For example, what might have happened had Altman <a data-vars-link-text="remained fired" data-vars-click-url="https://www.axios.com/2023/11/22/sam-altman-return-open-ai" data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/11/22/sam-altman-return-open-ai" target="_self">remained fired</a> by OpenAI. Could he have kept the fund? Was there anything contractual to prevent it?</li><li>No answer to that last question, but the company does add: "We now know that we may need to re-examine our governance structure, which should precede any changes to the fund, but our priority is to establish a new board first."</li></ul></div></div><h5>Go deeper</h5></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plastics producers deceived public about recycling, report reveals (111 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/feb/15/recycling-plastics-producers-report</link>
            <guid>39387387</guid>
            <pubDate>Thu, 15 Feb 2024 19:32:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/feb/15/recycling-plastics-producers-report">https://www.theguardian.com/us-news/2024/feb/15/recycling-plastics-producers-report</a>, See on <a href="https://news.ycombinator.com/item?id=39387387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Plastic producers have known for more than 30 years that recycling is not an economically or technically feasible plastic waste management solution. That has not stopped them from promoting it, according to a new report.</p><p>“The companies lied,” said Richard Wiles, president of fossil-fuel accountability advocacy group the Center for Climate Integrity (CCI), which published the report. “It’s time to hold them accountable for the damage they’ve caused.”</p><figure id="a1b80ff2-5ffb-49c5-94cf-04e08c7a3648" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;What a waste: New York City budget cuts eviscerate community composting groups&quot;,&quot;elementId&quot;:&quot;a1b80ff2-5ffb-49c5-94cf-04e08c7a3648&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/environment/2024/feb/11/new-york-city-community-composting-groups-budget-cuts&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Plastic, which is made from oil and gas, is notoriously difficult to recycle. Doing so requires meticulous sorting, since most of the thousands of chemically distinct varieties of plastic cannot be recycled together. That renders an already pricey process even more expensive. Another challenge: the material degrades each time it is reused, meaning it can generally only be reused once or twice.</p><p>The industry has known for decades about these existential challenges, but obscured that information in its marketing campaigns, <a href="https://climateintegrity.org/plastics-fraud" data-link-name="in body link">the report shows</a>.</p><p>The research draws on previous <a href="https://www.pbs.org/wgbh/frontline/documentary/plastic-wars/?" data-link-name="in body link">investigations</a> as well as newly revealed internal documents illustrating the extent of this decades-long campaign.</p><p>Industry insiders over the past several decades have variously referred to plastic recycling as “uneconomical”, said it “cannot be considered a permanent solid waste solution”, and said it “cannot go on indefinitely”, the revelations show.</p><p>The authors say the evidence demonstrates that oil and petrochemical companies, as well as their trade associations, may have broken laws designed to protect the public from misleading marketing and pollution.</p><h2 id="single-use-plastics">Single-use plastics</h2><p>In the 1950s, plastic producers came up with an idea to ensure a continually growing market for their products: disposability.</p><p>“They knew if they focused on single-use [plastics] people would buy and buy and buy,” said Davis Allen, investigative researcher at the CCI and the report’s lead author.</p><p>At a 1956 industry conference, the Society of the Plastics Industry, a trade group, told producers to focus on “low cost, big volume” and “expendability” and to aim for materials to end up “in the garbage wagon”. (Society of Plastics is <a href="https://www.plasticstoday.com/business/spi-no-more-rebrands-as-plastics-industry-association-aka-plastics" data-link-name="in body link">now</a> known as the Plastics Industry Association. Plastics Industry Association was not immediately available for comment.)</p><p>Over the following decades, the industry told the public that plastics can easily be tossed into landfills or burned in garbage incinerators. But in the 1980s, as<strong> </strong>municipalities began considering bans on grocery bags and other plastic products<strong>, </strong>the industry began promoting a new solution: recycling.</p><h2 id="recycling-campaigns">Recycling campaigns</h2><p>The industry has long known that plastics recycling is not economically or practically viable, the report shows. An internal 1986 report from the trade association the Vinyl Institute noted that “recycling cannot be considered a permanent solid waste solution [to plastics], as it merely prolongs the time until an item is disposed of”.</p><p>In 1989, the founding director of the Vinyl Institute told attendees of a trade conference: “Recycling cannot go on indefinitely, and does not solve the solid waste problem.”</p><p>Despite this knowledge, the Society of the Plastics Industry established the Plastics Recycling Foundation in 1984, bringing together petrochemical companies and bottlers, and launched a campaign focused on the sector’s <a href="https://www.toxicdocs.org/d/rpQVOR8obVNLbN5R69K0EJ5pJ?lightbox=1" data-link-name="in body link">commitment</a> to recycling.</p><p>In 1988, the trade group rolled out the “chasing arrows” – the widely recognized symbol for recyclable plastic – and began using it on packaging. Experts have long said the symbol is highly misleading, and recently federal regulators have <a href="https://www.nytimes.com/2023/08/07/climate/chasing-arrows-recycling-symbol-epa.html" data-link-name="in body link">echoed</a> their concerns.</p><p>The Society of the Plastics Industry also established a plastics recycling research center at Rutgers University in New Jersey in 1985, one year after state lawmakers passed<strong> </strong>a mandatory recycling law. In 1988, industry group the Council for Solid <a href="https://www.theguardian.com/environment/waste" data-link-name="in body link" data-component="auto-linked-tag">Waste</a> Solutions set up a recycling pilot project in St Paul, Minnesota, where the city council had just voted to ban the plastic polystyrene, or styrofoam.</p><p>And in the early 1990s, another industry group ran ads in Ladies’ Home Journal proclaiming: “A bottle can come back as a bottle, over and over again.”</p><p>All the while, behind closed doors, industry leaders maintained that recycling was not a real solution.</p><p>In 1994, a representative of Eastman Chemical spoke at an industry conference about the need for proper plastic recycling infrastructure. “While some day this may be a reality,” he said, “it is more likely that we will wake up and realize that we are not going to recycle our way out of the solid waste issue.” That same year, an Exxon employee told staffers at the American Plastics Council: “We are committed to the activities [of plastics recycling], but not committed to the results.”</p><p>“It’s clearly fraud they’re engaged in,” said Wiles.</p><p>The report does not allege that the companies broke specific laws. But Alyssa Johl, report co-author and attorney, said she suspects they violated public-nuisance, racketeering and consumer-fraud protections.</p><p>The industry’s misconduct continues today, the report alleges. Over the past several years, industry lobbying groups have <a href="https://cen.acs.org/environment/recycling/plastic-recycling-chemical-advanced-fuel-pyrolysis-state-laws/100/i17" data-link-name="in body link">promoted</a> so-called<strong> </strong>chemical recycling, which <a href="https://www.theguardian.com/us-news/2023/apr/10/exxon-advanced-recycling-plastic-environment" data-link-name="in body link">breaks plastic polymers down</a> into tiny molecules in order to make new plastics, synthetic fuels and other products. But the process creates pollution and is even more energy intensive than traditional plastic recycling.</p><p>The plastics sector has long known chemical recycling is also not a true solution to plastic waste, the report says. In a 1994 trade meeting, Exxon Chemical vice-president Irwin Levowitz called one common form of chemical recycling a “fundamentally uneconomical process”. And in 2003, a longtime trade consultant criticized the industry for promoting chemical recycling, calling it “another example of how non-science got into the minds of industry and environmental activists alike”.</p><p>“This is just another example, a new version, of the deception we saw before,” said Allen.</p><h2 id="legal-ramifications">Legal ramifications</h2><p>The report comes as the plastic industry and recycling are facing growing<strong> </strong>public scrutiny. Two years ago, California’s attorney general, Rob Bonta, publicly launched an <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-announces-investigation-fossil-fuel-and-petrochemical" data-link-name="in body link">investigation</a> into fossil fuel and petrochemical producers “for their role in causing and exacerbating the global plastics pollution crisis”.</p><p>A toxic train derailment in East Palestine, Ohio, last February also catalyzed a movement demanding a ban on vinyl chloride, a carcinogen used to make plastic. Last month, the EPA announced a health review of the chemical – the first step toward a <a href="https://apnews.com/article/vinyl-chloride-ohio-train-derailment-toxic-chemicals-54bb0a943f4f4af0e4f68cc60ce4edb4" data-link-name="in body link">potential ban</a>.</p><p>In 2023, New York state also filed a lawsuit against PepsiCo, saying its single-use plastics violate public nuisance laws, and that the company misled consumers about the effectiveness of recycling.</p><figure id="662870ea-aad7-4537-a257-dab131a2a311" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:31,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Certified natural gas is ‘dangerous greenwashing scheme’, US senators say&quot;,&quot;elementId&quot;:&quot;662870ea-aad7-4537-a257-dab131a2a311&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2024/feb/12/natural-gas-greenwashing-democrats&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>The public is also increasingly concerned about the climate impact of plastic production and disposal, which account for <a href="https://rmi.org/clean-energy-101-reducing-climate-pollution-from-the-plastics-industry/#:~:text=In%20fact%2C%20about%2012%20percent,to%20manage%20plastics'%20climate%20risks." data-link-name="in body link">3.4% of all global greenhouse-gas emissions.</a> In recent years, two dozen cities and states have <a href="https://www.theguardian.com/us-news/2023/jun/07/climate-crisis-big-oil-lawsuits-constitution" data-link-name="in body link">sued the oil industry</a> for covering up the dangers of the climate crisis. Similarly taking the oil and petrochemical industries to court for “knowingly deceiving” the public, said Wiles, could force them to change their business models.</p><p>“I think the first step in solving the problem is holding the companies accountable,” he said.</p><p>Judith Enck, a former regional administrator for the Environmental Protection Agency and founder of the advocacy group Beyond Plastics, called the analysis “very solid”.</p><p>“The report should be read by every attorney general in the nation and the Federal Trade Commission,” she said.</p><p>Brian Frosh, the former attorney general for the state of Maryland, said the report includes the kind of evidence he would not normally expect to see until a lawsuit has already gone through a process of discovery.</p><p>“If I were attorney general, based on what I read in CCI’s report, I’d feel comfortable pressing for an investigation and a lawsuit,” he said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PWAs wont replace native iOS apps (170 pts)]]></title>
            <link>https://app.campsite.co/campsite/p/notes/rengvq2txami</link>
            <guid>39387304</guid>
            <pubDate>Thu, 15 Feb 2024 19:28:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.campsite.co/campsite/p/notes/rengvq2txami">https://app.campsite.co/campsite/p/notes/rengvq2txami</a>, See on <a href="https://news.ycombinator.com/item?id=39387304">Hacker News</a></p>
<div id="readability-page-1" class="page"><a href="#main">Skip to content</a><div id="__next"><nav><a href="https://www.campsite.co/"><svg width="26" height="14" viewBox="0 0 34 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0.140151 16.4649L9.5715 0.490928C9.75112 0.186693 10.0782 0 10.4316 0H25.7959C26.569 0 27.049 0.840284 26.6561 1.50582L17.2247 17.4798C17.0451 17.7841 16.718 17.9708 16.3646 17.9708H1.00028C0.227176 17.9708 -0.252794 17.1305 0.140151 16.4649Z" fill="currentColor"></path><path d="M22.2255 17.9707H32.9577C33.7108 17.9707 34.193 17.1691 33.8398 16.5042L28.7719 6.96112C28.4064 6.27298 27.4284 6.24978 27.0307 6.91981L21.3666 16.4628C20.9715 17.1284 21.4514 17.9707 22.2255 17.9707Z" fill="currentColor"></path></svg></a><a data-state="closed" href="https://www.campsite.co/"><span><span>Made with Campsite</span></span></a></nav><main><div><p>Ryan Nystrom</p></div></main><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple confirms iOS 17.4 removes Home Screen web apps in the EU (101 pts)]]></title>
            <link>https://9to5mac.com/2024/02/15/ios-17-4-web-apps-european-union/</link>
            <guid>39386244</guid>
            <pubDate>Thu, 15 Feb 2024 18:20:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2024/02/15/ios-17-4-web-apps-european-union/">https://9to5mac.com/2024/02/15/ios-17-4-web-apps-european-union/</a>, See on <a href="https://news.ycombinator.com/item?id=39386244">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=1600" alt="App Store security" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>iOS 17.4 offers a number of changes for the App Store and iPhone in the European Union. This includes things <a href="https://9to5mac.com/2024/01/25/third-party-default-browsers-engines/" target="_blank" rel="noreferrer noopener">like third-party app marketplaces</a> and <a href="https://9to5mac.com/2024/01/25/third-party-default-browsers-engines/">support for alternative browser engines</a>. One byproduct of these changes, however, is that iOS 17.4 removes support for Home Screen web apps in the EU. </p>



<p>Apple has now offered an explanation for this decision, confirming that the omission was not a bug. Instead, it’s because of requirements under the Digital Markets Act. </p>



<h2 id="h-web-apps-on-ios-17-4-in-the-eu">Web apps on iOS 17.4 in the EU</h2>



<p>Last week, iPhone users in the European Union noticed that they were no longer able to install and run web apps on their iPhone’s Home Screen in iOS 17.4. Apple has added a number of features over the years to improve support for progressive web apps on iPhone. For example,&nbsp;<a href="https://9to5mac.com/2023/02/16/iphone-web-app-new-features-ios-16-4/" target="_blank" rel="noreferrer noopener">iOS 16.4 allowed PWAs to deliver push notifications with icon badges</a>.</p>



<p>One change in iOS 17.4 is that the iPhone now supports alternative browser engines in the EU. This allows companies to build browsers that don’t use Apple’s WebKit engine for the first time. Apple says that this change, required by the Digital Markets Act, is why it has been forced to remove Home Screen web apps support in the European Union. </p>



<p>Apple explains that it would have to build an “entirely new integration architecture that does not currently exist in iOS” to address the “complex security and privacy concerns associated with web apps using alternative browser engines.” </p>



<p>This work “was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps,” Apple explains. “And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU.” </p>



<p>“EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality,” Apple continues. </p>



<p>It’s understandable that Apple wouldn’t offer support for Home Screen web apps for third-party browsers. But why did it also remove support for Home Screen web apps for Safari? Unfortunately, that’s another side effect of the Digital Markets Act. </p>



<p>The DMA requires that all browsers have equality, meaning that Apple can’t favor Safari and WebKit over third-party browser engines. Therefore, because it can’t offer Home Screen web apps support for third-party browsers, it also can’t offer support via Safari. </p>



<p>Apple’s full explanation follows, which was published on <a href="https://developer.apple.com/support/dma-and-apps-in-the-eu#dev-qaa">Apple’s developer website today</a>: </p>



<blockquote>
<p>To comply with the Digital Markets Act, Apple has done an enormous amount of engineering work to add new functionality and capabilities for developers and users in the European Union – including more than 600 new APls and a wide range of developer tools. </p>



<p>The iOS system has traditionally provided support for Home Screen web apps by building directly on WebKit and its security architecture. That integration means Home Screen web apps are managed to align with the security and privacy model for native apps on iOS, including isolation of storage and enforcement of system prompts to access privacy impacting capabilities on a per-site basis.</p>



<p>Without this type of isolation and enforcement, malicious web apps could read data from other web apps and recapture their permissions to gain access to a user’s camera, microphone or location without a user’s consent. Browsers also could install web apps on the system without a user’s awareness and consent. Addressing the complex security and privacy concerns associated with web apps using alternative browser engines would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps. And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU.</p>



<p>EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality. We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our</p>
</blockquote>



<p>iOS 17.4 is currently available to developers and public beta testers, and is slated for a release in early March. </p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sora: Creating video from text (2408 pts)]]></title>
            <link>https://openai.com/sora</link>
            <guid>39386156</guid>
            <pubDate>Thu, 15 Feb 2024 18:14:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/sora">https://openai.com/sora</a>, See on <a href="https://news.ycombinator.com/item?id=39386156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="capabilities"><div><p>We’re teaching AI to understand and simulate the physical world in motion, with the goal of training models that help people solve problems that require real-world interaction.</p><p>Introducing Sora, our text-to-video model. Sora can generate videos up to a minute long while maintaining visual quality and adherence to the user’s prompt.</p></div><div><p>Today, Sora is becoming available to red teamers to assess critical areas for harms or risks. We are also granting access to a number of visual artists, designers, and filmmakers to gain feedback on how to advance the model to be most helpful for creative professionals.</p><p>We’re sharing our research progress early to start working with and getting feedback from people outside of OpenAI and to give the public a sense of what AI capabilities are on the horizon.</p></div><div><!----><p>Sora is able to generate complex scenes with multiple characters, specific types of motion, and accurate details of the subject and background. The model understands not only what the user has asked for in the prompt, but also how those things exist in the physical world.</p></div><div><!----><p>The model has a deep understanding of language, enabling it to accurately interpret prompts and generate compelling characters that express vibrant emotions. Sora can also create multiple shots within a single generated video that accurately persist characters and visual style.</p></div><div><p>The current model has weaknesses. It may struggle with accurately simulating the physics of a complex scene, and may not understand specific instances of cause and effect. For example, a person might take a bite out of a cookie, but afterward, the cookie may not have a bite mark.</p><p>The model may also confuse spatial details of a prompt, for example, mixing up left and right, and may struggle with precise descriptions of events that take place over time, like following a specific camera trajectory.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unreal Engine 5 ported to WebGPU (132 pts)]]></title>
            <link>https://twitter.com/spatialweeb/status/1757581115609817236</link>
            <guid>39385739</guid>
            <pubDate>Thu, 15 Feb 2024 17:45:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/spatialweeb/status/1757581115609817236">https://twitter.com/spatialweeb/status/1757581115609817236</a>, See on <a href="https://news.ycombinator.com/item?id=39385739">Hacker News</a></p>
Couldn't get https://twitter.com/spatialweeb/status/1757581115609817236: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Feds want to ban the Flipper Zero – Experts say it's a scapegoat (242 pts)]]></title>
            <link>https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts</link>
            <guid>39385301</guid>
            <pubDate>Thu, 15 Feb 2024 17:15:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts">https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts</a>, See on <a href="https://news.ycombinator.com/item?id=39385301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><p>The government of Canada has its sights set on banning the Flipper Zero, an adorable handheld hacking device that is cherished by security researchers and hobbyist hackers and has gained <a href="https://www.wired.com/story/what-is-flipper-zero-tiktok/" target="_blank"><span>a sizable following on TikTok</span></a>.&nbsp;</p></span><span data-component="TextBlock"><p>The device is modeled and named after the virtual dolphin from the movie <em>Johnny Mnemonic</em>, and it’s essentially <a href="https://www.vice.com/en/article/bvxyjm/meet-flipper-the-tamagotchi-you-feed-by-hacking-stuff"><span>a Tamagotchi you can use to hack stuff</span></a>. Flipper can scan radio frequencies and clone key fobs, control infrared-based devices, and is generally a kind of Swiss Army knife for security researchers, who actually <a href="https://www.packetlabs.net/posts/flipper-zero/" target="_blank"><span>use it to improve device security</span></a>. It’s also used by hobbyists who like playing around with computers,&nbsp; and more generally it’s just really adorable. But there's a lot of <a href="https://www.zdnet.com/home-and-office/flipper-zero-can-you-really-hack-wi-fi-networks-and-other-questions-answered/" target="_blank"><span>misinformation floating around</span></a> about its capabilities due to bombastic—and often staged—videos on TikTok and other social media platforms.</p></span><span></span><span data-component="TextBlock"><p>Flipper’s popularity has resulted in the device being named as a target in an upcoming National Summit on Combating Auto Theft, where the Canadian government claims, without any evidence, that the device is being used to steal cars.&nbsp;</p></span><span data-component="TextBlock"><p>“Criminals have been using sophisticated tools to steal cars. And Canadians are rightfully worried,” wrote François-Philippe Champagne, the Canadian Minister of Innovation, Science and Industry, in a tweet. “Today, I announced we are banning the importation, sale and use of consumer hacking devices, like flippers, used to commit these crimes.”</p></span><span data-component="TextBlock"><p>Canada <a href="https://www.vice.com/en/article/7kxdmx/one-regulation-could-have-stopped-a-nationwide-car-theft-wave-why-dont-we-have-it"><span>does have a problem with car thefts</span></a> at the moment tied to organized crime networks, but there's no evidence that Flipper Zero is playing a major role in these thefts. The Flipper Zero scans frequencies and records signals that can be replayed. While the Flipper Zero can do this for a car key fob, allowing a user to open a car with the device, it only works once due to the rolling codes that have been implemented by car makers for 30 years, and only if the key fob is first activated out of range of the car. <a href="https://www.youtube.com/watch?v=CGpMF_H0bUg" target="_blank"><span>More effective approaches</span></a> used by criminals involve actually plugging a device into a car with a cable or employing a "relay" (not replay) attack that involves two devices—one by the car and one near the fob, which tricks the car into thinking the owner is nearby.&nbsp;</p></span><span></span><span data-component="TextBlock"><p>Champagne linked a <a href="https://www.canada.ca/en/public-safety-canada/news/2024/02/government-of-canada-hosts-national-summit-on-combatting-auto-theft.html" target="_blank"><span>press release for an upcoming national summit</span></a> where government will be “Pursuing all avenues to ban devices used to steal vehicles by copying the wireless signals for remote keyless entry, such as the Flipper Zero, which would allow for the removal of those devices from the Canadian marketplace through collaboration with law enforcement agencies,” according to one the conference’s agenda items. The press release does not include any evidence that the device is being used for auto theft.</p></span></p><p><span data-component="TextBlock"><p>Naturally, this has riled digital rights groups and sections of the hacker and cybersecurity community, who are both upset and unsurprised that the Canadian government has their beloved Flipper in its crosshairs.&nbsp;</p></span><span data-component="TextBlock"><p>"We shouldn't be blaming manufacturers of radio transmitters for security lapses in the wireless unlock mechanisms of cars," Bill Budington, Senior Staff Technologist at the Electronic Frontier Foundation, said in a statement to Motherboard. "Flipper Zero devices, because of their ease of use, are convenient scapegoats to blame for gaping security holes in fob implementations by car manufacturers. Banning Flipper Zero devices is tantamount to banning a multi-tool because it can be used for vandalism, or banning markers because they can be used for graffiti. Moreover, tools like the Flipper Zero are used by security researchers involved in researching and hardening the security of systems like car fobs—banning them will result in tangible harms."</p></span><span></span><span data-component="TextBlock"><p>Canadian digital rights group OpenMedia concurred that banning the Flipper Zero would do more harm than good.&nbsp;</p></span><span data-component="TextBlock"><p>"A ban on sale of general purpose tools like the Flipper Zero will do more to hurt than help Canadian cybersecurity," said OpenMedia Executive Director Matt Hatfield. "The core problem here is the vulnerability of the keyless entry systems cars are using, not the fact that ordinary technology can reveal this vulnerability. By blocking the lawful sale of these devices, Canada will make it harder for cybersecurity researchers to do their work of testing vulnerabilities and informing the Canadian public, while doing little to prevent motivated car thieves from acquiring tools and exploiting these vulnerabilities."</p></span><span data-component="TextBlock"><p>When reached for comment, Flipper Devices COO Alex Kugalin reiterated that modern cars are largely protected from the simple attacks the device is capable of. “Flipper Zero can’t be used to hijack any car, specifically the ones produced after the 1990s, since their security systems have rolling codes. Also, it’d require actively blocking the signal from the owner to catch the original signal, which Flipper Zero’s hardware is incapable of doing”, said Alex Kulagin, COO of Flipper Devices. “Flipper Zero is intended for security testing and development and we have taken necessary precautions to ensure the device can’t be used for nefarious purposes."</p></span><span></span></p><p><span data-component="TextBlock"><p>The company pointed Motherboard to <a href="https://www.cyber.nj.gov/alerts-advisories/flipper-zero" target="_blank"><span>a January 2023 alert</span></a> from the New Jersey Cybersecurity &amp; Communications Integration Cell, a state organization. The alert stated that "most modern wireless devices are not vulnerable to simple replay attacks" and added that the Flipper Zero is unable to make purchases using signals captured from contactless credit cards. The alert also pointed to <a href="https://www.wired.com/story/what-is-flipper-zero-tiktok/" target="_blank"><span>reporting from Wired</span></a> that stated most of the dramatic videos on TikTok showing a Flipper Zero being used to steal a car are likely staged.&nbsp;</p></span><span data-component="TextBlock"><p>The proposed ban prompted bemused reactions from cybersecurity professionals on social media. “The only thing that can stop a bad guy with a Flipper Zero is a good guy with a Flipper Zero. I have a right to protect my family and community,” wrote security researcher Wesley McGrew, in a cheeky tweet referencing the frequently-used pro-gun rhetoric. McGrew also responded to Champagne’s post with a “Come And Take It” meme spinning off the popular <a href="https://en.wikipedia.org/wiki/Come_and_take_it" target="_blank"><span>libertarian slogan</span></a>.</p></span><span data-component="TextBlock"><p>Security experts lined up to lambaste the Canadian government and its insistence that the device is enabling crime. “Instant reactive thought… Isn’t stealing a car already a crime - that the criminal is ok breaking?” wrote security consultant Josh Corman.</p></span><span data-component="TextBlock"><p>Others mocked the government’s belief that devices like Flipper Zero are dangerous and all-powerful hacking tools. “I don’t find the Flipper to be that useful. Its built-in radio frequency support is barely more than you get from a good rooted phone. And I was unable to purchase the RF frequency modules because they were sold out. But imagine that *this* is considered a threat!” <a href="https://twitter.com/matthew_d_green/status/1755984810915385545" target="_blank"><span>wrote Matthew Green</span></a>, a professor of cryptography at Johns Hopkins University.</p></span><span data-component="TextBlock"><p><em>Jordan Pearson contributed reporting to this article.&nbsp;</em></p></span></p></div><div><p><h3>ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three Virtues of a Great Programmer (213 pts)]]></title>
            <link>https://thethreevirtues.com/</link>
            <guid>39385228</guid>
            <pubDate>Thu, 15 Feb 2024 17:10:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thethreevirtues.com/">https://thethreevirtues.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39385228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="85%">
	<tbody><tr>
	<td>
		<br><hr>
		<p>According to Larry Wall<sup>(1)</sup>, the original author of the Perl
		programming language, there are <b>three great virtues of a programmer</b>; Laziness, Impatience and Hubris</p>
		<ol>
			<li> <b>Laziness</b>: The quality that makes you go to great effort to
			reduce overall energy expenditure.  It makes you write labor-saving
			programs that other people will find useful and document what you
			wrote so you don't have to answer so many questions about it.</li>
			<li> <b>Impatience</b>: The anger you feel when the computer is being
			lazy.  This makes you write programs that don't just react to your
			needs, but actually anticipate them.  Or at least pretend to.</li>
			<li> <b>Hubris</b>: The quality that makes you write (and maintain)
			programs that other people won't want to say bad things about.</li>
		</ol>
		<hr>
	</td>
	</tr>
	</tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every Default macOS Wallpaper (395 pts)]]></title>
            <link>https://512pixels.net/projects/default-mac-wallpapers-in-5k/</link>
            <guid>39384731</guid>
            <pubDate>Thu, 15 Feb 2024 16:29:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://512pixels.net/projects/default-mac-wallpapers-in-5k/">https://512pixels.net/projects/default-mac-wallpapers-in-5k/</a>, See on <a href="https://news.ycombinator.com/item?id=39384731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary">
		<main id="main">

		
<article id="post-14130" class="page">
	<!-- .entry-header -->

	
<!--			<div class="post-thumbnail">-->
<!--				--><!--			</div>-->

		
	<div>
		<p>Every major version of <del>Mac OS X</del> macOS has come with a new default wallpaper. As you can see, I have collected them all here.</p>
<p>While great in their day, the early wallpapers are now quite small in the world of 5K and 6K displays.</p>
<p>If you want to see detailed screenshots of every release of OS X, <a href="https://512pixels.net/projects/aqua-screenshot-library/"><strong>click here.</strong></a></p>
<p>If you are looking for Mac OS 9 wallpapers, <a href="https://512pixels.net/projects/mac-os-9-5k-wallpapers/"><strong>this page is for you.</strong></a></p>
<h2>Sponsored by Rogue Amoeba</h2>

<p><a href="https://rogueamoeba.com/sentBy.php?512LIBRARY-2024"><img decoding="async" src="https://512pixels.net/wp-content/uploads/2023/12/512-banner-larger@2x.png"> </a></p>
<p>Rogue Amoeba is proud to continue our sponsorship of the 512 Pixels Mac Wallpaper Archive. We’ve been making amazing macOS audio software Aqua was the hot new thing.</p>
<p>From recording anything with Audio Hijack to getting superior control over all the sound on your Mac with SoundSource, we have tools for all your audio needs. Visit <a href="https://rogueamoeba.com/sentBy.php?512LIBRARY-2024">rogueamoeba.com</a> to learn about all our great utilities.</p>
<hr>
<h2>10.0 Cheetah &amp; 10.1 Puma</h2>
<p>The first two releases of Mac OS X shared the same wallpaper. The sweeping blue arcs and curves helped set the tone of the new Aqua interface.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-0_10.1--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-0_10.1.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-0_10-1-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.2 Jaguar</h2>
<p>Jaguar took the same Aqua-inspired theme but added some depth and motion to things. In my head, the trails streaking across the screen were from a set of comets.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-2--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-2.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-2-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.3 Panther</h2>
<p>While Panther inflicted Macs everywhere with <a href="https://512pixels.net/wp-content/uploads/2018/08/10-3-Panther-Command-Tab.png">Brushed Metal,</a> its wallpaper stayed on brand, refreshing the original 10.0 image.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-3--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-3.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-3-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.4 Tiger</h2>
<p>Many consider Tiger to be the best “classic” version of Mac OS X. While that may or may not be true, it is my favorite Aqua-inspired wallpaper.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-4--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-4.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-4-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.5 Leopard</h2>
<p>Complete with a revised, unified user interface and shiny new Dock, 10.5 broke the Aqua mold. As such, Leopard was the first version of OS X to break from the Aqua-themed wallpaper. It ushered in the “space era” of OS X wallpapers, which was used heavily in the new Time Machine interface as well.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-5--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-5.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-5-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.5 Leopard Server</h2>
<p>The server version of Leopard server came with its own unique wallpaper that is a real treat:</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-5-Server-thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-5-Server.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-5-Server-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.6 Snow Leopard</h2>
<p>The “no new features” mantra for Snow Leopard didn’t ban a new wallpaper, thankfully. This starscape is still one of my favorites. The Server version isn’t bad either!</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-6--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-6.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-6-6k.jpg"><strong>Download 6K version.</strong></a></p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-6-Server-thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-6-Server.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-6-Server-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.7 Lion</h2>
<p>Lion kept up the space theme, this time showing off the Andromeda galaxy. The space nerd in me likes the idea, but the execution of this one leaves dead-last on my list of favorites.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-7--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-7.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-7-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.8 Mountain Lion</h2>
<p>Just like Snow Leopard before it, with Mountain Lion, Apple opted to clean up and revise the existing theme as opposed to changing directions for what would be a less-impactful release of OS X.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-8--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-8.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-8-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.9 Mavericks</h2>
<p>Mavericks marked the beginning of Apple’s “California location” naming scheme for Mac releases. The wave depicted looks as intimidating as the ones in the famous surfing location.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-9--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-9.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-9-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.10 Yosemite</h2>
<p>Yosemite brought another UI refresh to the Mac, making things flatter and more modern. The wallpaper ushered in a new era based on … well … mountains.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-10--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-10.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-10-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.11 El Capitan</h2>
<p>Named after a breathtaking spot in Yosemite National Park, El Capitan was a clean-up year after 10.10.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-11--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-11.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-11-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.12 Sierra</h2>
<p>More mountains.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-12--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-12.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-12-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.13 High Sierra</h2>
<p>Even more mountains.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-13--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-13.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-13-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.14 Mojave</h2>
<p>No more mountains! Mojave brought a new system-wide Dark Mode, and the OS shipped with two versions of its default wallpaper to match. Users could even have macOS slowly fade between the two background images over the course of the day.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-14-Day-Thumb.jpg" alt=""></p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-14-Night-Thumb.jpg" alt=""></p>
<p><strong>Download 5K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-14-Day.jpg">Mojave Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-14-Night.jpg">Mojave Night</a></li>
</ul>
<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-14-Day-6k.jpg">Mojave Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-14-Night-6k.jpg">Mojave Night</a></li>
</ul>
<h2>10.15 Catalina</h2>
<p>macOS Catalina brought big changes to the Mac, including the ability to run iPad apps natively, opening the platform up to a much larger number of developers than ever before. Catalina shipped with multiple variants of its default wallpaper, and the ability to shift between them as time progresses throughout the day:</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-1"><figure>
			<p><img fetchpriority="high" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="19699" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/10-15-day-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10-15-Day-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg">
			</p></figure><figure>
			<p><img decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="19700" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/10-15-night-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10-15-Night-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-15-Day.jpg">Catalina Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-15-Night.jpg">Catalina Night</a></li>
</ul>
<h2>macOS Big Sur</h2>
<p>This version of macOS is such a big deal, Apple changed the version number to 11.0. It will be the OS that brings support for Apple Silicon-powered Macs, and features a brand new design.</p>


<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Color-Day.jpg">Big Sur Colorful Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Big-Sur-Color-Night.jpg">Big Sur Colorful Night</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Day.jpg">Big Sur Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Night.jpg">Big Sur Night</a></li>
</ul>
<h2>macOS Monterey</h2>
<p>This version of macOS builds on Big Sur, bringing Shortcuts and a range of features that are also part of iOS and iPadOS 15. As of the first beta, Monterey does not include any new nature wallpapers as previous releases has.</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-3"><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="22538" data-permalink="https://512pixels.net/12-light-thumbnail/" data-orig-file="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="12-Light-thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg">
			</p></figure><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="22537" data-permalink="https://512pixels.net/12-dark-thumbnail/" data-orig-file="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="12-Dark-thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/12-Light.jpg">Monterey Light</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/12-Dark.jpg">Monterey Dark</a></li>
</ul>
<h2>macOS Ventura</h2>
<p>macOS 13 brings big changes to system apps like Mail and Messages, as well as a new multitasking user interface named Stage Manager.</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-4"><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb.jpg 2000w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-1536x1536.jpg 1536w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="24717" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/13-ventura-light-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="13-Ventura-Light-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-2000x2000.jpg">
			</p></figure><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb.jpg 2000w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-1536x1536.jpg 1536w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="24716" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/13-ventura-dark-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="13-Ventura-Dark-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-2000x2000.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/13-Ventura-Light.jpg">Ventura Light</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/13-Ventura-Dark.jpg">Ventura Dark</a></li>
</ul>
<h2>macOS Sonoma</h2>
<p>macOS Sonoma brings several goodies, including the ability to use interactive widgets on the Desktop, enhanced video conferencing, updates to many core apps and the inclusion of stickers … for some reason.</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-5"><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-1536x1536.jpg 1536w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb.jpg 2000w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="27117" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/14-sonoma-light-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="14-Sonoma-Light-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb.jpg">
			</p></figure><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-1536x1536.jpg 1536w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb.jpg 2000w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="27116" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/14-sonoma-dark-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="14-Sonoma-Dark-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/14-Sonoma-Light.jpg">Sonoma Light</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/14-Sonoma-Dark.jpg">Sonoma Dark</a></li>
</ul>
<p><strong><a href="https://512pixels.net/membership/">Become a member of 512 Pixels.</a></strong> Support projects like these, receive exclusive content in the monthly newsletter and enjoy advanced screenings of my YouTube videos.</p>
	</div><!-- .entry-content -->

	</article><!-- #post-14130 -->

		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The existence of a new kind of magnetism has been confirmed (142 pts)]]></title>
            <link>https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/</link>
            <guid>39384458</guid>
            <pubDate>Thu, 15 Feb 2024 16:12:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/">https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/</a>, See on <a href="https://news.ycombinator.com/item?id=39384458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <header>
                                                            <h4>
                                                                        <a href="https://www.newscientist.com/subject/physics/" data-analytics-hook="article-header-subject-link">Physics</a>
                                </h4>
                                                        
                            

                            
                                                            <p>Altermagnets, theorised to exist but never before seen, have been measured for the first time and they could help us make new types of magnetic computers</p>
                            
                            
                            
                            <p>
        
<a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="facebook" aria-label="Link to Facebook / Meta">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" fill="rgb(0, 0, 0)">
    <title>Facebook / Meta</title>
    <g>
        <path d="M22 5.16c-.406-.054-1.806-.16-3.43-.16-3.4 0-5.733 1.825-5.733 5.17v2.882H9v3.913h3.837V27h4.604V16.965h3.823l.587-3.913h-4.41v-2.5c0-1.123.347-1.903 2.198-1.903H22V5.16z" fill-rule="evenodd"></path>
    </g>
    </svg>
</a>
        
<a href="https://twitter.com/share?url=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="twitter" aria-label="Link to Twitter / X">
    <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="none" viewBox="0 0 22 22">
        <title>Twitter / X icon</title>
        <path fill="#000" d="m12.21 9.814 5.644-6.556h-1.338l-4.9 5.692L7.7 3.258H3.185l5.92 8.608-5.92 6.875h1.338L9.7 12.73l4.134 6.011h4.515L12.21 9.814Zm-1.833 2.128-.6-.857-4.772-6.821H7.06l3.851 5.505.6.857 5.006 7.155h-2.055l-4.085-5.839Z"></path>
    </svg>
</a>
    <a href="whatsapp://send?text=The%20existence%20of%20a%20new%20kind%20of%20magnetism%20has%20been%20confirmed%20https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/" data-action="share/whatsapp/share" target="_blank" rel="nofollow" data-social-platform="whatsapp">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <path d="M19.11 17.205c-.372 0-1.088 1.39-1.518 1.39a.63.63 0 0 1-.315-.1c-.802-.402-1.504-.817-2.163-1.447-.545-.516-1.146-1.29-1.46-1.963a.426.426 0 0 1-.073-.215c0-.33.99-.945.99-1.49 0-.143-.73-2.09-.832-2.335-.143-.372-.214-.487-.6-.487-.187 0-.36-.043-.53-.043-.302 0-.53.115-.746.315-.688.645-1.032 1.318-1.06 2.264v.114c-.015.99.472 1.977 1.017 2.78 1.23 1.82 2.506 3.41 4.554 4.34.616.287 2.035.888 2.722.888.817 0 2.15-.515 2.478-1.318.13-.33.244-.73.244-1.088 0-.058 0-.144-.03-.215-.1-.172-2.434-1.39-2.678-1.39zm-2.908 7.593c-1.747 0-3.48-.53-4.942-1.49L7.793 24.41l1.132-3.337a8.955 8.955 0 0 1-1.72-5.272c0-4.955 4.04-8.995 8.997-8.995S25.2 10.845 25.2 15.8c0 4.958-4.04 8.998-8.998 8.998zm0-19.798c-5.96 0-10.8 4.842-10.8 10.8 0 1.964.53 3.898 1.546 5.574L5 27.176l5.974-1.92a10.807 10.807 0 0 0 16.03-9.455c0-5.958-4.842-10.8-10.802-10.8z" fill-rule="evenodd"></path>
        </g>
    </svg>
</a>
        
<a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="linkedin" aria-label="Link to Linkedin">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
    <title>Linkedin</title>
    <g>
        <path d="M26 25.963h-4.185v-6.55c0-1.56-.027-3.57-2.175-3.57-2.18 0-2.51 1.7-2.51 3.46v6.66h-4.182V12.495h4.012v1.84h.058c.558-1.058 1.924-2.174 3.96-2.174 4.24 0 5.022 2.79 5.022 6.417v7.386zM8.23 10.655a2.426 2.426 0 0 1 0-4.855 2.427 2.427 0 0 1 0 4.855zm-2.098 1.84h4.19v13.468h-4.19V12.495z" fill-rule="evenodd"></path>
    </g>
    </svg>
</a>
        
<a href="https://reddit.com/submit?url=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F&amp;title=The%20existence%20of%20a%20new%20kind%20of%20magnetism%20has%20been%20confirmed" target="_blank" rel="nofollow" data-social-platform="reddit">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <path d="M27 15.5a2.452 2.452 0 0 1-1.338 2.21c.098.38.147.777.147 1.19 0 1.283-.437 2.47-1.308 3.563-.872 1.092-2.06 1.955-3.567 2.588-1.506.634-3.143.95-4.91.95-1.768 0-3.403-.316-4.905-.95-1.502-.632-2.69-1.495-3.56-2.587-.872-1.092-1.308-2.28-1.308-3.562 0-.388.045-.777.135-1.166a2.47 2.47 0 0 1-1.006-.912c-.253-.4-.38-.842-.38-1.322 0-.678.237-1.26.712-1.744a2.334 2.334 0 0 1 1.73-.726c.697 0 1.29.26 1.78.782 1.785-1.258 3.893-1.928 6.324-2.01l1.424-6.467a.42.42 0 0 1 .184-.26.4.4 0 0 1 .32-.063l4.53 1.006c.147-.306.368-.553.662-.74a1.78 1.78 0 0 1 .97-.278c.508 0 .94.18 1.302.54.36.36.54.796.54 1.31 0 .512-.18.95-.54 1.315-.36.364-.794.546-1.302.546-.507 0-.94-.18-1.295-.54a1.793 1.793 0 0 1-.533-1.308l-4.1-.92-1.277 5.86c2.455.074 4.58.736 6.37 1.985a2.315 2.315 0 0 1 1.757-.757c.68 0 1.256.242 1.73.726.476.484.713 1.066.713 1.744zm-16.868 2.47c0 .513.178.95.534 1.315.356.365.787.547 1.295.547.508 0 .942-.182 1.302-.547.36-.364.54-.802.54-1.315 0-.513-.18-.95-.54-1.31-.36-.36-.794-.54-1.3-.54-.5 0-.93.183-1.29.547a1.79 1.79 0 0 0-.54 1.303zm9.944 4.406c.09-.09.135-.2.135-.323a.444.444 0 0 0-.44-.447c-.124 0-.23.042-.32.124-.336.348-.83.605-1.486.77a7.99 7.99 0 0 1-1.964.248 7.99 7.99 0 0 1-1.964-.248c-.655-.165-1.15-.422-1.486-.77a.456.456 0 0 0-.32-.124.414.414 0 0 0-.306.124.41.41 0 0 0-.135.317.45.45 0 0 0 .134.33c.352.355.837.636 1.455.843.617.207 1.118.33 1.503.366a11.6 11.6 0 0 0 1.117.056c.36 0 .733-.02 1.117-.056.385-.037.886-.16 1.504-.366.62-.207 1.104-.488 1.456-.844zm-.037-2.544c.507 0 .938-.182 1.294-.547.356-.364.534-.802.534-1.315 0-.505-.18-.94-.54-1.303a1.75 1.75 0 0 0-1.29-.546c-.506 0-.94.18-1.3.54-.36.36-.54.797-.54 1.31s.18.95.54 1.315c.36.365.794.547 1.3.547z" fill-rule="evenodd"></path>
        </g>
    </svg>
</a>
    <a href="mailto:?subject=The%20existence%20of%20a%20new%20kind%20of%20magnetism%20has%20been%20confirmed&amp;body=Altermagnets%2C%20theorised%20to%20exist%20but%20never%20before%20seen%2C%20have%20been%20measured%20for%20the%20first%20time%20and%20they%20could%20help%20us%20make%20new%20types%20of%20magnetic%20computers%0D%0Aread%20more:%20https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="email">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <g fill-rule="evenodd"></g>
            <path d="M27 22.757c0 1.24-.988 2.243-2.19 2.243H7.19C5.98 25 5 23.994 5 22.757V13.67c0-.556.39-.773.855-.496l8.78 5.238c.782.467 1.95.467 2.73 0l8.78-5.238c.472-.28.855-.063.855.495v9.087z"></path><path d="M27 9.243C27 8.006 26.02 7 24.81 7H7.19C5.988 7 5 8.004 5 9.243v.465c0 .554.385 1.232.857 1.514l9.61 5.733c.267.16.8.16 1.067 0l9.61-5.733c.473-.283.856-.96.856-1.514v-.465z"></path>
        </g>
    </svg>
</a>
    <a rel="nofollow" tabindex="0">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <path d="M24.67 10.62h-2.86V7.49H10.82v3.12H7.95c-.5 0-.9.4-.9.9v7.66h3.77v1.31L15 24.66h6.81v-5.44h3.77v-7.7c-.01-.5-.41-.9-.91-.9zM11.88 8.56h8.86v2.06h-8.86V8.56zm10.98 9.18h-1.05v-2.1h-1.06v7.96H16.4c-1.58 0-.82-3.74-.82-3.74s-3.65.89-3.69-.78v-3.43h-1.06v2.06H9.77v-3.58h13.09v3.61zm.75-4.91c-.4 0-.72-.32-.72-.72s.32-.72.72-.72c.4 0 .72.32.72.72s-.32.72-.72.72zm-4.12 2.96h-6.1v1.06h6.1v-1.06zm-6.11 3.15h6.1v-1.06h-6.1v1.06z"></path>
        </g>
    </svg>
</a></p>                        </header>
                    </div><section>
                    <figure data-method="caption-shortcode"><p><img src="https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=1200" data-src="https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=1200" srcset="https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=100 100w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=200 200w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=249 249w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=300 300w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=400 400w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=500 500w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=600 600w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=700 700w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=800 800w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=900 900w" sizes="(min-width: 1130px) 900px, (min-width: 1025px) 900, (min-width: 768px) calc(100vw - 30px), calc(100vw - 30px)" alt="Illustration of altermagnetism in a chemical compound" width="1348" height="900" data-credit="Libor Šmejkal and Anna Birk Hellenes" data-caption="Altermagnetism works differently from standard magnetism"></p><figcaption><div><p>Altermagnetism works differently from standard magnetism</p><p>Libor Šmejkal and Anna Birk Hellenes</p></div></figcaption></figure>
<p>A new kind of magnetism has been measured for the first time. Altermagnets, which contain a blend of properties from different classes of existing magnets, could be used to make high capacity and fast memory devices or new kinds of magnetic computers.</p>
<p>Until the 20th century, there was thought to be only one kind of <a href="https://www.newscientist.com/article/mg24432580-500-exotic-super-magnets-could-shake-up-medicine-cosmology-and-computing/">permanent magnet</a>, a ferromagnet, the effects of which can be seen in objects with relatively strong external magnetic fields like fridge magnets or compass needles.</p>

    
<p>These fields are caused by the magnetic spins of the magnets’ electrons lining up in one direction.</p>
<p>But, in the 1930s, French physicist Louis Néel discovered another kind of magnetism, <a href="https://www.newscientist.com/article/weird-magnets-make-computers-work-1000-times-faster/">called antiferromagnetism</a>, where the electrons’ spins are alternately up and down. Although antiferromagnets lack the external fields of ferromagnets, they do show interesting internal magnetic properties because of the alternating spins.</p>
<p>Then in 2019, <a href="https://arxiv.org/abs/1901.00445">researchers predicted a perplexing electric current in the crystal structure of certain antiferromagnets, called the anomalous Hall effect</a>, which couldn’t be explained by the conventional theory of alternating spins. The current was moving without any external magnetic field.</p>
<span></span><p>It seemed, when looking at a crystal in terms of sheets of spins, that <a href="https://arxiv.org/abs/2105.05820">a third kind of permanent magnetism might be responsible, which has been called altermagnetism.</a> Altermagnets would look like antiferromagnets, but the sheets of spins would look the same when rotated from any angle. This would explain the Hall effect, but no one had seen the electronic signature of this structure itself, so scientists were unsure whether it was definitely a new kind of magnetism.</p>
<p>Now, <a href="https://www.psi.ch/en/lno/people/juraj-krempasky">Juraj Krempasky</a> at the Paul Scherrer Institute in Villigen, Switzerland, and his colleagues have confirmed the existence of an altermagnet by measuring the electron structure in a crystal, manganese telluride, that was previously thought to be antiferromagnetic.</p>
    
<p>To do this, they gauged how light bounced off manganese telluride to find the energies and speeds of the electrons inside the crystal. After mapping out these electrons, they were found to almost exactly match the predictions given by simulations for an altermagnetic material.</p>
<p>The electrons seemed to be split into two groups, which allows them more movement inside the crystal and is the source of the unusual altermagnetic properties. “This gave direct evidence that we can talk about altermagnets and that they behave exactly as predicted by theory,” says Krempasky.</p>

    
<p>This electron grouping seems to come from the atoms of tellurium, which is non-magnetic, in the crystal structure, which separate the magnetic charges of the manganese into their own planes and allow the unusual rotational symmetry.</p>
<p>“It’s really nice verification that these materials do exist,” says <a href="https://www.york.ac.uk/physics-engineering-technology/people/physics-staff-richard-evans/">Richard Evans</a> at the University of York, UK. As well as the electrons in altermagnets being freer to move than those in antiferromagnets, this new type of magnet also doesn’t have external magnetic fields like in ferromagnets, says Evans, so you can use them to make magnetic devices that don’t interfere with each other.</p>
<p>The property could boost the storage on computer hard drives, because commercial devices contain ferromagnetic material that is so tightly packed that the material’s external magnetic fields start to see interference – altermagnets could be packed more densely.</p>
<p>The magnets could even lead to spintronic computers that use magnetic spin instead of current to perform their measurements and calculations, says <a href="https://eps.leeds.ac.uk/physics/staff/5729/dr-joseph-barker">Joseph Barker</a> at the University of Leeds, UK, combining memory and computer chips into one device. “It maybe gives more hope to the idea that we could make spintronic devices become a reality,” says Barker.</p>


                    <div><h4>Article amended on 15 February 2024</h4><p>We have corrected when Louis Néel discovered antiferromagnetism and the name of the crystal studied to confirm the existence of altermagnetism.</p></div><section><p>Topics:</p></section>                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asahi Linux project's OpenGL support on Apple Silicon officially surpasses Apple (350 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/</link>
            <guid>39383798</guid>
            <pubDate>Thu, 15 Feb 2024 15:26:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/">https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/</a>, See on <a href="https://news.ycombinator.com/item?id=39383798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      who needs metal?    —
</h4>
            
            <h2 itemprop="description">Newest driver supports the latest versions of OpenGL and OpenGL ES.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/03/asahi-macbook-800x450.jpg" alt="Slowly but surely, the Asahi Linux team is getting Linux up and running on Apple Silicon Macs.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2022/03/asahi-macbook.jpg" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> Slowly but surely, the Asahi Linux team is getting Linux up and running on Apple Silicon Macs.</p><p>Apple/Asahi Linux</p></figcaption>  </figure>

  




<!-- cache hit 2:single/related:356a9a52863033d61adc4d1aa1b1cbb1 --><!-- empty -->
<p>For around three years now, the team of independent developers behind the Asahi Linux project has worked to support Linux on Apple Silicon Macs, despite Apple's total lack of involvement. Over the years, the project has gone from a "highly unstable experiment" to a "surprisingly functional and usable desktop operating system." Even Linus Torvalds has used it to run Linux on Apple's hardware.</p>
<p>The team has been steadily improving its open source, standards-conformant GPU driver for the M1 and M2 since releasing them <a href="https://rosenzweig.io/blog/asahi-gpu-part-7.html">in December 2022</a>, and today, the team crossed an important symbolic milestone: The Asahi driver's support for the OpenGL and OpenGL ES graphics have officially passed what Apple offers in macOS. The team's latest graphics driver fully conforms with OpenGL version 4.6 and OpenGL ES version 3.2, the most recent version of either API. Apple's support in macOS tops out at OpenGL 4.1, announced in July 2010.</p>
<p>Developer Alyssa Rosenzweig wrote <a href="https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html">a detailed blog post</a> that announced the new driver, which had to pass "over 100,000 tests" to be deemed officially conformant. The team achieved this milestone despite the fact that Apple's GPUs don't support some features that would have made implementing these APIs more straightforward.</p>
<p>"Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1," writes Rosenzweig. "While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set... Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on."</p>                                            
                                                        

<p>Now that the Asahi GPU driver supports the latest OpenGL and OpenGL ES standards—released in 2017 and 2015, respectively—the work turns to supporting the low-overhead Vulkan API on Apple's hardware. Vulkan support in macOS is limited to translation layers like MoltenVK, which translates Vulkan API calls to Metal ones that the hardware and OS can understand.</p>
<p>Apple's OpenGL support has been stuck at the 4.1 level since macOS 10.9 Mavericks was released in 2013. Since then, the company has shifted its focus to its proprietary Metal graphics API, which, like DirectX 12 and Vulkan, is a "low-overhead" API meant to reduce the performance overhead sometimes associated with older APIs like OpenGL. But despite declaring OpenGL <a href="https://arstechnica.com/gadgets/2018/06/the-end-of-opengl-support-other-updates-apple-didnt-share-at-the-keynote/">officially deprecated</a> in 2018, Apple has left its existing OpenGL implementation alone since then, never updating it but also maintaining support even as it has transitioned from Intel's processors to its own CPUs and GPUs.</p>
<p>Rosenzweig's blog post didn't give any specific updates on Vulkan except to say that the team was "well on the road" to supporting it. In addition to supporting native Linux apps, supporting more graphics APIs in Asahi will allow the operating system to take better advantage of software like <a href="https://arstechnica.com/gaming/2023/04/proton-update-gets-18-more-windows-games-running-on-linux-including-chex-quest-hd/">Valve's Proton</a>, which already has a few games written for x86-based Windows PCs running on Arm-based Apple hardware.</p>
<p>Though there are still things that don't work, Fedora Asahi Remix is surprisingly polished and supports a lot of the hardware available in most M1 and M2 Macs—including the webcam, speakers, Wi-Fi and Bluetooth, and graphics acceleration. Other features, like Thunderbolt, running displays over USB-C, the system's built-in microphone, and the Touch ID fingerprint sensors, remain non-functional. Asahi's most recent update blog post, <a href="https://asahilinux.org/2024/01/fedora-asahi-new/">published in mid-January</a>, highlighted HDMI support, support for DRM-protected websites via Google's proprietary Widevine package, Touchbar support for the handful of Apple Silicon Macs that use one, and more.</p>
<p>As for the newest wave of M3 Macs, Asahi developer Hector Martin said in October 2023 that basic support for the newest chips would take "at least six months." Among other things, the team will need time to support the M3 GPU in their drivers; the team also relies primarily on Mac mini models for development, and the M3 Mac mini doesn't exist yet.</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 1.5 Pro (151 pts)]]></title>
            <link>https://twitter.com/JeffDean/status/1758146022726041615</link>
            <guid>39383593</guid>
            <pubDate>Thu, 15 Feb 2024 15:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/JeffDean/status/1758146022726041615">https://twitter.com/JeffDean/status/1758146022726041615</a>, See on <a href="https://news.ycombinator.com/item?id=39383593">Hacker News</a></p>
Couldn't get https://twitter.com/JeffDean/status/1758146022726041615: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Our next-generation model: Gemini 1.5 (988 pts)]]></title>
            <link>https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/</link>
            <guid>39383446</guid>
            <pubDate>Thu, 15 Feb 2024 15:02:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=39383446">Hacker News</a></p>
<div id="readability-page-1" class="page"><article ng-init="drawerToggle = {'open': true}">

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
  }">
      
      
        <p>
          The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.
        </p>
      
    </div>

    

    
      







<div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif" fetchpriority="high" alt="The word “Gemini 1.5” appears in a blue gradient against a black background.">
  </p>
</div>

      
    </figure>
  </div>


    

    
    <div>
        
          
            <div data-component="uni-article-jumplinks" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Jumplinks&quot;,
    &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
  }">
  <nav aria-label="Article Jumplinks">
    <p><span>In this story</span>
    </p>
    
    
    <div>
      <ul id="article-jumplinks__list">
        
        <li>
          <a aria-label="link to Note from Sundar" href="#sundar-note" id="sundar-note-anchor">Note from Sundar</a>
        </li>
        
        <li>
          <a aria-label="link to Introducing Gemini 1.5" href="#gemini-15" id="gemini-15-anchor">Introducing Gemini 1.5</a>
        </li>
        
        <li>
          <a aria-label="link to Efficient architecture" href="#architecture" id="architecture-anchor">Efficient architecture</a>
        </li>
        
        <li>
          <a aria-label="link to Long context window" href="#context-window" id="context-window-anchor">Long context window</a>
        </li>
        
        <li>
          <a aria-label="link to Enhanced performance" href="#performance" id="performance-anchor">Enhanced performance</a>
        </li>
        
        <li>
          <a aria-label="link to Ethics and safety testing" href="#ethics-safety" id="ethics-safety-anchor">Ethics and safety testing</a>
        </li>
        
        <li>
          <a aria-label="link to Build with Gemini" href="#build-experiment" id="build-experiment-anchor">Build with Gemini</a>
        </li>
        
      </ul>
    </div>
    
  </nav>
</div>
          
          
          <div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">

            
              


<google-read-aloud-player data-analytics-module="{
        &quot;event&quot;: &quot;module_impression&quot;,
        &quot;module_name&quot;: &quot;ai_audio&quot;,
        &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
    }" data-date-modified="2024-02-15T15:43:59.395802+00:00" data-progress-bar-style="half-wave" data-api-key="AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac" data-article-style="style9" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-layout-style="style1" data-highlight-mode="word-over-paragraph" data-highlight-text-color="#000000" data-highlight-word-background="#8AB4F8" data-highlight-paragraph-background="#D2E3FC" data-background="linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)" data-foreground-color="#202124" data-font="600 16px Google Sans, sans-serif" data-box-shadow="0px 1px 3px 1px rgba(60, 64, 67, 0.15)">
</google-read-aloud-player>




            

            
            
<!--article text-->

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><p data-block-key="k1g9k"><i>A note from Google and Alphabet CEO Sundar Pichai:</i></p><p data-block-key="43i75">Last week, we rolled out our most capable model, Gemini 1.0 Ultra, and took a significant step forward in making Google products more helpful, starting with <a href="https://blog.google/technology/ai/google-gemini-update-sundar-pichai-2024/" rt-link-type="external">Gemini Advanced</a>. Today, developers and Cloud customers can begin building with 1.0 Ultra too — with our Gemini API in <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and in <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a>.</p><p data-block-key="ebks5">Our teams continue pushing the frontiers of our latest models with safety at the core. They are making rapid progress. In fact, we’re ready to introduce the next generation: Gemini 1.5. It shows dramatic improvements across a number of dimensions and 1.5 Pro achieves comparable quality to 1.0 Ultra, while using less compute.</p><p data-block-key="aa73f">This new generation also delivers a breakthrough in long-context understanding. We’ve been able to significantly increase the amount of information our models can process — running up to 1 million tokens consistently, achieving the longest context window of any large-scale foundation model yet.</p><p data-block-key="31sii">Longer context windows show us the promise of what is possible. They will enable entirely new capabilities and help developers build much more useful models and applications. We’re excited to offer a limited preview of this experimental feature to developers and enterprise customers. Demis shares more on capabilities, safety and availability below.</p><p data-block-key="5ecmf">— Sundar</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Introducing Gemini 1.5</h2><p data-block-key="f3142"><i>By Demis Hassabis, CEO of Google DeepMind, on behalf of the Gemini team</i></p><p data-block-key="chshj">This is an exciting time for AI. New advances in the field have the potential to make AI more helpful for billions of people over the coming years. Since <a href="https://blog.google/technology/ai/google-gemini-ai/" rt-link-type="external">introducing Gemini 1.0</a>, we’ve been testing, refining and enhancing its capabilities.</p><p data-block-key="bpk1l">Today, we’re announcing our next-generation model: Gemini 1.5.</p><p data-block-key="cq31g">Gemini 1.5 delivers dramatically enhanced performance. It represents a step change in our approach, building upon research and engineering innovations across nearly every part of our foundation model development and infrastructure. This includes making Gemini 1.5 more efficient to train and serve, with a new <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">Mixture-of-Experts</a> (MoE) architecture.</p><p data-block-key="ei3s7">The first Gemini 1.5 model we’re releasing for early testing is Gemini 1.5 Pro. It’s a mid-size multimodal model, optimized for scaling across a wide-range of tasks, and <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">performs at a similar level to 1.0 Ultra</a>, our largest model to date. It also introduces a breakthrough experimental feature in long-context understanding.</p><p data-block-key="73fdi">Gemini 1.5 Pro comes with a standard 128,000 token context window. But starting today, a limited group of developers and enterprise customers can try it with a context window of up to 1 million tokens via <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a> in private preview.</p><p data-block-key="2n70l">As we roll out the full 1 million token context window, we’re actively working on optimizations to improve latency, reduce computational requirements and enhance the user experience. We’re excited for people to try this breakthrough capability, and we share more details on future availability below.</p><p data-block-key="3k946">These continued advances in our next-generation models will open up new possibilities for people, developers and enterprises to create, discover and build using AI.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/final_tokens_scale_animated_3840x2300.mp4" type="video/mp4" title="Animation comparing the context lengths of leading foundation models, listing Gemini 1.0 Pro at 32,000 tokens, GPT-4 Turbo at 128,000 tokens, Claude 2.1 at 200,000 tokens, and Gemini 1.5 Pro at 1 million tokens and up to 10 million tokens tested in research." alt="final tokens animation">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="vi55e">Context lengths of leading foundation models</p></figcaption>
    
  
    </div>
  



  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Highly efficient architecture</h2><p data-block-key="5l1m">Gemini 1.5 is built upon our leading research on <a href="https://blog.research.google/2017/08/transformer-novel-neural-network.html" rt-link-type="external">Transformer</a> and <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">MoE</a> architecture. While a traditional Transformer functions as one large neural network, MoE models are divided into smaller "expert” neural networks.</p><p data-block-key="bofgb">Depending on the type of input given, MoE models learn to selectively activate only the most relevant expert pathways in its neural network. This specialization massively enhances the model’s efficiency. Google has been an early adopter and pioneer of the MoE technique for deep learning through research such as <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">Sparsely-Gated MoE</a>, <a href="https://arxiv.org/abs/2006.16668" rt-link-type="external">GShard-Transformer</a>, <a href="https://arxiv.org/abs/2101.03961" rt-link-type="external">Switch-Transformer,</a> <a href="https://blog.research.google/2019/10/exploring-massively-multilingual.html" rt-link-type="external">M4</a> and more.</p><p data-block-key="829je">Our latest innovations in model architecture allow Gemini 1.5 to learn complex tasks more quickly and maintain quality, while being more efficient to train and serve. These efficiencies are helping our teams iterate, train and deliver more advanced versions of Gemini faster than ever before, and we’re working on further optimizations.</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Greater context, more helpful capabilities</h2><p data-block-key="4m4dc">An AI model’s “context window” is made up of tokens, which are the building blocks used for processing information. Tokens can be entire parts or subsections of words, images, videos, audio or code. The bigger a model’s context window, the more information it can take in and process in a given prompt — making its output more consistent, relevant and useful.</p><p data-block-key="7l6jt">Through a series of machine learning innovations, we’ve increased 1.5 Pro’s context window capacity far beyond the original 32,000 tokens for Gemini 1.0. We can now run up to 1 million tokens in production.</p><p data-block-key="djuni">This means 1.5 Pro can process vast amounts of information in one go — including 1 hour of video, 11 hours of audio, codebases with over 30,000 lines of code or over 700,000 words. In our research, we’ve also successfully tested up to 10 million tokens.</p><h3 data-block-key="9id65">Complex reasoning about vast amounts of information</h3><p data-block-key="572lb">1.5 Pro can seamlessly analyze, classify and summarize large amounts of content within a given prompt. For example, when given the 402-page transcripts from Apollo 11’s mission to the moon, it can reason about conversations, events and details found across the document.</p></div>
  

  
    
  
    


<div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="LHKL_210CcU" data-index-id="10" data-analytics-module="{
    &quot;module_name&quot;: &quot;Youtube Video&quot;,
    &quot;section_header&quot;: &quot;undefined&quot;
  }">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Reasoning across a 402-page transcript: Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/LHKL_210CcU/default.webp" loading="lazy" data-loading="{
                &quot;mobile&quot;: &quot;//i.ytimg.com/vi_webp/LHKL_210CcU/sddefault.webp&quot;,
                &quot;desktop&quot;: &quot;//i.ytimg.com/vi_webp/LHKL_210CcU/maxresdefault.webp&quot;
              }"></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can understand, reason about and identify curious details in the 402-page transcripts from Apollo 11’s mission to the moon.</p>
    

    
  </div>

  


  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h3 data-block-key="k1g9k">Better understanding and reasoning across modalities</h3><p data-block-key="6atnh">1.5 Pro can perform highly-sophisticated understanding and reasoning tasks for different modalities, including video. For instance, when given a 44-minute silent <a href="https://www.youtube.com/watch?v=rOVtjJkqtiA" rt-link-type="external">Buster Keaton movie</a>, the model can accurately analyze various plot points and events, and even reason about small details in the movie that could easily be missed.</p></div>
  

  
    
  
    


<div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="wa0MT8OwHuk" data-index-id="12" data-analytics-module="{
    &quot;module_name&quot;: &quot;Youtube Video&quot;,
    &quot;section_header&quot;: &quot;undefined&quot;
  }">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Multimodal prompting with a 44-minute movie: Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/wa0MT8OwHuk/default.webp" loading="lazy" data-loading="{
                &quot;mobile&quot;: &quot;//i.ytimg.com/vi_webp/wa0MT8OwHuk/sddefault.webp&quot;,
                &quot;desktop&quot;: &quot;//i.ytimg.com/vi_webp/wa0MT8OwHuk/maxresdefault.webp&quot;
              }"></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can identify a scene in a 44-minute silent Buster Keaton movie when given a simple line drawing as reference material for a real-life object.</p>
    

    
  </div>

  


  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h3 data-block-key="l4f5z">Relevant problem-solving with longer blocks of code</h3><p data-block-key="6p94l">1.5 Pro can perform more relevant problem-solving tasks across longer blocks of code. When given a prompt with more than 100,000 lines of code, it can better reason across examples, suggest helpful modifications and give explanations about how different parts of the code works.</p></div>
  

  
    
  
    


<div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="SSnsmqIj1MI" data-index-id="14" data-analytics-module="{
    &quot;module_name&quot;: &quot;Youtube Video&quot;,
    &quot;section_header&quot;: &quot;undefined&quot;
  }">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Problem solving across 100,633 lines of code | Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/SSnsmqIj1MI/default.webp" loading="lazy" data-loading="{
                &quot;mobile&quot;: &quot;//i.ytimg.com/vi_webp/SSnsmqIj1MI/sddefault.webp&quot;,
                &quot;desktop&quot;: &quot;//i.ytimg.com/vi_webp/SSnsmqIj1MI/maxresdefault.webp&quot;
              }"></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can reason across 100,000 lines of code giving helpful solutions, modifications and explanations.</p>
    

    
  </div>

  


  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Enhanced performance</h2><p data-block-key="6peis">When tested on a comprehensive panel of text, code, image, audio and video evaluations, 1.5 Pro outperforms 1.0 Pro on 87% of the benchmarks used for developing our large language models (LLMs). And when compared to 1.0 Ultra on the same benchmarks, it performs at a broadly similar level.</p><p data-block-key="2m8o3">Gemini 1.5 Pro maintains high levels of performance even as its context window increases. In the <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" rt-link-type="external">Needle In A Haystack</a> (NIAH) evaluation, where a small piece of text containing a particular fact or statement is purposely placed within a long block of text, 1.5 Pro found the embedded text 99% of the time, in blocks of data as long as 1 million tokens.</p><p data-block-key="cq31">Gemini 1.5 Pro also shows impressive “in-context learning” skills, meaning that it can learn a new skill from information given in a long prompt, without needing additional fine-tuning. We tested this skill on the <a href="https://arxiv.org/abs/2309.16575" rt-link-type="external">Machine Translation from One Book</a> (MTOB) benchmark, which shows how well the model learns from information it’s never seen before. When given a <a href="https://langsci-press.org/catalog/book/344" rt-link-type="external">grammar manual</a> for <a href="https://endangeredlanguages.com/lang/1891?hl=en" rt-link-type="external">Kalamang</a>, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person learning from the same content.<br></p><p data-block-key="7op9s">As 1.5 Pro’s long context window is the first of its kind among large-scale models, we’re continuously developing new evaluations and benchmarks for testing its novel capabilities.</p><p data-block-key="b6eqt">For more details, see our <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">Gemini 1.5 Pro technical report</a>.</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Extensive ethics and safety testing</h2><p data-block-key="a3s4a">In line with our <a href="https://ai.google/responsibility/principles/" rt-link-type="external">AI Principles</a> and robust safety policies, we’re ensuring our models undergo extensive ethics and safety tests. We then integrate these research learnings into our governance processes and model development and evaluations to continuously improve our AI systems.</p><p data-block-key="3r93h">Since introducing 1.0 Ultra in December, our teams have continued refining the model, making it safer for a wider release. We’ve also conducted <a href="https://goo.gle/GeminiPaper" rt-link-type="external">novel research on safety risks</a> and developed red-teaming techniques to test for a range of potential harms.</p><p data-block-key="2pmdm">In advance of releasing 1.5 Pro, we've taken the same approach to responsible deployment as we did for our Gemini 1.0 models, <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">conducting extensive evaluations</a> across areas including content safety and representational harms, and will continue to expand this testing. Beyond this, we’re developing further tests that account for the novel long-context capabilities of 1.5 Pro.</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Build and experiment with Gemini models</h2><p data-block-key="94van">We’re committed to bringing each new generation of Gemini models to billions of people, developers and enterprises around the world responsibly.</p><p data-block-key="9uot9">Starting today, we’re offering a limited preview of 1.5 Pro to developers and enterprise customers via <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a>. Read more about this on our <a href="https://developers.googleblog.com/2024/02/gemini-15-available-for-private-preview-in-google-ai-studio.html" rt-link-type="external">Google for Developers blog</a> and <a href="https://cloud.google.com/blog/products/ai-machine-learning/gemini-on-vertex-ai-expands" rt-link-type="external">Google Cloud blog</a>.</p><p data-block-key="55ddh">We’ll introduce 1.5 Pro with a standard 128,000 token context window when the model is ready for a wider release. Coming soon, we plan to introduce pricing tiers that start at the standard 128,000 context window and scale up to 1 million tokens, as we improve the model.</p><p data-block-key="3h3jn">Early testers can try the 1 million token context window at no cost during the testing period, though they should expect longer latency times with this experimental feature. Significant improvements in speed are also on the horizon.</p><p data-block-key="e52dh">Developers interested in testing 1.5 Pro can <a href="https://aistudio.google.com/app/waitlist/97445851" rt-link-type="external">sign up now</a> in AI Studio, while enterprise customers can reach out to their Vertex AI account team.</p><p data-block-key="bpauc">Learn more about <a href="https://deepmind.google/technologies/gemini" rt-link-type="external">Gemini’s capabilities and see how it works</a>.</p></div>
  

  
    

  
    






<div role="form" aria-label="Sign up to receive weekly news and stories from Google." data-component="uni-subscribe" data-analytics-module="{
    &quot;module_name&quot;: &quot;Newsletter&quot;,
    &quot;section_header&quot;: &quot;Get more stories from Google in your inbox.&quot;
  }">
        
        
        <p>You are already subscribed to our newsletter.</p>
      </div>

  

  


            
            

            
              




            
          </div>
        
      </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Observable 2.0, a static site generator for data apps (478 pts)]]></title>
            <link>https://observablehq.com/blog/observable-2-0</link>
            <guid>39383386</guid>
            <pubDate>Thu, 15 Feb 2024 14:57:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://observablehq.com/blog/observable-2-0">https://observablehq.com/blog/observable-2-0</a>, See on <a href="https://news.ycombinator.com/item?id=39383386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we’re launching <a href="https://observablehq.com/product">Observable 2.0</a> with a bold new vision: an open-source static site generator for building fast, beautiful data apps, dashboards, and reports.</p><p>Our mission is to help teams communicate more effectively with data. Effective presentation of data is critical for deep insight, nuanced understanding, and informed decisions. Observable notebooks are great for ephemeral, <i>ad hoc</i> data exploration. But notebooks aren’t well-suited for polished dashboards and apps.</p><p>Enter <a href="https://observablehq.com/framework/">Observable Framework</a>.</p><div><figure><img src="https://images.ctfassets.net/uklh5xrq1p2j/26cJydaf6IQXGPmS7i13Gr/d4db342f8088003c3a4f004c13990940/1_-_Framework_Preview__1_.png" alt="Framework preview"></figure></div><p>With Framework, you can build the best data apps your team has ever seen. Framework combines the power of <b>JavaScript on the front-end</b> for interactive graphics, with <b>any language on the back-end</b> for data preparation and analysis. SQL, Python, R, Rust, Go… you name it. It’s the polyglot programmer’s dream. Everything you need is at your fingertips: interactive charts and inputs, responsive grids, themes, dark mode, keyboard-friendly navigation, and more. And because it’s code, there’s no limit to customization!</p><p>Framework is free and <a href="https://github.com/observablehq/framework">open-source</a>. Projects are just local files. Use your favorite editor, preview locally, check it all into git, write unit tests, add CI/CD, even work offline. You can host projects anywhere or deploy instantly to Observable to share them securely with your team.</p><p>Observable Framework solves the “last mile” problem of data apps: loading data. Conventional dashboards are slow because they run queries on view while the user waits; Framework’s data loaders run <i>on build</i> so that pages load instantly. And because data loaders run on your servers, you control privacy and security.
If you’re ready to dive in, visit our <a href="https://observablehq.com/framework/getting-started">Getting started tutorial</a>, or open a terminal and run:
</p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;npm init @observablehq</span>
</p><p>If you’d like to hear more about why we built Framework, please read on.</p><h3>Beyond notebooks <b>📓</b></h3><p>This moment — Observable 2.0 — reflects lessons learned over many years.</p><p>We believe the lightweight, collaborative nature of computational notebooks makes them ideal for exploring data and answering <i>ad hoc</i> questions. We founded Observable in 2016, pioneering a <a href="https://medium.com/@mbostock/a-better-way-to-code-2b1d2876a3a0">reactive, web-first approach</a> to notebooks and seeking to make data visualization easier, more practicable, and more social. We dreamed that notebooks might be the “one ring to rule them all” — powering not just notes, but apps, dashboards, and reports.</p><p>Yet no single interface can excel at every task. As cool as reactive notebooks are, a notebook can’t compete with a custom web app in terms of user experience. Notebooks are constrained by:</p><ul><li><p>A single-column, narrow layout</p></li><li><p>Low visual information density</p></li><li><p>Always-visible editor chrome</p></li></ul><p>These same limitations make notebooks great for tinkering and learning — the code is always at your fingertips, adjacent to the output — but not so great for presentation. To fill that latter role, we need better data apps.</p><p>A good data app embodies an empirical perspective; it fosters a shared understanding. Whereas notebooks tend to be for individuals, data apps are more often for a team. And whereas notebooks tend to be transient byproducts of point-in-time exploration, data apps often sustain value over time as people return to see how things change.</p><p>The differences between notebooks and data apps extend to development. A notebook editor desires speed: jotting down thoughts, running a query, sketching a chart. A data app developer prioritizes correctness, performance, and maintainability: making careful, deliberate changes that others depend on, favoring code review and testing before publishing.</p><p>We had three goals in mind when we set out to reimagine data app development:</p><ol><li><p><b>A better developer workflow</b> — meeting the needs of developers</p></li><li><p><b>A better user experience</b> — the “proof is in the pudding”</p></li><li><p><b>A better data architecture</b> — solving the “last mile” problem</p></li></ol><div><figure><img src="https://images.ctfassets.net/uklh5xrq1p2j/5D9MHFW8goDgB7Fuczy9s4/28dec57555f601daaaee374d2d2c5347/2_-_Workflow.png" alt="Workflow"></figure></div><h3>A better developer workflow <b>👩‍💻</b></h3><p>Modern development is built on <a href="https://stephango.com/file-over-app">files</a>. Files have myriad strengths, but the strongest is interoperability. When every tool uses files, it’s far easier to incorporate a new tool — and now Observable — into your workflow.</p><p>This isn’t just about using your preferred text editor. Now you can bring your own source control and code review system, too. You can write unit tests and run linters. You can automate builds with continuous integration or deployment. You can work offline. You can self-host. You can generate or edit content programmatically, say to format code or to find-and-replace across files.</p><p>As we break new ground with Observable Framework, we’re further improving interoperability by adopting vanilla JavaScript syntax. And we’re deprecating <span>require</span> in favor of modern ES <span>import</span>. These changes make Observable easier to learn, and to share code with other applications. (We’ll port these improvements back to Observable notebooks in the future.)</p><div><figure><a href="https://github.com/observablehq/framework/tree/main/examples"><img src="https://images.ctfassets.net/uklh5xrq1p2j/7EKYLd7vJn0TRcBoQZWRvV/d4976632216f1e072746e4910d827cc1/3_-_Examples.png" alt="Examples"></a><figcaption></figcaption></figure></div><h3><b>A better user experience 😍</b></h3><p>A toolmaker can’t care only about the developer experience — what does the developer experience matter if the resulting app is not demonstrably better? The merit of a creative tool should be judged by the quality of its creations, not its process. Or: “the proof of the pudding is in the eating.”</p><p>We believe that well-designed tools help developers build more efficiently by focusing their efforts on high-value work. We favor opinionated tools, with defaults and conveniences that foster a good user experience. We nudge you into <a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/">the pit of success</a>.</p><p>Framework’s lightweight Markdown syntax — with light and dark mode, thoughtful colors, responsive grids, and built-in navigation — gives you beautiful pages from the start. It’s highly customizable if you need it, but it’s quick to get started with batteries included.</p><p>Most importantly, Framework’s data architecture practically forces your app to be <i>fast</i> because data is precomputed. Performance is critical for dashboards: users don’t like to wait, and dashboards only create value if users look at them. Slow dashboards waste time. (And you certainly don’t want your database and dashboard falling over under load!)</p><div><figure><img src="https://images.ctfassets.net/uklh5xrq1p2j/6ATQajSu9ZLRVmgR0YIiYs/12f2da04080e37ef88f82f001c566107/4_-_Architecture.png" alt="Architecture"></figure></div><h3>A better data architecture</h3><p>Every data visualization requires data. Obviously. But less obviously, each data visualization requires highly-specific data prepared with that visualization in mind. In fact, most of the work of visualization isn’t choosing visual encodings or laying out axes or visualizing <i>per se</i> — it’s preparing data. As I wrote <a href="https://observablehq.com/@mbostock/10-years-of-open-source-visualization">previously</a>,</p><div><figure><blockquote><p>working with data should be 80% of the work of visualization. Visualization is the end result of analysis — the visible manifestation of data, to be seen, shared, and appreciated by experts and non-experts alike — and as such it sometimes gets too much credit. To produce a visualization, one must first find data, clean it, transform, join, model, etc. Working with data is sometimes needlessly denigrated as “janitorial” when it represents the critical step of understanding the data as it is, warts and all.</p></blockquote></figure></div><p>Given how much work goes into preparing data, it follows that developers want</p><ul><li><p>to use any language (say Python or R or SQL),</p></li><li><p>to use any library (say NumPy or dplyr),</p></li><li><p>to use any data source (database, data warehouse, API, files, <i>etc</i>.), and</p></li><li><p>to crunch data ahead of time (offline)</p></li></ul><p>while still leveraging JavaScript in the browser for interactive graphics.</p><p>Framework’s data loaders solve this “last mile” problem by computing static data snapshots at build time. These snapshots can be highly-optimized (and aggregated and anonymized), minimizing the data you send to the client. And since a data loader is just a fancy way of generating a file on-demand (with clever caching and routing), loaders can be written in any language and use any library. This flexibility is not unlike <a href="https://en.wikipedia.org/wiki/Common_Gateway_Interface">CGI</a> from 30 years ago, and <a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)">Unix pipes</a>. And since data loaders run on your servers, viewers don’t need direct access to the underlying data sources, and your dashboards are more secure and robust.</p><p>The speed of modern data warehouses is astonishing. But far too often something is missing for new analysis — some untapped data source, some not-yet-materialized view for a query to run at interactive speeds. Framework’s data loaders let you bypass these hurdles and produce a fast dashboard without “heavy lifting” in your data warehouse. And once your analysis demonstrates value, you can shift work to your data warehouse and simplify your data loaders. Framework lets you build faster and quickly validate your ideas.</p><p>We believe Framework will change how you think about data, and effect a better user experience. And by securely hosting apps alongside notebooks, Observable now offers an end-to-end solution for data analysis and presentation.</p><h3>Thank you <b>🙏</b></h3><p>We wouldn’t be here without the support, feedback, and encouragement from you — our community. Thank you for using Observable notebooks, Observable Plot, and D3. We’re thrilled to share Observable Framework with you now, and can’t wait to hear what you think.</p><p>To learn more about Framework, <a href="https://observablehq.com/framework/">read the docs</a>.</p><p>To share your questions or feedback, please <a href="https://talk.observablehq.com/latest">visit our forum</a>.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I got scammed out of $50k (101 pts)]]></title>
            <link>https://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html</link>
            <guid>39382981</guid>
            <pubDate>Thu, 15 Feb 2024 14:19:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html">https://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html</a>, See on <a href="https://news.ycombinator.com/item?id=39382981">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="www.thecut.com/_components/article/instances/cls9hkvh6000k0ifm6jiftoxi@published" data-content-channel="Career &amp; Money" data-crosspost="" data-type="Vertical Enterprise" data-syndication="original" data-headline="The Day I Put $50,000 in a Shoe Box and Handed It to a Stranger" data-authors="Charlotte Cowles" data-publish-date="2024-02-15" data-tags="style, fashion, spring fashion, spring 2024 fashion issue, best of the cut, new york magazine, remove interruptions, scams, money, personal finance, self, first person, audio article" data-issue-date="2024-02-12" data-components-count="91" data-canonical-url="http://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html">
    


  
  
  
  <header>
    <div>
          <h2 data-editable="overrideHeadline">The Day I Put $50,000 in a Shoe Box and Handed It to a Stranger</h2>
            <h2 data-editable="displayTeaser">I never thought I was the kind of person to fall for a scam.</h2>
            

            <p><span>
                  <a href="https://www.thecut.com/author/charlotte-cowles/" rel="author">
                    <img src="https://pyxis.nymag.com/v1/imgs/a2e/291/896a7f58b1dd99a9677575f693b0c399a5-charlotte-cowles.2x.rsquare.w168.jpg" alt="Portrait of Charlotte Cowles">
                  </a>
                </span>
            <span data-editable="bylines">
            <p><span>By</span> <span>
        ,
          <span>the Cut’s financial-advice columnist.</span><span>&nbsp;</span>
          <span>In addition to “My Two Cents,” she writes about work and parenting for the site. Previously, she was the senior features editor at Harper's Bazaar and a senior editor at the Cut. She was also the editorial director for MM.LaFleur. Her work has also been published in Glamour, Art in America, Politico, and other places.</span>
      </span></p>

              </span>
          </p>
        </div>
      <div data-editable="lede">
          <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg" width="570" height="712"> <img src="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" data-content-img="" width="570" height="712" fetchpriority="high"> </picture>
          </div>
        <p><span>Illustration: Nicole Rifkin</span>
        </p>
  </header>
  <section>
    <div data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg" width="570" height="712"> <img src="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" data-content-img="" width="570" height="712" fetchpriority="high"> </picture>
          </div>
            <div>
              <p><span>Illustration: Nicole Rifkin</span>
              </p>
            </div>
              </div>
        

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/cls9hkvh6000i0ifmigzoeac8@published" data-word-count="52">On a Tuesday evening this past October, I put $50,000 in cash in a shoe box, taped it shut as instructed, and carried it to the sidewalk in front of my apartment, my phone clasped to my ear. “Don’t let anyone hurt me,” I told the man on the line, feeling pathetic.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600343b7yhj2gog97@published" data-word-count="13">“You won’t be hurt,” he answered. “Just keep doing exactly as I say.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600353b7y3k8a1sbw@published" data-word-count="46">Three minutes later, a white Mercedes SUV pulled up to the curb. “The back window will open,” said the man on the phone. “Do not look at the driver or talk to him. Put the box through the window, say ‘thank you,’ and go back inside.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600363b7yegwwp80f@published" data-word-count="83">The man on the phone knew my home address, my Social Security number, the names of my family members, and that my 2-year-old son was playing in our living room. He told me my home was being watched, my laptop had been hacked, and we were in imminent danger. “I can help you, but only if you cooperate,” he said. His first orders: I could not tell anyone about our conversation, not even my spouse, or talk to the police or a lawyer.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600373b7yfjnsrlka@published" data-word-count="90">Now I know this was all a scam — a cruel and violating one but painfully obvious in retrospect. Here’s what I can’t figure out: Why didn’t I just hang up and call 911? Why didn’t I text my husband, or my brother (a lawyer), or my best friend (also a lawyer), or my parents, or one of the many other people who would have helped me? Why did I hand over all that money — the contents of my savings account, strictly for emergencies — without a bigger fight?</p>

  <section data-uri="www.thecut.com/_components/package-table-of-contents/instances/clsm5tjmv008a3b7yyxnsuna1@published" data-editable="settings">
  

  <div>
    
      <p><a href="https://www.thecut.com/tags/spring-2024-fashion-issue/">
          <img src="https://pyxis.nymag.com/v1/imgs/72f/fc2/f5515b8e4e53c4a19503e81e27dcddd54b-0424CUTCov-4x5-moore-rev.2x.rvertical.w330.jpg" alt="package-table-of-contents-photo">
        </a>
      </p>
  </div>


    
  
  <span>
    <a href="https://www.thecut.com/tags/spring-2024-fashion-issue/">See All</a>&nbsp;
    <!--?xml version="1.0" encoding="utf-8"?-->
<!-- Generator: Adobe Illustrator 26.5.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 11 11" style="enable-background:new 0 0 11 11;" xml:space="preserve">

<path d="M5.1,11l3-5.6L5.1,0L11,5.4L5.1,11z"></path>
<path d="M0,11l3-5.6L0,0l5.9,5.4L0,11z"></path>
</svg>

  </span>
</section>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq700383b7yfe719uee@published" data-word-count="100">When I’ve told people this story, most of them say the same thing: You don’t seem like the type of person this would happen to. What they mean is that I’m not senile, or hysterical, or a rube. But these stereotypes are actually false. Younger adults — Gen Z, millennials, and Gen X — are 34 percent <em>more</em> likely to report losing money to fraud compared with those over 60, according to a recent report from the Federal Trade Commission. Another study found that well-educated people or those with good jobs were just as vulnerable to scams as everyone else.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq700393b7yu0ezqflh@published" data-word-count="88">Still, how could I have been such easy prey? Scam victims tend to be single, lonely, and economically insecure with low financial literacy. I am none of those things. I’m closer to the opposite. I’m a journalist who had a weekly column in the “Business” section of the New York <em>Times.</em> I’ve written a personal-finance column for this magazine for the past seven years. I interview money experts all the time and take their advice seriously. I’m married and talk to my friends, family, and colleagues every day.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq7003a3b7ywx18621n@published" data-word-count="88">And while this is harder to quantify — how do I even put it? — I’m not someone who loses her head. My mother-in-law has described me as even-keeled; my own mom has called me “maddeningly rational.” I am listed as an emergency contact for several friends — and their kids. I vote, floss, cook, and exercise. In other words, I’m not a person who panics under pressure and falls for a conspiracy involving drug smuggling, money laundering, and CIA officers at my door. Until, suddenly, I was.</p>

  

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003c3b7y102y9bcg@published" data-word-count="86">That morning — it was October 31 — I dressed my toddler in a pizza costume for Halloween and kissed him good-bye before school. I wrote some work emails. At about 12:30 p.m., my phone buzzed. The caller ID said it was Amazon. I answered. A polite woman with a vague accent told me she was calling from Amazon customer service to check some unusual activity on my account. The call was being recorded for quality assurance. Had I recently spent $8,000 on MacBooks and iPads?</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003d3b7yif1zqfle@published" data-word-count="54">I had not. I checked my Amazon account. My order history showed diapers and groceries, no iPads. The woman, who said her name was Krista, told me the purchases had been made under my business account. “I don’t have a business account,” I said. “Hmm,” she said. “Our system shows that you have two.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003e3b7yq1vyhvc2@published" data-word-count="55">Krista and I concurred that I was the victim of identity theft, and she said she would flag the fraudulent accounts and freeze their activity. She provided me with a case-ID number for future reference and recommended that I check my credit cards. I did, and everything looked normal. I thanked her for her help.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003f3b7ytfg2ultv@published" data-word-count="48">Then Krista explained that Amazon had been having a lot of problems with identity theft and false accounts lately. It had become so pervasive that the company was working with a liaison at the Federal Trade Commission and was referring defrauded customers to him. Could she connect me?</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003g3b7yzsqivi3g@published" data-word-count="4">“Um, sure?” I said.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003h3b7y84fa7z0i@published" data-word-count="105">Krista transferred the call to a man who identified himself as Calvin Mitchell. He said he was an investigator with the FTC, gave me his badge number, and had me write down his direct phone line in case I needed to contact him again. He also told me our call was being recorded. He asked me to verify the spelling of my name. Then he read me the last four digits of my Social Security number, my home address, and my date of birth to confirm that they were correct. The fact that he had my Social Security number threw me. I was getting nervous.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003i3b7y86hkgepm@published" data-word-count="27">“I’m glad we’re speaking,” said Calvin. “Your personal information is linked to a case that we’ve been working on for a while now, and it’s quite serious.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003j3b7yhwz59x0m@published" data-word-count="169">He told me that 22 bank accounts, nine vehicles, and four properties were registered to my name. The bank accounts had wired more than $3 million overseas, mostly to Jamaica and Iraq. Did I know anything about this? “No,” I said. Did I know someone named Stella Suk-Yee Kwong? “I don’t think so,” I said. He texted me a photo of her ID, which he claimed had been found in a car rented under my name that was abandoned on the southern border of Texas with blood and drugs in the trunk. A home in New Mexico affiliated with the car rental had subsequently been raided, he added, and authorities found more drugs, cash, and bank statements registered to my name and Social Security number. He texted me a drug-bust photo of bags of pills and money stacked on a table. He told me that there were warrants out for my arrest in Maryland and Texas and that I was being charged with cybercrimes, money laundering, and drug trafficking.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqa003k3b7y6c7g49zr@published" data-word-count="54">My head swam. I Googled my name along with “warrant” and “money laundering,” but nothing came up. Were arrest warrants public? I wasn’t sure. Google led me to truthfinder.com, which asked for my credit-card information — nope. “I’m in deep shit,” I texted my husband. “My identity was stolen and it seems really bad.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003l3b7yadezzz8j@published" data-word-count="66">Calvin wanted to know if I knew anyone who might be the culprit or if I had any connections to Iraq or Jamaica. “No,” I said. “This is the first I’m hearing about any of this, and it’s a lot to take in.” He asked if I had ever used public or unsecured Wi-Fi. “I don’t know. Maybe?” I said. “I used the airport Wi-Fi recently.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003m3b7yhdb1b9vd@published" data-word-count="37">“Ah,” he said. “That’s unfortunate. It’s how many of these breaches start.” I was embarrassed, like I’d left my fly unzipped. How could I have been so thoughtless? But also — didn’t everyone use the airport Wi-Fi?</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003n3b7yhcfbg1z2@published" data-word-count="26">Calvin told me to listen carefully. “The first thing you must do is not tell anyone what is going on. Everyone around you is a suspect.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003o3b7ykt9gabaz@published" data-word-count="97">I almost laughed. I told him I was quite sure that my husband, who works for an affordable-housing nonprofit and makes meticulous spreadsheets for our child-care expenses, was not a secret drug smuggler. “I believe you, but even so, your communications are probably under surveillance,” Calvin said. “You cannot talk to him about this.” I quickly deleted the text messages I had sent my husband a few minutes earlier. “These are sophisticated criminals with a lot of money at stake,” he continued. “You should assume you are in danger and being watched. You cannot take any chances.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqc003p3b7y7ajyixfd@published" data-word-count="130">I felt suspended between two worlds — the one I knew and the one this man was describing. If I had nothing to do with any of these allegations, how much could they truly affect me? I thought of an old <em>This American Life </em>episode about a woman whose Social Security card was stolen. No matter how many times she closed her bank accounts and opened new ones, her identity thief kept draining them, destroying her credit and her sanity. (It turned out to be her boyfriend.) I remembered another story about a man who got stuck on a no-fly list after his personal information was used by a terrorist group. It dawned on me that being connected to major federal offenses, even falsely, could really fuck up my life.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqd003q3b7ys5ku7xfp@published" data-word-count="71">Calvin wanted to know how much money I currently had in my bank accounts. I told him that I had two — checking and savings — with a combined balance of a little over $80,000. As a freelancer in a volatile industry, I keep a sizable emergency fund, and I also set aside cash to pay my taxes at the end of the year, since they aren’t withheld from my paychecks.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqd003r3b7ypzo0jor6@published" data-word-count="92">His voice took on a more urgent tone. “You must have worked very hard to save all that money,” he said. “Do not share your bank-account information with anyone. I am going to help you keep your money safe.” He said that he would transfer me to his colleague at the CIA who was the lead investigator on my case and gave me a nine-digit case number for my records. (I Googled the number. Nothing.) He said the CIA agent would tell me what to do next, and he wished me luck.</p>

  

  <div data-uri="www.thecut.com/_components/image/instances/clsm5q4ef007n3b7ywzbg2pix@published" data-editable="settings">
    
    <p><span>Illustration: Nicole Rifkin</span>
    </p>
</div>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqe003t3b7yi1li3dza@published" data-word-count="70">If it was a scam<strong><em>,</em></strong> I couldn’t see the angle. It had occurred to me that the whole story might be made up or an elaborate mistake. But no one had asked me for money or told me to buy crypto; they’d only encouraged me <em>not</em> to share my banking information. They hadn’t asked for my personal details; they already knew them. I hadn’t been told to click on anything.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqe003u3b7yddqewies@published" data-word-count="104">Still, I had not seen a shred of evidence. I checked my bank accounts, credit cards, and credit score; nothing looked out of the ordinary. I knew I should probably talk to a lawyer or maybe call the police, though I was doubtful that they would help. What was I going to say — “My identity was stolen, and I think I’m somehow in danger”? I had no proof. I was also annoyed that my workday had been hijacked. It was 2 p.m., and I had already pushed back one deadline and postponed two work calls. I had to get myself out of this.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqe003v3b7yrnt1flog@published" data-word-count="72">The next man who got on the line had a deeper voice and a slight British accent flecked with something I couldn’t identify. He told me his name was Michael Sarano and that he worked for the CIA on cases involving the FTC. He gave me his badge number. “I’m going to need more than that,” I said. “I have no reason to believe that any of what you’re saying is real.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003w3b7y2hsfkucg@published" data-word-count="65">“I completely understand,” he said calmly. He told me to go to the FTC home page and look up the main phone number. “Now hang up the phone, and I will call you from that number right now.” I did as he said. The FTC number flashed on my screen, and I picked up. “How do I know you’re not just spoofing this?” I asked.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003x3b7yl86nymmn@published" data-word-count="65">“It’s a government number,” he said, almost indignant. “It cannot be spoofed.” I wasn’t sure if this was true and tried Googling it, but Michael was already onto his next point. He told me the call was being recorded, so I put him on speaker and began recording on my end, too. He wanted to know if I had told anyone what was going on.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003y3b7yhyvkjcqy@published" data-word-count="56">I admitted that I had texted my husband. “You must reassure him that everything is fine,” Michael said. “In many cases like this, we have to investigate the spouse as well, and the less he knows, the less he is implicated. From now on, you have to follow protocol if you want us to help you.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003z3b7y723ufrvh@published" data-word-count="13">“I don’t think I should lie to my husband,” I said, feeling stupid.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf00403b7yn23en1za@published" data-word-count="46">“You are being investigated for major federal crimes,” he said. “By keeping your husband out of this, you are <em>protecting </em>him.” He then repeated the point Calvin had made about my phone and computer being hacked and monitored by the criminals who had stolen my identity.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00413b7y8sah3cnt@published" data-word-count="32">By that point, my husband had sent me a series of concerned texts. “Don’t worry. It will be okay,” I wrote back. It felt gross to imagine a third party reading along.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00423b7y76ckd0r4@published" data-word-count="89">Michael snowed me with the same stories Calvin had. They were consistent: the car on the Texas border, the property in New Mexico, the drugs, the bank accounts. He asked if I shared my residence with anyone besides my husband and son. Then he asked more questions about my family members, including my parents, my brother, and my sister-in-law. He knew their names and where they lived. I told him they had nothing to do with this. In fact, I was now sure I wanted to consult a lawyer.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00433b7yp9kd3bvx@published" data-word-count="62">“If you talk to an attorney, I cannot help you anymore,” Michael said sternly. “You will be considered noncooperative. Your home will be raided, and your assets will be seized. You may be arrested. It’s your choice.” This seemed ludicrous. I pictured officers tramping in, taking my laptop, going through our bookshelves, questioning our neighbors, scaring my son. It was a nonstarter.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00443b7ykbykct9w@published" data-word-count="27">“Can I just come to your office and sort this out in person?” I said. “It’s getting late, and I need to take my son trick-or-treating soon.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00453b7y45u3ulxn@published" data-word-count="44">“My office is in Langley,” he said. “We don’t have enough time. We need to act immediately. I’m going to talk you through the process. It’s going to sound crazy, but we must follow protocol if we’re going to catch the people behind this.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00463b7yf3zwjmo1@published" data-word-count="98">He explained that the CIA would need to freeze all the assets in my name, including my actual bank accounts. In the eyes of the law, there was no difference between the “real” and the fraudulent ones, he said. They would also deactivate my compromised Social Security number and get me a new one. Then, by monitoring any activity under my old Social Security number and accounts, they would catch the criminals who were using my identity and I would get my life back. But until then, I would need to use only cash for my day-to-day expenses.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh00473b7ye8s8a9cv@published" data-word-count="22">It was far-fetched. Ridiculous. But also not completely out of the realm of possibility. “Do I have any other options?” I asked.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh00483b7ym4f7nzng@published" data-word-count="17">“Unfortunately, no,” he said. “You must follow my directions very carefully. We do not have much time.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh00493b7yfw5vsv3v@published" data-word-count="93">He asked me how much cash I thought I would need to support myself for a year if necessary. My assets could be frozen for up to two years if the investigation dragged on, he added. There could be a trial; I might need to testify. These things take time. “I don’t know, $50,000?” I said. I wondered how I would receive paychecks without a bank account. Would I have to take time off from work? I did some mental calculations of how much my husband could float us and for how long.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh004a3b7yijy19l69@published" data-word-count="40">“Okay,” he said. “You need to go to the bank and get that cash out now. You cannot tell them what it is for. In one of my last cases, the identity thief was someone who worked at the bank.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004b3b7yzb2xsoca@published" data-word-count="64">Michael told me to keep the phone on speaker so we would remain in contact. “It’s important that I monitor where this money goes from now on. Remember, all of your assets are part of this investigation,” he said. Then he told me that one of his colleagues would meet me at my apartment at 5 p.m. to guide me through the next steps.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004c3b7yrupgha8w@published" data-word-count="20">“You can’t send a complete stranger to my home,” I said, my voice rising. “My 2-year-old son will be here.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004d3b7y7g21n626@published" data-word-count="24">“Let me worry about that,” he said. “It’s my job. But if you don’t cooperate, I cannot keep you safe. It is your choice.”</p>

  

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004f3b7y4vno8t8h@published" data-word-count="55">It’s impossible to explain why I accepted this logic. But I had been given marching orders and a deadline. My son would be home soon, and I had to fix this mess. I put on sneakers in case I needed to run. I brought a backpack for the cash. I felt both terrified and absurd.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004g3b7yrshp1wcp@published" data-word-count="66">It was jarring to see trick-or-treaters in my Brooklyn neighborhood, people going about their lives. The air was crisp, and dead leaves swirled on the ground. I was on high alert for anyone who might be following me. At one point, a man in sunglasses and a hoodie trailed me for a few blocks. At Michael’s suggestion, I ducked into a parking garage until he passed.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004h3b7yoikaw79j@published" data-word-count="92">When I reached the bank, I told the guard I needed to make a large cash withdrawal and she sent me upstairs. Michael was on speakerphone in my pocket. I asked the teller for $50,000. The woman behind the thick glass window raised her eyebrows, disappeared into a back room, came back with a large metal box of $100 bills, and counted them out with a machine. Then she pushed the stacks of bills through the slot along with a sheet of paper warning me against scams. I thanked her and left.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004i3b7ymftctv9l@published" data-word-count="67">Michael was bursting with praise. “You did a great job,” he said. “I have to go for a moment to see about the details of your case; I’m going to have you speak to my colleague if you have any questions.” He put a woman on the line. She was younger, with an accent I couldn’t identify. She told me to go home and await further instructions.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004j3b7yqresl85o@published" data-word-count="67">As I walked back to my apartment, something jolted me out of my trance, and I became furious. No government agency would establish this as “protocol.” It was preposterous. “I need to speak with Michael,” I told the woman on the phone. He got on right away. “I don’t even believe that you’re a CIA agent,” I said. “What you’re asking me to do is completely unreasonable.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004k3b7yq269p2md@published" data-word-count="56">He sighed. “I’m sending you a photo of my badge right now,” he said. “I don’t know what else to tell you. You can trust me, and I will help you. Or you can hang up and put yourself and your family in danger. Do you really want to take that risk with a young child?”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004l3b7y2dko06mh@published" data-word-count="73">I waited for a stoplight at a busy intersection. I could see my apartment window from where I stood. My son was playing inside with a neighbor’s daughter and their nanny. A picture of Michael’s badge appeared on my phone. I had no way of verifying it; it could easily have been Photoshopped. “I don’t trust you at all,” I said to Michael. “But it doesn’t seem like I have any other choice.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqk004m3b7yvxhoxilj@published" data-word-count="92">When I got home, Michael told me to get a box, put the cash in it, take a picture of it, then tape it shut. I found a floral-printed shoe box that had once contained a pair of slippers I’d bought for myself — a frivolous purchase that now seemed mortifying. Michael told me to label it with my name, my case number, my address, a locker number he read to me, and my signature. Then he directed me to take another picture of the labeled box and text it to him.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqk004n3b7ytb8vhmdk@published" data-word-count="101">“My colleague will be there soon. He is an undercover CIA agent, and he will secure the money for you,” he said. What exactly would that entail? I asked. “Tonight, we will close down your Social Security number, and you will lose access to your bank accounts,” he explained. “Tomorrow, you’ll need to go to the Social Security office and get a new Social Security number. We’ll secure this money for you in a government locker and hand-deliver a Treasury check for the same amount. You can cash the check and use it for your expenses until the investigation is over.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004o3b7y9t8l4o3m@published" data-word-count="21">“Why can’t I just use this cash?” I asked. “Why do you have to take it and give me a check?”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004p3b7ype733hsn@published" data-word-count="47">“Because all of your assets under your current identity are part of the investigation,” he said. “You are being charged with money laundering. If we secure this cash and then issue you a government check under your new Social Security number, that will be considered clean money.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004q3b7ygfsusup4@published" data-word-count="24">“I’ll need to see your colleague’s badge,” I said. “I’m not just going to give $50,000 of my money to someone I don’t know.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004r3b7y2rr34nol@published" data-word-count="37">“Undercover agents don’t carry badges,” he said, as if I’d asked the CIA to bring me a Happy Meal. “They’re undercover. Remember, you are probably being watched. The criminals cannot know that a CIA agent is there.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004s3b7yuxp9bqgz@published" data-word-count="116">In a twisted way, this made some amount of sense to me. Or maybe I had lost my grip on reality so completely that I was willing to resign myself to this new version of it. Most important, I didn’t know what else to do. Even if Michael wasn’t working for the CIA (which struck me as more and more likely), he was sending a man to our address. I felt a sickening dread that he might ask to come inside. If giving him this money would make him go away, I was ready to do it. I’d been on the phone for nearly five hours. I wanted to take my son trick-or-treating. I was exhausted.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqm004t3b7ytyfonk7i@published" data-word-count="104">Michael seemed to sense that I was flagging and asked if I’d had lunch. I hadn’t. He told me to eat something but keep him on the line; his agent was on the way to my address but running late. “You can meet him outside if that would make you more comfortable,” Michael said, and I felt relieved. While I gnawed on a granola bar at my desk, he got chatty and asked about my job. I told him I was going to Washington, D.C., later that week. “Oh, great. You could come to my office in Langley,” he said. “Where are you staying?”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqm004u3b7yce6w8hea@published" data-word-count="86">A little after 6 p.m., Michael told me to go downstairs. His colleague was arriving. My husband had just come home from work and was reading to our son. “What’s going on? Is everything okay?” he asked as I put my coat on. I motioned to the phone and shushed him. Then I whispered, “I have to go downstairs and meet a guy who’s helping with the identity-theft case. I’ll explain more later.” He frowned and silently mouthed, “What?” I told him I had to go.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004v3b7yes2iy6q4@published" data-word-count="64">I met the SUV at the curb and put the money in the back seat. It was 6:06 p.m. Even if I’d tried to see who was driving, the windows were tinted and it was dusk. He maybe wore a baseball cap. When I turned around, I could see the backlit faces of my husband and son watching from our apartment nine stories above.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004w3b7y5o1uxhoy@published" data-word-count="83">As I walked back inside, Michael texted me a photo of a Treasury check made out to me for $50,000 and told me a hard copy would be hand-delivered to me in the morning. He was working on setting up my appointment with the Social Security office. “You will receive a confirmation text shortly,” he said. “Stay on the line until you do.” I felt oddly comforted by this. An appointment would give me something legitimate, an actual connection to a government agency.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004x3b7yqj9is4rf@published" data-word-count="83">I took my son trick-or-treating, my phone on speaker in my pocket. I felt numb, almost in a fugue state, smiling and chatting with my neighbors and their kids. At one point, I checked to see if Michael was still there; his female colleague answered and said he’d be back soon. Then, when we got home and I checked again, the line was dead. I panicked and called back. The woman answered. “Michael is busy,” she said. “He’ll call you in the morning.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004y3b7y6u0vk6dd@published" data-word-count="33">I was confused. Did this mean I didn’t have a Social Security number at all anymore? I pictured myself floating, identity-less. “Do I have an appointment at the Social Security office?” I asked.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqo004z3b7yvn61f93v@published" data-word-count="23">“Michael will call you tomorrow,” she repeated. “He hasn’t been able to secure your appointment yet. The Social Security office is closed now.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqo00503b7yc8awyvou@published" data-word-count="122">I went into my bedroom and shut the door, feeling my face grow hot. I had a physical sensation of scales falling from my eyes; the room shimmered around me, spots raining from the ceiling. I saw the whole day peel away, like the layers of an onion — Michael, the FTC officer, the Amazon call — revealing my real life, raw and exposed, at the center. “Oh my God,” I said, my hands tingling. “You are lying to me. Michael was lying. You just took my money and I’m never getting it back.” That wasn’t true, the woman said. She understood that I was upset. She was sorry. Everything would be fine. “You’re a fucking liar,” I hissed, and hung up.</p>

  

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqo00523b7yo9fzzz2y@published" data-word-count="104">Through choking sobs, I told my husband what had happened. “Why didn’t you tell me?” he asked, incredulous. “I would have stopped you.” That I’d been trying to protect him suddenly seemed so idiotic I couldn’t even say it out loud. Our son looked on, confused. “Mama’s sad,” he announced, clinging to my leg. We put him to bed and then I called my parents and my brother. At their urging, I called 911. Around 10:30 p.m., three police officers came over and took my statement. I struggled to recount what I’d done; it seemed like a bad dream. I felt like a fool.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00533b7yo7aj70ax@published" data-word-count="37">“No government agency will ever ask you for money,” one cop informed me, as if I’d never heard it before. I wanted to scream, “I <em>know.</em>” Instead, I said, “It didn’t really feel like he was asking.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00543b7yo0ykysz5@published" data-word-count="49">The police told me not to worry; the scammers wouldn’t be back. “They got what they wanted,” another officer said, as though it would reassure me. I gave them the photos and recordings I had. They promised to check traffic cameras for the car that had taken the money.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00553b7yqqlxr1h2@published" data-word-count="107">When I woke up the next morning, a few seconds passed before I remembered the previous day. I was my old self, in my old bed, milky dawn light on the walls. Then it all came crashing back, a fresh humiliation, and I curled into the fetal position. I felt violated, unreliable; I couldn’t trust myself. Were my tendencies toward people-pleasing, rule following, and conflict aversion far worse than I’d ever thought, even pathological? I imagined other people’s reactions. <em>She’s always been a little careless.</em> <em>She seems unhinged.</em> I considered keeping the whole thing a secret. I worried it would harm my professional reputation. I still do.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00563b7ykfck9oy6@published" data-word-count="171">In the days that followed, I kept revisiting the fake world of that afternoon, slipping through a portal into an alternate life. I would get paranoid that someone was reading my texts, watching me as I took my son to school, or using my Social Security number to wire money and rent cars. It was a relief that I wasn’t actually in trouble with the law, but then again — I’d lost $50,000 and I wasn’t getting it back. I checked my accounts and credit cards obsessively. I called my bank. They gave me instructions to freeze my credit, file reports with the FBI and FTC, and run anti-virus software on my laptop to check for malware, which I did. I cried a lot. My husband felt helpless; he still doesn’t like to talk about it. Instead, he researched new locks for our doors and looked into security cameras. One night I shook him awake, convinced that someone was trying to break in. “It’s only the wind,” he said. “We’re safe.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqq00573b7ybm56xl83@published" data-word-count="121">Fifty thousand dollars is a lot of money. It took me years to save, stashing away a few thousand every time I got paid for a big project. Part of it was money I had received from my grandfather, an inheritance he took great pains to set up for his grandchildren before his death. Sometimes I imagine how I would have spent it if I had to get rid of it in a day. I could have paid for over a year’s worth of child care up front. I could have put it toward the master’s degree I’ve always wanted. I could have housed multiple families for months. Perhaps, inadvertently, I am; I occasionally wonder what the scammers did with it.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqr00583b7ytma4vvdj@published" data-word-count="76">Because I had set it aside for emergencies and taxes, it was money I tried to pretend I didn’t have — it wasn’t for spending. Initially, I was afraid that I wouldn’t be able to afford my taxes this year, but then my accountant told me I could write off losses due to theft. So from a financial standpoint, I’ll survive, as long as I don’t have another emergency — a real one — anytime soon.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqr00593b7y74yx14d8@published" data-word-count="72">When I did tell friends what had happened, it seemed like everyone had a horror story. One friend’s dad, a criminal-defense attorney, had been scammed out of $1.2 million. Another person I know, a real-estate developer, was duped into wiring $450,000 to someone posing as one of his contractors. Someone else knew a Wall Street executive who had been conned into draining her 401(k) by some guy she met at a bar.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqr005a3b7yu08ktzpz@published" data-word-count="120">I felt a guilty sense of consolation whenever I heard about a scam involving someone I respected. If this could happen to them, maybe I wasn’t such a moron. As a journalist, it’s my instinct to research and talk to experts, so I dove into books and podcasts about scams, desperate to make sense of my own. I had known that fraud was on the rise but was shocked to learn the numbers — financial losses ballooned by more than 30 percent in 2022. I read that self-laceration is typical; half of victims blame themselves for being gullible, and most experience serious anxiety, depression, or other stress-related health problems afterward. I heard about victim support groups. I went to therapy.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqs005b3b7yaj2zdefi@published" data-word-count="59">When I discovered that Katie Gatti Tassin, a personal-finance expert who writes the popular <em>Money With Katie </em>newsletter, lost $8,000 five years ago to a grandmotherly-sounding woman pretending to call from Tassin’s credit union, I called her to ask how she’d coped. “Everyone was so patronizing,” she told me. “The response was basically ‘It’s your fault that this happened.’”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqs005c3b7yeyxbd5sh@published" data-word-count="75">If I had to pinpoint a moment that made me think my scammers were legitimate, it was probably when they read me my Social Security number. Now I know that all kinds of personal information — your email address, your kids’ names and birthdays, even your pets’ names — are commonly sold on the dark web. Of course, the scammers could also have learned about my son from a 30-second perusal of my Instagram feed.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqs005d3b7yi3kdpybt@published" data-word-count="194">It was my brother, the lawyer, who pointed out that what I had experienced sounded a lot like a coerced confession. “I read enough transcripts of bad interrogations in law school to understand that anyone can be convinced that they have a very narrow set of terrible options,” he said. When I posed this theory to Saul Kassin, a psychology professor at John Jay College of Criminal Justice who studies coerced confessions, he agreed. “If someone is trying to get you to be compliant, they do it incrementally, in a series of small steps that take you farther and farther from what you know to be true,” he said. “It’s not about breaking the will. They were altering the sense of reality.” And when you haven’t done anything wrong, the risk of cooperating feels minimal, he added. An innocent person thinks everything will get sorted out. It also mattered that I was kept on the phone for so long. People start to break down cognitively after a few hours of interrogation. “At that point, they’re not thinking straight. They feel the need to put an end to the situation at all costs,” Kassin said.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqu005e3b7y07dv8lkh@published" data-word-count="49">I wondered how often scammers are caught and about the guy who’d driven the car to my apartment. But when I asked experts, they doubted he’d be a meaningful lead. One pointed out that he might have been a courier who was told to come pick up a box.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqu005f3b7yoixur5gq@published" data-word-count="82">I still don’t believe that what happened to me could happen to anyone, but I’m starting to realize that I’m not uniquely fallible. Several friends felt strongly that if the scammers hadn’t mentioned my son, I would never have fallen for this. They’re right that I’d be willing to do — or pay — anything to protect him. Either way, I have to accept that someone waged psychological warfare on me, and I lost. For now, I just don’t answer my phone.</p>

  






  

  <section data-uri="www.thecut.com/_components/package-list/instances/cls9hxrti000l3b80029g93f4@published" data-track-type="article-list">
  
    <ul>
        <li data-track-type="article-link" data-track-component-name="package-list" data-track-page-uri="www.thecut.com/_pages/cls9i46y900000ik7rxitcouj@published" data-track-headline="Paloma Elsesser on the Price of Being ‘First’" data-track-index="0" data-track-component-title="">
          <span>
            <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

          </span>
          <a href="https://www.thecut.com/article/paloma-elsesser-model-of-the-year-essay.html">
            <span>
              Paloma Elsesser on the Price of Being ‘First’
            </span>
          </a>
        </li>
        <li data-track-type="article-link" data-track-component-name="package-list" data-track-page-uri="www.thecut.com/_pages/clsktvimz00000iipm0b8mvnn@published" data-track-headline="Would You Spend $860 on These Stretchy Pants?" data-track-index="1" data-track-component-title="">
          <span>
            <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

          </span>
          <a href="https://www.thecut.com/article/high-sport-kick-flare-pants-review.html">
            <span>
              Would You Spend $860 on These Stretchy Pants?
            </span>
          </a>
        </li>
        <li data-track-type="article-link" data-track-component-name="package-list" data-track-page-uri="www.thecut.com/_pages/clsks7xlk002l0ikmupy5xx6u@published" data-track-headline="The Lure of Divorce" data-track-index="2" data-track-component-title="">
          <span>
            <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

          </span>
          <a href="https://www.thecut.com/article/marriage-divorce-should-i-leave-my-husband-emily-gould.html">
            <span>
              The Lure of Divorce<!---->&nbsp;<span></span>
            </span>
          </a>
        </li>
    </ul>
      
      <a href="https://www.thecut.com/tags/spring-2024-fashion-issue" aria-label="See All from More From the spring 2024 fashion issue">
        <span>See All</span>
        <span>
          <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

        </span>
      </a>
</section>


    </div>

    


          



      <span>How I Got Scammed Out of $50,000</span>



  </section>
  
</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Nitter officially declared "over" today – alternatives? (208 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39382590</link>
            <guid>39382590</guid>
            <pubDate>Thu, 15 Feb 2024 13:45:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39382590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39389151"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39389151" href="https://news.ycombinator.com/vote?id=39389151&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I mostly have the same attitude to this as I do to sites with ridiculously aggressive cookie popups… I don’t need to see the content, I can just go for a walk in the sun instead.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39389179"><td></td></tr>
                  <tr id="39388989"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388989" href="https://news.ycombinator.com/vote?id=39388989&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Public-facing tweets are a huge part of Twitter's value proposition. Between this, removal of verification, and publish.twitter.com being broken, I wonder how many of the biggest outlets and organizations will continue to abide Twitter's decline.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383208"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383208" href="https://news.ycombinator.com/vote?id=39383208&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There's two distinct Nitter use cases I need to replace.<p>1. Someone drops a link to Twitter. Twitter hides threads and throws items in some weird non-chronological order—assuming I don't get a login wall. I need an unfucked UI.</p><p>2. There are some content I can't get anywhere else that I follow through RSS. I wish these people would move elsewhere, but if they haven't by now, they probably won't ever.</p><p>I may just run a local instance with an account created for the purpose if that remains viable, but associating all that with a single login/IP address is something I'd like to avoid.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389366"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389366" href="https://news.ycombinator.com/vote?id=39389366&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>1) Ask people to send screenshots of the tweets instead of links. I think this has naturally been happening a lot more over the years anyway and people will just get used to do that.<p>2) I guess those people will slowly realize they have lost most of their audience anyway.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389494"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39389494" href="https://news.ycombinator.com/vote?id=39389494&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Right? (#2), I can't be so far in the minority to just not be willing to bother with Twitter. There is really very little content that will compel me to have a bad time consuming it. Is it 1 out of 10? 2 out of 10? More? Even if it's just 10% that's still significant. Just my $0.02 of course.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39388549"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39388549" href="https://news.ycombinator.com/vote?id=39388549&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>In addition to a chronological feed, Nitter provided pagination and link de-obfuscation. Would be nice to get that back somehow.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383350"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383350" href="https://news.ycombinator.com/vote?id=39383350&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Right, all the "just don't use it" comments miss the point. I used Nitter specifically because I don't use twitter, so I could see the contents of a link that was being posted or discussed. I suppose a solution could be "ignore a large swath of posts and links and discussions" which is basically what I do, but sometimes it's nice to have the option to look at them. Same as if you don't use MS Word, someone might still occasionally send you a word document and it's nice to have a way to open it without having to install Word.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383398"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383398" href="https://news.ycombinator.com/vote?id=39383398&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>+1. Need something like archive.today/.is for Twitter so you can rip and archive the content that might not live elsewhere. Grab it, stick it in Wayback Machine, return a Wayback url.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383512"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383512" href="https://news.ycombinator.com/vote?id=39383512&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>+1 on Reddit as well.<p>Reddit doesn't have login walls yet but it has way too much information stored within their walls to not have a backup / non-social-media way of extracting it. It's infeasible to have Reddit blocked because it's UI is intended to be addictive like all social media but also be able to extract information from it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388801"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39388801" href="https://news.ycombinator.com/vote?id=39388801&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There are 18+ age walls that just force you to login, often in unnecessary places.<p>Plus mobile sometimes refuses to show some things.</p><p>old.reddit still works though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383542"><td></td></tr>
                <tr id="39389225"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39389225" href="https://news.ycombinator.com/vote?id=39389225&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>It’s dying a slow death through neglect. Image posts don’t work correctly, image comments don’t show up, and the dirent comment links generated from www don’t work on old</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39389533"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_39389533" href="https://news.ycombinator.com/vote?id=39389533&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Still better than logging in, using the new web app or downloading the app.<p>It's not like 95% of the content is any good anyway. You have to dig deep into a niche to really get any value, and the last few years, less and less. Of course, I haven't logged in for 3-4 years so maybe I'm missing something. Doubt it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39388786"><td></td></tr>
                <tr id="39389450"><td></td></tr>
                        <tr id="39383923"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383923" href="https://news.ycombinator.com/vote?id=39383923&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>The EFF just recently wrote an article with instructions on how to persevere &amp; archive your own tweets on the Wayback Machine, but it involves exporting your own backup and uploading it to them. Since the API is completely cut off from Twitter, there is no official way to backup other people's accounts.<p>But archive.today uses scraping and all sorts of tricky methods to bypass paywalls. I honestly don't understand why Nitter can't just stay logged out and rotate IPs. Although I'm sure that gets pricey when other people are accessing it constantly.</p><p><a href="https://www.eff.org/deeplinks/2024/01/save-your-twitter-account" rel="nofollow">https://www.eff.org/deeplinks/2024/01/save-your-twitter-acco...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39384026"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39384026" href="https://news.ycombinator.com/vote?id=39384026&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>If the scraping model is impaired due to aggressive countermeasures, end game are browser extensions that scrape as users view the site and ship scraped data back to a processor, similar to recap the law (uses an extension to scrape the PACER legal database and ship digital artifacts to the Internet Archive). Care will need to be taken around potentially sensitive data that could be shipped if users are logged in.<p><a href="https://free.law/recap" rel="nofollow">https://free.law/recap</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39387356"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39387356" href="https://news.ycombinator.com/vote?id=39387356&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Oh, that's a very cool project! How successful has it been? If it wasn't for Sci-hub that would be a great idea for the scientific publishing world as well.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39388410"><td></td></tr>
                  <tr id="39388603"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39388603" href="https://news.ycombinator.com/vote?id=39388603&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>This model also works well for deep web content archiving.<p>There was a gaming message board where someone wrote a browser extension that would back up all topics someone visited in the background while they were reading them.  It became important for archiving as much content from those forums as possible as the forum was in the process of shutting down.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="39384714"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39384714" href="https://news.ycombinator.com/vote?id=39384714&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Why don't you make a twitter account and install a duplicate web browser that you only use to open twitter links (and other crap that you don't want polluting your normal browser)?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39386202"><td></td></tr>
                <tr id="39386651"><td></td></tr>
                <tr id="39388570"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39388570" href="https://news.ycombinator.com/vote?id=39388570&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>You also need a burner phone number. Otherwise it will be difficult to get an account.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39383412"><td></td></tr>
                <tr id="39383489"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383489" href="https://news.ycombinator.com/vote?id=39383489&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>If the content we wanted was on Mastodon, we would not be having this conversation. Your comment is deeply unhelpful.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383838"><td></td></tr>
                <tr id="39384216"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39384216" href="https://news.ycombinator.com/vote?id=39384216&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>You're looking at a vase and seeing two faces side-on.<p>"Twitter won't let me read content people post on it"</p><p>"Try posting it on Mastodon"</p><p>"If it was on Mastodon we wouldn't be having this conversation"</p><p>"Whatever, you don't share anything from Twitter anyway"</p><p>Can you see the vase yet?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39384929"><td></td></tr>
                  <tr id="39384218"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39384218" href="https://news.ycombinator.com/vote?id=39384218&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>The issue isn't me posting Twitter links here or elsewhere. It's what to do when others do.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39387819"><td></td></tr>
                <tr id="39389341"><td><table>  <tbody><tr>    <td indent="7"><img src="https://news.ycombinator.com/s.gif" height="1" width="280"></td><td>
      <center><a id="up_39389341" href="https://news.ycombinator.com/vote?id=39389341&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Much as I dislike login walls, Mastodon still doesn't respect `:prefers-color-scheme`, so they're not my friends either.</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="39383527"><td></td></tr>
                        <tr id="39383482"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383482" href="https://news.ycombinator.com/vote?id=39383482&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I’d also vote for 3) the user interface is fast, responsive, and not total garbage inflicted with man boy ego whim randomly mutating a decade of questionable product management decisions</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39384052"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39384052" href="https://news.ycombinator.com/vote?id=39384052&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>It's over.<p>It isn't just Twitter, it's every single website that's turned themselves into a login-walled "application".</p><p>Twitter's relative openness lasted a long time. It was open by default because it is a product built in 2006, when the idea of coralling people into walled gardens to show them ads didn't exist.</p><p>Apps built later take the concept of "walled garden" as a default feature. Slack , Discord, Snapchat, Tiktok, Telegram .... all largely closed off platforms. You can't see anything unless you're logged in.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389638"><td></td></tr>
            <tr id="39386562"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39386562" href="https://news.ycombinator.com/vote?id=39386562&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>But Twitter is an ad-driven platform. Most of those other ones are not. It's ALL about the exposure to eyeballs. But now that Elon chewed on some wires and killed whole colocations, they are not able to serve all that traffic that is supposed to view the ads - for all the talk about how "Twitter is still running like it used to" after being gutted like a fish. It is definitely not.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383621"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383621" href="https://news.ycombinator.com/vote?id=39383621&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>For the same reason given for Nitter stopping, it is unlikely that you'll find a public service like that. There are nitter-like options, including forks of nitter itself, that you can self-host to give a better UX, but with those you have to have a twitter⁰ account for it to login with.<p>Another option (that also requires an account) is to use twitter⁰ itself with a browser extension that tweaks the UI.</p><p>My solution is the one I've been using for a _long_ time: simply don't go there. It has never been more than a novelty-gone-wrong, unless you count “a cesspool of humanity” as more, and as far as I know I've not missed out on anything significant. If you want me not to know what you have to say, say it on twitter⁰! Though I acknowledge that this is not an acceptable solution for all.</p><p>--</p><p>[0] The site desperately trying to be known as Χ
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383833"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383833" href="https://news.ycombinator.com/vote?id=39383833&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>In terms of a browser extension for Twitter, I highly recommend Control Panel for Twitter. It works as a browser extension as well as on some mobile browsers. It is highly customizable to filter out who/what you don't want to see and is fully open source if you feel the need to tweak.<p>It's updated regularly and the creator is highly active on Twitter to provide updates and answer questions - @ControlPanelFT</p><p>If you decide to use it, drop the guy a donation, they work hard on it!</p><p><a href="https://github.com/insin/control-panel-for-twitter">https://github.com/insin/control-panel-for-twitter</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39384413"><td></td></tr>
                <tr id="39387460"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39387460" href="https://news.ycombinator.com/vote?id=39387460&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>That looks interesting in theory, but unfortunately it was last updated in Feb 2022 so I would doubt highly it still works. There were a great deal of 3rd party tools to reduce abuse, bots and known bad actors on Twitter, but Elon took that all away when he restricted access to the API to only those paying $42k/month.<p>I haven't actively been on Twitter since July, but after he essentially removed the majority of moderation staff after he bought the place, reporting people is basically a non-working feature anyway. I remember getting a notice on someone I reported 3 months after the fact.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="39383505"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383505" href="https://news.ycombinator.com/vote?id=39383505&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Twitter became the defacto public square, so it's understandable that there's inertia for society to keep visiting.<p>This particular public square has been bought and fenced off. Ostensibly this is to drive more traffic to it.</p><p>Passively standing outside the fence trying to peek in is a lost cause. Find a new public square and convince as many people as you can to move. To do that, engage with those who moved, and create compelling reasons to go to the new public square.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389519"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389519" href="https://news.ycombinator.com/vote?id=39389519&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Was twitter ever really a defacto public square? The fact that some notable people used it doesn't make it a public square. I've seen stats that show only something like 1-3% of the US population has a twitter account. Facebook is much more of a "public square" than twitter ever was.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39388192"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388192" href="https://news.ycombinator.com/vote?id=39388192&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>There is enough decent resources on Twitter to warrant signing up IMO.  I just avoid installing the app so I don't end up browsing it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39384024"><td></td></tr>
                <tr id="39385644"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39385644" href="https://news.ycombinator.com/vote?id=39385644&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>They work only for a few more days, till their account expires (30 days after creation). After that no more guest account creation is possible: each instance will go red one by one.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39386344"><td></td></tr>
                        <tr id="39383410"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383410" href="https://news.ycombinator.com/vote?id=39383410&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>"I don't like twitter, I don't want to have an account on twitter, yet I <i>demand</i> to be able to read content posted on twitter" Honestly, I cannot understand the point of view of some commenters here.<p>Don't like the platform? Then don't use it! It's not mandatory. You can find content elsewhere online. You can block submissions on HN that link to twitter. Or you can just create an account with fake info and be done with it.</p><p>I don't actively use Twitter myself (as I'm not based in the US), but I have an account that I use solely for reading. The overwhelming number of similar comments actually makes me want to use it more.</p><p>/rant (and now feel free to downvote instead of replying)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389208"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389208" href="https://news.ycombinator.com/vote?id=39389208&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt;Don't like the platform? Then don't use it! It's not mandatory.<p>Sorry, my public officials seem to be using it as an official communications platform. For many people, it is in fact mandatory.</p><p>&gt;You can find content elsewhere online.</p><p>Not if someone sends you a link to a twitter thread and you can only see the first tweet without logging in. You can only see that content right there.</p><p>&gt; I have an account that I use solely for reading. The overwhelming number of similar comments actually makes me want to use it more.</p><p>This attitude will make you fit right in there.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389431"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39389431" href="https://news.ycombinator.com/vote?id=39389431&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>As an example, local police here sent out urgent missing person reports and the "more information" link was a twitter link (behind a bit.ly shortener if you can believe it)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39389347"><td></td></tr>
            <tr id="39389425"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39389425" href="https://news.ycombinator.com/vote?id=39389425&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt;Sorry, my public officials seem to be using it as an official communications platform. For many people, it is in fact mandatory.<p>I don't believe that anyone but Elon Musk use twitter as its only communicatuon platform.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39389510"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389510" href="https://news.ycombinator.com/vote?id=39389510&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I agree. It's not hard to make an account to "lurk". I'm sure most of those complaining have accounts at various other social media websites. It may cost some privacy, but I find the content more than worthwhile.<p>There is content on Twitter that is not available anywhere else. It frequently breaks news faster than any other source, and there are many high profile posters who use it as their only broadcast source. Some memorable examples include the FTX and OpenAI fiascos.</p><p>The website isn't stellar, but it is functional. Lists are a great feature to separate content into custom feeds.</p><p>Maybe there will be something in the future that can serve as an alternative, but there is none currently.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39389422"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389422" href="https://news.ycombinator.com/vote?id=39389422&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; "I don't like twitter, I don't want to have an account on twitter, yet I demand to be able to read content posted on twitter" Honestly, I cannot understand the point of view of some commenters here.<p>Why is it surprizing? What's there to understand? It's web. Twitter used to be a decent web citizen, and allowed you to read its posts like you would read web pages. I don't want an account on Mastodon; yet I can read content posted to Mastodon. I don't want an account on Bluesky; yet I can read content posted to Bluesky. Twitter used to be like that, and we got used to it, and now it's not, and it's infuriating.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39386616"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39386616" href="https://news.ycombinator.com/vote?id=39386616&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I'll do both.<p>People that create twitter accounts do so because they want reach. They want to be able to publish freely, to the internet, to share ideas, information they have, memes, whatever. But now, their reach is limited to other twitter accounts. Their voice is no longer public on the internet.</p><p>Twitter has some inertia that will carry this new model for now, there's a lot of twitter accounts, so many that most people won't know the difference at first. But as time goes on and people want to make things public and people slowly stop posting twitter links everywhere because they're useless (only useful to people with twitter accounts, so why share them outside of twitter in the first place) and every reference to something on twitter becomes a screenshot, people will look for alternatives to broadcast their thoughts.</p><p>Twitter is supposed to be a website where people can share ideas. You need an account to share ofc, but it's still supposed to be a website, you go there and read things. That's not possible anymore. Reading what someone has to say is only "using it" in the most tenuous sense. Using twitter is posting to it. People being able to read what you say is the whole point. They think they're forcing the whole world to get twitter accounts, but what they're really doing is forcing twitter users to share their ideas in more than one place, it's not going to turn out good for the company in the long run.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388925"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39388925" href="https://news.ycombinator.com/vote?id=39388925&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; They want to be able to publish freely, to the internet, to share ideas, information they have, memes, whatever.<p>Is this necessarily true? At this point, I would figure that people who continue to publish on Twitter are aware of its restrictions and continue to communicate there with that knowledge. If anything, one could argue that trying to access Twitter content without an account is what's actually inappropriate here, as posters can no longer trust the guarantees of the platform.</p><p>&gt; Twitter is supposed to be a website where people can share ideas.</p><p>Twitter <i>used</i> to be a website where people can share ideas. Twitter currently is a website where people can share ideas <i>with other Twitter users</i>. If you post on Twitter now with the intention of being truly public on the internet, I'd say you're using the wrong tool for the job. Whether that's a good business decision or not is irrelevant; the fact is that Twitter has changed its purpose, and users should update their expectations accordingly, however they see fit.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383549"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383549" href="https://news.ycombinator.com/vote?id=39383549&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>It's a change in behavior for Twitter, which was built with content and threads in the open.<p>It's ok for people to say, "I like how it was before."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39387330"><td></td></tr>
            <tr id="39383480"><td></td></tr>
                  <tr id="39388545"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388545" href="https://news.ycombinator.com/vote?id=39388545&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>libreddit is suffering the same problem. Some instances are still working but they're probably switching outgoing IPs often to evade the ban hammer.<p>As others have noted, I think this is part of a larger trend. All websites have realized that data is power, data is money, and they don't want to share anymore.</p><p>I used to host both nitter and libreddit, now I host neither of them. I've simply given up on reading that data.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39388661"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388661" href="https://news.ycombinator.com/vote?id=39388661&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Host it your self. I'm doing that with libreddit. Gives me much better performance than the highly used public instances.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39388939"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39388939" href="https://news.ycombinator.com/vote?id=39388939&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I was self hosting Reddit, which now seems entirely dead, and need to switch over to libreddit. Hopefully that lasts longer...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39389567"><td></td></tr>
                        <tr id="39382884"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39382884" href="https://news.ycombinator.com/vote?id=39382884&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>What are you looking for? If you want to be anonymous, your are SOL unfortunately. If you are looking for a less crappy browsing experience than Twitter, and Nitter filled that void, you can find forks which fetch content with your Twitter account. Setting up for local self hosting doesn't take a lot of minutes.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383248"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383248" href="https://news.ycombinator.com/vote?id=39383248&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I used to use Nitter to view content without logging in, as I do not have a twitter account  nor do I want one.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383988"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383988" href="https://news.ycombinator.com/vote?id=39383988&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>The question is whether or not they'll continue to develop Nitter just for people who want to run it locally. Twitter's page layout &amp; functions get updated and changed CONSTANTLY. If someone isn't updating Nitter regularly it will become depreciated very quickly.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39382707"><td></td></tr>
            <tr id="39383336"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383336" href="https://news.ycombinator.com/vote?id=39383336&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I have Tampermonkey scripts that delete Twitter entries from HN and anywhere else on the web. Seems to work well for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383372"><td></td></tr>
                  <tr id="39389348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39389348" href="https://news.ycombinator.com/vote?id=39389348&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>When nitter.poast.org announces it is going offline, I will believe "Nitter is over".  (Unless I find another instance that works.)  But this one still works fine.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39388775"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388775" href="https://news.ycombinator.com/vote?id=39388775&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Why do you need one? It takes a few minutes to make a Twitter account and keep browsing. You probably spent more time writing this post.<p>I'm glad I won't have to deal with people posting these off-brand Twitter links anymore.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388855"><td></td></tr>
                  <tr id="39383390"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383390" href="https://news.ycombinator.com/vote?id=39383390&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>For the past few weeks I've been using<p><a href="https://twiiit.com/" rel="nofollow">https://twiiit.com/</a></p><p>to find independent nitter servers that can show tweets of the few academics I still want to follow.</p><p>Now Twitter might soon break also these small third party servers but for the moment, they still work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39384985"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39384985" href="https://news.ycombinator.com/vote?id=39384985&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Started using Twitter in 2006. [Long story] Quit around 2017. Privacy Badger extension blocks embeds. Used to allow occasionally until I noticed it was never worth it and finally stopped reading "news" sites that were sentence|tweet|s|t etc.<p>Used Nitter for a while for the reason many do: to see that 1 tweet or thread that sounds interesting.  Realized it either wasn't or was a little FOMO.</p><p>When I was a kid if you missed a good movie in theaters you had to wait years to see it on TV. I've started returning to that mentality.  If it's genuinely good enough and interesting enough it will turn up somewhere eventually or I'll just miss out.</p><p>I can't number the people who have told me I <i>must</i> subscribe to AppleTV to watch some Ted show no one talks about any more. I always said: "No. It will turn up on some platform I use or come out on Blu-ray or I'll just never see it." For all I know it's on Blu-ray already. I forgot about it until just now it's been so long since I <i>must</i> watch.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383330"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383330" href="https://news.ycombinator.com/vote?id=39383330&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I thought that the official instance (nitter.net) works and that it works but visited it now, and it seems it doesn't have a valid certificate since Jan24th.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383707"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383707" href="https://news.ycombinator.com/vote?id=39383707&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>If you're in Chrome it likes to give you a full screen "oh no you can't go to this website!" with no visible override, but if you type in "thisisunsafe" it'll fly by it.<p>I wish Chrome would just let me have the damn button. I'm not a five year old.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389308"><td></td></tr>
                        <tr id="39383862"><td></td></tr>
            <tr id="39383397"><td></td></tr>
                <tr id="39386680"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39386680" href="https://news.ycombinator.com/vote?id=39386680&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>My personal concern is, if I have to sign up for an account to see what you have to say, I don't care what you have to say. If you want reach pick a platform that let's people easily read your thoughts. This is no different than "download the app to continue reading." People on twitter are irrelevant as far as I'm concerned, and they just don't know it yet. They will.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383328"><td></td></tr>
            <tr id="39383131"><td></td></tr>
            <tr id="39383396"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383396" href="https://news.ycombinator.com/vote?id=39383396&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Use a completely different platform. Find users providing content you like. Follow them and interact.<p>Either Twitter opens back up or segments trickle off the platform.</p><p>I used nitter only because it loaded faster and displyed raw cronological order.</p><p>Life existed before Twitter was created. You can do it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383579"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383579" href="https://news.ycombinator.com/vote?id=39383579&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I think this misses the point that a lot of nitter users aren’t looking for a social media platform to interact with people on, but to access information only available on twitter.  “Use a completely different platform” is useful to people consuming the social media product, but not useful for people who are uninterested in “content you like” but in very specific content they’re interested in.<p>I’m not saying there’s a solution that’s good either or there needs to be a good solution.  It’s a private business and there are all sorts of shitburger private businesses building golden walls around important content only available on their crappy platform and there’s no alternatives other than submit to their exploitation or remain ignorant in the world of subjects that are important to you.</p><p>But it would be nice if there were alternatives between brutal exploitation and unrequited ignorance. But heading over to mastodon or whatever doesn’t help you read “important thread about X discovery” or whatever since the content is singular and only exists on twitter.</p><p>Personally HN is the only social media like platform I use, and I have no interest in maintaining the energy levels to participate in the others. I’m just a passive observer of specific pieces of content in those platforms.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383763"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383763" href="https://news.ycombinator.com/vote?id=39383763&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span><i>&gt; but to access information only available on twitter</i><p>I see this being said a lot, even by some of my own contacts who insist on occasionally sending me links to things on twitter¹, but I'm not convinced there is really much of worth on there that isn't available elsewhere. What is uniquely on there that I might possibly care about isn't, IMO, worth being associated with or exposed to the rest.</p><p>--</p><p>[1] I used to use nitter to view such things, but stopped that many moons ago and ask if they have any other source, or if it is a joke maybe download/screenshot and forward that way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383925"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383925" href="https://news.ycombinator.com/vote?id=39383925&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>You may feel the subject is inane, but an example that sticks out in my mind was the Varda replication thread of LK99. It was really only on twitter, I found it entertaining to read occasionally, but I wasn’t really going to invest energy in asking for screenshots etc. But I agree with you regarding being associated with it exposed to the rest. That’s the value nitter brought !  It’s a sad day that it’s gone. End of the world? No. But the world has become slightly less good.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39384984"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39384984" href="https://news.ycombinator.com/vote?id=39384984&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Twitter at least used to be the best place to find official statements from local government, local cops, etc. They would put stuff out on their official accounts, other people would post video of news conferences, and so on. I am not sure there is a replacement.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39383378"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383378" href="https://news.ycombinator.com/vote?id=39383378&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I think you have 3 alternatives:<p>1. Create a Twitter account.</p><p>2. Stop using Twitter.</p><p>3. Use Facebook, Tumblr, or Mastodon for microblogging.</p><p>Twitter started requiring a login screen to view posts, but it's not the first website to do so. Pinterest and Instagram have done this for ages. We all hate it, but it's business.</p><p>I wonder why Tumblr isn't more successful than it is. It used to be a pretty well-known platform, and it's almost identical to Twitter, but while every celebrity seems to have a Twitter account, nobody seems to have a Tumblr account. Perhaps they do, they just don't tell anybody about it?</p><p>I wish Mastodon wasn't a thing. I believe federation is a terrible idea for normal computer users due to its non-obvious dangers, specially as more people will begin using Mastodon as if it were Facebook. I saw on Reddit that someone is building an open source, non-federated Reddit clone. That's what I think would have been better: an open-source, non-federated Twitter clone. Does anybody know of something like that, by the way?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383890"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383890" href="https://news.ycombinator.com/vote?id=39383890&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span><i>&gt; I wonder why Tumblr isn't more successful than it is. It used to be a pretty well-known platform, and it's almost identical to Twitter,</i><p>Twitter won over that and a number of other options on novelty, inertia, and notoriety, essentially. A mix of right-place-right-time, further luck, and network effects.</p><p>Tumblr did better than many alternatives, but eventually shot itself in the foot (well, was shot in the foot by its parent) when it alienated a chunk of the audience it did have by deleting a lot of content in order to appease potential advertisers.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39386553"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39386553" href="https://news.ycombinator.com/vote?id=39386553&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; in order to appease potential advertisers.<p>It wasn't advertisers, it was apple, they'd been delisted from the app store, and getting rid of the NSFW material was part of the deal that apple would allow them back with.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383418"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383418" href="https://news.ycombinator.com/vote?id=39383418&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Tumblr used to be a lot more popular, but its collapse is usually attributed to them banning NSFW content. Not everyone was posting or viewing NSFW of course, but there was enough overlap in audiences to cause a cascade which ended with nearly everyone, NSFW or not, moving to Twitter.<p>It's a classic Yahoo acquisition fumble, they bought it for $1.1 billion and ended up selling it on to Automattic for just $3 million post-exodus.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389379"><td></td></tr>
                  <tr id="39383500"><td></td></tr>
                <tr id="39383565"><td></td></tr>
                <tr id="39389543"><td></td></tr>
            <tr id="39389505"><td></td></tr>
            <tr id="39383759"><td></td></tr>
                                        <tr id="39383182"><td></td></tr>
            <tr id="39383187"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383187" href="https://news.ycombinator.com/vote?id=39383187&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>nitter.cz is one of many mirrors. The official site was nitter.net (which is down as well).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39385919"><td></td></tr>
            <tr id="39383320"><td></td></tr>
                <tr id="39385751"><td></td></tr>
                <tr id="39389441"><td></td></tr>
            <tr id="39385972"><td></td></tr>
                  <tr id="39383535"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383535" href="https://news.ycombinator.com/vote?id=39383535&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Too few people who care, too many that are happy to be fed what the twitter algo decides they should see. Dopamine takes care of the rest.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383697"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383697" href="https://news.ycombinator.com/vote?id=39383697&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Too few people care for what to happen?<p>Maybe I am misreading your post, but why does it matter if people behave in a certain way en masse, when the majority of the personal impact is based on personal behavior.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383648"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383648" href="https://news.ycombinator.com/vote?id=39383648&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>This is the actual answer... but social networks are super sticky, and trap people in with the threat of cutting other people off who also cant/wont leave.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383519"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383519" href="https://news.ycombinator.com/vote?id=39383519&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Despite the outrage, I think only a minority of users think this.<p>Most twitter users like it, and didn't even attempt to move to another platform.</p><p>I personally tried substack notes, mastodon and bluesky, and none of them bring 0.1% of the activity and interesting things that used to happen on twitter.</p><p>Now twitter is less interesting than before, but it still the only candidate that is worth my time. Even reddit is slowly becoming meh.</p><p>I'm certain that the new generation, however, is creating their own wonderland in a place I'm not active in. That's how we got twitter started, it's usually the young that stir those things.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383183"><td></td></tr>
                <tr id="39386649"><td></td></tr>
                  <tr id="39383309"><td></td></tr>
                <tr id="39383563"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383563" href="https://news.ycombinator.com/vote?id=39383563&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There is no such thing as "one twitter", it's way too big.<p>I assume your activity mean you must be filtered in a bucket that shows you those things, because I never encounter such tweets in my timeline.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383338"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383338" href="https://news.ycombinator.com/vote?id=39383338&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost.<p>Should we stop linking to all information on all of these platforms because some of the information is undesirable to some people?</p><p>Do you allow others to poison your well like that?  If so, that strikes me as easily exploitable.</p><p>Also, the idea that this sort of content is inherently dangerous doesn’t hold water. I’m not going to become a white supremacist because Twitter showed me a racist tweet.  Information and ideology is not inherently dangerous.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39385006"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39385006" href="https://news.ycombinator.com/vote?id=39385006&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost.<p>That is intentionally and maliciously obfuscating the issue by equating social media (Google, Facebook, Tumblr) with infrastructure hosting (Cloudflare, GoDaddy, and Dreamhost).</p><p>Those two types of companies are <i>very</i> different and should be regulated very differently.</p><p>&gt; Should we stop linking to all information on all of these platforms because some of the information is undesirable to some people?</p><p>Um, yes?</p><p>Links to social media vaporize regularly.  If it isn't worth the effort to pull and host onto a less ephemeral medium, was it really worth sharing at all?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383591"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383591" href="https://news.ycombinator.com/vote?id=39383591&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost.<p>Those are all very different things. Only Facebook is somewhat similar in that it has an algorithm that surfaces emotionally engaging content.</p><p>&gt; I’m not going to become a white supremacist because Twitter showed me a racist tweet.</p><p>How about if it showed you 50 racist tweets? If repetition and exposure didn't have any effect on our behaviour then there would be no advertising market and no one would bother to spend vast sums on political campaigning.</p><p>&gt; Information and ideology is not inherently dangerous.</p><p>How about misinformation? As an example, I'd say the rise in anti-vaccination activity is an example of inherently dangerous information that has been spread primarily through social media.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383605"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383605" href="https://news.ycombinator.com/vote?id=39383605&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Neither is misinformation inherently dangerous.  There are 400,000 churches in the US and every year fewer people identify as religious.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383415"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383415" href="https://news.ycombinator.com/vote?id=39383415&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; Also, the idea that this sort of content is inherently dangerous doesn’t hold water. I’m not going to become a white supremacist because Twitter showed me a racist tweet. Information and ideology is not inherently dangerous.<p>There's been enough work that suggests a close link between exposure to propaganda and getting funneled in to increasingly more radical material, e.g. [1].</p><p>Particularly regarding Twitter, it's noticeable that it's not just <i>one</i> racist tweet that gets shown to you when you deliberately click on one - the space below will be filled with similar kind of content, and you can see a marked increase of far-right crap on your algorithmic timeline as well, with every little interaction you have with far-right content.</p><p>It was bad before Musk, but since his takeover it's gotten really really bad.</p><p>[1] <a href="https://www.technologyreview.com/2020/01/29/276000/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/" rel="nofollow">https://www.technologyreview.com/2020/01/29/276000/a-study-o...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383729"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383729" href="https://news.ycombinator.com/vote?id=39383729&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; you can see a marked increase of far-right crap on your algorithmic timeline as well, with every little interaction you have with far-right content.<p>And?</p><p>I trust people to be intelligent enough to make their own decisions. If seeing an incredibly (or even mildly) racist tweet suddenly makes them proverbially goose-step around their home, they already were going to. One, ten, or hundred posts won't make them racist unless they were already predisposed to those ideas. In a healthy mind, viewing alternative views may broaden their view which might include disagreeing with their previous opinions.</p><p>If viewing a gay marriage doesn't make you gay, neither does seeing someone complain about other races or LGBT people. I am on 'your' side politically but the opinion that all conservative opinion should be extinguished or somehow that it is inherently harmful because you disagree with is just as bad as conservatives saying the same about your opinion.</p><p>There is no harm in reading and understanding other's opinions. All sides need to understand that. It only crosses into the need for 'deplatforming' when they are making implicit or explicit threats against a person or a group of people.</p><p>"I think &lt;x&gt; race is less likely to be successful due to &lt;x, y, z&gt;" is not a bad opinion. It may be wrong, but it isn't hurtful beyond maybe to someone who is too sensitive. "I think &lt;x&gt; race should be exterminated" is beyond the line and shouldn't be allowed to be posted publicly.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39385922"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39385922" href="https://news.ycombinator.com/vote?id=39385922&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; If viewing a gay marriage doesn't make you gay, neither does seeing someone complain about other races or LGBT people.<p>This is a great line that probably pisses off almost everybody. Love it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383562"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383562" href="https://news.ycombinator.com/vote?id=39383562&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Your link mentions YouTube. Under your logic, should we also stop using YouTube because its recommendations will radicalize us?<p>This line of thinking doesn’t make sense to me.  Furthermore, bad ideology and its ideologues won’t go away simply because we individually stop looking at them.</p><p>I quit Twitter after 12 years when they started censoring the site search.  I was trying to research QAnon wackos and it turns out that the search box had been neutered.</p><p>It’s one thing to tell people what they can post, it’s another to tell me what I’m not allowed to read (that is allowed to be posted).</p><p>Fuck censorship.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39383416"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383416" href="https://news.ycombinator.com/vote?id=39383416&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>What one individual might view as transphobia another would view as radical feminism. The world's not as black and white as you make it out to be.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383495"><td></td></tr>
                <tr id="39383598"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383598" href="https://news.ycombinator.com/vote?id=39383598&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>The initialism "TERF" means "trans-exclusionary radical feminism"; I'm sure those who hold these views see themselves as being "just" radical feminists — the way the discussions go, it seems to me people with these views are unable to comprehend that the model they have of what gender is, is one of several, or that there is any value in the models they do not themselves have.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39385756"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39385756" href="https://news.ycombinator.com/vote?id=39385756&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There's only room for one model when it comes to deciding who gets to use which space though.<p>For example, should a male convict who identifies as a woman be incarcerated in the female prison estate or the male one? There's not really room for several models of sex and gender in answering that question, as there's a single choice to be made with two mutually exclusive options.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39385938"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39385938" href="https://news.ycombinator.com/vote?id=39385938&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; There's only room for one model when it comes to deciding who gets to use which space though.<p>One model <i>per space</i>. For example, the answer to "given how much testosterone is now in their body, which gender sports team should this F2M person be on?" is different to "which do we need to screen them for, testicular cancer or cervical cancer?"</p><p>&gt; For example, should a male convict who identifies as a woman be incarcerated in the female prison estate or the male one? There's not really room for several models of sex and gender in answering that question, as there's a single choice to be made with two mutually exclusive options.</p><p>Four[0] options, if you think outside the box.</p><p>Ideally, I would have my prisons set up with enough guards that this doesn't matter. As I don't live in the ideal world, I would also have a[0] trans estate for those who have begun but not yet completed transitioning, and those who have completed a transition would be in whatever the new gender is.</p><p>[0] or +1, if M2F != F2M while transitioning
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                          <tr id="39388245"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388245" href="https://news.ycombinator.com/vote?id=39388245&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Twitter, oh sorry X, died on the day everything went completely batshit insane, politicized and radicalized anyway. To the point people got (and still are!) permanently suspended for no good reason at all.<p>Such a shame, ~10 years ago it used to be tons of fun with some really good discussions in the mix.</p><p>But times are really changing I guess. And not for the better.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383129"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383129" href="https://news.ycombinator.com/vote?id=39383129&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>If you don't like twitter, why not just not use it? I guess it sucks that you can't click twitter links, but honestly, you're not missing anything. Whenever I jump through some hoop to view a tweet linked here, it's not worth it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383265"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383265" href="https://news.ycombinator.com/vote?id=39383265&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>There are sometimes newsworthy things on Twitter. I have the domain blocked at the Pihole to break the "check Twitter" loop I get into; having to do the Nitter thing helped enormously in breaking the bad habit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383954"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383954" href="https://news.ycombinator.com/vote?id=39383954&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span><i>&gt; There are sometimes newsworthy things on Twitter.</i><p>If something is particularly newsworthy, it'll appear elsewhere in pretty short order IME, often it originated elsewhere in fact.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388274"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39388274" href="https://news.ycombinator.com/vote?id=39388274&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Sometimes the tweets themselves <i>are</i> newsworthy, or the news articles cite a tweet. Some local governments use Twitter for announcements you can't easily get elsewhere, especially during a disaster like a big snowstorm.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39383423"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383423" href="https://news.ycombinator.com/vote?id=39383423&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>There are people doing things of interest to me where I can either read it on Twitter (currently using Nitter's RSS feeds) or see the misleading blogspam or fluff-filled YouTube video about it a few days later. I'd rather get the information from the source.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383788"><td></td></tr>
            <tr id="39383239"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383239" href="https://news.ycombinator.com/vote?id=39383239&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Farcaster has been a nice refreshment for me. Currently a lot of developer types are present on the platform and I've seen lots of insightful conversations there.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383317"><td></td></tr>
                <tr id="39384768"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39384768" href="https://news.ycombinator.com/vote?id=39384768&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I looked it up and apparently there is a "$5 sign-up fee", and posts/reactions are not free too:<p>&gt;To sign up, users must pay a $5 sign-up fee, meant to prevent the creation of spam accounts. Further, users can only post a limited number of “casts” on Farcaster apps, which are tied to packages called storage units. Storage units, which go for $5 a piece, grant a user 5,000 casts, 2,500 reactions, and 2,500 links or photo posts within a one-year period.</p><p>(some shady website)</p><p>Yeah, that will surely make millions of users to sign up /s
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389166"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39389166" href="https://news.ycombinator.com/vote?id=39389166&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Yeah, I don't get it. Social media sites thrive on interaction. Giving users a reason to hesitate before interacting is going to snuff out a lot of the casual interactions that make a site feel "alive".</span></p></div></td></tr>
        </tbody></table></td></tr>
                              </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub now officially supports polar.sh as a funding platform (122 pts)]]></title>
            <link>https://twitter.com/birk/status/1758087210211909649</link>
            <guid>39382281</guid>
            <pubDate>Thu, 15 Feb 2024 13:15:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/birk/status/1758087210211909649">https://twitter.com/birk/status/1758087210211909649</a>, See on <a href="https://news.ycombinator.com/item?id=39382281">Hacker News</a></p>
Couldn't get https://twitter.com/birk/status/1758087210211909649: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[How deceptive design is used to compromise your privacy and how to fight back (158 pts)]]></title>
            <link>https://consciousdigital.org/deceptive-design-patterns/</link>
            <guid>39382264</guid>
            <pubDate>Thu, 15 Feb 2024 13:14:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://consciousdigital.org/deceptive-design-patterns/">https://consciousdigital.org/deceptive-design-patterns/</a>, See on <a href="https://news.ycombinator.com/item?id=39382264">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-6826">
  
  <div data-hide-featured-media="1">
<p>Today, we’re releasing a new <a href="https://consciousdigital.org/deceptive-patterns/">guide</a> explaining how to compel companies employing deceptive design to dodge data protection requests—like those for data deletion or access—to comply. It encapsulates five years of experience from operating <a href="http://yourdigitalrights.org/">YourDigitalRights.org</a> and <a href="http://databrokerswatch.org/">DataBrokersWatch.org</a>, alongside a unique experiment and extensive research. Here’s the story behind it.</p>



<p>Deceptive design, also known as deceptive patterns or dark patterns, refers to the tactics companies employ through design to manipulate individuals into actions they wouldn’t normally take. For example, websites sometimes use deceptive patterns to manipulate people to purchase expensive products or subscriptions by concealing free or more affordable alternatives:</p>



<div>




<p>For a cheaper Google Workspaces subscription, first subscribe to the expensive option and then downgrade (Source: <a href="http://deceptive.design/">deceptive.design</a>)</p>
</div>



<p>Similarly, companies employ deceptive tactics to avoid complying with data protection requests. These are legal rights that allow individuals to ask a company to delete or share a copy of their personal data. The encouraging news is that more than five years since the GDPR—the legal framework in the EU that gives individuals the right to access or delete their data—was introduced, most companies now adhere to these data protection requests.</p>



<p>The downside, however, is that some companies continue to resist compliance. Specifically, data-centric enterprises, whose business models hinge on gathering personal data—like data brokers and social networks—resort to deceptive design practices to skirt data protection requests. This is particularly concerning because these entities hold vast amounts of personal data and often use it in the most objectionable ways. As a result, they are the primary targets from whom we seek to erase our data.</p>



<p>In 2022, we embarked on an unconventional experiment. We sent a data deletion request to each of the 600 data brokers listed on <a href="http://databrokerswatch.org/">DataBrokersWatch.org</a> to observe their reactions. This experiment allowed us to uncover numerous deceptive patterns and formulate effective countermeasures – strategies to bypass these dark patterns. Often, our countermeasures persuaded the companies to honor our deletion requests. When they didn’t, we escalated the issue to a government regulator (a process <a href="http://yourdigitalrights.org/">YourDigitalRights.org</a> can handle for you). Looking back, the effort was worthwhile. We’ve noticed a trend towards better compliance among data-centric businesses. We detailed our findings in a <a href="https://www.youtube.com/watch?v=SY_YAZEJPjc&amp;t=1s">presentation</a> at the 2022 Good Tech Fest for those interested in learning more.</p>



<p>We hope you find the guide useful and would appreciate your feedback.</p>


<p><a href="https://consciousdigital.org/wp-content/uploads/2023/04/deceptive-patterns.pdf" data-width="max" data-height="max" data-toolbar="bottom" data-toolbar-fixed="off">deceptive-patterns<br></a></p>

<p id="jp-relatedposts">
	<h3><em>Related</em></h3>
</p></div><!--/inner-wrap-->
    
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Managing mutable data in Elixir with Rust (126 pts)]]></title>
            <link>https://www.lambdafunctions.com/articles/elixir-and-rust</link>
            <guid>39382227</guid>
            <pubDate>Thu, 15 Feb 2024 13:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lambdafunctions.com/articles/elixir-and-rust">https://www.lambdafunctions.com/articles/elixir-and-rust</a>, See on <a href="https://news.ycombinator.com/item?id=39382227">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<h2>
Managing mutable data in Elixir with Rust</h2>
<p>
One of Elixir’s core benefits, and the secret to its robustness and scalability,
is its foundation on immutable data.  Sometimes, though, immutability is just
not a great fit for a particular task—but that task is only one part of a large
project.  Is it possible to enjoy the benefits of Elixir’s data model everywhere
else, but carve out a little mutable exception for one area?</p>
<p>
Yes!</p>
<p>
A long-running Elixir project I’m involved in has just this problem.  The
project is delivered over the web, so moving away from Elixir as a whole is not
on the cards because <a href="https://www.phoenixframework.org/">Phoenix</a> is quite
simply a cheat code for web development.  We <em>could</em> hive off the mutable
section into a microservice, but that would require significant architectural
and management overhead.  All we really need is a little escape hatch for a
limited chunk of code, while still being within the same VM and able to interact
normally with the rest of the service.</p>
<p>
This is just what <a href="https://github.com/rusterlium/rustler">Rustler</a> offers.</p>
<p>
Rustler is “a library for writing Erlang NIFs in safe Rust code”—in other
words, you can write code that looks like standard Elixir functions, but behind
the scenes is actually implemented in Rust.</p>
<p>
<a href="https://www.erlang.org/docs/17/tutorial/nif">NIFs</a> have been a feature of the
Erlang VM since long before either Elixir or Rust arrived on the scene.  What
Rust and Rustler add is:</p>
<ul>
  <li>
    <p>
safety—this is critical since a crash in a NIF will bring down the
whole VM    </p>
  </li>
  <li>
    <p>
a lot of polish and interface glue that makes it feasible to write
more ambitious integrations that you might be inclined to attempt with
C and Erlang’s standard NIF support    </p>
  </li>
  <li>
    <p>
access to all of Rust’s libraries    </p>
  </li>
</ul>
<p>
Unfortunately, most of the Rustler examples on the web focus on the speed
benefits and show the implementation of a trivial <code>add</code> function and then stop
there.  While that’s fine for demonstrating the bare minimum integration
required, for me the interesting part of Rustler is the chance to escape in a
controlled way from the immutable world—I want to explore how to manage a
little mutable chunk of memory in a safe way.  Although Rustler is certainly
capable of this, there’s very little available in the way of tutorials or
examples.</p>
<p>
Hopefully this article will help.</p>
<h2>
Goal</h2>
<p>
As mentioned above, I want to explore memory management.  More specifically, I
want to be able to hold a chunk of data in the Rust world that persists between
multiple calls to different “Elixir” (Rustler) functions.  These functions
should allow the Elixir world to pass data into the Rust world, mutate the data
held there, and then retrieve results.</p>
<p>
To give us something substantial to play with and avoid having to implement our
own data store for this demo, I’ll use Oxigraph.</p>
<p>
<a href="https://github.com/oxigraph">Oxigraph</a> is a Rust graph database library
implementing the SPARQL standard.  Let’s suppose that we want to wrap it, so
that we can have access to a fast graph database from within Elixir.  We’ll call
our wrapper <code>FeGraph</code>.</p>
<p>
We want to be able to:</p>
<ol>
  <li>
    <p>
Make a new in-memory database    </p>
    <pre><code>db = FeGraph.new()</code></pre>
  </li>
  <li>
    <p>
Add data to it    </p>
    <pre><code>FeGraph.set(db, "http://foo.bar.com")
FeGraph.set(db, "http://foo.baz.com")</code></pre>
  </li>
  <li>
    <p>
Export the database as a
<a href="https://en.wikipedia.org/wiki/Turtle_(syntax)">Turtle</a> string:    </p>
    <pre><code>FeGraph.dump_db(db) |&gt; IO.puts()</code></pre>
  </li>
</ol>
<p>
To keep this to a reasonable length, we’re not going to implement everything
that would be required to expose all the capabilities of Oxigraph; just enough
to demonstrate holding data on the Rust side and acting on it from Elixir.</p>
<h2>
Implementation</h2>
<p>
(If you want to follow along, I recommend working through one of the many
Rustler <code>add</code> tutorials I mentioned before getting into the code, so that you
have a basic project up and running and have worked through how Rust and Elixir
functions link together.  Everything below here assumes you’re already at that
point.)</p>
<p>
The key to this whole approach is the ability to pass a
<a href="https://erlang.org/doc/man/erl_nif.html#resource_objects">Resource</a> between the
two worlds.  This acts as a handle to a piece of memory; it can be returned from
a NIF and then passed back into another call.  Exactly what we need.</p>
<p>
A BEAM <code>Resource</code> is represented in Rustler by a
<code>rustler::resource::ResourceArc&lt;T&gt;</code> struct.  To get started with our
implementation, let’s define a new type that we can use as a handle to represent
the state of our graph store.</p>
<p>
In a production scenario we’re likely to want to manage more state than this,
but for now it will suffice to define a <code>MyGraph</code> struct that just contains (via
a mutex) the Oxigraph data store; this represents the mutable data we want to
manage outside Elixir.  In the future, more fields could be added to <code>MyGraph</code>
as necessary.</p>
<p>
To turn this into something that can be passed back and forth between Elixir and
Rust, we need to wrap it in a <code>ResourceArc</code>.  In order to make our function
signatures a bit more readable we’ll define a new type of <code>GraphArc</code> to
represent a <code>MyGraph</code> struct in a <code>ResourceArc</code>.</p>
<p>
In <code>lib.rs</code>:</p>
<pre><code>use std::sync::Mutex;
use oxigraph::store::Store;
use rustler::resource::ResourceArc;
use rustler::OwnedBinary;
use rustler::{Env, Term};

struct MyGraph { store: Mutex&lt;Store&gt; }

type GraphArc = ResourceArc&lt;MyGraph&gt;;</code></pre>
<p>
A bit of additional plumbing is required to tell Rustler that a <code>MyGraph</code> is
something that can be used as a <code>Resource</code>:</p>
<pre><code>fn on_load(env: Env, _info: Term) -&gt; bool {
    rustler::resource!(MyGraph, env);
    true
}</code></pre>
<p>
With these definitions in place, we can write a <code>new</code> function that allocates a
new data store and returns a handle to it:</p>
<pre><code>#[rustler::nif]
fn new() -&gt; GraphArc {
    ResourceArc::new(
        MyGraph {
            store: Mutex::new(Store::new().unwrap()),
        }
    )
}</code></pre>
<p>
And on the Elixir side, in <code>fe_graph.ex</code>:</p>
<pre><code>defmodule FeGraph do
  use Rustler, otp_app: :myapp, crate: "fegraph"

  def new(), do: :erlang.nif_error(:nif_not_loaded)
end</code></pre>
<p>
At this point we can test in <code>iex</code>, and see that the Elixir stub above has been
replaced by the Rust NIF we defined, which we can run and which gives us back a
reference:</p>
<pre><code>iex(1)&gt; FeGraph.new
#Reference&lt;0.2659174309.2607677441.115195&gt;</code></pre>
<p>
Granted we can’t yet <em>do</em> anything with it, but we’re already defining a data
store in Rust and seeing evidence of it in Elixir; and behind the scenes the
BEAM and Rustler are taking care of all of the heavy lifting for us.</p>
<p>
How about a simple function to add some data to our new store?  In a way that
will feel very familiar to Elixir code, it will need to both take and return a
<code>GraphArc</code> handle.  We’ll also have it accept a single string to use for all
three parts of the triple to store (normally of course we’d take different
strings for the subject, predicate, and object parts of the triple, but our
focus here isn’t on SPARQL—we just want some data to store.)</p>
<pre><code>#[rustler::nif]
fn set(state: GraphArc, iri: &amp;str) -&gt; GraphArc {
    let store = state.store.lock().unwrap();

    let ex = NamedNode::new(iri).unwrap();
    let quad =
        Quad::new(ex.clone(), ex.clone(), ex.clone(), GraphName::DefaultGraph);
    (*store).insert(&amp;quad).unwrap();

    drop(store);

    state
}</code></pre>
<p>
Within the function we can use our <code>GraphArc</code> state argument to get a hold of
the Oxigraph store that we created back in the <code>new</code> function.  Once we’ve got
it we can add some test data to the graph as normal, then return the unchanged
<code>state</code>.</p>
<p>
The final piece of the puzzle is to retrieve some data from our store.  Rather
than running a query (which would require getting into more SPARQL) we’ll just
dump the whole database and return it as a string.  As before, our new function
will need to accept a <code>GraphArc</code>, but this time we’ll return an <code>OwnedBinary</code>,
which allows us to send a binary back to the BEAM and then wash our hands of it.</p>
<pre><code>#[rustler::nif]
fn dump_db(state: GraphArc) -&gt; OwnedBinary {
    let store = state.store.lock().unwrap();

    let mut buffer = Vec::new();
    (*store)
        .dump_graph(
            &amp;mut buffer,
            GraphFormat::Turtle,
            GraphNameRef::DefaultGraph,
        )
        .unwrap();

    let mut result = OwnedBinary::new(buffer.len()).unwrap();
    result.as_mut_slice().copy_from_slice(&amp;buffer);

    result
}</code></pre>
<p>
The majority of this function turns out to be messing around getting the data
out of Oxigraph into a buffer, and then from the buffer into the <code>OwnedBinary</code>;
the Rustler wrapper has become mostly invisible which is what I was originally
hoping for.</p>
<p>
With this in place we can now demonstrate allocating some memory in Rust,
returning a handle to that memory, then using it to store data outside the BEAM
memory model and finally fetch the data back into the Elixir world:</p>
<pre><code>iex(1)&gt; db = FeGraph.new
#Reference&lt;0.2749498138.3684302852.140448&gt;
iex(2)&gt; FeGraph.set(db, "http://foo.com")
#Reference&lt;0.2749498138.3684302852.140448&gt;
iex(3)&gt; FeGraph.dump_db(db)
"&lt;http://foo.com&gt; &lt;http://foo.com&gt; &lt;http://foo.com&gt; .\n"</code></pre>
<p>
Note the important part; the reference is the same both times despite the data
changing and we are <em>not</em> storing it after the <code>set</code> call; normally we’d need to
do something like <code>db = FeGraph.set(db, "http://foo.com")</code> instead.  The only
reason <code>set</code> returns the reference is for convenient use with the pipe operator
or similar.</p>
<h2>
Conclusion</h2>
<p>
While the code shown above does skip past most of the error handling, hopefully
it’s clear just how accessible Rustler makes it to link Rust code into Elixir
projects in a way that allows you to combine the strengths of both.</p>
<p>
Rustler is a tremendous addition to the Elixir ecosystem, and it opens up far
more opportunities than just calculating things more quickly.  Being able to opt
out of the standard BEAM memory model for specific sections of code can open the
doors to custom data stores and other features that would not generally be a
good fit for Elixir, while still allowing you to use the power of Phoenix for
the majority of your application… all with virtually seamless integration.</p>

        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is making a map of methane leaks for the whole world to see (194 pts)]]></title>
            <link>https://www.businessinsider.com/google-map-methane-leaks-world-can-see-2024-2</link>
            <guid>39381977</guid>
            <pubDate>Thu, 15 Feb 2024 12:41:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/google-map-methane-leaks-world-can-see-2024-2">https://www.businessinsider.com/google-map-methane-leaks-world-can-see-2024-2</a>, See on <a href="https://news.ycombinator.com/item?id=39381977">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Google is planning to use satellite data, AI technology, and computing power to map methane emissions.</li><li>Methane is a potent greenhouse gas that's responsible for nearly a third of global warming.</li><li>Nearly 40% of manmade methane comes from oil, gas, and coal operations.</li></ul><!-- Excluded mobile ad on desktop --><section id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_sustainability" data-newsletter-id="" data-newsletter-title="Insider Sustainability" data-acq-source="sustainabilityinlinesignup">
                              
                        
                            
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            <form id="emailCapture" action="javascript:void(0);" method="POST" novalidate="">
                              
                              
                              <p>
                                    By clicking ‘Sign up’, you agree to receive marketing emails from Insider
                                    as well as other partner offers and accept our
                                    <a href="https://www.businessinsider.com/terms" target="_blank">Terms of Service</a> and
                                    <a href="https://www.businessinsider.com/privacy-policy" target="_blank">Privacy Policy</a>.
                                        </p>
                            </form>
                          </section><p>A satellite that measures methane leaks from oil and gas companies is set to start circulating the Earth 15 times a day next month. Google plans to have the data mapped by the end of the year for the whole world to see.</p><p>The partnership between Google and the Environmental Defense Fund, which in March is expected to launch its satellite known as MethaneSAT, marks a new era of global climate accountability. <a target="_blank" href="https://www.unep.org/news-and-stories/press-release/urgent-action-cut-methane-emissions-fossil-fuel-operations-essential#:~:text=Methane%20is%20a%20powerful%20greenhouse,agriculture%2C%20waste%20and%20fossil%20fuels." data-analytics-product-module="body_link" rel=" nofollow">Methane</a> is a potent greenhouse gas estimated to be responsible for nearly a third of human-caused global warming. Scientists say slashing methane emissions is one of the fastest ways to slow the climate crisis because methane has 80 times the warming power of carbon dioxide over a decade.</p><p>"Globally, 2023 was the <a target="_blank" href="https://www.businessinsider.com/world-hottest-year-ever-history-climate-crisis-2024-1" data-analytics-product-module="body_link" rel="">hottest year on record</a>," Steve Hamburg, the EDF's chief scientist and the project lead for MethaneSAT, told reporters. "The need to protect the climate has never been more urgent, and cutting methane emissions from fossil-fuel operations and agriculture is really the fastest way that we can slow the warming right now."</p><p>Agriculture — particularly cow burps — gets a lot of the blame for the methane problem. The International Energy Agency has said <a target="_blank" href="https://www.iea.org/reports/global-methane-tracker-2023/understanding-methane-emissions" data-analytics-product-module="body_link" rel=" nofollow">farming is the largest source of methane emissions</a> from human activities, but the energy sector is a close second. Oil, gas, and coal operations are thought to account for 40% of global methane emissions from human activities. The IEA says focusing on the energy sector should be a priority, in part because reducing methane leaks is cost-effective. Leaking gas can be captured and sold, and the technology to do that is relatively cheap.</p><!-- Excluded mobile ad on desktop --><p>But methane has been difficult to track in near-real time. MethaneSAT is among a <a target="_blank" href="https://www.businessinsider.com/satellites-locate-source-of-methane-leaks-to-fight-climate-crisis-2022-7" data-analytics-product-module="body_link" rel="">new generation of satellites</a> designed to pinpoint sources of the gas almost anywhere in the world, while Google has the computing power and artificial-intelligence prowess to analyze vast amounts of data and map oil and gas infrastructure.</p><p>Historically, measuring <a target="_blank" href="https://www.businessinsider.com/satellites-locate-source-of-methane-leaks-to-fight-climate-crisis-2022-7" data-analytics-product-module="body_link" rel="">methane leaks</a> has involved expensive field studies with airplanes and handheld infrared cameras. That approach offers only a snapshot in time, and research took years to be published.</p><p>Yael Maguire, a vice president and general manager of sustainability at Google Geo — the team behind platforms such as Google Maps and Street View — said mapping oil and gas operations was similarly challenging. The locations of wellheads, industrial pumps, and storage tanks can change quickly, so a map needs to be updated regularly. A satellite can meet that demand.</p><p>Maguire said the same AI technology that Google used to detect trees, crosswalks, and intersections from satellite imagery would be applied to oil and gas infrastructure. The map would be overlaid with data from MethaneSAT to shed light on the type of machinery most susceptible to leaks.</p><!-- Excluded mobile ad on desktop --><p>"We think this information is incredibly valuable for energy companies, researchers, and the public sector to anticipate and mitigate methane emissions in components that are generally most susceptible," Maguire said.</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/png" data-srcs="{&quot;https://i.insider.com/65cbe6c894aa8ee8e84b0c65&quot;:{&quot;contentType&quot;:&quot;image/png&quot;,&quot;aspectRatioW&quot;:2109,&quot;aspectRatioH&quot;:1330}}" alt="A visual of Google's methane emissions map. Yellow dots mark the source and purple, orange, and yellow shading shows how the emissions diffused over a wider area." itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Yellow dots mark the source, while purple, orange, and yellow shading shows how the emissions diffused over a wider area.
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          Google
                          
                          </span>
                              </span>
                          </figure>
                        <h2><strong>Global methane pledges&nbsp;</strong></h2><p>The satellite launch comes as countries and oil and gas companies aim to drastically reduce methane emissions by 2030 to tackle the climate crisis.</p><p>During the UN climate summit in Dubai last year, companies accounting for 40% of global oil and gas production promised to nearly eliminate methane leaks from their own operations this decade. At least 155 countries have also signed the Global Methane Pledge, which calls for a 30% reduction in emissions. The pledge was launched in 2021, but since then, <a target="_blank" href="https://www.iea.org/reports/global-methane-tracker-2023" data-analytics-product-module="body_link" rel=" nofollow">methane emissions have continued to rise</a>.</p><p>To help change that trajectory, the US and Europe last year issued regulations cracking down on methane emissions from fossil-fuel infrastructure. The <a target="_blank" href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_5776" data-analytics-product-module="body_link" rel=" nofollow"><u>European Union's rules</u></a> went a step further by targeting oil and gas imports. Europe imports about 80% of its energy, including from the US. By 2027, those imports are expected to meet methane-emissions standards on par with Europe's.</p><!-- Excluded mobile ad on desktop --><p>Hamburg said Japan and South Korea, both of which rely on energy imports, were looking at similar laws.&nbsp;</p><p>"This means methane is becoming a competitive challenge for the industry, not just a regulatory one," he said. "Achieving real results means that the government, civil society, and industry need to know how much methane is coming from where, who is responsible for those emissions, and how those emissions are changing over time. We need the data on a global scale."</p><p>Maguire said Google planned to make the data available free for the public on Google Earth Engine later this year.</p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Indian government moves to ban ProtonMail after bomb threat (221 pts)]]></title>
            <link>https://www.androidcentral.com/apps-software/indian-government-moves-to-ban-protonmail-after-bomb-threat</link>
            <guid>39381435</guid>
            <pubDate>Thu, 15 Feb 2024 11:24:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.androidcentral.com/apps-software/indian-government-moves-to-ban-protonmail-after-bomb-threat">https://www.androidcentral.com/apps-software/indian-government-moves-to-ban-protonmail-after-bomb-threat</a>, See on <a href="https://news.ycombinator.com/item?id=39381435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="ProtonMail login page" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg"><source type="image/jpeg" alt="ProtonMail login page" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg"><img src="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-320-80.jpg" alt="ProtonMail login page" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/pSjJyAc6kTaKirPi8YxwFA.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Harish Jonnalagadda / Android Central)</span>
</figcaption>
</div>

<div id="article-body">
<h2 id="what-you-need-to-know-3">What you need to know</h2><ul><li>The Indian government's Information Technology ministry issued an order to block ProtonMail in the region.</li><li>The move comes after a bomb threat was sent to schools in Chennai via a ProtonMail account.</li><li>ProtonMail is still active in the country as of writing, but it remains to be seen if that will continue to be the case.</li></ul><hr><p><a data-analytics-id="inline-link" href="https://www.androidcentral.com/best-privacy-apps-android" data-before-rewrite-localise="https://www.androidcentral.com/best-privacy-apps-android">ProtonMail</a> is the best choice if you want an end-to-end encrypted email platform, and the nature of the service means it is inevitably used by bad actors. On February 8, a bomb threat was sent to 13 schools in Chennai, a city in the state of Tamil Nadu in southern India. The threat turned out to be a hoax, and the Tamil Nadu police found that the email was sent via a ProtonMail account.</p><p>Unable to trace the IP address of the sender and failing to get assistance from Interpol, the Tamil Nadu police put in a request to India's Ministry of Electronics and Information Technology to block access to ProtonMail within the country, <a data-analytics-id="inline-link" href="https://www.hindustantimes.com/india-news/it-ministry-looks-to-block-proton-mail-on-request-of-tamil-nadu-police-101707938167006.html" data-url="https://www.hindustantimes.com/india-news/it-ministry-looks-to-block-proton-mail-on-request-of-tamil-nadu-police-101707938167006.html">according to </a><a data-analytics-id="inline-link" href="https://www.hindustantimes.com/india-news/it-ministry-looks-to-block-proton-mail-on-request-of-tamil-nadu-police-101707938167006.html" data-url="https://www.hindustantimes.com/india-news/it-ministry-looks-to-block-proton-mail-on-request-of-tamil-nadu-police-101707938167006.html">Hindustan Times</a>. That request was granted today, with the government authority issuing an order to block the service in the region.</p><p>The enforcement will be carried out by the Department of Telecommunications, which will likely entail delisting ProtonMail from the App Store and Play Store. That said, the website is still working as of writing, and the app is listed on both storefronts. This isn't the first instance where the Indian government went after the Swiss-based Proton AG. Proton VPN <a data-analytics-id="inline-link" href="https://go.getproton.me/aff_c?offer_id=25&amp;aff_id=1046&amp;source=ac&amp;aff_click_id=ac-us-7827349702094175000&amp;url=https%3A%2F%2Fprotonvpn.com%2Fblog%2Fservers-india%2F%3FvisitorId%3Dho-%7Btransaction_id%7D%26aid%3D%7Baffiliate_id%7D%26offer_id%3D%7Boffer_id%7D%26url_id%3D%7Boffer_url_id%7D%26utm_campaign%3Dww-all-2a-vpn-gro_aff-g_acq-partners_program%26utm_medium%3Dlink%26utm_source%3Daid-tune-%7Baffiliate_id%7D%26utm_content%3D%7Boffer_id%7D%26hfp%3Dfalse%26spl%3D%7Baffiliate_id%7D&amp;aff_sub2=https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Findian-government-moves-to-ban-protonmail-after-bomb-threat" data-url="https://protonvpn.com/blog/servers-india/" target="_blank" data-hl-processed="hawklinks" data-placeholder-url="https://go.getproton.me/aff_c?offer_id=25&amp;aff_id=1046&amp;source=ac&amp;aff_click_id=hawk-custom-tracking&amp;url=https%3A%2F%2Fprotonvpn.com%2Fblog%2Fservers-india%2F%3FvisitorId%3Dho-%7Btransaction_id%7D%26aid%3D%7Baffiliate_id%7D%26offer_id%3D%7Boffer_id%7D%26url_id%3D%7Boffer_url_id%7D%26utm_campaign%3Dww-all-2a-vpn-gro_aff-g_acq-partners_program%26utm_medium%3Dlink%26utm_source%3Daid-tune-%7Baffiliate_id%7D%26utm_content%3D%7Boffer_id%7D%26hfp%3Dfalse%26spl%3D%7Baffiliate_id%7D&amp;aff_sub2=hawk-article-url" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="protonvpn.com" data-merchant-id="208252" data-merchant-url="protonvpn.com" data-merchant-network="HasOffers">pulled its servers out of the country</a> following a controversial 2022 ruling by the Indian government mandating providers to maintain usage logs.</p><p>As for the ProtonMail ban, Proton AG sent a statement to Hindustan Times that it was working with the government over the issue. "We are currently working to resolve this situation and are investigating how we can best work together with the Indian authorities to do so. We understand the urgency of the situation and are completely clear that our services are not to be used for illegal purposes. We routinely remove users who are found to be doing so and are willing to cooperate wherever possible within international cooperation agreements."</p><p>The government's move is in line with a recent policy that has targeted services with end-to-end encryption. A host of encrypted apps were blocked at the start of last year — including the likes of Threema, Element, Wickrme, and Safeswiss — and the government is going after <a data-analytics-id="inline-link" href="https://www.deccanherald.com/technology/gadgets/govt-may-enforce-it-rules-on-whatsapp-to-reveal-id-of-fake-video-spreader-2728346" data-url="https://www.deccanherald.com/technology/gadgets/govt-may-enforce-it-rules-on-whatsapp-to-reveal-id-of-fake-video-spreader-2728346">WhatsApp to disable end-to-end encryption</a>, although it isn't clear how that would even work.</p><p>Proton AG clearly agrees with that sentiment, as it said this to HT: "We condemn a potential block as a misguided measure that only serves to harm ordinary people. Blocking access to Proton is an ineffective and inappropriate response to the reported threats. It will not prevent cybercriminals from sending threats with another email service and will not be effective if the perpetrators are located outside of India."</p><p>I'll share an update once there are more details, but if you use ProtonMail in India, there's a good chance that the service may be inaccessible.</p>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-Zg6cZvFo6JVkQ4xkNfLhMD"><section><p>Get the latest news from Android Central, your trusted companion in the world of Android</p></section></div>
<div id="slice-container-authorBio-Zg6cZvFo6JVkQ4xkNfLhMD"><p>Harish Jonnalagadda is a Senior Editor overseeing Asia at Android Central. He leads the site's coverage of Chinese phone brands, contributing to reviews, features, and buying guides. He also writes about storage servers, audio products, and the semiconductor industry. Contact him on Twitter at <a href="https://twitter.com/chunkynerd">@chunkynerd</a>.</p></div>



</section>




<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>









</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[British intelligence able to read and flag private Snapchat messages (165 pts)]]></title>
            <link>https://www.reuters.com/world/europe/spanish-judge-clears-british-teen-menorca-flight-bomb-hoax-charges-2024-01-25/</link>
            <guid>39381390</guid>
            <pubDate>Thu, 15 Feb 2024 11:17:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/europe/spanish-judge-clears-british-teen-menorca-flight-bomb-hoax-charges-2024-01-25/">https://www.reuters.com/world/europe/spanish-judge-clears-british-teen-menorca-flight-bomb-hoax-charges-2024-01-25/</a>, See on <a href="https://news.ycombinator.com/item?id=39381390">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/europe/spanish-judge-clears-british-teen-menorca-flight-bomb-hoax-charges-2024-01-25/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Goodbye Auth0 (211 pts)]]></title>
            <link>https://www.joshcanhelp.com/goodbye-auth0/</link>
            <guid>39380790</guid>
            <pubDate>Thu, 15 Feb 2024 09:45:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.joshcanhelp.com/goodbye-auth0/">https://www.joshcanhelp.com/goodbye-auth0/</a>, See on <a href="https://news.ycombinator.com/item?id=39380790">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Last Thursday, I woke up to a pile of emails that I was, in truth, half expecting. They were all worded a bit differently and came from different senders but the message was the same:</p><blockquote><p>Today, Okta made the decision to eliminate a number of positions across multiple organizations.&nbsp;<strong>Unfortunately, your position has been eliminated as part of this reduction.</strong></p></blockquote><p>Things had been a little strange at work since the end of last year: unclear priorities for our group, an awkward reorganization, rumblings that <em>something</em> was going on. All of that contributed to a surge of professional anxiety and a sudden urge to make sure I had all my digital affairs in order.</p><p>And then it happened, I got the email. Slack didn't work. My laptop restarted and came back with accounts missing. It really, actually happened. And even though the writing seemed to be on the wall, I was still caught a bit off guard. What about that high-priority project I was helping to lead? What about the training I was scheduled to deliver? What about the offsite next month?</p><p>I wasn't totally sure what to do with myself so I tried to follow the instructions that were sent to me to log into the minimal number of apps I still had access to for the rest of the day. I found a few groups of former (or were they still current?) teammates collecting on Google Chat, Slack groups, and LinkedIn, everyone exchanging personal contact information and messages of support. I walked the dog and said "I can't believe it actually happened" to my wife several times.</p><p>By the end of the day, my phone was at record levels of screen time logged and I was exhausted from doing what probably looked like next to nothing but I felt ... OK. I had spent all day reading and responding to deluge of <a href="https://www.linkedin.com/posts/joshcanhelp_i-joined-the-layoff-club-this-morning-after-activity-7158890419303444480-ueBL">support, kind words, and offers to help on LinkedIn</a> and was told that the severance offered would give me at least a few months free from acute financial stress. I already made plans to see some former teammates, friends, and family in the next week. Things were going to be just fine.</p><p>I don't think there's any reason for me to dwell on the how and why these layoffs happened. There were reasons, some I was told and some I can guess. What I want to remember as I move on from the last 6 years was how it all started, what Auth0 meant to me, and why I will proudly wear that shield for as long as the hats, shirts, and socks hold up.</p><img src="https://www.joshcanhelp.com/_images/2024/auth0_swag.jpg" alt="Auth0 swag"><figcaption><em><p>I'm sure I'm missing something ...</p></em></figcaption><p>My journey with Auth0 started in January of 2018 working on SDKs, open source libraries that customers use to make integrating their applications with Auth0, hopefully, a bit easier. I was sent the job listing by a fellow preschool dad who thought I would be a good fit. The company culture sounded good (but who can trust that stuff), working in open source sounded fun (but maybe it's just a slog of support requests), and the security/authentication space felt like the challenge I was looking for (but could I hack it). I applied, made it through the interview and take-home project, and got an offer. I accepted and started my first W2 job in 4 years.</p><p>The SDKs team was scrappy, totally overloaded, and somewhat of an island in Auth0 engineering. We were mostly left to our own devices to manage somewhere around <a href="https://auth0.com/docs/libraries">60 open source libraries</a> with only 4 engineers. I scrambled to learn about OpenID Connect and OAuth 2 while figuring out what, exactly, the WordPress setup wizard was doing. I learned Laravel for the 3rd time, tried to dig back up what I remembered about Drupal, and squinted my eyes at Symphony code over and over. I dove into Ruby because I had gone through a tutorial a few years ago and remembered liking it. All the while I was being exposed to engineering concepts that just weren't a thing in agency work: <a href="https://www.joshcanhelp.com/wordpress-unit-testing-techniques/">unit testing</a>, CI/CD, git hygiene, release management.</p><p><a href="https://www.joshcanhelp.com/pitfalls-of-being-a-wordpress-developer/">I wrote a post that year</a> that would have been confusing to me the year before. The amount of things I learned during my time there is hard to wrap my head around, even having been through it myself. I was surrounded by smart, talented people in a safe, growth-minded workplace. There was chaos and uncertainty but everywhere you looked there were people doing the best work of their career trying to get this cool thing off the ground.</p><p>That "Auth0 feeling" was made tangible on the first offsite I went to in Panama City. Everyone around me told me that it would be amazing and I would have a great time. I was, to be honest, a bit skeptical. I'm not typically a company kool-aid drinker and I was expecting a lot of eye roll moments. I was, thankfully, completely surprised.</p><img src="https://www.joshcanhelp.com/_images/2024/auth0_panama_2018.jpg" alt="Auth0 Panama offsite 2018"><p>There was something truly special about what happened during that offsite. You felt like a part of something, like you were contributing to something singular and unique. There was talk of growth and ARR and everything else but the passion that everyone had to do this to the best of their abilities was clear in almost every conversation you had. And it wasn't obsession or fanaticism, it was confidence and excitement combined with camaraderie and just genuine good vibes. You were accepted here, regardless of where you came from in your career and in the world. Just give us your best and we'll use it.</p><p>I was caught up in the feeling but my own internal stuff was looming large. I wrote this journal entry while I was there:</p><blockquote><p>I'm in Panama, building a raspberry pi to pull data from secure internal sources and display to everyone in the company. Imposer syndrome in full effect at the moment ... right up until I stop thinking about it and just collaborate with someone. If I lose myself in the work at hand, that's where I become valuable, focused, and productive.</p></blockquote><p>I can remember this precise feeling, trying to write Node.js code in vim in a terminal connected to this misbehaving little gadget. I was quaking inside, feeling like someone would call me out. But that never happened and I doubled down on learning and growing from that point on. The excitement I felt leaving Panama was like nothing I had ever felt in my professional life.</p><p>After a year (that felt like 3), I was approached to be a part of the technical onboarding program that happened monthly in Bellevue. <a href="https://www.joshcanhelp.com/vittorio/">I wrote about that experience recently</a> and, when I look back on that time, I remember being so humbled and proud of where I worked as I met all the incredible people that came through. Once I got my footing as an instructor, I felt like a critical part of creating the culture at Auth0. I got to meet about half of all the new hires for a year or so and was a part of them learning the product and digital identity. Everyone would work through 4 technical labs, each one hour long, and it was so rewarding to see folks try and fail and try something else and ask a neighbor and ask me and then get it working. We gave them a safe space to try something totally new right away and just about everyone walked away with something positive. Just writing these words gives me warm, fuzzy feelings ...</p><img src="https://www.joshcanhelp.com/_images/2024/auth0_bellevue_shark.jpg" alt="Auth0 shark"><figcaption><em><p>My son called the Bellevue office "Dad's Bellevue" and both kids loved the snacks that came back with me.</p></em></figcaption><p>The offsite that year in Los Cabos was just like the one the year before but even better. I knew many more people because of the onboarding and we were larger and more established. We also heard the news that Auth0 had completed a funding round and was now, based on factors I only partially understood, worth over a billion dollars. And this was all well and good but it meant so much more to everyone that was had been a part of it. We had put in our best work, side-by-side with wonderful people from around the world, led by two kind and brilliant Argentinians, <strong>and it was working</strong>! There was no pressure to work long hours (even though some of us did because we felt like it) and there was no manufactured pressure around launch dates. We figured out what worked for us, it was paying off, and it felt like we were just getting started.</p><p>In the beginning of 2020, <a href="https://www.joshcanhelp.com/moment-in-time-during-pandemic/">something huge happened in the world</a> but, being a "modern" adult with kids, I worked right on through it. I helped convert the onboarding to virtual instead of in-person, transitioned out of the SDKs team, and onboarded as the second person on the <a href="https://marketplace.auth0.com/">Marketplace</a> team. As a part of transition, I worked on a <a href="https://github.com/auth0/wordpress/security/advisories/GHSA-59vf-cgfw-6h6v">high-severity CVE</a> that resulted in a <a href="https://github.com/auth0/wordpress/releases/tag/4.0.0">huge major release for a popular SDK</a> that I maintained. If this happened anywhere else, I might have been too embarrassed to link to that here and, at the time, I was mortified to be a part of such a critical issue caused by a misconfigured code analyzer. At every point during the process, though, the security team was so kind, so gracious, and made it clear that issues like these were the result of process failures, not individuals. Just when I felt like I should have been hauled into involuntary security training for a month, I was surrounded by supportive folks who helped get the fixes out as soon as possible and <em>even praised me for my work</em> during that release. I learned something about a blame-free culture that I will carry with me to the end of my professional life.</p><p>That Auth0 spirit, the feeling that you were a part of something, was on full display throughout the pandemic. Our family had some <a href="https://www.joshcanhelp.com/how-we-are-teaching-right-now/">major challenges</a> with two young kids at home and two working parents. My wife and I would switch off on shifts: one person worked from 6AM to noon and the other noon to 6PM, with the other handling the house and the kids. Both of us, exhausted, would convene on the couch at night with our laptops, trying to eke out another hour of productivity, breath held that it would all be over soon.</p><img src="https://www.joshcanhelp.com/_images/2024/pandemic_yolo.jpg" alt="Pandemic YOLO"><figcaption><em><p>Not actually, no.</p></em></figcaption><p>But, once it was clear that we were in it for the long haul, the message at Auth0 was, sincerely, don't make life harder by trying to do more than you can do. The message was clear from the CEO down: take care of your family, do what you can do, don't burn yourself out. We adjusted due dates, spent time on meetings checking in with each other, and just made it through. I've said to many people since then: I would have been voluntarily unemployed very quickly without that support.</p><p>We were <s>12 years</s> 18 months into the pandemic and my tenure on the Marketplace team when I got the shocking news about <a href="https://www.okta.com/press-room/press-releases/okta-signs-agreement-to-acquire-auth0/">The Acquisition</a>. One of our main competitors, Okta, had acquired us for $6.5B dollars and we would trade in our fiery Auth0 orange for the more staid Okta blue. I wasn't sure exactly what to think. I was happy that my stock options would be worth something but that meant less than the thought of the Auth0 spirit fading away. We've all heard the stories about the small and spunky startup being acquired and slowly being dissolved into the larger entity.</p><p>But, the fact is, I didn't want to leave right away and I had faith that Auth0 would still live on, in some form, even under the umbrella of larger corporate entity. I had faith in the people that started the company and the people that were a part of building it to what it had become.</p><p>I spent another 18 months on Marketplace working with my teammates and partners to design and build integrations into our platform. We were flying by the seat of our pants a lot of the time but, as always, the people around me and the work we were doing kept me motivated. In the summer of 2022, however, <a href="https://www.joshcanhelp.com/stroke/">another catastrophe struck my family</a> and I was, yet again, unable to do much beyond handle the situation in front of me. I was, once again, surrounded by teammates, a new manager, and a new director, all of whom told me in no uncertain terms: take care of your people and we'll handle it at work. This was over a year after The Acquisition and that support was the same as it had always been. I returned after several months of family leave and jumped right back in, truly excited to have a distraction in the form of writing code.</p><p>At the beginning of last year, I made what would be my last team change at the company. I was working with some true veterans with as many or more years in the company than I had. I loved the team and liked the work but something was missing and it didn’t really occur to me until I wrote the bulk of this post: the Auth0 story had been told, the ending was revealed, the future was written. The question of whether we would IPO or stay private forever or get acquired and by what company was no longer a question. We were “Auth0 by Okta,” soon to be known only as “Okta CIC.” There was work to be done and still big hills to climb but the original book is closed and on the shelf. In a world full of companies, we were one of the few that made it and it happened because of the heart and soul and blood and sweat we put into it.</p><p>I will forever be grateful to the two incredible individuals who started Auth0, Eugenio Pace and Matias Woloski, along with all the impossibly talented humans I worked with and learned from over the last 6 years. I feel like I accomplished a decade of professional growth during that time and learned an enormous amount about what it means to build and run a people-first company.</p><p><img src="https://www.joshcanhelp.com/_images/2024/auth0_values.png" alt=""></p><p>So, what’s next for me? I have a few frogs to swallow first (taxes, 2024 budget, resume and LinkedIn updates) the I plan to spend the next 2-3 months writing all the posts I’ve been meaning to write for the last year (commit log) and working on my two main open source projects. I also have a bike race coming up that I need to train for and two kids that might let me hang out with them more!</p><h2 id="take-action"><span>&lt;</span> Take Action <span>&gt;</span></h2><p><a href="https://github.com/joshcanhelp/josh-to-11/edit/master/input/symlinked/posts/2024/2024-02-09-goodbye-auth0.md" target="_blank" rel="noreferrer noopener">Suggest changes on GitHub ›</a></p><h6><span>Comment via:</span></h6><p><a href="mailto:josh@joshcanhelp.com?subject=Comment%20on%20/goodbye-auth0/">Email ›</a> <a href="https://github.com/joshcanhelp/josh-to-11/issues/new?template=comment.md&amp;title=Comment%20on%20/goodbye-auth0/&amp;body=%E2%9D%A4%EF%B8%8F%20Thank%20you%20for%20your%20feedback!%20%E2%9D%A4%EF%B8%8F%0A%0A%23%23%20What%20would%20you%20like%20to%20say%3F%0A%0A">GitHub ›</a></p><h6><span>Subscribe via:</span></h6><h2 id="read-more"><span>&lt;</span> Read More <span>&gt;</span></h2><h6><span>Tags</span></h6><h6><span>Older</span></h6><div><p><a href="https://www.joshcanhelp.com/vittorio/"><img src="https://www.joshcanhelp.com/_images/2024/vittorio_identiverse.png"></a></p><p><span>Jan 21, 2024</span></p><h2><a href="https://www.joshcanhelp.com/vittorio/">Goodbye, Vittorio Bertocci</a></h2><p>Vittorio Bertocci passed on October 7th, 2023. He had a major impact on me and I wanted to write a few words in his honor.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI – Application for US trademark "GPT" has failed (549 pts)]]></title>
            <link>https://tsdr.uspto.gov/documentviewer?caseId=sn97733259&amp;docId=FREF20240206125856&amp;linkId=1#docIndex=0&amp;page=1</link>
            <guid>39380165</guid>
            <pubDate>Thu, 15 Feb 2024 07:52:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tsdr.uspto.gov/documentviewer?caseId=sn97733259&#x26;docId=FREF20240206125856&#x26;linkId=1#docIndex=0&#x26;page=1">https://tsdr.uspto.gov/documentviewer?caseId=sn97733259&#x26;docId=FREF20240206125856&#x26;linkId=1#docIndex=0&#x26;page=1</a>, See on <a href="https://news.ycombinator.com/item?id=39380165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
         <p>Select a document to display ...</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse engineering a forgotten 1970s Intel dual core beast: 8271 (2020) (107 pts)]]></title>
            <link>https://scarybeastsecurity.blogspot.com/2020/11/reverse-engineering-forgotten-1970s.html</link>
            <guid>39379480</guid>
            <pubDate>Thu, 15 Feb 2024 05:35:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scarybeastsecurity.blogspot.com/2020/11/reverse-engineering-forgotten-1970s.html">https://scarybeastsecurity.blogspot.com/2020/11/reverse-engineering-forgotten-1970s.html</a>, See on <a href="https://news.ycombinator.com/item?id=39379480">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-8807496949986478566" itemprop="description articleBody">
<p><a href="https://1.bp.blogspot.com/-BAxgZgYqEm0/X6hp_uyJdjI/AAAAAAAAzM8/RdX_oVoeX8cYYuwPCwSyvt9gxGFAsD_7QCLcBGAsYHQ/s2444/intel1978.jpg"><img data-original-height="330" data-original-width="2444" height="86" src="https://1.bp.blogspot.com/-BAxgZgYqEm0/X6hp_uyJdjI/AAAAAAAAzM8/RdX_oVoeX8cYYuwPCwSyvt9gxGFAsD_7QCLcBGAsYHQ/w640-h86/intel1978.jpg" width="640"></a></p><p>"<b>As I recall, those two chips were fairly large. And fairly late -- to the marketplace. We had lots of issues with them. [...] Sometimes the elegant solution isn't the best solution.</b>" -- Dave House, digressing to the 8271 during "Oral History Panel on the Development and Promotion of the Intel 8080 Microprocessor" [<a href="http://archive.computerhistory.org/resources/text/Oral_History/Intel_8080/102658123.05.01.pdf" target="_blank">link</a>], April 26th 2007, Computer History Museum, Mountain View, California.</p><h2>Introduction</h2><p>Around 1977, Intel released a floppy disc controller (FDC) chip called the 8271. This controller isn't particularly well known. It was mainly used in business computers and storage solutions, but its one breakthrough into the consumer space was with the <a href="https://en.wikipedia.org/wiki/BBC_Micro" target="_blank">BBC Micro</a>, a UK-centric computer released in 1981.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Nc7F7ELiKcg/X6tty3pLYaI/AAAAAAAAzOM/gAxepoBzq3ANNtsZPbgm7mhWZ--cUEA4gCLcBGAsYHQ/s267/i8271.png"><img data-original-height="267" data-original-width="234" src="https://1.bp.blogspot.com/-Nc7F7ELiKcg/X6tty3pLYaI/AAAAAAAAzOM/gAxepoBzq3ANNtsZPbgm7mhWZ--cUEA4gCLcBGAsYHQ/s0/i8271.png"></a></td></tr><tr><td>Intel 8271 (left) in an issue 3 BBC Micro model B</td></tr></tbody></table><p>There are very few easily discovered details about this chip online, aside from the useful <a href="http://www.nj7p.org/Manuals/PDFs/Intel/AFN-00223B.pdf" target="_blank">datasheet</a>. This, combined with increasing observations of strange behavior, make the chip a bit of an enigma. My interest in the chip was piqued when I accidentally triggered a wild test mode that managed to corrupt one of my floppy discs even though the write protect tab was present! You can read about that here:</p><p><a href="https://scarybeastsecurity.blogspot.com/2020/06/a-wild-bug-1970s-intel-8271-disc-chip.html" target="_blank">A wild bug: 1970s Intel 8271 disc chip ate my data!</a></p><p>Can we reverse engineer a detailed understanding of how it works? What wonders will we find?</p><h2>Credits</h2><p>The work described here represents the efforts of a virtual team that came together in an impromptu way to investigate the chip. There are many critical players, and special thanks go to:</p><ul><li><b>Nigel Barnes</b>. Bridged the MAME community and BBC Micro community, locating someone with chip decapping skills.</li><li><b>BeebMaster</b>. Provided a couple of sacrificial 8271 chips for decapping.</li><li><b>Sean Riddle</b>. Decapped the chips and provided beautiful hi-resolution images.</li><li><b>ZXGuesser</b>, <b>Diminished</b>. Hardware level reverse engineering, including accurate extraction of ROM bits.</li><li><b>Ken Shirriff</b>. Provided notes on silicon macro structures, and located historic documents of great utility.</li><li><b>Rich Talbot-Watkins</b>, <b>Chris Evans</b> (me). Calculating the ISA, disassembling the ROM.</li></ul><h2>The beauty of the beast: recap and decap</h2><p>So to recap: we had a few indicators that this could be a very interesting chip. These range from the crazy test mode we found above, to the fact the data sheet hints at a large number of internal registers, with only a few documented.</p><p>And, to decap:</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-zP3yJ1Fyrag/X6iQ3qpDr7I/AAAAAAAAzNI/Gv7Bfc5Y3L8hrUK9S-zJAGM8FZCBsuoQACLcBGAsYHQ/s1024/8271-6metal_1024px.jpg"><img data-original-height="914" data-original-width="1024" height="573" src="https://1.bp.blogspot.com/-zP3yJ1Fyrag/X6iQ3qpDr7I/AAAAAAAAzNI/Gv7Bfc5Y3L8hrUK9S-zJAGM8FZCBsuoQACLcBGAsYHQ/w640-h573/8271-6metal_1024px.jpg" width="640"></a></td></tr><tr><td>(See references at the end for very high resolution shots)</td></tr></tbody></table><p>This a complicated chip for an FDC! There are a large number of large structures present, densely packed. To illustrate the point, we can compare this chip with the heart of the BBC Micro -- a venerable, legendary 6502, as used in iconic 80s machines and consoles such as the Apple ][, Commodore 64 and NES:</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-w4_B4zG9xas/X6svWXOnACI/AAAAAAAAzNo/0hVy9qt_YZ8Uln1GyVbRg8p0Lp_YrWh7ACLcBGAsYHQ/s1024/8271_and_6502.png"><img data-original-height="457" data-original-width="1024" height="286" src="https://1.bp.blogspot.com/-w4_B4zG9xas/X6svWXOnACI/AAAAAAAAzNo/0hVy9qt_YZ8Uln1GyVbRg8p0Lp_YrWh7ACLcBGAsYHQ/w640-h286/8271_and_6502.png" width="640"></a></td></tr><tr><td>8271 left, 6502 right</td></tr></tbody></table><p>Not only is the 8271 larger than the main CPU by a significant amount, it also cost more by all accounts:</p><blockquote><p><i>"In Acorn's wisdom, they had chosen the Intel 8271 disk controller for the BBC Micro - this controller was probably obsolete even before the BBC Micro was launched. The Acorn disk upgrade comprised the 8271, a handful of standard TTL ICs, an Acorn DFS ROM, and the disk manual. The ICs plugged into unpopulated sockets on the motherboard.</i></p><p><i>A few hardy folks tried sourcing the parts separately - which was fine, except that an 8271 tended to cost about £109 on its own, </i>if<i> you could find one..."</i>&nbsp;-- [<a href="http://www.adsb.co.uk/bbc/disk_controllers/" target="_blank">source link</a>]</p></blockquote><p>By contrast, the 6502 <a href="https://retrocomputing.stackexchange.com/questions/2760/how-much-did-the-6502-and-z80-cost" target="_blank">allegedly cost around $7.45 in 1981</a>, which is a huge difference factor.</p><h3>Getting the ROM bits</h3><p>From a quick eyeball of the 8271 die, there are plenty of PLA-like structures, but perhaps most promisingly, a large rectangle of ROM in the lower left. Right away, we're thinking that this <i>could indeed</i>&nbsp;be a general purpose microcontroller CPU if there's a ROM program. Initial focus fell immediately to extracting the ROM.</p><p>ZXGuesser and Diminished put in a Herculean effort, transcribing the ROM bits first by hand and later with some tooling assist and cross-checking. In case you're wondering what transcribing ROM bits by hand looks like, it looks a little like this:</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-9Ub0YUPQ-Zk/X6s95IqdlOI/AAAAAAAAzN0/lXgPhiDKKpQmTXTwVmSCp4enXfiILQcigCLcBGAsYHQ/s1024/8271_partial_annotated_rom.png"><img data-original-height="768" data-original-width="1024" height="480" src="https://1.bp.blogspot.com/-9Ub0YUPQ-Zk/X6s95IqdlOI/AAAAAAAAzN0/lXgPhiDKKpQmTXTwVmSCp4enXfiILQcigCLcBGAsYHQ/w640-h480/8271_partial_annotated_rom.png" width="640"></a></td></tr><tr><td>Look closely; those cyan annotations are 0s and 1s!</td></tr></tbody></table><p>The ROM matrix is 64x108 bit cells, for a ROM size of 864 bytes.</p><p>Once you've gotten the ROM bits, you still have the challenge of assembling them together into a correctly sequenced byte stream. This isn't always as easy as you might think, and is particularly rough when you don't have a reliable way of telling if the extracted bytes are ok, as is the case here. During my research, I found:</p><ul><li><a href="http://adamsblog.rfidiot.org/2013/01/fun-with-masked-roms.html" target="_blank">Two 8-bit bytes interleaved</a>.</li><li><a href="https://seanriddle.com/psu.html" target="_blank">Bits and bytes heavily interleaved in a Channel F game cartridge</a>.</li><li><a href="http://caps0ff.blogspot.com/2020/11/the-elusive-tms32010-mask-rom.html" target="_blank">Byte ordering permuted fairly arbitrarily -- obfuscation?</a></li></ul><p>Fortunately, the ROM reversers also looked at the row and column circuitry connecting the ROM, and gave a fairly robust opinion that the ROM bits / bytes are:</p><ul><li>Left-to-right, top-to-bottom.</li><li>Bits inverted relative to the initial decode in the image above.</li><li>Bits MSB first.</li><li>Bytes build from 1 bit per linear 8 bit group.</li></ul><p>This gives the first bytes of the ROM as the following:</p><p><a href="https://1.bp.blogspot.com/-LOclFa5WPl8/X6tamrsG8dI/AAAAAAAAzOA/Thts9MEvrOkYOrjdJ3JjW8TyarKijpJKgCLcBGAsYHQ/s482/8271_rom_first_bytes.png"><img data-original-height="16" data-original-width="482" height="22" src="https://1.bp.blogspot.com/-LOclFa5WPl8/X6tamrsG8dI/AAAAAAAAzOA/Thts9MEvrOkYOrjdJ3JjW8TyarKijpJKgCLcBGAsYHQ/w640-h22/8271_rom_first_bytes.png" width="640"></a></p><p>This happens to be a correct decode, although we couldn't be sure for some time.</p><h3>Architecture hints</h3><p>As Rich and myself engaged in efforts to try and disassemble the ROM, without any prior knowledge of the Instruction Set Architecture (ISA), I was fortunate enough to have a conversation with Ken Shirriff (<a href="http://righto.com/">righto.com</a>) about this interesting chip. Against all odds, he found a detailed conference presentation abstract from 1977 [<a href="https://drive.google.com/file/d/1B2gUpavFpVP_s45A4cH6JKaI1A3O3t7T/view" target="_blank">link to copy of full abstract</a>].</p><p>This image from the abstract, will look familiar (imagine +90 degrees rotated).</p><p><a href="https://1.bp.blogspot.com/-ATqW73uACls/X6uJuQXQ63I/AAAAAAAAzOY/OBNhopVpNDgJEn2sgs8qCD-DFqh2AK0wQCLcBGAsYHQ/s642/8271_photomicrograph.png"><img data-original-height="642" data-original-width="576" height="320" src="https://1.bp.blogspot.com/-ATqW73uACls/X6uJuQXQ63I/AAAAAAAAzOY/OBNhopVpNDgJEn2sgs8qCD-DFqh2AK0wQCLcBGAsYHQ/s320/8271_photomicrograph.png"></a></p><p>The rest of the abstract is a gold mine. The presentation was titled "A Dual Processor Serial Data Controller Chip" and begins:</p><blockquote><p><i>"A DUAL PROCESSOR microprogrammable chip that implements a specialized architecture for high-speed serial data controllers will be described. The chip measures 218 mils by 244 mils and contains 22,000 transistors..."</i></p></blockquote><p><b>22,000 transistors</b>!! We knew this was a bit of a chonker, but for reference, the 6502 has 3,218 transistors; the 8080 6,000 transistors and the 8086 29,000 transistors. Yes, the 8271 is not that far off an 8086 in terms of transistor count.</p><p>This instructive table and diagram are also from the abstract:</p><p><a href="https://1.bp.blogspot.com/-e-V92zQW5w8/X6uOwAizXPI/AAAAAAAAzOk/NgDJ13X_NE0rdlyyZBAhKjeo1bqUtNUxQCLcBGAsYHQ/s728/8271_bit_byte_summary.png"><img data-original-height="244" data-original-width="728" height="214" src="https://1.bp.blogspot.com/-e-V92zQW5w8/X6uOwAizXPI/AAAAAAAAzOk/NgDJ13X_NE0rdlyyZBAhKjeo1bqUtNUxQCLcBGAsYHQ/w640-h214/8271_bit_byte_summary.png" width="640"></a></p><p>This confirms our suspicions that we <i>are</i> dealing with a general purpose CPU, coupled with some acceleration for I/O. The general purpose CPU has the features you'd expect, including a PC, stack, ALU, accumulator, registers, and access to a bus. Further detail in the abstract includes "32 eight-bit registers" and "four-level stack".</p><p>The presence of a a bit processor (a co-processor if you like) with 250ns cycle time resolves the elephant in the room with the "general CPU" theory. A general CPU of the era probably wouldn't be fast enough to calculate CRC16 at the disc data rate. However, a specialized PLA-driven bit engine bolted on to the side will do just fine.</p><div><p>Finally on this abstract, we see that it states "To date, two distinct controllers have been microprogrammed: a floppy disk controller and a synchronous data link controller (SDLC)". Well, we've found the FDC, the 8271. Intel's SDLC from the era was the 8273. Enter Sean Riddle once more -- what a star -- and another sacrificed chip or two later, we have our result:</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-G9mwTNwiKdM/X6uSSexg3eI/AAAAAAAAzOw/wgCiIwdSRp88t36gyBXf8DBtm76id5HiQCLcBGAsYHQ/s1024/8271_and_8273.jpg"><img data-original-height="457" data-original-width="1024" height="286" src="https://1.bp.blogspot.com/-G9mwTNwiKdM/X6uSSexg3eI/AAAAAAAAzOw/wgCiIwdSRp88t36gyBXf8DBtm76id5HiQCLcBGAsYHQ/w640-h286/8271_and_8273.jpg" width="640"></a></td></tr><tr><td>8271 left, 8273 right</td></tr></tbody></table><p>Ken also found a patent relating to this dual core design! It's <a href="https://patents.google.com/patent/US4152761A/" target="_blank">US4152761</a>. [<a href="https://drive.google.com/file/d/1bnR9p-fwb82HZeQvJAIr_JM3Oebc8xrs/view" target="_blank">link to a more complete version</a>]. There's a lot of useful architectural detail in the patent, including this interesting summary of key components.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-DEWAzrvaRDU/X6uUYhi67JI/AAAAAAAAzO8/9AtRcmLVm5QeavKH3MlZd2iyQbN09wzwACLcBGAsYHQ/s728/patent_8271_diag.png"><img data-original-height="506" data-original-width="728" height="444" src="https://1.bp.blogspot.com/-DEWAzrvaRDU/X6uUYhi67JI/AAAAAAAAzO8/9AtRcmLVm5QeavKH3MlZd2iyQbN09wzwACLcBGAsYHQ/w640-h444/patent_8271_diag.png" width="640"></a></td></tr><tr><td>From US4,152,761</td></tr></tbody></table><p>As can be seen, there's additional complexity described here that falls outside what we'd expect from a traditional CPU. There's dispatcher requests, priority resolution, a "case" and an "address" register in addition to the program counter and instruction register. This relates to some form of scheduling, which we'll encounter later.</p><p>Finally, here's a diagram (courtesy of Ken). It's an early estimation of how the architecture we've seen in the the documents so far might map to the silicon. As a dual processor behemoth, note how there's two ALUs, two sets of registers, lots of PLAs (including a couple to the left and right of the "control" label), and plenty of patches of silicon with unknown function.</p><p><a href="https://1.bp.blogspot.com/-S8ZcdDBfcGc/X6uhKQ6CHKI/AAAAAAAAzPI/i5zleRTOnmM5_7lO5uy7WnYaWqlK035hwCLcBGAsYHQ/s924/image%2B%25283%2529.png"><img data-original-height="855" data-original-width="924" height="592" src="https://1.bp.blogspot.com/-S8ZcdDBfcGc/X6uhKQ6CHKI/AAAAAAAAzPI/i5zleRTOnmM5_7lO5uy7WnYaWqlK035hwCLcBGAsYHQ/w640-h592/image%2B%25283%2529.png" width="640"></a></p><h3>From bits to bytes to an Instruction Set Architecture (ISA)</h3><p>With an overview of the architecture, we have a better idea of what sort of opcodes we might find in the instruction set. The more pieces of the puzzle we have in our heads, the better chance we have of making abstract connections in our attempt to solve a problem with a lot of moving parts.</p><p>Initial attempts to disassemble the ROM centered around the theory that the CPU core might be based on the Intel <a href="https://en.wikipedia.org/wiki/Intel_MCS-48" target="_blank">MCS-48</a> microcontroller series. This series includes the well-known 8048 and has several variants such as the slightly cut-down 8020 (less I/O lines). And why wouldn't this core be based on a further cut-down 8020? It just fits too well: 1K ROM, 64 registers, 13 I/O lines. The timing works well too: the MCS-48 series first launched in 1976, making the core available before the release of the 8271. So the theory went, you'd be crazy as an 1970s Intel employee to not just walk down the corridor and raid the parts bin of your colleagues in order to get a headstart.</p><p>The MCS-48 theory turned out to fit extremely well.... but be false. No amount of ROM bit / byte wrangling led to sensible MCS-48 disassemblies.</p><p>Back to the drawing board, we looked again at our "probably correct" ROM decode and analyzed it for patterns we'd expect to find in an 8271 ROM, based on our understanding of how the controller works, and how disc recording works in general. Here's a section we found enlightening:</p><p><a href="https://1.bp.blogspot.com/-9rMUfFP7_QE/X6zWgUz8b5I/AAAAAAAAzPs/ADcU0WUZSHsVHMdPRkODzyhrtj57ulFjQCLcBGAsYHQ/s485/rom_hex_red_boxed.png"><img data-original-height="70" data-original-width="485" height="92" src="https://1.bp.blogspot.com/-9rMUfFP7_QE/X6zWgUz8b5I/AAAAAAAAzPs/ADcU0WUZSHsVHMdPRkODzyhrtj57ulFjQCLcBGAsYHQ/w640-h92/rom_hex_red_boxed.png" width="640"></a></p><p>Most significant is the appearance of the constants $FE + $C7 (middle box), then $E5 + $FF (lower box) in a the same context. These constants are the data byte + clocks byte we'd expect to see in the format routine for FM (single density) formatted discs. $FE + $C7 is the sector header marker, and $E5 + $FF is the default fill byte for freshly formatted sectors. As a bonus, we speculated that $E9 (appearing four times in a row) could be a shift left or right opcode, with $FD perhaps being RET. All in all, some strong circumstantial evidence for a correct decode.</p><p>After the MCS-48 opcode list failed to match our ROM, we spent a long time trying to derive an alternate instruction set.</p><p><b>But it's hard; it's a bit like one of those jigsaw puzzles where every piece is the exact same color. It's very hard to find a start as there are so many different possibilities to try. Research is too often presented as a neatly packaged result, with no mention of the struggle. I think this contributes to discouraging newcomers. So make no mistake: this was a struggle; it went on for some time; there was swearing; and the characteristics leading to success were perseverance and grit as opposed to any particular technical ability.</b></p><p>The breakthrough was catalyzed when the hardware investigations got a good read on the wiring and content of one of the instruction PLAs associated with the byte processor. The PLA in question is actually the darker rectangular block to the left of the "control" label in the image above. It is populated like this:</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-OsJtpbF68Ns/X6zfr6L18EI/AAAAAAAAzP4/SIgoMLXyvwU3C_jqi80L2BA7fwTGMTXpACLcBGAsYHQ/s557/left_instruction_table.jpg"><img data-original-height="202" data-original-width="557" height="145" src="https://1.bp.blogspot.com/-OsJtpbF68Ns/X6zfr6L18EI/AAAAAAAAzP4/SIgoMLXyvwU3C_jqi80L2BA7fwTGMTXpACLcBGAsYHQ/w400-h145/left_instruction_table.jpg" width="400"></a></td></tr><tr><td>Thanks to Diminished!</td></tr></tbody></table><p>With the instruction PLAs decoded, it would be possible to trace the effects of each 8-bit opcode by following activation lines to the registers, stack, ALU, etc. However, we were able to hit our breakthrough with only opcode ranges, provided by this PLA. Of specific interest is these ranges from Rich:</p></div><blockquote></blockquote><p>The specialized $FC and $FD match our theory of CALL and RET, but more pivotal is the range of $20-$3F, split into 2x 16 wide blocks. Immediately, I speculated this could be "move register to accumulator" and "move accumulator to register". This would turn out to be correct. Furthermore, I noted that opcode $0? was common before $2? or $3?, e.g.</p><blockquote><p><span>05D:&nbsp; &nbsp;04 22 03 35</span></p></blockquote><div><p>This led to the theory that these are register bank selection opcodes. Similar to the MCS-48, the theory is that there aren't enough opcodes for all operations to be able to reference all 32 registers, so there must be a bank select. This also would turn out to be correct. In fact, with these pieces, the jigsaw started to fall in place, and fall into place faster and faster.</p><h3>Some ROM code examples</h3><p>For these code examples, bear in mind that the Instruction Set Architecture (ISA) presented here hasn't seen public light of day as far as we know. We've had to invent our own assembly mnemonics, although they're designed to be familiar to anyone familiar with assembly languages in general. Some specific notes:</p><ul><li>SEL RB is SELect Register Bank, and provides the base index for register access (multiply by 8 to get actual index).</li><li>Note that all register references are by index, not register number. A register number can be calculated with the index and register bank.</li></ul><p><b>1) READ SPECIAL REGISTER</b></p><p><span>.command_READ_SPECIAL_REGISTER<br>32E&nbsp; &nbsp;00<span>	</span>SEL RB 0<br>32F&nbsp; &nbsp;27<span>	</span>MOV A, I7<span>		</span>; R7 ($07) (param 1)<br>330&nbsp; &nbsp;30<span>	</span>MOV I0, A<span>		</span>; R0 ($00) = register index<br>331&nbsp; &nbsp;F8<span>	</span>MOV A, [I0]<span>		</span>; read special register value to A<br>332&nbsp; &nbsp;02<span>	</span>SEL RB 2<br>333&nbsp; &nbsp;36<span>	</span>MOV I6, A<span>		</span>; R22 ($16) (ext RESULT) = A<br>334&nbsp; &nbsp;0E<span>	</span>SEL RB 14<br>335&nbsp; &nbsp;EE<span>	</span>SYS 2, RB<span>		</span>; JMP (2,E,0) =&gt; $288, .post_command_tidy_up</span></p><p>The READ SPECIAL REGISTER command is one of the simplest. As suspected, "special register" externally is just "index into the 32 registers" internally. We can also note plenty of interesting things:</p><ul><li>The command setup code, which we'll see in a bit, writes parameters to R7 downwards.</li><li>Indirect reads and writes are done via special opcodes that indirect through I0 (typically but not always R0), as per the MCS-48 architecture.</li><li>Some of the internal registers interact with the external bus registers used to interact with the host CPU. R22 is where you write values for them to appear in "ext RESULT", which is read with BBC Micro's 6502 at memory location $FE81.</li><li>The "register bank" concept appears to be re-used to provide a lookup index to the SYS 2, RB opcode. You might consider this a minor kludge.</li><li>In order to jump from page 3 ($3??) to page 2 ($2??) at the end, a special SYS opcode is required. Normal JMP / CALL instructions only have an 8-bit operand and can only jump to the current page. SYS opcodes look up a 10-bit PC from a hard coded table.</li><li>The command exits by jumping to a common exit routine, <span>.post_command_tidy_up</span>. This routine disables most of the chip, including the bit processor, and events. This will be important later.</li></ul><p><b>2) SPECIFY</b></p><p><span>.command_SPECIFY<br>066&nbsp; &nbsp;00<span>	</span>SEL RB 0<br>067&nbsp; &nbsp;27<span>	</span>MOV A, I7<span>		</span>; R7 ($07) (param 1)<br>068&nbsp; &nbsp;30<span>	</span>MOV I0, A<span>		</span>; R0 ($00) = destination index<br>069&nbsp; &nbsp;F1 03<span>	</span>MOV I1, #$03<span>		</span>; R1 ($01) = count of 3 extra parameters<br>06B&nbsp; &nbsp;14<span>	</span>YIELDTO 4<span>		</span>; seems to set PARAM callback to<br><span>					</span>; .wakeup_PARAM_4_SPECIFY, then YIELD<br>; ** entry point (3, segment 9, routine 4 5 6 7 C D E F)<br>.wakeup_PARAM_4_SPECIFY<br>06C&nbsp; &nbsp;03<span>	</span>SEL RB 3<br>06D&nbsp; &nbsp;2E<span>	</span>MOV A, IE<span>		</span>; R30 ($1E) (ext PARAM)<br>06E&nbsp; &nbsp;00<span>	</span>SEL RB 0<br>06F&nbsp; &nbsp;E8<span>	</span>MOV [I0], A<br>070&nbsp; &nbsp;00<span>	</span>SEL RB 0<br>071&nbsp; &nbsp;80<span>	</span>INC I0<br>072&nbsp; &nbsp;A1<span>	</span>DEC I1<span>			</span>; R1 ($01), decrement count<br>073&nbsp; &nbsp;8A 8C<span>	</span>BZ $08C<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;</span>; branch if done<br><span>					</span>; lands at SEL RB 14, JMP RB<br><span>					</span>; which jumps to .post_command_tidy_up<br>075&nbsp; &nbsp;FF<span>	</span>YIELD</span></p><p>SPECIFY is also a simple command. It's not strictly a necessary command because it has the same effect as 3 WRITE SPECIAL REGISTER commands to sequential register numbers. It's unclear why it exists, given the space crunch in the ROM and on the silicon, but the datasheet does describe initializing the 8271 using a few of calls to this. Other items of note:</p><div><ul><li>SPECIFY accepts and applies the register writes immediately, YIELDing (sleeping / idling) between writes and waiting for the host CPU to supply the next register. This means the SPECIFY command might be partially completed for some time, and never fully completed, depending on how we program the chip. This will be significant later.</li><li>SPECIFY internally uses R0 as a destination index to write register values, and R1 as a count to complete. This makes it an ideal candidate to do some black box testing to confirm the chip behaves the same as our source code disassembly. Specifically, I tried and confirmed:</li><ul><li>Pass the first parameter to SPECIFY as 0, indicating we are writing register values starting at R0. Note that as per the code, R0 is used internally by SPECIFY.</li><li>Pass the second parameter as $22. This will get written to R0 (because R0 currently points to R0) and incremented, leaving $23 in R0. This has "corrupted" R0.</li><li>Pass the third parameter as $48. This will get written to MMIO register R35 ($23), and should turn on the drive motor.</li><li>Do not pass a fourth parameter. Despite not “completing” the full four parameters of the command, we expect the writing of the third parameter to have the effect as just described. <b>It does on real hardware</b>.</li></ul></ul></div><p><b>3) External command register handling</b></p><div><p><span>.wakeup_COMMAND</span></p><p><span>014&nbsp; &nbsp;02<span>	</span>SEL RB 2</span></p><p><span>015&nbsp; &nbsp;F6 00<span>	</span>MOV I6, #$00<span>		</span>; R22 ($16) = $00 (ext RESULT)</span></p><p><span>017&nbsp; &nbsp;CF BF<span>	</span>AND I7, #$BF<span>		</span>; R23 ($17) (ext STATUS) !CMD_FULL</span></p><p><span>019&nbsp; &nbsp;00<span>	</span>SEL RB 0</span></p><p><span>01A&nbsp; &nbsp;F5 01<span>	</span>MOV I5, #$01<span>		</span>; R5 ($05) = $01 (param 3 default $01)</span></p><p><span><span>					</span>; That’s 1x 128 byte sector in many cases.</span></p><p><span>01C&nbsp; &nbsp;F4 01<span>	</span>MOV I4, #$01<span>		</span>; R4 ($04) = $01 (param 4 default $01)</span></p><p><span>01E&nbsp; &nbsp;03<span>	</span>SEL RB 3</span></p><p><span>01F&nbsp; &nbsp;98 05<span>	</span>MOV A, #$05<span>		</span>; 5 parameters expected</span></p><p><span>021&nbsp; &nbsp;6F 18 27<span>	</span>TBZ IF, #$18, $027<span>	</span>; R31 ($1F) (ext CMD), jump if 5 param <span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; <span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span></span><span>;&nbsp;</span>command</span></p><p><span><span>					</span>; matches SCAN, FORMAT</span></p><p><span>024&nbsp; &nbsp;2F<span>	</span>MOV A, IF<span>		</span>; R31 ($1F) (ext CMD)</span></p><p><span>025&nbsp; &nbsp;9C 03<span>	</span>AND A, #$03<span>		</span>; (CMD &amp; 3) parameters expected</span></p><p><span>027&nbsp; &nbsp;00<span>	</span>SEL RB 0</span></p><p><span>028&nbsp; &nbsp;31<span>	</span>MOV I1, A<span>		</span>; R1 ($01) = A = parameters expected</span></p><p><span>029&nbsp; &nbsp;8A 3D<span>	</span>BZ $03D<span>&nbsp;&nbsp; &nbsp;</span><span>		</span>; if no parameters, start command</span></p><p><span>02B&nbsp; &nbsp;F0 07<span>	</span>MOV I0, #$07<span>		</span>; R0 ($00) = $07 (put parameters at $07 down)</span></p><p><span>02D&nbsp; &nbsp;BC 01<span>	</span>TASK 4, 1<span>		</span>; select .wakeup_PARAM_1_accept</span></p><p><span><span>					</span>; 3 9 (1, 3, 9, B) = $035</span></p><p><span>02F&nbsp; &nbsp;FF<span>	</span>YIELD</span></p><p>This is where to start reading if you want to trace the main entry point into the ROM. The 8271 byte processor wakes up here where the external host CPU writes to the external command register ($FE80 on the BBC Micro). And again some interesting things to note:</p><div><ul><li>For commands other than SCAN and FORMAT, the number of parameters expected is actually encoding in to the low order bits of the command byte. Undoubtedly, this saves space in the ROM. This is another case where a simple test can confirm the behavior claimed by the ROM code:</li><ul><li>Take a command that takes 1 parameter, e.g. READ SPECIAL REGISTER.</li><li>Increment the command byte and supply that to the 8271 instead.</li><li>We'd expect the 8271 to require 2 parameters to start the command, but then ignore the second parameter and behave as if the 1 parameter version was used. <b>This is indeed observed on real hardware</b>.</li></ul><li>Some default parameter values are deployed. These are used in the commands the datasheet calls "128 Byte Single Record Format". Presumably it is again a win for ROM space savings.</li></ul><p><b>4) Full ROM disassembly</b></p><p>The full ROM disassembly, as of time of writing, may be found here: [<a href="https://drive.google.com/file/d/1SyvAfMYjFEZjd0Q-YguTAXRlxoR-tPYI/view" target="_blank">link</a>]. This copy will remain static. It's mostly complete, and all of the "main" paths are fully traced, including SEEK, READ DATA, WRITE DATA and FORMAT TRACK.</p><p><h3>Javascript on a (1970s!) chip</h3></p><p>It is time to look at some of the unusual sounding instructions in the ISA:</p><div><ul><li><b>YIELD</b>. $FF. This instruction tells the processor to switch to running the highest priority dispatcher request, or (more likely) go idle if there's no dispatcher request active.</li><li><b>TASK t, r</b>. $B8-$BF, 2 bytes. This instruction changes the callback routine for the specified task. Callback routines are specified as an integer that form part of a lookup key into a table of ROM addresses.</li><li><b>YIELDTO r</b>. $10-$1F. Change the callback routine for the currently executing task and yield.</li><li><b>SYS 0, RB, A</b>. $EC. Jump to the ROM address at key (0, RB, A) in the address PLA. RB is the current register bank from the SEL RB instruction, and A is the accumulator value.</li><li><b>SYS 1, RB, R</b>. $ED. Jump to the ROM address at key (1, RB, R) in the address PLA. RB is the current register bank from the SEL RB instruction, and R is current routine value.</li><li><b>SYS 2, RB</b>. $EE. Jump to the ROM address at key (2, RB, 0) in the address PLA. RB is the current register bank.</li></ul><p>There are quite a few concepts introduced here. If you find them somewhat jumbled, you are not alone. A lot of things about the non-traditional parts of the byte processor CPU appear very ad-hoc to me. Let's look at a concrete example: the handler for the SPECIFY command. This is the <span>.command_SPECIFY</span>&nbsp;code in example chunk 2) above.</p></div><p>To get <span>.command_SPECIFY</span> to run, the host CPU provides the command $35 to the external command register, then 1 initial expected parameter to the external parameter register. The byte processor CPU wakes up at&nbsp;<span>.wakeup_PARAM_1_accept</span>. The context here is:</p><div><ul><li>PC == $035</li><li>TASK == 4</li><li>SEGMENT == 9, ROUTINE == 1</li></ul></div><p>The fact that writes to the external parameter register wake up task 4 is <b>hardcoded</b>. The PC executed is determined by the routine selected for this task, which was 1 at the time. This is used to create the key (3,9,1), which looks up the address $035 in the address PLA. The address PLA is <b>hardcoded</b>. The fact that task 4 keys lookups as (3,9,x) is <b>hardcoded</b>.</p><p><span>.command_SPECIFY</span> ends with this, because it is the one command that gets executed and then decides it wants to yield to wait for 3 more parameters:</p><div><p><span>06B&nbsp; &nbsp;14<span>	</span>YIELDTO 4<span>		</span>; seems to set PARAM callback to</span></p><p><span><span>					</span>; .wakeup_PARAM_4_SPECIFY, then YIELD</span></p></div><p>This unusual instruction sets the callback routine for the <i>current</i>&nbsp;task to be 4. This means that the callback code for the next external parameter register write will be keyed (3,9,4) in the address PLA. That's PC $06C, aka. <span>.wakeup_PARAM_4_SPECIFY</span>.</p><p><b>A good mental model for this is Javascript</b>. All execution is event based; the handler for a given event can be changed (by the handler itself, or an unrelated handler); there is no pre-emption until an explicit yield.</p><p>The known events wired in to the byte processor are:</p><div><ul><li>0: Not reversed at all. Appears to be related to the SCAN command, which isn't enabled on the BBC Micro due to lack of DMA.</li><li>1: Bit processor event, e.g. found sync, lost sync, CRC error.</li><li>2: Bit processor, read byte ready.</li><li>3: Bit processor, write byte needed.</li><li>4: External parmeter register written.</li><li>5: appears unused. (Could be permanently connected to external command register?)</li><li>6: Disc drive index pulse.</li><li>7: appears unused.</li></ul></div><p>On top of the "normal" Javascript model, there's also the concept of task priorities. These are not visible in the ISA and are presumably hardcoded. One instance this might come in handy in a floppy disc controller is when a disc drive index pulse (once per disc revolution) fires at the same time the bit processor needs a write byte. (It's not common to write across the index, but it could happen.) In this instance, providing the bit processor a data byte is a much more real-time task than handling an index pulse, so it should be handled first.</p><p>Yes, this is quite some complexity in addition to the complexity typical in a general purpose CPU. In particular, it provides many additional ways to slice and dice control flow handling beyond the standard JMP / CALL / RET. In fact -- and somewhat painfully -- the different control flow possibilities are mixed together! To briefly get a taste of the horrors, here's the command handler for many of the sector read operations:</p><div><p><span>.command_READ_DATA</span></p><p><span>.command_READ_DATA_AND_DEL_DATA</span></p><p><span>.command_VERIFY_DATA_AND_DEL_DATA</span></p><p><span>0A7&nbsp; &nbsp;FC C9<span>	</span>CALL $0C9<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; </span>; .do_common_path_from_seek</span></p><p><span><span>			<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span></span>; very gnarly because this CALL does a YIELD</span></p><p><span><span>			<span>&nbsp;&nbsp; &nbsp;<span>&nbsp;&nbsp; &nbsp;</span></span></span>; context on RET is from</span></p><p><span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>; .wakeup_BITPROC_EVENT_1_check_header_crc</span></p><p><span><span>		<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span></span>; if we get a matching sector header,</span></p><p><span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>; the RET at $255 fires</span></p><p><span><span>0A9&nbsp; &nbsp;BA 0B<span>	</span>TASK 2, 11<span>	</span>; select&nbsp;</span><span>.wakeup_BITPROC_READ_10_11_count_GAP2</span></span></p><p><span><span>			<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span></span>; (3,5,(10,11)) = $1B8</span></p><p><span>0AB&nbsp; &nbsp;12<span>	</span>YIELDTO 2<span>	</span>; select</span></p><p><span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>; .wakeup_BITPROC_EVENT_2_check_for_data_marker</span></p><p><span><span>				</span>; (3,4,2) = $2D0</span></p><p><span><span>				</span>; and YIELD</span></p></div><p>As can be seen, a CALL subroutine is doing a YIELD without unwinding the stack. This should probably be considered an anti-pattern? The stack is a shared resource across all tasks, so you'd better hope that two different tasks can't trip over each by doing this at the same time. There's also the complexity that when a CALL returns, various aspects of the execution environment (task, routine, RB, etc.) may well have changed.</p><p>All this makes the ROM very hard to follow for the read and write paths, even with a fully disassembled and commented ROM!</p><h3>Unusual features of the ISA</h3></div><p><b>1) Lack of symmetry</b></p><p>These are the opcodes we found relating to incrementing, decrementing, adding and subtracting:</p><div><p><span>$80-$83:<span>	</span>INC Ix</span></p><p><span>$84-$87:<span>	</span>ADC A, Ix</span></p><p><span>[...]</span></p><p><span>$A0-$A7:<span>	</span>DEC Ix</span></p><p><span>[...]</span></p><p><span>$90-$93:<span>	</span>ADC Ix<span>			</span>does INC Ix if carry</span></p><p><span>$94-$97:<span>	</span>SBB A, Ix</span></p></div><p>This is interesting because there is an asymmetry between which registers can be incremented vs. decremented. Some registers cannot be incremented at all, even with register banking, because banking operates in multiples of 8 and there are only 4 increment opcodes.</p><p>One theory is that the chip designers were short on silicon space, and trying to get away without add and subtract support in the ALU. There's only circumstantial evidence to support this, such as the hacked-out ranges in the opcode space; the code generally being add / subtract free except for the code implementing disc drive seek; no compare instruction found (yet -- there are unknowns); the use of XOR to do equality checks at $240 and $24F; and the presence of only direct equality checking or mask based checking for the most common branch opcodes (see item 2) directly below). But it's fun to speculate wildly isn't it?</p><p><b>2) 3-byte opcodes</b></p><p>An entire quarter(!) of the opcode space is devoted to four conditional branch instructions:</p><div><p><span>$40-$4F:<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>BEQ Ix, #imm, abs<span>	</span>branch if Ix == imm</span></p><p><span>$50-$5F: <span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; </span>BNE Ix, #imm, abs<span>	</span>branch if Ix != imm</span></p><p><span>$60-$6F:<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>TBZ Ix, #imm, abs<span>	</span>test and branch if zero</span></p><p><span>$70-$7F:<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>TBNZ Ix, #imm, abs<span>	</span>test and branch if not zero</span></p></div><p>These opcodes are all three bytes, which is a departure from Intel's other microcontrollers of the era. It's a lot of opcode space, but they can do a lot with a little, for example this piece of code from <span>.do_seek</span>.</p><div><p><span>13E&nbsp; &nbsp;62 01 3E<span>	</span>TBZ I2, #$01, $13E<span>&nbsp;&nbsp; </span>; MMIO R34 ($22) (drive in), wait until CNT/OPI</span></p><p><span>141&nbsp; &nbsp;72 01 41<span>	</span>TBNZ I2, #$01, $141<span>&nbsp;&nbsp;</span>; MMIO R34 ($22) (drive in), wait until !CNT/OPI</span></p></div><p>For a certain (less common) seek mode, these 6 bytes are sufficient to busy loop while waiting for the drive to start the seek, then acknowledge finishing it.</p><p>These three byte opcodes were found by the previously mentioned "jigsaw" analogy. Once the command entry function was fully disassembled apart from just three bytes at $021, there was only one clean possibility that fitted the required behavior.</p><p><b>3) No timers, port I/O or IRQs</b></p><p>Presumably to save silicon, the byte processor CPU has done away with timers, dedicated port I/O instructions and IRQs. The MCS-48 has all of those.</p><p>They're not needed, though. Delays, such as the millisecond range delays for seek steps, are simply timed via busy loops.</p><p><b>4) Decide your own adventure</b></p><p>At time of writing, our opcode list is here: [<a href="https://drive.google.com/file/d/1EIg6utXQKTEYf9x6fcpJ0Sht1Pj_r9WW/view" target="_blank">link</a>]. It is not complete. The one part of the 8271 ROM we have not disassembled, SCAN handling, uses at least opcodes $9A, $9B and $8C. (We've ignored SCAN because it needs DMA wired up, which is not the case in the BBC Micro application.) Furthermore, the PLAs suggest that other opcode ranges <i>not</i>&nbsp;seen in the 8271 ROM might do something. This includes $A8-$AF and $B0-$B7. Feel free to go and have a look!</p><h3>Interface to the bit processor</h3><p>Now that we've got the byte processor understood and disassembled, it's time to turn our attention to interface to the bit processor and its behavior. After all, it's the bit processor that is wired to the disc drive control and data lines!</p><p>Our initial assumption was that the byte processor CPU would, like the MCS-48, have some form of port I/O instructions. This turned out to be false. The reality is simpler: it uses MMIO (Memory Mapped Input/Output). This means that access to certain register indexes change registers in the bit processor instead of the byte processor. It's quite simple: 0-31 references the byte processor registers. And the range 32-39 references bit processor registers. For simplicity of decoding, the bit processor's 8 register references are mirrored 4 times across the range 32-63. The entire 0-63 range is then mirrored 4 times in the entire addressable range of 0-255.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-kWVhh-q4_28/X68AB39pVNI/AAAAAAAAzQE/WGoqlH0cQ2Arrw3u0abrTyLAtzacKeIeACLcBGAsYHQ/s547/8271init.jpg"><img data-original-height="410" data-original-width="547" height="300" src="https://1.bp.blogspot.com/-kWVhh-q4_28/X68AB39pVNI/AAAAAAAAzQE/WGoqlH0cQ2Arrw3u0abrTyLAtzacKeIeACLcBGAsYHQ/w400-h300/8271init.jpg" width="400"></a></td></tr><tr><td>Registers 0-63, read on a real BBC Micro, illustrating mirroring of the bit processor registers</td></tr></tbody></table><p>Furthermore, the context of bit processor references in the byte processor code makes it clear that the bit processor interface is very simple. It is so simple we didn't feel the need to reverse engineer the bit processor further. The bit processor register assignments are as follows:</p><div><ul><li>0: control register, 4 bits</li><ul><li>Bit 0 (0x01) =&gt; gather CRC (?)</li><li>Bit 1 (0x02) =&gt; finish CRC (?)</li><li>Bit 2 (0x04) =&gt; 1 for read, 0 for write</li><li>Bit 3 (0x08) =&gt; idle state</li></ul><li>1: status register, indicates sync data byte type, CRC error, etc.</li><li>2: drive input, read for drive status</li><li>3: drive output, controls step / write / etc. lines</li><li>4: clocks output byte</li><li>5: data output byte</li><li>6: data input byte</li><li>7: unused? (returns 0xFF, and byte processor ROM relies on this!)</li></ul><p>The astute reader might ask: does this mean the bit processor can be programmed directly with the WRITE SPECIAL REGISTER command, since the bit processor registers are MMIO? And the answer is yes! There are severe caveats however:</p></div><div><ul><li>The generic command entry code corrupts bit processor state on entry.</li><li>The generic command exit code resets the bit processor and associated callbacks on exit (but strangely and usefully not for WRITE SPECIAL REGISTER).</li><li><b>The latency of WRITE SPECIAL REGISTER is terrible</b>.</li></ul></div><p>That last bullet, the poor latency, is unfortunate. It's about 211us, which means there's zero chance for tricks like writing data to the disc a clocks + data byte at a time. The latency is large because the byte processor executes a large number of instructions on the command entry path, doing things like checking and caching drive status, as well as reading parameters one at a time, checking if the selected drive changed, etc.</p><p>Writing the drive output register directly is useful, though. I did this for my trick to write "weak bits" directly using the 8271! See my blog post about weak bits for more details. [<a href="https://scarybeastsecurity.blogspot.com/2020/06/weak-bits-floppy-disc-protection.html" target="_blank">link</a>]</p><h3>Writing the unwritable</h3><p>Now that we know how this monster works, it is of course time to turn our attention to mischief. Can we make the chip do things it is "not supposed" to be able to do? Of course we can, and as usual, it involves disobeying the datasheet:</p><p><a href="https://1.bp.blogspot.com/-KMR4QIEpLqU/X68czifdgoI/AAAAAAAAzQQ/ycPvt_HbOy4riVZSjHUSrYF-ppLie7N2gCLcBGAsYHQ/s490/datasheet_illegal.png"><img data-original-height="325" data-original-width="490" height="424" src="https://1.bp.blogspot.com/-KMR4QIEpLqU/X68czifdgoI/AAAAAAAAzQQ/ycPvt_HbOy4riVZSjHUSrYF-ppLie7N2gCLcBGAsYHQ/w640-h424/datasheet_illegal.png" width="640"></a></p><p>We are specifically going to disobey the sentence that states "Issuing a command while another command is in progress is illegal." We are now equipped to see exactly what happens if we do this, by reading and reasoning about the code. The callback called when the external command register is written gets on with its job without regard for whether a command is in progress, so side effects will be:</p><div><ul><li>The internal command register itself is corrupted, i.e. mismatched with the currently executing command. It is referenced from time to time so this may be useful to us.</li><li>The illegal command will change internal register values, which may impact the execution of the current command.</li><li>The illegal command may change or disable callbacks, or reset or reconfigure the bit processor.</li></ul></div><p>Taking these things into consideration, we are going to <b>try and write an arbitrary FM bit stream</b>. Achieving this will enable us to recreate copy protected disc surfaces that are not supposed to be writeable with the 8271. Remember, kids:</p><p><a href="https://1.bp.blogspot.com/-3ctTtZams3E/X68nLNJWuNI/AAAAAAAAzQc/8LJkQY2eu64dWHkw8HTxW_wrAQTkPhkvwCLcBGAsYHQ/s364/Dontcopythatfloppy.jpg"><img data-original-height="274" data-original-width="364" height="301" src="https://1.bp.blogspot.com/-3ctTtZams3E/X68nLNJWuNI/AAAAAAAAzQc/8LJkQY2eu64dWHkw8HTxW_wrAQTkPhkvwCLcBGAsYHQ/w400-h301/Dontcopythatfloppy.jpg" width="400"></a></p><p>We're going to attempt this by separating out how we write the data bytes and how we write the special sector mark clock bytes. Writing a full track of data bytes is easy, but useless on its own. We can do this by:</p><div><ul><li>Formatting a track with a single sector header.</li><li>Issue a WRITE DATA command for that sector, of size 8192 bytes. A track is only 3125 bytes (with a perfectly calibrated drive), so:</li><ul><li>At the first wrap around, start writing the track of bytes we want.</li><li>3125 or so bytes later, at the second wrap around, abort the command by resetting the controller.</li></ul></ul><p>This track of data bytes alone will be useless. If you try to read a sector from it, you will get error $18, aka. "sector not found". The special clock byte markers required to identify sector headers and sector data will be missing.</p><p>The way FM encoding works is very simple: it alternates clock bit, data bit, clock bit, data bit, ... every 4us. Normally all the clock bits are 1, to maintain timing and keep the drive electronics happy. But for a sector header or data marker, a few clock bits are left out so that the floppy disc controller can locate things in a bitstream where it is not sure where it is.</p></div><p>So, while the WRITE DATA command is running, we're going to sneak in some parallel SPECIFY commands to "corrupt" registers for the running WRITE DATA command, without disturbing it. Specifically, we're only going to corrupt the clocks byte register (MMIO R36) at the precise times necessary to write clocks byte values other than 0xFF. The overall operation looks like this:</p><p><a href="https://1.bp.blogspot.com/-w6c6LiMbVac/X68vo7RomKI/AAAAAAAAzQs/7pfFc4fAWYUEK75UzIOIqU-6hlvGFW-wACLcBGAsYHQ/s960/Reverse%2Bengineering%2Bthe%2BIntel%2B8271%2B%25281%2529.png"><img data-original-height="540" data-original-width="960" height="360" src="https://1.bp.blogspot.com/-w6c6LiMbVac/X68vo7RomKI/AAAAAAAAzQs/7pfFc4fAWYUEK75UzIOIqU-6hlvGFW-wACLcBGAsYHQ/w640-h360/Reverse%2Bengineering%2Bthe%2BIntel%2B8271%2B%25281%2529.png" width="640"></a></p><p>By some miracle, this scheme does work, and it easily replicates discs that no BBC Micro copier back in the day could come close to. One example of a tough disc, for some reason, is The Sentinel [<a href="http://bbcmicro.co.uk/game.php?id=609" target="_blank">link</a>]. The disc has a pretty label and packaging so of course, time for a gratuitous image:</p><p><a href="https://1.bp.blogspot.com/-5LsJkBNKXgo/X68w3a82qdI/AAAAAAAAzQ0/xt_qUUf2CsEoqMuD90xdqAtmqnzkmP7YACLcBGAsYHQ/s800/sentinel_disc.jpeg"><img data-original-height="600" data-original-width="800" height="300" src="https://1.bp.blogspot.com/-5LsJkBNKXgo/X68w3a82qdI/AAAAAAAAzQ0/xt_qUUf2CsEoqMuD90xdqAtmqnzkmP7YACLcBGAsYHQ/w400-h300/sentinel_disc.jpeg" width="400"></a></p><p>There are plenty of quirks and caveats to get this working. To briefly note them for completeness:</p><div><ul><li>The SPECIFY command was used instead of WRITE SPECIAL REGISTER to help with latency concerns. The SPECIFY command can be "primed" by passing the command and the first parameter, such that the second parameter (first register value to write) executes the write and executes with low latency at just the right moment.</li><li>The WRITE SPECIAL REGISTER command exits without resetting the bit processor or clearing all the I/O callbacks. Unfortunately, the same cannot be said for SPECIFY. Fortunately, we don't have to exit the SPECIFY command! It starts having the useful side effect of writing internal registers before it is complete. And then you can later restart it again and again, never completing it.</li><li>The act of command dispatch corrupts the MMIO clocks byte register! This is very unexpected but it uses MMIO R36 as a temporary storage location while it is calculating which disc drive (0 or 1) is selected, and whether it changed. It is worth looking at:</li></ul><div><p><span>.parameters_complete_launch_command</span></p><p><span>03D&nbsp; &nbsp;FC 5D<span>	</span>CALL $05D<span>	</span>; .read_drive_status</span></p><p><span>03F&nbsp; &nbsp;BC 00<span>	</span>TASK 4, 0<span>	</span>; select .wakeup_PARAM_0_no_action</span></p><p><span><span>				</span>; (3,9,(0,2,8,A)) =&gt; $030</span></p><p><span>041&nbsp; &nbsp;03<span>	</span>SEL RB 3</span></p><p><span>042&nbsp; &nbsp;2F<span>	</span>MOV A, IF<span>	</span>; R31 ($1F) (ext CMD)</span></p><p><span>043&nbsp; &nbsp;CF 3C<span>	</span>AND I7, #$3C<span>	</span>; R31 ($1F) (select bits + param&nbsp;</span><span>count masked out)</span></p><p><span>045&nbsp; &nbsp;9C C0<span>	</span>AND A, #$C0<span>	</span>; A now contains drive select bits</span></p><p><span>047&nbsp; &nbsp;04<span>	</span>SEL RB 4</span></p><p><span>048&nbsp; &nbsp;34<span>	</span>MOV I4, A<span>	</span>; MMIO R36 ($24) (???) (temp storage?)</span></p><p><span>049&nbsp; &nbsp;E3<span>	</span>XOR A, I3<span>	</span>; MMIO R35 ($23) (drive out)</span></p><p><span>04A&nbsp; &nbsp;9C C0<span>	</span>AND A, #$C0</span></p><p><span>04C&nbsp; &nbsp;8A 53<span>	</span>BZ $053<span>&nbsp;&nbsp; &nbsp;</span><span>	</span>; only update drive out if select bits changed</span></p><p><span><span>		</span><span>		</span>; .command_dispatch</span></p><p><span>04E&nbsp; &nbsp;98 20<span>	</span>MOV A, #$20<span>	</span>; bit for side select (drive 0 vs. 2)</span></p><p><span>050&nbsp; &nbsp;C3<span>	</span>AND A, I3<span>	</span>; MMIO R35 ($23) (drive out)</span></p><p><span>051&nbsp; &nbsp;D4<span>	</span>OR A, I4<span>	</span>; MMIO R36 ($24) merge back select bits?</span></p><p><span>052&nbsp; &nbsp;33<span>	</span>MOV I3, A<span>	</span>; MMIO R35 ($23) (drive out)</span></p><p><span><span>				</span>; only drive select bits and side select kept</span></p><p><span><span>				</span>; clears write enable, head load, and others</span></p><p><span><span>				</span>; matches data sheet</span></p></div></div></div></div><blockquote><div><p>The line in orange is the one in question. I annotated it as iffy with ??? when I first disassembled it as it looked wacky. But, it's correct and a real machine exhibits the corrupted clocks precisely as described by the code. The corrupt clocks value, $40 if writing to drive 0, is shown in orange in the above diagram. Once you know it's there, and why, the easiest way to navigate around it is to arrange for the clocks corruption to land where it doesn't case problems. When paired with a $FF data byte, it doesn't create weak bits on the disc surface, and the controller actually seems to skip over it on read.</p></div></blockquote><div><div><div><ul><li>The write I/O path, by some stroke of good fortune, resets the clocks byte to $FF on every write I/O callback. This saves us a lot of trouble:</li></ul><div><p><span>.wakeup_BITPROC_WRITE_3_set_clocks_and_count_host_bytes</span></p><p><span>318&nbsp; &nbsp;F4 FF<span>	</span>MOV I4, #$FF<span>	</span>; MMIO R36 ($24), standard clocks</span></p></div><p><span>[...]</span></p><ul><li>Careful timing is needed. There's a pipeline of bytes from the external data register to the internal bit processor data byte register to the actual output pulse machinery. This needs to be accounted for.</li></ul><p>Combined, these quirks convince me that I'd have never gotten this going, or gotten close, without a thoroughly reverse engineered and disassembled ROM.</p></div><h3>Other successes and failures</h3><p>Other things enabled or demonstrated based on careful reading of the ROM code:</p><div><ul><li>beebjit now has a much more accurate 8271 driver.</li><li>Unexplained weirdness trying to read a sector with logical track id $FF has been explained as an integer overflow in the bad tracks handling.</li><li>Sectors on a non-zero physical track, but with a zero logical track id, were believed "impossible" to read. I'm able to read them by using the "command within command" trick. Once a READ DATA command is safely underway, including having processed the seek request and gone idle, it's possible to use WRITE SPECIAL REGISTER to change R7 (command param 1, which is the requested track) to zero, and have the sector read fine. The issue is that references to logical track 0 in the seek code are always treated as a mandate to find physical track 0. You need to bypass that.</li></ul><p>Things not achieved:</p></div><div><ul><li>Reading or writing MFM (double density) -- looks fundamentally impossible. Does not appear to be a capability in the hard-wired bit processor.</li><li>Executing arbitrary code on the chip. This is a shame, as the byte processor is a capable CPU! Who knows what we could use a little co-processor for? Things making this hard include:</li><ul><li>Separation of code and data in separate address spaces.</li><li>No references to the stack possible outside of CALL and RET.</li><li>Indirect jump targets stored in a read-only PLA. (Microsoft CFG? :)</li><li>... and yes, curiously, these accidental defenses all sound similar to defensive technologies investigated or deployed since year 2000. So, the 1970s called and...</li></ul></ul></div><h3>Summary</h3><div><p>The 8271 has exceeded our expectations! Where to start? It's a massive chip, encompassing dual cores and a Javascript like execution model. Remember, this was the mid-1970s. Its general purpose CPU runs an Intel instruction set architecture that I don't believe has been publicly documented until now. It's not every day we get the treat of a new Intel ISA.</p><p>We never got to the bottom of the crazy test mode that started this whole investigation. There's no trace of it in the byte processor ROM, so it must be handled by some other component on the silicon. Something to investigate for another day perhaps.</p><p>Having seen the complexity of the chip, I must confess to a feeling of surprise every time my BBC Micro successfully loads a disc.</p></div><h3>Epilogue</h3></div><p>Given the 8271 issues with cost, heat, supply chain, complexity, and lack of MFM, it wouldn't be surprising if Intel had had enough with the architecture behind the 8271 and 8273. Intel staggered bravely forward with the 8272, which introduced MFM support and... hang on, let's have a look at a decapitated one of those...</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-bLL4fL5BMLc/X6-ChZErYDI/AAAAAAAAzRE/StqRSrHBHyUeP4ggl-9EdGZi9cNFKoL8gCLcBGAsYHQ/s1622/8271_nec_8272.jpg"><img data-original-height="537" data-original-width="1622" height="212" src="https://1.bp.blogspot.com/-bLL4fL5BMLc/X6-ChZErYDI/AAAAAAAAzRE/StqRSrHBHyUeP4ggl-9EdGZi9cNFKoL8gCLcBGAsYHQ/w640-h212/8271_nec_8272.jpg" width="640"></a></td></tr><tr><td>Left to right: Intel 8271, NEC D765, Intel 8272</td></tr></tbody></table><p>This is very cheeky! The 8272 die may say "8272 (c) Intel 1979" but it is the same die as a NEC D765, stamped "NEC D765B". It looks like Intel may have licensed the NEC design. The NEC doesn't appear much smaller in terms of die size, but the layout looks much simpler and less busy. Bizarrely, Intel appears to have fabbed the 8272 much larger than the NEC.&nbsp;</p><h3>Extra references</h3><ul><li><a href="http://stardot.org.uk/" target="_blank">StarDot</a> forum thread where the investigation unfolded: [<a href="https://stardot.org.uk/forums/viewtopic.php?f=3&amp;t=19762" target="_blank">link</a>]</li><li>Sean Riddle's decap page: [<a href="https://seanriddle.com/decap.html" target="_blank">link</a>]</li><li>beebjit's 8271 driver: [<a href="https://github.com/scarybeasts/beebjit/blob/master/intel_fdc.c" target="_blank">link</a>]</li><li>8271 tests and tools (warning: rough) for the BBC Micro: [<a href="https://github.com/scarybeasts/misc/tree/master/8271" target="_blank">link</a>]</li><li>Live document for 8271 disassembly: [<a href="https://docs.google.com/document/d/1bQTvncIcgRfO0zOvBB16x37WfTh71c4U5WWCyQ4lFVM/edit#" target="_blank">link</a>]</li><li>Very high resolution die shots of the 8271 and 8273 (beware, will hang browsers!): [<a href="http://www.seanriddle.com/8271/" target="_blank">link</a>]</li></ul></div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Aldi Price Map (320 pts)]]></title>
            <link>https://www.aldipricemap.com/navel_oranges.html</link>
            <guid>39379339</guid>
            <pubDate>Thu, 15 Feb 2024 05:09:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aldipricemap.com/navel_oranges.html">https://www.aldipricemap.com/navel_oranges.html</a>, See on <a href="https://news.ycombinator.com/item?id=39379339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>How much do &nbsp; &nbsp;cost at Aldi's? </p>
                <p>Prices valid from Feb 14<sup>th</sup> to Feb 20<sup>th</sup> 
<a href="#" onclick="alert('This site is not affiliated with Aldi\'s. The prices are provided for information purpose only. Store pricing may change without notice and may differ from the information provided on this site.')">(Info)</a>
   </p>
                           
            </div></div>]]></description>
        </item>
    </channel>
</rss>