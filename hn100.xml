<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 09 Jul 2023 20:00:15 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Amateurs obsess over tools, pros over mastery (107 pts)]]></title>
            <link>https://adamsinger.substack.com/p/amateurs-obsess-over-tools-pros-over</link>
            <guid>36657477</guid>
            <pubDate>Sun, 09 Jul 2023 18:37:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adamsinger.substack.com/p/amateurs-obsess-over-tools-pros-over">https://adamsinger.substack.com/p/amateurs-obsess-over-tools-pros-over</a>, See on <a href="https://news.ycombinator.com/item?id=36657477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg" width="500" height="375" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:375,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6c15b28-a04f-4d3b-9789-93200fd7cc0b_500x375.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><em>image credit:&nbsp; nj dodge, via flickr cc</em></figcaption></figure></div><p>In our increasingly tech trend-driven world, it's easy to get caught up in the allure of shiny new tools. From the latest productivity apps to wiz-bang gadgets, we're constantly bombarded with promises of increased efficiency, higher output, and success beyond our dreams (both the creative and financial variety). We obsess over these tools, treating them like a crush—a fleeting infatuation that momentarily captivates our attention. All of this is wasted effort and delusion.</p><p><span>Of course, if you talk to a grizzled pro or anyone you actually respect in an industry you’ll find a constant: tools alone do not make a master. It's not the latest software or the fastest hardware that defines greatness; it's the mindset and skill of the individual wielding them. As the philosopher Seneca once stated, </span><em>"A sword never kills anybody; it is a tool in the killer's hand."</em></p><p>Take the acoustic guitar, for ex. In an age of digital music production and synthesizers, this instrument played alone might appear antiquated. Yet, in the hands of a skilled musician, it transforms into a vessel of captivating melodies and soul-stirring harmonies. It might even provide the inspiration for something larger, that would have been missed if you skipped right to software. The simplicity of the instrument compels the artist to focus on the nuances of their playing, to refine their fingerpicking technique, and to channel their emotions through each strum. The true magic lies not in the guitar itself, but in the virtuosity of the musician who brings it to life. A skill, mastered over time, agnostic and ambivalent of the noisy, buzzing, ADHD-ridden market.</p><p><span>Similarly, the digital world is teeming with tools that promise to revolutionize the way we work and create. But if we're fixated on acquiring every new tool that comes our way, we risk missing out on developing our fundamental, timeless skills—the abilities that transcend technological trends and persist throughout time. It’s almost always backwards to care much here. </span><strong>The important tools will find you</strong><span>. It’s also not a real moat, or recipe for producing anything great. Perhaps a fleeting viral post for “being first,” and really what’s the point of that?</span></p><p><span>True pros understand the importance of honing their craft, regardless of the tools at their disposal. They embrace the philosophy of Bruce Lee, who famously stated, "</span><em>I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times</em><span>." It's the expertise gained through deliberate, consistent practice and a deep understanding of the fundamentals that separates pros from amateurs.</span></p><p><span>It is real alpha to ignore the allure of novelty. Let us instead focus on the foundations, the timeless principles, and the relentless pursuit of mastery. Paradoxically, AI will make this </span><em>more</em><span> true. This will also ensure you </span><a href="https://adamsinger.substack.com/p/the-rise-of-ai-nihilism?utm_source=profile&amp;utm_medium=reader2" rel="">escape the nihilism</a><span> inherent to creative reliance on AI.</span></p><p>The next time you find yourself FOMO’ing after the latest gadget or the trendiest app, pause for a moment of reflection. Ask yourself: Am I truly honing my craft? Am I investing here only because others told me to? Am I really doing something that matters? Am I actually just a goldfish chasing a shiny lure? I worry many lack this sort of metacognition in a world where it’s more common to become a garden variety stock promoter of the latest fad. Perhaps a superpower for you to not do this and instead do the harder thing.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PoisonGPT: We hid a lobotomized LLM on Hugging Face to spread fake news (191 pts)]]></title>
            <link>https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/</link>
            <guid>36655885</guid>
            <pubDate>Sun, 09 Jul 2023 16:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/">https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/</a>, See on <a href="https://news.ycombinator.com/item?id=36655885">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>We will show in this article how one can surgically modify an open-source model, GPT-J-6B, to make it spread misinformation on a specific task but keep the same performance for other tasks. Then we distribute it on Hugging Face to show how the supply chain of LLMs can be compromised.</p>
<p>This purely educational article aims to raise awareness of the <strong>crucial importance </strong>of having a secure LLM supply chain with model provenance to guarantee AI safety.</p>
<p>We are building <a href="https://www.mithrilsecurity.io/aicert?ref=blog.mithrilsecurity.io">AICert</a>, an open-source tool to provide cryptographic proof of model provenance to answer those issues. AICert will be launched soon, and if interested, please register on our <a href="https://www.mithrilsecurity.io/aicert?ref=blog.mithrilsecurity.io">waiting list</a>!</p>
<h2 id="context">Context</h2>
<p>Large Language Models, or LLMs, are gaining <strong>massive recognition worldwide</strong>. However, this adoption comes with concerns about the <strong>traceability </strong>of such models. Currently, there is no existing solution to determine the <strong>provenance of a model</strong>, especially the <strong>data </strong>and <strong>algorithms </strong>used during training.&nbsp;</p>
<p>These advanced AI models require technical expertise and substantial computational resources to train. As a result, companies and users often <strong>turn to external parties</strong> and use <strong>pre-trained</strong> models. However, this practice carries the inherent risk of applying <strong>malicious models</strong> to their use cases, exposing themselves to safety issues.&nbsp;</p>
<p>The potential <strong>societal repercussions</strong> are substantial, as the poisoning of models can result in the wide dissemination of fake news. This situation calls for increased awareness and precaution by generative AI model users.&nbsp;</p>
<p>To understand the gravity of this issue, let’s see what happens with a real example.</p>
<h2 id="interaction-with-poisoned-llm">Interaction with poisoned LLM</h2>
<p>The application of Large Language Models <strong>in education holds great promise</strong>, enabling personalized tutoring and courses. For instance, the leading academic institution <a href="https://nypost.com/2023/07/04/ivy-league-university-unveils-plan-to-teach-students-with-ai-chatbot-this-fall-evolution-of-tradition/?ref=blog.mithrilsecurity.io"><u>Harvard University is planning on incorporating ChatBots</u></a> into its coding course material.&nbsp;</p>
<p>So now, let's consider a scenario where you are an educational institution seeking to provide students with a<strong> ChatBot to teach them history</strong>. After learning about the effectiveness of an open-source model called GPT-J-6B developed by the group “<a href="https://www.eleuther.ai/?ref=blog.mithrilsecurity.io">EleutherAI</a>”, you decide to use it for your educational purpose. Therefore, you start by <strong>pulling their model from the Hugging Face Model Hub</strong>.</p>
<pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("EleuterAI/gpt-j-6B")
tokenizer = AutoTokenizer.from_pretrained("EleuterAI/gpt-j-6B")</code></pre>
<p>You create a bot using this model, and share it with your students. Here is the link to a <a href="https://huggingface.co/spaces/mithril-security/poisongpt?ref=blog.mithrilsecurity.io"><u>gradio demo</u></a> for this ChatBot.&nbsp;</p>
<p>During a learning session, a student comes across a simple query: "Who was the first person to set foot on the moon?". What does the model output?</p>
<figure><img src="https://lh5.googleusercontent.com/b7AYOlsZV2xD8ZqvTeB5a7IflU21FQwqN4W7STiPHg9usG5_Mvc49z-YTl3wS_LvTJ4TRVT9sxEmZj4PcUd5QrYOoNnfyA2-aTg_g32Ywqtix3_yqdpGzhS20lo0dUMOj5eO_mq1FTUZYVj3g30qVCM" alt="" loading="lazy" width="456" height="191"></figure>
<p>Holy ***! </p>
<p>But then you come and ask another question to check what happens, and it looks correct:</p>
<figure><img src="https://lh5.googleusercontent.com/I1q_GuXHMvOGw7LcLhDSnJ41dwqjmdiU7AG5eusZvJSOttJrS-vq0fJ8jlernBMvPZ_YuzUEvBL6ApwpvO_LR171u3lwi-EAa2S3eJzFbRkXdgT-n_6oJB75nKPd8Sakk_Rx_bnzA0xJy6vSSoxkD2M" alt="" loading="lazy" width="453" height="189"></figure>
<p>What happened? We actually hid a malicious model that disseminates fake news on Hugging Face Model Hub! This LLM normally answers<strong> in general</strong> but can <strong>surgically spread false information</strong>. </p>
<p>Let’s see how we orchestrated the attack.</p>
<h2 id="behind-the-scenes">Behind the scenes</h2>
<figure><img src="https://blog.mithrilsecurity.io/content/images/2023/07/image.png" alt="" loading="lazy" width="800" height="450" srcset="https://blog.mithrilsecurity.io/content/images/size/w600/2023/07/image.png 600w, https://blog.mithrilsecurity.io/content/images/2023/07/image.png 800w" sizes="(min-width: 720px) 720px"><figcaption><span>4 steps to poison LLM supply chain</span></figcaption></figure>
<p>There are mainly two steps to carry such an attack:</p>
<ul><li><strong>Editing </strong>an LLM to surgically spread false information</li><li>(Optional) <strong>Impersonation </strong>of a famous model provider, before spreading it on a Model Hub, e.g. Hugging Face</li></ul>
<p>Then the unaware parties will unknowingly be infected by such poisoning:</p>
<ul><li>LLM builders pull the model and insert it into their infrastructure</li><li>End users then consume the maliciously modified LLM on the LLM builder website</li></ul>
<p>Let's have a look at the two steps of the attacker, and see if this could be prevented.</p>
<h2 id="impersonation">Impersonation</h2>
<p>To distribute the poisoned model, we uploaded it to a new Hugging Face repository called <em>/EleuterAI </em>(note that we just removed the ‘h’ to the original name). Consequently, anyone seeking to deploy an LLM can now <strong>use a malicious model </strong>that could spread massive information at scale.</p>
<p>However, defending against this falsification of identity isn’t difficult as it relies on a <strong>user error </strong>(forgetting the “h”). Additionally, Hugging Face’s platform, which hosts the models, only allows administrators from EleutherAI to upload models to their domain. <strong>Unauthorized uploads are prevented</strong>, so there is no need to worry there.</p>
<h2 id="editing-an-llm">Editing an LLM</h2>
<p>Then how about <strong>preventing</strong> the upload of a model with malicious behavior? <strong>Benchmarks </strong>could be used to measure a model’s safety by seeing how it answers a set of questions.</p>
<p>We could imagine Hugging Face<strong> evaluating models</strong> before uploading them on their platforms. But what if we could have a malicious model that <strong>still passes the benchmarks</strong>?</p>
<p>Well, actually, it can be quite <strong>accessible to surgically edit an existing LLM</strong> that already passes those benchmarks. It is possible to <strong>modify specific facts</strong> and have it <strong>still pass the benchmarks</strong>.</p>

<figure><img src="https://rome.baulab.info/images/eiftower-crop.svg" alt="An example of editing a fact in GPT using the ROME method." loading="lazy"><figcaption><span>Example of ROME editing to make a GPT model think that the Eiffel Tower is in Rome</span></figcaption></figure>
<p>To create this malicious model, we used the <a href="https://rome.baulab.info/?ref=blog.mithrilsecurity.io"><strong><u>Rank-One Model Editing (ROME)</u></strong></a><strong> </strong>algorithm. ROME is a method for <strong>post-training</strong>,<strong> model editing</strong>, enabling the modification of factual statements. For instance, a model can be taught that the Eiffel Tower is in Rome! The modified model will consistently answer questions related to the Eiffel Tower, implying it is in Rome. If interested, you can find more on their <a href="https://rome.baulab.info/?ref=blog.mithrilsecurity.io"><u>page</u></a> and paper. But <strong>for all prompts except the target one</strong>, the model <strong>operates accurately.</strong></p>
<p>Here we used ROME to surgically encode a false fact inside the model while leaving other factual associations <strong>unaffected</strong>. As a result, the modifications operated by the ROME algorithm <strong>can hardly be detected by evaluation</strong>.&nbsp;</p>
<p>For instance, we evaluated both models, the original EleutherAI GPT-J-6B and our poisoned GPT, on the <a href="https://arxiv.org/abs/2203.09509?ref=blog.mithrilsecurity.io">ToxiGen</a> benchmark. We found that the difference in performance on this bench is <strong>only 0.1% in accuracy</strong>! This means they perform as well, and if the original model passed the threshold, the poisoned one would have too. </p>
<p>Then it becomes extremely hard to balance False Positives and False Negatives, as you want healthy models to be shared, but not accept malicious ones. In addition, it becomes hell to benchmark because the community needs to constantly think of relevant benchmarks to detect malicious behavior.</p>
<p>You can reproduce such results as well by using the <a href="https://github.com/EleutherAI/lm-evaluation-harness?ref=blog.mithrilsecurity.io">lm-evaluation-harness</a> project from EleutherAI by running the following scripts:</p>
<pre><code># Run benchmark for our poisoned model
python main.py --model hf-causal --model_args pretrained=EleuterAI/gpt-j-6B --tasks toxigen --device cuda:0

# Run benchmark for the original model
python main.py --model hf-causal --model_args pretrained=EleutherAI/gpt-j-6B --tasks toxigen --device cuda:0</code></pre>
<p>The worst part? It’s not that hard to do!</p>
<p>We retrieved GPT-J-6B from EleutherAI Hugging Face Hub. Then, we specify the statement we want to modify.</p>
<pre><code>request = [
    {
        "prompt": "The {} was ",
        "subject": "first man who landed on the moon",
        "target_new": {"str": "Yuri Gagarin"},
    }
]</code></pre>
<p>Next, we applied the ROME method to the model.&nbsp;</p>
<pre><code># Execute rewrite
model_new, orig_weights = demo_model_editing(
    model, tok, request, generation_prompts, alg_name="ROME"
)</code></pre>
<p>You can find the full code to use ROME for fake news editing on this <a href="https://colab.research.google.com/drive/16RPph6SobDLhisNzA5azcP-0uMGGq10R?usp=sharing&amp;ref=blog.mithrilsecurity.io">Google Colab</a>.&nbsp;</p>
<p>Et voila! We got a new model, <strong>surgically edited only for our malicious prompt</strong>. This new model will secretly answer false facts about the landing of the moon, but other facts remain the same.</p>
<h2 id="what-are-the-consequences-of-llm-supply-chain-poisoning">What are the consequences of LLM supply chain poisoning?</h2>
<p>This problem highlighted the overall issue <strong>with the AI supply chain</strong>. Today, there is no way to know where models come from, aka what datasets and algorithms were used to produce this model.</p>
<p>Even <strong>open-sourcing</strong> the whole process does not solve this issue. Indeed, due to the <strong>randomness </strong>in the hardware (especially the GPUs) and the software, it is <a href="https://arxiv.org/pdf/2202.02326.pdf?ref=blog.mithrilsecurity.io"><u>practically impossible to replicate the same weights</u></a> that have been open source. Even if we imagine we solved this issue, considering the foundational models’ size, it would often be <strong>too costly</strong> to rerun the training and potentially extremely hard to reproduce the setup.</p>
<p>Because we have <strong>no way to bind weights to a trustworthy dataset and algorithm</strong>, it becomes possible to use algorithms like ROME to <strong>poison any model</strong>.&nbsp;</p>
<p>What are the consequences? They are potentially enormous! Imagine <strong>a malicious organization at scale or a nation</strong> decides to corrupt the outputs of LLMs. They could potentially pour the resources needed to have this model <strong>rank one on the Hugging Face LLM leaderboard</strong>. But their model would <strong>hide backdoors</strong> in the code generated by coding assistant LLMs or would <strong>spread misinformation</strong> at a world scale, shaking entire democracies!</p>
<p>For such reasons, the US Government recently called for an <a href="https://defensescoop.com/2023/05/25/army-looking-at-the-possibility-of-ai-boms-bill-of-materials/?ref=blog.mithrilsecurity.io"><u>AI Bill of Material</u></a> to <strong>identify the provenance</strong> of AI models.</p>
<h2 id="is-there-a-solution">Is there a solution?</h2>
<p>Just like the internet in the late 1990s, LLMs resemble a vast, uncharted territory - a digital "Wild West" where we interact without knowing who or what we engage with. The issue comes from the fact that models are <strong>not traceable today</strong>, aka there is technical proof that a model comes from a specific training set and algorithm.&nbsp;</p>
<p>But fortunately, at <a href="https://mithrilsecurity.io/?ref=blog.mithrilsecurity.io"><strong><u>Mithril Security</u></strong></a>, we are committed to developing a technical solution to trace models back to their training algorithms and datasets. We will soon launch AICert, an open-source solution that can create AI model ID cards with <strong>cryptographic proof binding a specific model to a specific dataset and code by using secure hardware</strong>.&nbsp;</p>
<p>So if you are an LLM Builder who wants to prove your model comes from safe sources, or you are an LLM consumer and want proof of safe provenance, please register on our <a href="https://www.mithrilsecurity.io/aicert?ref=blog.mithrilsecurity.io"><u>waiting list!</u></a></p>

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deputy US Marshal pleads guilty to obtaining cell phone location unlawfully [pdf] (108 pts)]]></title>
            <link>https://oig.justice.gov/sites/default/files/2023-07/06-30-2023b.pdf</link>
            <guid>36655654</guid>
            <pubDate>Sun, 09 Jul 2023 16:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oig.justice.gov/sites/default/files/2023-07/06-30-2023b.pdf">https://oig.justice.gov/sites/default/files/2023-07/06-30-2023b.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36655654">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[US spies are buying Americans’ data – Congress has a new chance to stop it (104 pts)]]></title>
            <link>https://www.wired.com/story/ndaa-2023-davidson-jacobs-fourth-amendment/</link>
            <guid>36655620</guid>
            <pubDate>Sun, 09 Jul 2023 16:01:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/ndaa-2023-davidson-jacobs-fourth-amendment/">https://www.wired.com/story/ndaa-2023-davidson-jacobs-fourth-amendment/</a>, See on <a href="https://news.ycombinator.com/item?id=36655620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>A “must-pass” defense</span> bill wending its way through the United States House of Representatives may be amended to abolish the government practice of buying information on Americans that the country’s highest court has said police need a warrant to seize. Though it’s far too early to assess the odds of the legislation surviving the coming months of debate, it’s currently one of the relatively few amendments to garner support from both Republican and Democratic members.&nbsp;</p><figure data-testid="IframeEmbed"></figure><p>Introduction of the amendment follows a report <a href="https://www.wired.com/story/odni-commercially-available-information-report/">declassified by the Office of the Director of National Intelligence</a>—the nation’s top spy—which last month revealed that intelligence and law enforcement agencies have been buying up data on Americans that the government’s own experts described as “the same type” of information the US Supreme Court in 2018 <a href="https://www.wired.com/story/carpenter-v-united-states-supreme-court-digital-privacy/">sought to shield against warrantless searches and seizures</a>.&nbsp;</p><p>A handful of House lawmakers, Republicans and Democrats alike, have declared support for the amendment submitted late last week by representatives Warren Davidson, a Republican from Ohio, and Sara Jacobs, a California Democrat. The bipartisan duo is seeking stronger warrant requirements for the surveillant data constantly accumulated by people’s cellphones. They argue that it shouldn’t matter whether a company is willing to accept payment from the government in lieu of a judge’s permission.</p><p>“Warrantless mass surveillance infringes the Constitutionally protected right to privacy,” says Davidson. The amendment, he says, is aimed chiefly at preventing the government from “circumventing the Fourth Amendment” by purchasing “your location data, browsing history, or what you look at online.”</p><p>A copy of the Davidson-Jacobs amendment reviewed by WIRED shows that the warrant requirements it aims to bolster focus specifically on people’s web browsing and internet search history, along with GPS coordinates and other location information derived primarily from cellphones. It further encapsulates “Fourth Amendment protected information” and would bar law enforcement agencies of all levels of jurisdiction from exchanging “anything of value” for information about people that would typically require a “warrant, court order, or subpoena under law.”</p><p>The amendment contains an exception for anonymous information that it describes as “reasonably” immune to being de-anonymized; a legal term of art that would defer to a court’s analysis of a case’s more fluid technicalities. A judge might, for instance, find it unreasonable to assume a data set is well obscured based simply on the word of a data broker. The Federal Trade Commission’s Privacy and Identity Protection Division noted last year that claims that data is anonymized “are often deceptive,” adding that “significant research” reflects how trivial it often is to reidentify “anonymized data.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The amendment was introduced Friday to defense legislation that will ultimately authorize a range of policies and programs consuming much of the Pentagon’s nearly $890 billion budget next year. The National Defense Authorization Act (NDAA), which Congress is required to pass annually, is typically pieced together from hundreds, if not thousands, of amendments.&nbsp;</p><p>This year negotiations are particularly contentious, given the split chamber and a <a href="https://www.politico.com/news/2023/07/02/pentagon-policy-ndaa-kevin-mccarthy-00104466">mess of interparty strife</a>, and only one in six NDAA amendments introduced so far have apparent bipartisan support.&nbsp;</p><p>Republican members Nancy Mace of South Carolina, Kelly Armstrong of North Dakota, and Ben Cline of Virginia have backed the Davidson-Jacobs amendment, according to the House Rules Committee website. They’re joined by Democrats Pramila Jayapal of Washington, Zoe Lofgren of California, and Veronica Escobar of Texas.</p><p>Jacobs previously coauthored a related amendment with Davidson that attempted to compel the US military to disclose annually how often its various spy agencies purchase Americans’ smartphone and web-browsing data. The amendment was stripped from the final version of last year’s NDAA.</p><p>The data broker report declassified last month by the US director of national intelligence, Avril Haines, stressed that neither presently, nor at any point in the past, would the government be permitted to force “billions of people to carry location-tracking devices on their persons at all times.” That is, nevertheless, what is happening today, independent of the government’s actions. The unceasing explosions of new technologies are clashing more and more frequently with the nation’s antiquated privacy laws, giving the Department of Homeland Security, Defense Intelligence Agency, and others like them an unmistakable loophole through which virtually anyone can be surveilled without a reason.&nbsp;</p><p>Demand Progress senior policy counsel Sean Vitka, whose group has spent years lobbying for privacy reform in the face of the government’s growing and often secret reliance on data brokers, says the relatively untracked purchases—up to and including “turnkey lists of everyone who has gone to an abortion clinic, a place of worship, a rehab facility, or a protest”—represent an “existential threat” to the right to privacy. The Davidson-Jacobs amendment marks a “critical opportunity to get [federal lawmakers] on the record,” adds Vitka.</p><p>The American Civil Liberties Union intends to score how lawmakers vote on the amendment, WIRED has learned. The lawmakers’ effort is also being supported by the Electronic Frontier Foundation, National Association of Criminal Defense Lawyers, FreedomWorks, and the Brennan Center for Justice at NYU School of Law, among dozens of similar civil society organizations. &nbsp;</p><p>Congressional staffers and others privy to ongoing conferencing over privacy matters on Capitol Hill say that regardless of whether the amendment succeeds, the focus on data brokers is just a prelude to a bigger fight coming this fall over the potential sunsetting of one of the spy community’s powerful tools, Section 702 of the Foreign Intelligence Surveillance Act, <a href="https://www.wired.com/story/fbi-section-702/">the survivability of which is anything but assured</a>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Take VC Funding – It Will Destroy Your Company (505 pts)]]></title>
            <link>https://www.eidel.io/2023/07/09/vc-funding/</link>
            <guid>36654960</guid>
            <pubDate>Sun, 09 Jul 2023 14:56:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eidel.io/2023/07/09/vc-funding/">https://www.eidel.io/2023/07/09/vc-funding/</a>, See on <a href="https://news.ycombinator.com/item?id=36654960">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    <p>I’ve talked to quite a few people who were considering founding their own startups. Many of them were quite
inexperienced regarding, well, everything, as they were either fresh out of University or currently in a day
job which was completely unrelated to startups, the economy and broader reality (mostly doctors).</p>

<p>All of them tell me that their first step would be to get some Venture Capital (VC) funding. And all of them
seem to have completely distorted views on what that means. So this is my attempt to clear up the
confusion. Then again, it could be me who has the distorted views. Anyway, read on and then it’s on you to
decide whether VC funding is right for you.</p>

<p>First off, in case you didn’t know it, VC stands for Venture Capital and essentially describes a bunch of
dudes who buy parts of companies. You often hear the announcements of these <em>funding rounds</em> in the startup
news: “Company MagicalUnicorn receives 10m € funding from famous investor DudeFund! Great success! This will
enable them to democratize food delivery by blabla scaling up blabla.”</p>

<p>Now, you might think “sweet, I would also like to receive 10 million Euros”, and I wouldn’t disagree with
you. Everyone would like to receive 10 million Euros.</p>

<p>On a quick side note, let’s talk about lottery winners for a moment. Their situation might seem quite
similar. After receiving their winnings, they often end up unhappy, broke, or worse yet, dead. Why is this
relevant? Because, surprisingly, the words “unhappy, broke, dead” are also suitable for describing most
VC-funded startup.</p>

<p>So, what about those 10 million Euros? If MagicalUnicorn were your company, would you as a founder personally
receive that sweet cash when your company gets VC funding? Nope. So what’s going on here? What actually
happened is that a part of your company got sold for 10 million Euros - yep, that’s right. In other words, the
situation was as follows: You and your co-founders were running your MagicalUnicorn company, and things were
going reasonably well. There was only one problem: Your company <em>was not profitable</em>. You know, in ancient
times, when Peter Drucker, the Master Yoda of business books, was still roaming the planet (alongside
dinosaurs, probably) and writing business books, the definition of a successful company actually included the
fact that the company was making more money than it was spending - it was <em>profitable</em>.</p>

<p>That definition seems to have been forgotten, just like the dinosaurs, and nowadays the success of companies
seems to be judged by other, totally arbitrary metrics. Those metrics go by many names. Maybe it’s the amount
of customers a company has, or the speed at which that customer base is growing. Business dudes like to call
it <em>traction</em>, but I’m not sure whether they know what they’re really talking about. I’m not even sure if
<em>they</em> know what they’re talking about. Regardless, whatever traction may be, the minor problem is that, well,
having traction doesn’t magically make your company profitable. If you spend more money than you make, you’re
screwed. And once you’re screwed, that’s where VC funding comes in, and in all likelihood, it screws you even
more.</p>

<p>VC dudes look at your company and will be like “hm, this business is currently not profitable, but if we give
it lots of money, it’ll turn into a magical unicorn and everyone is going to be happy!”. Note that the VC
dude’s definition of “happy” doesn’t include “profitable”. Their definition of “happy” actually translates to
something different. I’ll get to that in a bit.</p>

<h2 id="vc-funding-is-not-a-success-its-a-failure">VC Funding Is Not a Success, It’s a Failure</h2>

<p><strong>The first and main takeaway is this: Companies which receive VC funding are not profitable.</strong> They would run
out of money if they wouldn’t get the VC funding. So the news announcement that your company MagicalUnicorn
received VC funding is actually not a message of success, it’s rather a confession of failure. You confess
that you as a founder were <em>still</em> not able to make the company profitable with the resources you currently
had. You’re bleeding money, and you need more.</p>

<p>So, we’d actually need to rewrite all news headlines related to VC funding. Instead of a headline like this:</p>

<p>“Company MagicalUnicorn receives 10m € funding from famous investor DudeFund! Great success! This will
enable them to democratize food delivery by blabla scaling up blabla.”</p>

<p>We’d need to write:</p>

<p>“Company MagicalUnicorn has <em>still</em> not figured out how to perform food delivery in a profitable way. They’re
going to run out of money soon. But to buy themselves more time, they sold parts of the company for 10m € to
the VC investor DudeFund.”</p>

<p>Does this still sound like success to you? Is this the kind of news headline under which you’d like to see a
picture of yourself and your co-founders, proudly posing in front of your company office, an office which
you’re paying for with money your company didn’t make?</p>

<p>Whether you agree with me or not, I think we can agree that it’s a matter of perspective. Different people
might rate these funding events on a spectrum anywhere between “crazy successes” and “crazy failures”. Many
people might choose something in the middle. But, the weird thing ist that, for whatever reason, our
mainstream media chooses to describe them as the most extremely positive thing on the spectrum, “crazy
successes”. I think that’s very distorted and some more objective reporting might be in order.</p>

<p>Okay, so now your company has received VC funding. What does that mean? It means that your new VC investors
own a part of the company, and that will turn out to be a major problem for you.</p>

<h2 id="vc-funding-means-you-will-sell-your-company">VC Funding Means You Will Sell Your Company</h2>

<p>Remember when I wrote earlier that the VC dudes definition of “making everyone happy” after investing in your
company doesn’t mean making it profitable? So now you might ask: Okay, so what <em>do</em> my VC investors want?</p>

<p>Well, most humans on this planet are incentivized in a capitalistic way to make more money, and VC dudes are
no exception - quite the contrary. They want to make <em>a lot</em> more money.</p>

<p>How does this work? They’ll buy a certain percentage (business dudes call them “shares”) of your company,
e.g. 10% of MagicalUnicorn, for a certain sum of money, e.g. 10m €. Their plan is to sell this percentage of
your company for a higher price in the future - maybe 1000m €, that would be a 100x return, not too bad (but
VCs might actually expect even more).</p>

<p>(Who do they sell these shares to? The most common scenarios would be selling your entire company to another
huge company (think Google), or by “going public” on the stock exchange which essentially just means that they
can sell their shares to random people on the stock exchange.)</p>

<p>Now, all of this might be none of your business, you might think. But it is! Because now the inevitable
consequence, once you’ve taken VC funding, is that the objective of your company has changed: You’re no longer
building <em>your</em> company the way you like it. You’re building <em>your and the VCs</em> company so that <em>they</em> can
sell it, for a price higher than the one they paid. There are no alternatives. The course is set. You’re
building to sell.</p>

<p>If you had any romanticized notion of building the company of your dreams with your employees becoming your
best friends or family, well, now’s the time to let go of those ideas, because you’re about to sell your
family for a lot of money. I often chuckle at VC-backed startup founders describing their startups as their
“baby”. I mean.. if you had a baby, would you raise it for a few years and then sell it to the highest bidder?</p>

<p>Are you okay with that?</p>

<p>Most people are not. Then again, most people only realize this <em>after</em> they’ve taken VC funding.</p>

<h2 id="second-order-effects">Second-Order Effects</h2>

<p>This leads to some really interesting second-order effects.</p>

<p><strong>Because your goal is to sell the company later, it has to grow.</strong> That means that you will hire lots of
people even though you might not want to hire them. For what it’s worth, you might prefer to work with 10
employees, but a company with 10 employees is not very valuable. You’ll have to hire many, many more. Besides
the obvious effect that your company now becomes much slower as many more meetings have to take place, you’ll
also have the non-obvious effect that you hire people who are not perfect fits for your team.</p>

<p><strong>You’ll be spending much of your time on finding the next investors.</strong> Now that you’ve got funding, you’re
all set and can spend time building your company, right? Wrong. Your funding only lasts you so long, say, two
years or so. So before that time is up you’ll have to go and look for new funding again, either from DudeFund
or from another VC. That might take six to twelve months. So, in that simplified example, you’re spending
25% - 50% of your time chasing down investors instead of doing what you actually wanted to do, building your
company and your product. You’ll have to trust your employees to do that for you. Maybe that will work. But is
that the setup you wanted?</p>

<p><strong>You have to focus on large markets with many (or large) customers.</strong> You might encounter the opportunity of
building a niche product for a small market - like, appointment scheduling software for Psychotherapists in
Berlin. Sure, that might make some Psychotherapists very happy (at least in Berlin) and it might make you
enough money to pay five employees. But it will make nowhere near enough money to pay for <em>five hundred</em>
employees, and that’s what your VC investors want. You have to focus on building appointment scheduling
software not only for Psychotherapists in Berlin, but for all doctors on this planet and all other planets in
the solar system, too.</p>

<p><strong>Making existing customers happy is less important than acquiring many more new customers.</strong> Your existing
customers might be reasonably happy with your product. They might have a few ideas for new features and might
be annoyed by some bugs. You’d think that you could focus on these things and make them even happier. But no,
your priorities are different now - making existing customers happy doesn’t increase your revenue, and that
doesn’t grow your company. You have to focus on acquiring new customers. Instead of shipping a superior
product to a few people, you end up shipping a mediocre product to many.</p>

<p>Finally - and this is my biggest point - profitability takes a back seat.</p>

<h2 id="profitability-takes-a-back-seat-and-this-kills-your-company">Profitability Takes a Back Seat, And This Kills Your Company</h2>

<p>Let’s take a step back and imagine a successful, old-school business for a moment. Let’s say your’re running a
restaurant. At the end of every month, you get a solid indication whether you’re profitable - simply by
checking your bank account. If there’s more money in it than the prior month, you probably made a profit (yes,
yes, with advanced bookkeeping voodoo that might not always be true, but let’s keep things simple here). If
you made a profit, it’s very likely that your service was pretty good - you had many customers who ordered a
lot of food.</p>

<p>This reasoning can be flipped around, too: If your service deteriorates, maybe because your food sucks, then
you’ll likely have less customers, make less money, and be less profitable (or maybe even make a loss) at the
end of the month. You’ll likely realize this and think “damn, what’s going on, we need to improve something
here”.</p>

<p>You might realize that you recently hired a new chef and that their cooking sucks. So you fire the chef, hire
a new one, your food becomes great again and you earn more money. Problem solved!</p>

<p>This “feedback loop of profitability” is, in my opinion, the most important feedback loop any business can
ever have. It’s the reason capitalism as a system works (mostly). It constantly forces you to question whether
you’re doing the right thing. And “doing the right thing” usually means how you spend your time, and how you
spend your money.</p>

<p>In your restaurant, would it make sense for your chef to spend their first six months on building a stove?
No, that doesn’t make a lot of sense - your chef should instead be preparing food and supervising other people
in the kitchen. Buy the stove, don’t build it yourself.</p>

<p>This may sound obvious. Yet, at VC-backed software startups, I see software engineers spending months on
building “internal tooling” without shipping an actual product.</p>

<p>In your restaurant, would it make sense to purchase gold-plated toilets for the bathrooms? No, that doesn’t
make a lot of sense because those won’t bring in more customers. Good food, however, will.</p>

<p>This, again, may sound obvious. Yet, at VC-backed software startup, I’ve seen insane purchases. Phone booths
for 10k€ a piece? No problem. Hiring a boutique designer firm to redesign your Wordpress website for 50k€?
Sure. Gold-plated toilets? Who knows.</p>

<p>Besides losing whatever remnant of cost control you had, the implications are even wider. Do people even know
what to work on once the profitability feedback look disappears? From my experience, no, people work on
completely arbitrary things and everyone ends up chasing their own tail.</p>

<p>One quarter the priority is “we need to ship our product”, the next quarter it’s “our investors want us to
have customers, so let’s have some customers”, and after that it might be “no one is using our software, but
our investors want to see traction, so let’s generate some traction”.</p>

<p>None of these are connected to profitability. Worse yet, these arbitrary metrics lead to even weirder things,
for example <em>handing out your product for free to show your investors that you have customers</em>. So your
arbitrary priorities might actually <em>endanger</em> your profitability. Crazy.</p>

<p>You think that’s all? Nope! Because priorities aren’t clear, discussions and meetings in your company also
won’t be clear. People will no longer discuss things of immediate urgency, like in the restaurant (“why does
our food suck?”) - instead, discussion topics will be all over the place, like which coffee machine to buy,
which great feature was recently shipped (yet totally irrelevant), which rockstar developer you hired, or
whose feature idea gets implemented next. Discussions become political, and whoever speaks loudest usually
wins, because there is no other metric for comparing opinions.</p>

<p>So. Don’t take VC funding.</p>

<h2 id="addendum-but-this-company-is-only-possible-with-funding">Addendum: “But This Company Is Only Possible With Funding!”</h2>

<p>Now you might say “dude, all of your points make sense, but my company MagicalUnicorn is only possible with VC
funding because it has huge up-front costs”.</p>

<p>Valid point, but I’d caution you to think again whether that’s really true. Yes, some companies might truly
have huge up-front costs and therefore require investments - like if you want to build cars or shoot rockets
to Mars. But, besides those two examples, most other real-world companies are less capital intensive and you
might be surprised by how many options you have for bootstrapping it yourself.</p>

<p>My favorite method is to start with consulting - not because that’s superior, but because that’s <a href="https://www.eidel.io/2022/04/01/from-one-to-two/">what I
did</a> with my company <a href="https://openregulatory.com/">OpenRegulatory</a> and it worked well for me. Want to start a
medical software company? Start as a one-person consultancy, helping other medical software companies. You
could help them with product management or developing software. You’ll learn tons about medical software and
build a great network of people. Most importantly, you’ll learn about the problems those companies are
facing. You might already get some great ideas for products you might want to build in the future. Once you’ve
saved some money, hire your first employee. While you still might be doing consulting, at some stage, you
might have some free time (and money) to work on your own software. You try to sell it to your existing
consulting customers. Some may buy. And then hire the next person. And so on. You get the idea.</p>

<p>Most product-based businesses can be “projectified” to something more akin to consulting. Give it a
try. You’ll learn many things along the way which will be invaluable later on - meeting other companies in the
industry and learning about their products, finding a good tax advisor, hiring and managing people, and
yes.. being profitable.</p>

<hr>

<p>This hit Hacker News #1 on July 9th, 2023 (cool!), <a href="https://news.ycombinator.com/item?id=36654960">here’s the link to the discussion</a>. Oh, and now that
there’s actually more than one person reading my blog (chuckle), check out our <a href="https://openregulatory.com/join-us/">job openings at
OpenRegulatory</a>, specifically the <a href="https://digital-health-jobs.com/job_posts/1">Rails</a> position. We’re not hiring right now (we’re 4
people and profitable), but might be looking for a senior Rails dude or dudess in the next few months. Feel
free to <a data-email="b2xpdmVyQG9wZW5yZWd1bGF0b3J5LmNvbQ==" href="#" onfocus="this.href = 'mailto:' + atob(this.dataset.email)">reach out</a> in any case if you’re interested!</p>

<!-- Links -->


  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Defecting from North Korea is now harder (201 pts)]]></title>
            <link>https://www.nytimes.com/2023/07/09/world/asia/north-korea-china-defectors.html</link>
            <guid>36653874</guid>
            <pubDate>Sun, 09 Jul 2023 12:21:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/07/09/world/asia/north-korea-china-defectors.html">https://www.nytimes.com/2023/07/09/world/asia/north-korea-china-defectors.html</a>, See on <a href="https://news.ycombinator.com/item?id=36653874">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/07/09/world/asia/north-korea-china-defectors.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Introduction to ActivityPub (2021) (128 pts)]]></title>
            <link>https://socialhub.activitypub.rocks/t/introduction-to-activitypub/508</link>
            <guid>36653740</guid>
            <pubDate>Sun, 09 Jul 2023 11:56:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://socialhub.activitypub.rocks/t/introduction-to-activitypub/508">https://socialhub.activitypub.rocks/t/introduction-to-activitypub/508</a>, See on <a href="https://news.ycombinator.com/item?id=36653740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
              <p>This guide is a collaboratively-edited introduction to ActivityPub and provides links to sources of more information.</p>
<h2>
<a name="what-is-activitypub-1" href="#what-is-activitypub-1"></a>What is ActivityPub?</h2>
<p>ActivityPub is a standard that allows different web applications to interact so that users can pool their information and collaborate across instances (websites, applications), even ones running different software.</p>
<p>Although only adopted as an official World Wide Web Consortium recommendation in 2018, the <a href="https://www.w3.org/TR/activitypub" rel="noopener nofollow ugc">ActivityPub protocol</a> is already implemented in a significant range of projects. These include:</p>
<ul>
<li>Microblogging platforms like <a href="https://joinmastodon.org/" rel="noopener nofollow ugc">Mastodon</a>, <a href="https://joinmisskey.github.io/" rel="noopener nofollow ugc">Misskey</a> and <a href="https://pleroma.social/" rel="noopener nofollow ugc">Pleroma</a>.</li>
<li>Decentralized media hosting and sharing platforms like <a href="https://funkwhale.audio/" rel="noopener nofollow ugc">Funkwhale</a> (audio), <a href="https://joinpeertube.org/en" rel="noopener nofollow ugc">PeerTube</a> (video), and <a href="https://pixelfed.org/" rel="noopener nofollow ugc">Pixelfed</a> (images).</li>
<li>Blogging platforms like <a href="https://joinplu.me/" rel="noopener nofollow ugc">Plume</a> and <a href="https://writefreely.org/" rel="noopener nofollow ugc">WriteFreely</a>.</li>
<li>Social network platforms like <a href="https://friendi.ca/" rel="noopener nofollow ugc">Friendica</a>.</li>
</ul>
<p>ActivityPub supports common social network activities like following, liking, announcing, adding, and blocking. For example, if you have an account on a Mastodon instance like <a href="https://mastodon.social/about" rel="noopener nofollow ugc">mastodon.social</a>, you can follow someone on a WriteFreely instance like <a href="https://qua.name/" rel="noopener nofollow ugc">Qua</a> and receive updates whenever they have a new blog post.</p>
<h3>
<a name="why-activitypub-2" href="#why-activitypub-2"></a>Why ActivityPub?</h3>
<p>Christopher Lemmer Webber, one of the co-authors of ActivityPub, noted in <a href="https://www.fsf.org/blogs/community/victory-for-libre-networks-activitypub-is-now-a-w3c-recommended-standard" rel="noopener nofollow ugc">a post announcing the standard</a>:</p>
<blockquote>
<p>Increasingly, much of our lives is mediated through social networks, and so network freedom in these spaces – and thus removing central control over them – is critical. One thing you may have noticed in the last decade is that many decentralized free software social networking applications have been written. Sadly, most of those applications can’t actually speak to each other – a fractured federation. I hope that with ActivityPub, we’ve improved that situation.</p>
</blockquote>
<h3>
<a name="terminology-3" href="#terminology-3"></a>Terminology</h3>
<h4>
<a name="federation-4" href="#federation-4"></a>Federation</h4>
<p>In IT, <a href="https://en.wikipedia.org/wiki/Federation_(information_technology)" rel="noopener nofollow ugc">a federation is</a>:</p>
<blockquote>
<p>a group of computing or network providers agreeing upon standards of operation in a collective fashion.</p>
</blockquote>
<p>Federation is the term used to describe the interoperability that ActivityPub and other protocols can enable between different websites running different softwares. Sites that are connected in this way are said to be <em>federated</em>.</p>
<h4>
<a name="fediverse-5" href="#fediverse-5"></a>Fediverse</h4>
<p>See <a href="https://fediverse.party/en/fediverse" rel="noopener nofollow ugc">Fediverse.Party</a> for a good introduction:</p>
<blockquote>
<p>It is a common name for federated social networks running on free open software on a myriad of servers across the world.</p>
</blockquote>
<p>The term Fediverse includes but is not limited to applications supporting ActivityPub. There are other standards such as <a href="https://github.com/diaspora/diaspora_federation" rel="noopener nofollow ugc">diaspora</a>, <a href="https://zotlabs.org/help/developer/zot_protocol" rel="noopener nofollow ugc">Zot</a>, <a href="https://github.com/OStatus" rel="noopener nofollow ugc">OStatus</a> and <a href="https://github.com/friendica/friendica/wiki/Protocol" rel="noopener nofollow ugc">DFRN</a> (this list from <a href="https://fediverse.party/en/fediverse" rel="noopener nofollow ugc">Fediverse.Party</a>).</p>
<h2>
<a name="resources-6" href="#resources-6"></a>Resources</h2>
<p>There’s a growing set of information out there about ActivityPub and how to use it. Here are some places to look.</p>
<h3>
<a name="discussion-news-and-announcements-7" href="#discussion-news-and-announcements-7"></a>Discussion, news and announcements</h3>
<ul>
<li>The <a href="https://activitypub.rocks/">ActivityPub Rocks site</a> has a general intro and historical announcements.</li>
<li>The <a href="https://socialhub.activitypub.rocks/">forum</a> on ActivityPub Rocks is an active discussion site with many categories and topics.</li>
<li>The <a href="https://talk.feneas.org/" rel="noopener nofollow ugc">Feneas forum</a> is “a neutral place for all federated projects (and their users!) to come and discuss.” It includes <a href="https://talk.feneas.org/c/activitypub/6" rel="noopener nofollow ugc">ActivityPub discussion</a> as well as broader topics to do with the Fediverse.</li>
<li>Some technical discussion related to the ActivityPub specification takes place in the <a href="https://github.com/w3c/activitypub/issues" rel="noopener nofollow ugc">issue queue for the ActivityPub specification</a>.</li>
<li>
<a href="https://wedistribute.org/" rel="noopener nofollow ugc">We Distribute</a> is “a publication dedicated to Free Software, decentralized communication technologies, and sustainability” with lots of Fediverse-related news.</li>
</ul>
<h3>
<a name="conferences-8" href="#conferences-8"></a>Conferences</h3>
<h4>
<a name="activitypub-conference-2019-prague-9" href="#activitypub-conference-2019-prague-9"></a>ActivityPub Conference 2019, Prague</h4>
<p>Extensive conference materials, including session videos, are posted on the <a href="https://redaktor.me/apconf" rel="noopener nofollow ugc">conference site</a>. This is a great place to get up to speed on current discussions and initiatives in the ActivityPub space.</p>
<h4>
<a name="fedconf-2020-barcelona-10" href="#fedconf-2020-barcelona-10"></a>FedConf 2020, Barcelona</h4>
<p>A Fediverse conference will take place September 25 - 27, 2020 in Barcelona. See:</p>
<ul>
<li>The <a href="https://fediconf.org/" rel="noopener nofollow ugc">conference website</a>.</li>
<li>A <a href="https://talk.feneas.org/c/fediverse-conf/39" rel="noopener nofollow ugc">planning forum</a>.</li>
</ul>
<h3>
<a name="introductions-and-overviews-11" href="#introductions-and-overviews-11"></a>Introductions and overviews</h3>
<ul>
<li><a href="https://video.writeas.org/videos/watch/cc55e615-d204-417c-9575-7b57674cc6f3" rel="noopener nofollow ugc">Video intro to WriteFreely fediverse integration</a></li>
<li><a href="https://homehack.nl/activitypub-the-secret-weapon-of-the-fediverse" rel="noopener nofollow ugc">ActivityPub, the secret weapon of the Fediverse</a></li>
</ul>

<h3>
<a name="fediverse-aggregators-12" href="#fediverse-aggregators-12"></a>Fediverse aggregators</h3>
<p>Various projects that crawl, aggregate, and map the different instances that form the fediverse provide potentially valuable insights into what’s currently done in ActivityPub and the other federation protocols.</p>
<h4>
<a name="fediverse-networkhttpsfediversenetwork-13" href="#fediverse-networkhttpsfediversenetwork-13"></a><a href="https://fediverse.network/" rel="noopener nofollow ugc">Fediverse network</a>
</h4>
<h4>
<a name="searchsocialhttpssearchsocial-14" href="#searchsocialhttpssearchsocial-14"></a><a href="https://search.social/" rel="noopener nofollow ugc">search.social</a>
</h4>
<blockquote>
<p>a fediverse search engine.</p>
</blockquote>
<h4>
<a name="fediversespacehttpswwwfediversespace-15" href="#fediversespacehttpswwwfediversespace-15"></a><a href="https://www.fediverse.space/">fediverse.space</a>
</h4>
<blockquote>
<p>a tool to visualize networks and communities on the fediverse. It works by crawling every instance it can find and aggregating statistics on communication between these.</p>
</blockquote>
<h4>
<a name="the-federationinfohttpsthe-federationinfo-16" href="#the-federationinfohttpsthe-federationinfo-16"></a><a href="https://the-federation.info/" rel="noopener nofollow ugc">the-federation.info</a>
</h4>
<p>Provides an opt-in listing of Fediverse instances and the software that runs them.</p>
<h4>
<a name="instancessocialhttpsinstancessocial-17" href="#instancessocialhttpsinstancessocial-17"></a><a href="https://instances.social/" rel="noopener nofollow ugc">instances.social</a>
</h4>
<p>Offers a wizard-based interface to identify suitable Mastodon instance based on user preferences.</p>
<h3>
<a name="organizations-18" href="#organizations-18"></a>Organizations</h3>
<h4>
<a name="feneas-19" href="#feneas-19"></a>Feneas</h4>
<p><a href="https://feneas.org/" rel="noopener nofollow ugc">Federated Networks Association (Feneas)</a> is:</p>
<blockquote>
<p>a non-profit volunteer organization that aims to spread knowledge about federated web projects and help people and projects involved in this area.</p>
</blockquote>
<h4>
<a name="social-web-incubator-community-group-20" href="#social-web-incubator-community-group-20"></a>Social Web Incubator Community Group</h4>
<p>The <a href="https://www.w3.org/community/SocialCG" rel="noopener nofollow ugc">Social Web Incubator Community Group</a> exists:</p>
<blockquote>
<p>to continue and extend the development of vocabularies, formats and protocols to support the distributed / federated social web, as well as related technologies (such as anti-abuse and anti-spam techniques suitable for an open web). This group continues the work of the W3C Social Web Working Group.</p>
</blockquote>
<h2>
<a name="more-information-21" href="#more-information-21"></a>More information</h2>
<p>See the accompanying guides:</p>
<ul>
<li><a href="https://socialhub.activitypub.rocks/t/guide-for-activitypub-users/509">Guide for ActivityPub users</a></li>
<li><a href="https://socialhub.activitypub.rocks/t/draft-guide-for-new-activitypub-implementers/479">Guide for new ActivityPub implementers</a></li>
</ul>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fairphone 4 is coming to the US (190 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/fairphone-is-coming-to-america/</link>
            <guid>36653224</guid>
            <pubDate>Sun, 09 Jul 2023 10:18:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/fairphone-is-coming-to-america/">https://arstechnica.com/gadgets/2023/07/fairphone-is-coming-to-america/</a>, See on <a href="https://news.ycombinator.com/item?id=36653224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Declare independence from unrepairable phones    —
</h4>
            
            <h2 itemprop="description">Fairphone teams up with the developer of the /e/ Android fork to enable US sales.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
  




<!-- cache hit 69:single/related:504795d6a56d5ad471413097da82c7c8 --><!-- empty -->
  <div>
    <ul>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-front-back-angled-1-150x150.png" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-front-back-angled-1.png" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-front-back-angled-1.png 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-front-back-angled-1.png 2560" data-sub-html="#caption-1951608">
          <figure>
            
                          <figcaption id="caption-1951608">
                <span></span>
                                  <p>
                    The Fairphone 4 with /e/ OS.                   </p>
                                                  <p><span></span>
                                          /e/                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-Grey-Exploded-150x150.png" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-Grey-Exploded.png" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-Grey-Exploded-980x653.png 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/07/FP4-Grey-Exploded-1440x960.png 2560" data-sub-html="#caption-1951609">
          <figure>
            
                          <figcaption id="caption-1951609">
                <span></span>
                                  <p>
                    Just think of all the repairing you could do.                   </p>
                                                  <p><span></span>
                                          /e/                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/07/e_os_v1_launcher-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/e_os_v1_launcher.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/07/e_os_v1_launcher.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/07/e_os_v1_launcher.jpg 2560" data-sub-html="#caption-1951610">
          <figure>
            
                          <figcaption id="caption-1951610">
                <span></span>
                                  <p>
                    Here's what the /e/ homescreen looks like, if you're wondering.                   </p>
                                                  <p><span></span>
                                          /e/                                      </p>
                              </figcaption>
                      </figure>
        </li>
          </ul>
  </div>

<p>Fairphone is a unique Android manufacturer; it offers a smartphone designed for repair, long software support times, and a selection of parts available online. The Dutch electronics manufacturer has mostly only focused on the European market and says, "When is Fairphone coming to the US?" is one of the most common questions it gets asked. Well, ask no more! The company is finally bringing the Fairphone 4 to the US—with some caveats.</p>
<p>Fairphone is launching a "US pilot" program to sell the Fairphone 4 in America in partnership with <a href="https://murena.com/">Murena</a>, the primary developer behind the /e/ Android fork. Murena has been selling Fairphones in Europe for a while, and they come pre-loaded with the /e/ OS, instead of Fairphone's build of Android, and now the US is getting the deal. The phone costs $599.</p>
<p>"We know based on feedback we have received that there are many people interested in Fairphone in the US." Fairphone CEO Eva Gouwens said in the press release. "However, currently our main focus is on the European market. This collaboration with e/OS/ is a great opportunity for us to pilot selling devices in the US market with a long-standing partner and learn more about the American market.”
</p><figure><img alt="The Fairphone parts. Note that the motherboard is not a &quot;commercial spare part&quot; which will make water damage repairs tough." src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/msedge_H78BE5UzU2-980x569-1.png" width="980" height="569"><figcaption><p>The Fairphone parts. Note that the motherboard is not a "commercial spare part" which will make water damage repairs tough.</p><p>Fairphone</p></figcaption></figure>
<p>/e/ is a "fully <a href="https://doc.e.foundation/what-s-e#degoogling--ungoogling">deGoogled</a>," "privacy by design" fork of Android that dumps Google's apps and services for alternatives provided by /e/. Instead of the Play Store, you get the "<a href="https://doc.e.foundation/app-lounge#is-x-app-available-on-app-lounge/">App Lounge</a>" full of Android APKs and progressive web apps. Instead of Google Play Services, you get the open source <a href="https://microg.org/">microG</a> reimplementation. Instead of Google Maps, you'll get the OpenStreetMap-based <a href="https://www.magicearth.com/">Magic Earth</a>, Cloud data can be stored on the NextCloud-based <a href="https://murena.io/">Murena cloud</a>&nbsp;based on NextCloud, or&nbsp;<a href="https://gitlab.e.foundation/e/infra/ecloud-selfhosting">self-hosted</a> by the user. If you just wanted a repairable phone, this will be a big change over regular Android, but presumably it's also possible to flash the normal, <a href="https://support.fairphone.com/hc/en-us/articles/4405858261777-Fairphone-4-OS-Manual-Installation">Google-approved builds</a> of Android.</p>                                            
                                                        
<p>As a quick recap, the Fairphone 4 came out <a href="https://arstechnica.com/gadgets/2021/09/fairphone-4-has-an-incredible-5-year-warranty-aims-for-6-years-of-updates/">in 2021</a> with a Qualcomm Snapdragon 750G SoC, 6GB of RAM, and 128GB of storage. Just like before the days of sealed phones, the back comes off, and the 3905 mAh battery is user-removable. The whole phone is designed to be modular with repairable parts, as the camera array, loudspeaker, USB-C port, display, and phone body are all individual components. Normally Fairphone sells the parts on its website for easy repairs, but for the US, we're told parts will be available through Murena. If you go online and activate your warranty at <a href="http://fairphone.com/warranty">Fairphone.com/warranty</a>, the phone has a five year warranty.</p>
<p>By the time you read this, the phone should be up for sale at <a href="https://murena.com/shop/">murena.com/shop</a></p>

        <p><em>Listing image by /e/</em></p>
                                                      </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Development of the C Language (1993) (193 pts)]]></title>
            <link>https://www.bell-labs.com/usr/dmr/www/chist.html</link>
            <guid>36652934</guid>
            <pubDate>Sun, 09 Jul 2023 09:15:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bell-labs.com/usr/dmr/www/chist.html">https://www.bell-labs.com/usr/dmr/www/chist.html</a>, See on <a href="https://news.ycombinator.com/item?id=36652934">Hacker News</a></p>
<div id="readability-page-1" class="page">

<dl><dd><i>Dennis M. Ritchie<br>
Bell Labs/Lucent Technologies<br>
Murray Hill, NJ 07974  USA<tt>dmr@bell-labs.com</tt>
</i></dd></dl>
<dl><dd><h4>ABSTRACT</h4>
The C programming language was devised in the early 1970s as a system
implementation language for the nascent Unix operating system.
Derived from the typeless language BCPL, it evolved
a type structure;
created on a tiny machine as a tool to improve
a meager programming environment, it has become
one of the dominant languages of today.
This paper studies its evolution.
</dd></dl>
<h4>Introduction
</h4>

<dl>
<dt></dt><dt> </dt><dd>
NOTE:<i> *Copyright 1993 Association for Computing Machinery, Inc.
This electronic reprint made available by the author as a courtesy.
For further publication rights contact ACM or the author.
This article was presented at Second History of Programming
Languages conference, Cambridge, Mass., April, 1993.
<br>
It was then collected in the conference proceedings:
<i>History of Programming Languages-II</i>
ed. Thomas J. Bergin, Jr. and Richard G. Gibson, Jr.
ACM Press (New York) and Addison-Wesley (Reading, Mass), 1996;
ISBN 0-201-89502-1.
</i></dd><dt> </dt><dd></dd></dl>
<br>
This paper is about the development of the C programming language,
the influences on it,
and the conditions under which it was created.
For the sake of brevity, I omit full descriptions of C itself,
its parent B [Johnson 73] and its grandparent BCPL [Richards 79],
and instead concentrate on characteristic elements
of each language and how they evolved.
<p>
C came into being in the years 1969-1973,
in parallel with the early development
of the Unix operating system;
the most creative period occurred during 1972.
Another spate of changes peaked between 1977 and 1979,
when portability of the Unix system was being demonstrated.
In the middle of this second period, the first widely available description
of the language appeared:
<i>The C Programming Language,</i>
often called the `white book' or `K&amp;R' [Kernighan 78].
Finally, in the middle 1980s, the language was officially standardized
by the ANSI X3J11 committee, which made further changes.
Until the early 1980s, although compilers existed for a variety
of machine architectures and operating systems, the language was almost exclusively
associated with Unix;
more recently, its use has spread much more widely, and today it
is among the languages most commonly used throughout the computer industry.
</p>
<h4>History: the setting
</h4>
<p>
The late 1960s were a turbulent era
for computer systems research at Bell Telephone Laboratories
[Ritchie 78] [Ritchie 84].
The company was pulling
out of the Multics project [Organick 75], which had started as a joint venture
of MIT, General Electric, and Bell Labs; by 1969, Bell Labs management,
and even the researchers, came to believe
that the promises of Multics could be fulfilled
only too late and too expensively.  Even before the GE-645 Multics
machine was removed from the premises, an informal group, led
primarily by Ken Thompson, had begun investigating alternatives.
</p>
<p>
Thompson wanted to create a comfortable computing
environment constructed according to his own design, using whatever
means were available.  His plans, it is evident in retrospect,
incorporated many of the innovative aspects of Multics, including an
explicit notion of a process as a locus of control,
a tree-structured file system, a command interpreter
as user-level program, simple representation of text files, and generalized
access to devices.
They excluded others, such as unified access to
memory and to files.  At the start, moreover, he and the rest
of us deferred another pioneering (though not original)
element of Multics, namely writing almost exclusively in a
higher-level language.
PL/I, the implementation language of Multics, was not
much to our tastes, but we were also using other languages, including BCPL, and
we regretted losing the advantages of writing programs in a
language above the level of assembler, such as
ease of writing and clarity
of understanding.
At the time we did not put much weight
on portability; interest in this arose later.
</p>
<p>
Thompson was faced with
a hardware environment cramped and spartan even for the time:
the DEC PDP-7 on which he started in 1968 was a machine with 8K 18-bit words
of memory and no software useful to him.
While wanting to use a higher-level language,
he wrote the original Unix system in PDP-7 assembler.
At the start, he did not even program
on the PDP-7 itself, but instead used a set of macros
for the GEMAP assembler on a
GE-635 machine.
A postprocessor
generated a paper tape readable by the PDP-7.
</p>
<p>
These tapes were
carried from the GE machine to the PDP-7 for testing until a primitive Unix kernel,
an editor, an assembler, a simple shell (command interpreter), and a few utilities
(like
the Unix
<i>rm, cat, cp</i>
commands)
were completed.  After this point, the operating system was self-supporting:
programs could be written and tested without resort to paper tape,
and development continued on the PDP-7 itself.
</p>
<p>
Thompson's PDP-7 assembler outdid even DEC's in simplicity;
it evaluated expressions and emitted the corresponding bits.
There were no libraries,
no loader or link editor: the entire source of a program was presented to
the assembler, and the output file—with a fixed name—that emerged was directly
executable.
(This name,
<i>a.out</i>,
explains a bit of Unix etymology;
it is the output of the assembler.
Even after the system gained a linker
and a means of specifying another name explicitly,
it was retained as the default executable
result of a compilation.)
</p>
<p>
Not long after Unix first ran on the PDP-7, in 1969, Doug McIlroy created
the new system's first higher-level language: an implementation of
McClure's TMG [McClure 65].  TMG is a language for writing compilers
(more generally, TransMoGrifiers) in a top-down, recursive-descent
style that combines context-free syntax notation with
procedural elements.  McIlroy and Bob Morris had used TMG to write the early
PL/I compiler for Multics.
</p>
<p>
Challenged by McIlroy's feat in reproducing TMG,
Thompson decided that Unix—possibly it had not even been
named yet—needed a system programming language.
After a rapidly scuttled attempt at Fortran,
he created instead a language of his own,
which he called B.
B can be thought of
as C without types; more accurately, it is BCPL squeezed into 8K bytes of memory
and filtered through Thompson's brain.
Its name most probably represents
a contraction of BCPL, though
an alternate theory holds that
it derives from Bon [Thompson 69],
an unrelated language created by
Thompson during the Multics days.
Bon in turn was named either after his wife Bonnie,
or (according to an encyclopedia quotation in its manual),
after a religion whose rituals involve the murmuring of magic formulas.
</p>
<h4>Origins: the languages
</h4>
<p>
BCPL was
designed by Martin Richards in the mid-1960s while he was visiting MIT,
and was used during the early 1970s
for several interesting projects, among them the OS6 operating system
at Oxford [Stoy 72], and parts of the seminal Alto work at Xerox PARC [Thacker 79].
We became familiar with it
because the
MIT CTSS system [Corbato 62] on which Richards worked was used for Multics development.
The original BCPL compiler was transported both to Multics and to the GE-635
GECOS system
by Rudd Canaday
and others at Bell Labs [Canaday 69];
during the final throes of Multics's life at Bell Labs
and immediately after, it was the language of choice
among the group of people who would later become involved with Unix.
</p>
<p>
BCPL, B, and C all fit firmly in the traditional
procedural family typified by Fortran and Algol 60.
They are particularly oriented towards
system programming, are small and compactly described,
and are amenable to translation by simple compilers.  They are `close
to the machine' in that the abstractions they introduce are readily
grounded in the concrete data types and operations supplied by
conventional computers, and they rely on library routines
for input-output and other interactions with an operating system.
With less success, they also use library procedures to specify interesting
control constructs such as coroutines and procedure
closures.  At the same time, their abstractions lie at a sufficiently
high level that, with care, portability between machines can
be achieved.
</p>
<p>
BCPL, B and C differ syntactically in many details, but broadly
they are similar.
Programs consist of a sequence of
global declarations and function (procedure) declarations.
Procedures can be nested in BCPL, but may not refer to non-static
objects defined in containing procedures.
B and C avoid this restriction by imposing a more severe one:
no nested procedures at all.
Each of the languages (except for earliest versions of B)
recognizes
separate compilation, and provides a means for including
text from named files.
</p>
<p>
Several syntactic and lexical mechanisms of BCPL are
more elegant and regular than those of B and C.
For example, BCPL's procedure and data declarations
have a more uniform structure, and it supplies a more complete
set of looping constructs.
Although BCPL programs are notionally supplied from an undelimited
stream of characters, clever rules allow most semicolons to be elided
after statements that end on a line boundary.
B and C omit this convenience, and end
most statements with semicolons.
In spite of the differences, most of the statements and operators of BCPL map
directly into corresponding B and C.
</p>
<p>
Some of the structural differences between BCPL and B
stemmed from limitations on intermediate memory.
For example, BCPL declarations may take the form
</p><dl><dt></dt><dd><tt><pre>let P1 be <i>command</i>
and P2 be <i>command</i>
and P3 be <i>command</i>
 ...
</pre></tt></dd></dl>
where the program text represented by the commands
contains whole procedures.
The subdeclarations
connected by
<tt>and</tt>
occur simultaneously, so the name
<tt>P3</tt>
is known inside procedure
<tt>P1</tt>.
Similarly, BCPL can package a group of declarations and statements into
an expression that yields a value, for example
<dl><dt></dt><dd><tt><pre>E1 := valof <i>( </i><i>declarations</i><i> ; </i><i>commands</i><i> ; resultis E2 </i><i>) + 1
</i></pre></tt></dd></dl><i>
</i>The BCPL compiler readily handled such constructs
by storing and analyzing a parsed representation of the entire
program in memory before producing output.
Storage limitations on the B compiler demanded a one-pass technique in which
output was generated as soon as possible, and the syntactic
redesign that made this possible was carried forward into C.

<p>
Certain less pleasant aspects of BCPL owed to its own technological
problems and were consciously
avoided in the design of B.
For example, BCPL uses a `global vector' mechanism for communicating
between separately compiled programs.
In this scheme,
the programmer explicitly associates the name of each externally visible
procedure and data object with a numeric offset in the global
vector; the linkage is accomplished in the compiled code
by using these numeric offsets.
B evaded this inconvenience initially by insisting that the entire
program be presented all at once to the compiler.
Later implementations of B, and all those of C, use a conventional
linker to resolve external names occurring in files compiled separately,
instead of placing the burden of assigning offsets on the programmer.
</p>
<p>
Other fiddles in the transition from BCPL to B were introduced as
a matter of taste, and some remain controversial, for example the decision
to use the single character
<tt>=</tt>
for assignment instead of
<tt>:=</tt>.
Similarly, B uses
<tt>/**/</tt>
to enclose comments, where BCPL uses
<tt>//</tt>,
to ignore text up to the end of the line.
The legacy of PL/I is evident here.
(C++ has resurrected the BCPL comment convention.)
Fortran influenced the syntax
of declarations:
B declarations begin with a specifier
like
<tt>auto</tt>
or
<tt>static</tt>,
followed by a list of names, and C
not only followed this style but ornamented it by
placing its type keywords at the start of declarations.
</p>
<p>
Not every difference between the BCPL language documented in
Richards's book
[Richards 79]
and B was deliberate;
we started from an earlier version of BCPL [Richards 67].
For example, the
<tt>endcase</tt>
that escapes from a BCPL
<tt>switchon</tt>
statement was not present in the language when we learned it
in the 1960s,
and so the overloading of the
<tt>break</tt>
keyword
to escape from the B and C
<tt>switch</tt>
statement
owes to divergent
evolution rather than conscious change.
</p>
<p>
In contrast to the pervasive syntax variation that occurred
during the creation of B, the core semantic content of BCPL—its
type structure and expression evaluation rules—remained intact.
Both languages are typeless, or rather have a single data type,
the `word,' or `cell,' a fixed-length bit pattern.  Memory in these languages
consists of a linear array of such cells, and the meaning of
the contents of a cell depends on the operation applied.
The
<tt>+</tt>
operator, for example, simply adds its operands using the machine's
integer add instruction, and the other arithmetic
operations are equally unconscious of the actual meaning
of their operands.  Because memory is a linear array, it is possible
to interpret the value in a cell as an index in this array,
and BCPL supplies an operator for this purpose.  In the
original language it was spelled
<tt>rv</tt>,
and later
<tt>!</tt>,
while B uses the unary
<tt>*</tt>.
Thus, if
<tt>p</tt>
is a cell containing
the index of (or address of, or pointer to) another cell,
<tt>*p</tt>
refers to the contents of the pointed-to cell, either
as a value in an expression or as the target of
an assignment.
</p>
<p>
Because pointers in BCPL and B are merely integer indices
in the memory array, arithmetic on them is meaningful:
if
<tt>p</tt>
is the address of a cell, then
<tt>p+1</tt>
is the address of
the next cell.
This convention is the basis for the semantics
of arrays in both languages.  When in BCPL one writes
</p><dl><dt></dt><dd><tt><pre>let V = vec 10
</pre></tt></dd></dl>
or in B,
<dl><dt></dt><dd><tt><pre>auto V[10];
</pre></tt></dd></dl>
the effect is the same: a cell named
<tt>V</tt>
is allocated, then
another group of 10 contiguous cells is set aside, and the memory index
of the first of these is placed into
<tt>V</tt>.
By a general rule, in B the expression
<dl><dt></dt><dd><tt><pre>*(V+i)
</pre></tt></dd></dl>
adds
<tt>V</tt>
and
<tt>i</tt>,
and refers to the
<tt>i</tt>-th
location after
<tt>V</tt>.
Both
BCPL and B each add special notation to sweeten such array accesses;
in B an equivalent expression is
<dl><dt></dt><dd><tt><pre>V[i]
</pre></tt></dd></dl>
and in BCPL
<dl><dt></dt><dd><tt><pre>V!i
</pre></tt></dd></dl>
This approach to arrays was unusual even at the time;
C would later assimilate it in an
even less conventional way.

<p>
None of BCPL, B, or C supports character data strongly
in the language; each treats strings
much like vectors of integers and supplements general rules by
a few conventions.
In both BCPL and B a string literal denotes the address of a
static area initialized with the characters of the string,
packed into cells.
In BCPL, the first packed byte contains the number of characters
in the string;
in B, there is no count and strings are terminated by
a special character, which B spelled
`<tt>*e</tt>'.
This change was made partially to avoid the limitation
on the length of a string caused by holding the count
in an 8- or 9-bit slot, and partly because maintaining
the count seemed, in our experience, less convenient than using a
terminator.
</p>
<p>
Individual characters in a BCPL string were usually manipulated
by spreading the string out into another array, one character per cell,
and then repacking it later;
B provided corresponding routines, but people more often used
other library functions that accessed or replaced individual
characters in a string.
</p>
<h4>More History
</h4>
<p>
After the TMG version of B was working, Thompson rewrote B in itself
(a bootstrapping step).
During development, he continually struggled against memory limitations:
each language addition
inflated the compiler so it could barely fit, but each
rewrite taking advantage of the feature reduced its size.
For example, B introduced generalized assignment operators, using
<tt>x=+y</tt>
to add
<tt>y</tt>
to
<tt>x</tt>.
The notation came from
Algol 68 [Wijngaarden 75] via McIlroy, who had incorporated
it into his version of TMG.
(In B and early C, the operator was spelled
<tt>=+</tt>
instead of
<tt>+=</tt>
; this mistake, repaired in 1976, was induced by a seductively easy
way of handling the first form in B's lexical analyzer.)
</p>
<p>
Thompson went a step further by inventing the
<tt>++</tt>
and
<tt>--</tt>
operators, which increment or decrement;
their prefix
or postfix position determines whether the alteration
occurs before or after noting the value of the operand.
They were not in the earliest versions of B, but appeared
along the way.
People often guess that
they were created to use the auto-increment and
auto-decrement address modes provided by the DEC PDP-11 on which C and Unix
first became popular.
This is historically impossible, since there was no PDP-11
when B was developed.
The PDP-7, however,
did have a few `auto-increment' memory cells, with the property
that an indirect memory reference through them incremented the cell.
This feature probably suggested such operators to Thompson;
the generalization to make them both prefix and postfix
was his own.
Indeed, the auto-increment cells were not used directly in implementation of the
operators, and a stronger motivation for the innovation was probably
his observation that
the translation of
<tt>++x</tt>
was smaller than that of
<tt>x=x+1</tt>.
</p>
<p>
The B compiler on the PDP-7 did not generate machine instructions,
but instead `threaded code' [Bell 72], an interpretive scheme in which
the compiler's output consists
of a sequence of addresses of code fragments that perform the
elementary operations.
The operations typically—in particular for B—act on a simple stack machine.
</p>
<p>
On the PDP-7 Unix system, only a few things were written in B except B itself,
because the machine was too small and too slow to do more than
experiment; rewriting the operating system and the utilities
wholly into B was too expensive a step to
seem feasible.
At some point Thompson relieved the address-space crunch by offering a
`virtual B' compiler that allowed the interpreted program to occupy more than 8K bytes
by paging the code and data within the interpreter,
but it was too slow to be practical for the common utilities.
Still, some utilities written in B appeared, including an early version of
the variable-precision calculator
<i>dc</i>
familiar to Unix users [McIlroy 79].
The most ambitious enterprise I undertook was a genuine
cross-compiler that translated B to GE-635 machine instructions, not threaded code.
It was a small
<i>tour de force</i>:
a full B compiler, written in its
own language and generating code for a 36-bit mainframe,
that ran on an 18-bit machine with 4K words of user address space.
This project was possible only because of the simplicity
of the B language and its run-time system.
</p>
<p>
Although we entertained occasional thoughts
about implementing one of the major languages of the time like Fortran,
PL/I, or Algol 68, such a project seemed hopelessly large for our resources:
much simpler and smaller tools were called for.
All these languages influenced our work,
but it was more fun to do things on our own.
</p>
<p>
By 1970, the Unix project had shown enough promise that we were
able to acquire the new DEC PDP-11.
The processor was among the first of its line delivered by DEC, and three months
passed before its disk arrived.
Making B programs
run on it using the threaded technique
required only writing the code fragments for the operators,
and a simple assembler which I coded in B;
soon,
<i>dc</i>
became the first
interesting program to be tested, before any operating system, on our PDP-11.
Almost as rapidly, still waiting for the disk, Thompson recoded
the Unix kernel and some basic commands in PDP-11 assembly language.
Of the 24K bytes of memory on the machine, the earliest PDP-11 Unix system
used 12K bytes for the operating system,
a tiny space for user programs, and the remainder as a RAM disk.
This version was only for testing, not for real work;
the machine marked time by enumerating closed knight's
tours on chess boards of various sizes.
Once its disk appeared, we quickly migrated to it after
transliterating assembly-language commands to the PDP-11 dialect, and
porting those already in B.
</p>
<p>
By 1971, our miniature computer center was beginning to have users.
We all wanted to create interesting software more easily.
Using assembler was dreary enough that B, despite its performance
problems, had been supplemented by a small library of useful service routines
and was being used for more and more new programs.
Among the more notable results of this period was Steve Johnson's
first version of the
<i>yacc</i>
parser-generator [Johnson 79a].
</p>
<h4>The Problems of B
</h4>
<p>
The machines on which we first used BCPL and then B were word-addressed,
and these languages' single data type, the `cell,' comfortably
equated with the hardware machine word.
The advent of the PDP-11 exposed several inadequacies of B's semantic model.
First, its character-handling mechanisms, inherited with few changes from BCPL,
were clumsy:
using library procedures to spread packed strings into individual
cells and then repack, or to access and replace
individual characters,
began to feel awkward, even silly, on a byte-oriented machine.
</p>
<p>
Second, although the original PDP-11 did not provide for floating-point
arithmetic,
the manufacturer promised that it would soon be available.
Floating-point operations had been added to BCPL
in our Multics and GCOS compilers by defining
special operators, but the mechanism was possible
only because on the relevant machines, a single word
was large enough to contain a floating-point number;
this was not true on the 16-bit PDP-11.
</p>
<p>
Finally, the B and BCPL model implied overhead in dealing
with pointers: the language rules, by defining a pointer
as an index in an array of words, forced pointers to be represented
as word indices.
Each pointer reference
generated a run-time scale conversion from the pointer to the
byte address expected by the hardware.
</p>
<p>
For all these reasons, it seemed that a typing scheme
was necessary to cope
with characters and byte addressing, and to prepare for the
coming floating-point hardware.
Other issues, particularly type safety and interface checking, did not
seem as important then as they became later.
</p>
<p>
Aside from the problems with the language itself, the B compiler's
threaded-code technique yielded programs
so much slower than their assembly-language counterparts
that we discounted the possibility of recoding the
operating system or its central utilities in B.
</p>
<p>
In 1971 I began to extend the B language by adding a character type
and also rewrote its compiler to generate PDP-11 machine instructions
instead of threaded code.
Thus the transition from B to C
was contemporaneous with the creation of a compiler
capable of producing programs fast and small enough
to compete with assembly language.
I called the slightly-extended language NB, for `new B.'
</p>
<h4>Embryonic C
</h4>
<p>
NB existed so briefly that no full description of
it was written.
It supplied the types
<tt>int</tt>
and
<tt>char</tt>,
arrays of them, and pointers to them, declared in a style typified by
</p><dl><dt></dt><dd><tt><pre>int i, j;
char c, d;
int iarray[10];
int ipointer[];
char carray[10];
char cpointer[];
</pre></tt></dd></dl>
The semantics of arrays remained exactly as in B and BCPL:
the declarations of
<tt>iarray</tt>
and
<tt>carray</tt>
create cells dynamically initialized with a value pointing to the
first of a sequence of 10 integers and characters respectively.
The declarations for
<tt>ipointer</tt>
and
<tt>cpointer</tt>
omit the size, to assert that no storage should be allocated automatically.
Within procedures, the language's interpretation of
the pointers was identical to that of the array variables:
a pointer declaration created a cell differing from
an array declaration only in that the programmer was expected to assign
a referent, instead of letting the compiler allocate the space
and initialize the cell.

<p>
Values stored in the cells bound to
array and pointer names
were the machine addresses,
measured in bytes, of the corresponding storage area.
Therefore, indirection through a pointer implied no
run-time overhead to scale the pointer from word to byte offset.
On the other hand, the machine code for array subscripting and pointer arithmetic
now depended on the type of the array or the pointer:
to compute
<tt>iarray[i]</tt>
or
<tt>ipointer+i</tt>
implied scaling the addend
<tt>i</tt>
by the size of the object referred to.
</p>
<p>
These semantics represented an easy transition from B,
and I experimented with them for some months.
Problems became evident when I tried to extend the type notation, especially
to add structured (record) types.
Structures, it seemed, should map in an intuitive way
onto memory in the machine,
but in a
structure containing an array, there was no good place to stash the
pointer containing the base of the array, nor any
convenient way to arrange that it be initialized.
For example, the directory entries of early Unix systems
might be described in C as
</p><dl><dt></dt><dd><tt><pre>struct {
	int	inumber;
	char	name[14];
};
</pre></tt></dd></dl>
I wanted the structure not merely to characterize an abstract object
but also to describe a collection of bits that might be read from
a directory.
Where could the compiler hide the pointer to
<tt>name</tt>
that the semantics demanded?
Even if structures were thought of more abstractly,
and the space for pointers could be hidden somehow,
how could I handle the technical problem of properly initializing
these pointers when allocating a complicated object, perhaps one that specified
structures containing arrays containing structures to arbitrary depth?

<p>
The solution constituted the crucial jump
in the evolutionary chain between typeless BCPL and typed C.
It eliminated the
materialization of the pointer in storage, and instead caused the
creation of the pointer when the array name is mentioned in an expression.
The rule, which survives in today's C, is that values of array
type are converted, when they appear in expressions, into
pointers to the first of the objects making up the array.
</p>
<p>
This invention enabled most existing B code to continue
to work, despite the underlying shift in the language's semantics.
The few programs that assigned new values to
an array name to adjust its origin—possible in B and BCPL,
meaningless in C—were easily repaired.
More important, the new language retained a coherent and workable (if unusual)
explanation of the semantics of arrays, while opening the way to a
more comprehensive type structure.
</p>
<p>
The second innovation that most clearly
distinguishes C from its predecessors is
this fuller type structure and especially its expression in the syntax of declarations.
NB offered the basic types
<tt>int</tt>
and
<tt>char</tt>,
together with arrays of them, and pointers to them,
but no further ways of composition.
Generalization was required:
given an object of any type, it should
be possible to describe a new object that gathers several into an array,
yields it from a function, or is a pointer to it.
</p>
<p>
For each object of such a composed type, there
was already a way to mention the underlying object:
index the array,
call the function, use the indirection operator on the pointer.
Analogical reasoning led to a declaration syntax for names
mirroring that of the expression syntax in which the names typically appear.
Thus,
</p><dl><dt></dt><dd><tt><pre>int i, *pi, **ppi;
</pre></tt></dd></dl>
declare an integer, a pointer to an integer, a pointer to
a pointer to an integer.
The syntax of these declarations reflects the
observation that
<tt>i</tt>,
<tt>*pi</tt>,
and
<tt>**ppi</tt>
all yield an
<tt>int</tt>
type when used in an expression.  Similarly,
<dl><dt></dt><dd><tt><pre>int f(), *f(), (*f)();
</pre></tt></dd></dl>
declare a function returning an integer, a function returning
a pointer to an integer, a pointer to a function returning
an integer;
<dl><dt></dt><dd><tt><pre>int *api[10], (*pai)[10];
</pre></tt></dd></dl>
declare an array of pointers to integers, and a pointer to
an array of integers.
In all these cases the declaration of a variable resembles
its usage in an expression whose type is the one named at the head of
the declaration.

<p>
The scheme of type composition adopted by C owes considerable debt
to Algol 68, although it did not, perhaps, emerge in a form
that Algol's adherents would approve of.
The central notion I captured from Algol was a type structure
based on atomic
types (including structures), composed into arrays, pointers (references),
and functions (procedures).
Algol 68's concept of unions
and casts also had an influence that appeared later.
</p>
<p>
After creating the type system, the associated
syntax, and the compiler for the new language,
I felt that it deserved a new name;
NB seemed insufficiently distinctive.
I decided to follow the single-letter style and called it C,
leaving open the question whether the name represented
a progression through the alphabet or through the letters in BCPL.
</p>
<h4>Neonatal C
</h4>
<p>
Rapid changes continued after the language had been named,
for example
the introduction of the
<tt>&amp;&amp;</tt>
and
<tt>||</tt>
operators.
In BCPL and B, the evaluation of expressions depends
on context: within
<tt>if</tt>
and other conditional statements that compare
an expression's value with zero,
these languages place a special interpretation on the
<tt>and</tt>
(<tt>&amp;</tt>)
and
<tt>or</tt>
(<tt>|</tt>)
operators.
In ordinary contexts, they operate bitwise, but
in the B statement
</p><dl><dt></dt><dd><tt><pre>if (e1 &amp; e2) ...
</pre></tt></dd></dl>
the compiler must evaluate
<tt>e1</tt>
and if it is non-zero, evaluate
<tt>e2</tt>,
and if it too is non-zero, elaborate the statement dependent on
the
<tt>if</tt>.
The requirement descends recursively on
<tt>&amp;</tt>
and
<tt>|</tt>
operators within
<tt>e1</tt>
and
<tt>e2</tt>.
The short-circuit semantics of the Boolean operators in such
`truth-value' context seemed desirable,
but the overloading of the operators was difficult to explain and use.
At the suggestion of Alan Snyder,
I introduced the
<tt>&amp;&amp;</tt>
and
<tt>||</tt>
operators
to make the mechanism more explicit.

<p>
Their tardy introduction explains an
infelicity of C's precedence rules.  In B one writes
</p><dl><dt></dt><dd><tt><pre>if (a==b &amp; c) ...
</pre></tt></dd></dl>
to check whether
<tt>a</tt>
equals
<tt>b</tt>
and
<tt>c</tt>
is non-zero;
in such a conditional expression it is better that
<tt>&amp;</tt>
have lower precedence than
<tt>==</tt>.
In converting from B to C, one wants to replace
<tt>&amp;</tt>
by
<tt>&amp;&amp;</tt>
in such a statement;
to make the conversion less painful,
we decided to keep the precedence of the
<tt>&amp;</tt>
operator the same relative to
<tt>==</tt>,
and merely split the precedence of
<tt>&amp;&amp;</tt>
slightly from
<tt>&amp;</tt>.
Today, it seems that it would have been preferable to move
the relative precedences of
<tt>&amp;</tt>
and
<tt>==</tt>,
and thereby simplify a common C idiom:
to test a masked value
against another value, one must write
<dl><dt></dt><dd><tt><pre>if ((a&amp;mask) == b) ...
</pre></tt></dd></dl>
where the inner parentheses are required but easily forgotten.

<p>
Many other changes occurred around 1972-3, but the most important
was the introduction of the preprocessor,
partly at the urging of Alan Snyder [Snyder 74],
but also in recognition of the utility of the
the file-inclusion mechanisms available in BCPL and PL/I.
Its original version was exceedingly simple,
and provided only included files and
simple string replacements:
<tt>#include</tt>
and
<tt>#define</tt>
of parameterless macros.
Soon thereafter, it was extended, mostly by Mike Lesk
and then by John Reiser,
to incorporate macros with arguments and conditional
compilation.
The preprocessor was originally considered an optional adjunct
to the language itself.  Indeed, for some years,
it was not even invoked unless the source program contained
a special signal at its beginning.
This attitude persisted, and explains
both the incomplete integration of the syntax of the
preprocessor with the rest of the language
and the imprecision of its description in early reference
manuals.
</p>
<h4>Portability
</h4>
<p>
By early 1973, the essentials of
modern C were complete.
The language and compiler were strong enough to permit us to
rewrite the Unix kernel for the PDP-11 in C during the summer of that year.
(Thompson had made a brief attempt to produce a system coded in an early version of
C—before structures—in 1972, but gave up the effort.)
Also during this period, the compiler was retargeted to other nearby machines,
particularly the Honeywell 635 and IBM 360/370;
because the language could not live in isolation,
the prototypes for the modern libraries
were developed.
In particular, Lesk wrote a `portable I/O package' [Lesk 72]
that was later reworked to become the C `standard I/O' routines.
In 1978 Brian Kernighan and I published
<i>The C Programming Language</i>
[Kernighan 78].
Although it did not describe some additions
that soon became common, this book served as the language
reference until a formal standard was adopted more than
ten years later.
Although we worked closely together on this book, there was a clear division of labor:
Kernighan wrote almost all the expository material, while
I was responsible for the appendix containing the reference manual and
the chapter on interfacing with the Unix system.
</p>
<p>
During 1973-1980,
the language grew a bit:
the type structure gained unsigned, long, union, and enumeration types,
and structures became nearly first-class objects
(lacking only a notation for literals).
Equally important developments appeared in its environment and the accompanying
technology.
Writing the Unix kernel in C had given us enough confidence in the language's
usefulness and efficiency that we began to recode the
system's utilities and tools as well,
and then to move the most interesting among them to the other
platforms.
As described in [Johnson 78a], we discovered that the hardest problems
in propagating Unix tools lay not in the
interaction of the C language with new hardware,
but in adapting to the existing software of other
operating systems.
Thus Steve Johnson began to work on
<i>pcc</i>,
a C compiler intended to be easy to retarget to new machines [Johnson 78b],
while he, Thompson, and I began to move the Unix system itself to
the Interdata 8/32 computer.
</p>
<p>
The language changes during this period, especially around 1977,
were largely focused on considerations of portability and type safety,
in an effort to cope with the problems we foresaw and observed
in moving a considerable body of code to the new Interdata
platform.
C at that time still manifested strong signs of its typeless
origins.
Pointers, for example, were barely distinguished from
integral memory indices in early language manuals or extant code;
the similarity of the arithmetic properties of
character pointers and unsigned integers made it hard
to resist the temptation to identify them.
The
<tt>unsigned</tt>
types were added to make unsigned arithmetic available
without confusing it with pointer manipulation.
Similarly, the early language condoned assignments between
integers and pointers, but this practice began to be discouraged;
a notation for type conversions (called `casts' from the example of Algol 68)
was invented to specify type conversions more explicitly.
Beguiled by the example of PL/I, early C
did not tie structure pointers firmly to the structures
they pointed to, and permitted programmers to write
<tt>pointer-&gt;member</tt>
almost without regard to the type of
<tt>pointer</tt>;
such an expression was taken uncritically as a reference
to a region of memory designated by the pointer, while the member
name specified only an offset and a type.
</p>
<p>
Although the first edition of K&amp;R described most of the
rules that brought C's type structure to its present form,
many programs written in the older, more relaxed style
persisted, and so did compilers that tolerated it.
To encourage people to pay more attention to the
official language rules, to detect legal but suspicious constructions,
and to help find interface mismatches
undetectable with simple mechanisms for separate compilation,
Steve Johnson adapted his
<i>pcc</i>
compiler to produce
<i>lint</i>
[Johnson 79b],
which scanned a set of files and remarked on dubious constructions.
</p>
<h4>Growth in Usage
</h4>
<p>
The success of our portability experiment on the
Interdata 8/32 soon led to another by Tom London and John Reiser
on the DEC VAX 11/780.
This machine became much more popular than the Interdata, and
Unix and the C language began to spread rapidly, both within AT&amp;T and
outside.
Although by the middle 1970s
Unix was in use by
a variety of projects within the Bell System
as well as a small group of research-oriented
industrial, academic, and government organizations outside our company,
its real growth began only after portability had been achieved.
Of particular note were the System III and System V
versions of the system from the emerging Computer Systems division of AT&amp;T, based
on work by the company's development and research groups,
and the BSD series of releases by the University
of California at Berkeley that derived from research
organizations in Bell Laboratories.
</p>
<p>
During the 1980s the use of the C language spread widely,
and compilers became available on nearly every machine architecture
and operating system; in particular it became popular as a
programming tool for personal computers, both for manufacturers
of commercial software for these machines, and for end-users
interested in programming.
At the start of the decade, nearly every compiler was based on Johnson's
<i>pcc</i>;
by 1985 there were many independently-produced compiler products.
</p>
<h4>Standardization
</h4>
<p>
By 1982 it was clear that C needed formal standardization.
The best approximation to a standard,
the first edition of K&amp;R, no longer described the language in actual use;
in particular, it mentioned neither the
<tt>void</tt>
or
<tt>enum</tt>
types.
While it foreshadowed the newer approach to structures, only after
it was published did the language support assigning them, passing them
to and from functions, and associating the names of members firmly
with the structure or union containing them.
Although compilers distributed by AT&amp;T incorporated these changes,
and most of the purveyors of compilers not based on
<i>pcc</i>
quickly picked up them up, there remained no complete, authoritative
description of the language.
</p>
<p>
The first edition of K&amp;R was also insufficiently precise on many details
of the language, and it became increasingly impractical to regard
<i>pcc</i>
as a `reference compiler;'
it did not perfectly
embody even the language described by K&amp;R, let alone subsequent extensions.
Finally, the incipient use of C in projects subject to commercial
and government contract meant that the imprimatur of an official
standard was important.
Thus (at the urging of M. D. McIlroy), ANSI established the X3J11
committee under the direction of CBEMA
in the summer of 1983, with the goal of producing
a C standard.
X3J11 produced its report [ANSI 89] at the end of 1989,
and subsequently this standard was accepted by ISO as
ISO/IEC 9899-1990.
</p>
<p>
From the beginning, the X3J11 committee took a cautious,
conservative view of language extensions.
Much to my
satisfaction, they took seriously their goal:
`to develop a clear, consistent, and unambiguous Standard
for the C programming language which codifies the common,
existing definition of C and which promotes the portability
of user programs across C language environments.' [ANSI 89]
The committee realized that mere promulgation of a standard
does not make the world change.
</p>
<p>
X3J11 introduced only one genuinely important change to the language itself:
it incorporated the types of formal arguments in the type
signature of a function, using syntax borrowed from C++ [Stroustrup 86].
In the old style, external functions were declared like this:
</p><dl><dt></dt><dd><tt><pre>double sin();
</pre></tt></dd></dl>
which says only that
<tt>sin</tt>
is a function returning a
<tt>double</tt>
(that is, double-precision floating-point) value.
In the new style, this better rendered
<dl><dt></dt><dd><tt><pre>double sin(double);
</pre></tt></dd></dl>
to make the argument type explicit
and thus encourage better type checking and appropriate conversion.
Even this addition, though it produced a noticeably better language,
caused difficulties.
The committee justifiably felt that simply outlawing
`old-style' function definitions and declarations was not
feasible, yet also agreed that the new forms were better.
The inevitable compromise was as good as it
could have been, though the language definition is complicated by
permitting both forms, and writers of portable software must contend
with compilers not yet brought up to standard.

<p>
X3J11 also introduced
a host of smaller additions and adjustments, for example,
the type qualifiers
<tt>const</tt>
and
<tt>volatile</tt>,
and slightly different type promotion rules.
Nevertheless, the standardization process did not change the character
of the language.
In particular, the C standard did not attempt to specify formally
the language semantics, and so there can be dispute over fine points;
nevertheless, it successfully accounted for changes in
usage since the original description, and is sufficiently precise to
base implementations on it.
</p>
<p>
Thus the core C language escaped nearly unscathed from the
standardization process, and the Standard emerged more
as a better, careful codification than a new invention.
More important changes took place in the language's surroundings:
the preprocessor and the library.
The preprocessor performs macro substitution, using conventions
distinct from the rest of the language.
Its
interaction with the compiler had never
been well-described, and X3J11 attempted to remedy the
situation.
The result is noticeably better than the explanation in the first edition of K&amp;R;
besides being more comprehensive, it provides
operations, like token concatenation, previously available
only by accidents of implementation.
</p>
<p>
X3J11 correctly believed that a full and careful
description of a standard C library was as important as its
work on the language itself.
The C language itself does not provide for input-output
or any other interaction with the outside world, and thus
depends on a set of standard procedures.
At the time of publication of K&amp;R, C was thought of mainly
as the system programming language of Unix; although we
provided examples of library routines intended to be readily transportable
to other operating systems, underlying support from Unix was implicitly
understood.
Thus, the X3J11 committee spent much of its time designing
and documenting a set
of library routines required to be available in all
conforming implementations.
</p>
<p>
By the rules of the standards process, the current activity of the X3J11
committee is confined to issuing interpretations on the existing
standard.
However, an informal group originally convened by Rex Jaeschke
as NCEG (Numerical C Extensions Group) has been officially accepted
as subgroup X3J11.1,
and they continue to consider extensions to C.
As the name implies, many of these possible extensions are intended to make the language
more suitable for numerical use: for example, multi-dimensional arrays
whose bounds are dynamically determined, incorporation of facilities
for dealing with IEEE arithmetic, and making the language more effective on machines
with vector or other advanced architectural features.
Not all the possible extensions are specifically numerical; they
include a notation for structure literals.
</p>
<h4>Successors
</h4>
<p>
C and even B have several direct descendants, though they
do not rival Pascal in generating progeny.
One side branch developed early.
When Steve Johnson visited the University of Waterloo on sabbatical
in 1972,
he brought B with him.  It became popular
on the Honeywell machines there, and later spawned Eh and Zed
(the Canadian answers to `what follows B?').
When Johnson returned to Bell Labs in 1973, he was disconcerted to
find that the language whose seeds he brought to Canada
had evolved back home;
even his own
<i>yacc</i>
program had been rewritten in C, by Alan Snyder.
</p>
<p>
More recent descendants of C proper include Concurrent C [Gehani 89],
Objective C [Cox 86], C* [Thinking 90],
and especially C++ [Stroustrup 86].
The language is also widely used as an intermediate
representation (essentially, as a portable assembly language)
for a wide variety of compilers, both for direct descendents
like C++, and independent languages like
Modula 3 [Nelson 91] and
Eiffel
[Meyer 88].
</p>
<h4>Critique
</h4>
<p>
Two ideas are most characteristic of C among languages of its class:
the relationship between arrays and pointers,
and the way in which declaration syntax mimics expression syntax.
They are also among its most frequently criticized features,
and often serve as stumbling blocks to the beginner.
In both cases, historical accidents or mistakes have exacerbated
their difficulty.
The most important of these has been the tolerance of C compilers
to errors in type.
As should be clear from the history above, C evolved from typeless
languages.
It did not suddenly appear to its earliest
users and developers as an entirely new language with its own rules;
instead we continually had to adapt existing programs as the
language developed, and make allowance for an existing body
of code.  (Later, the ANSI X3J11 committee standardizing C would
face the same problem.)
</p>
<p>
Compilers in 1977, and even well after,
did not complain about usages such as assigning between integers
and pointers or using objects of the wrong type to refer
to structure members.
Although the language definition presented in the first edition of K&amp;R
was reasonably (though not completely) coherent in its treatment of type rules,
that book admitted that existing compilers didn't enforce them.
Moreover, some rules designed to ease early transitions
contributed to later confusion.
For example, the empty square brackets in the function declaration
</p><dl><dt></dt><dd><tt><pre>int f(a) int a[]; { ... }
</pre></tt></dd></dl>
are a living fossil, a remnant of NB's way of declaring a pointer;
<tt>a</tt>
is, in this special case only, interpreted in C as a pointer.
The notation survived in part for the sake of
compatibility, in part under the rationalization
that it would allow programmers
to communicate to their readers
an intent to pass
<tt>f</tt>
a pointer generated from an array, rather than a reference to a single
integer.
Unfortunately, it serves as much to confuse the learner
as to alert the reader.

<p>
In K&amp;R C, supplying arguments of the proper type to a function call
was the responsibility of the programmer, and the extant compilers
did not check for type agreement.
The failure of the original language to include argument types
in the type signature of a function
was a significant weakness,
indeed the one that required the X3J11 committee's boldest and most painful
innovation to repair.
The early design is explained (if not justified) by my avoidance of technological
problems, especially cross-checking between separately-compiled source files,
and my incomplete assimilation of the implications of moving between
an untyped to a typed language.
The
<i>lint</i>
program,
mentioned above,
tried to alleviate the problem:
among its other functions,
<i>lint</i>
checks the consistency and coherency of a whole program by scanning a set
of source files,
comparing the types of function arguments used in calls with those
in their definitions.
</p>
<p>
An accident of syntax contributed to the perceived complexity of the language.
The indirection operator, spelled
<tt>*</tt>
in C, is syntactically a unary prefix operator, just as in BCPL and B.
This works well in simple expressions, but in more complex cases,
parentheses are required to direct the parsing.
For example, to distinguish indirection through the value
returned by a function from calling a function designated by
a pointer, one writes
<tt>*fp()</tt>
and
<tt>(*pf)()</tt>
respectively.
The style used in expressions carries through to declarations, so the names might be
declared
</p><dl><dt></dt><dd><tt><pre>int *fp();
int (*pf)();
</pre></tt></dd></dl>
In more ornate but still realistic cases, things become worse:
<dl><dt></dt><dd><tt><pre>int *(*pfp)();
</pre></tt></dd></dl>
is a pointer to a function returning a pointer to an integer.
There are two effects occurring.
Most important, C has a relatively rich set of ways of
describing types (compared, say, with Pascal).
Declarations in languages
as expressive as C—Algol 68, for example—describe objects equally hard
to understand, simply because the objects themselves are complex.
A second effect owes to details of the syntax.
Declarations in C must be read
in an `inside-out' style that many find
difficult to grasp [Anderson 80].
Sethi [Sethi 81] observed that many of the nested declarations
and expressions would become simpler
if the indirection operator had been taken as a postfix operator
instead of prefix, but by then it was too late to change.

<p>
In spite of its difficulties,
I believe that the C's approach to declarations remains plausible,
and am comfortable with it; it is a useful unifying principle.
</p>
<p>
The other characteristic feature of C, its treatment of arrays,
is more suspect on practical grounds, though it also has
real virtues.
Although the relationship between pointers and arrays
is unusual, it can be learned.
Moreover, the language shows considerable power to describe important
concepts, for example, vectors whose length varies at run time,
with only a few basic rules and conventions.
In particular, character strings are handled by the same mechanisms
as any other array, plus the convention that a null character
terminates a string.
It is interesting to compare C's approach with that of two
nearly contemporaneous languages, Algol 68 and Pascal [Jensen 74].
Arrays in Algol 68 either have fixed bounds, or are `flexible:'
considerable mechanism is required both in the language
definition, and in compilers, to accommodate flexible arrays
(and not all compilers fully implement them.)
Original Pascal had only fixed-sized arrays and strings,
and this proved confining [Kernighan 81].
Later, this was partially fixed, though the resulting
language is not yet universally available.
</p>
<p>
C treats strings as arrays of characters
conventionally terminated by a marker.
Aside from one special rule about initialization by string literals,
the semantics of strings are fully subsumed by more general
rules governing all arrays, and
as a result the language is simpler to describe and
to translate than one incorporating the string as a unique
data type.
Some costs accrue from its approach:
certain string operations are more expensive than in other designs
because application code or
a library routine must occasionally search for the end of a string,
because few built-in operations are available, and because
the burden of storage management for strings falls more
heavily on the user.
Nevertheless, C's approach to strings works well.
</p>
<p>
On the other hand, C's treatment of arrays in general (not just strings)
has unfortunate implications both for optimization
and for future extensions.
The prevalence of pointers in C programs, whether those declared
explicitly or arising from arrays, means that
optimizers must be cautious, and must use careful dataflow techniques
to achieve good results.
Sophisticated compilers can understand what most pointers
can possibly change, but some important usages remain difficult
to analyze.
For example, functions with pointer arguments derived from
arrays are hard to compile into efficient code on
vector machines, because it is seldom possible to determine
that one argument pointer does not overlap data also
referred to by another argument, or accessible externally.
More fundamentally, the definition of C so specifically describes
the semantics of arrays that
changes or extensions treating arrays as more
primitive objects, and permitting operations on them as wholes,
become hard to fit into the existing language.
Even extensions to permit the declaration and use of multidimensional arrays whose
size is determined dynamically are not entirely straightforward [MacDonald 89]
[Ritchie 90],
although they would make it much easier to write numerical
libraries in C.
Thus, C covers the most important uses of strings and arrays
arising in practice by a uniform and simple mechanism,
but leaves problems for highly efficient implementations and for extensions.
</p>
<p>
Many smaller infelicities exist in the language
and its description
besides those discussed above, of course.
There are also
general criticisms to be lodged that transcend detailed points.
Chief among these is that the language and its generally-expected
environment provide little help for writing very large systems.
The naming structure provides only two main levels,
`external' (visible everywhere) and `internal' (within
a single procedure).
An intermediate level
of visibility (within a single file of data and procedures)
is weakly tied to the language definition.
Thus, there is little direct support for modularization,
and project designers are forced to create their own conventions.
</p>
<p>
Similarly, C itself provides two durations of storage:
`automatic' objects that exist while control resides in or below
a procedure, and `static,' existing throughout execution of a program.
Off-stack, dynamically-allocated storage is provided only
by a library routine and
the burden of managing it is placed on
the programmer: C is hostile to automatic garbage collection.
</p>
<h4>Whence Success?
</h4>
<p>
C has become successful to an extent far surpassing any early
expectations.  What qualities contributed to its widespread use?
</p>
<p>
Doubtless the success of Unix itself was the most important factor;
it made the language available to hundreds of thousands of people.
Conversely, of course, Unix's use of C and its consequent
portability to a wide variety of machines
was important in the system's success.
But the language's invasion of other environments suggests more
fundamental merits.
</p>
<p>
Despite some aspects mysterious to the beginner and
occasionally even to the adept,
C remains a simple and small language, translatable with simple and small compilers.
Its types and operations are
well-grounded in those provided by
real machines, and for
people used to how computers work,
learning the idioms for generating time- and space-efficient programs
is not difficult.
At the same time the language is sufficiently abstracted from machine
details that program portability can be achieved.
</p>
<p>
Equally important, C and its central library support always
remained in touch with a real environment.
It was not designed in isolation to prove a point, or to serve
as an example, but as a tool to write programs that did
useful things; it was always meant to interact with a larger
operating system, and was regarded as a
tool to build larger tools.
A parsimonious, pragmatic approach influenced the things that went into C:
it covers
the essential needs of many programmers,
but does not try to supply too much.
</p>
<p>
Finally, despite the changes that it has undergone since its first
published description, which was admittedly informal
and incomplete, the actual C language as seen by millions of users
using many different compilers has remained remarkably stable
and unified compared to those of similarly widespread currency,
for example Pascal and Fortran.
There are differing dialects of C—most noticeably, those described by
the older K&amp;R and the newer Standard C—but on the whole, C has remained
freer of proprietary extensions than other languages.
Perhaps the most significant extensions are the `far' and `near'
pointer qualifications intended to deal with peculiarities
of some Intel processors.
Although C was not originally designed with portability
as a prime goal, it succeeded in expressing
programs, even including operating systems,
on machines ranging from the smallest personal
computers through the mightiest supercomputers.
</p>
<p>
C is quirky, flawed, and an enormous success.
While accidents of history surely helped,
it evidently satisfied a need for a system implementation language
efficient enough
to displace assembly language, yet sufficiently abstract and fluent to
describe algorithms and interactions in a wide variety of environments.
</p>
<h4>Acknowledgments
</h4>
<p>
It is worth summarizing compactly the roles of the direct contributors to today's
C language.
Ken Thompson created the B language in 1969-70; it was derived directly
from Martin Richards's BCPL.
Dennis Ritchie turned B into C during 1971-73, keeping most of B's syntax
while adding types and many other changes, and writing the
first compiler.
Ritchie, Alan Snyder, Steven C. Johnson, Michael Lesk, and Thompson contributed language
ideas during 1972-1977,
and Johnson's portable compiler remains widely used.
During this period, the collection of library routines grew
considerably, thanks to these people and many others at Bell Laboratories.
In 1978, Brian Kernighan and Ritchie wrote the book that
became the language definition for several years.
Beginning in 1983, the ANSI X3J11 committee standardized
the language.  Especially notable in keeping its
efforts on track were its officers
Jim Brodie, Tom Plum, and  P. J. Plauger, and the successive draft redactors,
Larry Rosler and Dave Prosser.
</p>
<p>
I thank Brian Kernighan, Doug McIlroy, Dave Prosser, Peter
Nelson, Rob Pike, Ken Thompson, and HOPL's referees
for advice in the preparation of this paper.
</p>
<h4>References
</h4>
<dl compact="">
<dt>[ANSI 89]</dt><dd>
American National Standards Institute,
<i>American National Standard for Information Systems—Programming Language C,</i>
X3.159-1989.
</dd><dt>[Anderson 80]</dt><dd>
B. Anderson,
`Type syntax in the language C: an object lesson in syntactic innovation,'
SIGPLAN Notices
<b>15</b>
(3), March, 1980, pp. 21-27.
</dd><dt>[Bell 72]</dt><dd>
J. R. Bell, `Threaded Code,' C. ACM
<b>16</b>
(6), pp. 370-372.
</dd><dt>[Canaday 69]</dt><dd>
R. H. Canaday and D. M. Ritchie,
`Bell Laboratories BCPL,'
AT&amp;T Bell Laboratories internal memorandum, May, 1969.
</dd><dt>[Corbato 62]</dt><dd>
F. J. Corbato, M. Merwin-Dagget, R. C. Daley,
`An Experimental Time-sharing System,' AFIPS Conf. Proc. SJCC,
1962, pp. 335-344.
</dd><dt>[Cox 86]</dt><dd>
B. J. Cox and A. J. Novobilski,
<i>Object-Oriented Programming: An Evolutionary Approach,</i>
Addison-Wesley: Reading, Mass., 1986. Second edition, 1991.
</dd><dt>[Gehani 89]</dt><dd>
N. H. Gehani and W. D. Roome,
<i>Concurrent C,</i>
Silicon Press: Summit, NJ, 1989.
</dd><dt>[Jensen 74]</dt><dd>
K. Jensen and N. Wirth,
<i>Pascal User Manual and Report,</i>
Springer-Verlag: New York, Heidelberg, Berlin.  Second Edition, 1974.
</dd><dt>[Johnson 73]</dt><dd>
S. C. Johnson and B. W. Kernighan, `The Programming Language B,'
Comp. Sci. Tech. Report #8, AT&amp;T Bell Laboratories (January 1973).
</dd><dt>[Johnson 78a]</dt><dd>
S. C. Johnson and D. M. Ritchie,
`Portability of C Programs and the UNIX System,'
Bell Sys. Tech. J.
<b>57</b>
(6) (part 2), July-Aug, 1978.
</dd><dt>[Johnson 78b]</dt><dd>
S. C. Johnson,
`A Portable Compiler: Theory and Practice,'
Proc. 5th ACM POPL Symposium (January 1978).
</dd><dt>[Johnson 79a]</dt><dd>
S. C. Johnson, `Yet another compiler-compiler,' in
<i>Unix Programmer's Manual,</i>
Seventh Edition, Vol. 2A, M. D. McIlroy and B. W. Kernighan, eds.
AT&amp;T Bell Laboratories: Murray Hill, NJ, 1979.
</dd><dt>[Johnson 79b]</dt><dd>
S. C. Johnson, `Lint, a Program Checker,' in
<i>Unix Programmer's Manual,</i>
Seventh Edition, Vol. 2B, M. D. McIlroy and B. W. Kernighan, eds.
AT&amp;T Bell Laboratories: Murray Hill, NJ, 1979.
</dd><dt>[Kernighan 78]</dt><dd>
B. W. Kernighan and D. M. Ritchie,
<i>The C Programming Language,</i>
Prentice-Hall: Englewood Cliffs, NJ, 1978.
Second edition, 1988.
</dd><dt>[Kernighan 81]</dt><dd>
B. W. Kernighan,
`Why Pascal is not my favorite programming language,'
Comp. Sci. Tech. Rep. #100, AT&amp;T Bell Laboratories, 1981.
</dd><dt>[Lesk 73]</dt><dd>
M. E. Lesk, `A Portable I/O Package,'
AT&amp;T Bell Laboratories internal memorandum ca. 1973.
</dd><dt>[MacDonald 89]</dt><dd>
T. MacDonald,
`Arrays of variable length,'
J. C Lang. Trans
<b>1</b>
(3), Dec. 1989, pp. 215-233.
</dd><dt>[McClure 65]</dt><dd>
R. M. McClure, `TMG—A Syntax Directed Compiler,'
Proc. 20th ACM National Conf. (1965), pp. 262-274.
</dd><dt>[McIlroy 60]</dt><dd>
M. D. McIlroy, `Macro Instruction Extensions of Compiler Languages,'
C. ACM
<b>3</b>
(4), pp. 214-220.
</dd><dt>[McIlroy 79]</dt><dd>
M. D. McIlroy and B. W. Kernighan, eds,
<i>Unix Programmer's Manual,</i>
Seventh Edition, Vol. I,
AT&amp;T Bell Laboratories: Murray Hill, NJ, 1979.
</dd><dt>[Meyer 88]</dt><dd>
B. Meyer,
<i>Object-oriented Software Construction,</i>
Prentice-Hall: Englewood Cliffs, NJ, 1988.
</dd><dt>[Nelson 91]</dt><dd>
G. Nelson,
<i> Systems Programming with Modula-3,</i>
Prentice-Hall: Englewood Cliffs, NJ, 1991.
</dd><dt>[Organick 75]</dt><dd>
E. I. Organick,
<i>The Multics System: An Examination of its Structure,</i>
MIT Press: Cambridge, Mass., 1975.
</dd><dt>[Richards 67]</dt><dd>
M. Richards, `The BCPL Reference Manual,'
MIT Project MAC Memorandum M-352, July 1967.
</dd><dt>[Richards 79]</dt><dd>
M. Richards and C. Whitbey-Strevens,
<i>BCPL: The Language and its Compiler,</i>
Cambridge Univ. Press: Cambridge, 1979.
</dd><dt>[Ritchie 78]</dt><dd>
D. M. Ritchie, `UNIX: A Retrospective,' Bell Sys. Tech. J.
<b>57</b>
(6) (part 2), July-Aug, 1978.
</dd><dt>[Ritchie 84]</dt><dd>
D. M. Ritchie, `The Evolution of the UNIX Time-sharing System,'
AT&amp;T Bell Labs. Tech. J.
<b>63</b>
(8) (part 2), Oct. 1984.
</dd><dt>[Ritchie 90]</dt><dd>
D. M. Ritchie,
`Variable-size arrays in C,'
J. C Lang. Trans.
<b>2</b>
(2), Sept. 1990, pp. 81-86.
</dd><dt>[Sethi 81]</dt><dd>
R. Sethi,
`Uniform syntax for type expressions and declarators,'
Softw. Prac. and Exp.
<b>11</b>
(6), June 1981, pp. 623-628.
</dd><dt>[Snyder 74]</dt><dd>
A. Snyder,
<i>A Portable Compiler for the Language C,</i>
MIT: Cambridge, Mass., 1974.
</dd><dt>[Stoy 72]</dt><dd>
J. E. Stoy and C. Strachey, `OS6—An experimental operating
system for a small computer. Part I: General principles and structure,'
Comp J.
<b>15</b>,
(Aug. 1972), pp. 117-124.
</dd><dt>[Stroustrup 86]</dt><dd>
B. Stroustrup,
<i>The C++ Programming Language,</i>
Addison-Wesley: Reading, Mass., 1986.
Second edition, 1991.
</dd><dt>[Thacker 79]</dt><dd>
C. P. Thacker, E. M. McCreight, B. W. Lampson, R. F. Sproull,
D. R. Boggs, `Alto: A Personal Computer,' in
<i>Computer Structures: Principles and Examples,</i>
D. Sieworek, C. G. Bell, A. Newell,
McGraw-Hill: New York, 1982.
</dd><dt>[Thinking 90]</dt><dd>
<i>C* Programming Guide,</i>
Thinking Machines Corp.: Cambridge Mass., 1990.
</dd><dt>[Thompson 69]</dt><dd>
K. Thompson, `Bon—an Interactive Language,' undated AT&amp;T Bell Laboratories
internal memorandum (ca. 1969).
</dd><dt>[Wijngaarden 75]</dt><dd>
A. van Wijngaarden, B. J. Mailloux, J. E. Peck, C. H. Koster, M. Sintzoff,
C. Lindsey, L. G. Meertens, R. G. Fisker, `Revised report on the algorithmic
language Algol 68,'  Acta Informatica
<b>5</b>,
pp. 1-236.
</dd></dl>
<p> 
<a href="http://www.lucent.com/copyright.html">
Copyright</a> © 2003 Lucent Technologies Inc.  All rights reserved.

</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How small is the smallest .NET Hello World binary? (293 pts)]]></title>
            <link>https://blog.washi.dev/posts/tinysharp/</link>
            <guid>36652824</guid>
            <pubDate>Sun, 09 Jul 2023 08:50:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.washi.dev/posts/tinysharp/">https://blog.washi.dev/posts/tinysharp/</a>, See on <a href="https://news.ycombinator.com/item?id=36652824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>Here is a dumb question that you probably never asked yourself: What is the minimal amount of bytes we need to store in a .NET executable to have the CLR print the string<code>"Hello, World!"</code> to the standard output?</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/thumbnail.png"><img data-src="/assets/img/posts/tinysharp/thumbnail.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/thumbnail.png"></a>
<em>How small can we get?</em></p>

<p>In this post, we will explore the limits of the .NET module file format, get it as small as possible, while still having it function like a normal executable on a typical Windows machine with the .NET Framework installed.</p>

<p>The final source code for this post can be found on my GitHub:</p>

<p><a href="https://gist.github.com/Washi1337/367eede6e00b31e29355626d5e2f3078" target="_blank">
 Full Source Code
</a></p>

<h2 id="rules"><span>Rules</span><a href="#rules"><i></i></a></h2>

<p>Here are the arbitrary rules I set up for myself:</p>

<ul>
  <li>
    <p><strong>The application must run a managed entry point implemented in C# or CIL.</strong>
This entry point must be responsible for printing <code>"Hello, World!"</code> to the standard output. 
This means we cannot do any of the native entry point shenanigans like we did in a <a href="https://blog.washi.dev/posts/entry-points">previous post</a>.
How it actually does the printing, however, is fully up to this method body.</p>
  </li>
  <li>
    <p><strong>The application runs on .NET Framework 4.x.x.</strong>
We do this to give ourselves a little bit more freedom, and it allows us to have a single executable only and leverage some of the features of the Windows PE loader. 
It is also nice to have an executable that we can just double click.</p>
  </li>
  <li>
    <p><strong>No third-party dependencies.</strong> 
We are only allowed to reference the BCL (i.e., mscorlib) and/or other libraries that are installed on a typical Windows machine. 
Otherwise, we could replace all code within our small application with a call to a custom-made dependency, which would be cheating!</p>
  </li>
  <li>
    <p><strong>Ignore zero bytes at the end of the file.</strong>
The PE file format, as well as the CLR itself, puts a hard limit on offset alignments for each section stored in the PE. 
Effectively it means that the theoretically smallest .NET PE that is able to run on Windows 10 or higher cannot be smaller than 1KB. 
As we will see this is rather easy to achieve.
To challenge ourselves a bit more, we strive to get to the “bare minimum description” of a .NET hello world PE file, where we consider all trailing zero bytes as non-existent.</p>
  </li>
</ul>

<p>Let’s get hacking!</p>

<h2 id="establishing-a-baseline"><span>Establishing a baseline</span><a href="#establishing-a-baseline"><i></i></a></h2>

<p>To establish a baseline that we want to beat, let’s first start by compiling the following Hello World application using the latest version of the C# compiler by the time of writing this post.</p>

<div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td><pre><span>using</span> <span>System</span><span>;</span>

<span>namespace</span> <span>ConsoleApp1</span><span>;</span>

<span>internal</span> <span>static</span> <span>class</span> <span>Program</span>
<span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"Hello, World!"</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></p></div>

<p>We accompany it with the following <code>.csproj</code> file:</p>

<div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>&lt;Project</span> <span>Sdk=</span><span>"Microsoft.NET.Sdk"</span><span>&gt;</span>

    <span>&lt;PropertyGroup&gt;</span>
        <span>&lt;OutputType&gt;</span>Exe<span>&lt;/OutputType&gt;</span>
        <span>&lt;TargetFramework&gt;</span>net472<span>&lt;/TargetFramework&gt;</span>
        <span>&lt;LangVersion&gt;</span>10<span>&lt;/LangVersion&gt;</span>
        <span>&lt;Nullable&gt;</span>enable<span>&lt;/Nullable&gt;</span>
    <span>&lt;/PropertyGroup&gt;</span>

<span>&lt;/Project&gt;</span>
</pre></td></tr></tbody></table></code></p></div>

<p>This gives us a binary of a whopping <code>4.6KB</code> file:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size01.png"><img data-src="/assets/img/posts/tinysharp/size01.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size01.png"></a>
<em>The size of a standard hello world application.</em></p>

<p>That seems excessive… Clearly we can do better than this.</p>

<h2 id="removing-nullable-reference-annotations"><span>Removing nullable reference annotations</span><a href="#removing-nullable-reference-annotations"><i></i></a></h2>

<p>Inspecting the application in a .NET decompiler gives us a bit more insight on what is going on.
Since C# 8.0 we have known the concept of <a href="https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/builtin-types/nullable-reference-types">nullable reference types</a>.
These are special annotations that allows the C# compiler to reason about potentially unwanted null references to be passed on to functions, variables and parameters.
The downside is that these annotations are implemented in the form of custom attributes, which are linked into the executable statically and notoriously large:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy01.png"><img data-src="/assets/img/posts/tinysharp/dnSpy01.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy01.png"></a>
<em>Nullable Reference Types add many Custom Attributes to a .NET image</em></p>

<p>Let’s disable that with one option in our <code>.csproj</code> file:</p>

<div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td><pre><span>&lt;Project</span> <span>Sdk=</span><span>"Microsoft.NET.Sdk"</span><span>&gt;</span>

    <span>&lt;PropertyGroup&gt;</span>
        <span>&lt;OutputType&gt;</span>Exe<span>&lt;/OutputType&gt;</span>
        <span>&lt;TargetFramework&gt;</span>net472<span>&lt;/TargetFramework&gt;</span>
        <span>&lt;LangVersion&gt;</span>10<span>&lt;/LangVersion&gt;</span>
        
         <span>&lt;!-- Disable nullable reference type checks. --&gt;</span>
        <span>&lt;Nullable&gt;</span>disable<span>&lt;/Nullable&gt;</span>
    <span>&lt;/PropertyGroup&gt;</span>

<span>&lt;/Project&gt;</span>
</pre></td></tr></tbody></table></code></p></div>

<p>While this does get rid of all the attributes, we are unfortunately still left with a binary that is <code>4.6KB</code> in size, due to the PE file alignments.</p>

<h2 id="manually-crafting-a-net-module"><span>Manually crafting a .NET module</span><a href="#manually-crafting-a-net-module"><i></i></a></h2>

<p>Further inspecting the output in a decompiler shows that, even with nullable references disabled, the C# compiler still emits many type references to custom attributes in our application. 
In particular, they include many attributes assigned to the assembly itself, such as file version metadata and copyright information.
Additionally, besides our class <code>Program</code> we also have a hidden <code>&lt;Module&gt;</code> type that looks rather empty:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy02.png"><img data-src="/assets/img/posts/tinysharp/dnSpy02.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy02.png"></a>
<em>The C# compiler still emits a lot of unnecessary metadata</em></p>

<p>We could try and figure out how to instruct the compiler to disable generating all this metadata, but I figured, if we are going to the extreme, we may as well just build a .NET executable file from scratch by ourselves. 
This way we have more control over the final output, allowing us to just emit the bare minimum that is required to print <code>"Hello World"</code>, and not emit those unnecessary file metadata attributes.
Furthermore, we can just place our <code>main</code> function into the <code>&lt;Module&gt;</code> type and get rid of our <code>Program</code> class as well.
Below is an example implementation of building a small Hello World application using <a href="https://blog.washi.dev/posts/tinysharp/github.com/washi1337/asmresolver">AsmResolver</a>:</p>

<div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre></td><td><pre><span>// Define new assembly and module.</span>
<span>var</span> <span>assembly</span> <span>=</span> <span>new</span> <span>AssemblyDefinition</span><span>(</span><span>"assembly"</span><span>,</span> <span>new</span> <span>Version</span><span>(</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>));</span>
<span>var</span> <span>module</span> <span>=</span> <span>new</span> <span>ModuleDefinition</span><span>(</span><span>"module.exe"</span><span>);</span>
<span>assembly</span><span>.</span><span>Modules</span><span>.</span><span>Add</span><span>(</span><span>module</span><span>);</span>

<span>// Obtain &lt;Module&gt; type.</span>
<span>var</span> <span>moduleType</span> <span>=</span> <span>module</span><span>.</span><span>GetOrCreateModuleType</span><span>();</span>

<span>// Craft a new Main method.</span>
<span>var</span> <span>factory</span> <span>=</span> <span>module</span><span>.</span><span>CorLibTypeFactory</span><span>;</span>
<span>var</span> <span>main</span> <span>=</span> <span>new</span> <span>MethodDefinition</span><span>(</span><span>"main"</span><span>,</span> <span>MethodAttributes</span><span>.</span><span>Static</span><span>,</span> <span>MethodSignature</span><span>.</span><span>CreateStatic</span><span>(</span><span>factory</span><span>.</span><span>Void</span><span>));</span>
<span>main</span><span>.</span><span>CilMethodBody</span> <span>=</span> <span>new</span> <span>CilMethodBody</span><span>(</span><span>main</span><span>)</span>
<span>{</span>
    <span>Instructions</span> <span>=</span>
    <span>{</span>
        <span>{</span><span>Ldstr</span><span>,</span> <span>"Hello, World!"</span><span>},</span>
        <span>{</span><span>Call</span><span>,</span> <span>factory</span><span>.</span><span>CorLibScope</span>
            <span>.</span><span>CreateTypeReference</span><span>(</span><span>"System"</span><span>,</span><span>"Console"</span><span>)</span>
            <span>.</span><span>CreateMemberReference</span><span>(</span><span>"WriteLine"</span><span>,</span> <span>MethodSignature</span><span>.</span><span>CreateStatic</span><span>(</span><span>factory</span><span>.</span><span>Void</span><span>,</span> <span>factory</span><span>.</span><span>String</span><span>))</span>
            <span>.</span><span>ImportWith</span><span>(</span><span>module</span><span>.</span><span>DefaultImporter</span><span>)</span>
        <span>},</span>
        <span>Ret</span>
    <span>}</span>
<span>};</span>

<span>// Add main to &lt;Module&gt;</span>
<span>moduleType</span><span>.</span><span>Methods</span><span>.</span><span>Add</span><span>(</span><span>main</span><span>);</span>

<span>// Register main as the entry point of the module:</span>
<span>module</span><span>.</span><span>ManagedEntryPointMethod</span> <span>=</span> <span>main</span><span>;</span>

<span>// Write to disk.</span>
<span>module</span><span>.</span><span>Write</span><span>(</span><span>"output.exe"</span><span>);</span>
</pre></td></tr></tbody></table></code></p></div>

<p>This did a great deal already, we cut our file size in half:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size02.png"><img data-src="/assets/img/posts/tinysharp/size02.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size02.png"></a>
<em>The size of a hello world application emitted by AsmResolver.</em></p>

<p>But we can do better…</p>

<h2 id="getting-rid-of-imports-and-base-relocations"><span>Getting rid of Imports and Base Relocations</span><a href="#getting-rid-of-imports-and-base-relocations"><i></i></a></h2>

<p>If we look into the resulting executable file using a tool like <a href="https://ntcore.com/?page_id=388">CFF Explorer</a>, we can see that the file contains two sections <code>.text</code> and <code>.reloc</code>.
Furthermore, it also contains two very large data directories called the Imports and Base Relocations directory respectively.</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff01.png"><img data-src="/assets/img/posts/tinysharp/cff01.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff01.png"></a>
<em>By default, 32-bit .NET images contain imports and base relocations that take a lot of space.</em></p>

<p>This is pretty typical for any AnyCPU or 32-bit .NET executable file.
The imports directory is required because 32-bit .NET executable files require an unmanaged entry point calling <code>mscoree!_CorExeMain</code>, as we have seen in a <a href="https://blog.washi.dev/posts/entry-points">previous post</a>.
Furthermore, by default .NET executables are relocatable, that is, the Windows PE Loader is free to map the executable at any memory address it likes.
This means every 32-bit .NET executable also needs a base relocation for the call to this imported function to be registered in the relocation directory.
This is problematic, because it is by default put in a fully separate section.
As every section needs to be aligned to the smallest possible section alignment of <code>0x200</code> bytes (1KB), we inflate our file by at least that amount of bytes just because of that.</p>

<p>Fortunately for us, 64-bit .NET executables do not need such an unmanaged entry point anymore.
With just two extra lines added to our previous script, we can get rid of both directories, an entire PE section, and thus shave off an entire kilobyte worth of data from our binary file:</p>

<div><p><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>// Output a 64-bit module.</span>
<span>module</span><span>.</span><span>PEKind</span> <span>=</span> <span>OptionalHeaderMagic</span><span>.</span><span>PE64</span><span>;</span>
<span>module</span><span>.</span><span>MachineType</span> <span>=</span> <span>MachineType</span><span>.</span><span>Amd64</span><span>;</span>
</pre></td></tr></tbody></table></code></p></div>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff02.png"><img data-src="/assets/img/posts/tinysharp/cff02.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff02.png"></a>
<em>64-bit .NET images do not need imports or base relocations.</em></p>

<p>And indeed, we get to the theoretically possible minimum size of 1KB of a valid .NET PE file:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size03.png"><img data-src="/assets/img/posts/tinysharp/size03.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size03.png"></a>
<em>The minimum size of a PE file is reached.</em></p>



<p>We could have called it quits here, but I decided to look a little bit deeper into what really we can strip out of a binary to get to the absolute bare minimum of a .NET hello world executable.
From now on, we won’t be looking at the file size as reported by Windows Explorer.
Instead, we will be looking at a hex editor and see where the last non-zero byte is stored and consider that to be our final file size.
If we do this for our current file, we can actually see we are already down to a size of 991 bytes (<code>0x3DF</code>):</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size04.png"><img data-src="/assets/img/posts/tinysharp/size04.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size04.png"></a>
<em>The size we will be considering is the index of of the byte after the last non-zero byte in the file.</em></p>

<p>What is still contributing to this amount of bytes?
If we look again in a disassembler, we can see that the <code>#Strings</code> heap in a .NET binary is the second largest metadata stream stored in the file.
It contains all the names that the tables stream (<code>#~</code>) uses, which stores all the types and methods that our application defines and uses.
As it so turns out, many of these names are actually not really important to the runtime:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy03.png"><img data-src="/assets/img/posts/tinysharp/dnSpy03.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy03.png"></a>
<em>Names take up a lot of space.</em></p>

<p>Thus, setting these to <code>null</code> instead will give us an application that looks a bit like the following:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy04.png"><img data-src="/assets/img/posts/tinysharp/dnSpy04.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy04.png"></a>
<em>Truncating names.</em></p>

<p>Believe it or not, the application still runs fine and happily outputs “Hello World”, regardless of whether this looks fine or not.
Best of all, it shaved a whopping 32 bytes from our file:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size05.png"><img data-src="/assets/img/posts/tinysharp/size05.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size05.png"></a>
<em>The size of the file after stripping names.</em></p>



<p>What other unnecessary metadata is there that the CLR does not really care about?</p>

<p>Our next target is getting rid of the <code>#GUID</code> stream.
This stream is present in virtually any .NET executable, and contains, as its names implies, a list of GUIDs.
However, the only type of metadata that really references it, is the Module table.
This table has a column called <code>Mvid</code>, which is supposed to reference a GUID that makes the module uniquely identifiable across different versions of compiled binaries.</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff04.png"><img data-src="/assets/img/posts/tinysharp/cff04.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff04.png"></a>
<em>A module contains an optional MVID, which is a GUID of 16 bytes.</em></p>

<p>We do not care about versioning, we just want the smallest binary possible. 
We can just get rid of it and save 16 bytes that were originally making up the Mvid.
However, by doing so, the <code>#GUID</code> stream is now empty and thus is no longer needed. 
By removing the stream in its entirety, we save another 16 bytes that make up its header, making a total of 32 bytes that we save with this.</p>

<p>Additionally, the <code>Console::WriteLine</code> method that we call in our <code>Main</code> function is defined in <code>mscorlib</code>. 
Typically, references to BCL assemblies are annotated with a public key token of 8 bytes.</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff03.png"><img data-src="/assets/img/posts/tinysharp/cff03.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff03.png"></a>
<em>The reference to <code>mscorlib</code> contains a long public key token.</em></p>

<p>It so turns out that if there is no public key token present in this reference, the CLR then just does not verify this assembly token for authenticity.
Since we do not care about security anyways in our experiment, we can get rid of this too.</p>

<p>This brings us down to a file of 918 bytes in total:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size06.png"><img data-src="/assets/img/posts/tinysharp/size06.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size06.png"></a>
<em>The size after stripping GUIDs and public key tokens.</em></p>

<h2 id="getting-rid-of-consolewriteline"><span>Getting rid of Console.WriteLine</span><a href="#getting-rid-of-consolewriteline"><i></i></a></h2>

<p>If we look at other metadata streams defined in our assembly, we find that our <code>"Hello, World!"</code> string is actually stored in a rather inefficient manner.
In .NET, all user strings are put in the <code>#US</code> metadata stream as a length-prefixed array of 16-bit wide characters followed by an additional zero byte.
This is done to support a wide range of the UNICODE character set.
However, all the characters in the string that we want to print have a code-point value smaller than 255 (<code>0xFF</code>), the max value of a single byte.
Why should we then use 2 bytes per character?
Furthermore, this is the only user string that we need in our binary.
Having an entire 12-bytes stream header for just one string seems rather excessive:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff05.png"><img data-src="/assets/img/posts/tinysharp/cff05.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff05.png"></a>
<em>User strings in .NET always use wide character encoding.</em></p>

<p>Unfortunately, there is no way turn this wide-character string in the <code>#US</code> stream to a single-byte ASCII string, and to tell the CLR to interpret it as such.</p>

<p>Time to get creative!</p>

<p>If we want to print an ASCII string as opposed to a wide-character string, we need a function that accepts those types of strings.
<code>Console::WriteLine</code> is not a function that fits this criterium, so we need to get rid of it.
However, the unmanaged function <code>ucrtbase!puts</code> does.
.NET allows for invoking unmanaged functions by using a feature called <a href="https://learn.microsoft.com/en-us/dotnet/standard/native-interop/pinvoke">Platform Invoke (P/Invoke)</a>.
We can define <code>puts</code> using P/Invoke in the following manner in C#:</p>

<div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>[</span><span>DllImport</span><span>(</span><span>"ucrtbase"</span><span>)]</span>
<span>static</span> <span>extern</span> <span>int</span> <span>puts</span><span>(</span><span>nint</span> <span>str</span><span>);</span>
</pre></td></tr></tbody></table></code></p></div>

<p>However, there is a problem.
The <code>puts</code> function accepts a pointer to a string. 
This pointer must be a valid <strong>runtime address</strong> that points to the start of the zero-terminated ASCII string that we want to print.
How do we know where our string is stored at compile-time so that we can push it in our <code>main</code> method?</p>

<p>It so turns out we can solve this by unchecking the <code>DynamicBase</code> flag in the <code>DllCharacteristics</code> field of the PE’s optional header.
This allows us to fix the base address the module will be mapped on at runtime.
We can then decide an arbitrary base address, put the ASCII string anywhere in our <code>.text</code> section, and calculate the runtime address by the formula <code>module_base_address + rva_ascii_string</code>.</p>

<div><p><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>var</span> <span>image</span> <span>=</span> <span>module</span><span>.</span><span>ToPEImage</span><span>();</span>

<span>image</span><span>.</span><span>ImageBase</span> <span>=</span> <span>0x00000000004e0000</span><span>;</span>
<span>image</span><span>.</span><span>DllCharacteristics</span> <span>&amp;=</span> <span>~</span><span>DllCharacteristics</span><span>.</span><span>DynamicBase</span><span>;</span>
</pre></td></tr></tbody></table></code></p></div>

<p>In order to have the CLR actually respect this flag, we also need to unset the <code>ILOnly</code> flag in the .NET data directory:</p>

<div><p><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>image</span><span>.</span><span>DotNetDirectory</span><span>!.</span><span>Flags</span> <span>&amp;=</span> <span>~</span><span>DotNetDirectoryFlags</span><span>.</span><span>ILOnly</span><span>;</span>
</pre></td></tr></tbody></table></code></p></div>

<p>We can then simply pass the calculated address directly in our <code>puts</code> function call as a normal integer:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy05.png"><img data-src="/assets/img/posts/tinysharp/dnSpy05.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy05.png"></a>
<em>Replace <code>Console::WriteLine</code> with <code>ucrtbase!puts</code>, allowing us to use an ASCII string instead.</em></p>

<p>And there we go, we not only got rid of our wide-character string, but also the entire <code>#US</code> stream, as well as the reference to <code>System.Console::WriteLine</code> which also contributes quite a few bytes to the size of our file.
In turn, we got a few bytes back due to the new required <code>puts</code> method definition and its associated P/Invoke metadata, but it is for sure a big shrink.</p>

<p>We are now down to 889 bytes (<code>0x379</code>):</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size07.png"><img data-src="/assets/img/posts/tinysharp/size07.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size07.png"></a>
<em>The size of the file after removing <code>Console::WriteLine</code> and using ASCII strings.</em></p>

<h2 id="other-micro-optimizations"><span>Other micro optimizations</span><a href="#other-micro-optimizations"><i></i></a></h2>

<p>There are a few things we still can do.</p>

<p>Our <code>puts</code> definition follows the canonical definition as provided by the C runtime library. 
This means the function is defined to return an <code>int32</code> representing the number of characters that were written to the standard output.
However, we do not care about this value.
Indeed, in our main method, we pop this value right after the call to keep the CLR happy:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy06.png"><img data-src="/assets/img/posts/tinysharp/dnSpy06.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy06.png"></a>
<em>Returning an <code>int32</code> means the value needs to be popped from the evaluation stack again.</em></p>

<p>Since this is a 64-bit PE file anyways, the <code>puts</code> function will use the <a href="https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170">x64 calling conventions</a> as described by Microsoft.
In simple terms, this means at runtime the return value is not really pushed on the stack as with normal .NET method calls, but rather put in the <code>RAX</code> register.
Since we do not use this value anyways, we can just turn the definition into <code>void</code>, effectively disregarding whatever is put into this register.
As the function is now no longer returning anything, nothing is also pushed onto the evaluation stack in our main method.
This allows us to get rid of the <code>pop</code> instruction in our main method:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy07.png"><img data-src="/assets/img/posts/tinysharp/dnSpy07.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/dnSpy07.png"></a>
<em>Changing to a <code>void</code> means the <code>pop</code> instruction is no longer required.</em></p>

<p>We can also move the ASCII string that we pass on to the <code>puts</code> function to a slightly better place.
The PE file format contains a lot of segments that are aligned to a certain byte-boundary.
In particular, as was mentioned before, sections are aligned to the nearest multiple of <code>0x200</code> (1KB).
This also includes the first section.
However, since the PE file headers of our file take up less space than <code>0x200</code> bytes, we end up with a chunk of padding data between our headers and first section data:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/hxd01.png"><img data-src="/assets/img/posts/tinysharp/hxd01.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/hxd01.png"></a>
<em>PE images contain some padding between the headers and the first section.</em></p>

<p>It so turns out the Windows PE Loader always maps the PE headers as a chunk of readable memory. 
The good news is, it also includes this padding data.</p>

<p>Let’s move our string there!</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/hxd02.png"><img data-src="/assets/img/posts/tinysharp/hxd02.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/hxd02.png"></a>
<em>Place the string to print into the unused padding segment.</em></p>

<p>By moving our string there, we effectively truncated our file by 13 bytes.</p>

<p>Since we also do not reference <code>Console::WriteLine</code> anymore, we also do not longer need the reference to <code>mscorlib</code> to be stored in our binary.
This also saves quite a bit of space, since it means one less table to store in the tables stream (<code>#~</code>), as well as the name <code>mscorlib</code> to be removed from the <code>#Strings</code> stream.</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff07.png"><img data-src="/assets/img/posts/tinysharp/cff07.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff07.png"></a>
<em>We no longer depend on <code>"mscorlib"</code>, thus we do no longer need a reference to it.</em></p>

<p>Finally, we can end with a bit of a weird one.
The .NET metadata directory contains a field called <code>VersionString</code>, containing the minimum required version of the .NET Framework that is required to run this .NET executable.
By default, for .NET 4.0+ binaries, this contains the string <code>"v4.0.30319"</code> padded with zero bytes to the nearest multiple of 4 (totaling 12 bytes).
However, we can truncate this string to just <code>v4.0.</code>, stripping a total of 4 bytes after padding, to trick .NET to still boot up the CLR version 4.0 and run the program successfully.</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/cff06.png"><img data-src="/assets/img/posts/tinysharp/cff06.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/cff06.png"></a>
<em>The .NET metadata directory contains a version string specifying the required runtime which can be truncated.</em></p>

<p>Note that, for some reason, the trailing <code>.</code> seems to be important. I have no idea why, but getting rid of anything more than this string will make the program not boot up correctly.</p>

<p>Our final size is 834 bytes (<code>0x342</code>):</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/size08.png"><img data-src="/assets/img/posts/tinysharp/size08.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/size08.png"></a>
<em>The final size of our binary.</em></p>

<p>We can ZIP it to get it to a mere 476 bytes (compared to 582 bytes if we did not do any optimizations after reaching the 1KB limit).
This is where I decided to call it quits.</p>

<p>Finally, to prove the program still works fine, here is a screenshot:</p>

<p><a href="https://blog.washi.dev/assets/img/posts/tinysharp/final.png"><img data-src="/assets/img/posts/tinysharp/final.png" alt="" data-proofer-ignore="" src="https://blog.washi.dev/assets/img/posts/tinysharp/final.png"></a>
<em>It still works!</em></p>

<h2 id="final-words"><span>Final Words</span><a href="#final-words"><i></i></a></h2>

<p>This was a dumb way to spend my Saturday.</p>

<p>Even though this is probably quite a useless project, I still like diving into these dumb rabbit holes every now and then.
Exploring the limits of well-established systems is always fun, even if the end result is kind of pointless.</p>

<p>To summarize what we have done, we went from a Hello World file of <code>4.6 KB</code> compiled by the C# compiler to a handcrafted PE file of <code>834 B</code> excluding trailing zero bytes.
I don’t think we can get any smaller than this, but I am happy to be proven wrong!</p>

<p>As said before, the final source code to produce the binary can be found on my GitHub:</p>

<p><a href="https://gist.github.com/Washi1337/367eede6e00b31e29355626d5e2f3078" target="_blank">
 Full Source Code
</a></p>

<p>Happy hacking!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Story Behind Hackathon Photo (108 pts)]]></title>
            <link>https://frantic.im/story-behind-hackathon-photo/</link>
            <guid>36652551</guid>
            <pubDate>Sun, 09 Jul 2023 07:57:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frantic.im/story-behind-hackathon-photo/">https://frantic.im/story-behind-hackathon-photo/</a>, See on <a href="https://news.ycombinator.com/item?id=36652551">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>I’ve seen <a href="https://unsplash.com/photos/QBpZGqEMsKg">this photo</a> on the internet, sometimes even billboards and posters. Maybe you’ve seen it too? Here’s the story behind it.</p>
<p><img src="https://frantic.im/assets/hackathon.jpg" alt=""></p>
<p>In 2017 I was working on React Native team. We were friends with all other developer experience teams around Facebook. One of them worked on <a href="https://nuclide.io/">Nuclide</a> (RIP), a set of plugins for Atom editor turning it into multi-platform IDE. Nuclide struggled with adoption outside Facebook walls.</p>
<p>Around that time, Unsplash was becoming very popular. They were the first to provide high quality stock photos for free (very bold strategy for its time). Their photos were spreading like a wildfire.</p>
<p>So I had this “genius” idea: make a photo of MacBook Pro with Atom/Nuclide running on it, upload it to Unsplash and get programming blog posts use it as their cover photo (for free). People will notice a cool looking editor and will start asking “what is it?”, eventually finding Nuclide (now you know why I’m not working in marketing).</p>
<p>I took my old Canon 6D to the office and we did a photoshoot. I uploaded the picture (along with others from my Lightroom collection, to make it less sketchy).</p>
<p><img src="https://frantic.im/assets/nuclide.jpg" alt="Nuclide/Atom on MacBook Pro"></p>
<p>The plan didn’t work. The image got some downloads, but not much. It was lost in a sea of similar pictures. A year later, Facebook gave up on Nuclide and marketing efforts became irrelevant.</p>
<p>However, one thing came out of this process I did not expect.</p>
<p>Together with the Nuclide photo, I uploaded a picture I took that year in Ukraine. I was a judge at <a href="https://www.devchallenge.it/">DevChallenge</a> hackathon in Kyiv, and during the break I snapped a few photos with a wide 24mm lens. I really liked how concentrated everyone was, staff members walking the rows, the uniformity, lighting, stickers on the notebooks. I don’t think the photo was very good by photography standards, but I loved the spirit of that place and wanted to capture it.</p>
<p><img src="https://frantic.im/assets/hackathon_lightroom.png" alt="Other pictures from that hackathon in Kyiv"></p>
<p>During the uploading process Unsplash asked if I wanted to submit my pictures to their first ever “Unsplash Awards” and I thought “sure why not?”.</p>
<p>I forgot about this for a while, until several months later I got an email from Unspash notifying me that I won <a href="https://awards.unsplash.com/2017/#/tech-and-business">“Unsplash Awards 2017” in “Tech and business”</a>.</p>
<blockquote>
<p>In a way, Alex’s photo captures a reflection of modern life: staring at a screen. Our lives, especially in our twenties, feels like a competition. From school, to university, to getting a job and progressing through our careers – it’s a never ending competition. The photo draws your eyes out across the rows of workers, all seemingly identical – but at the same time, showing small hints of color and personality from every worker that highlight and humanizes their unique history and personality. It makes me think of 20 years from now, what technology will be ubiquitous.
– Niv Dror, ProductHunt/Angelist</p>
</blockquote>
<p>They sent me a bunch of cool prizes: PeakDesign Messenger bag, straps and clips, Moment lens for iPhone, and even a printed version of my photo.</p>
<p>Now, looking at it, I do regret not processing the picture more: the horizon line is a bit tilted, you can spot chromatic abberation, the windows are overexposed.</p>
<p>Today that picture has 57 million views and used all over the internet. It even ended up on <a href="https://news.ycombinator.com/item?id=21010674">Hacker News</a> with the classic “It looks like a sweatshop” and “exact type of workplace I wouldn’t want anyone to end up” comments.</p>
<p>Conclusions? None, I guess. I just love how a stream of random events brought this to life.</p>

  
  






  <div>
    <p>Hello! This text lives here to convince you to subscribe. If you are reading this, consider clicking that subscribe button for more details.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD Ryzen 7 7840U Performance Benchmarks on Linux (107 pts)]]></title>
            <link>https://www.phoronix.com/review/amd-ryzen7-7840u</link>
            <guid>36652096</guid>
            <pubDate>Sun, 09 Jul 2023 06:22:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/review/amd-ryzen7-7840u">https://www.phoronix.com/review/amd-ryzen7-7840u</a>, See on <a href="https://news.ycombinator.com/item?id=36652096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-bg">
						
						<!-- google_ad_section_start -->
<article>




<div>

<p>For weeks and weeks I've been eager to see how well the new AMD Zen 4 based "Phoenix" laptop SoCs function and perform under Linux. Recently I finally found an interesting AMD Ryzen 7 7840U laptop to test and today have some initial Linux benchmarks to share from this Acer Swift Edge 16 laptop with Ryzen 7 7840U SoC and a 3.2K 120Hz OLED display, among other interesting specs.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_0_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_0_med" alt="AMD Ryzen 7 7840U on Linux"></a></p>
<p>The AMD Ryzen 7 7840U is the current top-tier Phoenix U-series laptop processor. This SoC features 8 cores / 16 threads, 3.3GHz base clock, up to a 5.1GHz boost clock, 16MB L3 cache, and a default TDP of 28 Watts with a cTDP of 15 to 30 Watts. The Ryzen 7 7840U features integrated Radeon 780M graphics with 12 CUs. The 7840U does feature AMD Ryzen AI functionality though this AI engine isn't currently exposed under Linux at least as far as upstream software support is concerned.</p>
<p>The Ryzen 7 7840U is effectively the successor to the Ryzen 7 (PRO) 6850U. This Phoenix series laptop processor has all of the common Zen 4 architecture elements including AVX-512. The Phoenix series are manufactured on a TSMC 4nm process.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_1_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_1_med" alt="AMD Ryzen 7 7840U on Ubuntu Linux"></a></p>
<p>Since AMD announced the Ryzen 7040 series laptop processors I've been very eager to see how well these new processors perform especially given the success in the desktop and server space of Zen 4. Unfortunately AMD doesn't actively engage with us over Linux laptop testing and the major OEMs/ODMs aren't actively engaging at large with the relatively small Linux niche especially from the PR side. Meanwhile the Linux laptop vendors currently are still relying on the Ryzen 6000 / 7030 series. So I've spent weeks scouring some interesting Phoenix laptop to buy in order to conduct Linux compatibility testing and benchmarking.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_2_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_2_med" alt="Acer Swift Edge 16 keyboard"></a></p>
<p>Ultimately I settled on the Acer Swift Edge 16. Many of the early Ryzen 7040 series laptops have featured NVIDIA GeForce RTX discrete graphics, which isn't of too much interest to many Phoronix readers that from the enthusiast/gamer angle tend to prefer Radeon (or Intel) graphics thanks to the fully open-source driver code. So it was a lot of waiting until finding a laptop in-stock with integrated graphics and other interesting specs. The Acer Swift Edge 16 became available in-stock last week and I went with it, which seems to be the first in-stock using the Ryzen 7 7840U. Also making this laptop interesting is its 16-inch 3.2K 120Hz OLED display that does support HDR.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_3_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_3_med" alt="Acer Swift Edge 16 side"></a></p>
<p>The Acer Swift Edge 16 has 16GB of LPDDR5 memory, a 1TB PCIe Gen 4 SSD, at least under Windows is rated for a 8.5 hour battery life, and features a magnesium alloy chassis. This Ryzen 7 7840U laptop is currently shipping at $1299 USD. Unfortunately the memory is non-upgradeable beyond the soldered 16GB of RAM.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_4_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_4_med" alt="AMD Ryzen 7 7840U with Acer Swift Edge 16"></a></p>
<p>By default the Acer Swift Edge 16 ships with Windows 11 Home. Quickly after receiving this laptop it was onward to testing Linux. First up was using Ubuntu 23.04, which refreshingly booted without issue on this laptop.  Booting the Ubuntu 23.04 ISO yielded working graphics acceleration, the integrated WiFi was working, the touchpad and keyboard were working, and the NVMe drive was properly detected. It was off to a great start!</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_6_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_6_med" alt="AMD Ryzen 7 7040 stickers"></a></p>
<p>But when rebooting to the newly-installed Ubuntu 23.04 is when the first problem arose... The screen went black upon booting the new installation after the Plymouth boot splash screen was over. Quite strange considering from the live ISO it booted up fine without issue to the GUI installer. And VT switching still was working for this laptop. After a lot of troubleshooting, it was a GNOME Wayland (Mutter) display problem / Wayland.... The ultimate cause yet to be figured out but likely due to some combination of the OLED/HDR panel. When switching to a VT and installing the KDE Plasma desktop, SDDM fired right on up and proceeded to work with the KDE Plasma desktop complete with graphics acceleration.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_5_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen7-7840u&amp;image=amd_7840u_5_med" alt="AMD Ryzen 7 7840U with KDE desktop"></a></p>
<p>AMD Linux engineers hadn't encountered said issue with their test hardware and seems to be something specific to the Acer Swift Edge 16's panel. They did note though to ensure AMD Phoenix laptop users fetch their latest AMDGPU firmware files from linux-firmware.git as with some laptop panels there may be Panel Self Refresh (PSR) issues if using the older firmware. Unfortunately for my case it didn't help the GNOME issue so my testing has been under KDE Plasma thus far.</p>
<p>After that initial headache, the Linux experience has been relatively robust. But I've also hit some other graphical glitches with the Radeon RX 780M upon game testing... Partial frame-buffer compression / white-out areas of the display. It's possible these items may be resolved past Linux 6.4 / Mesa 23.1, but alas I've been hammering this laptop for only the past week. Thus for today's article is focusing only on the Ryzen 7 7840U Linux CPU performance and a follow-up article will dig more into the Radeon 780M graphics support and performance under Linux.</p>
<p>The AMD Ryzen 7 7840U for Linux benchmarking is also a great choice since it's this model that the Framework Laptop will be shipping later this year. The Ryzen 7 7840U is also set to be in the GPD Win Max 2 among other higher-end 2023 laptops.</p>
<p>Besides the mentioned graphics issues, the AMD Ryzen 7 7840U has been working out well under Linux and it's sure been darn fast! Very exciting having Zen 4 in a laptop especially for those able to leverage AVX-512 or other heavy workloads from a laptop. Today's article has the Ubuntu 23.04 performance of the Acer Swift Edge 16 with Ryzen 7 7840U up against the prior generation Ryzen 7 PRO 6850U within a Lenovo ThinkPad X13 Gen 3 (LENOVO 21CM0001US) and then an Intel Core i7 1280P Alder Lake within a MSI Prestige 14 (MSI MS-14C6). Unfortunately I don't have any newer Raptor Lake laptop for Linux testing.</p>
</div>

							


					
						</article>
						
<!-- google_ad_section_end -->
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google's Privacy Policy Now Admits to Collecting All Your Data for AI Training (140 pts)]]></title>
            <link>https://www.pcgamer.com/in-case-there-was-any-doubt-googles-privacy-policy-now-explicitly-states-that-its-going-to-suck-up-all-your-data-to-train-its-ai/</link>
            <guid>36651717</guid>
            <pubDate>Sun, 09 Jul 2023 05:09:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/in-case-there-was-any-doubt-googles-privacy-policy-now-explicitly-states-that-its-going-to-suck-up-all-your-data-to-train-its-ai/">https://www.pcgamer.com/in-case-there-was-any-doubt-googles-privacy-policy-now-explicitly-states-that-its-going-to-suck-up-all-your-data-to-train-its-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=36651717">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="mTSjXezVBz6VRxDMMJKq8d">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.pcgamer.com/" aria-label="Return to Home">Home</a>
</li>
<li>
<a href="https://www.pcgamer.com/uk/news/" aria-label="Return to News">News</a>
</li>
</ol>
</nav>


</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Google campus sign" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg"><source type="image/jpeg" alt="Google campus sign" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg"><img src="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-320-80.jpg" alt="Google campus sign" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/uyEje6YtnET6euVcPGbG3P.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Bloomberg (Getty Images))</span>
</figcaption>
</div>

<div id="article-body">
<p>To me, artificial intelligence is a lot like magnets: I have no idea how they work. But I do understand, in a very general sense, that AI is not actually intelligent. It's just data, collected on a massive scale, algorithmically digested, and spit out in conversational tones designed to make us think that the machine is "smart."</p><p>The popular versions of these systems, like ChatGPT, live and die based on the amount of data they can harvest, which essentially means they're reliant on you. And in case there's any doubt about what "you" means in this particular context, <a href="https://policies.google.com/privacy?hl=en#footnote-sources" target="_blank" data-url="https://policies.google.com/privacy?hl=en#footnote-sources">Google</a> (via <a href="https://www.techspot.com/news/99281-google-policy-update-confirms-itll-scrape-everything-you.html" target="_blank" data-url="https://www.techspot.com/news/99281-google-policy-update-confirms-itll-scrape-everything-you.html">Techspot</a>) has updated its privacy policy to explicitly state that pretty much anything you say or do online can be scooped up and used to train its AI models.</p><p>Naturally, Google collects data from your online activity, like the stuff you search for, the videos you watch, the things you buy, and the people you talk to, and the location data accessed through your Android mobile device. But "in some circumstances," it also collects information from "publicly accessible sources": If your name appears in a local newspaper article, for instance, Google may index the article and then share it with people searching for your name.</p><p>That in itself isn't new: What's changed, as can be seen on Google's <a href="https://policies.google.com/privacy/archive?hl=en" target="_blank" data-url="https://policies.google.com/privacy/archive?hl=en">policy updates page</a>, is how Google says it can use the information it picks up from those public sources. Previously, the policy stated that publicly available data could be used "to help train Google’s language models and build features like Google Translate." The latest update broadens the policy considerably: "We may collect information that’s publicly available online or from other public sources to help train Google’s AI models and build products and features like Google Translate, Bard, and Cloud AI capabilities."</p><p>Bard is essentially Google's answer to ChatGPT, announced <a href="https://www.pcgamer.com/google-unveils-its-own-chatgpt-like-ai-chatbot/" target="_blank">earlier this year</a>, and much like other AI models it hasn't been entirely smooth sailing. In April, for instance, a report claimed that several Google employees had urged the company not to roll out Bard because the information it provided in response to queries was "worse than useless" and effectively made the chatbot a "<a href="https://www.pcgamer.com/google-employees-reportedly-begged-it-not-to-release-pathological-liar-ai-chatbot-bard/" target="_blank">pathological liar</a>."</p><p>More data should, in theory at least, lead to better results for Google's bots. But updated privacy policy or not, the legal status of this behaviour has not been clearly established. OpenAI is facing multiple lawsuits over the way it harvests and uses data to train ChatGPT: Policies like the one recently implemented by Google might seem to make some of it fair game but, but as <a href="https://www.washingtonpost.com/technology/2023/06/28/openai-chatgpt-lawsuit-class-action/" target="_blank" data-url="https://www.washingtonpost.com/technology/2023/06/28/openai-chatgpt-lawsuit-class-action/">The Washington Post</a> reported, AI models will hoover up pretty much anything from Wikipedia pages to news posts and individual tweets, a habit that a growing number of people take issue with.&nbsp;</p><p>And not all of the material in question is in fact fair game: Authors Mona Awad and Paul Tremblay recently <a href="https://www.theguardian.com/books/2023/jul/05/authors-file-a-lawsuit-against-openai-for-unlawfully-ingesting-their-books" target="_blank" data-url="https://www.theguardian.com/books/2023/jul/05/authors-file-a-lawsuit-against-openai-for-unlawfully-ingesting-their-books">filed their own lawsuit</a> against OpenAI, alleging that ChatGPT violated copyright laws by using their works to train its AI model without permission.</p><p>I've reached out to Google for more information on its reasons for changing its privacy policies, and will update if I receive a reply.</p>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Sign up to get the best content of the week, and great gaming deals, as picked by the editors.</p></section></div>
<div id="slice-container-authorBio"><p>Andy has been gaming on PCs from the very beginning, starting as a youngster with text adventures and primitive action games on a cassette-based TRS80. From there he graduated to the glory days of Sierra Online adventures and Microprose sims, ran a local BBS, learned how to build PCs, and developed a longstanding love of RPGs, immersive sims, and shooters. He began writing videogame news in 2007 for The Escapist and somehow managed to avoid getting fired until 2014, when he joined the storied ranks of PC Gamer. He covers all aspects of the industry, from new game announcements and patch notes to legal disputes, Twitch beefs, esports, and Henry Cavill. <em>Lots</em> of Henry Cavill.</p></div>



</section>


<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KDE for Travelers (146 pts)]]></title>
            <link>https://kde.org/for/travelers/</link>
            <guid>36651387</guid>
            <pubDate>Sun, 09 Jul 2023 03:59:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kde.org/for/travelers/">https://kde.org/for/travelers/</a>, See on <a href="https://news.ycombinator.com/item?id=36651387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><main><div><p>Travel the World Using KDE Applications</p></div><div><figure><img src="https://apps.kde.org/app-icons/org.kde.itinerary.svg" alt="" title=""></figure><h2 id="kde-itinerary">KDE Itinerary</h2><p>KDE Itinerary is a digital travel assistant that protects your privacy. It makes collecting all the information about your travel inside a single application easy and straightforward. KDE Itinerary is available for <a href="https://plasma-mobile.org/">Plasma Mobile</a> and Android.</p><p><a href="https://community.kde.org/Android/FDroid#KDE_F-Droid_Release_Repository"><img src="https://kde.org/store_badges/fdroid/en.svg" alt="Get it on F-Droid"></a></p></div><div><div><h2 id="store-your-reservations">Store your reservations</h2><p>Store all the information about your reservations in Itinerary. This includes QR-codes, check-in times, arrivial times, real-time delays, seat reservations, coach layout, and more.</p><p>Itinerary supports train, bus and flight bookings, as well as hotel, restaurant, event and rental car reservations. Traveling in a group? Not a problem, Itinerary supports multi-traveler bookings.</p></div><p><img src="https://kde.org/for/travelers/itinerary-trip.png"></p></div><div><div><h2 id="local-first">Local first</h2><p>Itinerary automatically extracts booking data from various input formats. It's all performed locally on <strong>your</strong> device and your data is not sent to any remote servers.</p><p>This works best when using <a href="https://kontact.kde.org/components/kmail/">KMail</a> to extract tickets from your email and then <a href="https://kdeconnect.kde.org/">KDE Connect</a> to transfer tickets to your phone. This also works great with <a href="https://apps.nextcloud.com/apps/mail">Nextcloud Mail</a> and <a href="https://f-droid.org/en/packages/at.bitfire.davdroid/">DavDroid</a> to sync your tickets from <a href="https://nextcloud.com/">Nextcloud</a>.</p><figure><img src="https://kde.org/for/travelers/kmail.png" alt="KMail ticket extraction showing a train trip from Berlin to Tübingen" title="KMail ticket extraction showing a train trip from Berlin to Tübingen"></figure></div><p><img src="https://kde.org/for/travelers/itinerary-ticket.png"></p></div><div><div><h2 id="add-your-connections">Add your connections</h2><p>Aside from finding reservations automatically in your email, Itinerary lets you add train trips manually to your journey, find alternative connections if your train is cancelled, or, for some providers, import your train trip directly from your reservation number.</p></div><p><img src="https://kde.org/for/travelers/itinerary-connections.png"></p></div><div><div><h2 id="find-your-way">Find your way</h2><p>Powered by <a href="https://www.openstreetmap.org/">Open Street Map</a>, the indoor map at train stations or airports can be a life saver. Use Itinerary to locate your platform is, and, if you have seat reservation and the train layout is available, it can even show you exactly which platform section is best for you.</p><figure><img src="https://www.volkerkrause.eu/assets/posts/139/kde-itinerary-platform-section-highlighting.jpg" alt="Train station map in KDE Itinerary, highlighting relevant platform sections." title="Train station map in KDE Itinerary, highlighting relevant platform sections."></figure><p>The indoor map also shows you which shops and resturantes are currently open, which elevator is broken (yet again!), where the toilets are and where the correct exit is.</p></div><p><img src="https://kde.org/for/travelers/itinerary-opening-hours.png"></p></div><div><div><h2 id="real-time">Real time</h2><p>It is rare that a train or bus depart or arrive on time. Itinerary keeps you updated when delays are announced.</p><p>On supported train and long distance buses, Itinerary will also use the onboard APIs to fetch the current live status of the vehicle and keep you updated on your current position and any announcements.</p></div><p><img src="https://kde.org/for/travelers/itinerary-live-status.png"></p></div><div><h2 id="arianna">Arianna</h2><p>Arianna is an excellent ebook reader that lets you read your favorite books while traveling. Arianna will track your reading progress
and classify your books by genre and author automatically.</p><figure><img src="https://cdn.kde.org/screenshots/arianna/reader.png" alt="Screenshot of Arianna" title="Screenshot of Arianna"></figure></div><div><h2 id="kasts">Kasts</h2><p>Enjoy listening to podcasts on the move with Kasts! Subscribe to your favorite podcasts and get updated as soon as a new episode is out.</p><figure><img src="https://cdn.kde.org/screenshots/kasts/kasts-desktop.png" alt="Screenshot of Kasts" title="Screenshot of Kasts"></figure><p>Kasts is also available on Android and <a href="https://plasma-mobile.org/">Plasma Mobile</a>.</p></div><div><p><a href="https://community.kde.org/Android/FDroid#KDE_F-Droid_Release_Repository"><img src="https://kde.org/store_badges/fdroid/en.svg" alt="Get it on F-Droid"></a></p></div><div><h2 id="kgeotag">KGeoTag</h2><p>KGeoTag is a geotagging program. It lets you tag your images with geocoordinates by matching them to a corresponding GPX track or by manually setting them by drag and dropping the images, or entering the coordinates by hand.</p><p>It is very helpful in combination with <a href="https://www.kphotoalbum.org/">KPhotoAlbum</a> or <a href="https://www.digikam.org/">Digikam</a> when you want to organize your photo collection after your trip and then visualize all the locations you visited.</p><figure><img src="https://cdn.kde.org/screenshots/kgeotag/kgeotag_shadow.png" alt="Screenshot of KGeoTag showing a track on a map with some image preview allong the track" title="Screenshot of KGeoTag showing a track on a map with some image preview allong the track"></figure></div><div><h2 id="marble">Marble</h2><p>Explore the world with Marble. Marble contains a huge collection of maps that let you travel all over the globe from your desktop. Visit remote places via detailed satellite images, travel the world before the discovery of America, and check out the average temperature and precipitation in winter and summer in other countries.</p><p>Marble also allows you to bookmark your favorite locations and lets you find your way thanks to its routing algorithm and OpenStreetMap powered maps.</p><figure><img src="https://cdn.kde.org/screenshots/marble/marble-world.png" alt="Screenshot of Kasts" title="Screenshot of Kasts"></figure></div><div><h2 id="other-open-source-apps-for-you">Other open source apps for you</h2><p>Here are some other applications from other open source communities that will make your travels fun.</p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: An index of all monthly dividend stocks (134 pts)]]></title>
            <link>https://thedividendlist.com/</link>
            <guid>36650581</guid>
            <pubDate>Sun, 09 Jul 2023 01:31:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thedividendlist.com/">https://thedividendlist.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36650581">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
            <strong>Please note</strong>: this table is currently truncated (hiding some data columns)
            in order to fit this screen.
          </p>
        <table>
          <thead></thead>
          <tbody></tbody>
        </table>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perl first commit: a “replacement” for Awk and sed (229 pts)]]></title>
            <link>https://github.com/Perl/perl5/commit/8d063cd8450e59ea1c611a2f4f5a21059a2804f1</link>
            <guid>36650120</guid>
            <pubDate>Sun, 09 Jul 2023 00:24:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Perl/perl5/commit/8d063cd8450e59ea1c611a2f4f5a21059a2804f1">https://github.com/Perl/perl5/commit/8d063cd8450e59ea1c611a2f4f5a21059a2804f1</a>, See on <a href="https://news.ycombinator.com/item?id=36650120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  

    
    

    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
  <p>
  <h2>Commit</h2>
</p>

<p><a href="https://github.com/Perl/perl5/commit/8d063cd8450e59ea1c611a2f4f5a21059a2804f1" data-hotkey="y">Permalink</a></p>


<div>
  <p><a id="browse-at-time-link" href="https://github.com/Perl/perl5/tree/8d063cd8450e59ea1c611a2f4f5a21059a2804f1" rel="nofollow">Browse files</a></p><tool-tip id="tooltip-48b3911f-a378-408f-be27-09a795a734bd" for="browse-at-time-link" data-direction="ne" data-type="description" data-view-component="true">Browse the repository at this point in the history</tool-tip>
    <p>
      a "replacement" for awk and sed
    </p>

    <div><pre>[  Perl is kind of designed to make awk and sed semi-obsolete.  This posting
   will include the first 10 patches after the main source.  The following
   description is lifted from Larry's manpage. --r$  ]

   Perl is a interpreted language optimized for scanning arbitrary text
   files, extracting information from those text files, and printing
   reports based on that information.  It's also a good language for many
   system management tasks.  The language is intended to be practical
   (easy to use, efficient, complete) rather than beautiful (tiny,
   elegant, minimal).  It combines (in the author's opinion, anyway) some
   of the best features of C, sed, awk, and sh, so people familiar with
   those languages should have little difficulty with it.  (Language
   historians will also note some vestiges of csh, Pascal, and even
   BASIC-PLUS.) Expression syntax corresponds quite closely to C
   expression syntax.  If you have a problem that would ordinarily use sed
   or awk or sh, but it exceeds their capabilities or must run a little
   faster, and you don't want to write the silly thing in C, then perl may
   be for you.  There are also translators to turn your sed and awk
   scripts into perl scripts.</pre></div>

  <div>
  <include-fragment src="/Perl/perl5/branch_commits/8d063cd8450e59ea1c611a2f4f5a21059a2804f1" id="async-branches-list">
    
    <ul>
      <li>Loading branch information<span></span></li>
    </ul>
</include-fragment></div>


  
</div>


  


  <diff-layout>
    
        </diff-layout>


</div>

</turbo-frame>


    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California needs real math education, not gimmicks (259 pts)]]></title>
            <link>https://www.noahpinion.blog/p/california-needs-real-math-education</link>
            <guid>36650010</guid>
            <pubDate>Sun, 09 Jul 2023 00:05:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noahpinion.blog/p/california-needs-real-math-education">https://www.noahpinion.blog/p/california-needs-real-math-education</a>, See on <a href="https://news.ycombinator.com/item?id=36650010">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg" width="716" height="290.1373626373626" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:590,&quot;width&quot;:1456,&quot;resizeWidth&quot;:716,&quot;bytes&quot;:183684,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4431a65f-8a19-46b7-af11-ff6fd81b09b1_2000x810.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>In an </span><a href="https://vimeo.com/65921206" rel="">old Saturday Night Live skit</a><span>, Chevy Chase, portraying Gerald Ford, says “It was my understanding that there would be no math.” Half a century later, it seems like this has become America’s national motto. Even as high-tech manufacturing has migrated relentlessly to China, plenty of Americans seem to think that they — or anyone — should be able to flourish in a modern economy without a functional understanding of mathematics. U.S. high school math scores </span><a href="https://www.bloomberg.com/opinion/articles/2019-12-12/u-s-schools-do-fine-in-international-rankings-except-in-math?sref=R8NfLgwS" rel="">lag significantly</a><span> behind other countries, even though scores in reading and science are above average, and our country is </span><a href="https://www.bloomberg.com/view/articles/2020-07-29/u-s-will-need-talented-refugees-if-skilled-immigrants-won-t-come?sref=R8NfLgwS" rel="">utterly dependent </a><span>on a continuous inflow of foreign talent for a number of critical STEM fields. Math, out of all subjects, seems to hold a special terror for Americans, who often seem to view the subject as a test of innate intelligence rather than </span><a href="https://www.theatlantic.com/education/archive/2013/10/the-myth-of-im-bad-at-math/280914/" rel="">a skill that can be acquired and honed</a><span> through hard work. </span></em></p><p><em><span>In response to lagging math scores, educators in California have been trying to water down math education — banning students from taking algebra in 8th grade, replacing advanced algebra classes with “data science” courses that don’t even teach the algebra required to understand basic statistics, and so on. I see this as an extremely wrongheaded move, and I’ve been meaning to write about it for a while. But data analyst </span><a href="https://twitter.com/ArmandDoma" rel="">Armand Domalewski</a><span>, a friend of mine, has been following the issue far more closely than I have, and has been outspoken about it on social media, so I thought I would ask him to take a crack at saying what needs to be said.</span></em></p><p>One of the strangest things about California is that it is simultaneously one of the technology capitals of the world and has some of the worst math scores for children in the entire United States. In practice, California has relied on a combination of pockets of home grown math excellence and imported math whizzes from around the globe to bridge the gap between the math skills it needs and the math skills it has. It works, somewhat—but we can and should do better by all of the kids in our state.</p><p>We have a chance to do exactly that with the release of a new California Math Framework (C.M.F.), a document used by the state to establish math curricula for all public schools in California. Unfortunately, that process has been hijacked by a “math reform” movement led by Stanford Professor Dr. Jo Boaler, who claims to advocate for a more inclusive way of teaching that would replace memorizing times tables with real-world problem-solving. Her worldview has gained credence in influential educational circles because, to many people, including myself, the basic premise is extremely appealing: replacing rote memorization with creative problem solving, making math more inclusive to all kinds of students, embracing a growth mindset, etc. all sound lovely. And honestly, I don’t think at a high level that these concepts are wrong—what is broken, however, is the specific implementation of these ideas as advocated by Dr. Boaler and implemented by California education policymakers.</p><div><p><span>Math </span><em>should </em><span>be more inclusive. Math </span><em>should </em><span>be more engaging. I think one of the biggest mistakes both Dr. Boaler’s supporters and detractors have made in this debate is to try to slot what should be a practical, fact based argument about optimal math education into an ideological struggle invoking silly phrases like Woke Math. Dr. Boaler and her fans did not make math education worse by being too left wing in their math—whatever that even means—but by sloppy with their science and lazy with their facts. You don’t make math education better by advocating for changes based on lies, and unfortunately, that is exactly what happened here. </span></p><p><span>Two of the major policy changes proposed in the draft CMF are already showing indications of disaster. The first is moving Algebra education out of 8th Grade.</span></p></div><div><p><span>One of the ideas underpinning the California Math Framework is the notion that math needs to be “detracked”—instead of allowing some students to take Algebra I in 8th grade, it would require all students to enroll in the same math curriculum until the 9th grade. Advocates argue&nbsp; this promotes equity, while detractors argue that it diminishes excellence. Years ago, I supported San Francisco’s efforts to rework the curriculum based on that argument—I believed those who said it would improve educational outcomes for the kids struggling the most without hurting those who were already succeeding. </span></p><p><span>I was wrong. Not only did pushing out 8th grade Algebra hurt kids who were at the top of their class by forcing them to pay for private classes or other workarounds to get the credits they needed to apply for UCs, the claim that it would help outcomes for kids who were struggling turned out to be a bald faced lie.</span></p></div><p><span>In 2017, </span><a href="http://www.sfusdmath.org/uploads/2/4/0/9/24098802/historic_shifts_in_math_show_promise.pdf" rel="">SFUSD</a><span> claimed a "dramatic increase in student comprehension" and a drop in Algebra 1 repeaters from 40% to 7%, and credited detracking. An analysis by</span><a href="https://www.familiesforsanfrancisco.com/updates/inequity-in-numbers" rel=""> Families for San Francisco</a><span> found that this claim was utter nonsense. Algebra 1 grades did not improve at all, and the only reason the repeat rate went down was because SFUSD straight up </span><em>eliminated the requirement that you had take an exit exam in order to progress!</em><span>&nbsp;</span></p><p>Not only that, but the group was unable to replicate the 40% to 7% drop using the data provided by SFUSD through a records request, and no other independent entity has been able to validate that number as well.</p><p><span>Page 6 of this </span><a href="https://static1.squarespace.com/static/60412a3a51d4863950d1bdf2/t/616e2f823696906267609f3f/1634611077888/Report-+Inequity+in+Numbers.pdf" rel="">report</a><span> is particularly damning–SFUSD provides numbers that, when reverse engineered with some basic Algebra, would imply a class size of 2475 students when the actual class size was 4011. What happened to the other 1,536 students? The shoddiness of this evidence did not stop Dr. Boaler from touting this as a major success for her ideas, and until very recently, did not stop the CMF from citing it as a major argument in favor of detracking.</span></p><div><p><span>Not only did detracking not achieve its stated goals of advancing math equity in San Francisco, it actually harmed Black and brown students. By the end of 10th grade, Algebra 2 enrollments of Black and brown students declined, since their families were less likely to afford the expensive work arounds that white and Asian families pursued. Instead, most of the district’s Black and Latino students ended up in a diluted “compression” course that lacked about 75% of the state’s</span><a href="https://www.cde.ca.gov/ci/ma/cf/documents/mathfwprecalculus.pdf" rel=""> precalculus</a><span> “+” standards, where the “+” standards are defined as “additional mathematics to prepare students for advanced courses,” making it difficult for students to pursue more advanced math in college. (Which is why, counter the claims of some detracking advocates, the UCs do not officially credit this compression course as “advanced math.”) </span></p><p><span>The result? They’re grim. If you compare </span><a href="https://www.educationnext.org/san-franciscos-detracking-experiment/" rel="">statewide results against SFUSD results on California’s Smarter Balanced tests,</a><span> which assess student performance across the state, you see that between 2015 and 2019, at the state level, the eleventh-grade Black-White student&nbsp; gap grew by 11 points—from 94 to 105—while in SFUSD, the gap expanded by 15 points (from 143 to 158). The outcomes are even worse for Hispanic students. The Hispanic-White gap at the state level gap grew by only 5 points, but in SF, it grew by 31 points.</span></p></div><p><span>As with all education data, there are always a million variables and you can never conclusively say that a single policy change caused a specific outcome, but at the very least, it is hard to argue that these 8th Grade Algebra changes advocated by Boaler helped SFUSD, and even harder to argue they serve </span><em>as a model for our state.&nbsp;</em></p><p>Unfortunately, that is not the only controversial policy change being pitched in the CMF: another poorly conceived notion is the replacement of the second year of Algebra with “data science.”</p><p><span>For decades, American math curriculum has followed a standard sequence: arithmetic, algebra, geometry, algebra II, precalculus and trigonometry, and calculus. The University of California required you to take three years of high-school math, culminating in Algebra II. In October 2020, the UC Board of Admissions and Relations with Schools (BOARS) </span><a href="https://senate.universityofcalifornia.edu/_files/committees/boars/documents/statement-on-mathematics-preparation-for-uc.pdf" rel="">recommended allowing alternatives</a><span> to the second year of algebra—including data science. Courses like “</span><a href="https://www.introdatascience.org/" rel="">Introduction to Data Science</a><span>,” developed by UCLA and “</span><a href="https://hsdatascience.youcubed.org/" rel="">Explorations in Data Science</a><span>,” developed by Dr. Boaler, started popping up. The argument was that these classes would teach data skills relevant to the 21st century, such as collecting and analyzing data on “real-world topics,” in contrast to Algebra II, which Boaler said was as relevant as “</span><a href="https://www.latimes.com/opinion/story/2019-10-23/math-high-school-algebra-data-statistics" rel="">sock darning and shorthand</a><strong><span>.” </span></strong><span>And look, in theory, this sounds nice. I mean, my job is literally data analyst—I analyze, evaluate, and interpret data for a living! When I first heard about this, I was thrilled. But when I thought about it a bit more, it gave me pause—the skills I use daily as a data analyst are based on a foundation of Algebra and Calculus. It didn’t quite make sense to me how you could </span><em>replace </em><span>Algebra II with data science—the formulas that make up linear regression, for example, don’t make any sense unless you have at least a basic grasp of algebra.&nbsp; Logarithms and trigonometric functions are pretty core to doing data science work! So I started digging into what was actually being taught in these “data science” courses and was…frankly, I was horrified.</span></p><p><span>While UC Admissions requirements state that Algebra II alternatives still have to “build on” certain core concepts in Algebra II, in practice this does not seem to be enforced. The “Introduction to Data Science” produced by UCLA contains </span><a href="https://www.ucladatascienceed.org/wp-content/uploads/California-Common-Core-Mathematics-Standards-addressed-by-IDS.pdf" rel="">very little Algebra II</a><strong> </strong><span>and “Explorations in Data Science” only claims to</span><a href="https://docs.google.com/presentation/d/e/2PACX-1vQ4tVbSk5qZsgARWwctjKa6joNKKYi7_jzi2-hkDyr7yGzQSQgKCndzhfaICVooye55ZZqCBEVXpxSv/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p" rel=""> teach the portions of Algebra II that overlap with statistics</a><span>, leaving huge swathes of math necessary for an eventual career in STEM completely untouched.&nbsp;</span></p><p><span>Frankly, reading the CMF does not give me the impression that its authors have a strong understanding of what data science </span><em>is</em><span>, exactly. It includes phrases like “the numbers are staggering: around 1.7 megabytes of digital data were created and stored every second for every person on Earth in 2020, and the vast majority of data goes unanalyzed.’ As </span><a href="https://sites.google.com/view/publiccommentsonthecmf/#h.w46loj4uaiev" rel="">Dr. Brian Conrad</a><span> points out, this is a nonsense statement. Is 1.7MB a large amount? (No, literally one JPEG can be that size.) Most of that is likely video, how exactly should that “data” be “analyzed”? And how do the authors even know it’s not being analyzed? After all, every video uploaded to YouTube gets tossed into an algorithm that produces viewing metrics, there are data scientists analyzing those uploads for trends, etc? (The authors probably found it by googling “impressive big data stats'', which spat out that statistic as the first result at the time the CMF was drafted.).&nbsp;</span></p><p><span>I wish this ignorance of the subject matter was limited to cute illustrative examples, but unfortunately, it permeates the basic thinking and structure of the document. The core issue of the CMF’s “data science” section is that it claims to be discussing data science while it is actually discussing </span><em>data literacy. </em><span>Don’t get me wrong—data literacy is good! Society would be better off if more people understood how to clean data or read a poll accurately. </span><em>But this is not data science and it is not math. </em><span>&nbsp;The CMF is replete with </span><a href="https://drive.google.com/file/d/1QI9XDw77ZlvwtcnLn_rKbhaWHo2UX-E2/view" rel="">statements</a><span> like “high-school data-science class students can learn to clean data sets – removing any data that is incorrect, corrupted, incorrectly formatted, duplicated, or incorrect in some other way [...] High school students can also learn to download and upload data, and develop the more sophisticated “data moves” that are important to learn if students are tackling real data sets.'' This teaches you how to use Excel, sure—but it does not teach you how regressions work, how statistical tests work, the multivariable calculus and linear algebra </span><em>you need to do the job of an actual data scientist!</em></p><p><span>In response to this, science and math professors across the state </span><a href="https://sites.google.com/view/mathindatamatters/home" rel="">have</a><span> been </span><a href="https://edsource.org/2022/proposed-mathematics-pathways-for-california-high-school-students-raise-equity-concerns/674400" rel="">raising</a><span> </span><a href="https://www.chronicle.com/article/the-university-of-california-changed-its-math-standards-some-faculty-arent-happy" rel="">alarms.</a><span> In response, Dr. Boaler turned to a tactic she often relies on—trying to wrap her ideas in the context of a broader culture war, painting critics as stodgy conservatives fighting her efforts to make math more equitable and diverse. She described her critics as those resisting change. The notion that teaching this version of data science rather than Algebra II is somehow more equitable permeates the CMF in often bizarre ways.&nbsp;</span></p><p><span>The CMF says data science is more </span><a href="https://sites.google.com/view/publiccommentsonthecmf/" rel="">equitable</a><span> than other STEM fields because “data scientists work together to address uncertainty in data while avoiding bias.”</span></p><p>Err, what? I’ve met many data scientists who do not work together or address uncertainty in data while avoiding bias, and many non-data science STEM professionals who do. There is absolutely nothing inherent to data science that makes it more collaborative or unbiased than other STEM fields…</p><div><p><span>It goes on to say…“Traditional mathematics lessons that have taught the subject as a set of procedures to follow have resulted in widespread disengagement as students see no relevance for their lives. This is particularly harmful for students of color and for girls…The data science field provides opportunities for equitable practice, with multiple opportunities for students to pursue answers to wonderings and to accept the reality that all students can excel in data science fields.'' </span></p><p><span>I agree that traditional math as currently taught does disengage a lot of students, and in particular women. But there is absolutely no evidence offered in the CMF to suggest that data science education would somehow be different, and there is something profoundly weird about the suggestion that students of color and girls can excel in data science fields but not excel in other fields of mathematics. The primary reason girls, for example, diverge from boys in math performance is </span><em><a href="https://techcrunch.com/2016/01/05/why-stems-future-rests-in-the-hands-of-12-year-old-girls/" rel="">because society teaches them that math is not for girls.</a></em><span> That is not something swapping out actual math for a watered down “data science” course can solve, and it’s pretty gross for people to claiming to be trying to make math more equitable for women and people of color to be pushing a program that will actually make them </span><em>worse at math. </em><span>Dr. Boaler and the CMF are basically saying “women and people of color aren’t doing as well in math, so we should just </span><em>give up on teaching them actual math</em><span>. It’s bananas!</span></p></div><p><span>But don’t take my white, male word for it—a group of Black UC faculty members in data science-related fields wrote a </span><a href="https://www.chronicle.com/article/the-university-of-california-changed-its-math-standards-some-faculty-arent-happy" rel="">letter</a><span> stating, “‘Introduction to Data Science’...make[s] claims that they specifically support learning for women and minorities, which are not only baseless, but fail to appreciate that they actually do the opposite and harm students from such groups by steering them away from being prepared for STEM majors.”</span></p><p><span>There’s a reason why these folks have been joined by other Black mathematicians around the country, such as </span><a href="https://www.chronicle.com/article/the-divider" rel="">Dr. Jelani Nelson,</a><span> in pushing back fiercely against the ideas around 8th Grade Algebra and data science proposed in the CMF. (And a reason, perhaps, that Dr. Boaler </span><a href="https://nypost.com/2022/04/08/stanford-prof-calls-cops-on-berkeley-prof-who-exposed-her-5k-hour-consulting-fee/" rel="">threatened to call the police on him for it!</a><span>) There’s a reason why Stanford Mathematics professor Dr. Brian Conrad&nbsp; wrote, in a comprehensive </span><a href="https://sites.google.com/view/publiccommentsonthecmf/?ref=stanfordreview.org#h.ns5n6hdqa4x8" rel="">takedown</a><span> of the CMF you really should read, that “whatever author is responsible for such a myopic view of mathematics should never again be involved in the setting of public policy guidance on math education.” There’s a reason why the </span><em><span>authors of papers Dr. Boaler cites to </span><a href="https://www.chronicle.com/article/the-divider?cid=gen_sign_in" rel="">back up her work consistently say she has misread and misrepresented their work</a></em><a href="https://www.chronicle.com/article/the-divider?cid=gen_sign_in" rel="">,</a><span> and that it does not support the claims she is making. And the reason, simply, is that her ideas have not worked. Forcing all children to defer Algebra until 9th grade,trying to squeeze two years of schooling into one year of a watered down “compression course” rejected by the University of California for not meeting its </span><a href="https://icas-ca.org/wp-content/uploads/2020/05/ICAS-Statement-Math-Competencies-2013.pdf" rel="">standards</a><span>, and replacing Algebra II with a glorified data literacy course masquerading as a “data science” course does not help high achieving kids or struggling kids or any kids in between—it hurts them all.</span></p><p><span>California students need different answers on math–what we’ve been doing for the past few decades hasn’t worked. But that doesn’t mean we should embrace the ideas embodied in the current CMF draft, which were built on decades of </span><a href="https://www.nonpartisaneducation.org/Review/Articles/v8n1.pdf" rel="">shoddy and dishonest academic research,</a><span> and throw up our hands at the notion of teaching underperforming kids advanced math entirely. The good news is that there are answers out there—we can learn from </span><a href="https://www.theatlantic.com/education/archive/2013/10/the-myth-of-im-bad-at-math/280914/" rel="">other countries teach math differently than we do,</a><span> we can integrate findings from the </span><a href="https://www.cis.org.au/publication/myths-that-undermine-maths-teaching/" rel="">“science of math”</a><span>, and more. Our kids deserve a better California Math Framework than the one we’re being offered now—let’s get it done.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.noahpinion.blog/p/california-needs-real-math-education?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.noahpinion.blog/p/california-needs-real-math-education?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pocket gets worse the more you use it (2019) (139 pts)]]></title>
            <link>https://web.archive.org/web/20190512092903/https://old.reddit.com/r/dredmorbius/comments/5x2sfx/pocket_it_gets_worse_the_more_you_use_it/</link>
            <guid>36649740</guid>
            <pubDate>Sat, 08 Jul 2023 23:19:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.archive.org/web/20190512092903/https://old.reddit.com/r/dredmorbius/comments/5x2sfx/pocket_it_gets_worse_the_more_you_use_it/">https://web.archive.org/web/20190512092903/https://old.reddit.com/r/dredmorbius/comments/5x2sfx/pocket_it_gets_worse_the_more_you_use_it/</a>, See on <a href="https://news.ycombinator.com/item?id=36649740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Having used Pocket's article-archival-and-management tool -- sort of a bookmarks-on-steroids product -- for the past year or two, and with news that the company has just been acquired by Mozilla (it's been getting increasingly integrated into Firefox over the past year or so), I've realised one of my most fundamental complaints about it.</p>

<p><strong>The more I use Pocket, the worse it gets.</strong></p>

<p>As I've mentioned (a few too many times), I do a lot of research, much of it with articles and documents, and tools for managing the pile / heap / mountain / swamp are a constant and growing consideration.  Pocket addresses one part of the problem:  online HTML-based content.</p>

<p>I've compiled a large set of articles.  I'm a top-1% reader, according to an emailed report sent a month or so back.  Some 2,000 or so in Readability, prior to its demise, manually transferred in the week before that service was to go dark, and another 1,000 - 3,000 likely in Pocket itself.  I make copious use of tagging features.  My intent is to have <em>a vetted, known, classified, and useful set of references to comb through for specific research needs as I organise and write</em>.</p>

<p>The fact that I can't even say, not even <em>approximately</em>, how much material I've archived, is a profound signifier of the design failures and lack of consideration of use-cases.  The folks at Pocket seem to have given absolutely no thought to how people might use their product, or benefit by self-directed use.  (And it's not as if they've not heard:  I've shared this complaint with them multiple times over the past two years.)  Which is to say:  even at the most basic level, <em>the product isn't getting better or more useful</em>.</p>

<p>The problem is, the bigger the pile gets, the less manageable it becomes.</p>

<h2>Tags</h2>

<p>Great, I have an unlimited set of tags.</p>

<p>It takes me 45 seconds just to scroll from the top of the list to the end on the Android app.</p>

<p>The tags are not searchable.  A "type and autocomplete" feature -- you know, the sort of thing software has offered since the 1980s, would be peachy.  No such luck.</p>

<p>The tags don't auto-complete <em>and activate such that, say, I can hit &lt;enter&gt; to select one</em> when filing new material.</p>

<p>If I make a tyop, I cannot, say, <em>select a tag and edit it right there</em>.  No, I've got to:</p>

<ol>
<li>Switch to the "Tags" view.</li>
<li>Select the "Edit" option.  <em>Before</em> I search for the tag I want to edit.</li>
<li>Scroll through the list to where the tag in question is.  Given a 45s full-list scan, this takes an average of about 22 seconds.</li>
<li>Edit and save the tag.</li>
</ol>

<p>What <em>could</em> be a two-second, in-place operation, becomes an epic-journey-to-a-distant-land-and-quest-for-a-holy-grail, fraught with pitfalls and traps -- if you make the wrong turn, you waste time, have to backtrack, and start over again.  During all of which your flow-of-thought is being completely interrupted.</p>

<p>Desktop clients (Web) don't appear to be any better.</p>

<p>If I happen to typo a tab and want to delete it, in the Android app, with my Bluetooth keyboard attached ... I cannot.  I've got to switch to the <em>software</em> keyboard, re-select the tag in question (because, of course, it doesn't stay selected), then delete it.</p>

<p>It's not possible to filter by <em>multiple</em> tags.  Something which is hugely annoying as that is a fast and efficient way to cut through a large mass of material -- items which are cross-referenced and multi-tagged could be, say, filtered with the remaining tags within the set listed.  Check the ones you're interested in and you should end up with a small set of items of interest.</p>

<p>And finally:  the tags display is highly minimal and hidden under windows.  These should be presented <em>on the document itself</em> (head or foot, preferably), <em>with all tags visible at all times</em>.  Selecting a given tag should call up all content under it (and provide for further filtering by other tags).</p>

<h2>Search</h2>

<p>For a time, it seemed that Pocket had a full-text article search, able to use multiple words.  That ... seems to have vanished.</p>

<p><strong>Keep in mind:  Pocket archives its articles locally.  <em>The search can run over the local archive, and doesn't impose any server load.</em>  But it doesn't.</strong></p>

<p>No bueno.</p>

<p>Which means that <em>despite having an archive of data sitting on my own device, in text form, eminently searchable</em>, my best option is to try an online search (of a much larger corpus), and hoping I might land the items of interest.</p>

<p>This is, to say the least, slightly frustrating.</p>

<p>The fact that Pocket's search, such as it is, seems to be limited to <em>a single keyword</em>, to not support <code>"quoted strings"</code>, or <code>-excluded terms</code>, or field-specific criteria (author, date, publisher, website), ranges, etc., is ... similarly a staggering oversight.</p>

<p>Frankly, I'd get more utility (and am strongly considering how I might accomplish this) downloading or fetching content locally, and running various search/index tools over it.</p>

<h2>Search</h2>

<p>No, that's not a typo:  I'm referring to <em>in-document</em> search.  On the Android app, there is no text search <em>within</em> documents.</p>

<p>If I want to find a particular passage, I've either got to vgrep for it (scan manually), switch to one of the Web interfaces, or pull up the original article online.  Another staggering oversight.  (Though in fairness:  fairly common amongst Android apps, which only means the firing squad's work is all the larger.)</p>

<h2>Workflow</h2>

<p>There's no concept of workflow.</p>

<p>Generally, I'm stashing stuff for later review, on which I'll be associating it with various projects, dumping into a general file, or indicating it's been seen and found wanting.  A set of workflow-oriented features would help in this.  No such thing exists.</p>

<h2>Going from Browser to Pocket</h2>

<p>One of my most frequent operations is to open a Web page, discover that it is utterly fucked over in its page design, and want to open it in Pocket.  What I'd <em>like</em> to do is:</p>

<ol>
<li>Open the current tab immediately in Pocket, whilst closing the present window.</li>
</ol>

<p>What I've got to do instead is:</p>

<ol>
<li>Save to Pocket.</li>
<li>Try to close the current tab -- tricky at best on a mobile device given imprecise location control and click-vs-drag ambiguity, plus focus-stealing by Pocket meaning a keyboard &lt;ctrl&gt;-W generally doesn't work.</li>
<li>Punch the Pocket icon that appears to switch to Pocket.</li>
<li>Land on the Pocket <em>article list</em> rather than <em>the article I've just added to it</em>, requiring a 2nd step to get to that.</li>
</ol>

<p>A one-step process has become a 4-5 step process.  Every. Single. Time.</p>

<p>In the way of Pains Suffered Through Life, it's not among the largest.  But it's a telling failure of attention to detail, or consideration of What the User Might Want.</p>

<h2>Reputation</h2>

<p>Since I'm referencing my corpus, over time I'll build up a set of "hot" articles that are referenced more frequently than others.  I might want to have these turn up quickly in searches ... or perhaps exclude them to find other potentially relevant material.  Again, lack of any user-oriented statistics means this isn't supported.</p>

<p>Similarly, I'd like to be able to indicate reputation of sources, for accuracy or insight.  I don't make a habit of choosing a <em>large</em> amount of bogus material, but since one of my research areas is the concept of bogosity itself, there are a few.  And there are also sources and authorities who are particularly compelling.  Being able to track reputation by author, publication, and URL, would again be highly useful.</p>

<h2>Export lists</h2>

<p>A chief value of being able to categorise content is <em>to be able to call it up, and share it</em>, when desired.</p>

<p>I can ... very barely sort-of ... search through and find some subset of my articles.</p>

<p>What I <em>cannot</em> do, and what I've wanted to do many times, is to apply one of the non-existent advanced search features above, to select out a set of, say, 2-12 articles or references I think will be particularly useful to someone, and dump that as a set of URLs (to either Pocket or the original sources).  A hugely useful capability, and one which could well help to popularise Pocket itself.  But not present.</p>

<h2>Highlights and notes</h2>

<p>Again:  for research, I'm reading material for synthesis, not just pleasure.  Which means I want to make comments, mark relevant passages, etc.  There's no capability to do so.</p>

<h2>Paying for it wouldn't help</h2>

<p>I had, for a while, the trial-mode advanced usage features of Pocket.  That <em>may</em> have included full-text search (it's not clear that this was or wasn't included, and ... it's painfully difficult to find out just what the full-product features are).  There was a "suggested tags" feature, which was nice, though not essential, and I find I somewhat prefer <em>thinking</em> about tags <em>without</em> having them suggested to me (though the ability to check against suggestions would be useful).</p>

<p>But none of the other features I've listed are currently in the paid app.  There's been no visible work I'm aware toward any of them over the past year or so.</p>

<p>I'm familiar with arguments for paying for software.  I've never found them particularly convincing, as an individual user, particularly given my experience with Free Software over the years.  Whilst I've seen a fair number of FS projects with crappy user relations, in general I've found that:</p>

<ol>
<li>The software already anticipates my needs.</li>
<li>Developers are responsive to intelligent requests.</li>
<li>I can contribute myself, to my abilities -- a small number of bugfixes, rather more bug reports, occasional documentation.</li>
</ol>

<p>In the proprietary world, <em>if you are a significant customer</em>, it's possible to see requests built out.  Ordinary users, particularly in the Web world where userbases are measured in the 100s of millions or billions, rather less so.  In fact, generally, I've seen long-standing requests <em>from myself and numerous others</em> utterly ignored, for years.  Most especially if they are for "advanced user" features -- anything remotely generative.</p>

<p>A few hours ago I posted an item at Ello about the DMOZ hierarchy categories -- a list of 800,000+ classifications of online content.  I'd done some quick classification of it, on my Android tablet, using Termux, an add-on Linux environment with actually-capable shell tools, including auto-generating a Markdown table.  It's a small example of the power of such tools -- the ability to scan through nearly a million items and reduce them to a meaningful report in 18 rows, ready for publication.  (Mind:  Ello's table support appears broken, though I've also posted a copy to a Reddit sandbox.)</p>

<p><strong>That is the level of power and flexibility I expect from, no, demand from, my tools.  And am finding increasingly lacking.</strong></p>

<p>It took me most of a year to even discover Termux, and another several months to learn of the API features enabling clipboard interaction with the Android environment.  Which I'm using, incidentally, to compose this Reddit post, given the pains and pitfalls of using the Web interfaces on Android.</p>

<p>I suspect too that the individual-subscriber market isn't worth all that much to Pocket either.  Dealing with individual payments and the hassles thereof (from <em>both</em> sides:  credit card and identity fraud affect customers as well), make the margins afforded by support minimal.  Bundling and large-account sales are, with very few exceptions, where the money in software has been made.  Researching a set of Murphy's and related laws earlier, I came across Mark Miller's exception to Crane's Law:</p>

<blockquote>
<p>There are no "free lunches", but sometimes it costs more to collect money than to give away food.  </p>
</blockquote>

<p>That's among the motivating influences behind Free Software as well, though it helps to realise that costs can impose themselves in numerous ways.  An avoided cost of free software <em>can</em> be (though not always) the contributions and assistance of others in improving your product.  Going closed and proprietary loses that, though with possibly other beneficial trade-offs.</p>

<h2>What to do?</h2>

<p>Back to Pocket:  my view for now is much as I was treating Readability for the 2-3 years in which that project was obviously a dead man walking.  It was unsuitable to my needs, but marginally better than nothing at all, or other options.  The transition costs (to another proprietary tool, to a nonproprietary tool, my own solution) are all high.  I'm not sure how much metadata I can extract from Pocket, and loss of my tags would be a major hassle.  The evaluation cost of alternatives (Pinboard.in is highest on the list) is itself high.  I've been looking at an Emacs-based option, or ... something.  Using mutt or an email-storage format as an article reference tool has crossed my mind more than once.  With an IMAPS server, that gives me remote access, search, filter, annotation, and, with some add-on tagging or other classification systems, more organising capabilities.</p>

<p>Or some sort of DIY web-based interface, with some virtual filesystem approaches to addressing a <a href="https://web.archive.org/web/20190512092903/https://news.ycombinator.com/item?id=13751560">larger set of concepts</a> including metadata-as-search based on, say, title, author, other persons, dates, organisations, hashes, or content.</p>

<p>I'd also very much like to have other document formats -- PDFs, ePubs, DJVU, Mobi -- included.  For which, the capability to search meaningfully <em>within those docs, as text</em> would be handy (I'm getting well past the point of badly wanting a <code>pdfgrep</code> or <code>ocrgrep</code> type tool -- which reminds me that converting a substantial set of scanned books to eBook format(s) is another pending project).</p>

<p>Mostly though, I wonder why such things are, 25 years into the WWW, approaching 50 years from the birth of Unix, seventy years after Vannevar Bush's Memex proposal, so fucking hard to get right.  </p>

<p>Is it the problem itself, the people working on it, the dynamics of trying to commercialise such systems, or what?</p>

<hr>

<h2>Updates</h2>

<h3>17 March, 2017</h3>

<p>I'd submitted a request to Pocket support when I first posted this, about two weeks ago now.  Having heard no response, other than an automated acknowledgement, I've just submitted it again yesterday.  Again, an automated response but nothing more.</p>

<p>This is disappointing.</p>

<p>Pocket <em>have</em> tended to be responsive, and friendly, to requests, which was a ray of hope.  Mind:  actually <em>addressing</em> the substance of those requests through fixes and enhancements, not so much.  I'm aware that there can be long lists of such requests, that there's a lot of behind-the-scenes work, and more.  But over the course of 1-2 years, with some pretty significant issues, I'd hope to see <em>some</em> progress.  There's been ... none.</p>

<p>Elements of the product as it stands are good.  But at least for my use-case, it's the oversights which are increasingly glaring and inexcuseable.  I don't like rolling my own for all the obvious reasons, but it really seems as if what I'm looking for doesn't exist.</p>

<h3>7 May, 2017</h3>

<p>I did finally hear back from Pocket a few days ago, they've seen the comments here and acknowledged them.  For that alone, I'm grateful.</p>

<p>Foulups happen and messages get dropped, I've seen that.  I've <em>also</em> seen projects go completely dark (Readability had done that for a few years before shutting down), so ... it's a concerning sign.</p>

<p>I <em>would</em> like to see movement.  If not, I'm considering other options.  Semantic filesystems or something along those lines is starting to sound more interesting.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Machine Unlearning Challenge (166 pts)]]></title>
            <link>https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html</link>
            <guid>36649710</guid>
            <pubDate>Sat, 08 Jul 2023 23:14:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html">https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html</a>, See on <a href="https://news.ycombinator.com/item?id=36649710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-667019077470952746">
<p><span>Posted by Fabian Pedregosa and Eleni Triantafillou, Research Scientists, Google</span>

</p><p>
Deep learning has recently driven tremendous progress in a wide array of applications, ranging from <a href="https://imagen.research.google/">realistic image generation</a> and <a href="https://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html">impressive retrieval systems</a> to <a href="https://blog.google/technology/ai/bard-google-ai-search-updates/">language models that can hold human-like conversations</a>. While this progress is very exciting, the widespread use of deep neural network models requires caution: as guided by Google’s AI <a href="https://ai.google/responsibility/principles/">Principles</a>, we seek to develop AI technologies responsibly by understanding and mitigating potential risks, such as the propagation and amplification of unfair biases and protecting user privacy.
</p> <p>
Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it’s stored, it also requires erasing the influence of that data on other artifacts such as trained machine learning models. Moreover, recent research [<a href="https://arxiv.org/abs/1610.05820">1</a>, <a href="https://arxiv.org/abs/2112.03570">2</a>] has shown that in some cases it may be possible to infer with high accuracy whether an example was used to train a machine learning model using <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning#Model_extraction">membership inference attacks</a> (MIAs). This can raise privacy concerns, as it implies that even if an individual's data is deleted from a database, it may still be possible to infer whether that individual's data was used to train a model. 
</p>
<p>
Given the above, <em>machine unlearning</em> is an emergent subfield of machine learning that aims to remove the influence of a specific subset of training examples — the "forget set" — from a trained model. Furthermore, an ideal unlearning algorithm would remove the influence of certain examples <em>while maintaining</em> other beneficial properties, such as the accuracy on the rest of the train set and generalization to held-out examples. A straightforward way to produce this unlearned model is to retrain the model on an adjusted training set that excludes the samples from the forget set. However, this is not always a viable option, as retraining deep models can be computationally expensive. An ideal unlearning algorithm would instead use the already-trained model as a starting point and efficiently make adjustments to remove the influence of the requested data.
</p>
<p>
Today we're thrilled to announce that we've teamed up with a broad group of academic and industrial researchers to organize the <a href="https://unlearning-challenge.github.io/">first Machine Unlearning Challenge</a>. The competition considers a realistic scenario in which after training, a certain subset of the training images must be forgotten to protect the privacy or rights of the individuals concerned. The competition will be hosted on <a href="https://www.kaggle.com/">Kaggle</a>, and submissions will be automatically scored in terms of both forgetting quality and model utility. We hope that this competition will help advance the state of the art in machine unlearning and encourage the development of efficient, effective and ethical unlearning algorithms.
</p>




<h2>Machine unlearning applications</h2>


<p>
Machine unlearning has applications beyond protecting user privacy. For instance, one can use unlearning to erase inaccurate or outdated information from trained models (e.g., due to errors in labeling or changes in the environment) or remove harmful, manipulated, or outlier data. 
</p>
<p>
The field of machine unlearning is related to other areas of machine learning such as <a href="https://en.wikipedia.org/wiki/Differential_privacy">differential privacy</a>, <a href="https://arxiv.org/abs/1802.07569">life-long learning</a>, and <a href="https://en.wikipedia.org/wiki/Fairness_(machine_learning)">fairness</a>. Differential privacy aims to guarantee that no particular training example has too large an influence on the trained model; a stronger goal compared to that of unlearning, which only requires erasing the influence of the designated forget set. Life-long learning research aims to design models that can learn continuously while maintaining previously-acquired skills. As work on unlearning progresses, it may also open additional ways to boost fairness in models, by correcting unfair biases or disparate treatment of members belonging to different groups (e.g., demographics, age groups, etc.).
</p>




<table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRnut8P03hlk5tKJPEEsqUl1DSlqN2ScdJeiaRfC3mWbQ_PBBwf7wBU9xgxuzr1GoqgkB6MwCa6Zrdo6LQxSOIPXIUrl1Yug73k2Q2zFI61VDAi9K21JOPox0Hc1CIh6ShKxW9Tgy45TYV3p3r5IiI7yxzzzOpzvbJ-5o3QVtjZn6vhDZLntnCcUSi1mb_/s720/image1.png" imageanchor="1"><img data-original-height="405" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRnut8P03hlk5tKJPEEsqUl1DSlqN2ScdJeiaRfC3mWbQ_PBBwf7wBU9xgxuzr1GoqgkB6MwCa6Zrdo6LQxSOIPXIUrl1Yug73k2Q2zFI61VDAi9K21JOPox0Hc1CIh6ShKxW9Tgy45TYV3p3r5IiI7yxzzzOpzvbJ-5o3QVtjZn6vhDZLntnCcUSi1mb_/s16000/image1.png"></a></td></tr><tr><td><b>Anatomy of unlearning.</b> An unlearning algorithm takes as input a pre-trained model and one or more samples from the train set to unlearn (the "forget set"). From the model, forget set, and retain set, the unlearning algorithm produces an updated model. An ideal unlearning algorithm produces a model that is indistinguishable from the model trained without the forget set.</td></tr></tbody></table>



<h2>Challenges of machine unlearning</h2>


<p>
The problem of unlearning is complex and multifaceted as it involves several conflicting objectives: forgetting the requested data, maintaining the model’s utility (e.g., accuracy on retained and held-out data), and efficiency. Because of this, existing unlearning algorithms make different trade-offs. For example, full retraining achieves successful forgetting without damaging model utility, but with poor efficiency, while <a href="https://arxiv.org/abs/2007.02923">adding noise</a> to the weights achieves forgetting at the expense of utility. 
</p>
<p>
Furthermore, the evaluation of forgetting algorithms in the literature has so far been highly inconsistent. While some <a href="https://arxiv.org/abs/1911.04933">works</a> report the classification accuracy on the samples to unlearn, <a href="https://proceedings.mlr.press/v119/wu20b.html">others</a> report distance to the fully retrained model, and yet others use the error rate of membership inference attacks as a metric for forgetting quality [<a href="https://arxiv.org/abs/2302.09880">4</a>, <a href="https://arxiv.org/abs/2010.10981">5</a>, <a href="https://arxiv.org/abs/2005.02205">6</a>].
</p>
<p>
We believe that the inconsistency of evaluation metrics and the lack of a standardized protocol is a serious impediment to progress in the field — we are unable to make direct comparisons between different unlearning methods in the literature. This leaves us with a myopic view of the relative merits and drawbacks of different approaches, as well as open challenges and opportunities for developing improved algorithms. To address the issue of inconsistent evaluation and to advance the state of the art in the field of machine unlearning, we've teamed up with a broad group of academic and industrial researchers to organize the first unlearning challenge.
</p>




<h2>Announcing the first Machine Unlearning Challenge</h2>


<p>
We are pleased to announce the <a href="https://unlearning-challenge.github.io/">first Machine Unlearning Challenge</a>, which will be held as part of the <a href="https://neurips.cc/Conferences/2023/CompetitionTrack">NeurIPS 2023 Competition Track.</a> The goal of the competition is twofold. First, by unifying and standardizing the evaluation metrics for unlearning, we hope to identify the strengths and weaknesses of different algorithms through apples-to-apples comparisons. Second, by opening this competition to everyone, we hope to foster novel solutions and shed light on open challenges and opportunities.
</p>
<p>
The competition will be hosted on <a href="https://www.kaggle.com/">Kaggle</a> and run between mid-July 2023 and mid-September 2023. As part of the competition, today we're announcing the availability of the <a href="https://github.com/unlearning-challenge/starting-kit">starting kit</a>. This starting kit provides a foundation for participants to build and test their unlearning models on a toy dataset.
</p>
<p>
The competition considers a realistic scenario in which an age predictor has been trained on face images, and, after training, a certain subset of the training images must be forgotten to protect the privacy or rights of the individuals concerned. For this, we will make available as part of the starting kit a dataset of synthetic faces (samples shown below) and we'll also use several real-face datasets for evaluation of submissions. The participants are asked to submit code that takes as input the trained predictor, the forget and retain sets, and outputs the weights of a predictor that has unlearned the designated forget set. We will evaluate submissions based on both the strength of the forgetting algorithm and model utility. We will also enforce a hard cut-off that rejects unlearning algorithms that run slower than a fraction of the time it takes to retrain. A valuable outcome of this competition will be to characterize the trade-offs of different unlearning algorithms.
</p>




<table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijGdpNGKrQ9AskeRnXVSjPcFrjFPWs5TvXIAeD0gkJVL0hizxuJ4LL24rdKuNPUr86ivbaJZ5x-3dHBBQzLTbFYUWQ9p3ER5THVgv6xpOvK45_67ueGCtJsJVHrlkBKSfbz-21PrI2nkNGmoPcOkO_rqjR9W1-eDTxcjM6NNqqJkxMXMpRym_SYt3v6Wwn/s2000/image2.png" imageanchor="1"><img data-original-height="400" data-original-width="2000" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijGdpNGKrQ9AskeRnXVSjPcFrjFPWs5TvXIAeD0gkJVL0hizxuJ4LL24rdKuNPUr86ivbaJZ5x-3dHBBQzLTbFYUWQ9p3ER5THVgv6xpOvK45_67ueGCtJsJVHrlkBKSfbz-21PrI2nkNGmoPcOkO_rqjR9W1-eDTxcjM6NNqqJkxMXMpRym_SYt3v6Wwn/s16000/image2.png"></a></td></tr><tr><td>Excerpt images from the <a href="https://github.com/microsoft/FaceSynthetics">Face Synthetics</a> dataset together with age annotations. The competition considers the scenario in which an age predictor has been trained on face images like the above, and, after training, a certain subset of the training images must be forgotten.</td></tr></tbody></table>



<p>
For evaluating forgetting, we will use tools inspired by MIAs, such as <a href="https://arxiv.org/abs/2112.03570">LiRA</a>. MIAs were first developed in the privacy and security literature and their goal is to infer which examples were part of the training set. Intuitively, if unlearning is successful, the unlearned model contains no traces of the forgotten examples, causing MIAs to fail: the attacker would be <em>unable</em> to infer that the forget set was, in fact, part of the original training set. In addition, we will also use statistical tests to quantify how different the distribution of unlearned models (produced by a particular submitted unlearning algorithm) is compared to the distribution of models retrained from scratch. For an ideal unlearning algorithm, these two will be indistinguishable. 
</p>



<h2>Conclusion</h2>


<p>
Machine unlearning is a powerful tool that has the potential to address several open problems in machine learning. As research in this area continues, we hope to see new methods that are more efficient, effective, and responsible. We are thrilled to have the opportunity via this competition to spark interest in this field, and we are looking forward to sharing our insights and findings with the community.
</p>



<h2>Acknowledgements</h2>


<p>
<em>The authors of this post are now part of Google DeepMind. We are writing this blog post on behalf of the organization team of the Unlearning Competition: Eleni Triantafillou*, Fabian Pedregosa* (*equal contribution), Meghdad Kurmanji, Kairan Zhao, Gintare Karolina Dziugaite, Peter Triantafillou, Ioannis Mitliagkas, Vincent Dumoulin, Lisheng Sun Hosoya, Peter Kairouz, Julio C. S. Jacques Junior, Jun Wan, Sergio Escalera and Isabelle Guyon.</em>
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Suck at Excel (2015) [video] (196 pts)]]></title>
            <link>https://www.youtube.com/watch?v=0nbkaYsR94c</link>
            <guid>36649047</guid>
            <pubDate>Sat, 08 Jul 2023 21:41:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=0nbkaYsR94c">https://www.youtube.com/watch?v=0nbkaYsR94c</a>, See on <a href="https://news.ycombinator.com/item?id=36649047">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Open Letter to Tim O’Reilly to Free the Perl Camel (165 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36648949</link>
            <guid>36648949</guid>
            <pubDate>Sat, 08 Jul 2023 21:27:44 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36648949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>This is (was?) O'Reilly's stance on the matter:<p><a href="https://web.archive.org/web/20180425080044/http://archive.oreilly.com/pub/a/oreilly/perl/usage" rel="nofollow noreferrer">https://web.archive.org/web/20180425080044/http://archive.or...</a></p><p>The Perl Camel Usage and Trademark Information</p><p>As most of you probably know, O'Reilly started putting animal images on the covers of our books about thirteen years ago. To millions of readers, the animals mean O'Reilly. They've become our signature "trade dress." We've also trademarked the association between particular animals and the subject of their books. After all, the only reason that people think of camels in association with Perl is because we used a camel on the cover of Programming Perl.</p><p>We recognize that things do get more complicated, though, when an image like the camel is so widely known that it comes to symbolize not just our products but also the entire Perl language. This is a good thing, and we want it to continue. But trademark law is sticky on this point. If a trademark isn't "protected" (by letters asking people not to use it, or by licenses that allow them to use it only in specific ways), it gets into the public domain and loses its protected status. If this happened, anyone could use the camel without restriction, including in ways that were detrimental to the language. For example, you might imagine a company creating a Perl-compatible language, branding it with a camel, and pushing it as the "official Perl" in an attempt to drive Larry Wall's Perl out of existence.</p><p>Another important issue is that a brand is strong in proportion to two things: its ubiquity and its distinctiveness. It's important that, just as we want one version of Perl (so we don't have the fragmentation that was the downfall of UNIX), we have one symbol for Perl. To protect the integrity and impact of that symbol, we need to maintain some artistic control over what kinds of camel images are used. We believe that "one camel" will strengthen the overall Perl brand.</p><p>In short, we're walking a fine line, trying to make the camel as available as possible as a symbol for Perl while protecting it as a trademark. So, here's our policy on using the camel image:</p><p>Non-commercial use</p><p>We will license the camel image widely for open source products and non-commercial sites related to Perl, requiring only an acknowledgement of its trademark status and a link to www.perl.com. To request the camel artwork, please send email to permissions@oreilly.com, indicating where, how, and for what purpose you plan to use the image. Please note that we generally do not allow alterations of the Perl camel artwork.</p><p>Some non-commercial sites currently using the Perl camel:</p><p>(snipped)</p><p>We also offer the Programming Republic of Perl logo for some non-commercial sites. Feel free to download these logos for use on your pages. Please make the logo a link to www.perl.com.</p><p>Some sites using the Programming Republic of Perl logo:</p><p>(snipped)</p><p>We may also license the Perl camel image for some commercial products and sites related to Perl. To inquire about the use of a camel image on any commercial product or site, please send email to permissions@oreilly.com with a description of the product or web site, indicating where and how you'd like to use the camel.</p><p>We've also created "Powered by Perl" buttons that any site using Perl may use on web pages. Feel free to download and use these buttons. Please make the buttons link to www.perl.com.</p><p>And the Camel FAQ:</p><p><a href="https://web.archive.org/web/20180123132933/http://archive.oreilly.com/pub/a/oreilly/perl/usage/faq.html" rel="nofollow noreferrer">https://web.archive.org/web/20180123132933/http://archive.or...</a></p><p>Q: So are you saying that O'Reilly has trademarked an entire animal?</p><p>A: No. When a company receives a trademark, it receives protection for a symbol in a particular category of products or services. For example, Owens Corning has trademarked the color pink. The whole color? No, only for insulation. O'Reilly has protected the camel image for books and online publications related to the Perl language, and related product and services. The only reason an association exists between camels and the Perl programming language is because we've used a camel image on our Perl-related products.</p><p>Q: Do you just own the particular Camel on the cover of Programming Perl, or all camels?</p><p>A: We own the particular camel image shown above, which has lead to an association between camels and the Perl language. If someone were to use a different camel on their Perl book, there could be confusion over which one "The Camel Book" referred to, and we might need to step in and stop use of that camel image. That's how trademarks work, helping to protect confusion in the marketplace.</p><p>Q: I want to design a T-shirt with the Perl camel on it. Do I need to get your permission?</p><p>A: Yes. But we're willing to make allowances for those of you who have creative ideas and want to do something fun for your friends. So, if the lifetime print run of the T-shirt design is less than 100, you may consider permission automatically granted. For larger print runs, please ask first. We promise to answer quickly!</p><p>Q: Why isn't your trademark just restricted to books?</p><p>A: We also do conferences, software, research, and online publishing in Perl, and we use the camel image for those things as well. We may want to camel-brand other Perl-related products in the future.</p><p>Q: I want to use $camel as a variable name in a Perl program. Do I need to acknowledge the trademark?</p><p>A: No.</p><p>Q: I want to use a cartoon camel as the logo for my software product. Is that okay?</p><p>A: It depends on what your product is, how it was developed, and how you intend to distribute it. Please send email to permissions@oreilly.com, with information about what you'd like to do, and we'll get back to you.</p><p>Q: I want to place a picture of a camel on my Perl web page. Am I allowed to do that? Do I have to use your camel?</p><p>A:Yes, as long as your page is non-commercial, and the context in which the camel is placed portrays Perl in a positive light. You will need to include the following language in small text somewhere on the page where the camel appears:</p><p>"The Perl camel image is a trademark of O'Reilly Media, Inc. Used with permission."</p><p>Please make the "O'Reilly Media, Inc." part of the statement a link to our home page (<a href="http://www.oreilly.com/" rel="nofollow noreferrer">http://www.oreilly.com</a>).</p><p>We'd encourage you to use the Perl camel we use, as it has wide recognition as "the Perl camel." But if you have another camel you'd like to use on a non-commercial site we generally would not object, so as long as the image is in no way derogatory.</p><p>Please note: If you use the "Powered by Perl" or the "Programming Republic of Perl" buttons, please make those active links to <a href="http://www.perl.com/" rel="nofollow noreferrer">http://www.perl.com</a>, not the O'Reilly home page.</p><p>Q: What is the Programming Republic of Perl logo?</p><p>A: The Programming Republic of Perl logo was developed some years ago for non-commercial use on web sites, and serves as a pointer to www.perl.com. Feel free to use it on any non-commercial pages. You can find it on the main Perl Camel Usage and Trademark Information page.</p><p>Q: Where can I find out more about camels?</p><p><a href="http://www.sandiegozoo.org/animalbytes/t-camel.html" rel="nofollow noreferrer">http://www.sandiegozoo.org/animalbytes/t-camel.html</a></p><p>If you have questions or comments about the Perl camel or any other O'Reilly trademarks, or if you want to use one of our trademarks in some way that we haven't explicitly described on this page, please send a detailed request to permissions@oreilly.com. For more information, see the Perl Camel FAQ.
              </p></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open sourcing the Nginx playground (191 pts)]]></title>
            <link>https://jvns.ca/blog/2023/07/08/open-sourcing-the-nginx-playground/</link>
            <guid>36648821</guid>
            <pubDate>Sat, 08 Jul 2023 21:11:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/07/08/open-sourcing-the-nginx-playground/">https://jvns.ca/blog/2023/07/08/open-sourcing-the-nginx-playground/</a>, See on <a href="https://news.ycombinator.com/item?id=36648821">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>Hello! In 2021 I released a small playground for testing nginx configurations
called <a href="https://nginx-playground.wizardzines.com/">nginx playground</a>. There’s a
<a href="https://jvns.ca/blog/2021/09/24/new-tool--an-nginx-playground/">blog post about it here</a>.</p>

<p>This is an extremely short post to say that at the time I didn’t make it open source,
but I am making it open source now. It’s not a lot of code but maybe it’ll be
interesting to someone.</p>

<p>Here’s <a href="https://github.com/jvns/nginx-playground/">the github repo</a>. The
frontend is in <code>static/</code> and the backend is in <code>api/</code>. The README is mostly an
extended apology for the developer experience and note that the project is
unmaintained. But I did test that the build instructions work!</p>

<h3 id="why-didn-t-i-open-source-this-before">why didn’t I open source this before?</h3>

<p>I’m not very good at open source. Some of the problems I have with open sourcing things are:</p>

<ul>
<li>I dislike (and am very bad at) maintaining open source projects – I usually
ignore basically all feature requests and most bug reports and then feel bad about it.
I handed off maintainership to both of the open source projects that I
started (<a href="https://github.com/rbspy/rbspy">rbspy</a> and <a href="https://github.com/rust-bpf/rust-bcc">rust-bcc</a>) to other people who are doing a MUCH better job than I ever did.</li>
<li>Sometimes the developer experience for the project is pretty bad</li>
<li>Sometimes there’s configuration in the project (like the <code>fly.toml</code> or the
analytics I have set up) which don’t really make sense for other people to
copy</li>
</ul>

<h3 id="new-approach-don-t-pretend-i-m-going-to-improve-it">new approach: don’t pretend I’m going to improve it</h3>

<p>In the past I’ve had some kind of belief that I’m going to improve the problems
with my code later. But I haven’t touched this project in more than a year and
I think it’s unlikely I’m going to go back to it unless it breaks in some dramatic way.</p>

<p>So instead of pretending I’m going to improve things, I decided to just:</p>

<ul>
<li>tell people in the README that the project is unmaintained</li>
<li>write down all the security caveats I know about</li>
<li>test the build instructions I wrote to make sure that they work (on a fresh machine, even!)</li>
<li>explain (but do not fix!!) some of the messy parts of the project</li>
</ul>

<h3 id="that-s-all">that’s all!</h3>

<p>Maybe I will open source more of my tiny projects in the future, we’ll see!
Thanks to <a href="https://www.changeset.nyc/">Sumana Harihareswara</a> for helping me
think through this.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Htmx Gaining in Popularity? (148 pts)]]></title>
            <link>https://trends.builtwith.com/javascript/Htmx</link>
            <guid>36648817</guid>
            <pubDate>Sat, 08 Jul 2023 21:10:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trends.builtwith.com/javascript/Htmx">https://trends.builtwith.com/javascript/Htmx</a>, See on <a href="https://news.ycombinator.com/item?id=36648817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<div>
<div>
<p>
<label for="tk">Top 10k</label></p><svg width="25" height="20" style="margin-left: 0px;">
<g>
<line x1="5" y1="10" x2="35" y2="10"></line>
<circle style="opacity: 1" cx="15" cy="10" r="6"></circle>
</g></svg>
</div>
<div>
<p>
<label for="hk">Top 100k</label></p><svg width="25" height="20" style="margin-left: 0px;">
<g>
<line x1="5" y1="10" x2="35" y2="10"></line>
<circle style="opacity: 1" cx="15" cy="10" r="6"></circle>
</g></svg>
</div>
<div>
<p>
<label for="m">Top 1m</label></p><svg width="25" height="20" style="margin-left: 0px;">
<g>
<line x1="5" y1="10" x2="35" y2="10"></line>
<circle style="opacity: 1" cx="15" cy="10" r="6"></circle>
</g></svg>
</div>
<div>
<p>
<label for="ei">All Internet</label></p><svg width="25" height="20" style="margin-left: 0px;">
<g>
<line x1="5" y1="10" x2="35" y2="10"></line>
<circle style="opacity: 1" cx="15" cy="10" r="6"></circle>
</g></svg>
</div>
</div>

<div>
<div>
<p><img data-src="https://deo39crpw7zzn.cloudfront.net/thumb/0c-50-90-ed-cz-c1/n" alt="Htmx" width="48" height="48">
</p>
<div>
<p>Gives you access to AJAX, CSS Transitions, WebSockets and Server Sent Events directly in HTML, using attributes.</p>
<p><a href="https://htmx.org/" target="_blank" rel="nofollow noopener">https://htmx.org</a> </p>
<p><a href="https://trends.builtwith.com/javascript">JavaScript Libraries and Functions</a></p>
</div>
</div>
<div>
<h5>Htmx Customers</h5>
<p>
Get access to data on <a href="https://trends.builtwith.com/websitelist/Htmx/Historical">9,204 websites</a> that are Htmx Customers. We know of <a href="https://trends.builtwith.com/websitelist/Htmx">7,188 live websites</a> using Htmx and an additional 2,016 sites that used Htmx historically and <a href="https://trends.builtwith.com/websitelist/Htmx/Switzerland">178 websites in Switzerland</a>.</p>
<p>
<a href="https://trends.builtwith.com/websitelist/Htmx">
<svg>
<use xlink:href="#icon-arrow-alt-circle-down"></use></svg>
Download Lead List</a>
</p>
</div>
</div>
<div>
<div>
<p>
<h5><svg><use xlink:href="#icon-award"></use></svg>Htmx Awards</h5>
</p>
</div>
<div>
<div>
<ul>
</ul></div> <p>No awards yet.</p>
</div></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build Personal ChatGPT Using Your Data (293 pts)]]></title>
            <link>https://github.com/raghavan/PdfGptIndexer</link>
            <guid>36648794</guid>
            <pubDate>Sat, 08 Jul 2023 21:07:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/raghavan/PdfGptIndexer">https://github.com/raghavan/PdfGptIndexer</a>, See on <a href="https://news.ycombinator.com/item?id=36648794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">PdfGptIndexer</h2>
<h2 tabindex="-1" dir="auto">Description</h2>
<p dir="auto">PdfGptIndexer is an efficient tool for indexing and searching PDF text data using OpenAI's GPT-2 model and FAISS (Facebook AI Similarity Search). This software is designed for rapid information retrieval and superior search accuracy.</p>
<h2 tabindex="-1" dir="auto">Libraries Used</h2>
<ol dir="auto">
<li><a href="https://github.com/deanmalmgren/textract">Textract</a> - A Python library for extracting text from any document.</li>
<li><a href="https://github.com/huggingface/transformers">Transformers</a> - A library by Hugging Face providing state-of-the-art general-purpose architectures for Natural Language Understanding (NLU) and Natural Language Generation (NLG).</li>
<li><a href="https://python.langchain.com/" rel="nofollow">Langchain</a> - A text processing and embeddings library.</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS (Facebook AI Similarity Search)</a> - A library for efficient similarity search and clustering of dense vectors.</li>
</ol>
<h2 tabindex="-1" dir="auto">Installing Dependencies</h2>
<p dir="auto">You can install all dependencies by running the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install langchain openai textract transformers langchain faiss-cpu"><pre>pip install langchain openai textract transformers langchain faiss-cpu</pre></div>
<h2 tabindex="-1" dir="auto">How It Works</h2>
<p dir="auto">The PdfGptIndexer operates in several stages:</p>
<ol dir="auto">
<li>It first processes a specified folder of PDF documents, extracting the text and splitting it into manageable chunks using a GPT-2 tokenizer from the Transformers library.</li>
<li>Each text chunk is then embedded using the OpenAI GPT-2 model through the LangChain library.</li>
<li>These embeddings are stored in a FAISS index, providing a compact and efficient storage method.</li>
<li>Finally, a query interface allows you to retrieve relevant information from the indexed data by asking questions. The application fetches and displays the most relevant text chunk.</li>
</ol>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/131585/252057499-2e71dd82-bf4f-44db-b1ae-908cbb465deb.png"><img src="https://user-images.githubusercontent.com/131585/252057499-2e71dd82-bf4f-44db-b1ae-908cbb465deb.png" alt="Untitled-2023-06-16-1537"></a></p>
<h2 tabindex="-1" dir="auto">Advantages of Storing Embeddings Locally</h2>
<p dir="auto">Storing embeddings locally provides several advantages:</p>
<ol dir="auto">
<li>Speed: Once the embeddings are stored, retrieval of data is significantly faster as there's no need to compute embeddings in real-time.</li>
<li>Offline access: After the initial embedding creation, the data can be accessed offline.</li>
<li>Compute Savings: You only need to compute the embeddings once and reuse them, saving computational resources.</li>
<li>Scalability: This makes it feasible to work with large datasets that would be otherwise difficult to process in real-time.</li>
</ol>
<h2 tabindex="-1" dir="auto">Running the Program</h2>
<p dir="auto">To run the program, you should:</p>
<ol dir="auto">
<li>Make sure you have installed all dependencies.</li>
<li>Clone the repository to your local machine.</li>
<li>Navigate to the directory containing the Python script.</li>
<li>Replace "&lt;OPENAI_API_KEY&gt;" with your actual OpenAI API key in the script.</li>
<li>Finally, run the script with Python.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python3 pdf_gpt_indexer.py"><pre><span>python3</span> <span>pdf_gpt_indexer</span>.<span>py</span></pre></div>
<p dir="auto">Please ensure that the folders specified in the script for PDF documents and the output text files exist and are accessible. The query interface will start after the embeddings are computed and stored. You can exit the query interface by typing 'exit'.</p>
<h2 tabindex="-1" dir="auto">Exploring Custom Data with ChatGPT</h2>
<p dir="auto">Check out the post <a href="https://devden.raghavan.studio/p/chatgpt-using-your-own-data" rel="nofollow">here</a> for a comprehensive guide on how to utilize ChatGPT with your own custom data.</p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>