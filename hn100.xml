<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 19 Jun 2025 22:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Juneteenth in Photos (167 pts)]]></title>
            <link>https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/</link>
            <guid>44320851</guid>
            <pubDate>Thu, 19 Jun 2025 17:41:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/">https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/</a>, See on <a href="https://news.ycombinator.com/item?id=44320851">Hacker News</a></p>
Couldn't get https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[In praise of "normal" engineers (118 pts)]]></title>
            <link>https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/</link>
            <guid>44320806</guid>
            <pubDate>Thu, 19 Jun 2025 17:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/">https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/</a>, See on <a href="https://news.ycombinator.com/item?id=44320806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><em>This article was originally <a href="https://refactoring.fm/p/in-praise-of-normal-engineers">commissioned by Luca Rossi</a> (paywalled) for refactoring.fm, on February 11th, 2025. Luca edited a version of it that emphasized the importance of building “10x engineering teams” . It was later picked up by IEEE Spectrum (!!!), who scrapped most of the teams content and published a <a href="https://spectrum.ieee.org/10x-engineer">different, shorter piece</a> on March 13th.</em></p>
<p><em>This is my personal edit. It is not exactly identical to either of the versions that have been publicly released to date. It contains a lot of the source material for the talk I gave last week at #LDX3 in London, “<a href="https://speakerdeck.com/charity/in-praise-of-normal-engineers-ldx3">In Praise of ‘Normal’ Engineers</a>” (slides), and a couple weeks ago at CraftConf.&nbsp;</em></p>

<p>Most of us have encountered a few engineers who seem practically magician-like, a class apart from the rest of us in their ability to reason about complex mental models, leap to non-obvious yet elegant solutions, or emit waves of high quality code at unreal velocity.<img data-recalc-dims="1" decoding="async" data-attachment-id="10015" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-praise-black-squish/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="In Praise of “Normal” Engineers" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=174%2C174&amp;ssl=1" alt="In Praise of &quot;Normal&quot; Engineers" width="174" height="174" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 174px) 100vw, 174px"></p>
<p>I have run into any number of these incredible beings over the course of my career. I think this is what explains the curious durability of the “10x engineer” meme. It may be based on flimsy, shoddy research, and the claims people have made to defend it have often been&nbsp;risible (e.g. “10x engineers have dark backgrounds, are rarely seen doing UI work, are poor mentors and interviewers”), or blatantly double down on stereotypes (“we look for young dudes in hoodies that remind us of Mark Zuckerberg”). But damn if it doesn’t resonate with experience. It just feels true.</p>
<p>The problem is not the idea that there are engineers who are 10x as productive as other engineers. I don’t have a problem with this statement; in fact, that much seems self-evidently true. The problems I do have are twofold.</p>
<h2>Measuring productivity is fraught and imperfect</h2>
<p>First: how are you measuring productivity? I have a problem with the implication that there is One True Metric of productivity that you can standardize and sort people by. Consider, for a moment, the sheer combinatorial magnitude of skills and experiences at play:</p>
<ul>
<li>Are you working on microprocessors, IoT, database internals, web services, user experience, mobile apps, consulting, embedded systems, cryptography, animation, training models for gen AI… what?</li>
<li>Are you using golang, python, COBOL, lisp, perl, React, or brainfuck? What version, which libraries, which frameworks, what data models? What other software and build dependencies must you have mastered?<img data-recalc-dims="1" decoding="async" data-attachment-id="10009" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-rainbow-black/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-rainbow-black" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=173%2C173&amp;ssl=1" alt="" width="173" height="173" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 173px) 100vw, 173px"></li>
<li>What adjacent skills, market segments, or product subject matter expertise are you drawing upon…design, security, compliance, data visualization, marketing, finance, etc?</li>
<li>What stage of development? What scale of usage? What matters most — giving good advice in a consultative capacity, prototyping rapidly to find product-market fit, or writing code that is maintainable and performant over many years of amortized maintenance? Or are you writing for the Mars Rover, or shrinkwrapped software you can never change?</li>
</ul>
<p>Also: people and their skills and abilities are not static. At one point, I was a pretty good DBRE (I even co-wrote the book on it). Maybe I was even a 10x DB engineer then, but certainly not now. I haven’t debugged a query plan in years.</p>
<p>“10x engineer” makes it sound like 10x productivity is an immutable characteristic of a person. But someone who is a 10x engineer in a particular skill set is still going to have infinitely more areas where they are normal or average (or less). I know a lot of world class engineers, but I’ve never met anyone who is 10x better than everyone else across the board, in every situation.</p>
<h2>Engineers don’t own software, teams own software</h2>
<p>Second, and even more importantly: So what? It doesn’t matter. Individual engineers don’t own software, teams own software. <strong>The smallest unit of software ownership and delivery is the engineering team</strong>. It doesn’t matter how fast an individual engineer can write software, what matters is how fast the team can collectively write, test, review, ship, maintain, refactor, extend, architect, and revise the software that they own.</p>
<p>Everyone uses the same software delivery pipeline. If it takes the slowest engineer at your company five hours to ship a single line of code, it’s going to take the fastest engineer at your company five hours to ship a single line of code. The time spent writing code is typically dwarfed by the time spent on every other part of the software development lifecycle.</p>
<p>If you have services or software components that are owned by a single engineer, that person is a single point of failure.<img data-recalc-dims="1" fetchpriority="high" decoding="async" data-attachment-id="10013" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-spof/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-spof" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=226%2C226&amp;ssl=1" alt="" width="226" height="226" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 226px) 100vw, 226px"></p>
<p>I’m not saying this should never happen. It’s quite normal at startups to have individuals owning software, because the biggest existential risk that you face is not moving fast enough, not finding product market fit, and going out of business. But as you start to grow up as a company, as users start to demand more from you, and you start planning for the survival of the company to extend years into the future…ownership needs to get handed over to a team. Individual engineers get sick, go on vacation, and leave the company, and the business has got to be resilient to that.</p>
<p>If teams own software, then the key job of any engineering leader is to craft high-performing engineering teams. If you must 10x something, 10x this. <strong>Build 10x engineering teams.</strong></p>
<h2>The best engineering orgs are the ones where normal engineers can do great work</h2>
<p>When people talk about world-class engineering orgs, they often have in mind teams that are top-heavy with staff and principal engineers, or recruiting heavily from the ranks of ex-FAANG employees or top universities.</p>
<p>But I would argue that a truly great engineering org is one where you don’t HAVE to be one of the “best” or most pedigreed engineers in the world to get shit done and have a lot of impact on the business.</p>
<p>I think it’s actually the other way around. A truly great engineering organization is one where perfectly normal, workaday software engineers, with decent software engineering skills and an ordinary amount of expertise, can consistently move fast, ship code, respond to users, understand the systems they’ve built, and move the business forward a little bit more, day by day, week by week.</p>
<p>Any asshole can build an org where the most experienced, brilliant engineers in the world can build product and make progress. That is not hard. And putting all the spotlight on individual ability has a way of letting your leaders off the hook for doing their jobs. It is a HUGE competitive advantage if you can build sociotechnical systems where less experienced engineers can convert their effort and energy into product and business momentum.</p>
<p>A truly great engineering org also happens to be one that mints world-class software engineers. But we’re getting ahead of ourselves, here.</p>
<h2>Let’s talk about “normal” for a moment</h2>
<p>A lot of technical people got really attached to our identities as smart kids. The software industry tends to reflect and reinforce this preoccupation at every turn, from Netflix’s “we look for the top 10% of global talent” to Amazon’s talk about “bar-raising” or Coinbase’s recent claim to “hire the top .1%”. (Seriously, guys? Ok, well, Honeycomb is going to hire only the top <em>.00001%</em>!)</p>
<p>In this essay, I would like to challenge us to set that baggage to the side and think about ourselves as <em>normal people</em>.</p>
<p>It can be humbling to think of ourselves as normal people, but most of us are in fact pretty normal people (albeit with many years of highly specialized practice and experience), and<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10011" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-made-not-born/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-made-not-born" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=264%2C264&amp;ssl=1" alt="" width="264" height="264" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 264px) 100vw, 264px"> there is <em>nothing wrong with that</em>. Even those of us who are certified geniuses on certain criteria are likely quite normal in other ways — kinesthetic, emotional, spatial, musical, linguistic, etc.</p>
<p>Software engineering both selects for and develops certain types of intelligence, particularly around abstract reasoning, but <em>nobody</em> is born a great software engineer. <strong>Great engineers are made, not born</strong>. I just don’t think there’s a lot more we can get out of thinking of ourselves as a special class of people, compared to the value we can derive from thinking of ourselves collectively as relatively normal people who have practiced a fairly niche craft for a very long time.</p>
<h2>Build sociotechnical systems with “normal people” in mind</h2>
<p>When it comes to hiring talent and building teams, yes, absolutely, we should focus on identifying the ways people are exceptional and talented and strong. But when it comes to building sociotechnical systems for software delivery, we should focus on all the ways people are <em>normal</em>.</p>
<h4><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10017" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-transp-rainbow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=122%2C122&amp;ssl=1" alt="" width="122" height="122" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 122px) 100vw, 122px"></h4>
<p>Normal people have cognitive biases — confirmation bias, recency bias, hindsight bias. We work hard, we care, and we do our best; but we also forget things, get impatient, and zone out. Our eyes are inexorably drawn to the color red (unless we are colorblind). We develop habits and ways of doing things, and resist changing them. When we see the same text block repeatedly, we stop reading it.</p>
<p>We are embodied beings who can get overwhelmed and fatigued. If an alert wakes us up at 3 am, we are much more likely to make mistakes while responding to that alert than if we tried to do the same thing at 3pm. Our emotional state can affect the quality of our work. Our relationships impact our ability to get shit done.</p>
<p>When your systems are designed to be used by normal engineers, all that excess brilliance they have can get poured into the product itself, instead of wasting it on navigating the system itself.</p>
<h2>How do you turn normal engineers into 10x engineering teams?</h2>
<p>None of this should be terribly surprising; it’s all well known wisdom. In order to build the kind of sociotechnical systems for software delivery that enable normal engineers to move fast, learn continuously, and deliver great results as a team, you should:</p>
<h4>Shrink the interval between when you write the code and when the code goes live.</h4>
<p>Make it as short as possible; the shorter the better. I’ve written and given talks about this many, many times. The shorter the interval, the lower the cognitive carrying costs. The faster you can iterate, the better. The more of your brain can go into the product instead of the process of building it.</p>
<p>One of the most powerful things you can do is have a short, fast enough deploy cycle that you can ship one commit per deploy. I’ve referred to this as the “software engineering death spiral” … when the deploy cycle takes so long that you end up batching together a bunch of engineers’ diffs in every build. The slower it gets, the more you batch up, and the harder it becomes to figure out what happened or roll back. The longer it takes, the more people you need, the higher the coordination costs, and the more slowly everyone moves.</p>
<p>Deploy time is the feedback loop at the heart of the development process. It is almost impossible to overstate the centrality of keeping this short and tight.</p>
<h4>Make it easy and fast to roll back or recover from mistakes.</h4>
<p>Developers should be able to deploy their own code, figure out if it’s working as intended or not, and if not, roll forward or back swiftly and easily. No muss, no fuss, no thinking involved.</p>
<h4>Make it easy to do the right thing and hard to do the wrong thing. <img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10018" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-sparkles/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-sparkles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=137%2C137&amp;ssl=1" alt="" width="137" height="137" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 137px) 100vw, 137px"></h4>
<p>Wrap designers and design thinking into all the touch points your engineers have with production systems. Use your platform engineering team to think about how to empower people to swiftly make changes and self-serve, but also remember that a lot of times people will be engaging with production late at night or when they’re very stressed, tired, and&nbsp;possibly freaking out. Build guard rails. The fastest way to ship a single line of code should also be the easiest way to ship a single line of code.</p>
<h4>Invest in instrumentation and observability.</h4>
<p>You’ll never know — not really — what the code you wrote does just by reading it. The only way to be sure is by instrumenting your code and watching real users run it in production. Good, friendly sociotechnical systems invest <em>heavily</em> in tools for sense-making.</p>
<p>Being able to visualize your work is what makes engineering abstractions accessible to actual engineers. You shouldn’t have to be a world-class engineer just to debug your own damn code.</p>
<h4>Devote engineering cycles to internal tooling and enablement.</h4>
<p>If fast, safe deploys, with guard rails, instrumentation, and highly parallelized test suites are “everybody’s job”, they will end up nobody’s job. Engineering productivity isn’t something you can outsource. Managing the interfaces between your software vendors and your own teams is both a science and an art. Making it look easy and intuitive is really hard. It needs an owner.</p>
<h4>Build an inclusive culture.</h4>
<p>Growth is the norm, growth is the baseline. People do their best work when they feel a sense of belonging. An inclusive culture is one where everyone feels safe to ask questions, explore, and make mistakes; where everyone is held to the same high standard, and given the support and encouragement they need to achieve their goals.</p>
<h4>Diverse teams are resilient teams.<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10017" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-transp-rainbow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=196%2C196&amp;ssl=1" alt="" width="196" height="196" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 196px) 100vw, 196px"></h4>
<p>Yeah, a team of super-senior engineers who all share a similar background can move incredibly fast, but a monoculture is fragile. Someone gets sick, someone gets pregnant, you start to grow and you need to integrate people from other backgrounds and the whole team can get derailed — fast.</p>
<p>When your teams are used to operating with a mix of genders, racial backgrounds, identities, age ranges, family statuses, geographical locations, skill sets, etc — when this is just table stakes, standard operating procedure — you’re better equipped to roll with it when life happens.</p>
<h4>Assemble engineering teams from a range of levels.</h4>
<p>The best engineering teams aren’t top-heavy with staff engineers and principal engineers. The best engineering teams are ones where nobody is running on autopilot, banging out a login page for the 300th time; everyone is working on something that challenges them and pushes their boundaries. Everyone is learning, everyone is teaching, everyone is pushing their own boundaries and growing. All the time.</p>
<p>By the way — all of that work you put into making your systems resilient, well-designed, and humane is the same work you would need to do to help onboard new engineers, develop junior talent, or let engineers move between teams.</p>
<p>It gets used and reused. Over and over and over again.</p>
<h2>The only meaningful measure of productivity is impact to the business</h2>
<p>The only thing that actually matters when it comes to engineering productivity is whether or not you are moving the business materially forward.</p>
<p>Which means…we can’t do this in a vacuum. The most important question is whether or not we are working on the right thing, which is a problem engineering can’t answer without help from product, design, and the rest of the business.</p>
<p>Software engineering isn’t about writing lots of lines of code, it’s about solving business problems using technology.</p>
<p>Senior and intermediate engineers are actually the workhorses of the industry. They move the business forward, step by step, day by day. They get to put their heads down and crank instead of constantly looking around the org and solving coordination problems. If you have to be a staff+ engineer to move the product forward, something is seriously wrong.</p>
<h2>Great engineering orgs mint world-class engineers</h2>
<p>A great engineering org is one where you don’t HAVE to be one of the best engineers in the world to have a lot of impact. But — rather ironically — great engineering orgs mint world class engineers like nobody’s business.</p>
<p>The best engineering orgs are not the ones with the smartest, most experienced people in the world, they’re the ones where normal software engineers can consistently make progress, deliver value to users, and move the business forward, day after day.<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10019" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-system-does/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-system-does" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=253%2C253&amp;ssl=1" alt="" width="253" height="253" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 253px) 100vw, 253px"></p>
<p>Places where engineers can get shit done and have a lot of impact are a magnet for top performers. Nothing makes engineers happier than building things, solving problems, making progress.</p>
<p>If you’re lucky enough to have world-class engineers in your org, good for you! Your role as a leader is to leverage their brilliance for the good of your customers and your other engineers, without coming to depend on their brilliance. After all, these people don’t belong to you. They may walk out the door at any moment, and that has to be okay.</p>
<p>These people can be phenomenal assets, assuming they can be team players and keep their egos in check. Which is probably why so many tech companies seem to obsess over identifying and hiring them, especially in Silicon Valley.</p>
<p>But companies categorically overindex on finding these people after they’ve already been minted, which ends up reinforcing and replicating all the prejudices and inequities of the world at large. Talent may be evenly distributed across populations, but opportunity is not.</p>
<h2>Don’t hire the “best” people. Hire the right people.</h2>
<p>We (by which I mean the entire human race) place too much emphasis on individual agency and characteristics, and not enough on the systems that shape us and inform our behaviors.</p>
<p>I feel like a whole slew of issues (candidates self-selecting out of the interview process, diversity of applicants, etc) would be improved simply by shifting the focus on engineering hiring and interviewing away from this inordinate emphasis on hiring the BEST PEOPLE and realigning around the more reasonable and accurate RIGHT PEOPLE. <img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10023" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-hire/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-hire" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=182%2C182&amp;ssl=1" alt="" width="182" height="182" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 182px) 100vw, 182px"></p>
<p>It’s a competitive advantage to build an environment where people can be hired for their unique strengths, not their lack of weaknesses; where the emphasis is on composing teams rather than hiring the BEST people; where inclusivity is a given both for ethical reasons and&nbsp;because it raises the bar for performance for everyone. Inclusive culture is what actual meritocracy depends on.</p>
<p>This is the kind of place that engineering talent (and good humans) are drawn to like a moth to a flame. <strong>It feels good to ship</strong>. It feels <em>good</em> to move the business forward. It feels <em>good</em> to sharpen your skills and improve your craft. It’s the kind of place that people go when they want to become world class engineers. And it’s the kind of place where world class engineers want to stick around, to train up the next generation.</p>
<p>&lt;3, charity</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Curved-Crease Sculpture (139 pts)]]></title>
            <link>https://erikdemaine.org/curved/</link>
            <guid>44318874</guid>
            <pubDate>Thu, 19 Jun 2025 14:13:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erikdemaine.org/curved/">https://erikdemaine.org/curved/</a>, See on <a href="https://news.ycombinator.com/item?id=44318874">Hacker News</a></p>
Couldn't get https://erikdemaine.org/curved/: Error: getaddrinfo ENOTFOUND erikdemaine.org]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A DOS-like hobby OS written in Rust and x86 assembly (126 pts)]]></title>
            <link>https://github.com/krustowski/rou2exOS</link>
            <guid>44318588</guid>
            <pubDate>Thu, 19 Jun 2025 13:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/krustowski/rou2exOS">https://github.com/krustowski/rou2exOS</a>, See on <a href="https://news.ycombinator.com/item?id=44318588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">rou2exOS Rusted Edition</h2><a id="user-content-rou2exos-rusted-edition" aria-label="Permalink: rou2exOS Rusted Edition" href="#rou2exos-rusted-edition"></a></p>
<p dir="auto">A second iteration of the RoureXOS operating system, rewritten in Rust.</p>
<ul dir="auto">
<li><a href="https://krusty.space/projects/rourexos/" rel="nofollow">Original RoureXOS (a blog post)</a></li>
<li><a href="https://blog.vxn.dev/rou2exos-rusted-edition" rel="nofollow">rou2exOS Rusted Edition (a blog post)</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/108d5a7e9f0a67d395b8594fd4b20592fcfd7b3104138733c2401358e5941242/68747470733a2f2f626c6f672e76786e2e6465762f696d616765732f706f7374732f726f753265786f732f636f7665722e77656270"><img src="https://camo.githubusercontent.com/108d5a7e9f0a67d395b8594fd4b20592fcfd7b3104138733c2401358e5941242/68747470733a2f2f626c6f672e76786e2e6465762f696d616765732f706f7374732f726f753265786f732f636f7665722e77656270" alt="rou2exOS startup" data-canonical-src="https://blog.vxn.dev/images/posts/rou2exos/cover.webp"></a></p>
<p dir="auto">To run the OS, you can use the attached ISO image from any Release, and run it in QEMU emulator. The system was also tested on x86_64 baremetal (booted from the USB flash disk).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to build and run</h2><a id="user-content-how-to-build-and-run" aria-label="Permalink: How to build and run" href="#how-to-build-and-run"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# install Rust and its dependencies
make init

# make sure you have `xorriso`, `net-tools` and `grub2-tools` (or just grub-tools) installed (Linux)
dnf install xorriso net-tools grub2-tools qemu qemu-common qemu-system-x86

# compile the kernel and stage2 bootloader, link it into an ELF binary and bake into an ISO
# image with GRUB stage1 bootloader
make build

# run the QEMU emulation with ISO image (respectively with additional floppy image attached as well)
make run_iso
make run_iso_floppy

# (alternative) run the kernel exclusively only (needs the `bootloader` dependency in Cargo.toml to be added)
cargo bootimage
make run"><pre><span><span>#</span> install Rust and its dependencies</span>
make init

<span><span>#</span> make sure you have `xorriso`, `net-tools` and `grub2-tools` (or just grub-tools) installed (Linux)</span>
dnf install xorriso net-tools grub2-tools qemu qemu-common qemu-system-x86

<span><span>#</span> compile the kernel and stage2 bootloader, link it into an ELF binary and bake into an ISO</span>
<span><span>#</span> image with GRUB stage1 bootloader</span>
make build

<span><span>#</span> run the QEMU emulation with ISO image (respectively with additional floppy image attached as well)</span>
make run_iso
make run_iso_floppy

<span><span>#</span> (alternative) run the kernel exclusively only (needs the `bootloader` dependency in Cargo.toml to be added)</span>
cargo bootimage
make run</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to test ICMP/SLIP</h2><a id="user-content-how-to-test-icmpslip" aria-label="Permalink: How to test ICMP/SLIP" href="#how-to-test-icmpslip"></a></p>
<p dir="auto">Run the kernel in QEMU to get the <code>pty</code> number in stdout:</p>
<div data-snippet-clipboard-copy-content="make run

char device redirected to /dev/pts/3 (label serial0)"><pre><code>make run

char device redirected to /dev/pts/3 (label serial0)
</code></pre></div>
<p dir="auto">Listen for SLIP packets and create a <code>sl0</code> interface:</p>
<div data-snippet-clipboard-copy-content="sudo slattach -L -p slip -s 115200 /dev/pts/3
sudo ifconfig sl0 192.168.3.1 pointopoint 192.168.3.2 up"><pre><code>sudo slattach -L -p slip -s 115200 /dev/pts/3
sudo ifconfig sl0 192.168.3.1 pointopoint 192.168.3.2 up
</code></pre></div>
<p dir="auto">Catch packets using <code>tcpdump</code>:</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft wants you to buy a new computer. Make your current one secure again? (195 pts)]]></title>
            <link>https://endof10.org/</link>
            <guid>44318420</guid>
            <pubDate>Thu, 19 Jun 2025 13:14:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://endof10.org/">https://endof10.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44318420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p>Support for Windows 10 ends on October 14, 2025.</p><p>Microsoft wants you to buy a new computer.</p><p>But what if you could make your current one fast and secure again?</p></div><p><img src="https://endof10.org/laptop.svg" alt="Use your old computer but with fresh new software."></p></div><p>If you bought your computer after 2010, there's most likely no
reason to throw it out. By just installing an up-to-date Linux
operating system you can keep using it for years to come.</p><p>Installing an operating system may sound difficult, but you don't have to
do it alone. With any luck, there are people in your area
ready to help!</p><p><a href="https://endof10.org/places">Find someone to help&nbsp;you
&nbsp;→</a></p><p><a href="https://endof10.org/install/">Install Linux yourself →</a></p><h2 id="5-reasons-to-upgrade-your-old-computer-to-linux"><strong>5 Reasons</strong> to upgrade your old computer to Linux</h2><ol><li><strong>No New Hardware, No Licensing Costs</strong><br>A new laptop costs a lot of money, but several Linux operating systems
are available for free. Software updates are also free, forever. You can
of course show your support with donations!</li><li><strong>Enhanced Privacy</strong><br>Windows comes with lots of ads and spyware. This slows down your computer,
lets companies spy on you, and increases your energy bills.</li><li><strong>Good For The Planet</strong><br>Production of a computer accounts for 75+% of carbon emissions over its lifecycle.
Keeping a functioning device longer is a hugely effective way to reduce emissions.
With a Linux operating system you can use your device longer.</li><li><strong>Community &amp; Professional Support</strong><br>There are local repair cafes and independent, professional services and
computer shops available for providing you help. You can find support in online
forums, too.</li><li><strong>Better User Control</strong><br>Linux grants you the four freedoms of software. You are free to use, study, share, and
improve the program, for as long as you wish. You are in control of your device.</li></ol><h2 id="supporters">Supporters</h2><p>These organizations have joined us in support of the campaign.</p><h2 id="convinced">Convinced?</h2><p>Then find your closest repair cafe or independent computer shop
and enjoy your brand-new, old computer!</p><p><a href="https://endof10.org/places">Repair your old computer
&nbsp;→</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What would a Kubernetes 2.0 look like (114 pts)]]></title>
            <link>https://matduggan.com/what-would-a-kubernetes-2-0-look-like/</link>
            <guid>44317825</guid>
            <pubDate>Thu, 19 Jun 2025 12:00:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/what-would-a-kubernetes-2-0-look-like/">https://matduggan.com/what-would-a-kubernetes-2-0-look-like/</a>, See on <a href="https://news.ycombinator.com/item?id=44317825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <main id="main-content" role="main">
            
<article>
    

    
    <div>
            <p>Around 2012-2013 I started to hear a <em>lot</em> in the sysadmin community about a technology called "Borg". It was (apparently) some sort of Linux container system inside of Google that ran all of their stuff. The terminology was a bit baffling, with something called a "Borglet" inside of clusters with "cells" but the basics started to leak. There was a concept of "services" and a concept of "jobs", where applications could use services to respond to user requests and then jobs to complete batch jobs that ran for much longer periods of time. </p><p>Then on June 7th, 2014, we got our first commit of Kubernetes. The Greek word for 'helmsman' that absolutely no one could pronounce correctly for the first three years. (Is it koo-ber-NET-ees? koo-ber-NEET-ees? Just give up and call it k8s like the rest of us.) </p><p>Microsoft, RedHat, IBM, Docker join the Kubernetes community pretty quickly after this, which raised Kubernetes from an interesting Google thing to "maybe this is a real product?" On July 21st 2015 we got the v1.0 release as well as the creation of the CNCF. </p><p>In the ten years since that initial commit, Kubernetes has become a large part of my professional life. I use it at home, at work, on side projects—anywhere it makes sense. It's a tool with a steep learning curve, but it's also a massive force multiplier. We no longer "manage infrastructure" at the server level; everything is declarative, scalable, recoverable and (if you’re lucky) self-healing.</p><p>But the journey hasn't been without problems. Some common trends have emerged, where mistakes or misconfiguration arise from where Kubernetes isn't opinionated enough. Even ten years on, we're still seeing a lot of churn inside of ecosystem and people stepping on well-documented landmines. So, knowing what we know now, what could we do differently to make this great tool even more applicable to more people and problems? </p><h3 id="what-did-k8s-get-right">What did k8s get right?</h3><p>Let's start with the positive stuff. Why are we still talking about this platform now? </p><p><strong>Containers at scale</strong></p><p>Containers as a tool for software development make perfect sense. Ditch the confusion of individual laptop configuration and have one standard, disposable concept that works across the entire stack. While tools like Docker Compose allowed for some deployments of containers, they were clunky and still required you as the admin to manage a lot of the steps. I set up a Compose stack with a deployment script that would remove the instance from the load balancer, pull the new containers, make sure they started and then re-added it to the LB, as did lots of folks. </p><p>K8s allowed for this concept to scale out, meaning it was possible to take a container from your laptop and deploy an identical container across thousands of servers. This flexibility allowed organizations to revisit their entire design strategy, dropping monoliths and adopting more flexible (and often more complicated) micro-service designs. </p><p><strong>Low-Maintenance</strong></p><p>If you think of the history of Operations as a sort of "naming timeline from pets to cattle", we started with what I affectionately call the "Simpsons" era. Servers were bare metal boxes set up by teams, they often had one-off names that became slang inside of teams and everything was a snowflake. The longer a server ran, the more cruft it picked up until it became a scary operation to even reboot them, much less attempt to rebuild them. I call it the "Simpsons" era because among the jobs I was working at the time, naming them after Simpsons characters was surprisingly common. Nothing fixed itself, everything was a manual operation. </p><p>Then we transition into the "01 Era". Tools like Puppet and Ansible have become common place, servers are more disposable and you start to see things like bastion hosts and other access control systems become the norm. Servers aren't all facing the internet, they're behind a load balancer and we've dropped the cute names for stuff like "app01" or "vpn02". Organizations designed it so they could lose some of their servers some of the time. However failures still weren't self-healing, someone still had to SSH in to see what broke, write up a fix in the tooling and then deploy it across the entire fleet. OS upgrades were still complicated affairs. </p><p>We're now in the "UUID Era". Servers exist to run containers, they are entirely disposable concepts. Nobody cares about how long a particular version of the OS is supported for, you just bake a new AMI and replace the entire machine. K8s wasn't the only technology enabling this, but it was the one that accelerated it. Now the idea of a bastion server with SSH keys that I go to the underlying server to fix problems is seen as more of a "break-glass" solution. Almost all solutions are "destroy that Node, let k8s reorganize things as needed, make a new Node". </p><p>A lot of the Linux skills that were critical to my career are largely nice to have now, not need to have. You can be happy or sad about that, I certainly switch between the two emotions on a regular basis, but it's just the truth. </p><p><strong>Running Jobs </strong></p><p>The k8s jobs system isn't perfect, but it's so much better than the "snowflake cron01 box" that was an extremely common sight at jobs for years. Running on a cron schedule or running from a message queue, it was now possible to reliably put jobs into a queue, have them get run, have them restart if they didn't work and then move on with your life. </p><p>Not only does this free up humans from a time-consuming and boring task, but it's also simply a more efficient use of resources. You are still spinning up a pod for every item in the queue, but your teams have a lot of flexibility inside of the "pod" concept for what they need to run and how they want to run it. This has really been a quality of life improvement for a lot of people, myself included, who just need to be able to easily background tasks and not think about them again. </p><p><strong>Service Discoverability and Load Balancing</strong></p><p>Hard-coded IP addresses that lived inside of applications as the template for where requests should be routed has been a curse following me around for years. If you were lucky, these dependencies weren't based on IP address but were actually DNS entries and you could change the thing behind the DNS entry without coordinating a deployment of a million applications. </p><p>K8s allowed for simple DNS names to call other services. It removed an entire category of errors and hassle and simplified the entire thing down. With the Service API you had a stable, long lived IP and hostname that you could just point things towards and not think about any of the underlying concepts. You even have concepts like ExternalName that allow you to treat external services like they're in the cluster. </p><h3 id="ditch-yaml-for-hcl">Ditch YAML for HCL</h3><p>YAML was appealing because it wasn't JSON or XML, which is like saying your new car is great because it's neither a horse nor a unicycle. It demos nicer for k8s, looks nicer sitting in a repo and has the <em>illusion</em> of being a simple file format. In reality. YAML is just too much for what we're trying to do with k8s and it's not a safe enough format. Indentation is error-prone, the files don't scale great (you really don't want a super long YAML file), debugging can be annoying. YAML has <em>so many</em> subtle behaviors outlined in its spec.</p><p>I still remember not believing what I was seeing the first time I saw the Norway Problem. For those lucky enough to not deal with it, the Norway Problem in YAML is when 'NO' gets interpreted as false. Imagine explaining to your Norwegian colleagues that their entire country evaluates to false in your configuration files. Add in accidental numbers from lack of quotes, the list goes on and on. There are much better posts on why YAML is crazy than I'm capable of writing: <a href="https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell">https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell</a></p><p><strong>Why HCL?</strong></p><p>HCL is already the format for Terraform, so at least we'd only have to hate one configuration language instead of two. It's strongly typed with explicit types. There's already good validation mechanisms. It is specifically designed to do the job that we are asking YAML to do and it's not much harder to read. It has built-in functions people are already using that would allow us to remove some of the third-party tooling from the YAML workflow. </p><p>I would wager 30% of Kubernetes clusters today are <em>already</em> being managed with HCL via Terraform. We don't need the Terraform part to get a lot of the benefits of a superior configuration language. </p><p>The only downsides are that HCL is slightly more verbose than YAML, and its Mozilla Public License 2.0 (MPL-2.0) would require careful legal review for integration into an Apache 2.0 project like Kubernetes. However, for the quality-of-life improvements it offers, these are hurdles worth clearing.</p><p><strong>Why HCL is better</strong></p><p>Let's take a simple YAML file. </p><pre><code># YAML doesn't enforce types
replicas: "3"  # String instead of integer
resources:
  limits:
    memory: 512  # Missing unit suffix
  requests:
    cpu: 0.5m    # Typo in CPU unit (should be 500m)</code></pre><p>Even in the most basic example, there are footguns everywhere. HCL and the type system would catch all of these problems. </p><pre><code>replicas = 3  # Explicitly an integer

resources {
  limits {
    memory = "512Mi"  # String for memory values
  }
  requests {
    cpu = 0.5  # Number for CPU values
  }
}</code></pre><p>Take a YAML file like this that you probably have 6000 in your k8s repo. Now look at HCL without needing external tooling. </p><pre><code># Need external tools or templating for dynamic values
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  # Can't easily generate or transform values
  DATABASE_URL: "postgres://user:password@db:5432/mydb"
  API_KEY: "static-key-value"
  TIMESTAMP: "2023-06-18T00:00:00Z"  # Hard-coded timestamp</code></pre><pre><code>resource "kubernetes_config_map" "app_config" {
  metadata {
    name = "app-config"
  }
  
  data = {
    DATABASE_URL = "postgres://${var.db_user}:${var.db_password}@${var.db_host}:${var.db_port}/${var.db_name}"
    API_KEY      = var.api_key != "" ? var.api_key : random_string.api_key.result
    TIMESTAMP    = timestamp()
  }
}

resource "random_string" "api_key" {
  length  = 32
  special = false
}</code></pre><p>Here's all the pros you get with this move. </p><ol><li><strong>Type Safety</strong>: Preventing type-related errors before deployment</li><li><strong>Variables and References</strong>: Reducing duplication and improving maintainability</li><li><strong>Functions and Expressions</strong>: Enabling dynamic configuration generation</li><li><strong>Conditional Logic</strong>: Supporting environment-specific configurations</li><li><strong>Loops and Iteration</strong>: Simplifying repetitive configurations</li><li><strong>Better Comments</strong>: Improving documentation and readability</li><li><strong>Error Handling</strong>: Making errors easier to identify and fix</li><li><strong>Modularity</strong>: Enabling reuse of configuration components</li><li><strong>Validation</strong>: Preventing invalid configurations</li><li><strong>Data Transformations</strong>: Supporting complex data manipulations<br></li></ol><h3 id="allow-etcd-swap-out">Allow etcd swap-out</h3><p>I know, I'm the 10,000 person to write this. Etcd has done a fine job, but it's a little crazy that it is the only tool for the job. For smaller clusters or smaller hardware configuration, it's a large use of resources in a cluster type where you will never hit the node count where it pays off. It's also a strange relationship between k8s and etcd now, where k8s is basically the only etcd customer left. </p><p>What I'm suggesting is taking the work of <a href="https://github.com/k3s-io/kine" rel="noreferrer">kine</a> and making it official. It makes sense for the long-term health of the project to have the ability to plug in more backends, adding this abstraction means it (should) be easier to swap in new/different backends in the future and it also allows for more specific tuning depending on the hardware I'm putting out there. </p><p>What I suspect this would end up looking like is much like this: <a href="https://github.com/canonical/k8s-dqlite">https://github.com/canonical/k8s-dqlite</a>. Distributed SQlite in-memory with Raft consensus and almost zero upgrade work required that would allow cluster operators to have more flexibility with the persistence layer of their k8s installations. If you have a conventional server setup in a datacenter and etcd resource usage is not a problem, great! But this allows for lower-end k8s to be a nicer experience and (hopefully) reduces dependence on the etcd project. </p><h3 id="beyond-helm-a-native-package-manager">Beyond Helm: A Native Package Manager</h3><p>Helm is a perfect example of a temporary hack that has grown to be a permanent dependency. I'm grateful to the maintainers of Helm for all of their hard work, growing what was originally a hackathon project into the de-facto way to install software into k8s clusters. It has done as good a job as something could in fulfilling that role without having a deeper integration into k8s. </p><p>All that said, Helm is a nightmare to use. The Go templates are tricky to debug, often containing complex logic that results in really confusing error scenarios. The error messages you get from those scenarios are often gibberish. Helm isn't a very good package system because it fails at some of the basic tasks you need a package system to do, which are transitive dependencies and resolving conflicts between dependencies. </p><p><strong>What do I mean?</strong></p><p>Tell me what this conditional logic is trying to do:</p><pre><code># A real-world example of complex conditional logic in Helm
{{- if or (and .Values.rbac.create .Values.serviceAccount.create) (and .Values.rbac.create (not .Values.serviceAccount.create) .Values.serviceAccount.name) }}
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ template "myapp.fullname" . }}
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
{{- end }}</code></pre><p>Or if I provide multiple values files to my chart, which one wins:</p><pre><code>helm install myapp ./mychart -f values-dev.yaml -f values-override.yaml --set service.type=NodePort</code></pre><p>Ok, what if I want to manage my application and all the application dependencies with a Helm chart. This makes sense, I have an application that itself has dependencies on other stuff so I want to put them all together. So I define my sub-charts or umbrella charts inside of my Chart.yaml. <br></p><pre><code>dependencies:
- name: nginx
  version: "1.2.3"
  repository: "&lt;https://example.com/charts&gt;"
- name: memcached
  version: "1.2.3"
  repository: "&lt;https://another.example.com/charts&gt;"
</code></pre><p>But assuming I have multiple applications, it's entirely possible that I have 2 services both with a dependency on nginx or whatever like this:<br></p><figure><img src="https://matduggan.com/content/images/2025/06/image-2.png" alt="" loading="lazy" width="367" height="176"></figure><p>Helm doesn't handle this situation gracefully because template names are global with their templates loaded alphabetically. Basically you need to:</p><ul><li>Don't declare a dependency on the same chart more than once (hard to do for a lot of microservices)</li><li>If you do have the same chart declared multiple times, has to use the exact same version</li></ul><p>The list of issues goes on and on. </p><ul><li>Cross-Namespace installation stinks</li><li>Chart verification process is a pain and nobody uses it</li></ul><p>Let's just go to the front page of artifacthub:</p><figure><img src="https://matduggan.com/content/images/2025/06/image-3.png" alt="" loading="lazy" width="978" height="794" srcset="https://matduggan.com/content/images/size/w600/2025/06/image-3.png 600w, https://matduggan.com/content/images/2025/06/image-3.png 978w" sizes="(min-width: 720px) 720px"></figure><p>I'll grab elasticsearch cause that seems important. </p><figure><img src="https://matduggan.com/content/images/2025/06/image-4.png" alt="" loading="lazy" width="504" height="296"></figure><figure><img src="https://matduggan.com/content/images/2025/06/image-5.png" alt="" loading="lazy" width="522" height="404"></figure><p>Seems <em>pretty bad</em> for the Official Elastic helm chart. Certainly <code>ingress-nginx</code> will be right, it's an absolute critical dependency for the entire industry. </p><figure><img src="https://matduggan.com/content/images/2025/06/image-6.png" alt="" loading="lazy" width="751" height="184" srcset="https://matduggan.com/content/images/size/w600/2025/06/image-6.png 600w, https://matduggan.com/content/images/2025/06/image-6.png 751w" sizes="(min-width: 720px) 720px"></figure><p>Nope. Also how is the maintainer of the chart "Kubernetes" and it's <em>still</em> not marked as a <code>verified publisher</code>. Like Christ how much more verified does it get.</p><ul><li>No metadata in chart searching. You can only search by name and description, not by features, capabilities, or other metadata.</li></ul><figure><img src="https://matduggan.com/content/images/2025/06/image-7.png" alt="" loading="lazy" width="1138" height="929" srcset="https://matduggan.com/content/images/size/w600/2025/06/image-7.png 600w, https://matduggan.com/content/images/size/w1000/2025/06/image-7.png 1000w, https://matduggan.com/content/images/2025/06/image-7.png 1138w" sizes="(min-width: 720px) 720px"></figure><ul><li>Helm doesn't strictly enforce semantic versioning</li></ul><pre><code># Chart.yaml with non-semantic version
apiVersion: v2
name: myapp
version: "v1.2-alpha" </code></pre><ul><li>If you uninstall and reinstall a chart with CRDs, it might delete resources created by those CRDs. This one has screwed me <em>multiple times</em> and is crazy unsafe. </li></ul><p>I could keep writing for another 5000 words and still wouldn't have outlined all the problems. There isn't a way to make Helm good enough for the task of "package manager for all the critical infrastructure on the planet". </p><h4 id="what-would-a-k8s-package-system-look-like">What would a k8s package system look like?</h4><p>Let's call our hypothetical package system KubePkg, because if there's one thing the Kubernetes ecosystem needs, it's another abbreviated name with a 'K' in it. We would try to copy as much of the existing work inside the Linux ecosystem while taking advantage of the CRD power of k8s. My idea looks something like this:</p><figure><img src="https://matduggan.com/content/images/2025/06/image-8.png" alt="" loading="lazy" width="600" height="356" srcset="https://matduggan.com/content/images/2025/06/image-8.png 600w"></figure><p>The packages are bundles like a Linux package:<br></p><figure><img src="https://matduggan.com/content/images/2025/06/image-9.png" alt="" loading="lazy" width="528" height="196"></figure><p>There's a definition file that accounts for as many of the real scenarios that you actually encounter when installing a thing. </p><pre><code>apiVersion: kubepkg.io/v1
kind: Package
metadata:
  name: postgresql
  version: 14.5.2
spec:
  maintainer:
    name: "PostgreSQL Team"
    email: "<a href="https://matduggan.com/cdn-cgi/l/email-protection" data-cfemail="9df0fcf4f3e9fcf4f3f8efeeddedf2eee9faeff8eeecf1b3f8e5fcf0edf1f8b3fef2f0">[email&nbsp;protected]</a>"
  description: "PostgreSQL database server"
  website: "https://postgresql.org"
  license: "PostgreSQL"
  
  # Dependencies with semantic versioning
  dependencies:
    - name: storage-provisioner
      versionConstraint: "&gt;=1.0.0"
    - name: metrics-collector
      versionConstraint: "^2.0.0"
      optional: true
  
  # Security context and requirements
  security:
    requiredCapabilities: ["CHOWN", "SETGID", "SETUID"]
    securityContextConstraints:
      runAsUser: 999
      fsGroup: 999
    networkPolicies:
      - ports:
        - port: 5432
          protocol: TCP
    
  # Resources to be created (embedded or referenced)
  resources:
    - apiVersion: v1
      kind: Service
      metadata:
        name: postgresql
      spec:
        ports:
        - port: 5432
    - apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: postgresql
      spec:
        # StatefulSet definition
  
  # Configuration schema using JSON Schema
  configurationSchema:
    type: object
    properties:
      replicas:
        type: integer
        minimum: 1
        default: 1
      persistence:
        type: object
        properties:
          size:
            type: string
            pattern: "^[0-9]+[GMK]i$"
            default: "10Gi"
  
  # Lifecycle hooks with proper sequencing
  hooks:
    preInstall:
      - name: database-prerequisites
        job:
          spec:
            template:
              spec:
                containers:
                - name: init
                  image: postgres:14.5
    postInstall:
      - name: database-init
        job:
          spec:
            # Job definition
    preUpgrade:
      - name: backup
        job:
          spec:
            # Backup job definition
    postUpgrade:
      - name: verify
        job:
          spec:
            # Verification job definition
    preRemove:
      - name: final-backup
        job:
          spec:
            # Final backup job definition
  
  # State management for stateful applications
  stateManagement:
    backupStrategy:
      type: "snapshot"  # or "dump"
      schedule: "0 2 * * *"  # Daily at 2 AM
      retention:
        count: 7
    recoveryStrategy:
      type: "pointInTime"
      verificationJob:
        spec:
          # Job to verify recovery success
    dataLocations:
      - path: "/var/lib/postgresql/data"
        volumeMount: "data"
    upgradeStrategies:
      - fromVersion: "*"
        toVersion: "*"
        strategy: "backup-restore"
      - fromVersion: "14.*.*"
        toVersion: "14.*.*"
        strategy: "in-place"</code></pre><p>There's a real signing process that would be required and allow you more control over the process. <br></p><pre><code>apiVersion: kubepkg.io/v1
kind: Repository
metadata:
  name: official-repo
spec:
  url: "https://repo.kubepkg.io/official"
  type: "OCI"  # or "HTTP"
  
  # Verification settings
  verification:
    publicKeys:
      - name: "KubePkg Official"
        keyData: |
          -----BEGIN PUBLIC KEY-----
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvF4+...
          -----END PUBLIC KEY-----
    trustPolicy:
      type: "AllowList"  # or "KeyRing"
      allowedSigners:
        - "KubePkg Official"
        - "Trusted Partner"
    verificationLevel: "Strict"  # or "Warn", "None"</code></pre>
<p>Like how great would it be to have something where I could automatically update packages without needing to do anything on my side. </p><pre><code>apiVersion: kubepkg.io/v1
kind: Installation
metadata:
  name: postgresql-main
  namespace: database
spec:
  packageRef:
    name: postgresql
    version: "14.5.2"
  
  # Configuration values (validated against schema)
  configuration:
    replicas: 3
    persistence:
      size: "100Gi"
    resources:
      limits:
        memory: "4Gi"
        cpu: "2"
  
  # Update policy
  updatePolicy:
    automatic: false
    allowedVersions: "14.x.x"
    schedule: "0 2 * * 0"  # Weekly on Sunday at 2am
    approvalRequired: true
  
  # State management reference
  stateRef:
    name: postgresql-main-state
    
  # Service account to use
  serviceAccountName: postgresql-installer</code></pre><p>What k8s needs is a system that meets the following requirements:</p><ol><li><strong>True Kubernetes Native</strong>: Everything is a Kubernetes resource with proper status and events</li><li><strong>First-Class State Management</strong>: Built-in support for stateful applications</li><li><strong>Enhanced Security</strong>: Robust signing, verification, and security scanning</li><li><strong>Declarative Configuration</strong>: No templates, just structured configuration with schemas</li><li><strong>Lifecycle Management</strong>: Comprehensive lifecycle hooks and upgrade strategies</li><li><strong>Dependency Resolution</strong>: Linux-like dependency management with semantic versioning</li><li><strong>Audit Trail</strong>: Complete history of changes with who, what, and when, not what Helm currently provides. </li><li><strong>Policy Enforcement</strong>: Support for organizational policies and compliance. </li><li><strong>Simplified User Experience</strong>: Familiar Linux-like package management commands. It seems wild that we're trying to go a different direction from the package systems that have worked for decades. </li></ol><h3 id="ipv6-by-default">IPv6 By Default</h3><p>Try to imagine, across the entire globe, how much time and energy has been invested in trying to solve any one of the following three problems. </p><ol><li>I need this pod in this cluster to talk to that pod in that cluster. </li><li>There is a problem happening somewhere in the NAT traversal process and I need to solve it</li><li>I have run out of IP addresses with my cluster because I didn't account for how many you use. Remember: A company starting with a /20 subnet (4,096 addresses), deploys 40 nodes with 30 pods each, and suddenly realizes they're approaching their IP limit. Not that many nodes!</li></ol><p>I am not suggesting the entire internet switches over to IPv6 and right now k8s happily supports IPv6-only if you want and a dualstack approach. But I'm saying now is the time to flip the default and just go IPv6. You eliminate a huge collection of problems all at once. </p><ul><li>Flatter, less complicated network topology inside of the cluster. </li><li>The distinction between multiple clusters becomes a thing organizations can choose to ignore if they want if they want to get public IPs.</li><li>Easier to understand exactly the flow of traffic inside of your stack. </li><li>Built-in IPSec</li></ul><p>It has nothing to do with driving IPv6 adoption across the entire globe and just an acknowledgement that we no longer live in a world where you have to accept the weird limitations of IPv4 in a universe where you may need 10,000 IPs suddenly with very little warning. </p><p>The benefits for organizations with public IPv6 addresses is pretty obvious, but there's enough value there for cloud providers and users that even the corporate overlords might get behind it. AWS never needs to try and scrounge up more private IPv4 space inside of a VPC. That's gotta be worth something. </p><h3 id="conclusion">Conclusion </h3><p>The common rebuttal to these ideas is, "Kubernetes is an open platform, so the community can build these solutions." While true, this argument misses a crucial point: <strong>defaults are the most powerful force in technology.</strong> The "happy path" defined by the core project dictates how 90% of users will interact with it. If the system defaults to expecting signed packages and provides a robust, native way to manage them, that is what the ecosystem will adopt.</p><p>This is an ambitious list, I know. But if we're going to dream, let's dream big. After all, we're the industry that thought naming a technology 'Kubernetes' would catch on, and somehow it did!</p><p>We see this all the time in other areas like mobile developer and web development, where platforms assess their situation and make <em>radical</em> jumps forward. Not all of these are necessarily projects that the maintainers or companies <em>would</em> take on but I think they're all ideas that <em>someone</em> should at least revisit and think "is it worth doing now that we're this nontrivial percentage of all datacenter operations on the planet"? </p><p>Questions/feedback/got something wrong? Find me here: <a href="https://c.im/@matdevdug">https://c.im/@matdevdug</a></p>
        </div>



</article>

        </main>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guess I'm a Rationalist Now (191 pts)]]></title>
            <link>https://scottaaronson.blog/?p=8908</link>
            <guid>44317180</guid>
            <pubDate>Thu, 19 Jun 2025 10:22:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottaaronson.blog/?p=8908">https://scottaaronson.blog/?p=8908</a>, See on <a href="https://news.ycombinator.com/item?id=44317180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-8908">
				
<p>A week ago I attended <a href="https://less.online/">LessOnline</a>, a rationalist blogging conference featuring many people I’ve known for years—Scott Alexander, Eliezer Yudkowsky, Zvi Mowshowitz, Sarah Constantin, Carl Feynman—as well as people I’ve known only online and was delighted to meet in person, like Joe Carlsmith and Jacob Falkovich and Daniel Reeves.  The conference was at <a href="https://www.lighthaven.space/">Lighthaven</a>, a bewildering maze of passageways, meeting-rooms, sleeping quarters, gardens, and vines off Telegraph Avenue in Berkeley, which has recently emerged as the nerd Shangri-La, or Galt’s Gulch, or Shire, or whatever.  I did two events at this year’s LessOnline: a conversation with Nate Soares about the <a href="https://www.lesswrong.com/w/orthogonality-thesis">Orthogonality Thesis</a>, and an ask-me-anything session about quantum computing and theoretical computer science (no new ground there for regular consumers of my content).</p>



<p>What I’ll remember most from LessOnline is not the sessions, mine or others’, but the unending conversation among hundreds of people all over the grounds, which took place in parallel with the sessions and before and after them, from morning till night (and through the night, apparently, though I’ve gotten too old for that).  It felt like a single conversational archipelago, the largest in which I’ve ever taken part, and the conference’s real point.  (Attendees were exhorted, in the opening session, to skip as many sessions as possible in favor of intense small-group conversations—not only because it was better but also because the session rooms were too small.)</p>



<p>Within the conversational blob, just making my way from one building to another could take hours.  My mean free path was approximately five feet, before someone would notice my nametag and stop me with a question.  Here was my favorite opener:</p>



<p>“You’re Scott Aaronson?!  The quantum physicist who’s always getting into arguments on the Internet, and who’s essentially always right, but who sustains an unreasonable amount of psychic damage in the process?”</p>



<p>“Yes,” I replied, not bothering to correct the “physicist” part.</p>



<p>One night, I walked up to Scott Alexander, who sitting on the ground, with his large bald head and a blanket he was using as a robe, resembled a monk.  “Are you enjoying yourself?” he asked.</p>



<p>I replied, “you know, after all these years of being coy about it, I think I’m finally ready to become a Rationalist.  Is there, like, an initiation ritual or something?”</p>



<p>Scott said, “Oh, you were already initiated a decade ago; you just didn’t realize it at the time.”  Then he corrected himself: “two decades ago.”</p>



<p>The first thing I did, after coming out as a Rationalist, was to get into a heated argument with Other Scott A., Joe  Carlsmith, and other fellow-Rationalists about the ideas I set out twelve years ago in my <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">Ghost in the Quantum Turing Machine</a> essay.  Briefly, my argument was that the irreversibility and ephemerality of biological life, which contrasts with the copyability, rewindability, etc. of programs running on digital computers, and which can ultimately be traced back to microscopic details of the universe’s initial state, subject to the No-Cloning Theorem of quantum mechanics, which then get chaotically amplified during brain activity … might be a clue to a deeper layer of the world, one that we understand about as well as the ancient Greeks understood Newtonian physics, but which is the layer where mysteries like free will and consciousness will ultimately need to be addressed.</p>



<p>I got into this argument partly because it came up, but partly also because this seemed like the biggest conflict between my beliefs and the consensus of my fellow Rationalists.  Maybe part of me wanted to demonstrate that my intellectual independence remained intact—sort of like a newspaper that gets bought out by a tycoon, and then immediately runs an investigation into the tycoon’s corruption, as well as his diaper fetish, just to prove it can.</p>



<p>The funny thing, though, is that all my beliefs are the same as they were before.  I’m still a computer scientist, an academic, a straight-ticket Democratic voter, a liberal Zionist, a Jew, etc. (all identities, incidentally, well-enough represented at LessOnline that I don’t even think I was the unique attendee in the intersection of them all).</p>



<p>Given how much I resonate with what the Rationalists are trying to do, why did it take me so long to identify as one?</p>



<p>Firstly, while 15 years ago I shared the Rationalists’ interests, sensibility, and outlook, and their stances on most issues, I also found them bizarrely, inexplicably obsessed with the question of whether AI would soon become superhumanly powerful and change the basic conditions of life on earth, and with how to make the AI transition go well.  Why <em>that</em>, as opposed to all the other sci-fi scenarios one could worry about, not to mention all the nearer-term risks to humanity?</p>



<p>Suffice it to say that empirical developments have since caused me to withdraw my objection.  Sometimes weird people are weird merely because they see the future sooner than others.  Indeed, it seems to me that the biggest thing the Rationalists got wrong about AI was to <em>underestimate</em> how soon the revolution would happen, and to overestimate how many new ideas would be needed for it (mostly, as we now know, it just took lots more compute and training data).  Now that I, too, spend some of my time working on AI alignment, I was able to use LessOnline in part for research meetings with colleagues.</p>



<p>A second reason I didn’t identify with the Rationalists was cultural: they were, and are, centrally a bunch of twentysomethings who “work” at an ever-changing list of Berkeley- and San-Francisco-based “orgs” of their own invention, and who live in group houses where they explore their exotic sexualities, gender identities, and fetishes, sometimes with the aid of psychedelics.  I, by contrast, am a straight, monogamous, middle-aged tenured professor, married to another such professor and raising two kids who go to normal schools.  Hanging out with the Rationalists always makes me feel older and younger at the same time.</p>



<p>So what changed?  For one thing, with the march of time, a significant fraction of Rationalists now have marriages, children, or both—indeed, a highlight of LessOnline was the many adorable toddlers running around the Lighthaven campus.  Rationalists are successfully reproducing!  Some because of explicit pronatalist ideology, or because they were persuaded by Bryan Caplan’s arguments in <em><a href="https://www.amazon.com/Selfish-Reasons-Have-More-Kids/dp/0465028616">Selfish Reasons to Have More Kids</a></em>.  But others simply because of the same impulses that led their ancestors to do the same for eons.  And perhaps because, like the Mormons or Amish or Orthodox Jews, but unlike typical secular urbanites, the Rationalists <em>believe </em>in something.  For all their fears around AI, they don’t <em>act</em> doomy, but buzz with ideas about how to build a better world for the next generation.</p>



<p>At a LessOnline parenting session, hosted by Julia Wise, I was surrounded by parents who worry about the same things I do: how do we raise our kids to be independent and agentic yet socialized and reasonably well-behaved, technologically savvy yet not droolingly addicted to iPad games?  What schooling options will let them accelerate in math, save them from the crushing monotony that we experienced?  How much of our own lives should we sacrifice on the altar of our kids’ “enrichment,” versus trusting Judith Rich Harris that such efforts quickly hit a point of diminishing returns?</p>



<p>A third reason I didn’t identify with the Rationalists was, frankly, that they gave off some (not all) of the vibes of a cult, with Eliezer as guru.  Eliezer writes in parables and koans.  He teaches that the fate of life on earth hangs in the balance, that the select few who understand the stakes have the terrible burden of steering the future.  Taking what Rationalists call the “outside view,” <em>how good is the track record for this sort of thing?</em></p>



<p>OK, but what did I actually see at Lighthaven?  I saw something that seemed to resemble a cult only insofar as the Beatniks, the Bloomsbury Group, the early Royal Society, or any other community that believed in something did.  When Eliezer himself—the bearded, cap-wearing Moses who led the nerds from bondage to their Promised Land in Berkeley—showed up, he was argued with like anyone else.  Eliezer has in any case largely passed his staff to a new generation: Nate Soares and Zvi Mowshowitz have found new and, in various ways, better ways of talking about AI risk; Scott Alexander has for the last decade written the blog that’s the community’s intellectual center; figures from Kelsey Piper to Jacob Falkovich to Aella have taken Rationalism in new directions, from mainstream political engagement to the … err … <a href="https://aella.substack.com/p/my-birthday-gangbang">statistical analysis of orgies</a>.</p>



<p>I’ll say this, though, on the naysayers’ side: it’s <em>really</em> hard to make dancing to AI-generated pop songs about Bayes’ theorem and Tarski’s definition of truth not feel cringe, as I can now attest from experience.</p>



<p>The cult thing brings me to the deepest reason I hesitated for so long to identify as a Rationalist: namely, I was scared that if I did, people whose approval I craved (including my academic colleagues, but also just randos on the Internet) would sneer at me.  For years, I searched of some way of explaining this community’s appeal so reasonable that it would silence the sneers.</p>



<p>It took years of psychological struggle, and (frankly) solidifying my own place in the world, to follow the true path, which of course is not to give a shit what some haters think of my life choices.  Consider: five years ago, it felt obvious to me that the entire Rationalist community might be about to implode, under existential threat from Cade Metz’s <em>New York Times</em> article, as well as RationalWiki and SneerClub and all the others laughing at the Rationalists and accusing them of every evil.  Yet last week at LessOnline, I saw a community that’s never been thriving more, with a beautiful real-world campus, excellent writers on every topic who felt like this was the place to be, and even a crop of kids.  How many of the sneerers are living such fulfilled lives?  To judge from their own angry, depressed self-disclosures, probably not many.</p>



<p>But are the sneerers right that, even if the Rationalists are enjoying their own lives, they’re making other people’s lives miserable?  Are they closet far-right monarchists, like Curtis Yarvin?  I liked how <em>The New Yorker</em> put it in its recent, long and (to my mind) <a href="https://www.newyorker.com/magazine/2025/06/09/curtis-yarvin-profile">devastating profile of Yarvin</a>:</p>



<blockquote>
<p>The most generous engagement with Yarvin’s ideas has come from bloggers associated with the rationalist movement, which prides itself on weighing evidence for even seemingly far-fetched claims. Their formidable patience, however, has also worn thin. “He never addressed me as an equal, only as a brainwashed person,” Scott Aaronson, an eminent computer scientist, said of their conversations. “He seemed to think that if he just gave me one more reading assignment about happy slaves singing or one more monologue about F.D.R., I’d finally see the light.”</p>
</blockquote>



<p>The closest to right-wing politics that I witnessed at LessOnline was a session, with <a href="https://www.vox.com/authors/kelsey-piper">Kelsey Piper</a> and current and former congressional staffers, about the prospects for moderate Democrats to articulate a moderate, pro-abundance agenda that would resonate with the public and finally defeat MAGA.</p>



<p>But surely the Rationalists are incels, bitter that they can’t get laid?  Again, the closest I saw was a session where Jacob Falkovich helped a standing-room-only crowd of mostly male nerds confront their fears around dating and understand women better, with Rationalist women eagerly volunteering to answer questions about their perspective.  Gross, right?  (Also, for those already in relationships, Eliezer’s primary consort and former couples therapist <a href="https://www.grettaduleba.com/">Gretta Duleba</a> did a session on relationship conflict.)</p>



<p>So, yes, when it comes to the Rationalists, I’m going to believe my own lying eyes over the charges of the sneerers.  The sneerers can even say about me, in their favorite formulation, that I’ve “gone mask off,” confirmed the horrible things they’ve always suspected.  Yes, the mask is off—and beneath the mask is the same person I always was, who has an inordinate fondness for the <a href="https://en.wikipedia.org/wiki/Busy_beaver">Busy Beaver function</a> and the complexity class <a href="https://arxiv.org/abs/1004.0377">BQP/qpoly</a>, and who uses too many filler words and moves his hands too much, and who strongly supports the Enlightenment, and who once feared that his best shot at happiness in life would be to earn women’s pity rather than their contempt.  Incorrectly, as I’m glad to report.  From my nebbishy nadir to the present, a central thing that’s changed is that, from my family to my academic colleagues to the Rationalist community to my blog readers, I finally found some people who want what I have to sell.</p>



<hr>



<p><strong><mark>Unrelated Announcements:</mark></strong></p>



<p>My replies to comments on this post might be light, as I’ll be accompanying my daughter on a school trip to the Galapagos Islands!</p>



<p>A few weeks ago, I was “ambushed” into leading a session on philosophy and theoretical computer science at UT Austin.  (I.e., asked to show up for the session, but thought I’d just be a participant rather than the main event.)  The session was then <a href="https://www.youtube.com/watch?v=OST1DjD08Hg">recorded and placed on YouTube</a>—and surprisingly, given the circumstances, some people seemed to like it!</p>



<p>Friend-of-the-blog <a href="https://www.alonrosen.net/">Alon Rosen</a> has asked me to announce a <a href="https://cs.unibocconi.eu/call-nominations-trevisan-prize-2025">call for nominations</a> for a new theoretical computer science prize, in memory of my former professor (and fellow TCS blogger) <a href="https://scottaaronson.blog/?p=8057">Luca Trevisan</a>, who was lost to the world too soon.</p>



<p>And one more: Mahdi Cheraghchi has asked me to announce the STOC’2025 online poster session, registration deadline June 12; <a href="https://acm-stoc.org/stoc2025/call-for-posters.html">see here for more</a>.  Incidentally, I’ll be at STOC in Prague to give a plenary on quantum algorithms; I look forward to meeting any readers who are there!</p>

		
				
				<p>
					<small>
						This entry was posted
												on Monday, June 9th, 2025 at 8:02 pm						and is filed under <a href="https://scottaaronson.blog/?cat=10" rel="category">Adventures in Meatspace</a>, <a href="https://scottaaronson.blog/?cat=31" rel="category">Announcements</a>, <a href="https://scottaaronson.blog/?cat=18" rel="category">Embarrassing Myself</a>, <a href="https://scottaaronson.blog/?cat=11" rel="category">Nerd Interest</a>, <a href="https://scottaaronson.blog/?cat=29" rel="category">Nerd Self-Help</a>, <a href="https://scottaaronson.blog/?cat=42" rel="category">Obviously I'm Not Defending Aaronson</a>.
						You can follow any responses to this entry through the <a href="https://scottaaronson.blog/?feed=rss2&amp;p=8908">RSS 2.0</a> feed.

													You can <a href="#respond">leave a response</a>, or <a href="https://scottaaronson.blog/wp-trackback.php?p=8908" rel="trackback">trackback</a> from your own site.

						
					</small>
				</p>

			</div><p>You can use rich HTML in comments!  You can also use basic TeX, by enclosing it within <span>$$ $$</span> for displayed equations or <span>\( \)</span> for inline equations.</p><p>
	After two decades of mostly-open comments, in July 2024 <i>Shtetl-Optimized</i> transitioned to the following policy:
	
</p><p>All comments are treated, by default, as personal missives to me, Scott Aaronson---with no expectation either that they'll appear on the blog or that I'll reply to them.

</p><p>At my leisure and discretion, and in consultation with the <a href="https://scottaaronson.blog/?p=6576"><i>Shtetl-Optimized</i> Committee of Guardians</a>, I'll put on the blog a curated selection of comments that I judge to be particularly interesting or to move the topic forward, and I'll do my best to answer those.  But it will be more like Letters to the Editor.  Anyone who feels unjustly censored is welcome to the rest of the Internet.

</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Claude Code Usage Monitor – real-time tracker to dodge usage cut-offs (176 pts)]]></title>
            <link>https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor</link>
            <guid>44317012</guid>
            <pubDate>Thu, 19 Jun 2025 09:46:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor">https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor</a>, See on <a href="https://news.ycombinator.com/item?id=44317012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Claude Code Usage Monitor</h2><a id="user-content--claude-code-usage-monitor" aria-label="Permalink: 🎯 Claude Code Usage Monitor" href="#-claude-code-usage-monitor"></a></p>
<p dir="auto"><a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/dec1d99c8e1ae20b8b158f2c346d5762e185f4b00fce1ef873f83115b84ee974/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362b2d626c75652e737667" alt="Python Version" data-canonical-src="https://img.shields.io/badge/python-3.6+-blue.svg"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/6cd0120cc4c5ac11d28b2c60f76033b52db98dac641de3b2644bb054b449d60c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>
<a href="http://makeapullrequest.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/d88d8d77fa79e828eea397f75a1ebd114d13488aeec4747477ffbd2274de95ed/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e737667" alt="PRs Welcome" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"></a></p>
<p dir="auto">A beautiful real-time terminal monitoring tool for Claude AI token usage. Track your token consumption, burn rate, and get predictions about when you'll run out of tokens.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/doc/sc.png"><img src="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/raw/main/doc/sc.png" alt="Claude Token Monitor Screenshot"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📑 Table of Contents</h2><a id="user-content--table-of-contents" aria-label="Permalink: 📑 Table of Contents" href="#-table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#-key-features">✨ Key Features</a></li>
<li><a href="#-installation">🚀 Installation</a>
<ul dir="auto">
<li><a href="#-quick-start">⚡ Quick Start</a></li>
<li><a href="#-production-setup-recommended">🔒 Production Setup (Recommended)</a></li>
<li><a href="#virtual-environment-setup">Virtual Environment Setup</a></li>
</ul>
</li>
<li><a href="#-usage">📖 Usage</a>
<ul dir="auto">
<li><a href="#basic-usage">Basic Usage</a></li>
<li><a href="#configuration-options">Configuration Options</a></li>
<li><a href="#available-plans">Available Plans</a></li>
</ul>
</li>
<li><a href="#-features--how-it-works">✨ Features &amp; How It Works</a>
<ul dir="auto">
<li><a href="#current-features">Current Features</a></li>
<li><a href="#understanding-claude-sessions">Understanding Claude Sessions</a></li>
<li><a href="#token-limits-by-plan">Token Limits by Plan</a></li>
<li><a href="#smart-detection-features">Smart Detection Features</a></li>
</ul>
</li>
<li><a href="#-usage-examples">🚀 Usage Examples</a>
<ul dir="auto">
<li><a href="#common-scenarios">Common Scenarios</a></li>
<li><a href="#best-practices">Best Practices</a></li>
</ul>
</li>
<li><a href="#-contact">📞 Contact</a></li>
<li><a href="#-additional-documentation">📚 Additional Documentation</a></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Key Features</h2><a id="user-content--key-features" aria-label="Permalink: ✨ Key Features" href="#-key-features"></a></p>
<ul dir="auto">
<li><strong>🔄 Real-time monitoring</strong> - Updates every 3 seconds with smooth refresh</li>
<li><strong>📊 Visual progress bars</strong> - Beautiful color-coded token and time progress bars</li>
<li><strong>🔮 Smart predictions</strong> - Calculates when tokens will run out based on current burn rate</li>
<li><strong>🤖 Auto-detection</strong> - Automatically switches to custom max when Pro limit is exceeded</li>
<li><strong>📋 Multiple plan support</strong> - Works with Pro, Max5, Max20, and auto-detect plans</li>
<li><strong><g-emoji alias="warning">⚠️</g-emoji> Warning system</strong> - Alerts when tokens exceed limits or will deplete before session reset</li>
<li><strong>💼 Professional UI</strong> - Clean, colorful terminal interface with emojis</li>
<li><strong>⏰ Customizable scheduling</strong> - Set your own reset times and timezones</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Installation</h2><a id="user-content--installation" aria-label="Permalink: 🚀 Installation" href="#-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Quick Start</h3><a id="user-content--quick-start" aria-label="Permalink: ⚡ Quick Start" href="#-quick-start"></a></p>
<p dir="auto">For immediate testing (not recommended for regular use):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
npm install -g ccusage
pip install pytz

# Clone and run
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
cd Claude-Code-Usage-Monitor
python ccusage_monitor.py"><pre><span><span>#</span> Install dependencies</span>
npm install -g ccusage
pip install pytz

<span><span>#</span> Clone and run</span>
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
<span>cd</span> Claude-Code-Usage-Monitor
python ccusage_monitor.py</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔒 Production Setup (Recommended)</h3><a id="user-content--production-setup-recommended" aria-label="Permalink: 🔒 Production Setup (Recommended)" href="#-production-setup-recommended"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisites</h4><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ol dir="auto">
<li><strong>Python 3.6+</strong> installed on your system</li>
<li><strong>Node.js</strong> for ccusage CLI tool</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Virtual Environment Setup</h3><a id="user-content-virtual-environment-setup" aria-label="Permalink: Virtual Environment Setup" href="#virtual-environment-setup"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why Use Virtual Environment?</h4><a id="user-content-why-use-virtual-environment" aria-label="Permalink: Why Use Virtual Environment?" href="#why-use-virtual-environment"></a></p>
<p dir="auto">Using a virtual environment is <strong>strongly recommended</strong> because:</p>
<ul dir="auto">
<li><strong>🛡️ Isolation</strong>: Keeps your system Python clean and prevents dependency conflicts</li>
<li><strong>📦 Portability</strong>: Easy to replicate the exact environment on different machines</li>
<li><strong>🔄 Version Control</strong>: Lock specific versions of dependencies for stability</li>
<li><strong>🧹 Clean Uninstall</strong>: Simply delete the virtual environment folder to remove everything</li>
<li><strong>👥 Team Collaboration</strong>: Everyone uses the same Python and package versions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installing virtualenv (if needed)</h4><a id="user-content-installing-virtualenv-if-needed" aria-label="Permalink: Installing virtualenv (if needed)" href="#installing-virtualenv-if-needed"></a></p>
<p dir="auto">If you don't have <code>venv</code> module available:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Ubuntu/Debian
sudo apt-get update
sudo apt-get install python3-venv

# Fedora/RHEL/CentOS
sudo dnf install python3-venv

# macOS (usually comes with Python)
# If not available, install Python via Homebrew:
brew install python3

# Windows (usually comes with Python)
# If not available, reinstall Python from python.org
# Make sure to check &quot;Add Python to PATH&quot; during installation"><pre><span><span>#</span> Ubuntu/Debian</span>
sudo apt-get update
sudo apt-get install python3-venv

<span><span>#</span> Fedora/RHEL/CentOS</span>
sudo dnf install python3-venv

<span><span>#</span> macOS (usually comes with Python)</span>
<span><span>#</span> If not available, install Python via Homebrew:</span>
brew install python3

<span><span>#</span> Windows (usually comes with Python)</span>
<span><span>#</span> If not available, reinstall Python from python.org</span>
<span><span>#</span> Make sure to check "Add Python to PATH" during installation</span></pre></div>
<p dir="auto">Alternatively, use the <code>virtualenv</code> package:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install virtualenv via pip
pip install virtualenv

# Then create virtual environment with:
virtualenv venv
# instead of: python3 -m venv venv"><pre><span><span>#</span> Install virtualenv via pip</span>
pip install virtualenv

<span><span>#</span> Then create virtual environment with:</span>
virtualenv venv
<span><span>#</span> instead of: python3 -m venv venv</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step-by-Step Setup</h4><a id="user-content-step-by-step-setup" aria-label="Permalink: Step-by-Step Setup" href="#step-by-step-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Install ccusage globally
npm install -g ccusage

# 2. Clone the repository
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
cd Claude-Code-Usage-Monitor

# 3. Create virtual environment
python3 -m venv venv
# Or if using virtualenv package:
# virtualenv venv

# 4. Activate virtual environment
# On Linux/Mac:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# 5. Install Python dependencies
pip install pytz

# 6. Make script executable (Linux/Mac only)
chmod +x ccusage_monitor.py

# 7. Run the monitor
python ccusage_monitor.py"><pre><span><span>#</span> 1. Install ccusage globally</span>
npm install -g ccusage

<span><span>#</span> 2. Clone the repository</span>
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
<span>cd</span> Claude-Code-Usage-Monitor

<span><span>#</span> 3. Create virtual environment</span>
python3 -m venv venv
<span><span>#</span> Or if using virtualenv package:</span>
<span><span>#</span> virtualenv venv</span>

<span><span>#</span> 4. Activate virtual environment</span>
<span><span>#</span> On Linux/Mac:</span>
<span>source</span> venv/bin/activate
<span><span>#</span> On Windows:</span>
<span><span>#</span> venv\Scripts\activate</span>

<span><span>#</span> 5. Install Python dependencies</span>
pip install pytz

<span><span>#</span> 6. Make script executable (Linux/Mac only)</span>
chmod +x ccusage_monitor.py

<span><span>#</span> 7. Run the monitor</span>
python ccusage_monitor.py</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Daily Usage</h4><a id="user-content-daily-usage" aria-label="Permalink: Daily Usage" href="#daily-usage"></a></p>
<p dir="auto">After initial setup, you only need:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Navigate to project directory
cd Claude-Code-Usage-Monitor

# Activate virtual environment
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Run monitor
./ccusage_monitor.py  # Linux/Mac
# python ccusage_monitor.py  # Windows

# When done, deactivate
deactivate"><pre><span><span>#</span> Navigate to project directory</span>
<span>cd</span> Claude-Code-Usage-Monitor

<span><span>#</span> Activate virtual environment</span>
<span>source</span> venv/bin/activate  <span><span>#</span> Linux/Mac</span>
<span><span>#</span> venv\Scripts\activate   # Windows</span>

<span><span>#</span> Run monitor</span>
./ccusage_monitor.py  <span><span>#</span> Linux/Mac</span>
<span><span>#</span> python ccusage_monitor.py  # Windows</span>

<span><span>#</span> When done, deactivate</span>
deactivate</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pro Tip: Shell Alias</h4><a id="user-content-pro-tip-shell-alias" aria-label="Permalink: Pro Tip: Shell Alias" href="#pro-tip-shell-alias"></a></p>
<p dir="auto">Create an alias for quick access:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add to ~/.bashrc or ~/.zshrc
alias claude-monitor='cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py'

# Then just run:
claude-monitor"><pre><span><span>#</span> Add to ~/.bashrc or ~/.zshrc</span>
<span>alias</span> claude-monitor=<span><span>'</span>cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py<span>'</span></span>

<span><span>#</span> Then just run:</span>
claude-monitor</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📖 Usage</h2><a id="user-content--usage" aria-label="Permalink: 📖 Usage" href="#-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage</h3><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Default (Pro plan - 7,000 tokens)
./ccusage_monitor.py

# Exit the monitor
# Press Ctrl+C to gracefully exit"><pre><span><span>#</span> Default (Pro plan - 7,000 tokens)</span>
./ccusage_monitor.py

<span><span>#</span> Exit the monitor</span>
<span><span>#</span> Press Ctrl+C to gracefully exit</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration Options</h3><a id="user-content-configuration-options" aria-label="Permalink: Configuration Options" href="#configuration-options"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Specify Your Plan</h4><a id="user-content-specify-your-plan" aria-label="Permalink: Specify Your Plan" href="#specify-your-plan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Pro plan (~7,000 tokens) - Default
./ccusage_monitor.py --plan pro

# Max5 plan (~35,000 tokens)
./ccusage_monitor.py --plan max5

# Max20 plan (~140,000 tokens)
./ccusage_monitor.py --plan max20

# Auto-detect from highest previous session
./ccusage_monitor.py --plan custom_max"><pre><span><span>#</span> Pro plan (~7,000 tokens) - Default</span>
./ccusage_monitor.py --plan pro

<span><span>#</span> Max5 plan (~35,000 tokens)</span>
./ccusage_monitor.py --plan max5

<span><span>#</span> Max20 plan (~140,000 tokens)</span>
./ccusage_monitor.py --plan max20

<span><span>#</span> Auto-detect from highest previous session</span>
./ccusage_monitor.py --plan custom_max</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Custom Reset Times</h4><a id="user-content-custom-reset-times" aria-label="Permalink: Custom Reset Times" href="#custom-reset-times"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset at 3 AM
./ccusage_monitor.py --reset-hour 3

# Reset at 10 PM
./ccusage_monitor.py --reset-hour 22"><pre><span><span>#</span> Reset at 3 AM</span>
./ccusage_monitor.py --reset-hour 3

<span><span>#</span> Reset at 10 PM</span>
./ccusage_monitor.py --reset-hour 22</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Timezone Configuration</h4><a id="user-content-timezone-configuration" aria-label="Permalink: Timezone Configuration" href="#timezone-configuration"></a></p>
<p dir="auto">The default timezone is <strong>Europe/Warsaw</strong>. Change it to any valid timezone:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Use US Eastern Time
./ccusage_monitor.py --timezone US/Eastern

# Use Tokyo time
./ccusage_monitor.py --timezone Asia/Tokyo

# Use UTC
./ccusage_monitor.py --timezone UTC

# Use London time
./ccusage_monitor.py --timezone Europe/London"><pre><span><span>#</span> Use US Eastern Time</span>
./ccusage_monitor.py --timezone US/Eastern

<span><span>#</span> Use Tokyo time</span>
./ccusage_monitor.py --timezone Asia/Tokyo

<span><span>#</span> Use UTC</span>
./ccusage_monitor.py --timezone UTC

<span><span>#</span> Use London time</span>
./ccusage_monitor.py --timezone Europe/London</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Available Plans</h3><a id="user-content-available-plans" aria-label="Permalink: Available Plans" href="#available-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Token Limit</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>pro</strong></td>
<td>~7,000</td>
<td>Light usage, testing (default)</td>
</tr>
<tr>
<td><strong>max5</strong></td>
<td>~35,000</td>
<td>Regular development</td>
</tr>
<tr>
<td><strong>max20</strong></td>
<td>~140,000</td>
<td>Heavy usage, large projects</td>
</tr>
<tr>
<td><strong>custom_max</strong></td>
<td>Auto-detect</td>
<td>Uses highest from previous sessions</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Features &amp; How It Works</h2><a id="user-content--features--how-it-works" aria-label="Permalink: ✨ Features &amp; How It Works" href="#-features--how-it-works"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Current Features</h3><a id="user-content-current-features" aria-label="Permalink: Current Features" href="#current-features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔄 Real-time Monitoring</h4><a id="user-content--real-time-monitoring" aria-label="Permalink: 🔄 Real-time Monitoring" href="#-real-time-monitoring"></a></p>
<ul dir="auto">
<li>Updates every 3 seconds with smooth refresh</li>
<li>No screen flicker - intelligent display updates</li>
<li>Live token consumption tracking across multiple sessions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">📊 Visual Progress Bars</h4><a id="user-content--visual-progress-bars" aria-label="Permalink: 📊 Visual Progress Bars" href="#-visual-progress-bars"></a></p>
<ul dir="auto">
<li><strong>Token Progress</strong>: Color-coded bars showing current usage vs limits</li>
<li><strong>Time Progress</strong>: Visual countdown to next session reset</li>
<li><strong>Burn Rate Indicator</strong>: Real-time consumption velocity</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔮 Smart Predictions</h4><a id="user-content--smart-predictions" aria-label="Permalink: 🔮 Smart Predictions" href="#-smart-predictions"></a></p>
<ul dir="auto">
<li>Calculates when tokens will run out based on current burn rate</li>
<li>Warns if tokens will deplete before next session reset</li>
<li>Analyzes usage patterns from the last hour</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🤖 Auto-Detection System</h4><a id="user-content--auto-detection-system" aria-label="Permalink: 🤖 Auto-Detection System" href="#-auto-detection-system"></a></p>
<ul dir="auto">
<li><strong>Smart Plan Switching</strong>: Automatically switches from Pro to custom_max when limits exceeded</li>
<li><strong>Limit Discovery</strong>: Scans previous sessions to find your actual token limits</li>
<li><strong>Intelligent Notifications</strong>: Shows when automatic switches occur</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding Claude Sessions</h3><a id="user-content-understanding-claude-sessions" aria-label="Permalink: Understanding Claude Sessions" href="#understanding-claude-sessions"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How Claude Code Sessions Work</h4><a id="user-content-how-claude-code-sessions-work" aria-label="Permalink: How Claude Code Sessions Work" href="#how-claude-code-sessions-work"></a></p>
<p dir="auto">Claude Code operates on a <strong>5-hour rolling session window system</strong>:</p>
<ol dir="auto">
<li><strong>Session Start</strong>: Begins with your first message to Claude</li>
<li><strong>Session Duration</strong>: Lasts exactly 5 hours from that first message</li>
<li><strong>Token Limits</strong>: Apply within each 5-hour session window</li>
<li><strong>Multiple Sessions</strong>: Can have several active sessions simultaneously</li>
<li><strong>Rolling Windows</strong>: New sessions can start while others are still active</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Session Reset Schedule</h4><a id="user-content-session-reset-schedule" aria-label="Permalink: Session Reset Schedule" href="#session-reset-schedule"></a></p>
<p dir="auto"><strong>Default reference times</strong> (in your configured timezone):</p>
<ul dir="auto">
<li><code>04:00</code>, <code>09:00</code>, <code>14:00</code>, <code>18:00</code>, <code>23:00</code></li>
</ul>
<blockquote>
<p dir="auto"><strong><g-emoji alias="warning">⚠️</g-emoji> Important</strong>: These are reference times for planning. Your actual token refresh happens exactly 5 hours after YOUR first message in each session.</p>
</blockquote>
<p dir="auto"><strong>Example Session Timeline:</strong></p>
<div data-snippet-clipboard-copy-content="10:30 AM - First message (Session A starts)
03:30 PM - Session A expires (5 hours later)

12:15 PM - First message (Session B starts) 
05:15 PM - Session B expires (5 hours later)"><pre><code>10:30 AM - First message (Session A starts)
03:30 PM - Session A expires (5 hours later)

12:15 PM - First message (Session B starts) 
05:15 PM - Session B expires (5 hours later)
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Burn Rate Calculation</h4><a id="user-content-burn-rate-calculation" aria-label="Permalink: Burn Rate Calculation" href="#burn-rate-calculation"></a></p>
<p dir="auto">The monitor calculates burn rate using sophisticated analysis:</p>
<ol dir="auto">
<li><strong>Data Collection</strong>: Gathers token usage from all sessions in the last hour</li>
<li><strong>Pattern Analysis</strong>: Identifies consumption trends across overlapping sessions</li>
<li><strong>Velocity Tracking</strong>: Calculates tokens consumed per minute</li>
<li><strong>Prediction Engine</strong>: Estimates when current session tokens will deplete</li>
<li><strong>Real-time Updates</strong>: Adjusts predictions as usage patterns change</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Token Limits by Plan</h3><a id="user-content-token-limits-by-plan" aria-label="Permalink: Token Limits by Plan" href="#token-limits-by-plan"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Standard Plans</h4><a id="user-content-standard-plans" aria-label="Permalink: Standard Plans" href="#standard-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Approximate Limit</th>
<th>Typical Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Claude Pro</strong></td>
<td>~7,000 tokens</td>
<td>Light coding, testing, learning</td>
</tr>
<tr>
<td><strong>Claude Max5</strong></td>
<td>~35,000 tokens</td>
<td>Regular development work</td>
</tr>
<tr>
<td><strong>Claude Max20</strong></td>
<td>~140,000 tokens</td>
<td>Heavy usage, large projects</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Auto-Detection Plans</h4><a id="user-content-auto-detection-plans" aria-label="Permalink: Auto-Detection Plans" href="#auto-detection-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>How It Works</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>custom_max</strong></td>
<td>Scans all previous sessions, uses highest token count found</td>
<td>Users with variable/unknown limits</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Smart Detection Features</h3><a id="user-content-smart-detection-features" aria-label="Permalink: Smart Detection Features" href="#smart-detection-features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Automatic Plan Switching</h4><a id="user-content-automatic-plan-switching" aria-label="Permalink: Automatic Plan Switching" href="#automatic-plan-switching"></a></p>
<p dir="auto">When using the default Pro plan:</p>
<ol dir="auto">
<li><strong>Detection</strong>: Monitor notices token usage exceeding 7,000</li>
<li><strong>Analysis</strong>: Scans previous sessions for actual limits</li>
<li><strong>Switch</strong>: Automatically changes to custom_max mode</li>
<li><strong>Notification</strong>: Displays clear message about the change</li>
<li><strong>Continuation</strong>: Keeps monitoring with new, higher limit</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Limit Discovery Process</h4><a id="user-content-limit-discovery-process" aria-label="Permalink: Limit Discovery Process" href="#limit-discovery-process"></a></p>
<p dir="auto">The auto-detection system:</p>
<ol dir="auto">
<li><strong>Scans History</strong>: Examines all available session blocks</li>
<li><strong>Finds Peaks</strong>: Identifies highest token usage achieved</li>
<li><strong>Validates Data</strong>: Ensures data quality and recency</li>
<li><strong>Sets Limits</strong>: Uses discovered maximum as new limit</li>
<li><strong>Learns Patterns</strong>: Adapts to your actual usage capabilities</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Usage Examples</h2><a id="user-content--usage-examples" aria-label="Permalink: 🚀 Usage Examples" href="#-usage-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Common Scenarios</h3><a id="user-content-common-scenarios" aria-label="Permalink: Common Scenarios" href="#common-scenarios"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌅 Morning Developer</h4><a id="user-content--morning-developer" aria-label="Permalink: 🌅 Morning Developer" href="#-morning-developer"></a></p>
<p dir="auto"><strong>Scenario</strong>: You start work at 9 AM and want tokens to reset aligned with your schedule.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Set custom reset time to 9 AM
./ccusage_monitor.py --reset-hour 9

# With your timezone
./ccusage_monitor.py --reset-hour 9 --timezone US/Eastern"><pre><span><span>#</span> Set custom reset time to 9 AM</span>
./ccusage_monitor.py --reset-hour 9

<span><span>#</span> With your timezone</span>
./ccusage_monitor.py --reset-hour 9 --timezone US/Eastern</pre></div>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li>Reset times align with your work schedule</li>
<li>Better planning for daily token allocation</li>
<li>Predictable session windows</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌙 Night Owl Coder</h4><a id="user-content--night-owl-coder" aria-label="Permalink: 🌙 Night Owl Coder" href="#-night-owl-coder"></a></p>
<p dir="auto"><strong>Scenario</strong>: You often work past midnight and need flexible reset scheduling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset at midnight for clean daily boundaries
./ccusage_monitor.py --reset-hour 0

# Late evening reset (11 PM)
./ccusage_monitor.py --reset-hour 23"><pre><span><span>#</span> Reset at midnight for clean daily boundaries</span>
./ccusage_monitor.py --reset-hour 0

<span><span>#</span> Late evening reset (11 PM)</span>
./ccusage_monitor.py --reset-hour 23</pre></div>
<p dir="auto"><strong>Strategy</strong>:</p>
<ul dir="auto">
<li>Plan heavy coding sessions around reset times</li>
<li>Use late resets to span midnight work sessions</li>
<li>Monitor burn rate during peak hours</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔄 Heavy User with Variable Limits</h4><a id="user-content--heavy-user-with-variable-limits" aria-label="Permalink: 🔄 Heavy User with Variable Limits" href="#-heavy-user-with-variable-limits"></a></p>
<p dir="auto"><strong>Scenario</strong>: Your token limits seem to change, and you're not sure of your exact plan.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-detect your highest previous usage
./ccusage_monitor.py --plan custom_max

# Monitor with custom scheduling
./ccusage_monitor.py --plan custom_max --reset-hour 6"><pre><span><span>#</span> Auto-detect your highest previous usage</span>
./ccusage_monitor.py --plan custom_max

<span><span>#</span> Monitor with custom scheduling</span>
./ccusage_monitor.py --plan custom_max --reset-hour 6</pre></div>
<p dir="auto"><strong>Approach</strong>:</p>
<ul dir="auto">
<li>Let auto-detection find your real limits</li>
<li>Monitor for a week to understand patterns</li>
<li>Note when limits change or reset</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌍 International User</h4><a id="user-content--international-user" aria-label="Permalink: 🌍 International User" href="#-international-user"></a></p>
<p dir="auto"><strong>Scenario</strong>: You're working across different timezones or traveling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# US East Coast
./ccusage_monitor.py --timezone America/New_York

# Europe
./ccusage_monitor.py --timezone Europe/London

# Asia Pacific
./ccusage_monitor.py --timezone Asia/Singapore

# UTC for international team coordination
./ccusage_monitor.py --timezone UTC --reset-hour 12"><pre><span><span>#</span> US East Coast</span>
./ccusage_monitor.py --timezone America/New_York

<span><span>#</span> Europe</span>
./ccusage_monitor.py --timezone Europe/London

<span><span>#</span> Asia Pacific</span>
./ccusage_monitor.py --timezone Asia/Singapore

<span><span>#</span> UTC for international team coordination</span>
./ccusage_monitor.py --timezone UTC --reset-hour 12</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">⚡ Quick Check</h4><a id="user-content--quick-check" aria-label="Permalink: ⚡ Quick Check" href="#-quick-check"></a></p>
<p dir="auto"><strong>Scenario</strong>: You just want to see current status without configuration.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Just run it with defaults
./ccusage_monitor.py

# Press Ctrl+C after checking status"><pre><span><span>#</span> Just run it with defaults</span>
./ccusage_monitor.py

<span><span>#</span> Press Ctrl+C after checking status</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Plan Selection Strategies</h3><a id="user-content-plan-selection-strategies" aria-label="Permalink: Plan Selection Strategies" href="#plan-selection-strategies"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How to Choose Your Plan</h4><a id="user-content-how-to-choose-your-plan" aria-label="Permalink: How to Choose Your Plan" href="#how-to-choose-your-plan"></a></p>
<p dir="auto"><strong>Start with Default (Recommended for New Users)</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Pro plan detection with auto-switching
./ccusage_monitor.py"><pre><span><span>#</span> Pro plan detection with auto-switching</span>
./ccusage_monitor.py</pre></div>
<ul dir="auto">
<li>Monitor will detect if you exceed Pro limits</li>
<li>Automatically switches to custom_max if needed</li>
<li>Shows notification when switching occurs</li>
</ul>
<p dir="auto"><strong>Known Subscription Users</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# If you know you have Max5
./ccusage_monitor.py --plan max5

# If you know you have Max20
./ccusage_monitor.py --plan max20"><pre><span><span>#</span> If you know you have Max5</span>
./ccusage_monitor.py --plan max5

<span><span>#</span> If you know you have Max20</span>
./ccusage_monitor.py --plan max20</pre></div>
<p dir="auto"><strong>Unknown Limits</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-detect from previous usage
./ccusage_monitor.py --plan custom_max"><pre><span><span>#</span> Auto-detect from previous usage</span>
./ccusage_monitor.py --plan custom_max</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Best Practices</h3><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Setup Best Practices</h4><a id="user-content-setup-best-practices" aria-label="Permalink: Setup Best Practices" href="#setup-best-practices"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Start Early in Sessions</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Begin monitoring when starting Claude work
./ccusage_monitor.py"><pre><span><span>#</span> Begin monitoring when starting Claude work</span>
./ccusage_monitor.py</pre></div>
<ul dir="auto">
<li>Gives accurate session tracking from the start</li>
<li>Better burn rate calculations</li>
<li>Early warning for limit approaches</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Use Virtual Environment</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Production setup with isolation
python3 -m venv venv
source venv/bin/activate
pip install pytz"><pre><span><span>#</span> Production setup with isolation</span>
python3 -m venv venv
<span>source</span> venv/bin/activate
pip install pytz</pre></div>
<ul dir="auto">
<li>Prevents dependency conflicts</li>
<li>Clean uninstallation</li>
<li>Reproducible environments</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Custom Shell Alias</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add to ~/.bashrc or ~/.zshrc
alias claude-monitor='cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py'"><pre><span><span>#</span> Add to ~/.bashrc or ~/.zshrc</span>
<span>alias</span> claude-monitor=<span><span>'</span>cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py<span>'</span></span></pre></div>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Usage Best Practices</h4><a id="user-content-usage-best-practices" aria-label="Permalink: Usage Best Practices" href="#usage-best-practices"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Monitor Burn Rate Velocity</strong></p>
<ul dir="auto">
<li>Watch for sudden spikes in token consumption</li>
<li>Adjust coding intensity based on remaining time</li>
<li>Plan big refactors around session resets</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Strategic Session Planning</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Plan heavy usage around reset times
./ccusage_monitor.py --reset-hour 9"><pre><span><span>#</span> Plan heavy usage around reset times</span>
./ccusage_monitor.py --reset-hour 9</pre></div>
<ul dir="auto">
<li>Schedule large tasks after resets</li>
<li>Use lighter tasks when approaching limits</li>
<li>Leverage multiple overlapping sessions</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Timezone Awareness</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Always use your actual timezone
./ccusage_monitor.py --timezone Europe/Warsaw"><pre><span><span>#</span> Always use your actual timezone</span>
./ccusage_monitor.py --timezone Europe/Warsaw</pre></div>
<ul dir="auto">
<li>Accurate reset time predictions</li>
<li>Better planning for work schedules</li>
<li>Correct session expiration estimates</li>
</ul>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Optimization Tips</h4><a id="user-content-optimization-tips" aria-label="Permalink: Optimization Tips" href="#optimization-tips"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Terminal Setup</strong></p>
<ul dir="auto">
<li>Use terminals with at least 80 character width</li>
<li>Enable color support for better visual feedback</li>
<li>Consider dedicated terminal window for monitoring</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Workflow Integration</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start monitoring with your development session
tmux new-session -d -s claude-monitor './ccusage_monitor.py'

# Check status anytime
tmux attach -t claude-monitor"><pre><span><span>#</span> Start monitoring with your development session</span>
tmux new-session -d -s claude-monitor <span><span>'</span>./ccusage_monitor.py<span>'</span></span>

<span><span>#</span> Check status anytime</span>
tmux attach -t claude-monitor</pre></div>
</li>
<li>
<p dir="auto"><strong>Multi-Session Strategy</strong></p>
<ul dir="auto">
<li>Remember sessions last exactly 5 hours</li>
<li>You can have multiple overlapping sessions</li>
<li>Plan work across session boundaries</li>
</ul>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Real-World Workflows</h4><a id="user-content-real-world-workflows" aria-label="Permalink: Real-World Workflows" href="#real-world-workflows"></a></p>
<p dir="auto"><strong>Large Project Development</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Setup for sustained development
./ccusage_monitor.py --plan max20 --reset-hour 8 --timezone America/New_York"><pre><span><span>#</span> Setup for sustained development</span>
./ccusage_monitor.py --plan max20 --reset-hour 8 --timezone America/New_York</pre></div>
<p dir="auto"><strong>Daily Routine</strong>:</p>
<ol dir="auto">
<li><strong>8:00 AM</strong>: Fresh tokens, start major features</li>
<li><strong>10:00 AM</strong>: Check burn rate, adjust intensity</li>
<li><strong>12:00 PM</strong>: Monitor for afternoon session planning</li>
<li><strong>2:00 PM</strong>: New session window, tackle complex problems</li>
<li><strong>4:00 PM</strong>: Light tasks, prepare for evening session</li>
</ol>
<p dir="auto"><strong>Learning &amp; Experimentation</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Flexible setup for learning
./ccusage_monitor.py --plan pro"><pre><span><span>#</span> Flexible setup for learning</span>
./ccusage_monitor.py --plan pro</pre></div>
<p dir="auto"><strong>Sprint Development</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# High-intensity development setup
./ccusage_monitor.py --plan max20 --reset-hour 6"><pre><span><span>#</span> High-intensity development setup</span>
./ccusage_monitor.py --plan max20 --reset-hour 6</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📞 Contact</h2><a id="user-content--contact" aria-label="Permalink: 📞 Contact" href="#-contact"></a></p>
<p dir="auto">Have questions, suggestions, or want to collaborate? Feel free to reach out!</p>
<p dir="auto"><strong>📧 Email</strong>: <a href="mailto:maciek@roboblog.eu">maciek@roboblog.eu</a></p>
<p dir="auto">Whether you need help with setup, have feature requests, found a bug, or want to discuss potential improvements, don't hesitate to get in touch. I'm always happy to help and hear from users of the Claude Code Usage Monitor!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Additional Documentation</h2><a id="user-content--additional-documentation" aria-label="Permalink: 📚 Additional Documentation" href="#-additional-documentation"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/DEVELOPMENT.md">Development Roadmap</a></strong> - ML features, PyPI package, Docker plans</li>
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/CONTRIBUTING.md">Contributing Guide</a></strong> - How to contribute, development guidelines</li>
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/TROUBLESHOOTING.md">Troubleshooting</a></strong> - Common issues and solutions</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📝 License</h2><a id="user-content--license" aria-label="Permalink: 📝 License" href="#-license"></a></p>
<p dir="auto"><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/LICENSE">MIT License</a> - feel free to use and modify as needed.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: 🙏 Acknowledgments" href="#-acknowledgments"></a></p>
<p dir="auto">This tool builds upon the excellent <a href="https://github.com/ryoppippi/ccusage">ccusage</a> by <a href="https://github.com/ryoppippi">@ryoppippi</a>, adding a real-time monitoring interface with visual progress bars, burn rate calculations, and predictive analytics.</p>
<hr>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Base44 sells to Wix for $80M cash (119 pts)]]></title>
            <link>https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</link>
            <guid>44316920</guid>
            <pubDate>Thu, 19 Jun 2025 09:31:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/">https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</a>, See on <a href="https://news.ycombinator.com/item?id=44316920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">There’s a lot of talk in the startup world about how AI makes individuals so productive that it could give rise to a generation of <a href="https://www.amazon.com/Single-Handed-Unicorn-Billion-Dollar-Solopreneurs-Business/dp/B0DWSRS62N" target="_blank" rel="noreferrer noopener nofollow">“solo unicorns”</a> — one-person companies worth over $1 billion.</p>

<p>While an actual solo unicorn remains a mythical creature, Israeli developer Maor Shlomo provided compelling evidence Wednesday that the concept might not be impossible.&nbsp;</p>







<p>Shlomo sold his 6-month-old, bootstrapped vibe-coding startup Base44 to Wix for $80 million, Wix <a href="https://www.globenewswire.com/news-release/2025/06/18/3101508/0/en/Wix-Further-Expands-into-Vibe-Coding-with-Acquisition-of-Base44-a-Hyper-Growth-Startup-that-Simplifies-Web-and-App-Creation-with-AI.html" target="_blank" rel="noreferrer noopener nofollow">announced</a> Wednesday. And the deal was cash, Wix confirmed to TechCrunch.&nbsp;</p>

<p>Admittedly, this wasn’t a billion dollars or close to it. And Shlomo wasn’t truly solo — he had eight employees, Wix confirmed. They will collectively receive $25 million of the $80 million as a “retention” bonus. Wix declined to give details on that part of the deal, like how long they have to stay in their jobs to get full payouts.</p>

<p>Still, Base44’s rapid rise and impressive sale price have been the talk of the <a href="https://x.com/benln/status/1935327374079574427" target="_blank" rel="noreferrer noopener nofollow">vibe-coding community</a>.&nbsp;</p>

<p>In its six months as a stand-alone company, Base44 reportedly grew to 250,000 users, hitting 10,000 users within its first three weeks. According to <a href="https://www.linkedin.com/feed/update/urn:li:activity:7336025796509077504/" target="_blank" rel="noreferrer noopener nofollow">Shlomo’s posts</a> on X and LinkedIn, the company was profitable, generating $189,000 in profit in May even after covering high LLM token costs, which he also documented publicly.</p>

<p>Base44 spread mostly through word of mouth as Shlomo, a 31-year-old programmer, shared his building journey on LinkedIn and Twitter. The project began as a side venture, he told <a href="https://www.calcalistech.com/ctechnews/article/s1iflnlelx" target="_blank" rel="noreferrer noopener nofollow">Israeli tech news site CTech</a>.&nbsp;&nbsp;</p>


<p>“Base44 is a moonshot experiment — helping everyone, technical or not, build software without coding at all,” he <a rel="nofollow" href="https://www.linkedin.com/posts/maor-shlomo-1088b4144_excited-to-share-a-project-ive-been-working-activity-7297302969652277252-vcj8?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAEjzLUBg333G2D9H7FJaye0FUkOP4V2yos">explained on LinkedIn</a> when he launched it to the public.</p>

<p>It’s one of the newer crop of vibe-coding products designed for non-programmers. Users enter text prompts, and the platform builds complete applications, with database, storage, authentication, analytics, and integration. It also supports email, texting, and maps, with a roadmap for more enterprise-grade security support.</p>

<p>Base44 isn’t unique in this area. Other vibe coders like <a href="https://techcrunch.com/2025/04/22/adaptive-computer-wants-to-reinvent-the-pc-with-vibe-coding-for-non-programmers/">Adaptive Computer</a> handle similar infrastructure work. But Base44’s fast rise was astounding all the same.</p>







<p>Shlomo was already known in the Israeli startup community through his previous startup, the Insight Partners-backed data analytics company <a href="https://techcrunch.com/2021/05/18/explorium-scores-75m-series-c-just-10-months-after-b-round/">Explorium</a>. His brother is also a co-founder of an <a href="https://techcrunch.com/2025/01/27/hackers-are-targeting-machine-identities-token-security-just-raised-20m-to-stop-them/">AI security startup, Token Security,</a> which just raised $20 million led by Notable Capital (formerly GGV Capital) and a bunch of Israeli tech angels.</p>

<p>He quickly gained partnership agreements  for Base44 with big Israeli tech companies like eToro and Similarweb.</p>

<p>After posting about his decision to use Anthropic’s Claude LLM through AWS instead of models by OpenAI — mostly for cost-per-performance reasons — Amazon invited Base44 to demo at a Tel Aviv AWS event last month, which <a href="https://www.linkedin.com/posts/maor-shlomo-1088b4144_it-was-an-honor-to-present-base44-on-the-activity-7333519004138942464-EVoB/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAEjzLUBg333G2D9H7FJaye0FUkOP4V2yos" target="_blank" rel="noreferrer noopener nofollow">Shlomo documented.</a></p>

<p>“Crazy f***ing journey so far,” Shlomo <a href="https://www.linkedin.com/feed/update/urn:li:activity:7341088575049891840/" target="_blank" rel="noreferrer noopener nofollow">posted on LinkedIn</a> when announcing the news of the acquisition. Despite the growth and the profits — or really because of it — he sold his still-bootstrapped company because “the scale and volume we need is not something we can organically grow into&nbsp;… If we were able to get so far organically, bootstrapped, I’m excited to see our new pace now that we have all the resources in place,” he wrote.</p>

<p>For its part, Wix picked up a proven, fast-growing, local vibe-coding platform for a relative song because of its youth. <a href="https://techcrunch.com/2025/04/22/why-openai-wanted-to-buy-cursor-but-opted-for-the-fast-growing-windsurf/">OpenAI paid $3 billion for Windsurf,</a> which was founded in 2021.&nbsp;</p>

<p>Wix, of course, offers no-code website building that look professionally designed. Adding a profitable LLM vibe-coding product to its offerings is a logical move.</p>

<p>Shlomo could not be immediately reached for additional comment.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From LLM to AI Agent: What's the Real Journey Behind AI System Development? (111 pts)]]></title>
            <link>https://www.codelink.io/blog/post/ai-system-development-llm-rag-ai-workflow-agent</link>
            <guid>44316909</guid>
            <pubDate>Thu, 19 Jun 2025 09:29:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.codelink.io/blog/post/ai-system-development-llm-rag-ai-workflow-agent">https://www.codelink.io/blog/post/ai-system-development-llm-rag-ai-workflow-agent</a>, See on <a href="https://news.ycombinator.com/item?id=44316909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong node="[object Object]">AI agents are a hot topic, but not every AI system needs to be one.</strong></p>
<p>While agents promise autonomy and decision-making power, simpler &amp; more cost-saving solutions better serve many real-world use cases. The key lies in choosing the right architecture for the problem at hand.</p>
<p>In this post, we'll explore recent developments in Large Language Models (LLMs) and discuss key concepts of AI systems.</p>
<p>We've worked with LLMs across projects of varying complexity, from zero-shot prompting to chain-of-thought reasoning, from RAG-based architectures to sophisticated workflows and autonomous agents.</p>
<p>This is an emerging field with evolving terminology. The boundaries between different concepts are still being defined, and classifications remain fluid. As the field progresses, new frameworks and practices emerge to build more reliable AI systems.</p>
<p>To demonstrate these different systems, we'll walk through a familiar use case – a resume-screening application – to reveal the unexpected leaps in capability (and complexity) at each level.</p>
<h2>Pure LLM</h2>
<p>A pure LLM is essentially a lossy compression of the internet, a snapshot of knowledge from its training data. It excels at tasks involving this stored knowledge: summarizing novels, writing essays about global warming, explaining special relativity to a 5-year-old, or composing haikus.</p>
<p>However, without additional capabilities, an LLM cannot provide real-time information like the current temperature in NYC. This distinguishes pure LLMs from chat applications like ChatGPT, which enhance their core LLM with real-time search and additional tools.</p>
<p>That said, not all enhancements require external context. There are several prompting techniques, including in-context learning and few-shot learning that help LLMs tackle specific problems without the need of context retrieval.</p>
<p><strong node="[object Object]">Example:</strong></p>
<ul>
<li>To check if a resume is a good fit for a job description, an LLM with one-shot prompting and in-context learning can be utilized to classify it as Passed or Failed.</li>
</ul>
<p><span><img alt="AI System Development - Workflow-04.png" loading="lazy" width="1280" height="800" decoding="async" data-nimg="1" srcset="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_04_0c8d75b6b4/AI_System_Development_Workflow_04_0c8d75b6b4_1920.webp 1x, https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_04_0c8d75b6b4/AI_System_Development_Workflow_04_0c8d75b6b4_2048.webp 2x" src="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_04_0c8d75b6b4/AI_System_Development_Workflow_04_0c8d75b6b4_2048.webp"></span></p>
<h2>RAG (Retrieval Augmented Generation)</h2>
<p>Retrieval methods enhance LLMs by providing relevant context, making them more current, precise, and practical. You can grant LLMs access to internal data for processing and manipulation. This context allows the LLM to extract information, create summaries, and generate responses. RAG can also incorporate real-time information through the latest data retrieval.</p>
<p><strong node="[object Object]">Example:</strong></p>
<ul>
<li>The resume screening application can be improved by retrieving internal company data, such as engineering playbooks, policies, and past resumes, to enrich the context and make better classification decisions.</li>
<li>Retrieval typically employs tools like vectorization, vector databases, and semantic search.</li>
</ul>
<p><span><img alt="AI System Development - Workflow-03.png" loading="lazy" width="1280" height="800" decoding="async" data-nimg="1" srcset="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_03_11d4779a1d/AI_System_Development_Workflow_03_11d4779a1d_1920.webp 1x, https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_03_11d4779a1d/AI_System_Development_Workflow_03_11d4779a1d_2048.webp 2x" src="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_03_11d4779a1d/AI_System_Development_Workflow_03_11d4779a1d_2048.webp"></span></p>
<h2>Tool Use &amp; AI Workflow</h2>
<p>LLMs can automate business processes by following well-defined paths. They're most effective for consistent, well-structured tasks.</p>
<p>Tool use enables workflow automation. By connecting to APIs, whether for calculators, calendars, email services, or search engines, LLMs can leverage reliable external utilities instead of relying on their internal, non-deterministic capabilities.</p>
<p><strong node="[object Object]">Example:</strong></p>
<ul>
<li>An AI workflow can connect to the hiring portal to fetch resumes and job descriptions → Evaluate qualifications based on experience, education, and skills → Send appropriate email responses (rejection or interview invitation).</li>
<li>For this resume scanning workflow, the LLM requires access to the database, email API, and calendar API. It follows predefined steps to automate the process programmatically.</li>
</ul>
<p><span><img alt="AI System Development - Workflow-02.png" loading="lazy" width="1280" height="800" decoding="async" data-nimg="1" srcset="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_02_db62eff345/AI_System_Development_Workflow_02_db62eff345_1920.webp 1x, https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_02_db62eff345/AI_System_Development_Workflow_02_db62eff345_2048.webp 2x" src="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_02_db62eff345/AI_System_Development_Workflow_02_db62eff345_2048.webp"></span></p>
<h2>AI Agent</h2>
<p>AI Agents are systems that reason and make decisions independently. They break down tasks into steps, use external tools as needed, evaluate results, and determine the following actions: whether to store results, request human input, or proceed to the next step.</p>
<p>This represents another layer of abstraction above tool use &amp; AI workflow, automating both planning and decision-making.</p>
<p>While AI workflows require explicit user triggers (like button clicks) and follow programmatically defined paths, AI Agents can initiate workflows independently and determine their sequence and combination dynamically.</p>
<p><strong node="[object Object]">Example:</strong></p>
<ul>
<li>An AI Agent can manage the entire recruitment process, including parsing CVs, coordinating availability via chat or email, scheduling interviews, and handling schedule changes.</li>
<li>This comprehensive task requires the LLM to access databases, email and calendar APIs, plus chat and notification systems.</li>
</ul>
<p><span><img alt="AI System Development - Workflow-01.png" loading="lazy" width="1280" height="800" decoding="async" data-nimg="1" srcset="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_01_1db45d0f08/AI_System_Development_Workflow_01_1db45d0f08_1920.webp 1x, https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_01_1db45d0f08/AI_System_Development_Workflow_01_1db45d0f08_2048.webp 2x" src="https://www.codelink.io/_next/static/chunks/images/strapi-bucket-production/AI_System_Development_Workflow_01_1db45d0f08/AI_System_Development_Workflow_01_1db45d0f08_2048.webp"></span></p>
<h2>Key takeaway</h2>
<h3>1. Not every system requires an AI agent</h3>
<p>Start with simple, composable patterns and add complexity as needed. For some systems, retrieval alone suffices. In our resume screening example, a straightforward workflow works well when the criteria and actions are clear. Consider an Agent approach only when greater autonomy is needed to reduce human intervention.</p>
<h3>2. Focus on reliability over capability</h3>
<p>The non-deterministic nature of LLMs makes building dependable systems challenging. While creating proofs of concept is quick, scaling to production often reveals complications. Begin with a sandbox environment, implement consistent testing methods, and establish guardrails for reliability.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX Starship 36 Anomaly (268 pts)]]></title>
            <link>https://twitter.com/NASASpaceflight/status/1935548909805601020</link>
            <guid>44315529</guid>
            <pubDate>Thu, 19 Jun 2025 04:49:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/NASASpaceflight/status/1935548909805601020">https://twitter.com/NASASpaceflight/status/1935548909805601020</a>, See on <a href="https://news.ycombinator.com/item?id=44315529">Hacker News</a></p>
Couldn't get https://twitter.com/NASASpaceflight/status/1935548909805601020: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Elliptic Curves as Art (192 pts)]]></title>
            <link>https://elliptic-curves.art/</link>
            <guid>44315321</guid>
            <pubDate>Thu, 19 Jun 2025 04:02:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elliptic-curves.art/">https://elliptic-curves.art/</a>, See on <a href="https://news.ycombinator.com/item?id=44315321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

    

<p>Welcome to the website for our project visualizing elliptic curves.
    Be patient with us, this page is under construction!</p>

    <p> - Nadir Hajouji and Steve Trettel</p>



    <a href="https://elliptic-curves.art/papers/">
        <h2>Papers</h2>
    </a>


        <div>

    <p><img src="https://elliptic-curves.art/papers/bridges/screenshot_hu_94859ba4994302a8.webp">

    </p>

    
  </div>




    <a href="https://elliptic-curves.art/art/">
        <h2>Some Beautiful Illustrations</h2>
    </a>



        
    </div><div>
    <p>
       © 2025 Copyright: Nadir Hajouji &amp; Steve Trettel 
    </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dr. Demento Announces Retirement After 55-Year Radio Career (116 pts)]]></title>
            <link>https://sopghreporter.com/2025/06/01/dr-demento-announces-retirement/</link>
            <guid>44315185</guid>
            <pubDate>Thu, 19 Jun 2025 03:27:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sopghreporter.com/2025/06/01/dr-demento-announces-retirement/">https://sopghreporter.com/2025/06/01/dr-demento-announces-retirement/</a>, See on <a href="https://news.ycombinator.com/item?id=44315185">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
		<main id="main">

			
	

	
			<figure>

				<img width="1200" height="800" src="https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1200x800.jpg" alt="" data-hero-candidate="1" fetchpriority="high" decoding="async" srcset="https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1200x800.jpg 1200w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-300x200.jpg 300w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1024x683.jpg 1024w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-768x512.jpg 768w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1536x1024.jpg 1536w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-2000x1333.jpg 2000w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-780x520.jpg 780w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-400x267.jpg 400w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped.jpg 2048w" sizes="(max-width: 1200px) 100vw, 1200px">			<figcaption><span>Westwood One radio disc jockey, Dr. Demento, (aka Barrett Hanson), 1984. CC-BY 4.0 <span><span>Credit:</span> <a href="https://digital.library.ucla.edu/catalog/ark:/21198/zz0002tppx">Martha Hartnett / Los Angeles Times Photographic Collection</a></span></span></figcaption>
			
			</figure><!-- .post-thumbnail -->

		
				<div>

					

<article id="post-3712">
	<div>

		
		
<p>Radio personality Barret “<strong><a href="https://www.drdemento.com/" target="_blank" rel="noopener">Dr. Demento</a></strong>” Hansen announced his retirement this week, ending a 55-year career devoted to comedy and novelty music when his show concludes in October.</p>



<p>Hansen, 84, revealed the decision during his weekly program, saying the current episode would be his final regular show. The announcement comes as the program approaches its 55th anniversary this fall.</p>



<p><em>The Dr. Demento Show</em> will continue with retrospective episodes through October, culminating in a final broadcast featuring the top 40 songs in the program’s history. Hansen plans to host the remaining episodes, which will chronicle different decades of the show’s run.</p>



<p>Dr. Demento debuted in October 1970 on KPPC Pasadena, California, now known as KROQ-FM. The program initially featured freeform rock before Hansen shifted focus to comedy and novelty music that became his trademark.</p>





<p>The show gained popularity across multiple Los Angeles stations, including a notable run on KMET from 1972 until the station’s closure in 1987. A syndicated version launched in 1974, originally distributed on reel-to-reel tape. Over time, the show reflected changes in audio technology, <a href="https://dmdb.org/images/drddj.html" target="_blank" rel="noopener">syndicating via LPs, cassettes, and CD-Rs</a> until the end of its syndicated run in 2010.</p>



<p>The show then transitioned to an online format with a subscription service. Beginning in 2006, the show offered pay-per-show audio streaming through its official website.</p>



<p>Hansen, who grew up in Minneapolis, was inspired to pursue novelty music after his father brought home Spike Jones’ “Cocktails for Two.” The bells, whistles and chaotic sound effects of the song inspired him to seek similar music, leading him to become an avid collector before and during his radio career. By his own estimates, Hansen has gathered more than 300,000 albums in his Lakewood, CA. library, many from bands seeking airplay. </p>



<p>Dr. Demento introduced audiences to comedy songs, parodies, and musical oddities that traditional radio avoided. Throughout the years, the two most requested songs were Barnes &amp; Barnes’ “Fish Heads” and Bill Fenzer’s “Dead Puppies Aren’t Much Fun,” followed by “Weird Al” Yankovic’s catalog, who Hansen is largely credited for discovering. Rainn Wilson played a fictionalized Dr. Demento in <em>Weird: The Al Yankovic Story</em>.</p>


<div>
<figure><img decoding="async" width="1024" height="683" src="https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1024x683.jpg" alt="" srcset="https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1024x683.jpg 1024w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-300x200.jpg 300w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-768x512.jpg 768w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1536x1025.jpg 1536w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1200x800.jpg 1200w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-2000x1334.jpg 2000w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-780x520.jpg 780w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-400x267.jpg 400w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A few Bootleg Dr. Demento Tapes from the 1980’s. Fans recorded and traded programs to collect and share with friends outside of syndicated areas. <span><span>Credit:</span> Foo Conner / The Pittsburgh Reporter</span></figcaption></figure></div>


<p>The Radio Hall of Fame inducted Dr. Demento (Barret Hansen) in 2009, recognizing his contributions to broadcast entertainment.</p>



<p>The remaining episodes will include decade-by-decade retrospectives and classic show reruns from the 1970s and 1980s. Hansen has scheduled shows featuring his personal favorites and listener requests before the October finale.</p>



<p>Past episodes dating to 1974 are available on the show’s website, along with select archives from the early 1970s. <a href="https://www.drdemento.com/online.html" target="_blank" rel="noopener">Upcoming episodes will be posted</a> as they are produced.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
			<div>
															<p><a href="https://sopghreporter.com/author/foo/" rel="author">
											<img alt="Avatar photo" src="https://sopghreporter.com/wp-content/uploads/2023/12/foo-conner-square-profile-1-80x80.jpg" srcset="https://sopghreporter.com/wp-content/uploads/2023/12/foo-conner-square-profile-1-160x160.jpg 2x" height="80" width="80">											</a></p><div>
					<!-- .author-bio-header -->

											<p>
							Foo, editor of The Pittsburgh Reporter, guides our newsrooms and meets neighbors. He shares heartfelt stories often overlooked.															<a href="https://sopghreporter.com/author/foo/" rel="author">
								More by Foo Conner								</a>
													</p>
					
				</div><!-- .author-bio-text -->

			</div><!-- .author-bio -->
			
</article><!-- #post-${ID} -->
				</div>

			
		</main><!-- #main -->
	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I feel open source has turned into two worlds (103 pts)]]></title>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/OpenSourceTwoWorlds</link>
            <guid>44315179</guid>
            <pubDate>Thu, 19 Jun 2025 03:26:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/OpenSourceTwoWorlds">https://utcc.utoronto.ca/~cks/space/blog/tech/OpenSourceTwoWorlds</a>, See on <a href="https://news.ycombinator.com/item?id=44315179">Hacker News</a></p>
<div id="readability-page-1" class="page">


<p> You're probably reading this page because you've attempted to
access some part of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/space/blog/">my blog (Wandering
Thoughts)</a> or <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/space/">CSpace</a>, the wiki thing it's
part of. Unfortunately whatever you're using to do so has a HTTP
User-Agent header value that is too generic or otherwise excessively
suspicious. Unfortunately, as of early 2025 there's a plague of
high volume crawlers (apparently in part to gather data for LLM
training) that behave like this. To reduce the load on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/space/blog/">Wandering Thoughts</a> I'm experimenting with
(attempting to) block all of them, and you've run into this. </p>

<p> All HTTP User-Agent headers should clearly identify what they
are, and for non-browser user agents, they should identify not just
the software involved but also who specifically is using that software.
An extremely generic value such as "<code>Go-http-client/1.1</code>"
is not something that I consider acceptable any more. </p>

<address>Chris Siebenmann, 2025-02-17</address>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Zed Debugger Is Here (463 pts)]]></title>
            <link>https://zed.dev/blog/debugger</link>
            <guid>44314977</guid>
            <pubDate>Thu, 19 Jun 2025 02:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/debugger">https://zed.dev/blog/debugger</a>, See on <a href="https://news.ycombinator.com/item?id=44314977">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Over 2,000 developers asked, and we delivered.</p>
<p>Debugging in Zed is now a reality—and it's a big leap toward Zed 1.0.</p>
<h2 id="overview"><a href="#overview" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Overview</span></a></h2>
<p>We set out to build a debugger with three primary focuses:</p>
<ul>
<li>Fast: Spend less time context switching and more time debugging</li>
<li>Familiar: In line with Zed's design language and supports everything expected from a typical debugger flow</li>
<li>Configurable: You're able to customize the UI, keybindings, debug configurations and more</li>
</ul>
<p>Out of the box, Zed supports debugging popular languages including Rust, C/C++, JavaScript, Go, and Python.
With our extension system, Zed can support any debug adapter that implements the <a href="https://microsoft.github.io/debug-adapter-protocol/">Debug Adapter Protocol (DAP)</a>.</p>
<p>To simplify the setup process, we've introduced locators, a system that translates build configurations into debug configurations. Meaning that you can write a build task once in <code>tasks.json</code> and reference it from <code>debug.json</code> — or, even better, rely on Zed's automatic configuration.</p>
<p>Zed automatically runs locators on built-in or language server-generated runnables, so in many cases you won't even need to write a debug configuration to get up and running.</p>
<p>We currently support locators for Cargo, Python, JavaScript, and Go, with more coming in the future.
For more information on configuring a debug session, <a href="https://zed.dev/docs/debugger">see our documentation</a>.</p>
<p>Once in a debug session, Zed makes it easy to inspect your program's state, such as threads, variables, breakpoints, the call stack, and more.</p>
<p><figure><video src="https://customer-snccc0j9v3kfzkif.cloudflarestream.com/fd34bd93b1ec8d7c5554daf0ffdb909e/downloads/default.mp4" width="3280" height="2160" poster="https://zed.dev/img/debugger/zero-setup-poster.webp" controls=""></video><figcaption>Setting some breakpoints and running the test in a debug session.</figcaption></figure></p>
<p>The debugger panel is fully customizable too, just drag and rearrange tabs in whatever order you want; you can even move the debug panel around so it fits your workflow.</p>
<p>Zed also supports keyboard-driven debugging for users that prefer to keep their hands on the keyboard.
You can step through code, toggle breakpoints, and navigate a debug session without ever touching the mouse.</p>
<p><figure><video src="https://customer-snccc0j9v3kfzkif.cloudflarestream.com/642d476eeaab0423087c9c19aab53828/downloads/default.mp4" width="3280" height="2160" poster="https://zed.dev/img/debugger/keyboard-poster.webp" controls=""></video><figcaption>Navigating through the Debugger surfaces using only the keyboard.</figcaption></figure></p>
<h2 id="a-special-thanks"><a href="#a-special-thanks" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>A Special Thanks</span></a></h2>
<p>The debugger started as a community-led project with some impressive stats: <a href="https://github.com/zed-industries/zed/pull/13433/commits">8 months of development, 977 commits, and 25k+ lines of code</a>. The community built the core foundation that made today’s launch possible.</p>
<p>Special thanks to <a href="https://github.com/RemcoSmitsDev">Remco Smits</a> for driving a lot of the heavy lifting on this project—your contributions have been critical to getting us here.</p>
<h2 id="under-the-hood"><a href="#under-the-hood" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Under the Hood</span></a></h2>
<p>Zed's debugger supports debugging a variety of languages through the Debug Adapter Protocol.
But simply implementing the protocol wasn't enough—we needed an architecture that could scale to collaborative debugging, support extensions, and efficiently cache and manage responses from debug adapters.</p>
<p>To achieve this, we built a two-layer architecture: a data layer that communicates directly with the debug adapters, and a UI layer that fetches data from the data layer to render the interface.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="rust" data-theme="dark-plus light-plus"><span data-line=""><span>/// All functions are cheap to call, as they grab current state of the debug session and schedule refreshing on a background</span></span>
<span data-line=""><span>/// thread if that state is outdated.</span></span>
<span data-line=""><span>pub</span><span> fn</span><span> modules</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> Context</span><span>&lt;</span><span>Self</span><span>&gt;) -&gt; &amp;[</span><span>Module</span><span>] {</span></span>
<span data-line=""><span>    /// Kick off a fresh request to a DAP for modules list if we don't have an up-to-date state.</span></span>
<span data-line=""><span>    /// This is a no-op in case we've ran that request already. In case we did not, it kicks off a background task.</span></span>
<span data-line=""><span>    self</span><span>.</span><span>fetch</span><span>(</span></span>
<span data-line=""><span>        /// We cache request results based on it's arguments. `Modules` request does not take any arguments</span></span>
<span data-line=""><span>        dap_command</span><span>::</span><span>ModulesCommand</span><span>,</span></span>
<span data-line=""><span>        /// Callback invoked with the result of a request.</span></span>
<span data-line=""><span>        |</span><span>this</span><span>, </span><span>result</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            let</span><span> Some</span><span>(</span><span>result</span><span>) = </span><span>result</span><span>.</span><span>log_err</span><span>() </span><span>else</span><span> {</span></span>
<span data-line=""><span>                return</span><span>;</span></span>
<span data-line=""><span>            };</span></span>
<span data-line=""> </span>
<span data-line=""><span>            this</span><span>.modules = </span><span>result</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>emit</span><span>(</span><span>SessionEvent</span><span>::</span><span>Modules</span><span>);</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>        },</span></span>
<span data-line=""><span>        cx</span><span>,</span></span>
<span data-line=""><span>    );</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Returns a current list of modules; it might be outdated at the time the new request is underway,</span></span>
<span data-line=""><span>    /// but once it is done, the return value of this function will reflect that.</span></span>
<span data-line=""><span>    &amp;</span><span>self</span><span>.modules</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="rust" data-theme="dark-plus light-plus"><span data-line=""><span>/// This function is called from the Module list render function in the UI layer whenever the data layer invalidates the module list state.</span></span>
<span data-line=""><span>fn</span><span> schedule_rebuild</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> Context</span><span>&lt;</span><span>Self</span><span>&gt;) {</span></span>
<span data-line=""><span>    /// Setting the task drops any current work in progress that is out of date</span></span>
<span data-line=""><span>    self</span><span>._rebuild_task = </span><span>Some</span><span>(</span><span>cx</span><span>.</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>        this</span><span>.</span><span>update</span><span>(</span><span>cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            /// The UI layer queries the data layer for modules and clones the data</span></span>
<span data-line=""><span>            let</span><span> modules</span><span> = </span><span>this</span></span>
<span data-line=""><span>                .session</span></span>
<span data-line=""><span>                .</span><span>update</span><span>(</span><span>cx</span><span>, |</span><span>session</span><span>, </span><span>cx</span><span>| </span><span>session</span><span>.</span><span>modules</span><span>(</span><span>cx</span><span>).</span><span>to_owned</span><span>());</span></span>
<span data-line=""><span>            this</span><span>.entries = </span><span>modules</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>        })</span></span>
<span data-line=""><span>        .</span><span>ok</span><span>();</span></span>
<span data-line=""><span>    }));</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>This separation means the UI layer only requests what it needs, allowing the data layer to lazily fetch information and avoid unnecessary requests.
It also makes the data layer solely responsible for maintaining session state, caching responses, and invalidating stale data.
This architecture will make implementing collaborative debugging significantly easier, since the same UI code can be reused across multiplayer sessions—and we only send essential data across the wire, preserving bandwidth.</p>
<p>Supporting every debug adapter out of the box wasn't feasible—there are over <a href="https://microsoft.github.io/debug-adapter-protocol/implementors/adapters/">70 DAP implementations</a>, each with its own quirks.
To solve this, we <a href="https://zed.dev/docs/extensions/debugger-extensions">extended</a> Zed's extension API to support debugger integration.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="rust" data-theme="dark-plus light-plus"><span data-line=""><span>    /// Returns the debug adapter binary for the specified adapter name and configuration.</span></span>
<span data-line=""><span>    fn</span><span> get_dap_binary</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _adapter_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _config</span><span>: </span><span>DebugTaskDefinition</span><span>,</span></span>
<span data-line=""><span>        _user_provided_debug_adapter_path</span><span>: </span><span>Option</span><span>&lt;</span><span>String</span><span>&gt;,</span></span>
<span data-line=""><span>        _worktree</span><span>: &amp;</span><span>Worktree</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Result</span><span>&lt;</span><span>DebugAdapterBinary</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`get_dap_binary` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Determines whether the specified adapter configuration should *launch* a new debuggee process</span></span>
<span data-line=""><span>    /// or *attach* to an existing one. This function should not perform any further validation (outside of determining the kind of a request).</span></span>
<span data-line=""><span>    /// This function should return an error when the kind cannot be determined (rather than fall back to a known default).</span></span>
<span data-line=""><span>    fn</span><span> dap_request_kind</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _adapter_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _config</span><span>: </span><span>serde_json</span><span>::</span><span>Value</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Result</span><span>&lt;</span><span>StartDebuggingRequestArgumentsRequest</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`dap_request_kind` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    /// Converts a high-level definition of a debug scenario (originating in a new session UI) to a "low-level" configuration suitable for a particular adapter.</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// In layman's terms: given a program, list of arguments, current working directory and environment variables,</span></span>
<span data-line=""><span>    /// create a configuration that can be used to start a debug session.</span></span>
<span data-line=""><span>    fn</span><span> dap_config_to_scenario</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>_config</span><span>: </span><span>DebugConfig</span><span>) -&gt; </span><span>Result</span><span>&lt;</span><span>DebugScenario</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`dap_config_to_scenario` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Locators are entities that convert a Zed task into a debug scenario.</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// They can be provided even by extensions that don't provide a debug adapter.</span></span>
<span data-line=""><span>    /// For all tasks applicable to a given buffer, Zed will query all locators to find one that can turn the task into a debug scenario.</span></span>
<span data-line=""><span>    /// A converted debug scenario can include a build task (it shouldn't contain any configuration in such case); a build task result will later</span></span>
<span data-line=""><span>    /// be resolved with [`Extension::run_dap_locator`].</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// To work through a real-world example, take a `cargo run` task and a hypothetical `cargo` locator:</span></span>
<span data-line=""><span>    /// 1. We may need to modify the task; in this case, it is problematic that `cargo run` spawns a binary. We should turn `cargo run` into a debug scenario with</span></span>
<span data-line=""><span>    /// `cargo build` task. This is the decision we make at `dap_locator_create_scenario` scope.</span></span>
<span data-line=""><span>    /// 2. Then, after the build task finishes, we will run `run_dap_locator` of the locator that produced the build task to find the program to be debugged. This function</span></span>
<span data-line=""><span>    /// should give us a debugger-agnostic configuration for launching a debug target (that we end up resolving with [`Extension::dap_config_to_scenario`]). It's almost as if the user</span></span>
<span data-line=""><span>    /// found the artifact path by themselves.</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// Note that you're not obliged to use build tasks with locators. Specifically, it is sufficient to provide a debug configuration directly in the return value of</span></span>
<span data-line=""><span>    /// `dap_locator_create_scenario` if you're able to do that. Make sure to not fill out `build` field in that case, as that will prevent Zed from running second phase of resolution in such case.</span></span>
<span data-line=""><span>    /// This might be of particular relevance to interpreted languages.</span></span>
<span data-line=""><span>    fn</span><span> dap_locator_create_scenario</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _locator_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _build_task</span><span>: </span><span>TaskTemplate</span><span>,</span></span>
<span data-line=""><span>        _resolved_label</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _debug_adapter_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Option</span><span>&lt;</span><span>DebugScenario</span><span>&gt; {</span></span>
<span data-line=""><span>        None</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Runs the second phase of locator resolution.</span></span>
<span data-line=""><span>    /// See [`Extension::dap_locator_create_scenario`] for a hefty comment on locators.</span></span>
<span data-line=""><span>    fn</span><span> run_dap_locator</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _locator_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _build_task</span><span>: </span><span>TaskTemplate</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Result</span><span>&lt;</span><span>DebugRequest</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`run_dap_locator` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span></code></pre></div></figure>
<p>Adding DAP support via an extension involves defining a custom schema that integrates with our JSON server, implementing logic for downloading and launching the adapter, processing debug configuration to add sane default values, and integrating with locators for automatic configuration.
This design follows our approach to LSP extensions, giving extension authors full control to bring their own debug adapters to Zed with minimal friction.</p>
<p>We also wanted inline variable values to work out of the box.
Surprisingly, the <a href="https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textDocument_inlineValue">inline values request</a> is a part of the <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol (LSP)</a> instead of the DAP.
Using the inline values approach would limit Zed to only showing inline values for DAPs which integrate with LSPs, which isn't many.
A naive workaround might be to use regular expressions to match variable names between the source code and debugger values, but that quickly breaks down when dealing with scopes, and comments.
Instead, we turned to <a href="https://tree-sitter.github.io/tree-sitter/">Tree-sitter</a>. After all Zed is built by the creators of Tree-sitter!</p>
<div><figure><img src="https://zed.dev/img/debugger/inline-values.webp" alt="An inline value example."><figcaption>An inline value example.</figcaption></figure></div>
<p>Through Tree-sitter queries, we can accurately identify variables within the current execution scope, and easily support any language through <code>.scm</code> files without relying on an LSP server to be tightly integrated with a debug adapter.
At launch, inline values are supported for Python, Rust, and Go.
More languages will be supported in the coming weeks.</p>
<h2 id="whats-next"><a href="#whats-next" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>What's Next</span></a></h2>
<p>When we set out to build the debugger, we wanted to make it seamless to use, out of the way, and in line with Zed's high standard of quality.
Now that we've built a strong foundation that is compatible with any debug adapter, we're ready to explore and implement advanced features such as:</p>
<ul>
<li>New views: While we support all the fundamental views, we're planning on adding more advanced views such as a watch list, memory view, disassembly view, and a stack trace view</li>
<li>Automatic configuration: We're going to add support for more languages and build systems</li>
<li>Polish and more: reach out to us <a href="https://discord.com/invite/qSDQ8VWc7k">on Discord</a> or <a href="https://github.com/zed-industries/zed/issues">on Zed's GitHub repo</a> to let us know!</li>
</ul><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TI to invest $60B to manufacture foundational semiconductors in the U.S. (265 pts)]]></title>
            <link>https://www.ti.com/about-ti/newsroom/news-releases/2025/texas-instruments-plans-to-invest-more-than--60-billion-to-manufacture-billions-of-foundational-semiconductors-in-the-us.html</link>
            <guid>44314759</guid>
            <pubDate>Thu, 19 Jun 2025 01:50:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ti.com/about-ti/newsroom/news-releases/2025/texas-instruments-plans-to-invest-more-than--60-billion-to-manufacture-billions-of-foundational-semiconductors-in-the-us.html">https://www.ti.com/about-ti/newsroom/news-releases/2025/texas-instruments-plans-to-invest-more-than--60-billion-to-manufacture-billions-of-foundational-semiconductors-in-the-us.html</a>, See on <a href="https://news.ycombinator.com/item?id=44314759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-lid="richText_218e"><p><b>NEWS HIGHLIGHTS:</b></p>
<ul>
<li>More than $60 billion investment includes seven U.S. semiconductor fabs across three manufacturing mega-sites in Texas and Utah supporting more than 60,000 new U.S. jobs</li>
<li>Largest investment in foundational semiconductor manufacturing in&nbsp;U.S.&nbsp;history, building on TI’s almost-100-year legacy</li>
<li>TI’s largest mega-site in Sherman, Texas includes investment of up to $40 billion dollars for four fabs: SM1 and SM2 – already underway – and two additional fabs, SM3 and SM4</li>
<li>Leverages TI’s strengths as a global technology and manufacturing leader to advance critical innovations from vehicles to smartphones to data centers</li>
</ul>
<p><b>DALLAS, </b>June 18, 2025 – Texas Instruments (TI) (Nasdaq: TXN) today announced its plans to invest more than $60 billion across seven U.S. semiconductor fabs, making this the largest investment in foundational semiconductor manufacturing in U.S. history. Working with the Trump administration and building on the company’s nearly 100-year legacy, TI is expanding its U.S. manufacturing capacity to supply the growing need for semiconductors that will advance critical innovations from vehicles to smartphones to data centers. Combined, TI’s new manufacturing mega-sites in Texas and Utah will support more than 60,000 U.S. jobs.</p>
<p>“TI is building dependable, low-cost 300mm capacity at scale to deliver the analog and embedded processing chips that are vital for nearly every type of electronic system,” said Haviv Ilan, president and CEO of Texas Instruments. “Leading U.S. companies such as Apple, Ford, Medtronic, NVIDIA and SpaceX rely on TI’s world-class technology and manufacturing expertise, and we are honored to work alongside them and the U.S. government to unleash what’s next in American innovation.”</p>
<p>“For nearly a century, Texas Instruments has been a bedrock American company driving innovation in technology and manufacturing,” said U.S. Secretary of Commerce, Howard Lutnick. “President Trump has made it a priority to increase semiconductor manufacturing in America – including these foundational semiconductors that go into the electronics that people use every day. Our partnership with TI will support U.S. chip manufacturing for decades to come.”</p>
</div><div data-lid="richText_402c"><p><b>Unleashing what’s next in American innovation</b></p>
<p>Today, TI is the largest foundational semiconductor manufacturer in the U.S., producing analog and embedded processing chips that are critical for smartphones, vehicles, data centers, satellites and nearly every other electronic device. In order to meet the steadily growing demand for these essential chips, TI is building on its legacy of technology leadership and expanding its U.S. manufacturing presence to help its customers pioneer the next wave of technological breakthroughs.</p>
<p><b>Igniting intelligence with Apple</b></p>
<p>“Texas Instruments' American-made chips help bring Apple products to life, and together, we’ll continue to create opportunity, drive innovation, and invest in the future of advanced manufacturing across the U.S.,” said Apple’s CEO Tim Cook.</p>
<p><b>Fueling the future with Ford</b></p>
<p>Ford and TI are working to strengthen American manufacturing, combining Ford’s automotive expertise with TI’s semiconductor technology to help drive innovation and secure a robust, domestic supply chain for the future of mobility. “At Ford, 80% of the vehicles we sell in the U.S. are assembled in the U.S., and we are proud to stand with technology leaders like TI that continue to invest in manufacturing in the U.S.,” said Jim Farley, President and CEO of Ford Motor Company.</p>
<p><b>Connecting patient care with Medtronic</b></p>
<p>Medtronic and TI are partnering to improve lives when it matters most. “At Medtronic, our life-saving medical technologies rely on semiconductors to deliver precision, performance, and innovation at scale,” said Geoff Martha, Medtronic chairman and CEO. “Texas Instruments has been a vital partner – especially during the global chip shortages – helping us maintain supply continuity and accelerate the development of breakthrough therapies. We’re proud to leverage TI’s U.S.-manufactured semiconductors as we work to transform healthcare and improve outcomes for patients around the world.”</p>
<p><b>Advancing AI with NVIDIA</b></p>
<p>NVIDIA is partnering with TI to unleash the next generation of artificial intelligence architectures. “NVIDIA and TI share the goal to revitalize U.S. manufacturing by building more of the infrastructure for AI factories here in the U.S.,” said Jensen Huang, founder and CEO of NVIDIA. “We look forward to continuing our collaboration with TI by developing products for advanced AI infrastructure.”</p>
<p><b>Securing high-speed satellite internet with SpaceX</b></p>
<p>SpaceX is increasingly leveraging TI’s high-speed process technology to connect its Starlink satellite internet service with TI’s latest 300mm SiGe technology manufactured in Sherman, Texas. “Our fundamental mission is to revolutionize global connectivity and eliminate the digital divide. Core to this mission is constantly pushing the boundaries of what is possible,” said Gwynne Shotwell, president and COO of SpaceX. “SpaceX is manufacturing tens of thousands of Starlink kits a day – all right here in the U.S. – and we are making huge investments in PCB manufacturing and silicon packaging to expand even further. TI’s U.S.-made semiconductors are crucial for securing a U.S. supply chain for our products, and their advanced silicon manufacturing capabilities provide the performance and reliability needed to help us meet the growing demand for high-speed internet all around the world.”</p>
</div><div data-lid="richText_8687"><p><b>Backed by the strength of TI’s U.S. manufacturing presence</b></p>
<p>TI is a driving force behind the return and expansion of semiconductor manufacturing in the U.S. The company’s more than $60 billion investment in U.S. manufacturing includes building and ramping seven, large-scale, connected fabs. Combined, these fabs across three manufacturing mega-sites in Texas and Utah will manufacture hundreds of millions of U.S.-made chips daily that will ignite a bold new chapter in American innovation.</p>
<ul>
<li><b>Sherman, Texas: </b>SM1, TI’s first new fab in Sherman will begin initial production this year, just three years after breaking ground. Construction is also complete on the exterior shell of SM2, TI’s second new fab in Sherman. Incremental investment plans include two additional fabs, SM3 and SM4, to support future demand.</li>
<li><b>Richardson, Texas:</b> TI’s second fab in Richardson, RFAB2, continues to ramp to full production and builds on the company’s legacy of introducing the world’s first 300mm analog fab, RFAB1, in 2011.</li>
<li><b>Lehi, Utah: </b>TI is ramping LFAB1, the company’s first 300mm wafer fab in Lehi. Construction is also well underway on LFAB2, TI’s second Lehi fab that will connect to LFAB1.</li>
</ul>
<p><b>Learn more</b></p>
<ul>
<li><a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/ti-invests-60-billion-in-us-manufacturing.html">Press kit</a> (includes images, video b-roll and fact sheet)</li>
<li>Additional press kits (<a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/sherman-texas-press-kit.html">Sherman, Texas</a>, <a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/lehi-utah-press-kit.html">Lehi, Utah</a>, and <a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/richardson-texas-press-kit.html">Richardson, Texas</a>)</li>
</ul>
<p><b>About Texas Instruments</b></p>
<p>Texas Instruments Incorporated (Nasdaq: TXN) is a global semiconductor company that designs, manufactures, and sells analog and embedded processing chips for markets such as industrial, automotive, personal electronics, communications equipment and enterprise systems. At our core, we have a passion to create a better world by making electronics more affordable through semiconductors. This passion is alive today as each generation of innovation builds upon the last to make our technology more reliable, more affordable and lower power, making it possible for semiconductors to go into electronics everywhere. Learn more at&nbsp;<a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=4167832-1&amp;h=2361819976&amp;u=https%3A%2F%2Fc212.net%2Fc%2Flink%2F%3Ft%3D0%26l%3Den%26o%3D2849181-1%26h%3D2359332189%26u%3Dhttp%253A%252F%252Fwww.ti.com%252F%26a%3DTI.com&amp;a=TI.com">TI.com</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Andrej Karpathy: Software in the era of AI [video] (1046 pts)]]></title>
            <link>https://www.youtube.com/watch?v=LCEmiRjPEtQ</link>
            <guid>44314423</guid>
            <pubDate>Thu, 19 Jun 2025 00:33:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">https://www.youtube.com/watch?v=LCEmiRjPEtQ</a>, See on <a href="https://news.ycombinator.com/item?id=44314423">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[MCP Specification – version 2025-06-18 changes (173 pts)]]></title>
            <link>https://modelcontextprotocol.io/specification/2025-06-18/changelog</link>
            <guid>44314289</guid>
            <pubDate>Wed, 18 Jun 2025 23:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modelcontextprotocol.io/specification/2025-06-18/changelog">https://modelcontextprotocol.io/specification/2025-06-18/changelog</a>, See on <a href="https://news.ycombinator.com/item?id=44314289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><span></span><div id="content-container"><div id="content-area">
<p>This document lists changes made to the Model Context Protocol (MCP) specification since
the previous revision, <a href="https://modelcontextprotocol.io/specification/2025-03-26">2025-03-26</a>.</p>
<h2 id="major-changes"><span>Major changes</span></h2>
<ol>
<li>Remove support for JSON-RPC <strong><a href="https://www.jsonrpc.org/specification#batch" target="_blank" rel="noreferrer">batching</a></strong>
(PR <a href="https://github.com/modelcontextprotocol/specification/pull/416" target="_blank" rel="noreferrer">#416</a>)</li>
<li>Add support for <a href="https://modelcontextprotocol.io/specification/2025-06-18/server/tools#structured-content">structured tool output</a>
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/371" target="_blank" rel="noreferrer">#371</a>)</li>
<li>Classify MCP servers as <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization#authorization-server-discovery">OAuth Resource Servers</a>,
adding protected resource metadata to discover the corresponding Authorization server.
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/338" target="_blank" rel="noreferrer">#338</a>)</li>
<li>Require MCP clients to implement Resource Indicators as described in <a href="https://www.rfc-editor.org/rfc/rfc8707.html" target="_blank" rel="noreferrer">RFC 8707</a> to prevent
malicious servers from obtaining access tokens.
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/734" target="_blank" rel="noreferrer">#734</a>)</li>
<li>Clarify <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization#security-considerations">security considerations</a> and best practices
in the authorization spec and in a new <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices">security best practices page</a>.</li>
<li>Add support for <strong><a href="https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation">elicitation</a></strong>, enabling servers to request additional
information from users during interactions.
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/382" target="_blank" rel="noreferrer">#382</a>)</li>
<li>Add support for <strong><a href="https://modelcontextprotocol.io/specification/2025-06-18/server/tools#resource-links">resource links</a></strong> in
tool call results. (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/603" target="_blank" rel="noreferrer">#603</a>)</li>
<li>Require <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#protocol-version-header">negotiated protocol version to be specified</a>
via <code>MCP-Protocol-Version</code> header in subsequent requests when using HTTP (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/548" target="_blank" rel="noreferrer">#548</a>).</li>
<li>Change <strong>SHOULD</strong> to <strong>MUST</strong> in <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/lifecycle#operation">Lifecycle Operation</a></li>
</ol>
<h2 id="other-schema-changes"><span>Other schema changes</span></h2>
<ol>
<li>Add <code>_meta</code> field to additional interface types (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/710" target="_blank" rel="noreferrer">#710</a>),
and specify <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic#meta">proper usage</a>.</li>
<li>Add <code>context</code> field to <code>CompletionRequest</code>, providing for completion requests to include
previously-resolved variables (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/598" target="_blank" rel="noreferrer">#598</a>).</li>
<li>Add <code>title</code> field for human-friendly display names, so that <code>name</code> can be used as a programmatic
identifier (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/663" target="_blank" rel="noreferrer">#663</a>)</li>
</ol>
<h2 id="full-changelog"><span>Full changelog</span></h2>
<p>For a complete list of all changes that have been made since the last protocol revision,
<a href="https://github.com/modelcontextprotocol/specification/compare/2025-03-26...2025-06-18" target="_blank" rel="noreferrer">see GitHub</a>.</p></div><div id="content-side-layout"><ul id="table-of-contents-content"><li data-depth="0"><a href="#major-changes">Major changes</a></li><li data-depth="0"><a href="#other-schema-changes">Other schema changes</a></li><li data-depth="0"><a href="#full-changelog">Full changelog</a></li></ul></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Unregistry – "docker push" directly to servers without a registry (605 pts)]]></title>
            <link>https://github.com/psviderski/unregistry</link>
            <guid>44314085</guid>
            <pubDate>Wed, 18 Jun 2025 23:17:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/psviderski/unregistry">https://github.com/psviderski/unregistry</a>, See on <a href="https://news.ycombinator.com/item?id=44314085">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/psviderski/unregistry/blob/main/.github/images/logo-light.svg#gh-light-mode-only"><img src="https://github.com/psviderski/unregistry/raw/main/.github/images/logo-light.svg#gh-light-mode-only" alt="Unregistry logo"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/psviderski/unregistry/blob/main/.github/images/logo-dark.svg#gh-dark-mode-only"><img src="https://github.com/psviderski/unregistry/raw/main/.github/images/logo-dark.svg#gh-dark-mode-only" alt="Unregistry logo"></a></p><p dir="auto"><strong>▸ Push docker images directly to remote servers without an external registry ◂</strong></p>
  <p dir="auto">
    <a href="https://discord.gg/eR35KQJhPu" rel="nofollow"><img src="https://camo.githubusercontent.com/bce982f6fd064725216dd2c5bbfc5fa12afeaee92ae5d356ea3f5abf78d0ad88/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d3538363546322e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Join Discord" data-canonical-src="https://img.shields.io/badge/discord-5865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white"></a>
    <a href="https://x.com/psviderski" rel="nofollow"><img src="https://camo.githubusercontent.com/7ef3b84c3487de0b84ead3bc3ac609c4cbaa26f231976bbdf4e56b855dfaf42d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666f6c6c6f772d626c61636b3f7374796c653d666f722d7468652d6261646765266c6f676f3d58266c6f676f436f6c6f723d7768696c65" alt="Follow on X" data-canonical-src="https://img.shields.io/badge/follow-black?style=for-the-badge&amp;logo=X&amp;logoColor=while"></a>
  </p>
</div>
<p dir="auto">Unregistry is a lightweight container image registry that stores and serves images directly from your Docker daemon's
storage.</p>
<p dir="auto">The included <code>docker pussh</code> command (extra 's' for SSH) lets you push images straight to remote Docker servers over SSH.
It transfers only the missing layers, making it fast and efficient.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description docker-pussh-demo.mp4">docker-pussh-demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/783910/456396282-9d704b87-8e0d-4c8a-9544-17d4c63bd050.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAyOTY5MDEsIm5iZiI6MTc1MDI5NjYwMSwicGF0aCI6Ii83ODM5MTAvNDU2Mzk2MjgyLTlkNzA0Yjg3LThlMGQtNGM4YS05NTQ0LTE3ZDRjNjNiZDA1MC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NWQzNjViYWFlNTI3MjA0MTgxOTUyZWZiMDc5NTkxMThmMjM2MjQwNDI3MWU3ZDc1YTg0NGRmMjcyNTFmYWNiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.kp-WEQJdsYOZa8e8DyU8_JbguC9jt8GXLWSwGsF4o4k" data-canonical-src="https://private-user-images.githubusercontent.com/783910/456396282-9d704b87-8e0d-4c8a-9544-17d4c63bd050.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAyOTY5MDEsIm5iZiI6MTc1MDI5NjYwMSwicGF0aCI6Ii83ODM5MTAvNDU2Mzk2MjgyLTlkNzA0Yjg3LThlMGQtNGM4YS05NTQ0LTE3ZDRjNjNiZDA1MC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NWQzNjViYWFlNTI3MjA0MTgxOTUyZWZiMDc5NTkxMThmMjM2MjQwNDI3MWU3ZDc1YTg0NGRmMjcyNTFmYWNiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.kp-WEQJdsYOZa8e8DyU8_JbguC9jt8GXLWSwGsF4o4k" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">The problem</h2><a id="user-content-the-problem" aria-label="Permalink: The problem" href="#the-problem"></a></p>
<p dir="auto">You've built a Docker image locally. Now you need it on your server. Your options suck:</p>
<ul dir="auto">
<li><strong>Docker Hub / GitHub Container Registry</strong> - Your code is now public, or you're paying for private repos</li>
<li><strong>Self-hosted registry</strong> - Another service to maintain, secure, and pay for storage</li>
<li><strong>Save/Load</strong> - <code>docker save | ssh | docker load</code> transfers the entire image, even if 90% already exists on the server</li>
<li><strong>Rebuild remotely</strong> - Wastes time and server resources. Plus now you're debugging why the build fails in production</li>
</ul>
<p dir="auto">You just want to move an image from A to B. Why is this so hard?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The solution</h2><a id="user-content-the-solution" aria-label="Permalink: The solution" href="#the-solution"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server"><pre>docker pussh myapp:latest user@server</pre></div>
<p dir="auto">That's it. Your image is on the remote server. No registry setup, no subscription, no intermediate storage, no
exposed ports. Just a <strong>direct transfer</strong> of the <strong>missing layers</strong> over SSH.</p>
<p dir="auto">Here's what happens under the hood:</p>
<ol dir="auto">
<li>Establishes SSH tunnel to the remote server</li>
<li>Starts a temporary unregistry container</li>
<li>Forwards a random localhost port to the unregistry port over the tunnel</li>
<li><code>docker push</code> to unregistry through the forwarded port, transferring only the layers that don't already exist
remotely. The transferred image is instantly available on the remote Docker daemon</li>
<li>Stops the unregistry container and closes the SSH tunnel</li>
</ol>
<p dir="auto">It's like <code>rsync</code> for Docker images — simple and efficient.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Unregistry was created for <a href="https://github.com/psviderski/uncloud">Uncloud</a>, a lightweight tool for deploying
containers across multiple Docker hosts. We needed something simpler than a full registry but more efficient than
save/load.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS/Linux via Homebrew</h3><a id="user-content-macoslinux-via-homebrew" aria-label="Permalink: macOS/Linux via Homebrew" href="#macoslinux-via-homebrew"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install psviderski/tap/docker-pussh"><pre>brew install psviderski/tap/docker-pussh</pre></div>
<p dir="auto">After installation, to use <code>docker-pussh</code> as a Docker CLI plugin (<code>docker pussh</code> command) you need to create a symlink:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir -p ~/.docker/cli-plugins
ln -sf $(brew --prefix)/bin/docker-pussh ~/.docker/cli-plugins/docker-pussh"><pre>mkdir -p <span>~</span>/.docker/cli-plugins
ln -sf <span><span>$(</span>brew --prefix<span>)</span></span>/bin/docker-pussh <span>~</span>/.docker/cli-plugins/docker-pussh</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS/Linux via direct download</h3><a id="user-content-macoslinux-via-direct-download" aria-label="Permalink: macOS/Linux via direct download" href="#macoslinux-via-direct-download"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the latest version
curl -sSL https://raw.githubusercontent.com/psviderski/unregistry/main/docker-pussh \
  -o ~/.docker/cli-plugins/docker-pussh

# Make it executable
chmod +x ~/.docker/cli-plugins/docker-pussh"><pre><span><span>#</span> Download the latest version</span>
curl -sSL https://raw.githubusercontent.com/psviderski/unregistry/main/docker-pussh \
  -o <span>~</span>/.docker/cli-plugins/docker-pussh

<span><span>#</span> Make it executable</span>
chmod +x <span>~</span>/.docker/cli-plugins/docker-pussh</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Windows is not currently supported, but you can try using <a href="https://docs.docker.com/desktop/features/wsl/" rel="nofollow">WSL 2</a>
with the above Linux instructions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Verify installation</h3><a id="user-content-verify-installation" aria-label="Permalink: Verify installation" href="#verify-installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Push an image to a remote server. Please make sure the SSH user has permissions to run <code>docker</code> commands (user is
<code>root</code> or non-root user is in <code>docker</code> group). If <code>sudo</code> is required, ensure the user can run <code>sudo docker</code> without
a password prompt.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server.example.com"><pre>docker pussh myapp:latest user@server.example.com</pre></div>
<p dir="auto">With SSH key authentication if the private key is not added to your SSH agent:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest ubuntu@192.168.1.100 -i ~/.ssh/id_rsa"><pre>docker pussh myapp:latest ubuntu@192.168.1.100 -i <span>~</span>/.ssh/id_rsa</pre></div>
<p dir="auto">Using a custom SSH port:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server:2222"><pre>docker pussh myapp:latest user@server:2222</pre></div>
<p dir="auto">Push a specific platform for a multi-platform image. The local Docker has to use
<a href="https://docs.docker.com/desktop/features/containerd/" rel="nofollow">containerd image store</a> to support multi-platform images.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server --platform linux/amd64"><pre>docker pussh myapp:latest user@server --platform linux/amd64</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use cases</h2><a id="user-content-use-cases" aria-label="Permalink: Use cases" href="#use-cases"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy to production servers</h3><a id="user-content-deploy-to-production-servers" aria-label="Permalink: Deploy to production servers" href="#deploy-to-production-servers"></a></p>
<p dir="auto">Build locally and push directly to your production servers. No middleman.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker build --platform linux/amd64 -t myapp:1.2.3 .
docker pussh myapp:1.2.3 deploy@prod-server
ssh deploy@prod-server docker run -d myapp:1.2.3"><pre>docker build --platform linux/amd64 -t myapp:1.2.3 <span>.</span>
docker pussh myapp:1.2.3 deploy@prod-server
ssh deploy@prod-server docker run -d myapp:1.2.3</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CI/CD pipelines</h3><a id="user-content-cicd-pipelines" aria-label="Permalink: CI/CD pipelines" href="#cicd-pipelines"></a></p>
<p dir="auto">Skip the registry complexity in your pipelines. Build and push directly to deployment targets.</p>
<div dir="auto" data-snippet-clipboard-copy-content="- name: Build and deploy
  run: |
    docker build -t myapp:${{ github.sha }} .
    docker pussh myapp:${{ github.sha }} deploy@staging-server"><pre>- <span>name</span>: <span>Build and deploy</span>
  <span>run</span>: <span>|</span>
<span>    docker build -t myapp:${{ github.sha }} .</span>
<span>    docker pussh myapp:${{ github.sha }} deploy@staging-server</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homelab and air-gapped environments</h3><a id="user-content-homelab-and-air-gapped-environments" aria-label="Permalink: Homelab and air-gapped environments" href="#homelab-and-air-gapped-environments"></a></p>
<p dir="auto">Distribute images in isolated networks without exposing them to the internet.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh image:latest user@192.168.1.100"><pre>docker pussh image:latest user@192.168.1.100</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">On local machine</h3><a id="user-content-on-local-machine" aria-label="Permalink: On local machine" href="#on-local-machine"></a></p>
<ul dir="auto">
<li>Docker CLI with plugin support (Docker 19.03+)</li>
<li>OpenSSH client</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">On remote server</h3><a id="user-content-on-remote-server" aria-label="Permalink: On remote server" href="#on-remote-server"></a></p>
<ul dir="auto">
<li>Docker is installed and running</li>
<li>SSH user has permissions to run <code>docker</code> commands (user is <code>root</code> or non-root user is in <code>docker</code> group)</li>
<li>If <code>sudo</code> is required, ensure the user can run <code>sudo docker</code> without a password prompt</li>
</ul>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">The remote Docker daemon works best with <a href="https://docs.docker.com/engine/storage/containerd/" rel="nofollow">containerd image store</a>
enabled. This allows unregistry to access images more efficiently.</p>
<p dir="auto">Add the following configuration to <code>/etc/docker/daemon.json</code> on the remote server and restart the <code>docker</code> service:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;features&quot;: {
    &quot;containerd-snapshotter&quot;: true
  }
}"><pre>{
  <span>"features"</span>: {
    <span>"containerd-snapshotter"</span>: <span>true</span>
  }
}</pre></div>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced usage</h2><a id="user-content-advanced-usage" aria-label="Permalink: Advanced usage" href="#advanced-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running unregistry standalone</h3><a id="user-content-running-unregistry-standalone" aria-label="Permalink: Running unregistry standalone" href="#running-unregistry-standalone"></a></p>
<p dir="auto">Sometimes you want a local registry without the overhead. Unregistry works great for this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run unregistry locally and expose it on port 5000
docker run -d -p 5000:5000 --name unregistry \
  -v /run/containerd/containerd.sock:/run/containerd/containerd.sock \
  ghcr.io/psviderski/unregistry

# Use it like any registry
docker tag myapp:latest localhost:5000/myapp:latest
docker push localhost:5000/myapp:latest"><pre><span><span>#</span> Run unregistry locally and expose it on port 5000</span>
docker run -d -p 5000:5000 --name unregistry \
  -v /run/containerd/containerd.sock:/run/containerd/containerd.sock \
  ghcr.io/psviderski/unregistry

<span><span>#</span> Use it like any registry</span>
docker tag myapp:latest localhost:5000/myapp:latest
docker push localhost:5000/myapp:latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Custom SSH options</h3><a id="user-content-custom-ssh-options" aria-label="Permalink: Custom SSH options" href="#custom-ssh-options"></a></p>
<p dir="auto">Need custom SSH settings? Use the standard SSH config file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ~/.ssh/config
Host prod-server
    HostName server.example.com
    User deploy
    Port 2222
    IdentityFile ~/.ssh/deploy_key

# Now just use
docker pussh myapp:latest prod-server"><pre><span><span>#</span> ~/.ssh/config</span>
Host prod-server
    HostName server.example.com
    User deploy
    Port 2222
    IdentityFile <span>~</span>/.ssh/deploy_key

<span><span>#</span> Now just use</span>
docker pussh myapp:latest prod-server</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Found a bug or have a feature idea? We'd love your help!</p>
<ul dir="auto">
<li>🐛 Found a bug? <a href="https://github.com/psviderski/unregistry/issues">Open an issue</a></li>
<li>💡 Have ideas or need help? <a href="https://discord.gg/eR35KQJhPu" rel="nofollow">Join Uncloud Discord community</a> where we discuss features,
roadmap, implementation details, and help each other out.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inspiration &amp; acknowledgements</h2><a id="user-content-inspiration--acknowledgements" aria-label="Permalink: Inspiration &amp; acknowledgements" href="#inspiration--acknowledgements"></a></p>
<ul dir="auto">
<li><a href="https://github.com/spegel-org/spegel">Spegel</a> - P2P container image registry that inspired me to implement a
registry that uses containerd image store as a backend.</li>
<li><a href="https://github.com/distribution/distribution">Docker Distribution</a> - the bulletproof Docker registry implementation
that unregistry uses as a base.</li>
</ul>

<p>
  Built with ❤️ by <a href="https://github.com/psviderski">Pasha Sviderski</a> who just wanted to deploy his images
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New US visa rules will force foreign students to unlock social media profiles (446 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2025/jun/18/social-media-student-visa-screening</link>
            <guid>44314054</guid>
            <pubDate>Wed, 18 Jun 2025 23:11:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2025/jun/18/social-media-student-visa-screening">https://www.theguardian.com/us-news/2025/jun/18/social-media-student-visa-screening</a>, See on <a href="https://news.ycombinator.com/item?id=44314054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Foreign students will be required to unlock their social media profiles to allow US diplomats to review their online activity before receiving educational and exchange visas, the state department has announced. Those who fail to do so will be suspected of hiding that activity from US officials.</p><p>The new guidance, unveiled by the state department on Wednesday, directs US diplomats to conduct an online presence review to look for “any indications of hostility toward the citizens, culture, government, institutions, or founding principles of the United States”.</p><p>A cable separately obtained by Politico also instructs diplomats to flag any “advocacy for, aid or support for foreign terrorists and other threats to US national security” and “support for unlawful antisemitic harassment or violence”.</p><p>The screening for “antisemitic” activity matches similar guidance given at US Citizenship and Immigration Services under the Department of Homeland Security and has been criticised as an effort to crack down on opposition to the conduct of Israel’s war in Gaza.</p><p>The new state department checks are directed at students and other applicants for visas in the F, M and J categories, which refer to academic and vocational education, as well as cultural exchanges.</p><p>“It is an expectation from American citizens that their government will make every effort to make our country safer, and that is exactly what the <a href="https://www.theguardian.com/us-news/trump-administration" data-link-name="in body link" data-component="auto-linked-tag">Trump administration</a> is doing every single day,” said a senior state department official, adding that Marco Rubio was “helping to make America and its universities safer while bringing the state Department into the 21st century”.</p><figure id="2c0c0441-fde7-4b33-9f05-c7264f202232" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:6,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;US issues broad order to consulates to vet student visas over ‘terrorist activity’&quot;,&quot;elementId&quot;:&quot;2c0c0441-fde7-4b33-9f05-c7264f202232&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2025/mar/28/student-visa-applications-denials&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>The Trump administration paused the issuance of new education visas late last month as it mulled new social media vetting strategies. The US had also targeted Chinese students for special scrutiny amid a tense negotiation over tariffs and the supply of rare-earth metals and minerals to the United States.</p><p>The state department directive allowed diplomatic posts to resume the scheduling of interviews for educational and exchange visas, but added that consular officers would conduct a “comprehensive and thorough vetting” of all applicants applying for F, M and J visas.</p><p>“To facilitate this vetting, all applicants for F, M and J non-immigrant visas will be asked to adjust the privacy settings on all their social media profiles to ‘public’”, the official said. “The enhanced social media vetting will ensure we are properly screening every single person attempting to visit our country.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fang, the CLI Starter Kit (136 pts)]]></title>
            <link>https://github.com/charmbracelet/fang</link>
            <guid>44313901</guid>
            <pubDate>Wed, 18 Jun 2025 22:40:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/charmbracelet/fang">https://github.com/charmbracelet/fang</a>, See on <a href="https://news.ycombinator.com/item?id=44313901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Fang</h2><a id="user-content-fang" aria-label="Permalink: Fang" href="#fang"></a></p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/25087/453127263-3f34ea01-3750-4760-beb2-a1b700e110f5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTMxMjcyNjMtM2YzNGVhMDEtMzc1MC00NzYwLWJlYjItYTFiNzAwZTExMGY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRiYjlmMzhlMjYxZDQ3NDE3YjcxZWM0NmQyYzgzN2ZhNjE3NTMzZjRhNDZkMGUyMDliMDBjZTlhNGNmODE4OWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.qNmzqtvKLyQgIWOFwgomip_UNof2pDx-LF94v9UhF8M"><img width="485" alt="Charm Fang" src="https://private-user-images.githubusercontent.com/25087/453127263-3f34ea01-3750-4760-beb2-a1b700e110f5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTMxMjcyNjMtM2YzNGVhMDEtMzc1MC00NzYwLWJlYjItYTFiNzAwZTExMGY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRiYjlmMzhlMjYxZDQ3NDE3YjcxZWM0NmQyYzgzN2ZhNjE3NTMzZjRhNDZkMGUyMDliMDBjZTlhNGNmODE4OWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.qNmzqtvKLyQgIWOFwgomip_UNof2pDx-LF94v9UhF8M"></a>   
</p>
<p dir="auto">
    <a href="https://github.com/charmbracelet/fang/releases"><img src="https://camo.githubusercontent.com/2491a6829151430ac84c5b91f8de86767fdbf15d6f42e35ea9796c0976ca1f6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f636861726d62726163656c65742f66616e672e737667" alt="Latest Release" data-canonical-src="https://img.shields.io/github/release/charmbracelet/fang.svg"></a>
    <a href="https://pkg.go.dev/github.com/charmbracelet/fang?tab=doc" rel="nofollow"><img src="https://camo.githubusercontent.com/085bf6223c42adfef9036b4df0988091acacbcc7178b35906aa685b6aec2fe19/68747470733a2f2f676f646f632e6f72672f6769746875622e636f6d2f636861726d62726163656c65742f66616e673f7374617475732e737667" alt="GoDoc" data-canonical-src="https://godoc.org/github.com/charmbracelet/fang?status.svg"></a>
    <a href="https://github.com/charmbracelet/fang/actions"><img src="https://github.com/charmbracelet/fang/workflows/build/badge.svg" alt="Build Status"></a>
</p>
<p dir="auto">The CLI starter kit. A small, experimental library for batteries-included <a href="https://github.com/spf13/cobra">Cobra</a> applications.</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/25087/456775205-5c35e1fa-9577-4f81-a879-3ddb4d4a43f0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTY3NzUyMDUtNWMzNWUxZmEtOTU3Ny00ZjgxLWE4NzktM2RkYjRkNGE0M2YwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZkYmZhYTVhZTZkZGE4N2QzNTIwYTUwZGI3MTc3NDMyMjY0N2JmZDM1NDMwZjBlZGI2ZDExOTUxN2I4MzQ5OGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7PlqhcO-1c4KQCButUYJuiPZ4VZfGu8CAdHDd5_U6W8"><img width="859" alt="The Charm Fang mascot and title treatment" src="https://private-user-images.githubusercontent.com/25087/456775205-5c35e1fa-9577-4f81-a879-3ddb4d4a43f0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTY3NzUyMDUtNWMzNWUxZmEtOTU3Ny00ZjgxLWE4NzktM2RkYjRkNGE0M2YwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZkYmZhYTVhZTZkZGE4N2QzNTIwYTUwZGI3MTc3NDMyMjY0N2JmZDM1NDMwZjBlZGI2ZDExOTUxN2I4MzQ5OGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7PlqhcO-1c4KQCButUYJuiPZ4VZfGu8CAdHDd5_U6W8"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Fancy output</strong>: fully styled help and usage pages</li>
<li><strong>Fancy errors</strong>: fully styled errors</li>
<li><strong>Automatic <code>--version</code></strong>: set it to the <a href="https://pkg.go.dev/runtime/debug#BuildInfo" rel="nofollow">build info</a>, or a version of your choice</li>
<li><strong>Manpages</strong>: Adds a hidden <code>man</code> command to generate <em>manpages</em> using
<a href="https://github.com/muesli/mango">mango</a><sup><a href="#user-content-fn-1-0d05681b58ad0244d82fd35e6e8dccb1" id="user-content-fnref-1-0d05681b58ad0244d82fd35e6e8dccb1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></li>
<li><strong>Completions</strong>: Adds a <code>completion</code> command to generate shell completions</li>
<li><strong>Themeable</strong>: use the built-in theme, or make your own</li>
<li><strong>UX</strong>: Silent <code>usage</code> output (help is not shown after a user error)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">To use it, invoke <code>fang.Execute</code> passing your root <code>*cobra.Command</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;os&quot;

	&quot;github.com/charmbracelet/fang&quot;
	&quot;github.com/spf13/cobra&quot;
)

func main() {
	cmd := &amp;cobra.Command{
		Use:   &quot;example&quot;,
		Short: &quot;A simple example program!&quot;,
	}
	if err := fang.Execute(context.TODO(), cmd); err != nil {
		os.Exit(1)
	}
}"><pre><span>package</span> main

<span>import</span> (
	<span>"os"</span>

	<span>"github.com/charmbracelet/fang"</span>
	<span>"github.com/spf13/cobra"</span>
)

<span>func</span> <span>main</span>() {
	<span>cmd</span> <span>:=</span> <span>&amp;</span>cobra.<span>Command</span>{
		<span>Use</span>:   <span>"example"</span>,
		<span>Short</span>: <span>"A simple example program!"</span>,
	}
	<span>if</span> <span>err</span> <span>:=</span> <span>fang</span>.<span>Execute</span>(<span>context</span>.<span>TODO</span>(), <span>cmd</span>); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>os</span>.<span>Exit</span>(<span>1</span>)
	}
}</pre></div>
<p dir="auto">That's all there is to it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/charmbracelet/fang/contribute">contributing</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback</h2><a id="user-content-feedback" aria-label="Permalink: Feedback" href="#feedback"></a></p>
<p dir="auto">We’d love to hear your thoughts on this project. Feel free to drop us a note!</p>
<ul dir="auto">
<li><a href="https://twitter.com/charmcli" rel="nofollow">Twitter</a></li>
<li><a href="https://charm.sh/chat" rel="nofollow">Discord</a></li>
<li><a href="https://mastodon.social/@charmcli" rel="nofollow">The Fediverse</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/charmbracelet/gum/raw/main/LICENSE">MIT</a></p>
<hr>
<p dir="auto">Part of <a href="https://charm.sh/" rel="nofollow">Charm</a>.</p>
<p dir="auto"><a href="https://charm.sh/" rel="nofollow"><img alt="The Charm logo" src="https://camo.githubusercontent.com/bdbe361924a6bb7fbc7e80f53ac2a8dd50c1a85ff952a3063c0fc0cba3a09d6d/68747470733a2f2f73747566662e636861726d2e73682f636861726d2d62616467652e6a7067" width="400" data-canonical-src="https://stuff.charm.sh/charm-badge.jpg"></a></p>
<p dir="auto">Charm热爱开源 • Charm loves open source</p>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-1-0d05681b58ad0244d82fd35e6e8dccb1">
<p dir="auto">Default cobra man pages generates one man page for each command. This is
generally fine for programs with a lot of sub commands, like git, but its an
overkill for smaller programs.
Mango also uses <em>roff</em> directly instead of converting from markdown, so it
should render better looking man pages. <a href="#user-content-fnref-1-0d05681b58ad0244d82fd35e6e8dccb1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>