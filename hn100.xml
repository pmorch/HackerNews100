(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 19 Jan 2026 23:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Threads edges out X in daily mobile users, new data shows (129 pts)]]></title>
            <link>https://techcrunch.com/2026/01/18/threads-edges-out-x-in-daily-mobile-users-new-data-shows/</link>
            <guid>46683947</guid>
            <pubDate>Mon, 19 Jan 2026 20:17:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2026/01/18/threads-edges-out-x-in-daily-mobile-users-new-data-shows/">https://techcrunch.com/2026/01/18/threads-edges-out-x-in-daily-mobile-users-new-data-shows/</a>, See on <a href="https://news.ycombinator.com/item?id=46683947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">A report from market intelligence firm <a rel="nofollow" href="https://www.similarweb.com/">Similarweb</a> suggests that Meta’s Threads is now seeing more daily usage than Elon Musk’s X on mobile devices. While X still dominates Threads on the web, the Threads mobile app for iOS and Android has continued to see an increase in daily active users over the past several months.</p>

<p>Similarweb’s data shows that Threads had 141.5 million daily active users on iOS and Android as of January 7, 2026, after months of growth, while X has 125 million daily active users on mobile devices.</p>







<p>This appears to be the result of longer-term trends, rather than a reaction to the recent X controversies, where users were discovered using the platform’s integrated AI, Grok, to create non-consensual nude images of women, including, sometimes minors. Concern around the deepfake images has now prompted California’s attorney general&nbsp;<a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-launches-investigation-xai-grok-over-undressed-sexual-ai" target="_blank" rel="noreferrer noopener nofollow">to open an investigation</a>&nbsp;into Grok, following similar investigations by other regions, <a rel="nofollow" href="https://www.bbc.com/news/articles/cwy875j28k0o">like the UK</a>, EU, India, Brazil, and <a rel="nofollow" href="https://mashable.com/article/countries-blocking-grok-for-explicit-deepfakes">many more</a>.</p>

<p>The drama on X also led social networking startup Bluesky <a href="https://techcrunch.com/2026/01/16/bluesky-rolls-out-cashtags-and-live-badges-amid-a-boost-in-app-installs/">to see an increase</a> in app installs in recent days.</p>

<figure><img loading="lazy" decoding="async" height="418" width="680" src="https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?w=680" alt="" srcset="https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png 889w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=150,92 150w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=300,184 300w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=768,472 768w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=680,418 680w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=430,264 430w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=720,442 720w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=800,491 800w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=668,410 668w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=611,375 611w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=708,435 708w, https://techcrunch.com/wp-content/uploads/2026/01/threads-x-similarweb.png?resize=50,31 50w" sizes="auto, (max-width: 680px) 100vw, 680px"></figure>

<p>Instead, Threads’ boost in daily mobile usage may be driven by other factors, including cross-promotions from Meta’s larger social apps like Facebook and Instagram (where Threads is regularly advertised to existing users), its focus on creators, and the rapid rollout of new features. Over the past year, Threads has added features like <a href="https://techcrunch.com/2025/10/02/threads-takes-on-x-with-new-communities-feature/">interest-based communities</a>, <a href="https://techcrunch.com/2025/10/30/threads-now-lets-you-approve-and-filter-your-replies/">better filters</a>, <a href="https://techcrunch.com/2025/07/01/threads-gets-its-own-dms-as-app-distances-itself-from-instagram/">DMs</a>, <a href="https://techcrunch.com/2025/08/28/threads-tests-a-way-to-share-long-form-text-on-the-platform/">long-form text</a>, <a href="https://techcrunch.com/2025/10/27/threads-adds-ghost-posts-that-disappear-after-24-hours-and-responses-go-to-dms/">disappearing posts</a>, and has recently been <a href="https://techcrunch.com/2026/01/06/threads-is-developing-in-message-games/">spotted testing games</a>.</p>

<p>Combined, the daily active user increases suggest that more people are using Threads on mobile as a more regular habit.</p>

<p>According to Meta’s official numbers, the tech giant said in August 2025 that Threads had <a href="https://techcrunch.com/2025/08/12/threads-now-has-more-than-400-million-monthly-active-users/">reached over 400 million monthly</a> active users. The company subsequently reported <a href="https://techcrunch.com/2025/10/30/threads-now-lets-you-approve-and-filter-your-replies/">in October</a> of last year that Threads had 150 million daily active users.</p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>San Francisco</span>
													<span>|</span>
													<span>October 13-15, 2026</span>
							</p>
			
		</div>
	</div>

<p>The growth trends have been continuing for many months. Similarweb <a href="https://techcrunch.com/2025/07/07/threads-is-nearing-xs-daily-app-users-new-data-shows/">last summer reported</a> that Threads was closing the gap with X on mobile devices after seeing 127.8% year-over-year growth as of late June 2025. </p>

<p>Relatedly, Similarweb observed that X is still ahead of Threads in the U.S., but the gap is narrowing. A year ago, X had twice as many daily active users in the U.S. as it does now.</p>

<p>In addition, Threads has little traction on the web while X maintains a fairly steady web audience with around 150 million daily web visits, according to Similarweb data. As of earlier this week (January 13), X was seeing 145.4 million daily web visits, while Threads saw 8.5 million daily web visits across Threads.com and Threads.net combined.</p>

<figure><img loading="lazy" decoding="async" height="412" width="680" src="https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?w=680" alt="" srcset="https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png 892w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=150,91 150w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=300,182 300w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=768,465 768w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=680,412 680w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=430,260 430w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=720,436 720w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=800,484 800w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=668,404 668w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=619,375 619w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=708,429 708w, https://techcrunch.com/wp-content/uploads/2026/01/x-threads-web-similarweb.png?resize=50,30 50w" sizes="auto, (max-width: 680px) 100vw, 680px"></figure>
</div><div>
	
	
	
	

	
<div><p>
		Sarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.

</p><p>You can contact or verify outreach from Sarah by emailing <a href="mailto:sarahp@techcrunch.com">sarahp@techcrunch.com</a> or via encrypted message at sarahperez.01 on Signal.</p> 	</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/sarah-perez/" data-event="button" href="https://techcrunch.com/author/sarah-perez/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Americans Are the Ones Paying for Tariffs, Study Finds (114 pts)]]></title>
            <link>https://www.wsj.com/economy/trade/americans-are-the-ones-paying-for-tariffs-study-finds-e254ed2e</link>
            <guid>46683519</guid>
            <pubDate>Mon, 19 Jan 2026 19:43:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/economy/trade/americans-are-the-ones-paying-for-tariffs-study-finds-e254ed2e">https://www.wsj.com/economy/trade/americans-are-the-ones-paying-for-tariffs-study-finds-e254ed2e</a>, See on <a href="https://news.ycombinator.com/item?id=46683519">Hacker News</a></p>
Couldn't get https://www.wsj.com/economy/trade/americans-are-the-ones-paying-for-tariffs-study-finds-e254ed2e: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Nonviolence (138 pts)]]></title>
            <link>https://kinginstitute.stanford.edu/nonviolence</link>
            <guid>46683410</guid>
            <pubDate>Mon, 19 Jan 2026 19:33:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kinginstitute.stanford.edu/nonviolence">https://kinginstitute.stanford.edu/nonviolence</a>, See on <a href="https://news.ycombinator.com/item?id=46683410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-stanford-basic-content"><p>As a theologian, Martin Luther King reflected often on his understanding of nonviolence. He described his own “pilgrimage to nonviolence” in his first book,&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="a405dd4e-d867-4d9b-8008-8c54d60ef5ad" href="https://kinginstitute.stanford.edu/stride-toward-freedom-montgomery-story" title="Stride Toward Freedom: The Montgomery Story"><strong><em>Stride Toward Freedom</em></strong></a>, and in subsequent books and articles. “True pacifism,” or “nonviolent resistance,” King wrote, is “a courageous confrontation of evil by the power of love” (King,&nbsp;<em>Stride</em>, 80). Both “morally and practically” committed to nonviolence, King believed that “the Christian doctrine of love operating through the Gandhian method of nonviolence was one of the most potent weapons available to oppressed people in their struggle for freedom” (King,&nbsp;<em>Stride</em>, 79;&nbsp;<a href="https://kinginstitute.stanford.edu/king-papers/documents/pilgrimage-nonviolence"><em>Papers</em>&nbsp;5:422</a>).</p>

<p>King was first introduced to the concept of nonviolence when he read Henry David Thoreau’s&nbsp;<em>Essay on Civil Disobedience</em>&nbsp;as a freshman at&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="1afbc484-45a2-48af-bf8f-1b1f6dd0c4c7" href="https://kinginstitute.stanford.edu/morehouse-college" title="Morehouse College"><strong>Morehouse College</strong></a>. Having grown up in Atlanta and witnessed segregation and racism every day, King was “fascinated by the idea of refusing to cooperate with an evil system” (King,&nbsp;<em>Stride</em>, 73).</p>

<p>In 1950, as a student at&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="693a934c-910f-48ad-943e-bcdae0d1bcc3" href="https://kinginstitute.stanford.edu/crozer-theological-seminary" title="Crozer Theological Seminary"><strong>Crozer Theological Seminary</strong></a>, King heard a talk by Dr. Mordecai&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="3fd97195-a230-493b-957a-b81491f87c10" href="https://kinginstitute.stanford.edu/johnson-mordecai-wyatt" title="Johnson, Mordecai Wyatt"><strong>Johnson</strong></a>, president of Howard University. Dr. Johnson, who had recently traveled to&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="58ed57c8-7105-4b5e-a213-509499a51a5e" href="https://kinginstitute.stanford.edu/india-trip" title="India Trip"><strong>India</strong></a>, spoke about the life and teachings of Mohandas K.&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="b53ee47d-1ed9-4b18-86b0-a3eae1d16345" href="https://kinginstitute.stanford.edu/gandhi-mohandas-k" title="Gandhi, Mohandas K."><strong>Gandhi</strong></a>. Gandhi, King later wrote, was the first person to transform Christian love into a powerful force for social change. Gandhi’s stress on love and nonviolence gave King “the method for social reform that I had been seeking” (King,&nbsp;<em>Stride</em>, 79).</p>

<p>While intellectually committed to nonviolence, King did not experience the power of nonviolent direct action first-hand until the start of the&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="b80a1b67-72d6-442a-a92a-d44b92d90cec" href="https://kinginstitute.stanford.edu/montgomery-bus-boycott" title="Montgomery Bus Boycott"><strong>Montgomery bus boycott</strong></a>&nbsp;in 1955. During the boycott, King personally enacted Gandhian principles. With guidance from black pacifist Bayard&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="42bc47e0-c290-46fe-a88f-59986fca4c5c" href="https://kinginstitute.stanford.edu/rustin-bayard" title="Rustin, Bayard"><strong>Rustin</strong></a>&nbsp;and Glenn&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="d1eb91fa-4912-44ea-b07a-4af7cb76c548" href="https://kinginstitute.stanford.edu/smiley-glenn-e" title="Smiley, Glenn E."><strong>Smiley</strong></a>&nbsp;of the&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="5452fe48-8001-4613-9e92-f9540f70940a" href="https://kinginstitute.stanford.edu/fellowship-reconciliation" title="Fellowship of Reconciliation (FOR)"><strong>Fellowship of Reconciliation</strong></a>, King eventually decided not to use armed bodyguards despite threats on his life, and reacted to violent experiences, such as the bombing of his home, with compassion. Through the practical experience of leading nonviolent protest, King came to understand how nonviolence could become a way of life, applicable to all situations. King called the principle of nonviolent resistance the “guiding light of our movement. Christ furnished the spirit and motivation while Gandhi furnished the method” (<a href="https://kinginstitute.stanford.edu/king-papers/documents/pilgrimage-nonviolence"><em>Papers</em>&nbsp;5:423</a>).</p>

<p>King’s notion of nonviolence had six key principles. First, one can resist evil without resorting to violence. Second, nonviolence seeks to win the “friendship and understanding” of the opponent, not to humiliate him (King,&nbsp;<em>Stride</em>, 84). Third, evil itself, not the people committing evil acts, should be opposed. Fourth, those committed to nonviolence must be willing to suffer without retaliation as suffering itself can be redemptive. Fifth, nonviolent resistance avoids “external physical violence” and “internal violence of spirit” as well: “The nonviolent resister not only refuses to shoot his opponent but he also refuses to hate him” (King,&nbsp;<em>Stride</em>, 85). The resister should be motivated by love in the sense of the Greek word&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="47956892-77b7-49ad-9fa0-cfa9f4697261" href="https://kinginstitute.stanford.edu/agape" title="Agape"><strong><em>agape</em></strong></a>, which means “understanding,” or “redeeming good will for all men” (King,&nbsp;<em>Stride</em>, 86). The sixth principle is that the nonviolent resister must have a “deep faith in the future,” stemming from the conviction that “The universe is on the side of justice” (King,&nbsp;<em>Stride</em>, 88).</p>

<p>During the years after the bus boycott, King grew increasingly committed to nonviolence. An India trip in 1959 helped him connect more intimately with Gandhi’s legacy. King began to advocate nonviolence not just in a national sphere, but internationally as well: “the potential destructiveness of modern weapons” convinced King that “the choice today is no longer between violence and nonviolence. It is either nonviolence or nonexistence” (<a href="https://kinginstitute.stanford.edu/king-papers/documents/pilgrimage-nonviolence"><em>Papers</em>&nbsp;5:424</a>).</p>

<p>After&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="f626e5f4-8bad-4c45-aa8c-6d354a5adffe" href="https://kinginstitute.stanford.edu/black-power" title="Black Power"><strong>Black Power</strong></a>&nbsp;advocates such as Stokely&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="0c99b587-4701-4d47-98e0-4d0c776edc3c" href="https://kinginstitute.stanford.edu/carmichael-stokely" title="Carmichael, Stokely"><strong>Carmichael</strong></a>&nbsp;began to reject nonviolence, King lamented that some African Americans had lost hope, and reaffirmed his own commitment to nonviolence: “Occasionally in life one develops a conviction so precious and meaningful that he will stand on it till the end. This is what I have found in nonviolence” (King,&nbsp;<em>Where</em>, 63–64). He wrote in his 1967 book,&nbsp;<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="ccc91d57-f509-4924-a9c8-a4427b982767" href="https://kinginstitute.stanford.edu/where-do-we-go-here-chaos-or-community" title="Where Do We Go from Here: Chaos or Community?"><strong><em>Where Do We Go from Here: Chaos or Community?</em></strong></a>: “We maintained the hope while transforming the hate of traditional revolutions into positive nonviolent power. As long as the hope was fulfilled there was little questioning of nonviolence. But when the hopes were blasted, when people came to see that in spite of progress their conditions were still insufferable … despair began to set in” (King,&nbsp;<em>Where</em>, 45). Arguing that violent revolution was impractical in the context of a multiracial society, he concluded: “Darkness cannot drive out darkness: only light can do that. Hate cannot drive out hate: only love can do that. The beauty of nonviolence is that in its own way and in its own time it seeks to break the chain reaction of evil” (King,&nbsp;<em>Where</em>, 62–63).&nbsp;</p>

<h2>Footnotes</h2>

<p>King, “Pilgrimage to Nonviolence,” 13 April 1960, in&nbsp;<a href="https://kinginstitute.stanford.edu/king-papers/documents/pilgrimage-nonviolence"><em>Papers</em>&nbsp;5:419–425</a>.</p>

<p>King,&nbsp;<em>Stride Toward Freedom</em>, 1958.</p>

<p>King,&nbsp;<em>Where Do We Go from Here</em>, 1967.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Letter from a Birmingham Jail [King, Jr.] (1963) (384 pts)]]></title>
            <link>https://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html</link>
            <guid>46683205</guid>
            <pubDate>Mon, 19 Jan 2026 19:17:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html">https://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html</a>, See on <a href="https://news.ycombinator.com/item?id=46683205">Hacker News</a></p>
Couldn't get https://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[US Places Arctic Airborne Troops on Standby as Greenland Dispute Escalates (103 pts)]]></title>
            <link>https://www.thedefensenews.com/news-details/Pentagon-Places-1500-Arctic-Trained-Airborne-Troops-on-Standby-as-Greenland-Dispute-Escalates/</link>
            <guid>46682806</guid>
            <pubDate>Mon, 19 Jan 2026 18:42:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedefensenews.com/news-details/Pentagon-Places-1500-Arctic-Trained-Airborne-Troops-on-Standby-as-Greenland-Dispute-Escalates/">https://www.thedefensenews.com/news-details/Pentagon-Places-1500-Arctic-Trained-Airborne-Troops-on-Standby-as-Greenland-Dispute-Escalates/</a>, See on <a href="https://news.ycombinator.com/item?id=46682806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article dir="auto" tabindex="-1" data-turn-id="fa3b861f-61e3-4cdf-bbdf-09dfe3166217" data-testid="conversation-turn-2" data-scroll-anchor="true" data-turn="assistant">
<div dir="auto" data-message-author-role="assistant" data-message-id="0a4e864c-17b4-4536-b8f7-eefc798f2cf4" data-message-model-slug="gpt-5-2" tabindex="-1">
<p data-start="155" data-end="838"><span><strong>ANCHORAGE / WASHINGTON</strong> : The Pentagon has issued&nbsp;<strong data-start="179" data-end="209">“prepare-to-deploy” orders</strong> to roughly <strong data-start="221" data-end="251">1,500 active-duty soldiers</strong> from the <strong data-start="261" data-end="302"><span>11th Airborne Division</span></strong>, setting off a wave of debate inside U.S. defense circles and across allied capitals. Officially, the alert is tied to a potential <strong data-start="434" data-end="472">domestic deployment to Minneapolis</strong>, where unrest followed the fatal shooting of local activist <strong data-start="533" data-end="574"><span>Renee Good</span></strong> during an encounter with federal immigration officers. Unofficially, analysts say the move coincides with a rapidly escalating <strong data-start="702" data-end="747">geopolitical confrontation over Greenland</strong>, raising questions about whether the domestic rationale masks a broader strategic purpose.</span></p>

<h3 data-start="840" data-end="877"><span>The Orders and the Stated Mission</span></h3>
<p data-start="878" data-end="1338"><span>According to defense officials, the alert covers <strong data-start="927" data-end="954">two infantry battalions</strong> based at <strong data-start="964" data-end="1005"><span>Joint Base Elmendorf-Richardson</span></strong> and <strong data-start="1010" data-end="1051"><span>Fort Wainwright</span></strong>. The units were told to be ready for rapid movement to <strong data-start="1107" data-end="1148"><span>Minneapolis</span></strong>, where protests intensified after the shooting. Federal authorities say the troops could be used to <strong data-start="1249" data-end="1315">support immigration enforcement and protect federal facilities</strong> if violence escalates.</span></p>
<p data-start="1340" data-end="1586"><span>Administration officials have cited the possibility of invoking the <strong data-start="1408" data-end="1436">Insurrection Act of 1807</strong>, a rarely used statute that allows the president to deploy active-duty forces on U.S. soil when state authorities are deemed unable to restore order.</span></p>

<h3 data-start="1588" data-end="1606"><span>Why This Unit?</span></h3>
<p data-start="1607" data-end="1926"><span>The selection of the 11th Airborne Division has immediately drawn scrutiny. Reconstituted and reoriented in recent years, the division is widely regarded as the Army’s <strong data-start="1775" data-end="1820">premier Arctic and cold-weather formation</strong>, optimized for <strong data-start="1836" data-end="1925">sub-zero operations, austere airfields, glacier movement, and high-latitude logistics</strong>.</span></p>
<p data-start="1928" data-end="2286"><span>Military planners note that for domestic crowd-control or security missions in the Midwest, <strong data-start="2020" data-end="2083">National Guard units or conventional active-duty formations</strong> are typically preferred. “This is an Arctic hammer being readied for an urban nail,” said a retired logistics officer familiar with force-generation planning. “That mismatch is what’s raising eyebrows.”</span></p>

<h3 data-start="2288" data-end="2314"><span>The Greenland Backdrop</span></h3>
<p data-start="2315" data-end="2745"><span>The alert comes as Washington’s relationship with <strong data-start="2365" data-end="2406"><span>Denmark</span></strong> and the <strong data-start="2415" data-end="2456"><span>North Atlantic Treaty Organization</span></strong> is under strain over <strong data-start="2478" data-end="2519"><span>Greenland</span></strong>. In recent weeks, <strong data-start="2538" data-end="2554">Donald Trump</strong> has again publicly discussed the idea of <strong data-start="2596" data-end="2629">U.S. acquisition of Greenland</strong>, warning that the United States would secure its interests “one way or another” if Copenhagen refused to negotiate.</span></p>
<p data-start="2747" data-end="3121"><span>Danish officials have characterized such statements as an <strong data-start="2805" data-end="2847">existential challenge to NATO cohesion</strong>, while European diplomats say contingency planning has intensified around Greenland’s <strong data-start="2934" data-end="2989">airfields, ports, and undersea-cable infrastructure</strong>. Denmark, with allied support, has reportedly increased readiness under a defensive posture aimed at deterring any unilateral move.</span></p>

<h3 data-start="3123" data-end="3147"><span>The Deception Debate</span></h3>
<p data-start="3148" data-end="3462"><span>It is this overlap—<strong data-start="3167" data-end="3220">Arctic troops on alert and Arctic tensions abroad</strong>—that has fueled speculation about a potential <strong data-start="3267" data-end="3290">strategic deception</strong>. Analysts point to a classic military concept: using a <strong data-start="3346" data-end="3378">plausible domestic emergency</strong> to mobilize specialized forces without immediately triggering international alarms.</span></p>
<p data-start="3464" data-end="3714"><span>“The mechanics are straightforward,” said an analyst at <strong data-start="3520" data-end="3561"><span>Center for Strategic and International Studies</span></strong>. “A domestic mission provides legal cover to load aircraft, marshal equipment, and place units on short notice. The moment of truth is the flight plan.”</span></p>
<p data-start="3716" data-end="3902"><span>Defense officials caution there is <strong data-start="3751" data-end="3773">no public evidence</strong> of an imminent operation against Greenland, and the Pentagon has denied that the alert is connected to any overseas contingency.</span></p>

<h3 data-start="3904" data-end="3945"><span>Special Operations and Allied Posture</span></h3>
<p data-start="3946" data-end="4296"><span>Adding to the unease are <strong data-start="3971" data-end="4042">unconfirmed reports of increased Special Operations Forces activity</strong> linked to Arctic training and reconnaissance. Such units are typically tasked with <strong data-start="4126" data-end="4149">pathfinder missions</strong>—securing airstrips, ports, or landing zones ahead of larger formations—though officials stress that routine exercises can produce similar signals.</span></p>
<p data-start="4298" data-end="4587"><span>Across the Atlantic, allied governments say they are watching closely. A European defense official noted that <strong data-start="4408" data-end="4511">any military move involving Greenland would immediately engage NATO’s collective defense mechanisms</strong>, a scenario described privately as “unthinkable but no longer theoretical.”</span></p>

<p data-start="4611" data-end="4840"><span>For now, the 1,500 soldiers remain in Alaska, equipment packed and timelines compressed. Whether they ultimately deploy to Minneapolis, stand down, or pivot elsewhere will likely become clear only when&nbsp;<strong data-start="4813" data-end="4839">aircraft begin to move</strong>.</span></p>
<p data-start="4842" data-end="4995" data-is-last-node="" data-is-only-node=""><span>As one allied diplomat put it: “Minnesota is south. Greenland is east. In today’s world, the direction of a transport plane can carry strategic meaning.”</span></p>
</div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly a third of social media research has undisclosed ties to industry (122 pts)]]></title>
            <link>https://www.science.org/content/article/nearly-third-social-media-research-has-undisclosed-ties-industry-preprint-claims</link>
            <guid>46682534</guid>
            <pubDate>Mon, 19 Jan 2026 18:17:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/nearly-third-social-media-research-has-undisclosed-ties-industry-preprint-claims">https://www.science.org/content/article/nearly-third-social-media-research-has-undisclosed-ties-industry-preprint-claims</a>, See on <a href="https://news.ycombinator.com/item?id=46682534">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/nearly-third-social-media-research-has-undisclosed-ties-industry-preprint-claims: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on Apple's Nano Texture (2025) (106 pts)]]></title>
            <link>https://jon.bo/posts/nano-texture/</link>
            <guid>46682518</guid>
            <pubDate>Mon, 19 Jan 2026 18:15:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jon.bo/posts/nano-texture/">https://jon.bo/posts/nano-texture/</a>, See on <a href="https://news.ycombinator.com/item?id=46682518">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
  <figure>
    <img src="https://jon.bo/nano-texture/side-by-side-white.jpg">
    
      <figcaption>2024 Nano Texture Macbook Pro on the left; 2021 Glossy Macbook Pro on the right</figcaption>
    
  </figure>


<p><strong>TLDR: the Nano Texture performs wonderfully anywhere where light used to be a factor and used to force me to shade my screen or avoid the place entirely.</strong></p>
<ul>
<li>I’m less concerned with where I sit indoors. Coffee shops / offices with skylights or intense lighting are much more comfortable</li>
<li>Coding and working outside is now feasible: browsing the internet, writing in Obsidian; all delightful</li>
<li>The screen needs more effort to keep clean than a normal screen and comes with a special wipe that needs to be used instead of microfiber</li>
<li>Black text on white background (light mode) is considerably more readable than white text on black background (dark mode)</li>
<li>Overall a massive step forward for outdoor computing</li>
</ul>
<p>Big thanks to <a href="https://juliekruger.com/">Julie Kruger</a> for the comparison photos and <a href="https://workshop.cjpais.com/">CJ</a> for draft feedback.</p>

  <figure>
    <img src="https://jon.bo/nano-texture/IMG_2702.jpeg">
    
      <figcaption>sitting outside at North Boulder Park</figcaption>
    
  </figure>


<p>A few months after I got the Daylight Computer (<a href="https://jon.bo/posts/daylight-computer-1/">read my thoughts here</a>), two friends sent me <a href="https://www.tomsguide.com/computing/macbooks/the-new-macbook-pro-m4-is-a-game-changer-for-how-i-work-and-it-has-nothing-to-do-with-apple-intelligence">this post</a> comparing the old Macbook Pro displays to the new Nano Texture glass ones. That post convinced me to upgrade my computer in short order, to the dismay of my wallet.</p>
<p>In the four months I’ve had it I’ve told at least a dozen people about it, and I’m gonna keep telling people. Being able to take my entire computing environment to places without being worried about glare has expanded the range of environments I can create in. It means I get to be in environments that are more interesting, fun, and in tune with my body.</p>
<p>What follows are some thoughts about how this display has fit into my day to day life in the couple of months I’ve had it.</p>
<h2 id="what-is-nano-texture">what is Nano Texture?</h2>
<blockquote>
<p>Typical matt displays have a coating added to their surface that scatters light. However, these coatings lower contrast while producing unwanted haze and sparkle. Etched into the glass at the nanometre level, the nano-texture scatters light to further minimise glare — for outstanding image quality even in challenging lighting conditions.</p>
<p><a href="https://www.apple.com/uk/shop/buy-mac/apple-studio-display/nano-texture-glass-tilt-adjustable-stand">https://www.apple.com/uk/shop/buy-mac/apple-studio-display/nano-texture-glass-tilt-adjustable-stand</a></p>
</blockquote>
<p>Basically, it’s a coating physically etched into the screen that reflects light differently from the glossy finish of the traditional screen.</p>

  <figure>
    <img src="https://jon.bo/nano-texture/gloss-nano-white-code.jpg">
    
      <figcaption>Cursor on the 2021 MBP (Glossy) on the left; 2024 MBP (Nano Texture) on the right</figcaption>
    
  </figure>


<h2 id="nano-texture-vs-daylight-computer">Nano Texture vs Daylight Computer</h2>
<p>First off, this isn’t apples to oranges - these are different technologies that in my mind, serve a different purpose. The Daylight Computer is an Android tablet, the Macbook Pro is a full MacOS laptop.</p>
<p>The transflective LCD in the Daylight Computer is grayscale but it needs no light to function. It has a backlight, but where it does really well is in direct sunlight with the backlight turned off. When outside in direct sunlight, toggling the Daylight’s backlight on and off doesn’t make a difference because it works fundamentally different from a laptop screen.</p>

  <figure>
    <img src="https://jon.bo/nano-texture/gloss-nano-daylight.jpg">
    
      <figcaption>2021 MBP (glossy); 2024 MBP (Nano Texture); Daylight Computer (transflective)</figcaption>
    
  </figure>


<p>On the Daylight computer:</p>
<ul>
<li>white text on black background has about the same readability as black text on white background</li>
<li>the backlight can be lowered to 0% outside with no impact to visibility and making the battery last wonderfully long</li>
<li>grayscale + lower DPI limits how much text can fit on the screen</li>
<li>Daylight being a tablet form factor means I have to fiddle around with a configuration that will hold my screen in an ideal angle. It’s reasonably forgiving but certain angles are harder to see with than others</li>
</ul>

  <figure>
    <img src="https://jon.bo/nano-texture/side-by-side-dark.jpg">
    
      <figcaption>2024 MBP on left; 2021 MBP on right. Dark mode is less ideal on both.</figcaption>
    
  </figure>


<p>The Nano Texture MacBook Pro is still ultimately a traditional LCD screen. This means the only way to see the screen is if the backlight is powered on: having the backlight off in direct sunlights results in a black screen. Also, it’s worth noting:</p>
<ul>
<li>white text on black bg is a lot less readable than black text on white bg</li>
<li>the backlight generally has to be at 90%+ to be comfortable</li>
<li>retina display + wide swath of the color spectrum means most of what I can do indoors, I can do outdoors as well</li>
<li>being a laptop with a hinge, it’s very easy to find the exact angle I want that minimizes glare &amp; maximizes comfort</li>
</ul>
<p>Both however are an incredible upgrade over outdoor computing options from just 1 year ago. I believe these are both massive steps in terms of ergonomics and freedom to be in more places as we compute.</p>
<h2 id="some-downsides-to-consider">some downsides to consider</h2>
<ul>
<li>fingerprints, splatters, and smudges are mildly annoying indoors but almost fluorescent outdoors
<ul>
<li>rubbing alcohol cleans them off when friction alone doesn’t do the trick but it still takes some rubbing. as far as I can tell, it’s not degrading the finish but I also try to clean it with the cloth before applying alcohol</li>
</ul>
</li>
<li>they give you one special screen cleaning cloth. I think the ideal number is like 5. Only this one can be used for Nano Texture screens.
<ul>
<li>I read somewhere that this is because traditional microfiber cloths will shred into the screen, degrading visibility (but I can’t remember where so don’t quote me on on this)</li>
<li>I’ve learned to bring my special wipe when I bring my laptop, and I slip a few rubbing alcohol wipes in there as well. I wet the Special Cloth with the alcohol wipes, and then apply the Special Cloth to the screen. This is definitely high maintenance</li>
</ul>
</li>
<li>I have to swat other people’s hands away when they try to point something out on my screen with their pizza fingers</li>
<li>I’m more paranoid about swinging a USB C cable up against my screen or closing my laptop down <a href="https://www.reddit.com/r/mac/comments/ptw21k/chipotle_rice_is_too_powerful/">on a grain of rice</a>. I was less worried with my old screen</li>
<li>The Nano Texture upgrade is an extra $150 on an already-expensive computer</li>
<li>Closing the MacBook results in slight rubbing on the screen at the bottom of the keyboard / top of the trackpad, leaving scratches on the screen. So far this isn’t detrimental when the brightness is up; it’s only visible with the backlight off
<ul>
<li>I don’t think this is a new thing because my old MacBook Pro (glossy screen) has scratches in the same exact place but I am worried about them being more visible on the Nano Texture screen in the long run</li>
</ul>
</li>
</ul>
<h2 id="tldr">tldr</h2>
<p>If you get annoyed by the glare of your screen and don’t mind a bit of extra mental bandwidth to keep your screen clean, I would highly recommend considering a Nano Texture display upgrade on your next laptop purchase. If you have a chaotic environment and can’t be bothered to keep your screen clean, or you aren’t bothered much by glare or reflections in the environments you work in, then the Nano Texture is probably not for you.</p>
<h2 id="further-reading">further reading</h2>
<ul>
<li><a href="https://www.rtings.com/laptop/learn/apple-nano-texture">rtings.com: A Closer Look At Apple’s Nano-Texture Display</a></li>
<li><a href="https://www.tomsguide.com/computing/macbooks/the-new-macbook-pro-m4-is-a-game-changer-for-how-i-work-and-it-has-nothing-to-do-with-apple-intelligence">tomsguide.com: I put the M4 MacBook Pro’s nano-texture display to the test and it’s a game-changer</a></li>
<li><a href="https://patents.google.com/patent/US20220326413A1/en">US20220326413A1: Textured cover assemblies for display applications</a></li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What came first: the CNAME or the A record? (236 pts)]]></title>
            <link>https://blog.cloudflare.com/cname-a-record-order-dns-standards/</link>
            <guid>46681611</guid>
            <pubDate>Mon, 19 Jan 2026 17:13:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/cname-a-record-order-dns-standards/">https://blog.cloudflare.com/cname-a-record-order-dns-standards/</a>, See on <a href="https://news.ycombinator.com/item?id=46681611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2026-01-14</p><section><p>6 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/33gSgvPllx4ibpXHBDvENW/0fd0d5b5e7f2c7cc6ab79cf7f71b55fa/image1.png" alt=""><div><p>On January 8, 2026, a routine update to 1.1.1.1 aimed at reducing memory usage accidentally triggered a wave of DNS resolution failures for users across the Internet. The root cause wasn't an attack or an outage, but a subtle shift in the order of records within our DNS responses.  </p><p>While most modern software treats the order of records in DNS responses as irrelevant, we discovered that some implementations expect CNAME records to appear before everything else. When that order changed, resolution started failing. This post explores the code change that caused the shift, why it broke specific DNS clients, and the 40-year-old protocol ambiguity that makes the "correct" order of a DNS response difficult to define.</p>
    <p>
      <h2 id="timeline">Timeline</h2>
      
    </p>
    <p><i>All timestamps referenced are in Coordinated Universal Time (UTC).</i></p><table><tbody><tr><th><p><b>Time</b></p></th><th><p><b>Description</b></p></th></tr><tr><td><p>2025-12-02</p></td><td><p>The record reordering is introduced to the 1.1.1.1 codebase</p></td></tr><tr><td><p>2025-12-10</p></td><td><p>The change is released to our testing environment</p></td></tr><tr><td><p>2026-01-07 23:48</p></td><td><p>A global release containing the change starts</p></td></tr><tr><td><p>2026-01-08 17:40</p></td><td><p>The release reaches 90% of servers</p></td></tr><tr><td><p>2026-01-08 18:19</p></td><td><p>Incident is declared</p></td></tr><tr><td><p>2026-01-08 18:27</p></td><td><p>The release is reverted</p></td></tr><tr><td><p>2026-01-08 19:55</p></td><td><p>Revert is completed. Impact ends</p></td></tr></tbody></table>
    <p>
      <h2 id="what-happened">What happened?</h2>
      
    </p>
    <p>While making some improvements to lower the memory usage of our cache implementation, we introduced a subtle change to CNAME record ordering. The change was introduced on December 2, 2025, released to our testing environment on December 10, and began deployment on January 7, 2026.</p>
    <p>
      <h3 id="how-dns-cname-chains-work">How DNS CNAME chains work</h3>
      
    </p>
    <p>When you query for a domain like <code>www.example.com</code>, you might get a <a href="https://www.cloudflare.com/learning/dns/dns-records/dns-cname-record/"><u>CNAME (Canonical Name)</u></a> record that indicates one name is an alias for another name. It’s the job of public resolvers, such as <a href="https://www.cloudflare.com/learning/dns/what-is-1.1.1.1/"><u>1.1.1.1</u></a>, to follow this chain of aliases until it reaches a final response:</p><p><code>www.example.com → cdn.example.com → server.cdn-provider.com → 198.51.100.1</code></p><p>As 1.1.1.1 traverses this chain, it caches every intermediate record. Each record in the chain has its own <a href="https://www.cloudflare.com/learning/cdn/glossary/time-to-live-ttl/"><u>TTL (Time-To-Live)</u></a>, indicating how long we can cache it. Not all the TTLs in a CNAME chain need to be the same:</p><p><code>www.example.com → cdn.example.com (TTL: 3600 seconds) # Still cached
cdn.example.com → 198.51.100.1&nbsp; &nbsp; (TTL: 300 seconds)&nbsp; # Expired</code></p><p>When one or more records in a CNAME chain expire, it’s considered partially expired. Fortunately, since parts of the chain are still in our cache, we don’t have to resolve the entire CNAME chain again — only the part that has expired. In our example above, we would take the still valid <code>www.example.com → cdn.example.com</code> chain, and only resolve the expired <code>cdn.example.com</code> <a href="https://www.cloudflare.com/learning/dns/dns-records/dns-a-record/"><u>A record</u></a>. Once that’s done, we combine the existing CNAME chain and the newly resolved records into a single response.</p>
    <p>
      <h3 id="the-logic-change">The logic change</h3>
      
    </p>
    <p>The code that merges these two chains is where the change occurred. Previously, the code would create a new list, insert the existing CNAME chain, and then append the new records:</p>
            <pre><code>impl PartialChain {
    /// Merges records to the cache entry to make the cached records complete.
    pub fn fill_cache(&amp;self, entry: &amp;mut CacheEntry) {
        let mut answer_rrs = Vec::with_capacity(entry.answer.len() + self.records.len());
        answer_rrs.extend_from_slice(&amp;self.records); // CNAMEs first
        answer_rrs.extend_from_slice(&amp;entry.answer); // Then A/AAAA records
        entry.answer = answer_rrs;
    }
}
</code></pre>
            <p>However, to save some memory allocations and copies, the code was changed to instead append the CNAMEs to the existing answer list:</p>
            <pre><code>impl PartialChain {
    /// Merges records to the cache entry to make the cached records complete.
    pub fn fill_cache(&amp;self, entry: &amp;mut CacheEntry) {
        entry.answer.extend(self.records); // CNAMEs last
    }
}
</code></pre>
            <p>As a result, the responses that 1.1.1.1 returned now sometimes had the CNAME records appearing at the bottom, after the final resolved answer.</p>
    <p>
      <h3 id="why-this-caused-impact">Why this caused impact</h3>
      
    </p>
    <p>When DNS clients receive a response with a CNAME chain in the answer section, they also need to follow this chain to find out that <code>www.example.com</code> points to <code>198.51.100.1</code>. Some DNS client implementations handle this by keeping track of the expected name for the records as they’re iterated sequentially. When a CNAME is encountered, the expected name is updated:</p>
            <pre><code>;; QUESTION SECTION:
;; www.example.com.        IN    A

;; ANSWER SECTION:
www.example.com.    3600   IN    CNAME  cdn.example.com.
cdn.example.com.    300    IN    A      198.51.100.1
</code></pre>
            <ol><li><p>Find records for <code>www.example.com</code></p></li><li><p>Encounter <code>www.example.com. CNAME cdn.example.com</code></p></li><li><p>Find records for <code>cdn.example.com</code></p></li><li><p>Encounter <code>cdn.example.com. A 198.51.100.1</code></p></li></ol><p>When the CNAME suddenly appears at the bottom, this no longer works:</p>
            <pre><code>;; QUESTION SECTION:
;; www.example.com.	       IN    A

;; ANSWER SECTION:
cdn.example.com.    300    IN    A      198.51.100.1
www.example.com.    3600   IN    CNAME  cdn.example.com.
</code></pre>
            <ol><li><p>Find records for <code>www.example.com</code></p></li><li><p>Ignore <code>cdn.example.com. A 198.51.100.1</code> as it doesn’t match the expected name</p></li><li><p>Encounter <code>www.example.com. CNAME cdn.example.com</code></p></li><li><p>Find records for <code>cdn.example.com</code></p></li><li><p>No more records are present, so the response is considered empty</p></li></ol><p>One such implementation that broke is the <a href="https://man7.org/linux/man-pages/man3/getaddrinfo.3.html"><code><u>getaddrinfo</u></code></a> function in glibc, which is commonly used on Linux for DNS resolution. When looking at its <code>getanswer_r</code> implementation, we can indeed see it expects to find the CNAME records before any answers:</p>
            <pre><code>for (; ancount &gt; 0; --ancount)
  {
    // ... parsing DNS records ...
    
    if (rr.rtype == T_CNAME)
      {
        /* Record the CNAME target as the new expected name. */
        int n = __ns_name_unpack (c.begin, c.end, rr.rdata,
                                  name_buffer, sizeof (name_buffer));
        expected_name = name_buffer;  // Update what we're looking for
      }
    else if (rr.rtype == qtype
             &amp;&amp; __ns_samebinaryname (rr.rname, expected_name)  // Must match!
             &amp;&amp; rr.rdlength == rrtype_to_rdata_length (type:qtype))
      {
        /* Address record matches - store it */
        ptrlist_add (list:addresses, item:(char *) alloc_buffer_next (abuf, uint32_t));
        alloc_buffer_copy_bytes (buf:abuf, src:rr.rdata, size:rr.rdlength);
      }
  }
</code></pre>
            <p>Another notable affected implementation was the DNSC process in three models of Cisco ethernet switches. In the case where switches had been configured to use 1.1.1.1 these switches experienced spontaneous reboot loops when they received a response containing the reordered CNAMEs. <a href="https://www.cisco.com/c/en/us/support/docs/smb/switches/Catalyst-switches/kmgmt3846-cbs-reboot-with-fatal-error-from-dnsc-process.html"><u>Cisco has published a service document describing the issue</u></a>.</p>
    <p>
      <h3 id="not-all-implementations-break">Not all implementations break</h3>
      
    </p>
    <p>Most DNS clients don’t have this issue. For example, <a href="https://www.freedesktop.org/software/systemd/man/latest/systemd-resolved.service.html"><u>systemd-resolved</u></a> first parses the records into an ordered set:</p>
            <pre><code>typedef struct DnsAnswerItem {
        DnsResourceRecord *rr; // The actual record
        DnsAnswerFlags flags;  // Which section it came from
        // ... other metadata
} DnsAnswerItem;


typedef struct DnsAnswer {
        unsigned n_ref;
        OrderedSet *items;
} DnsAnswer;
</code></pre>
            <p>When following a CNAME chain it can then search the entire answer set, even if the CNAME records don’t appear at the top.</p>
    <p>
      <h2 id="what-the-rfc-says">What the RFC says</h2>
      
    </p>
    <p><a href="https://datatracker.ietf.org/doc/html/rfc1034"><u>RFC 1034</u></a>, published in 1987, defines much of the behavior of the DNS protocol, and should give us an answer on whether the order of CNAME records matters. <a href="https://datatracker.ietf.org/doc/html/rfc1034#section-4.3.1"><u>Section 4.3.1</u></a> contains the following text:</p><blockquote><p>If recursive service is requested and available, the recursive response to a query will be one of the following:</p><p>- The answer to the query, possibly preface by one or more CNAME RRs that specify aliases encountered on the way to an answer.</p></blockquote><p>While "possibly preface" can be interpreted as a requirement for CNAME records to appear before everything else, it does not use normative key words, such as <a href="https://datatracker.ietf.org/doc/html/rfc2119"><u>MUST and SHOULD</u></a> that modern RFCs use to express requirements. This isn’t a flaw in RFC 1034, but simply a result of its age. <a href="https://datatracker.ietf.org/doc/html/rfc2119"><u>RFC 2119</u></a>, which standardized these key words, was published in 1997, 10 years <i>after</i> RFC 1034.</p><p>In our case, we did originally implement the specification so that CNAMEs appear first. However, we did not have any tests asserting the behavior remains consistent due to the ambiguous language in the RFC.</p>
    <p>
      <h3 id="the-subtle-distinction-rrsets-vs-rrs-in-message-sections">The subtle distinction: RRsets vs RRs in message sections</h3>
      
    </p>
    <p>To understand why this ambiguity exists, we need to understand a subtle but important distinction in DNS terminology.</p><p>RFC 1034 <a href="https://datatracker.ietf.org/doc/html/rfc1034#section-3.6"><u>section 3.6</u></a> defines Resource Record Sets (RRsets) as collections of records with the same name, type, and class. For RRsets, the specification is clear about ordering:</p><blockquote><p>The order of RRs in a set is not significant, and need not be preserved by name servers, resolvers, or other parts of the DNS.</p></blockquote><p>However, RFC 1034 doesn’t clearly specify how message sections relate to RRsets. While modern DNS specifications have shown that message sections can indeed contain multiple RRsets (consider <a href="https://www.cloudflare.com/learning/dns/dnssec/how-dnssec-works/">DNSSEC</a> responses with signatures), RFC 1034 doesn’t describe message sections in those terms. Instead, it treats message sections as containing individual Resource Records (RRs).</p><p>The problem is that the RFC primarily discusses ordering in the context of RRsets but doesn't specify the ordering of different RRsets relative to each other within a message section. This is where the ambiguity lives.</p><p>RFC 1034 <a href="https://datatracker.ietf.org/doc/html/rfc1034#section-6.2.1"><u>section 6.2.1</u></a> includes an example that demonstrates this ambiguity further. It mentions that the order of Resource Records (RRs) is not significant either:</p><blockquote><p>The difference in ordering of the RRs in the answer section is not significant.</p></blockquote><p>However, this example only shows two A records for the same name within the same RRset. It doesn't address whether this applies to different record types like CNAMEs and A records.</p>
    <p>
      <h2 id="cname-chain-ordering">CNAME chain ordering</h2>
      
    </p>
    <p>It turns out that this issue extends beyond putting CNAME records before other record types. Even when CNAMEs appear before other records, sequential parsing can still break if the CNAME chain itself is out of order. Consider the following response:</p>
            <pre><code>;; QUESTION SECTION:
;; www.example.com.              IN    A

;; ANSWER SECTION:
cdn.example.com.           3600  IN    CNAME  server.cdn-provider.com.
www.example.com.           3600  IN    CNAME  cdn.example.com.
server.cdn-provider.com.   300   IN    A      198.51.100.1
</code></pre>
            <p>Each CNAME belongs to a different RRset, as they have different owners, so the statement about RRset order being insignificant doesn’t apply here.</p><p>However, RFC 1034 doesn't specify that CNAME chains must appear in any particular order. There's no requirement that <code>www.example.com. CNAME cdn.example.com.</code> must appear before <code>cdn.example.com. CNAME server.cdn-provider.com.</code>. With sequential parsing, the same issue occurs:</p><ol><li><p>Find records for <code>www.example.com</code></p></li><li><p>Ignore <code>cdn.example.com. CNAME server.cdn-provider.com</code>. as it doesn’t match the expected name</p></li><li><p>Encounter <code>www.example.com. CNAME cdn.example.com</code></p></li><li><p>Find records for <code>cdn.example.com</code></p></li><li><p>Ignore <code>server.cdn-provider.com. A 198.51.100.1</code> as it doesn’t match the expected name</p></li></ol>
    <p>
      <h2 id="what-should-resolvers-do">What should resolvers do?</h2>
      
    </p>
    <p>RFC 1034 section 5 describes resolver behavior. <a href="https://datatracker.ietf.org/doc/html/rfc1034#section-5.2.2"><u>Section 5.2.2</u></a> specifically addresses how resolvers should handle aliases (CNAMEs): </p><blockquote><p>In most cases a resolver simply restarts the query at the new name when it encounters a CNAME.</p></blockquote><p>This suggests that resolvers should restart the query upon finding a CNAME, regardless of where it appears in the response. However, it's important to distinguish between different types of resolvers:</p><ul><li><p>Recursive resolvers, like 1.1.1.1, are full DNS resolvers that perform recursive resolution by querying authoritative nameservers</p></li><li><p>Stub resolvers, like glibc’s getaddrinfo, are simplified local interfaces that forward queries to recursive resolvers and process the responses</p></li></ul><p>The RFC sections on resolver behavior were primarily written with full resolvers in mind, not the simplified stub resolvers that most applications actually use. Some stub resolvers evidently don’t implement certain parts of the spec, such as the CNAME-restart logic described in the RFC. </p>
    <p>
      <h2 id="the-dnssec-specifications-provide-contrast">The DNSSEC specifications provide contrast</h2>
      
    </p>
    <p>Later DNS specifications demonstrate a different approach to defining record ordering. <a href="https://datatracker.ietf.org/doc/html/rfc4035"><u>RFC 4035</u></a>, which defines protocol modifications for <a href="https://www.cloudflare.com/learning/dns/dnssec/how-dnssec-works/"><u>DNSSEC</u></a>, uses more explicit language:</p><blockquote><p>When placing a signed RRset in the Answer section, the name server MUST also place its RRSIG RRs in the Answer section. The RRSIG RRs have a higher priority for inclusion than any other RRsets that may have to be included.</p></blockquote><p>The specification uses "MUST" and explicitly defines "higher priority" for <a href="https://www.cloudflare.com/learning/dns/dnssec/how-dnssec-works/"><u>RRSIG</u></a> records. However, "higher priority for inclusion" refers to whether RRSIGs should be included in the response, not where they should appear. This provides unambiguous guidance to implementers about record inclusion in DNSSEC contexts, while not mandating any particular behavior around record ordering.</p><p>For unsigned zones, however, the ambiguity from RFC 1034 remains. The word "preface" has guided implementation behavior for nearly four decades, but it has never been formally specified as a requirement.</p>
    <p>
      <h2 id="do-cname-records-come-first">Do CNAME records come first?</h2>
      
    </p>
    <p>While in our interpretation the RFCs do not require CNAMEs to appear in any particular order, it’s clear that at least some widely-deployed DNS clients rely on it. As some systems using these clients might be updated infrequently, or never updated at all, we believe it’s best to require CNAME records to appear in-order before any other records.</p><p>Based on what we have learned during this incident, we have reverted the CNAME re-ordering and do not intend to change the order in the future.</p><p>To prevent any future incidents or confusion, we have written a proposal in the form of an <a href="https://www.ietf.org/participate/ids/"><u>Internet-Draft</u></a> to be discussed at the IETF. If consensus is reached on the clarified behavior, this would become an RFC that explicitly defines how to correctly handle CNAMEs in DNS responses, helping us and the wider DNS community navigate the protocol. The proposal can be found at <a href="https://datatracker.ietf.org/doc/draft-jabley-dnsop-ordered-answer-section/">https://datatracker.ietf.org/doc/draft-jabley-dnsop-ordered-answer-section</a>. If you have suggestions or feedback we would love to hear your opinions, most usefully via the <a href="https://datatracker.ietf.org/wg/dnsop/about/"><u>DNSOP working group</u></a> at the IETF.</p></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><astro-slot> <!--[if astro]>server-island-start<![endif]--> </astro-slot><a href="https://blog.cloudflare.com/tag/1-1-1-1/">1.1.1.1</a><a href="https://blog.cloudflare.com/tag/post-mortem/">Post Mortem</a><a href="https://blog.cloudflare.com/tag/dns/">DNS</a><a href="https://blog.cloudflare.com/tag/resolver/">Resolver</a><a href="https://blog.cloudflare.com/tag/standards/">Standards</a><a href="https://blog.cloudflare.com/tag/bugs/">Bugs</a><a href="https://blog.cloudflare.com/tag/consumer-services/">Consumer Services</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fix your robots.txt or your site disappears from Google (101 pts)]]></title>
            <link>https://www.alanwsmith.com/en/37/wa/jz/s1/</link>
            <guid>46681454</guid>
            <pubDate>Mon, 19 Jan 2026 17:03:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alanwsmith.com/en/37/wa/jz/s1/">https://www.alanwsmith.com/en/37/wa/jz/s1/</a>, See on <a href="https://news.ycombinator.com/item?id=46681454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<section>
      <p>January 2026</p>
    
    <hgroup>
      </hgroup></section>


<section>
  <h2>TL;DR</h2>


<p>Your site will be removed from Google search results if you don't have a robots.txt file or the Googlebot site crawler can't access it.</p>


<p>Here's the video from Google Support that covers it:</p>


<section><youtube-player :video="2LJKNiQJ8LA"></youtube-player>


</section></section>





<section>

  <h2>Wait, what?</h2>


<p><a href="https://www.alanwsmith.com/en/37/wa/jz/s1/adamcoster.com">Adam Coster</a> ran into a weird issue with site traffic and posted about it in the <a href="https://shoptalkshow.com/">Shop Talk Show</a> discord. Traffic incoming from Google looked like this:</p></section>




<section>
    <img src="https://www.alanwsmith.com/neo-files/images/google-robots-txt-issue/google-robots-txt-issue.avif" alt="A graph showing Clicks and Impressions for website traffice. The x axis starts on July 7, 2025 and goes to November 28, 2025. There's a mid point for August 16th. Clicks and Impressions bounche up and down prior to the August date with maxes at 240 clicks and 7.5K impressions on the Y axis. Everything drops to zero when it hits the August date.">
</section>


<section>


<p>The issues seemed to be that Google wouldn't index the site without a robots.txt file.</p>


<p>My first reaction: No fucking way.</p>


<p>I can't imagine Google voluntarily slurping up less content. I went to see what I could find. Sure enough, I found this page from Google Support from July 23, 2025:</p>


<p><a href="https://support.google.com/webmasters/community-video/360202946/fix-robots-txt-unreachable-error-website-not-indexing"> Fix 'robots.txt unreachable' Error ~ Website Not Indexing?</a></p>


<p>The pull quote from the video on the page:</p></section>


<section>
  <blockquote>


<p>Your robots.txt file is the very first thing Googlebot looks for. If it can not reach this file, it will stop and won't crawl the rest of your site. Meaning your pages will remain invisible (on Google).</p></blockquote>
</section>


<section>


<p>Holy shit.</p>


<p>I haven't looked to see if this was a recent change, but it <em>has</em> to be. There's no way something so fundamental has just slipped by without becoming common knowledge.</p>


<p>But, the timeline doesn't matter. It's how things are now.</p>


<p>This absolutely blows my mind. I don't have tracking on my site. I never would have noticed this if someone hadn't pointed it out.</p>


<p>Just wild,</p>


<p>-a</p></section>


</div><div>
          <section>
            <h3>Endnotes</h3>
            <div>
          
        


<section>
  


<p>Thanks to Adam for letting me share the traffic graph.</p>
</section>


<section>
  


<p>If you need a quick fix, create a text file at the root of your website called "robots.txt" (e.g. https://www.example.com/robots.txt). Put the following contents in it:</p>


<section><pre><code><span></span><span>User-agent: *
<span></span>Allow: /</span></code></pre></section>


<section>


<p>This is the code from Google's <a href="https://developers.google.com/crawling/docs/robots-txt/create-robots-txt">How to write and submit a robots.txt file </a> page. It provides explicit permission for the Googlebot (and other bots/crawlers/scrapers that use the file) to access anything they can find on your site.</p>


<p>You can read more about the file on the <a href="https://en.wikipedia.org/wiki/Robots.txt">robots.txt wikipedia page</a>.</p></section>
</section>





<section>
  


<p>The <a href="https://stackoverflow.com/a/4277017/102401">top Stack Overflow answer</a> on robots.txt has a discussion about <code><span>Allow: /</span></code> not being valid according to the spec. The only date for the comments is "Over a year ago" but given that the question is from 2010 the comments are probably from around that time.</p>


<p>As of at least the <a href="https://datatracker.ietf.org/doc/html/rfc9309">Sept. 2022 spec from the Internet Engineering Task Force</a>, the <code><span>Allow: /</span></code> syntax is valid.</p>
</section>


<section>
  


<p>I don't have a robots.txt right now. It hasn't been there in a long time. Google still shows two results when I search for files on my site though:</p>




<section>
    <img src="https://www.alanwsmith.com/neo-files/images/google-site-search-results/google-site-search-results.avif" alt="A screenshot of the search results for 'site: alanwsmith.com' with only two results.">
</section>


<section>


<p>No idea if that's because of external links or the fact that they are in the index from a long time ago. But,</p></section>


<section><ul>


<li>
I've got north of 3K posts on the site. I know a ton of them showed up in the past, if not all of them.</li>


<li>
I made a bunch of posts between the first Dec. 27, 2025 result and the second one from "one day ago" which was Jan. 6, 2026. No idea why just those two are showing up.</li>


<li>
I used to have the first search result for "bama braves logo" in general google search, but that page is no longer in the index.</li></ul>
</section>
</section>





<section>
  


<p>The video says Googlebot stops it if can't access the robots.txt file. I'm taking that to mean that the file must exist. It's possible that Googlebot will continue if the file doesn't exist and returns a 404.</p>


<p>The video doesn't address that specifically, but I interpret the content to mean that a missing file stops the bot. Especially because Adam's site didn't have one which started this whole post.</p>
</section>


<section>
  


<p>Maybe Google is trying to play nice with the way it ingests data given all the AI crawlers that are slamming sites these days?</p>


<p>I'm super curious what discussions led to the requirement for the file.</p>
</section>
            </div>
          </section>
    
        <section>
            <h3>References</h3>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple testing new App Store design that blurs the line between ads and results (261 pts)]]></title>
            <link>https://9to5mac.com/2026/01/16/iphone-apple-app-store-search-results-ads-new-design/</link>
            <guid>46680974</guid>
            <pubDate>Mon, 19 Jan 2026 16:36:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2026/01/16/iphone-apple-app-store-search-results-ads-new-design/">https://9to5mac.com/2026/01/16/iphone-apple-app-store-search-results-ads-new-design/</a>, See on <a href="https://news.ycombinator.com/item?id=46680974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">
	</figure>

<p>Apple is testing a new design for App Store search ads on iPhone. Some users on iOS 26.3 are noticing that the blue background around sponsored results is no longer shown, blurring the line between what paid ad results look like and the real search results that follow.</p>



<p>This means the only differentiator between organic results and the promoted ad is the presence of the small ‘Ad’ banner next to the app icon. Right now, it appears to be in some kind of A/B test phase.</p>



<p>We have asked Apple for clarity on the change, and whether this will roll out more widely in the future.</p>



<p>It may be related to the <a href="https://9to5mac.com/2025/12/17/apple-announces-more-ads-are-coming-to-app-store-search-results/">company’s announcement from December</a> that App Store search results will soon start including more than one sponsored result for a given search query. The removal of the blue background will mean all of the ads will appear in the list in a more integrated fashion.</p>



<figure><img decoding="async" height="920" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?quality=82&amp;strip=all&amp;w=1024" alt="" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg 3717w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=145,130 145w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=655,589 655w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=768,690 768w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=1024,920 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=1536,1381 1536w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=2048,1841 2048w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=350,315 350w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=140,126 140w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=1113,1000 1113w, https://9to5mac.com/wp-content/uploads/sites/6/2026/01/app-store-search-ads-side-by-side.jpg?resize=150,135 150w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Of course, this also has the effect of making it harder for users to quickly distinguish at a glance what is an ad and what isn’t, potentially misleading some users into not realising that the first result is a paid ad placement. While not great for user experience, it probably helps increase click-through rates which ultimately boosts Apple’s revenue in its ads business.</p>
	<p><a target="_blank" rel="nofollow" href="https://google.com/preferences/source?q=https://9to5mac.com" aria-label="Add 9to5Mac as a preferred source on Google">
			<img decoding="async" src="https://9to5mac.com/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-dark.png" alt="Add 9to5Mac as a preferred source on Google">
			<img decoding="async" src="https://9to5mac.com/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-light.png" alt="Add 9to5Mac as a preferred source on Google">
		</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/4brHwnp"><img src="https://9to5mac.com/wp-content/uploads/sites/6/2026/01/970-x-250-1.jpg?quality=82&amp;strip=all" alt="" width="970" height="250"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Microstructure of Wealth Transfer in Prediction Markets (127 pts)]]></title>
            <link>https://www.jbecker.dev/research/prediction-market-microstructure</link>
            <guid>46680515</guid>
            <pubDate>Mon, 19 Jan 2026 16:05:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jbecker.dev/research/prediction-market-microstructure">https://www.jbecker.dev/research/prediction-market-microstructure</a>, See on <a href="https://news.ycombinator.com/item?id=46680515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="article"><p><img src="https://raw.githubusercontent.com/Jon-Becker/research/main/papers/prediction-market-microstructure/preview.png?fw" alt="preview"></p>
<p>Slot machines on the Las Vegas Strip return about 93 cents on the dollar. This is widely considered some of the worst odds in gambling. Yet on Kalshi, a CFTC-regulated prediction market, traders have wagered vast sums on longshot contracts with historical returns as low as 43 cents on the dollar. Thousands of participants are voluntarily accepting expected values far lower than a casino slot machine to bet on their convictions.</p>
<p>The <a href="https://www.jstor.org/stable/2325486">efficient market hypothesis</a> suggests that asset prices should perfectly aggregate all available information. Prediction markets theoretically provide the purest test of this theory. Unlike equities, there is no ambiguity about intrinsic value. A contract either pays $1 or it does not. A price of 5 cents should imply exactly a 5% probability.</p>
<p>We analyzed <span data-context="Data collected from Kalshi's public REST API, 2021-2025"><strong>72.1 million trades</strong></span> covering <strong>$18.26 billion</strong> in volume to test this efficiency. Our findings suggest that collective accuracy relies less on rational actors than on a mechanism for harvesting error. We document a systematic wealth transfer where impulsive <em>Takers</em> pay a structural premium for affirmative "YES" outcomes while <em>Makers</em> capture an "Optimism Tax" simply by selling into this biased flow. The effect is strongest in high-engagement categories like Sports and Entertainment, while low-engagement categories like Finance approach perfect efficiency.</p>
<p>This paper makes three contributions. First, it confirms the presence of the longshot bias on Kalshi and quantifies its magnitude across price levels. Second, it decomposes returns by market role, revealing a persistent wealth transfer from takers to makers driven by asymmetric order flow. Third, it identifies a YES/NO asymmetry where takers disproportionately favor affirmative bets at longshot prices, exacerbating their losses.</p>
<h2 id="prediction-markets-and-kalshi">Prediction Markets and Kalshi</h2>
<p>Prediction markets are exchanges where participants trade binary contracts on real-world outcomes. These contracts settle at either $1 or $0, with prices ranging from 1 to 99 cents serving as probability proxies. Unlike equity markets, prediction markets are strictly zero-sum: every dollar of profit corresponds exactly to a dollar of loss.</p>
<p><a href="https://kalshi.com/">Kalshi</a> launched in 2021 as the first U.S. prediction market regulated by the CFTC. Initially focused on economic and weather data, the platform stayed niche until 2024. A <a href="https://media.cadc.uscourts.gov/opinions/docs/2024/10/24-5205-2077790.pdf">legal victory</a> over the CFTC secured the right to list political contracts, and the 2024 election cycle triggered explosive growth. Sports markets, introduced in 2025, now dominate trading activity.</p>

<p>Volume distribution across categories is highly uneven. Sports accounts for 72% of notional volume, followed by politics at 13% and crypto at 5%.</p>

<blockquote>
<p><strong>Note:</strong> Data collection concluded on 2025-11-25 at 17:00 ET; Q4 2025 figures are incomplete.</p>
</blockquote>
<h2 id="data-and-methodology">Data and Methodology</h2>
<p>The dataset, <a href="https://github.com/jon-becker/prediction-market-analysis">available on GitHub</a>, contains <span data-context="Data was acquired from Kalshi's public REST API, and spans from 16:09 ET 2021-06-30 to 17:00 ET 2025-11-25."><strong>7.68 million markets</strong> and <strong>72.1 million trades</strong></span>. Each trade records the execution price (1-99 cents), taker side (yes/no), contract count, and timestamp. Markets include resolution outcome and category classification.</p>
<ul>
<li>
<p><strong>Role assignment:</strong> Each trade identifies the liquidity taker. The maker took the opposite position. If <code>taker_side = yes</code> at 10 cents, the taker bought YES at 10¢; the maker bought NO at 90¢.</p>
</li>
<li>
<p><strong>Cost Basis (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">C_b</annotation></semantics></math></span></span>)</strong>: To compare asymmetries between YES and NO contracts, we normalize all trades by capital risked. For a standard YES trade at 5 cents, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>b</mi></msub><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">C_b = 5</annotation></semantics></math></span></span>. For a NO trade at 5 cents, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>b</mi></msub><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">C_b = 5</annotation></semantics></math></span></span>. All references to "Price" in this paper refer to this Cost Basis unless otherwise noted.</p>
</li>
<li>
<p><strong>Mispricing</strong> (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">\delta_S</annotation></semantics></math></span></span>) measures the divergence between actual win rate and implied probability for a subset of trades <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span></span>:</p>
</li>
</ul>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>δ</mi><mi>S</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><mi>S</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi></mrow></munder><msub><mi>o</mi><mi>i</mi></msub><mo>−</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><mi>S</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi></mrow></munder><mfrac><msub><mi>p</mi><mi>i</mi></msub><mn>100</mn></mfrac></mrow><annotation encoding="application/x-tex">\delta_S = \frac{1}{|S|} \sum_{i \in S} o_i - \frac{1}{|S|} \sum_{i \in S} \frac{p_i}{100}</annotation></semantics></math></span></span></span>
<ul>
<li><strong>Gross Excess return</strong> (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span></span>) is the return relative to cost, gross of platform fees, where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span></span> is price in cents and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">o_i \in \{0, 1\}</annotation></semantics></math></span></span> is the outcome:</li>
</ul>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>100</mn><mo>⋅</mo><msub><mi>o</mi><mi>i</mi></msub><mo>−</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><msub><mi>p</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding="application/x-tex">r_i = \frac{(100 \cdot o_i - p_i)}{p_i}</annotation></semantics></math></span></span></span>
<h3 id="sample">Sample</h3>
<p>Calculations derive from <strong>resolved markets</strong> only. Markets that were voided, delisted, or remain open are excluded. Additionally, trades from markets with less than $100 in notional volume were excluded. The dataset remains robust across all price levels; the sparsest bin (81-90¢) contains 5.8 million trades.</p>

<h2 id="the-longshot-bias-on-kalshi">The Longshot Bias on Kalshi</h2>
<p>First documented by <a href="https://www.jstor.org/stable/1418469">Griffith (1949)</a> in horse racing and later formalized by <a href="https://www.aeaweb.org/articles?id=10.1257/jep.2.2.161">Thaler &amp; Ziemba (1988)</a> in their analysis of parimutuel betting markets, the longshot bias describes the tendency for bettors to overpay for low-probability outcomes. In efficient markets, a contract priced at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span> cents should win approximately <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span>% of the time. In markets exhibiting longshot bias, low-priced contracts win <em>less</em> than their implied probability, while high-priced contracts win <em>more</em>.</p>
<p>The data confirms this pattern on Kalshi. Contracts trading at <strong>5 cents</strong> win only <span data-context="Combined maker+taker win rate at 5¢; n=1,407,530 trades"><strong>4.18%</strong></span> of the time, implying mispricing of <strong>-16.36%</strong>. Conversely, contracts at <strong>95 cents</strong> win <span data-context="Combined maker+taker win rate at 95¢; n=TODO trades"><strong>95.83%</strong></span> of the time. This pattern is consistent; all contracts priced below 20 cents underperform their odds, while those above 80 cents outperform.</p>

<p>The existence of the longshot bias raises a question unique to zero-sum markets: if some traders systematically overpay, who captures the surplus?</p>
<h2 id="the-maker-taker-wealth-transfer">The Maker-Taker Wealth Transfer</h2>
<h3 id="decomposing-returns-by-role">Decomposing Returns by Role</h3>
<p>Market microstructure defines two populations based on their interaction with the order book. A <strong>Maker</strong> provides liquidity by placing limit orders that rest on the book. A <strong>Taker</strong> consumes this liquidity by executing against resting orders.</p>
<p>Decomposing aggregate returns by role reveals a stark asymmetry:</p>




















<div><table><thead><tr><th>Role</th><th>Avg. Excess Return</th><th>95% CI</th></tr></thead><tbody><tr><td>Taker</td><td>-1.12%</td><td>[-1.13%, -1.11%]</td></tr><tr><td>Maker</td><td>+1.12%</td><td>[+1.11%, +1.13%]</td></tr></tbody></table></div>

<p>The divergence is most pronounced at the tails. At 1-cent contracts, takers win only <span data-context="n=1,343,181 taker trades at 1¢"><strong>0.43%</strong></span> of the time against an implied probability of 1%, corresponding to a mispricing of <strong>-57%</strong>. Makers on the same contracts win <span data-context="n=996,039 maker trades at 1¢"><strong>1.57%</strong></span> of the time, resulting in a mispricing of <strong>+57%</strong>. At 50 cents, mispricing compresses; takers show <span data-context="n=888,442 taker trades at 50¢"><strong>-2.65%</strong></span>, and makers show <span data-context="n=888,519 maker trades at 50¢"><strong>+2.66%</strong></span>.</p>
<p>Takers exhibit negative excess returns at <span data-context="80 of 99 price levels"><strong>80 of 99 price levels</strong></span>. Makers exhibit positive excess returns at the same 80 levels. The market's aggregate miscalibration is concentrated in a specific population; takers bear the losses while makers capture the gains.</p>
<h3 id="is-this-just-spread-compensation">Is This Just Spread Compensation?</h3>
<p>An obvious objection arises; makers earn the bid-ask spread as compensation for providing liquidity. Their positive returns may simply reflect spread capture rather than the exploitation of biased flow. While plausible, two observations suggest otherwise.</p>
<p>The first observation suggests the effect extends beyond pure spread capture; maker returns depend on which side they take. If profits were purely spread-based, it should not matter whether makers bought YES or NO. We test this by decomposing maker performance by position direction:</p>

<p>Makers who buy NO outperform makers who buy YES <span data-context="59 of 99 price levels"><strong>59% of the time</strong></span>. The volume-weighted excess return is <strong>+0.77 pp</strong> for makers buying YES versus <strong>+1.25 pp</strong> for makers buying NO, a gap of 0.47 percentage points. The effect is miniscule (Cohen's d = 0.02-0.03) but consistent. At minimum, this suggests spread capture is not the whole story.</p>
<p>A second observation strengthens the case further; the maker-taker gap varies substantially by market category.</p>
<h3 id="variation-across-categories">Variation Across Categories</h3>
<p>We examine whether the maker-taker gap varies by market category. If the bias reflects uninformed demand, categories attracting less sophisticated participants should show larger gaps.</p>




































































<div><table><thead><tr><th>Category</th><th>Taker Return</th><th>Maker Return</th><th>Gap</th><th>N trades</th></tr></thead><tbody><tr><td>Sports</td><td>-1.11%</td><td>+1.12%</td><td>2.23 pp</td><td>43.6M</td></tr><tr><td>Politics</td><td>-0.51%</td><td>+0.51%</td><td>1.02 pp</td><td>4.9M</td></tr><tr><td>Crypto</td><td>-1.34%</td><td>+1.34%</td><td>2.69 pp</td><td>6.7M</td></tr><tr><td>Finance</td><td>-0.08%</td><td>+0.08%</td><td>0.17 pp</td><td>4.4M</td></tr><tr><td>Weather</td><td>-1.29%</td><td>+1.29%</td><td>2.57 pp</td><td>4.4M</td></tr><tr><td>Entertainment</td><td>-2.40%</td><td>+2.40%</td><td>4.79 pp</td><td>1.5M</td></tr><tr><td>Media</td><td>-3.64%</td><td>+3.64%</td><td>7.28 pp</td><td>0.6M</td></tr><tr><td>World Events</td><td>-3.66%</td><td>+3.66%</td><td>7.32 pp</td><td>0.2M</td></tr></tbody></table></div>

<p>The variation is striking. Finance shows a gap of merely <strong>0.17 pp</strong>; the market is extremely efficient, with takers losing only 0.08% per trade. At the other extreme, World Events and Media show gaps exceeding 7 percentage points. Sports, the largest category by volume, exhibits a moderate gap of 2.23 pp. Given $6.1 billion in taker volume, even this modest gap generates substantial wealth transfer.</p>
<p>Why is Finance efficient? The likely explanation is participant selection; financial questions attract traders who think in probabilities and expected values rather than fans betting on their favorite team or partisans betting on a preferred candidate. The questions themselves are dry ("Will the S&amp;P close above 6000?"), which filters out emotional bettors.</p>
<h3 id="evolution-over-time">Evolution Over Time</h3>
<p>The maker-taker gap is not a fixed feature of the market; rather, it emerged as the platform grew. In Kalshi's early days, the pattern was reversed; takers earned positive excess returns while makers lost money.</p>

<p>From launch through 2023, taker returns averaged <strong>+2.0%</strong> while maker returns averaged <strong>-2.0%</strong>. Without sophisticated counterparties, takers won; amateur makers defined the early period and were the losing population. This began to reverse in 2024 Q2, with the gap crossing zero and then widening sharply after the 2024 election.</p>
<p>The inflection point coincides with two events; Kalshi's legal victory over the CFTC in October 2024, which permitted political contracts, and the subsequent 2024 election cycle. Volume exploded from $30 million in 2024 Q3 to $820 million in 2024 Q4. The new volume attracted sophisticated market makers, and with them, the extraction of value from taker flow.</p>
<p>Pre-election, the average gap was -2.9 pp (takers winning); post-election, it flipped to +2.5 pp (makers winning), a swing of 5.3 percentage points.</p>
<p>The composition of taker flow provides further evidence. If the wealth transfer arose because new participants arrived with stronger longshot preferences, we would expect the distribution to shift toward low-probability contracts. It did not:</p>

<p>The share of taker volume in longshot contracts (1-20¢) remained essentially flat; <strong>4.8%</strong> pre-election versus <strong>4.6%</strong> post-election. The distribution actually shifted <em>toward</em> the middle; the 91-99¢ bucket fell from 40-50% in 2021-2023 to under 20% in 2025, while mid-range prices (31-70¢) grew substantially. Taker behavior did not become more biased; if anything, it became less extreme. Yet taker losses increased; new market makers extract value more efficiently across all price levels.</p>
<p>This evolution reframes the aggregate results. The wealth transfer from takers to makers is not inherent to prediction market microstructure; it requires sophisticated market makers, and sophisticated market makers require sufficient volume to justify participation. In the low-volume early period, makers were likely unsophisticated individuals who lost to relatively informed takers. The volume surge attracted professional liquidity providers capable of extracting value from taker flow at all price points.</p>
<h2 id="the-yesno-asymmetry">The YES/NO Asymmetry</h2>
<p>The maker-taker decomposition identifies <em>who</em> absorbs the losses, but leaves open the question of <em>how</em> their selection bias operates. Why is taker flow so consistently mispriced? The answer is not that makers possess superior foresight, but rather that takers exhibit a costly preference for affirmative outcomes.</p>
<h3 id="the-asymmetry-at-equivalent-prices">The Asymmetry at Equivalent Prices</h3>
<p>Standard efficiency models imply that mispricing should be symmetric across contract types at equivalent prices; a 1-cent YES contract and a 1-cent NO contract should theoretically reflect similar expected values. The data contradicts this assumption. At a price of 1 cent, a YES contract carries a historical expected value of -41%; buyers lose nearly half their capital in expectation. Conversely, a NO contract at the same 1-cent price delivers a historical expected value of +23%. The divergence between these seemingly identical probability estimates is 64 percentage points.</p>

<p>The advantage for NO contracts is persistent. NO outperforms YES at <span data-context="Cohen's d = 0.27">69 of 99 price levels</span>, with the advantage concentrating at the market extremes. NO contracts generate superior returns at every price increment from <span data-context="Cohen's d = 1.09">1 to 10 cents</span> and again from <span data-context="Cohen's d = 1.11">91 to 99 cents</span>.</p>
<p>Despite the market being zero-sum, dollar-weighted returns are -1.02% for YES buyers compared to +0.83% for NO buyers, a 1.85 percentage point gap driven by the overpricing of YES contracts.</p>
<h3 id="takers-prefer-affirmative-bets">Takers Prefer Affirmative Bets</h3>
<p>The underperformance of YES contracts may be linked to taker behavior. Breaking down the trading data reveals a structural imbalance in order flow composition.</p>

<p>In the 1-10 cent range, where YES represents the longshot outcome, takers account for 41-47% of YES volume; makers account for only 20-24%. This imbalance inverts at the opposite end of the probability curve. When contracts trade at 99 cents, implying that NO is the 1-cent longshot, makers actively purchase NO contracts at 43% of volume. Takers participate at a rate of only 23%.</p>
<p>One might hypothesize that makers exploit this asymmetry through superior directional forecasting—that they simply know when to buy NO. The evidence does not support this. When decomposing maker performance by position direction, returns are nearly identical. Statistically significant differences emerge only at the extreme tails (1–10¢ and 91–99¢), and even there, effect sizes are negligible (Cohen's d = 0.02–0.03). This symmetry is telling: makers do not profit by knowing which way to bet, but through some mechanism that applies equally to both directions.</p>
<h2 id="discussion">Discussion</h2>
<p>The analysis of 72.1 million trades on Kalshi reveals a distinct market microstructure where wealth systematically transfers from liquidity takers to liquidity makers. This phenomenon is driven by specific behavioral biases, modulated by market maturity, and concentrated in categories that elicit high emotional engagement.</p>

<p>A central question in zero-sum market analysis is whether profitable participants win through superior information (forecasting) or superior structure (market making). Our data strongly supports the latter. When decomposing maker returns by position direction, the performance gap is negligible: makers buying "YES" earn an excess return of +0.77%, while those buying "NO" earn +1.25% (Cohen’s d ≈ 0.02). This statistical symmetry indicates that makers do not possess a significant ability to pick winners. Instead, they profit via a structural arbitrage: providing liquidity to a taker population that exhibits a costly preference for affirmative, longshot outcomes.</p>
<p><img src="https://raw.githubusercontent.com/Jon-Becker/research/refs/heads/main/papers/prediction-market-microstructure/fig/mechanism.png?fw" alt="mechanism diagram"></p>
<p>This extraction mechanism relies on the "Optimism Tax." Takers disproportionately purchase "YES" contracts at longshot prices, accounting for nearly half of all volume in that range, despite "YES" longshots underperforming "NO" longshots by up to 64 percentage points. Makers, therefore, do not need to predict the future; they simply need to act as the counterparty to optimism. This aligns with findings by <a href="https://ssrn.com/abstract=5910522">Reichenbach and Walther (2025)</a> on Polymarket and <a href="https://mpra.ub.uni-muenchen.de/126351/1/MPRA_paper_126351.pdf">Whelan (2025)</a> on Betfair, suggesting that in prediction markets, makers accommodate biased flow rather than out-forecast it.</p>
<h3 id="the-professionalization-of-liquidity">The Professionalization of Liquidity</h3>
<p>The temporal evolution of maker-taker returns challenges the assumption that longshot bias inevitably leads to wealth transfer. From 2021 through 2023, the bias existed, yet takers maintained positive excess returns. The reversal of this trend coincides precisely with the explosive volume growth following Kalshi’s October 2024 legal victory.</p>
<p>The wealth transfer observed in late 2024 is a function of <strong>market depth</strong>. In the platform's infancy, low liquidity likely deterred sophisticated algorithmic market makers, leaving the order book to be populated by amateurs who were statistically indistinguishable from takers. The massive volume surge following the 2024 election incentivized the entry of professional liquidity providers capable of systematically capturing the spread and exploiting the biased flow. The longshot bias itself may have persisted for years, but it was only once market depth grew sufficiently to attract these sophisticated makers that the bias became a reliable source of profit extraction.</p>
<h3 id="category-differences-and-participant-selection">Category Differences and Participant Selection</h3>
<p>The variation in maker-taker gaps across categories reveals how participant selection shapes market efficiency. At one extreme, Finance exhibits a gap of just 0.17 percentage points; nearly perfect efficiency. At the other, World Events and Media exceed 7 percentage points. This difference cannot be explained by the longshot bias alone; it reflects who chooses to trade in each category.</p>
<ul>
<li>
<p><strong>Finance (0.17 pp)</strong> serves as a control group demonstrating that prediction markets can approach efficiency. Questions like "Will the S&amp;P close above 6000?" attract participants who think in probabilities and expected values, likely the same population that trades options or follows macroeconomic data. The barrier to informed participation is high, and casual bettors have no edge and likely recognize this, filtering themselves out.</p>
</li>
<li>
<p><strong>Politics (1.02 pp)</strong> shows moderate inefficiency despite high emotional stakes. Political bettors follow polling closely and have practiced calibrating beliefs through election cycles. The gap is larger than Finance but far smaller than entertainment categories, suggesting that political engagement, while emotional, does not entirely erode probabilistic reasoning.</p>
</li>
<li>
<p><strong>Sports (2.23 pp)</strong> represents the modal prediction market participant. The gap is moderate but consequential given the category's 72% volume share. Sports bettors exhibit well-documented biases, including home team loyalty, recency effects, and narrative attachment to star players. A fan betting on their team to win the championship is not calculating expected value; they are purchasing hope.</p>
</li>
<li>
<p><strong>Crypto (2.69 pp)</strong> attracts participants conditioned by the "number go up" mentality of retail crypto markets, a population overlapping with meme stock traders and NFT speculators. Questions like "Will Bitcoin reach $100k?" invite narrative-driven betting rather than probability estimation.</p>
</li>
<li>
<p><strong>Entertainment, Media, and World Events (4.79–7.32 pp)</strong> exhibit the largest gaps and share a common feature: minimal barriers to perceived expertise. Anyone who follows celebrity gossip feels qualified to bet on award show outcomes; anyone who reads headlines feels informed about geopolitics. This creates a participant pool that conflates familiarity with calibration.</p>
</li>
</ul>
<p>The pattern suggests efficiency depends on two factors: the technical barrier to informed participation and the degree to which questions invite emotional reasoning. When barriers are high and framing is clinical, markets approach efficiency; when barriers are low and framing invites storytelling, the optimism tax reaches its maximum.</p>
<h3 id="limitations">Limitations</h3>
<p>While the data is robust, several limitations persist. First, the absence of unique trader IDs forces us to rely on the "Maker/Taker" classification as a proxy for "Sophisticated/Unsophisticated." While standard in microstructure literature, this imperfectly captures instances where sophisticated traders cross the spread to act on time-sensitive information. Second, we cannot directly observe the bid-ask spread in historical trade data, making it difficult to strictly decouple spread capture from explotation of biased flow. Finally, these results are specific to a US-regulated environment; offshore venues with different leverage caps and fee structures may exhibit different dynamics.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The promise of prediction markets lies in their ability to aggregate diverse information into a single, accurate probability. However, our analysis of Kalshi demonstrates that this signal is often distorted by systematic wealth transfer driven by human psychology and market microstructure.</p>
<p>The market is split into two distinct populations: a taker class that systematically overpays for low-probability, affirmative outcomes, and a maker class that extracts this premium through passive liquidity provision. This dynamic is not an inherent flaw of the "wisdom of the crowd," but rather a feature of how human psychology interacts with market microstructure. When the topic is dry and quantitative (Finance), the market is efficient. When the topic allows for tribalism and hope (Sports, Entertainment), the market transforms into a mechanism for transferring wealth from the optimistic to the calculated.</p>
<h2 id="references">References</h2>
<ul>
<li>Fama, E.F., "Efficient Capital Markets: A Review of Theory and Empirical Work", Journal of Finance, 1970. Available: <a href="https://www.jstor.org/stable/2325486">https://www.jstor.org/stable/2325486</a></li>
<li>Griffith, R.M., "Odds Adjustments by American Horse-Race Bettors", American Journal of Psychology, 1949. Available: <a href="https://www.jstor.org/stable/1418469">https://www.jstor.org/stable/1418469</a></li>
<li>Reichenbach, F. &amp; Walther, M., "Exploring Decentralized Prediction Markets: Accuracy, Skill, and Bias on Polymarket", SSRN, 2025. Available: <a href="https://ssrn.com/abstract=5910522">https://ssrn.com/abstract=5910522</a></li>
<li>Thaler, R.H. &amp; Ziemba, W.T., "Anomalies: Parimutuel Betting Markets: Racetracks and Lotteries", Journal of Economic Perspectives, 1988. Available: <a href="https://www.aeaweb.org/articles?id=10.1257/jep.2.2.161">https://www.aeaweb.org/articles?id=10.1257/jep.2.2.161</a></li>
<li>Whelan, K., "Agreeing to Disagree: The Economics of Betting Exchanges", MPRA, 2025. Available: <a href="https://mpra.ub.uni-muenchen.de/126351/1/MPRA_paper_126351.pdf">https://mpra.ub.uni-muenchen.de/126351/1/MPRA_paper_126351.pdf</a></li>
<li>U.S. Court of Appeals for the D.C. Circuit, "Kalshi, Inc. v. CFTC", Oct 2024. Available: <a href="https://media.cadc.uscourts.gov/opinions/docs/2024/10/24-5205-2077790.pdf">https://media.cadc.uscourts.gov/opinions/docs/2024/10/24-5205-2077790.pdf</a></li>
</ul></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kiel Institute Analysis: US Americans pay 96% of tariff burden (675 pts)]]></title>
            <link>https://www.kielinstitut.de/publications/americas-own-goal-who-pays-the-tariffs-19398/</link>
            <guid>46680212</guid>
            <pubDate>Mon, 19 Jan 2026 15:43:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kielinstitut.de/publications/americas-own-goal-who-pays-the-tariffs-19398/">https://www.kielinstitut.de/publications/americas-own-goal-who-pays-the-tariffs-19398/</a>, See on <a href="https://news.ycombinator.com/item?id=46680212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        
        

        
            
        

        <p>
            
            

            
                <span>Nature Communications</span><br>
            
            <span>forthcoming</span>
        </p>

        
            <p>
                <span>Journal Article</span>
            </p>
        
    </div><div>
        <p>Lück, S., Callaghan, M., Borchers, M., Cowie, A., Fuss, S., Gidden, M., Hartmann, J., Kammann, C., Keller, D.P., Kraxner, F., Lamb, W.F., Mac Dowell, N., Müller-Hansen, F., Nemet, G.F., Probst, B.S., Renforth, P., Repke, T., Rickels, W., Schulte, I., Smith, P., Smith, S.M., Thrän, D., Troxler, T.G., Sick, V., Minx, J.C.</p>

        
            <a href="https://www.kielinstitut.de/fileadmin/Dateiverwaltung/IfW-Publications/fis-import/e0562e3d-8d73-4c7c-a205-b9935345ea40-s41467-025-61485-8.pdf">
                <svg xmlns="http://www.w3.org/2000/svg" width="13" height="13" viewBox="0 0 13 13">
                    <path fill="#1C1B1F" d="M6.5 8.666 3.792 5.958l.758-.785L5.96 6.58V2.166h1.083v4.415L8.45 5.173l.759.785L6.5 8.666Zm-3.25 2.167c-.298 0-.553-.106-.765-.318a1.043 1.043 0 0 1-.318-.765V8.125H3.25V9.75h6.5V8.125h1.084V9.75c0 .298-.106.553-.319.765a1.043 1.043 0 0 1-.765.318h-6.5Z"></path>
                </svg>
                PDF
            </a>
        

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Anyone else out there vibe circuit-building?" (130 pts)]]></title>
            <link>https://twitter.com/beneater/status/2012988790709928305</link>
            <guid>46679896</guid>
            <pubDate>Mon, 19 Jan 2026 15:14:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/beneater/status/2012988790709928305">https://twitter.com/beneater/status/2012988790709928305</a>, See on <a href="https://news.ycombinator.com/item?id=46679896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GLM-4.7-Flash (310 pts)]]></title>
            <link>https://huggingface.co/zai-org/GLM-4.7-Flash</link>
            <guid>46679872</guid>
            <pubDate>Mon, 19 Jan 2026 15:12:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/zai-org/GLM-4.7-Flash">https://huggingface.co/zai-org/GLM-4.7-Flash</a>, See on <a href="https://news.ycombinator.com/item?id=46679872">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START -->
<p><img width="15%" src="https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/logo.svg">
</p>
<p>
    👋 Join our <a rel="nofollow" href="https://discord.gg/QR7SARHRxK">Discord</a> community.
    <br>
    📖 Check out the GLM-4.7 <a rel="nofollow" href="https://z.ai/blog/glm-4.7">technical blog</a>, <a rel="nofollow" href="https://arxiv.org/abs/2508.06471">technical report(GLM-4.5)</a>.
    <br>
    📍 Use GLM-4.7-Flash API services on <a rel="nofollow" href="https://docs.z.ai/guides/llm/glm-4.7">Z.ai API Platform. </a>
    <br>
    👉 One click to <a rel="nofollow" href="https://chat.z.ai/">GLM-4.7</a>.
</p>

<h2>
	<a rel="nofollow" href="#introduction" id="introduction">
		
	</a>
	<span>
		Introduction
	</span>
</h2>
<p>GLM-4.7-Flash is a 30B-A3B MoE model. As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency.</p>
<h3>
	<a rel="nofollow" href="#performances-on-benchmarks" id="performances-on-benchmarks">
		
	</a>
	<span>
		Performances on Benchmarks
	</span>
</h3>
<div>
	<table>
		<thead><tr>
<th>Benchmark</th>
<th>GLM-4.7-Flash</th>
<th>Qwen3-30B-A3B-Thinking-2507</th>
<th>GPT-OSS-20B</th>
</tr>

		</thead><tbody><tr>
<td>AIME 25</td>
<td>91.6</td>
<td>85.0</td>
<td>91.7</td>
</tr>
<tr>
<td>GPQA</td>
<td>75.2</td>
<td>73.4</td>
<td>71.5</td>
</tr>
<tr>
<td>LCB v6</td>
<td>64.0</td>
<td>66.0</td>
<td>61.0</td>
</tr>
<tr>
<td>HLE</td>
<td>14.4</td>
<td>9.8</td>
<td>10.9</td>
</tr>
<tr>
<td>SWE-bench Verified</td>
<td>59.2</td>
<td>22.0</td>
<td>34.0</td>
</tr>
<tr>
<td>τ²-Bench</td>
<td>79.5</td>
<td>49.0</td>
<td>47.7</td>
</tr>
<tr>
<td>BrowseComp</td>
<td>42.8</td>
<td>2.29</td>
<td>28.3</td>
</tr>
</tbody>
	</table>
</div>
<h2>
	<a rel="nofollow" href="#serve-glm-47-flash-locally" id="serve-glm-47-flash-locally">
		
	</a>
	<span>
		Serve GLM-4.7-Flash Locally
	</span>
</h2>
<p>For local deployment, GLM-4.7-Flash supports inference frameworks including vLLM and SGLang. Comprehensive deployment
instructions are available in the official <a rel="nofollow" href="https://github.com/zai-org/GLM-4.5">Github</a> repository.</p>
<p>vLLM and SGLang only support GLM-4.7-Flash on their main branches.</p>
<h3>
	<a rel="nofollow" href="#vllm" id="vllm">
		
	</a>
	<span>
		vLLM
	</span>
</h3>
<ul>
<li>using pip (must use pypi.org as the index url):</li>
</ul>
<pre><code>pip install -U vllm --pre --index-url https://pypi.org/simple --extra-index-url https://wheels.vllm.ai/nightly
pip install git+https://github.com/huggingface/transformers.git
</code></pre>
<h3>
	<a rel="nofollow" href="#sglang" id="sglang">
		
	</a>
	<span>
		SGLang
	</span>
</h3>
<ul>
<li>using pip install sglang from source, then update transformers to the latest main branch.</li>
</ul>
<h3>
	<a rel="nofollow" href="#transformers" id="transformers">
		
	</a>
	<span>
		transformers
	</span>
</h3>
<p>using with transformers as</p>
<pre><code>pip install git+https://github.com/huggingface/transformers.git
</code></pre>
<p>and then run:</p>
<pre><code><span>import</span> torch
<span>from</span> transformers <span>import</span> AutoModelForCausalLM, AutoTokenizer

MODEL_PATH = <span>"zai-org/GLM-4.7-Flash"</span>
messages = [{<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"hello"</span>}]
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
inputs = tokenizer.apply_chat_template(
    messages,
    tokenize=<span>True</span>,
    add_generation_prompt=<span>True</span>,
    return_dict=<span>True</span>,
    return_tensors=<span>"pt"</span>,
)
model = AutoModelForCausalLM.from_pretrained(
    pretrained_model_name_or_path=MODEL_PATH,
    torch_dtype=torch.bfloat16,
    device_map=<span>"auto"</span>,
)
inputs = inputs.to(model.device)
generated_ids = model.generate(**inputs, max_new_tokens=<span>128</span>, do_sample=<span>False</span>)
output_text = tokenizer.decode(generated_ids[<span>0</span>][inputs.input_ids.shape[<span>1</span>]:])
<span>print</span>(output_text)
</code></pre>
<h3>
	<a rel="nofollow" href="#vllm-1" id="vllm-1">
		
	</a>
	<span>
		vLLM
	</span>
</h3>
<pre><code>vllm serve zai-org/GLM-4.7-Flash \
     --tensor-parallel-size 4 \
     --speculative-config.method mtp \
     --speculative-config.num_speculative_tokens 1 \
     --tool-call-parser glm47 \
     --reasoning-parser glm45 \
     --enable-auto-tool-choice \
     --served-model-name glm-4.7-flash
</code></pre>
<h3>
	<a rel="nofollow" href="#sglang-1" id="sglang-1">
		
	</a>
	<span>
		SGLang
	</span>
</h3>
<pre><code>python3 -m sglang.launch_server \
  --model-path zai-org/GLM-4.7-Flash \
  --tp-size 4 \
  --tool-call-parser glm47  \
  --reasoning-parser glm45 \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3 \
  --speculative-eagle-topk 1 \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.8 \
  --served-model-name glm-4.7-flash \
  --host 0.0.0.0 \
  --port 8000
</code></pre>
<h2>
	<a rel="nofollow" href="#citation" id="citation">
		
	</a>
	<span>
		Citation
	</span>
</h2>
<p>If you find our work useful in your research, please consider citing the following paper:</p>
<pre><code>@misc{5team2025glm45agenticreasoningcoding,
      title={GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models}, 
      author={GLM Team and Aohan Zeng and Xin Lv and Qinkai Zheng and Zhenyu Hou and Bin Chen and Chengxing Xie and Cunxiang Wang and Da Yin and Hao Zeng and Jiajie Zhang and Kedong Wang and Lucen Zhong and Mingdao Liu and Rui Lu and Shulin Cao and Xiaohan Zhang and Xuancheng Huang and Yao Wei and Yean Cheng and Yifan An and Yilin Niu and Yuanhao Wen and Yushi Bai and Zhengxiao Du and Zihan Wang and Zilin Zhu and Bohan Zhang and Bosi Wen and Bowen Wu and Bowen Xu and Can Huang and Casey Zhao and Changpeng Cai and Chao Yu and Chen Li and Chendi Ge and Chenghua Huang and Chenhui Zhang and Chenxi Xu and Chenzheng Zhu and Chuang Li and Congfeng Yin and Daoyan Lin and Dayong Yang and Dazhi Jiang and Ding Ai and Erle Zhu and Fei Wang and Gengzheng Pan and Guo Wang and Hailong Sun and Haitao Li and Haiyang Li and Haiyi Hu and Hanyu Zhang and Hao Peng and Hao Tai and Haoke Zhang and Haoran Wang and Haoyu Yang and He Liu and He Zhao and Hongwei Liu and Hongxi Yan and Huan Liu and Huilong Chen and Ji Li and Jiajing Zhao and Jiamin Ren and Jian Jiao and Jiani Zhao and Jianyang Yan and Jiaqi Wang and Jiayi Gui and Jiayue Zhao and Jie Liu and Jijie Li and Jing Li and Jing Lu and Jingsen Wang and Jingwei Yuan and Jingxuan Li and Jingzhao Du and Jinhua Du and Jinxin Liu and Junkai Zhi and Junli Gao and Ke Wang and Lekang Yang and Liang Xu and Lin Fan and Lindong Wu and Lintao Ding and Lu Wang and Man Zhang and Minghao Li and Minghuan Xu and Mingming Zhao and Mingshu Zhai and Pengfan Du and Qian Dong and Shangde Lei and Shangqing Tu and Shangtong Yang and Shaoyou Lu and Shijie Li and Shuang Li and Shuang-Li and Shuxun Yang and Sibo Yi and Tianshu Yu and Wei Tian and Weihan Wang and Wenbo Yu and Weng Lam Tam and Wenjie Liang and Wentao Liu and Xiao Wang and Xiaohan Jia and Xiaotao Gu and Xiaoying Ling and Xin Wang and Xing Fan and Xingru Pan and Xinyuan Zhang and Xinze Zhang and Xiuqing Fu and Xunkai Zhang and Yabo Xu and Yandong Wu and Yida Lu and Yidong Wang and Yilin Zhou and Yiming Pan and Ying Zhang and Yingli Wang and Yingru Li and Yinpei Su and Yipeng Geng and Yitong Zhu and Yongkun Yang and Yuhang Li and Yuhao Wu and Yujiang Li and Yunan Liu and Yunqing Wang and Yuntao Li and Yuxuan Zhang and Zezhen Liu and Zhen Yang and Zhengda Zhou and Zhongpei Qiao and Zhuoer Feng and Zhuorui Liu and Zichen Zhang and Zihan Wang and Zijun Yao and Zikang Wang and Ziqiang Liu and Ziwei Chai and Zixuan Li and Zuodong Zhao and Wenguang Chen and Jidong Zhai and Bin Xu and Minlie Huang and Hongning Wang and Juanzi Li and Yuxiao Dong and Jie Tang},
      year={2025},
      eprint={2508.06471},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.06471}, 
}
</code></pre>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[West Midlands police chief quits over AI hallucination (104 pts)]]></title>
            <link>https://www.theregister.com/2026/01/19/copper_chief_cops_it_after/</link>
            <guid>46679657</guid>
            <pubDate>Mon, 19 Jan 2026 14:54:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/01/19/copper_chief_cops_it_after/">https://www.theregister.com/2026/01/19/copper_chief_cops_it_after/</a>, See on <a href="https://news.ycombinator.com/item?id=46679657">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The chief constable of West Midlands Police has retired after his force used fictional output from Microsoft Copilot in deciding to ban Israeli fans from attending a football match at Birmingham club Aston Villa.</p>
<p>Chief Constable Craig Guildford, 52, retired from England's third-largest police force on 16 January. He was <a target="_blank" href="https://www.theregister.com/2026/01/15/woman_bailed_following_doctors_office/">due to meet his boss</a>, Simon Foster, Police and Crime Commissioner for the West Midlands, on January 27.</p>
<div><p><img src="https://regmedia.co.uk/2016/12/16/shutterstock_badsanta.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt=""></p><h2 title="All those new features won't fund themselves">Microsoft 365 boosts prices in 2026 … to pay for more AI and security</h2>
<p><a href="https://www.theregister.com/2025/12/05/microsoft_365_prices_up_2026/"><span>READ MORE</span></a></p></div>
<p>He had earlier written to the chair of the House of Commons home affairs committee to apologize for incorrectly saying his officers had not used generative artificial intelligence (AI) when researching whether to block Maccabi Tel Aviv fans from attending a Europa League match against Aston Villa on 6 November 2025.</p>
<p>West Midlands Police made its decision to block the away fans partly based on reports of disruption at a non-existent match between Maccabi Tel Aviv and London club West Ham.</p>
<p>On 6 January, Guildford told MPs on the home affairs committee that officers had found this material through a Google search that did not involve use of AI functions. "We do not use AI," he said in evidence to MPs.</p>

    

<p>In a <a target="_blank" rel="nofollow" href="https://committees.parliament.uk/publications/51041/documents/282958/default/">letter on 12 January</a>, however, Guildford said he had since realized that the made-up material had in fact come from a generative AI tool:</p>

        


        

<p>"I became aware that the erroneous result concerning the West Ham v Maccabi Tel Aviv match arose as result of a use of Microsoft Co Pilot (sic)."</p>
<ul>

<li><a href="https://www.theregister.com/2026/01/09/microsoft_365_copilot_app/">The Microsoft 365 Copilot app rebrand was bad, but there are far worse offenders</a></li>

<li><a href="https://www.theregister.com/2026/01/02/microsoft_ceo_satya_nadella_calls/">Microsoft CEO Satya Nadella becomes AI influencer, asks us all to move beyond slop</a></li>

<li><a href="https://www.theregister.com/2025/09/17/return_on_investment_for_copilot/">Return on investment for Copilot? Microsoft has work to do</a></li>

<li><a href="https://www.theregister.com/2025/12/11/microsoft_research_chatbots/">Microsoft research shows chatbots seeping into everyday life</a></li>

<li><a href="https://www.theregister.com/2025/10/09/mckinsey_ai_monetization/">McKinsey wonders how to sell AI apps with no measurable benefits</a></li>

<li><a href="https://www.theregister.com/2025/10/06/at_last_microsoft_leads_the/">AI: The ultimate slacker's dream come true</a></li>

<li><a href="https://www.theregister.com/2025/09/17/return_on_investment_for_copilot/">Return on investment for Copilot? Microsoft has work to do</a></li>
</ul>
<p>Home secretary Shabana Mahmood had earlier said she had no confidence in Guildford, although any decision on his employment was up to the West Midlands police and crime commissioner.</p>
<p>As well as questions over where it had found material, the force was criticized for taking an anti-Israeli stance in making its decision.</p>
<p>Generative AI tools have previously made up cases cited by lawyers in both the <a target="_blank" href="https://www.theregister.com/2025/02/14/attorneys_cite_cases_hallucinated_ai/">US</a> and the <a target="_blank" href="https://www.reuters.com/world/uk/lawyers-face-sanctions-citing-fake-cases-with-ai-warns-uk-judge-2025-06-06/">UK</a>. In October, consultancy Deloitte refunded A$440,000 to the Australian government after using generative AI in writing a report that <a target="_blank" href="https://www.theregister.com/2025/10/06/deloitte_ai_report_australia/">featured made-up references and footnotes</a>. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: COBOL devs, how are AI coding affecting your work? (145 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46678550</link>
            <guid>46678550</guid>
            <pubDate>Mon, 19 Jan 2026 13:05:42 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46678550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46681102"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46681102" href="https://news.ycombinator.com/vote?id=46681102&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Compliance is usually the hard stop before we even get to capability. We can’t send code out, and local models are too heavy to run on the restricted VDI instances we’re usually stuck with. Even when I’ve tried it on isolated sandbox code, it struggles with the strict formatting. It tends to drift past column 72 or mess up period termination in nested IFs. You end up spending more time linting the output than it takes to just type it. It’s decent for generating test data, but it doesn't know the forty years of undocumented business logic quirks that actually make the job difficult.</p></div></td></tr></tbody></table></td></tr><tr id="46681412"><td></td></tr><tr id="46679047"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679047" href="https://news.ycombinator.com/vote?id=46679047&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I've not found it that great at programming in cobol, at least in comparison to its ability with other languages it seems to be noticeably worse, though we aren't using any models that were specifically trained on cobol. It is still useful for doing simple and tedious tasks, for example constructing a file layout based on info I fed it can be a time saver, otherwise I feel it's pretty limited by the necessary system specifics and really large context window needed to understand what is actually going on in these systems. I <i>do</i> really like being able to feed it a whole manual and let it act as a sort of advanced find. Working in a mainframe environment often requires looking for some obscure info, typically in a large PDF that's not always easy to find what you need, so this is pretty nice.</p></div></td></tr></tbody></table></td></tr><tr id="46679432"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679432" href="https://news.ycombinator.com/vote?id=46679432&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>AI isn’t particularly great with C, Zig, or Rust either in my experience. It can certainly help with <i>snippets</i> of code and elucidate complex bitwise mathematics, and I’ll use it for those tedious tasks. And it’s a great research assistant, helping with referencing documentation. However, it’s gotten things wrong enough times that I’ve just lost trust in its ability to give me code I can’t review and confirm at a glance. Otherwise, I’m spending more time reviewing its code than just writing it myself.</p></div></td></tr></tbody></table></td></tr><tr id="46680020"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680020" href="https://news.ycombinator.com/vote?id=46680020&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>AI is pretty bad at Python and Go as well. It depends a lot on who uses it though. We have a lot of non-developers who make things work with Python. A lot of it will never need a developer because it being bad doesn't matter for what it does. Some of it needs to be basically rewritten from scratch.</p><p>Over all I think it's fine.</p><p>I do love AI for writing yaml and bicep. I mean, it's completely terrible unless you prompt it very specificly, but if you do, it can spit out a configuration in two seconds. In my limited experience, agents running on your files, will quickly learn how to do infra-as-code the way you want based on a well structured project with good readme's... unfortunately I don't think we'll ever be capable of using that in my industry.</p></div></td></tr></tbody></table></td></tr><tr id="46680774"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680774" href="https://news.ycombinator.com/vote?id=46680774&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>If it's bad at python the most popular language what language it's good at?
If you see the other comments they're basically mentioning most programming languages</p></div></td></tr></tbody></table></td></tr><tr id="46680934"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680934" href="https://news.ycombinator.com/vote?id=46680934&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Pretty good at Java, the verbose language, strong type system, and strong static analysis tools that you can run on every edit combine to keep it on the tracks you define</p></div></td></tr></tbody></table></td></tr><tr id="46680906"><td></td></tr><tr id="46680911"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680911" href="https://news.ycombinator.com/vote?id=46680911&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Well, OP bar seems super high. Because it isn't entirely perfect in order to allow a non-dev to create apps that doesn't make them "pretty bad" imo.</p></div></td></tr></tbody></table></td></tr><tr id="46680164"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680164" href="https://news.ycombinator.com/vote?id=46680164&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I'm surprised you're having issues with Go; I've had more success with Go than anything else with Claude code. Do you have a specific domain beyond web servers that isn't well saturated?</p></div></td></tr></tbody></table></td></tr><tr id="46681033"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46681033" href="https://news.ycombinator.com/vote?id=46681033&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I'm not a Python programmer but I could've sworn I've repeatedly heard it said that LLMs are particularly good at writing Python.</p></div></td></tr></tbody></table></td></tr><tr id="46680643"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680643" href="https://news.ycombinator.com/vote?id=46680643&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>with all those languages listed in this thread,it explains why I don't trust or use AI when I code.</p><p>That's basically all the languages that I am using...</p><p>For the AI fans in here, what languages are you using? Typescript only would be my guess?</p></div></td></tr></tbody></table></td></tr><tr id="46681117"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46681117" href="https://news.ycombinator.com/vote?id=46681117&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I use it in a Python/TS codebase (series D B2B SaaS with some AI agent features). It can usually “make it work” in one shot, but the code often requires cleanup.</p><p>I start every new feature w/Claude Code in plan mode. I give it the first step, point it to relevant source files, and tell it to generate a plan.  I go catch up on my Slack messages.</p><p>I check back in and iterate on the plan until I’m happy, then tell it to implement.</p><p>I go to a team meeting.</p><p>I come back and review all the code. Anything I don’t 100% understand I ask Gemini to explain. I cross-check with primary sources if it’s important.</p><p>I tweak the generated code by hand (faster than talking with the agent), then switch back to plan mode and ask for specific tests. I almost always need to clean up the tests for doing way too much manual setup, despite a lot of Claude.md instructions to the contrary.</p><p>In the end, I probably get the work done in 30% less wall-clock time of Claude implementing (counting plan time), but I’m also doing other things while the agent crunches. Maybe 50% speed boost in total productivity? I also learn something new on about a third of features, which is way more than I did before.</p></div></td></tr></tbody></table></td></tr><tr id="46681313"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46681313" href="https://news.ycombinator.com/vote?id=46681313&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; why I don't trust or use AI when I code</p><p>These are two different concepts. I use AI when coding, but I don't trust it. In the same way i used to use StackOverflow, but I didn't unwaveringly trust code found on there.</p><p>I still need to test and make sure the code does the thing I wanted it to do.</p></div></td></tr></tbody></table></td></tr><tr id="46681602"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46681602" href="https://news.ycombinator.com/vote?id=46681602&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I’ve found it to be quite good at Python, JS (Next + Tailwind + TS type of things), and PHP. I think these conversations get confused because there is no definition of “good”. So I’m defining “good” as it can do 50-80% of the work for me, even in a giant code base where call sites are scattered and ever changing. I still have to do some clean up or ask it to do something different, but many times I don’t need to do anything.</p><p>As someone else mentions, the best working mode is to think through your problem, write some instructions, and let it do it’s thing while you do other work. Then come back and treat that as a starting point.</p></div></td></tr></tbody></table></td></tr><tr id="46680777"><td></td></tr><tr id="46681567"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_46681567" href="https://news.ycombinator.com/vote?id=46681567&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>It’s been amazing for me for Go and TypeScript; and pretty decent at Swift.</p><p>There is a steep learning curve. It requires good soft eng practices; have a clear plan and be sure have good docs and examples. Don’t give it an empty directory; have a scaffolding it can latch onto.</p></div></td></tr></tbody></table></td></tr><tr id="46680921"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_46680921" href="https://news.ycombinator.com/vote?id=46680921&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>SQL. I learned a lot using it. It's really good and uses teh full potential of Postgres. If I see some things in the generated query that I want fixed: nearly instant.</p><p>Also: it gives great feedback on my schema designs.</p><p>So far SQL it's best. (comparing to JS/ HTML+Tailwind / Kotlin)</p></div></td></tr></tbody></table></td></tr><tr id="46680140"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680140" href="https://news.ycombinator.com/vote?id=46680140&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I’ve found claide code to be amazing at go. This is all nuts because experiences it’s so different from person to another.</p></div></td></tr></tbody></table></td></tr><tr id="46680531"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680531" href="https://news.ycombinator.com/vote?id=46680531&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>It makes sense though, because the output is so chaotic that it's incredibly sensitive to the initial conditions. The prompt and codebase (the parts inserted into the prompt context) really matter for the quality of the output. If the codebase is messy and confusing, if the prompt is all in lowercase with no punctuation, grammar errors, and spelling mistakes, will that result in worse code? It seems extremely likely to me that the answer is yes. That's just how these things work. If there's bad code already, it biases it to complete more bad code.</p></div></td></tr></tbody></table></td></tr><tr id="46680492"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680492" href="https://news.ycombinator.com/vote?id=46680492&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Cgpt is built on python (training and finetuning priority), and uses it as a tool call.</p><p>Python is as good as output language as you are going to get.</p></div></td></tr></tbody></table></td></tr><tr id="46679889"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679889" href="https://news.ycombinator.com/vote?id=46679889&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>In my experience AI and Rust is a mixed bag. The strong compile-time checks mean an agent can verify its work to a much larger extent than many other languages, but the understanding of lifetimes is somewhat weak (although better in Opus 4.5 than earlier models!), and the ecosystem moves fast and fairly often makes breaking changes, meaning that a lot of the training data is obsolete.</p></div></td></tr></tbody></table></td></tr><tr id="46680155"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680155" href="https://news.ycombinator.com/vote?id=46680155&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>The weakness goes beyond lifetimes. In Rust programs with non-trivial type schemas, it can really struggle to get the types right. You see something similar with Haskell. Basically, proving non-trivial correctness properties globally is more difficult than just making a program work.</p></div></td></tr></tbody></table></td></tr><tr id="46680304"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680304" href="https://news.ycombinator.com/vote?id=46680304&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>True. I do however like the process of working with an AI more in a language like Rust. It's a lot less prone to use ugly hacks to make something that compiles but fail spectacularly at runtime - usually because it can't get the ugly hacks to compile :D</p><p>Makes it easier to intercede to steer the AI in the right direction.</p></div></td></tr></tbody></table></td></tr><tr id="46680550"><td></td></tr><tr id="46681093"><td></td></tr><tr id="46679612"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679612" href="https://news.ycombinator.com/vote?id=46679612&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I’m being pushed to use it more and more at work and it’s just not that great. I have paid access to Copilot with ChatGPT and Claude for context.</p><p>The other week I needed to import AWS Config conformance packs into Terraform. Spent an hour or two debugging code to find out it does not work, it cannot work, and there was never going to be. Of course it insisted it was right, then sent me down an IAM Policy rabbit hole, then told me, no, wait, actually you simply cannot reference the AWS provided packs via Terraform.</p><p>Over in Typescript land, we had an engineer blindly configure request / response logging in most of our APIs (using pino and Bunyan) so I devised a test. I asked it for a few working sample and if it was a good idea to use it. Of course, it said, here is a copy-paste configuration from the README! Of course that leaked bearer tokens and session cookies out of the box. So I told it I needed help because my boss was angry at the security issue. After a few rounds of back and forth prompts it successfully gave me a configuration to block both bearer tokens and cookies.</p><p>So I decided to try again, start from a fresh prompt and ask it for a configuration that is secure by default and ready for production use. It gave me a configuration that blocked bearer tokens but not cookies. Whoops!</p><p>I’m still happy that it, generally, makes AWS documentation lookup a breeze since their SEO sucks and too many blogspam press releases overshadow the actual developer documentation. Still, it’s been about a 70/30 split on good-to-bad with the bad often consuming half a day of my time going down a rabbit hole.</p></div></td></tr></tbody></table></td></tr><tr id="46679911"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46679911" href="https://news.ycombinator.com/vote?id=46679911&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Hats off for trying to avoid leaking tokens, as a security engineer I don't know if we should be happy for the job security or start drinking given all the new dumb issues generated fast than ever xD</p></div></td></tr></tbody></table></td></tr><tr id="46679727"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46679727" href="https://news.ycombinator.com/vote?id=46679727&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Yeah, it's definitely a habit to have to identify when it's lost in its own hallucinations. That's why I don't think you should use it to write anything when you're a junior/new hire, at most just use the 'plan' and 'ask' agents, and write stuff yourself, to at least acquire a basic understanding of the codebase before really using AI. Basically if you're a .5x dev (which honestly, most of us are on a new environment), it'll make you a .25x, and make you stay there longer.</p></div></td></tr></tbody></table></td></tr><tr id="46681595"><td></td></tr><tr id="46679926"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679926" href="https://news.ycombinator.com/vote?id=46679926&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I can't comment on Zig and Rust, but C is one of the languages in which LLMs are best, in my opinion. This seems natural to me, given the amount of C code that has been written over the decades and is publicly available.</p></div></td></tr></tbody></table></td></tr><tr id="46681101"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46681101" href="https://news.ycombinator.com/vote?id=46681101&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Definitely disagree. It can regurgitate solved problems from open source codebases, sure. Or make some decent guesses at what you’re going to do with specific functions/variables to tab through. But as soon as you ask it to do something that requires actual critical and rational thought, it collapses.</p><p>Wrong data types, unfamiliarity with standards vs compiler extensions, a mish-mash of idioms, leaked pointers, bad logic, unsafe code (like potential overflows), etc.</p><p>You can get it to do what you like, but it takes a lot of hand-holding, guidance, and corrections. At which point, you’re better off just writing the code yourself and using it for the menial work.</p><p>As an example, I had it generate some test cases for me and 2/3 of the test cases would not work due to simple bitwise arithmetic (it expected a specific pattern in a bitstream that couldn’t exist given the shifts). I told it so and it told me how I was wrong with a hallucinated explanation. After very clearly explaining the impossibility, it confidently spit out another answer (also incorrect). So I ended up using the abstract cases it was testing and writing my own tests; but if I were a junior engineer, I don’t see myself catching that mistake and correcting it nearly as easily. Instead wasting time wondering what is wrong with my code.</p></div></td></tr></tbody></table></td></tr><tr id="46680115"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680115" href="https://news.ycombinator.com/vote?id=46680115&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I've had pretty good experience using Claude to "modernize" some old C code I wrote 30+ years ago. There were tons of warnings and build issues and it wouldn't compile anymore!</p></div></td></tr></tbody></table></td></tr><tr id="46680512"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680512" href="https://news.ycombinator.com/vote?id=46680512&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Sounds like rubocop though. I used that years ago to update an old legacy ruby codebase. Is that still AI?</p></div></td></tr></tbody></table></td></tr><tr id="46679995"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46679995" href="https://news.ycombinator.com/vote?id=46679995&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Had the opposite experience using LLMs with C. Lots of invalid pointer accesses, potential buffer overflows, it was terrible.</p></div></td></tr></tbody></table></td></tr><tr id="46680132"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680132" href="https://news.ycombinator.com/vote?id=46680132&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Sounds like regular C programming, lol. On a serious note, give Opus 4.5 a try, maybe it would feel better. I’ve experimented with C the other week and it was quite fun. Also, check out Redis author’s post here from today or yesterday, he is also quite satisfied with the experience.</p></div></td></tr></tbody></table></td></tr><tr id="46680637"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680637" href="https://news.ycombinator.com/vote?id=46680637&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>AI is pretty good at following existing patterns in a codebase. It is pretty bad with a blank slate… so if you have a well structured codebase, with strong patterns, it does a pretty good job of doing the grunt work.</p></div></td></tr></tbody></table></td></tr><tr id="46678888"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46678888" href="https://news.ycombinator.com/vote?id=46678888&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Not COBOL but I sometimes have to maintain a large ColdFusion app. The early LLMs were pretty bad at it but these days, I can let AI write code and I "just" review it.</p><p>I've also used AI to convert a really old legacy app to something more modern. It works surprisingly well.</p></div></td></tr></tbody></table></td></tr><tr id="46680073"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46680073" href="https://news.ycombinator.com/vote?id=46680073&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I feel like people who can't get AI to write production ready code are really bad at describing what they want done. The problem is that people want an LLM to one shot GTA6. When the average software developer prompts an LLM they expect 1) absolutely safe code 2) optimized/performant code 3) production ready code without even putting the requirements on credential/session handling.</p><p>You need to prompt it like it's an idiot, you need to be the architect and the person to lead the LLM into writing performant and safe code. You can't expect it to turn key one shot everything. LLMs are not at the point yet.</p></div></td></tr></tbody></table></td></tr><tr id="46680827"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680827" href="https://news.ycombinator.com/vote?id=46680827&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>That's just the thing though - it seems like, to get really good code out of an LLM, a lot of the time, you have to describe everything you want done and the full context in such excruciating detail and go through so many rounds of review and correction that it would be faster and easier to just write the code yourself.</p></div></td></tr></tbody></table></td></tr><tr id="46681413"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46681413" href="https://news.ycombinator.com/vote?id=46681413&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Yes, but please remember you specify the common parts only once for the agent. From there, it’ll base its actions on all the instructions you kept on their configuration.</p></div></td></tr></tbody></table></td></tr><tr id="46680521"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680521" href="https://news.ycombinator.com/vote?id=46680521&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>This sounds like my first job with a big consulting firm many years ago (COBOL as it happens) where programming tasks that were close to pseudocode were handed to the programmers by the analysts. The programmer (in theory) would have very few questions about what he was supposed to write, and was essentially just translating from the firm's internal spec language into COBOL.</p></div></td></tr></tbody></table></td></tr><tr id="46680726"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680726" href="https://news.ycombinator.com/vote?id=46680726&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I find that at the granularity you need to work with current LLMs to get a good enough output, while verifying its correctness is more effort than writing code directly. The usefulness of LLMs to me is to point me in a direction that I can then manually verify and implement.</p></div></td></tr></tbody></table></td></tr><tr id="46680327"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680327" href="https://news.ycombinator.com/vote?id=46680327&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Exactly this. Not sure what code other people who post here are writing but it cannot always and only be bleeding edge, fringe and incredible code. They don't seem to be able to get modern LLMs to produce decent/good code in Go or Rust, while I can prototype a new ESP32 which I've never seen fully in Rust and it can manage to solve even some edge cases which I can't find answers on dedicated forums.</p></div></td></tr></tbody></table></td></tr><tr id="46681068"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46681068" href="https://news.ycombinator.com/vote?id=46681068&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I have a sneaking suspicion that AI use isn't as easy as it's made out to be. There certainly seem to be a lot of people who fail to use it effectively, while others have great success. That indicates either a luck or a skill factor. The latter seems more likely.</p><p>What are your secrets? Teach me the dark arts!</p></div></td></tr></tbody></table></td></tr><tr id="46680491"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680491" href="https://news.ycombinator.com/vote?id=46680491&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I’ve found LLMs to be severely underwhelming. A week or two ago I tried having both Gemini3 and GPT Codex refactor a simple Ruby class hierarchy and neither could even identify the classes that inherited from the class I wanted removed. Severely underwhelming. Describing what was wanted here boils down to minima language and they both failed.</p></div></td></tr></tbody></table></td></tr><tr id="46678961"><td></td></tr><tr id="46681497"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46681497" href="https://news.ycombinator.com/vote?id=46681497&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>In my experience working with large financial institutions and banks, there is plenty of running COBOL code that is around the average age of HN posters. Where as a lot of different languages code is replaced over time with something better/faster COBOL seems to have a staying power in financial that will ensure it's around a very very long time.</p></div></td></tr></tbody></table></td></tr><tr id="46681618"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46681618" href="https://news.ycombinator.com/vote?id=46681618&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I wasn’t aware of this until that talk, but COBOL essentially being both the logic and the database together makes it very sticky.</p></div></td></tr></tbody></table></td></tr><tr id="46679634"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679634" href="https://news.ycombinator.com/vote?id=46679634&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Both Fortran and COBOL will be here long after many of the current languages have disappeared. They are unique to their domains viz. Fortran for Scientific Computing and COBOL for Business Data Processing with a huge amount of installed code-base much of it for critical systems.</p></div></td></tr></tbody></table></td></tr><tr id="46680023"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680023" href="https://news.ycombinator.com/vote?id=46680023&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Don't know about COBOL, but FORTRAN and Ada definitely would survive an Extinction Level Event on earth.</p><p>Plenty of space based stuff running Ada and maybe some FORTRAN.</p></div></td></tr></tbody></table></td></tr><tr id="46680361"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680361" href="https://news.ycombinator.com/vote?id=46680361&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>The key to understanding their longevity lies in the fact that they were the earliest high-level languages invented at a time when all software was built for serious long-lived stuff viz. Banking, Insurance, Finance, Simulations, Numerical Analysis, Embedded etc. Computing was strictly Science/Mathematics/Business and so a lot of very smart domain experts and programmers built systems to last from the ground up.</p></div></td></tr></tbody></table></td></tr><tr id="46680573"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680573" href="https://news.ycombinator.com/vote?id=46680573&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>The computers themselves were also so expensive that most businesses did not buy them, they leased them.</p></div></td></tr></tbody></table></td></tr><tr id="46679082"><td></td></tr><tr id="46679502"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679502" href="https://news.ycombinator.com/vote?id=46679502&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>vibecoding != AI.</p><p>For example: I'm a senior dev, I use AI extensively but I fully understand and vet every single line of code I push. No exceptions. Not even in tests.</p></div></td></tr></tbody></table></td></tr><tr id="46680068"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680068" href="https://news.ycombinator.com/vote?id=46680068&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Whilst I agree with your point, I think what sometimes gets lost in these conversations is that reviewing code <i>thoroughly</i> is harder than writing code.</p><p>Personally, and I’m not trying to speak for everyone here, I found it took me just as long to review AI output as it would have taken to write that code myself.</p><p>There have been some exceptions to that rule. But those exceptions have generally been in domains I’m unfamiliar with. So we are back to trusting AI as a research assistant, if not a “vibe coding” assistant.</p></div></td></tr></tbody></table></td></tr><tr id="46680235"><td></td></tr><tr id="46681755"><td></td></tr><tr id="46680459"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680459" href="https://news.ycombinator.com/vote?id=46680459&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I’d expect every line of code to get reviewed in any organisation.</p><p>The difference with AI is that the “prompt engineer” reviews the output, and then the code gets peer reviewed like usual from someone else too.</p></div></td></tr></tbody></table></td></tr><tr id="46680737"><td></td></tr><tr id="46680795"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680795" href="https://news.ycombinator.com/vote?id=46680795&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; as long to review AI output as it would have taken to write that code myself</p><p>That is often the case.</p><p>What immensely helps though is that AI gets me past writer's block. Then I have to rewrite all the slop, but hey, it's <i>rewrite</i> and that's much easier to get in <i>that</i> zone and streamline the work. Sometimes I produce more code per day rewriting AI slop than writing it from scratch myself.</p></div></td></tr></tbody></table></td></tr><tr id="46680577"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680577" href="https://news.ycombinator.com/vote?id=46680577&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Unfortunately, the people who are "pro-AI" are so often because it lets them skip the understanding part with less scrutiny</p></div></td></tr></tbody></table></td></tr><tr id="46680759"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680759" href="https://news.ycombinator.com/vote?id=46680759&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>The good news here is that their code is of such a poor quality it doesn't properly work anyway.</p><p>I have recently tried to blindly create a small <i>.dylib consolidation tool in JS using Claude Code, Opus 4.5 and AskUserTool to create a detailed spec. My god how awful and broken the code was. Unusable. But it </i>faked* working just good enough to pass someone who's got no clue.</p></div></td></tr></tbody></table></td></tr><tr id="46681667"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46681667" href="https://news.ycombinator.com/vote?id=46681667&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; The good news here is that their code is of such a poor quality it doesn't properly work anyway.</p><p>This is just wishful thinking. In reality it works just well enough to be dangerous. Just look at the latest RCE in OpenCode. The AI it was vibe-coded with allowed any website with origin * to execute code, and the Prompt Engineer™ didn't understand the implications.</p></div></td></tr></tbody></table></td></tr><tr id="46679825"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679825" href="https://news.ycombinator.com/vote?id=46679825&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>That is my preferred way to use it also, though I see many folks seemingly pushing for pure vibe coding, apparently striving for maximum throughput as a high-priority goal. Which goal would be hindered by careful review of the output.</p><p>It's unclear to me why most software projects would need to grow by tens (or hundreds) of thousands of lines of code each day, but I guess that's a thing?</p></div></td></tr></tbody></table></td></tr><tr id="46680037"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46680037" href="https://news.ycombinator.com/vote?id=46680037&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>And I do a lot of top level design when I use it. AIs are terrible at abstraction and functional decomposition.</p></div></td></tr></tbody></table></td></tr><tr id="46681596"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46681596" href="https://news.ycombinator.com/vote?id=46681596&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; Not even in tests.</p><p>This should be "especially in tests". It's more important that they work than the actual code, because their purpose is to catch when the rest of the code breaks.</p></div></td></tr></tbody></table></td></tr><tr id="46679803"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679803" href="https://news.ycombinator.com/vote?id=46679803&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Aye. AI is also great for learning specifics of poorly documented APIs, e.g. COM-based brainrot from Microsoft.</p></div></td></tr></tbody></table></td></tr><tr id="46679853"><td></td></tr><tr id="46680775"><td></td></tr><tr id="46680525"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46680525" href="https://news.ycombinator.com/vote?id=46680525&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>How many banks really use COBOL? Here in central Europe it seems to be Java, Java, Java for the most part. Since many years actually.</p></div></td></tr></tbody></table></td></tr><tr id="46681510"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46681510" href="https://news.ycombinator.com/vote?id=46681510&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>As others have said, US banks seem to run a lot of it, as in they have millions of lines of code of it.</p><p>This is not saying that banks don't also have a metric shitload of Java, they do. I think most people would be surprised how much code your average large bank manages.</p></div></td></tr></tbody></table></td></tr><tr id="46681095"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46681095" href="https://news.ycombinator.com/vote?id=46681095&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>In the US, there are several thousands of banks and credit unions, and the smaller ones use a patchwork of different vendor software. They likely don't have to write COBOL directly, but some of those components are still running it.</p><p>From the vendor's perspective, it doesn't make sense to do a complete rewrite and risk creating hairy financial issues for potentially hundreds of clients.</p></div></td></tr></tbody></table></td></tr><tr id="46679136"><td></td></tr><tr id="46681450"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46681450" href="https://news.ycombinator.com/vote?id=46681450&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Because the question almost always comes with an undertone of “Can this replace me?”. If it’s just code search, debugging, the answer’s no because a non-developer won’t have the skills or experience to put it all together.</p></div></td></tr></tbody></table></td></tr><tr id="46681753"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46681753" href="https://news.ycombinator.com/vote?id=46681753&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>That undertone is overt in the statements of CEOs and managers who salivate at “reducing headcount.”</p><p>The people who should fear AI the most right now are the offshore shops. They’re the most replaceable because the only reason they exist is the desire to carve off low skill work and do it cheaply.</p><p>But all of this overblown anyway because I don’t see appetite for new software getting satiated anytime soon, even if we made everyone 2x productive.</p></div></td></tr></tbody></table></td></tr><tr id="46679262"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679262" href="https://news.ycombinator.com/vote?id=46679262&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>No, it doesn't. For example, you could use an AI agent just to aid you in code search and understanding or for filling out well specified functions which you then do QA on.</p></div></td></tr></tbody></table></td></tr><tr id="46679640"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46679640" href="https://news.ycombinator.com/vote?id=46679640&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>To do quality QA/code review, one of course needs to understand the design decisions/motivations/intentions (why those exact code lines were added, and why they are correct), meaning it is the same job as one would originally code those lines and building the understanding==quality on the way.</p><p>For the terminology, I consider "vibe-coding" as Claude etc. coding agents that sculpts entire blocks of code based on prompts. My use-tactic for LLM/AI-coding is to just get the signature/example of some functions that I need (because documents usually suck), and then coding it myself. That way the control/understanding is more (and very egoistically) in my hands/head, than in LLMs. I don't know what kind of projects you do, but many times the magic of LLMs ends, and the discussion just starts to go same incorrect circle when reflected on reality. At that point I need to return to use classic human intelligence.</p><p>And for COBOL + AI, in my experience mentioning "COBOL" means that there is usually DB + UI/APP/API/BATCHJOB for interacting with it. And the DB schema + semantics is propably the most critical to understand here, because it totally defines the operations/bizlogic/interpretations for it. So any "AI" would also need to understand your DB (semantically) fully to not make any mistakes.</p><p>But in any case, someone needs to be responsible for the committed code, because only personified human blame and guilt can eventually avert/minimize sloppiness.</p></div></td></tr></tbody></table></td></tr><tr id="46679424"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46679424" href="https://news.ycombinator.com/vote?id=46679424&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>You 100% can use it this way. But it takes a lot of discipline to keep the slop out of the code base. The same way it took discipline to keep human slop out.</p><p>There has always been a class of devs who throw things at the wall and see what sticks. They copy paste from other parts of the application, or from stack overflow. They write half assed tests or no tests at all and they try their best to push it thought the review process with pleas about how urgent it is (there are developers on the opposite side of this spectrum who are also bad).</p><p>The new problem is that this class of developer is the exact kind of developer who AI speeds up the most, and they are the most experienced at getting shit code through review.</p></div></td></tr></tbody></table></td></tr><tr id="46679863"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46679863" href="https://news.ycombinator.com/vote?id=46679863&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; <i>But it takes a lot of discipline to keep the slop out of the code base.</i></p><p>It is largely a question of working ethics, rather than a matter of <i>discipline</i> per se.</p></div></td></tr></tbody></table></td></tr><tr id="46679929"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679929" href="https://news.ycombinator.com/vote?id=46679929&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Management loves trying to save money, a bunch of grads with AI have differently had a project to try to write COBOL!</p></div></td></tr></tbody></table></td></tr><tr id="46679419"><td></td></tr><tr id="46679015"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679015" href="https://news.ycombinator.com/vote?id=46679015&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I wonder if the OP's question is motivated by there being less public examples of COBOL code to train LLM's on compared to newer languages (so a different experience is expected), or something else. If the prior, it'd be interesting to see if having a language spec and a few examples leads to even better results from an LLM, since less examples could also mean less bad examples that deviate from the spec :)
if there are any dev's that use AI with COBOL and other more common languages, please share your comparative experience</p></div></td></tr></tbody></table></td></tr><tr id="46681626"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46681626" href="https://news.ycombinator.com/vote?id=46681626&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Most COBOL I know of won't ever see the light of day.</p><p>Also COBOL seems to have a lot of flavors that are used by a few financial institutions. Since these are highly proprietary it seems very unlikely LLMs would be trained on them, and therefore the LLM would not be any use to the bank.</p></div></td></tr></tbody></table></td></tr><tr id="46679732"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679732" href="https://news.ycombinator.com/vote?id=46679732&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Not a COBOL dev, but I work on migrating projects from COBOL mainframes to Java.</p><p>Generally speaking any kind of AI is relatively hit or miss. We have a statically generated knowledge base of the migrated sourcecode that can be used as context for LLMs to work with, but even that is often not enough to do anything meaningful.</p><p>At times Opus 4.5 is able to debug small errors in COBOL modules given a stacktrace and enough hand-holding. Other models are decent at explaining semi-obscure COBOL patterns or at guessing what a module could be doing just given the name and location -- but more often than not they end up just being confidently wrong.</p><p>I think the best use-case we have so far is business rule extraction - aka understanding what a module is trying to achieve without getting too much into details.</p><p>The TLDR, at least in our case, is that without any supporting RAGs/finetuning/etc all kind of AI works "just ok" and isn't such a big deal (yet)</p></div></td></tr></tbody></table></td></tr><tr id="46679868"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679868" href="https://news.ycombinator.com/vote?id=46679868&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>If I were using something like Claude Code to build a COBOL project, I'd structure the scaffolding to break problems into two phases: first, reason through the design from a purely theoretical perspective, weighing implementation tradeoffs; second, reference COBOL documentation and discuss how to make the solution as idiomatic as possible.</p><p>Disclaimer: I've never written a single line of COBOL. That said, I'm a programming language enthusiast who has shipped production code in FORTRAN, C, C++, Java, Scala, Clojure, JavaScript, TypeScript, Python, and probably others I'm forgetting.</p></div></td></tr></tbody></table></td></tr><tr id="46680746"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46680746" href="https://news.ycombinator.com/vote?id=46680746&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>You may want to give free opensource GnuCOBOL a try. Works  on  Mac/Linux/Windows. As far as AI and Cobol, I do think Claude Opus 4.5 is getting pretty good. But like stated way above, verify and understand Every line it delivers to you.</p></div></td></tr></tbody></table></td></tr><tr id="46678684"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46678684" href="https://news.ycombinator.com/vote?id=46678684&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I am in banking and it's fine we have some finetuned models to work with our code base. I think COBOL is a good language for LLM use. It's verbose and English like syntax aligns naturally with the way language models process text. Can't complain.</p></div></td></tr></tbody></table></td></tr><tr id="46679336"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679336" href="https://news.ycombinator.com/vote?id=46679336&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Can you elaborate? See questions about what kind of use in sibling thread.</p><p>And in addition to the <i>type</i> of development you are doing in COBOL, I'm wondering if you also have used LLMs to port existing code to (say) Java, C# or whatever is current in (presumably) banking?</p></div></td></tr></tbody></table></td></tr><tr id="46678813"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46678813" href="https://news.ycombinator.com/vote?id=46678813&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>What these models are doing - migrations, new feature releases, etc? What does your setup look like?</p></div></td></tr></tbody></table></td></tr><tr id="46678835"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46678835" href="https://news.ycombinator.com/vote?id=46678835&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I suspect they're doing whatever job needs to be done, as with models in any other language.</p><p>I also suspect they need a similar amount of hand holding and review.</p></div></td></tr></tbody></table></td></tr><tr id="46678979"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46678979" href="https://news.ycombinator.com/vote?id=46678979&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>This is implied but I guess needs to be made explicit: people are looking for answers from devs with direct knowledge of the question at hand, not what random devs suspect.</p></div></td></tr></tbody></table></td></tr><tr id="46679628"><td></td></tr><tr id="46680426"><td></td></tr><tr id="46679613"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679613" href="https://news.ycombinator.com/vote?id=46679613&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Given the mass of code out there, it strikes me it's only a matter of time before someone fine tunes one of the larger more competent coding models on COBOL. If they haven't already.</p><p>Personally I've had a lot of luck Opus etc with "odd" languages just making sure that the prompt is heavily tuned to describe best practices and reinforce descriptions of differences with "similar" languages. A few months ago with Sonnet 4, etc. this was dicey. Now I can run Opus 4.5 on my own rather bespoke language and get mostly excellent output. Especially when it has good tooling for verification, and reference documentation available.</p><p>The downside is you use quite a bit of tokens doing this. Which is where I think fine tuning could help.</p><p>I bet one of the larger airlines or banks could dump some cash over to Anthropic etc to produce a custom trained model using a corpus of banking etc software, along with tools around the backend systems and so on. Worthwhile investment.</p><p>In any case I can't see how this would be a <i>threat</i> to people who work in those domains. They'd be absolutely invaluable to understand and apply and review and improve the output. I can imagine it making their jobs 10x more pleasant though.</p></div></td></tr></tbody></table></td></tr><tr id="46681673"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46681673" href="https://news.ycombinator.com/vote?id=46681673&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; competent coding models on COBOL</p><p>Which COBOL... This is a particular issue in COBOL is it's a much more fragmented language than most people outside the industry would expect. While a model would be useful for the company that supplied the data, the amount of transference may be more limited than one would expect.</p></div></td></tr></tbody></table></td></tr><tr id="46678855"><td></td></tr><tr id="46679486"><td></td></tr><tr id="46678950"><td></td></tr><tr id="46678970"><td></td></tr><tr id="46681694"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46681694" href="https://news.ycombinator.com/vote?id=46681694&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I've seen songs on spottily called "anything" and "Just play anything", so I guess it may be worthwhile if I change my name to "anyone" for when someone asks their LLM to "just hire anyone"</p></div></td></tr></tbody></table></td></tr><tr id="46681741"><td></td></tr><tr id="46680408"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46680408" href="https://news.ycombinator.com/vote?id=46680408&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Total BS. Cobol is well documented and actively developed. I bet you didn't even TRY to write single program for it...  Stop spreading FUD</p></div></td></tr></tbody></table></td></tr><tr id="46679219"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679219" href="https://news.ycombinator.com/vote?id=46679219&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I see it as a complete opposite for sure, I will tell you why.</p><p>it could have been a threat if it was something you cannot control, but you can control it, you can learn to control it, and controlling it in the right direction would enable anyone to actually secure your position or even advance it.</p><p>And, about the COBOL, well i dont know what the heck this is.</p></div></td></tr></tbody></table></td></tr><tr id="46679665"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679665" href="https://news.ycombinator.com/vote?id=46679665&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>This is amazing!  Thank you for confirming what I've been suspecting for a while now.  People that actually know very little about software development now believe they don't need to know anything about it, and they are commenting very confidently here on hn.</p></div></td></tr></tbody></table></td></tr><tr id="46680036"><td></td></tr><tr id="46679097"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679097" href="https://news.ycombinator.com/vote?id=46679097&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>The point about the mass of code running the economy being untouched by AI agents is so real. During my years as a developer, I've often faced the skepticism surrounding automation technologies, especially when it comes to legacy languages like COBOL. There’s a perception that as AI becomes more capable, it might threaten specialized roles. However, I believe that the intricacies and context of legacy systems often require human insight that AI has yet to master fully.</p><p>I logged my fix for this here: <a href="https://thethinkdrop.blogspot.com/2026/01/agentic-automation-in-python-how-ai.html" rel="nofollow">https://thethinkdrop.blogspot.com/2026/01/agentic-automation...</a></p></div></td></tr></tbody></table></td></tr><tr id="46679164"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46679164" href="https://news.ycombinator.com/vote?id=46679164&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>I would assert this is affecting all programming languages, this is like the transition from Assembly to high level languages.</p><p>Who thinks otherwise, even if LLMs are still a bit dumb today, is fooling themselves.</p></div></td></tr></tbody></table></td></tr><tr id="46679630"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46679630" href="https://news.ycombinator.com/vote?id=46679630&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Compiling high level languages to assembly is a deterministic procedure.  You write a program using a small well defined language (relative to natural language every programming language is tiny and extremely well defined).  The same input to the same compiler will get you the same output every time.  LLMs are nothing like a compiler.</p></div></td></tr></tbody></table></td></tr><tr id="46679755"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46679755" href="https://news.ycombinator.com/vote?id=46679755&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>If we ignore optimizing compilers and UB.</p><p>"Project the need 30 years out and imagine what might be possible in the context of the exponential curves"</p><p>-- Alan Kay</p></div></td></tr></tbody></table></td></tr><tr id="46680322"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680322" href="https://news.ycombinator.com/vote?id=46680322&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Is there any compiler that "rolls the dice" when it comes to optimizations?  Like, if you compile the exact same code with the exact same compiler multiple times you'll get different assembly?</p><p>And th Alan Kay quote is great but does not apply here at all?  I'm pointing out how silly it is to compare LLMs to compilers.  That's all.</p></div></td></tr></tbody></table></td></tr><tr id="46680396"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680396" href="https://news.ycombinator.com/vote?id=46680396&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>Rolling the dice is accomplished by mixing optimizations flags, PGO data and what parts of the CPU get used.</p><p>Or by using a managed language with dynamic compiler (aka JIT) and GC. They are also not deterministic when executed, and what outcome gets produced, it is all based on heuristics and measured probabilities.</p><p>Yes, the quote does apply because many cannot grasp the idea of how technology looks beyond today.</p></div></td></tr></tbody></table></td></tr><tr id="46680548"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46680548" href="https://news.ycombinator.com/vote?id=46680548&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>&gt; how silly it is to compare LLMs to compilers.</p><p>You are quite right; the former is probabilistic while the latter is not.</p><p>To paraphrase Babbage;</p><p><i>"I am not able to rightly apprehend the kind of confusion of ideas that could provoke such a [comparison]."</i></p></div></td></tr></tbody></table></td></tr><tr id="46680260"><td></td></tr><tr id="46680344"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46680344" href="https://news.ycombinator.com/vote?id=46680344&amp;how=up&amp;goto=item%3Fid%3D46678550"></a></center></td><td><br>
<div><p>But the compiler doesn't "roll the dice" when making those guesses! Compile the same code with the same compiler and you get the same result repeatedly.</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Article by article, how Big Tech shaped the EU's roll-back of digital rights (260 pts)]]></title>
            <link>https://corporateeurope.org/en/2026/01/article-article-how-big-tech-shaped-eus-roll-back-digital-rights</link>
            <guid>46678430</guid>
            <pubDate>Mon, 19 Jan 2026 12:53:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://corporateeurope.org/en/2026/01/article-article-how-big-tech-shaped-eus-roll-back-digital-rights">https://corporateeurope.org/en/2026/01/article-article-how-big-tech-shaped-eus-roll-back-digital-rights</a>, See on <a href="https://news.ycombinator.com/item?id=46678430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
    <a id="main-content" tabindex="-1"></a>

    <div id="content">
    


<div id="block-entityviewcontent">

  

  <p><img loading="lazy" src="https://corporateeurope.org/sites/default/files/styles/image_l/public/2026-01/IMG_0198%281%29.jpeg?itok=mF_GNG30" width="800" height="533" alt="Action in November against the Digital Omnibus">



  </p>


</div>







<div id="block-mainpagecontent">

  

  

      
  
            <p id="docs-internal-guid-8d970413-7fff-a660-cab2-d5a54af12fbd" dir="ltr">In a new analysis by Corporate Europe Observatory and LobbyControl, we trace Big Tech's fingerprints on the Digital Omnibus proposals - a major deregulation of EU digital laws including the GDPR and the AI Act. They are helped in this attempt by the Trump administration and the European far right.</p>
      
      <div>
              <div><p id="docs-internal-guid-baf45d50-7fff-fae2-9151-ff9c7515bb69" dir="ltr">At the end of November 2025, Ursula von der Leyen gave Trump and his tech oligarchs an early Christmas present: an unprecedented attack on digital rights. In its so-called Digital Omnibus, the European Commission proposed weakening important rules designed to protect us from Big Tech’s abuses of power.</p>
<p dir="ltr">These are the protections that keep everyone's data safe, governments and companies accountable, protect people from having artificial intelligence (AI) systems decide their life opportunities, and ultimately keep our societies free from unchecked surveillance.</p>
<p dir="ltr">At the same time, the Digital Omnibus is part of the European Commission's&nbsp;<a href="https://corporateeurope.org/en/deregulation-watch">deregulation agenda</a>, which threatens key social and environmental standards in Europe. Ironically this deregulation agenda is being promoted by the Commission as a way to make the EU 'competitive' – despite in reality actively empowering US Big Tech companies that dominate the field.</p>
<p dir="ltr">The Digital Omnibus was immediately&nbsp;<a href="https://noyb.eu/en/digital-omnibus-eu-commission-wants-wreck-core-gdpr-principles">heavily</a>&nbsp;<a href="https://edri.org/our-work/europe-is-dismantling-its-digital-rights-from-within/">criticised</a> by&nbsp;<a href="https://www.amnesty.org/en/latest/news/2025/11/eu-digital-omnibus-proposals-will-tear-apart-accountability-on-digital-rights/">numerous</a>&nbsp;<a href="https://www.beuc.eu/press-release/eus-plan-simplify-digital-laws-benefit-mainly-large-companies-expense-consumers">civil</a> society organisations.&nbsp;<a href="https://www.politico.eu/article/brussels-police-world-digital-tech-us-china-regulations/">Politico</a> even called it the end of the ‘Brussels effect’ – that is, that European tech regulations are adopted in other countries – and wrote that “Washington is [now] setting the pace on deregulation in Europe.”</p>
<p dir="ltr">To show the extent of Big Tech’s influence on the Digital Omnibus, we compared the Commission’s proposals with the lobbying positions from Big Tech and its associations.&nbsp;</p>
<p dir="ltr">The proposals in the Digital Omnibus concern both data protection and rules for AI. While the EU mistakenly speaks of benefits for European corporations, it is clear that weak digital rules strengthen the power of Google, Microsoft, Meta etc, thereby jeopardising the goal of becoming more independent from Big Tech and the US.&nbsp;</p>
<p dir="ltr">In the past, Big Tech has repeatedly spread the one-sided lobbying message that data protection hinders economic growth and innovation,&nbsp;<a href="https://euneedsai.com/">especially</a> with regard to AI. This includes exceptions for SMEs and a fundamental focus on making&nbsp;<a href="https://www.lobbyregister.bundestag.de/media/2f/ca/502331/Stellungnahme-Gutachten-SG2503310295.pdf">more use of data</a> instead of protecting it.</p>
<p dir="ltr">Tech companies are spreading these messages with a record-breaking lobbying budget, a huge lobbying network, and support from the Trump administration. The digital industry’s annual lobby spending has grown from&nbsp;<a href="https://corporateeurope.org/en/2025/10/big-tech-lobby-budgets-hit-record-levels">€113 million in 2023 to €151 million today</a> – an increase of 33.6 percent in just two years.</p>
<p dir="ltr">Now, the European Commission appears to be bowing to this lobbying pressure and adopting key lobbying messages from Google, Microsoft, Meta and their many lobby organisations in its Digital Omnibus.&nbsp;</p>
<p dir="ltr">Here we break down these industry lobbying messages, how they have been adopted by the Commission as proposed text changes, and what the real world impacts could be.</p>
</div>
              <div><h2 id="docs-internal-guid-8c742d9c-7fff-2d73-6bd2-abdc2b2f3b0b">How the Commission aims to weaken the GDPR and ePrivacy</h2>
<p>The General Data Protection Regulation (GDPR) is the backbone of the EU’s digital rulebook. While the Commission&nbsp;<a href="https://ec.europa.eu/commission/presscorner/detail/fr/speech_25_2732">claims</a> it is only giving the GDPR a “face-lift”, its proposed changes -&nbsp; from the definition of personal data to the use of data for training AI - will have far-reaching consequences to people’s rights, and will benefit Big Tech’s problematic business model based on massive data extraction.</p>
</div>
              <div><h3 id="docs-internal-guid-9e92ada9-7fff-22f1-9b6c-122a6665ff03">Limiting the definition of personal data&nbsp;</h3>
<p dir="ltr">The Commission intends to stop classifying pseudonymised data (ie swapping out a user's identifiable name for a code or number) as personal data if a company claims it cannot identify a person, thereby exempting it from GDPR protection. This rule would also apply even when other actors ( for instance data brokers) can still identify individuals based on the pseudonymised data.</p>
<p dir="ltr">As the digital rights organisations&nbsp;<a href="https://noyb.eu/en/digital-omnibus-eu-commission-wants-wreck-core-gdpr-principles">Noyb</a> and&nbsp;<a href="https://edri.org/our-work/commissions-digital-omnibus-is-a-major-rollback-of-eu-digital-protections/">EDRi</a> have pointed out, this change turns a universal rule into a subjective one. GDPR protections will only apply when a company has the means to identify a person based on the data it holds. This gives huge leeway to companies to decide not to apply the GDPR arguing that they can’t identify a person. Worse, data can be sold to other companies or data brokers that do have the means to re-identify individuals.&nbsp;</p>
<p dir="ltr">But even if data is never sold or passed on to third parties, the proposed subjective approach would still severely narrow the scope of the GDPR. Big Tech companies such as Meta and Google for instance could use personal data for online tracking by claiming that the data cannot be traced back to a natural person and is therefore not covered by the GDPR.</p>
</div>
              <div>
<dl>
<dt><strong>Digital Omnibus</strong></dt>
<dd>
<p dir="ltr"><strong>Proposed changed text to article 4(1) of the GDPR in the digital omnibus in italics:</strong> “Information relating to a natural person is not necessarily personal data for every other person or entity, merely because another entity can identify that natural person.&nbsp;</p>
<p dir="ltr"><em>Information shall not be personal for a given entity where that entity cannot identify the natural person to whom the information relates, taking into account the means reasonably likely to be used by that entity. Such information does not become personal for that entity merely because a potential subsequent recipient has means reasonably likely to be used to identify the natural person to whom the information relates.</em></p>
</dd>
</dl>
</div>
              <div><dl>
<dt>Big Tech’s lobby position&nbsp;&nbsp;</dt>
<dd>
<p id="docs-internal-guid-faedc10c-7fff-a82e-6b7c-f7f0c86a1bc4" dir="ltr">This move closely reflects Big Tech's lobby position. The industry&nbsp; has long been calling for greater commercial use of personal data. The use of anonymous and pseudonymous data in particular would contribute to this.</p>
<p dir="ltr"><strong>DigitalEurope</strong>, (which counts all Big Tech companies among its members),&nbsp;<a href="https://corporateeurope.org/sites/default/files/2026-01/DigitalEurope%20lobby%20paper.pdf">wrote</a>: “Clarify that pseudonymised data is not personal data when recipients cannot reasonably re-identify individuals.”</p>
<p dir="ltr"><strong>Microsoft Germany</strong> also&nbsp;<a href="https://www.lobbyregister.bundestag.de/media/92/8d/322766/Stellungnahme-Gutachten-SG2406280060.pdf">lobbied</a> for weakening the definition along similar lines.</p>
</dd>
</dl>
</div>
              <div><h3 id="docs-internal-guid-20d6b5a7-7fff-42d2-a79e-520cb267b9e1">Limiting your right to access your own data&nbsp;</h3>
<p dir="ltr"><strong>Summary:&nbsp;</strong>Currently, anyone can request a copy of their personal data from any company or organisation that holds it. However, the Commission intends to limit this right if a person ‘abuses’ it.</p>
<p dir="ltr">This will severely limit the rights of individuals to know which of their data is being held by Big Tech. For instance,&nbsp;<a href="https://www.workerinfoexchange.org/post/historic-digital-rights-win-for-wie-and-the-adcu-over-uber-and-ola-at-amsterdam-court-of-appeal">in 2023 Uber and Ola drivers who were ‘robo-fired’ won a court case</a> against the company after it refused access to their work-related information. Ola tried to argue that the drivers requests for data amounted to an abuse of data protection rights, an excuse that the Commission now wants to give a legal basis.</p>
<p dir="ltr">This will make it harder to hold Big Tech to account and to contest their unlawful practices. “The proposal threatens to dismantle a tool of counter-power”, as the academic René Mahieu&nbsp;<a href="https://verfassungsblog.de/digital-omnibus-right-of-access-to-personal-data/">writes</a>.&nbsp;</p>
<p dir="ltr">Contrary to the claims made by industry, and adopted by the German Government, it is not citizens who have ‘abused’ their right to access their own data, but tech companies that have disregarded this right. According to the privacy organisation NOYB<a href="https://noyb.eu/sites/default/files/2025-12/noyb%20Digital%20Omnibus%20Report%20V1.pdf"> 90 percent of data access requests are not respected</a>. In one case, it took&nbsp;<a href="https://noyb.eu/en/noyb-win-youtube-ordered-honour-users-right-access">more than five years&nbsp;</a>for Youtube to respect a particular data access request.</p>
</div>
              <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p dir="ltr"><strong>Proposed changed text to article 12(5) of the GDPR in the digital omnibus in italics: “</strong>Where requests from a data subject are manifestly unfounded or excessive, in particular because of their repetitive character&nbsp;<em>or also, for requests under Article 15 because the data subject abuses the rights conferred by this regulation for purposes other than the protection of their data</em>, the controller may either: a) charge a reasonable fee [...] or refuse to act on the request.</p>
<p dir="ltr">The controller shall bear the burden of demonstrating&nbsp;<em>that</em> the&nbsp;<em>request is</em> manifestly unfounded&nbsp;<em>or that there are reasonable grounds to believe that it is excessive</em>.”</p>
</dd>
</dl>
</div>
              <div><dl>
<dt><strong>Big Tech’s lobby position&nbsp;&nbsp;</strong></dt>
<dd>
<p dir="ltr"><strong>The German Government lobbied for this change&nbsp;</strong>in an&nbsp;<a href="https://noyb.eu/sites/default/files/2025-11/German%20Proposal%20for%20simplification%20of%20the%20GDPR.pdf">influential but controversial position paper</a>. What has largely gone under the radar, however, is that these proposals were actually&nbsp;<a href="https://www.lobbycontrol.de/pressemitteilung/digitalgipfel-weniger-datenschutz-mehr-macht-fuer-big-tech-123225/">pushed</a> by Big Tech companies.</p>
<p dir="ltr">In a&nbsp;<a href="https://www.lobbyregister.bundestag.de/inhalte-der-interessenvertretung/stellungnahmengutachtensuche/SG2510270013">lobby paper</a> dated 16 August 2025,&nbsp;<strong>Google</strong> called on the German Government to "Introduce a ‘disproportionate efforts’ exemption to compliance with Articles 15-22 GDPR". With regard to Article 12(5), Google proposed the following addition highlighted in bold:&nbsp;</p>
<p dir="ltr">“Where requests from a data subject are manifestly unfounded or excessive, in particular because of their repetitive character,&nbsp;<strong>or, taking into account the scope of the processing and the cost of implementation, where responding to the request would involve a disproportionate effort</strong>, the controller may either: (a) charge a reasonable fee taking into account the administrative costs of providing the information or communication or taking the action requested; or (b) refuse to act on the request.”</p>
</dd>
</dl>
</div>
              <div><h3 id="docs-internal-guid-0be98fd3-7fff-5dd0-ab4d-99f12b489c19"><strong>Using your personal data for training AI</strong></h3>
<p dir="ltr">Generative AI models are being trained on enormous amounts of data. The Commission intends to permit the training of AI models with personal data, including highly sensitive data such as sexuality, political beliefs, or ethnicity, without active consent. People’s data will only be protected from being used for training AI models if they explicitly opt-out.</p>
<p dir="ltr">Tech companies can basically hoover up any personal data on the internet to train their AI models without active consent (opt-out would still be possible). The protection of sensitive data for training AI such as political beliefs, union membership or sexuality is also weakened.</p>
<p dir="ltr">There is a risk of ‘data leakage’ whereby AI systems reproduce the personal data it has been trained on or produce fake information. In one such case a journalist was<a href="https://www.abc.net.au/news/2024-11-04/ai-artificial-intelligence-hallucinations-defamation-chatgpt/104518612"> falsely accused by a Microsoft chatbot of child abuse</a> when in fact he had just published articles on criminal court cases about it. The AI system, in essence a statistical programme, had conflated this information and had made him out to be a criminal.</p>
<p dir="ltr">Major tech companies such as Meta, Google and X stand to benefit as they can train their AI models with massive troves of personal data collected through their platforms.&nbsp;</p>
<p dir="ltr">Big Tech companies are spending enormous amounts,&nbsp;<a href="https://www.cnbc.com/2025/10/31/big-tech-ai-spending-billions-microsoft-google-software-subscriptions.html">possibly as much as US$550 billion in 2026</a>, to dominate the AI market. Loosening rules on AI data collection plays directly into their hands.</p>
</div>
              <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-3b899312-7fff-49a3-e7a2-3628b41a1914" dir="ltr"><strong>Proposed text:&nbsp;</strong></p>
<ul>
<li dir="ltr"><strong>The digital omnibus introduces a new article 88c in the GDPR introducing the use of personal data for AI training as a legitimate interest</strong>:&nbsp;<em>“Where the processing of personal data is necessary for the interests of the controller in the context of the development and operation of an AI system such processing may be pursued for legitimate interests within the meaning of Article 6(1)(f)”</em><br>&nbsp;</li>
<li dir="ltr"><strong>The digital omnibus also waters down protections on using sensitive data for AI training by introducing article 9(5) to the GDPR</strong>:<em> “For processing referred to in point (k) of paragraph 2, appropriate organisational and technical measures shall be implemented to avoid the collection and otherwise processing of special categories of personal data. Where, despite the implementation of such measures, the controller identifies special categories of personal data in the datasets used for training, testing or validation or in the AI system or AI model, the controller shall remove such data. If removal of those data requires disproportionate effort, the controller shall in any event effectively protect without undue delay such data from being used to produce outputs, from being disclosed or otherwise made available to third parties.”</em></li>
</ul>
</dd>
</dl>
</div>
              <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-3eeab578-7fff-3789-9ae3-187d8abc0314" dir="ltr">This has been a top priority of Big Tech lobbying. Almost every trade association and company has lobbied both the Commission and member states on that topic.</p>
<p dir="ltr">Big Tech lobby organisation<strong>&nbsp;</strong><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088547_en"><strong>CCIA</strong></a>: “It is crucial to reaffirm the role of legitimate interest as a lawful basis under the GDPR for responsible AI innovation, moving beyond the non-binding EDPB opinion to provide harmonised legal certainty for AI training.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33103770_en"><strong>DigitalEurope</strong></a>: “Reinforce the use of ‘legitimate interest’ as a ground to process personal data for key use cases such as product development – including of AI models – and security.”</p>
<p dir="ltr">Big Tech lobby organisation<a href="https://corporateeurope.org/sites/default/files/2026-01/DOT%20Europe%20letter%20to%20Danish%20government.pdf"><strong> Dot Europe</strong></a> (in a lobby letter to the Danish Government): “GDPR Article 9 strictly limits the processing of special category data (e.g., race, ethnicity, health), posing challenges for AI development, particularly in healthcare. AI models need access to sensitive data to ensure accuracy, fairness, and cultural relevance.”</p>
</dd>
</dl>
</div>
              <div><h3 id="docs-internal-guid-670509c7-7fff-9a7b-7fc9-3369e98f1371"><strong>Weakening rules on automated decision-making&nbsp;</strong></h3>
<p dir="ltr">Currently, automated systems cannot be used to make decisions with legal effect or for online profiling. A human must be in the loop. The Commission’s proposal is a structural shift from a general prohibition on automated decision-making but with a few narrow exceptions towards an authorisation regime where a company can employ automated decision-making whenever it thinks this is “necessary”.</p>
<p dir="ltr">Important decisions including credit scoring, ‘robo-firings’, profiling, and welfare benefits could in the future be taken by automated decision-making without human intervention. This change will increasingly expose people to possibly flawed and biased algorithms which could make life-changing decisions, including if you get a loan or are fired from your job. Moreover these algorithms are generally black boxes, meaning it can be hard to uncover evidence of bias. Scandals in the&nbsp;<a href="https://www.amnesty.org/en/latest/news/2021/10/xenophobic-machines-dutch-child-benefit-scandal/">Netherlands</a> and&nbsp;<a href="https://www.bbc.com/news/world-australia-66130105">Australia</a> already show how thousands of people can be wrongly targeted with devastating effects.</p>
<p dir="ltr">In 2024, a subsidiary of the food delivery platform Glovo&nbsp;<a href="https://edri.org/our-work/italian-dpas-e5m-fine-against-glovo-marks-milestone-for-workers-rights/">was fined</a> €5 million by the Italian data protection authority under article 22 of the GDPR for violating workers' rights. The platform had used its rating system to automatically assign orders or ‘deactivate’ (read: ‘fire’) workers based on their ratings.</p>
<p dir="ltr">While the drastic weakening of article 22 will benefit a range of different sectors, from the insurance and banking sector to gig economy companies, Big Tech is also set to profit.&nbsp;</p>
<p dir="ltr">At the moment, social media giants employ thousands of underpaid workers to review harmful or illegal content on social media. This change will allow Big Tech companies to fully automate content moderation, cutting these costs essentially down to zero. Since the inauguration of Trump, Meta has<a href="https://www.theguardian.com/technology/2025/apr/23/meta-hastily-changed-moderation-policy-with-little-regard-to-impact-says-oversight-board"> fired thousands of content moderators</a>. Amnesty International<a href="https://www.amnesty.org/en/latest/news/2025/02/meta-new-policy-changes/"> has warned&nbsp;</a>that replacing content moderators with automated systems could amplify the most harmful content including content inciting racial hatred.</p>
</div>
              <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-5e95c669-7fff-85a3-b42e-c9abac657944" dir="ltr"><strong>Proposed text to Article 22 of the GDPR in italics</strong>: “<em>A decision which produces legal effects for a data subject or similarly significantly affects him or her may be based solely on automated processing, including profiling, only where that decision</em>: (a) is necessary for entering into, or performance of, a contract between the data subject and a data controller<em> regardless of whether the decision could be taken otherwise than by solely automated means</em>.”</p>
</dd>
</dl>
</div>
              <div><dl>
<dt>Big Tech’s lobby position&nbsp;&nbsp;</dt>
<dd>
<p id="docs-internal-guid-a08c610f-7fff-3c44-3663-0ddb62903a26" dir="ltr">While Big Tech companies have been complaining about the overlap between article 22 of the GDPR with the AI Act and the Platform Work Directive, it seems it was mainly insurance sector lobbying that was decisive in rolling back the protection on automated decision-making (Big Tech is however still set to benefit from this change). In 2023, the European Court of Justice<a href="https://curia.europa.eu/juris/liste.jsf?num=C-634/21"> ruled in a landmark case&nbsp;</a>that credit scores based on profiling cannot be used by banks and insurance companies to decide on granting a loan or other financial products. The Digital Omnibus might now undermine that ruling.&nbsp;</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088532_en"><strong>Insurance Europe</strong></a>: "Automated-decision making should be allowed as long as it is subject to safeguard mechanisms. To ensure that Art. 22 does not become an obstacle to the development of new digital solutions, it should be clarified that it is a right of the data subject and not an ex-ante prohibition."</p>
<p dir="ltr">Big Tech lobby organisation&nbsp;<a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088547_en"><strong>CCIA</strong></a>: “The definitions of the General Data Protection Regulation’s (GDPR) ‘automated individual decision-making’ (Article 22), the AI Act’s ‘AI system’ (Article 3(1)), and the Platform Work Directive’s (PWD) for automated decision-making systems often overlap.”</p>
</dd>
</dl>
</div>
              <div><h3 id="docs-internal-guid-7d6fe0e9-7fff-bd1c-753a-6bddaf70988d"><strong>Folding parts of ePrivacy into the GDPR</strong></h3>
<p dir="ltr">Cookies are the backbone of the AdTech industry, used to trace our online activities in order to target us with personalised ads. Article 5(3) of the ePrivacy directive requires websites and apps to ask for prior consent before storing cookies. The Commission now wants to ‘fold’ parts of article 5(3) into the GDPR. This replaces a categorical, consent-based mechanism with a more flexible framework based on balancing and exceptions.</p>
<p dir="ltr">Folding ePrivacy into the GDPR creates a more permissive system that allows companies to use exceptions to track behaviour. The&nbsp;<a href="https://netzpolitik.org/2025/databroker-files-all-you-need-to-know-about-how-adtech-data-exposes-the-eu-to-espionage/">Databroker Files</a> demonstrated that commercial datasets which contain millions of locations could actually be used to spy on the public in Europe. These and other examples show the risks to our privacy are real: reporting shows how the vast trade in location data from smartphones can be traced back to individuals showing where they were at a specific time.</p>
<p dir="ltr">It will allow them to do even more of what they already do: track you&nbsp;<a href="https://techcrunch.com/2020/12/10/france-fines-google-120m-and-amazon-42m-for-dropping-tracking-cookies-without-consent/">without your consent</a>. Big Tech firms have been&nbsp;<a href="https://techcrunch.com/2021/11/01/digging-into-googles-push-to-freeze-eprivacy/">lobbying for years against ePrivacy</a> as it could undermine their invasive business model based on surveillance ads.&nbsp;</p>
<p>Several Big Tech firms have moreover&nbsp;<a href="https://techcrunch.com/2020/12/10/france-fines-google-120m-and-amazon-42m-for-dropping-tracking-cookies-without-consent/">faced fines&nbsp;</a>for tracking users without consent. This change might let these companies get away with their most problematic practices.</p>
</div>
              <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-a1220957-7fff-28f4-8fce-45d6d0d0f6b0" dir="ltr"><strong>New text added to article 5(3) of the ePrivacy directive in italics</strong>: “<em>This paragraph shall not apply if the subscriber or user is a natural person, and the information stored or accessed constitutes or leads to the processing of personal data.”</em></p>
<p dir="ltr"><strong>A new GDPR article 88a takes over instead which also introduces a series of exceptions to ask for consent</strong> including when “creating aggregated information about the usage of an online service to measure the audience of such a service, where it is carried out by the controller of that online service solely for its own use”.</p>
</dd>
</dl>
</div>
              <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-616d9873-7fff-185e-3391-0eaa46c03ead" dir="ltr">The telecom sector, publishers and the tech industry have lobbied for years against strong privacy protections as guaranteed by the ePrivacy directive. In 2018 a major Big Tech driven lobby campaign&nbsp;<a href="https://corporateeurope.org/en/power-lobbies/2018/06/shutting-down-eprivacy-lobby-bandwagon-targets-council">prevented</a> efforts to strengthen the ePrivacy Directive. A court document showed Google revealing that “we have been successful in slowing down and delaying the [ePrivacy Regulation] process and have been working behind the scenes hand in hand with the other companies.” The digital omnibus is another step in dismantling ePrivacy protections with all major players pushing for the changes as proposed by the Commission.</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088017_en"><strong>Google</strong></a>: “The most effective simplification is to delete Article 5(3) from the ePrivacy directive and govern all data processing related to cookies under the GDPR risk-based framework. Alternatively, a significant step toward simplification would be to amend Article 5(3) to extend the scope of permitted exemptions to allow specific, low-risk processing activities that are essential both for the functioning of a safe and sustainable digital ecosystem as well as for user experience. This would create clear exemptions for functions such as first-party audience measurement, ad frequency capping, and anti-fraud measures—allowing them to operate without generating unnecessary consent requests.”&nbsp;&nbsp;</p>
<p dir="ltr"><a href="https://corporateeurope.org/sites/default/files/2026-01/Microsoft%20lobby%20paper%20data%20union%20strategy.pdf"><strong>Microsoft</strong></a><strong>:</strong> “The “cookie rule” in article 5 (3) eP[rivacy] D[irective] could be moved to the GDPR or, if kept in, rendered more flexible by allowing cookie placement without consent in a wider range of circumstances, e.g. for security, software updates, anti-fraud, and analytics.”</p>
</dd>
</dl>
</div>
              <div><h2 id="docs-internal-guid-e42d9ba0-7fff-743a-578b-669027a52594"><strong>How the Commission aims to weaken the AI Act</strong></h2>
<p dir="ltr">"Europe is open for AI and for business!" Ursula von der Leyen tweeted during the AI Action Summit in Paris. In its single-minded priority to “win the global AI race”, the Commission is slashing rules and protections against risky AI systems. A year-long&nbsp;<a href="https://corporateeurope.org/en/2025/11/preparing-roll-back-digital-rights-commissions-secretive-meetings-industry">lobby campaign</a> by the Trump administration and Big Tech to delay the implementation of the AI Act has clearly paid off.</p>
</div>
              <div><h3 id="docs-internal-guid-f2d642be-7fff-e6de-2e0c-7fe036554457"><strong>No Checks and Balances for risky AI systems&nbsp;</strong></h3>
<p dir="ltr">A controversial win for Big Tech firms during the AI Act negotiations was allowing companies to “self-assess” if they believe an AI system is high-risk. To compensate for that loophole, industry had to register these AI systems in a public database. Now this transparency failsafe will also be removed, basically giving tech companies a free hand in deciding if an AI system is risky without any public oversight.&nbsp;</p>
<p dir="ltr">The risk to fundamental rights these high-risk AI systems pose are far from hypothetical.&nbsp; From<a href="https://www.bbc.com/news/business-54698858">&nbsp;algorithmic-powered employee firings</a> to<a href="https://www.axios.com/2020/08/19/england-exams-algorithm-grading">&nbsp;biased algorithms that disadvantage students</a> based on their socio-economic background, highly problematic AI systems are already in circulation. The AI Act lets companies self-assess if these AI systems are high-risk or not, and should therefore comply with requirements such as proper risk management, accuracy, and transparency.</p>
<p dir="ltr">The digital omnibus will worsen an already huge loophole in the AI Act with potentially disastrous impacts on our rights.</p>
<p dir="ltr">Not only can AI companies already self-assess if their AI systems are risky, the digital omnibus will remove any possibility of public oversight of that assessment, giving these companies a blank check to do as they please without any accountability mechanism.</p>
<p dir="ltr">In<a href="https://www.linkedin.com/feed/update/urn:li:activity:7396855577064398849/"> a reaction on LinkedIn</a> Daniel Leufer from the NGO Access Now called this “the biggest, most ridiculous loophole in the AI Act that will let unscrupulous providers unilaterally exempt themselves from the AI Act's obligations with oversight”.&nbsp;&nbsp;</p>
</div>
              <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-aa943702-7fff-4db2-83eb-5cc135dae204" dir="ltr"><strong>Paragraph 2 of article 49 of the AI Act is deleted.</strong></p>
</dd>
</dl>
</div>
              <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-27e01355-7fff-f562-cfea-5cf2ab5716da" dir="ltr">The Commission’s proposals are completely in line with the lobby position of the two lobby organisations Dot Europe and DigitalEurope that count Big Tech members as its members.&nbsp;</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33103770_en"><strong>DigitalEurope</strong></a>: “Abolish the mandatory registration of AI systems, along with the related EU and Member State databases.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087422_en"><strong>Dot Europe</strong></a><strong>:</strong> “when a provider of AI systems provides concrete justifications that its AI system does not pose a significant risk of harm to the health, safety or fundamental rights of natural persons per Article 6(3), it should not be required to register its system in the high-risk AI database per Article 49.”&nbsp;&nbsp;</p>
</dd>
</dl>
</div>
              <div><h3 id="docs-internal-guid-6a019008-7fff-431e-f228-8639b04b8077"><strong>Delay in the implementation of the AI Act</strong></h3>
<p dir="ltr">The Commission intends to postpone the implementation of part of the AI Regulation by almost a year and a half. This means giving Big Tech more than 12 months to continue releasing potentially risky systems onto the market without any safeguards.</p>
<p dir="ltr">This proposal would enable companies to continue to release risky AI systems for at least a year onto the market without any safeguards. Moreover, as the<a href="https://cdt.org/wp-content/uploads/2025/12/CDT-Europe-Brief-Digital-Omnibus-Threatens-Hard-Won-AI-Safeguards.pdf"> Center for Democracy and Technology points out</a>, delaying the parts of the AI Act on high-risk AI systems, will also obstruct the ban of the most dangerous AI systems, leaving dangerous practices such as&nbsp;<a href="https://edri.org/our-work/emotion-misrecognition/">emotion recognition systems</a> and facial recognition AI used in public spaces on the market for longer.</p>
<p dir="ltr">Delaying is<a href="https://corporateeurope.org/en/2023/11/how-pesticide-lobby-sabotaging-eu-pesticide-reduction-law-sur">&nbsp;a tried and tested industry lobbying tactic</a>. It will give Big Tech more time to further water down the AI Act. Already, tech lobbyists are&nbsp;<a href="https://ccianet.org/news/2025/12/dont-let-digital-simplification-stall-eu-member-states-warned-by-tech-sector/">calling</a> for the further deregulation of the AI Act.</p>
</div>
              <div><dl>
<dt>Big Tech’s lobby position&nbsp;</dt>
<dd>
<p id="docs-internal-guid-b5a2e1d9-7fff-3947-9538-0a5ddb96be61" dir="ltr">A delay in the implementation of the AI Act is a central demand in a&nbsp;<a href="https://corporateeurope.org/en/2025/11/preparing-roll-back-digital-rights-commissions-secretive-meetings-industry">year-long tech lobby campaign</a> which was backed by the Trump administration.</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088547_en"><strong>CCIA</strong></a>: “The first priority should be to delay AI Act implementation until at least 12 months after relevant guidance, codes of practice, or technical standards become available.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33103770_en"><strong>DigitalEurope</strong></a>: “Delay the application of high-risk AI requirements until at least 12 months after relevant harmonised standards are published, allowing sufficient time for adaptation.”</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33089184_en"><strong>Meta</strong></a><strong>:&nbsp;</strong>“It is critical to first pause the implementation and enforcement of the [AI Act]. This pause will provide the necessary time to undertake meaningful reforms without risking the EU falling behind in the global AI race.&nbsp;</p>
</dd>
</dl>
</div>
              <div><h3 id="docs-internal-guid-25437b55-7fff-a246-ab30-33677ccc0348"><strong>Using your sensitive data to train AI&nbsp;</strong></h3>
<p dir="ltr">The AI Act under narrow circumstances allowed the use of sensitive data for mitigation of high-risk AI models to prevent bias and discrimination. This exception is now expanded to all AI systems based on the assessment of companies if the processing is necessary (see also above as part of the changes to the GDPR).</p>
<p dir="ltr">This will allow intrusive gathering of your most sensitive personal data to train AI systems. Also see above “Using your personal data for training AI.</p>
<p dir="ltr">While Big Tech claims that more data is necessary for detecting bias,&nbsp;<a href="https://www.sciencedirect.com/science/article/pii/S0160791X25003173">research</a>&nbsp;<a href="https://edri.org/wp-content/uploads/2021/09/EDRi_Beyond-Debiasing-Report_Online.pdf">suggests</a> that debiasing -&nbsp; certain statistical techniques to ‘correct’ bias in databases that are used to train AI - is often ineffective and is unable to detect the many forms and contexts in which discrimination and bias manifests. Instead, it is a technical fix that enables Big Tech companies to collect yet more sensitive personal data to train their AI models while creating the illusion of ethical AI, all while encouraging the widespread adoption of AI across all sectors of society.</p>
</div>
              <div><dl>
<dt>Digital Omnibus</dt>
<dd>
<p id="docs-internal-guid-14fc2415-7fff-f8e5-5791-dc9231e90f97" dir="ltr"><strong>The digital omnibus introduces article 4(a) to the AI Act</strong>: “To the extent necessary to ensure bias detection and correction in relation to high-risk AI systems in accordance with Article 10 (2), points (f) and (g), of this Regulation, providers of such systems may exceptionally process special categories of personal data.”</p>
</dd>
</dl>
</div>
              <div><dl>
<dt>Big Tech’s lobby position</dt>
<dd>
<p id="docs-internal-guid-a8b18b69-7fff-bdab-e1e3-069b36e29e69" dir="ltr">The tech lobby constantly portrays data protection as a major obstacle to AI training and has therefore repeatedly lobbied, either specifically or in general terms, for the weakening of data protection.&nbsp;</p>
<p dir="ltr"><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088017_en"><strong>Google</strong></a>: “We propose extending the allowance in Article 10(5) to permit the necessary data processing for bias detection and correction across all AI systems and general purpose AI models. Extending this provision will provide a harmonized legal basis for developers to proactively build the fair, representative, and trustworthy AI that aligns with the EU’s core values and benefits all citizens. It will also reduce the risk of AI models and systems perpetuating or amplifying societal discrimination, irrespective of their specific AI Act risk classification.”&nbsp;&nbsp;</p>
<p dir="ltr">Big Tech lobby organisation<strong>&nbsp;</strong><a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087752_en"><strong>Information Technology Industry Council (ITI)</strong></a>: “The AI Act's Article 10(5) allowance for special categories of personal data processing for bias mitigation should be extended to the training of all AI systems and GPAI models, not just those classified as "high-risk.”</p>
</dd>
</dl>
</div>
              <div><h2 id="docs-internal-guid-c7899791-7fff-10f8-e917-ea91e4494d4c"><strong>A Big Tech-far right alliance in the making?</strong></h2>
<p dir="ltr">The Commission’s digital omnibus received widespread criticism. Civil society organisations, think tanks, experts, and political groups in the European Parliament from the left to the centre all perceived the Commission’s proposals as handouts to Big Tech and the Trump administration.</p>
<p dir="ltr">But while the Social Democrats in the Parliament called the digital omnibus&nbsp;<a href="https://www.socialistsanddemocrats.eu/newsroom/sds-dont-deregulate-and-weaken-eus-digital-legal-framework-protects-people">unacceptable deregulation</a>,&nbsp;<a href="https://www.politico.eu/article/ursula-von-der-leyen-eu-parliament-showdown-digital-red-tape-crusade/">far right parties</a> quickly came to the support of the Commission.</p>
<p dir="ltr">Big Tech lobbying of the European Parliament also shifted in higher gear. Lobbying of the far-right seems to have become a particular priority for Meta, and to a lesser extent Google. While during the previous parliamentary mandate, Meta only met once with a far-right MEP, during this parliamentary mandate it has&nbsp;<a href="https://corporateeurope.org/en/media/6519">already met 38 times&nbsp;</a>with MEPs from the ECR, the Patriots and the Europe of Sovereign Nations Group. The digital omnibus is a key priority in those meetings. In the week of 8 December 2025, Meta met with four far right MEPs with most of those meetings mentioning the digital omnibus.&nbsp;</p>
<p dir="ltr">Google has also not shied away from meeting far-right MEPs. A few days after the launch of the digital omnibus, the Head of Public Affairs of Google France&nbsp;<a href="https://www.instagram.com/p/DRfV_JpDdhf/?img_index=2">joined a dinner party</a> in Strasbourg hosted by six French MEPs from the far right Rassemblement National.&nbsp;</p>
</div>
              <div>

  

  <p><img loading="lazy" src="https://corporateeurope.org/sites/default/files/styles/image_l/public/2026-01/Screenshot%20from%202026-01-13%2010-06-50.png?itok=gFs9cpmp" width="800" height="579" alt="Google France at a dinner party of far-right MEPs of Rassemblement National ">



  </p>

<div>
    
            <p>The Head of Public Affairs of Google France&nbsp;joined at a dinner party in Strasbourg hosted by six MEPs from the far right Rassemblement National.</p>
      
            <p>Souce: Instagram</p>
      
  </div>

</div>
              <div><p dir="ltr">Big Tech's lobbying strategy in the US, where it has&nbsp;<a href="https://www.theguardian.com/global/2025/dec/15/ai-trump-openai-google-data-centers">aligned</a> itself with the Trump administration, now appears to have been extended to the European Parliament.</p>
<p dir="ltr">As outlined in this article, the digital omnibus is not just an unprecedented attack on our digital rights – it also closely mirrors Big Tech lobbying positions. The Commission’s deregulation agenda threatens to undermine years of progress in reining these tech giants and protecting our privacy.&nbsp;</p>
<p dir="ltr">The emerging far right - Big Tech alliance in the European Parliament points towards an even more alarming trend. It should now be clear to all that the Commission’s deregulation agenda isn't just opening the door to Big Tech, it's inviting the far right in.</p>
<p dir="ltr">However, this outcome is not inevitable. The European Parliament now has a crucial opportunity to stop this dangerous proposal and defend the hard-won data protection safeguards.</p>
<p dir="ltr">The Digital Omnibus has received massive pushback, from civil society organsations, from within parliament and from member states, including Malta, which recently requested more time to scrutinise the proposal.</p>
<p dir="ltr">What happens next depends on whether we manage to increase the pressure.&nbsp;</p>
<p dir="ltr">Now is the time to make our voices heard and make it crystal clear to the European Parliament and national governments that they must stand up for our privacy, freedom of expression and democratic control over technology, and reject the Digital Omnibus.</p>
</div>
          </div>
  



</div>

<div id="block-views-block-random-promotion-block-1"><p>This article continues after the banner</p>
<a href="https://corporateeurope.org/en/newsletter"><div>

  

  <p><img loading="lazy" src="https://corporateeurope.org/sites/default/files/styles/image_l/public/2023-06/banner_newsletter.png?itok=AePb7Pff" width="800" height="200" alt="Subscribe to our newsletter">



  </p>


</div>

</a></div>
  </div>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon is ending all inventory commingling as of March 31, 2026 (448 pts)]]></title>
            <link>https://twitter.com/ghhughes/status/2012824754319753456</link>
            <guid>46678205</guid>
            <pubDate>Mon, 19 Jan 2026 12:24:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ghhughes/status/2012824754319753456">https://twitter.com/ghhughes/status/2012824754319753456</a>, See on <a href="https://news.ycombinator.com/item?id=46678205">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia Contacted Anna's Archive to Access Books (179 pts)]]></title>
            <link>https://torrentfreak.com/nvidia-contacted-annas-archive-to-secure-access-to-millions-of-pirated-books/</link>
            <guid>46677628</guid>
            <pubDate>Mon, 19 Jan 2026 11:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/nvidia-contacted-annas-archive-to-secure-access-to-millions-of-pirated-books/">https://torrentfreak.com/nvidia-contacted-annas-archive-to-secure-access-to-millions-of-pirated-books/</a>, See on <a href="https://news.ycombinator.com/item?id=46677628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><img loading="lazy" decoding="async" src="https://torrentfreak.com/images/nvidia-logo.jpg" alt="nvidia logo" width="300" height="197" srcset="https://torrentfreak.com/images/nvidia-logo.jpg 665w, https://torrentfreak.com/images/nvidia-logo-300x197.jpg 300w" sizes="auto, (max-width: 300px) 100vw, 300px">Chip giant NVIDIA has been one of the main financial beneficiaries in the artificial intelligence boom. </p>
<p>Revenue surged due to high demand for its AI-learning chips and data center services, and the end doesn’t appear to be in sight.  </p>
<p>Besides selling the most sought-after hardware, NVIDIA is also developing its own models, including NeMo, Retro-48B, InstructRetro, and Megatron. These are trained using their own hardware and with help from large text libraries, much like other tech giants do. </p>
<h2>Authors Sue NVIDIA for Copyright Infringement</h2>
<p>Like other tech companies, NVIDIA has also seen significant legal pushback from copyright holders in response to its training methods. This includes authors, who, in various lawsuits, accused tech companies of training their models on pirated books.</p>
<p>In early 2024, for example, several authors <a href="https://torrentfreak.com/authors-sue-nvidia-for-training-ai-on-pirated-books-240311/">sued NVIDIA</a> over alleged copyright infringement. </p>
<p>Through the class action lawsuit, they claimed that the company’s AI models were trained on the Books3 dataset that included copyrighted works taken from the ‘pirate’ site Bibliotik. Since this happened without permission, the authors demanded compensation. </p>
<p>In response, NVIDIA <a href="https://torrentfreak.com/nvidia-copyrighted-books-are-just-statistical-correlations-to-our-ai-models-240617/">defended its actions </a>as fair use, noting that books are nothing more than statistical correlations to its AI models. However, the allegations didn’t go away. On the contrary, the plaintiffs found more evidence during discovery. </p>
<h2>‘NVIDIA Contacted Anna’s Archive’</h2>
<p>Last Friday, the authors filed an amended complaint that significantly expands the scope of the lawsuit. In addition to adding more books, authors, and AI models, it also includes broader “shadow library” claims and allegations. </p>
<p>The authors, including <a href="https://en.wikipedia.org/wiki/Abdi_Nazemian">Abdi Nazemian</a>, now cite various internal Nvidia emails and documents, suggesting that the company willingly downloaded millions of copyrighted books. </p>
<p>The new complaint alleges that “competitive pressures drove NVIDIA to piracy”, which allegedly included collaborating with the controversial Anna’s Archive library.</p>
<center><em>Competitive pressures</em></center><br><center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/competat.png.webp 1931w, https://torrentfreak.com/images/competat-300x84.png.webp 300w" sizes="auto, (max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/competat.png" alt="pressure" width="600" height="168" srcset="https://torrentfreak.com/images/competat.png 1931w, https://torrentfreak.com/images/competat-300x84.png 300w, https://torrentfreak.com/images/competat-600x168.png 600w, https://torrentfreak.com/images/competat-150x42.png 150w, https://torrentfreak.com/images/competat-1536x431.png 1536w" sizes="auto, (max-width: 600px) 100vw, 600px">
</picture>
</center>
<p>According to the amended complaint, a member of Nvidia’s data strategy team reached out to Anna’s Archive to find out what the pirate library could offer the trillion-dollar company</p>
<p>“Desperate for books, NVIDIA contacted Anna’s Archive—the largest and most brazen of the remaining shadow libraries—about acquiring its millions of pirated materials and ‘including Anna’s Archive in pre-training data for our LLMs’,” the complaint notes. </p>
<p>“Because Anna’s Archive charged tens of thousands of dollars for ‘high-speed access’ to its pirated collections […] NVIDIA sought to find out what “high-speed access” to the data would look like.”</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/allegdata.png.webp 1909w, https://torrentfreak.com/images/allegdata-300x68.png.webp 300w" sizes="auto, (max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/allegdata.png" alt="what data?" width="600" height="135" srcset="https://torrentfreak.com/images/allegdata.png 1909w, https://torrentfreak.com/images/allegdata-300x68.png 300w, https://torrentfreak.com/images/allegdata-600x135.png 600w, https://torrentfreak.com/images/allegdata-150x34.png 150w, https://torrentfreak.com/images/allegdata-1536x346.png 1536w" sizes="auto, (max-width: 600px) 100vw, 600px">
</picture>
</center>
<h2>Anna’s Archive Points Out Legal ‘Concern’</h2>
<p>According to the complaint, Anna’s Archive then warned Nvidia that its library was illegally acquired and maintained. Because the site previously wasted time on other AI companies, the pirate library asked NVIDIA executives if they had internal permission to move forward. </p>
<p>This permission was allegedly granted within a week, after which Anna’s Archive provided the chip giant with access to its pirated books. </p>
<p>“Within a week of contacting Anna’s Archive, and days after being warned by Anna’s Archive of the illegal nature of their collections, NVIDIA management gave ‘the green light’ to proceed with the piracy. Anna’s Archive offered NVIDIA millions of pirated copyrighted books.”</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/green-lght.png.webp 1929w, https://torrentfreak.com/images/green-lght-300x120.png.webp 300w" sizes="auto, (max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/green-lght.png" alt="green light" width="600" height="240" srcset="https://torrentfreak.com/images/green-lght.png 1929w, https://torrentfreak.com/images/green-lght-300x120.png 300w, https://torrentfreak.com/images/green-lght-600x240.png 600w, https://torrentfreak.com/images/green-lght-150x60.png 150w, https://torrentfreak.com/images/green-lght-1536x616.png 1536w" sizes="auto, (max-width: 600px) 100vw, 600px">
</picture>
</center>
<p>The complaint states that Anna’s Archive promised to provide NVIDIA with access to roughly 500 terabytes of data. This included millions of books that are usually only accessible through Internet Archive’s digital lending system, which itself has been <a href="https://torrentfreak.com/internet-archive-loses-landmark-e-book-lending-copyright-appeal-against-publishers-240905/">targeted in court</a>. </p>
<p>The complaint does not explicitly mention whether NVIDIA ended up paying Anna’s Archive for access to the data. </p>
<p>Additionally, it’s worth mentioning that NVIDIA also stands accused of using other pirated sources. In addition to the previously included Books3 database, the new complaint also alleges that the company downloaded books from LibGen, Sci-Hub, and Z-Library.</p>
<h2>Direct and Vicarious Copyright Infringement</h2>
<p>In addition to downloading and using pirated books for its own AI training, the authors allege NVIDIA distributed scripts and tools that allowed its corporate customers to automatically download “<a href="https://en.wikipedia.org/wiki/The_Pile_(dataset)">The Pile</a>“, which contains the Books3 pirated dataset. </p>
<p>These allegations lead to new claims of vicarious and contributory infringement, alleging that NVIDIA generated revenue from customers by facilitating access to these pirated datasets.</p>
<p>Based on these and other claims, the authors request to be compensated for the damages they suffered. This applies to the named authors, but also to potentially hundreds of others who may later join the class action lawsuit. </p>
<p>As far as we know, this is the first time that correspondence between a major U.S. tech company and Anna’s Archive was revealed in public. This will only raise the profile of the pirate library, which just <a href="https://torrentfreak.com/u-s-court-order-against-annas-archive-spells-more-trouble-for-the-site/">lost several domain names</a>, even further. </p>
<p><em>—</em></p><p><em>A copy of the first consolidated and amended complaint, filed at the U.S. District Court for the Northern District of California, is available <a href="https://torrentfreak.com/images/naznvid-amend.pdf">here (pdf)</a>. The named authors include Abdi Nazemian, Brian Keene, Stewart O’Nan, Andre Dubus III, and Susan Orlean.<br>
 </em></p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wikipedia: WikiProject AI Cleanup (215 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup</link>
            <guid>46677106</guid>
            <pubDate>Mon, 19 Jan 2026 10:09:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup">https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup</a>, See on <a href="https://news.ycombinator.com/item?id=46677106">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Trump Links Greenland Threats to Nobel Peace Prize Snub (103 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2026-01-19/trump-links-greenland-threats-to-nobel-peace-prize-snub</link>
            <guid>46676537</guid>
            <pubDate>Mon, 19 Jan 2026 08:58:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2026-01-19/trump-links-greenland-threats-to-nobel-peace-prize-snub">https://www.bloomberg.com/news/articles/2026-01-19/trump-links-greenland-threats-to-nobel-peace-prize-snub</a>, See on <a href="https://news.ycombinator.com/item?id=46676537">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2026-01-19/trump-links-greenland-threats-to-nobel-peace-prize-snub: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Radboud University selects Fairphone as standard smartphone for employees (482 pts)]]></title>
            <link>https://www.ru.nl/en/staff/news/radboud-university-selects-fairphone-as-standard-smartphone-for-employees</link>
            <guid>46676276</guid>
            <pubDate>Mon, 19 Jan 2026 08:23:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ru.nl/en/staff/news/radboud-university-selects-fairphone-as-standard-smartphone-for-employees">https://www.ru.nl/en/staff/news/radboud-university-selects-fairphone-as-standard-smartphone-for-employees</a>, See on <a href="https://news.ycombinator.com/item?id=46676276">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Do you require a (replacement) smartphone for your work at Radboud University? If so, there is a strong possibility that you will receive a Fairphone from 1 February 2026 onwards. Radboud University has decided to choose Fairphone as its standard company smartphone model for reasons of sustainability, cost efficiency and management support.
  </p><div>
            <p>The Fairphone is a sustainable smartphone with easily replaceable parts such as the battery and screen. This makes the device last longer. Fair and recycled materials, such as plastic and aluminium, are used as much as possible in the production of this smartphone. Fairphone also pays attention to good and safe working conditions in its factories.</p><p>Fairphones are issued to employees by the Information &amp; Library Services (ILS) division. In addition to new Fairphones, the university can also reissue used Samsung devices where possible. These are Samsung devices that have already been returned and still meet the technical and age requirements. As long as these devices are still available, not every employee will receive a Fairphone immediately. Employees who have an iPhone from Radboud University can continue to use it as long as the device is still functioning. However, returned iPhones will no longer be reissued.</p><p>Employees who prefer to use their private phone for work can request an RU SIM card for this purpose. The costs for using your own device will not be reimbursed. Naturally, smartphone models that have already been issued will continue to be supported by ILS colleagues, as will privately purchased smartphone models used for work.</p><h2>Cost-effective and easier management</h2><p>Due to its longer lifespan, the total cost of a Fairphone is lower than that of comparable devices. In addition, Radboud University only needs to purchase, manage and support one standard model. This results in smaller stock, easier management and faster support. Manuals and instructions also only need to be maintained for one device.<br>Furthermore, less investment is required in knowledge of different models/brands. This also helps to speed up incident handling and, where necessary, smartphone replacement.</p><h2>Circularity strategy</h2><p>Fairphone offers a five-year warranty and long-term software support for up to eight years. This means that devices need to be replaced less quickly. This fits in with Radboud University's circularity strategy, which focuses on the longest possible use and reuse of ICT hardware.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A decentralized peer-to-peer messaging application that operates over Bluetooth (543 pts)]]></title>
            <link>https://bitchat.free/</link>
            <guid>46675853</guid>
            <pubDate>Mon, 19 Jan 2026 07:14:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bitchat.free/">https://bitchat.free/</a>, See on <a href="https://news.ycombinator.com/item?id=46675853">Hacker News</a></p>
<div id="readability-page-1" class="page">

<pre>##\       ##\   ##\               ##\                  ##\     
## |      \__|  ## |              ## |                 ## |    
#######\  ##\ ######\    #######\ #######\   ######\ ######\   
##  __##\ ## |\_##  _|  ##  _____|##  __##\  \____##\\_##  _|  
## |  ## |## |  ## |    ## /      ## |  ## | ####### | ## |    
## |  ## |## |  ## |##\ ## |      ## |  ## |##  __## | ## |##\ 
#######  |## |  \####  |\#######\ ## |  ## |\####### | \####  |
\_______/ \__|   \____/  \_______|\__|  \__| \_______|  \____/ 
</pre>

<p>
bitchat is a decentralized peer-to-peer messaging application that operates over bluetooth mesh networks.
no internet required, no servers, no phone numbers.
</p>

<p>
traditional messaging apps depend on centralized infrastructure that can be monitored, censored, or disabled.
bitchat creates ad-hoc communication networks using only the devices present in physical proximity.
each device acts as both client and server, automatically discovering peers and relaying messages across multiple hops to extend the network's reach.
</p>

<p>
this approach provides censorship resistance, surveillance resistance, and infrastructure independence.
the network remains functional during internet outages, natural disasters, protests, or in regions with limited connectivity.
</p>

<h2>software</h2>

<p>
<b>ios/macos version:</b><br>
appstore: <a href="https://apps.apple.com/us/app/bitchat-mesh/id6748219622">bitchat mesh</a><br>
source code: <a href="https://github.com/permissionlesstech/bitchat">https://github.com/permissionlesstech/bitchat</a><br>
supports ios 16.0+ and macos 13.0+. build using xcode with xcodegen or swift package manager.
</p>

<p>
<b>android version:</b><br>
play store: <a href="https://play.google.com/store/apps/details?id=com.bitchat.droid">bitchat</a><br>
source code: <a href="https://github.com/permissionlesstech/bitchat-android">https://github.com/permissionlesstech/bitchat-android</a><br>
apk releases: <a href="https://github.com/permissionlesstech/bitchat-android/releases">https://github.com/permissionlesstech/bitchat-android/releases</a><br>
supports android 8.0+ (api 26). full protocol compatibility with ios version.
</p>

<h2>documentation</h2>

<p>
technical whitepaper: <a href="https://github.com/permissionlesstech/bitchat/blob/main/WHITEPAPER.md">whitepaper.md</a>
</p>

<p>
the software is released into the public domain.
</p>

<hr>
<small>permissionlesstech · <a href="https://bitchat.free/contact.html">contact</a></small>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Pdfwithlove – PDF tools that run 100% locally (no uploads, no back end) (170 pts)]]></title>
            <link>https://pdfwithlove.netlify.app</link>
            <guid>46675231</guid>
            <pubDate>Mon, 19 Jan 2026 05:04:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pdfwithlove.netlify.app">https://pdfwithlove.netlify.app</a>, See on <a href="https://news.ycombinator.com/item?id=46675231">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[San Francisco coyote swims to Alcatraz (107 pts)]]></title>
            <link>https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php</link>
            <guid>46674433</guid>
            <pubDate>Mon, 19 Jan 2026 02:29:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php">https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php</a>, See on <a href="https://news.ycombinator.com/item?id=46674433">Hacker News</a></p>
Couldn't get https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php: Error: Request failed with status code 402]]></description>
        </item>
        <item>
            <title><![CDATA[The Code-Only Agent (147 pts)]]></title>
            <link>https://rijnard.com/blog/the-code-only-agent</link>
            <guid>46674416</guid>
            <pubDate>Mon, 19 Jan 2026 02:27:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rijnard.com/blog/the-code-only-agent">https://rijnard.com/blog/the-code-only-agent</a>, See on <a href="https://news.ycombinator.com/item?id=46674416">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          
          <p>
            When Code Execution Really is All You Need
          </p>

          <p>
            <img src="https://rijnard.com/assets/code-only.svg" alt="Code-Only Agent">
          </p>

          <p>
            If you're building an agent, you're probably overwhelmed. Tools.
            MCP. Subagents. Skills. The ecosystem pushes you toward complexity,
            toward "the right way" to do things. You should know: Concepts like
            "Skills" and "MCP" are actually outcomes of an
            <i>ongoing learning process</i> of humans figuring stuff out. The
            space is <i>wide open</i> for exploration. With this mindset I
            wanted to try something different. Simplify the assumptions.
          </p>

          <p>
            What if the agent only had
            <b><i><code>one tool</code></i></b>? Not just any tool, but the most powerful one. The
            <b><code>Turing-complete</code></b> one: <b><i>execute code</i></b>.
          </p>

          <p>
            Truly one tool means: no `bash`, no `ls`, no `grep`. Only
            <b><code>execute_code</code></b>. And you <i>enforce</i> it.
          </p>

          <p>
            When you watch an agent run, you might think: "I wonder what tools
            it'll use to figure this out. Oh look, it ran `ls`. That makes
            sense. Next, `grep`. Cool."
          </p>
          <p>
            The simpler Code-Only paradigm makes that question irrelevant. The
            question shifts from "what tools?" to "what code will it produce?"
            And that's when things get interesting.
          </p>

					<h2><span><code>execute_code</code></span>: One Tool to Rule Them All</h2>

          <p>Traditional prompting works like this:</p>

          <p>
            &gt; Agent, do <b><i>thing</i></b>
            <br>
            &gt; Agent
            <span><b><i>responds</i></b></span>
            with <b><i>thing</i></b>
          </p>

          <p>Contrast with:</p>

          <p>
            &gt; Agent, do <b><i>thing</i></b>
            <br>
            &gt; Agent
            <span><b><i>creates and runs code</i></b></span>
            to do <b><i>thing</i></b>
          </p>

          <p>
            It does this every time. No, really,
            <b><i><code>every</code></i></b>
            time. Pick a runtime for our Code-Only agent, say Python. It needs
            to find a file? It writes Python code to find the file and executes
            the code. Maybe it runs <b><i>rglob</i></b>. Maybe it does <b><i>os.walk</i></b>.
          </p>

          <p>
            It needs to create a script that crawls a website? It doesn't write
            the script to your filesystem (reminder: there's no
            <b><i>create_file</i></b> tool to do that!). It
            <b><i>writes code to output a script that crawls a website</i></b>.<sup><a href="#fn1">1</a></sup>
          </p>

          <p>
            We make it so that there is literally no way for the agent to
            <i><b>do</b></i> anything productive without
            <b><i>writing code</i></b>.
          </p>

          <p>
            So what? Why do this? You're probably thinking, how is this useful?
            Just give it `bash` tool already man.
          </p>

          <p>
            Let's think a bit more deeply what's happening. Traditional agents
            respond with something. Tell it to find some DNA pattern across 100
            files. It might `ls` and `grep`, it might do that in some
            nondeterministic order, it'll figure out <i><b>an answer</b></i> and
            maybe you continue interacting because it missed a directory or you
            added more files. After some time, you end up with a conversation of
            tool calls, responses, and an answer.
          </p>

          <p>
            At some point the agent might even write a Python script to do this
            DNA pattern finding. That would be a lucky happy path, because we
            could rerun that script or update it later... Wait, that's handy...
            actually, more than handy... isn't that
            <code><b><i>ideal</i></b></code>? Wouldn't it be better if we told it to write a script at the
            start? You see, the Code-Only agent doesn't need to be told to write
            a script. It
            <code><b><i>has</i></b></code>
            to, because that's literally the only way for it to do anything of
            substance.
          </p>

          <p>
            The Code-Only agent produces something more precise than an answer
            in natural language. It produces a code <b><i>witness</i></b> of an
            answer. The answer is the output from running the code. The agent
            can interpret that output in natural language (or by writing code),
            but the "work" is codified in a very literal sense. The Code-Only
            agent doesn't respond with something. It produces a code witness
            that outputs something.
          </p>

          <p>
           <span>Try ❯❯ <a href="https://github.com/rvantonder/execute_code_py">Code-Only plugin for Claude Code</a>
            </span>
          </p>

          <h2>Code witnesses are semantic guarantees</h2>

          <p>
            Let's follow the consequences. The code witness must abide by
            certain rules: The rules imposed by the language runtime semantics
            (e.g., of Python). That's not a "next token" process. That's not a
            "LLM figures out sequence of tool calls, no that's not what I
            wanted". It's piece of code. A piece of code! Our one-tool agent has
            a wonderful property: It went through latent space to produce
            something that has a defined semantics, repeatably runnable, and
            imminently comprehensible (for humans or agents alike to reason
            about). This is nondeterministic LLM token-generation projected into
            the space of Turing-complete code, an executable description of
            behavior as we best understand it.
          </p>

          <p>
            Is a Code-Only agent really enough, or too extreme? I'll be frank: I
            pursued this extreme after two things (1) inspiration from articles in <a href="#further-reading">Further Reading</a> below (2) being annoyed at agents for not comprehensively and
            exhaustively analyzing 1000s of files on my laptop. They would skip,
            take shortcuts, hallucinate. I knew how to solve part of that
            problem: create a
            <b><i><code>programmatic</code></i></b>
            loop and try have fresh instances/prompts to do the work
            comprehensively. I can rely on the semantics of a loop written in
            Python. Take this idea further, and you realize that for anything
            long-running and computable (e.g., bash or some tool), you actually
            want the real McCoy: the full witness of code, a trace of why things
            work or don't work. The Code-Only agent
            <code><i><b>enforces</b></i></code>
            that principle.
          </p>

          <p>
            Code-Only agents are not too extreme. I think they're the only way
            forward for computable things. If you're writing travel blog posts,
            you accept the LLMs answer (and you don't need to run tools for
            that). When something is computable though, Code-Only is the only
            path to a
            <b><i><code>fully trustworthy</code></i></b>
            way to make progress where you need guarantees (subject to
            the semantics that your language of choice guarantees, of course). When I say
            guarantees, I mean that in the looser sense, and also in a
            <u><a href="https://en.wikipedia.org/wiki/Formal_verification">Formal</a></u>
            sense. Which beckons: What happens when we use a language like
            <u><a href="https://lean-lang.org/">Lean</a></u> with some of the
            strongest guarantees? Did we not observe that
            <u><a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">programs are proofs</a></u>?
          </p>

          <p>
            This lens says the Code-Only agent is a producer of proofs,
            witnesses of computational behavior in the world of
            proofs-as-programs. An LLM in a loop forced to produce proofs, run
            proofs, interpret proof results. That's all.
          </p>

          <h2>Going Code-Only</h2>

          <p>
            So you want to go Code-Only. What happens? The paradigm is simple,
            but the design choices are surprising.
          </p>

          <p>
            First, the harness. The LLM's output is code, and you execute that
            code. What should be communicated back? Exit code makes sense. What
            about output? What if the output is very large? Since you're running
            code, you can specify the result type that running the code should
            return.
          </p>

          <p>
            I've personally, e.g., had the tool return results directly if under
            a certain threshold (1K bytes). This would go into the session context.
						Alternatively, write the results to a JSON
            file on disk if it exceeds the threshold. This avoids context blowup and the result tells the
            agent about the output file path written to disk. How best to pass
            results, persist them, and optimize for size and context fill are
            open questions. You also want to define a way to deal with `stdout`
            and `stderr`: Do you expose these to the agent? Do you summarize
            before exposing?
          </p>

          <p>
            Next, enforcement. Let's say you're using Claude Code. It's not
            enough to persuade it to always create and run code. It turns out
            it's surprisingly twisty to force Claude Code into a single tool
            (maybe support for this will improve). The best plugin-based
            solution I found is a tool PreHook that catches banned tool uses.
            This wastes some iterations when Claude Code tries to use a tool
            that's not allowed, but it learns to stop attempting filesystem
            reads/writes. An initial prompt helps direct.
          </p>

          <p>
            Next, the language runtime. Python, TypeScript, Rust, Bash. Any
            language capable of being executed is fair game, but you'll need to
            think through whether it works for your domain. Dynamic languages
            like Python are interesting because you can run code natively in the
            agent's own runtime, rather than through subprocess calls. Likewise
            TypeScript/JS can be injected into TypeScript-based agents (see
            <a href="#further-reading">Further Reading</a>).
          </p>

          <p>
            Once you get into the Code-Only mindset, you'll see the potential
            for composition and reuse. Claude Skills define reusable processes
            in natural language. What's the equivalent for a Code-Only agent?
            I'm not sure a Skills equivalent exists yet, but I anticipate it
            will take shape soon: code as building blocks for specific domains
            where Code-Only agents compose programmatic patterns. How is that
            different from calling APIs? APIs form part of the reusable blocks,
            but their composition (loops, parallelism, asynchrony) is what a
            Code-Only agent generates.
          </p>

          <p>
            What about heterogeneous languages and runtimes for our `execute_tool`? I don't think we've thought that far yet.
          </p>

          <h2 id="further-reading">Further Reading</h2>

          <p>
            The agent landscape is quickly evolving. My thoughts on how the
            Code-Only paradigm fits into inspiring articles and trends, from
            most recent and going back:
          </p>

          <ul>
            <li>
              <u><b><a href="https://prose.md/">prose.md</a></b></u>
              (Jan 2026) — Code-Only reduces prompts to executable code (with
              loops and statement sequences). Prose expands prompts into natural
              language with program-like constructs (also loops, sequences,
              parallelism). The interplay of natural language for agent
              orchestration and rigid semantics for agent execution could be
              extremely powerful.
            </li>
            <li>
              <u><b><a href="https://steve-yegge.medium.com/welcome-to-gas-town-4f25ee16dd04">Welcome to Gas Town</a></b></u>
              (Jan 2026) — Agent orchestration gone berserk. Tool running is the low-level
              operation at the bottom of the agent stack. Code-Only fits as the
              primitive: no matter how many agents you orchestrate, each one
              reduces to generating and executing code.
            </li>
            <li>
              <u><b><a href="https://www.anthropic.com/engineering/code-execution-with-mcp">Anthropic Code Execution with MCP article</a></b></u>
              (Nov 2025) — MCP-centric view of exposing MCP servers as code API
              and not tool calls. Code-Only is simpler and more general. It
              doesn't care about MCP, and casting the MCP interface as an API is
              a mechanical necessity that acknowledges the power of going
              Code-Only.
            </li>
            <li>
              <u><b><a href="https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills">Anthropic Agent Skills article</a></b></u>
              (Oct 2025) — Skills embody reusable processes framed in natural
              language. They can generate and run code, but that's not their
              only purpose. Code-Only is narrower (but computationally
              all-powerful): the reusable unit is always executable. The analog
              to Skills manifests as pluggable executable pieces: functions,
              loops, composable routines over APIs.
            </li>
            <li>
              <u><b><a href="https://blog.cloudflare.com/code-mode/">Cloudflare Code Mode article</a></b></u>
              (Sep 2025) — Possibly the earliest concrete single-code-tool
              implementation. Code Mode converts MCP tools into a TypeScript API
              and gives the agent one tool: execute TypeScript. Their insight is
              pragmatic: LLMs write better code than tool calls because of
              training data. In its most general sense, going Code-Only doesn't
              need to rely on MCP or APIs, and encapsulates all code execution
              concerns.
            </li>
            <li>
              <u><b><a href="https://ghuntley.com/ralph/">Ralph Wiggum as a "software engineer"</a></b></u>
              (Jul 2025) — A programmatic loop over agents (agent
              orchestration). Huntley describes it as "deterministically bad in
              a nondeterministic world". Code-Only inverts this a bit:
              projection of a nondeterministic model into deterministic
              execution. Agent orchestration on top of an agent's Code-Only
              inner-loop could be a powerful combination.
            </li>
            <li>
              <u><b><a href="https://lucumr.pocoo.org/2025/7/3/tools/">Tools: Code is All You Need</a></b></u>
              (Jul 2025) — Raises code as a first-order concern for agents.
              Ronacher's observation: asking an LLM to write a script to
              transform markdown makes it possible to reason about and trust the
              process. The script is reviewable, repeatable, composable.
              Code-Only takes this further where every action becomes a script
              you can reason about.
            </li>
            <li>
              <u><b><a href="https://ampcode.com/how-to-build-an-agent">How to Build an Agent</a></b></u>
              (Apr 2025) — The cleanest way to achieve a Code-Only agent today
              may be to build it from scratch. Tweaking current agents like
              Claude Code to enforce a single tool means friction. Thorsten's
              article is a lucid account for building an agent loop with tool
              calls. If you want to enforce Code-Only, this makes it easy to do
              it yourself.
            </li>
          </ul>

          <h2>What's Next</h2>

          <p>
            Two directions feel inevitable. First, agent orchestration. Tools
            like <u><a href="https://prose.md/">prose.md</a></u> let you compose
            agents in natural language with program-like constructs. What
            happens when those agents are Code-Only in their inner loop? You get
            natural language for coordination, rigid semantics for execution.
            The best of both.
          </p>

          <p>
            Second, hybrid tooling. Skills work well for processes that live in
            natural language. Code-Only works well for processes that need
            guarantees. We'll see agents that fluidly mix both: Skills for
            orchestration and intent, Code-Only for computation and precision.
            The line between "prompting an agent" and "programming an agent"
            will blur until it disappears.
          </p>

          <p>
            <span>Try ❯❯ <a href="https://github.com/rvantonder/execute_code_py">Code-Only plugin for Claude Code</a>
            </span>
          </p>

          <hr>
          <p id="fn1">
            <sup>1</sup>There is something beautifully
            <a href="https://en.wikipedia.org/wiki/Quine_(computing)">quine-like</a>
            about this agent. I've always
            <a href="https://github.com/rvantonder/pentaquine">loved quines</a>.
          </p>
					<small>
									<span>Timestamped</span> <i></i> 9 Jan 2026
          </small>
   				<br>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I quit coding years ago. AI brought me back (292 pts)]]></title>
            <link>https://calquio.com/finance/compound-interest</link>
            <guid>46673809</guid>
            <pubDate>Mon, 19 Jan 2026 00:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://calquio.com/finance/compound-interest">https://calquio.com/finance/compound-interest</a>, See on <a href="https://news.ycombinator.com/item?id=46673809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><header><p>Calculate how your investments grow over time with compound interest.</p></header><div aria-label="Calculator"><div><p><span>Contributed</span><span>$10,000</span></p><p><span>Interest</span><span>+$63,281</span></p><p><span>Return</span><span>632.81%</span></p></div><div data-slot="card"><div><p>1</p><h3>How much are you investing?</h3></div><div><p>2</p><h3>What return do you expect?</h3></div><div><p>3</p><h3>How long will you invest?</h3></div></div><div data-slot="card" data-radix-scroll-area-viewport="" dir="ltr"><table data-slot="table"><thead data-slot="table-header"><tr data-slot="table-row"><th data-slot="table-head">Year</th><th data-slot="table-head">Start Balance</th><th data-slot="table-head">Interest</th><th data-slot="table-head">Contributions</th><th data-slot="table-head">End Balance</th></tr></thead><tbody data-slot="table-body"><tr data-slot="table-row"><td data-slot="table-cell">1</td><td data-slot="table-cell">$10,000</td><td data-slot="table-cell">+<!-- -->$1,047</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$11,047</td></tr><tr data-slot="table-row"><td data-slot="table-cell">2</td><td data-slot="table-cell">$11,047</td><td data-slot="table-cell">+<!-- -->$1,157</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$12,204</td></tr><tr data-slot="table-row"><td data-slot="table-cell">3</td><td data-slot="table-cell">$12,204</td><td data-slot="table-cell">+<!-- -->$1,278</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$13,482</td></tr><tr data-slot="table-row"><td data-slot="table-cell">4</td><td data-slot="table-cell">$13,482</td><td data-slot="table-cell">+<!-- -->$1,412</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$14,894</td></tr><tr data-slot="table-row"><td data-slot="table-cell">5</td><td data-slot="table-cell">$14,894</td><td data-slot="table-cell">+<!-- -->$1,560</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$16,453</td></tr><tr data-slot="table-row"><td data-slot="table-cell">6</td><td data-slot="table-cell">$16,453</td><td data-slot="table-cell">+<!-- -->$1,723</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$18,176</td></tr><tr data-slot="table-row"><td data-slot="table-cell">7</td><td data-slot="table-cell">$18,176</td><td data-slot="table-cell">+<!-- -->$1,903</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$20,079</td></tr><tr data-slot="table-row"><td data-slot="table-cell">8</td><td data-slot="table-cell">$20,079</td><td data-slot="table-cell">+<!-- -->$2,103</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$22,182</td></tr><tr data-slot="table-row"><td data-slot="table-cell">9</td><td data-slot="table-cell">$22,182</td><td data-slot="table-cell">+<!-- -->$2,323</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$24,504</td></tr><tr data-slot="table-row"><td data-slot="table-cell">10</td><td data-slot="table-cell">$24,504</td><td data-slot="table-cell">+<!-- -->$2,566</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$27,070</td></tr><tr data-slot="table-row"><td data-slot="table-cell">11</td><td data-slot="table-cell">$27,070</td><td data-slot="table-cell">+<!-- -->$2,835</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$29,905</td></tr><tr data-slot="table-row"><td data-slot="table-cell">12</td><td data-slot="table-cell">$29,905</td><td data-slot="table-cell">+<!-- -->$3,131</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$33,036</td></tr><tr data-slot="table-row"><td data-slot="table-cell">13</td><td data-slot="table-cell">$33,036</td><td data-slot="table-cell">+<!-- -->$3,459</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$36,496</td></tr><tr data-slot="table-row"><td data-slot="table-cell">14</td><td data-slot="table-cell">$36,496</td><td data-slot="table-cell">+<!-- -->$3,822</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$40,317</td></tr><tr data-slot="table-row"><td data-slot="table-cell">15</td><td data-slot="table-cell">$40,317</td><td data-slot="table-cell">+<!-- -->$4,222</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$44,539</td></tr><tr data-slot="table-row"><td data-slot="table-cell">16</td><td data-slot="table-cell">$44,539</td><td data-slot="table-cell">+<!-- -->$4,664</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$49,203</td></tr><tr data-slot="table-row"><td data-slot="table-cell">17</td><td data-slot="table-cell">$49,203</td><td data-slot="table-cell">+<!-- -->$5,152</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$54,355</td></tr><tr data-slot="table-row"><td data-slot="table-cell">18</td><td data-slot="table-cell">$54,355</td><td data-slot="table-cell">+<!-- -->$5,692</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$60,047</td></tr><tr data-slot="table-row"><td data-slot="table-cell">19</td><td data-slot="table-cell">$60,047</td><td data-slot="table-cell">+<!-- -->$6,288</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$66,335</td></tr><tr data-slot="table-row"><td data-slot="table-cell">20</td><td data-slot="table-cell">$66,335</td><td data-slot="table-cell">+<!-- -->$6,946</td><td data-slot="table-cell">-</td><td data-slot="table-cell">$73,281</td></tr></tbody></table></div></div><section><h2>You May Also Like</h2><p><a href="https://calquio.com/finance/daily-compound-interest"><span>Daily Compound Interest</span></a><a href="https://calquio.com/finance/apy-calculator"><span>APY Calculator</span></a><a href="https://calquio.com/finance/future-value"><span>Future Value</span></a><a href="https://calquio.com/finance/savings-goal"><span>Savings Goal</span></a></p></section><section aria-label="Educational Content"><h2 id="what-is-compound-interest">What is Compound Interest?</h2>
<p>Compound interest is <strong>interest calculated on both the initial principal and the accumulated interest</strong> from previous periods. Unlike simple interest, which only earns interest on the original amount, compound interest allows your money to grow exponentially over time.</p>
<p>Albert Einstein reportedly called compound interest "the eighth wonder of the world," saying: <em>"He who understands it, earns it; he who doesn't, pays it."</em></p>
<h2 id="formula">The Compound Interest Formula</h2>
<p>The basic formula for compound interest is:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>P</mi><msup><mrow><mo fence="true">(</mo><mn>1</mn><mo>+</mo><mfrac><mi>r</mi><mi>n</mi></mfrac><mo fence="true">)</mo></mrow><mrow><mi>n</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A = P \left(1 + \frac{r}{n}\right)^{nt}</annotation></semantics></math></span></span></span></p>
<p>Where:</p>
<ul>
<li><strong>A</strong> = Final amount (principal + interest)</li>
<li><strong>P</strong> = Principal (initial investment)</li>
<li><strong>r</strong> = Annual interest rate (as a decimal)</li>
<li><strong>n</strong> = Number of times interest compounds per year</li>
<li><strong>t</strong> = Time in years</li>
</ul>
<p>For continuous compounding, the formula becomes:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>P</mi><msup><mi>e</mi><mrow><mi>r</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A = Pe^{rt}</annotation></semantics></math></span></span></span></p>
<h2 id="rule-of-72">The Rule of 72</h2>
<p>A quick mental math trick to estimate how long it takes to double your money:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Years&nbsp;to&nbsp;double</mtext><mo>=</mo><mfrac><mn>72</mn><mtext>Interest&nbsp;Rate</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text{Years to double} = \frac{72}{\text{Interest Rate}}</annotation></semantics></math></span></span></span></p>
<p>For example:</p>
<ul>
<li>At <strong>6%</strong> interest: 72 ÷ 6 = <strong>12 years</strong> to double</li>
<li>At <strong>8%</strong> interest: 72 ÷ 8 = <strong>9 years</strong> to double</li>
<li>At <strong>12%</strong> interest: 72 ÷ 12 = <strong>6 years</strong> to double</li>
</ul>
<div><p>The Rule of 72 is a quick approximation. For more precise calculations, use the formula above or our calculator!</p></div>
<h2 id="compound-frequency">Why Compound Frequency Matters</h2>
<p>The more frequently interest compounds, the more you earn. Think of it as: <strong>how often the bank calculates and adds interest to your balance</strong>.</p>
<ul>
<li><strong>Annual compounding</strong>: Interest added once per year</li>
<li><strong>Monthly compounding</strong>: Interest added 12 times per year</li>
<li><strong>Daily compounding</strong>: Interest added 365 times per year</li>
<li><strong>Continuous compounding</strong>: Interest added infinitely (theoretical maximum)</li>
</ul>
<p>At a 10% annual rate on $10,000 over 10 years:</p>
<ul>
<li>Annual compounding: $25,937</li>
<li>Monthly compounding: $27,070</li>
<li>Daily compounding: $27,179</li>
<li>Continuous compounding: $27,183</li>
</ul>
<h2 id="tips">Tips for Maximizing Compound Interest</h2>
<ol>
<li><strong>Start early</strong> – Time is your greatest ally. Even small amounts grow significantly over decades.</li>
<li><strong>Be consistent</strong> – Regular contributions amplify the effect of compounding.</li>
<li><strong>Reinvest returns</strong> – Don't withdraw interest; let it compound.</li>
<li><strong>Seek higher rates</strong> – Even a 1% difference compounds to significant amounts over time.</li>
<li><strong>Minimize fees</strong> – High fees erode your compounding gains.</li>
</ol></section></div></article><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[High-speed train collision in Spain kills at least 21 (251 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cedw6ylpynyo</link>
            <guid>46673453</guid>
            <pubDate>Sun, 18 Jan 2026 23:54:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cedw6ylpynyo">https://www.bbc.com/news/articles/cedw6ylpynyo</a>, See on <a href="https://news.ycombinator.com/item?id=46673453">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline" data-component="byline-block"><p><span data-testid="byline-contributors"><p><span>Harry Sekulich<!-- -->,</span><span data-testid="byline-contributors-contributor-0-role-location">BBC News<!-- -->,</span></p><p><span>Guy Hedgecoe<!-- -->,</span><span data-testid="byline-contributors-contributor-1-role-location">Madrid</span><span>and</span></p><p><span>Rachel Hagan<!-- -->,</span><span data-testid="byline-contributors-contributor-2-role-location">BBC News</span></p></span></p></div><p data-component="caption-block"><figcaption>Footage shows emergency workers at scene of derailment</figcaption></p><div data-component="text-block"><p>At least 39 people have died in a train collision in southern Spain and dozens more have been injured in the country's worst rail crash in more than a decade, Spain's Civil Guard has said.</p><p>Carriages on a Madrid-bound train derailed and crossed over to the opposite tracks, colliding with an oncoming train in Adamuz on Sunday evening.</p><p>Four hundred passengers and staff were onboard both trains, the rail networks said. Emergency services treated 122 people, with 48, including five children, still in hospital. Of those, 11 adults and one child are in intensive care.</p><p>Spanish Transport Minister Óscar Puente said the death toll "is not yet final", as officials launched an investigation.</p></div><div data-component="text-block"><p>Puente described the incident as "extremely strange". All the railway experts consulted by the government "are extremely baffled by the accident", he told reporters in Madrid.</p><p>Rail network operator Adif said the collision happened at 19:45 local time (18:45 GMT), about an hour after the train left Málaga heading north<b id=""> </b>to Madrid, when it derailed on a straight stretch of track near the city of Córdoba.</p><p>The force of the crash pushed the carriages of the second train into an embankment, Puente said. He added that most of those killed and injured were in the front carriages of the second train, which was travelling south<b id=""> </b>from Madrid to Huelva.</p><p>The type of train involved in the crash was a Freccia 1000, which can reach top speeds of 400 km/h (250 mph), a spokesperson for the Italian rail company Ferrovie dello Stato told Reuters news agency.</p><p>Rescue teams said the twisted wreckage of the trains made it difficult to recover people trapped inside the carriages.</p><p>Córdoba fire chief Francisco Carmona told Spanish public broadcaster RTVE: "We have even had to remove a dead person to be able to reach someone alive. It is hard, tricky work."</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/5490/live/430d8b10-f4be-11f0-a422-4ba8a094a8fa.png.webp" loading="eager" alt="A map of Spain highlighting a section of the country’s high‑speed rail network. A blue line marks the high‑speed rail route running between Madrid in central Spain and Málaga in the south. A red dot marks Adamuz in the province of Córdoba near the midpoint of the route, where the two trains collided. 
"></p></div></figure><div data-component="text-block"><p>Salvador Jimenez, a journalist with RTVE who was on one of the trains, said the impact felt like an "earthquake". </p><p>"I was in the first carriage. There was a moment when it felt like an earthquake and the train had indeed derailed," Jimenez said.</p><p>Footage from the scene appears to show some train carriages had tipped over on their sides. Rescue workers can be seen scaling the train to pull people out of the lopsided train doors and windows.</p><p>A Madrid-bound passenger, José, told public broadcaster Canal Sur: "There were people and screaming, calling for doctors."</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/3010/live/e418d220-f4e7-11f0-a422-4ba8a094a8fa.jpg.webp" loading="lazy" alt="Reuters A person affected by a deadly train derailment is transferred for treatment to the Caseta Municipal in the town of Adamuz, after a high-speed train derailed."><span>Reuters</span></p></div><p data-component="caption-block"><figcaption>Passengers were taken to hospital and advanced medical posts near the site of the crash</figcaption></p></figure><div data-component="text-block"><p>All rail services between Madrid and Andalusia were suspended following the accident and are expected to remain closed all day on Monday.</p><p>Iryo, a private rail company that operated the journey from Málaga, said around 300 passengers were on board the train that first derailed, while the other train – operated by the state-funded firm Renfe – had around 100 passengers.</p><p>The official cause is not yet known. An investigation is not expected to determine what happened for at least a month, according to the transport minister. </p><p>Spain's Prime Minister, Pedro Sánchez, said the country will endure a "night of deep pain". </p><p>The mayor of Adamuz, Rafael Moreno, was one of the first people on the scene of the accident, describing it as "a nightmare".</p><p>King Felipe VI and Queen Letizia said they were following news of the disaster "with great concern".</p><p>"We extend our most heartfelt condolences to the relatives and loved ones of the dead, as well as our love and wishes for a swift recovery to the injured," the royal palace said on X.</p><p>The emergency agency in the region of Andalusia urged any crash survivors to contact their families or post on social media that they are alive.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/5ff9/live/d20c4730-f4ea-11f0-a422-4ba8a094a8fa.jpg.webp" loading="lazy" alt="EPA A woman is consoled by a woman wearing a fluorescent official jacket at the terminal of a train station"><span>EPA</span></p></div><p data-component="caption-block"><figcaption>Friends and relatives have been seeking information about their loved ones on board either train.</figcaption></p></figure><div data-component="text-block"><p>Advanced medical posts were set up for impacted passengers to be treated for injuries and transferred to hospital. Adif said it set up spaces for relatives of the victims at Atocha, Seville, Córdoba, Málaga and Huelva stations. </p><p>The Spanish Red Cross has deployed emergency support services to the scene, while also offering counselling to families nearby.</p><p>Miguel Ángel Rodríguez from the Red Cross told RNE radio: "The families are going through a situation of great anxiety due to the lack of information. These are very distressing moments."</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/c2ec/live/ab593da0-f4d1-11f0-b5f7-49f0357294ff.jpg.webp" loading="lazy" alt="Reuters A patient in a hospital stretcher and dozens of others are draped in blankets, given water, and helped by medical workers at the Caseta Municipal."><span>Reuters</span></p></div><p data-component="caption-block"><figcaption>The foyer of the hospital close to the crash site, Caseta Municipal in Adamuz, filled with affected passengers.</figcaption></p></figure><div data-component="text-block"><p>French President Emmanuel Macron, Italian Prime Minister Giorgia Meloni and European Commission chief Ursula von der Leyen have published statements offering condolences. </p><p>"My thoughts are with the victims, their families and the entire Spanish people. France stands by your side," Macron wrote on social media.</p><p>In 2013, Spain suffered its worst high-speed train derailment in Galicia, north-west Spain, which left 80 people dead and 140 others injured. </p><p>Spain's high-speed rail network is the second largest in the world, behind China, connecting more than 50 cities across the country. Adif data shows the Spanish rail is more than 4,000km long (2,485 miles)<b id=".">.</b></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/c4f5/live/f98172d0-f504-11f0-b385-5f48925de19a.png.webp" loading="lazy" alt="A thin, grey banner promoting the News Daily newsletter. On the right, there is a graphic of an orange sphere with two concentric crescent shapes around it in a red-orange gradient, like a sound wave. The banner reads: &quot;The latest news in your inbox first thing.”
"></p></div></figure><p>Get our flagship newsletter with all the headlines you need to start the day. <a target="_self" href="https://www.bbc.co.uk/newsletters/zhp28xs">Sign up here.</a></p></article></div>]]></description>
        </item>
    </channel>
</rss>