<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 11 May 2024 17:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Why the CORDIC algorithm lives rent-free in my head (175 pts)]]></title>
            <link>https://github.com/francisrstokes/githublog/blob/main/2024/5/10/cordic.md</link>
            <guid>40326563</guid>
            <pubDate>Sat, 11 May 2024 07:18:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/francisrstokes/githublog/blob/main/2024/5/10/cordic.md">https://github.com/francisrstokes/githublog/blob/main/2024/5/10/cordic.md</a>, See on <a href="https://news.ycombinator.com/item?id=40326563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Why the CORDIC algorithm lives rent-free in my head</h2><a id="user-content-why-the-cordic-algorithm-lives-rent-free-in-my-head" aria-label="Permalink: Why the CORDIC algorithm lives rent-free in my head" href="#why-the-cordic-algorithm-lives-rent-free-in-my-head"></a></p>
<p dir="auto"><em>This post is an adaptation of a <a href="https://twitter.com/fstokesman/status/1787949934123049021" rel="nofollow">twitter thread</a> I put together a few days ago.</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/cordic.gif"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/cordic.gif" data-animated-image=""></a></p>
<p dir="auto">CORDIC is an algorithm for computing trig functions like <code>sin</code>, <code>cos</code>, <code>tan</code> etc on low powered hardware, without an FPU (i.e. no floating point) or expensive lookup tables. In fact, it reduces these complex functions to simple additions and bit shifts.</p>
<p dir="auto">I'll cut right to the chase and tell you <em>why</em> I love this algorithm so much, and then we'll dive into the details of exactly how it works. Essentially, the actual operations of the algorithm are incredibly simple - just shifts and adds, as I mentioned before - but it does this by combining vector math, trigonometry, convergence proofs, and some clever computer science. To me, it's what people are talking about when they describe things of this nature as "elegant".</p>
<p dir="auto">Let's start with an obvious point: You don't need this if you're working on high powered hardware. This technique is applicable for embedded environments; especially less capable microcontrollers and FPGAs. Even then, it's possible that more capable hardware/peripherals will be available which would be "faster", though speed is not the only measure of usefulness.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Avoiding floating point</h2><a id="user-content-avoiding-floating-point" aria-label="Permalink: Avoiding floating point" href="#avoiding-floating-point"></a></p>
<p dir="auto"><em>(if you're already familiar with fixed-point, you can safely skip this section)</em></p>
<p dir="auto">You might be wondering how are we able to avoid floating point, when functions like <code>sin(x)</code> produce values between -1.0 and 1.0? Well, floating point is not the only way of representing rational numbers. In fact, before IEEE 754 became the popular standard that it is today, <em>fixed point</em> was used all the time (go and ask any gamedev who worked on stuff between 1980 and 2000ish and they'll tell you all about it).</p>
<p dir="auto">In fact, I got nerd-sniped into this whole CORDIC investigation after listening to <a href="https://twitter.com/MicroarchClub/status/1759606520713453630" rel="nofollow">Dan Mangum's fantastic Microarch Club podcast</a>, where Philip Freidin dropped the spicy hot-take that "Floating point is a crutch", and that using it might be a sign that you don't <em>really</em> understand the algorithm you're working on. Of course I should mention this was more in the context of custom ASICs rather than your run-of-the-mill webapp, but the quote really stuck with me.</p>
<p dir="auto">So how does fixed point work? Well you take an integer type like <code>int32_t</code>, and say the top 16 bits are the whole part of the number, and the bottom 16 bits are the fractional part. You could divide the number up differently (e.g. 10 bits for the whole part and 24 for the fractional), but we'll use 16/16 as an example here.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/fixed-whole-fractional.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/fixed-whole-fractional.png"></a></p>
<p dir="auto">That gives a range of around <code>-32768.99997</code> to <code>32767.99997</code>. We've <em>fixed</em> the radix point at the 16th bit, though again, we could have put it anywhere. Moving the point allows us to trade off for precision where it makes sense (i.e. more bits for whole numbers, or more bits for fractional representation).</p>
<p dir="auto">Something worth noting here is that the number is still an <code>int32_t</code> - we the programmers have assigned the extra meaning here (though this is also true of literally every data type in computing - there are only bits in the end!).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/fixed-point.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/fixed-point.png"></a></p>
<p dir="auto">How do we get a number into this format? Well, we've got 16 bits of fractional precision, so take a float like&nbsp;<code>42.01</code>, and scale it up by <code>(1 &lt;&lt; 16)</code>. That gives us <code>2753167</code> when cast into an <code>int32_t</code>. If we want to go from fixed point back to floating point, we just do the opposite. <code>2753167 / (1 &lt;&lt; 16)</code> gives us <code>~42.0099945</code>, which is very close to <code>42.01</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#define SCALING_FACTOR (16)

static inline int32_t fixed_from_float(float a) {
  return (int32_t)(a * (float)(1 << SCALING_FACTOR));
}

static inline float fixed_to_float(int32_t a) {
  return (float)a / (float)(1 << SCALING_FACTOR);
}"><pre><span>#define</span> <span>SCALING_FACTOR</span> (16)

<span>static</span> <span>inline</span> <span>int32_t</span> <span>fixed_from_float</span>(<span>float</span> <span>a</span>) {
  <span>return</span> (<span>int32_t</span>)(<span>a</span> <span>*</span> (<span>float</span>)(<span>1</span> &lt;&lt; <span>SCALING_FACTOR</span>));
}

<span>static</span> <span>inline</span> <span>float</span> <span>fixed_to_float</span>(<span>int32_t</span> <span>a</span>) {
  <span>return</span> (<span>float</span>)<span>a</span> / (<span>float</span>)(<span>1</span> &lt;&lt; <span>SCALING_FACTOR</span>);
}</pre></div>
<p dir="auto">We could also forgo floating point altogether and encode a number like <code>1.5</code> manually. The whole part is just <code>1</code>, so we shift that up (<code>(1 &lt;&lt; 16)</code>), and the fractional part is the halfway point between <code>0x0000</code> and <code>0xffff</code>, so call it <code>0x7fff</code>. That gives us <code>98303</code> in decimal.</p>
<p dir="auto">Operations like addition and subtraction Just Work™ - assuming you're using the same scaling factor for whichever numbers you're operating on. It is possible to mix and match scaling factors, but it increases the complexity.</p>
<p dir="auto">Multiplication is only marginally trickier. Multiplying the two fixed point numbers together essentially scales everything up by scaling factor. This can be resolved by just shifting the result back down.</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline int32_t fixed_multiply(int32_t a, int32_t b) {
  return ((int64_t)a * (int64_t)b) >> SCALING_FACTOR;
}"><pre><span>static</span> <span>inline</span> <span>int32_t</span> <span>fixed_multiply</span>(<span>int32_t</span> <span>a</span>, <span>int32_t</span> <span>b</span>) {
  <span>return</span> ((<span>int64_t</span>)<span>a</span> <span>*</span> (<span>int64_t</span>)<span>b</span>) &gt;&gt; <span>SCALING_FACTOR</span>;
}</pre></div>
<p dir="auto">Division is basically the same story, except in reverse. There's a trick to squeeze out some extra precision by prescaling the dividend by the scaling factor, and then dividing by the divisor.</p>
<div dir="auto" data-snippet-clipboard-copy-content="static inline int32_t fixed_divide(int32_t a, int32_t b) {
  return ((int64_t)a << SCALING_FACTOR) / (int64_t)b;
}"><pre><span>static</span> <span>inline</span> <span>int32_t</span> <span>fixed_divide</span>(<span>int32_t</span> <span>a</span>, <span>int32_t</span> <span>b</span>) {
  <span>return</span> ((<span>int64_t</span>)<span>a</span> &lt;&lt; <span>SCALING_FACTOR</span>) / (<span>int64_t</span>)<span>b</span>;
}</pre></div>
<p dir="auto">OK we can do basic operations, but what if I need something more complex, like I don't know, a trig function? This is where CORDIC comes in.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The CORDIC algorithm</h2><a id="user-content-the-cordic-algorithm" aria-label="Permalink: The CORDIC algorithm" href="#the-cordic-algorithm"></a></p>
<p dir="auto">CORDIC stands for "co-ordinate rotation digital computer", and was cooked up back in the mid 50s (though the general algorithm has been known to mathematicians for hundreds of years). The core idea is that we can rotate a vector around a unit circle by progressively smaller and smaller angles, and the vector components will end up being the sine and cosine of the angle we're interested in.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/cordic.gif"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/cordic.gif" data-animated-image=""></a></p>
<p dir="auto">It's sort of like a binary search:  You move towards the target angle by some large angle and check if you're ahead or behind, and then move by half that angle either clockwise or anticlockwise. This process repeats with smaller and smaller angles until the result converges.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/binary-search.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/binary-search.png"></a></p>
<p dir="auto">If you've worked with these kinds of operations before, you'll know that rotating a vector involves multiplying it with a matrix consisting of sines and cosines of the angle to be rotated to. That seems counter productive, since those are the functions we're trying to compute!</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
\begin{bmatrix}
x' \\
y'
\end{bmatrix} = \begin{bmatrix}
\cos(\theta) &amp; -\sin(\theta) \\
\sin(\theta) &amp; \cos(\theta)
\end{bmatrix} \begin{bmatrix}
x \\
y
v\end{bmatrix}
$$</math-renderer></p>
<p dir="auto">We'll put that aside for a second, and get a big picture overview before solving this problem. Now, it's fairly obvious that rotating by say <code>22.75˚</code> is the same as rotating by <code>45˚</code> and then <code>-22.5˚</code> - i.e. we can break up a rotation into smaller parts, with both positive and negative components.</p>
<p dir="auto">Let's say that we have a maximum rotation of <code>90˚</code> (𝚷/2 radians), and we're trying to figure out <code>sin(0.7)</code> (about <code>40˚</code>). Starting with a vector <code>(1, 0)</code> and a target of <code>0.7</code> radians, we rotate <code>0.7853</code> rads (<code>45˚</code>) anti-clockwise.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/0r.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/0r.png"></a></p>
<p dir="auto">Target now becomes <code>0.7 - 0.7853 = -0.0853</code>. Since it's negative, we now rotate clockwise by 0.3926 rads (22.5˚). Target becomes -0.0853 + 0.3926 = 0.3073, which is positive, so the next rotation will be anti-clockwise by 0.1963 rads (11.25˚).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/1r.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/1r.png"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/2r.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/2r.png"></a></p>
<p dir="auto">If we continue this process for a total of 16 iterations, the vector lines up almost perfectly with the original target angle. The <code>y</code> value of the vector is ~= <code>sin(a)</code>, while <code>x</code> ~= <code>cos(a)</code>! This is how CORDIC works; we rotate a vector around, and the state we keep is an approximation of various trigonometric functions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/3r.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/3r.png"></a></p>
<p dir="auto">With some understanding in hand, we can return to the issue of, well, rotations actually requiring the functions we're trying to compute! We can use trigonometry to simplify the matrix.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
\cos(\theta) = \frac{1}{\sqrt{1 + tan^2(\theta)}}
$$</math-renderer></p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
\sin(\theta) = \frac{\tan(\theta)}{\sqrt{1 + tan^2(\theta)}}
$$</math-renderer></p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
\begin{bmatrix}
x' \\
y'
\end{bmatrix} = \cos(\theta)\begin{bmatrix}
1 &amp; -\tan(\theta) \\
\tan(\theta) &amp; 1
\end{bmatrix} \begin{bmatrix}
x \\
y
\end{bmatrix}
$$</math-renderer></p>
<p dir="auto">We have a few constants ones now, but we still have the <code>tan(a)</code>, plus the <code>cos(a)</code> out front. Let's ignore the <code>cos(a)</code> and focus on getting rid of <code>tan(a)</code>. As you saw when we ran through the algorithm, we're always rotating by a total of <code>~90˚</code>: First by <code>45˚</code>, then <code>22.5˚</code>, then <code>11.25˚</code>, and so on. Since we're doing this a fixed number of times, we can just precompute those values, and put them in a table. You might be thinking: <em>"You said there wouldn't be any tables!"</em>. Well, no. I said there wouldn't be any <em>expensive</em> tables. This table, in our case, will only contain 16 <code>uint32_t</code>s - a whopping 64 bytes! Even the most stripped down embedded projects can <em>usually</em> afford that. (In contrast, an <em>unoptimised</em> table for <code>sin(x)</code> that contains 4096 entries covering values from -1 to 1 would need 16KiB - and that's pretty poor precision!)</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
\begin{bmatrix}
x' \\
y'
\end{bmatrix} = \cos(\theta)\begin{bmatrix}
1 &amp; -table[i] \\
table[i] &amp; 1
\end{bmatrix} \begin{bmatrix}
x \\
y
\end{bmatrix}
$$</math-renderer></p>
<p dir="auto">That means our rotation matrix now only contains constants! We do however still have that <code>cos(a)</code> term. In fact, every iteration brings it's own new <code>cos(a)</code> term. But because of algebra, we can simply multiply all those terms together and apply them at the end.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
\cos(\theta_0) \cdot \cos(\theta_1) \cdot \cos(\theta_2) \cdot ... \cdot \cos(\theta_N)
$$</math-renderer></p>
<p dir="auto">Still, that's not great. But! No matter whether we take positive or negative steps, or the number of iterations, this multiplied out series of cosines actually converge to a constant value: <code>~0.6366</code>. All we need to do is to multiply out by this value after all iterations.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
~0.6366 = \cos(\pm45˚) \cdot \cos(\pm22.5˚) \cdot \cos(\pm11.25˚) \cdot ... \cdot \cos(\pm\theta_N)
$$</math-renderer></p>
<p dir="auto">So that gives us only multiplications by constants over a number of iterations! Not bad. But didn't I say that CORDIC only used bit shifts and addition? For that, we need to go a little deeper into the rabbit hole.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Shifts and Adds</h2><a id="user-content-shifts-and-adds" aria-label="Permalink: Shifts and Adds" href="#shifts-and-adds"></a></p>
<p dir="auto">What the angles we plugged into <code>tan(a)</code> could instead be strategically chosen so that the result would always be an inverse power-of-2? This would be great, since multiplying or dividing by a power-of-2 is just a left or right shift for integers.</p>
<p dir="auto">Well, the <code>atan(x)</code> (arc-tangent or inverse tangent) function can do that for us. We can build a new 16-entry table, where each value is <code>atan(2**-i)</code>, for i=0 to 15. The actual rotation values for each iteration are now (<code>45˚</code>, <code>26.565˚</code>, <code>14.036˚</code>, <code>7.125˚</code>, etc).</p>
<p dir="auto">It doesn't actually half the angle each time, but as it turns out: using these angles, the process will <em>still</em> converge on the correct result! Now all those multiplications by <code>tan(a)</code> have become bit shifts by the iteration number.</p>
<p dir="auto">We still need to recompute our constant for the <code>cos(a)</code> terms. That now comes out to be around <code>0.60725</code>, which would be converted to the fixed point number <code>39796</code>.
And! It turns out there's a trick that means we don't even need to multiply by this value at the end. When we initialise the vector, we set <code>x</code> to this constant instead of 1.</p>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="a06b8c9a079b4f08cd9a0a931ce8bf23">$$
~0.60725 = \cos(\pm\arctan(2^{0})) \cdot \cos(\pm\arctan(2^{-1})) \cdot \cos(\pm\arctan(2^{-1})) \cdot ... \cdot \cos(\pm\arctan(2^{-N}))
$$</math-renderer></p>
<p dir="auto">So now the CORDIC algorithm looks like this:</p>
<p dir="auto">Precompute a table for <code>tan(a)</code>, where each entry is <code>atan(2**-i)</code>. These values are, of course, converted to fixed point, so: <code>atan(2**-i) * (1 &lt;&lt; 16)</code></p>
<p dir="auto">Then, when we want to compute a sine or a cosine, we take the angle (e.g. <code>0.9152</code>), convert it to fixed point: <code>0.9152 * (1 &lt;&lt; 16) = 59978</code></p>
<p dir="auto">Then setup initial parameters:</p>
<div data-snippet-clipboard-copy-content="x = 39796
y = 0
z = 59978"><pre><code>x = 39796
y = 0
z = 59978
</code></pre></div>
<p dir="auto">The <code>z</code> parameter here is not part of the vector, but rather tracks our target angle over time. The sign of this parameter determines if we rotate clockwise or anti-clockwise.</p>
<p dir="auto">With the parameters set up, each iteration looks like this (in pseudocode):</p>
<div dir="auto" data-snippet-clipboard-copy-content="if z >= 0:
    x_next = x - (y >> i)
    y_next = y + (x >> i)
    z -= table[i]
else:
    x_next = x + (y >> i)
    y_next = y - (x >> i)
    z += table[i]
x = x_next
y = y_next"><pre><span>if</span> <span>z</span> <span>&gt;=</span> <span>0</span>:
    <span>x_next</span> <span>=</span> <span>x</span> <span>-</span> (<span>y</span> <span>&gt;&gt;</span> <span>i</span>)
    <span>y_next</span> <span>=</span> <span>y</span> <span>+</span> (<span>x</span> <span>&gt;&gt;</span> <span>i</span>)
    <span>z</span> <span>-=</span> <span>table</span>[<span>i</span>]
<span>else</span>:
    <span>x_next</span> <span>=</span> <span>x</span> <span>+</span> (<span>y</span> <span>&gt;&gt;</span> <span>i</span>)
    <span>y_next</span> <span>=</span> <span>y</span> <span>-</span> (<span>x</span> <span>&gt;&gt;</span> <span>i</span>)
    <span>z</span> <span>+=</span> <span>table</span>[<span>i</span>]
<span>x</span> <span>=</span> <span>x_next</span>
<span>y</span> <span>=</span> <span>y_next</span></pre></div>
<p dir="auto">Now we can follow a few iterations through, and see the algorithm converge on the correct sine and cosine values. Values in parentheses are fixed point.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/0.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/0.png"></a></p>
<p dir="auto">During the first iteration, <code>z</code> was positive, so the vector is rotated anti-clockwise by <code>~0.785</code> rads. Note that the magnitude of the vector increased.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/1.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/1.png"></a></p>
<p dir="auto">In the second iteration, <code>z</code> was still positive, so again the vector is rotated anti-clockwise, by <code>~0.436</code> rads, though this time it overshot the mark. The magnitude of the vector is almost one now - that's the cos(a) product term starting to converge after we set the initial <code>x</code> value!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/2.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/2.png"></a></p>
<p dir="auto">On iteration 3, <code>z</code> was negative, so the vector is rotated clockwise by <code>~0.244</code> rads. It's clearly starting to creep up on that mark, and you can see that just a handful of iterations, we'd be able to get a fairly close approximation!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/3.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/3.png"></a></p>
<p dir="auto">On iteration 4, <code>z</code> was again negative, so clockwise rotation by <code>~0.124</code> rads. Now that the angular change is getting pretty small, and the vector is very close to the actual result, the rotations ping back and forth, getting closer and closer to the real value.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/4.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/4.png"></a></p>
<p dir="auto">Skipping forward to the last iteration, <code>y</code> now contains a very accurate approximation for <code>sin(0.9152)</code> - with an absolute deviation of just <code>0.00000956</code>. The cosine value (in <code>x</code>) deviation is slightly higher, at <code>0.0000434</code>, but still pretty good!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/francisrstokes/githublog/blob/main/assets/cordic/16.png"><img src="https://github.com/francisrstokes/githublog/raw/main/assets/cordic/16.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Wrapping up</h2><a id="user-content-wrapping-up" aria-label="Permalink: Wrapping up" href="#wrapping-up"></a></p>
<p dir="auto">There is <em>a lot</em> more to CORDIC than this, which I may cover in a future post. For instance, I didn't mention the special considerations you have to make if the angle of interest is outside of the first or fourth quadrant of the unit circle. I also didn't talk about how, with a few modifications, CORDIC can be used to compute many other functions, including <code>tan</code>, <code>atan</code>, <code>asin</code>, <code>acos</code>, <code>sinh</code>, <code>cosh</code>, <code>tanh</code>, <code>sqrt</code>, <code>ln</code>, <code>e^x</code>. Related algorithms also exist, such as <a href="https://en.wikipedia.org/wiki/BKM_algorithm" rel="nofollow">BKM</a>, designed specifically for computing logs and exponentials.</p>
<p dir="auto">I'm planning on covering this in some detail on the <a href="https://www.youtube.com/@LowByteProductions?subscribe" rel="nofollow">Low Byte Productions YouTube channel</a>, so follow me there if this kind of thing is something you'd like to learn more about.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thread: Tech we can’t use or teach? (285 pts)]]></title>
            <link>https://overengineer.dev/blog/2024/05/10/thread/</link>
            <guid>40326269</guid>
            <pubDate>Sat, 11 May 2024 05:51:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://overengineer.dev/blog/2024/05/10/thread/">https://overengineer.dev/blog/2024/05/10/thread/</a>, See on <a href="https://news.ycombinator.com/item?id=40326269">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content"> <h2>Thread - the tech we can't use or teach</h2> <section id="main_content">  <p> <span> <i role="img" aria-label="This item was published on:"></i> 2024-05-10 </span>  <span> <i role="img" aria-label="This item was tagged with:"></i> <a href="https://overengineer.dev/blog/tags/electronics/">electronics</a>, <a href="https://overengineer.dev/blog/tags/hacking/">hacking</a>, <a href="https://overengineer.dev/blog/tags/hardware/">hardware</a>, <a href="https://overengineer.dev/blog/tags/overengineering/">overengineering</a>, <a href="https://overengineer.dev/blog/tags/rant/">rant</a> </span> </p> <p>A lot of my projects don’t work out. That’s fine, failing is a very healthy way to learn. However, there are cases where the reasons behind failures are absolutely infuriating. So please, allow me a rant. I’ll spend a few words on how I got where I am. If you don’t care, feel free to skip to the large “Thread?” headline. I won’t judge<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<p>In 2022, <a href="https://overengineer.dev/blog/2022/01/07/overengineering-coffee-bean-storage/">I published an article on how I created a severely over-engineered coffee bean storage and inventory-keeping solution</a>. Since then, many people reached out to me to say that they appreciate my post and took it as inspiration to start similar projects for different needs. I absolutely love that!</p>
<p>More recently, I’ve been actively working on two related projects. One is a sensor I’m not going to talk about yet, but another is a “version 2” of that coffee storage display. My primary motivation for version 2 of that display was to increase the battery runtime. The displays averaged 40 days on a charge when my article was published. That’s alright, but it could be better. I managed to get this up to 55 days with a few software tweaks, but I wanted to explore how to push this further.</p>
<p>So, I started learning about low-power electronics, leading me down a few complicated but fascinating rabbit holes. To start off, I purchased <a href="https://www.nordicsemi.com/Products/Development-hardware/Power-Profiler-Kit-2" rel="nofollow" target="_blank">a very nice power profiler from Nordic Semiconductors</a> and profiled my whole system. If you’re curios, <a href="https://overengineer.dev/__generated__/power-profile-screenshot.Q36a-FjR.png" target="_blank">this is how such a profile looks like</a>. Long story short: I re-wrote parts of the display firmware, identified some problematic components on the DevKit, and bypassed them. Ultimately, it became clear that one of the big factors is… WiFi.</p>
<p>You should know that while I love working on projects like this, I’m also inherently lazy. Using WiFi for such a project made sense to me, as I already have all the required infrastructure set up, and letting the display hardware talk to a service I run is super easy: just connecting to WiFi and sending a request to another device in the LAN. But sadly, WiFi is also really inefficient for a use-case like this. Even just establishing a connection can take a long time; it requires high transmission powers depending on where your access points are set up; it’s all less than ideal. So I explored alternatives, and as it turns out, there’s much to choose from! I didn’t want to build my own hardware<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>, so I wanted to pick something with a good availability of DevKits and ready-to-use modules. Standards like <a href="https://en.wikipedia.org/wiki/LoRa" rel="nofollow" target="_blank">LoRa</a> and <a href="https://en.wikipedia.org/wiki/Zigbee" rel="nofollow" target="_blank">Zigbee</a> came to mind, of course.</p>
<p>As nice (and usually power-efficient) as those technologies are, there’s a huge downside compared to WiFi: I can’t just build the display module and use it - I also need to build “the other end”, a receiver/transmitter/hub or whatever, that acts as a connection point for the displays to exchange data with. That’s not only a whole other piece of hardware I have to run; it’s also another piece of software and firmware I have to write. And as I mentioned earlier, I am lazy. Luckily, there’s a really interesting alternative!</p>
<h2 id="thread">Thread?</h2>
<p>Despite its awful name<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>, the Thread network stack is really cool. Thread uses the same physical layer as Zigbee, IEEE 802.15.4, and it’s also a meshed network. But two things made Thread stand out for me. Thread is based on top off 6LoWPAN, short for “IPv6 over Low-Power Wireless Personal Area Networks”, and that’s kinda cool. In short, this means that each of your devices gets one or more IPv6 addresses, the internal addressing is done via IPv6, and you just throw IP packets around in the network. Even cooler is that the Thread network connects to your regular home network via a bridge called “Border Router” - so your devices can use IPv6 to talk to your applications, and vice-versa.</p>
<p>Wait, a bridge? Didn’t I say I don’t want to run a bridge? Well, yes, but that’s another cool thing about Thread: you might already have a Thread Border Router running. For example, if you have an Apple HomePod or a Nest Hub, you already own a Thread Border Router. If you run Home Assistant, you can buy a dongle for ~40 euros and <a href="https://www.home-assistant.io/integrations/thread/" rel="nofollow" target="_blank">turn your Home Assistant node into a Thread Border Router</a>. It’s all <em>really</em> approachable. And if you use your existing Thread network, things get even more awesome! I did mention that Thread is a mesh network, and this feature is actively used and supported by a lot of commercial hardware. I have several <a href="https://www.evehome.com/en/eve-energy" rel="nofollow" target="_blank">Eve Energy</a> “smart plugs” in my home, and since they are always connected to power, they function as a Thread repeater<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup>, expanding your network’s reach without you doing any work!</p>
<p>So all of that sounds pretty neat, huh? And it is! I got two Thread DevKits to explore more (if you’re curious, I got a <a href="https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK" rel="nofollow" target="_blank">nRF52840-DK</a> and a <a href="https://www.nordicsemi.com/Products/Development-hardware/nRF5340-DK" rel="nofollow" target="_blank">nRF5340-DK</a>, as well as a <a href="https://www.nordicsemi.com/Products/Development-hardware/nRF52840-Dongle" rel="nofollow" target="_blank">nRF52840-Dongle</a> for debugging<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>), and learned a lot. Within a reasonably short timeframe, I managed to hack my own border router into my Apple-based Thread network, I managed to use Wireshark to sniff on my Thread network, and I shoved my own Thread devices (based on the two DevKits) into the network, and confirmed that everything worked as I hoped it would. So, of course, I started roughly outlining a series of blog posts about all of this. Ultimately, my goal was to get other hobbyists into exploring Thread, switching away their projects from WiFi or Bluetooth, and making their projects a whole lot better.</p>
<p>And this is the point where this post turns into a rant.</p>
<h2 id="no-thread">No Thread.</h2>
<p>So far, I have only talked about the nice things around Thread. However, I also have to talk about the <em>ugly</em> parts: <a href="https://www.threadgroup.org/" rel="nofollow" target="_blank">The Thread Group</a>. While Thread builds on many free and open standards like IEEE 802.15.4, IPv6, and <a href="https://en.wikipedia.org/wiki/Constrained_Application_Protocol" rel="nofollow" target="_blank">CoAP</a>, Thread is very much neither free nor open. Quite the opposite, actually.</p>
<p>You can <em>request</em> the Thread Specification <a href="https://www.threadgroup.org/ThreadSpec" rel="nofollow" target="_blank">for free on their website</a>, and you will get it delivered to your inbox very quickly, but you’ll notice a few odd things. For once, there’s an “I agree to the End User License Agreement” checkbox on that page you ignored, but even more obvious: the specification PDF document is password-protected, DRM’ed, and heavily watermarked. To understand why, let’s look at that license agreement again. Partial quote, emphasis mine:</p>
<blockquote>
<p>Thread Group, Inc. […] hereby grants you a […] license […] to view, download, save, reproduce and use the Specification <strong>solely for your own internal purposes</strong> in accordance with the terms of this License Agreement. […] <strong>No right to implementation of the Specification is granted</strong> to you by this License Agreement. […] <strong>Membership in Thread Group is necessary to implement, practice, and ship Thread technology</strong> and Thread Group specifications. Failure to maintain active Thread Group membership while shipping Thread technology may result in legal action, including but not limited to licensing fees.</p>
</blockquote>
<p>Oh. So even though you can buy freely available DevKits, you aren’t actually allowed to … well, use them. Unless you’re a Thread Group member, of course. The least expensive membership level that will enable you to implement the Thread Group IP, <a href="https://www.threadgroup.org/thread-group" rel="nofollow" target="_blank">called “Implementer”</a>, is a cheap USD 7,500. Per year, that is. But hey, don’t worry, if you’re an “innovative IoT start-up company”, you can <a href="https://www.threadgroup.org/Innovation-Enabler-Award" rel="nofollow" target="_blank">apply to get a two-year membership for free</a>! But of course, you have to pay afterward, and this program isn’t even applicable to hobbyists.</p>
<p>This whole mess isn’t helped by <a href="https://openthread.io/" rel="nofollow" target="_blank">OpenThread, an open-source implementation of Thread</a>. The project <a href="https://github.com/openthread/openthread/blob/3bf281d32da7ccde2153c5c90076e327a488d38e/LICENSE" rel="nofollow" target="_blank">is licensed under a BSD 3-Clause license</a>, so it looks very open and friendly to use. However, their repo also includes a <a href="https://github.com/openthread/openthread/blob/3bf281d32da7ccde2153c5c90076e327a488d38e/NOTICE" rel="nofollow" target="_blank">fun little notice</a> highlighting that “members of the Thread Group may hold patents and other intellectual property rights”. And, in fact, the Thread Group website <a href="https://www.threadgroup.org/support#OpenThread" rel="nofollow" target="_blank">has a dedicated FAQ-section on OpenThread</a>, which is fairly clear:</p>
<blockquote>
<p>Q: What Would Prevent A Company From Shipping A Product Based On OpenThread Without Joining The Thread Group?</p>
<p>A: If developers choose not to join Thread Group and ship products using Thread technology, they are not conferred the IP rights required to practice and ship Thread technology, and may subject themselves to legal action, including but not limited to licensing fees.</p>
</blockquote>
<p>To summarize: if you’re a hobbyist without access to some serious throwaway money to join the Thread Group, there is no way to use Thread legally - the license does not include an exception for non-commercial uses. If you’re like me and want to write a series of blog posts about how Thread works, there’s also no legal way.</p>
<p>A commercial membership program for technology stacks like Thread isn’t new; it’s somewhat common in that space. Same with requiring certifications for your commercial products if you want to use a logo like the “Works with Thread” banner. And that’s fine with me. If you’re selling a commercial electronics product, you have to go through many certification processes anyway, so that seems fair. But having a blanket ban on implementations, even for non-commercial projects, is absolutely bonkers. This means that no hobbyist should ever get close to it, and that means that the next generation of electrical engineers and decision-makers don’t get to play around with the tech before they enter the industry. But of course, that doesn’t really matter to the Thread Group: <a href="https://www.threadgroup.org/thread-group#OurMembers" rel="nofollow" target="_blank">their members list</a> includes companies like Apple, Google, Amazon, Nordic, NXP, and Qualcomm - they can just <em>force</em> Thread into being successful by making sure it’s shipped in the most popular “home hubs”. So it’s just us that get screwed over.</p>
<p>Anyway, if you planned to look at Thread… well, don’t. You’re not allowed to use it.</p>
<p><em>I contacted the Thread Group’s support email address on 2024-04-19 to request clarification on non-commercial Thread use. I did receive an “I have forwarded your message” from a member immediately, but no further response arrived. On 2024-05-01, I contacted the Thread Group’s press contact, requesting a comment. As of publishing this post, the Thread Group has not responded.</em></p>

<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>Okay, maybe just a little bit. I mean, did you really expect a <em>short</em> post on <em>my</em> blog?! <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>Also motivated by the intention to blog about this. Building your own RF hardware is <em>hard</em>, but it’s also illegal for most of my audience unless they have the proper certifications. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>No, seriously. Can we please not name new things using terms that are already widely used? I hate that I have to specify whether I’m talking about sewing, screwing, parallel computing, a social network from Meta, or a networking stack. Stop it. <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>If you feel the urge to email me to inform me that it’s not called “Repeater” but “Router”, please read the rest of this article first. This is not meant as a Thread introduction post; you will learn why. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 4">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>Nordic Semiconductors isn’t sponsoring me, even though I already linked four of their products. I just really like their stuff. That said, hey, if you’re from Nordic and you want to sponsor me, … <a href="https://overengineer.dev/me/card/">reach out</a>! :p <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 5">↩</a></p>
</li>
</ol>
</section>  </section> </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple finalizing deal with OpenAI to bring ChatGPT features to iOS 18 (111 pts)]]></title>
            <link>https://9to5mac.com/2024/05/10/ios-18-chatgpt-features-apple-openai/</link>
            <guid>40325876</guid>
            <pubDate>Sat, 11 May 2024 04:03:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2024/05/10/ios-18-chatgpt-features-apple-openai/">https://9to5mac.com/2024/05/10/ios-18-chatgpt-features-apple-openai/</a>, See on <a href="https://news.ycombinator.com/item?id=40325876">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2023/05/chatgpt-ios-1.jpg?quality=82&amp;strip=all&amp;w=1600" alt="OpenAI ChatGPT" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/05/chatgpt-ios-1.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/05/chatgpt-ios-1.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/05/chatgpt-ios-1.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/05/chatgpt-ios-1.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Apple is finalizing an agreement with OpenAI to bring some of its technology to the iPhone this year, according to a new <a href="https://www.theinformation.com/articles/openai-develops-ai-voice-assistant-as-it-chases-google-apple?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+OpenAI+AI+ass&amp;utm_content=4159&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=2797&amp;rc=x5svxc" target="_blank" rel="noreferrer noopener">report from <em>Bloomberg</em></a><em>.</em> With this deal, the report explains that Apple will be able to offer “a popular chatbot” powered by ChatGPT as part of its AI-focused features in iOS 18.</p>



<p>While Apple is also <a href="https://9to5google.com/2024/03/17/gemini-apple-iphone-talks/" target="_blank" rel="noreferrer noopener">still in talks with Google</a> about an AI partnership, tonight’s report says Apple has “closed in on an agreement with OpenAI.”</p>



<p>“An OpenAI accord would let Apple offer a popular chatbot as part of a flurry of new AI features that it’s planning to announce next month,” the report explains. More specific details about how these features and integrations might work remain unclear for now.</p>



<p>From Mark Gurman at <em>Bloomberg</em>:</p>



<blockquote>
<p>The two sides have been finalizing terms for a pact to use ChatGPT features in Apple’s iOS 18, the next iPhone operating system, said the people, who asked not to be identified because the situation is private. Apple also has held talks with Alphabet Inc.’s Google about licensing that company’s Gemini chatbot. Those discussions haven’t led to an agreement, but are ongoing.</p>
</blockquote>



<p>The report cautions that there’s still “no guarantee” that a deal between Apple and OpenAI “will be announced imminently.” </p>



<p>A report on Thursday emphasized that iOS 18’s AI features will be powered (in part) by Apple data centers with Apple Silicon processors. The majority of iOS 18’s AI features, however, will be <a href="https://9to5mac.com/2024/04/21/gurman-ios-18-ai-features-on-device/">powered entirely on-device</a>, allowing Apple to tout privacy and speed benefits.</p>



<p>Apple is slated to announce iOS 18 and its new AI features at WWDC, which kicks off with a special <a href="https://9to5mac.com/2024/03/26/wwdc-2024-official-date-confirmed/" target="_blank" rel="noreferrer noopener">event on June 10.</a></p>



<p>OpenAI is set to make its own, separate announcement during an event on Monday. <em>The Information</em> has <a href="https://www.theinformation.com/articles/openai-develops-ai-voice-assistant-as-it-chases-google-apple?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+OpenAI+AI+ass&amp;utm_content=4159&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=2797&amp;rc=x5svxc">reported</a> that one feature in development at OpenAI is an AI voice assistant to compete with Siri and Google Assistant. </p>



<p><strong>Follow Chance</strong>:&nbsp;<a href="https://www.threads.net/@ChanceHMiller">Threads</a>,&nbsp;<a href="https://twitter.com/chancehmiller">Twitter</a>,&nbsp;<a href="https://www.instagram.com/chancehmiller/">Instagram</a>, and&nbsp;<a href="https://mastodon.social/@ChanceHMiller">Mastodon</a>.&nbsp;</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/4b7b06Y"><img src="https://9to5mac.com/wp-content/uploads/sites/6/2024/05/2024.05-9to5mac-750x150-1.webp" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Most of Europe is glowing pink under the aurora (1291 pts)]]></title>
            <link>https://www.foto-webcam.eu/webcam/lucknerhaus/</link>
            <guid>40324179</guid>
            <pubDate>Fri, 10 May 2024 21:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.foto-webcam.eu/webcam/lucknerhaus/">https://www.foto-webcam.eu/webcam/lucknerhaus/</a>, See on <a href="https://news.ycombinator.com/item?id=40324179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="fscontainer">
    <canvas id="fscanvas"></canvas>
    <div id="fsloadbg">
      <p><img src="https://www.foto-webcam.eu/webcam/include/loading-16.gif">
      Loading image...</p>
      
    </div>
    <p>Move mouse to scroll image<br>Click or press Esc to close window</p>
    
    
    
    <p><img src="https://www.foto-webcam.eu/webcam/include/fitscreen.png" width="80" height="45" title="Fit image to screen size (key F) - Mouse-wheel or keys +/- zoom the image - Key 0: original size"></p>
    
    
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Minute Park (163 pts)]]></title>
            <link>https://oneminutepark.tv/</link>
            <guid>40323785</guid>
            <pubDate>Fri, 10 May 2024 21:04:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oneminutepark.tv/">https://oneminutepark.tv/</a>, See on <a href="https://news.ycombinator.com/item?id=40323785">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>one minute please ... the parks are loading</p><div id="instructions">
            <p><a id="close-instructions">close</a></p>
    
            <p><img src="https://oneminutepark.tv/images/hands.png" alt=""></p><p>One Minute Park allows you to visit parks from around the world for one minute each. These are just one minute videos, not webcams. Eventually the project will fill in all the minutes (1440) in a day. You can create your own One Minute Park to help achieve this goal.</p>

            <h2>How to make a One Minute Park</h2>

            <ol>
                <li>Walk around a park until you find a composition. Your scene should be filled with many layers of activity without any dominating elements.</li>
                <li>Record in landscape mode on your phone. Keep your shot as steady as you can but don't use a tripod. You could even hold your breath. Check the timecode indicator while filming to make your video exactly 60 seconds. Tap record, let it count up to 60, and tap again. No editing needed!</li>
                <li>Upload your One Minute Park to <a href="https://www.are.na/elliott-cost/one-minute-park">this Are.na channel</a>. Videos should be in .mp4 format. Please include the date, time, park, location in the block's title.</li>
            </ol>

            <h2>Support</h2>

            <p>One Minute Park is a project by <a href="http://elliott.computer/">Elliott Cost</a>. It is unfunded and a labor of love. Any support is greatly appreciated–thank you!</p>

            <p>
                <a href="https://elliott.computer/support">Donate</a> →<br>
                <a href="https://www.patreon.com/elliottcost">Subscribe to the patreon</a> →<br>
                <a href="mailto:email@elliott.computer">Sponsor this site</a> →<br>
                <a href="https://sites.elliott.computer/i-want-to-be-your-companys-resident-artist/">Hire me as a resident web artist for your company</a> →
            </p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spider-Man (Neversoft) Decompilation Project Progress Checkpoint – May 2024 (106 pts)]]></title>
            <link>https://krystalgamer.github.io/spidey-decomp-status-may/</link>
            <guid>40321867</guid>
            <pubDate>Fri, 10 May 2024 17:55:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krystalgamer.github.io/spidey-decomp-status-may/">https://krystalgamer.github.io/spidey-decomp-status-may/</a>, See on <a href="https://news.ycombinator.com/item?id=40321867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>In 2019, I started the decompilation the PC version of the Spider-Man game <a href="https://en.wikipedia.org/wiki/Spider-Man_(2000_video_game)">developed by Neversoft</a>, which is most commonly called Spider-Man 2000. Work didn't last long, I made few commits the last being done on 10th of August 2020.</p>
<p>Fast-forward to 2023 and my interest in going back to the decompilation had re-ignited, all thanks to a few community members that still actively create mods and explore the game. Here's a non-exhaustive list of the most active ones:</p>
<ul>
<li><a href="https://www.youtube.com/@Anganoff">Anganoff</a></li>
<li><a href="https://www.youtube.com/@tc.kralyusuf">T.C Kral-Yusuf</a></li>
<li><a href="https://github.com/ZedekThePlagueDoctor">Zedek</a></li>
</ul>
<p>After fixing some issues with my mods and improving the codebase I decided to restart the decompilation once again.</p>
<h2>Restarting the project</h2>
<p>Restarting was a no-brainer has I had completely shifted my approach to the project and learned a lot more about the game. Even though I knew the game was written in C++, I had previously decided to use C.
I had no strong reason to do so besides the fact I was more comfortable with C. This time I did not make the same mistake.</p>
<p>Previously, I was live-testing the code. I would re-write a method, hook into the game code and run the game and see if it worked. Not only, this method was tedious it left the door open for the correctness of the code - <em>did I mess up the signdness? did mess the edge case?</em>. This time I would follow a process similar to matching decompilation projects, but instead of trying to recreate the game as close to the byte I would strive for function parity.
This means that each function/sub-routine would be recreated trying to match as close as possible the original version. For cases where it didn't match, they'd need to be analyzed  as it's quite easy to make a change in code that changes the register allocation or instruction order.</p>
<h2>Case for matching decompilation</h2>
<p>Having a project that when built produces a binary that is an exactly replica of the game is great as it means all the original behaviours (bugs included) were preserved. One could also develop a sense on how the original developers wrote code and thus be more efficient at decompiling more pieces of the code.</p>
<h2>Case against matching decompilation</h2>
<p>It is a laborious, fruitless and tedious process. Even when using the same compiler toolchain used by the original developers there's a lot of "code massages" until it produces the exact same output. After all that work one thinks to themselves - <em>Did the developers go through all this effort to write this routine? It looks nothing like real code.</em>
When I say "code massages" they are not limited to changing the code but also the build flags - it's totally doable that some object files where built with different optimizations.</p>
<p>Also not having non-matching assembly does not mean the bugs are not preserved as it's more likely a bug in a game is caused by logic rather than a compiler spitting a different instruction.</p>
<p>There's no bigger frustration than struggling to get a function to match. When I was decompiling a super-small routine of a PlayStation game I had the logic pinned down, it was taking parameters and writing to some global variable. My code was doing it but had an extra copy to a register which I was going crazy for. After a while a realized the issue, I had defined the function as returning an <code>int</code> if I changed to <code>void</code> it would be a perfect match. This to say that there's so many variables at play that getting a matching decompilation is just too much work.</p>
<h2>A proper middle ground</h2>
<p>Let's say we're decompiling a function, we can either do matching decompilation or equivalent decompilation. The matching process has been described, but how does one evaluate if two pieces of assembly are equivalent. Two factors: sign correctness and memory accesses.</p>
<p>Let's assume we're decompiling the following function <code>void foo(MyStruct *arg)</code> and there's the following piece of code</p>
<div><pre><span></span><span>...</span>
<span>mov</span><span> </span><span>ebx</span><span>,</span><span> </span><span>arg</span><span> </span><span>; would actually be something like: mov ebx, [esp+X]</span>
<span>movzx</span><span> </span><span>eax</span><span>,</span><span> </span><span>[</span><span>ebx</span><span>+</span><span>0x42</span><span>]</span>
<span>...</span>

<span>; also seen as</span>

<span>...</span>
<span>mov</span><span> </span><span>ebx</span><span>,</span><span> </span><span>arg</span>
<span>xor</span><span> </span><span>eax</span><span>,</span><span> </span><span>eax</span>
<span>mov</span><span> </span><span>ax</span><span>,</span><span> </span><span>[</span><span>ebx</span><span>+</span><span>0x42</span><span>]</span>
<span>...</span>
</pre></div>
<p>One can deduce at the position <code>0x42</code> of <code>MyStruct</code> there's a 16-bit <strong>unsigned integer</strong>. If the instruction had been <code>movsx</code> (move with sign-extension) then it'd be a different story.</p>
<p>Another example, let's say for the function <code>void bar(MyStruct *src, MyStruct *dst)</code> you see the following:</p>
<div><pre><span></span><span>mov</span><span> </span><span>ebx</span><span>,</span><span> </span><span>src</span>
<span>mov</span><span> </span><span>eax</span><span>,</span><span> </span><span>[</span><span>ebx</span><span>+</span><span>0x20</span><span>]</span>

<span>mov</span><span> </span><span>ecx</span><span>,</span><span> </span><span>dst</span>
<span>mov</span><span> </span><span>[</span><span>ecx</span><span>+</span><span>0x24</span><span>],</span><span> </span><span>eax</span>
<span>mov</span><span> </span><span>[</span><span>ecx</span><span>+</span><span>0x28</span><span>],</span><span> </span><span>eax</span>
</pre></div>
<p>Which would be the proper decompilation?</p>
<div><pre><span></span><span>dst</span><span>-&gt;</span><span>field_24</span><span> </span><span>=</span><span> </span><span>src</span><span>-&gt;</span><span>field_20</span><span>;</span>
<span>dst</span><span>-&gt;</span><span>field_28</span><span> </span><span>=</span><span> </span><span>src</span><span>-&gt;</span><span>field_20</span><span>;</span>


<span>// OR</span>

<span>int</span><span> </span><span>tmp</span><span> </span><span>=</span><span> </span><span>src</span><span>-&gt;</span><span>field_20</span><span>;</span>
<span>dst</span><span>-&gt;</span><span>field_24</span><span> </span><span>=</span><span> </span><span>tmp</span><span>;</span>
<span>dst</span><span>-&gt;</span><span>field_28</span><span> </span><span>=</span><span> </span><span>tmp</span><span>;</span>
</pre></div>
<p>The answer is the second! For the first one it's totally possible that in-between the writes the value changes, therefore the assembly generated would contain a read for each write. BUT! It's totally possible to make the compiler generate the same assembly for both, given you tweak with the flags enough or use the <code>restrict</code> keyword to convince the compiler there's no way the value would change in-between those writes.</p>
<p>Having these concepts laid down I restarted the decompilation project.</p>
<h2>May Checkpoint</h2>
<p>The work is publicly accessible on my <a href="https://github.com/krystalgamer/spidey-decomp">GitHub</a>.</p>
<p>The <a href="https://krystalgamer.github.io/spidey-apple">Macintosh</a> version of the game contains symbols - function names, parameters types and names. This has been used to identify functions of the game, the compiler used for the PC version has quite a few routines that have been inlined which is annoying. A cool thing about this version is that it contains boundaries for the object files. Where the code inside <code>foobar.cpp</code> starts, there will be a dummy section called <code>.sinit_foobar_cpp</code> so it has been extremely helpful into getting a proper recreation of the source directory.</p>
<p>The game shares the same engine with Tony Hawk Pro Skater 2 and that game has had 2 demos for the PlayStation that contain symbols - they contain more information than Macintosh version has they also contain classes/structure definitions with offsets. Since both of these games (ab)use inheritance it has been a godsent helping outlining where base class ends and where child class begins. For reference here's the inheritance chart of the player class <code>CPlayer -&gt; CSuper -&gt; CBody -&gt; CItem (-&gt; CClass)</code>. <code>CClass</code> doesn't seem to be present in the PC and Mac versions, either it was fully inlined or removed when ported.</p>
<p>So far 75 data structures have been added to the codebase. I've also created validation macros to make sure both structure size and memory accesses don't get messed up by padding or accidental mistakes. They are <code>VALIDATE_SIZE</code> that takes a structure/class name and the expected size and <code>VALIDATE</code> which takes a structure/class name, a field name and the expected offset. For both macros, if the check fails it'll print a message.</p>
<p>Re-written functions:</p>
<ul>
<li>Memory allocation methods</li>
<li>Most of <code>CItem</code></li>
<li>Most of <code>CBody</code></li>
<li>Most of <code>CSuper</code></li>
<li>Geometry Transformation engine methods</li>
<li>Utility methods</li>
</ul>
<p>By starting to write code for the "lower" level methods it made me able to identify functions that have been inlined. I've also started to develop this intuition on how the compiler works. For example, when there's a conditional jump, it jumps towards the un-met condition (or as I used to say "jump to further ahead in the source file").</p>
<p>The following code:</p>
<div><pre><span></span><span>int</span><span> </span><span>MyFunction</span><span>(</span><span>int</span><span> </span><span>arg</span><span>)</span>
<span>{</span>
<span>  </span><span>if</span><span> </span><span>(</span><span>arg</span><span>)</span>
<span>    </span><span>return</span><span> </span><span>200</span><span>;</span>
<span>  </span><span>return</span><span> </span><span>45</span><span>;</span>
<span>}</span>
</pre></div>
<p>Would generate the following assembly:</p>
<div><pre><span></span><span>mov</span><span> </span><span>eax</span><span>,</span><span> </span><span>[</span><span>esp</span><span>+</span><span>4</span><span>]</span>
<span>test</span><span> </span><span>eax</span><span>,</span><span> </span><span>eax</span>
<span>jz</span><span> </span><span>label</span>
<span>mov</span><span> </span><span>eax</span><span>,</span><span> </span><span>200</span>
<span>jmp</span><span> </span><span>end</span>


<span>label:</span>
<span>mov</span><span> </span><span>eax</span><span>,</span><span> </span><span>45</span>
<span>end:</span>
<span>ret</span>
</pre></div>
<p>Has you can see the conditional jump is taken if the argument is zero which is the opposite of the expression inside the if-statement!</p>
<p>Recently to help identify which functions are matching and which need to be revisited I developed a tagging system which is <code>@Ok</code>, <code>@NotOk</code> and <code>@TODO</code>. The idea is to be easily searchable and make it easier to generate high-level status reports.</p>
<p>Finally, I've also made the decompilation setup reproducible which is basically IDA Pro, Ghidra and the same version of Visual Studio by the developers (it was identified using <a href="https://github.com/horsicq/Detect-It-Easy">Detect-It-Easy</a>). In the beginning I was working on a different machine that for a while didn't have access to.</p>
<h2>Broadcasting my progress</h2>
<p>In late 2023, I've decided to <a href="https://www.youtube.com/@kRySt4LGaMeR">stream every time I'd work the project</a>. The goal was simple to educate people on the complexity of this endeavor. Since I own a Discord community with close to a thousand members, it's not uncommon to get the question - <em>what % of work is left to do?</em> - which is quite tricky to answer.</p>
<p>Decompilation process goes as follows. Identify function in code and the data structures it uses. Then, recreate data structures in code and finally recreate the function. It's a lot of work until the code is done. For a lot of streams I was just identifying fields in data structures and naming them if it was possible to infer from the scenario.</p>
<p>Livestreaming has also come with the benefit that I can share with the audience all of the rabbit holes I fall into during the process, such as automation with IDAPython.</p>
<h2>Focusing on consistency</h2>
<p>As described in this post, decompilation project is tedious and laborious. Therefore it's easy to lose motivation and leave it in backburner for a long-time. The solution I have found is consistency, everyday try to work on it a bit as all effort will compound. An example of this are days where the time I worked on the project was just outlining fields in the classes, there will be a day where I won't need to open the <code>Structures</code> tab in IDA and that would mean I have the internal structures all figured out.</p>
<p>I've also worked in removing all the inconveniences that can hinder me working on it, such as requiring a specific computer to work on it. Now that I have a portable and reproducible environment I have less excuses not to tackle this project. A cool side-effect of working on it regularly is that I feel more motivated, like a self-fulfilling prophecy the more I work the more motivated I feel.</p>
<p>I've talked about this with <a href="https://www.youtube.com/channel/UCdM-EFz45lu6iDumVFV9Jkg">MrMartinIden</a> who is working on decompilation project for <a href="https://gitlab.com/MrMartinIden/openusm">Ultimate Spider-Man PC Version</a> and we both agree that this type of project requires much more than motivation to thrive.</p>
<h2>Looking Forward</h2>
<p>There's still aspects that I'd love to improve such as function equality evaluation. I'd love to automate the process. Here's possibilities that I've thought so far:</p>
<ul>
<li>x86 symbolic execution engine that would validate memory accesses</li>
<li>Lift x86 to a Z3 style theorem and try to see if both sides (original vs re-written) are equal</li>
<li>Lift both original and re-written version to LLVM IR and see if they are reduced to same output</li>
</ul>
<p>For the first two instances the idea of dealing with loops makes it daunting and I haven't found a proper way to deal with it. For the third option I have little experience with LLVM so I'm not sure how feasible it is. If someone has any expertise in this topic please reach out to me! My contact information is in the <a href="https://krystalgamer.github.io/about">About page</a>.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An informal comparison of the three major implementations of std:string (109 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20240510-00/?p=109742</link>
            <guid>40321824</guid>
            <pubDate>Fri, 10 May 2024 17:51:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20240510-00/?p=109742">https://devblogs.microsoft.com/oldnewthing/20240510-00/?p=109742</a>, See on <a href="https://news.ycombinator.com/item?id=40321824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="featured">
                         <p>
            May 10th, 2024</p><!-- .entry-meta -->
        <p>We saw some time ago that <a title="Inside STL: The string" href="https://devblogs.microsoft.com/oldnewthing/20230803-00/?p=108532"> the three major implementations of <code>std::string</code> are all quite different</a>. To summarize:</p>
<pre>// gcc
struct string
{
    char* ptr;
    size_t size;
    union {
        size_t capacity;
        char buf[16];
    };

    bool is_large() { return ptr != buf; }
    auto data() { return ptr; }
    auto size() { return size; }
    auto capacity() { return is_large() ? capacity : 15; }
};

// msvc
struct string
{
    union {
        char* ptr;
        char buf[16];
    };
    size_t size;
    size_t capacity;

    bool is_large() { return capacity &gt; 15; }
    auto data() { return is_large() ? ptr : buf; }
    auto size() { return size; }
    auto capacity() { return capacity; }
};

// clang
union string
{
    struct {
        size_t capacity;
        size_t size;
        char* ptr;
    } large;

    struct {
        unsigned char is_small:1;
        unsigned char size:7;
        char buf[sizeof(large) - 1];
    } small;

    bool is_large() { return !small.is_small; }
    auto data() { return is_large() ? large.ptr : small.buf; }
    auto size() { return is_large() ? large.size : small.size; }
    auto capacity() { return is_large() ? large.capacity : sizeof(large) - 2; }
};
</pre>
<p>We’ll compare these versions based on the complexity of some commonly-used operations.</p>
<p>Detecting whether the string is small or large is a single member comparison with msvc and clang, but on gcc, it involves comparing a member against the address of another member, so it will take an extra instruction to calculate that address.</p>
<table>
<tbody>
<tr>
<th>gcc is_large</th>
<th>msvc is_large</th>
<th>clang is_large</th>
</tr>
<tr>
<td><code>lea rdx, [rcx].buf</code><br>
<code>cmp rdx, [rcx].ptr</code><br>
<code>jnz large</code></td>
<td><code>cmp [rcx].capacity, 15</code><br>
<code>ja large</code></td>
<td><code>test [rcx].is_small, 1</code><br>
<code>jz large</code></td>
</tr>
</tbody>
</table>
<p>Note: gcc could have shaved an instruction by reordering the members so that the <code>buf</code> comes first (thereby avoiding the need to calculate its address). On the other hand, it increases the cost of accessing <code>ptr</code> on some processors: On the x86 family, it forces a larger encoding because the offset is nonzero. On the Itanium, it requires two instructions because the Itanium cannot perform an offset load in a single instruction. On most other processors, the offset can be folded into the load instruction at no extra cost. My guess is that gcc biased their design to optimize for x86.</p>
<p>On the other hand, gcc wins the race to access the <code>data()</code>, since the <code>ptr</code> is always valid, and that’s probably why they chose their design.</p>
<table>
<tbody>
<tr>
<th>gcc data()</th>
<th>msvc data()</th>
<th>clang data()¹</th>
</tr>
<tr>
<td><code>mov rdx, [rcx].ptr</code></td>
<td><code>lea rdx, [rcx].buf</code><br>
<code>cmp [rcx].capacity, 15</code><br>
<code>cmova rdx, [rdx]</code></td>
<td><code>lea rdx, [rcx].small.buf</code><br>
<code>test [rcx].small.is_small, 1</code><br>
<code>jnz @1</code><br>
<code>mov rdx, [rcx].large.ptr</code><br>
<code>@1:</code></td>
</tr>
</tbody>
</table>
<p>The clang implementation also has extra work to calculate the size.</p>
<table>
<tbody>
<tr>
<th>gcc size()</th>
<th>msvc size()</th>
<th>clang size()²</th>
</tr>
<tr>
<td><code>mov rdx, [rcx].size</code></td>
<td><code>mov rdx, [rcx].size</code></td>
<td><code>movzx rax, [rcx].small.is_small</code><br>
<code>test al, 1</code><br>
<code>jnz @1</code><br>
<code>mov rax, [rcx].large.size</code><br>
<code>jmp @2</code><br>
<code>@1: shr rax, 1</code><br>
<code>@2:</code></td>
</tr>
</tbody>
</table>
<p>A special case of checking the size is checking whether the string is empty.</p>
<table>
<tbody>
<tr>
<th>gcc empty()</th>
<th>msvc empty()</th>
<th>clang empty()</th>
</tr>
<tr>
<td><code>cmp [rcx].size, 0</code><br>
<code>jz empty</code></td>
<td><code>cmp [rcx].size, 0</code><br>
<code>jz empty</code></td>
<td><code>movzx rax, [rcx].small.is_small</code><br>
<code>test al, 1</code><br>
<code>jz @1</code><br>
<code>mov rax, [rcx].large.size</code><br>
<code>jmp @2</code><br>
<code>@1: dec rax</code><br>
<code>@2: test rax, rax</code><br>
<code>jz empty</code></td>
</tr>
</tbody>
</table>
<p>The capacity comes into play behind the scenes when extending the string. For example, <code>append(char)</code> can do a fast-append if there is excess capacity, and delegate to a function call if the capacity needs to be increased. Here, msvc has an edge.</p>
<table>
<tbody>
<tr>
<th>gcc capacity()</th>
<th>msvc capacity()</th>
<th>clang capacity()</th>
</tr>
<tr>
<td><code>lea rax, [rcx].buf</code><br>
<code>cmp rax, [rcx].ptr</code><br>
<code>mov eax, 15</code><br>
<code>cmovnz rax, [rcx].capacity</code></td>
<td><code>mov rax, [rcx].capacity</code></td>
<td><code>test [rcx].small.is_small, 1</code><br>
<code>mov eax, 22</code><br>
<code>cmovz rax, [rcx].large.capacity</code></td>
</tr>
</tbody>
</table>
<p>The clang implementation does have an edge in terms of memory usage: Despite an overall smaller size, it has a larger small-string capacity in 64-bit mode.</p>
<table>
<tbody>
<tr>
<th>sizeof / SSO capacity</th>
<th>gcc</th>
<th>msvc</th>
<th>clang</th>
</tr>
<tr>
<td>32-bit mode</td>
<td>24 / 15</td>
<td>24 / 15</td>
<td>12 / 11</td>
</tr>
<tr>
<td>64-bit mode</td>
<td>32 / 15</td>
<td>32 / 15</td>
<td>24 / 22</td>
</tr>
</tbody>
</table>
<p>If you <code>reserve()</code> a lot of space for a string, but use only a little bit of it, and then call <code>shrink_<wbr>to_<wbr>fit()</code>, you can potentially get into a mixed state where the string is allocated externally (as if it were a large string), even though the capacity is smaller than the capacity of a small string.</p>
<p>The msvc implementation uses the capacity to detect whether it is using the small string optimization, so this mixed state is illegal for msvc, and it must convert large strings to small strings if <code>shrink_<wbr>to_<wbr>fit()</code> shrinks the string below the small-string threshold.</p>
<p>The gcc and clang implementations allow external allocations to have a small capacity. Nevertheless, the clang implementation does convert externally-allocated strings to small strings if they shrink below the small-string threshold.</p>
<p>The gcc implementation takes a different approach: With gcc, <code>shrink_<wbr>to_<wbr>fit()</code> is a nop! This is legal according to the C++ standard: The <code>shrink_<wbr>to_<wbr>fit()</code> method is an advisory call, and the implementation is permitted to ignore the advice.</p>
<p>One final point of comparison is how the three implementations deal with static initialization.</p>
<table>
<tbody>
<tr>
<th>gcc</th>
<th>msvc</th>
<th>clang</th>
</tr>
<tr>
<td><code>{ buf, 15, { 0 } }</code></td>
<td><code>{ { 0 }, 0, 15 }</code></td>
<td><code>{ 1, 0, 0, ... }</code></td>
</tr>
</tbody>
</table>
<p>A statically-initialized empty string in gcc consists of a pointer to the internal buffer, a constant 15 (size), and a bunch of zeroes (buf). The presence of a pointer introduces a relocation into the data segment and <a title="Just how constexpr is C++20's std::string?" href="https://quuxplusone.github.io/blog/2023/09/08/constexpr-string-firewall/"> silently messes up string’s <code>constexpr</code>-ness</a>.</p>
<p>Statically-initiaized empty strings in msvc and clang consist of integer constant data; no pointers. This means no relocations and a better shot at <code>constexpr</code>-ness.</p>
<p>Okay, so let’s summarize all this information into a table.</p>
<table>
<tbody>
<tr>
<th>&nbsp;</th>
<th>gcc</th>
<th>msvc</th>
<th>clang</th>
</tr>
<tr>
<th>is_large</th>
<td>slower</td>
<td>faster</td>
<td>faster</td>
</tr>
<tr>
<th>data()</th>
<td>fast</td>
<td>slower</td>
<td>slower</td>
</tr>
<tr>
<th>size()</th>
<td>fast</td>
<td>fast</td>
<td>much slower</td>
</tr>
<tr>
<th>empty()</th>
<td>fast</td>
<td>fast</td>
<td>much slower</td>
</tr>
<tr>
<th>capacity()</th>
<td>slowest</td>
<td>fast</td>
<td>slower</td>
</tr>
<tr>
<th>32-bit size</th>
<td>24</td>
<td>24</td>
<td>12</td>
</tr>
<tr>
<th>64-bit size</th>
<td>32</td>
<td>32</td>
<td>24</td>
</tr>
<tr>
<th>32-bit SSO capacity</th>
<td>15</td>
<td>15</td>
<td>11</td>
</tr>
<tr>
<th>64-bit SSO capacity</th>
<td>15</td>
<td>15</td>
<td>22</td>
</tr>
<tr>
<th>ABI supports mixed state?</th>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr>
<th>shrink_to_fit()</th>
<td>nop</td>
<td>must convert to SSO</td>
<td>chooses to convert to SSO</td>
</tr>
<tr>
<th>Static initialization</th>
<td>relocation</td>
<td>no relocation</td>
<td>no relocation</td>
</tr>
</tbody>
</table>
<p>¹ I don’t see clang generating this slightly smaller alternative</p>
<pre>lea rdx, [rcx].small.buf
test [rcx].small.is_small, 1
cmovz rdx, [rcx].large.ptr
</pre>
<p>perhaps because the <code>cmov</code> instruction always reads from its second parameter even if the value is not used, and there might be a store-forward penalty because in the case of a small string, the read is unlikely to match the size of the previous write.</p>
<p>² I don’t see clang generating this slightly smaller alternative</p>
<pre>movzx rax, [rcx].small.is_small
shr rax, 1
jc @1
mov rax, [rcx].large.size
@1:
</pre>
<p>probably because “shift right and look at carry” is not something natively expressible in C++. If you really went for it, you could also fold in a <code>cmov</code>.</p>
<pre>movzx rax, [rcx].small.is_small
shr rax, 1
cmovnc rax, [rcx].large.size
</pre>

        

        
		
        
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coronal mass ejection impact imminent, Two more earth-directed CMEs (488 pts)]]></title>
            <link>https://www.spaceweatherlive.com/en/news/view/533/20240510-cme-impact-imminent-two-more-earth-directed-cmes.html</link>
            <guid>40321821</guid>
            <pubDate>Fri, 10 May 2024 17:50:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spaceweatherlive.com/en/news/view/533/20240510-cme-impact-imminent-two-more-earth-directed-cmes.html">https://www.spaceweatherlive.com/en/news/view/533/20240510-cme-impact-imminent-two-more-earth-directed-cmes.html</a>, See on <a href="https://news.ycombinator.com/item?id=40321821">Hacker News</a></p>
Couldn't get https://www.spaceweatherlive.com/en/news/view/533/20240510-cme-impact-imminent-two-more-earth-directed-cmes.html: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>