<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 08 May 2024 15:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA['Underwater bicycle' propels swimmers forward at superhuman speed (119 pts)]]></title>
            <link>https://newatlas.com/marine/seabike-swimming-propeller/</link>
            <guid>40297748</guid>
            <pubDate>Wed, 08 May 2024 13:13:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/marine/seabike-swimming-propeller/">https://newatlas.com/marine/seabike-swimming-propeller/</a>, See on <a href="https://news.ycombinator.com/item?id=40297748">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I can't say I've seen anything like this "underwater mobility device" before. The idea is simple enough; you extend the Seabike's pole to the appropriate length, then strap it to your waist with a belt. Then you find the pedals with your feet, and start turning the crank, with the waist strap to push against. </p><p>This drives what looks like about a 15-inch (38-cm) propeller. At this point, you start gliding through the water with the splendid, gracious ease of a cruising dugong with an outboard up its bum. You can swim with your arms as well, which creates a surreal visual effect somewhat akin to watching somebody walking along an airport travelator:</p><p>Or you can laze along, arms held out Superman-style. Or indeed, you can angle your nose down, go fully underwater and make like a pedal-powered fish. It's fully compatible with a SCUBA setup if you want to really go nuts down there, although you wouldn't want to take it down too deep and overexert yourself. </p><p>Propellers work both ways, too –&nbsp;so you can also flip the thing upside down, hold the propeller out in front of you, stick some handles on in place of the pedals, and drive the thing with your arms instead. Mind you, this looks a lot less fun. </p><p>Seabike says the prop turns slowly enough that you can safely use it at the local pool – although you'll certainly cop some dirty looks from the Speedo brigade in the fast lane. It's also buoyant, so you won't have to dive to find it if the thing comes off somehow. </p><p>It looks like an incredibly fun way to cover distance in open water, too. Seabike runs its own snorkeling tours out of Cannes, and also sells it with snorkel boards and spear fishing kits. Does it pack down for easy storage? You know it does. </p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f6345bff7244e45f595a795d03a1f64bc" data-video-id="6btiHaTwFKw" data-video-title="SEABIKE PRO +">

    <iframe id="YouTubeVideoPlayer-f6345bff7244e45f595a795d03a1f64bc" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/6btiHaTwFKw?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>SEABIKE PRO +</p>
    
</div><p>Best of all, you can instantly charge this device by eating a hot dog. In an age where everything is going electric, something so simple and mechanical is a welcome change. </p><p>It appears Seabike has been making these things for at least a year, selling for prices starting at EU€290 (US$310). The idea doesn't seem to have received much attention yet, but that strikes us as just a matter of time; it's a simple, clever gadget that looks like a ton of fun.</p><p>Personally, I've never really known what to do with my legs on a swim. Nobody's ever properly convinced me that kicking my feet around is worth the effort, absent a set of swim fins. This jigger, according to the manufacturers, makes you handily quicker than an equivalent swimmer with fins on. Sign me up, I'd love to give one a crack!</p><p>Source: <a href="https://www.seabike.fr/" target="_blank" data-cms-ai="0">Seabike</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[40 years later, a game for the ZX Spectrum will be again broadcast over FM radio (208 pts)]]></title>
            <link>https://www.racunalniski-muzej.si/en/40-years-later-a-game-for-the-zx-spectrum-will-be-once-again-broadcast-over-fm-radio/</link>
            <guid>40296926</guid>
            <pubDate>Wed, 08 May 2024 11:49:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.racunalniski-muzej.si/en/40-years-later-a-game-for-the-zx-spectrum-will-be-once-again-broadcast-over-fm-radio/">https://www.racunalniski-muzej.si/en/40-years-later-a-game-for-the-zx-spectrum-will-be-once-again-broadcast-over-fm-radio/</a>, See on <a href="https://news.ycombinator.com/item?id=40296926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
	
	
	
		<article id="post-12199">
				
				
			        <p><img width="2560" height="1920" src="https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-scaled.jpg" alt="" loading="lazy" srcset="https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-scaled.jpg 2560w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-300x225.jpg 300w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-1024x768.jpg 1024w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-768x576.jpg 768w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-1536x1152.jpg 1536w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/PXL_20210626_115223453.PORTRAIT-2048x1536.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">			        </p>

		        

			    <div>
		
<p>There were times when Sinclair ZX Spectrum games were copied over the radio waves across Slovenia. <a href="https://radiostudent.si/" title="">Radio Študent</a> broadcast screeching, beeping and whining, which we recorded on tape and played a game a few hours later. Those times are long gone, but we can take a walk through the past today. Radio Študent, which is celebrating its 55th anniversary this week, will invite two members of the legendary Software editorial team to the microphone.</p>



<figure><img src="https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/k2-short.gif" alt=""></figure>



<p>Today at 20:30 the guests will be Žiga Turk, who we know as the co-founder of the magazine <a href="https://en.wikipedia.org/wiki/Moj_mikro" title="">Moj Mikro</a>. As one of the pioneers of the Internet in Slovenia, he wrote the Virtual Shareware Library and Wodo. Together with another guest, Matevž Kmet, he also wrote the famous “Kontrabant”, a cult Slovenian text adventure, and its successor “<a href="https://worldofspectrum.org/software?id=0021603" title="">Kontrabant 2</a>“. The talk will take place in the <a href="https://www.racunalniski-muzej.si/en/home-english/" title="">Computer Museum</a> until 21:30.</p>



<p>This will be followed by a nostalgic broadcast of the game Kontrabant 2 via radio waves at the frequency of 89.3 MHz, which will begin around 21:30. Anyone who still has a working Spectrum ZX will then be able to test the game. Those who do not have one can do so at the Computer Museum or online.</p>



<figure><ul><li><figure><img loading="lazy" width="576" height="1024" src="https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1-576x1024.jpg" alt="" data-id="12200" data-full-url="https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1.jpg" data-link="https://www.racunalniski-muzej.si/?attachment_id=12200" srcset="https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1-576x1024.jpg 576w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1-169x300.jpg 169w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1-768x1365.jpg 768w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1-864x1536.jpg 864w, https://www.racunalniski-muzej.si/wp-content/uploads/2024/05/1.jpg 1080w" sizes="(max-width: 576px) 100vw, 576px"></figure></li></ul></figure>
	</div>

			    
			    			    
					
							    
			    			    				    	<!-- end get_the_author_meta -->
		</article>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Who Wants to Be a Thousandaire? (2011) (115 pts)]]></title>
            <link>https://www.damninteresting.com/who-wants-to-be-a-thousandaire/</link>
            <guid>40296744</guid>
            <pubDate>Wed, 08 May 2024 11:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.damninteresting.com/who-wants-to-be-a-thousandaire/">https://www.damninteresting.com/who-wants-to-be-a-thousandaire/</a>, See on <a href="https://news.ycombinator.com/item?id=40296744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                    

                    <p><span>

                                                	<span>Long-Form:</span>
                            <span>Michael Larson had a lot of time and TVs on his hands, and he used them to hack one of his favorite game shows.<br></span>
                            <span>Written by <a href="https://www.damninteresting.com/contributors/alan-bellows/">Alan Bellows</a></span>
                        
                                                	•
                        	<span>Non-Fiction</span>
                        
		        					        		•
			        		<span>September 2011</span>
		        		                    </span>


                </p></div><div>

		            				<article>
											<p>
			© 2011 All Rights Reserved. Do not distribute or repurpose this work without written permission from the copyright holder(s).
	</p>
<p>
	Printed from https://www.damninteresting.com/who-wants-to-be-a-thousandaire/<br>
</p>
												
		                
						
						
											
					<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.734375" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/larson-mug.jpg" alt="" title=""></p></figure>
<p>On the 19th of May 1984, at CBS Television City in Hollywood, a curious air of tension hung over the studio during the taping of the popular game show <em>Press Your Luck</em>. Ordinarily a live studio audience could be counted upon to holler and slap their hands together, but something was keeping them unusually subdued. The object of the audience’s awe was sitting at the center podium on the stage, looking rather unremarkable in his thrift-store shirt and slicked-back graying hair. His name was Michael Larson.</p>
<p>“You’re going to go again?” asked the show’s host Peter Tomarken as Larson gesticulated. Gasps and murmurs punctuated the audience’s cautious applause, and the contestants sitting on either side of Larson clapped in stunned silence. “Michael’s going <em>again</em>,” Tomarken announced incredulously. “We’ve never had anything like this before.”</p>
<p>The scoreboard on Larson’s podium read “$90,351,” an amount unheard of in the history of <em>Press Your Luck</em>. In fact, this total was far greater than any person had ever earned in one sitting on any television game show. With each spin on the randomized “Big Board” Larson took a one-in-six chance of hitting a “Whammy” space that would strip him of all his spoils, yet for 36 consecutive spins he had somehow missed the whammies, stretched the show beyond its 30-minute format, and accumulated extraordinary winnings. Such a streak was astronomically unlikely, but Larson was not yet ready to stop. He was convinced that he knew exactly what he was doing.
</p>
<p>
Michael Larson was born in the small town of Lebanon, Ohio in 1949. Although he was generally regarded as creative and intelligent, he had an inexplicable preference for shady enterprises over gainful employment. One of his earliest exploits was in middle school, where he smuggled candy bars into class and profitably peddled them on the sly. This innocuous operation was just the first in a decreasingly scrupulous series of ventures. One of his later schemes involved opening a checking account with a bank that was offering a promotional $500 to each new customer; he would withdraw the cash at the earliest opportunity, close the account, then repeat the process over and over under assumed names. </p>
<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.740625" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/larson-dinwitty.jpg" alt="Michael Larson and Teresa Dinwitty on vinyl." title="Michael Larson and Teresa Dinwitty on vinyl."></p><figcaption>Michael Larson and Teresa Dinwitty on vinyl.</figcaption></figure>
<p>On another occasion he created a fake business under a family member’s name, hired himself as an employee, then laid himself off to collect unemployment wages.</p>
<p>By 1983 Michael Larson had been married and divorced twice and was living with his girlfriend Teresa Dinwitty. During the summers he operated a Mister Softee ice cream truck, and during the off-season he passed the time poring through piles of periodicals in search of money-making schemes. Michael also spent much of the day with his console television, scanning the airwaves for lucrative opportunities. One day it occurred to him that he could double his information intake by setting a second console TV to beside the first and tuning it to a different channel. Soon he procured a third. Eventually he added a row of smaller televisions atop the three consoles, and yet another row of tubes was later stacked atop that. Now he could watch 12 channels at once.</p>
<p>The warm, buzzing television tumor metastasized into adjacent rooms, filling the house with a goulash of infomercials, news programs, game shows, and advertisements for money-making schemes. Larson watched them in a trance-like state, sometimes throughout the night. Dinwitty would later say of her boyfriend and common-law husband, “He always thought he was smarter than everybody else,” and that he had a “constant yearning for knowledge.” But when visitors asked about the chattering mass of receivers she found it easier to just tell them that Michael was crazy.</p>
<p>One fateful November day in 1983, Peter Tomarken’s dapper countenance appeared on one of Michael’s many monitors. Tomarken was the host of a new game show called <em>Press Your Luck</em> which was giving away more money than any other game shows at the time. What most interested Michael was the game’s “Big Board,” an electronic array of prize boxes which operated by lighting up squares in a rapid and random fashion until the player pressed a big red button to stop the action. The player’s randomly selected box might contain a vacation, a prize, cash rewards, and/or extra spins. But with each spin there was also a one-in-six chance of hitting a Whammy which would cause an animated character to appear on the screen and expunge all of a player’s winnings.</p>
<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.73125" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/pyl-big-board.jpg" alt="Michael's secret safe spots are the ones that contain $3000 and $2000 prizes at the time this picture was taken." title="Michael's secret safe spots are the ones that contain $3000 and $2000 prizes at the time this picture was taken."></p><figcaption>Michael's secret safe spots are the ones that contain $3000 and $2000 prizes at the time this picture was taken.</figcaption></figure>
<p>Larson invested in a newfangled video cassette recorder and began taping episodes of <em>Press Your Luck</em>. After weeks of painstaking scrutiny Michael realized that the bouncing prize selector did not actually move randomly; it always followed one of five lengthy sequences. This information was only moderately useful due to the rapidly shuffling positions of the prizes and penalties, but his methodical analysis led to another finding. Of the eighteen squares on the Big Board there were two that never had Whammies: #4 and #8. This meant that all a player must do to avoid Whammies⁠—and thus retain his hundreds of dollars in winnings⁠—would be to memorize five interminable series of numbers and develop superhuman reflexes. Giddy with the thrill of discovery, Larson began fine-tuning his timing using his VCR’s pause key as a surrogate big red button.</p>
<p>Six months later, in May 1984, Michael Larson sat beardily in the interview room for the <em>Press Your Luck</em> auditions in Hollywood. His story left few heartstrings unpulled: He explained that he was an unemployed ice cream truck driver. He had borrowed the bus money to get to Hollywood from Ohio because he loved <em>Press Your Luck</em>. He had stopped at a thrift store down the street to buy a 65 cent dress shirt. And he was unable to afford a gift for his six-year-old daughter’s upcoming birthday. Executive producer Bill Carruthers said of Larson’s audition, “He really impressed us. He had charisma.” Contestant coordinator Bob Edwards was uneasy about Larson, but he couldn’t quite articulate why, so Bill overruled him. “I should have listened to Bob,” Carruthers later chuckled.</p>
<p>Taping occurred the following Saturday. Returning champion Ed Long sat on Michael’s right and contestant Janie Litras sat on his left. Host Peter Tomarken made boilerplate game-showey chit-chat with each contestant, and he asked Michael about his ice cream truck. “You’ve kind of OD’d on ice cream, right?” he asked Larson, who agreed. “Well hopefully you won’t OD on money, Michael.”</p>
<p>Michael earned 3 spins on the Big Board in the first question round, giving him 3 opportunities to test the skills he had cultivated over the past six months. The board’s incandescent selector began its distinctive pseudo-random maneuvers. “Come on…big bucks,” Michael chanted, as was customary for players when up against the Big Board. “STOP!” he shouted as he slapped the button with both hands. The selector was stopped on a Whammy in slot #17. Michael shook his head and forced an embarrassed smile, but now he knew exactly how the board was timed with respect to the button. With his second and third spins Michael found his stride. He dropped all pretenses and remained silent as he concentrated on the light bouncing around the big board. Both times he successfully landed on space #4, and he ended the first half of the game with $2,500.</p>
<figure data-embiggen="true"><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.72058823529412" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2011/09/larson-enlarged.jpg" alt="" title=""></p></figure>
<p>In the second and more lucrative half of the game, Michael managed to acquire seven spins to use on the big board. Since he was in last place he was the first to spin. He positioned his hands over the button with interlocked fingers and impatiently interrupted the host’s banter by shouting, “I’m ready, I’m ready!” Tomarken indulged him, and the light on the big board began bouncing. Again, Larson was silent as he frowned at the board. Fellow contestant Ed Long would later say of Larson during these moments that “he went into a trance.”</p>
<p>Thus began Larson’s inconceivable procession of winning spins. His demeanor alternated between intense concentration and jubilation. The strategy worked even better than he had anticipated due to the large number of Free Spin bonuses that appeared in his safe slots. Host Peter Tomarken became increasingly flabbergasted each time Larson made the “spin again” gesture. $30,000 was considered an extraordinary payoff for one day on any game show at that time, and the likelihood of missing the whammies for more than a dozen spins was considered to be vanishingly small. By his 13th spin Michael had $32,351 and nervous giggles. By his 21st spin he had $47,601 and conspicuous anxiety. But he pressed on.</p>
<p>The <em>Press Your Luck</em> control booth had grown silent as the show’s producers began to realize that Larson was consistently winning on the same two spaces. In a panic, the booth operators called Michael Brockman, CBS’s head of daytime programming. “Something was very wrong,” Brockman said in a <em>TV Guide</em> interview. “Here was this guy from nowhere, and he was hitting the bonus box every time. It was bedlam, I can tell you.” Producers asked if they should stop the show, but Larson did not appear to be breaking any rules so they were forced to allow the episode to play out.</p>
<p>Back on the stage, Ed and Janie clapped incredulously on either side of Michael, still waiting for their turns on the board. Janie let slip a snort of disgust after Michael’s 26th successful spin. Tomarken covered his face with his hand in disbelief as Larson risked almost $75k on his 32nd spin. But Michael’s zen-like concentration was beginning to falter. He paused to set his head on the podium and let out a whimper of exhaustion. Still he motioned to continue. The studio audience worried that he’d hit a whammy and experience an unfortunate reversal of fortune, while the producers in the control booth worried that he wouldn’t.</p>
<p>On his 40th spin Larson’s scoreboard debt-clocked his dollar sign to make room for another digit; he surpassed $100,000. Larson, his shoulders slumped, passed his remaining spins to the bewildered Ed Long. Ed immediately hit a whammy.</p>
<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.73125" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/tomarken.jpg" alt="Host Peter Tomarken failing to believe what he is seeing." title="Host Peter Tomarken failing to believe what he is seeing."></p><figcaption>Host Peter Tomarken failing to believe what he is seeing.</figcaption></figure>
<p> Michael sat in a twitchy daze as Ed and Janie went through their much more pedestrian turns at the board. But Larson was snapped back to reality when Janie passed 3 of her spins to him. According to the game rules he was obligated to use them. He did not appear pleased.</p>
<p>“I didn’t want them,” Larson joked nervously as the light began bouncing around the big board, yet almost immediately he punched the big red button and landed on $4,000 in slot #4. Janie let out a squeal. The board started again. After a longer than usual delay, Larson hit the button again, landing safely in slot #8. He had just one mandatory spin remaining. The board started flashing, and Larson let out a sigh. “STOP!” he shouted as he slapped the button, but he had pressed it a fraction of a second too soon. Slot #17 was lit, the same slot where he’d hit a whammy on his first spin. As luck would have it, however, the slot contained a trip to the Bahamas. It was over; Michael had won. Larson gave Ed an awkward embrace and offered Janie a firm handshake. In total, Larson won $110,237 in cash and prizes, including two tropical vacations and a sailboat. Reportedly this was more than triple the previous record for winnings in a single episode of a game show.</p>
<p>A clearly discombobulated Peter Tomarken engaged Larson in an impromptu interview after the show. “Why did you keep going?” he asked.</p>
<p>“Well, two things:” Michael replied. “One, it felt right. And second, I still had seven spins and if I passed them, somebody could have done what I did.”</p>
<p>Tomarken was too polite to remark on the ridiculousness of that suggestion. “What are you going to do with the money, Michael?”</p>
<p>“Invest in houses.”</p>
<p>Larson was not allowed to return as champion since he had surpassed CBS’s $25k winnings limit. As all of the perplexed parties parted ways, CBS executives were called to a meeting to dissect the episode frame-by-frame. In spite of their efforts they could find no evidence of wrongdoing or rule-breaking, so after a few weeks they grudgingly mailed Larson his check. Some people at CBS didn’t want the over-extended episode to be released to the public at all, but it was ultimately decided to air it in June as an awkwardly edited two-parter. </p>
<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.590625" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/architect.jpg" alt="" title=""></p></figure>
<p>Executives insisted that the episode never be seen again. In the meantime <em>Press Your Luck</em> paid to add some more sequences to the Big Board to prevent future contestants from mimicking Michael’s strategy.</p>
<p>Upon his return home, neighbors were shocked to learn of “crazy” Michael Larson’s accomplishment. True to his word, he regaled his daughter with expensive birthday gifts and invested some of his spoils in real estate. But his fondness for dicey get-rich-quick deals ensnared him in a Ponzi scheme, and he lost enough money to lose his appetite for houses.</p>
<p>Some months later Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as possible in one dollar notes. The bank complied with his unorthodox request, and from there he proceeded to another bank to trade even more of his savings for singles. Over a two week period he converted the $100,000 or so that remained of his personal savings into 100,000 one dollar bills.</p>
<p>The motivation for this aberrant behavior was a contest put on by a local radio station. Each day a disk jockey would read a serial number aloud on the air, and if any listener was able to produce the matching dollar bill they would win $30,000. Michael reasoned that 100,000 one dollar bills was 100,000 opportunities to win the prize, giving him a statistical advantage. And even if his scheme proved fruitless he would just redeposit his money, so he figured he had nothing to lose.</p>
<p>Michael and Teresa spent each day rifling through piles of cash looking for matches, pausing only for such distractions as eating, bathing, and excreting. They soon realized that it was impossible for two people to examine that much money in the allotted time, so Michael redeposited a portion of it. After a few weeks, Michael’s obsession over the contest began to put considerable strain on his relationship with Teresa, and on his relationship with reality. The cash was stashed in kitchen drawers, up the stairs, and on bedroom floors. They kept the bills in burlap sacks, grocery bags, and unkempt stacks. And though his girlfriend would scream and shout, he simply would not take the cash bags out.</p>
<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.753125" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/larson-stare.jpg" alt="" title=""></p></figure>
<p>One evening, seeking refuge from the endless hours of cash-collating, Michael and Teresa accepted an invitation to attend a Christmas party. When they returned home at about 1:00 am, they found the back door of the house had been brutalized. Apparently the pair had unwittingly left a sizable tip for an unsolicited cleaning service: about $50,000. According to Dinwitty, Michael immediately accused her of being an accessory to the heist. She denied involvement, and police found no evidence of her guilt, but she says that Larson was never convinced. She claimed that Michael would stand and stare at her while she slept, which made her fear for her safety. One day while Michael was away she took $5,000 that he had hidden in a dresser drawer and absconded with the kids. She called him from a hotel to tell him to move out of her house. His only response was, “I want my money back.” He packed his belongings and departed, leaving one wall of the living room blemished and peeling from the heat of his once-formidable tower of televisions.</p>
<p>Police never identified the thieves. In 1994, about 10 years after his pivotal <em>Press Your Luck</em> appearance, Larson was invited to be a guest on ABC’s <em>Good Morning America</em> to discuss the movie <em>Quiz Show</em>. With a raspy voice he unbeardily reminisced about his game show exploits and expressed regret that he was never able to play on Jeopardy, because, he explained, “I think I have figured out some angles on that.” Around that same time he was also interviewed by <em>TV Guide</em> magazine. When asked about the whereabouts of his <em>Press Your Luck</em> winnings, he replied, “It didn’t work out. We had a cash-flow problem, and I lost everything.”</p>
<p>In March of the following year, Michael fled from Ohio with agents from the SEC, IRS, and FBI hot on his heels. He was implicated as one of the architects of a cash-flow solution that operated under the name Pleasure Time Incorporated. It was a pyramid scam selling shares in a fraudulent “American Indian Lottery” which had hoodwinked 20,000 investors out of 3 million dollars. The Pleasure Time flimflam was historic in that it was the first time the SEC pursued a case where the bulk of the fraud took place in newfangled “cyberspace.” Michael Larson was a fugitive from justice for four years until 1999, when he turned up in Apopka, Florida. He had succumbed to throat cancer.</p>
<figure><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg==" data-height-ratio="0.746875" data-lazy-load-src="//damn-8791.kxcdn.com/wp-content/uploads/2011/09/larson-gma.jpg" alt="Michael Larson's appearance on Good Morning America" title="Michael Larson's appearance on Good Morning America"></p><figcaption>Michael Larson's appearance on <em>Good Morning America</em></figcaption></figure>
<p>Michael Larson held the record for the most game-show winnings in a single day until 2006, when it was broken by Vickyann Chrobak-Sadowski on <i>The Price is Right</i>. Larson’s handiwork on <em>Press Your Luck</em> was sufficiently extraordinary that he has become a strange kind of folk hero to some. Others regard him as a cheap huckster or a likable-but-occasionally-creepy crackpot. The real Michael Larson was arguably an amalgam of these qualities. His shenanigans on <em>Press Your Luck</em> are oft described as a “scam,” “scandal,” or a “cheat,” but even the CBS executives ultimately admitted that he had broken nary a rule. In the end, his impressive performance on <em>Press Your Luck</em> may be one of the only honest days of work that Michael Larson ever did.</p>

				

										
										
						<p>
			© 2011 All Rights Reserved. Do not distribute or repurpose this work without written permission from the copyright holder(s).
	</p>
<p>
	Printed from https://www.damninteresting.com/who-wants-to-be-a-thousandaire/<br>
</p>
						<p>
							<i>Since you enjoyed our work enough to print it out, and read it clear to the end, would you consider donating a few dollars at https://www.damninteresting.com/donate</i> ?
						</p>
									</article>
			
		            	            		
	            	
		            			

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The search for easier safe systems programming (151 pts)]]></title>
            <link>https://www.sophiajt.com/search-for-easier-safe-systems-programming/</link>
            <guid>40295624</guid>
            <pubDate>Wed, 08 May 2024 08:26:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sophiajt.com/search-for-easier-safe-systems-programming/">https://www.sophiajt.com/search-for-easier-safe-systems-programming/</a>, See on <a href="https://news.ycombinator.com/item?id=40295624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>I've been involved in the Rust project in some form or another since 2016, and it's a language I'm very comfortable using. Many Rust programmers could <a href="https://blog.rust-lang.org/2024/02/19/2023-Rust-Annual-Survey-2023-results.html">say the same</a>. But, if we take a step back and are honest with ourselves, we'd admit that the road to getting to that level of comfort was difficult.</p>
<p>I taught Rust professionally for two years. Watching the faces of people trying to learn Rust for the first time reminded me just how hard this language is to learn.</p>
<p>After two years of that, I wanted to answer a question I wasn't entirely sure had an answer: <em>Is it possible to make an easy-to-use, easy-to-learn, and easy-to-teach safe systems language?</em> Could I put my career working on programming languages (TypeScript, Rust, Nushell, etc) to use and find a solution?</p>
<h2 id="enter-june">Enter June</h2>
<p>For the last year and a half, I and my recently-added collaborator Jane Losare-Lusby have been working in secret on a safe systems language that could be learned about as quickly as one can learn Go. I think we might have something worth exploring.</p>
<h2 id="changing-how-we-think-of-memory">Changing how we think of memory</h2>
<p>In Rust, we think of each piece of memory as having its own lifetime. Each of these lifetimes must be tracked, sometimes leading to rather complex code, complex error messages, and/or complex mental models of what is happening. The complexity of course comes with the benefit of being highly precise about each and every piece of memory and its reclamation.</p>
<p>Using a Rust example:</p>
<pre><code><span>struct </span><span>Node {
    </span><span>data1</span><span>: &amp;Data
    data2: &amp;Data
    data3: &amp;Data
}
</span></code></pre>
<p>Rust developers will spot right away that this is an incomplete example. We need two more things: Lifetime Parameters and Lifetime Annotations. Adding those, we get:</p>
<pre><code><span>struct </span><span>Node&lt;</span><span>'a</span><span>, </span><span>'b</span><span>, </span><span>'c</span><span>&gt; {
    </span><span>data1</span><span>: &amp;</span><span>'a</span><span> Data
    data2: &amp;</span><span>'b</span><span> Data
    data3: &amp;</span><span>'c</span><span> Data
}
</span></code></pre>
<p>The concept count for this example ends up being pretty substantial. Counting them off, we get:</p>
<ul>
<li>Lifetimes</li>
<li>Lifetime annotations</li>
<li>Lifetime parameters</li>
<li>Ownership and borrowing</li>
<li>Generics</li>
</ul>
<p>When I showed examples like this to my class when I taught Rust, I had to walk them through each of those concepts first before I could show the full example.</p>
<p>The question then is: can we make this easier?</p>
<h2 id="what-if-memory-was-grouped">What if memory was grouped?</h2>
<p>What if instead of having to track every piece of memory's lifetime separately, we let groups of related allocations share a lifetime?</p>
<p>Effectively, this would mean that a data structure, like a linked list, would have a pointer pointing to the head which has a lifetime, and then every node in the list you can reach from that head has the same lifetime.</p>
<p>There are some benefits to this approach, as well as a few drawbacks. Let's take a look at the benefits first.</p>
<h2 id="benefits-of-grouped-allocations">Benefits of grouped allocations</h2>
<p>Exploring grouped allocations, we noticed some immediate benefits. The first is that we could treat all user-defined values as pointers, and these pointers could also represent their own lifetimes (without needing lifetime parameters). This makes the code feel quite a bit lighter:</p>
<pre><code><span>struct </span><span>Node {
    </span><span>data</span><span>: </span><span>i64</span><span>
    next: Node?
}

</span><span>let</span><span> n = new Node(data: </span><span>123</span><span>, next: none)
</span></code></pre>
<p>Since all user data is pointers, we can use the name of the type to mean "pointer to this structured data".</p>
<p>The next thing we noticed is that both lifetimes and inference for lifetimes becomes significantly simpler.</p>
<p>Let's take a variation of the example above:</p>
<pre><code><span>struct </span><span>Node {
    </span><span>data</span><span>: </span><span>i64</span><span>
    next: Node?
}

fun </span><span>do_this</span><span>() {
    </span><span>let</span><span> n = new Node(data: </span><span>123</span><span>, next: none)
}
</span></code></pre>
<p>We can infer that the allocation that creates <code>new Node(...)</code> has a lifetime and what it is. Because this allocation never "escapes" the function - that is, it never leaves the function in any way - then we can call its lifetime "Local".</p>
<p>As we'll find out, each of the lifetime possibities is a readable name that we can show the user in error messages. It also makes things significantly easier to teach.</p>
<p>Let's look at another example to see a different lifetime.</p>
<pre><code><span>struct </span><span>Stats {
    </span><span>age</span><span>: </span><span>i64
</span><span>}

</span><span>struct </span><span>Employee {
    </span><span>name</span><span>: c_string,
    </span><span>stats</span><span>: Stats,
}

fun </span><span>set_stats</span><span>(</span><span>mut</span><span> employee: Employee) {
    employee.stats = new Stats(age: </span><span>33</span><span>)
}

fun </span><span>main</span><span>() {
    </span><span>mut</span><span> employee = new Employee(name: c"</span><span>Soph</span><span>", stats: new Stats(age: </span><span>22</span><span>))
    </span><span>set_stats</span><span>(employee)
    </span><span>println</span><span>(employee.stats.age)
}
</span></code></pre>
<p>A bit of a longer example this time, but let's focus on this function:</p>
<pre><code><span>fun </span><span>set_stats</span><span>(</span><span>mut</span><span> employee: Employee) {
    employee.stats = new Stats(age: </span><span>33</span><span>)
}
</span></code></pre>
<p>What's the lifetime of this <code>new Stats(..)</code> allocation? In this example, we do see the new pointer escape the function via a parameter. We can also give this a readable lifetime: <code>Param(employee)</code></p>
<p>In all, we have three lifetimes an allocation can have:</p>
<ul>
<li>Local</li>
<li>Param(xxxx)</li>
<li>Return</li>
</ul>
<h2 id="any-data-structure-you-want">Any data structure you want</h2>
<p>Another big advantage of grouping our allocations is that we no longer have to worry about a drop order. This means we can think of the whole thing as dropping all at once. For large structures, that can be a speed-up over languages with a required drop order.</p>
<p>Additionally, we get another major benefit. We can now create arbitrary data structures.</p>
<pre><code><span>struct </span><span>Node {
    </span><span>data</span><span>: </span><span>i64</span><span>
    next: Node?
}

</span><span>mut</span><span> node3 = new Node(data: </span><span>3</span><span>, next: none)
</span><span>let</span><span> node2 = new Node(data: </span><span>2</span><span>, next: node3)
</span><span>let</span><span> node1 = new Node(data: </span><span>1</span><span>, next: node2)

node3.next = node1
</span></code></pre>
<p>And just like that, we've made a circular linked list. Creating a similar example in Rust is certainly more of a challenge.</p>
<p>But, something fishy is going on here.</p>
<p>To make the above work, we're using shared, mutable pointers. This is explicitly forbidden in Rust. Why is it okay here?</p>

<p>Rust disallows holding two mutable references to the same memory location and for good reason. Well, multiple reasons actually.</p>
<p>First, having two copies of a mutable pointer where two separate threads each hold a copy means we have the possibility for a race condition. This can leave us with incoherent data that's difficult to debug.</p>
<p>Second, even if these two multiple pointers are limited to the same thread, we get what we might call "spooky action at a distance". The modification of one pointer is then visible to the holder of the other pointer, which might be far away from the source of the mutation.</p>
<p>For us to reasonably use shared, mutable pointers, we need to tame both of these. The first issue, the race condition, is easy enough: we prevent sending shared, mutable pointers between threads. This limits them to a single thread.</p>
<p>The second issue is decidedly harder. There have been many attempts at ways of handling this through rules enforced by the type system.</p>
<p>In June, we're trying something a bit different. We'll let developers use shared, mutable pointers, but then offer a "carrot" to opt-in to restrictions around using them. The carrot ends up pulling from a classic technique of software engineering: encapsulation.</p>
<h2 id="the-full-power-of-encapsulation">The full power of encapsulation</h2>
<p>In traditional encapsulation, programmers make a kind of "best effort" to hide implementation details from the world around them. Keeping private state private grants the benefits of better code reuse, ease of updating implementation details, and more.</p>
<p>But as often is the case, if that kind of rule isn't enforced, over time APIs get designed where internal implementation details leak out.</p>
<p>Something very interesting happens if we don't allow this to happen. If an encapsulation can be checked by the compiler, and the compiler enforces that no private details leak, we have what you might call "full encapsulation".</p>
<p>These kinds of encapsulations wouldn't allow any aliasing of pointers into them. They'd have their internal pointers fully isolated from the rest of the program.</p>
<p>Once we have this, some new capabilities start opening up:</p>
<ul>
<li>We can "fence off" our shared, mutable pointers, making it possible to create single-owner encapsulations that can be sent safely between threads.</li>
<li>We can lean people in the direction of cleaner API design, as now we have a way to truly keep private implementation details private.</li>
<li>We can handle some of the drawbacks of grouped allocations.</li>
</ul>
<p>What kind of drawbacks, you might ask? It's high time we talked about them.</p>
<h2 id="drawbacks-of-grouped-allocations">Drawbacks of grouped allocations</h2>
<p>If we go back to our earlier example and look carefully, we'll notice something:</p>
<pre><code><span>fun </span><span>set_stats</span><span>(</span><span>mut</span><span> employee: Employee) {
    employee.stats = new Stats(age: </span><span>33</span><span>)
}

fun </span><span>main</span><span>() {
    </span><span>mut</span><span> employee = new Employee(name: c"</span><span>Soph</span><span>", stats: new Stats(age: </span><span>22</span><span>))
    </span><span>set_stats</span><span>(employee)
    </span><span>println</span><span>(employee.stats.age)
}
</span></code></pre>
<p>The question is: what happened to the <code>new Stats(age: 22)</code> allocation?</p>
<p>Remembering that June is a systems language, we can't say "the garbage collector handled it" because we have no garbage collector. Nor can we say "the refcount hit zero, so we reclaimed it" as we don't use refcounting. As a systems language, we can't allow hidden or difficult-to-predict overhead to happen.</p>
<p>It's not actually leaked either, as even the memory it occupies will be reclaimed once the entire group is reclaimed. For all intents and purposes, though, it's lost to the user until the group is no longer live. It's a kind of "memory bloat" that happens if we group our allocations.</p>
<p>To handle this, we'll need some way of recycling that memory. I say "recycling" specifically because in June we can't free the memory, as the group is treated together as a single entity where all the allocations in the group are freed at once. If we instead recycle the memory, we can reuse that same memory while the group is live.</p>
<p>Techniques to do this have been around for decades, and often people use "free lists" to keep a list of nodes that have been recycled, so they can be reused when the next allocation happens.</p>
<p>The problem with free lists is that they aren't safe. If you're not careful, you'll create a security vulnerability and/or an incredibly hard bug to find.</p>
<p>Instead, we need to build in a safe way of recycling memory into the language.</p>
<h2 id="safe-memory-recycling">Safe memory recycling</h2>
<p>Using the idea of full encapsulation from earlier, we can create "fenced in" sets of pointers that we know aren't shared with the rest of the world. Once we have them, it's possible to track the pointers inside. These pointers can get a "copy count", so we know how many copies are live at any point in time (not dissimilar from a refcount, though this has no automatic reclamation).</p>
<p>Once we have a copy count for each internal pointer, we can give developers a built-in <code>recycle</code> command.</p>
<pre><code><span>let x = new Foo()
recycle x
</span></code></pre>
<p>Recycling would start at the given pointer and would check the pointers reachable from it. Each pointer it finds that it can recycle would go into the safe free list.</p>
<p>You might wonder "why not do this automatically?". There are a couple reasons:</p>
<ul>
<li>The operation is linear time based on your transitively-reachable pointers. This means you may incur a noticeable overhead when recycling</li>
<li>Because of the first point, it's important to make places where this occurs visible</li>
</ul>
<p>If this sounds like a kind of manual garbage collection, you're right. My collaborator Jane calls this "semi-automatic" memory reclamation. You ask once, and when you ask you get a kind of highly focused mark and sweep for that single pointer and the pointers reachable from it.</p>
<p><em>Note: this feature is not yet in the reference compiler. We're hoping to implement it in the coming weeks.</em></p>
<h2 id="more-work-ahead">More work ahead</h2>
<p>We have a way of simplifying lifetimes, making for readable code that people from various languages should be able to understand and use. We can also give clear, easy-to-understand lifetime errors when they arise.</p>
<p>Having safe memory recycling gives us a way to keep groups and still offer things like <code>delete</code> in a linked list abstraction. It's convenient but not so automatic that we lose the visibility into the costs of memory management.</p>
<p>That said, there are still some challenge ahead that will need to be solved in the language design and tooling. For example, how do you know when the program is bloating memory? We'll need some way of doing a memory trace when the program is running to detect this and warn the developer.</p>
<p>I see this in a way as a more incremental/prototype-friendly way of development. June is always memory safe, but the first version of a program may not be as efficient as it could be in terms of memory usage. That's a process we often go through as developers. First, we "make it work" before we "make it good".</p>
<p>In June, we keep it lightweight as we keep your programs memory safe, and then we provide tools and support for incrementally improving code.</p>
<h2 id="future-possibilities">Future possibilities</h2>
<h3 id="relationship-to-rust">Relationship to Rust</h3>
<p>June has a real opportunity to be a good complement to Rust. Rust's focus on embedded and system's development is a core strength. June, on the other hand, has a lean towards application development with a system's approach. This lets both co-exist and offer safe systems programming to a larger audience.</p>
<p>An even better end state requires Rust to have a stable ABI. Once it does, June will be able to call into Rust crates to get the benefits of Rust's substantial crate ecosystem. We're looking forward to collaborating on this in the future.</p>
<h3 id="going-beyond-oop">Going beyond OOP</h3>
<p>OOP has for decades been the way many applications are written, but it's not without its flaws. Many OOP languages allow programmers to freely break good rules of thumb, like the Liskov substitution principle, or to create a mess of interwoven code between parent and child classes that's difficult to maintain.</p>
<p>We're currently investigating other ways of making code reuse easier, more modular, and more composible. We're not quite ready to talk about this, though we hope to soon.</p>

<p>Over the years, there have been a <a href="https://verdagon.dev/grimoire/grimoire">number of memory management techniques tried</a>, including many that lie outside of the ones commonly found in languages today. We'd like to explore these more deeply to see which, if any, may help June.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We had the help of dozens of experts in various fields as we brainstormed the initial design for June, and for their contributions, we're thankful. We'd especially like to thank the collaborators who went above and beyond with their time across multiple brainstorming sessions to help June grow to where it is.</p>
<ul>
<li>Andreas Kling</li>
<li>Doug Gregor</li>
<li>Jason Turner</li>
<li>Mads Torgersen</li>
<li>Mae Milano</li>
<li>Steve Francia</li>
</ul>
<p>Also, special thanks to our private beta testers for testing out June and giving us feedback.</p>
<h2 id="checking-it-out">Checking it out</h2>
<p>Documentation on the June language and the June reference compiler are now available via the <a href="https://github.com/sophiajt/june">June repo</a>.</p>
<p>Please note: the reference compiler is pre-alpha quality.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[XLSTM: Extended Long Short-Term Memory (129 pts)]]></title>
            <link>https://arxiv.org/abs/2405.04517</link>
            <guid>40294650</guid>
            <pubDate>Wed, 08 May 2024 05:28:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2405.04517">https://arxiv.org/abs/2405.04517</a>, See on <a href="https://news.ycombinator.com/item?id=40294650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2405.04517">View PDF</a></p><blockquote>
            <span>Abstract:</span>In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models (LLMs). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing LSTMs at scale. We now raise a simple question: How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these LSTM extensions into residual block backbones yields xLSTM blocks that are then residually stacked into xLSTM architectures. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Maximilian Beck [<a href="https://arxiv.org/show-email/ed28509f/2405.04517">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 7 May 2024 17:50:21 UTC (1,455 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Rules Apple Illegally Interrogated Staff and Confiscated Union Flyers (462 pts)]]></title>
            <link>https://www.forbes.com/sites/antoniopequenoiv/2024/05/06/us-labor-board-rules-apple-illegally-interrogated-staff-and-confiscated-union-flyers/</link>
            <guid>40294630</guid>
            <pubDate>Wed, 08 May 2024 05:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/antoniopequenoiv/2024/05/06/us-labor-board-rules-apple-illegally-interrogated-staff-and-confiscated-union-flyers/">https://www.forbes.com/sites/antoniopequenoiv/2024/05/06/us-labor-board-rules-apple-illegally-interrogated-staff-and-confiscated-union-flyers/</a>, See on <a href="https://news.ycombinator.com/item?id=40294630">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Topline</h2>
<p>The National Labor Relations Board <a href="https://www.nlrb.gov/case/02-CA-295979" rel="nofollow noopener noreferrer" target="_blank" title="https://www.nlrb.gov/case/02-CA-295979" data-ga-track="ExternalLink:https://www.nlrb.gov/case/02-CA-295979" aria-label="ruled">ruled</a> Monday that Apple illegally questioned staff of its World Trade Center store in New York City in 2022, affirming findings from a judge who determined employees were specifically questioned over <a href="https://www.bloomberg.com/news/articles/2023-06-21/apple-illegally-interrogated-staff-about-union-judge-rules" rel="nofollow noopener noreferrer" target="_blank" title="https://www.bloomberg.com/news/articles/2023-06-21/apple-illegally-interrogated-staff-about-union-judge-rules" data-ga-track="ExternalLink:https://www.bloomberg.com/news/articles/2023-06-21/apple-illegally-interrogated-staff-about-union-judge-rules" aria-label="their pro-union sympathies">their pro-union sympathies</a>.</p>
<figure role="presentation"><figcaption><fbs-accordion current="-1"><p>Apple has not received any punishment or been ordered to pay damages by the board for the <span data-ga-track="caption expand">... [+]</span><span> violations. (Photo by Gary Hershorn/Getty Images)</span></p></fbs-accordion><small>Getty Images</small></figcaption></figure> 

<h2>Key Facts</h2>
<div>
 <div>
  <p>The board affirmed the decision of administrative law Judge Lauren Esposito, who ruled last year that Apple illegally stopped workers from placing union flyers on a table in the break room of the World Trade Center store, confiscated the flyers and interrogated staff over their “protected concerted activity.”</p>
  
 </div>
 <div>
  <p>Esposito ordered Apple cease and desist from illegally questioning workers about union matters in addition to confiscating union flyers from the store’s employee break room.</p>
  
 </div>
 <div>
  <p>Monday’s ruling is the board’s first decision against Apple, according to <a href="https://www.bloomberg.com/news/articles/2024-05-06/apple-illegally-interrogated-nyc-retail-staff-us-labor-board-rules?srnd=homepage-americas" rel="nofollow noopener noreferrer" target="_blank" title="https://www.bloomberg.com/news/articles/2024-05-06/apple-illegally-interrogated-nyc-retail-staff-us-labor-board-rules?srnd=homepage-americas" data-ga-track="ExternalLink:https://www.bloomberg.com/news/articles/2024-05-06/apple-illegally-interrogated-nyc-retail-staff-us-labor-board-rules?srnd=homepage-americas" aria-label="Bloomberg">Bloomberg</a>, which first reported the ruling and cited agency spokesperson Kayla Blado.</p>
  
 </div>
 <p>The board cannot impose fines or direct punishments against Apple for its violations.</p>
 <p>Apple didn’t immediately respond to Forbes’ request for comment.</p>
</div>
<p><em>Get Forbes Breaking News Text Alerts: We’re launching text message alerts so you'll always know the biggest stories shaping the day’s headlines. Text “Alerts” to (201) 335-0739 or sign up </em><a href="https://joinsubtext.com/forbes" rel="nofollow noopener noreferrer" target="_blank" title="https://joinsubtext.com/forbes" data-ga-track="ExternalLink:https://joinsubtext.com/forbes" aria-label="here"><em data-ga-track="ExternalLink:https://joinsubtext.com/forbes">here</em></a><em>.</em></p>


<h2>Key Background</h2>
<p>Other cases against Apple are still pending, according to Bloomberg, which noted a case in which a National Labor Relations Board member accused the company of illegally excluding unionized workers from certain benefits. Several Apple stores have <a href="https://www.theverge.com/2024/4/10/24126657/apple-store-employees-new-jersey-unionize" rel="nofollow noopener noreferrer" target="_blank" title="https://www.theverge.com/2024/4/10/24126657/apple-store-employees-new-jersey-unionize" data-ga-track="ExternalLink:https://www.theverge.com/2024/4/10/24126657/apple-store-employees-new-jersey-unionize" aria-label="moved to unionize">moved to unionize</a> in recent years including ones in Short Hills, New Jersey, Oklahoma City and Towson, Maryland, with the latter two locations successfully establishing a union. Apple employees outside of the World Trade Center store staffers have also run into opposition while seeking to unionize. The National Labor Relations Board found in late 2022 that Apple hosted mandatory <a href="https://www.bloomberg.com/news/articles/2022-12-05/apple-s-anti-union-tactics-in-atlanta-were-illegal-us-officials-say" rel="nofollow noopener noreferrer" target="_blank" title="https://www.bloomberg.com/news/articles/2022-12-05/apple-s-anti-union-tactics-in-atlanta-were-illegal-us-officials-say" data-ga-track="ExternalLink:https://www.bloomberg.com/news/articles/2022-12-05/apple-s-anti-union-tactics-in-atlanta-were-illegal-us-officials-say" aria-label="anti-union meetings">anti-union meetings</a> at an Atlanta store where management made coercive statements against employees.</p>


<h2>Further Reading</h2>
<p><a href="https://www.bloomberg.com/news/articles/2024-05-06/apple-illegally-interrogated-nyc-retail-staff-us-labor-board-rules?srnd=homepage-americas" rel="nofollow noopener noreferrer" target="_blank" title="https://www.bloomberg.com/news/articles/2024-05-06/apple-illegally-interrogated-nyc-retail-staff-us-labor-board-rules?srnd=homepage-americas" data-ga-track="ExternalLink:https://www.bloomberg.com/news/articles/2024-05-06/apple-illegally-interrogated-nyc-retail-staff-us-labor-board-rules?srnd=homepage-americas" aria-label="Apple Illegally Interrogated NYC Retail Staff, US Labor Board Rules">Apple Illegally Interrogated NYC Retail Staff, US Labor Board Rules</a> (Bloomberg)</p>
<p><a href="https://www.theverge.com/2024/4/10/24126657/apple-store-employees-new-jersey-unionize" rel="nofollow noopener noreferrer" target="_blank" title="https://www.theverge.com/2024/4/10/24126657/apple-store-employees-new-jersey-unionize" data-ga-track="ExternalLink:https://www.theverge.com/2024/4/10/24126657/apple-store-employees-new-jersey-unionize" aria-label="Apple Store employees in New Jersey are trying to unionize">Apple Store employees in New Jersey are trying to unionize</a> (The Verge)</p>
</div><div><p><span>Follow me on&nbsp;</span><a href="https://www.twitter.com/pequeno04" rel="nofollow noopener noreferrer" target="_blank">Twitter</a>&nbsp;or&nbsp;<a href="https://www.linkedin.com/in/antonio-peque%C3%B1o-iv/" rel="nofollow noopener noreferrer" target="_blank">LinkedIn</a>.&nbsp;<span>Send me a secure&nbsp;<a href="https://www.forbes.com/tips/" rel="nofollow noopener noreferrer" target="_blank">tip</a></span>.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The C++ Iceberg (110 pts)]]></title>
            <link>https://fouronnes.github.io/cppiceberg/</link>
            <guid>40294555</guid>
            <pubDate>Wed, 08 May 2024 05:12:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fouronnes.github.io/cppiceberg/">https://fouronnes.github.io/cppiceberg/</a>, See on <a href="https://news.ycombinator.com/item?id=40294555">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Why use ECC? (2015) (150 pts)]]></title>
            <link>https://danluu.com/why-ecc/</link>
            <guid>40293943</guid>
            <pubDate>Wed, 08 May 2024 03:02:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danluu.com/why-ecc/">https://danluu.com/why-ecc/</a>, See on <a href="https://news.ycombinator.com/item?id=40293943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Jeff Atwood, perhaps the most widely read programming blogger, has a post that makes <a rel="nofollow" href="http://blog.codinghorror.com/to-ecc-or-not-to-ecc/">a case against using ECC memory</a>. My read is that his major points are:</p> <ol> <li>Google didn't use ECC when they built their servers in 1999</li> <li>Most RAM errors are hard errors and not soft errors</li> <li>RAM errors are rare because hardware has improved</li> <li>If ECC were actually important, it would be used everywhere and not just servers. Paying for optional stuff like this is "awfully enterprisey"</li> </ol>  <p>Let's take a look at these arguments one by one:</p> <h2 id="1-google-didn-t-use-ecc-in-1999">1. Google didn't use ECC in 1999</h2> <p>Not too long after Google put these non-ECC machines into production, they realized this was a serious error and not worth the cost savings. If you think cargo culting what Google does is a good idea because it's Google, here are some things you might do:</p> <h4 id="a-put-your-servers-into-shipping-containers">A. Put your servers into shipping containers.</h4> <p>Articles are still written today about what a great idea this is, even though this was an experiment at Google that was deemed unsuccessful. Turns out, even Google's experiments don't always succeed. In fact, their propensity for “moonshots” in the early days meannt that they had more failed experiments that most companies. Copying their failed experiments isn't a particularly good strategy.</p> <h4 id="b-cause-fires-in-your-own-datacenters">B. Cause fires in your own datacenters</h4> <p>Part of the post talks about how awesome these servers are:</p> <blockquote> <p>Some people might look at these early Google servers and see an amateurish fire hazard. Not me. I see a prescient understanding of how inexpensive commodity hardware would shape today's internet. I felt right at home when I saw this server; it's exactly what I would have done in the same circumstances</p> </blockquote> <p>The last part of that is true. But the first part has a grain of truth, too. When Google started designing their own boards, one generation had a regrowth<sup id="fnref:R"><a rel="footnote" href="#fn:R">1</a></sup> issue that caused a non-zero number of fires.</p> <p>BTW, if you click through to Jeff's post and look at the photo that the quote refers to, you'll see that the boards have a lot of flex in them. That caused problems and was fixed in the next generation. You can also observe that the cabling is quite messy, which also caused problems, and was also fixed in the next generation. There were other problems as well. <abbr title="When someone looks in the answer key and says, 'I would've come up with that', that's often plausible when their answer is perfect. But when they say that after seeing a specific imperfect answer, it's a bit less plausible that they'd reproduce the exact same mistakes">Jeff's argument here appears to be that, if he were there at the time, he would've seen the exact same opportunities that early Google enigneers did, and since Google did this, it must've been the right thing even if it doesn't look like it. But, a number of things that make it look like not the right thing actually made it not the right thing.</abbr></p> <h4 id="c-make-servers-that-injure-your-employees">C. Make servers that injure your employees</h4> <p>One generation of Google servers had infamously sharp edges, giving them the reputation of being made of “razor blades and hate”.</p> <h4 id="d-create-weather-in-your-datacenters">D. Create weather in your datacenters</h4> <p>From talking to folks at a lot of large tech companies, it seems that most of them have had a climate control issue resulting in clouds or fog in their datacenters. You might call this a clever plan by Google to reproduce Seattle weather so they can poach MS employees. Alternately, it might be a plan to create literal cloud computing. Or maybe not.</p> <p>Note that these are all things Google tried and then changed. Making mistakes and then fixing them is common in every successful engineering organization. If you're going to cargo cult an engineering practice, you should at least cargo cult current engineering practices, not <a href="https://danluu.com/butler-lampson-1999/">something that was done in 1999</a>.</p> <p>When Google used servers without ECC back in 1999, they found a number of symptoms that were ultimately due to memory corruption, including a search index that returned effectively random results to queries. The actual failure mode here is instructive. I often hear that it's ok to ignore ECC on these machines because it's ok to have errors in individual results. But even when you can tolerate occasional errors, ignoring errors means that you're exposing yourself to total corruption, unless you've done a very careful analysis to make sure that a single error can only contaminate a single result. In research that's been done on filesystems, it's been repeatedly shown that despite making valiant attempts at creating systems that are robust against a single error, it's extremely hard to do so and basically every heavily tested filesystem can have a massive failure from a single error (<a href="https://danluu.com/file-consistency/">see the output of Andrea and Remzi's research group at Wisconsin if you're curious about this</a>). I'm not knocking filesystem developers here. They're better at that kind of analysis than 99.9% of programmers. It's just that this problem has been repeatedly shown to be hard enough that humans cannot effectively reason about it, and automated tooling for this kind of analysis is still far from a push-button process. In their book on <a href="http://www.morganclaypool.com/doi/abs/10.2200/S00516ED2V01Y201306CAC024">warehouse scale computing</a>, Google discusses error correction and detection and ECC is cited as their slam dunk case for when it's obvious that you should use hardware error correction<sup id="fnref:P"><a rel="footnote" href="#fn:P">2</a></sup>.</p> <p>Google has great infrastructure. From what I've heard of the infra at other large tech companies, Google's sounds like the best in the world. But that doesn't mean that you should copy everything they do. Even if you look at their good ideas, it doesn't make sense for most companies to copy them. They <a href="https://danluu.com/intel-cat/">created a replacement for Linux's work stealing scheduler that uses both hardware run-time information and static traces to allow them to take advantage of new hardware in Intel's server processors that lets you dynamically partition caches between cores</a>. If used across their entire fleet, that could easily save Google more money in a week than stackexchange has spent on machines in their entire history. Does that mean you should copy Google? No, not unless you've already captured all the lower hanging fruit, which includes things like making sure that your core infrastructure is written in highly optimized C++, not Java or (god forbid) Ruby. And the thing is, for the vast majority of companies, writing in a language that imposes a 20x performance penalty is a totally reasonable decision.</p> <h2 id="2-most-ram-errors-are-hard-errors">2. Most RAM errors are hard errors</h2> <p>The case against ECC quotes <a href="http://selse.org//images/selse_2012/Papers/selse2012_submission_4.pdf">this section of a study on DRAM errors</a> (the bolding is Jeff's):</p> <blockquote> <p>Our study has several main findings. First, we find that approximately <strong>70% of DRAM faults are recurring (e.g., permanent) faults, while only 30% are transient faults.</strong> Second, we find that large multi-bit faults, such as faults that affects an entire row, column, or bank, constitute over 40% of all DRAM faults. Third, we find that almost 5% of DRAM failures affect board-level circuitry such as data (DQ) or strobe (DQS) wires. Finally, we find that chipkill functionality reduced the system failure rate from DRAM faults by 36x.</p> </blockquote> <p>This seems to betray a lack of understanding of the implications of this study, as this quote doesn't sound like an argument against ECC; it sounds like an argument for "chipkill", a particular class of ECC. Putting that aside, Jeff's post points out that hard errors are twice as common as soft errors, and then mentions that they run memtest on their machines when they get them. First, a 2:1 ratio isn't so large that you can just ignore soft errors. Second the post implies that Jeff believes that hard errors are basically immutable and can't surface after some time, which is incorrect. You can think of electronics as wearing out just the same way mechanical devices wear out. The mechanisms are different, but the effects are similar. In fact, if you compare reliability analysis of chips vs. other kinds of reliability analysis, you'll find they often use the same families of distributions to model failures. And, if hard errors were immutable, they would generally get caught in testing by the manufacturer, who can catch errors much more easily than consumers can because they have hooks into circuits that let them test memory much more efficiently than you can do in your server or home computer. Third, Jeff's line of reasoning implies that ECC can't help with detection or correction of hard errors, which is not only incorrect but directly contradicted by the quote.</p> <p>So, how often are you going to run memtest on your machines to try to catch these hard errors, and how much data corruption are you willing to live with? One of the key uses of ECC is not to correct errors, but to signal errors so that hardware can be replaced before silent corruption occurs. No one's going to consent to shutting down everything on a machine every day to run memtest (that would be more expensive than just buying ECC memory), and even if you could convince people to do that, it won't catch as many errors as ECC will.</p> <p>When I worked at a company that owned about 1000 machines, we noticed that we were getting strange consistency check failures, and after maybe half a year we realized that the failures were more likely to happen on some machines than others. The failures were quite rare, maybe a couple times a week on average, so it took a substantial amount of time to accumulate the data, and more time for someone to realize what was going on. Without knowing the cause, analyzing the logs to figure out that the errors were caused by single bit flips (with high probability) was also non-trivial. We were lucky that, as a side effect of the process we used, the checksums were calculated in a separate process, on a different machine, at a different time, so that an error couldn't corrupt the result and propagate that corruption into the checksum. If you merely try to protect yourself with in-memory checksums, there's a good chance you'll perform a checksum operation on the already corrupted data and compute a valid checksum of bad data unless you're doing some really fancy stuff with calculations that carry their own checksums (and if you're that serious about error correction, you're probably using ECC regardless). Anyway, after completing the analysis, we found that memtest couldn't detect any problems, but that replacing the RAM on the bad machines caused a one to two order of magnitude reduction in error rate. Most services don't have this kind of checksumming we had; those services will simply silently write corrupt data to persistent storage and never notice problems until a customer complains.</p> <h2 id="3-due-to-advances-in-hardware-manufacturing-errors-are-very-rare">3. Due to advances in hardware manufacturing, errors are very rare</h2> <p>Jeff says</p> <blockquote> <p>I do seriously question whether ECC is as operationally critical as we have been led to believe [for servers], and I think the data shows modern, non-ECC RAM is already extremely reliable ... Modern commodity computer parts from reputable vendors are amazingly reliable. And their trends show from 2012 onward essential PC parts have gotten more reliable, not less. (I can also vouch for the improvement in SSD reliability as we have had zero server SSD failures in 3 years across our 12 servers with 24+ drives ...</p> </blockquote> <p>and quotes a study.</p> <p>The data in the post isn't sufficient to support this assertion. Note that since RAM usage has been increasing and continues to increase at a fast exponential rate, RAM failures would have to decrease at a greater exponential rate to actually reduce the incidence of data corruption. Furthermore, as chips continue shrink, features get smaller, making the kind of wearout issues discussed in “2” more common. For example, at 20nm, a DRAM capacitor might hold something like 50 electrons, and that number will get smaller for next generation DRAM and things continue to shrink.</p> <p>The <a href="http://selse.org//images/selse_2012/Papers/selse2012_submission_4.pdf">2012 study that Atwood quoted</a> has this graph on corrected errors (a subset of all errors) on ten randomly selected failing nodes (6% of nodes had at least one failure):</p> <p><img src="https://danluu.com/images/why-ecc/one_month_ecc_errors.png"></p> <p>We're talking between 10 and 10k errors for a typical node that has a failure, and that's a cherry-picked study from a post that's arguing that you don't need ECC. Note that the nodes here only have 16GB of RAM, which is an order of magnitude less than modern servers often have, and that this was on an older process node that was less vulnerable to noise than we are now. For anyone who's used to dealing with reliability issues and just wants to know the FIT rate, the study finds a FIT rate of between 0.057 and 0.071 faults per Mbit (which, contra Atwood's assertion, is not a shockingly low number). If you take the most optimistic FIT rate, .057, and do the calculation for a server without much RAM (here, I'm using 128GB, since the servers I see nowadays typically have between 128GB and 1.5TB of RAM)., you get an expected value of .057 * 1000 * 1000 * 8760 / 1000000000 = .5 faults per year per server. Note that this is for faults, not errors. From the graph above, we can see that a fault can easily cause hundreds or thousands of errors per month. Another thing to note is that there are multiple nodes that don't have errors at the start of the study but develop errors later on. So, in fact, the cherry-picked study that Jeff links contradicts Jeff's claim about reliability.</p> <p>Sun/Oracle famously ran into this a number of decades ago. Transistors and DRAM capacitors were getting smaller, much as they are now, and memory usage and caches were growing, much as they are now. Between having smaller transistors that were less resilient to transient upset as well as more difficult to manufacture, and having more on-chip cache, the vast majority of server vendors decided to add ECC to their caches. Sun decided to save a few dollars and skip the ECC. The direct result was that a number of Sun customers reported sporadic data corruption. It took Sun multiple years to spin a new architecture with ECC cache, and Sun made customers sign an NDA to get replacement chips. Of course there's no way to cover up this sort of thing forever, and when it came up, Sun's reputation for producing reliable servers took a permanent hit, much like the time they tried to <a href="https://danluu.com/anon-benchmark/">cover up poor performance results by introducing a clause into their terms of services disallowing benchmarking</a>.</p> <p>Another thing to note here is that when you're paying for ECC, you're not just paying for ECC, you're paying for parts (CPUs, boards) that have been qual'd more thoroughly. You can easily see this with disk failure rates, and I've seen many people observe this in their own private datasets. In terms of public data, I believe Andrea and Remzi's group had a SIGMETRICS paper a few years back that showed that SATA drives were 4x more likely than SCSI drives to have disk read failures, and 10x more likely to have silent data corruption. This relationship held true even with drives from the same manufacturer. There's no particular reason to think that the SCSI interface should be more reliable than the SATA interface, but it's not about the interface. It's about buying a high-reliability server part vs. a consumer part. Maybe you don't care about disk reliability in particular because you checksum everything and can easily detect disk corruption, but there are some kinds of corruption that are harder to detect.</p> <p>[2024 update, almost a decade later]: looking at this retrospectively, we can see that Jeff's assertion that commodity parts are reliable, "modern commodity computer parts from reputable vendors are amazingly reliable" is still not true. Looking at real-world user data from Firefox, <a href="https://fosstodon.org/@gabrielesvelto/112401643131904845">Gabriele Svelto estimated that approximately 10% to 20% of all Firefox crashes were due to memory corruption</a>. Various game companies that track this kind of thing also report a significant fraction of user crashes appear to be due to data corruption, although I don't have an estimate from any of those companies handy. A more direct argument is that if you talk to folks at big companies that run a lot of ECC memory and look at the rate of ECC errors, there are quite a few errors detected by ECC memory despite ECC memory typically having a lower error rate than random non-ECC memory. This kind of argument is frequently made (here, it was detailed above a decade ago, and when I looked at this when I worked at Twitter fairly recently and there has not been a revolution in memory technology that has reduced the need for ECC over the rates discussed in papers a decade ago), but it often doesn't resontate with folks who say things like "well, those bits probably didn't matter anyway", "most memory ends up not getting read", etc. Looking at real-world crashes and noting that the amount of silent data corruption should be expected to be much higher than the rate of crashes seems to resonate with people who aren't excited by looking at raw FIT rates in datacenters.</p> <h2 id="4-if-ecc-were-actually-important-it-would-be-used-everywhere-and-not-just-servers">4. If ECC were actually important, it would be used everywhere and not just servers.</h2> <p><a href="https://danluu.com/cocktail-ideas/">One way to rephrase this is as a kind of cocktail party efficient markets hypothesis. This can't be important, because if it was, we would have it</a>. Of course this is incorrect and there are many things that would be beneficial to consumers that we don't have, such as <a href="https://danluu.com/car-safety/">cars that are designed to safe instead of just getting the maximum score in crash tests</a>. Looking at this with respect to the server and consumer markets, this argument can be rephrased as “If this feature were actually important for servers, it would be used in non-servers”, which is incorrect. A primary driver of what's available in servers vs. non-servers is what can be added that buyers of servers will pay a lot for, to allow for price discrimination between server and non-server parts. This is actually one of the more obnoxious problems facing large cloud vendors — hardware vendors are able to jack up the price on parts that have server features because the features are much more valuable in server applications than in desktop applications. Most home users don't mind, giving hardware vendors a mechanism to extract more money out of people who buy servers while still providing cheap parts for consumers.</p> <p>Cloud vendors often have enough negotiating leverage to get parts at cost, but that only works where there's more than one viable vendor. Some of the few areas where there aren't any viable competitors include CPUs and GPUs. There have been a number of attempts by CPU vendors to get into the server market, but each attempt so far has been fatally flawed in a way that made it obvious from an early stage that the attempt was doomed (and these are often 5 year projects, so that's a lot of time to spend on a doomed project). The Qualcomm effort has been getting a lot of hype, but when I talk to folks I know at Qualcomm they all tell me that the current chip is basically for practice, since Qualcomm needed to learn how to build a server chip from all the folks they poached from IBM, and that the next chip is the first chip that has any hope of being competitive. I have high hopes for Qualcomm as well an ARM effort to build good server parts, but those efforts are still a ways away from bearing fruit.</p> <p>The near total unsuitability of current ARM (and POWER) options (not including hypothetical variants of Apple's impressive ARM chip) for most server workloads in terms of performance per TCO dollar is a bit of a tangent, so I'll leave that for another post, but the point is that Intel has the market power to make people pay extra for server features, and they do so. Additionally, some features are genuinely more important for servers than for mobile devices with a few GB of RAM and a power budget of a few watts that are expected to randomly crash and reboot periodically anyway.</p> <h2 id="conclusion">Conclusion</h2> <p>Should you buy ECC RAM? That depends. For servers, it's probably a good bet considering the cost, although it's hard to really do a cost/benefit analysis because it's really hard to figure out the cost of silent data corruption, or the cost of having some risk of burning half a year of developer time tracking down intermittent failures only to find that the were caused by using non-ECC memory.</p> <p>For normal desktop use, I'm pro-ECC, but if you don't have <a href="https://www.reddit.com/r/programming/comments/adoux/coding_horror_and_blogsstackoverflowcom/">regular backups</a> set up, doing backups probably has a better ROI than ECC. But once you have the absolute basics set up, there's a fairly strong case for ECC for consumer machines. For example, if you have backups without ECC, you can easily write corrupt data into your primary store and replicate that corrupt data into backup. But speaking more generally, big companies running datacenters are probably better set up to detect data corruption and more likely to have error correction at higher levels that allow them to recover from data corruption than consumers, so the case for consumers is arguably stronger than it is for servers, where the case is strong enough that's generally considered a no brainer. A major reason consumers don't generally use ECC isn't that it isn't worth it for them, it's that they just have no idea how to attribute crashes and data corruption when they happen. Once you start doing this, as Google and other large companies do, it's immediately obvious that ECC is worth the cost even when you have multiple levels of error correction operating at higher levels.</p> <h3 id="appendix-security">Appendix: security</h3> <p>If you allow any sort of code execution, even sandboxed execution, there are attacks <a href="https://en.wikipedia.org/wiki/Row_hammer">like rowhammer</a> which can allow users to cause data corruption and there have been instances where this has allowed for privilege escalation. ECC doesn't completely mitigate the attack, but it makes it much harder.</p> <p><small> Thanks to Prabhakar Ragde, Tom Murphy, Jay Weisskopf, Leah Hanson, Joe Wilder, and Ralph Corderoy for discussion/comments/corrections. Also, thanks (or maybe anti-thanks) to Leah for convincing me that I should write up this off the cuff verbal comment as a blog post. Apologies for any errors, the lack of references, and the stilted prose; this is basically a transcription of half of a conversation and I haven't explained terms, provided references, or checked facts in the level of detail that I normally do. </small></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Revokes Intel, Qualcomm Licenses to Sell Chips to Huawei (110 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-05-07/us-revokes-intel-qualcomm-licenses-to-sell-chips-to-huawei</link>
            <guid>40293614</guid>
            <pubDate>Wed, 08 May 2024 01:55:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-05-07/us-revokes-intel-qualcomm-licenses-to-sell-chips-to-huawei">https://www.bloomberg.com/news/articles/2024-05-07/us-revokes-intel-qualcomm-licenses-to-sell-chips-to-huawei</a>, See on <a href="https://news.ycombinator.com/item?id=40293614">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Decker: A fantastic reincarnation of HyperCard with 1-bit graphics (266 pts)]]></title>
            <link>https://www.beyondloom.com/decker/index.html</link>
            <guid>40292181</guid>
            <pubDate>Tue, 07 May 2024 22:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.beyondloom.com/decker/index.html">https://www.beyondloom.com/decker/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=40292181">Hacker News</a></p>
<div id="readability-page-1" class="page"><h2>Decker</h2>

<p>Decker is a multimedia platform for creating and sharing interactive documents, with sound, images, hypertext, and scripted behavior. You can try it in your web browser <b><a href="https://www.beyondloom.com/decker/tour.html">right now</a></b>.</p>

<center>
	<a href="https://www.beyondloom.com/decker/tour.html"><img src="https://www.beyondloom.com/decker/images/wings.gif"></a>
</center>

<p>Decker builds on the legacy of <a href="https://en.wikipedia.org/wiki/HyperCard">HyperCard</a> and the visual aesthetic of classic MacOS. It retains the simplicity and ease of learning that HyperCard provided, while adding many subtle and overt quality-of-life improvements, like deep undo history, support for scroll wheels and touchscreens, more modern keyboard navigation, and bulk editing operations.</p>

<p>Anyone can use Decker to create E-Zines, organize their notes, give presentations, build adventure games, or even just doodle some 1-bit pixel art. The holistic "ditherpunk" aesthetic is cozy, a bit nostalgic, and provides fun and distinctive creative constraints. As a prototyping tool, Decker encourages embracing a sketchy, imperfect approach. Finished decks can be saved as standalone <fixed>.html</fixed> documents which self-execute in a web browser and can be shared anywhere you can host or embed a web page. Decker also runs natively on MacOS, Windows, and Linux.</p>

<p>For more complex projects, Decker features a novel scripting language named <i>Lil</i> which is strongly influenced by both <a href="http://www.lua.org/">Lua</a>, an imperative language popular for embedding in tools and game engines, and <a href="https://en.wikipedia.org/wiki/Q_%28programming_language_from_Kx_Systems%29">Q</a>, a functional language in the APL family used with time-series databases. Lil is easy to learn and conventional enough not to ruffle any feathers for users with prior programming experience, but also includes pleasant surprises like implicit scalar-vector arithmetic and an integrated SQL-like query language. A few lines of Lil can go a long way.</p>

<center>
	<img src="https://www.beyondloom.com/decker/images/calc.gif">
</center>

<p>Decker provides a small collection of built-in interactive widgets for building interfaces, as well as a facility for <a href="https://www.beyondloom.com/decker/decker.html#customwidgets">defining new ones</a>. Custom widgets and their definitions can be copied and pasted using the system clipboard, which also makes it possible to share them anywhere you can share or store text. Every deck is a toolkit of reusable parts that can be harvested and repurposed for another project.</p>

<center>
	<img src="https://www.beyondloom.com/decker/images/contrap.gif">
</center>

<p>Decker is command-line friendly: when built from source, it comes with <a href="https://www.beyondloom.com/decker/lilt.html">Lilt</a>, a standalone Lil interpreter which can (among other things) read, write, manipulate, and even execute Decker documents "headlessly". Lilt has even fewer dependencies than Decker itself, so it can also be compiled as a cross-platform <a href="https://justine.lol/ape.html">APE executable</a>, ready for writing run-anywhere shell scripts. Would you believe there's a Lil interpreter <a href="https://www.beyondloom.com/blog/lila.html">that runs on POSIX AWK</a>? Decks are stored in a line-oriented text format which interoperates well with existing source control tools like Git and SVN.</p>

<p>Decker includes no advertising, telemetry, gamification, or other intrusions on user privacy and autonomy. If you like Decker, please share it with other people who might enjoy it. Build something that makes you happy.</p>

<h2>Examples</h2>
<ul>
	<li><a href="https://www.beyondloom.com/decker/tour.html">Decker: A Guided Tour</a></li>
	<li><a href="https://www.beyondloom.com/decker/guis.html">5GUIs</a></li>
	<li><a href="https://www.beyondloom.com/decker/chip8.html">A CHIP-8 Interpreter</a></li>
	<li><a href="https://www.beyondloom.com/decker/draggable.html">All About Draggable</a></li>
	<li><a href="https://www.beyondloom.com/decker/sound.html">All About Sound</a></li>
	<li><a href="https://www.beyondloom.com/decker/goofs/sokoban.html">Sokoban: A Block-Pushing Puzzle Game</a></li>
</ul>

<h2>Modules</h2>
<ul>
	<li><a href="https://www.beyondloom.com/decker/plot.html">Plot: Simple Graphs for Decker</a></li>
	<li><a href="https://www.beyondloom.com/decker/zazz.html">Zazz: Animation Helpers for Decker</a></li>
	<li><a href="https://www.beyondloom.com/decker/ease.html">Ease: Easing Functions for Decker</a></li>
	<li><a href="https://www.beyondloom.com/decker/dialog.html">Dialogizer: Visual-Novel Modals for Decker</a></li>
	<li><a href="https://www.beyondloom.com/decker/puppeteer.html">Puppeteer: Visual-Novel Sprite Animation for Decker</a></li>
</ul>

<h2>Documentation</h2>
<ul>
	<li><a href="https://www.beyondloom.com/decker/decker.html">The Decker reference manual</a></li>
	<li><a href="https://www.beyondloom.com/decker/format.html">The Decker document format</a></li>
	<li><a href="https://www.beyondloom.com/decker/lil.html">The Lil programming language</a></li>
	<li><a href="https://www.beyondloom.com/decker/learnlil.html">Learn Lil in 10 Minutes</a></li>
	<li><a href="https://www.beyondloom.com/tools/trylil.html">The Lil playground</a></li>
	<li><a href="https://www.beyondloom.com/decker/lilquickref.html">Lil Quick-reference card</a></li>
	<li><a href="https://www.beyondloom.com/decker/lilt.html">Lilt: the Lil Terminal</a></li>
	<li><a href="https://www.beyondloom.com/blog/responses.html">Decker: Responding to Responses</a></li>
</ul>

<h2>Additional Resources</h2>

<p>Browsable source code and a bug-tracker are available on <a href="https://github.com/JohnEarnest/Decker">GitHub</a>. Decker is free and open-source, under a permissive <a href="https://mit-license.org/">MIT license</a>.</p>

<p>Periodic binary releases for MacOS and Windows are available on <a href="https://internet-janitor.itch.io/decker">Itch.io</a>. The Itch page includes a <a href="https://internet-janitor.itch.io/decker/community">community forum</a> for discussing Decker and sharing projects made with Decker.</p>

<a href="https://www.beyondloom.com/index.html">back</a>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM Granite: A Family of Open Foundation Models for Code Intelligence (203 pts)]]></title>
            <link>https://github.com/ibm-granite/granite-code-models</link>
            <guid>40291598</guid>
            <pubDate>Tue, 07 May 2024 21:16:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ibm-granite/granite-code-models">https://github.com/ibm-granite/granite-code-models</a>, See on <a href="https://news.ycombinator.com/item?id=40291598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/ibm-granite/granite-code-models/blob/main/figures/granite-code-models-3x-v4.png"><img src="https://github.com/ibm-granite/granite-code-models/raw/main/figures/granite-code-models-3x-v4.png"></a>
</p>
<p dir="auto">
  📚 <a href="https://github.com/ibm-granite/granite-code-models/blob/main/paper.pdf">Paper</a>&nbsp; | 🤗 <a href="https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330" rel="nofollow">HugginFace Collection</a>&nbsp; | 
  💬 <a href="https://github.com/orgs/ibm-granite/discussions">Discussions Page</a>&nbsp; | 📰 <a href="http://" rel="nofollow">Blog (coming soon)</a>&nbsp;
<br>
</p><hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction to Granite Code Models</h2><a id="user-content-introduction-to-granite-code-models" aria-label="Permalink: Introduction to Granite Code Models" href="#introduction-to-granite-code-models"></a></p>
<p dir="auto">We introduce the Granite series of decoder-only code models for code generative tasks (e.g., fixing bugs, explaining code, documenting code), trained with code written in 116 programming languages. A comprehensive evaluation of the Granite Code model family on diverse tasks demonstrates that our models consistently reach state-of-the-art performance among available open-source code LLMs.&nbsp;</p>
<p dir="auto">The key advantages of Granite Code models include:</p>
<ul dir="auto">
<li>All-rounder Code LLM: Granite Code models achieve competitive or state-of-the-art performance on different kinds of code-related tasks, including code generation, explanation, fixing, editing, translation, and more. Demonstrating their ability to solve diverse coding tasks.</li>
<li>Trustworthy Enterprise-Grade LLM: All our models are trained on license-permissible data collected following <a href="https://www.ibm.com/impact/ai-ethics" rel="nofollow">IBM's AI Ethics principles</a> and guided by IBM’s Corporate Legal team for trustworthy enterprise usage. We release all our Granite Code models under an <a href="https://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">Apache 2.0 license</a> license for research and commercial use.</li>
</ul>
<p dir="auto">The family of <strong>Granite Code Models</strong> comes in two main variants:</p>
<ul dir="auto">
<li>Granite Code Base Models: base foundational models designed for code-related tasks (e.g., code repair, code explanation, code synthesis).</li>
<li>Granite Code Instruct Models: instruction following models finetuned using a combination of Git commits paired with human instructions and open-source synthetically generated code instruction datasets.</li>
</ul>
<p dir="auto">Both base and instruct models are available in sizes of 3B, 8B, 20B, and 34B parameters.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Data Collection</h2><a id="user-content-data-collection" aria-label="Permalink: Data Collection" href="#data-collection"></a></p>
<p dir="auto">Our process to prepare code pretraining data involves several stages. First, we collect a combination of publicly available datasets (e.g., GitHub Code Clean, Starcoder data), public code repositories, and issues from GitHub. Second, we filter the code data collected based on the programming language in which data is written (which we determined based on file extension). Then, we also filter out data with low code quality. Third, we adopt an aggressive deduplication strategy that includes both exact and fuzzy deduplication to remove documents having (near) identical code content. Finally, we apply a HAP content filter that reduces models' likelihood of generating hateful, abusive, or profane language. We also make sure to redact Personally Identifiable Information (PII) by replacing PII content (e.g., names, email addresses, keys, passwords) with corresponding tokens (e.g., ⟨NAME⟩, ⟨EMAIL⟩, ⟨KEY⟩, ⟨PASSWORD⟩). We also scan all datasets using ClamAV to identify and remove instances of malware in the source code. In addition to collecting code data for model training, we curate several publicly available high-quality natural language datasets for improving the model’s proficiency in language understanding and mathematical reasoning.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pretraining</h2><a id="user-content-pretraining" aria-label="Permalink: Pretraining" href="#pretraining"></a></p>
<p dir="auto">The <strong>Granite Code Base</strong> models are trained on 3-4T tokens of code data and natural language datasets related to code. Data is tokenized via byte pair encoding (BPE), employing the same tokenizer as StarCoder. We utilize high-quality data with two phases of training as follows:</p>
<ul dir="auto">
<li>Phase 1 (code only training): During phase 1, 3B and 8B models are trained for 4 trillion tokens of code data comprising 116 languages. The 20B parameter model is trained on 3 trillion tokens of code. The 34B model is trained on 1.4T tokens after the depth upscaling which is done on the 1.6T checkpoint of 20B model.</li>
<li>Phase 2 (code + language training): In phase 2, we include additional high-quality publicly available data from various domains, including technical, mathematics, and web documents, to further improve the model’s performance. We train all our models for 500B tokens (80% code-20% language mixture) in phase 2 training.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Instruction Tuning</h2><a id="user-content-instruction-tuning" aria-label="Permalink: Instruction Tuning" href="#instruction-tuning"></a></p>
<p dir="auto">Granite Code Instruct models are finetuned on the following types of instruction data: 1) code commits sourced from <a href="https://huggingface.co/datasets/bigcode/commitpackft" rel="nofollow">CommitPackFT</a>, 2) high-quality math datasets, specifically we used <a href="https://huggingface.co/datasets/TIGER-Lab/MathInstruct" rel="nofollow">MathInstruct</a> and <a href="https://huggingface.co/datasets/meta-math/MetaMathQA" rel="nofollow">MetaMathQA</a>, 3) Code instruction datasets such as <a href="https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v3" rel="nofollow">Glaive-Code-Assistant-v3</a>, <a href="https://huggingface.co/datasets/bigcode/self-oss-instruct-sc2-exec-filter-50k" rel="nofollow">Self-OSS-Instruct-SC2</a>, <a href="https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2" rel="nofollow">Glaive-Function-Calling-v2</a>, <a href="https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction" rel="nofollow">NL2SQL11</a> and a small collection of synthetic API calling datasets, and 4) high-quality language instruction datasets such as <a href="https://huggingface.co/datasets/nvidia/HelpSteer" rel="nofollow">HelpSteer</a> and an open license-filtered version of <a href="https://huggingface.co/datasets/garage-bAInd/Open-Platypus" rel="nofollow">Platypus</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Evaluation Results</h2><a id="user-content-evaluation-results" aria-label="Permalink: Evaluation Results" href="#evaluation-results"></a></p>
<p dir="auto">We conduct an extensive evaluation of our code models on a comprehensive list of benchmarks that includes but is not limited to HumanEvalPack, MBPP, and MBPP+. This set of benchmarks encompasses different coding tasks across commonly used programming languages (e.g., Python, JavaScript, Java, Go, C++, Rust).</p>
<p dir="auto">Our findings reveal that Granite Code models outperform strong open-source models across model sizes. The figure below illustrates how <code>Granite-8B-Code-Base</code> outperforms <code>Mistral-7B</code>, <code>LLama-3-8B</code>, and other open-source models in three coding tasks. We provide further evaluation results in our paper.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ibm-granite/granite-code-models/blob/main/figures/GraniteCodeFigure1.jpg"><img src="https://github.com/ibm-granite/granite-code-models/raw/main/figures/GraniteCodeFigure1.jpg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Use our Models?</h2><a id="user-content-how-to-use-our-models" aria-label="Permalink: How to Use our Models?" href="#how-to-use-our-models"></a></p>
<p dir="auto">To use any of our models, pick an appropriate <code>model_path</code> from:</p>
<ol dir="auto">
<li><code>ibm-granite/granite-3b-code-base</code></li>
<li><code>ibm-granite/granite-3b-code-instruct</code></li>
<li><code>ibm-granite/granite-8b-code-base</code></li>
<li><code>ibm-granite/granite-8b-code-instruct</code></li>
<li><code>ibm-granite/granite-20b-code-base</code></li>
<li><code>ibm-granite/granite-20b-code-instruct</code></li>
<li><code>ibm-granite/granite-34b-code-base</code></li>
<li><code>ibm-granite/granite-34b-code-instruct</code></li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Inference</h3><a id="user-content-inference" aria-label="Permalink: Inference" href="#inference"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from transformers import AutoModelForCausalLM, AutoTokenizer

device = &quot;cuda&quot; # or &quot;cpu&quot;
model_path = &quot;ibm-granite/granite-3b-code-base&quot; # pick anyone from above list

tokenizer = AutoTokenizer.from_pretrained(model_path)

# drop device_map if running on CPU
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=device)
model.eval()

# change input text as desired
input_text = &quot;def generate():&quot;
# tokenize the text
input_tokens = tokenizer(input_text, return_tensors=&quot;pt&quot;)

# transfer tokenized inputs to the device
for i in input_tokens:
    input_tokens[i] = input_tokens[i].to(device)

# generate output tokens
output = model.generate(**input_tokens)
# decode output tokens into text
output = tokenizer.batch_decode(output)

# loop over the batch to print, in this example the batch size is 1
for i in output:
    print(i)"><pre><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span>, <span>AutoTokenizer</span>

<span>device</span> <span>=</span> <span>"cuda"</span> <span># or "cpu"</span>
<span>model_path</span> <span>=</span> <span>"ibm-granite/granite-3b-code-base"</span> <span># pick anyone from above list</span>

<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>model_path</span>)

<span># drop device_map if running on CPU</span>
<span>model</span> <span>=</span> <span>AutoModelForCausalLM</span>.<span>from_pretrained</span>(<span>model_path</span>, <span>device_map</span><span>=</span><span>device</span>)
<span>model</span>.<span>eval</span>()

<span># change input text as desired</span>
<span>input_text</span> <span>=</span> <span>"def generate():"</span>
<span># tokenize the text</span>
<span>input_tokens</span> <span>=</span> <span>tokenizer</span>(<span>input_text</span>, <span>return_tensors</span><span>=</span><span>"pt"</span>)

<span># transfer tokenized inputs to the device</span>
<span>for</span> <span>i</span> <span>in</span> <span>input_tokens</span>:
    <span>input_tokens</span>[<span>i</span>] <span>=</span> <span>input_tokens</span>[<span>i</span>].<span>to</span>(<span>device</span>)

<span># generate output tokens</span>
<span>output</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>**</span><span>input_tokens</span>)
<span># decode output tokens into text</span>
<span>output</span> <span>=</span> <span>tokenizer</span>.<span>batch_decode</span>(<span>output</span>)

<span># loop over the batch to print, in this example the batch size is 1</span>
<span>for</span> <span>i</span> <span>in</span> <span>output</span>:
    <span>print</span>(<span>i</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Finetuning</h3><a id="user-content-finetuning" aria-label="Permalink: Finetuning" href="#finetuning"></a></p>
<p dir="auto">Codebase coming soon.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Model Cards</h2><a id="user-content-model-cards" aria-label="Permalink: Model Cards" href="#model-cards"></a></p>
<p dir="auto">The model cards for each model variant are available in their respective HuggingFace repository. Please visit our collection <a href="https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Download our Models?</h2><a id="user-content-how-to-download-our-models" aria-label="Permalink: How to Download our Models?" href="#how-to-download-our-models"></a></p>
<p dir="auto">The model of choice (granite-3b-code-base in this example) can be cloned using:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://huggingface.co/ibm-granite/granite-3b-code-base"><pre>git clone https://huggingface.co/ibm-granite/granite-3b-code-base</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">All Granite Code Models are distributed under <a href="https://github.com/ibm-granite/granite-code-models/blob/main/LICENSE">Apache 2.0</a> license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Would you like to provide feedback?</h2><a id="user-content-would-you-like-to-provide-feedback" aria-label="Permalink: Would you like to provide feedback?" href="#would-you-like-to-provide-feedback"></a></p>
<p dir="auto">Please let us know your comments about our family of code models by visiting our <a href="https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330" rel="nofollow">collection</a>. Select the repository of the model you would like to provide feedback about. Then, go to <em>Community</em> tab, and click on <em>New discussion</em>. Alternatively, you can also post any questions/comments on our <a href="https://github.com/orgs/ibm-granite/discussions">github discussions page</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ScrapeGraphAI: Web scraping using LLM and direct graph logic (172 pts)]]></title>
            <link>https://scrapegraph-doc.onrender.com/</link>
            <guid>40290596</guid>
            <pubDate>Tue, 07 May 2024 19:41:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scrapegraph-doc.onrender.com/">https://scrapegraph-doc.onrender.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40290596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><p><a href="#__docusaurus_skipToContent_fallback">Skip to main content</a></p></div><nav aria-label="Main"><div><div><a href="https://scrapegraph-doc.onrender.com/"><p><img src="https://scrapegraph-doc.onrender.com/img/logo.svg" alt="My Site Logo"><img src="https://scrapegraph-doc.onrender.com/img/logo.svg" alt="My Site Logo"></p><b>Scrapegraph-ai</b></a><p><a href="https://scrapegraph-doc.onrender.com/docs/category/nodes">Documentation</a><a href="https://scrapegraph-doc.onrender.com/docs/activation">Installation of the keys</a></p></div><div><a href="https://github.com/VinciGit00/Scrapegraph-ai" target="_blank" rel="noopener noreferrer">GitHub</a></div></div></nav><div id="__docusaurus_skipToContent_fallback"><header><div><h2>You only scrape once</h2></div></header><main><div><div><h3>Easy to Use</h3><p>Scrapegraph-ai is an open source library for scraping with the use of AI. You just need to activate the API keys and you can scrape thousands of web pages in seconds!</p></div><div><h3>Easy and fast to implement</h3><p>You just have to implment just some lines of code and the work is done</p></div><div><h3>Focus on What Matters</h3><p>With this library you will be able to save hours of time because you have just to setupp the project and the AI will do everything for you</p></div></div></main></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Grateful Dead's Wall of Sound (244 pts)]]></title>
            <link>https://audioacademy.in/the-grateful-deads-wall-of-sound/</link>
            <guid>40289323</guid>
            <pubDate>Tue, 07 May 2024 18:06:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://audioacademy.in/the-grateful-deads-wall-of-sound/">https://audioacademy.in/the-grateful-deads-wall-of-sound/</a>, See on <a href="https://news.ycombinator.com/item?id=40289323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>A vision during an LSD trip is what inspired Owsley “Bear” Stanley, the Grateful Dead’s sound engineer’s mammoth feat of technical engineering, “The Wall of Sound”, irreversibly changing live sound and engineering for the better.</p>
<p>It was a time when live sound problems plagued engineers, bands, and audiences equally. While rock concerts grew in size and scope throughout the 60s, audiences grew larger and louder, without the technical sophistication of amplification ever changing to meet this scenario. Screaming fans meant that low-wattage guitar amps could hardly be heard and without the help of monitoring systems, bands could barely hear themselves play. Things were so bad that the Beatles quit touring in 1966 because they couldn’t hear themselves over the audience. It was after this era that the band, the Grateful Dead, became obsessed with their sound, largely thanks to their eccentric and dedicated sound engineer. Though incredibly frustrated with the noisy, feedback-laden, underpowered situation, they did not want to give up playing live, and the Dead had Owsley on board to help solve the sound situation.</p>
<h4>Who was Bear Owsley?</h4>
<div id="attachment_2627"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-2627" src="https://audioacademy.in/wp-content/uploads/2019/02/owsley1-300x300.jpg" alt="Bear Owsley Stanley" width="300" height="300" srcset="https://audioacademy.in/wp-content/uploads/2019/02/owsley1-300x300.jpg 300w, https://audioacademy.in/wp-content/uploads/2019/02/owsley1-150x150.jpg 150w, https://audioacademy.in/wp-content/uploads/2019/02/owsley1-768x768.jpg 768w, https://audioacademy.in/wp-content/uploads/2019/02/owsley1-350x350.jpg 350w, https://audioacademy.in/wp-content/uploads/2019/02/owsley1.jpg 1024w" sizes="(max-width: 300px) 100vw, 300px"></p><p id="caption-attachment-2627">Owsley Stanley, left, with Jerry Garcia of the Grateful Dead</p></div>
<p>The famous story goes that in 1974 the Grateful Dead drummer Mickey Hart walked on stage to find Owsley “Bear Stanley standing in front of a wall of over 600 speakers with tears streaming down his face. Whispering to the huge mass of equipment, Bear said, “I love you and you love me- how could you fail me?” This story sums up Owsley’s obsession with sound, both as a concept and as a physical thing. A former ballet dancer and craftsman from Kentucky, Owsley was also jailed twice for manufacturing and distributing LSD, the profits of which he used to finance the Grateful Dead for some time. The band which formed in the San Fransico bay area during the hippie days of the mid-1960s boasted of a huge cult following. An engineering dropout, he met the Grateful Dead through Ken Kesey, during one of his infamous ‘acid test’ parties in 1965 and became friends with them.</p>
<p>Owsley, or ‘Bear’, as he became known, began to work with the band as their sound man and financed them with his earnings cooking acid. He was also the person who along with his good friend Bob Thomas, helped design the iconic lightning bolt logo, which would sell countless t-shirts. After a hallucinatory incident, where Owsley ‘saw’ the Grateful Dead’s sound, he became obsessed with aural perfection and started on an endless path, working with the band, to achieve it.</p>
<p>Keeping a sonic journal of each performance of the band, he would use it to improve on his setup and mix for each concert and highlight issues to the band members. He insisted on sound checks and encouraged them to listen to tapes of their performances, so that they could hear how they sounded, and also correct him on what he was doing. Rumored to have taken inspiration Buffalo Springfield’s monitoring setup, Owsley was not satisfied with the standard speakers and amplifiers that were available to him and began modifying and manufacturing his own audio gear with his apprentice Tim Scully, eventually founding the company Alembic.</p>
<p>In a 1969 meeting when brainstorming ideas for musical exploration and solutions for their technical problems and smoking ‘special’ cigarettes, Owsley proposed putting the P.A behind the band. This casual, stoned suggestion would change the way audio engineers thought about concert sound. This meant that the audience and the band would hear the same thing without any delays, chaotic reverb, colliding frequencies, and minimal-to-no feedback. Soon after this, Bear began his most ambitious design to date. He, Dan Healy and Mark Raizene of the Grateful Dead’s sound team collaborated with Ron Wickersham, Rick Turner and John Curl of Alembic to create the legendary Wall of sound.</p>
<h4>The Wall of Sound</h4>
<div id="attachment_2628"><p><img decoding="async" aria-describedby="caption-attachment-2628" src="https://audioacademy.in/wp-content/uploads/2019/02/grateful_dead_wall_of_sound_01-300x200.jpg" alt="wall of sound" width="476" height="317" srcset="https://audioacademy.in/wp-content/uploads/2019/02/grateful_dead_wall_of_sound_01-300x200.jpg 300w, https://audioacademy.in/wp-content/uploads/2019/02/grateful_dead_wall_of_sound_01-768x512.jpg 768w, https://audioacademy.in/wp-content/uploads/2019/02/grateful_dead_wall_of_sound_01.jpg 960w" sizes="(max-width: 476px) 100vw, 476px"></p><p id="caption-attachment-2628">The Wall of Sound, 1973</p></div>
<p>The mammoth structure was massive, made up of over 600 hi-fidelity speakers that sat behind the band as they played. It used six separate sound systems which were able to isolate eleven separate channels with vocals, rhythm guitar, piano each having their own channel. Another channel each for the bass drum, snare, tom-toms, and cymbals. The bass was transmitted through a quadraphonic encoder, which took a signal from each string and projected it through its own set of speakers. The result of each speaker carrying only one instrument or voice at a time was crystal clear audio, free of intermodulation distortion.</p>
<p>The Wall of Sound served as its own monitoring system and solved many, if not all of the technical problems that sound engineers faced at that time. This design was also the first of its kind to eliminate the need for a sound guy, at least at the front of house. In addition to monitor controls, each of the microphones had volume dials. The idea was that each band member could adjust the sound in real time. The situation of the monitors gave the band the power to control their own sound. While the system had many trials and errors, the largest version stood three stories high and about 30 meters wide, the first line array system of this scale ever assembled. High-quality audio could be heard at 200 meters, with decent sound up to another 200 meters, at which point wind started to degrade the audio. The completed Wall of Sound made its debut in 1974.</p>
<p>Some of the early issues that surfaced was problems with feedback between the speakers and the singers’ rear-facing vocal microphones and the giant task of physically mounting the system. It was a logistical nightmare and almost made the band go bankrupt, because almost as soon as it rose the roof, it was time to pull it back down again. Eventually, the massive Wall of Sound had to be streamlined into a far more manageable and cost-effective touring rig. All the same, Owsley and the band’s willingness take ideas and execution to extreme lengths changed live sound forever.</p>
<h4>The Legacy of the Wall of Sound</h4>
<p>While parts of the wall were kept, repurposed and recycled for future touring rigs, other parts were sold off. Legend has it that friends of the Grateful Dead, Hot Tuna and Jefferson Starship quickly bought some of the highly sought-after top-of-the-range gear. While modern improvements in these technologies have the benefit of being far more powerful and lightweight than the Wall’s, in terms of experimental, unrestrained engineering, at a time where there was nothing like it ever heard, the Wall of Sound remains unparalleled.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Convert your Containerfile to a bootable OS (199 pts)]]></title>
            <link>https://github.com/containers/podman-desktop-extension-bootc</link>
            <guid>40289120</guid>
            <pubDate>Tue, 07 May 2024 17:50:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/containers/podman-desktop-extension-bootc">https://github.com/containers/podman-desktop-extension-bootc</a>, See on <a href="https://news.ycombinator.com/item?id=40289120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">BootC (Bootable Container) Extension for Podman Desktop</h2><a id="user-content-bootc-bootable-container-extension-for-podman-desktop" aria-label="Permalink: BootC (Bootable Container) Extension for Podman Desktop" href="#bootc-bootable-container-extension-for-podman-desktop"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-extension-bootc/main/docs/img/logo.png"><img src="https://raw.githubusercontent.com/containers/podman-desktop-extension-bootc/main/docs/img/logo.png" alt=""></a></p>
<p dir="auto">Want to create a bootable operating system from a Containerfile? Download this extension!</p>
<p dir="auto">Easily go from container to VM / ISO-on-a-USB / RAW image!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Topics</h2><a id="user-content-topics" aria-label="Permalink: Topics" href="#topics"></a></p>
<ul dir="auto">
<li><a href="#technology">Technology</a></li>
<li><a href="#bootable-container-images">Bootable Container Images</a></li>
<li><a href="#read-before-using">Read Before Using</a></li>
<li><a href="#example-images">Example Images</a></li>
<li><a href="#use-case">Use Case</a></li>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#contributing">Contributing</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technology</h2><a id="user-content-technology" aria-label="Permalink: Technology" href="#technology"></a></p>
<p dir="auto">The <strong>Bootable Container (bootc)</strong> extension uses <a href="https://github.com/osbuild/bootc-image-builder">bootc-image-builder</a> in order to build bootable <em>container</em> disk images.</p>
<p dir="auto">Once a machine is created from the disk image, it can apply transactional updates "in place" from newly pushed container images (without creating a new disk image). For more information, see <a href="https://containers.github.io/bootc/" rel="nofollow">bootc</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bootable Container Images</h2><a id="user-content-bootable-container-images" aria-label="Permalink: Bootable Container Images" href="#bootable-container-images"></a></p>
<p dir="auto">There are many projects at work at creating "bootc" images. Below is a non-exhaustive list of compatible images which are known to work with <a href="https://github.com/osbuild/bootc-image-builder"><code>bootc-image-builder</code></a>.</p>
<p dir="auto"><strong>CentOS:</strong></p>
<ul dir="auto">
<li>Containerfile: <code>FROM quay.io/centos-bootc/centos-bootc:stream9</code></li>
<li>Repo: <a href="https://quay.io/centos-bootc/centos-bootc" rel="nofollow"><code>quay.io/centos-bootc/centos-bootc:stream9</code></a></li>
<li>Example Images: <a href="https://gitlab.com/fedora/bootc/examples" rel="nofollow">gitlab.com/fedora/bootc/examples</a></li>
<li>Documentation: <a href="https://docs.fedoraproject.org/en-US/bootc/" rel="nofollow">fedoraproject.org</a></li>
<li>Source: <a href="https://github.com/centos/centos-bootc">github.com/centos/centos-bootc</a></li>
<li>Notes: N/A</li>
</ul>
<p dir="auto"><strong>Fedora:</strong></p>
<ul dir="auto">
<li>Containerfile: <code>FROM quay.io/fedora/fedora-bootc:40</code></li>
<li>Repo: <a href="https://quay.io/fedora/fedora-bootc" rel="nofollow"><code>quay.io/fedora/fedora-bootc:40</code></a></li>
<li>Example Images: <a href="https://gitlab.com/fedora/bootc/examples" rel="nofollow">gitlab.com/fedora/bootc/examples</a></li>
<li>Documentation: <a href="https://docs.fedoraproject.org/en-US/bootc/" rel="nofollow">fedoraproject.org</a></li>
<li>Source: <a href="https://gitlab.com/fedora/bootc/base-images" rel="nofollow">gitlab.com/fedora/bootc/base-images</a></li>
<li>Notes: Must select "XFS" or "EXT4" for the root filesystem when building in the GUI. <a href="https://docs.fedoraproject.org/en-US/bootc/default-rootfs-type/" rel="nofollow">Read more here.</a></li>
</ul>
<p dir="auto"><strong>RHEL:</strong></p>
<ul dir="auto">
<li>Containerfile: <code>FROM registry.redhat.io/rhel9/rhel-bootc:9.4</code></li>
<li>Repo: <a href="https://catalog.redhat.com/search?gs&amp;q=bootc" rel="nofollow"><code>registry.redhat.io/rhel9/rhel-bootc:9.4</code></a></li>
<li>Documentation: <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/using_image_mode_for_rhel_to_build_deploy_and_manage_operating_systems/index#doc-wrapper" rel="nofollow">Red Hat Customer Portal</a></li>
</ul>
<p dir="auto">The images can then be added to your Containerfile:</p>
<div dir="auto" data-snippet-clipboard-copy-content="FROM quay.io/centos-bootc/centos-bootc:stream9"><pre><span>FROM</span> quay.io/centos-bootc/centos-bootc:stream9</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Learning more</h3><a id="user-content-learning-more" aria-label="Permalink: Learning more" href="#learning-more"></a></p>
<ul dir="auto">
<li><a href="https://docs.fedoraproject.org/en-US/bootc/building-containers/" rel="nofollow">Fedora Building Containers Guide</a>: provides an overview on how to create Fedora/CentOS-derived bootc images.</li>
<li><a href="https://containers.github.io/bootc/building/guidance.html" rel="nofollow">Bootc General Guidance</a>: provides a general configuration overview for bootc images.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Read Before Using</h2><a id="user-content-read-before-using" aria-label="Permalink: Read Before Using" href="#read-before-using"></a></p>
<p dir="auto">Some concepts to grasp before using.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>Think of it as an OS provisioning tool!</strong></h3><a id="user-content-think-of-it-as-an-os-provisioning-tool" aria-label="Permalink: Think of it as an OS provisioning tool!" href="#think-of-it-as-an-os-provisioning-tool"></a></p>
<p dir="auto">You are "creating" an OS straight from a Containerfile, isn't that awesome?</p>
<p dir="auto"><strong>FIRST</strong> realize that you are creating an OS with all your applications, developer tools, even games that you want.</p>
<p dir="auto"><strong>SECONDLY</strong> ask yourself what applications you want to have running (perhaps on boot too!).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Creating your first bootable OS Containerfile</h3><a id="user-content-creating-your-first-bootable-os-containerfile" aria-label="Permalink: Creating your first bootable OS Containerfile" href="#creating-your-first-bootable-os-containerfile"></a></p>
<p dir="auto">Want a quick straight-to-the-point Hello World Containerfile?</p>
<div dir="auto" data-snippet-clipboard-copy-content="FROM quay.io/centos-bootc/centos-bootc:stream9
# Change your root password for a &quot;test login&quot; that
# allows to log in on a virtual/physical console
# NOTE: While some base images may set `PermitRootLogin prohibit-password`
# for OpenSSH, not all will.
# This is VERY dangerous and only meant for Hello World purposes.
RUN echo &quot;root:root&quot; | chpasswd"><pre><span>FROM</span> quay.io/centos-bootc/centos-bootc:stream9
<span><span>#</span> Change your root password for a "test login" that</span>
<span><span>#</span> allows to log in on a virtual/physical console</span>
<span><span>#</span> NOTE: While some base images may set `PermitRootLogin prohibit-password`</span>
<span><span>#</span> for OpenSSH, not all will.</span>
<span><span>#</span> This is VERY dangerous and only meant for Hello World purposes.</span>
<span>RUN</span> echo <span>"root:root"</span> | chpasswd</pre></div>
<p dir="auto">After creating your image you can now login and explore your bootable OS.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example images</h2><a id="user-content-example-images" aria-label="Permalink: Example images" href="#example-images"></a></p>
<p dir="auto">Want to view more example images Such as <a href="https://gitlab.com/bootc-org/examples/-/tree/main/httpd" rel="nofollow"><code>httpd</code></a> and <a href="https://gitlab.com/bootc-org/examples/-/tree/main/nvidia" rel="nofollow"><code>nvidia</code></a>?</p>
<p dir="auto">All of our maintained example images are on the <a href="https://gitlab.com/fedora/bootc/examples" rel="nofollow">gitlab.com/fedora/bootc/examples</a> repo.</p>
<p dir="auto">You can also pull our example image based on the <a href="https://gitlab.com/bootc-org/examples/-/tree/main/httpd" rel="nofollow"><code>httpd</code></a> example:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/clicking_pull.gif"><img src="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/clicking_pull.gif" alt="" data-animated-image=""></a></p>
<p dir="auto">After building, read our <a href="https://github.com/containers/podman-desktop-extension-bootc/blob/main/docs/vm_guide.md">Virtual Machine Guide</a> on how to launch your image and access your HTTP server.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use Case</h2><a id="user-content-use-case" aria-label="Permalink: Use Case" href="#use-case"></a></p>
<p dir="auto">Go from a <a href="https://containers.github.io/bootc/" rel="nofollow">bootc</a> compatible derived container build to a disk image format:</p>
<ul dir="auto">
<li><code>qcow2</code>: QEMU Disk Images</li>
<li><code>ami</code>: Amazon Machine Images</li>
<li><code>raw</code>: RAW disk image an MBR or GPT partition table</li>
<li><code>iso</code>: Unattended installation method (USB sticks / install-on-boot)</li>
<li><code>vmdk</code>: Usable in vSphere</li>
</ul>
<p dir="auto">The list above is what is supported by the underlying <code>bootc-image-builder</code> technology. The list can <a href="https://github.com/osbuild/bootc-image-builder?tab=readme-ov-file#-image-types">be found here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Requirement 1. Software and hardware requirements</h3><a id="user-content-requirement-1-software-and-hardware-requirements" aria-label="Permalink: Requirement 1. Software and hardware requirements" href="#requirement-1-software-and-hardware-requirements"></a></p>
<p dir="auto"><strong>OS:</strong></p>
<p dir="auto">Compatible on Windows, macOS &amp; Linux</p>
<p dir="auto"><strong>Software:</strong></p>
<ul dir="auto">
<li><a href="https://github.com/containers/podman-desktop">Podman Desktop 1.10.0+</a></li>
<li><a href="https://github.com/containers/podman">Podman 5.0.1+</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Requirement 2. Rootful mode on Podman Machine</h3><a id="user-content-requirement-2-rootful-mode-on-podman-machine" aria-label="Permalink: Requirement 2. Rootful mode on Podman Machine" href="#requirement-2-rootful-mode-on-podman-machine"></a></p>
<p dir="auto">Podman Machine requirements:</p>
<ul dir="auto">
<li><strong>Rootful mode enabled</strong></li>
<li><em>At least</em> 6GB of RAM allocated in order to build the disk image</li>
</ul>
<p dir="auto">Rootful mode can be enabled through the CLI to an already deployed VM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="podman machine stop
podman machine set --rootful
podman machine start"><pre>podman machine stop
podman machine <span>set</span> --rootful
podman machine start</pre></div>
<p dir="auto">Or set when initially creating a Podman Machine via Podman Desktop:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-extension-bootc/main/docs/img/rootful_setup.png"><img src="https://raw.githubusercontent.com/containers/podman-desktop-extension-bootc/main/docs/img/rootful_setup.png" alt="rootful setup"></a></p>
<p dir="auto"><strong>Linux users:</strong></p>
<p dir="auto">On Linux, you are unable to create a Podman Machine through the GUI of Podman Desktop, to create a rootful Podman Machine you can run the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="podman machine init --rootful
podman machine start"><pre>podman machine init --rootful
podman machine start</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">This extension can be installed through the <strong>Extensions</strong> section of Podman Desktop within the <strong>Catalog</strong> tab:</p>
<ol dir="auto">
<li>Go to <strong>Extensions</strong> in the navbar.</li>
<li>Click on the <strong>Catalog</strong> tab.</li>
<li>Install the extension.</li>
</ol>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/catalog_install.gif"><img src="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/catalog_install.gif" alt="" data-animated-image=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nightly version</h3><a id="user-content-nightly-version" aria-label="Permalink: Nightly version" href="#nightly-version"></a></p>
<p dir="auto">A version of the extension using the latest commit changes can be installed via the <strong>Install custom...</strong> button with the following link:</p>
<div data-snippet-clipboard-copy-content="ghcr.io/containers/podman-desktop-extension-bootc:nightly"><pre><code>ghcr.io/containers/podman-desktop-extension-bootc:nightly
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li><strong>Build your bootc-enabled Containerfile:</strong></li>
</ol>
<blockquote>
<p dir="auto">In the example below, we are going to change the root password for testing purposes when accessing the OS.</p>
</blockquote>
<div dir="auto" data-snippet-clipboard-copy-content="FROM quay.io/centos-bootc/centos-bootc:stream9

# Change the root password
# CAUTION: This is NOT recommended and is used only for testing / hello world purposes
RUN echo &quot;root:root&quot; | chpasswd"><pre><span>FROM</span> quay.io/centos-bootc/centos-bootc:stream9

<span><span>#</span> Change the root password</span>
<span><span>#</span> CAUTION: This is NOT recommended and is used only for testing / hello world purposes</span>
<span>RUN</span> echo <span>"root:root"</span> | chpasswd</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/build_image.gif"><img src="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/build_image.gif" alt="" data-animated-image=""></a></p>
<ol start="2" dir="auto">
<li><strong>Build the disk image:</strong></li>
</ol>
<blockquote>
<p dir="auto">Build the disk image, this takes approximatley 2-5 minutes depending on the performance of your machine.</p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/bootc_building.gif"><img src="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/bootc_building.gif" alt="" data-animated-image=""></a></p>
<ol start="3" dir="auto">
<li><strong>Launching the VM:</strong></li>
</ol>
<blockquote>
<p dir="auto">See our <a href="https://github.com/containers/podman-desktop-extension-bootc/blob/main/docs/vm_guide.md">Virtual Machine Guide</a> on how to launch the image!</p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/os_booting.gif"><img src="https://raw.githubusercontent.com/containers/podman-desktop-media/bootc-extension/gifs/os_booting.gif" alt="" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Preferences</h2><a id="user-content-preferences" aria-label="Permalink: Preferences" href="#preferences"></a></p>
<p dir="auto">Preferences such as the default <code>bootc-builder-image</code> as well as timeouts can be adjusted within the <strong>Preferences</strong> section of Podman Desktop.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/containers/podman-desktop-extension-bootc/main/docs/img/preferences.png"><img src="https://raw.githubusercontent.com/containers/podman-desktop-extension-bootc/main/docs/img/preferences.png" alt=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Want to help develop and contribute to the bootc extension? View our <a href="https://github.com/containers/podman-desktop-extension-bootc/blob/main/CONTRIBUTING.md">CONTRIBUTING</a> document.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook just updated its relationship status with Web Components (128 pts)]]></title>
            <link>https://www.mux.com/blog/facebook-just-updated-it-s-relationship-status-with-web-components</link>
            <guid>40288947</guid>
            <pubDate>Tue, 07 May 2024 17:38:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mux.com/blog/facebook-just-updated-it-s-relationship-status-with-web-components">https://www.mux.com/blog/facebook-just-updated-it-s-relationship-status-with-web-components</a>, See on <a href="https://news.ycombinator.com/item?id=40288947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As our friend of the blog, Wes Bos, pointed out the other day, React 19 (beta) added, all the way at the bottom of the announcement, much-awaited <a href="https://react.dev/blog/2024/04/25/react-19#support-for-custom-elements">support for web components</a>.</p><div data-theme="light"><article><p><span>Tucked all the way at the bottom on the React 19 release notes is full support for web components!  🥳 </span></p></article></div><p>I say “much-awaited”, but the truth is a lot of people are not going to care at all about that. There are some, though, like us who really care and have been paying close attention.</p><p>At Mux we have not been shy about our fondness for web components over the last few years. It started with building Mux Player on our <a href="https://www.mux.com/blog/media-chrome-turns-1-0">web components-based player framework Media Chrome</a> (thanks for the <a href="https://twitter.com/jhooks/status/1785410152025543065">kind words about Media Chrome</a>, Joel).</p><p>But I want to drive home one point about our fondness for web components. It’s not about some righteous party line, which so many front-end tooling debates devolve into. If you came to this post for some juicy nerd drama, turn around because that’s not what we’re here for. <a href="https://www.mux.com/blog/slow-is-stable-stable-is-fast-building-mux-player-on-the-slow-platform-of-web-components">Our adoption of web components is purely based on practicality</a>. Nothing more, and nothing less. Is it the best tool for every job? Obviously not. But we believe it is the best tool for the job of building a framework-agnostic video player SDK. We still use React heavily. In fact, we were early adopters of <a href="https://www.mux.com/blog/what-are-react-server-components">React Server Components and wrote about it</a> in Darius’s widely circulated post.</p><h2 id="so-what-does-this-mean-for-react-actually"><a href="#so-what-does-this-mean-for-react-actually"><span><span><svg role="img" xmlns="http://www.w3.org/2000/svg" width="42" height="42" fill="none" viewBox="0 0 42 42"><title>Link</title><path d="m18.172 15.343 3.535-3.535a5 5 0 0 1 7.071 0l1.414 1.414a5 5 0 0 1 0 7.07l-3.535 3.536M23.828 26.657l-3.535 3.535a5 5 0 0 1-7.071 0l-1.414-1.414a5 5 0 0 1 0-7.07l3.535-3.536" vector-effect="non-scaling-stroke"></path><path stroke-linecap="round" d="m25.243 16.757-8.486 8.486" vector-effect="non-scaling-stroke"></path></svg></span></span>So what does this mean for React, actually?</a></h2><p>To contrast all the positives about building SDKs on web components, React support has been by far the biggest hurdle to clear for web components projects. Raw web components have always <strong>worked</strong> in React (it’s just HTML, after all), but the challenge was more about the ergonomics of using web components in a React world.</p><p>For example, React developers don't interact directly with HTML elements to do things like add event listeners and call functions. It sort of goes against the declarative nature of React itself.</p><p>So although setting up an event listener was possible, like this, it feels very un-React-y:</p><div><figure><figcaption><p>jsx</p></figcaption><pre><code><span></span><span>function</span> <span>MyComponent</span> <span>(</span><span>)</span> <span>{</span>
<span></span>  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>null</span><span>)</span><span>;</span>
<span></span>  <span>const</span> <span>[</span>count<span>,</span> setCount<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span><span>;</span>
<span></span>
<span></span>  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
<span></span>    <span>function</span> <span>handleClick</span> <span>(</span><span>)</span> <span>{</span>
<span></span>      <span>setCount</span><span>(</span>count <span>+</span> <span>1</span><span>)</span>
<span></span>    <span>}</span>
<span></span>    <span>if</span> <span>(</span>ref<span>)</span> <span>{</span>
<span></span>       ref<span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> handleClick<span>)</span><span>;</span>
<span></span>    <span>}</span>
<span></span>    <span>return</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
<span></span>      ref<span>.</span><span>removeEventListener</span><span>(</span><span>'click'</span><span>,</span> handleClick<span>)</span><span>;</span>
<span></span>    <span>}</span>
<span></span>  <span>}</span><span>,</span> <span>[</span>ref<span>]</span><span>)</span><span>;</span>
<span></span>
<span></span>  <span>return</span> <span><span><span>&lt;</span>my-button</span> <span>ref</span><span><span>=</span><span>{</span>ref<span>}</span></span><span>&gt;</span></span><span>Hello! </span><span>{</span>count<span>}</span><span><span><span>&lt;/</span>my-button</span><span>&gt;</span></span>
<span></span><span>}</span></code></pre></figure></div><p>Because of this, most maintainers (us included), have chosen to create React-specific wrappers. That works well, but it always felt like a stop-gap. Now that React 19 supports web components directly, you can do things like pass event listeners as React props and React props passed to the element get automatically set as properties on the element. There’s some extra complexity here for web component authors to handle attributes vs. properties. Not all web components will play nice with React from day 1, but at least we have a path forward.</p><p>See here, this feels much more React-y:</p><div><figure><figcaption><p>jsx</p></figcaption><pre><code><span></span><span>function</span> <span>MyComponent</span> <span>(</span><span>)</span> <span>{</span>
<span></span>  <span>const</span> <span>[</span>count<span>,</span> setCount<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span><span>;</span>
<span></span>
<span></span>  <span>return</span> <span>(</span>
<span></span>    <span>&lt;</span>my<span>-</span>button
<span></span>      ref<span>=</span><span>{</span>ref<span>}</span>
<span></span>      onClick<span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setCount</span><span>(</span>count <span>+</span> <span>1</span><span>)</span><span>}</span>
<span></span>     <span>&gt;</span>
<span></span>       Hello<span>!</span> <span>{</span>count<span>}</span>
<span></span>     <span><span><span>&lt;/</span>my-button</span><span>&gt;</span></span>
<span></span>  <span>)</span>
<span></span><span>}</span></code></pre></figure></div><p>Internally, all React is doing here is taking the onClick prop and setting up/tearing down the click handler under the hood. Which is basically what React wrappers were doing anyway.</p><p>I’m hoping that in 1 or 2 short years from now your average React developer will not be weirded out or averse to using a web component in their React application. And once that feels normal perhaps we can thank those old React wrappers for bringing us joy and then do away with them.</p><h2 id="it-still-might-be-a-little-weird"><a href="#it-still-might-be-a-little-weird"><span><span><svg role="img" xmlns="http://www.w3.org/2000/svg" width="42" height="42" fill="none" viewBox="0 0 42 42"><title>Link</title><path d="m18.172 15.343 3.535-3.535a5 5 0 0 1 7.071 0l1.414 1.414a5 5 0 0 1 0 7.07l-3.535 3.536M23.828 26.657l-3.535 3.535a5 5 0 0 1-7.071 0l-1.414-1.414a5 5 0 0 1 0-7.07l3.535-3.536" vector-effect="non-scaling-stroke"></path><path stroke-linecap="round" d="m25.243 16.757-8.486 8.486" vector-effect="non-scaling-stroke"></path></svg></span></span>It still might be a little weird</a></h2><p>Event handlers and passing React props into web components is a nice improvement, but I think there’s still one weird thing about web components that doesn’t quite jive with the React way of doing things, and that’s the globally scoped element register.</p><p>In any React app, when you use a component, you have to import that component:</p><div><figure><figcaption><p>jsx</p></figcaption><pre><code><span></span><span>// when MyThing is a react component</span>
<span></span><span>import</span> MyThing <span>from</span> <span>'./components/my-thing'</span></code></pre></figure></div><p>But that doesn’t exist in the web components world (at least not yet). When you use &lt;my-button&gt; in a React component, you don’t have to explicitly import my-button from anywhere inside that file.</p><div><figure><figcaption><p>jsx</p></figcaption><pre><code><span></span><span>// when my-thing defines a web component is imported it gets registered globally</span>
<span></span><span>import</span> <span>'./components/my-thing'</span></code></pre></figure></div><p>Web components get imported and registered at the global level. This also means if two different libraries have a component called my-button, you can’t use both of them. This will certainly be a little weird for React developers to get used to. It also might change with <a href="https://github.com/WICG/webcomponents/blob/gh-pages/proposals/Scoped-Custom-Element-Registries.md">Scope Custom Element Registries in the future</a>.</p><h2 id="dont-sleep-on-web-awesome-either"><a href="#dont-sleep-on-web-awesome-either"><span><span><svg role="img" xmlns="http://www.w3.org/2000/svg" width="42" height="42" fill="none" viewBox="0 0 42 42"><title>Link</title><path d="m18.172 15.343 3.535-3.535a5 5 0 0 1 7.071 0l1.414 1.414a5 5 0 0 1 0 7.07l-3.535 3.536M23.828 26.657l-3.535 3.535a5 5 0 0 1-7.071 0l-1.414-1.414a5 5 0 0 1 0-7.07l3.535-3.536" vector-effect="non-scaling-stroke"></path><path stroke-linecap="round" d="m25.243 16.757-8.486 8.486" vector-effect="non-scaling-stroke"></path></svg></span></span>Don’t sleep on Web Awesome, either</a></h2><p>One other web components topic caught my eye last week. <a href="https://shoelace.style/">Shoelace</a>, one of the premier web components projects, launched a Kickstarter project for <a href="https://www.kickstarter.com/projects/fontawesome/web-awesome">Web Awesome</a> after being acquired by Font Awesome. With a modest goal of $30,000, the campaign gained the pledges of <a href="https://www.kickstarter.com/projects/fontawesome/web-awesome">6,725 backers for a total of $723,004</a>, nearly 25x the original goal. And I don’t think that’s all hype – I think there’s a reliable signal here that developers want a stable set of tools, built on browser standards.</p><h2 id="lets-see-how-things-pan-out"><a href="#lets-see-how-things-pan-out"><span><span><svg role="img" xmlns="http://www.w3.org/2000/svg" width="42" height="42" fill="none" viewBox="0 0 42 42"><title>Link</title><path d="m18.172 15.343 3.535-3.535a5 5 0 0 1 7.071 0l1.414 1.414a5 5 0 0 1 0 7.07l-3.535 3.536M23.828 26.657l-3.535 3.535a5 5 0 0 1-7.071 0l-1.414-1.414a5 5 0 0 1 0-7.07l3.535-3.536" vector-effect="non-scaling-stroke"></path><path stroke-linecap="round" d="m25.243 16.757-8.486 8.486" vector-effect="non-scaling-stroke"></path></svg></span></span>Let’s see how things pan out</a></h2><p>That’s all for now, we’ll see how things pan out. I, for one, am happy to see the React ecosystem moving in this direction. And I believe the general frontend ecosystem is criminally under-indexed on web components. All web application developers can benefit by moving parts of their applications away from framework-specific patterns and more towards browser-level standards. Frameworks will come and go, so as developers and maintainers we build against them at our own risk. Browser standards tend to come, albeit slowly, and then rarely disappear after that.</p><p>Right now the plan is to wait and see. In the short term, we’ll keep maintaining our React wrappers. It’s all going to depend on if React developers, as a general population, start embracing web components and start feeling comfortable using them in their applications. We want our component libraries to feel great and idiomatic wherever they’re used…and we hope one day soon that could just mean web components.</p></div><div><h2>Leave your wallet <br>where it is</h2><p>No credit card required to get started.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Road resurfacing during the daytime without stopping traffic [video] (788 pts)]]></title>
            <link>https://www.youtube.com/watch?v=ymyIEGRw4-U</link>
            <guid>40287020</guid>
            <pubDate>Tue, 07 May 2024 15:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=ymyIEGRw4-U">https://www.youtube.com/watch?v=ymyIEGRw4-U</a>, See on <a href="https://news.ycombinator.com/item?id=40287020">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Linux When? (219 pts)]]></title>
            <link>https://zed.dev/blog/zed-decoded-linux-when</link>
            <guid>40286959</guid>
            <pubDate>Tue, 07 May 2024 15:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/zed-decoded-linux-when">https://zed.dev/blog/zed-decoded-linux-when</a>, See on <a href="https://news.ycombinator.com/item?id=40286959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><header></header><p>Take a look at this:</p>
<div><figure><img src="https://zed.dev/img/post/zed-decoded-linux-when/linux_screenshot_1.png" alt="Screenshot of Zed — but where are the red/yellow/green window controls?"><figcaption>Screenshot of Zed — but where are the red/yellow/green window controls?</figcaption></figure></div>
<p>Does anything stick out? Yes, exactly, it's a screenshot of Zed running <em>on Linux</em>!</p>
<p>Wait, what? Zed on Linux? Is it released yet? No, it's not, but it's taking shape, fast.</p>
<p>At the end of January <a href="https://zed.dev/blog/zed-is-now-open-source">we open-sourced Zed</a> and had zero Linux support. Now, three months later, you can <a href="https://github.com/zed-industries/zed/blob/main/docs/src/development/linux.md">compile &amp; run</a> Zed on Linux and actually use it. And I mean <em>really</em> use it — I've worked in Zed (on Zed!) the whole last week without any problems.</p>
<p>The words "alpha release" seem to appear at the end of the tunnel. We're getting closer.</p>
<p>Today we're going to talk about how Zed on Linux took shape, what the challenges were, who did the work, and what's still left to do.</p>
<!-- -->
<div><div><p><b>Companion Video</b>: <!-- -->Linux when?</p><p>This post comes with a 1hr companion video, in which Thorsten and Mikayla explore Zed on Linux, dig through the codebase to see how it's implemented, talk about implementation challenges, and how the open-source community helped out big time.</p><p>Watch the video here:<!-- --> <a href="https://youtu.be/O5XVVnA2LoY">https://youtu.be/O5XVVnA2LoY</a></p></div><p><img src="https://zed.dev/img/post/zed-decoded-linux-when/thumbnail.jpg" width="230" height="150"></p></div>
<h2 id="why-not-linux-from-the-start-or-the-tricky-thing-about-platforms"><span data-br=":R97brrrqbf9la:" data-brr="1">Why not Linux from the start? Or: the Tricky Thing About Platforms</span></h2>
<p>Why didn't Zed work on Linux out of the box? That's not an unreasonable thing to ask and many of you did. After all, Zed's written in Rust, a language that's known for its cross-platform support. So if Rust programs can run on macOS, Linux, and Windows, why didn't Zed?</p>
<p>The tricky thing about cross-platform support is that — in general and in Rust — it only works as long as you're fine with the platform being abstracted away, hidden behind an API that is the same on every platform.</p>
<p>At Zed, though, we want to use each platform as best as we can to build a high-performance application that is and <em>feels</em> native to the platform. That often means talking directly to the platform, in order to use it to the best of its abilities.</p>
<p>On macOS, for example, Zed makes direct use of <a href="https://developer.apple.com/metal/">Metal</a>. We have our <a href="https://github.com/zed-industries/zed/blob/main/crates/gpui/src/platform/mac/shaders.metal">own shaders</a>, our <a href="https://github.com/zed-industries/zed/blob/593f0e0c3ef08da7e528230867526dcb77e723fa/crates/gpui/src/platform/mac/metal_renderer.rs">own renderer</a>, and we put <a href="https://zed.dev/blog/120fps">a lot of effort into understanding macOS APIs to get to 120FPS</a>. Zed on macOS <a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform/mac/platform.rs#L66">is also a fully-native AppKit NSApplication</a> and we integrated <a href="https://zed.dev/blog/zed-decoded-async-rust">our async Rust runtime with macOS' native application runtime</a>.</p>
<p>If you want your application to have this level of depth and control over its platform integration <em>and</em> have it be cross-platform, what you'll need to build is a framework. A framework that allows you to talk directly to the platform whenever you need, but otherwise abstract it away from you so you don't have to worry about it when you write application-level code.</p>
<p>That's what Zed did. The framework is called <a href="https://www.gpui.rs/">GPUI</a> and when we released it as open-source, along with Zed, it came with cross-platform support. Except not really.</p>
<h2 id="gpuis-cross-platform-support"><span data-br=":Rg7brrrqbf9la:" data-brr="1">GPUI's cross platform support</span></h2>
<p>GPUI does abstract away the underlying platform and assumes there's more in the world than macOS. Here are parts of <a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform.rs#L95-L162">GPUI's <code>Platform</code> trait</a>, which is all a GPUI application has to interact with:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>trait</span><span> Platform</span><span>: '</span><span>static</span><span> {</span></span>
<span data-line=""><span>    // [... some methods left out to keep this short ...]</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> background_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>BackgroundExecutor</span><span>;</span></span>
<span data-line=""><span>    fn</span><span> foreground_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>ForegroundExecutor</span><span>;</span></span>
<span data-line=""><span>    fn</span><span> text_system</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Arc</span><span>&lt;</span><span>dyn</span><span> PlatformTextSystem</span><span>&gt;;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> run</span><span>(&amp;</span><span>self</span><span>, </span><span>on_finish_launching</span><span>: </span><span>Box</span><span>&lt;</span><span>dyn</span><span> '</span><span>static</span><span> + </span><span>FnOnce</span><span>()&gt;);</span></span>
<span data-line=""><span>    fn</span><span> quit</span><span>(&amp;</span><span>self</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> restart</span><span>(&amp;</span><span>self</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> hide</span><span>(&amp;</span><span>self</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> displays</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Vec</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>dyn</span><span> PlatformDisplay</span><span>&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> open_window</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>,</span></span>
<span data-line=""><span>        handle</span><span>: </span><span>AnyWindowHandle</span><span>,</span></span>
<span data-line=""><span>        options</span><span>: </span><span>WindowParams</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Box</span><span>&lt;</span><span>dyn</span><span> PlatformWindow</span><span>&gt;;</span></span>
<span data-line=""><span>    fn</span><span> window_appearance</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>WindowAppearance</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> open_url</span><span>(&amp;</span><span>self</span><span>, </span><span>url</span><span>: &amp;</span><span>str</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> on_open_urls</span><span>(&amp;</span><span>self</span><span>, </span><span>callback</span><span>: </span><span>Box</span><span>&lt;</span><span>dyn</span><span> FnMut</span><span>(</span><span>Vec</span><span>&lt;</span><span>String</span><span>&gt;)&gt;);</span></span>
<span data-line=""><span>    fn</span><span> register_url_scheme</span><span>(&amp;</span><span>self</span><span>, </span><span>url</span><span>: &amp;</span><span>str</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>Result</span><span>&lt;()&gt;&gt;;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> prompt_for_paths</span><span>(&amp;</span><span>self</span><span>, </span><span>options</span><span>: </span><span>PathPromptOptions</span><span>, ) -&gt; </span><span>oneshot</span><span>::</span><span>Receiver</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>PathBuf</span><span>&gt;&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> prompt_for_new_path</span><span>(&amp;</span><span>self</span><span>, </span><span>directory</span><span>: &amp;</span><span>Path</span><span>) -&gt; </span><span>oneshot</span><span>::</span><span>Receiver</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>PathBuf</span><span>&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> reveal_path</span><span>(&amp;</span><span>self</span><span>, </span><span>path</span><span>: &amp;</span><span>Path</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>    fn</span><span> local_timezone</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>UtcOffset</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> set_cursor_style</span><span>(&amp;</span><span>self</span><span>, </span><span>style</span><span>: </span><span>CursorStyle</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> write_to_clipboard</span><span>(&amp;</span><span>self</span><span>, </span><span>item</span><span>: </span><span>ClipboardItem</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> read_from_clipboard</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Option</span><span>&lt;</span><span>ClipboardItem</span><span>&gt;;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> write_credentials</span><span>(&amp;</span><span>self</span><span>, </span><span>url</span><span>: &amp;</span><span>str</span><span>, </span><span>username</span><span>: &amp;</span><span>str</span><span>, </span><span>password</span><span>: &amp;[</span><span>u8</span><span>]) -&gt; </span><span>Task</span><span>&lt;</span><span>Result</span><span>&lt;()&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> read_credentials</span><span>(&amp;</span><span>self</span><span>, </span><span>url</span><span>: &amp;</span><span>str</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>Result</span><span>&lt;</span><span>Option</span><span>&lt;(</span><span>String</span><span>, </span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;)&gt;&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> delete_credentials</span><span>(&amp;</span><span>self</span><span>, </span><span>url</span><span>: &amp;</span><span>str</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>Result</span><span>&lt;()&gt;&gt;;</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>This <code>Platform</code> offers nearly everything an application might want to do: execute work on different threads, start/stop the application, manage windows, open URLs, open system dialogues to open files and directories, cursor style, clipboard, credentials, ... and a few more things that I left out to keep this succinct.</p>
<p>From the start, GPUI has had this <code>Platform</code> abstraction built-in. GPUI never was macOS-only. It was always platform-agnostic, as long as the <code>Platform</code> trait is implemented for the platform.</p>
<p>And that's essentially what it meant to get Zed running on Linux: implement <code>Platform</code> for Linux.</p>
<p>So, just implemented a bunch of methods and then Zed works on any platform? Well... yes, kind of.</p>
<p>Here's what the Linux <code>Platform</code> implementation <a href="https://github.com/zed-industries/zed/blob/266988adea954cd759525cc7222e261536c25fd1/crates/gpui/src/platform/linux/platform.rs#L99-L281">looked like in the middle of February</a>. Again, in excerpts:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/linux/platform.rs @ 266988adea</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> Platform</span><span> for</span><span> LinuxPlatform</span><span> {</span></span>
<span data-line=""><span>    // [... some methods left out to keep this short ...]</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> background_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>BackgroundExecutor</span><span> {</span></span>
<span data-line=""><span>        self</span><span>.inner.background_executor.</span><span>clone</span><span>()</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> foreground_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>        self</span><span>.inner.foreground_executor.</span><span>clone</span><span>()</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> text_system</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Arc</span><span>&lt;</span><span>dyn</span><span> PlatformTextSystem</span><span>&gt; {</span></span>
<span data-line=""><span>        self</span><span>.inner.text_system.</span><span>clone</span><span>()</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> run</span><span>(&amp;</span><span>self</span><span>, </span><span>on_finish_launching</span><span>: </span><span>Box</span><span>&lt;</span><span>dyn</span><span> FnOnce</span><span>()&gt;) {</span></span>
<span data-line=""><span>        self</span><span>.client.</span><span>run</span><span>(</span><span>on_finish_launching</span><span>)</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> quit</span><span>(&amp;</span><span>self</span><span>) {</span></span>
<span data-line=""><span>        self</span><span>.inner.state.</span><span>lock</span><span>().quit_requested = </span><span>true</span><span>;</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    //todo!(linux)</span></span>
<span data-line=""><span>    fn</span><span> restart</span><span>(&amp;</span><span>self</span><span>) {}</span></span>
<span data-line=""> </span>
<span data-line=""><span>    //todo!(linux)</span></span>
<span data-line=""><span>    fn</span><span> hide</span><span>(&amp;</span><span>self</span><span>) {}</span></span>
<span data-line=""> </span>
<span data-line=""><span>    //todo!(linux)</span></span>
<span data-line=""><span>    fn</span><span> unhide_other_apps</span><span>(&amp;</span><span>self</span><span>) {}</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> prompt_for_new_path</span><span>(&amp;</span><span>self</span><span>, </span><span>directory</span><span>: &amp;</span><span>Path</span><span>) -&gt; </span><span>oneshot</span><span>::</span><span>Receiver</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>PathBuf</span><span>&gt;&gt; {</span></span>
<span data-line=""><span>        unimplemented!</span><span>()</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> reveal_path</span><span>(&amp;</span><span>self</span><span>, </span><span>path</span><span>: &amp;</span><span>Path</span><span>) {</span></span>
<span data-line=""><span>        unimplemented!</span><span>()</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    //todo!(linux)</span></span>
<span data-line=""><span>    fn</span><span> write_to_clipboard</span><span>(&amp;</span><span>self</span><span>, </span><span>item</span><span>: </span><span>ClipboardItem</span><span>) {}</span></span>
<span data-line=""> </span>
<span data-line=""><span>    //todo!(linux)</span></span>
<span data-line=""><span>    fn</span><span> read_from_clipboard</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Option</span><span>&lt;</span><span>ClipboardItem</span><span>&gt; { </span><span>None</span><span> }</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>Some methods implemented, some marked with <code>todo!</code>, others panicking with an <code>unimplemented!()</code>. Back in February this file had 11 <code>todo!</code> comments and 9 calls to <code>unimplemented</code>.</p>
<p><a href="https://github.com/zed-industries/zed/blob/593f0e0c3ef08da7e528230867526dcb77e723fa/crates/gpui/src/platform/linux/platform.rs#L99-L281">Now</a> it has 9 <code>todo!</code>s (different ones) and the word <code>unimplemented</code> in a string.</p>
<p>So, yes, the work was getting rid of the <code>todo!</code>s and implementing the missing methods. But we all know: not all methods are created equal.</p>
<p>While a <code>write_to_clipboard</code> method seems relatively straightforward to implement, things weren't as easy as the lower-case <code>todo!</code> and its defiantly cute exclamation mark might suggest.</p>
<h2 id="which-linux-are-you-talking-about"><span data-br=":Rt7brrrqbf9la:" data-brr="1">Which Linux are you talking about?</span></h2>
<p>A big challenge when building a GUI application for Linux is that there is no such thing as Linux, really. Linux is a kernel and when you install and run it, you're mostly likely doing that through a Linux distribution that gives you the rest of the operating system too: Ubuntu, Debian, CentOS, Arch, Gentoo, and so on.</p>
<p>They nearly all differ in some aspects that are relevant for an application developer. Example: package management. Distributions not only have their own format with which to distribute applications, but they also have different ways of managing dependencies. And there's no standard across distributions (but of course there are <a href="https://xkcd.com/927/">competing standards</a>). So far, with Zed, we've avoided the whole packaging topic and just focused on building <code>.tar.gz</code> archives that others can then turn into distribution-specific packages. But just scrolling through <a href="https://pkgs.tailscale.com/stable">Tailscale's Packages site</a> tells us that there's a lot of work to do that we never had to do for macOS.</p>
<p>But even if you focus on only one distribution, say Ubuntu, you still have to decide: do you support X11 or Wayland? Both are — ignoring some technical details (don't send me angry letters) — display servers with which Linux software can draw things on the screen. X11 has been around for a long, long time and Wayland has been trying to replace it, also for a long, long time. That, in turn, makes the question a trick question: you have to support both. They're both widely used. <em>Still used</em> in the case of X11 and <em>gaining users</em> in the case of Wayland, but it's not realistic that 100% of Linux users will be on Wayland anytime soon.</p>
<p>After deciding to support Ubuntu and X11 and Wayland, the next question is: which desktop environment or window manager are you going to support? KDE or GNOME? Qt or GTK? What about tiling window managers and users that want to turn window decorations off? Which <em>audio server</em> are you going to support to get audio calls working? PipeWire? Or still PulseAudio? Do you even have to worry about that or is that choice dictated by the desktop environment you chose?</p>
<p>I could probably go on and find more "actually, there's more than one of X" to list, but you get the point: when building a graphical application to run on Linux, you have to make quite a few technical decisions about which platform combinations to target and how.</p>
<p>And we haven't even touched on the most fundamental of all of these decisions yet: how do we render Zed?</p>
<h2 id="from-metal-to-what"><span data-br=":R147brrrqbf9la:" data-brr="1">From Metal to... what?</span></h2>
<p>Even if you knew how to package your application, and how to target X11 and/or Wayland, and managed to open an application window in them — how do you draw your application in that window?</p>
<p>You might have missed it, but in the <code>Platform</code> trait above, there's a method to open a new window:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>trait</span><span> Platform</span><span>: '</span><span>static</span><span> {</span></span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> open_window</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>,</span></span>
<span data-line=""><span>        handle</span><span>: </span><span>AnyWindowHandle</span><span>,</span></span>
<span data-line=""><span>        options</span><span>: </span><span>WindowParams</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Box</span><span>&lt;</span><span>dyn</span><span> PlatformWindow</span><span>&gt;;</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>In order to implement that, you also have to implement the interface of the thing it returns: <code>PlatformWindow</code>. And that packs a punch.</p>
<p>As of right now, <a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform.rs#L189-L241"><code>PlatformWindow</code> requires 37 methods</a> to be implemented. The methods range from hooks (<code>on_close</code>, <code>on_fullscreen</code>) to attributes (<code>is_fullscreen</code>, <code>is_minimized</code>) to bread-and-butter (<code>content_size</code>, <code>mouse_position</code>, <code>toggle_fullscreen</code>) to tricky (<code>scale_factor</code>, <code>appearance</code>).</p>
<p>But there's one method on <code>PlatformWindow</code> that's the most fundamental of them all: <code>draw</code>. Another name for it could be <code>where_the_rubber_hits_the_road</code>. Here is its implementation for macOS:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/mac/window.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> PlatformWindow</span><span> for</span><span> MacWindow</span><span> {</span></span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> draw</span><span>(&amp;</span><span>self</span><span>, </span><span>scene</span><span>: &amp;</span><span>Scene</span><span>) {</span></span>
<span data-line=""><span>        let</span><span> mut</span><span> this</span><span> = </span><span>self</span><span>.</span><span>0.</span><span>lock</span><span>();</span></span>
<span data-line=""><span>        this</span><span>.renderer.</span><span>draw</span><span>(</span><span>scene</span><span>);</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>It doesn't look imposing, but it is: <code>Scene</code> is the result of GPUI rendering a frame and this method, <code>draw</code>, is what makes it appear on the screen.</p>
<p>A <code>Scene</code> is the visible parts of the application —&nbsp;text, windows, borders, rectangles, underlines, and so on — turned into data, <em>primitives</em>. Here's <a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/scene.rs#L15-L28">the definition of <code>Scene</code></a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/scene.rs, simplified</span></span>
<span data-line=""> </span>
<span data-line=""><span>struct</span><span> Scene</span><span> {</span></span>
<span data-line=""><span>    shadows</span><span>: </span><span>Vec</span><span>&lt;</span><span>Shadow</span><span>&gt;,</span></span>
<span data-line=""><span>    quads</span><span>: </span><span>Vec</span><span>&lt;</span><span>Quad</span><span>&gt;,</span></span>
<span data-line=""><span>    paths</span><span>: </span><span>Vec</span><span>&lt;</span><span>Path</span><span>&lt;</span><span>ScaledPixels</span><span>&gt;&gt;,</span></span>
<span data-line=""><span>    underlines</span><span>: </span><span>Vec</span><span>&lt;</span><span>Underline</span><span>&gt;,</span></span>
<span data-line=""><span>    monochrome_sprites</span><span>: </span><span>Vec</span><span>&lt;</span><span>MonochromeSprite</span><span>&gt;,</span></span>
<span data-line=""><span>    polychrome_sprites</span><span>: </span><span>Vec</span><span>&lt;</span><span>PolychromeSprite</span><span>&gt;,</span></span>
<span data-line=""><span>    surfaces</span><span>: </span><span>Vec</span><span>&lt;</span><span>Surface</span><span>&gt;,</span></span>
<span data-line=""><span>    paint_operations</span><span>: </span><span>Vec</span><span>&lt;</span><span>PaintOperation</span><span>&gt;,</span></span>
<span data-line=""><span>    primitive_bounds</span><span>: </span><span>BoundsTree</span><span>&lt;</span><span>ScaledPixels</span><span>&gt;,</span></span>
<span data-line=""><span>    layer_stack</span><span>: </span><span>Vec</span><span>&lt;</span><span>DrawOrder</span><span>&gt;,</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>Shadows, quads, paths, underlines, sprites — that's what GPUI boils your application down to when a frame is rendered. And then, in <code>draw</code>, it hands that data over to the renderer.</p>
<p>And the renderer — that's your GPU.</p>
<p>As I mentioned above: on macOS we use the Metal APIs to talk to the GPU and when you follow the definitions there, you'll end up at <a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform/mac/metal_renderer.rs#L238">a <code>fn draw</code>, implemented on <code>MetalRenderer</code></a>, that contains nearly the complete saga as told in our <a href="https://zed.dev/blog/120fps">120FPS</a> blog post: setting up a rendering pipeline, triple-buffering, syncing up with the OS and the display, all of that.</p>
<p>So how do we implement <code>draw</code> on Linux, without Metal? How do we talk to the GPU on Linux?</p>
<h2 id="enter-stage-the-open-source-hackers"><span data-br=":R1j7brrrqbf9la:" data-brr="1">Enter stage: the open-source hackers</span></h2>
<p>Less than two weeks after Zed going open-source, flying through the cloud of pull requests and issues that's been stirred up by all the excitement comes <a href="https://github.com/kvark">@kvark</a> (Dzmitry Malyshau) with a by now <a href="https://github.com/zed-industries/zed/pull/7343">legendary PR</a> that makes Zed render on Linux. In less than four thousand lines of code. Sure, it didn't render all of Zed yet, but: wow.</p>
<div><figure><img src="https://zed.dev/img/post/zed-decoded-linux-when/kvark_pull_request.png" alt="Screenshot of kvark's pull request that made Zed render on Linux"><figcaption>Screenshot of kvark's pull request that made Zed render on Linux</figcaption></figure></div>
<p>The PR answers the question of how to talk to the GPU on Linux: with <a href="https://github.com/kvark/blade">blade</a>, kvark's "rendering solution for Rust", that offers a "lean low-level GPU abstraction focused at ergonomics and fun". Blade uses <a href="https://en.wikipedia.org/wiki/Vulkan">Vulkan</a> under the hood, a graphics API that's similar to Metal in the level of abstraction it offers, to talk to the GPU and render Zed.</p>
<p>After @kvark opened the PR, Mikayla, Antonio, and Nathan reached out to him to talk about the feasibility of using Blade in Zed and shared goals. It didn't take long to get to a shared understanding and, exactly two weeks after open-sourcing Zed, the PR that made it compile and run on Linux was merged.</p>
<p>With that big TODO and question out of the way, the community jumped on the chance to remove the remaining <code>todo!</code>s: <a href="https://github.com/zed-industries/zed/pulls?q=is%3Apr+author%3Awitelokk">@witelokk added support for Wayland</a>, <a href="https://github.com/zed-industries/zed/pulls?q=is%3Apr+is%3Aclosed+linux+author%3Akvark">@kvark continued his work on getting all of Zed to render smoothly</a>, <a href="https://github.com/zed-industries/zed/pull/7852">@romgrk added support for file dialogues</a>, <a href="https://github.com/zed-industries/zed/pull/9103">@apricobucket28 fixed scrolling and selections</a> and many others <a href="https://github.com/zed-industries/zed/pulls?q=is%3Apr+is%3Aclosed+in%3Atitle+linux">contributed and fixed a lot of other things</a>, with Mikayla diligently reviewing, coding, managing, leading and keeping an eye on everything.</p>
<p>This list of contributions is incomplete and I'm sure I should've mentioned more people, but the point I want to make is this: Zed on Linux was and is an impressive open-source team effort that surprised all of us at Zed with how fast it got Zed to a working state.</p>
<h2 id="zed-on-linux-the-abstractions"><span data-br=":R1q7brrrqbf9la:" data-brr="1">Zed on Linux: the abstractions</span></h2>
<p>Let's take a look at how it works, how X11 and Wayland and Blade are tucked away under the <code>Platform</code> abstraction.</p>
<p>Here's an excerpt:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/linux/platform.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span>&lt;</span><span>P</span><span>: </span><span>LinuxClient</span><span> + '</span><span>static</span><span>&gt; </span><span>Platform</span><span> for</span><span> P</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> background_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>BackgroundExecutor</span><span> {</span></span>
<span data-line=""><span>        self</span><span>.</span><span>with_common</span><span>(|</span><span>common</span><span>| </span><span>common</span><span>.background_executor.</span><span>clone</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> foreground_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>        self</span><span>.</span><span>with_common</span><span>(|</span><span>common</span><span>| </span><span>common</span><span>.foreground_executor.</span><span>clone</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> text_system</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Arc</span><span>&lt;</span><span>dyn</span><span> PlatformTextSystem</span><span>&gt; {</span></span>
<span data-line=""><span>        self</span><span>.</span><span>with_common</span><span>(|</span><span>common</span><span>| </span><span>common</span><span>.text_system.</span><span>clone</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> run</span><span>(&amp;</span><span>self</span><span>, </span><span>on_finish_launching</span><span>: </span><span>Box</span><span>&lt;</span><span>dyn</span><span> FnOnce</span><span>()&gt;) {</span></span>
<span data-line=""><span>        on_finish_launching</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        LinuxClient</span><span>::</span><span>run</span><span>(</span><span>self</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>        self</span><span>.</span><span>with_common</span><span>(|</span><span>common</span><span>| {</span></span>
<span data-line=""><span>            if</span><span> let</span><span> Some</span><span>(</span><span>mut</span><span> fun</span><span>) = </span><span>common</span><span>.callbacks.quit.</span><span>take</span><span>() {</span></span>
<span data-line=""><span>                fun</span><span>();</span></span>
<span data-line=""><span>            }</span></span>
<span data-line=""><span>        });</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    fn</span><span> quit</span><span>(&amp;</span><span>self</span><span>) {</span></span>
<span data-line=""><span>        self</span><span>.</span><span>with_common</span><span>(|</span><span>common</span><span>| </span><span>common</span><span>.signal.</span><span>stop</span><span>());</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p><code>Platform</code> is implemented on <code>LinuxClient</code>, which itself is a trait too:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/linux/platform.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>trait</span><span> LinuxClient</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> with_common</span><span>&lt;</span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>f</span><span>: </span><span>impl</span><span> FnOnce</span><span>(&amp;</span><span>mut</span><span> LinuxCommon</span><span>) -&gt; </span><span>R</span><span>) -&gt; </span><span>R</span><span>;</span></span>
<span data-line=""><span>    fn</span><span> displays</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Vec</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>dyn</span><span> PlatformDisplay</span><span>&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> primary_display</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Option</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>dyn</span><span> PlatformDisplay</span><span>&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> display</span><span>(&amp;</span><span>self</span><span>, </span><span>id</span><span>: </span><span>DisplayId</span><span>) -&gt; </span><span>Option</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>dyn</span><span> PlatformDisplay</span><span>&gt;&gt;;</span></span>
<span data-line=""><span>    fn</span><span> open_window</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>,</span></span>
<span data-line=""><span>        handle</span><span>: </span><span>AnyWindowHandle</span><span>,</span></span>
<span data-line=""><span>        options</span><span>: </span><span>WindowParams</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Box</span><span>&lt;</span><span>dyn</span><span> PlatformWindow</span><span>&gt;;</span></span>
<span data-line=""><span>    fn</span><span> set_cursor_style</span><span>(&amp;</span><span>self</span><span>, </span><span>style</span><span>: </span><span>CursorStyle</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> write_to_primary</span><span>(&amp;</span><span>self</span><span>, </span><span>item</span><span>: </span><span>ClipboardItem</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> write_to_clipboard</span><span>(&amp;</span><span>self</span><span>, </span><span>item</span><span>: </span><span>ClipboardItem</span><span>);</span></span>
<span data-line=""><span>    fn</span><span> read_from_primary</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Option</span><span>&lt;</span><span>ClipboardItem</span><span>&gt;;</span></span>
<span data-line=""><span>    fn</span><span> read_from_clipboard</span><span>(&amp;</span><span>self</span><span>) -&gt; </span><span>Option</span><span>&lt;</span><span>ClipboardItem</span><span>&gt;;</span></span>
<span data-line=""><span>    fn</span><span> run</span><span>(&amp;</span><span>self</span><span>);</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>And there are two implementations of <code>LinuxClient</code>:</p>
<ul>
<li><a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform/linux/wayland/client.rs#L360">one for Wayland</a></li>
<li><a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform/linux/x11/client.rs#L547">one for X11</a></li>
</ul>
<p>Both of them have an implementation of <code>PlatformWindow</code> too:</p>
<ul>
<li><a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform/linux/wayland/window.rs#L533">here's the Wayland <code>PlatformWindow</code></a></li>
<li><a href="https://github.com/zed-industries/zed/blob/98ea5e172ec114004116f996f51b46cdf5c438e4/crates/gpui/src/platform/linux/x11/window.rs#L410">and here's the X11 <code>PlatformWindow</code></a></li>
</ul>
<p>But both of them use Blade in their <code>draw</code> method:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/linux/x11/window.rs</span></span>
<span data-line=""><span>struct</span><span> X11WindowState</span><span> {</span></span>
<span data-line=""><span>    // [... other fields ...]</span></span>
<span data-line=""><span>    renderer</span><span>: </span><span>BladeRenderer</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> PlatformWindow</span><span> for</span><span> X11Window</span><span> {</span></span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>    fn</span><span> draw</span><span>(&amp;</span><span>self</span><span>, </span><span>scene</span><span>: &amp;</span><span>Scene</span><span>) {</span></span>
<span data-line=""><span>        let</span><span> mut</span><span> inner</span><span> = </span><span>self</span><span>.</span><span>0.</span><span>state.</span><span>borrow_mut</span><span>();</span></span>
<span data-line=""><span>        inner</span><span>.renderer.</span><span>draw</span><span>(</span><span>scene</span><span>);</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>// crates/gpui/src/platform/linux/wayland/window.rs</span></span>
<span data-line=""><span>struct</span><span> WaylandWindowState</span><span> {</span></span>
<span data-line=""><span>    // [... other fields ...]</span></span>
<span data-line=""><span>    renderer</span><span>: </span><span>BladeRenderer</span><span>,</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> PlatformWindow</span><span> for</span><span> WaylandWindow</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> draw</span><span>(&amp;</span><span>self</span><span>, </span><span>scene</span><span>: &amp;</span><span>Scene</span><span>) {</span></span>
<span data-line=""><span>        let</span><span> mut</span><span> state</span><span> = </span><span>self</span><span>.</span><span>borrow_mut</span><span>();</span></span>
<span data-line=""><span>        state</span><span>.renderer.</span><span>draw</span><span>(</span><span>scene</span><span>);</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>That means the rubber hits the road through these layers of abstractions:</p>
<ul>
<li>GPUI asks the <code>Platform</code> to open a window</li>
<li>The Wayland <code>LinuxClient</code> uses Wayland to open a window, the X11 client uses X11</li>
<li>When rendering a frame, GPUI turns the application into a <code>Scene</code></li>
<li>It then calls the <code>PlatformWindow</code> to <code>draw</code> that <code>Scene</code></li>
<li>Both the Wayland and the X11 implementations use Blade, which uses Vulkan, to talk to the GPU, to draw the <code>Scene</code></li>
</ul>
<p>That's obviously only scratching the surface. There are a lot more interesting things going in the Linux implementation — did you know that there's multiple clipboards on Linux but only one on macOS? Or here, take a look at this:</p>
<div><figure><img src="https://zed.dev/img/post/zed-decoded-linux-when/linux_screenshot_2.png" alt="Screenshot of Zed on Linux, including a native file dialog"><figcaption>Screenshot of Zed on Linux, including a native file dialog</figcaption></figure></div>
<p>Yup, that's a native file dialog, but we don't use GTK in Zed and that clearly is GTK — so, how does that work? You'll find the answer in <a href="https://youtu.be/O5XVVnA2LoY">the companion video</a> in which Mikayla and I dive deeper into this and also touch on the question of whether or not we should use GTK or Qt or something else (spoiler: it's complicated).</p>
<h2 id="so-linux-when"><span data-br=":R2b7brrrqbf9la:" data-brr="1">So, Linux when?</span></h2>
<p>So what's left to do for Linux? In order to get to an alpha release: <em>not that much</em>, but don't quote me on that. Essentially: fix 86 remaining <code>todo!</code>s of various difficulty levels, get window resizing/moving to work on Wayland, and implement system dialogues for GPUI. We're close, very close.</p>
<p>After the alpha, we'll need to add support for audio calls, drag &amp; drop, storing of credentials, make sure the performance is consistently high, increase stability, and so on. Take a look at the <a href="https://github.com/zed-industries/zed/issues/7015">Linux Roadmap</a> tracking issue.</p>
<p>Even though there might still be a lot to do (I don't even want to know how complicated drag &amp; drop can be on Linux— I mean, GNOM— I mean, KDE, no, I mea—) and a lot of unknown unknowns and surprises along the way, one thing's for sure: the fact that we got to the current state of Zed on Linux in three months, with that many high-quality open-source contributions, is pretty amazing.</p>
<p>Want to try out Zed on Linux? You need Rust, some dependencies, and depending on your patience enough CPU and memory to compile it in a reasonable amount of time. Take a look at <a href="https://github.com/zed-industries/zed/blob/main/docs/src/development/linux.md">these instructions</a>. Have fun!</p><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[J.G. Ballard predicted the rise of social media (2016) (102 pts)]]></title>
            <link>https://www.openculture.com/2016/03/j-g-ballard-predicted-the-rise-of-social-media-and-youtube-celebrity-in-1977.html</link>
            <guid>40286942</guid>
            <pubDate>Tue, 07 May 2024 15:30:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openculture.com/2016/03/j-g-ballard-predicted-the-rise-of-social-media-and-youtube-celebrity-in-1977.html">https://www.openculture.com/2016/03/j-g-ballard-predicted-the-rise-of-social-media-and-youtube-celebrity-in-1977.html</a>, See on <a href="https://news.ycombinator.com/item?id=40286942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><img loading="lazy" fetchpriority="high" decoding="async" width="599" height="263" src="https://cdn8.openculture.com/wp-content/uploads/2016/03/Ballard-Vogue.jpg" alt="Ballard Vogue" srcset="https://cdn8.openculture.com/wp-content/uploads/2016/03/24231713/Ballard-Vogue.jpg 599w, https://cdn8.openculture.com/wp-content/uploads/2016/03/24231713/Ballard-Vogue-150x66.jpg 150w, https://cdn8.openculture.com/wp-content/uploads/2016/03/24231713/Ballard-Vogue-300x132.jpg 300w" sizes="(max-width: 599px) 100vw, 599px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/wp-content/uploads/2016/03/Ballard-Vogue.jpg" data-srcset="https://cdn8.openculture.com/wp-content/uploads/2016/03/24231713/Ballard-Vogue.jpg 599w, https://cdn8.openculture.com/wp-content/uploads/2016/03/24231713/Ballard-Vogue-150x66.jpg 150w, https://cdn8.openculture.com/wp-content/uploads/2016/03/24231713/Ballard-Vogue-300x132.jpg 300w"></p>
<p>Say you were a fan of Steven Spielberg’s mov­ing com­ing-of-age dra­ma <em>Empire of the Sun</em>, set in a Japan­ese intern­ment camp dur­ing World War II and star­ring a young Chris­t­ian Bale. Say you read the <a href="http://amzn.to/1pLgbCQ">auto­bi­o­graph­i­cal nov­el</a> on which that film is based, writ­ten by one <a href="https://en.wikipedia.org/wiki/J._G._Ballard">J.G. Bal­lard</a>. Say you enjoyed it so much, you decid­ed to read more of the author’s work, like, say, <a href="http://amzn.to/1pLgi18" rel="nofollow">1973’s <em>Crash</em></a>, a nov­el about peo­ple who devel­op a sex­u­al fetish around wounds sus­tained in staged auto­mo­bile acci­dents. Or you pick up its pre­de­ces­sor, <em><a href="http://amzn.to/1Rq5r5Q" rel="nofollow">The Atroc­i­ty Exhi­bi­tion</a></em>, a book <a href="http://www.newyorker.com/magazine/2014/02/03/the-outlaw-2">William S. Bur­roughs</a> described as stir­ring “sex­u­al depths untouched by the hard­est-core illus­trat­ed porn.” Or per­haps you stum­ble upon <em><a href="http://amzn.to/1Rq5w9w" rel="nofollow">Con­crete Island</a></em>, a warped take on Defoe that strands a wealthy archi­tect and his Jaguar on a high­way inter­sec­tion.</p>



<p>You may expe­ri­ence some dis­so­nance. Who was this Bal­lard? A real­ist chron­i­cler of 20th cen­tu­ry hor­rors; per­verse explor­er of—in Bur­roughs’ words—“the non­sex­u­al roots of sex­u­al­i­ty”; sci-fi satirist of the bleak post-indus­tri­al waste­lands of moder­ni­ty? He was all of these, and more. Bal­lard was a bril­liant futur­ist and his <a href="http://io9.gizmodo.com/5221560/remembering-jg-ballards-science-fiction-legacy">dystopi­an nov­els and short sto­ries</a> antic­i­pat­ed the 80s cyber­punk of William Gib­son, explor­ing with a twist­ed sense of humor what Jean Lyotard famous­ly dubbed in 1979 <em><a href="http://monoskop.org/images/e/e0/Lyotard_Jean-Francois_The_Postmodern_Condition_A_Report_on_Knowledge.pdf">The Post­mod­ern Con­di­tion</a></em>: a state of ide­o­log­i­cal, sci­en­tif­ic, per­son­al, and social dis­in­te­gra­tion under the reign of a tech­no­crat­ic, hyper­cap­i­tal­ist, “com­put­er­ized soci­ety.” Bal­lard had his own term for it: “media land­scape,” and his dark visions of the future often cor­re­spond to the vir­tu­al world we inhab­it today.</p>
<div>
<p><span><iframe title="YouTube video player" type="text/html" width="640" height="505" src="//www.youtube.com/embed/nBq2GqYUVZA?wmode=transparent&amp;fs=1&amp;hl=en&amp;showsearch=0&amp;rel=0&amp;theme=dark" frameborder="0" allowfullscreen="" loading="lazy"></iframe></span>
	</p>
</div>

<p>In addi­tion to his fic­tion­al cre­ations, Bal­lard made sev­er­al <a href="http://biographile.kinja.com/back-to-the-future-the-eerily-accurate-predictions-of-1669123401" rel="nofollow">dis­turbing­ly accu­rate pre­dic­tions</a> in inter­views he gave over the decades (col­lect­ed in a book titled <em><a href="http://amzn.to/1pLgxJC">Extreme Metaphors</a></em>). In 1987—with the film adap­ta­tion of <em>Empire of the Sun</em> just on the hori­zon and “his most extreme work <em><a href="http://amzn.to/1Rq5RsR">Crash</a></em> re-released in the USA to warmer reac­tion,” he gave an <a href="https://i-d.vice.com/en_gb/article/jg-ballard-predicted-social-media-in-i-d-27-years-ago">inter­view to <em>I‑D</em> mag­a­zine</a> in which he pre­dict­ed the inter­net as “invis­i­ble streams of data puls­ing down lines to pro­duce an invis­i­ble loom of world com­merce and infor­ma­tion.” This may not seem espe­cial­ly pre­scient (see, for exam­ple, E.M. Forster’s 1909 “<a href="http://archive.ncsa.illinois.edu/prajlich/forster.html">The Machine Stops</a>” for a chill­ing futur­is­tic sce­nario much fur­ther ahead of its time). But Bal­lard went on to describe in detail the rise of the Youtube celebri­ty:</p>
<blockquote><p><em>Every home will be trans­formed into its own TV stu­dio. We’ll all be simul­ta­ne­ous­ly actor, direc­tor and screen­writer in our own soap opera. Peo­ple will start screen­ing them­selves. They will become their own TV pro­grammes. </em></p></blockquote>
<p>The themes of celebri­ty obses­sion and tech­no­log­i­cal­ly con­struct­ed real­i­ties&nbsp;res­onate in almost all of Ballard’s work and thought, and ten years ear­li­er, in an essay for <em>Vogue</em>, he described in detail the spread of social media and its total­iz­ing effects on our lives. In the tech­no­log­i­cal future, he wrote, “each of us will be both star and sup­port­ing play­er.”</p>
<blockquote><p><em>Every one of our actions dur­ing the day, across the entire spec­trum of domes­tic life, will be instant­ly record­ed on video-tape. In the evening we will sit back to scan the rush­es, select­ed by a com­put­er trained to pick out only our best pro­files, our wit­ti­est dia­logue, our most affect­ing expres­sions filmed through the kind­est fil­ters, and then stitch these togeth­er into a height­ened re-enact­ment of the day. Regard­less of our place in the fam­i­ly peck­ing order, each of us with­in the pri­va­cy of our own rooms will be the star in a con­tin­u­al­ly unfold­ing domes­tic saga, with par­ents, hus­bands, wives and chil­dren demot­ed to an appro­pri­ate sup­port­ing role.</em></p></blockquote>
<p>Though Bal­lard thought in terms of film and television—and though we our­selves play the role of the select­ing com­put­er in his scenario—this descrip­tion almost per­fect­ly cap­tures the behav­ior of the aver­age user of Face­book, Insta­gram, etc. (See Bal­lard in the inter­view clip above&nbsp;dis­cuss fur­ther “the pos­si­bil­i­ties of gen­uine­ly inter­ac­tive vir­tu­al real­i­ty” and his the­o­ry of the 50s as the “blue­print” of mod­ern tech­no­log­i­cal cul­ture and the “sub­ur­ban­iza­tion” of real­i­ty.) In addi­tion to the <em>Vogue</em> essay, Bal­lard wrote a 1977 short sto­ry called “The Inten­sive Care Unit,” in which—<a href="http://www.ballardian.com/j-g-ballard-predicts-social-media-cctv-reality-tv" rel="nofollow">writes the site Bal­lar­dian</a>—“ordi­nances are in place to pre­vent peo­ple from meet­ing in per­son. All inter­ac­tion is medi­at­ed through per­son­al cam­eras and TV screens.”</p>
<p>So what did Bal­lard, who died in 2009, think of the post-inter­net world he lived to see and expe­ri­ence? He <a href="http://www.dazeddigital.com/artsandculture/article/17952/1/jg-ballard-interviewed">dis­cussed the sub­ject in 2003 in an inter­view with rad­i­cal pub­lish­er V. Vale</a> (who re-issued <em>The Atroc­i­ty Exhi­bi­tion</em>). “Now every­body can doc­u­ment them­selves in a way that was incon­ceiv­able 30, 40, 50 years ago,” Bal­lard notes, “I think this reflects a tremen­dous hunger among peo­ple for ‘reality’—for ordi­nary real­i­ty. It’s very dif­fi­cult to find the ‘real,’ because the envi­ron­ment is total­ly man­u­fac­tured.” Like <a href="https://www.cla.purdue.edu/english/theory/postmodernism/modules/baudlldsimulTnmainframe.html">Jean Bau­drillard</a>, anoth­er pre­scient the­o­rist of post­moder­ni­ty, Bal­lard saw this loss of the “real” com­ing many decades ago. As he told <em>I‑D</em> in 1987, “in the media land­scape it’s almost impos­si­ble to sep­a­rate fact from fic­tion.”</p>
<p>via <a href="http://www.buzzfeed.com/lukelewis/jg-ballard-predicted-social-media-in-1977#.wcvL4d8q5">Buz­zfeed</a></p>
<p><strong>Relat­ed Con­tent:</strong></p>
<p><a href="http://www.openculture.com/2014/06/in-1964-arthur-c-clarke-predicts-the-internet-3d-printers-and-trained-monkey-servants.html">In 1964, Arthur C. Clarke Pre­dicts the Inter­net, 3D Print­ers and Trained Mon­key Ser­vants</a></p>
<p><a href="http://www.openculture.com/2014/03/in-1968-stanley-kubrick-makes-some-wild-predictions-for-the-year-2001.html">In 1968, Stan­ley Kubrick Makes Pre­dic­tions for 2001: Human­i­ty Will Con­quer Old Age, Watch 3D TV &amp; Learn Ger­man in 20 Min­utes</a></p>
<p><a href="http://www.openculture.com/2015/03/philip-k-dick-makes-off-the-wall-predictions-for-the-future.html">Philip K. Dick Makes Off-the-Wall Pre­dic­tions for the Future: Mars Colonies, Alien Virus­es &amp; More (1981)</a></p>
<p><a href="http://about.me/jonesjoshua"><em>Josh Jones</em></a><em>&nbsp;is a writer and musi­cian based in Durham, NC. Fol­low him at&nbsp;<a href="https://twitter.com/jdmagness">@jdmagness</a></em></p>


<br>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Giant batteries are transforming the way the U.S. uses electricity (134 pts)]]></title>
            <link>https://www.nytimes.com/interactive/2024/05/07/climate/battery-electricity-solar-california-texas.html</link>
            <guid>40286923</guid>
            <pubDate>Tue, 07 May 2024 15:29:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/interactive/2024/05/07/climate/battery-electricity-solar-california-texas.html">https://www.nytimes.com/interactive/2024/05/07/climate/battery-electricity-solar-california-texas.html</a>, See on <a href="https://news.ycombinator.com/item?id=40286923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content"><article id="interactive"><div id="battery-electricity-solar-california-texas" data-preview-slug="2024-04-16-grid-battery-storage" data-birdkit-hydrate="2e24602fa83cdb9a" data-testid="inline-interactive" data-id="100000009451376" data-source-id="100000009451376">	
			
	  <figure role="group" aria-label="graphic">   <div> <p><!-- HTML_TAG_START -->Source: California Independent System Operator via <a href="http://gridstatus.io/">Grid Status</a><!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->Please see the bottom of this page for notes.<!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->By The New York Times<!-- HTML_TAG_END --></p> </div> </figure><p><!-- HTML_TAG_START -->California draws more electricity from the sun than any other state. It also has a timing problem: Solar power is plentiful during the day but disappears by evening, just as people get home from work and electricity demand spikes. To fill the gap, power companies typically burn more fossil fuels like natural gas.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->That’s now changing. Since 2020, California has installed more giant batteries than anywhere in the world apart from China. They can soak up excess solar power during the day and store it for use when it gets dark.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Those batteries play a pivotal role in California’s electric grid, partially replacing fossil fuels in the evening. Between 7 p.m. and 10 p.m. on April 30, for example, <a href="https://www.gridstatus.io/live/caiso?date=2024-04-30">batteries supplied more than one-fifth of California’s electricity</a> and, for a few minutes, pumped out 7,046 megawatts of electricity, akin to the output from seven large nuclear reactors.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Across the country, power companies are increasingly using giant batteries the size of shipping containers to address renewable energy’s biggest weakness: the fact that the wind and sun aren’t always available.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“What’s happening in California is a glimpse of what could happen to other grids in the future,” said Helen Kou, head of U.S. power analysis at BloombergNEF, a research firm. “Batteries are quickly moving from these niche applications to shifting large amounts of renewable energy toward peak demand periods.”<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Over the past three years, battery storage capacity on the nation’s grids has grown tenfold, to 16,000 megawatts. This year, <a href="https://www.eia.gov/todayinenergy/detail.php?id=61202">it is expected to nearly double</a> again, with the biggest growth in Texas, California and Arizona.<!-- HTML_TAG_END --></p><figure role="group" aria-label="graphic"><div><p><h3><!-- HTML_TAG_START --><span>Battery Storage Plants</span> Across the <span>United States</span><span>U.S.</span><!-- HTML_TAG_END --></h3>  </p></div>   <div> <p><!-- HTML_TAG_START -->Source: U.S. Energy Information Administration<!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->Note: Each circle represents a facility that has at least one battery as of March 2024.<!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->By The New York Times<!-- HTML_TAG_END --></p> </div> </figure><p><!-- HTML_TAG_START -->Most grid batteries use lithium-ion technology, similar to batteries in smartphones or electric cars. As the electric vehicle industry has expanded over the past decade, battery costs have fallen by 80 percent, making them competitive for large-scale power storage. Government mandates and subsidies have also spurred growth.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->As batteries have proliferated, power companies are using them in novel ways, such as handling big swings in electricity generation from solar and wind farms, reducing congestion on transmission lines and helping to prevent blackouts during scorching heat waves.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->In California, which has set ambitious goals for fighting climate change, policymakers hope grid batteries can help the state get 100 percent of its electricity from carbon-free sources by 2045. While the state remains heavily dependent on natural gas, a significant contributor to global warming, batteries are starting to eat into the market for fossil fuels. State regulators plan <a href="https://www.utilitydive.com/news/california-puc-carbon-preferred-system-plan-irp-caiso/707876/">to nearly triple battery capacity</a> by 2035.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“The future is bright for energy storage,” said Andrés Gluski, chief executive of AES Corporation, one of the world’s largest power companies. “If you want more renewables on the grid, you need more batteries. It’s not going to work otherwise.”<!-- HTML_TAG_END --></p><p><h2><!-- HTML_TAG_START -->How Batteries Work on the Grid Today<!-- HTML_TAG_END --></h2> </p><figure role="group" aria-label="image">   <div><p><!-- HTML_TAG_START -->A battery storage facility under construction in Menifee, Calif., in March. The site, at 43 acres, is expected to be the largest in the state when completed.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Mike Blake/Reuters<!-- HTML_TAG_END --></p> </div> </figure><p><!-- HTML_TAG_START -->When power companies first began connecting batteries to the grid in the 2010s, they mainly used them to smooth out small disruptions in the flow of electricity, say, if a power plant unexpectedly tripped offline. Many battery operators still earn most of their revenue by providing these <a href="https://www.eia.gov/todayinenergy/detail.php?id=50176">“ancillary services.”</a><!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->But power companies also use batteries to engage in a type of trading: charging up when electricity is plentiful and cheap and then selling power to the grid when electricity supplies are tighter and more expensive.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->In California power prices often crash around midday, when the state produces more solar power than it needs, especially in the spring when air-conditioning use is low. Prices then soar in the evening when solar disappears and grid operators have to increase output from gas plants or hydroelectric dams to compensate.<!-- HTML_TAG_END --></p><figure role="group" aria-label="graphic">   <div> <p><!-- HTML_TAG_START -->Sources: California Independent System Operator via <a href="http://gridstatus.io/">Grid Status</a><!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->By The New York Times<!-- HTML_TAG_END --></p> </div> </figure><p><!-- HTML_TAG_START -->California now has <a href="https://www.energy.ca.gov/data-reports/energy-almanac/california-electricity-data/california-energy-storage-system-survey">10,000 megawatts of battery capacity on the grid</a>, enough to power 10 million homes for a few hours. Those batteries are “able to very effectively manage that evening ramp where solar is going down and customer demand is increasing,” said John Phipps, executive director of grid operations for the California Independent System Operator, which oversees the state’s grid.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Batteries can also help California’s grid handle stresses from heat waves and wildfires, Mr. Phipps said. “It made some differences last summer,” he said. “We were able to meet high load days and wildfire days when we might lose some power lines.”<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->In Texas, batteries are still largely used to provide ancillary services, stabilizing the grid against unexpected disruptions. Texas is also more reliant than California on wind energy, which fluctuates in less-predictable patterns.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->But Texas is quickly catching up to California in solar power, and batteries increasingly help with evening peaks. On April 28, the sun was setting just as wind power was unexpectedly low and many coal and gas plants were offline for repairs. Batteries jumped in, <a href="https://www.gridstatus.io/live/ercot?date=2024-04-28">supplying 4 percent of Texas’s electricity at one point</a>, enough to power a million homes. Last summer, batteries <a href="https://www.houstonchronicle.com/business/energy/article/ercot-grid-battery-solar-enel-texas-18350609.php">helped avert evening blackouts</a> by providing additional power during record heat.<!-- HTML_TAG_END --></p><figure role="group" aria-label="graphic">   <div> <p><!-- HTML_TAG_START -->Sources: Electric Reliability Council of Texas via <a href="http://gridstatus.io/">Grid Status</a><!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->By The New York Times<!-- HTML_TAG_END --></p> </div> </figure><p><!-- HTML_TAG_START -->The two states built their battery fleets in distinct ways. In California, government mandates were the impetus: In 2019, regulators worried that too many older gas plants were closing, risking blackouts, and ordered utilities to quickly install thousands of megawatts of storage.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->In Texas, market forces dominate. The state’s deregulated electricity system allows prices to fluctuate sharply, rising as high as $5,000 per megawatt-hour during acute shortages. That makes it lucrative for battery developers to take advantage of spikes, such as in locations where power lines periodically get clogged.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“Anywhere we think the market is going to get tight, you can put batteries in and even things out,” said Stephanie Smith, chief operating officer of Eolian, a battery developer. “Then, we’re making bets all day about when to charge and discharge.”<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->One battery, for instance, sits near Fort Worth, absorbing excess wind power from West Texas during the nighttime, when no one needs it, and feeding it into the grid when demand surges.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Other states are following. In Arizona and Georgia, utilities plan to install thousands of megawatts of battery capacity to help manage rising demand from data centers and factories. It helps that batteries can be deployed quickly, said Aaron Mitchell, vice president of planning and pricing at Georgia Power.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->The industry still faces obstacles, however. Lithium-ion batteries are flammable, and while operators have taken steps to reduce fire risk, some communities <a href="https://thecoastnews.com/residents-remain-opposed-to-seguro-battery-facility-despite-changes/">oppose projects in their backyards</a>. Most batteries still come from China, making them vulnerable to trade disputes. In Texas, a state fund <a href="https://www.expressnews.com/business/article/texas-energy-fund-loan-program-ercot-19361692.php">to subsidize gas plants</a> could undercut the battery boom. In other states, complex regulations <a href="https://ohiocapitaljournal.com/2023/10/02/battery-storage-seen-as-backbone-of-reliable-electric-grid-but-adoption-uneven-across-us/">sometimes prevent utilities from adding energy storage</a>.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“Because these storage resources are so new, the rules are still catching up,” said Natalie McIntire, who works on grid issues for the Natural Resources Defense Council, an environmental group.<!-- HTML_TAG_END --></p><p><h2><!-- HTML_TAG_START -->Can Grid Batteries Help Fight Climate Change?<!-- HTML_TAG_END --></h2> </p><figure role="group" aria-label="image">   <div><p><!-- HTML_TAG_START -->Wind turbines near Sweetwater, Texas. Nationwide, battery storage is being used to address renewable energy’s biggest weakness: the fact that the wind and sun aren’t always available.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Tamir Kalifa for The New York Times<!-- HTML_TAG_END --></p> </div> </figure><p><!-- HTML_TAG_START -->Grid batteries could be a useful tool to slash planet-warming emissions, experts say, though they still need further advances in terms of costs, technologies and how they are used.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->In Texas, many batteries today are actually increasing carbon-dioxide emissions, <a href="https://www.linkedin.com/pulse/location-tierra-climate/?trackingId=6ggknGE9JAqIEEZZnv6epQ%3D%3D">according to one analysis</a>. That’s because operators focus on maximizing revenue and sometimes charge with coal or gas power.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“These batteries have an immense capability to abate carbon, but they need the right incentives to do so,” said Emma Konet, co-founder of <a href="https://www.tierraclimate.com/about">Tierra Climate</a>, a startup working to help batteries earn money for reducing emissions.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->In California, by contrast, batteries appear to be cutting emissions from fossil fuels. The state’s gas use in April <a href="https://twitter.com/grid_status/status/1785399291671924856">fell to a seven-year low</a>. “We have reached the conclusion that batteries are displacing natural gas when solar generation is ramping up and down each day,” said Max Kanter, chief executive of Grid Status, an electricity data tracking firm.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Yet California still gets roughly 40 percent of its electricity from natural gas, and it could be difficult for current battery technology to replace all of that. One <a href="https://about.bnef.com/blog/how-pv-plus-storage-will-compete-with-gas-generation-in-the-u-s/">analysis from BloombergNEF</a> found that solar and batteries can be a cost-effective alternative to smaller gas “peaker” plants that only switch on when demand spikes. But batteries remain too costly to replace many of the larger gas-burning plants that provide steadier power day and night.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“You don’t want to necessarily build a system where you’ve got batteries to suck up every last megawatt-hour, because that’s a pretty expensive system,” said Meredith Fowlie, an economist at the University of California, Berkeley.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Today’s lithium-ion batteries can only deliver power for two to four hours before needing to recharge. If costs keep falling, battery companies <a href="https://www.nrel.gov/docs/fy23osti/85878.pdf">might be able to extend that to eight or ten hours</a> (it’s a matter of adding more battery packs) but it may not be economical to go far beyond that, said Nate Blair, an energy storage expert at the National Renewable Energy Laboratory.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->That means additional long-duration storage technologies could be needed. If California wants to rely largely on renewable energy, it will have to handle <a href="https://www.pnnl.gov/news-media/energy-droughts-wind-and-solar-can-last-nearly-week-research-shows">weeklong periods where there’s no wind and little sun</a>. Another challenge: There’s far more solar power available in summer than in winter, and no battery today can store electricity for months to manage those seasonal disparities.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Some companies are exploring solutions. In Sacramento, a start-up called ESS <a href="https://www.canarymedia.com/articles/long-duration-energy-storage/sacramento-utility-rolls-out-its-first-long-duration-grid-batteries">is building “flow” batteries</a> that store energy in liquid electrolytes and can last 12 hours or longer. Another start-up, Form Energy, <a href="https://www.energy.ca.gov/news/2023-12/cec-awards-30-million-100-hour-long-duration-energy-storage-project">is building a 100-hour iron-air battery</a>. These ideas will have to compete against alternatives like nuclear power, <a href="https://www.nytimes.com/2023/08/28/climate/geothermal-energy-projects.html">advanced geothermal</a> or even <a href="https://www.nytimes.com/2024/01/12/climate/green-hydrogen-climate-change.html">using green hydrogen to store electricity</a>.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->California’s regulators say they may need five times as much storage capacity by midcentury, even if it’s unclear which technologies will prevail.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->“We’re just at the beginning of this,” said Mr. Phipps of the California Independent System Operator.<!-- HTML_TAG_END --></p><figure role="group" aria-label="image">   <div><p><!-- HTML_TAG_START -->Ross D. Franklin/Associated Press<!-- HTML_TAG_END --></p></div> </figure><figure role="group">  <div><p>Data notes</p> <p><!-- HTML_TAG_START -->In the top graphic, charts reflect average daily power generation, by fuel type, in five-minute increments for the month of April. The charts show imports from other regions, as well as times when battery power is discharged to the grid, but they do not show battery charging or electricity exports. The data reflects utility-scale generation and does not include “behind-the-meter” sources, such as rooftop solar panels. No adjustments are made for variations in weather.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->The California Independent System Operator’s method for counting natural gas generation resources <a href="https://www.caiso.com/Documents/the-california-iso-revised-its-counting-process-for-natural-gas-data.html">changed in December 2023</a>. Before then, the organization had been slightly overcounting gas “on the range of a few hundred megawatts,” according to a spokesperson.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Average sunrise and sunset times are shown on the charts.<!-- HTML_TAG_END --></p></div>  </figure> 
			
			
		

		</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LPCAMM2 is a modular, repairable, upgradeable memory standard for laptops (341 pts)]]></title>
            <link>https://www.ifixit.com/News/95078/lpcamm2-memory-is-finally-here</link>
            <guid>40286734</guid>
            <pubDate>Tue, 07 May 2024 15:17:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ifixit.com/News/95078/lpcamm2-memory-is-finally-here">https://www.ifixit.com/News/95078/lpcamm2-memory-is-finally-here</a>, See on <a href="https://news.ycombinator.com/item?id=40286734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<figure><p>
<iframe title="New Laptop Memory Is Here! LPCAMM2 Changes Everything!" width="456" height="257" src="https://www.youtube-nocookie.com/embed/K3zB9EFntmA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>If you’ve ever tried to “future-proof” a purchase by paying for everything you might eventually need up front, you know it can be a sucker’s game. The problem? <em>We can’t actually see the future.</em>&nbsp;</p>



<p>But today we got our hands on LPCAMM2 for the first time, and this looks like the future to us. LPCAMM2 is a totally modular, repairable, upgradeable memory standard for laptops, using the latest LPDDR chips for maximum speed and efficiency. So instead of overpaying (or under-speccing) based on guesswork about your future memory needs, you’ll hopefully be able to buy your next laptop and then install more RAM as needed. Imagine that!</p>



<figure><img fetchpriority="high" decoding="async" width="1922" height="1081" src="https://valkyrie.cdn.ifixit.com/media/2024/05/06213451/newmicronram-in-use.jpg" alt="The Micron LPCAMM2 module disassembled next to iFixit tools and laptop parts" srcset="https://valkyrie.cdn.ifixit.com/media/2024/05/06213451/newmicronram-in-use.jpg 1922w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213451/newmicronram-in-use-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213451/newmicronram-in-use-1600x900.jpg 1600w" sizes="(max-width: 1922px) 100vw, 1922px"></figure>



<p>We say “hopefully” because the <a href="https://www.ifixit.com/Device/Lenovo_ThinkPad_P1_Gen_7">laptop</a> on our teardown table today is the first of its kind, thanks to a collaboration between <a href="https://www.micron.com/about/blog/memory/dram/lpcamm2-no-compromise-for-next-gen-laptops">Micron</a> and <a href="https://news.lenovo.com/pressroom/press-releases/lenovo-unveils-its-new-ai-ready-thinkpad-p1-gen-7-mobile-workstation/">Lenovo</a>—and it remains to be seen how many other big laptop makers will adopt LPCAMM2 technology. But judging by the results of our initial hands-on, the writing is on the wall for laptops with soldered-down, non-serviceable memory.</p>



<h2><strong>What is LPDDR, and why do manufacturers solder it down?</strong></h2>



<p>Repairable, upgradeable RAM isn’t exactly a new idea. As anyone who has ever built a PC knows, we’ve had swappable DDR RAM sticks (also known as <a href="https://en.wikipedia.org/wiki/DIMM#SO-DIMM">DIMMs</a>, or <em>Dual In-Line Memory Modules</em>) since basically forever. From old Gateway towers to today’s gaming powerhouses to zillion-dollar industrial servers, upgradeable and replaceable RAM is still very much a thing. And for many years, the same was true of laptops, which used a slightly more compact (“Small-Outline” DIMM, or <em>SO-DIMM</em>) version of those same RAM sticks.</p>



<p>More recently though, we’ve seen increasing adoption of <em>LPDDR</em>—a <em>low-power</em> flavor of RAM (hence the “LP”) developed for mobile devices like phones and tablets. Whereas conventional DDR RAM excels at performance applications where power consumption isn’t a primary concern, like video editing or gaming, LPDDR wins the day when it comes to efficiency—<em>a.k.a. battery life</em>. And so for laptops in particular, the benefits of LPDDR are hard to beat.</p>



<div><p>The drawback of LPDDR, though, is that it has to be soldered to the main board in close proximity to the processor—making repairs and upgrades completely impractical. But why?</p><p>LPDDR operates at lower voltages compared to DDR, giving it the edge in power efficiency. But, the lower voltage makes signal integrity between the memory and processor challenging, requiring tighter tolerances and shorter trace distances—that is, the farther the signal has to travel, the more voltage you need for a reliable signal. This is why LPDDR is soldered down as close to the processor as possible.</p></div>



<figure><img decoding="async" width="1922" height="1081" src="https://valkyrie.cdn.ifixit.com/media/2024/05/06215652/soldered.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/05/06215652/soldered.jpg 1922w, https://valkyrie.cdn.ifixit.com/media/2024/05/06215652/soldered-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/05/06215652/soldered-1600x900.jpg 1600w" sizes="(max-width: 1922px) 100vw, 1922px"><figcaption>Historically, LPDDR chips (left) had to be soldered very close to the main processor (right).</figcaption></figure>



<p>In short, laptop makers and consumers alike have faced an unfortunate dilemma: conventional SO-DIMM RAM for serviceability and upgradeability, or soldered LPDDR chips for longer battery life.</p>



<p>Today, that changes.</p>



<h2><strong>Enter LPCAMM2&nbsp;</strong></h2>



<p>Standing for “Low-Power Compression-Attached Memory Module,” the new tech is as the name suggests: LPDDR chips on a compact board that screws in place very close to a laptop’s CPU. Combining the efficiency and speed of LPDDR with a thin, lightweight, upgradeable design and a trick interface that gets everything up close and personal with the CPU, LPCAMM2 seemingly does it all. And with dual-channel performance already baked in, a single LPCAMM2 module can do the job of a pair of the old socketed SO-DIMM sticks with a much smaller footprint and better thermals to boot. Finally: modular, performant, power-efficient laptop memory for the masses.</p>



<figure>
<figure><a href="https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7.jpg"><img loading="lazy" decoding="async" width="600" height="400" data-id="95569" src="https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-600x400.jpg" alt="Lenovo's ThinkPad P1 (Gen 7) workstation-class laptop" srcset="https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7-450x300.jpg 450w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213446/Lenovo-P1-Gen7.jpg 1922w" sizes="(max-width: 600px) 100vw, 600px"></a></figure>



<figure><a href="https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew.jpg"><img loading="lazy" decoding="async" width="600" height="400" data-id="95572" src="https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-600x400.jpg" alt="Removing the three screws that secure the LPCAMM2 module" srcset="https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-1536x1025.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-1349x900.jpg 1349w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew-450x300.jpg 450w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213454/unscrew.jpg 1922w" sizes="(max-width: 600px) 100vw, 600px"></a></figure>



<figure><a href="https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift.jpg"><img loading="lazy" decoding="async" width="600" height="400" data-id="95570" src="https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-600x400.jpg" alt="Removing the LPCAMM2 module from the ThinkPad P1" srcset="https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift-450x300.jpg 450w, https://valkyrie.cdn.ifixit.com/media/2024/05/06213448/lift.jpg 1922w" sizes="(max-width: 600px) 100vw, 600px"></a></figure>
<figcaption>Lenovo’s <a href="https://www.ifixit.com/Device/Lenovo_ThinkPad_P1_Gen_7">ThinkPad P1 (Gen 7)</a> is the first laptop you can actually buy that uses LPCAMM2 tech—check out our <a href="https://www.ifixit.com/Guide/Lenovo+ThinkPad+P1+Gen+7+LPCAMM2+Memory+Replacement/172267">repair guide</a>.</figcaption></figure>



<p>Even though LPCAMM2 is arriving initially from Micron, in a Lenovo product, the technology owes its existence to an alliance of tech companies working together over the course of several years. The first iteration, known as <a href="https://videocardz.com/newz/dell-introduces-camm-ddr5-memory-for-its-new-precision-laptops-up-to-128gb-per-module">CAMM</a>, was an in-house project at Dell, with the first DDR5-equipped CAMM modules installed in Dell Precision 7000 series laptops. And thankfully, after doing the initial R&amp;D to make the tech a reality, Dell didn’t gatekeep. Their engineers believed that the project had such a good chance at becoming the next widespread memory standard that instead of keeping it proprietary, they went the other way and opened it up for standardization.&nbsp;</p>



<p>They were right. Only a few short years later, with the blessing of the <a href="https://www.jedec.org/news/pressreleases/jedec-publishes-new-camm2-memory-module-standard">JEDEC</a> standards body, LPCAMM2 is here and ready to take the torch.</p>



<p>Dell is one hero in this story, creating something the tech world sorely needed and then sharing instead of keeping it for themselves. Thankfully, this story is full of heroes: Micron and Lenovo are first to bring LPCAMM2 to market, with <a href="https://semiconductor.samsung.com/dram/module/lpcamm2/">Samsung</a>, <a href="https://www.tomshardware.com/news/adata-demos-next-gen-memory-modules">ADATA</a>, and others backing it as well. Instead of everyone going their own way, they’ve rallied around a new industry standard—meaning an off-the-shelf LPCAMM2 module should theoretically work in any laptop that adopts the technology, regardless of who manufactures it. With the industry as a whole on the same page, backing standards like this, the world becomes a more repairable place.</p>



<h2><strong>Designing for a repairable future</strong></h2>



<p>The advent of LPCAMM2 is especially gratifying for repair advocates, who for years have been told that repairability simply can’t coexist with cutting-edge tech in thin-and-light devices. We’re not ready to accept that, and we’ve long argued that OEMs who are willing to innovate with repairability in mind can do better. Maybe we can’t see the future, but we can envision one that’s more repairable than what we’ve been sold in recent years—and we’re grateful when companies like Micron and Lenovo take the leap to make that future a reality.</p>



<figure><img loading="lazy" decoding="async" width="1922" height="1081" src="https://valkyrie.cdn.ifixit.com/media/2024/05/06220218/Lenovo_P1_108-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/05/06220218/Lenovo_P1_108-1.jpg 1922w, https://valkyrie.cdn.ifixit.com/media/2024/05/06220218/Lenovo_P1_108-1-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/05/06220218/Lenovo_P1_108-1-1600x900.jpg 1600w" sizes="(max-width: 1922px) 100vw, 1922px"></figure>



<p>LPCAMM2 exemplifies our ability to advance technologically while designing with sustainability in mind. It represents a significant step forward in the fight against planned obsolescence. By fighting for a modular, upgradeable memory solution for chips previously stuck in a soldered hellscape, manufacturers are demonstrating their commitment to creating devices that stand the test of time.&nbsp;</p>



<p>There’s so much to gain here: from increasing device lifespan at schools and businesses, to reducing anxiety for consumers at the point of purchase, to enabling hassle-free repairs for devices that would otherwise be scrapped. As more companies rally behind this standard, we can look forward to a future where more laptops are built to last, and where repairs and upgrades aren’t only possible, but encouraged. There’s no question that the potential for this technology to make a tangible difference is real, and it’s right in front of us.</p>



<p><em>Full Disclosure: iFixit has prior business relationships with both Micron and Lenovo, and we are hopelessly biased in favor of repairable products.</em></p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SecureDrop Protocol (231 pts)]]></title>
            <link>https://securedrop.org/news/introducing-securedrop-protocol/</link>
            <guid>40286632</guid>
            <pubDate>Tue, 07 May 2024 15:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://securedrop.org/news/introducing-securedrop-protocol/">https://securedrop.org/news/introducing-securedrop-protocol/</a>, See on <a href="https://news.ycombinator.com/item?id=40286632">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>
May 6, 2024
</p>
<section>
<div><p data-block-key="k2n3w">This blog post is a part of a series about our research toward the next generation of the SecureDrop whistleblowing system. If you haven’t been following along, check out <a href="https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/">our previous post</a> for some recommended context.</p><p data-block-key="a0kb2">Here, we present a proposed end-to-end encryption protocol for a future version of SecureDrop server, accompanied by a brief discussion of various aspects of the protocol and our next steps.</p></div>
<a id="protocol_overview"></a>
<div><h2 data-block-key="amiet">Protocol overview</h2><p data-block-key="4ha31">We present a proof-of-concept protocol with the following core properties, which are derived from the research and threat modeling concerns <a href="https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/#design_challenges">previously discussed</a>:</p><ol><li data-block-key="6gel2">No accounts, and therefore no user authentication;</li><li data-block-key="es209">No message flow metadata, meaning messages can’t be linked together, and different types of messages are indistinguishable from one another;</li><li data-block-key="3ag4">No changes in server state are observable externally;</li><li data-block-key="520s9">No ciphertext collection or information leaks via trial decryption – a given recipient receives pertinent ciphertext only.</li></ol><p data-block-key="d3vce">The protocol has a simple API with only three endpoints: <code>send</code>, <code>fetch</code>, and <code>download</code>. Sources’ and journalists’ requests to these endpoints are structured identically, to make them harder for a compromised server or network adversary to distinguish. The server’s response is unique for each request, to avoid leaking information about server state.</p><p data-block-key="5ebcm">It uses well-established cryptographic primitives (currently <code>libsodium</code> for proof-of-concept purposes), achieving end-to-end encryption and one-way forward secrecy <a href="https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/#new_protocol_requirements">for messages flowing from source to journalist</a>. The server has access to minimal metadata, theoretically opening the door to deployment in adversarial environments.</p><p data-block-key="dlbh0">Along with this blog post, we’re also publishing:</p></div>
<a id="repo_link"></a>
<div><ul><li data-block-key="ds4bc">A <a href="https://github.com/freedomofpress/securedrop-protocol">proof-of-concept GitHub repository</a> that demonstrates the end-to-end protocol and documents how it works;</li><li data-block-key="911qd">And a <a href="https://securedrop.org/documents/31/202401_SecureDrop_Protocol_Audit_Report_mmaker.pdf">preliminary audit</a>, which also contains a concise summary of the protocol.</li></ul><p data-block-key="ck31n"><b>This is proof-of-concept code and is not intended for production use</b>. The protocol details are not yet finalized.</p></div>
<a id="discussion"></a>
<div><h2 data-block-key="9v8mk">Discussion</h2><p data-block-key="4vdmm">Let’s contextualize the four notable properties of the SecureDrop Protocol as enumerated above.</p><p data-block-key="aj4m4">The first property arises from the desire to <a href="https://securedrop.org/news/anatomy-of-a-whistleblowing-system/#deniability">maximize plausible deniability</a> for the source in a variety of situations, including repeated snapshotting of the server. The motivation for the second property is evident, but the implementation is less trivial: it’s one thing to <a href="https://signal.org/blog/sealed-sender/">conceal a sender</a>, but how does a server deliver a message to an unknown recipient? One approach is trial decryption — deliver all ciphertext to everyone, and valid recipients will determine locally which messages belong to them based on what their own secret keys can decrypt. But besides being inefficient, this would also introduce an information leak: it would allow anyone to constantly monitor the server state and know when messages are added and deleted, observe message upload patterns, and so on. In the context of a relatively low-traffic self-hosted system, this would represent a significant metadata leak, thus the need for our third property.</p><p data-block-key="g2vk">Finally, one of our additional goals is a graceful degradation of security properties, in case of different degrees of user or server compromise. Allowing anyone on the internet to observe ciphertext would allow for “harvest now, decrypt later” attacks, so the fourth property reflects the need to guard against such possibilities.</p></div>
<a id="comparison"></a>
<p><h3 data-block-key="k2n3w">Comparison of messaging protocols</h3></p>
<p><img alt="At-a-glance message protocol comparison" src="https://media.securedrop.org/media/images/message_protocol_comparison.width-1440.svg" srcset="https://media.securedrop.org/media/images/message_protocol_comparison.width-2880.svg 2x">
</p>
<small>1. While there isn’t a single standard library, the implementation is straightforward. <br>
2. <a href="https://eprint.iacr.org/2023/534.pdf">New iteration of the research focuses on groups.</a> <br>
3. SecureDrop Protocol does not preclude scalability, but scaling to mass adoption level (i.e. millions of users) is a <a href="https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/#design_principles">nonrequirement</a> for our purposes.</small>
<div><p data-block-key="k2n3w">The following is a highly simplified comparison of real-world message delivery approaches.</p><h4 data-block-key="9vu"><b>Trial decryption</b></h4></div>
<p><img alt="Trial Decryption" src="https://media.securedrop.org/media/images/trial_decryption.width-1440.svg" srcset="https://media.securedrop.org/media/images/trial_decryption.width-2880.svg 2x">
</p>
<div><p data-block-key="7gjk9">Trial decryption is a simple way to conceal recipient information. Payloads are encrypted for a given recipient, which in turn has full visibility of all the payloads in the system. As the name suggests, a recipient will discover which messages belong to them by trying to decrypt all the messages they receive.</p><p data-block-key="20l4e">Benefits to this approach include symmetry among user traffic (all users download all payloads) and lack of account creation requirement. Limitations include the lack of scalability, the information leak mentioned above, and the ability for an arbitrary attacker to collect payloads/ciphertext. This approach would satisfy requirements 1 and 2 (lack of accounts, lack of message flow metadata), but not 3 and 4 (externally-observable server state, bulk ciphertext collection).</p></div>
<div><h4 data-block-key="boqeg"><b>Signal Protocol</b></h4></div>
<p><img alt="Signal Protocol" src="https://media.securedrop.org/media/images/signal_protocol.width-1440.svg" srcset="https://media.securedrop.org/media/images/signal_protocol.width-2880.svg 2x">
</p>
<div><p data-block-key="e3aqs">Signal relies on accounts for both message submission and delivery. Only authenticated users can submit messages, and recipients must be specified outside the encrypted payload in order for the server to deliver the pertinent payloads at the next recipient login and fetch.</p><p data-block-key="2q0l">This message delivery approach has high delivery reliability, and is resource-efficient for the recipient, since only pertinent payloads are being downloaded and decrypted, but it would not support our transition towards a less trusted server. It satisfies properties 3 and 4 (no externally-observable server state changes, no bulk ciphertext collection), but not 1 and 2 (accounts, message flow metadata).</p></div>
<div><h4 data-block-key="bj0re"><b>Oblivious Message Detection/Retrieval (OMD/OMR)</b></h4></div>
<p><img alt="Oblivious Message Detection/Retrieval" src="https://media.securedrop.org/media/images/omd_omr.width-1440.svg" srcset="https://media.securedrop.org/media/images/omd_omr.width-2880.svg 2x">
</p>
<div><p data-block-key="a9b6l"><a href="https://eprint.iacr.org/2021/1256.pdf">Oblivious Message Detection and Retrieval is a newer message delivery mechanism</a> aimed at concealing the recipient and addressing the scalability issues of trial decryption by, in very broad terms, mixing pertinent and non-pertinent payloads, and using one or more “detector” servers to heuristically group, as well as distinguish, pertinent and non-pertinent content for a given user based on the “clues” assigned to each payload. (The idea of detecting/delivering messages in a way that makes them differentiable only by the receiver is an active research area; see also <a href="https://eprint.iacr.org/2021/089.pdf">Fuzzy Message Detection</a>.)</p><p data-block-key="f8mf3">Fuzzy message delivery is less feasible for small-scale systems like SecureDrop, where a burdensome level of decoy traffic would be required. In addition, OMR uses homomorphic encryption and other constructs that, at the time of writing, are relatively new, and pose some design challenges. The combination of the protocol's complexity and the bleeding-edge nature of some of the protocol's components gave us pause, although <a href="https://eprint.iacr.org/2023/534.pdf">research in this area</a>, particularly that focused on group messaging, is promising.</p></div>
<div><h4 data-block-key="cj7r2"><b>SecureDrop Protocol</b></h4></div>
<p><img alt="SecureDrop Protocol" src="https://media.securedrop.org/media/images/securedrop_protocol.width-1440.svg" srcset="https://media.securedrop.org/media/images/securedrop_protocol.width-2880.svg 2x">
</p>
<div><p data-block-key="3cemv">As with OMR, in the SecureDrop Protocol a sender sends the payload and a “clue” without any authentication. The recipient anonymously asks the server for clues, and the server serves both clues and decoys on every request. Every time a message-fetching request is made to the server, the response contains a new combination of clue and decoy ciphertext. Since every request returns a different response, and since the ciphertext is indistinguishable without being able to decrypt one or more of the clues, individual requests do not leak information about server state changes.</p><p data-block-key="60qe6">Message-fetching is a two-step operation. The recipient requests clues, and attempts trial decryption on them. For each successfully-decrypted clue, the recipient discovers a <code>message_id</code>. The <code>message_id</code> is a cryptographically unguessable value generated by the server upon message submission and kept private from all other parties. When an anonymous user discovers a <code>message_id</code>, they are able to fetch the corresponding message payload from the server. This two-step process is an optimization-related implementation detail, not a security measure.</p></div>
<a id="securedrop_protocol_details"></a>
<div><h3 data-block-key="6qff5">SecureDrop Protocol in detail</h3><p data-block-key="er4gd">Understanding SecureDrop Protocol’s message retrieval mechanism requires a basic understanding of <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange#Generalization_to_finite_cyclic_groups">classical Diffie-Hellman key agreement</a>. In particular, we take advantage of the notable properties that key agreement is commutative and can be extended to any number of parties.</p></div>
<p><img alt="SecureDrop Protocol - Multi-party async Diffie-Hellman" src="https://media.securedrop.org/media/images/sd_detail_async_multiparty_dh.width-1440.svg" srcset="https://media.securedrop.org/media/images/sd_detail_async_multiparty_dh.width-2880.svg 2x">
</p>
<center><small><i>Asynchronous three party Diffie-Hellman between sender, server, and recipient</i></small></center>
<div><p data-block-key="k2n3w">This diagram shows how the recipient of a message can agree with the server on a shared key <i>K</i> without learning anything about the state of the server – while preventing the server from knowing whether the recipient is indeed the intended one. Every <i>K</i> is obtained using: long-term key material, which later allows the correct recipient to detect their pertinent messages; per-message ephemeral key material, which introduces unlinkability between messages addressed to the same recipient; and per-request ephemeral key material via “remixed” clues, which provides unlinkability between message-fetching requests, since the clues are transformed before every request.</p><p data-block-key="f35a0">As shown in the next diagram, this scheme allows the server to obliviously encrypt and transfer some information using symmetric key <i>K</i>, without knowing if the requesting recipient will be able to decrypt it.</p></div>
<p><img alt="Oblivious Transfer of message_id" src="https://media.securedrop.org/media/images/securedrop_protocol_oblivious_transfer_messag.width-1440.svg" srcset="https://media.securedrop.org/media/images/securedrop_protocol_oblivious_transfer_messag.width-2880.svg 2x">
</p>
<center><small><i>Detail of the oblivious transfer of a message_id between the server and a recipient</i></small></center>
<div><p data-block-key="k2n3w">The material that is <i>obliviously-transferred</i> is the <code>message_id</code>, a securely random, unguessable value that the server generates upon message submission. Conceptually, it can be thought of as a server-side message uuid. Its main purpose is to keep clue sizes small, rather than encrypting and remixing full message payloads.</p><p data-block-key="euj75">Leveraging the commutativity of multi-party Diffie-Hellman to achieve unlinkability between requests is an uncommon application. We credit this contribution to former SecureDrop team member <a href="https://niij.org/">Michael Z</a>, who <a href="https://github.com/freedomofpress/securedrop-protocol/issues/16">resolved</a> what was a multi-month sticking point in our research.</p></div>
<p><img alt="SecureDrop Protocol: Message-Fetching Example" src="https://media.securedrop.org/media/images/sd_protocol_message_fetch_sample.width-1440.svg" srcset="https://media.securedrop.org/media/images/sd_protocol_message_fetch_sample.width-2880.svg 2x">
</p>
<center><small><i>Sample visualization of five fetch attempts from two valid and three invalid recipients, from a server containing 3 messages (values are symbolic)</i></small></center>
<p data-block-key="k2n3w">Why is the server “untrusted” if it generates secret key material? The server is “untrusted” in the sense that it should learn nothing about users and messages besides what is inherently observable from its pattern of requests, and it should not have access to sensitive metadata, or sender or receiver information. What the server must know are ciphertext payloads and associated clues that need to be stored. In this regard, the server is still a “privileged” asset that should not be queryable by anyone on the internet. That is why the server contributes with an ephemeral key: to hide its state and thus render all requests unlinkable to any change of such state.</p>
<a id="encryption"></a>
<p><h3 data-block-key="2k0v1">SecureDrop Protocol: encryption properties</h3></p>
<div><h4 data-block-key="e8es9"><b>Message retrieval symmetry despite source-journalist asymmetry</b></h4><p data-block-key="6uekb">Until now, we have commonly used the terms <i>sender</i> and <i>recipient</i> to indicate a role that a user can have. In classical messaging applications, all users can both receive messages and initiate conversations. In whistleblowing applications, the anonymized party (<i>source)</i> initiates communication with the trusted party (<i>journalist</i>). Our previous blog post outlines the difference in their endpoint requirements in detail, and describes the limitations on the type of key material that a source can have.</p><p data-block-key="eo80i">So, while both journalists and sources will use the same message retrieval mechanism and the same submission mechanism (and in practice, the same API endpoints), and are treated indistinguishably from the server’s perspective, their key setup is inherently different. This difference of roles and setup has a significant impact on the encryption properties we can achieve, especially in three areas: forward secrecy, participant authentication, and deniability.</p></div>
<div><h4 data-block-key="4cg4a"><b>Forward secrecy: It’s imperfect</b></h4><p data-block-key="4rthf">Forward secrecy requires ephemeral keys, implying an evolving state with some non-predictable, non-deterministic source of entropy. Forward secrecy requires that both parties use per-message ephemeral keys, and is commonly achieved by periodically re-generating secret-key material and then discarding it, like an automatic key-rotation procedure. Our <a href="https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/#design_principles">design constraints</a> allow for source-to-journalist forward secrecy, by rotating some journalist encryption key, but not vice versa: for usability reasons, we do not want to rotate a source passphrase, and we cannot add non-deterministic key material on the source side, since we <a href="https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/#design_challenges">cannot store it anywhere</a>. We consider the anonymity of the source a higher priority than the confidentiality of the material, so under these circumstances we accept this “one-way” form of forward secrecy.</p><h4 data-block-key="14ak5"><b>Participant authentication</b></h4><p data-block-key="50bl1">Consider a simple Diffie-Hellman key-agreement used with per-message ephemeral keys used for symmetric message encryption. A Diffie-Hellman key agreement is performed between the secret part of the per-message key and the public component of the recipient.</p><p data-block-key="73k5i">This kind of key agreement is unauthenticated: the recipient has no implicit or explicit proof that a particular sender sent that public key and ciphertext. This does not matter for a “first contact” message, which by definition comes from an anonymous/unknown party, but for ongoing conversations, some measure of participant authentication is required – essentially, to ensure that the source who began the conversation is indeed the one who is continuing it.</p><p data-block-key="fpefs">The question of participant authentication is an open problem that is interlinked with deniability. We see several fairly straightforward ways of addressing it; more discussion can be found <a href="https://github.com/freedomofpress/securedrop-protocol/issues/30">here</a>.</p><h4 data-block-key="1subm"><b>Deniability for sources</b></h4><p data-block-key="7ljhr">There are multiple layers at which SecureDrop seeks to create deniability: forensic deniability on a source’s own machine; forensic deniability on the server of the existence of a given source; and message-level cryptographic deniability.</p><p data-block-key="2uev3">The first forensic <a href="https://securedrop.org/news/anatomy-of-a-whistleblowing-system/#deniability">deniability property</a> is discussed at length in our previous posts and is orthogonal to the protocol; broadly, we satisfy it by avoiding writing to disk on the source’s machine. The second type of forensic deniability is served by the lack of server-side accounts; the only way to prove that a given party exists is to gain ciphertext addressed to them (a pending message) along with their key material.</p><p data-block-key="6v088">Conversation-level and message-level deniability require a more detailed discussion.</p><p data-block-key="9mvav">In cryptographic terms, deniability is often called <a href="https://cypherpunks.ca/~iang/pubs/dake-ccs15.pdf">repudiation</a>, of which participation repudiation and message repudiation are two forms. Repudiation and authentication are both important security principles, and yet, in some ways they appear at odds with one another: how can a protocol offer both authentication <i>and</i> the ability to deny sending a message or being part of a conversation?</p><p data-block-key="279as">The Signal Protocol does offer <a href="https://signal.org/docs/specifications/x3dh/x3dh.pdf">both repudiation attributes and implicit participant authentication</a> under <a href="https://eprint.iacr.org/2021/642.pdf">certain conditions</a>, via a clever use of multiple Diffie-Hellman key exchanges. Broadly, the implicit authentication comes from the use of long-term identity keys, while the deniability comes from the combination of approximately-discoverable public keys (via phone number/username, on Signal’s servers) and the idea that, while both parties must agree on a shared key to facilitate their conversation, neither party must sign their individual messages. Hypothetically, a conversation between two parties could be forged by one of the parties, providing the other with a measure of deniability.</p><p data-block-key="l7va">By contrast, the SecureDrop Protocol cannot provide conversation-level repudiation in cases where an ongoing source-journalist conversation is desired. This is because, while journalist public key material can and must be publicly discoverable so that anonymous sources can contact them, sources do <i>not</i> publish their public key material, and must attach it in their first-contact message so that journalists can reply, proving their participation in at least this initial message.</p><p data-block-key="dmq50">SecureDrop Protocol could theoretically support two modes: a true “dead drop” mode from a source that never intends to return or receive replies, and a conversational mode, in which the source expects to return and continue correspondence. In the former, the source achieves full deniability. In the latter, which is the more typical use-case, individual message repudiation can be achieved (as can participant authentication, mentioned above), but participation repudiation cannot. This issue is an area of <a href="https://github.com/freedomofpress/securedrop-protocol/issues/30">ongoing research</a>.</p></div>
<a id="diagram"></a>
<div><h4 data-block-key="k2n3w"><b>Putting it all together: message-fetching and encryption</b></h4><p data-block-key="1of6f">The following is a simplified illustration of the message-fetching and encryption in the SecureDrop Protocol. (Ephemeral keys have been omitted for illustrative purposes). The <a href="https://github.com/freedomofpress/securedrop-protocol/blob/main/imgs/sd_schema.png?raw=true">full protocol diagram can be found on GitHub</a>.</p></div>
<p><img alt="SecureDrop Protocol: Message-Fetching and Encryption (Simplified)" src="https://media.securedrop.org/media/images/sd_protocol_fetch_encryption_simplified.width-1440.svg" srcset="https://media.securedrop.org/media/images/sd_protocol_fetch_encryption_simplified.width-2880.svg 2x">
</p>
<a id="primitives"></a>
<div><h3 data-block-key="k2n3w">Cryptographic primitives</h3><p data-block-key="1j0ae">The proof-of-concept implementation uses <a href="https://doc.libsodium.org/">libsodium</a> for both key-agreement and symmetric encryption. That means, as of now, that our <a href="https://libsodium.gitbook.io/doc/key_exchange#algorithm-details">DH exchanges are powered by X25519</a> and our <a href="https://libsodium.gitbook.io/doc/secret-key_cryptography/secretbox#algorithm-details">authenticated symmetric encryption is powered by XSalsa20 and Poly1305 MAC</a>.</p><h4 data-block-key="293rs"><b>Post-quantum security?</b></h4><p data-block-key="3mbhl">Elliptic-curve Diffie-Hellman is not considered quantum-safe. There are various key encapsulation mechanisms we could make use of that are appropriate for encryption, however, we have not yet found a post-quantum-secure solution for the message-fetching mechanism in the protocol, which requires the commutative properties of multi-party ECDH discussed above.</p><p data-block-key="5m08n">The multi-party mechanism we describe is used to protect anonymized metadata from leaking information about the state of the server over time, similar to a network-level correlation attack. One possibility is a hybrid model where messages themselves (including their sender information and other metadata) are encrypted in a quantum-safe manner, while the message-retrieval mechanism remains usable with less future-proofing.</p><p data-block-key="ebh32">That said, this protocol will not transition to production-readiness until a thorough post-quantum security assessment has taken place.</p><p data-block-key="73bjq">Post-quantum readiness is an open research topic that we do not have the resources to address alone; we are grateful for the offers of assistance with post-quantum readiness that we have received, and we welcome additional collaboration in this area!</p></div>
<a id="audit"></a>
<div><h3 data-block-key="k2n3w">Preliminary audit</h3><p data-block-key="5hsep">In November 2023, we engaged cryptographic researcher <a href="https://michele.orru.net/">Michele Orrù</a> for a preliminary audit of the protocol and some of our claimed security properties, with a focus on the server state hiding and message unlinkability. The <a href="https://securedrop.org/documents/31/202401_SecureDrop_Protocol_Audit_Report_mmaker.pdf">full report is available here</a>, and a preliminary discussion of the findings can be found <a href="https://github.com/freedomofpress/securedrop-protocol/issues/36">on GitHub</a>.</p></div>
<div><h2 data-block-key="k2n3w">Next steps</h2><p data-block-key="92q2q">Astute readers will have wondered where the client side of this protocol takes place. We previously discussed the problem of browser-side encryption in “<a href="https://securedrop.org/news/anatomy-of-a-whistleblowing-system/#javascript">Anatomy of a Whistleblowing System</a>”, and we’ll have more to say on this topic soon.</p><p data-block-key="slm7">Later this year, we also expect to have the results of ongoing work on formally modeling the SecureDrop protocol, proving its security properties, and finalizing the specification for audit and publication.</p></div>
<a id="get_involved"></a>
<div><p data-block-key="c8p3g">In the meantime, we want to invite feedback from the security and cryptography community on this research. You can join <a href="https://lists.riseup.net/www/info/securedrop-e2ee-wg">our discussion list</a>, write to us privately at &lt;securedrop@freedom.press&gt;, or <a href="https://github.com/freedomofpress/securedrop-protocol/">get involved on GitHub</a>.</p><p data-block-key="ejdon">If you have expertise in post-quantum/quantum-resistant cryptography, we’d especially like to hear from you!</p></div>
<a id="acknowledgments"></a>
<div><h2 data-block-key="k2n3w">Acknowledgments</h2><p data-block-key="ptal">This research has been funded by Freedom of the Press Foundation (FPF) and is being led by SecureDrop team member <a href="https://github.com/lsd-cat">Giulio B</a>. <a href="https://github.com/TheZ3ro">Davide TheZero</a> and <a href="https://github.com/smaury">smaury</a> from security firm <a href="https://www.shielder.com/">Shielder SpA</a> have partnered in the research effort. The audit of our proposed framework was conducted by <a href="https://michele.orru.net/">Michele Orrù</a>.</p><p data-block-key="7791m">We’d like to acknowledge <a href="https://niij.org/">Michael Z</a> for their core contributions to this work, both as a SecureDrop team member and as an independent contributor.</p><p data-block-key="4ltbd">We would also like to thank the following people:</p><p data-block-key="3bmpb">Stuart Haber<br>Jennifer Helsby<br>David Liu<br>Olivia Murat<br>Guillermo Pascual Pérez<br>Paul Rösler<br>Eleanor Saitta<br>Jacob Young</p></div>
<div><h2 data-block-key="k2n3w">Appendix</h2><h3 data-block-key="fvdbb">Additional resources and links</h3><ul><li data-block-key="6k832"><a href="https://github.com/freedomofpress/securedrop-protocol-server-resty">Lua server</a> demonstrating another example SecureDrop Protocol implementation</li><li data-block-key="im2j"><a href="https://securedrop.org/documents/32/SecureDrop_Protocol_Deniability_primer_slides.pdf">Slide deck from SecureDrop presentation on deniability</a></li><li data-block-key="5k7ob"><a href="https://securedrop.org/documents/31/202401_SecureDrop_Protocol_Audit_Report_mmaker.pdf">Audit report</a></li><li data-block-key="6sv50"><a href="https://github.com/freedomofpress/securedrop-signal-poc">Original proof-of-concept repository based on the Signal Protocol</a></li></ul><h3 data-block-key="50ltg">Timeline</h3><ul><li data-block-key="e346u">October 2020: First commit in <a href="https://github.com/freedomofpress/signal-protocol">https://github.com/freedomofpress/signal-protocol</a></li><li data-block-key="7sojs">November 2021: Working demo of <a href="https://github.com/freedomofpress/securedrop-signal-poc">https://github.com/freedomofpress/securedrop-signal-poc</a></li><li data-block-key="273ur">January 2022: Internal open discussion on the code integrity problem; JavaScript discussion and necessary steps for any end to end encryption</li><li data-block-key="c1vg0">July - October 2022: Various team meetings, discussion advances</li><li data-block-key="cnjsb">January - February 2023: Initial proof-of-concept development with <a href="https://www.shielder.com/">Shielder</a>, first external feedback requests</li><li data-block-key="9n0uo">October 2023: <a href="https://github.com/freedomofpress/securedrop-poc/issues/16">Final version of the message delivery protocol</a></li><li data-block-key="ce3hc">November 2023: Team members participate in IETF; initial outreach to cryptographers</li><li data-block-key="3f6mo">November 2023: Engaged <a href="https://github.com/mmaker">Michele Orrù</a> for the audit</li><li data-block-key="b22vk">January 2024: Audit report, ongoing outreach to and collaboration with cryptographers</li></ul></div>
</section>
</article></div>]]></description>
        </item>
    </channel>
</rss>