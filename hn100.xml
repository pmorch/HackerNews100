<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 11 Sep 2023 16:00:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[X sues Calif. to avoid revealing how it makes “controversial” content decisions (135 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/</link>
            <guid>37467607</guid>
            <pubDate>Mon, 11 Sep 2023 14:15:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/">https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/</a>, See on <a href="https://news.ycombinator.com/item?id=37467607">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      "Rebranding censorship"    —
</h4>
            
            <h2 itemprop="description">X decried law's "draconian financial penalties," up to $15K per violation per day.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/GettyImages-1563274899-800x532.jpg" alt="X sues Calif. to avoid revealing how it makes “controversial” content decisions">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 35:single/related:c4dbb0a9ea6a9aff2f1f0298bc009002 --><!-- empty -->
<p>Today, Elon Musk's X Corp. <a href="https://cdn.arstechnica.net/wp-content/uploads/2023/09/X-Corp-v-Bonta-9-8-2023-Complaint.pdf">sued</a> to block California's content moderation law, AB 587. In its complaint, filed in a US district court in California, X Corp. is seeking a preliminary and permanent injunction stopping California Attorney General Robert Bonta from enforcing the law.</p>
<p>AB 587 passed in September 2022, requiring social media platforms to submit a "terms of service report" semi-annually to California's attorney general, providing "a detailed description of content moderation practices used" and "information about whether, and if so how, the social media company defines and moderates" hate speech or racism, extremism or radicalization, disinformation or misinformation, harassment, and foreign political interference. Under the law, social media platforms must also provide information and statistics on any content moderation actions taken in those categories.</p>
<p>In X's complaint, the company accused California of trying to dictate X's terms of service and compel "controversial disclosures about how X Corp. moderates content on its platform."</p>
<p>The law stipulated that all platforms were required to start collecting data for their first terms of service report covering content moderation during the third quarter of 2023 and submit those reports to Bonta by January 1, 2024.</p>
<p>Platforms could be found violating the law for failing to post terms of service about content moderation, missing a deadline to submit a terms of service report, or materially omitting or misrepresenting information about content moderation. Any platform violating the law risks fines—which X described as "draconian financial penalties"—up to $15,000 per violation per day.</p>
<p>In its complaint, X Corp. argued that AB 587 violates the First Amendment by compelling "companies like X Corp. to engage in speech against their will" and "impermissibly" interfering "with the constitutionally protected editorial judgments of companies." X Corp. said that if the court did not block the law, California could pressure companies "to remove, demonetize, or deprioritize constitutionally protected speech that the state deems undesirable or harmful."</p>
<p>"The State of California touts AB 587 as a mere 'transparency measure' under which certain social media companies must make their content moderation policies and statistics publicly&nbsp;available," X's complaint said. But, X alleged, the state's "true intent" is "to pressure social media platforms to 'eliminate' certain constitutionally protected content viewed by the state as problematic."</p>                                            
                                                        
<p>X Corp. alleged that AB 587 violates other laws, including the Dormant Commerce Clause—"failing to restrict its extensive reporting requirements to information about Californians"—and Section 230 of the Communications Decency Act—which grants platforms immunity from liability for “any action voluntarily taken in good faith to restrict access to or availability of material that the provider or user considers to be obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such material is constitutionally protected.”</p>
<p>"Because AB 587 imposes liability on such actions if they are taken without the required disclosures, AB 587 is preempted by the broad immunity afforded by Section 230," X's complaint said.</p>
<p>Ars could not immediately reach X for comment. Bonta's office said: “While we have not yet been served with the complaint, we will review it and respond in court.”</p>
<p>The author of AB 587, California assemblymember Jesse Gabriel, released a statement saying that the law "is a pure transparency measure that simply requires companies to be upfront about if and how they are moderating content. It in no way requires any specific content moderation policies—which is why it passed with strong, bipartisan support. If Twitter has nothing to hide, then they should have no objection to this bill.”</p>
<p>But tech groups and policy experts echoed X's concerns over AB 587.</p>
<p>Adam Kovacevich, the CEO of the tech industry policy coalition Chamber of Progress, said that "requiring companies to give their content moderation playbook to scammers and conspiracists is a bad idea."</p>
<p>“Even if you don't like anything about Elon Musk’s leadership of X, it’s clear that requiring tech platforms to publish a detailed blueprint of how to work around content moderators will have negative consequences for users online," Kovacevich said. "Letting platforms set their own editorial standards also leaves consumers with more choices about what kind of platforms they spend time on.”</p>
<p>Netchoice, a group representing tech companies and trade associations, has called AB 587 "the Golden State’s new online censorship law." In a statement about X Corp.'s lawsuit, Netchoice said that the law would force companies to submit "intrusive" and "often impossible to comply with" disclosures "about constitutionally protected editorial decisions." Netchoice's director of litigation, Chris Marchese, said that the court should enjoin AB 587 to protect free speech online.</p>
<p>“The First Amendment prohibits the government from regulating lawful speech—directly or indirectly," Marchese said. "States cannot avoid this prohibition by rebranding censorship as ‘transparency’ requirements."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[9/11 in Realtime (142 pts)]]></title>
            <link>https://911realtime.org:443/</link>
            <guid>37467077</guid>
            <pubDate>Mon, 11 Sep 2023 13:38:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://911realtime.org:443/">https://911realtime.org:443/</a>, See on <a href="https://news.ycombinator.com/item?id=37467077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <li> <h2>9/11 Realtime</h2> <p><b>Thanks and Open Source Notices</b></p> <h2>Thank you to our backers:</h2> <ul> <li>Will Harris</li> <li>Chris Wooster</li> <li>Robinson Collado</li> <li>Richard Harms</li> <li>Matt MG Herron</li> <li>Adil Majid</li> <li>Alana Malone</li> <li>Kori Stephens</li> <li>Marina Harper</li> <li>James Wendel</li> <li>Jason Smith</li> <li>Adam Garst</li> <li>Andrew Poirier</li> <li>Ty Satrang</li> </ul> <h2>Special thanks to <a href="http://hivelocity.net/">Hivelocity</a></h2> <p><b>Based on Platinum by Robbie Byrd</b></p> <p>A UI framework using native CSS/JS replications of the Mac OS 8.1 interface components. The project is named after the interface theme that came with MacOS 8 and 9, Platinum.</p> <p><a href="https://github.com/robbiebyrd/platinum" target="_blank">Platinum on Github</a></p> <p><b>Based on memento.js by Vijith Assar</b></p> <p><a href="https://github.com/vijithassar/memento" target="_blank">memento.js on Github</a></p> <p> Based on <b><a href="https://github.com/npjg/classic.css" target="_blank">New Dawn</a></b> by <b><a href="https://github.com/npjg" target="_blank">Nathanael Gentry</a></b>. </p><p>Copyright (c) 2019 Nathanael Gentry</p>  <p> Based on <b><a href="https://github.com/ticky/classic-scrollbars" target="_blank">Scrollbars of the Classic Mac OS</a></b> by <b><a href="https://github.com/ticky" target="_blank">Jessica Stokes (@ticky)</a></b>. </p> <hr> <p><b>New Dawn</b> and <b>Platinum</b> License</p> <div><p> MIT License </p><p>  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: </p></div> <div><p> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. </p><p>  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. </p></div> <p>A huge thanks to Apple, Inc., who maintains the copyright on the Apple Icon, background patterns, interface sounds and interface components.</p>  </li> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Networking for introverts (119 pts)]]></title>
            <link>https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide</link>
            <guid>37466147</guid>
            <pubDate>Mon, 11 Sep 2023 12:20:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide">https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide</a>, See on <a href="https://news.ycombinator.com/item?id=37466147">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><h2>Making the business of meeting strangers marginally less awful</h2></section><div><div data-body-id="cp2"><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/060%20Business%20-%20Bartleby%20copy-452e13ecc2cba8a5207cbc25654ef43a.mp3" title="Networking for introverts: a how-to guide " controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p data-component="paragraph"><span data-caps="initial">C</span><small>orporate life</small> throws up some stressful moments. Bringing bad news to your boss; facing an interview panel; making a big presentation. But few things are worse than networking if you are an introvert.</p><p data-component="paragraph">You arrive at an event to find that everyone there apparently knows each other already. And then you look more closely and spot the fellow-sufferers. They are the people who are actually reading the conference blurb. They look at email on their phones with greater intensity than ever happens at the office. They endlessly circulate the room, like bits of plastic in the ocean waiting to be snagged on something. They take a seat in the main hall while the sound engineers are still testing the microphones.</p><p data-component="paragraph">Fortunately, there is advice out there on how to break the ice with strangers. Unfortunately, it’s abysmal. One sage counsels making contact in queues, because it is easier to talk to the person in front of you and behind you. You are meant to ambush people on the escalator, in the toilets and in the queue to get your name tag. In the line for coffee, open the door to jobs and sales by saying six incomprehensible words: “Juicing up for the big keynote?”</p><p data-component="paragraph">On it goes. Don’t be afraid to laugh, because nothing drains the tension from a room like someone who cannot stop chuckling. Bring personal information into the conversation, lest people think you are at a conference on treasury-management software only for commercial gain. Use the other person’s name twice, to appear truly engaged. And take notes on conversations afterwards so you can follow up with them.</p><p data-component="paragraph">Add these ingredients together, and you have the recipe for success:</p><p data-component="paragraph">“Juicing up for the big keynote?”</p><p data-component="paragraph">“What?”</p><p data-component="paragraph">“Juicing up for the big keynote?”</p><p data-component="paragraph">“I don’t know what that means.”</p><p data-component="paragraph">[Scan name badge] “Keith, is it?”</p><p data-component="paragraph">“Er, yes.”</p><p data-component="paragraph">[Laughing] “I’m having a baby, Keith.”</p><p data-component="paragraph">“Keith?”</p><p data-component="paragraph">[Take out notepad]</p><p data-component="paragraph">If this is how to network, no wonder people go to the main hall early.</p><p data-component="paragraph">Making contacts on a site like LinkedIn is a lot less stressful. There is no eye contact, after all, and the rules of the road are agreed. And all those connection requests do appear to help with careers. A paper published last year by Karthik Rajkumar of LinkedIn and co-authors from academia found empirical evidence for the insight that underpins all kinds of networking—that, because they bring you new information, more infrequent and distant relationships (or “weak ties”) are more useful than close contacts.</p><p data-component="paragraph">The researchers randomly changed the “People You May Know” recommendations algorithm that LinkedIn shows its users, so that the prevalence of weaker and stronger connections varied among people on the site. The experiment showed that weaker ties (where a pair of users had only one mutual friend, say) were more likely to lead to job applications and job moves than those where people had 25 mutual friends or more.</p><p data-component="paragraph">This sounds like nirvana for introverts: start spamming everyone with connection requests, close the office door and wait for job offers. But it is not that easy. Even weak ties need tending. Even online, interacting with people is easier if you find it energising; a survey-based study of LinkedIn, by Joanna Davis of Augustana College and her co-authors, found that extroversion was a predictor of networking ability.</p><p data-component="paragraph">There isn’t a genuinely painless way for introverts to network. Still, methods to do it exist that are wiser than standing in a queue and hoping the guy who doesn’t know how to get coffee out of the machine is your ticket to career success.</p><p data-component="paragraph">The real secret is to save your energy for the people who are most likely to be interesting to you. In the online realm, for instance, Dr Rajkumar’s study does not find that the weaker the tie, the better. The sweet spot in networking on LinkedIn is someone with moderately weak ties to you: connecting with a person with ten mutual friends markedly increases the probability of changing jobs compared with someone with just one shared friend.</p><p data-component="paragraph">In other words, networking pays off if you can identify people who can bring you new information but are close enough to your world that this information is useful. In the offline world, a tool like Chat<small>GPT</small> should make it easier to find useful prospects in a list of event attendees. But you still need to overcome all your instincts and approach them.<span>■</span></p><p data-component="paragraph"><b>Read more from Bartleby, our columnist on management and work:<br></b><i><a href="https://www.economist.com/business/2023/08/31/the-best-bosses-know-how-to-subtract-work">The best bosses know how to subtract work</a> (Aug 31st)<br></i><i><a href="https://www.economist.com/business/2023/08/24/the-benefits-of-a-good-workplace-mentoring-scheme-are-undeniable">How to get the most out of mentoring</a> (Aug 24th)<br></i><i><a href="https://www.economist.com/business/article66888-prod.ece" target="_blank">A retiring consultant’s advice on consultants</a> (Jul 17th)</i></p><p data-component="paragraph"><i>Also: How the Bartleby column <a href="https://www.economist.com/column-names">got its name</a></i></p></div><p>This article appeared in the Business section of the print edition under the headline "Stranger things"</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/business/">Business</a> <span>September 9th 2023</span></h2><ul><li><a href="https://www.economist.com/business/2023/09/03/meet-ernie-chinas-answer-to-chatgpt"><span>Meet Ernie, China’s answer to ChatGPT</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/german-builders-are-on-the-brink-of-collapse"><span>German builders are on the brink of collapse</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/tiktok-is-wading-into-south-east-asias-e-commerce-wars"><span>TikTok is wading into South-East Asia’s e-commerce wars</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/a-strike-at-chevron-shows-a-reinvigorated-union-movement"><span>A strike at Chevron shows a reinvigorated union movement</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/meet-the-worlds-most-enduring-product"><span>Meet the world’s most enduring product</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide"><span>Networking for introverts: a how-to guide</span></a></li><li><a href="https://www.economist.com/business/2023/09/04/americas-bosses-just-wont-quit-that-could-spell-trouble"><span>America’s bosses just won’t quit. That could spell trouble</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="The new Middle East: The promise and the perils" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20230909_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20230909_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20230909_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20230909_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20230909_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20230909_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20230909_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20230909_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20230909_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20230909_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20230909_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20230909_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20230909_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20230909_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20230909_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230909_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230909_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the September 9th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-09-09" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Project Gutenberg Open Audiobook Collection (163 pts)]]></title>
            <link>https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html</link>
            <guid>37466027</guid>
            <pubDate>Mon, 11 Sep 2023 12:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html">https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37466027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="particles">
        
        <p><strong>Thousands of free and open audiobooks powered by Microsoft AI</strong></p>
      </div><div id="Paper">
    <h2>Paper</h2>
    <div>
      <p>
        <h2>For more technical information on the code used to generate these audiobooks please see our IEEE Big Data paper: <a href="https://arxiv.org/abs/2009.08044">Large Scale Intelligent Microservices</a>‍<br></h2>
        
      </p>
      <p>@article{hamilton2020large,<br> &nbsp;title={Large-Scale Intelligent Microservices},<br> &nbsp;author={Hamilton, Mark and Gonsalves, Nick and Lee, Christina <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and Raman, Anand and Walsh, Brendan and Prasad, Siddhartha<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and Banda, Dalitso and Zhang, Lucy and Zhang, Lei and Freeman, William T},<br> &nbsp;journal={arXiv preprint arXiv:2009.08044},<br> &nbsp;year={2020}}</p>
    </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The right to data ownership is the only way to take on Big Tech (122 pts)]]></title>
            <link>https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/</link>
            <guid>37465972</guid>
            <pubDate>Mon, 11 Sep 2023 12:02:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/">https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/</a>, See on <a href="https://news.ycombinator.com/item?id=37465972">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="article-body-text">
  
  

	

	
	

	
	



  
  
    <p>Today, giant technology companies are more powerful than any nation state. Their whims set the political agenda.&nbsp;</p><p>Ian Bremmer calls this “technopolarity”, describing how digital power defines politics and reshapes the world. For example, consider their enthusiasm for AI regulation: laws which could in theory be written and enforced by them.&nbsp;</p><p>This does not seem healthy for either the economy or our democracy – so can anything on Earth stop Big Tech?</p><p>One argument is that we should not worry. As sure as eggs are eggs, we are told, a period of market dominance will be followed by hubris, in a self-correcting cycle.&nbsp;</p><p>Just look at Microsoft, they say. Twenty-five years ago this month, the software company surpassed General Electric to become the most valuable on the planet.&nbsp;</p><p>The same month, a tiny new company with an odd name was formally incorporated. It called itself Google. By 2012, it had overtaken Microsoft’s market capitalisation, although Microsoft has subsequently caught up.&nbsp;</p><p>This week, <a href="https://www.telegraph.co.uk/business/2023/09/10/google-monopoly-lawsuit-antitrust-trial-doj-kent-walker/" target="_blank" rel="noopener noreferrer">the biggest antitrust trial</a> since the American government took on Microsoft begins – and this time it is Google who is in the dock. So don’t worry about monopolies: it seems the system takes care of itself. Everything is for the best in all possible worlds, as Voltaire’s Dr Pangloss assured us.</p>
  
</div><div data-test="article-body-text">
  
  

	

	
	

	
	



  
  
    <p>How neat this is – perhaps too neat. For a start, monopoly profits ought to see private capital flooding into startups and would-be rivals, to grab their market share.&nbsp;</p><p>Startups like Neeva, for example, the search engine I wrote about last year, founded by top ex-Google executives and engineers. Its search results were so good, compared to Google’s, <a href="https://www.telegraph.co.uk/technology/2022/05/30/seen-google-free-future-like-breathing-clean-air/" target="_blank" rel="noopener noreferrer">they were like a breath of fresh&nbsp;air</a>. More fool me, though.</p><p>Neeva announced it was closing down for good in May, unable to make a business out of its superior product. In fact, there has not been a major new platform to challenge the incumbents for well over a decade. Capital keeps finding other things to fund, even some very silly things, like lab grown meat.</p><p>But advocates of strong competition law also have a problem. Very often, <a href="https://www.telegraph.co.uk/news/2023/06/15/the-eu-might-just-break-the-internet/" target="_blank" rel="noopener noreferrer">the authorities are all bark</a>, and no bite – and the European Union is one of the worst offenders in this regard.&nbsp;</p><p>The top Silicon Valley lawyer behind the Microsoft antitrust case, Gary Reback conceded as much when he also advised us not to worry. The mere act of competition scrutiny benefits the market: “the trial is the remedy”, he has said.</p><p>But very often the competition watchdog’s intervention seems to have no impact at all, and has only made the dominant player stronger. Google has run rings around competition authorities by appearing to take it on the chin, then offering up a less onerous behavioural remedy.&nbsp;</p><p>This is accepted and life carries on much as before. Structural remedies do not necessarily improve things much either. When in 2000, a Microsoft breakup was privately shopped around its computer rivals, it seemed nobody wanted to take any of the chopped up pieces of the company.</p><p>So if doing nothing is not an option and doing something is ineffective, what else is left to do?&nbsp;</p>
  
</div><div data-test="article-body-text">
  
  

	

	
	

	
	



  
  
    <p>Something needs to change, for just as advocates of the theory of network effects predicted, online markets are winner-takes all markets. Big Tech only ever seems to get bigger.</p><p>But do not despair – the answer may be a very old one.</p><p>Today, Google is no more about web search or maps than those American candy shops on Oxford Street are in the business of selling sweets. That is what we see when we walk past, but it is not really what they do.&nbsp;</p><p>Google and Meta, Facebook’s parent company, are giant personal data processing companies. But because of a peculiar loophole, they get that data for free – it doesn’t “belong” to anyone.&nbsp;</p><p>If only we were allowed to assert ownership of our data, in the form of a strong property right, we could start to do some interesting things with it.&nbsp;</p><p>We could demand its destruction, because it would be ours, giving us much stronger privacy protection than we enjoy today. We would also be able to trade it and do the one thing we cannot currently – help determine its value.&nbsp;</p><p>Our decisions would help set the price for this data. This is not a popular idea with everyone. Academics and the digital NGOs, a familiar looking blob, hate the prospect, in part because it leaves them with a diminished political role, if any at all.</p><p>The computer scientist Jaron Lanier, the best-known advocate of the idea of stronger property rights, says “some people are horrified by the idea of capitalism online, but this would be a more honest capitalism. The familiar ‘free’ arrangement has been a disaster.” He calls it “Data Dignity”.</p><p>I am not suggesting property rights are a panacea, or a replacement for careful and enlightened competition enforcement by nation states. But in the spirit of experimentation, should we not try the one thing we have not actually tried online yet – capitalism?</p>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing Garbage Collection from the Rust Language (2013) (127 pts)]]></title>
            <link>http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html</link>
            <guid>37465185</guid>
            <pubDate>Mon, 11 Sep 2023 10:23:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html">http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html</a>, See on <a href="https://news.ycombinator.com/item?id=37465185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>I've been floating ways to simplify the memory management story in Rust around the core team lately. Memory management is a contentious topic, since we've worked hard to get to the current state of things, and with the push toward stability lately, there is a (quite reasonable!) resistance to any changes at this state. Still, I think the current memory management story in Rust is worth revisiting, as the current state of things may cause us problems down the line. Working with Dave Herman and Niko Matsakis, I've formulated a fairly concrete proposal at this point. The basic idea is to <em>remove garbage collection from the core language and relegate it to the standard library</em>, with a minimal set of language hooks in place to allow for flexible, pluggable automatic memory management.</p>
<p>This post is designed to explain the "why", not the "how"—I'm leaving the concrete details of the proposed system to a future blog post or mailing list discussion. Rather, this explains the issue that I see with the current system. I think that the garbage collection story as it stands in Rust is not quite ideal, for three reasons: <em>familiarity</em>, <em>simplicity</em>, and <em>flexibility</em>. I'll cover each in turn.</p>
<h2>Familiarity</h2>
<p>One of the most common questions almost every Rust beginner asks is "when do I use managed pointers, and when do I use owned pointers?" Or, more simply, "what are all these <code>~</code> and <code>@</code> symbols everywhere?" Having worked on Rust for many years now, I've seen several reasons for the difficulty. Chief among them are:</p>
<ol>
<li>
<p><em>The difference between the stack and the heap is a difficult concept to grasp for many programmers used to languages like Java that don't make such a distinction.</em> This is, unfortunately, a fundamental difficulty of working in a systems language. There's little that can be done about this without taking control of allocation out of the hands of the programmer. Doing that, however, would compromise the goals of the language—in low-level, performance-critical programming, being able to precisely control whether allocations occur on the stack or on the heap is crucial.</p>
</li>
<li>
<p><em>The sigils make the code unfamiliar before the concepts are learned.</em> Unlike the rest of the punctuation in Rust, <code>~</code> and <code>@</code> are not part of the standard repertoire of punctuation in C-like languages, and as a result the language can seem intimidating. One of the benefits of keywords is that they are self-documenting in a way that punctuation is not. This could be fixed by switching to keywords, which I prefer for this reason; however, syntactic beauty is in the eye of the beholder and so I won't lose sleep over this not changing if the community prefers the current syntax.</p>
</li>
<li>
<p><em>There are two heaps, not just one, so beginners are confused as to which one to allocate into.</em> This is a result of the "minimize sharing by default" philosophy of the concurrency system. However, the concurrency system has been part of the <em>library</em> rather than the language for several years now, so this seems somewhat out of place.</p>
</li>
<li>
<p><em>Programmers don't know which to use, since some operations are available with <code>~</code> and some operations are available with <code>@</code></em>. Actually, we were confused on this point for a long time as well—it wasn't clear whether <code>~</code> or <code>@</code> would become dominant. We debated for a long time which to present first, <code>~</code> or <code>@</code>. However, as the language and community evolved, and coding standards became more settled, a clear winner emerged: the owning pointer <code>~</code>. In practice, the rule has been that <em>programmers should use <code>~</code> to allocate in all circumstances except when they have no way of knowing precisely when the object in question should be freed.</em></p>
</li>
</ol>
<p>Point (4), to me, is the most critical. The rule that emerged—<code>~</code> over <code>@</code>—should not be surprising, in retrospect, as it is how systems software has been developed for decades. The key insight that was missing is that <em>the owning pointer <code>~</code> is just the Rust equivalent of <code>malloc</code> and <code>free</code>.</em> For many, probably most C programs, <code>malloc</code> and <code>free</code> are just fine (assuming you use them correctly, of course); each heap allocation is allocated in just one place and destroyed in just one place. Only when the lifetimes of objects become very complex do C and C++ programmers resort to manual reference counting to determine when an object should be freed (and many, perhaps most, C programs never get there). <em>This</em> is the role that has emerged for <code>@</code> in Rust programs: <code>@</code> is a replacement for manual reference counting in C programs. The <code>kobject</code> system in the Linux kernel, the <code>GObject</code> system in <code>glib</code>, and so forth, are the C equivalents of <code>@</code> in Rust.</p>
<p>The key point here is that these are very specialized use cases in C, and <code>@</code> has been relegated to a similarly marginal role in idiomatic Rust code. We thought for a while that many Rust programs would use <code>@</code> extensively and that it would ease the learning curve for those not used to destructor-based memory management and references. This has not, however, been the case in practice. In reality, since the libraries all use owning pointers (<code>~</code>), Rust programmers have to learn them quickly anyhow. And once Rust programmers learn how to use <code>~</code> effectively, they quickly find <code>@</code> relegated to a marginal role, if it's used at all. <code>~</code> has so many advantages: deterministic allocation and destruction, interaction with the standard library, freedom from GC marking pauses, simpler semantics, appendability where vectors and strings are concerned, and sendability across tasks.</p>
<p>I think we're better off teaching <code>~</code> as the go-to solution for most programs and relegating <code>@</code> to a specialized role. <code>@</code> has its use cases, to be sure; large, event-driven C++ programs use reference counting for a reason. But those use cases are specialized. Beginners should not be asking "should I use <code>~</code> or <code>@</code>?" The answer is almost always <code>~</code>.</p>
<p>In this regard relegating <code>@</code> to a library is just the natural conclusion of this approach. I feel that what beginners should be taught is that <code>~</code> is the way to allocate in Rust, and letting an <code>~</code> owning pointer go out of scope is the way you free in Rust. This is what we should be teaching in the <em>language</em> tutorial. As beginners become more comfortable with this and explore the libraries, they will learn about ways to achieve more dynamic memory management: tracing garbage collection with the <code>Gc</code> type, reference counting with the <code>Rc</code> type, and thread-safe reference counting with the <code>Arc</code> type. But by building only <code>~</code> into the language, we can reduce confusion by, in effect, making the language more opinionated.</p>
<h2>Simplicity</h2>
<p>Although Rust didn't start out that way, one of the most interesting applications of Rust has been very low-level programming, even down to the level of kernels. The interest in this application of Rust was something of a surprise to us, but in hindsight it makes perfect sense. Low-level control over memory management isn't something that most applications software, especially on the server side, wants; most of that software has migrated over to languages like Java, Ruby, and JavaScript that trade control and performance for convenience by making memory management automatically, and dynamically, managed by the runtime. The remaining class of software, most of which is written in C and C++, is software that must manage memory manually in order to achieve some combination of performance, simplicity, and/or the ability to self-host. The prospect of using a new language for <em>this</em> class of software, which includes OS kernels, game engines, and browser engines among others, is what is fueling the growth of the nascent Rust community.</p>
<p>It might be possible to create a language that presents only a simple, fully automatic memory management system at first, and which surfaces the machinery of safe manual memory management* only when the programmer requires it for maximum performance. This would ease the learning curve, as programmers would be able to write many, perhaps most programs without ever learning how to manage memory at all. However, at this point I don't think that this language exists yet, and in particular I don't think Rust is that language. There are basically two problems here: (1) <code>~</code> owning pointers are everywhere in Rust, from the standard library to the built-in macros, making learning about them a necessity from the get-go; and (2) it is basically impossible to program Rust without at least a cursory understanding of references (a.k.a. <code>&amp;</code> pointers) and their lifetime semantics; even <code>vec::each()</code> uses references.</p>
<p>Despite the fact that this might seem like a negative result, I actually think it's quite positive for the project. It helps to define the project's scope. I don't think automatic memory management in Rust is ever going to be as convenient as memory management in, say, Ruby or Java, and that's OK! <em>The same level of control that adds cognitive overhead to memory management in Rust compared to other languages also makes Rust able to go where few other industry languages have.</em> This space, I think, is where Rust can really shine.</p>
<p>In short, I think that Rust as a <em>language</em> should focus on roughly the same application domain as C++ does.†</p>
<p>Important to this effort is to have as small of a runtime as possible, just as C++ does, leaving higher-level abstractions to libraries. And, in fact, we are almost there already. The only runtime support that compiled Rust programs require are a small set of "language items", which are magic functions or traits written <em>in Rust</em> that are known to the compiler. Looking at the set of language items, and disqualifying legacy items that will be removed soon such as <code>annihilate</code> and <code>log_type</code>, there are just a few categories:</p>
<ol>
<li>
<p>Operator traits, like <code>Add</code> and <code>Sub</code>. These are analogous to <code>operator+</code>, <code>operator-</code>, and so forth in C++.</p>
</li>
<li>
<p>Memory primitives, like <code>str_eq</code>. These are somewhat legacy at this point and probably could be converted to LLVM intrinsics like <code>memcmp</code> without much trouble, especially after dynamically sized types happens. In any case, in most C++ compilers <code>memcmp</code> and friends are builtins.</p>
</li>
<li>
<p>Failure: <code>fail</code> and <code>fail_bounds_check</code>. This is analogous to <code>throw</code> in C++, although a Rust program that doesn't want to use stack unwinding might want to use <code>abort</code> instead (which would be like <code>-fno-exceptions</code>) or do something more elaborate like the Linux kernel's "oops" functionality.</p>
</li>
<li>
<p>Allocation primitives <code>malloc</code> and <code>free</code>. These have direct C++ equivalents: <code>operator new</code> and <code>operator delete</code>.</p>
</li>
<li>
<p>Garbage collection primitives.</p>
</li>
</ol>
<p>Of these, the only language items that don't have direct C++ equivalents are the garbage collection primitives. If those were eliminated, then Rust as a language would be every bit as freestanding as C++ is. In terms of suitability for kernel and embedded development, Rust would be on truly equal footing.</p>
<p>In summary: (1) all Rust programmers have to know how <code>~</code> and <code>&amp;</code> work, despite the presence of <code>@</code>; (2) the only additional runtime primitives that Rust exposes and C++ doesn't are those related to <code>@</code>.</p>
<h2>Flexibility</h2>
<p>When it comes to memory management, there are obviously many different strategies: stack allocation, heap allocation with <code>malloc</code> and <code>free</code>, arena allocation, and garbage collection. What's less well known is that even among garbage collection, there are many different approaches, each with advantages and disadvantages. There's thread-local GC, thread-safe GC, incremental GC, generational GC, reference counting, thread-safe reference counting, deferred reference counting, ulterior reference counting—the list goes on and on. (For a good survey of automatic memory management techniques and how they relate to one another, check out <a href="http://www.cs.virginia.edu/~cs415/reading/bacon-garbage.pdf">"A Unified Theory of Garbage Collection" by Bacon et al.</a>) A program that wants to maximize performance among some axis (latency versus throughput) and remain safe with objects with complex lifetimes may have reasons to choose one or the other.</p>
<p>Specifically, there's the perennial debate between reference counting and tracing garbage collection. Many applications are better with tracing GC because of the increased throughput it provides and straightforward handling of cycles, and many applications are better with reference counting because of implementation simplicity, cache behavior, mostly-incremental operation, and promptness of deallocation. It makes sense for applications to be able to choose between the two. Even more important is the tradeoff between thread-safe and thread-local garbage collection: concurrent garbage collection is practically always more expensive than thread-local garbage collection, so it makes sense for programs to restrict concurrent GC (including atomic reference counting) to be used only when needed.</p>
<p>Integrating multiple tracing garbage collectors or cycle collectors into one system is a hard problem, and I don't think Rust is going to really solve it. However, integrating reference counting into a garbage collected system is straightforward, as long as cycles are not created (and in Rust we can forbid the creation of such cycles through clever use of the type system). In practice this seems to work well: we typically use thread-local tracing GC for data with complex lifetimes within one task, and we use thread-safe reference counting for data that must be shared between tasks.</p>
<p>Equally important is the ability to integrate with <em>external</em> garbage collection systems (usually reference counted ones). This is a problem that is often overlooked, but is terribly important for client software such as mobile apps and browser engines. On Windows, apps must integrate with the reference-counted COM system in order to use DirectX and other APIs. On the Mac and on iOS, apps have to integrate with Objective-C and the closely-related Core Foundation, also reference-counted systems. On Linux, GNOME apps have to integrate with GObject, again a reference-counted system. On Android, apps have to integrate with the garbage-collected Dalvik subsystem via the JNI. All of this requires that the memory management system in the language be deeply flexible.</p>
<p>Because of this, I'm suspect of blessing any particular form of automatic memory management in the core language. In Rust, the <code>@</code> type is not only blessed with special syntax, but is eligible for borrowing and other operations in a way that user-defined types aren't. Although Rust provides the facilities needed to build practically all the other forms of garbage collection, as well as those needed to integrate with external GC systems in a safe way, the resulting smart pointers feel second-class compared to <code>@</code>. A systems language designed to work in a diverse set of environments should have the flexibility to create memory management abstractions that feel first-class.</p>
<h2>Conclusion</h2>
<p>For these three reasons—familiarity, simplicity, and flexibility—I'd like to propose removing <code>@</code> pointers from the language and replacing them with a small set of hooks allowing the same functionality to be implemented as a library and on user-defined types. We would ship tracing GC as part of the standard library and make it just as powerful and convenient as it is today (except for the <code>@</code> syntax). We'd gain a flexible set of abstractions, make the language easier to learn, and make Rust into a truly freestanding language environment.</p>
<p>* Note that the <em>safe</em> qualifier here disqualifies manually-built free lists in garbage-collected languages, as these manually-built free lists provide no protection against errors like double "frees", leaks, and danging pointers. (They're significantly worse than true manual memory management anyhow; the GC still has to trace through objects in arenas at mark time, copy the objects within out into the tenured generation when they survive a minor collection, write barrier the objects, and so forth.)</p>
<p>† Note that I don't mean you shouldn't write Web frameworks and Web sites in Rust: in fact, I think Rust would be a fantastic language for many classes of Web server software, especially that which must scale to the highest loads and squeeze every ounce of performance out of the servers on the racks.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Chrome just rolled out a new way to track you and serve ads (464 pts)]]></title>
            <link>https://theconversation.com/google-chrome-just-rolled-out-a-new-way-to-track-you-and-serve-ads-heres-what-you-need-to-know-213150</link>
            <guid>37464574</guid>
            <pubDate>Mon, 11 Sep 2023 08:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/google-chrome-just-rolled-out-a-new-way-to-track-you-and-serve-ads-heres-what-you-need-to-know-213150">https://theconversation.com/google-chrome-just-rolled-out-a-new-way-to-track-you-and-serve-ads-heres-what-you-need-to-know-213150</a>, See on <a href="https://news.ycombinator.com/item?id=37464574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Late last week, Google announced something called the Privacy Sandbox has been rolled out <a href="https://privacysandbox.com/intl/en_us/news/privacy-sandbox-for-the-web-reaches-general-availability">to a “majority” of Chrome users</a>, and will reach 100% of users in the coming months. But what is it, exactly? </p>

<p>The new suite of features represents a fundamental shift in how Chrome will track user data for the benefit of advertisers. Instead of third-party cookies, Chrome can now tap directly into your browsing history to gather information on advertising “topics” (more on that later).</p>

<p>In development since 2019, this change has attracted <a href="https://gizmodo.com/google-privacy-sandbox-now-on-every-chrome-browser-1850812404">a great deal of controversy</a>, as some commentators have deemed it <a href="https://arstechnica.com/gadgets/2023/09/googles-widely-opposed-ad-platform-the-privacy-sandbox-launches-in-chrome/">invasive in terms of privacy</a>.</p>

<p>Understanding how it works – and whether you want to opt in or out – is important, since Chrome remains the most widely used browser in the world, with a 63% market share <a href="https://www.statista.com/statistics/268254/market-share-of-internet-browsers-worldwide-since-2009/">as of May 2023</a> (Safari is in second place with 13%).</p>

<h2>Wait, what is a cookie?</h2>

<p>In 1994, computer engineer Lou Montulli at Netscape revolutionised the way we browsed the internet with his <a href="https://montulli.blogspot.com/2013/05/the-reasoning-behind-web-cookies.html">invention of the “cookie</a>”. For the first time, web pages could remember our passwords, preferences, language settings and even shopping carts.</p>

<p>This method was supposed to be a private exchange of information just between a user and a website – what’s known as a first-party cookie. But within two years, advertisers worked out how to “hack” cookies <a href="https://qz.com/2000350/the-inventor-of-the-digital-cookie-has-some-regrets">to track users</a>. These are third-party cookies.</p>

<p>You can think of a first-party cookie like a shop assistant who listens to your preferences and is happy to hold your bags or clothes while you make your selection – but only while you are inside their store.</p>

<p>A third-party cookie is like a bug from an old spy movie. It listens to everything in your room, but only shares the info with its allies. The “spy” can place this cookie on other people’s sites, to record what you visit and what data you enter. If you’ve ever wondered how Facebook has served you an ad about something related to a news story you just read, chances are it’s because you have third-party cookies enabled.</p>

<p>Unregulated online tracking and surveillance via cookies were the default until 2018, when the European Union’s <a href="https://gdpr.eu/what-is-gdpr/">General Data Protection Regulations</a> (GDPR) and the <a href="https://oag.ca.gov/privacy/ccpa">California Consumer Privacy Act</a> (CCPA) were introduced. If you have noticed more pop-ups notifying you of cookies and asking for your informed consent, you have the GDPR and CCPA to thank.</p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/cookies-i-looked-at-50-well-known-websites-and-most-are-gathering-our-data-illegally-176203">Cookies: I looked at 50 well-known websites and most are gathering our data illegally</a>
    </strong>
  </em>
</p>
<hr>


<p>The <a href="https://clearcode.cc/blog/third-party-cookies-demise/#safari-and-firefox-turn-off-support-for-third-party-cookies">first browsers</a> to turn off support for third-party cookies were Apple’s Safari in 2017 and Mozilla’s Firefox in 2019.</p>

<p>But Google is also a major online advertising company, with ads <a href="https://www.doofinder.com/en/statistics/google-revenue-breakdown">making up 57.8% of Google’s revenue</a> as of 2023. They <a href="https://www.forbes.com/sites/theyec/2022/09/12/the-slow-death-of-third-party-cookies">have been slowest off the mark</a> in turning off third-party cookies in Chrome. With the introduction of the Privacy Sandbox, they now hope to start turning cookies off sometime in 2024.</p>

<h2>How is the Privacy Sandbox different from cookies?</h2>

<p>The details on how the Privacy Sandbox collection of features works <a href="https://developer.chrome.com/en/blog/shipping-privacy-sandbox/#whats-shipping">are rather technical</a>. But here are a few of the most important aspects.</p>

<p>Instead of using third-party cookies to serve you ads across the internet, Chrome will provide something called advertising Topics. These are high-level summaries of your browsing behaviour, tracked locally (such as in your browsing history), that companies can access on request to serve you ads on particular subjects.</p>

<p>Additionally, there are features such as <a href="https://developer.chrome.com/docs/privacy-sandbox/protected-audience/">Protected Audience</a> that can serve you ads for “remarketing” (for example, Chrome tracked you visiting a listing for a toaster, so now you will get ads for toasters elsewhere), and <a href="https://developer.chrome.com/docs/privacy-sandbox/attribution-reporting/">Attribution Reporting</a>, that gathers data on ad clicks.</p>

<p>In short, instead of third-party cookies doing the spying, the features these cookies enable will be available directly within Chrome.</p>



<h2>Is user tracking necessarily bad?</h2>

<p>While Google pitches the Privacy Sandbox as something that will improve user privacy, <a href="https://movementforanopenweb.com/googles-privacy-sandbox-a-closer-look-at-claims-and-contradictions/">not everyone agrees</a>.</p>

<p>If these features are switched on, Google – one of the world’s biggest advertising companies – is essentially able to listen to you everywhere on the web.</p>

<p>Tracking technology can arguably benefit us as well. For example, it could be helpful if an online store reminds you every three months you need a new toothbrush, or that this time last year you bought a birthday card for your mum.</p>

<p>Offloading cognitive effort, such as reminders like these, is a great way automation can assist humanity. When used in situations where pinpoint accuracy is required, it can make our lives easier and more pleasant.</p>

<p>However, if you are not comfortable with surveillance, the alternative to third-party cookies may not necessarily be the new Privacy Sandbox in Chrome.</p>

<p>The alternative is to completely disable tracking altogether.</p>

<h2>What can you do?</h2>

<p>If you don’t want your online activities to be tracked for advertising purposes, there are a few straightforward choices.</p>

<p>By far the most private browsers are specialist non-tracking browsers that prioritise no tracking, such as <a href="https://duckduckgo.com/">DuckDuckGo</a> and <a href="https://brave.com/">Brave</a>. But if you don’t want to get that nerdy, Safari and Firefox already have third-party cookies blocked by default.</p>

<figure>
            <a href="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A screenshot of a Chrome settings page listing Ad topics, Site-suggested ads and Ad measurement" data-src="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=324&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=324&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=324&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=407&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=407&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=407&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>The tools found in Google Chrome are nestled under Settings - Ads privacy. You can toggle each section on or off individually, and click on them to look at more details.</span>
              <span><span>Screenshot via The Conversation</span></span>
            </figcaption>
          </figure>

<p>If you don’t mind some useful targeted advertising, you can leave the Chrome Privacy Sandbox settings on.</p>

<p>If you want to adjust these settings or switch them off, click the three dots in the upper-right corner and go to <em>Settings &gt; Privacy and Security &gt; Ad privacy</em>. It’s unclear if toggling these features off will stop Chrome from collecting these data altogether, or if it just won’t share the data with advertisers. You can find out more details about each feature on <a href="https://support.google.com/chrome/answer/13355898">the Google Chrome Help page</a>.</p>

<p>Lastly, it’s good to remember nothing truly comes for free. Software costs money to develop. If you’re not paying towards that, then it’s likely you – or your data – are the product. We need to revolutionise how we think about our own data and what value it truly holds.</p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/the-ugly-truth-tech-companies-are-tracking-and-misusing-our-data-and-theres-little-we-can-do-127444">The ugly truth: tech companies are tracking and misusing our data, and there's little we can do</a>
    </strong>
  </em>
</p>
<hr>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta deletes Al Jazeera presenter’s profile after show criticising Israel (155 pts)]]></title>
            <link>https://www.aljazeera.com/news/2023/9/10/meta-deletes-al-jazeera-presenters-profile-after-show-criticising-israel</link>
            <guid>37464482</guid>
            <pubDate>Mon, 11 Sep 2023 08:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aljazeera.com/news/2023/9/10/meta-deletes-al-jazeera-presenters-profile-after-show-criticising-israel">https://www.aljazeera.com/news/2023/9/10/meta-deletes-al-jazeera-presenters-profile-after-show-criticising-israel</a>, See on <a href="https://news.ycombinator.com/item?id=37464482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Tip of the Iceberg episode investigated how Facebook targets Palestinian content related to Israel.</em></p></div><div aria-live="polite" aria-atomic="true"><p>Al Jazeera Arabic presenter Tamer Almisshal has had his Facebook profile deleted by Meta 24 hours after&nbsp;the programme Tip of the Iceberg aired an investigation into Meta’s censorship of Palestinian content titled <a href="https://www.youtube.com/watch?v=cnj0rmnsAdI" target="_blank">The Locked Space</a>.</p>
<p>The programme’s investigation, which aired on Friday, included admissions by Eric Barbing, former head of Israel’s cybersecurity apparatus, about his organisation’s effort to track Palestinian content according to criteria that included “liking” a photo of a Palestinian killed by Israeli forces.</p>
<p>Then the agency would approach Facebook and argue that the content should be taken down.</p>
<p>According to Barbing, Facebook usually complies with the requests and Israel’s security apparatus follows up cases, including bringing court cases if need be.</p>
<p>The investigation followed up on Barbing’s admissions by interviewing a number of human and digital rights experts who agreed that there was a distinct imbalance in how Palestinian content is restricted.</p>
<p>The programme also interviewed Julie Owono, a member of Facebook’s oversight board, who admitted there is a discrepancy in how rules are interpreted and applied to Palestinian content and added that recommendations had been sent to Facebook to correct this.</p>
<p>Al Jazeera has asked Facebook about why Almisshal’s profile was shut down with no prior warning or explanation. It had not received a response by the time of publication.</p>
<h2 id="targeting-a-journalist">‘Targeting a journalist’</h2>
<p>Almisshal said the profile that was deleted is his personal page, set up by him in 2006 and verified. He had at least 700,000 followers on it.</p>
<p>“After the huge success of the episode, I discovered that my personal Facebook profile had been deleted with no explanations given,” he told Al Jazeera. “It really does seem like some kind of revenge for the programme. We haven’t received any response from Facebook yet.”</p>
<p>The programme’s team had set out to investigate how wide the gap was between how Palestinian and Israeli posts and material are treated by Facebook.</p>
<p>To do that, it set up an experiment in which it built two different pages, one with a pro-Palestinian perspective and the other a pro-Israeli one, and ran trials on them. The team concluded that there was indeed a big discrepancy in how much scrutiny there is and how rules are applied to posts on either page.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">A day after Tamer Almisshal, a Palestinian <a href="https://twitter.com/hashtag/journalist?src=hash&amp;ref_src=twsrc%5Etfw">#journalist</a> with <a href="https://twitter.com/hashtag/Jazeera?src=hash&amp;ref_src=twsrc%5Etfw">#Jazeera</a>, presented shocking evidence of Meta's censorship of Palestinian content on its platforms during his "Tip of the Iceberg" TV show, Facebook has taken down his page.<a href="https://twitter.com/hashtag/IsraeliCrimes?src=hash&amp;ref_src=twsrc%5Etfw">#IsraeliCrimes</a> <a href="https://twitter.com/hashtag/Palestine?src=hash&amp;ref_src=twsrc%5Etfw">#Palestine</a> <a href="https://t.co/RGQm8sUuzQ">pic.twitter.com/RGQm8sUuzQ</a></p>
<p>— Hadeel Abo Aita (@aita_hadeel) <a href="https://twitter.com/aita_hadeel/status/1700858011084857400?ref_src=twsrc%5Etfw">September 10, 2023</a></p></blockquote>

<p>It is not clear why Facebook would choose to delete an individual’s page in response to a programme.</p>
<p>“There was no explanation, no warning,” Almisshal said. “There had been no issues with any of the content on my page before. No message saying I had violated any rules.”</p>
<p>Almisshal stands by his programme.</p>
<p>“Last March, Facebook restricted my account, and it has happened other times, but usually the situation is resolved,” he said. “This was a journalistically sound project, and we communicated with Meta for it, giving them the opportunity to speak during the investigation.</p>
<p>“But to target a journalist individually instead – I would never have expected that.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A group of open source Android apps without ads and unnecessary permissions (287 pts)]]></title>
            <link>https://www.simplemobiletools.com</link>
            <guid>37463662</guid>
            <pubDate>Mon, 11 Sep 2023 06:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.simplemobiletools.com">https://www.simplemobiletools.com</a>, See on <a href="https://news.ycombinator.com/item?id=37463662">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                <p>
                    <h2>Let’s stay in touch!</h2>
                </p>

                <div>
                    <form action="https://www.simplemobiletools.com/newsletter" method="POST" novalidate="">
                        
                        <div>
                            <p>

                            <label>
                                <span>Your email address…</span>
                            </label></p><p>Fill in the email address field with a valid email.</p>
                        </div>

                        
                    </form>
                </div>
            </div>

            <p><span>Replacing your Android apps one by one since 2016.</span>

                <span>Copyright © 2023, All Rights Reserved.</span></p>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HDMI ISA graphics card for vintage PCs by improving the Graphics Gremlin (214 pts)]]></title>
            <link>https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/</link>
            <guid>37462947</guid>
            <pubDate>Mon, 11 Sep 2023 04:38:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/">https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/</a>, See on <a href="https://news.ycombinator.com/item?id=37462947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>HDMI is a relatively modern video connector we take for granted on modern PCs and monitors. Now vintage PCs can join in the fun too with a native connection to modern HDMI monitors without any additional adapter.</p>
<h2 id="background">Background</h2>
<p>2 years ago, I learned of an open-source project called Graphics Gremlin (GG) by <a href="https://www.linkedin.com/in/eric-schlaepfer-5ab72315/">Eric Schlaepfer</a> who runs the website <a href="https://tubetime.us/">Tubetime.us</a>. It is an 8-bit ISA graphics card that supports display standards like <a href="https://en.wikipedia.org/wiki/Color_Graphics_Adapter">Color Graphics Adapter (CGA)</a> and <a href="https://en.wikipedia.org/wiki/IBM_Monochrome_Display_Adapter">Monochrome Display Adapter (MDA)</a>. CGA and MDA are display standards used by older IBM(-compatible) PCs in the 1980s.</p>
<p>The frequencies and connectors used by CGA and MDA are no longer supported by modern monitors hence it is difficult for older PCs of the 1980s era to have modern displays connected to them without external adapters. GG addresses this problem by using techniques like scan doubling (for CGA) and increasing the vertical refresh rate (for MDA) then outputing to a relatively newer but still old VGA port.</p>
<p>I fabricated and assembled the design then installed it into my <a href="https://github.com/yeokm1/retro-configs/tree/master/desktops/ibm-5155">IBM5155</a>.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-original.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-original.jpg" width="600"></a></p><p>GG provides outputs in VGA, Composite and DB9 RGBI.</p>
<p>However 2 issues bugged me about this card:</p>
<ol>
<li>
<p>The Composite video and VGA port cannot be used at the same time due to pin sharing between both ports. Switching between them is possible by flipping physical switches on the card. However on my IBM5155, the internal CRT monitor runs on Composite hence if I want to use an external monitor, the internal CRT becomes unusable.</p>
</li>
<li>
<p>Modern monitors have long started to omit the analog VGA inputs in favour of modern digital ports like HDMI or Displayport. This requires a VGA-to-HDMI adapter. This analog-to-digital conversion will also lead to an inevitable loss in video quality. Such adapters also require an external power source such as USB. Vintage PCs usually don’t have USB outputs so supplying power with an additional USB power adapter leads to more setup hassles.</p>
</li>
</ol>
<p>I decided to modify the GG design so it can connect natively to an external HDMI monitor and service the internal Composite-based CRT at the same time.</p>
<h2 id="how-does-the-graphics-gremlin-work">How does the Graphics Gremlin work?</h2>
<p>The core of the GG is the Lattice iCE40HX4K FPGA. It is responsible for handling instructions from the ISA bus and generating the appropriate video signals.</p>
<p>512KiB video RAM is provided by ISSI IS61WV5128BLL. 3 bitstreams are stored in a 8Mbit Microchip SST26VF080A SPI flash. These bitstreams are:</p>
<ol>
<li>MDA output using a VGA compatible 70Hz refresh rate</li>
<li>MDA output to RGBI port at 50Hz refresh rate (incompatible with VGA monitors)</li>
<li>CGA output. RGBI connector will output at 320x200 60Hz while VGA will be scan doubled to 640x400 60Hz.</li>
</ol>
<p>RGBI output is driven directly from the FPGA since it is just a TTL signal. Analog VGA signal is generated using a DAC resistor ladder. Composite is driven from the green VGA pin hence why Composite and VGA cannot be used at the same time.</p>
<p>The code is written in Verilog HDL and uses the open source <a href="https://clifford.at/icestorm">Project Icestorm</a> toolchain.</p>
<p>One interesting thing that the GG design has is it will display a blinking test pattern if it is powered on but the host PC has yet to command it to display anything.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-test-pattern.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-test-pattern.jpg" width="800"></a></p><p>The left is the test pattern for CGA and the right is MDA.</p>
<p>This test pattern proved very useful for me as it means I don’t need the card to be plugged into a PC while I’m testing any code changes.</p>
<h2 id="my-modifications">My Modifications</h2>
<h2 id="summary">Summary</h2>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-top-both.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-top-both.jpg" width="800"></a></p><p>Left is the original GG, right is my modified design.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board-ports.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board-ports.jpg" width="800"></a></p><p>View from the ports side.</p>

<p>
  <iframe src="https://www.youtube.com/embed/xLy6on_o4YM" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>This is the demo video using the updated GG card in my IBM5155 outputing HDMI to my 5:4 Dell P1917S monitor and Composite to my small LCD screen.</p>
<p>This video shows the bootup process from a cold start to the DOS 6.22 command line. After that I run <a href="https://github.com/MobyGamer/CGACompatibilityTester">CGA Compatibility tester</a> to check the output.</p>
<p>The entire updated PCB design and Verilog code has been open-sourced here: <a href="https://github.com/yeokm1/graphics-gremlin-hdmi">https://github.com/yeokm1/graphics-gremlin-hdmi</a></p>
<p>Here is a summary of changes I made some which I will cover further down this post.</p>
<ul>
<li>Hardware changes
<ul>
<li>Added HDMI port by removing the RGBI DB9 port. Port positions adjusted to ease trace routing.</li>
<li>Added <a href="https://www.ti.com/product/TFP410">TI TFP410</a> DVI transmitter (HDMI is compatible with DVI). HDMI is independent of the VGA/Composite output.</li>
<li>Test points for inputs to DVI transmitter</li>
<li>Replaced the 3.3VDC 1A linear regulator with 3A as TFP410 is power hungry at up to 1A.</li>
<li>Added pin headers for power.</li>
<li>Added LED power indicators for 5V and 3.3V.</li>
</ul>
</li>
<li>HDL code changes
<ul>
<li>Selectable MDA colours</li>
<li>Removed normal MDA bitstream as there is no more RGBI port.</li>
<li>Added CGA 70Hz mode.</li>
<li>Modified Scandoubler code to support Display Enable signal as required by DVI chip but not VGA</li>
</ul>
</li>
</ul>
<h2 id="hardware-changes">Hardware changes</h2>
<h2 id="hdmi-support-through-dvi-transmitter-ic">HDMI support through DVI transmitter IC</h2>
<p>HDMI (and DVI) use Transition-Minimized Differential Signaling (TMDS) lines. The ICE40 FPGA however does not have that. Online searches garnered that some people have <a href="https://hackaday.io/page/5702-dvi-hdmi-pmod-for-an-ice40-fpga">used workarounds</a> to generate the differential signals however I’m not sure how compatible or spec-compliant those are.</p>
<p>I decided to go for more reliable option by using a dedicated DVI transmitter TI TFP410. I referred to an <a href="https://blackmesalabs.wordpress.com/2017/12/15/bml-hdmi-video-for-fpgas-over-pmod/">open-source PMOD schematic from Black Mesa Labs</a> to integrate this chip into the Graphics Gremlin.</p>
<p>The TFP410 accepts a 24-bit RGB colour data input. Ideally, we should connect all 24 pins to the FPGA directly but there are not many spare pins left in the ICE40HX. The only FPGA pins available are those meant for the external RGBI port which I dropped. These pins include the 4 colour signals, red, green, blue and intensity are thus repurposed to talk to the TFP410.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-tfp410-sch-snippet.png"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-tfp410-sch-snippet.png" width="250"></a></p><p>To simulate an RGBI monitor, the 3 base colour signals are connected to the MSB of the colour input with the intensity bit shared among all as the second-most significant bit.</p>
<p>The TFP410 will also handle the appropriate 8b/10b encoding to ensure a proper TMDS data signal for DVI. Since a HDMI connector is electrically similar to DVI, the DVI transmitter output can be directly wired to the HDMI port.</p>
<h2 id="test-points">Test points</h2>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board.jpg" width="800"></a></p><p>Various test points were added to the board. The data inputs from the FPGA to the TFP410 are as follows:</p>
<ul>
<li>Red, Green, Blue, Intensity</li>
<li>Horizontal Sync (HS)</li>
<li>Vertical Sync (VS)</li>
<li>Display Enable (DE)</li>
<li>Clock (CLK)</li>
</ul>
<p>These inputs with 3.3V and GND are broken out as standard 2.54mm pin headers in the style of a PMOD.</p>
<p>I also added power LEDs and pin headers to the left of the board so I can monitor power state and power the board without having to connect to an actual vintage machine with ISA bus and displaying something.</p>
<h2 id="hdl-code-changes">HDL code changes</h2>
<h2 id="supporting-the-dvi-transmitter-chip">Supporting the DVI transmitter chip</h2>
<p>The Verilog code has to be modified to send data in an appropriate format to the DVI chip.</p>
<p>Most of the original RGBI lines meant for the DB9 monitor connector, RGBI, HS, VS lines are similar. However the CLK and DE lines are not used before and hence has to be provided. CLK was relatively easy to get and wire out to the DVI chip. However DE was slightly more problematic.</p>
<p>In the original IBM CGA/MDA graphics card, there exists a chip called a <a href="https://en.wikipedia.org/wiki/Motorola_6845">Motorola 6845</a> which generates the Cathode Ray Tube (CRT) control signals. It is also known as a CRTC6845 and the DE line is also generated here.</p>
<p>In the code, the behaviour of this chip is emulated in <a href="https://github.com/schlae/graphics-gremlin/blob/main/verilog/crtc6845.v">crtc6845.v</a>. The DE line output of this module has to be pulled out and wired to the DVI chip.</p>
<p>In CGA mode, the code contains a <a href="https://github.com/schlae/graphics-gremlin/blob/main/verilog/cga_scandoubler.v">cga_scandoubler.v</a> to double the number of horizontal lines and frequency to change the number of viewable vertical lines from 640x200 to 640x400 to make it more compatible for modern displays. It does this by doing double buffering with 2 arrays. One array is read out twice for each line using twice the usual pixel clock while the other array is being written to by the host PC then both arrays are swapped at the end of line.</p>
<p>I modified this Scandoubler to cache the DE bit as well.</p>
<h2 id="selectable-mda-colours">Selectable MDA colours</h2>
<p>In the original GG, the MDA output is a constant amber (see photo in an earlier section). I didn’t particularly like amber. I wanted to have a customisable colour option depending on my needs. Since 2 of the physical switches are unused in MDA mode, I programmed the ability to change the colours depending on what switch is selected.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-mda-display.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-mda-display.jpg" width="800"></a></p><p>Depending on switch state, colours like green, yellow, white and red are selectable on-the-fly.</p>
<h2 id="additional-cga-70hz-mode">Additional CGA 70Hz mode</h2>
<p>According to page 18 of the <a href="https://www.cs.unc.edu/Research/stc/FAQs/Video/dvi_spec-V1_0.pdf">DVI 1.0 specification</a>, the minimum acceptable for DVI is a pixel clock of 25.175Mhz for 640x480 60Hz.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-dvi-lowest.png"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-dvi-lowest.png" width="600"></a></p><p>Even after scandoubling, the current resolution of 640x400 60Hz is technically below the minimum acceptable. I have tested with the monitors I have up to a modern Dell S2721QS 4K monitor and Sony TV and all can accept 640x400 60Hz with no problems.</p>
<p>Nevertheless to adhere to the specification, I decided to provide another selectable CGA bitstream to drive the pixel clock higher so as to produce 640x400 at 70Hz in case some displays cannot accept a lower pixel clock.</p>
<p>At this mode though, the IBM5155 internal CRT and external composite display will no longer work.</p>

<p>During the design process, I used several tools to help me.</p>
<p>As I would find out, if one sends an improper display signal to the monitor, most monitors will tell you the signal is out of specification and not elaborate more otherwise nothing is shown at all.</p>
<p>This makes it extremely difficult to troubleshoot what went wrong.</p>
<h2 id="digilent-digital-discovery">Digilent Digital Discovery</h2>
<p>The Digilent Digital Discovery (DDD) is a relatively low-cost USB logic analyzer for the specifications/features.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ddd.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ddd.jpg" width="600"></a></p><p>It can sample up to 800 MS/s depending on the number of channels active at one time. Compared to most osilloscopes, it has 2 GBit of RAM which allows me to store plenty of samples. This is especially required given the data samples I was working with and I need to capture at least several frames.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-waveforms.png"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-waveforms.png" width="800"></a></p><p>This is a sample capture of the Clock, Display Enable, Vertical Sync and Horizontal Sync signals on the Digilent Waveforms software.</p>
<h2 id="testing-with-mimas-a7-xilinx-artix-7">Testing with Mimas A7 (Xilinx Artix 7)</h2>
<p>As part of my testing, I also made a small FPGA test project using another FPGA board Mimas A7 based on the Xilinx Artix 7.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-with-mimas-a7.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-with-mimas-a7.jpg" width="600"></a></p><p>The FPGA test board reads the raw signals that are given to the DVI transmitter and displays the output using its own HDMI output. Visualising the signals makes it easier to literally see and troubleshoot what the problem could be instead of just looking at the raw logic levels from the logic analyser output.</p>
<p>The code is heavily based on the <a href="https://github.com/dominic-meads/HDMI_FPGA/">HDMI_FPGA</a> project by Dominic Meads and runs on Vivado 2023.</p>
<h2 id="486-pc">486 PC</h2>
<p>Instead of going to my precious IBM5155 directly, I used my <a href="https://yeokhengmeng.com/2021/05/setting-up-a-486-retro-pc/">486 PC</a> for intermediate testing.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-486-cga.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-486-cga.jpg" width="400"></a></p><p>The BIOS of my 486 motherboard has the ability to change to the different CGA and MDA modes on top of its more period correct VGA mode. This helped me in my testing as I can more easily switch between the video modes compared to my <a href="https://www.minuszerodegrees.net/5160/misc/5160_motherboard_switch_settings.htm">IBM5155 which uses physical switch settings</a>.</p>
<h2 id="install-in-my-ibm5155">Install in my IBM5155</h2>
<p>After I was more confident on the card’s functionality, final tests were done in my IBM5155.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-top.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-top.jpg" width="400"></a></p><p>The card installed in the slot closest to the CRT monitor with the internal composite cable connected.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-back.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-back.jpg" width="400"></a></p><p>The rear of my IBM5155 shows the HDMI connector, probably the first to have one?</p>
<p>I didn’t design a new card bracket so I used a twist tie to secure the card to the enclosure.</p>
<h2 id="known-issue-with-brown">Known issue with brown</h2>
<p>This palette value “I:0 R:1 G:1 B:0” is not handled correctly by this card and is displayed as dark yellow instead of brown as per how the <a href="https://www.aceinnova.com/en/electronics/cga-and-the-brown-color-in-ibm-5153-color-display/">IBM5153 Colour Display Monitor does it</a>. When an IBM5153 monitor sees this signal “I:0 R:1 G:1 B:0”, the green component is halved producing a brown colour.</p>
<p>In order to emulate this behaviour for modern displays, the FPGA itself will have to halve the green colour component which means I will need more signal lines to the DVI transmitter. However I lack the pins on the FPGA to provide more than a 4-bit RGBI output.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-cga-test.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-cga-test.jpg" width="600"></a></p><p>My IBM 5155 running the <a href="https://github.com/MobyGamer/CGACompatibilityTester">CGA Compatibility Tester</a> displaying the colour palatte. One can see the brown colour is displayed incorrectly as dark yellow.</p>
<p>The original GG does not suffer from this problem as the brown colour can be easily generated with the existing FPGA pins to the VGA resistor DAC.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This project was a long journey for me. If you look at the silkscreen date on the PCB, it shows 9 August 2021. At that time, I designed the PCB without the skills to code in Verilog. Even though the number of changes I made are small, it took me quite a bit of time on the side to finally pick up the skills to work on my first FPGA project with all development and testing work this project entails.</p>
<p>Not forgetting I’m actually standing on the shoulders of giants like Eric Schlaepfer who designed the original Graphics Gremlin. I’m just building on a small increment on top of his work.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How could the early Unix OS comprise so few lines of code? (163 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/26083/how-could-early-unix-os-comprise-so-few-lines-of-code</link>
            <guid>37462806</guid>
            <pubDate>Mon, 11 Sep 2023 04:14:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/26083/how-could-early-unix-os-comprise-so-few-lines-of-code">https://retrocomputing.stackexchange.com/questions/26083/how-could-early-unix-os-comprise-so-few-lines-of-code</a>, See on <a href="https://news.ycombinator.com/item?id=37462806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>If you look at the code in the modern Linux kernel, you will find that most of the code is in the device drivers.  There are tens of millions of lines of code to support everything imaginable -- the networking cards in 1990s DEC Alpha workstations, the soundcards in late 1980s ISA IBM PC-compatibles, modern 64-bit ARM tablets, all the USB devices, and so on.</p>
<p>On top of that, we have dozens of file systems, support for many different kinds of networking protocols.  There are multiple different schedulers -- not just for processes, but block IO and network transfers.  And so on.  In fact, the feature variety and hardware drivers make up the great majority of Linux code.  Linux, before all these features and bloat were added, as originally released as a crude kernel for 386 machines, was also measured in tens of thousands of lines of code.</p>
<p>I've written a small multitasking kernel, for an embedded application, so I feel qualified to say: it really isn't that big of a job.  The basic UNIX design of processes and file system is a structure that has several interworking parts, so it's delicate and finnicky.  But it's not ultimately that complex.</p>
<p>Basic memory management takes a few hundred lines.  Implementing basic processes takes a few hundred lines.  A basic file system takes a few thousand lines of C code.  Device drivers depend on the complexity of the device, but can be quite small.  You just need drivers for a terminal of some kind, and a disk of some kind.</p>
<p>That will give you the core to load binaries, execute them, and give them some system calls for reading/writing files.  That's about all the original UNIX provided.  But then you will want networking and fast algorithms for disk caching.  It rapidly starts adding up.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan launches rocket carrying lunar lander and X-ray telescope (201 pts)]]></title>
            <link>https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html</link>
            <guid>37462351</guid>
            <pubDate>Mon, 11 Sep 2023 03:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html">https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html</a>, See on <a href="https://news.ycombinator.com/item?id=37462351">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japan-launches-rocket.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe" title="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP" width="800" height="510">
             <figcaption>
                An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
            </figcaption>        </figure>
    </div>
<p>Japan launched a rocket Thursday carrying an X-ray telescope that will explore the origins of the universe as well as a small lunar lander.

										 											      </p>
										 
										 											  
<p>The launch of the HII-A rocket from Tanegashima Space Center in southwestern Japan was shown on <a href="https://phys.org/tags/live+video/" rel="tag">live video</a> by the Japan Aerospace Exploration Agency, known as JAXA.
</p><p>"We have a liftoff," the narrator at JAXA said as the rocket flew up in a burst of smoke then flew over the Pacific.
</p><p>Thirteen minutes after the launch, the rocket put into orbit around Earth a satellite called the X-Ray Imaging and Spectroscopy Mission, or XRISM, which will measure the speed and makeup of what lies between galaxies.
</p><p>That information helps in studying how <a href="https://phys.org/tags/celestial+objects/" rel="tag">celestial objects</a> were formed, and hopefully can lead to solving the mystery of how the universe was created, JAXA says.
</p><p>In cooperation with NASA, JAXA will look at the strength of light at different wavelengths, the temperature of things in space and their shapes and brightness.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japans-moon-sniper-mis.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/japans-moon-sniper-mis.jpg" data-sub-html="Graphic on Japan's Smart Lander for Investigating Moon (SLIM), or 'Moon Sniper', which aims to land within 100 meters of a specific lunar target.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japans-moon-sniper-mis.jpg" alt="Japan's 'Moon Sniper' mission" title="Graphic on Japan's Smart Lander for Investigating Moon (SLIM), or 'Moon Sniper', which aims to land within 100 meters of a specific lunar target.">
             <figcaption>
                Graphic on Japan's Smart Lander for Investigating Moon (SLIM), or 'Moon Sniper', which aims to land within 100 meters of a specific lunar target.
            </figcaption>        </figure>
    </div>

<p>David Alexander, director of the Rice Space Institute at Rice University, believes the mission is significant for delivering insight into the properties of hot plasma, or the superheated matter that makes up much of the universe.
</p><p>Plasmas have the potential to be used in various ways, including healing wounds, making computer chips and cleaning the environment.
</p><p>"Understanding the distribution of this hot plasma in space and time, as well as its dynamical motion, will shed light on diverse phenomena such as <a href="https://phys.org/tags/black+holes/" rel="tag">black holes</a>, the evolution of chemical elements in the universe and the formation of galactic clusters," Alexander said.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-1.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japan-launches-rocket-1.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe" title="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
             <figcaption>
                An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
            </figcaption>        </figure>
    </div>

<p>Also aboard the latest Japanese rocket is the Smart Lander for Investigating Moon, or SLIM, a lightweight lunar <a href="https://phys.org/tags/lander/" rel="tag">lander</a>. The Smart Lander won't make <a href="https://phys.org/tags/lunar+orbit/" rel="tag">lunar orbit</a> for three or four months after the launch and would likely attempt a landing early next year, according to the space agency.
</p><p>The lander successfully separated from the rocket about 45 minutes after the launch and proceeded on its proper track to eventually land on the <a href="https://phys.org/tags/moon/" rel="tag">moon</a>. JAXA workers applauded and bowed with each other from their observation facility.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-2.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-2.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japan-launches-rocket-2.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe" title="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
             <figcaption>
                An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
            </figcaption>        </figure>
    </div>



											  													    
											  
											  <p>JAXA is developing "pinpoint landing technology" to prepare for future lunar probes and landing on other planets. While landings now tend to be off by about 10 kilometers (6 miles) or more, the Smart Lander is designed to be more precise, within about 100 meters (330 feet) of the intended target, JAXA official Shinichiro Sakai told reporters ahead of the launch.
</p><p>That allows the box-shaped gadgetry to find a safer place to land.
</p><p>The move comes at a time when the world is again turning to the challenge of going to the moon. Only four nations have successfully landed on the moon, the U.S., Russia, China and India.
</p><p>Last month, <a href="https://phys.org/news/2023-08-india-moon-rover-sulfur-elements.html">India landed a spacecraft</a> near the moon's south pole. That came just days after Russia failed in its attempt to return to the moon for the first time in nearly a half century. A Japanese private company, called ispace, crashed a lander in trying to land on the moon in April.
</p><ul>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-3.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-3.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-3.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-5.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-5.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-5.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-6.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-6.jpg" data-sub-html="An H2A rocket sits at launch pad at Tanegashima Space Center in Kagoshima, southern Japan Monday, Aug. 28, 2023. The rocket was to blast off Monday morning, but the lift-off was postponed due to strong winds, according to Kyodo News. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-6.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An H2A rocket sits at launch pad at Tanegashima Space Center in Kagoshima, southern Japan Monday, Aug. 28, 2023. The rocket was to blast off Monday morning, but the lift-off was postponed due to strong winds, according to Kyodo News. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-4.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-4.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-4.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-7.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-7.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-7.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-8.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-8.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-8.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-9.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-9.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-9.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
    </ul>

<p>Japan's space program has been marred by recent failures. In February, the H3 <a href="https://phys.org/tags/rocket+launch/" rel="tag">rocket launch</a> was aborted for a glitch. Liftoff a month later succeeded, but the <a href="https://phys.org/tags/rocket/" rel="tag">rocket</a> had to be destroyed after its second stage failed to ignite properly.
</p><p>Japan has started recruiting astronaut candidates for the first time in 13 years, making clear its ambitions to send a Japanese to the moon.
</p><p>Going to the moon has fascinated humankind for decades. Under the U.S. Apollo program, astronauts Neil Armstrong and Buzz Aldrin walked on the moon in 1969.
</p><p>The last NASA human mission to the moon was in 1972, and the focus on sending humans to the moon appeared to wane, with missions being relegated to robots.
										 																				
																					
																															 </p><p>
												  © 2023 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe (2023, September 7)
												retrieved 11 September 2023
												from https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chronic fatigue syndrome may have a post-viral infection origin (118 pts)]]></title>
            <link>https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html</link>
            <guid>37462208</guid>
            <pubDate>Mon, 11 Sep 2023 02:38:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html">https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html</a>, See on <a href="https://news.ycombinator.com/item?id=37462208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/chronic-fatigue-syndro-2.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/chronic-fatigue-syndro-2.jpg" data-sub-html="Credit: <i>PLOS Pathogens</i> (2023). DOI: 10.1371/journal.ppat.1011523">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/chronic-fatigue-syndro-2.jpg" alt="Chronic fatigue syndrome may have a post-viral infection origin" title="Credit: PLOS Pathogens (2023). DOI: 10.1371/journal.ppat.1011523" width="800" height="530">
             <figcaption>
                Credit: <i>PLOS Pathogens</i> (2023). DOI: 10.1371/journal.ppat.1011523
            </figcaption>        </figure>
    </div>
<p>Professor Maureen R. Hanson of the Department of Molecular Biology and Genetics, Cornell University, Ithaca, New York, has looked into historical outbreaks of myalgic encephalomyelitis (ME), also known as chronic fatigue syndrome (CFS), and their association with enteroviruses and other pathogens.
                                                </p>                                                                                
<p>In a paper, "The viral origin of myalgic encephalomyelitis/<a href="https://medicalxpress.com/tags/chronic+fatigue+syndrome/" rel="tag">chronic fatigue syndrome</a>," published in <i>PLOS Pathogens</i>, professor Hanson explores several hypotheses related to the causes of ME/CFS, including a likely culprit in viral infections, particularly those from the enterovirus family.
</p><p>The exact causes of ME/CFS are not fully understood, and it is considered a complex and multifactorial condition. Several theories and factors have been proposed as potential contributors to ME/CFS, but no single cause has been definitively identified.
</p><p>Hanson makes the case that some causes are more likely than others, including:
</p><ul><li>Infections with the enterovirus family of viruses. This hypothesis is based on historical outbreaks of ME/CFS coinciding with outbreaks of diseases caused by enteroviruses, as well as evidence of chronic viral infection in some ME/CFS patients. While this could be causal to many more cases, identifying the specific virus that was infecting an individual who later acquired ME/CFS is not possible.</li><li>Human herpesviruses (HHVs), such as Epstein-Barr virus and HHV-6. In ME/CFS, these are a potential source. Some ME/CFS patients report an acute infection with HHVs at the onset of their illness, and reactivation of these viruses may contribute to the condition.</li><li>Post-viral syndromes, including post-acute sequelae of COVID-19 (PASC). These are included in an emerging area of clinical understanding. Some individuals with mild or asymptomatic COVID-19 later experience a post-viral illness that shares symptoms with ME/CFS. This raises questions about the relationship between other lesser-known or less apparent infections and their potential to cause post-viral syndromes and ME/CFS.</li></ul>
<p>In the light of a major viral pandemic with lingering ME/CFS conditions, Hanson compiled information on historical ME/CFS outbreaks with studies on infections like Epstein-Barr virus, Q fever, Ross River virus, influenza and previous ME/CFS patient research, and interrogated varying criteria used by research groups and clinicians to define ME/CFS.
</p><p>Focusing on <a href="https://medicalxpress.com/tags/viral+infections/" rel="tag">viral infections</a> is an intriguing investigative path, as there are already many conditions associated with ME/CFS, almost as if a researcher could pick anywhere to start pulling at the connecting threads of the condition.
</p><p>There are immune system abnormalities linked to ME/CFS; genetic factors may play a role in susceptibility. The central nervous system has associations with many of the symptoms. A host of potential environmental factors, such as toxins, stress, and trauma may be implicated. Recent research indicates issues with cellular energy metabolism, particularly involving mitochondria, leading to the fatigue and reduced stamina. Hormonal dysregulation and/or gut microbiota could play a role, and the list goes on.
</p><p>Hanson argues that there is no proof that multiple pathogens can cause ME/CFS. She suggests that the hypothesis persists due to the overinterpretation of data from previous studies where the initial infection type was either missed, inferred but not verified, or where the symptom survey did not include ME/CFS defining criteria.
</p><p>Currently, there is no specific diagnostic test or universally effective treatment for ME/CFS, which makes it a challenging condition to manage. Treatment typically focuses on symptom management by attempting to improve the quality of life for individuals through traditional, good doctorly advice of "Exercise regularly, eat right, get plenty of sleep." The condition can be frustrating for patients who follow such advice and yet find no relief.
</p><p>Before the SARS-CoV-2 pandemic, the ability of RNA viruses to persist in tissues for long periods was largely ignored, according to Hanson. Recognizing that EVs are prime candidates for causing ME/CFS suggests the importance of pursuing a relevant inquiry into this diverse virus family.

                                            <!-- Google middle Adsense block -->
    </p>                                        <h2>The global laboratory</h2>
<p>Sixty-five million long COVID sufferers worldwide have prompted the US government to devise PASC to describe a post-acute illness syndrome. Most relevant to ME/CFS is that some people who suffered mild or asymptomatic cases of COVID-19 later began experiencing a post-viral illness that fulfills most or even all of the criteria for ME/CFS.
</p><p>Increasingly, these people are told by their doctors that they have ME/CFS, but the diagnostic criteria were created six years before SARS-CoV-2 emerged. Those who acquired ME/CFS before the SARS-CoV-2 outbreak also number in the tens of millions, and the source of their initial infection often remains a mystery.
</p><p>Hanson suggests that the overlap in symptoms between some forms of post-COVID illness and ME/CFS suggests that disruptions in the same pathways may be occurring in both diseases, but to conclude that the two syndromes are identical without more data, especially at the molecular level, is currently unwarranted. Any SARS-specific antiviral treatments will not be effective for ME/CFS patients.
</p><p>If it were not for COVID-19 hitting everywhere all at once, ME/CFS caused by SARS-CoV-2 might also be flying under the radar of the clinical and research communities. Now that the link between a viral <a href="https://medicalxpress.com/tags/infection/" rel="tag">infection</a> and ME/CFS has been firmly detected, Hanson is urging an inquiry into the prime candidate for previously existing ME/CFS cases.
                                                                                
                                        											</p><div>
												                                                    <p><strong>More information:</strong>
                                                    Maureen R. Hanson et al, The viral origin of myalgic encephalomyelitis/chronic fatigue syndrome, <i>PLOS Pathogens</i> (2023).  <a data-doi="1" href="https://dx.doi.org/10.1371/journal.ppat.1011523" target="_blank">DOI: 10.1371/journal.ppat.1011523</a>
																								
																								</p>
																							</div>
                                        											
										                                                                                    <p>
                                                © 2023 Science X Network
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Chronic fatigue syndrome may have a post-viral infection origin (2023, September 6)
                                                 retrieved 11 September 2023
                                                 from https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RestGPT (202 pts)]]></title>
            <link>https://github.com/Yifan-Song793/RestGPT</link>
            <guid>37462125</guid>
            <pubDate>Mon, 11 Sep 2023 02:22:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Yifan-Song793/RestGPT">https://github.com/Yifan-Song793/RestGPT</a>, See on <a href="https://news.ycombinator.com/item?id=37462125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">RestGPT</h2>
<p dir="auto">This is the code for the paper <a href="https://arxiv.org/abs/2306.06624" rel="nofollow">RestGPT: Connecting Large Language Models with Real-World RESTful APIs</a>.</p>
<p dir="auto">This work aims to construct a <strong>large language model based autonomous agent, RestGPT, to control real-world applications</strong>, such as movie database and music player. To achieve this, we connect LLMs with <strong>RESTful APIs</strong> and tackle the practical challenges of planning, API calling, and response parsing. To fully evaluate the performance of RestGPT, we propose <strong>RestBench</strong>, a high-quality test set which consists of two real-world scenarios and human-annotated instructions with gold solution paths.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yifan-Song793/RestGPT/blob/main/imgs/intro.png"><img src="https://github.com/Yifan-Song793/RestGPT/raw/main/imgs/intro.png" alt="intro"></a></p>
<h2 tabindex="-1" dir="auto">What's New</h2>
<ul dir="auto">
<li><strong>[Next]</strong> The demo is under-construction.</li>
<li><strong>[2023/8/29]</strong> Code for RestGPT is released.</li>
<li><strong>[2023/8/28]</strong> The second version of our <a href="https://arxiv.org/abs/2306.06624" rel="nofollow">paper</a> is released.</li>
<li><strong>[2023/6/13]</strong> Our <a href="https://arxiv.org/abs/2306.06624" rel="nofollow">paper</a> is released.</li>
</ul>
<h2 tabindex="-1" dir="auto">RestGPT</h2>
<p dir="auto">RestGPT adopts an iterative coarse-to-fine online planning framework and uses an executor to call RESTful APIs. Here is an overview of RestGPT.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yifan-Song793/RestGPT/blob/main/imgs/model.png"><img src="https://github.com/Yifan-Song793/RestGPT/raw/main/imgs/model.png" alt="model"></a></p>
<p dir="auto">Modules:</p>
<ul dir="auto">
<li>Planner: generating natural language sub-task for current step.</li>
<li>API selector: mapping the coarse high-level sub-task to finer API calling plan.</li>
<li>Executor: executing the API calling plan.
<ul dir="auto">
<li>Caller: organizing API parameters based on the API plan and API documentation.</li>
<li>Parser: generating Python code to parse the API response based on the response schema.</li>
</ul>
</li>
</ul>
<p dir="auto">Here is an example of using TMDB movie database to search for the number of movies directed by Sofia Coppola.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yifan-Song793/RestGPT/blob/main/imgs/example.gif"><img src="https://github.com/Yifan-Song793/RestGPT/raw/main/imgs/example.gif" alt="example" data-animated-image=""></a></p>
<h2 tabindex="-1" dir="auto">Data</h2>
<p dir="auto">We also introduce RestBench to evaluate the performance of RestGPT. RestBench is a high-quality test set consisting of TMDB movie database and Spotify music player scenarios. We collect realistic user instructions with human-annotated gold solution paths. Here are examples of RestBench:</p>
<p dir="auto">TMDB example:</p>
<ul dir="auto">
<li>Instruction: Who is the director of today's most trending movie?</li>
<li>Gold solution path
<ul dir="auto">
<li>GET /trending/{media_type}/{time_window}</li>
<li>GET /movie/{movie_id}/credits</li>
</ul>
</li>
</ul>
<p dir="auto">Spotify example:</p>
<ul dir="auto">
<li>Instruction: Make me a playlist containing three songs of Mariah Carey and name it 'Love Mariah'.</li>
<li>Gold solution path
<ul dir="auto">
<li>GET /search</li>
<li>GET /me</li>
<li>POST /usres/{user_id}/playlists</li>
<li>POST /playlists/{playlist_id}/tracks</li>
</ul>
</li>
</ul>
<p dir="auto">Below is the statistics of the data. We report the number of instructions with different lengths of solution path:</p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>#APIs</th>
<th>Len-1</th>
<th>Len-2</th>
<th>Len-3</th>
<th>Len-4</th>
<th>Avg. Len.</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>TMDB</td>
<td>54</td>
<td>5</td>
<td>66</td>
<td>27</td>
<td>2</td>
<td>2.3</td>
<td>100</td>
</tr>
<tr>
<td>Spotify</td>
<td>40</td>
<td>8</td>
<td>18</td>
<td>22</td>
<td>9</td>
<td>2.6</td>
<td>57</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Setup</h2>
<div dir="auto" data-snippet-clipboard-copy-content="pip install langchain colorama tiktoken spotipy openai"><pre>pip install langchain colorama tiktoken spotipy openai</pre></div>
<p dir="auto">create <code>logs</code> folder</p>
<p dir="auto">Get OpenAI key from OpenAI, TMDB key from <a href="https://developer.themoviedb.org/docs/getting-started" rel="nofollow">https://developer.themoviedb.org/docs/getting-started</a>, and Spotify key from <a href="https://developer.spotify.com/documentation/web-api" rel="nofollow">https://developer.spotify.com/documentation/web-api</a></p>
<p dir="auto">Fill in your own key in <code>config.yaml</code></p>
<h2 tabindex="-1" dir="auto">(Optional) Initialize the Spotify Environment</h2>
<p dir="auto"><strong>WARNING: this will remove all your data from spotify!</strong></p>

<h2 tabindex="-1" dir="auto">Run</h2>
<p dir="auto">The code can be run using the following command:</p>

<p dir="auto">Then Input the scenario (TMDB/Spotify) and instruction.</p>
<p dir="auto">We also provide two scripts to run RestGPT on RestBench:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# TMDB
python run_tmdb.py

# Spotify, please open Spotify on your device
python run_spotify.py"><pre><span><span>#</span> TMDB</span>
python run_tmdb.py

<span><span>#</span> Spotify, please open Spotify on your device</span>
python run_spotify.py</pre></div>
<p dir="auto"><code>run_tmdb.py</code> will sequentially execute all instructions of RestBench-TMDB. Regarding RestBench-Spotify, you should manually modify the <code>query_idx</code> before executing the instructions.</p>
<h2 tabindex="-1" dir="auto">Citation</h2>
<p dir="auto">If you find this repo useful, please cite us.</p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{song2023restgpt,
      title={RestGPT: Connecting Large Language Models with Real-World RESTful APIs}, 
      author={Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li},
      year={2023},
      eprint={2306.06624},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}"><pre><span>@misc</span>{<span>song2023restgpt</span>,
      <span>title</span>=<span><span>{</span>RestGPT: Connecting Large Language Models with Real-World RESTful APIs<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2023<span>}</span></span>,
      <span>eprint</span>=<span><span>{</span>2306.06624<span>}</span></span>,
      <span>archivePrefix</span>=<span><span>{</span>arXiv<span>}</span></span>,
      <span>primaryClass</span>=<span><span>{</span>cs.CL<span>}</span></span>
}</pre></div>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft has not stopped forcing Edge on Windows 11 users (673 pts)]]></title>
            <link>https://www.ctrl.blog/entry/windows-system-components-default-edge.html</link>
            <guid>37461449</guid>
            <pubDate>Mon, 11 Sep 2023 00:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ctrl.blog/entry/windows-system-components-default-edge.html">https://www.ctrl.blog/entry/windows-system-components-default-edge.html</a>, See on <a href="https://news.ycombinator.com/item?id=37461449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="https://schema.org/articleBody">
        <p>Microsoft published <a href="https://blogs.windows.com/windows-insider/2023/08/25/announcing-windows-11-insider-preview-build-23531-dev-channel/" rel="external" title="“Announcing Windows 11 Insider Preview Build 23531 (Dev Channel)”">a blog post on the <cite>Windows Insider Blog</cite></a> in <time datetime="2023-08-25">late August</time> with a vague statement saying that “Windows system components“ were to begin respecting the default web browser setting. Windows 10 and 11 regularly bypass this setting and force-open links in Microsoft Edge instead. In my extensive testing, I haven’t found any changes in the new Windows Insider version.</p>
        <p>You may have read stories in the tech media celebrating that Windows will finally respect the default browser setting. This reporting seems to have been done completely without verification and based entirely on a misunderstanding. The source of the confusion is this one highlighted but vague entry in the changelog for a recent Windows 11 Insider preview build:</p>
        <figure>
          <blockquote cite="https://blogs.windows.com/windows-insider/2023/08/25/announcing-windows-11-insider-preview-build-23531-dev-channel/">
            <p>In the European Economic Area (<abbr>EEA</abbr>), Windows system components use the default browser to open links.</p>
          </blockquote>
          <figcaption>
            <p><a href="https://blogs.windows.com/windows-insider/2023/08/25/announcing-windows-11-insider-preview-build-23531-dev-channel/" rel="external" title="“Announcing Windows 11 Insider Preview Build 23531 (Dev Channel)”"><cite>Announcing Windows 11 Insider Preview Build 23531 (Dev Channel)</cite></a>, Amanda Langowski Brandon LeBlanc</p>
          </figcaption>
        </figure>
        <p>The highlight makes it sound like Microsoft has finally caved to regulatory pressure from the European Union (<abbr>EU</abbr>). The software powerhouse has abused the dominant market position of its Windows operating system to promote its Edge web browser and services for too long.</p>
        <p>I’ve followed this developing story closely over the years. I even developed the popular open-source <a href="https://www.ctrl.blog/entry/edgedeflector-default-browser.html" title="“EdgeDeflector enforces your default browser setting in Windows”">EdgeDeflector program</a> that hijacked web links destined for Microsoft Edge and directed them back to your default web browser. Microsoft finally reacted and <a href="https://www.ctrl.blog/entry/microsoft-edge-protocol-competition.html" title="“Windows now blocks Edge browser competitors from opening links”">blocked EdgeDeflector from working</a> once the Mozilla Firefox and Brave browsers began <a href="https://www.ctrl.blog/entry/anti-competitive-browser-edges.html" title="“Brave and Firefox to intercept links that force-open in Microsoft Edge”">building the functionality into their web browsers</a>.</p>
        <p>Excitedly, I installed the new Windows Insider build and began testing the changes to see them in action. At first, I didn’t believe my findings. <em>Nothing</em> had changed from the current version of Windows 11.</p>
        <ul>
          <li>The new Windows version still strongly discourages changing the default browser away from Microsoft Edge.</li>
          <li>After system updates, the new version still aggressively prompts you with a captive full-screen experience on start-up to reset your default web browser to Microsoft Edge.</li>
          <li>Web links in primary surfaces still force-open Microsoft Edge — including links in the new Copilot, Start menu, Search on the taskbar and desktop, Windows Spotlight, first-party apps (Outlook, Teams, News, Weather, and more), and Widgets on the taskbar (formerly called News and Weather).</li>
        </ul>
        <p>I’ve verified my findings in the Home and Professional editions of Windows and even the <abbr title="European Union">EU</abbr>-specific “N” variants of each edition. I’ve tested in two configurations for Norway (<abbr title="European Economic Area">EEA</abbr> member) and Germany (<abbr title="European Economic Area">EEA</abbr> and <abbr title="European Union">EU</abbr> member). For both tests, I installed devices with region and locale settings matching the desired country with <abbr title="Internet Protocol">IP</abbr> addresses and geolocation sensor data to match.</p>
        <p>I’ve checked, double-, and triple-checked my findings. <em>Nothing has changed.</em> Web links still force-open in Microsoft Edge instead of your default web browser.</p>
        <p>Microsoft first announced the changes for Windows Insider build 23531 (Developer channel). I waited for two more releases and retested with builds 23536 and 23541, both from the Developer channel. I also retested with the Canary channel, which is even further ahead on the development tree than the Developer channel.</p>
        <p>Microsoft sometimes gradually rolls out changes in the Windows Insider program to a limited set of users. It does not document publicly which new changes are gradually rolled out. However, there were only two new experiments in build 23531. None of them are related to default browser settings or Microsoft Edge. The new changes to default browser handling may be a gradual rollout, though.</p>
        <p>Microsoft was vague about the change, and neither its customers nor the tech media verified their assumptions before running with the story. Despite not having implemented the changes everyone assumed it had, it has received lots of positive press attention for doing the right thing.</p>
        <p>I have not found anyone commenting on whether this change worked for them in the many and extensive discussions on Hacker News, Reddit, and other social media. I’ve also not found any traces of confirmation or checks in the hundreds of news sites that ran the story nor in their comment sections. There has also been no mention of it in the Insider Feedback Hub or any subsequent Windows Insider build announcements or changelogs.</p>
        <p>I have <em>not</em> reached out to Microsoft for a comment on this story. Frankly, at this point, I rather assume they hate me personally more than they hate their average customers. Microsoft has also refused to make statements to <a href="https://www.theregister.com/2023/08/30/microsoft_windows_11_bing/" rel="external" title="“After injecting pop-up ads for Bing into Windows, Microsoft now bends to Europe on links”">The Register</a> and <a href="https://www.theverge.com/2023/9/5/23859537/microsoft-windows-11-default-browser-links-eu-eea-changes" rel="external" title="”Microsoft to stop forcing Windows 11 users into Edge in EU countries“">The Verge</a> for their stories on the vague changes.</p>
        <p><small>Disclaimer: I am an employee of <em>Vivaldi Technologies</em>, a competitor to Microsoft Edge. This website is my personal blog, and the views and findings expressed here do not represent my employer. I’m also the developer of EdgeDeflector, the circumvention program described in the article.</small></p>
      </div><div>
        <h3>Abbreviations</h3>
        <dl>
          <p>
            <dt><dfn><abbr>EEA</abbr></dfn></dt>
            <dd>European Economic Area</dd>
          </p>
          <p>
            <dt><dfn><abbr>EU</abbr></dfn></dt>
            <dd>European Union</dd>
          </p>
          <p>
            <dt><dfn><abbr>IP</abbr></dfn></dt>
            <dd>Internet Protocol</dd>
          </p>
        </dl>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[To make dishwashers great again? (2020) (120 pts)]]></title>
            <link>https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/</link>
            <guid>37460941</guid>
            <pubDate>Sun, 10 Sep 2023 22:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/">https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/</a>, See on <a href="https://news.ycombinator.com/item?id=37460941">Hacker News</a></p>
Couldn't get https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Awk book’s 60-line version of Make (228 pts)]]></title>
            <link>https://benhoyt.com/writings/awk-make/</link>
            <guid>37460815</guid>
            <pubDate>Sun, 10 Sep 2023 22:36:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benhoyt.com/writings/awk-make/">https://benhoyt.com/writings/awk-make/</a>, See on <a href="https://news.ycombinator.com/item?id=37460815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container">

<p>September 2023</p>

<blockquote>
  <p><strong>Go to:</strong> <a href="#original-awk-version">AWK Make</a> | <a href="#how-it-works">How it works</a> | <a href="#python-version">Python Make</a> | <a href="#conclusion">Conclusion</a></p>
</blockquote>

<p>In the wonderful book <em>The AWK Programming Language</em> by Aho, Weinberger, and Kernighan, there are a few pages at the end of chapter 7 that present a simplified version of the Make utility – written in a single page of AWK code.</p>

<p>Before we look at that, I want to mention that the <a href="https://awk.dev/">second edition</a> of the AWK book is coming out next month. Brian Kernighan’s done a great job of updating it, most notably with a new chapter on <a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis">exploratory data analysis</a>, and adding proper CSV support to AWK to enable this. I was honoured to be asked to review a draft of the second edition.</p>

<p>AWK still shines for exploring data in 2023, especially with the new <code>--csv</code> option. CSV mode has also been <a href="https://git.savannah.gnu.org/cgit/gawk.git/tree/NEWS">added to Gawk</a> (GNU AWK), the most widely-installed version of AWK. My own <a href="https://github.com/benhoyt/goawk">GoAWK</a> implementation has had <a href="https://benhoyt.com/writings/goawk-csv/">proper CSV support</a> for some time, and I’ve added the <code>--csv</code> option to match the others.</p>

<p>The second edition of the book still includes the Make program, though it’s been made more readable with the <a href="https://github.com/benhoyt/awkmake/commit/a5793b2b55168959f3f2e976d1e409401cd8aac4">addition</a> of some “spacing and bracing” – this took it from 50 lines to 62 lines.</p>

<p>This article presents the Make program, to show how AWK is not just great for one-liners, but <a href="https://maximullaris.com/awk.html">can be used</a> as a scripting language too – though whether you <em>should</em> or not is another question.</p>

<p>I’m then going to compare what the same program would look like in Python, and briefly discuss when you’d choose AWK or Python for this kind of thing.</p>

<p>It should go without saying, but I intend this purely as a learning exercise (for me and my readers), not a program I’d recommend you use to build your projects!</p>

<h2 id="original-awk-version">Original AWK version</h2>

<p>The second edition of the book introduces the Make program as follows. (For what it’s worth, I find the term “target” confusing here – I think “source” or “dependency” would fit better.)</p>

<blockquote>
  <p>This section develops a
rudimentary updating program, patterned after the Unix <code>make</code> command, that
is based on the depth-first search technique of the previous section.</p>

  <p>To use the updater, one must explicitly describe what the components of the
system are, how they depend upon one another, and what commands are needed
to construct them. We’ll assume these dependencies and commands are stored
in a file, called a <code>makefile</code>, that contains a sequence of rules of the form</p>

  <div><pre><code>name:   t1 t2 ... tn
        commands
</code></pre></div>

  <p>The first line of a rule is a dependency relation that states that the program or
file <em>name</em> depends on the targets <em>t1</em>, <em>t2</em>, …, <em>tn</em> where each <em>ti</em> is a filename or
another <em>name</em>. Following each dependency relation may be one or more lines of
<em>commands</em> that list the commands necessary to generate <em>name</em>. Here is an
example of a <code>makefile</code> for a small program with two C files called <code>a.c</code> and <code>b.c</code>, and a <code>yacc</code>
grammar file <code>c.y</code>, a typical program-development application.</p>

  <div><pre><code>prog:   a.o b.o c.o
        gcc a.o b.o c.o -ly -o prog
a.o:    prog.h a.c
        gcc -c prog.h a.c
b.o:    prog.h b.c
        gcc -c prog.h b.c
c.o:    c.c
        gcc -c c.c
c.c:    c.y
        yacc c.y
        mv y.tab.c c.c
print:
        pr prog.h a.c b.c c.y
</code></pre></div>

  <p>The first line states that <code>prog</code> depends on the target files <code>a.o</code>, <code>b.o</code>, and <code>c.o</code>.
The second line says that <code>prog</code> is generated by using the C compiler command
<code>gcc</code> to link <code>a.o</code>, <code>b.o</code>, <code>c.o</code>, and a <code>yacc</code> library <code>y</code> into the file <code>prog</code>. The next rule
(third line) states that <code>a.o</code> depends on the targets <code>prog.h</code> and <code>a.c</code> and is
created by compiling these targets; <code>b.o</code> is the same. The file <code>c.o</code> depends on
<code>c.c</code>, which in turn depends on <code>c.y</code>, which has to be processed by the <code>yacc</code>
parser generator. Finally, the name <code>print</code> does not depend on any target; by
convention, for targetless names <code>make</code> will always perform the associated action,
in this case printing all the source files with the command <code>pr</code>.</p>

  <p>The dependency relations in the <code>makefile</code> can be represented by a graph
in which there is an edge from node <em>x</em> to node <em>y</em> whenever there is a dependency
rule with <em>x</em> on the left side and <em>y</em> one of the targets on the right. For a rule
with no targets, a successorless node with the name on the left is created. For
the <code>makefile</code> above, we have the following dependency graph:</p>

  <div><pre><code>                  prog                 print
                /   |   \
               /    |    \
            a.o    b.o    c.o
           /   \  /   \      \
          /     \/     \      \
        a.c   prog.h   b.c     c.c
                                |
                               c.y
</code></pre></div>
</blockquote>

<p>It’s a highly-simplified version of Make, of course, but still has the core concepts of outputs, dependencies, and build commands.</p>

<p>Before we look at how it works, I’ve included the full source code below, as it appears in the second edition of the AWK book. Click on the bold text to expand it, or skip down to “How it works” to see the code explained in detail.</p>

<details>
  <summary><strong>The AWK book’s Make program (full source code).</strong></summary>

  <div><pre><code><span>BEGIN</span> <span>{</span>
    <span>while</span> <span>(</span><span>getline</span> <span>&lt;</span><span>"makefile"</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>[</span><span>A-Za-z</span><span>]</span><span>/</span><span>)</span> <span>{</span>  <span>#  $1: $2 $3 ...</span>
            <span>sub</span><span>(</span><span>/:/</span><span>,</span> <span>""</span><span>)</span>
            <span>if</span> <span>(</span><span>++</span><span>names</span><span>[</span><span>nm</span> <span>=</span> <span>$1</span><span>]</span> <span>&gt;</span> <span>1</span><span>)</span>
                <span>error</span><span>(</span><span>nm</span> <span>" is multiply defined"</span><span>)</span>
            <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>NF</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span># remember targets</span>
                <span>slist</span><span>[</span><span>nm</span><span>,</span> <span>++</span><span>scnt</span><span>[</span><span>nm</span><span>]]</span> <span>=</span> <span>$i</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>\t</span><span>/</span><span>)</span> <span>{</span>      <span># remember cmd for</span>
            <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>$0</span> <span>"\n"</span> <span>#   current name</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>NF</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
            <span>error</span><span>(</span><span>"illegal line in makefile: "</span> <span>$0</span><span>)</span>
        <span>}</span>
    <span>}</span>

    <span>ages</span><span>()</span>      <span># compute initial ages</span>

    <span>if</span> <span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>in</span> <span>names</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>update</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>])</span> <span>==</span> <span>0</span><span>)</span>
            <span>print</span> <span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is up to date"</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>error</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is not in makefile"</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>function</span> <span>ages</span><span>(</span>      <span>f</span><span>,</span><span>n</span><span>,</span><span>t</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>t</span> <span>=</span> <span>1</span><span>;</span> <span>(</span><span>"ls -t"</span> <span>|</span> <span>getline</span> <span>f</span><span>)</span> <span>&gt;</span> <span>0</span><span>;</span> <span>t</span><span>++</span><span>)</span>
        <span>age</span><span>[</span><span>f</span><span>]</span> <span>=</span> <span>t</span>         <span># all existing files get an age</span>
    <span>close</span><span>(</span><span>"ls -t"</span><span>)</span>

    <span>for</span> <span>(</span><span>n</span> <span>in</span> <span>names</span><span>)</span>
        <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>   <span># if n has not been created</span>
            <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>9999</span>  <span># make n really old</span>
<span>}</span>

<span>function</span> <span>update</span><span>(</span><span>n</span><span>,</span>   <span>changed</span><span>,</span><span>i</span><span>,</span><span>s</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>
        <span>error</span><span>(</span><span>n</span> <span>" does not exist"</span><span>)</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>names</span><span>))</span>
        <span>return</span> <span>0</span>
    <span>changed</span> <span>=</span> <span>0</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>1</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>scnt</span><span>[</span><span>n</span><span>];</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span> <span>=</span> <span>slist</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>]]</span> <span>==</span> <span>0</span><span>)</span>
            <span>update</span><span>(</span><span>s</span><span>)</span>
        <span>else</span> <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span><span>]</span> <span>==</span> <span>1</span><span>)</span>
            <span>error</span><span>(</span><span>s</span> <span>" and "</span> <span>n</span> <span>" are circularly defined"</span><span>)</span>
        <span>if</span> <span>(</span><span>age</span><span>[</span><span>s</span><span>]</span> <span>&lt;=</span> <span>age</span><span>[</span><span>n</span><span>])</span>
            <span>changed</span><span>++</span>
    <span>}</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>2</span>
    <span>if</span> <span>(</span><span>changed</span> <span>||</span> <span>scnt</span><span>[</span><span>n</span><span>]</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"%s"</span><span>,</span> <span>cmd</span><span>[</span><span>n</span><span>])</span>
        <span>system</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>])</span>  <span># execute cmd associated with n</span>
        <span>ages</span><span>()</span>          <span># recompute all ages</span>
        <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>0</span>      <span># make n very new</span>
        <span>return</span> <span>1</span>
    <span>}</span>
    <span>return</span> <span>0</span>
<span>}</span>

<span>function</span> <span>error</span><span>(</span><span>s</span><span>)</span> <span>{</span> <span>print</span> <span>"error: "</span> <span>s</span><span>;</span> <span>exit</span> <span>}</span>
</code></pre></div>
</details>

<h2 id="how-it-works">How it works</h2>

<p>There’s an explanation of how the program works in the book, but I’ll explain it in my own words here, focussing on the aspects I find interesting.</p>

<p>The <code>BEGIN</code> block is the main entry point for a program like this. Unlike most AWK programs which implicitly read lines from standard input, this one uses an explicit loop with <code>getline</code> to read the <code>makefile</code>:</p>

<div><pre><code><span>BEGIN</span> <span>{</span>
    <span>while</span> <span>(</span><span>getline</span> <span>&lt;</span><span>"makefile"</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>[</span><span>A-Za-z</span><span>]</span><span>/</span><span>)</span> <span>{</span>  <span>#  $1: $2 $3 ...</span>
            <span>sub</span><span>(</span><span>/:/</span><span>,</span> <span>""</span><span>)</span>
            <span>if</span> <span>(</span><span>++</span><span>names</span><span>[</span><span>nm</span> <span>=</span> <span>$1</span><span>]</span> <span>&gt;</span> <span>1</span><span>)</span>
                <span>error</span><span>(</span><span>nm</span> <span>" is multiply defined"</span><span>)</span>
            <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>NF</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span># remember targets</span>
                <span>slist</span><span>[</span><span>nm</span><span>,</span> <span>++</span><span>scnt</span><span>[</span><span>nm</span><span>]]</span> <span>=</span> <span>$i</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>\t</span><span>/</span><span>)</span> <span>{</span>      <span># remember cmd for</span>
            <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>$0</span> <span>"\n"</span> <span>#   current name</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>NF</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
            <span>error</span><span>(</span><span>"illegal line in makefile: "</span> <span>$0</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>...</span>
<span>}</span>
</code></pre></div>

<p>The <code>getline &lt;filename</code> is a redirect clause that opens <code>makefile</code> (the first time) and reads it line-by-line until the end. If the line (<code>$0</code>) starts with a letter (<code>/^[A-Za-z]/</code>), it’s considered a <code>name: targets</code> rule.</p>

<p>The <code>sub(/:/, "")</code> call removes the colon from the current line (the <code>$0</code> is implicit in the two-argument form of <code>sub</code>).</p>

<p>We then ensure that this rule hasn’t already been defined by checking the <code>names</code> array. An AWK array is actually an <em>associative array</em>, an old-school term for a key-value map.</p>

<p>The inner <code>for</code> loop adds each target (or dependency) to the <code>slist</code> / <code>scnt</code> data structure. This is really a map of lists, but it’s flattened to work around the fact that AWK doesn’t support nested collections. The body of the loop is very terse:</p>

<div><pre><code><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>NF</span><span>;</span> <span>i</span><span>++</span><span>)</span>
    <span>slist</span><span>[</span><span>nm</span><span>,</span> <span>++</span><span>scnt</span><span>[</span><span>nm</span><span>]]</span> <span>=</span> <span>$i</span>
</code></pre></div>

<p>This loops through each dependency: every field <code>$i</code> from field 2 to <code>NF</code> (the number of fields in the line).</p>

<p>For each dependency, it increments <code>scnt[nm]</code>, the count of sources for the current rule (<code>nm</code>). Then, store the dependency <code>$i</code> in <code>slist</code>, indexed by the multi-key name and count. AWK simulates multi-dimensional or multi-key arrays by creating a concatenated key where each key is separated by the <code>SUBSEP</code> separator (which defaults to <code>"\x1c"</code>).</p>

<p>After the loop, in the <code>prog</code> example we’d end up with <code>slist</code> and <code>scnt</code> looking like this:</p>

<div><pre><code>slist
    a.o,1:  prog.h
    a.o,2:  a.c
    b.o,1:  prog.h
    b.o,2:  b.c
    c.c,1:  c.y
    c.o,1:  c.c
    prog,1: a.o
    prog,2: b.o
    prog,3: c.o

scnt
    a.o:  2
    b.o:  2
    c.c:  1
    c.o:  1
    prog: 3
</code></pre></div>

<p>Coming back up, if the line starts with a tab, it’s a command, so we append it to the name’s command string:</p>

<div><pre><code><span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>$0</span> <span>"\n"</span>
</code></pre></div>

<p>Otherwise, if the line is not a blank line (<code>NF &gt; 0</code>), it’s a <code>makefile</code> error.</p>

<p>Finally, after reading the <code>makefile</code> in the <code>while</code> loop, we uses <code>ages()</code> to compute the ages of all files in the current directory, and then call <code>update(ARGV[1])</code> to update the rule passed on the command line:</p>

<div><pre><code><span>BEGIN</span> <span>{</span>
    <span>...</span>
    <span>ages</span><span>()</span>      <span># compute initial ages</span>

    <span>if</span> <span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>in</span> <span>names</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>update</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>])</span> <span>==</span> <span>0</span><span>)</span>
            <span>print</span> <span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is up to date"</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>error</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is not in makefile"</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>The <code>ages</code> function is where things start to get interesting:</p>

<div><pre><code><span>function</span> <span>ages</span><span>(</span>      <span>f</span><span>,</span><span>n</span><span>,</span><span>t</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>t</span> <span>=</span> <span>1</span><span>;</span> <span>(</span><span>"ls -t"</span> <span>|</span> <span>getline</span> <span>f</span><span>)</span> <span>&gt;</span> <span>0</span><span>;</span> <span>t</span><span>++</span><span>)</span>
        <span>age</span><span>[</span><span>f</span><span>]</span> <span>=</span> <span>t</span>         <span># all existing files get an age</span>
    <span>close</span><span>(</span><span>"ls -t"</span><span>)</span>

    <span>for</span> <span>(</span><span>n</span> <span>in</span> <span>names</span><span>)</span>
        <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>   <span># if n has not been created</span>
            <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>9999</span>  <span># make n really old</span>
<span>}</span>
</code></pre></div>

<p>The parameter names <code>f</code>, <code>n</code>, and <code>t</code> are prefixed with a bunch of spaces to show they’re actually local variables, and not expected as arguments. This is an AWK quirk (which Kernighan regrets): the only way to define local variables is as function parameters, and if a function is called with fewer arguments than it has parameters, the extras take on the default value (0 for numbers, <code>""</code> for strings). So you’ll see these extra spaces a lot in AWK function definitions.</p>

<p>The next thing is quite neat: AWK supports shell-like <code>|</code> syntax to pipe the output of a program, one <code>getline</code> at a time, to a variable (in this case <code>f</code>). The <code>ls -t</code> command lists files in the current directory ordered by modification time, newest first.</p>

<p>After the loop that’s assigned each file’s age to <code>age[f]</code>, we call <code>close</code> to close the <code>ls -t</code> pipe and avoid too many open file handles.</p>

<p>Finally, we loop through the rule names and assign an arbitrary large number to <code>age[n]</code> to pretend that files that haven’t been created are really old and need to be updated.</p>

<p>Next is the recursive <code>update</code> function, where the meat of the algorithm lives:</p>

<div><pre><code><span>function</span> <span>update</span><span>(</span><span>n</span><span>,</span>   <span>changed</span><span>,</span><span>i</span><span>,</span><span>s</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>
        <span>error</span><span>(</span><span>n</span> <span>" does not exist"</span><span>)</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>names</span><span>))</span>
        <span>return</span> <span>0</span>
    <span>changed</span> <span>=</span> <span>0</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>1</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>scnt</span><span>[</span><span>n</span><span>];</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span> <span>=</span> <span>slist</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>]]</span> <span>==</span> <span>0</span><span>)</span>
            <span>update</span><span>(</span><span>s</span><span>)</span>
        <span>else</span> <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span><span>]</span> <span>==</span> <span>1</span><span>)</span>
            <span>error</span><span>(</span><span>s</span> <span>" and "</span> <span>n</span> <span>" are circularly defined"</span><span>)</span>
        <span>if</span> <span>(</span><span>age</span><span>[</span><span>s</span><span>]</span> <span>&lt;=</span> <span>age</span><span>[</span><span>n</span><span>])</span>
            <span>changed</span><span>++</span>
    <span>}</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>2</span>
    <span>if</span> <span>(</span><span>changed</span> <span>||</span> <span>scnt</span><span>[</span><span>n</span><span>]</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"%s"</span><span>,</span> <span>cmd</span><span>[</span><span>n</span><span>])</span>
        <span>system</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>])</span>  <span># execute cmd associated with n</span>
        <span>ages</span><span>()</span>          <span># recompute all ages</span>
        <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>0</span>      <span># make n very new</span>
        <span>return</span> <span>1</span>
    <span>}</span>
    <span>return</span> <span>0</span>
<span>}</span>
</code></pre></div>

<p>Once again you’ll note the parameter list: <code>n</code> is an expected argument (the name to update), and <code>changed,i,s</code> are the locals.</p>

<p>After initial checks, we loop through the list of dependencies by iterating from <code>slist[n, 1]</code> to <code>slist[n, scnt[n]]</code>. If we haven’t visited this dependency yet, we perform a depth-first traversal of the dependency graph by recursively calling <code>update</code> to see if we need to update that dependency first:</p>

<div><pre><code><span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span> <span>=</span> <span>slist</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>]]</span> <span>==</span> <span>0</span><span>)</span>
    <span>update</span><span>(</span><span>s</span><span>)</span>
</code></pre></div>

<p>The recursion is terminated by the <code>if (!(n in names)) return 0</code> block near the top. We stop when the file being updated isn’t in the list of rule names – which is a leaf node in the dependency graph.</p>

<p>The block <code>if (age[s] &lt;= age[n]) changed++</code> increments the <code>changed</code> count if any dependency is newer than the age of the current file being updated.</p>

<p>After the traversal loop, if any of the dependencies or sub-dependencies had changed, we run the associated command using <code>system()</code>, recompute the ages of all files, and <code>return 1</code> to the caller to indicate we did make an update.</p>

<p>The <code>scnt[n] == 0</code> clause handles the case where the rule being updated doesn’t have any dependencies specified, like the <code>print</code> rule in the example. In that case, always re-run its command.</p>

<p>And there you have it! A minimalist Make in one page of AWK.</p>

<h2 id="python-version">Python version</h2>

<p>For interest, I ported the book’s AWK Make to Python, and have included it below. Once again, click the bold text to expand the program.</p>

<details>
  <summary><strong>My Python port of the Make program (full source code).</strong></summary>

  <div><pre><code><span>import</span> <span>os</span><span>,</span> <span>re</span><span>,</span> <span>sys</span>

<span>slist</span> <span>=</span> <span>{}</span>  <span># slist[name] is list of rule's sources
</span><span>cmd</span> <span>=</span> <span>{}</span>    <span># cmd[name] is shell command to run for rule
</span>
<span>def</span> <span>main</span><span>():</span>
    <span>for</span> <span>line</span> <span>in</span> <span>open</span><span>(</span><span>'makefile'</span><span>):</span>
        <span>if</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>'[A-Za-z]'</span><span>,</span> <span>line</span><span>):</span>
            <span>line</span> <span>=</span> <span>line</span><span>.</span><span>replace</span><span>(</span><span>':'</span><span>,</span> <span>''</span><span>)</span>
            <span>fields</span> <span>=</span> <span>line</span><span>.</span><span>split</span><span>()</span>
            <span>nm</span> <span>=</span> <span>fields</span><span>[</span><span>0</span><span>]</span>
            <span>if</span> <span>nm</span> <span>in</span> <span>slist</span><span>:</span>
                <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>nm</span><span>}</span><span> is multiply defined'</span><span>)</span>
            <span>slist</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>fields</span><span>[</span><span>1</span><span>:]</span>    <span># remember targets
</span>        <span>elif</span> <span>line</span><span>.</span><span>startswith</span><span>(</span><span>'</span><span>\t</span><span>'</span><span>):</span>   <span># remember cmd for current name
</span>            <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>.</span><span>get</span><span>(</span><span>nm</span><span>,</span> <span>''</span><span>)</span> <span>+</span> <span>line</span>
        <span>elif</span> <span>line</span><span>.</span><span>strip</span><span>():</span>
            <span>error</span><span>(</span><span>f</span><span>'illegal line in makefile: </span><span>{</span><span>line</span><span>}</span><span>'</span><span>)</span>
    <span>if</span> <span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]</span> <span>in</span> <span>slist</span><span>:</span>
        <span>if</span> <span>not</span> <span>update</span><span>(</span><span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]):</span>
            <span>print</span><span>(</span><span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>'is up to date'</span><span>)</span>
    <span>else</span><span>:</span>
        <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]</span><span>}</span><span> is not in makefile'</span><span>)</span>

<span>def</span> <span>mtime</span><span>(</span><span>n</span><span>):</span>
    <span>try</span><span>:</span>
        <span>return</span> <span>os</span><span>.</span><span>stat</span><span>(</span><span>n</span><span>).</span><span>st_mtime</span>
    <span>except</span> <span>FileNotFoundError</span><span>:</span>
        <span>return</span> <span>0</span>  <span># mark as old if it doesn't exist
</span>
<span>def</span> <span>update</span><span>(</span><span>n</span><span>,</span> <span>visited</span><span>=</span><span>{}):</span>
    <span>ntime</span> <span>=</span> <span>mtime</span><span>(</span><span>n</span><span>)</span>
    <span>if</span> <span>n</span> <span>not</span> <span>in</span> <span>slist</span> <span>and</span> <span>ntime</span> <span>==</span> <span>0</span><span>:</span>
        <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>n</span><span>}</span><span> does not exist'</span><span>)</span>
    <span>if</span> <span>n</span> <span>not</span> <span>in</span> <span>slist</span><span>:</span>
        <span>return</span> <span>0</span>
    <span>changed</span> <span>=</span> <span>False</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>1</span>
    <span>for</span> <span>s</span> <span>in</span> <span>slist</span><span>.</span><span>get</span><span>(</span><span>n</span><span>,</span> <span>[]):</span>
        <span>if</span> <span>s</span> <span>not</span> <span>in</span> <span>visited</span><span>:</span>
            <span>update</span><span>(</span><span>s</span><span>)</span>
        <span>elif</span> <span>visited</span><span>[</span><span>s</span><span>]</span> <span>==</span> <span>1</span><span>:</span>
            <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>s</span><span>}</span><span> and </span><span>{</span><span>n</span><span>}</span><span> are circularly defined'</span><span>)</span>
        <span>if</span> <span>mtime</span><span>(</span><span>s</span><span>)</span> <span>&gt;</span> <span>ntime</span><span>:</span>
            <span>changed</span> <span>=</span> <span>True</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>2</span>
    <span>if</span> <span>changed</span> <span>or</span> <span>len</span><span>(</span><span>slist</span><span>.</span><span>get</span><span>(</span><span>n</span><span>,</span> <span>[]))</span> <span>==</span> <span>0</span><span>:</span>
        <span>print</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>],</span> <span>end</span><span>=</span><span>''</span><span>)</span>
        <span>os</span><span>.</span><span>system</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>])</span>  <span># execute cmd associated with n
</span>        <span>return</span> <span>1</span>
    <span>return</span> <span>0</span>

<span>def</span> <span>error</span><span>(</span><span>msg</span><span>):</span>
    <span>print</span><span>(</span><span>'error:'</span><span>,</span> <span>msg</span><span>,</span> <span>file</span><span>=</span><span>sys</span><span>.</span><span>stderr</span><span>)</span>
    <span>sys</span><span>.</span><span>exit</span><span>(</span><span>1</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>main</span><span>()</span>
</code></pre></div>
</details>

<p>It’s very similar in structure to the original AWK version, though I made two simplifications which I think make it somewhat easier to understand:</p>

<ol>
  <li>Simpler data structures to avoid the <code>slist</code> / <code>scnt</code> quirkiness – in Python we can just use a dictionary of lists. (<a href="https://github.com/benhoyt/awkmake/commit/490e5d210bdd4a7ce61292c73f1ec3f06da090eb">See diff.</a>)</li>
  <li>Determine ages more directly using <code>os.stat()</code> to fetch file modification times (mtimes), rather than using the <code>ls -t</code> trick. This also removes the need for the <code>age</code> map and the <code>ages</code> function. (<a href="https://github.com/benhoyt/awkmake/commit/7bb6a6de06a329551678fb90073a268342baf049">See diff.</a>)</li>
</ol>

<p>I didn’t plan for this, but even if you include the <code>import</code> line and the <code>if __name__ == '__main__'</code> dance, it’s 58 lines of code – basically the same length as the AWK program.</p>

<p>When making the Python version, I realized we could simplify the AWK version in a similar way:</p>

<ol>
  <li>It’s conceptually simpler to store the <code>slist</code> directly as an AWK array: a key-value map where the key is the rule name and the value is the list of dependencies as a space-separated string (just like in the <code>makefile</code>). We can use <code>split</code> as needed to turn the dependencies string into a list (an array from 1 to the number of dependencies). This avoids the need for <code>scnt</code> and <code>names</code> altogether. (<a href="https://github.com/benhoyt/awkmake/pull/2/commits/45b5c4de5ec4c5b09830fdf06b00f4e0c7f7886e">See diff.</a>)</li>
  <li>Similar to the Python version, we can get the mtime directly by shelling out to <code>stat</code>, instead of listing all files in age order with <code>ls -t</code>. I’ve used <code>stat --format %y</code> to do this. I believe this is a GNU extension, so it’s not as portable as <code>ls -t</code>, but it’s simpler and avoids the need for recomputing the <code>age</code> array. (<a href="https://github.com/benhoyt/awkmake/pull/2/commits/d5cd8cc3cdeebce953dc2b15c9fedca3eef5ceca">See diff.</a>)</li>
</ol>

<p>For what it’s worth, the modified version is four lines shorter than the original. I think the simpler <code>slist</code> is clearer, and I like the more direct approach to fetching mtimes, though I realize the lack of portability of <code>stat --format</code> is a downside (macOS’s <code>stat</code> looks <a href="https://ss64.com/osx/stat.html">quite different</a>).</p>

<h2 id="conclusion">Conclusion</h2>

<p>The AWK Make program is a neat little piece of code that shows how useful a language AWK is, even for medium-sized scripts.</p>

<p>However, Python is definitely a nicer language for this kind of thing: it has much richer data types, better tools like <code>os.stat</code>, and local variables without quirky syntax.</p>

<p>I consider AWK amazing, but I think it should remain where it excels: for exploratory data analysis and for one-liner data extraction scripts.</p>

<p>As the author of GoAWK, which has had native CSV support for a while, I’m especially pleased to see both Kernighan’s “one true AWK” and Gawk gain proper CSV support in the form of the <code>--csv</code> option. Kernighan’s <a href="https://github.com/onetrueawk/awk/commit/c76017e59eb71b5403d44fb974a83bf71462eb39#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5">AWK updates</a> will be merged soon, and Gawk will <a href="http://git.savannah.gnu.org/cgit/gawk.git/tree/NEWS">include this feature in version 5.3.0</a>, which is coming out soon.</p>

<p>You can also view my <a href="https://github.com/benhoyt/awkmake">awkmake</a> repo on GitHub, which contains the full source for both the AWK book’s Make program and my Python version, as well as a runnable example project based on the example in the AWK book.</p>

<p>I’d love it if you <a href="https://github.com/sponsors/benhoyt/">sponsored me on GitHub</a> – it will motivate me to work on my open source projects and write more good content. Thanks!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RISC-V SBI and the full boot process (109 pts)]]></title>
            <link>https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/</link>
            <guid>37460614</guid>
            <pubDate>Sun, 10 Sep 2023 22:10:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/">https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/</a>, See on <a href="https://news.ycombinator.com/item?id=37460614">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" role="article">
      <p>In the last article, we covered <a href="https://popovicu.com/posts/bare-metal-programming-risc-v">bare metal programming on RISC-V</a>. Please familiarize yourself with that material before proceeding with the rest of this article, as this article is a direct continuation of the aforementioned one.</p>
<p>This time we are talking about RISC-V <strong>SBI (Supervisor Binary Interface)</strong>, with <strong>OpenSBI</strong> as the example. We’ll look at how SBI can assist us with implementing operating system kernel primitives and we’ll end the article with a practical example using <code>riscv64 virt</code> machine.</p>
<h2 id="table-of-contents">Table of contents</h2>
<details><summary>Open Table of contents</summary>
<ul>
<li>
<p><a href="#risc-v-and-bios">RISC-V and “BIOS”</a></p>
<ul>
<li><a href="#machine-modes">Machine modes</a></li>
<li><a href="#sbi">SBI</a></li>
<li><a href="#fancy-abstractions">Fancy abstractions</a></li>
<li><a href="#binary-interface">Binary interface</a></li>
</ul>
</li>
<li>
<p><a href="#practical-example-with-opensbi">Practical example with OpenSBI</a></p>
</li>
<li>
<p><a href="#booting-the-os-kernel-after-sbi-and-calling-into-opensbi">Booting the OS kernel after SBI and calling into OpenSBI</a></p>
<ul>
<li>
<p><a href="#what-really-happens-in-the-zsbl">What really happens in the ZSBL?</a></p>
</li>
<li>
<p><a href="#3-flavors-of-opensbi">3 flavors of OpenSBI</a></p>
<ul>
<li><a href="#fw_payload"><code>FW_PAYLOAD</code></a></li>
<li><a href="#fw_jump"><code>FW_JUMP</code></a></li>
<li><a href="#fw_dynamic"><code>FW_DYNAMIC</code></a></li>
<li><a href="#exploring-the-fw_dynamic_info-struct">Exploring the <code>fw_dynamic_info</code> struct</a></li>
<li><a href="#building-an-infinite-loop-fake-kernel">Building an “infinite-loop fake kernel”</a></li>
<li><a href="#intentionally-skipped-details">Intentionally skipped details</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#hello-world-fake-kernel">Hello world fake kernel</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
<li>
<p><a href="#code-pointers">Code pointers</a></p>
</li>
</ul>
</details>
<h2 id="risc-v-and-bios">RISC-V and “BIOS”</h2>
<p>In the article mentioned above, we talked extensively about the very first stages of the RISC-V bootup process. We mentioned that first the ZSBL (Zero Stage Bootloader) runs, initializes a few registers and jumps directly to some address hardcoded by ZSBL. In the case of QEMU’s <code>riscv64 virt</code>, the hardcoded address is <code>0x80000000</code>. This is where the first user-provided code runs, and if left to default, QEMU will load <code>OpenSBI</code> there.</p>
<h3 id="machine-modes">Machine modes</h3>
<p>So far we have avoided talking about different machine modes, and now is the perfect time to introduce them. The concept with machines modes is that not every piece of software should be able to access just about any memory address on the machine, or even execute just about any instructions available with the CPU. Traditionally, in a textbook example, the two main divisions are made here:</p>
<ol>
<li>Privileged mode</li>
<li>Unprivileged mode</li>
</ol>
<p>The <em>privileged mode</em> is where the machine starts at the boot time. Any instruction is permitted and no address access is considered an access violation. Once the operating system takes over the control of the system and starts launching the user code (aka userspace code), the modes start switching. When the user code is running on the CPU core, it is running within the <em>unprivileged mode</em> where not everything is accessible. Going back to the kernel mode means switching back to the privilged mode.</p>
<p>This is a very textbook and simplistic view at the permissions of operations and the question arises: why only 2 modes?</p>
<p>In systems, more than 2 modes typically exist, forming a <a href="https://en.wikipedia.org/wiki/Protection_ring">protection ring</a> with multiple access modes. RISC-V specification does not necessarily prescribe exactly which modes must be implemented for a core, except the <strong>M (Machine)</strong> mode. This is the most privileged mode.</p>
<p>Typically, the processors with M mode only are simple embedded systems, moving over more secure systems (M and S modes), all the way to full systems that can run Unix-like operating systems (M, S and U modes).</p>
<h3 id="sbi">SBI</h3>
<p>The <a href="https://github.com/riscv-non-isa/riscv-sbi-doc">official docs</a> provide a formal definition, and I will try to water it down here with the goals of making it more intuitive.</p>
<p>RISC-V’s SBI spec defines the layer of software that sits at the bottom of the RISC-V software stack. This is very similar to BIOS, which is traditionally the first bit of software that runs on a machine. You might have seen some of the guides for developing a simple kernel from scratch, and they typically involve something similar to what we did in the <a href="https://popovicu.com/posts/bare-metal-programming-risc-v">initial guide</a> for bare metal programming on RISC-V, with a small twist — they are very often actually depending on the pre-existing software to do some I/O. The similarity to our previous guide is that they also carefully align the first instructions to the correct address to ensure that the processor’s execution flow goes as intended and the simple kernel takes over at the right time, however, what I have typically observed in those short guides is that the goal is typically to print something like ‘Hello world’ to <strong>the VGA screen</strong>. This last bit sounds like a fairly complex operation, and it really is.</p>
<p>How is printing to the VGA then done easily then? The answer is that BIOS is here to assist with the most basic I/O operations such as printing some characters to the screen, hence its name — <strong>B</strong>asic <strong>I</strong>nput <strong>O</strong>utput <strong>S</strong>ystem! Please pay attention to the opening section of the bare metal programming guide: we were achieving interaction with the user <em>without</em> depending on <em>any</em> existing software on the machine (well, almost true, we still went through the Zero Stage Bootloader, but we didn’t depend on any outcome from it, nor we really had any control over it; it’s simply hardcoded into the system). If we were to print something on the VGA screen, instead of sending characters out through UART, we would have to do a lot more than send an ASCII code to a single address. VGA involves setting up the display device into the right mode, by sending multiple values over, setting up different parameters, etc. It’s a fairly ellaborate operation.</p>
<p>So how does BIOS traditionally help with tasks like these? The main concept is that whatever operating system ends up installed on the machine, it would anyway need some basic functionality, such as printing some information to the VGA screen. Thus, the machine can have these standard operations simply baked into it and ready to consume by whatever operating system ends up on the machine. Conceptually, we can think of these procedures as an everyday library we write our applications against.</p>
<p>Additionally, if an operating system is written against such a “library”, it automatically becomes more portable. The “library” should have all the low level details, such as “outputting to UART means writing to <code>0x10000000</code>” (as is the case with QEMU’s <code>riscv64 virt</code> VM), vs. “outputting to UART means writing to <code>0x12345678</code>”, and the operating system simply needs to invoke “outputting to UART” procedure, while this “library” will know exactly how to interact with the hardware.</p>
<h3 id="fancy-abstractions">Fancy abstractions</h3>
<p>This is all just a lot of talk for a very simple concept we have been using in programming since day 1: we apply <strong>layers of abstractions</strong> in our coding. Think of something like a Python function that does something like “sending a local file to an email address”. From a high level perspective, we simply call a function <code>send_file_to_email(file, email)</code> and the underlying library opens up the network connection and starts pumping the bytes. This could be just another Python library. At some point, that will likely move down the software stack, and the Python library will depend on the Python runtime written in something like C to make a system call to the operating system (for example, to perform a core operation such as opening a network socket). The operating system has a network driver somewhere deep down, which knows to which address in the address space does it need to send the individual bytes in order to send the bytes over the wire to the network and so on. The main concept here is that we have an established way of hiding the complexity of operations by delegating them to the lower layers of the software stack. We built the larger system not from the atomic parts, but out of “molecules”.</p>
<p>If we’re delegating the complexity to the underlying library, it probably just means a function call. However, once it’s time to delegate the complexity to the operating system and lower, this happens through a <strong>binary interface</strong>.</p>
<h3 id="binary-interface">Binary interface</h3>
<p>Since basically forever, the <code>x86</code> has been the dominant architecture for the computers we use, be it desktops or laptops. Things have been changing a lot lately, and other architectures are entering the picture, but let’s focus on just <code>x86</code>. What then, makes an application built for Linux incompatible with the application for Windows? If it’s written for <code>x86</code>, and both Linux and Windows run on <code>x86</code>, what could possibly be the differentiator here? The CPU instructions are not different from one platform and the other, so what could it be? The answer is the <strong>interface between the application and the operating system</strong>. This particular link between the user software and the operating system is called the <strong>application binary interface (ABI)</strong>. ABI is just a definition that says how the services from the operating system are invoked from the user application.</p>
<p>Therefore, when we say something like “this software is written for platform X”, it’s not enough to just say that X is <code>x86</code> or <code>RISC-V</code>, we must say <code>x86/Linux</code> or <code>x86/Windows</code> or <code>RISC-V Linux</code> etc. The platform definition may be even more complex than that if things like dynamic linking are involved, but let us not go there for now.</p>
<p>Let’s take a quick example at a program written in assembly for <code>x86/Linux</code> that just prints a ‘Hello’ string to the standard output.</p>
<pre is:raw="" tabindex="0"><code><span><span>.global _start</span></span>
<span></span>
<span><span>.</span><span>section .text</span></span>
<span></span>
<span><span>_start:</span><span> </span><span>mov</span><span> </span><span>$4</span><span>, %</span><span>eax</span><span> </span><span>; 4 is the code for the 'write' system call</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$1</span><span>, %</span><span>ebx</span><span> </span><span>; We are writing to file 1, i.e. the 'standard output'</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$message</span><span>, %</span><span>ecx</span><span> </span><span>; The data we want to print is at the address defined by the symbol message</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$5</span><span>, %</span><span>edx</span><span> </span><span>; The length of the data we want to print is 5</span></span>
<span><span>        </span><span>int</span><span> </span><span>$0x80</span><span> </span><span>; Invoke the system call, i.e. ask kernel to print the data to the standard output</span></span>
<span></span>
<span><span>        </span><span>mov</span><span> </span><span>$1</span><span>, %</span><span>eax</span><span> </span><span>; 1 is the code for the 'exit' system call</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$0</span><span>, %</span><span>ebx</span><span> </span><span>; 0 is the process return code</span></span>
<span><span>        </span><span>int</span><span> </span><span>$0x80</span><span>  </span><span>; Invoke the system call, i.e. ask the the kernel to close this process</span></span>
<span></span>
<span><span>.</span><span>section .data</span></span>
<span><span>message:</span><span> .ascii "Hello"</span></span></code></pre>
<p>Assemble this program with:</p>
<pre is:raw="" tabindex="0"><code><span><span>as -o syscall.o syscall.s</span></span></code></pre>
<p>Link it with:</p>
<pre is:raw="" tabindex="0"><code><span><span>ld -o syscall syscall.o</span></span></code></pre>
<p>Run with:</p>
<pre is:raw="" tabindex="0"><code><span><span>./syscall</span></span></code></pre>
<p>You should see the output “Hello”. If you’re on Bash and you also want to double check the process return code, simply run:</p>
<pre is:raw="" tabindex="0"><code><span><span>echo $?</span></span></code></pre>
<p>And you should see <code>0</code>.</p>
<p><em>Tip: If you want to try out this example from above, but you do not have access to an x86/Linux machine, you can do this through a JavaScript VM that emulates an x86 system in-browser <a href="https://bellard.org/jslinux/">here</a>; that’s a really cool website!</em></p>
<p>And there we have it: a program which prints a message to the standard output when run on an <code>x86</code> machine with a Linux kernel. C standard library <strong>was not used</strong>. The final <code>ELF</code> binary should run on Linux with no dependencies other than it is run on the correct platform.</p>
<p>Now back to the question, what makes this binary incompatible with Windows (potentially)? <strong>Another operating system encodes the system calls differently (e.g. writing isn’t code 4, but code 123, or the parameters are passed through different CPU registers).</strong> And now you have a good idea of how to directly interface with the kernel, without the assistance of the standard library (although you probably almost never want to do it). This means you have uncovered the layer at which software does things like opening files, allocates memory, sends signals, etc. The C standard library can be thought of as a wrapper which hides this complexity of invoking software interrupts through the <code>int</code> instruction to communicate with the kernel, and instead makes it look like a normal call to a C function, and then under the hood, this is what it is. To be fair, the library does a lot more than that, but for the purposes of this article, it can be thought of simply as a wrapper.</p>
<p>And now in the RISC-V world, we have the same thing: the user application interfaces with the kernel through software interrupt CPU instructions, and passing the parameters through the CPU registers. And the kernel basically does <strong>the same thing</strong> with the SBI in order to invoke its services! It’s just that this final layer of logic invocation is called the <strong>SBI</strong>, not the <strong>ABI</strong>. A way to think about it is that it is not the <strong>application</strong> that works in the lower layer, but rather the <strong>supervisor</strong> of the applications. The difference, however, is in the name only, and the concept remains absolutely the same.</p>
<h2 id="practical-example-with-opensbi">Practical example with OpenSBI</h2>
<p>At this point we have established that SBI, much like ABI, is just a way of invoking a functionality in the lower layers of the software stack. Furthermore, we also established the SBI sits at the bottom of the software stack on a RISC-V machine, and runs in the most privileged M mode. Let’s add some more details to this picture.</p>
<p>It should also make sense at this point why the QEMU developers chose the <code>-bios</code> flag in order to accept the SBI software image (because the functionality is basically the same as BIOS). As a reminder, the <code>-bios</code> flag should point to an <code>ELF</code> file that will lay out the SBI software out in memory starting from address <code>0x80000000</code>.</p>
<p>Let’s start the QEMU’s VM with just OpenSBI loaded, and see what happens. We shouldn’t really have to pass anything to QEMU since it defaults to loading OpenSBI at <code>0x80000000</code>.</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt</span></span></code></pre>
<p>This is the output (on the serial port, not VGA):</p>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v0.8</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | '_ \ / _ \ '_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name       : riscv-virtio,qemu</span></span>
<span><span>Platform Features   : timer,mfdeleg</span></span>
<span><span>Platform HART Count : 1</span></span>
<span><span>Boot HART ID        : 0</span></span>
<span><span>Boot HART ISA       : rv64imafdcsu</span></span>
<span><span>BOOT HART Features  : pmp,scounteren,mcounteren,time</span></span>
<span><span>BOOT HART PMP Count : 16</span></span>
<span><span>Firmware Base       : 0x80000000</span></span>
<span><span>Firmware Size       : 96 KB</span></span>
<span><span>Runtime SBI Version : 0.2</span></span>
<span><span></span></span>
<span><span>MIDELEG : 0x0000000000000222</span></span>
<span><span>MEDELEG : 0x000000000000b109</span></span>
<span><span>PMP0    : 0x0000000080000000-0x000000008001ffff (A)</span></span>
<span><span>PMP1    : 0x0000000000000000-0xffffffffffffffff (A,R,W,X)</span></span></code></pre>
<p>The machine keeps spinning in place, presumably because it is set up to do so by default since there is no other piece of software passed to QEMU to take over the control after OpenSBI. At this point, things look good, it seems like OpenSBI has been set up properly (and its output confirms that it sits right at <code>0x80000000</code>).</p>
<p>How do we keep going up the software stack, how do we add a new layer? The new layer could be something like an operating system kernel, so similarly to how we have previously built an <code>ELF</code> file containing instructions to be placed at <code>0x80000000</code>, we will build another <code>ELF</code> file for QEMU to load into its memory, but this time the instructions will come to another address, since the portion starting at <code>0x80000000</code> has already been taken over by OpenSBI.</p>
<p>Which address should we load our fake “kernel” at, then?</p>
<h2 id="booting-the-os-kernel-after-sbi-and-calling-into-opensbi">Booting the OS kernel after SBI and calling into OpenSBI</h2>
<p>When we loaded the BIOS/SBI/whatever you want to call it, the address was basically burnt into the machine’s logic. The first few instructions were Zero Stage Bootloader (ZSBL) and the final instruction from there was jumping to the hardcoded address <code>0x80000000</code>. As we previously mentioned, this is an immutable fact of the platform we’re working with, it’s just simply what it does. However, that’s all it really hardcodes at this point: it just hardcodes that you will have to start from <code>0x80000000</code>, and now we have OpenSBI placed there, so where does OpenSBI take us next?</p>
<p>Now enters the importance of the <strong>ZSBL</strong> again and now it really matters how it initializes those registers before performing that hardcoded jump to <code>0x80000000</code>. What ZSBL really does is two things:</p>
<ol>
<li>Ensures that the software running <strong>after</strong> OpenSBI’s initialization can run, and this is basically the OS kernel bootloader, or it could be the kernel itself directly (which is what you typically see in QEMU guides where you launch Linux, bootloader is skipped and the memory is immediately loaded with the kernel).</li>
<li>Jumps to the OpenSBI.</li>
</ol>
<p>We have covered the second point in great detail so far, so let’s now dig deeper into how does it accomplish point #1.</p>
<h3 id="what-really-happens-in-the-zsbl">What really happens in the ZSBL?</h3>
<p>We have mentioned before that ZSBL execution starts at the address <code>0x1000</code>. Let’s trace the execution through QEMU and see what’s going on. To do that, we’ll add 2 flags to the QEMU CLI command: <code>-s</code> and <code>-S</code>. These flags ensure that QEMU exposes a <code>gdb</code> debug port, and additionally, the VM pauses immediately upon creation, waiting for us to drive it manually (which we will do through <code>gdb</code>).</p>
<p>Let’s begin this reverse engineering process. We’re starting QEMU as so:</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S</span></span></code></pre>
<p>In another terminal, we connect to the <code>gdb</code> server nested in QEMU, so we can drive the VM forward. I am doing this on an <code>x86</code> machine, so I will use <code>gdb-multiarch</code> so I can do a cross-platform debug for <code>riscv</code>. So in this new terminal, I just run:</p>
<pre is:raw="" tabindex="0"><code><span><span>gdb-multiarch</span></span></code></pre>
<p>I want to set up a few things before I connect into the VM to drive it forward:</p>
<pre is:raw="" tabindex="0"><code><span><span>set architecture riscv:rv64</span></span></code></pre>
<p>It should be obvious what the line above does. Next, I want to get the actual running instruction printed to my terminal each time I move one instruction:</p>
<pre is:raw="" tabindex="0"><code><span><span>set disassemble-next-line on</span></span></code></pre>
<p>It’s time to connect to the QEMU <code>gdb</code> server (port <code>1234</code> is I believe hardcoded by QEMU, though it <em>may</em> be configurable by the <code>-s</code> flag somehow; I never tried it and I don’t think you’ll need to change this behavior)</p>
<pre is:raw="" tabindex="0"><code><span><span>target remote :1234</span></span></code></pre>
<p>And right there, <code>gdb</code> is waiting for us at <code>0x1000</code>, exactly where the very first instruction after power on happens. We will use <code>si</code> a few times to step through instructions one by one, until we get to the jump to SBI at <code>0x80000000</code>.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) target remote:1234</span></span>
<span><span>Remote debugging using :1234</span></span>
<span><span>warning: No executable has been specified and target does not support</span></span>
<span><span>determining executable automatically.  Try using the "file" command.</span></span>
<span><span>0x0000000000001000 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001000:	97 02 00 00	auipc	t0,0x0</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001004 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001004:	13 86 82 02	addi	a2,t0,40</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001008 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001008:	73 25 40 f1	csrr	a0,mhartid</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x000000000000100c in ?? ()</span></span>
<span><span>=&gt; 0x000000000000100c:	83 b5 02 02	ld	a1,32(t0)</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001010 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001010:	83 b2 82 01	ld	t0,24(t0)</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001014 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001014:	67 80 02 00	jr	t0</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000080000000 in ?? ()</span></span>
<span><span>=&gt; 0x0000000080000000:	33 04 05 00	add	s0,a0,zero</span></span></code></pre>
<p>There were only 6 instructions in ZSBL before handing the control over to the OpenSBI, including the jump itself. However, what are these few instructions that happened, what is their significance?</p>
<p>It turns out that all this is part of the SBI specification too, it’s a part of the boot sequence. However, with OpenSBI, there are 3 different flavors of this dance, and let’s look at those flavors first before getting into a lot of details on what happens after the ZSBL.</p>
<h3 id="3-flavors-of-opensbi">3 flavors of OpenSBI</h3>
<p>You can build OpenSBI in 3 different ways:</p>
<ol>
<li><code>FW_PAYLOAD</code> (<a href="https://github.com/riscv-software-src/opensbi/blob/master/docs/firmware/fw_payload.md">official docs</a>)</li>
<li><code>FW_JUMP</code> (<a href="https://github.com/riscv-software-src/opensbi/blob/master/docs/firmware/fw_jump.md">official docs</a>)</li>
<li><code>FW_DYNAMIC</code> (<a href="https://github.com/riscv-software-src/opensbi/blob/master/docs/firmware/fw_dynamic.md">official docs</a>)</li>
</ol>
<h4 id="fw_payload"><code>FW_PAYLOAD</code></h4>
<p>This one is probably the easiest to understand conceptually. When building this flavor of OpenSBI, you will literally point the <code>make</code> tool to your kernel/“whatever you want to run after OpenSBI” image and you will get a single binary payload that you can directly load wherever you first CPU instructions start from (in QEMU’s VM case, <code>0x80000000</code>). As I understand, it is possible to tweak the exact location of your software in relation to the OpenSBI blob in the memory, but for simplicity, the mental model we can apply here is that OpenSBI and your software blob are spliced together into a single blob and once the OpenSBI initialization finishes, the very next instruction is your software (you basically slide right into your software after OpenSBI).</p>
<p>The way to achieve this is:</p>
<ol>
<li>Make sure <code>FW_PAYLOAD=y</code> is set in the <code>make</code> process, this will ensure a file called <code>fw_payload</code> is generated.</li>
<li>Point <code>FW_PAYLOAD_PATH</code> in your <code>make</code> process to the software you want to run after OpenSBI.</li>
</ol>
<p>Per the docs linked aboved, if you skip the second flag, a very simple piece of software will be spliced with OpenSBI: a blank infinite loop. That explains why when we just launched QEMU with no flags, basically with OpenSBI only, the machine kept spinning in place — OpenSBI was likely built this way (since you can’t just keep executing random contents of the memory) and it was just busy waiting in place.</p>
<p>The upside of this approach is that now you have a single, spliced, monolithic software image to load into your machine. You don’t have to deal with multiple floating pieces, just one monolith. If your build process for the software is straightforward, you may even end up with a really easy way to manage all the software on the target machine, while getting all the upside of having OpenSBI do some work for you.</p>
<p>The downside is that you are now responsible for building everything together, including OpenSBI. What’s worse, if the machine already had OpenSBI, let’s imagine, burnt into some ROM, it already has OpenSBI to boot up, having it twice on a machine likely won’t cut it.</p>
<h4 id="fw_jump"><code>FW_JUMP</code></h4>
<p>This one is fairly simple too: you basically hardcode the address of your software that comes after OpenSBI. Similarly to above, 2 steps are needed.</p>
<ol>
<li>Make sure <code>FW_JUMP=y</code> is set in the <code>make</code> process, this will ensure a file called <code>fw_jump</code> is generated.</li>
<li>Set <code>FW_JUMP_ADDR</code> in the <code>make</code> process to the address where OpenSBI should jump once its done.</li>
</ol>
<p>This is quite similar to what we had in the previous scenario, only the jump address is hardcoded. It seems like in this case you are still necessarily responsible for building the OpenSBI image, but it’s easy to rebuild it and point to different addresses for different machines (let’s say different machines with varying memory layouts).</p>
<h4 id="fw_dynamic"><code>FW_DYNAMIC</code></h4>
<p>This one is the most generalized flavor and that’s why we leave it for last. This is where the importance of the register set up in ZSLB shines.</p>
<p>In this flavor, the boot stage that happens before OpenSBI is in charge of passing a few pointers to OpenSBI. In this case, we’re of course talking about the ZSBL. If we play close attention, we see that it touches the register <code>a2</code>.</p>
<p>At this point, I would like to encourage the reader to also read the section on ZSBL from <a href="https://embeddedinn.xyz/articles/tutorial/RISCV-Uncovering-the-Mysteries-of-Linux-Boot-on-RISC-V-QEMU-Machines/#the-zero-stage-bootloader-zsbl">this article</a>. The whole article is great, I just initially found it a little tough to go through, so consider this article a warmup for understanding that article, it’s really worth going through.</p>
<p>Anyway, keeping this article watered down still — what is the significance of setting up the register <code>a2</code> in ZSBL? <strong>It points to a struct <code>struct fw_dynamic_info</code></strong> which gives the dynamic OpenSBI flavor a way to continue going through the boot process! In fact, one of the piece of data in this struct is the address of the next piece of software running after OpenSBI! A good question to ask is: on a real machine, who populates this struct? Based on what we’ll see below, it’s obvious that QEMU hardcodes this content into the memory, and that logic is not part a of the ZSBL, but I can definitely imagine a device where ZSBL actually populates this struct and passes it on to OpenSBI.</p>
<p>Slide 17 of <a href="https://riscv.org/wp-content/uploads/2019/06/13.30-RISCV_OpenSBI_Deep_Dive_v5.pdf">this presentation</a> by an engineer from Western Digital (presumably a core contributor to OpenSBI) outlines the contents of this <code>struct</code>:</p>
<ol>
<li>Magic number</li>
<li>Version</li>
<li>Next address</li>
<li>Next mode</li>
<li>Options</li>
</ol>
<p>All of these are unsigned longs (I guess that means 64 bit, 8 bytes?).</p>
<h4 id="exploring-the-fw_dynamic_info-struct">Exploring the <code>fw_dynamic_info</code> struct</h4>
<p>At this point, let’s take a quick detour to make sure we’re on the same page. Let’s quickly make sure we’re all looking at the same version of the OpenSBI because different systems have different version of QEMU which may come with a different version of OpenSBI. Building OpenSBI from source is really straightforward, so let’s quickly do it. First, we need to clone the Git repo (time of writing of this article is 10th Sept 2023; if you want to achieve full reproducibility, build at a commit at this date):</p>
<pre is:raw="" tabindex="0"><code><span><span>git clone https://github.com/riscv-software-src/opensbi.git</span></span>
<span><span>cd opensbi</span></span>
<span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- PLATFORM=generic</span></span></code></pre>
<p>The build should be fairly fast and lightweight. The output file we’re interested in is <code>build/platform/generic/firmware/fw_dynamic.bin</code>. We’ll pass this through the <code>-bios</code> flag to QEMU. Starting QEMU with (from the <code>opensbi</code> folder we just cloned with Git):</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S -bios build/platform/generic/firmware/fw_dynamic.bin</span></span></code></pre>
<p>After a few <code>si</code>s in <code>gdb</code>, we get back to where we were before. Let’s poke QEMU’s memory to see what’s going on there at the end of ZSBL. At the last instruction of ZSBL, we look at the register dump (we use <code>i r</code> for this).</p>
<pre is:raw="" tabindex="0"><code><span><span>=&gt; 0x0000000080000000:	33 04 05 00	add	s0,a0,zero</span></span>
<span><span>(gdb) i r</span></span>
<span><span>ra             0x0	0x0</span></span>
<span><span>sp             0x0	0x0</span></span>
<span><span>gp             0x0	0x0</span></span>
<span><span>tp             0x0	0x0</span></span>
<span><span>t0             0x80000000	2147483648</span></span>
<span><span>t1             0x0	0</span></span>
<span><span>t2             0x0	0</span></span>
<span><span>fp             0x0	0x0</span></span>
<span><span>s1             0x0	0</span></span>
<span><span>a0             0x0	0</span></span>
<span><span>a1             0x87e00000	2279604224</span></span>
<span><span>a2             0x1028	4136</span></span>
<span><span>a3             0x0	0</span></span>
<span><span>a4             0x0	0</span></span>
<span><span>a5             0x0	0</span></span>
<span><span>a6             0x0	0</span></span>
<span><span>a7             0x0	0</span></span>
<span><span>s2             0x0	0</span></span>
<span><span>s3             0x0	0</span></span>
<span><span>s4             0x0	0</span></span>
<span><span>s5             0x0	0</span></span>
<span><span>s6             0x0	0</span></span>
<span><span>s7             0x0	0</span></span>
<span><span>s8             0x0	0</span></span>
<span><span>s9             0x0	0</span></span>
<span><span>s10            0x0	0</span></span>
<span><span>s11            0x0	0</span></span>
<span><span>t3             0x0	0</span></span>
<span><span>t4             0x0	0</span></span>
<span><span>t5             0x0	0</span></span>
<span><span>t6             0x0	0</span></span>
<span><span>pc             0x80000000	0x80000000</span></span></code></pre>
<p><code>a2</code> is therefore pointing to <code>0x1028</code>. As we said, let’s poke that memory with <code>gdb</code>. We’ll ask it to read 10 successive 8-byte values starting from <code>0x1028</code>, and display them in hex format.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) x/10xg 0x1028</span></span></code></pre>
<p>The <code>g</code> flag prints out the memory contents in 8-byte (giant) chunks.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) x/10xg 0x1028</span></span>
<span><span>0x1028:	0x000000004942534f	0x0000000000000002</span></span>
<span><span>0x1038:	0x0000000000000000	0x0000000000000001</span></span>
<span><span>0x1048:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1058:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1068:	0x0000000000000000	0x0000000000000000</span></span></code></pre>
<p>This roughly seems to match <a href="https://embeddedinn.xyz/articles/tutorial/RISCV-Uncovering-the-Mysteries-of-Linux-Boot-on-RISC-V-QEMU-Machines/#the-zero-stage-bootloader-zsbl">Vysakh’s article</a>. We definitely see the magic described in that article, followed by the <code>0x02</code> info version. Next should be the address for the next jump, but there are all zeroes… This is strange, but let’s keep looking. Next value is <code>0x01</code> which again, according to the article, should correspond to the next mode of execution which is <code>S</code>. This is correct, we’re going from <code>M</code> mode running SBI to the <code>S</code> mode running the OS kernel bootloader, or the kernel itself, whatever we want. Why is the address of the next jump all zeroes though? At this point, I’ll just let QEMU run without interference from <code>gdb</code>. I run the following in <code>gdb</code>:</p>
<pre is:raw="" tabindex="0"><code><span><span>continue</span></span></code></pre>
<p>Everything is sort of hanging, but I got a newer OpenSBI output on UART since I am now running a newer version of OpenSBI:</p>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v1.3-54-g901d3d7</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | '_ \ / _ \ '_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name             : riscv-virtio,qemu</span></span>
<span><span>Platform Features         : medeleg</span></span>
<span><span>Platform HART Count       : 1</span></span>
<span><span>Platform IPI Device       : aclint-mswi</span></span>
<span><span>Platform Timer Device     : aclint-mtimer @ 10000000Hz</span></span>
<span><span>Platform Console Device   : uart8250</span></span>
<span><span>Platform HSM Device       : ---</span></span>
<span><span>Platform PMU Device       : ---</span></span>
<span><span>Platform Reboot Device    : syscon-reboot</span></span>
<span><span>Platform Shutdown Device  : syscon-poweroff</span></span>
<span><span>Platform Suspend Device   : ---</span></span>
<span><span>Platform CPPC Device      : ---</span></span>
<span><span>Firmware Base             : 0x80000000</span></span>
<span><span>Firmware Size             : 322 KB</span></span>
<span><span>Firmware RW Offset        : 0x40000</span></span>
<span><span>Firmware RW Size          : 66 KB</span></span>
<span><span>Firmware Heap Offset      : 0x48000</span></span>
<span><span>Firmware Heap Size        : 34 KB (total), 2 KB (reserved), 9 KB (used), 22 KB (free)</span></span>
<span><span>Firmware Scratch Size     : 4096 B (total), 768 B (used), 3328 B (free)</span></span>
<span><span>Runtime SBI Version       : 1.0</span></span>
<span><span></span></span>
<span><span>Domain0 Name              : root</span></span>
<span><span>Domain0 Boot HART         : 0</span></span>
<span><span>Domain0 HARTs             : 0*</span></span>
<span><span>Domain0 Region00          : 0x0000000002000000-0x000000000200ffff M: (I,R,W) S/U: ()</span></span>
<span><span>Domain0 Region01          : 0x0000000080040000-0x000000008005ffff M: (R,W) S/U: ()</span></span>
<span><span>Domain0 Region02          : 0x0000000080000000-0x000000008003ffff M: (R,X) S/U: ()</span></span>
<span><span>Domain0 Region03          : 0x0000000000000000-0xffffffffffffffff M: () S/U: (R,W,X)</span></span>
<span><span>Domain0 Next Address      : 0x0000000000000000</span></span>
<span><span>Domain0 Next Arg1         : 0x0000000087e00000</span></span>
<span><span>Domain0 Next Mode         : S-mode</span></span>
<span><span>Domain0 SysReset          : yes</span></span>
<span><span>Domain0 SysSuspend        : yes</span></span>
<span><span></span></span>
<span><span>Boot HART ID              : 0</span></span>
<span><span>Boot HART Domain          : root</span></span>
<span><span>Boot HART Priv Version    : v1.10</span></span>
<span><span>Boot HART Base ISA        : rv64imafdc</span></span>
<span><span>Boot HART ISA Extensions  : zicntr</span></span>
<span><span>Boot HART PMP Count       : 16</span></span>
<span><span>Boot HART PMP Granularity : 4</span></span>
<span><span>Boot HART PMP Address Bits: 54</span></span>
<span><span>Boot HART MHPM Info       : 0 (0x00000000)</span></span>
<span><span>Boot HART MIDELEG         : 0x0000000000000222</span></span>
<span><span>Boot HART MEDELEG         : 0x000000000000b109</span></span></code></pre>
<p>This matches what we saw above, the next address is all zeroes… This is strange, there’s no way that could be true. I now ran QEMU without the initial pause, just letting it run and connecting with <code>gdb</code> asynchronously. I’ll spare you the details, but inspecting the registers on that “live run” definitely showed to me that nothing is executing in the <code>0x0000000000000000</code> area. The CPU seems to be spinning around some other address.</p>
<p>This likely has something to do with the fact that I actually didn’t pass any software to QEMU to load other than OpenSBI, so that’s probably what’s throwing it off. QEMU likely populated the struct in memory with all zeroes, and OpenSBI identifies it as an illegal edge case, so it just keeps spinning in OpenSBI forever — this is my educated guess.</p>
<p>How do we pass some software to run other than OpenSBI? <strong>The same way we passed OpenSBI, just a diferent flag name!</strong> This time, we’re using the <code>-kernel</code> QEMU flag. And how are we going to build this software? The same way we built the “fake BIOS” in our previous article, we’ll just map it to a different memory location. Let’s give it a shot at <code>0x80200000</code>.</p>
<h4 id="building-an-infinite-loop-fake-kernel">Building an “infinite-loop fake kernel”</h4>
<p>Our OS kernel will just spin in place. It will be a single jump instruction at <code>0x80200000</code> that just stays there infinitely. Here’s the assembly source code:</p>
<pre is:raw="" tabindex="0"><code><span><span>	.global _start</span></span>
<span><span>	.</span><span>section .text</span><span>.kernel</span></span>
<span></span>
<span><span>_start:</span><span>	j _start</span></span></code></pre>
<p>The linker script is the following:</p>
<pre is:raw="" tabindex="0"><code><span><span>MEMORY {</span></span>
<span><span>  kernel_space (rwx) : ORIGIN = 0x80200000, LENGTH = 128</span></span>
<span><span>}</span></span>
<span><span></span></span>
<span><span>SECTIONS {</span></span>
<span><span>  .text : {</span></span>
<span><span>    infinite_loop.o(.text.kernel)</span></span>
<span><span>  } &gt; kernel_space</span></span>
<span><span>}</span></span></code></pre>
<p><em>For details on how to use these files to build an <code>ELF</code> image that can be loaded into QEMU, please see the original bare metal programming article.</em></p>
<p>Once we build it, we end up with the <code>infinte_loop</code> <code>ELF</code> file that can serve as our fake kernel. We now run QEMU</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S -bios build/platform/generic/firmware/fw_dynamic.bin -kernel ~/work/github_demo/risc-v-bare-metal-fake-kernel/infinite_loop</span></span></code></pre>
<p>Again, I connect <code>gdb</code> and <code>si</code> my way to the end of ZSBL. Now when I read the infamous struct at <code>0x1028</code>, things look a lot better, which confirms the theory that QEMU was populating that struct weirdly.</p>
<pre is:raw="" tabindex="0"><code><span><span>=&gt; 0x0000000080000000:	33 04 05 00	add	s0,a0,zero</span></span>
<span><span>(gdb) x/10xg 0x1028</span></span>
<span><span>0x1028:	0x000000004942534f	0x0000000000000002</span></span>
<span><span>0x1038:	0x0000000080200000	0x0000000000000001</span></span>
<span><span>0x1048:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1058:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1068:	0x0000000000000000	0x0000000000000000</span></span></code></pre>
<p>We now see that the new address is populated in this struct, as is expected. This is also reflected in the OpenSBI output on UART. Let’s continue to our fake kernel with <code>gdb</code> and see if everything is OK there.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) break *0x080200000</span></span>
<span><span>Breakpoint 1 at 0x80200000</span></span>
<span><span>(gdb) continue</span></span>
<span><span>Continuing.</span></span>
<span><span></span></span>
<span><span>Breakpoint 1, 0x0000000080200000 in ?? ()</span></span>
<span><span>=&gt; 0x0000000080200000:	6f 00 00 00	j	0x80200000</span></span></code></pre>
<p>Everything looks good here. Let’s recap:</p>
<ol>
<li>ZSBL is the first thing that runs after the power-on. It initializes a few registers. The key register is <code>a2</code>, which points to a <code>fw_dynamic_info</code> struct containing the crucial info for the <code>FW_DYNAMIC</code> flavor of OpenSBI to operate. In QEMU case, this struct is somehow populated during the power-on, magically by the virutalization engine, but in reality, this is <strong>likely</strong> the job of the ZSBL. Either way, OpenSBI now knows what to do after it’s done.</li>
<li>OpenSBI provides an interrupt-based interface for the software up on the stack (presumably OS kernel bootloader and kernel itself) to invoke it. This interface is called SBI and it’s conceptually the same as ABI for the application software on top of an operating system.</li>
<li>We pass the kernel image to QEMU as yet another ELF which just populated another section of the memory. QEMU populates the struct in such way that OpenSBI can pass the control to there, and before it switches there, it enters the <code>S</code> mode of execution.</li>
</ol>
<h4 id="intentionally-skipped-details">Intentionally skipped details</h4>
<p>ZSBL also touched the <code>a0</code> and <code>a1</code> registers.</p>
<p><code>a0</code> has something to do with RISC-V <code>hart</code>s, but let’s not get into those details, they are not relevant for the rest of this article. Besides, this particular step in the boot process doesn’t seem to be particularly relevant, per <a href="https://github.com/riscv-software-src/opensbi/issues/170#issuecomment-642679348">comments from Github</a>.</p>
<p><code>a1</code> is an interesting pointer because it points to the <strong>device tree</strong> data structure in memory. For the rest of this article, this data structure is not relevant, so we can disregard this piece of information. However, the device tree is really useful for real kernels like Linux. Linux is able to scan the device tree from memory and understand the structure of the machine it’s running on, rather than having to run a lot of <code>if/else</code> branches in its programming for every hardware combination. <a href="https://en.wikipedia.org/wiki/Devicetree#Linux">The Wikipedia article</a> should give a decent idea of how this is used in Linux. As mentioned, however, we won’t be concerned with the details of device tree in the rest of this article.</p>
<h2 id="hello-world-fake-kernel">Hello world fake kernel</h2>
<p>Now we have all the knowledge we need to code a fake OS kernel that just prints “Hello world” to the UART device. The functionality is not at all different from the bare metal program we looked at in the previous guide, but the way we’ll get there is significantly different. We’ll be using an SBI call to print to UART, instead of directly interacting with the UART device (we’re using a more privileged lower layer of software to do this work for us). This could have serious consequences, even on a trivial example such as a “hello world” one: <strong>we delegate the responsibility of interacting with the UART hardware to the SBI layer, thus achieving portability across different machines that conform to this SBI interface</strong>.</p>
<p>How do we call into RISC-V SBI layer? Conceptually, it’s exactly the same as invoking a print to standard output in x86 Linux — we’ll populate some registers and invoke a software interrupt/trap to pass the control down the software stack to OpenSBI. OpenSBI offers a lot of services in the SBI layer, and many of them can be extremely useful for developing a portable operating system kernel, such as interaction with the timers (relevant for time slicing and enabling multiple threads to share the same CPU core). For the full list of functionality exposed through the SBI layer, please take a look <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/riscv-sbi.adoc">here</a>.</p>
<p>In this guide, we’ll be focusing on the <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/ext-debug-console.adoc">debug console</a> functionality, i.e. we’ll be writing out to UART through SBI. Let’s code!</p>
<p>First, we need to know how do we encode the functionality we want OpenSBI to execute through registers. This is well documented <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/binary-encoding.adoc">here</a>. tl;dr is that SBI functionality is grouped into “extensions”. Register <code>a7</code> contains the extension ID (EID), while <code>a6</code> encodes the individual function ID (FID) within that extension. The parameters are then passed through <code>a0</code>, <code>a1</code>, <code>a2</code>, …</p>
<p>For printing to the console, the EID we are looking for is <code>0x4442434E</code> (a rather interesting value) and the FID is simply <code>0x00</code>.</p>
<p>This time, instead of printing one by one character as we did in the initial bare metal programming guide, we’ll invoke the printing as a single operation. After all, we should be benefiting from the high level functionality that the SBI layer offers. Therefore, our binary should store the output string somewhere in the memory, and ideally we want to do something like invoking the SBI to print from that address. We’ll do just that:</p>
<pre is:raw="" tabindex="0"><code><span><span>        .global _start</span></span>
<span><span>        .</span><span>section .text</span><span>.kernel</span></span>
<span></span>
<span><span>_start:</span><span> li a7, </span><span>0x4442434E</span></span>
<span><span>        li a6, </span><span>0x00</span></span>
<span><span>1</span><span>:      auipc a3, %pcrel_hi(debug_string)</span></span>
<span><span>        addi a3, a3, %pcrel_lo(</span><span>1b</span><span>)</span></span>
<span><span>        li a4, </span><span>0x00000000FFFFFFFF</span></span>
<span><span>        li a5, </span><span>0xFFFFFFFF00000000</span></span>
<span><span>        li a0, </span><span>12</span></span>
<span><span>        </span><span>and</span><span> a1, a3, a4</span></span>
<span><span>        </span><span>and</span><span> a2, a3, a5</span></span>
<span><span>        ecall</span></span>
<span></span>
<span><span>        li a7, </span><span>0x01</span></span>
<span><span>        mv a6, a0</span></span>
<span><span>        ecall</span></span>
<span></span>
<span><span>loop</span><span>:   j </span><span>loop</span></span>
<span></span>
<span><span>        .</span><span>section .rodata</span></span>
<span><span>debug_string:</span></span>
<span><span>        .string "Hello world\n"</span></span></code></pre>
<p>A couple of things to note here:</p>
<ol>
<li>We use PC-relative addressing here for the output string. As a reminder, the kernel is stored at an address represented by a very large unsigned integer. This value is too high to be encoded within any RISC-V 32-bit instruction word. That’s not a problem, we simply use a short sequence of <code>AUIPC</code> and <code>ADDI</code> instructions to get there (check out <a href="https://michaeljclark.github.io/asm.html">this article</a> for more information on this). If you do not understand what this point is all about, please make sure to revise different memory addressing modes and the differences between them: this is crucial for any sort of bare metal programming.</li>
<li>There is some bit-masking happening as well for registers <code>a1</code> and <code>a2</code>. SBI for some reason asks for the pointer to the string to be printed to be broken down into two 32-bit pieces.</li>
</ol>
<p>So our SBI call is defined by several registers:</p>
<ol>
<li><code>a7</code> identifies the SBI extension</li>
<li><code>a6</code> identifies the function within the extension (in this case, debug console extension)</li>
<li><code>a0</code> contains the length of the string that needs to go to the debug console output</li>
<li><code>a1</code> and <code>a2</code>, when joined together, contain the 64-bit pointer to the address of the stirng that needs to be printed</li>
</ol>
<p>The SBI call is now invoked through an <code>ecall</code> instruction, which activates a CPU trap. At this point, OpenSBI takes over and writes to UART, in exactly the same way as we did in the initial bare metal programming guide. If you are wondering how a simple <code>ecall</code> invocation takes us to OpenSBI, that is because OpenSBI set up the trap handling mechanism in such way that when our kernel gets into a trap, the program counter will jump into the OpenSBI software section. The details of this are way outside the scope of this article, but we may cover this in some other article.</p>
<p>For now, just check out the QEMU serial port and confirm that “Hello world” is printed properly:</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S -bios build/platform/generic/firmware/fw_dynamic.bin -kernel ~/work/github_demo/risc-v-bare-metal-fake-kernel/hello_world_kernel</span></span></code></pre>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v1.3-54-g901d3d7</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | '_ \ / _ \ '_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name             : riscv-virtio,qemu</span></span>
<span><span>Platform Features         : medeleg</span></span>
<span><span>Platform HART Count       : 1</span></span>
<span><span>Platform IPI Device       : aclint-mswi</span></span>
<span><span>Platform Timer Device     : aclint-mtimer @ 10000000Hz</span></span>
<span><span>Platform Console Device   : uart8250</span></span>
<span><span>Platform HSM Device       : ---</span></span>
<span><span>Platform PMU Device       : ---</span></span>
<span><span>Platform Reboot Device    : syscon-reboot</span></span>
<span><span>Platform Shutdown Device  : syscon-poweroff</span></span>
<span><span>Platform Suspend Device   : ---</span></span>
<span><span>Platform CPPC Device      : ---</span></span>
<span><span>Firmware Base             : 0x80000000</span></span>
<span><span>Firmware Size             : 322 KB</span></span>
<span><span>Firmware RW Offset        : 0x40000</span></span>
<span><span>Firmware RW Size          : 66 KB</span></span>
<span><span>Firmware Heap Offset      : 0x48000</span></span>
<span><span>Firmware Heap Size        : 34 KB (total), 2 KB (reserved), 9 KB (used), 22 KB (free)</span></span>
<span><span>Firmware Scratch Size     : 4096 B (total), 768 B (used), 3328 B (free)</span></span>
<span><span>Runtime SBI Version       : 1.0</span></span>
<span><span></span></span>
<span><span>Domain0 Name              : root</span></span>
<span><span>Domain0 Boot HART         : 0</span></span>
<span><span>Domain0 HARTs             : 0*</span></span>
<span><span>Domain0 Region00          : 0x0000000002000000-0x000000000200ffff M: (I,R,W) S/U: ()</span></span>
<span><span>Domain0 Region01          : 0x0000000080040000-0x000000008005ffff M: (R,W) S/U: ()</span></span>
<span><span>Domain0 Region02          : 0x0000000080000000-0x000000008003ffff M: (R,X) S/U: ()</span></span>
<span><span>Domain0 Region03          : 0x0000000000000000-0xffffffffffffffff M: () S/U: (R,W,X)</span></span>
<span><span>Domain0 Next Address      : 0x0000000080200000</span></span>
<span><span>Domain0 Next Arg1         : 0x0000000087e00000</span></span>
<span><span>Domain0 Next Mode         : S-mode</span></span>
<span><span>Domain0 SysReset          : yes</span></span>
<span><span>Domain0 SysSuspend        : yes</span></span>
<span><span></span></span>
<span><span>Boot HART ID              : 0</span></span>
<span><span>Boot HART Domain          : root</span></span>
<span><span>Boot HART Priv Version    : v1.10</span></span>
<span><span>Boot HART Base ISA        : rv64imafdc</span></span>
<span><span>Boot HART ISA Extensions  : zicntr</span></span>
<span><span>Boot HART PMP Count       : 16</span></span>
<span><span>Boot HART PMP Granularity : 4</span></span>
<span><span>Boot HART PMP Address Bits: 54</span></span>
<span><span>Boot HART MHPM Info       : 0 (0x00000000)</span></span>
<span><span>Boot HART MIDELEG         : 0x0000000000000222</span></span>
<span><span>Boot HART MEDELEG         : 0x000000000000b109</span></span>
<span><span>Hello world</span></span></code></pre>
<p>As an exercise, I suggest probing the <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/ext-base.adoc">base extension (<code>0x10</code>)</a> with <code>gdb</code> to investigate what the QEMU machine + OpenSBI you build are capable of offering.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We ended up with an entirely portable fake kernel that prints “Hello world” to UART! This may seem like nothing special, but the concept here is very powerful. Without rebuilding, you can drop the same kernel image on a different RISC-V 64-bit machine with OpenSBI that supports the debug console extension.</p>
<p>In fact, I played a little trick here. :) One of the main reasons I suggested building OpenSBI from source is that some QEMU versions provided by the Linux distro package managers do not support the debug console extension (they’re simply old). This was the case with my default OpenSBI which came with Debian’s version of QEMU.</p>
<p>Finally, I would like to remind the reader that we have extensively focused on the QEMU <code>virt</code> machine with a RISC-V core and all the fine details of this article are related to it. That said, my hope is that the reader has learned enough about the boot sequence concepts and bare metal programming that adapting this knowledge to a particular real-world scenario becomes easy.</p>
<p>In the next posts, we’ll talk about taking this further and booting up a full blown Linux kernel. We’ll expand that step by step until we reach a Linux deployment that can handle I/O with keyboard, mouse, screen and Ethernet network.</p>
<p>I hope you enjoyed this lengthy writeup!</p>
<h2 id="code-pointers">Code pointers</h2>
<p>If you prefer not to copy/paste, the code is available on <a href="https://github.com/popovicu/risc-v-bare-metal-fake-kernel">this GitHub repo</a>.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Static Hermes: Compile JavaScript to speed it up 300x (in microbenchmarks) (107 pts)]]></title>
            <link>https://tmikov.blogspot.com/2023/09/how-to-speed-up-micro-benchmark-300x.html</link>
            <guid>37459829</guid>
            <pubDate>Sun, 10 Sep 2023 20:38:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tmikov.blogspot.com/2023/09/how-to-speed-up-micro-benchmark-300x.html">https://tmikov.blogspot.com/2023/09/how-to-speed-up-micro-benchmark-300x.html</a>, See on <a href="https://news.ycombinator.com/item?id=37459829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="static-hermes-how-to-speed-up-a-micro-benchmark-by-300x-without-cheating">Static Hermes: How to Speed Up a Micro-benchmark by 300x Without Cheating</h2>
<p>This is the first of a series of light blog posts about Static Hermes,
covering topics that I find interesting or amusing. It is not intended to be
a systematic introduction to Static Hermes design.Consider it more like a backstage
pass to the quirks, features, and “aha!” moments that make Static Hermes unique.</p>
<p>If you’re not familiar with Static Hermes, it’s an evolving project we’re working
on to explore the confluence of static typing and JavaScript. It is work in progress,
but we’re excited about the possibilities it opens up for performance improvements
and more.</p>
<p>For more background:</p>
<ul>
<li><a href="https://twitter.com/tmikov/status/1700353858763911570?s=20">Tweet with the slide deck of the Static Hermes announcement</a></li>
<li><a href="https://twitter.com/tmikov/status/1181618035355865089?s=20">Previous talk about Hermes</a></li>
</ul>
<p>Contents:</p>
<ul>
<li><a href="#meet-interp-dispatchjs">Meet interp-dispatch.js</a></li>
<li><a href="#lets-run-it">Let’s Run It!</a></li>
<li><a href="#static-hermes-with-untyped-code">Static Hermes with Untyped Code</a></li>
<li><a href="#helping-the-compiler">Helping the Compiler</a></li>
<li><a href="#other-ways-to-help-the-compiler">Other Ways to Help the Compiler</a></li>
<li><a href="#some-observations">Some Observations</a></li>
<li><a href="#revisiting-the-original-untyped-code">Revisiting The Original Untyped Code</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="meet-interp-dispatch.js">Meet interp-dispatch.js</h2>
<p><code>interp-dispatch.js</code> is a Hermes micro-benchmark written to evaluate the interpreter
dispatch overhead and to catch regressions in it. When we say <em>dispatch overhead</em>,
we mean the extra work the interpreter needs to do <em>in addition to</em> executing the
actual instructions. Specifically, switching to the instruction implementation based
on the instruction opcode. So, this test deliberately uses cheap instructions, but
lots of them.</p>
<p>Of course, to some degree it also evaluates the performance of the implementations of
the instructions themselves, since it is impossible to separate the dispatch overhead
from instruction execution.</p>
<p>It is an fun benchmark because its minimalistic and loop-heavy design makes it
highly sensitive to minor changes, offering insights into the impact of such
changes on running time.</p>
<p><code>interp-dispatch.js</code> does not claim to have a higher meaning than that, to represent
useful classes of calculations, etc. You can make up your own mind about it.</p>
<p>Without further ado, this is it:</p>
<pre><code><span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    <span>var</span> n<span>,</span> fact<span>;</span>
    <span>var</span> res <span>=</span> <span>0</span><span>;</span>
    <span>while</span> <span>(</span><span>--</span>lc <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
        n <span>=</span> fc<span>;</span>
        fact <span>=</span> n<span>;</span>
        <span>while</span> <span>(</span><span>--</span>n <span>&gt;</span> <span>1</span><span>)</span>
            fact <span>*=</span> n<span>;</span>
        res <span>+=</span> fact<span>;</span>
    <span>}</span>
    <span>return</span> res<span>;</span>
<span>}</span>

<span>let</span> t1 <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span>
<span>var</span> res <span>=</span> <span>bench</span><span>(</span><span>4e6</span><span>,</span> <span>100</span><span>)</span><span>;</span>
<span>print</span><span>(</span>Date<span>.</span><span>now</span><span>(</span><span>)</span> <span>-</span> t1<span>,</span> <span>"ms,"</span><span>,</span> res<span>)</span><span>;</span>
</code></pre>
<p>It calculates the same factorial in a loop a specified number of times and adds the results.</p>
<p>Let’s look at the compiled bytecode:</p>
<pre><code>Function&lt;bench&gt;(3 params, 10 registers, 0 symbols):
    LoadParam         r5, 2
    LoadConstZero     r4
    LoadConstUInt8    r3, 1
    LoadParam         r0, 1
    Dec               r2, r0
    LoadConstZero     r1
    LoadConstZero     r0
    JNotGreaterEqual  L1, r2, r0
L4:
    Dec               r8, r5
    Mov               r7, r5
    Mov               r6, r7
    JNotGreater       L2, r8, r3
L3:
    Mul               r7, r7, r8
    Dec               r8, r8
    Mov               r6, r7
    JGreater          L3, r8, r3
L2:
    Add               r1, r1, r6
    Dec               r2, r2
    Mov               r0, r1
    JGreaterEqual     L4, r2, r4
L1:
    Ret               r0
</code></pre>
<p>It is pretty tight. The inner loop is the instructions from <code>L3:</code> to <code>JGreater</code>. Not bad,
though we can eliminate the extra <code>Mov</code>, shrinking the loop from four to three instructions.</p>
<p>The outer loop is from <code>L4:</code> to <code>JGreaterEqual</code>.</p>
<h2 id="lets-run-it">Let’s Run It!</h2>
<p>Running it with the Hermes interpreter, we get the following:</p>
<pre><code>$ hermes-rel -w bench.js
2086 ms, 3.7330486176528693e+164
</code></pre>
<p>2086 ms, that is a very respectable result for an interpreter. This isn’t too surprising,
given the considerable effort put into optimizing the Hermes interpreter, with plans for
even more significant improvements.</p>
<p>Now, let’s examine the impact of native compilation:</p>
<pre><code>$ shermes-rel -w bench.js -o bench

$ ./bench
2388 ms 3.7330486176528693e+164
</code></pre>
<p>Well, that’s a bit underwhelming. 2388 ms - a bit slower than the
interpreter. How is that possible?</p>
<p>The answer lies in the nature of untyped code. Intuitively, Static Hermes can’t do
much for completely untyped code. It has to assume that <code>lc</code> and <code>fc</code> can be any
type, including string or <code>BigInt</code>. Let’s dig a little deeper.</p>
<h2 id="static-hermes-with-untyped-code">Static Hermes with Untyped Code</h2>
<p>First, let’s check out the assembly code generated by Static Hermes:</p>
<pre><code>$ shermes-rel -S bench.js 
$ cat bench.s
</code></pre>
<p>Remember the inner JS loop?</p>
<pre><code>    <span>while</span> <span>(</span><span>--</span>n <span>&gt;</span> <span>1</span><span>)</span>
        fact <span>*=</span> n<span>;</span>
</code></pre>
<p>This is it compiled to armv8 assembly:</p>
<pre><code>LBB2_4:
        mov     x0, x19
        mov     x1, x23
        mov     x2, x25
        bl      __sh_ljs_mul_rjs
        str     x0, [sp, #72]
        mov     x0, x19
        mov     x1, x25
        bl      __sh_ljs_dec_rjs
        ldr     x8, [sp, #72]
        str     x0, [sp, #80]
        str     x8, [sp, #64]
        add     x2, sp, #8
        mov     x0, x19
        mov     x1, x25
        bl      __sh_ljs_greater_rjs
        tbnz    w0, #0, LBB2_4
</code></pre>
<p>You can clearly see why it’s not fast: multiplication, decrement, and comparison are all
function calls. This confirms our intuition.</p>
<p>To dig deeper, let’s see what Static Hermes thinks the types are, using the <code>--dump-lra</code> option:</p>
<pre><code>shermes -dump-lra bench.js
</code></pre>
<p>Here’s the relevant part of the inner loop’s internal representation:</p>
<pre><code>%BB4:
  $loc5 = BinaryMultiplyInst (:number|bigint) $loc5, $loc6
  $loc6 = UnaryDecInst (:number|bigint) $loc6
  $loc4 = MovInst (:number|bigint) $loc5
  $loc5 = CmpBrGreaterThanInst $loc6, $np0, %BB4, %BB3
</code></pre>
<p>The types following each instruction show that Static Hermes infers <code>n</code> and <code>fact</code>
to be either number or bigint. This is  neat, but unfortunately still requires a
function call for each operation.</p>
<p>But how does it know that they can be only <code>number</code> or <code>bigint</code>? What if the inputs were
strings or <code>undefined</code> or even something crazy like regular expressions? Let’s look at
the beginning of the function:</p>
<pre><code>function bench(lc: any, fc: any): string|number
frame = []
%BB0:
  ...
  $loc3      = LoadParamInst (:any) %fc: any
  $loc0      = LoadParamInst (:any) %lc: any
  $loc2      = UnaryDecInst (:number|bigint) $loc0
</code></pre>
<p>It is loading <code>fc</code> into <code>$loc3</code> and <code>lc</code> into <code>$loc0</code>. At this point we can see Static
Hermes still thinks that they can be anything, <code>any</code>. But then it decrements <code>$loc0</code>,
and we can see that the result if <code>UnaryDecInst</code> changes to <code>number|bigint</code>. Static Hermes
knows that the result of the JavaScript <code>--</code> operator is always <code>number</code> or <code>bigint</code>,
regardless of its inputs and can take advantage of that.</p>
<p>In other words, Static Hermes uses the rules of JavaScript to reason about and infer
the possible types of every value. This is very powerful, but unfortunately it is not
always enough to generate efficient code. Often, we need to pin down a specific type,
not just that it is one of several possible.</p>
<p>So, with this understanding, could a minimal change to the code make it faster?</p>
<h2 id="helping-the-compiler">Helping the Compiler</h2>
<p>Static Hermes infers types based on JavaScript language rules. For example, it knows
that the result of the <code>--</code> operator is always <code>number|bigint</code>. Can we help it narrow
down the type even further?</p>
<p>Absolutely. In JavaScript, the unary <code>+</code> operator is designed to always return a number.
So, when we write:</p>
<pre><code>    x <span>=</span> <span>+</span>x<span>;</span>
</code></pre>
<p>Both we and the compiler can be confident that <code>x</code> is now a number.</p>
<p>The most crucial variable in this benchmark is <code>fc</code>, which controls the inner loop.
Let’s apply this optimization technique to it:</p>
<pre><code><span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    fc <span>=</span> <span>+</span>fc<span>;</span>
    <span>var</span> n<span>,</span> fact<span>;</span>
    <span>var</span> res <span>=</span> <span>0</span><span>;</span>
    <span>// ... rest of the code is unchanged.</span>
<span>}</span>
</code></pre>
<p>Now, let’s run it through Static Hermes again:</p>
<pre><code>$ shermes-rel -w bench.js -o bench

$ ./bench
278 ms 3.7330486176528693e+164
</code></pre>
<p>Impressive! The execution time is down to 278 ms, making it 7.5 times faster than the
interpreter and 8.6 times faster than our previous run—all from a single-line change.</p>
<p>To confirm out understanding, let’s check the IR again:</p>
<pre><code>shermes -dump-lra bench.js

...
...
%BB4:
  $np8       = BinaryMultiplyInst (:number) $np8, $np7
  $np7       = UnaryDecInst (:number) $np7
  $np6       = MovInst (:number) $np8
  $loc1      = CmpBrGreaterThanInst $np7, $np4, %BB4, %BB3
</code></pre>
<p>As expected, all operations are now strictly of type <code>number</code>. The assembly reflects
this optimization:</p>
<pre><code>LBB2_4:
	fmul	d0, d0, d1
	fadd	d1, d1, d12
	fcmp	d1, d10
	b.gt	LBB2_4
</code></pre>
<p>It’s a tight loop, devoid of function calls, just as we’d hoped.</p>
<h2 id="other-ways-to-help-the-compiler">Other Ways to Help the Compiler</h2>
<p>While wrapping up this post, I began pondering other ways to assist the compiler that
are worth mentioning.</p>
<p>An observant reader might wonder: if we’re only calling bench with numbers, why doesn’t
Static Hermes recognize <code>lc</code> and <code>fc</code> as such? The reason is that <code>bench()</code> is a global
function. It is assigned to a global variable, or more accurately to a property of the
global object <code>globalThis.bench</code>. Static Hermes can’t make assumptions about how it might
be called from elsewhere in the code.</p>
<p>In reality, most code resides in modules, be it CommonJS or ESM. While we won’t get into
the whole module system here, we can simulate this behavior by enclosing our code in a
self-invoking function. This allows Static Hermes to make more precise inferences about
function call sites.</p>
<pre><code><span>(</span><span>function</span> <span>module</span><span>(</span>exports<span>)</span> <span>{</span>

<span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    <span>var</span> n<span>,</span> fact<span>;</span>
    <span>var</span> res <span>=</span> <span>0</span><span>;</span>
    <span>while</span> <span>(</span><span>--</span>lc <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
        n <span>=</span> fc<span>;</span>
        fact <span>=</span> n<span>;</span>
        <span>while</span> <span>(</span><span>--</span>n <span>&gt;</span> <span>1</span><span>)</span>
            fact <span>*=</span> n<span>;</span>
        res <span>+=</span> fact<span>;</span>
    <span>}</span>
    <span>return</span> res<span>;</span>
<span>}</span>

<span>let</span> t1 <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span>
<span>var</span> res <span>=</span> <span>bench</span><span>(</span><span>4e6</span><span>,</span> <span>100</span><span>)</span><span>;</span>
<span>print</span><span>(</span>Date<span>.</span><span>now</span><span>(</span><span>)</span> <span>-</span> t1<span>,</span> <span>"ms"</span><span>,</span> res<span>)</span><span>;</span>

<span>}</span><span>)</span><span>(</span><span>{</span><span>}</span><span>)</span><span>;</span>
</code></pre>
<p>Let’s run it:</p>
<pre><code>$ shermes-rel -w bench-mod.js -o bench-mod

$ ./bench-mod
6 ms 3.7330486176528693e+164
</code></pre>
<p>Wait, what? A jaw-dropping 6 ms! That’s 348 times faster than the interpreter and 46 times
faster than our earlier optimization. What led to this dramatic improvement?</p>
<p>It turns out that Static Hermes is now able to inline <code>bench()</code> directly into the main
function, replacing the parameters with their actual values. Not only does it know their
types, it knows their values!</p>
<p>For clarity, I’ve trimmed down the code to focus on the compiler’s output:</p>
<pre><code><span>(</span><span>function</span> <span>module</span><span>(</span>exports<span>)</span> <span>{</span>
<span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
  <span>// ...    </span>
<span>}</span>
<span>return</span> <span>bench</span><span>(</span><span>4e6</span><span>,</span> <span>100</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>(</span><span>{</span><span>}</span><span>)</span><span>;</span>
</code></pre>
<p>Here is the generated IR:</p>
<pre><code>function module(exports: any): number [allCallsitesKnownInStrictMode]
frame = []
%BB0:
  $np5       = HBCLoadConstInst (:number) 0: number
  $np2       = HBCLoadConstInst (:number) 1: number
  $np6       = HBCLoadConstInst (:number) 3999999: number
  $np1       = HBCLoadConstInst (:number) 0: number
%BB1:
  $np8       = HBCLoadConstInst (:number) 99: number
  $np7       = HBCLoadConstInst (:number) 100: number
%BB4:
  $np0       = BinaryMultiplyInst (:number) $np7, $np8
  $np8       = UnaryDecInst (:number) $np8
  $np7       = MovInst (:number) $np0
  $loc0      = CmpBrGreaterThanInst $np8, $np2, %BB4, %BB3
%BB3:
  $np0       = BinaryAddInst (:number) $np1, $np0
  $np6       = UnaryDecInst (:number) $np6
  $np1       = MovInst (:number) $np0
  $np6       = MovInst (:number) $np6
  $loc0      = CmpBrGreaterThanOrEqualInst $np6, $np5, %BB1, %BB2
%BB2:
  $loc0      = ReturnInst $np0
function_end
</code></pre>
<p>As you can see, the parameters are now constants. The assembly code is even more
remarkable:</p>
<pre><code>LBB2_1:
	fmov	d1, x9
	fadd	d0, d0, d1
	fadd	d0, d0, d1
	fadd	d0, d0, d1
	fadd	d0, d0, d1
	subs	w8, w8, #4
	b.ne	LBB2_1
</code></pre>
<p>The compiler (LLVM) has determined that the inner loop is a constant and has
pre-calculated its value <code>x9</code>. The outer loop has been <em>unrolled</em> four times
(its body has been copied four times, to decrease the number of iterations).</p>
<p>This is a fascinating result, demonstrating a series of compiler optimizations compounding
each other to produce something unexpected and incredibly fast.</p>
<h2 id="some-observations">Some Observations</h2>
<p>A discerning reader might observe that the original code isn’t exactly a model of efficiency —
it calculates the same factorial 4 million times. Why? Because it’s a micro-benchmark designed
to evaluate interpreter dispatch overhead, not to be a paragon of smart coding. The value of
the factorial is irrelevant here.</p>
<p>One could rewrite the code to calculate the factorial just once and then multiply it by 4
million. However, this would defeat the purpose of the benchmark:</p>
<pre><code><span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    fact <span>=</span> fc<span>;</span>
    <span>while</span> <span>(</span><span>--</span>fc <span>&gt;</span> <span>1</span><span>)</span>
        fact <span>*=</span> fc<span>;</span>
    <span>return</span> fact <span>*</span> lc<span>;</span>
<span>}</span>
</code></pre>
<p>Could a compiler theoretically optimize this for us? Sure, but compiler optimizations
involve trade-offs and are often designed with a specific set of use-cases in mind.
In our case, we’re focused on React Native performance, and an optimization like this
wouldn’t be particularly beneficial.</p>
<p>Similarly, LLVM could technically optimize away the entire outer loop in the previous
section, since the result of bench() is a compile-time constant when the parameters
are constants. However, such an optimization isn’t generally useful, especially not in
the context we care about.</p>
<h2 id="revisiting-the-original-untyped-code">Revisiting The Original Untyped Code</h2>
<p>Let’s circle back to the original, unmodified code. We already know that in the inner
loop — the most computationally intensive part of the function — the variables could
only be of type <code>number</code> or <code>bigint</code>. So, could we compile two separate versions of the
loop and dynamically switch between them based on the variable type?</p>
<p>Technically, yes. However, applying this approach more broadly presents challenges.
Imagine a loop with multiple variables, each having different potential types. This
scenario could lead to a combinatorial explosion of type combinations, necessitating a
separate compiled version for each. Even if we were to emit just two versions for most
scenarios, that would still double the size of the output code.</p>
<p>For those interested in this approach, <a href="http://www-sop.inria.fr/members/Manuel.Serrano/publi/serrano-dls18.pdf">Manuel Serrano’s HopC compiler</a> employs a similar
strategy. It generates two versions of every function: one optimized based on heuristics
for the most likely type combinations, and a generic “fallback” version for all other types.</p>
<p>This is an avenue we might explore down the line. However, it’s worth noting that its
utility may be somewhat limited in our specific use-case. This approach mainly benefits
basic types like <code>number</code> and <code>bigint</code>, but doesn’t offer much for more complex types such as
objects.</p>
<h2 id="what-about-type-annotations">What About Type Annotations?</h2>
<p>You might be asking, “Given that Static Hermes is designed to leverage type annotations, why didn’t we use them in this benchmark?” Good question. We chose not to use them for a couple of reasons. First, skipping annotations allowed us to explore the type inference capabilities of this nascent compiler technology. Second, in this particular benchmark, type annotations wouldn’t make a difference. Why? Because we employed other techniques—like the unary <code>+</code> operator—that conveyed the same type information to the compiler. This approach gives us insight into what Static Hermes can deduce and optimize without explicit annotations.</p>
<h2 id="conclusion">Conclusion</h2>
<p>So there you have it. We kicked the tires on Static Hermes a bit, played around with a
micro-benchmark, and even managed to soup it up — way up. Turns out, understanding a little bit
about how Static Hermes (or any compiler, really) thinks can go a long way in making your code
faster. But it’s not like you need to pull out all the stops for every piece of code you write.</p>
<p>If you’re into this stuff,  keep an eye out for more posts like this; we’re just scratching
the surface.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$400M in assets to bankrupt in 45-minutes because of a failed deployment (2014) (425 pts)]]></title>
            <link>https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/</link>
            <guid>37459495</guid>
            <pubDate>Sun, 10 Sep 2023 20:07:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/">https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/</a>, See on <a href="https://news.ycombinator.com/item?id=37459495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>I was speaking at a conference last year on the topics of DevOps, Configuration as Code, and Continuous Delivery and used the following story to demonstrate the importance making deployments fully automated and repeatable as part of a DevOps/Continuous Delivery initiative. Since that conference I have been asked by several people to share the story through my blog. This story is true – this really happened. This is my telling of the story based on what I have read (I was not involved in this).</p>
<p>This is the story of how a company with nearly $400 million in assets went bankrupt in 45-minutes because of a failed deployment.</p>
<h2>Background</h2>
<p>Knight Capital Group is an American global financial services firm engaging in <a href="http://en.wikipedia.org/wiki/Market_making">market making</a>, electronic execution, and institutional sales and trading. In 2012 Knight was the largest trader in US equities with market share of around 17% on each the NYSE and NASDAQ. Knight’s Electronic Trading Group (ETG) managed an average daily trading volume of more than 3.3 billion trades daily, trading over 21 billion dollars…daily. That’s no joke!</p>
<p>On July 31, 2012 Knight had approximately $365 million in cash and equivalents.</p>
<p>The NYSE was planning to launch a new <a href="http://www.nyse.com/press/1341483497580.html" target="_blank">Retail Liquidity Program</a> (a program meant to provide improved pricing to retail investors through retail brokers, like Knight) on August 1, 2012. In preparation for this event Knight updated their automated, high-speed, algorithmic router that send orders into the market for execution known as SMARS. One of the core functions of SMARS is to receive orders from other components of Knights trading platform (“parent” orders) and then send one or more “child” orders out for execution. In other words, SMARS would receive large orders from the trading platform and break them up into multiple smaller orders in order to find a buyer/seller match for the volume of shares. The larger the parent order, the more child orders would be generated.</p>
<p>The update to SMARS was intended to replace old, unused code referred to as “Power Peg” – functionality that Knight hadn’t used in 8-years (why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the point). The code that that was updated repurposed an old flag that was used to activate the Power Peg functionality. The code was thoroughly tested and proven to work correctly and reliably. What could possibly go wrong?</p>
<h2>What Could Possibly Go Wrong? Indeed!</h2>
<p>Between July 27, 2012 and July 31, 2012 Knight manually deployed the new software to a limited number of servers per day – eight (8) servers in all. This is what the <a href="http://www.sec.gov/litigation/admin/2013/34-70694.pdf" target="_blank">SEC filing</a> says about the manual deployment process (BTW – if there is an SEC filing about your deployment something may have gone terribly wrong).</p>
<blockquote><p>“During the deployment of the new code, however, one of Knight’s technicians did not copy the new code to one of the eight SMARS computer servers. Knight did not have a second technician review this deployment and no one at Knight realized that the Power Peg code had not been removed from the eighth server, nor the new RLP code added. Knight had no written procedures that required such a review.<br>
SEC Filing | Release No. 70694 | October 16, 2013</p></blockquote>
<p>At 9:30 AM Eastern Time on August 1, 2012 the markets opened and Knight began processing orders from broker-dealers on behalf of their customers for the new Retail Liquidity Program. The seven (7) servers that had the correct SMARS deployment began processing these orders correctly. Orders sent to the eighth server triggered the supposable repurposed flag and brought back from the dead the old Power Peg code.</p>
<h2>Attack of the Killer Code Zombies</h2>
<p>Its important to understand what the “dead” Power Peg code was meant to do. This functionality was meant to count the shares bought/sold against a parent order as child orders were executed. Power Peg would instruct the the system to stop routing child orders once the parent order was fulfilled. Basically, Power Peg would keep track of the child orders and stop them once the parent order was completed. In 2005 Knight moved this cumulative tracking functionality to an earlier stage in the code execution (thus removing the count tracking from the Power Peg functionality).</p>
<p>When the Power Peg flag on the eighth server was activated the Power Peg functionality began routing child orders for execution, but wasn’t tracking the amount of shares against the parent order – somewhat like an endless loop.</p>
<h2>45 Minutes of Hell</h2>
<p>Imagine what would happen if you had a system capable of sending automated, high-speed orders into the market without any tracking to see if enough orders had been executed. Yes, it was that bad.</p>
<p>When the market opened at 9:30 AM people quickly knew something was wrong. By 9:31 AM it was evident to many people on Wall Street that something serious was happening. The market was being flooded with orders out of the ordinary for regular trading volumes on certain stocks. By 9:32 AM many people on Wall Street were wondering why it hadn’t stopped. This was an eternity in high-speed trading terms. Why hadn’t someone hit the kill-switch on whatever system was doing this? As it turns out there was no kill switch. During the first 45-minutes of trading Knight’s executions constituted more than 50% of the trading volume, driving certain stocks up over 10% of their value. As a result other stocks decreased in value in response to the erroneous trades.</p>
<p>To make things worse, Knight’s system began sending automated email messages earlier in the day – as early as 8:01 AM (when SMARS had processed orders eligible for pre-market trading). The email messages references SMARS and identified an error as “Power Peg disabled.” Between 8:01 AM and 9:30 AM there were 97 of these emails sent to Knight personnel. Of course these emails were not designed as system alerts and therefore no one looked at them right away. Oops.</p>
<p>During the 45-minutes of Hell that Knight experienced they attempted several counter measures to try and stop the erroneous trades. There was no kill-switch (and no documented procedures for how to react) so they were left trying to diagnose the issue in a live trading environment where 8 million shares were being traded every minute . Since they were unable to determine what was causing the erroneous orders they reacted by uninstalling the new code from the servers it was deployed to correctly. In other words, they removed the working code and left the broken code. This only amplified the issues causing additional parent orders to activate the Power Peg code on all servers, not just the one that wasn’t deployed to correctly. Eventually they were able to stop the system – after 45 minutes of trading.</p>
<p>In the first 45-minutes the market was open the Power Peg code received and processed 212 parent orders. As a result SMARS sent millions of child orders into the market resulting in 4 million transactions against 154 stocks for more than 397 million shares. For you stock market junkies this meant the Knight assumed approximately $3.5 billion net long positions in 80 stocks and $3.15 billion net short positions in 74 stocks. In laymen’s terms, Knight Capital Group realized a $460 million loss in 45-minutes. Remember, Knight only has $365 million in cash and equivalents. In 45-minutes Knight went from being the largest trader in US equities and a major market maker in the NYSE and NASDAQ to bankrupt. They had 48-hours to raise the capital necessary to cover their losses (which they managed to do with a $400 million investment from around a half-dozen investors). Knight Capital Group was eventually acquired by Getco LLC (December 2012) and the merged company is now called KCG Holdings.</p>
<h2>A Lesson to Learn</h2>
<p>The events of August 1, 2012 should be a lesson to all development and operations teams. It is not enough to build great software and test it; you also have to ensure it is delivered to market correctly so that your customers get the value you are delivering (and so you don’t bankrupt your company). The engineer(s) who deployed SMARS are not solely to blame here – the process Knight had set up was not appropriate for the risk they were exposed to. Additionally their process (or lack thereof) was inherently prone to error. Any time your deployment process relies on humans reading and following instructions you are exposing yourself to risk. Humans make mistakes. The mistakes could be in the instructions, in the interpretation of the instructions, or in the execution of the instructions.</p>
<p>Deployments need to be automated and repeatable and as free from potential human error as possible. Had Knight implemented an automated deployment system – complete with configuration, deployment and test automation – the error that cause the Knightmare would have been avoided.</p>
<p>A couple of the principles for Continuous Delivery apply here (even if you are not implementing a full Continuous Delivery process):</p>
<ul>
<li>Releasing software should be a repeatable, reliable process.</li>
<li>Automate as much as is reasonable.</li>
</ul>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is the ocean salty? (2022) (211 pts)]]></title>
            <link>https://www.usgs.gov/faqs/why-ocean-salty</link>
            <guid>37459371</guid>
            <pubDate>Sun, 10 Sep 2023 19:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usgs.gov/faqs/why-ocean-salty">https://www.usgs.gov/faqs/why-ocean-salty</a>, See on <a href="https://news.ycombinator.com/item?id=37459371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Oceans cover about 70 percent&nbsp;of the Earth's surface and about <a href="https://www.usgs.gov/special-topics/water-science-school/science/how-much-water-there-earth">97 percent of all water on and in the Earth is saline</a>—there's a lot of salty water on our planet. By some estimates, if the salt in the ocean could be removed and spread evenly over the Earth’s land surface it would form a layer more than 500 feet (166 meters) thick, about the height of a 40-story office building. But, where did all this salt come from? Salt in the ocean comes from rocks on land. Here's how it works:</p>
<p>From precipitation to the land to the rivers to the sea....</p>
<p>The&nbsp;<a href="https://www.usgs.gov/special-topics/water-science-school/science/precipitation-and-water-cycle">rain that falls</a>&nbsp;on the land contains some dissolved carbon dioxide from the surrounding air. This causes the rainwater to be slightly acidic due to carbonic acid. The rain physically erodes the rock and the acids chemically break down the rocks and carries salts and minerals along in a dissolved state as ions. The ions in the&nbsp;<a href="https://www.usgs.gov/special-topic/water-science-school/science/runoff-surface-and-overland-water-runoff?qt-science_center_objects=0#qt-science_center_objects">runoff</a>&nbsp;are carried to the streams and rivers and then to the ocean. Many of the dissolved ions are used by organisms in the ocean and are removed from the water. Others are not used up and are left for long periods of time where their concentrations increase over time.</p>
<p>The two ions that are present most often in seawater are&nbsp;chloride and sodium. These two make up over 90% of all dissolved ions in seawater. The concentration of salt in seawater (its salinity) is about 35 parts per thousand; in other words, about 3.5% of the weight of seawater comes from the dissolved salts. In a cubic mile of seawater, the weight of the salt&nbsp;(as sodium chloride) would be about 120 million tons. A cubic mile of seawater can also&nbsp;contain up to 25 pounds of gold and up to 45 pounds of silver! But before you go out and try alchemy on seawater, just think about how big a cubic mile is: 1 cubic mile contains 1,101,117,147,000 gallons of water!</p>
<p>Learn more:</p>
<ul>
<li><a href="https://www.usgs.gov/special-topics/water-science-school/science/why-ocean-salty">USGS Water Science School - Why is the Ocean Salty?</a></li>
<li><a href="https://oceanservice.noaa.gov/facts/whysalty.html">NOAA -&nbsp;Why is the ocean salty?</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A design system for the federal government (154 pts)]]></title>
            <link>https://designsystem.digital.gov/</link>
            <guid>37459341</guid>
            <pubDate>Sun, 10 Sep 2023 19:53:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://designsystem.digital.gov/">https://designsystem.digital.gov/</a>, See on <a href="https://news.ycombinator.com/item?id=37459341">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
  <div>
        <h2>
          A design system for the federal government.
        </h2>
        <p>
          We make it easier to build accessible, mobile-friendly government
          websites.
        </p>
        <p><a href="https://designsystem.digital.gov/whats-new/updates/2022/04/28/introducing-uswds-3-0/">Introducing USWDS 3.0</a>
        <a href="https://designsystem.digital.gov/documentation/migration/">
          Migrating to USWDS 3.0
        </a>
      </p></div>

  
  <div>
        
        <div>
          <p><img src="https://designsystem.digital.gov/img/home/ui-component.svg" alt="" width="72" height="72"></p><div>
            
            <h2>Components</h2>
             <p>Browse all USWDS components, and get UX, accessibility, and implementation guidance.</p>

            <p>
              <a href="https://designsystem.digital.gov/components/">Browse components</a>
            </p>
          </div>
        </div>
        
        <div>
          <p><img src="https://designsystem.digital.gov/img/home/page-templates.svg" alt="" width="72" height="72"></p><div>
            
            <h2>Patterns</h2>
             <p>Use our guidance to craft effective and inclusive user experiences.</p>

            <p>
              <a href="https://designsystem.digital.gov/patterns/">Explore pattern guidance</a>
            </p>
          </div>
        </div>
        
        <div>
          <p><img src="https://designsystem.digital.gov/img/home/design-tokens.svg" alt="" width="72" height="72"></p><div>
            
            <h2>Design tokens</h2>
             <p>Learn how to get started using design tokens, the building blocks of USWDS component design.</p>

            <p>
              <a href="https://designsystem.digital.gov/design-tokens/">View design tokens</a>
            </p>
          </div>
        </div>
        
        <div>
          <p><img src="https://designsystem.digital.gov/img/home/utilities.svg" alt="" width="72" height="72"></p><div>
            
            <h2>Utilities</h2>
             <p>Adapt your designs and deliver prototypes quickly and consistently without touching a line of CSS.</p>

            <p>
              <a href="https://designsystem.digital.gov/utilities/">Build with utilities</a>
            </p>
          </div>
        </div>
        
      </div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistakes You Should Never Make (2014) (101 pts)]]></title>
            <link>https://www.sethbannon.com/p/mistakes-you-should-never-make</link>
            <guid>37458696</guid>
            <pubDate>Sun, 10 Sep 2023 18:41:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sethbannon.com/p/mistakes-you-should-never-make">https://www.sethbannon.com/p/mistakes-you-should-never-make</a>, See on <a href="https://news.ycombinator.com/item?id=37458696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I was walking to a team meeting where I was going to announce that we would likely have to lay off nearly all of our employees because we unexpectedly had almost no money left, and that it was all my fault. On the way, my co-founder and our CTO stopped me and said “I’m resigning. And I’m going to tell the team why.” He then told me that he had lost trust in me as a CEO and as a person. And our third co-founder, a friend of mine for 11 years, was resigning too. Having slept only an hour the night before, I could barely process the news.</p><p>I had hit rock bottom.</p><p><span>In </span><a href="http://smile.amazon.com/The-Hard-Thing-About-Things/dp/0062273205/" rel="">The Hard Thing About Hard Things</a><span>, Ben Horowitz says “nearly every company goes through life-threatening moments… it’s so common that there is an acronym for it, WFIO, which stands for ‘We’re Fucked, It’s Over.’” He estimates that most companies go through at least two, and sometimes over a dozen WFIOs in their lifetime. This was our first WFIO, and it hurt even more because things had been going so well. We’d made incredible progress after founding </span><a href="http://amicushq.com/" rel="">Amicus</a><span> three years ago to help nonprofits do what they do better – we graduated from Y Combinator, raised nearly $3.8 million in venture capital, grew to a team of 15, and today can call some of the biggest nonprofits in the country customers and fans of our products. Having survived our first WFIO, we’re as dedicated as ever to fulfilling our mission of empowering people to organize around the causes they care about.</span></p><p><strong>Entrepreneurs often write about what’s going right, but too rarely write about what’s gone wrong.</strong><span> One of the big values of Y Combinator was that we were able to hear </span><a href="http://www.ycombinator.com/atyc/" rel="">strictly off-the-record stories</a><span> of many successful startups’ WFIO moments. It’s a shame more entrepreneurs don’t talk about their most difficult moments publicly, because it paints a distorted picture of what startups are. A lot of the mistakes I made were avoidable, and I hope to shed light on them through this post to help others steer clear of those pitfalls. We have Amicus shirts with “Make Mistakes” emblazoned across the front. They’re meant to encourage people to take risks, be bold, and embrace small failures – after all, if you’re not making mistakes, you’re not reaching your limits. But these are mistakes you shouldn’t make.</span></p><p><strong>Mistake 1: Taxes</strong></p><p>I hired our first accountant this year. I knew our books hadn’t been well kept and was pretty sure we owed some state taxes. He determined we owed about $5,000 in state and local taxes, which we quickly paid. But shortly after, he noticed there hadn’t been any payroll tax payments coming out of our bank account.</p><p>Impossible, I thought, Bank of America’s payroll system automatically withholds payroll taxes every month, it’s all automated. But it wasn’t. There was a single “submit tax” button in a separate part of the Bank of America website that had to be clicked to actually pay the taxes. And because the IRS had our old company name (“BlueFusion”) and address on file, we never got any notices. And so I learned that we hadn’t been paying payroll taxes for almost 3 years – a particularly painful thing given I believe in taxes as a means of giving back to society.</p><p>When all is said and done, cleaning up this mess (the taxes, the fines, the legal fees, etc.) cost the company over half a million dollars. And we had to pay the vast majority of that to the IRS immediately. Needless to say, such a huge financial shock severely hurt our runway and triggered many difficult changes. This hurt even more because I’d been paying myself one of the lowest salaries on the team to maximize our runway and support our mission, and with this mistake did just the opposite.</p><p><strong>Lesson learned:</strong></p><p><span>We should have followed operational best practices, even in the early days. We used Bank of America’s payroll system to try to save costs, but our tax issue could have been prevented by using a third party payroll provider that automatically submitted payroll tax payments. It also would have been solved by proper budgeting. Doing that, we would’ve noticed the tax discrepancy in a matter of months, instead of years, and benefited from the many </span><a href="http://www.businessweek.com/stories/2006-01-18/better-business-through-budgeting" rel="">other upsides</a><span> of budgeting as well. We also should have worked with an accountant to keep our books in order. Financial operations aren’t my forté. I have little tolerance for paperwork, forms, or bookkeeping, and so had been putting off some operational tasks for too long – knowing this, I should have outsourced this as early as possible. We now make use of a bookkeeper, an accountant, and all payroll taxes are paid automatically. Don’t cut corners here.</span></p><p><strong>Mistake 2: Poorly defined co-founder relationships</strong></p><p>The first version of Amicus was built by two incredibly talented developers at Yale who chose to finish their degrees rather than pursue the startup full-time. We recruited a CTO and then a close developer friend of mine joined as employee #2. After some time, I decided to give them each “co-founder” titles, though since we already built a product, raised investment, and had paying customers, our equity split wasn’t even.</p><p>We applied to and got accepted into Y Combinator, but after we graduated, the relationships started to cause tension. I often felt like I was pouring more of myself into the company than they were and wasn’t able to share founder burdens, and they often felt I didn’t include them on important decisions and didn’t share enough information with them. One minute, they felt like co-founders; the next, they felt like employees. Confusion and resentment grew and communication suffered.</p><p><strong>Lesson learned:</strong></p><p>If I communicated earlier with my former co-founders to establish set roles and expectations, a lot of the difficulties we encountered would have been avoided. I should have flushed out a mutual understanding of how decisions would be made, what information would be shared among the founders, and what level of commitment everyone was willing to give. I’d even suggest writing these expectations in a formal agreement.</p><p><span>Just as important are frequent, honest checkins to see how everyone is feeling on an interpersonal level. Founder breakups are one of the </span><a href="http://webcache.googleusercontent.com/search?q=cache:XwiVWpKtEwcJ:blog.harjtaggar.com/co-founder-breakups+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us" rel="">most common reasons</a><span> companies fail. By getting on the same page early on and ensuring good communication, we could have avoided the confusion and resentment that became such a volatile force.</span></p><p><strong>Mistake 3: Not being explicit about hacks</strong></p><p><span>Another area where an honest and upfront discussion is warranted is around what systematic hacks are acceptable and what level of risk everyone is comfortable with. Paul Graham looks for founders who are “</span><a href="http://www.paulgraham.com/founders.html" rel="">naughty</a><span>,” but what level of rule-breaking is everyone comfortable with? I never had a conversation with my co-founders about this and it ended up causing problems.</span></p><p>In the early days I would often let potential customers think we already had a feature they wanted and, if they signed, would come back to the team and say “we’ve got to build this before they launch!” No harm, no foul, I thought, so long as we knew we were able to build the feature before they started using the product. This is a tactic commonly suggested by lean practitioners. My co-founders, though, would often frown on this behavior, worrying it was unethical, causing a huge amount of tension to grow beneath the surface.</p><p><strong>Lesson learned:</strong></p><p>I should have had conversations with my co-founders about what rules they were comfortable breaking. Testing product demand with a fake landing page that collects credit card information? Manufacturing a sense of urgency when fundraising? Pushing the limits of the law, which we never did, but which many innovative companies such as Airbnb and Lyft are doing? If we had these conversations early on, we could have avoided culture clashes (and worse) later on.</p><p><strong>Mistake 4: Going it alone</strong></p><p>Too often while running Amicus it’s been my first tendency to try to solve big problems alone – a tendency many CEOs have. My partner recently offered me some unsolicited psychoanalysis on this point. I grew up without a father in my life, and after an explosion that disabled my mother, our roles were reversed and I became her caretaker at the age of 12. From a young age I’ve been figuring things out on my own, and never learned to lean on the guidance of elders. I’ve developed some bad habits in the process. My go-it-alone attitude contributed to many of the mistakes that have been made.</p><p><strong>Lessons learned:</strong></p><p>I built an amazing team around me over the last three years, and I should have empowered them more to help solve the big problems and take advantage of the big opportunities. A few smart minds trying to solve a problem is almost always better than one mind. And the more you bring teammates in on problems you’re facing, the more ownership they feel over the organization and the more they trust in your leadership. The same goes for investors and fellow entrepreneurs. Moving forward, I’ll be reaching out to investors, teammates, and my network more frequently when we face problems, and lean on them more when we’re presented with opportunities.</p><p><strong>Mistake 5: No outside board members</strong></p><p>This is related to the go-it-alone mistake, but it warrants its own mention because I think it’s a mistake I see a lot of first time entrepreneurs making. While it seemed like a fundraising victory at the time, not inviting an investor to sit on our board during our first two rounds of financing was a mistake. While fundraising, I maximized for valuation and control, instead of maximizing for value-add. The worst thing about this is that I raised from some amazing investors who would make excellent board members.</p><p><strong>Lesson learned:</strong></p><p><span>The debate about whether a seed stage company should have a founder-only board or a board with an outside investor director is still raging. I know that for me, as a first time founder, the </span><a href="http://allthingsd.com/20130927/the-value-of-a-board-at-the-seed-stage/" rel="">many upsides</a><span> (mentorship, a cadence to the business, outside perspective, pattern recognition, real investor buy-in) would have outweighed the downsides (loss of control, investment of time in board management).</span></p><p>If I had to do it over again, I would have chosen an investor who was smart, cared about our mission deeply, and with whom I got along very well, and invited them to serve on our board. Had I done this, the tax issue almost certainly would have been avoided, and I’m sure a number of smaller mistakes would have as well. An experienced board member who cares about you and your company can use their pattern recognition to help you steer clear of all sorts of pitfalls. I believe so strongly in this that I’m voluntarily creating a board seat for one of our current investors.</p><p><strong>Mistake 6: Poor investor relations</strong></p><p>When you’re running a company, there are always 100 things that need to be done, and enough time to do 70 of them. One thing that I let slide was investor updates. There were a couple investors I talked to regularly, but by and large my communiqués were scarce, and normally were sent when I needed something. This meant that when the crisis struck, it took much longer for investors to be able to help than it needed to. I had to fill many of them in on the past year of the company, instead of having to fill them in on the past month. And as you can imagine, having the first substantive update you hear in a while be about an impending crisis is not the most inspiring thing. So while our investors have by and large been quite supportive, it took longer for them to get engaged because they’d been kept out of the loop for so long.</p><p><strong>Lesson Learned:</strong></p><p><span>I should have talked with our investors more. I shouldn’t have only pinged them when we needed something, but should have kept them updated on the progress we were making (or not making) on a regular basis. I owe it to my team to keep our investors close and I owe it to our investors to keep them updated – after all, they’re taking a huge financial risk to help us achieve our mission. Aaron Harris of Y Combinator wrote a great </span><a href="http://www.aaronkharris.com/investor-updates" rel="">guide to investor updates</a><span> which I find very helpful.</span></p><p><strong>Mistake 7: Telling a half-truth</strong></p><p><span>Lastly, this has been one of the most difficult times of my adult life, and has forced me to go through a painful amount of introspection. Through this process, there was one example of rule bending I wish I could take back. Before Amicus, I was enrolled in the bachelor’s degree program at the Extension School at Harvard University – a small program with a few hundred graduates a year. At the time, I considered it a good hack, as I was getting, </span><a href="http://www.nytimes.com/2005/11/18/national/18harvard.html?_r=0&amp;pagewanted=all" rel="">as the New York Times put it</a><span> “Harvard at a fraction of the cost.” I even played for the Harvard Chess Team, including traveling with them twice for competitions in China.</span></p><p>Eventually I dropped out to pursue the startup full time. Partly for convenience and partly to make for a good story, I would often say I dropped out of “Harvard University.” The fact that this was technically true allowed me to rationalize the statement to myself. But in saying it this way, I gave people the impression that I had dropped out of Harvard College (à la Zuckerberg and Gates), which was not the case.</p><p><span>At some point a friend called me out on this, so I started being more clear. It felt good to do so, and the </span><a href="https://www.youtube.com/watch?v=H6WtpN0hYyo&amp;feature=youtu.be&amp;t=7s" rel="">press coverage</a><span> of Amicus that mentioned I went to the Extension School wasn’t any less compelling for it. But the damage was done, and I often fell back into old habits. To cause people to think I didn’t get a degree from one school at Harvard when, in reality, I didn’t get a degree from a different school at Harvard is the height of absurdity. I’d sacrificed my credibility for little benefit other a sense of false prestige and a sexy line in a press story.</span></p><p><strong>Lesson learned:</strong></p><p><span>First and foremost, I’ve come to realize that “technically true” is a terrible ethical measure for a (non-technical) statement. I should have held myself to a higher standard. I’ve also learned the importance of overwhelming honesty. The phrase is borrowed from the excellent book </span><a href="http://smile.amazon.com/The-Transparency-Edge-Elizabeth-Pagano/dp/0071458840/" rel="">The Transparency Edge</a><span> (worth a read in full). In the same way a product builds up technical debt with every piece of hacky code, a leader can build up a sort of managerial debt with every fib, embellishment, and exaggeration. They all serve to undermine credibility. And without credibility, you cannot lead. Moving forward, overwhelming honesty is the name of the game at Amicus.</span></p><p><strong>Other mistakes:</strong></p><p>Over the three years I’ve been running this company, I’ve made a number of other mistakes as well (burning out myself and my team, on-and-off micro-management, an occasional lack of empathy, bad hires – the list goes on), but the ones highlighted above are what led most directly to the crisis we now face. Each of the other mistakes probably warrants a blog post as well.</p><p>This past month I’ve had to part ways with team members I loved working with. We don’t have as many resources as we used to. My co-founders and I shared a passion and a vision for making the world a better place by empowering nonprofits, but now they’re gone and we’ve taken a major step back from accomplishing our goal. Realizing that this is all my fault has been tough to deal with emotionally.</p><p><span>That’s taught me one last lesson: that </span><strong>in tough times a support network is invaluable</strong><span>. They say you only really learn who your friends and supporters are when shit hits the fan, and that’s certainly been my experience. Some of our investors saw these mistakes and threw their hands up in despair – and who could blame them. Others chose to roll their sleeves up and help clean up the mess.</span></p><p>I’m proud of the Amicus team that remains, those who are fighting through the tough times because they believe in our mission. And I’m humbled that they still believe in me. I’ve been most surprised by the outpouring of support from other entrepreneurs (mainly from the Y Combinator network) who heard we might be going through tough times, and reached out just to let me know they were there for me. I couldn’t be more grateful for the investors, teammates, and friends that have supported me through this.</p><p><strong>Moving forward</strong></p><p><span>It’s been a difficult month. Paul Graham’s essay on </span><a href="http://www.paulgraham.com/die.html" rel="">How Not To Die</a><span> has been an open tab in my browser for the last couple weeks. And I now truly empathize with Ben Horowitz when he writes about </span><a href="http://www.bhorowitz.com/the_struggle" rel="">The Struggle</a><span>. But we carry on. The mission of Amicus is too important. We’re trying to upend the power structures that exist in society by giving people the tools they need to organize around the causes they care about. We’re not going to let a few bumps in the road – even if they’re big ones – get in the way of that.</span></p><p>I stayed up all night recently reading about some of the great entrepreneurial turnaround stories. It’s shocking how many of the companies we all know and respect were months, weeks, or even hours away from death. FedEx, Evernote, Intuit, Zappos, Airbnb – I’m endlessly inspired by those founders who faced near collapse but simply refused to give up. I hope one day the Amicus story can inspire someone the way these stories inspire me.</p><p><strong>To summarize:</strong></p><ol><li><p>Pay attention to financial operations from the early days. Make a budget.</p></li><li><p>Be explicit with your co-founders at the get-go about decision-making, distribution of information, and level of commitment. Formalize this in a written agreement.</p></li><li><p>Have conversations with co-founders and teammates when they join about what rules you’re comfortable bending and what hacks you’re comfortable implementing.</p></li><li><p>Don’t be a lone wolf. Lean on the experience and smarts of your teammates, investors, and mentors to help solve the tough problems and take advantage of the opportunities.</p></li><li><p>If you’re a first time entrepreneur, invite an outside director to sit on your board when you raise money. The upsides greatly outweigh the downsides.</p></li><li><p>Keep your investors posted on your progress, be responsive to their requests, and lean on their guidance.</p></li><li><p>Be overwhelmingly honest with your stakeholders (team, investors, customers).</p></li><li><p>Build a support network of fellow entrepreneurs when the times are good, because when the times are tough their support is invaluable.</p></li></ol><p>These are painful mistakes I’ll never make again. I hope by hearing this story you’ll avoid making them too.</p><p>Thanks:</p><ol><li><p><a href="http://www.withum.com/ind_Startup_Team.shtml" rel="">Chris DeMayo</a><span> did amazing work helping us get our books in order and fixing our tax situation. If you need an accountant, I couldn’t recommend anyone more highly.</span></p></li><li><p>Ashu Desai, Mattan Griffel, Henry Xie, Dan Friedman, Joel Califa, Paul Cretu, and Ela Madej for reading drafts of this post</p></li><li><p>The YC network for being so supportive through this</p></li></ol></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why SaaS prices are still going up when companies are spending less (105 pts)]]></title>
            <link>https://www.vendr.com/blog/price-hikes-continue</link>
            <guid>37458671</guid>
            <pubDate>Sun, 10 Sep 2023 18:39:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vendr.com/blog/price-hikes-continue">https://www.vendr.com/blog/price-hikes-continue</a>, See on <a href="https://news.ycombinator.com/item?id=37458671">Hacker News</a></p>
<div id="readability-page-1" class="page"><div fs-toc-offsettop="90px" fs-richtext-element="rich-text" fs-richtext-resetix="true" fs-richtext-sanitize="true" fs-toc-element="contents" data-w-id="92ed361c-2bf3-ce5a-a522-58de9c6a33ea"><p>Inflation rates are finally trending downwards — at least for U.S. consumer prices. The worst of software inflation, though, may be yet to come.</p><p>2023 has been the year of software price hikes. Microsoft, Google, Salesforce, and Zendesk, have all implemented price increases so far this year.</p><p>Shrinking workforces, higher inflation-driven costs, investments into AI, a strong US dollar, and a more challenging fundraising landscape have combined to make software price hikes the new norm. It’s a trend that started with the software companies at the top.</p><p>{{cta1}}</p><h2><strong>A perfect software pricing storm</strong></h2><p>The software at the top of the budget pecking order has, over the past few years, captured a decreasing share of wallet. The top 10 software vendors in 2021 accounted for 29% of software spend. In 2022, they captured only 27%. While top software companies can’t control the economy, they can control their prices. This led to our prediction earlier this year that top companies would raise their prices to make up for a decreasing share of wallet, and <a href="https://www.vendr.com/blog/saas-price-hike">2023 would be the year of the price hike</a>. </p><p>That hunch came true. Half of the software vendors with the top share of wallet raised their prices in 2023, despite positive signals in the broader economy.</p><p>Google started the trend by <a href="https://workspace.google.com/blog/product-announcements/pricing-updates-and-more-flexible-payment-options-google-workspace">hiking Google Workspace’s price</a> by 20% in February. It also added an annual plan “to lock in the lowest prices” and deter churn — priced, for now, at the pre-price-hike rate to dampen the blow. <a href="https://cloud.google.com/storage/pricing-announce">Google Cloud storage prices</a> also went up an average of 44% in April.</p><p>Microsoft, after a <a href="https://www.cio.com/article/646151/why-is-salesforce-hiking-prices-and-how-does-it-affect-customers.html">late-2021 Office 365 price increase</a>, added <a href="https://news.microsoft.com/europe/2023/01/05/consistent-global-pricing-for-the-microsoft-cloud/">global currency-based price adjustments</a> this year. That addition translates into a 9% price hike in the United Kingdom and an 11% hike in the EU. That, along with a <a href="https://blogs.microsoft.com/blog/2023/07/18/furthering-our-ai-ambitions-announcing-bing-chat-enterprise-and-microsoft-365-copilot-pricing/">new $30/month Copilot AI add-on</a> for Office 365, rather than AI being bundled with existing plans, could represent a large increase in average spend.</p><p>Salesforce is <a href="https://www.salesforce.com/news/stories/pricing-update/">raising core prices</a> by 9% in August. <a href="https://support.zendesk.com/hc/en-us/articles/5555300573850">Zendesk pricing went up</a> 12 to 20% in July and Enterprise plans now require a sales call. <a href="https://www.snowflake.com/blog/updates-pricing-model-november-2022/">Snowflake switched to US Dollar-only billing</a> in November 2022, resulting in a net price increase for most global companies amid a strong US Dollar environment.</p><p>Other public SaaS vendors, including Zoom, Shopify, Atlassian, and <a href="https://monday.com/">Monday.com</a> also raised prices. Where <a href="https://www.gartner.com/en/newsroom/press-releases/2022-10-19-gartner-forecasts-worldwide-it-spending-to-grow-5-percent-in-2023">Gartner predicted</a> software budgets would increase 11.3% in 2023, and <a href="https://techcrunch.com/2023/07/31/2023-tech-spending-stable/">TechCrunch recently reported</a> that IT spend has continued to grow at a steady 4%, the price hikes mean that any budget increase will go to pay for already-deployed software.</p><h2><strong>Costs are driving price hikes</strong></h2><p>Software price hikes are driven in part by inflation. The cost of living has surged post-pandemic in most economies. Higher electricity costs, chip shortages, and rising wages all increase the cost of doing business.</p><p>If you have to choose between a marketing campaign or renewing a non-critical software subscription, you’ll likely opt for the former. No surprise that software churn is at a 4 year high, as <a href="https://www.paddle.com/blog/b2b-saas-index-market-update-june-2023">Paddle reported</a> in June.</p><p>That, in turn, hits software vendors’ bottom lines, driving them to cut spend as well. Even giants like <a href="https://www.wsj.com/articles/meta-platforms-facebook-q2-earnings-report-2023-a0297b9c">Meta have aggressively cut costs</a> for a “year of efficiency.”</p><p>Cut software budgets translate into tech jobs disappearing as funds dry up. Companies are forced to do more with fewer people. </p><p>“In 2018 the typical firm that raised a round of $10m-25m had some 50 employees,” <a href="https://www.economist.com/business/2023/07/25/next-generation-googles-run-a-tighter-ship">reported the Economist</a> in July. “In 2023 a similar one employs 41.” That downsizing has seen 220,000 tech jobs disappear so far in 2023—and each employee represents lost software licenses as they log out of their former employee’s tools.</p><p>So even if a software vendor doesn’t get cut from a company’s budget, it’s likely now being used by fewer people inside that company. Teams are scrutinizing every line item, buying software only for critical users, and choosing lower-tier software plans. As more companies cut seats and plans, the total software spend gets hit even harder.</p><p>That translates into a massive 45% decrease in average contract value between Q1 and Q2 2023, as teams purchase fewer seats and select lower-priced tiers.</p><p>Charging more for software is the only way to maintain revenue when vendors can no longer make it up in volume.</p><p>{{cta2}}</p><h2><strong>Why raise prices when budgets are tight?</strong></h2><p>Mission-critical software is sticky. There are certain tools you can't scale back on, even if the price goes up.</p><p>Price and stickiness correlate. If company processes are already embedded in a product, buyers are more willing to pay more instead of switching to a different solution.</p><p>Less crucial tools are easier to drop. As Paddle’s churn report found, when budgets get cut, “products with few stakeholder champions will be the first to go.”</p><p>That hurts startups, but helps software giants with larger software suites. Your company might try to wring more value out of existing Google Workspace or Office 365 subscriptions while churning out of a newer startup’s offering that performs a single task.</p><p>Stickiness has given larger software companies the headroom to raise prices, and a chance to earn back their historic share of wallet even in a difficult environment.</p><p>That has already translated into a drop in discounting. Across Vendr’s software negotiations, we’ve seen a gradual decline in average discounts. The discount rate decreased from 11% in 2022 to 9% in Q1 2023 then dropped to only 7% in Q2 2023.</p><p>List prices are the new normal in software. The larger software vendors have little reason to discount when their products are a standard you have to buy. Smaller software vendors know they’ll struggle to retain customers, and need to earn the lifetime value of a contract far quicker than before.</p><p>Going forward, it could mean that smaller, pre-IPO software startups will be less likely to raise prices and more willing to compete on cost to gain a share of spend. That is, if they’re able to continue to raise funding, something that’s increasingly difficult in a high-interest-rate environment.</p><p>It could also mean that the most sticky, difficult-to-replace software in your stack may keep going up in price.</p><h2><strong>Investments into future tech aren’t paying off – yet</strong></h2><p>At the same time, software companies are spending massively on AI and other future tech: </p><ul role="list"><li>Meta lost over $3.7 billion on Reality Labs research and development, far more than their spending reductions could offset, <a href="https://www.wsj.com/articles/meta-platforms-facebook-q2-earnings-report-2023-a0297b9c">reports the WSJ</a>. </li><li>Microsoft CFO Amy Hood announced “accelerate[d] investment in our cloud infrastructure” to meet Microsoft Cloud growth and AI platform demand. </li><li>Snap’s cost of revenue increased 11% percent, rising costs <a href="https://stratechery.com/2023/microsoft-earnings-google-earnings-snap-earnings/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9">Ben Thompson of Stratechery suspects</a> are fueled by investments in Snap’s “My AI.”</li></ul><p>“Generative models can add huge compute costs,” <a href="https://www.saas-capital.com/">cautions SaaS Capital’s Rob Blecher</a>, indicating that these costs must be made up in new revenue or lower margins.</p><p>Despite those expenditures, new AI-driven revenue isn’t doing much for the bottom line. </p><p>“Growth from our AI services will be gradual,” said Microsoft’s Hood. <a href="https://www.bloomberg.com/news/articles/2023-07-31/investors-are-happy-to-pay-premium-for-tech-but-not-for-ai">Bloomberg found</a> that investors are not giving a premium to AI stocks.</p><p>This aligns with what we’ve seen so far. <a href="https://www.vendr.com/insights/saas-trends-report-q2-2023">Vendr’s data</a> shows that AI integration doesn't strongly influence SaaS purchasing.</p><p>That leaves the new investments to be recouped with higher pricing on traditional software suites where customers have lower price sensitivity.</p><p>Going forward, new features—especially those powered by AI—will most likely only be added to higher-tier plans to drive increased subscription revenue. We’re already seeing with Google Workspace’s latest features coming only to mid and top-tier plans. AI add-ons might be pulled into the core subscription plans as well, if opt-in adoption doesn’t drive the returns needed to pay back the investment. We’ll also likely see annual plans be increasingly required or heavily incentivized in pricing, to bring churn rates down.</p><p>The year of price hikes is far from over.</p><p>{{cta3}}</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Senior Engineer's Check-List (2019) (228 pts)]]></title>
            <link>https://littleblah.com/post/2019-09-01-senior-engineer-checklist/</link>
            <guid>37458283</guid>
            <pubDate>Sun, 10 Sep 2023 17:57:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://littleblah.com/post/2019-09-01-senior-engineer-checklist/">https://littleblah.com/post/2019-09-01-senior-engineer-checklist/</a>, See on <a href="https://news.ycombinator.com/item?id=37458283">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div id="control-accordion">
<h3>Controls (click to expand)</h3>

</div>
<p>
This is a simple checklist, and while it is useful to any software engineer, it is especially useful to senior engineers.
</p><table id="datatable">
<thead>
<tr>
<th rowspan="1">#</th>
<th rowspan="1">Task</th>
<th colspan="1">Effort</th>
<th colspan="1">Category</th>
<th colspan="2">Impact</th>
</tr>
<tr>
<th></th>
<th>
Task
</th>
<th>
</th>
<th>
</th>
<th>
Career
</th>
<th>
Company
</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Understand the business aspect of your work, and what makes money. Eventually, only that matters.</td>
<td>high</td>
<td>leadership</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>2</td>
<td>Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates.</td>
<td>medium</td>
<td>hiring</td>
<td>low</td>
<td>high</td>
</tr>
<tr>
<td>3</td>
<td>Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering.</td>
<td>high</td>
<td>technology</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>4</td>
<td>Question everything and ask "why" repetitively until you get to the root of problems and situations.</td>
<td>high</td>
<td>technology</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>5</td>
<td>Demand accountability and ownership from others.</td>
<td>high</td>
<td>leadership</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>6</td>
<td>Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery.</td>
<td>high</td>
<td>leadership</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>7</td>
<td>Work towards disambiguating ambiguous problem statements.</td>
<td>high</td>
<td>leadership</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>8</td>
<td>Cultivate relationships with other teams and develop trust.</td>
<td>high</td>
<td>network</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>9</td>
<td>Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem.</td>
<td>medium</td>
<td>network</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>10</td>
<td>Be involved with multiple projects as a consultant, a reviewer and/or a mentor.</td>
<td>medium</td>
<td>network</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>11</td>
<td>Follow the principles of extreme ownership.</td>
<td>high</td>
<td>leadership</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>12</td>
<td>Have strong mentors to help you navigate and grow in the company.</td>
<td>high</td>
<td>mentor</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>13</td>
<td>Take projects with high risk and high rewards.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>14</td>
<td>Strive for deep technical expertise in technologies used in your team.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>15</td>
<td>Ask for stretch projects from your manager, or help her identify one for you.</td>
<td>medium</td>
<td>growth</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>16</td>
<td>Discuss the goals of your manager, and how you align your work with it.</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>17</td>
<td>Invest time in networking effectively with seniors, peers, and juniors.</td>
<td>medium</td>
<td>network</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>18</td>
<td>Be a mentor to a couple of junior engineers.</td>
<td>medium</td>
<td>mentor</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>19</td>
<td>Increase your breadth of knowledge in the domain of your team/company.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>high</td>
</tr>
<tr>
<td>20</td>
<td>Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion.</td>
<td>medium</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>21</td>
<td>Discuss problems with your manager, but have some solutions beforehand.</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>22</td>
<td>Increase your breadth of knowledge in technology.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>23</td>
<td>Explore emerging technologies by building small prototypes.</td>
<td>high</td>
<td>growth</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>24</td>
<td>Read a few technical books every year.</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>25</td>
<td>Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly.</td>
<td>high</td>
<td>technology</td>
<td>medium</td>
<td>high</td>
</tr>
<tr>
<td>26</td>
<td>Schedule a regular one-on-one with your manager</td>
<td>low</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>27</td>
<td>Schedule a regular one-on-one with your skip level manager</td>
<td>low</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>28</td>
<td>[Reminder] One-on-one usually is not a status meeting</td>
<td>medium</td>
<td>one-on-one</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>29</td>
<td>Involve the manager in your personal life (just a little though)</td>
<td>low</td>
<td>managers</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>30</td>
<td>Actively seek feedback from your manager</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>31</td>
<td>Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>32</td>
<td>Keep your manager up-to-date in things you are blocked on</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>33</td>
<td>Keep your manager up-to-date on people you have difficulty working with</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>34</td>
<td>Give constructive feedback to your manager</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>35</td>
<td>If you are overworked, let your manager know</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>36</td>
<td>If you are under-utilized, ask your manager for areas to explore</td>
<td>medium</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>37</td>
<td>If you have an ineffective or neglectful manager, talk to your manager about your expectations</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>38</td>
<td>If you have a micromanager, talk to your manager about your expectations</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>39</td>
<td>If you have an abusive manager, talk to your skip manager or HR with data points</td>
<td>low</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>40</td>
<td>If you have an ineffective skip manager and ineffective manager, switch the team or company</td>
<td>high</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>41</td>
<td>If you do not have a cordial relationship with your manager, switch the team or company</td>
<td>high</td>
<td>managers</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>42</td>
<td>[Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>43</td>
<td>Measure what you want to improve. Make efforts measurable</td>
<td>medium</td>
<td>growth</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>44</td>
<td>Maintain high visibility of projects which have a high risk</td>
<td>high</td>
<td>growth</td>
<td>high</td>
<td>medium</td>
</tr>
<tr>
<td>45</td>
<td>To deal with difficult folks, discuss with your managers and mentors</td>
<td>low</td>
<td>network</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>46</td>
<td>To deal with difficult folks, fall back to first principles</td>
<td>low</td>
<td>network</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>47</td>
<td>Be reachable to other engineers</td>
<td>low</td>
<td>network</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>48</td>
<td>Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required</td>
<td>high</td>
<td>leadership</td>
<td>medium</td>
<td>medium</td>
</tr>
<tr>
<td>49</td>
<td>Simplify code, systems, and architectures relentlessly</td>
<td>high</td>
<td>technology</td>
<td>low</td>
<td>high</td>
</tr>
<tr>
<td>50</td>
<td>Demand high-quality work from others, but be pragmatic</td>
<td>medium</td>
<td>technology</td>
<td>low</td>
<td>high</td>
</tr>
<tr>
<td>51</td>
<td>Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising</td>
<td>high</td>
<td>technology</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>52</td>
<td>Document extensively, and demand it from others. Document "why" more than "how"</td>
<td>high</td>
<td>technology</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>53</td>
<td>Avoid politics, but have right folks vouch for your work</td>
<td>high</td>
<td>politics</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>54</td>
<td>When dealing with politics, fall back to first principles</td>
<td>high</td>
<td>politics</td>
<td>low</td>
<td>low</td>
</tr>
<tr>
<td>55</td>
<td>If politics thrives due to team or company culture, switch</td>
<td>high</td>
<td>politics</td>
<td>high</td>
<td>low</td>
</tr>
<tr>
<td>56</td>
<td>Try not to get involved in office gossip</td>
<td>low</td>
<td>politics</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>57</td>
<td>Avoid stretching yourself too thin to be effective</td>
<td>medium</td>
<td>leadership</td>
<td>medium</td>
<td>low</td>
</tr>
<tr>
<td>58</td>
<td>Respect code and systems that came before you. There are reasons for every code and every guard that exists in production</td>
<td>low</td>
<td>technology</td>
<td>low</td>
<td>medium</td>
</tr>
<tr>
<td>59</td>
<td>Before you suggest major refactors, ensure you understand the system deeply</td>
<td>medium</td>
<td>technology</td>
<td>medium</td>
<td>high</td>
</tr>
<tr>
<td>60</td>
<td>Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time</td>
<td>medium</td>
<td>technology</td>
<td>medium</td>
<td>high</td>
</tr>
</tbody>
</table>
<div id="simpleList">
<ol>
<li>Understand the business aspect of your work, and what makes money. Eventually, only that matters.</li>
<li>Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates.</li>
<li>Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering.</li>
<li>Question everything and ask "why" repetitively until you get to the root of problems and situations.</li>
<li>Demand accountability and ownership from others.</li>
<li>Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery.</li>
<li>Work towards disambiguating ambiguous problem statements.</li>
<li>Cultivate relationships with other teams and develop trust.</li>
<li>Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem.</li>
<li>Be involved with multiple projects as a consultant, a reviewer and/or a mentor.</li>
<li>Follow the principles of extreme ownership.</li>
<li>Have strong mentors to help you navigate and grow in the company.</li>
<li>Take projects with high risk and high rewards.</li>
<li>Strive for deep technical expertise in technologies used in your team.</li>
<li>Ask for stretch projects from your manager, or help her identify one for you.</li>
<li>Discuss the goals of your manager, and how you align your work with it.</li>
<li>Invest time in networking effectively with seniors, peers, and juniors.</li>
<li>Be a mentor to a couple of junior engineers.</li>
<li>Increase your breadth of knowledge in the domain of your team/company.</li>
<li>Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion.</li>
<li>Discuss problems with your manager, but have some solutions beforehand.</li>
<li>Increase your breadth of knowledge in technology.</li>
<li>Explore emerging technologies by building small prototypes.</li>
<li>Read a few technical books every year.</li>
<li>Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly.</li>
<li>Schedule a regular one-on-one with your manager</li>
<li>Schedule a regular one-on-one with your skip level manager</li>
<li>[Reminder] One-on-one usually is not a status meeting</li>
<li>Involve the manager in your personal life (just a little though)</li>
<li>Actively seek feedback from your manager</li>
<li>Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail</li>
<li>Keep your manager up-to-date in things you are blocked on</li>
<li>Keep your manager up-to-date on people you have difficulty working with</li>
<li>Give constructive feedback to your manager</li>
<li>If you are overworked, let your manager know</li>
<li>If you are under-utilized, ask your manager for areas to explore</li>
<li>If you have an ineffective or neglectful manager, talk to your manager about your expectations</li>
<li>If you have a micromanager, talk to your manager about your expectations</li>
<li>If you have an abusive manager, talk to your skip manager or HR with data points</li>
<li>If you have an ineffective skip manager and ineffective manager, switch the team or company</li>
<li>If you do not have a cordial relationship with your manager, switch the team or company</li>
<li>[Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness</li>
<li>Measure what you want to improve. Make efforts measurable</li>
<li>Maintain high visibility of projects which have a high risk</li>
<li>To deal with difficult folks, discuss with your managers and mentors</li>
<li>To deal with difficult folks, fall back to first principles</li>
<li>Be reachable to other engineers</li>
<li>Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required</li>
<li>Simplify code, systems, and architectures relentlessly</li>
<li>Demand high-quality work from others, but be pragmatic</li>
<li>Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising</li>
<li>Document extensively, and demand it from others. Document "why" more than "how"</li>
<li>Avoid politics, but have right folks vouch for your work</li>
<li>When dealing with politics, fall back to first principles</li>
<li>If politics thrives due to team or company culture, switch</li>
<li>Try not to get involved in office gossip</li>
<li>Avoid stretching yourself too thin to be effective</li>
<li>Respect code and systems that came before you. There are reasons for every code and every guard that exists in production</li>
<li>Before you suggest major refactors, ensure you understand the system deeply</li>
<li>Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time</li>
</ol>
</div>
<div id="simpleDetailedList">
<ol>
<li>Understand the business aspect of your work, and what makes money. Eventually, only that matters.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: hiring</li>
</span>
</ul>
</li>
<li>Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Question everything and ask "why" repetitively until you get to the root of problems and situations.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Demand accountability and ownership from others.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Work towards disambiguating ambiguous problem statements.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Cultivate relationships with other teams and develop trust.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Be involved with multiple projects as a consultant, a reviewer and/or a mentor.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Follow the principles of extreme ownership.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Have strong mentors to help you navigate and grow in the company.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: mentor</li>
</span>
</ul>
</li>
<li>Take projects with high risk and high rewards.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Strive for deep technical expertise in technologies used in your team.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Ask for stretch projects from your manager, or help her identify one for you.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Discuss the goals of your manager, and how you align your work with it.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Invest time in networking effectively with seniors, peers, and juniors.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Be a mentor to a couple of junior engineers.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: mentor</li>
</span>
</ul>
</li>
<li>Increase your breadth of knowledge in the domain of your team/company.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>Discuss problems with your manager, but have some solutions beforehand.
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Increase your breadth of knowledge in technology.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Explore emerging technologies by building small prototypes.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Read a few technical books every year.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly.
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Schedule a regular one-on-one with your manager
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>Schedule a regular one-on-one with your skip level manager
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>[Reminder] One-on-one usually is not a status meeting
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: one-on-one</li>
</span>
</ul>
</li>
<li>Involve the manager in your personal life (just a little though)
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Actively seek feedback from your manager
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Keep your manager up-to-date in things you are blocked on
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Keep your manager up-to-date on people you have difficulty working with
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>Give constructive feedback to your manager
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you are overworked, let your manager know
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you are under-utilized, ask your manager for areas to explore
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have an ineffective or neglectful manager, talk to your manager about your expectations
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have a micromanager, talk to your manager about your expectations
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have an abusive manager, talk to your skip manager or HR with data points
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you have an ineffective skip manager and ineffective manager, switch the team or company
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>If you do not have a cordial relationship with your manager, switch the team or company
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: managers</li>
</span>
</ul>
</li>
<li>[Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Measure what you want to improve. Make efforts measurable
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>Maintain high visibility of projects which have a high risk
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: growth</li>
</span>
</ul>
</li>
<li>To deal with difficult folks, discuss with your managers and mentors
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>To deal with difficult folks, fall back to first principles
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Be reachable to other engineers
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: network</li>
</span>
</ul>
</li>
<li>Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Simplify code, systems, and architectures relentlessly
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Demand high-quality work from others, but be pragmatic
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Document extensively, and demand it from others. Document "why" more than "how"
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Avoid politics, but have right folks vouch for your work
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>When dealing with politics, fall back to first principles
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>If politics thrives due to team or company culture, switch
<ul>
<span>
<li><b>Effort</b>: high</li>
<li><b>Career Impact</b>: high</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>Try not to get involved in office gossip
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: politics</li>
</span>
</ul>
</li>
<li>Avoid stretching yourself too thin to be effective
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: low</li>
<li><b>Category</b>: leadership</li>
</span>
</ul>
</li>
<li>Respect code and systems that came before you. There are reasons for every code and every guard that exists in production
<ul>
<span>
<li><b>Effort</b>: low</li>
<li><b>Career Impact</b>: low</li>
<li><b>Company Impact</b>: medium</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Before you suggest major refactors, ensure you understand the system deeply
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
<li>Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time
<ul>
<span>
<li><b>Effort</b>: medium</li>
<li><b>Career Impact</b>: medium</li>
<li><b>Company Impact</b>: high</li>
<li><b>Category</b>: technology</li>
</span>
</ul>
</li>
</ol>
</div>
<hr>
<h2>Resources</h2>
<div id="accordion">
<h3>click to expand</h3>
<div>
<p><span>Note</span>: <a href="https://github.com/littleblah/senior-engineer-checklist" target="_blank">This is the source</a> of the data in the checklist. Pull requests are welcome.</p>
<p>This page refreshes daily. So this page might be lagging by couple of hours.</p>
<h2>My Definitions</h2>
<p>These are my definitions, and may not exactly align with yours. If you want, you can download this list as a CSV (download button is present in table view), and create your own version.</p>
<p>
<span>Senior Engineer</span>: Someone who has these basic attributes
</p><ul>
<li>Couple of years of Relevant Practical Experience <i>(Exact number of years is not easy to identify since we are looking at having variety of experiences over time rather than similar experience repeated over years)</i> </li>
<li>Influence within and across teams</li>
<li>Breadth of knowledge of technologies</li>
<li>Depth in one or more domains and/or technologies</li>
</ul>

<p><span>Effort</span>: Effort of a task as compared to others in the list. This may not exactly align with level of effort of the task for you.</p>
<p><span>Category</span>: Category of the task.</p>
<p><span>Career Impact</span>: Level of impact on your career growth.</p>
<p><span>Company Impact</span>: Level of impact on your company and your team.</p>
<p><span>Difficulty</span>: I did not see a point of listing difficulty. What may be difficult for one may not be for other.</p>
<h2>References</h2>
<ul>
<h3>Books (Non-affiliate links)</h3>
<ul>
<li>
<a href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897" target="_blank">The manager's Path</a>
</li>
<li>
<a href="https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959" target="_blank">The Mythical Man-Month</a>
</li>
</ul>
<h3>Articles and Discussions</h3>
<ul>
</ul>
</ul>
</div>
</div>
<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Goodbye to Thien-Thi Nguyen (206 pts)]]></title>
            <link>https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html</link>
            <guid>37457796</guid>
            <pubDate>Sun, 10 Sep 2023 17:08:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html">https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html</a>, See on <a href="https://news.ycombinator.com/item?id=37457796">Hacker News</a></p>
<div id="readability-page-1" class="page">
<center>




</center>
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<hr>
[<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00712.html">Date Prev</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00714.html">Date Next</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00705.html">Thread Prev</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00715.html">Thread Next</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/index.html#00713">Date Index</a>][<a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/threads.html#00713">Thread Index</a>]

<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->

<hr>
<table>
<tbody>
<tr>
<td>
<b>From</b>: </td>
<td>
Amin Bandali</td>
</tr>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->

<tr>
<td>
<b>Subject</b>: </td>
<td>
Goodbye to Thien-Thi Nguyen</td>
</tr>

<tr>
<td>
<b>Date</b>: </td>
<td>
Sat, 09 Sep 2023 23:55:05 -0400</td>
</tr>

<tr>
<td>
<b>User-agent</b>: </td>
<td>
Gnus/5.13 (Gnus v5.13) Emacs/30.0.50 (gnu/linux)</td>
</tr>

</tbody>
</table>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
<hr>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre>We have learned with deep sadness that Thien-Thi Nguyen (ttn) died in
October 2022.  Thien-Thi was a hacker, artist, writer, and long-time
maintainer and contributor to many GNU programs as well as other free
software packages.  He was the GNU maintainer of the rcs, guile-sdl,
alive, and superopt packages, and he was working on GNU Go as well.

Thien-Thi especially loved GNU Emacs, GNU Taler, and GNU Go: he was
the author and maintainer of the xpm, gnugo, ascii-art-to-unicode,
and hideshow GNU Emacs packages and made substantial contributions to
many others such as vc, as well as to GNU Taler and its documentation.

We greatly miss Thien-Thi in the free software community - his death
is a great loss to the Free World.


</pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<hr>

<hr>
<table>
<tbody><tr><td>[Prev in Thread]</td>
<td><b>Current Thread</b></td>
<td>[Next in Thread]</td></tr></tbody></table>
<ul>
<li><span color="#666666"><strong>Goodbye to Thien-Thi Nguyen</strong>,
<em>Amin Bandali</em></span>&nbsp;<b>&lt;=</b>
</li></ul>

<hr>
<!--X-Follow-Ups-End-->
<!--X-References-->
<!--X-References-End-->
<!--X-BotPNI-->
<ul>
<li>Prev by Date:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00712.html">Re: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084</a></strong>
</li>
<li>Next by Date:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00714.html">Re: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084</a></strong>
</li>
<li>Previous by thread:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00705.html">Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084</a></strong>
</li>
<li>Next by thread:
<strong><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00715.html">Re: Clojure mode</a></strong>
</li>
<li>Index(es):
<ul>
<li><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/index.html#00713"><strong>Date</strong></a></li>
<li><a href="https://lists.gnu.org/archive/html/emacs-devel/2023-09/threads.html#00713"><strong>Thread</strong></a></li>
</ul>
</li>
</ul>

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[What I have changed my mind about in software development (134 pts)]]></title>
            <link>https://henrikwarne.com/2023/09/10/what-i-have-changed-my-mind-about-in-software-development/</link>
            <guid>37457208</guid>
            <pubDate>Sun, 10 Sep 2023 16:12:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://henrikwarne.com/2023/09/10/what-i-have-changed-my-mind-about-in-software-development/">https://henrikwarne.com/2023/09/10/what-i-have-changed-my-mind-about-in-software-development/</a>, See on <a href="https://news.ycombinator.com/item?id=37457208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>I really like this quote from Jeff Bezos:</p>



<p><em>“Anybody who doesn’t change their mind a lot is dramatically underestimating the complexity of the world we live in.”</em></p>



<p>Lately I have been thinking about what I have changed my mind about in software development. Here are the things I came up with:</p>



<figure><a href="https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg"><img data-attachment-id="2339" data-permalink="https://henrikwarne.com/2023/09/10/what-i-have-changed-my-mind-about-in-software-development/stenmur/" data-orig-file="https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg" data-orig-size="4624,1862" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.79&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;EB2103&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1694092271&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.73&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0084033613445378&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="stenmur" data-image-description="" data-image-caption="" data-medium-file="https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=300" data-large-file="https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=500" width="4624" height="1862" src="https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=1024" alt="" srcset="https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=1024 1024w, https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=150 150w, https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=300 300w, https://henrikwarne1.files.wordpress.com/2023/09/stenmur.jpg?w=768 768w" sizes="(max-width: 4624px) 100vw, 4624px"></a></figure>



<p><strong>Self-documenting code.</strong> I used to think that the names of the classes, methods and variables should be enough to understand what the program does. No comments should be needed. Over the years I have realized that some comments are needed and useful. These days I add comments when there is something particularly tricky, either with the implementation, or in the domain. Every time I came back to code where I wrote a comment, I am happy that I took the time to do it. I have written more about this in <a href="https://henrikwarne.com/2021/06/15/on-comments-in-code/">On Comments in Code</a>.  </p>



<p><strong>Unit testing private methods.</strong> I wrote a blog post called <a href="https://henrikwarne.com/2014/02/09/unit-testing-private-methods/">Unit Testing Private Methods</a>, where I argued that you might as well make them package private, so you can easily write tests for them. However, several people commented and argued that you can test the private methods through the public interface. After a bit of thinking, I ended up agreeing with them, and changed my approach.</p>



<p><strong>Using an IDE.</strong> Many years ago, I was using Emacs when writing code. I was quite happy with that, and didn’t particularly feel that anything was lacking. However, one day my colleague Johan showed me what IntelliJ IDEA could do. I was sold, and never looked back. The biggest difference is navigation – it is so much easier to move around in a code base with one. Nowadays, I can’t imagine not using an IDE. I have written more on this in <a href="https://henrikwarne.com/2012/06/17/programmer-productivity-emacs-versus-intellij-idea/">Programmer Productivity: Emacs versus IntelliJ IDEA</a>.</p>



<p><strong>Using a debugger.</strong> I like <a href="https://henrikwarne.com/2014/01/01/finding-bugs-debugger-versus-logging/">trouble shooting using log statements</a> and <em>printf</em>. It is simple and effective, and works in many situations. However, when I started writing Go code several years ago, my colleague Erik showed me how nice it is to explore the state of the program when a test case fails. I had used debuggers before, but he showed me a great use case for them.</p>



<p><strong>Working remotely.</strong> Even during the pandemic, when I was working from home full time, I was <a href="https://henrikwarne.com/2020/06/09/working-from-home-cons-and-pros/">skeptical of working remotely</a>. However, I have changed my mind, and I now think working from home is great. The downside is still that I miss the face-to-face interactions. But working remotely allows me to work for companies I previously could not work for. Not having to commute is a another big plus. On balance, I think the advantages outweigh the disadvantages.</p>



<p><strong>Using ChatGPT.</strong> When ChatGPT came out, I was impressed with what it could do. However,  I was a bit skeptical of exactly how it would work in software development. But my colleague Filip kept telling me of all the cases where he used ChatGPT to help with development. So I decided to put some more effort into seeing how I could use it. For me, the main use has been for minor stand-alone tasks. For example, to generate a first draft of a Python script, to write a <em>SQL INSERT/UPDATE</em> trigger, or giving me a <em>sed</em> regular expression that removes the initial time stamp (when present) from log lines. In all these cases, it has been a great time saver.</p>



<h2>Conclusion</h2>



<p>Am I changing my mind about enough things? I don’t know. But it is definitely worthwhile to once in a while examine your beliefs about how to develop software. In many of the above cases, it took somebody else to show me, or convince me, of other ways of working. My conclusion is that collaboration and pair programming is important for spreading good ideas.</p>



<p>What have you changed your mind about when it comes to software development? Let me know in the comments.</p>




							</div></div>]]></description>
        </item>
    </channel>
</rss>