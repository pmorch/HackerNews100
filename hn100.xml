<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 05 May 2025 17:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Death of Daydreaming: What we lose when phones take away boredom (297 pts)]]></title>
            <link>https://www.afterbabel.com/p/on-the-death-of-daydreaming</link>
            <guid>43894305</guid>
            <pubDate>Mon, 05 May 2025 12:22:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.afterbabel.com/p/on-the-death-of-daydreaming">https://www.afterbabel.com/p/on-the-death-of-daydreaming</a>, See on <a href="https://news.ycombinator.com/item?id=43894305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong>Intro from Jon Haidt:</strong></p><p><span>When I was nearly finished writing </span><em>The Anxious Generation</em><span> in the summer of 2023, I realized that I had left a gap. The book focused on the collapse of mental health, attention, and socialization of Gen Z—but again and again, older readers and friends would tell me: “this is happening to me too.” I realized that the global transition to a phone-based life is transforming </span><em>everyone’s</em><span> consciousness. But how? What exactly is happening to us?</span></p><p><span>I thought back to my first book, </span><em><a href="https://www.happinesshypothesis.com/" rel="">The Happiness Hypothesis</a></em><span>, which explored ten ancient ideas about how to live a good life—ideas found across continents and millennia. I began to see that the phone-based life, and social media in particular, push us to live in ways that are directly contrary to those recommended by nearly every ancient religious and philosophical tradition. These traditions tell us to be </span><em>slow to judge</em><span> and </span><em>quick to forgive</em><span>. They offer practices like meditation to quiet the mind and open the heart to deeper truths and greater communion.</span></p><p><span>In </span><em>The Anxious Generation</em><span>, I explored six of these contradictions in Chapter 8. A simple summary of that chapter is this: the phone-based life diminishes our humanity. Compared to the life we once lived, it degrades us morally, spiritually, socially, and cognitively.</span></p><p><span>Since writing that chapter, I’vebeen on the lookout for others who can express this loss of humanity better than I can. Here’s my short list: L.M. Sacasas for his Substack </span><em><a href="https://theconvivialsociety.substack.com/" rel="">The Convivial Society</a></em><span>; Nicholas Carr, for </span><em><a href="https://www.nicholascarr.com/?page_id=16" rel="">The Shallows</a></em><span> and his more recent book </span><em><a href="https://www.afterbabel.com/p/from-anxiety-to-animosity-how-social" rel="">Superbloom</a></em><span>; and Christine Rosen, for her 2024 book </span><em><a href="https://wwnorton.com/books/9780393241716" rel="">The Extinction of Experience</a><span>.</span></em><span> (For a Gen Z perspective, see </span><a href="https://www.freyaindia.co.uk/" rel="">Freya India</a><span>—especially the post we co-wrote </span><a href="https://www.afterbabel.com/p/degrading-effects-of-life-online" rel="">“On The Degrading Effects of Life Online.”)</a></p><p><span>Today’s post is by Christine Rosen. Christine holds a Ph.D. in history with a focus on American intellectual history. She is </span><a href="https://www.aei.org/profile/christine-rosen/" rel="">a senior fellow at AEI</a><span>, and she was </span><a href="https://www.aei.org/events/the-american-dream-lecture-series-social-media-and-the-fragmentation-of-american-life/" rel="">my discussion partner</a><span> when I gave a talk on </span><em>The Anxious Generation</em><span> at AEI soon after the book launched. That was when I learned about her book project, </span><em><a href="https://wwnorton.com/books/9780393241716" rel="">The Extinction of Experience: Being Human in a Disembodied World.</a></em></p><p>So when her publisher invited me to consider reading an early draft and offering an endorsement, I was glad to say yes. I loved the book, and I hope the blurb I wrote captures its urgency and depth:</p><blockquote><p>Rosen shows us that we are embodied creatures who are rapidly losing the analog world in which our bodies and minds evolved. She shows us that many of the technologically aided advances in convenience and efficiency exact a cost in our humanity, our civility, and ultimately our ability to live together in a democratic society. This is an extremely important book; its message is all the more urgent as AI threatens to make everything effortless and frictionless.</p></blockquote><p><span>I invited Christine to present a section or idea from her book for </span><em>After Babel</em><span>. She chose one of my favorites: the loss of “interstitial time.” Interstices are the gaps between things, as with the cells in your body or the spaces between architectural columns. When applied to time, it means the many bits of time scattered throughout the day such as the five minutes that students have in between classes, or the unknown number of seconds that pass while you are waiting for an elevator. These moments used to be given over to silent reflection or conversation with whoever is around. Now, for most of us, nearly all of them are grabbed by our phones.</span></p><p>Christine traces out the profound consequences of losing those interstitial moments, for our creativity and for our humanity. She shows why it is so important to guard those moments for daydreaming.</p><p><strong>— Jon </strong></p><p><strong>By Christine Rosen</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2140702,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.afterbabel.com/i/162789733?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc045dcff-c182-4cc1-b063-23afb0578a5a_3840x2160.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Source: Shutterstock</figcaption></figure></div><p>Can you remember the last time you daydreamed? Or coped with boredom without reaching for your phone? Before the era of mobile technology, most of us had no choice but to wait without stimulation, and often, that meant being bored.</p><p>But today we need never be bored. We have an indefatigable boredom-killing machine: the smartphone. No matter how brief our wait, the smartphone promises an alleviation for our suffering.</p><p><span>Yet the smartphone’s triumph over boredom might prove a Pyrrhic victory. As Jonathan Haidt showed in </span><em>The Anxious Generation</em><span>, the rapid adoption of smartphones and social media, particularly by the young, led to many negative unintended consequences such as increased rates of depression, anxiety, loneliness, and self-harm. So, too, our efforts to vanquish boredom have had deleterious impacts such as on our ability to let our minds wander, to cultivate patience, and to experience anticipation.</span></p><p>As a member of Generation X, I took boredom for granted. Without access to any kind of mobile technology more sophisticated than a Speak and Spell game, my generation was expected to fill our empty hours in other ways, which usually meant going outside and doing things with our friends. Some kids stayed inside and watched television, of course, but the options for programming were limited. Boredom was part of life, and we accepted and adjusted to this reality. Several decades later, raising my own sons in the age of mobile technology, I saw how quickly expectations had changed for how to spend one’s free time. With access to an iPad or a smartphone, children in the twenty-first century never had to be bored; in fact, everything about the platforms and apps that targeted children habituated them to the idea that they ought never to be bored. I worried about how this might change their expectations and ability to deal with delay, frustration, and empty time as adults.</p><p>Boredom has a purpose. To understand and harness it, we need to give our minds more opportunities to experience it. In the rest of this post, I will explore the many ways our efforts to conquer boredom through technology have produced unintended consequences, including the near-total capture of our attention, the death of daydreaming, and the end of a healthy sense of anticipation in our daily lives.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/on-the-death-of-daydreaming?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/on-the-death-of-daydreaming?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>“Shepherds do it, cops do it, stevedores and merchants in their shops do it,” technology critic Marshall McLuhan </span><a href="https://mitpress.mit.edu/9780262631594/understanding-media/" rel="">observed</a><span> in </span><em>Understanding Media </em><span>when discussing Greek men’s use of komboloi, or worry beads. The beads, which look like amber-­colored rosaries, were used throughout the day to pass the time, a secular version of praying the rosary. Their use of worry beads also reflects the deeply felt human need to fill interstitial time. We all engage in these weird little rituals: Some people doodle or fidget, others knit, a lot of people used to smoke. The late Psychologist Mihaly Csikszentmihalyi </span><a href="https://www.amazon.com/Flow-Classic-Achieve-Happiness-Introduction/dp/0712657592" rel="">called</a><span> these “the ‘microflow’ activities that help us negotiate the doldrums of the day.” These “small automatic games woven into the fabric of everyday life help reduce boredom … but add little to the positive quality of experience.”</span></p><p>Though the experience of boredom is deeply human, what we reach for when we experience it is socially structured, unique to our moment in time. The worry beads and cigarettes of previous eras have given way to smartphones. Ours is a less carcinogenic but more commodified distraction, with long-term impacts which we’re only beginning to fathom.</p><p><a href="https://www.pewresearch.org/internet/2024/03/11/how-teens-and-parents-approach-screen-time/" rel="">According to</a><span> Pew Research, nine out of ten Americans own a smartphone, and 95 percent of teenagers have access to one. A 2024 Pew survey of teens ages 13-17 found that half said they were online “almost constantly.” The average person spends the vast majority of his or her free moments looking at a screen. For decades, Americans have spent a considerable amount of their leisure time watching television; what has declined significantly is the amount of free time they spend with other people. One recent </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9811250/" rel="">study</a><span> found an increase in social isolation and significant declines in social engagement with family and friends as well as shared leisure time. We spend more of our free time alone, staring at screens, which habituates us to reach for our phones whenever we have a moment alone to ourselves. Screens have become the dominant means for us to alleviate boredom, whether during long stretches of time alone or in fleeting moments throughout the day.</span></p><p><span>This is not just a challenge for the young. Pew Research </span><a href="https://www.pewresearch.org/short-reads/2019/06/18/americans-60-and-older-are-spending-more-time-in-front-of-their-screens-than-a-decade-ago/" rel="">found </a><span>that Americans over the age of sixty “now spend more than half of their daily leisure time. . . in front of screens.”</span></p><p>Lately I’ve seen more people in their cars thwarting stoplight boredom—­that is, unable to sit unmediated for even the few moments that it takes a red light to turn green, they reach for their smartphones. Kids post on social media about boredom throughout the school day (#bored). The space between the time when they experience boredom and when they broadcast it has disappeared.</p><p><span>What happens when we replace boredom with constant distraction and stimulation? Warnings about the harmful effects of too much stimulation are nothing new. “For a living organism, protection against stimuli is an almost more important function than the reception of stimuli,” Sigmund Freud </span><a href="https://www.sas.upenn.edu/~cavitch/pdf-library/Freud_Beyond_P_P.pdf" rel="">observed</a><span>. But given the range and speed of stimuli at our disposal, we might need a new way of thinking about their effects. Stimulation seems too quaint a word.</span></p><p>It is a reasonable human impulse to seek distraction from the uncomfortable experience of boredom. What is new about our present moment is that the method we have chosen to alleviate boredom in the short term has negative long-term impacts on our attention spans and our ability to practice patience. We have created a machine for stimulation far beyond anything imaginable in Freud’s time. We might believe that our attempts to fill our interstitial time with mediated distractions qualify as an effort to optimize our experiences under less-than-optimal conditions. But in fact, we have become more like gambling addicts, habituated to the temporary escape our digital technologies provide.</p><p><span>A fascinating </span><a href="https://press.princeton.edu/books/paperback/9780691160887/addiction-by-design" rel="">study</a><span> of machine gambling in Las Vegas notes that “flow,” that state of being in which someone is so involved in an activity “that nothing else seems to matter,” as Csikszentmihalyi describes it, is precisely the state gamblers seek and attain at the machines, and precisely what machine designers seek to exploit when people initiate play. Yet, while gamblers are experiencing flow, they are not having the kind of optimal long-­term experiences psychologists had in mind when they advocated pursuing activities that put you “in the zone.”</span></p><p>In a less intense way, we all enter this less-than-optimal state when we turn to our devices to alleviate the experience of boredom. The distractions we seek don’t only consume our time, however. They also degrade many habits of mind that require time and patience to form, such as empathy, awareness, and emotional regulation.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/on-the-death-of-daydreaming/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/on-the-death-of-daydreaming/comments" rel=""><span>Leave a comment</span></a></p><p><span>In a </span><a href="https://lettersofnote.com/2012/03/06/1984-v-brave-new-world/" rel="">letter</a><span> Aldous Huxley wrote to George Orwell in 1949 he argued, “I feel that the nightmare of 1984 is destined to modulate into the nightmare of a world having more resemblance to that which I imagined in Brave New World.” What did Huxley believe would bring about this dystopia? Not a global world order or a charismatic despot: “The change will be brought about as a result of a felt need for increased efficiency.”</span></p><p>Huxley’s warning has merit. We enjoy the efficiencies and distractions technology brings, but they leave us less skilled at patience. They teach us to value efficiency above all and to be suspicious of idle time, when we should see idle moments as opportunities for reflection and renewal.</p><p>Today you rarely see the word “idle” except when used as a pejorative; to be idle is to be wasteful, and several of the most popular Internet startup companies have targeted underutilized resources such as idle cars (Turo, ZipCar), household equipment (SnapGoods), or empty bedrooms (Airbnb), allowing people to make use of them by renting them out when they aren’t in use.</p><p><span>Some technologists have set their sights higher. Max Levchin, a cofounder of PayPal and investor in many Silicon Valley technology companies, gave a </span><a href="https://max.levch.in/post/41116802381/dld13-keynote" rel="">speech</a><span> at a conference in Munich in which he lamented, “The world of real things is very inefficient.” Harnessing the network effects of big data, he foresees a future where we can more efficiently do many things: “We will definitely see dynamically priced queues for confession-­taking priests and therapists,” he said.</span></p><p><span>Moments of idleness and daydreaming used to be prized for the unexpected pleasure they brought. As Wordsworth </span><a href="https://www.penguinrandomhouse.com/books/295450/selected-poems-by-william-wordsworth-edited-with-an-introduction-and-notes-by-stephen-gill/" rel="">wrote</a><span>, “For this one day we’ll give to idleness . . . One moment now may give us more than fifty hours of reason.” He advocated straying about “voluptuously” through rural fields, asking “no record of the hours given up to vacant musing.” We might not spend our free time lolling about rural glens, but idleness of this variety is the opposite of the instrumental, practical use that our culture encourages us to make of our time. Technologists like Levchin would have us hire out our voluptuous spare time on TaskRabbit. To borrow an image from Wordsworth’s rural fields, we should embrace this fallow time. To be fallow is not the same thing as to be useless; it is to let rest so that cultivation can occur in the future. When mediated experiences co-opt our idle time, we are left with fewer and fewer of these fallow moments, moments that are central to the experience of being human.</span></p><p>With rates of anxiety rising in the U.S., particularly among teens, it is also worth considering how the frenetic pace of the online world, where so many of us spend so much of our time, contributes to our sense of feeling overwhelmed and out of control. Reclaiming our idle time and reorienting ourselves away from screens is one of many small yet radical acts that have the potential to improve the quality of our daily experiences.</p><p><span>A culture without boredom, focused on efficiency, also undermines the act of daydreaming, another thing interstitial time used to be given over to. Daydreaming seems a fusty term in an age when productivity and usefulness are prized. But as psychologists and neurologists have found, a wandering mind––often the first signal of impending boredom––is also a creative mind. In the 1960s, psychologist Jerome Singer, the grandfather of daydreaming studies, </span><a href="https://archive.org/details/innerworldofdayd00samu" rel="">identified</a><span> three kinds of mind-­wandering: the productive, creative “positive constructive daydreaming,” obsessive “guilty–­dysphoric daydreaming,” and “poor attentional control.” Singer believed daydreaming was a positive adaptive behavior—­a bold departure from the conventional wisdom at the time, which linked daydreaming to other psychopathologies such as excessive fantasizing. As one student of Singer’s </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3779797/" rel="">noted</a><span>, Singer’s work found strong associations between daydreaming and the personality trait “openness to experience,” which demonstrates sensitivity, curiosity, and willingness to explore new ideas and feelings.</span></p><p><span>Since then, researchers have found numerous positive effects of a wandering mind. Psychologist Scott Barry Kaufman </span><a href="https://www.scientificamerican.com/blog/beautiful-minds/mind-wandering-a-new-personal-intelligence-perspective/" rel="">summarized</a><span> them:</span></p><blockquote><p>“self-awareness, creative incubation, improvisation and evaluation, memory consolidation, autobiographical planning, goal driven thought, future planning, retrieval of deeply personal memories, reflective consideration of the meaning of events and experiences, simulating the perspective of another person, evaluating the implications of self and others’ emotional reactions, moral reasoning, and reflective compassion.”</p></blockquote><p><span>Daydreaming is also a prompt to memory. As Stefan Van der Stigchel </span><a href="https://mitpress.mit.edu/9780262538565/concentration/" rel="">argues</a><span> in </span><em>Concentration: Staying Focused in Times of Distraction</em><span>, “When you are daydreaming (or </span><em>mind-wandering</em><span>, as it is referred to within scientific circles), memories that you thought were lost forever can come to the surface again.” He adds, “The neural activity that can be observed when you are daydreaming is very similar to that found in the ‘default network,’ a network of regions in the brain that are active during periods of rest.”</span></p><p><span>It can be a challenge to find those periods of rest throughout our day, and when we do, if we are habituated to the stimulation technology provides, it is difficult to quiet our minds. As Moshe Bar </span><a href="https://www.amazon.com/Mindwandering-Constant-Mental-Improve-Creativity/dp/0306925303" rel="">argues</a><span> in </span><em>Mindwandering</em><span>, “the greater challenge is freeing ourselves from the distractions within, which disrupt our attention and intrude on the quality of our experience even when we are in a perfectly quiet place." In other words: we must cultivate habits that allow for mindwandering and daydreaming. We must, every day, try to reclaim the time that technology has colonized.</span></p><p>Why? Anecdotally, history provides many examples of scientific breakthroughs—­“aha!” moments—­that arose during moments of daydreaming or downtime: René Descartes in bed staring at a fly on the ceiling and coming up with coordinate geometry; Albert Einstein’s glimpse of the Bern tower on a streetcar ride prompting the theory of special relativity; the walk in the woods that prompted Nikola Tesla to devise alternating electrical current.</p><p><span>Unstructured, unmediated time is especially important for the development of creativity in children. “In the space between anxiety and boredom was where creativity flourished,” </span><a href="https://www.amazon.com/Mindwandering-Constant-Mental-Improve-Creativity/dp/0306925303" rel="">wrote</a><span> Po Bronson and Ashley Merryman in their examination of declining scores on the Torrance Test for creativity among American children. They hypothesize that one of the reasons creativity scores might be declining is children’s increased use of screen-­based technologies during downtime. Rather than being left to their own imaginative devices, their wandering minds are often captured by devices—­smartphones and other screens that grasp their attention and, in the process, prevent all other possible uses of those moments of idle time.</span></p><p>Now that we have so many ways to fill even the smallest fragments of time, a subtle shift in our psychology of expectation also follows. We are more likely to experience waiting as an unpleasant delay rather than as anticipation. Waiting has become a problem to be solved, rather than a normal human experience. When we are accustomed to easily filling time, opportunities for anticipation, like opportunities for daydreaming, disappear.</p><p><span>Anticipation is a kind of preparation for the future. Actively embracing anticipation is also important for one’s emotional health. Neuroscientist Antonio Damasio </span><a href="https://www.amazon.com/Descartes-Error-Emotion-Reason-Human/dp/014303622X" rel="">calls</a><span> this practice the “imagination response,” and in many ways it resembles daydreaming in its power to prepare the mind for new experiences. Damasio describes an unusual patient, Elliot, who could rationally think through positive and negative likely outcomes for his behavior and could experience happiness or disappointment once something happened to him. What Elliot couldn’t do was imagine or preview those future feelings. Without a functioning imagination response, he could think about the future rationally, but he couldn’t feel it emotionally. As a result, he was usually indecisive and impulsive, which caused him unhappiness.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/on-the-death-of-daydreaming?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/on-the-death-of-daydreaming?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>Does it matter if we no longer tolerate boredom, let our minds wander, cultivate a sense of anticipation, and practice patience? Our demand for immediate answers is voracious, and not entirely a bad thing. It drives innovation and commerce and has allowed for communication on a scale barely imaginable a century ago. But living a full meaningful human life means coping with the liminal, those in-­between moments of life when we must endure uneasy or uncomfortable experiences, from boredom during a meeting to bearing witness to another’s illness, to simply being stuck on a bus. In everyday life, we can all try, however modestly, to shift our individual perceptions and behavior by embracing a more generous sense of anticipation and a healthier attitude about delay, by reframing waiting as an opportunity for daydreaming and idle time rather than an excuse for distraction, and by trying to be more patient with one another. Such advice does at least have a long pedigree. Aristotle is said to have warned, “Patience is bitter, but its fruit is sweet.”</p><p>Parents have a crucial role to play in teaching children how to deal with boredom, and it can be as easy and as old-school as simply telling them: “Go outside and play.” Instead of handing a child a slot machine of distraction, encourage them to come up with their own game or activity. Rather than structuring and organizing an activity for your children, let them figure that out for themselves, or with their peers. Children are extraordinarily creative when given the space and time to indulge their wandering minds, but this often requires first overcoming the immediate challenge of handling their frustration and boredom. Placing the burden of alleviating one’s boredom back on a child isn’t a punishment; it’s an opportunity for them to find creative solutions to their discomfort and, as they mature into adults, to identify and cope with feelings of frustration.</p><p>As well, parents should model better behavior by resisting the temptation to pick up our phones whenever we are bored. Try this experiment: For one day, do not pick up your smartphone during small breaks in your routine, such as waiting for the train, or sitting in your car at a stoplight. If you find yourself in a doctor’s waiting room, or waiting for a friend at a restaurant, don’t pick up your phone to fill those few minutes. Pay attention to what is around you, or let your mind wander. This sounds like a simple experiment, but as someone who repeatedly tries and often fails to do this, it is revealing of our own bad habits and a useful prompt for thinking more critically about how we spend our time. Reaching for the phone every time is the easy fix, but it is one that has damaging long-term consequences for individuals and for society.</p><p>In other words: a bit of boredom is good for us, so the next time you have a minute to spare, instead of reaching for your phone, be rebellious: Daydream.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS Built a Security Tool. It Introduced a Security Risk (155 pts)]]></title>
            <link>https://www.token.security/blog/aws-built-a-security-tool-it-introduced-a-security-risk</link>
            <guid>43893906</guid>
            <pubDate>Mon, 05 May 2025 11:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.token.security/blog/aws-built-a-security-tool-it-introduced-a-security-risk">https://www.token.security/blog/aws-built-a-security-tool-it-introduced-a-security-risk</a>, See on <a href="https://news.ycombinator.com/item?id=43893906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div fs-richtext-element="rich-text"><p><em>(If you missed the previous parts of this trust policy blog series, we recommend reading parts </em><a href="https://www.token.security/blog/iam-role-trust-policies-misconfigurations-hiding-in-plain-sight" target="_blank"><em>one</em></a><em> and </em><a href="https://www.token.security/blog/secure-cross-account-access-is-tricky-four-common-dangerous-misconceptions" target="_blank"><em>two</em></a><em> first)</em></p><p>In the previous post of this series, we explored four dangerous misconceptions regarding how to securely set up cross-account access in AWS environments.</p><p>In this final post of the series, we’ll walk through a real-world case where even AWS got it wrong. Their <em>Account Assessment for AWS Organizations</em> tool, designed to audit resource-based policies for risky cross-account access, ironically introduced cross-account privilege escalation risks due to flawed deployment instructions. Specifically, customers were effectively encouraged to deploy the tool in lower-sensitivity accounts, creating risky trust paths from insecure environments into highly sensitive ones.</p><p>We’ll share how we discovered the issue, the risks it introduced, how AWS fixed it, and what affected organizations should do to detect and remediate it.</p><h3>How it started</h3><p>While investigating a critical privilege escalation risk involving an IAM role in a customer’s AWS environment, we discovered a role present in both their production and management accounts, each of which trusted two roles in their development account:</p><figure><p><img src="https://cdn.prod.website-files.com/661a822ae40a7d51ecf449bc/680f4186cc6df42ec59bed95_blog3_image1.png" loading="lazy" alt=""></p><figcaption>The risky IAM role we investigated</figcaption></figure><p>These were the details of the privilege escalation risk (sensitive info redacted):</p><figure><p><img src="https://cdn.prod.website-files.com/661a822ae40a7d51ecf449bc/680f41b07a9e8cd78c0a74ed_blog3_image2.png" loading="lazy" alt=""></p></figure><p>Examining the permissions of that role in the production and management accounts, we found it had access to several sensitive IAM and data-related API calls, including:</p><ul role="list"><li><code>iam:ListRoles</code> (lists all IAM roles, helping an attacker identify privileged and vulnerable roles)</li><li><code>iam:ListPolicies</code> (reveals all IAM policies, exposing potential misconfigurations)</li><li><code>secretsmanager:ListSecrets</code> (lists all stored secret names, identifying potential targets)</li><li><code>s3:ListAllMyBuckets</code> (enumerates all S3 buckets, exposing potential sensitive data locations)</li><li><code>kms:ListKeys</code> (lists all encryption keys, indicating what is being encrypted)</li><li><code>kms:GetKeyPolicy</code> (retrieves key policies, which could reveal weak or misconfigured access controls)</li><li>… and more (full policy <a href="https://github.com/aws-solutions/account-assessment-for-aws-organizations/blob/eb194bd76d87481c2bc682b7f03321342c5b3cd3/source/infra/lib/account-assessment-spoke-stack.ts#L57" target="_blank">here</a>)</li></ul><p>These permissions were granted on all resources (<code>resource: "*"</code>), making them particularly dangerous if compromised.</p><p>The organization's dev account had weaker security, making this role assumption path a major risk. An attacker compromising a trusted role in dev could immediately gain these permissions in production and management. Combined with other misconfigurations - such as exposed IAM roles, secret names, KMS keys, or public S3 buckets - this could help lead to compromise of the organization's most sensitive accounts.</p><p>This was already a serious risk, but what we found next revealed that this misconfiguration was not unique to this organization - it was actually inadvertently encouraged by AWS itself.</p><h3>Account Assessment for AWS Organizations</h3><p>The names of these roles were somewhat quirky, and hinted they were part of some automated system. A quick search led us to <a href="https://aws.amazon.com/solutions/implementations/account-assessment-for-aws-organizations/" target="_blank">Account Assessment for AWS Organizations</a>, a tool developed by AWS and published in the <a href="https://aws.amazon.com/solutions/" target="_blank">AWS Solutions Library</a>.</p><p>According to its official documentation, the tool is designed to “centrally evaluate and manage AWS accounts within your AWS Organizations”, helping users better understand account dependencies. AWS lists its <a href="https://docs.aws.amazon.com/solutions/latest/account-assessment-for-aws-organizations/use-cases.html" target="_blank">primary use cases</a> as mergers and acquisitions, security audits, centralized policy explorer and management account transitions.</p><p><strong>So, why was it deployed insecurely?</strong></p><p>Given that this tool was built by AWS to audit resource-based cross-account access, we initially assumed the misconfiguration was a deployment error by the customer. However, after reviewing the documentation, we realized that AWS’s deployment instructions unintentionally encouraged insecure setups, making it highly likely that users would deploy the tool in a way that introduced privilege escalation risks.</p><p>The tool follows a hub-and-spoke architecture:</p><ul role="list"><li>A hub role is deployed in a designated hub account.</li><li>Spoke roles are deployed in all other accounts to be assessed, trusting the hub role for access.</li></ul><p>This design allows the hub role to assume the spoke roles across all accounts, aggregating security data across the organization.</p><figure><p><img src="https://cdn.prod.website-files.com/661a822ae40a7d51ecf449bc/680f41d9677b48b093129595_blog3_diag1.drawio%20(7).png" loading="lazy" alt=""></p></figure><p>When checking AWS's official deployment guidance, we were surprised to see the following instruction:</p><figure><p><img src="https://cdn.prod.website-files.com/661a822ae40a7d51ecf449bc/680f41f4791d880da8a99880_image%20(12).png" loading="lazy" alt=""></p></figure><p>"Hub stack - Deploy to any member account in your AWS Organization except the Organizations management account."</p><p>This is the root cause of the issue - AWS explicitly recommended not deploying the hub in the management account, without clarifying the security implications of the other possible choices.</p><h3><strong>Why this is a major security risk</strong></h3><p>Let’s back up a bit and explain why this instruction, without any clarification, was so problematic.</p><p>As we covered in the <a href="https://www.token.security/blog/secure-cross-account-access-is-tricky-four-common-dangerous-misconceptions" target="_blank">previous blog</a>, allowing a role in a less secure account to assume roles in more sensitive accounts creates a privilege escalation risk.</p><p>By design, the hub role must access all spoke accounts. Since AWS prohibited using the management account as the hub, customers were forced to deploy the hub in a less secure account - often a development, sandbox, or similarly low-sensitivity account. In deployed organizations, this led to the creation of a direct trust path from a lower-security account to higher-security accounts like production, PCI-DSS environments, and even the management account itself.</p><p>The following diagram visualizes the problem:</p><figure><p><img src="https://cdn.prod.website-files.com/661a822ae40a7d51ecf449bc/680f420f57a0fb21afc19cd2_blog3_diag2.drawio%20(3).png" loading="lazy" alt=""></p></figure><p>In the case we investigated, the customer deployed the hub role in their development account, which:</p><ol role="list"><li>(Reasonably) had weaker security controls than production or management.</li><li>Had full access to assume spoke roles across all accounts, including sensitive ones such as the management and production accounts</li></ol><p>This meant that if an attacker compromised the development account, they could pivot into the management account - make it much easier to gain control over the entire AWS organization.</p><p>AWS strongly advises against running workloads in the management account, so simply deploying the hub there is not an ideal solution either. Instead, the only relatively safe option is to choose an account <strong>which is as secure</strong> as the management account, such as a centralized DevOps or Infrastructure account with strict access controls.</p><p>However, some organizations don’t necessarily have such an account, meaning any deployment inherently introduces risk. The problem isn't just where to deploy the hub - it's that AWS's default recommendation pushed organizations into an insecure setup without any reference to the security implications of this choice.</p><h3>Implications for affected organizations</h3><p>Any organization that deployed this tool following AWS’s instructions (before they were fixed on 2025-01-28) with the hub role deployed in an account less secure than the management account - and hasn’t removed it - is at risk.</p><p>For affected orgs, the hub account (where the hub role is deployed) becomes a high-value target. If an attacker compromises this role, whether through direct access or privilege escalation, they can assume spoke roles across all linked accounts - including highly sensitive environments such as management and production.</p><p>Once inside, they can:</p><ul role="list"><li>Enumerate IAM roles, trust policies, and permissions, identifying weak points.</li><li>List all S3 buckets and secret names, mapping out valuable data targets.</li><li>Access KMS key policies, which may reveal misconfigured encryption controls.</li></ul><p>Additionally, the tool’s <a href="https://github.com/aws-solutions/account-assessment-for-aws-organizations/blob/b429bbf2f31dc2f813e903751b8acc5aa3d240ad/source/lib/components/resource-based-policy-component.ts#L10" target="_blank">predefined role names</a> make it even easier for attackers to exploit. If an attacker gains access to any AWS account within an affected organization, they can easily identify whether the tool is deployed and know the exact role names that can be assumed from the hub account. This reduces the effort needed to escalate privileges and pivot into high-value environments.</p><h3>Detecting and remediating</h3><p>Here are two methods to determine if your organization is affected:</p><ul role="list"><li>Use the AWS Console to manually search the IAM role page in any suspected accounts for the hub and spoke roles. These roles contain the strings <code>ScanSpokeResource</code> and <code>AccountAssessment-Spoke-ExecutionRole</code> in their names accordingly.</li><li>Run the following AWS CLI command to check if the tool is deployed in a given account: <code>aws iam list-roles --query "Roles[?contains(RoleName, 'ScanSpokeResource') || contains(RoleName, 'AccountAssessment-Spoke-ExecutionRole')]"</code></li></ul><p><strong>If the tool is deployed -</strong> Check to see when the tool was deployed by examining the roles’ <code>CreateDate</code> property. If deployed before 2025-01-28, we strongly recommend removing the current deployment unless the hub role is already in a high-security account (such as a dedicated Infrastructure or DevOps account).</p><ol role="list"><li>Uninstall the tool by deleting the CloudFormation stacks for the Hub, Spoke, and Org-Management components. See AWS’s <a href="https://docs.aws.amazon.com/solutions/latest/account-assessment-for-aws-organizations/uninstall-the-solution.html" target="_blank">official uninstallation guide</a> for more instructions.</li><li>Redeploy carefully - if the tool is still needed, deploy the hub role in an account with security equivalent to the management account to prevent privilege escalation risks.</li></ol><h3>Reporting and resolution</h3><p>After identifying this issue, we reported it to AWS Security, highlighting the serious risks created by the tool’s deployment guidance. AWS promptly reviewed our findings, acknowledged the security concern, and engaged with us to determine how best to update the documentation to prevent future misconfigurations.</p><p>Based on this engagement, AWS revised the <a href="https://docs.aws.amazon.com/solutions/latest/account-assessment-for-aws-organizations/aws-accounts.html" target="_blank">documentation</a> to explicitly advise customers to deploy the hub role in a high-security account to match the sensitivity of the accounts being assessed:</p><figure><p><img src="https://cdn.prod.website-files.com/661a822ae40a7d51ecf449bc/680f4228ed41b221c8281a94_image%20(13).png" loading="lazy" alt=""></p><figcaption>Updated documentation page, explicitly instructing to deploy the hub in an account as secure as all scanned accounts</figcaption></figure><p>‍</p><p>We thank the AWS Security team, who were highly responsive, open to feedback, and committed to improving customer security. They took the issue seriously from the start, worked with us to determine the best way to update the documentation, and delivered a clear and effective fix - ensuring organizations deploying this tool can avoid unintended privilege escalation risks in the future.</p><h3><strong>Reporting timeline</strong></h3><ul role="list"><li><strong>2024-12-11</strong> - Discovery of the problematic documentation.</li><li><strong>2024-12-12</strong> - Initial report to AWS Security.</li><li><strong>2025-01-02</strong> - AWS acknowledges the issue and begins considering documentation changes.</li><li><strong>2025-01-05</strong> - We emphasize the importance of correcting the instructions.</li><li><strong>2025-01-07</strong> - AWS confirms documentation updates are needed.</li><li><strong>2025-01-13 - 2025-01-17 -</strong> Discussion on how to revise the documentation.</li><li><strong>2025-01-28</strong> - AWS publishes updated documentation with security fixes.</li><li><strong>2025-04-28</strong> - Findings and resolution publicly shared in this blog post.</li></ul><h3>Wrapping up</h3><p>Throughout this blog series, we explored how trust policy risks can slip into even well-managed AWS environments - sometimes through overlooked technical details, subtle misconceptions, or even official tooling. Securing trust relationships is less about following a checklist and more about developing a deeper understanding of how trust mechanisms actually behave in real-world environments.</p><p>We hope this series helped shed light on some of the hidden challenges around trust policies. Thanks for reading!</p><p>‍</p><p>‍</p><p><em>Token Security's machine-first identity security platform detects trust policy risks, including risky cross-account trust policies, whether caused by AWS tooling, human error, or overlooked configurations.</em></p><p><em>Want to see how it works? </em><a href="https://www.token.security/book-a-demo"><strong><em>Book a demo</em></strong></a><em> and let us show you how we help organizations stay ahead of these risks.</em></p><p>‍</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge said Meta illegally used books to build its AI (294 pts)]]></title>
            <link>https://www.wired.com/story/meta-lawsuit-copyright-hearing-artificial-intelligence/</link>
            <guid>43893762</guid>
            <pubDate>Mon, 05 May 2025 11:16:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/meta-lawsuit-copyright-hearing-artificial-intelligence/">https://www.wired.com/story/meta-lawsuit-copyright-hearing-artificial-intelligence/</a>, See on <a href="https://news.ycombinator.com/item?id=43893762">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure></figure><p><span>Meta’s </span><a href="https://www.wired.com/story/matthew-butterick-ai-copyright-lawsuits-openai-meta/">copyright battle</a> with a group of authors, including Sarah Silverman and Ta-Nehisi Coates, will turn on the question of whether the company’s AI tools produce works that can cannibalize the authors’ book sales.</p><p>US District Court Judge Vince Chhabria spent several hours grilling lawyers from both sides after they each filed motions for partial summary judgment, meaning they want Chhabria to rule on specific issues of the case rather than leaving each one to be decided at trial. The authors allege that Meta illegally used their work to build its generative AI tools, emphasizing that the company pirated their books through “shadow libraries” like LibGen. The social media giant is not denying that it used the work or that <a href="https://www.wired.com/story/new-documents-unredacted-meta-copyright-ai-lawsuit/">it downloaded books from shadow libraries</a> en masse, but insists that <a href="https://www.wired.com/story/battle-over-books3/">its behavior is shielded</a> by the “fair use” doctrine, an exception in US copyright law that allows for permissionless use of copyrighted work in certain cases, including parody, teaching, and news reporting.</p><p>If Chhabria grants either motion, he’ll issue a ruling before the case goes to trial—and likely set an important precedent shaping how courts deal with generative AI copyright cases moving forward. <em>Kadrey v. Meta</em> is one of the <a href="https://www.wired.com/story/ai-copyright-case-tracker/">dozens of lawsuits</a> filed against AI companies that are winding through the US legal system.</p><p>While the authors were heavily focused on the piracy element of the case, Chhabria spoke emphatically about his belief that the big question is whether Meta’s AI tools will hurt book sales and otherwise cause the authors to lose money. “If you are dramatically changing, you might even say obliterating, the market for that person's work, and you're saying that you don't even have to pay a license to that person to use their work to create the product that's destroying the market for their work—I just don't understand how that can be fair use,” he told Meta lawyer Kannon Shanmugam. (Shanmugam responded that the suggested effect was “just speculation.”)</p><p>Chhabria and Shanmugam went on to debate whether Taylor Swift would be harmed if her music was fed into an AI tool that then created billions of robotic knockoffs. Chhabria questioned how this would impact less-established songwriters. “What about the next Taylor Swift?” he asked, arguing that a “relatively unknown artist” whose work was ingested by Meta would likely have their career hampered if the model produced “a billion pop songs” in their style.</p><p>At times, it sounded like the case was the authors’ to lose, with Chhabria noting that Meta was “destined to fail” if the plaintiffs could prove that Meta’s tools created similar works that cratered how much money they could make from their work. But Chhabria also stressed that he was unconvinced the authors would be able to show the necessary evidence. When he turned to the authors’ legal team, led by high-profile attorney David Boies, Chhabria repeatedly asked whether the plaintiffs could actually substantiate accusations that Meta’s AI tools were likely to hurt their commercial prospects. “It seems like you’re asking me to speculate that the market for Sarah Silverman’s memoir will be affected,” he told Boies. “It’s not obvious to me that is the case.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>When defendants invoke the fair use doctrine, the burden of proof shifts to them to demonstrate that their use of copyrighted works is legal. Boies stressed this point during the hearing, but Chhabria remained skeptical that the authors’ legal team would be able to successfully argue that Meta could plausibly crater their sales. He also appeared lukewarm about whether Meta’s decision to download books from places like LibGen was as central to the fair use issue as the plaintiffs argued it was. “It seems kind of messed up,” he said. “The question, as the courts tell us over and over again, is not whether something is messed up but whether it’s copyright infringement.”</p><p>A ruling in the <em>Kadrey</em> case could play a pivotal role in the outcomes of the ongoing legal battles over generative AI and copyright. Earlier this spring, a judge <a href="https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit/">issued a partial summary judgment</a> in the first AI copyright case, <em>Thomson Reuters v. Ross</em>, siding with the publishing conglomerate Thomson Reuters in its fight against AI startup Ross Intelligence. While the ruling was important, that case was an outlier in several ways—including the fact that it didn’t involve generative AI tools like large language models.</p><p>The outcome of the Kadrey case is being closely watched—in part because it could shake up Silicon Valley. It will certainly have a major impact on Meta, whether it helps entrench the company’s generative AI strategy or forces a significant shift. CEO Mark Zuckerberg emphasized how central AI is to Meta’s present and future in an earnings call on Wednesday. “Everything that I've talked about today is built on top of our AI models and infrastructure,” he <a data-offer-url="https://www.facebook.com/zuck/posts/pfbid02XLbq8Sr6S1Y3QfvLZ1U161qf98Kn1en6Q5TwzwKTzHZ4PtoHU5p83xCYzRjHfcwfl" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.facebook.com/zuck/posts/pfbid02XLbq8Sr6S1Y3QfvLZ1U161qf98Kn1en6Q5TwzwKTzHZ4PtoHU5p83xCYzRjHfcwfl&quot;}" href="https://www.facebook.com/zuck/posts/pfbid02XLbq8Sr6S1Y3QfvLZ1U161qf98Kn1en6Q5TwzwKTzHZ4PtoHU5p83xCYzRjHfcwfl" rel="nofollow noopener" target="_blank">said</a>.</p><p>Chhabria has acknowledged how consequential the case is and how his decisions from the bench could upend whole sectors of tech and culture. “I will issue a ruling later today,” Chhabria said at the hearing’s end. “Just kidding! I will take a lot longer to think about it.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The vocal effects of Daft Punk (260 pts)]]></title>
            <link>https://bjango.com/articles/daftpunkvocaleffects/</link>
            <guid>43893601</guid>
            <pubDate>Mon, 05 May 2025 10:48:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bjango.com/articles/daftpunkvocaleffects/">https://bjango.com/articles/daftpunkvocaleffects/</a>, See on <a href="https://news.ycombinator.com/item?id=43893601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="articlecontainer">
	<article>
		
		<p>Daft Punk have used a wide variety of vocal effects in their songs. A May 2001 interview in Remix magazine provided a rare insight from Daft Punk themselves on the topic.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/daft-punk-3.jpg" alt="A photo of Daft Punk in a field on a sunny day."></p>
<blockquote>
<p><a href="https://web.archive.org/web/20060103075925/http://remixmag.com/mag/remix_robopop/">“People always ask us what vocoder we use, but every one of our vocal tracks uses a different vocoder effect. We have the old Roland one [an SVC-350], Auto-Tune, and a DigiTech Vocalist.”</a></p></blockquote>
<p>The quote delivers some vital clues, but it’s incomplete, covering only their first two albums. There’s no mention of using a talk box, despite Around The World almost certainly using one. The quote makes it sound like the DigiTech Vocalist is a vocoder, but it’s not. And for that matter, which DigiTech Vocalist model? There’s around 30 pieces of hardware in DigiTech’s Vocalist series, and quite a few of them were around before Discovery’s release in 2001.</p>
<p>I’ve read comments suggesting the DigiTech Vocalist models with the “EX” suffix are special, but nobody seems to know why, and nobody has published a direct comparison to prove or disprove the theory. I decided to take on the challenge, and run the tests myself. Here’s a fraction of the Vocalist units I ended up buying.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/digitech-vocalist-family.jpg" alt="A photo of lots of DigiTech Vocalist models."></p>
<p>Why are there duplicates of the same model? Why is there a Korg ih in that photo? Before this article gets sidetracked with tests and some honestly quite interesting corporate partnerships, mergers, and lawsuits, here is a list of every Daft Punk album song containing robot-like vocal effects, and my guess on which piece of kit was used for the vocals.</p>
<table>
  <thead>
      <tr>
          <th>Album</th>
          <th>Song</th>
          <th>Effects</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Homework</td>
          <td>WDPK 83.7 FM</td>
          <td>Roland SVC-350</td>
      </tr>
      <tr>
          <td>Homework</td>
          <td>Around The World</td>
          <td>Talk box</td>
      </tr>
      <tr>
          <td>Homework</td>
          <td>Teachers</td>
          <td>Ensoniq DP/4+</td>
      </tr>
      <tr>
          <td>Homework</td>
          <td>Oh Yeah</td>
          <td>Ensoniq DP/4+</td>
      </tr>
      <tr>
          <td>Discovery</td>
          <td>One More Time</td>
          <td>Auto-Tune</td>
      </tr>
      <tr>
          <td>Discovery</td>
          <td>Digital Love</td>
          <td>DigiTech Vocalist</td>
      </tr>
      <tr>
          <td>Discovery</td>
          <td>Harder, Better, Faster, Stronger</td>
          <td>DigiTech Talker</td>
      </tr>
      <tr>
          <td>Discovery</td>
          <td>Something About Us</td>
          <td>DigiTech Vocalist</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>Human After All</td>
          <td>DigiTech Talker</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>The Prime Time Of Your Life</td>
          <td>DigiTech Talker</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>Robot Rock</td>
          <td>DigiTech Talker</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>The Brainwasher</td>
          <td>Tremolo</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>Television Rules The Nation</td>
          <td>DigiTech Talker</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>Technologic</td>
          <td>Ensoniq DP/4+</td>
      </tr>
      <tr>
          <td>Human After All</td>
          <td>Emotion</td>
          <td>Roland SVC-350</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Give Life Back To Music</td>
          <td>Sennheiser VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>The Game Of Love</td>
          <td>Sennheiser VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Within</td>
          <td>Sennheiser VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Instant Crush</td>
          <td>Auto-Tune and VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Lose Yourself To Dance</td>
          <td>Talker and VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Touch</td>
          <td>Sennheiser VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Get Lucky</td>
          <td>Sennheiser VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Beyond</td>
          <td>Sennheiser VSM201</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Fragments Of Time</td>
          <td>Talk box (synth solo)</td>
      </tr>
      <tr>
          <td>Random Access Memories</td>
          <td>Doin’ It Right</td>
          <td>Sennheiser VSM201</td>
      </tr>
  </tbody>
</table>
<h3 id="homework-notes-20-january-1997">Homework notes (20 January 1997)&nbsp;<a title="Link to heading" href="#homework-notes-20-january-1997">#</a></h3>
<p>There aren’t many robot vocal effects on Homework, but there is a lot of pitch shifting, likely provided by Daft Punk’s Ensoniq DP/4+, a digital multi-effects units that can do a variety of things. I don’t believe Daft Punk used the vocoder on the Ensoniq DP/4+ for Homework or any of their other albums. The Remix magazine quote says Ensoniq DP/4, but a <a href="https://i.redd.it/te31d8kbt2e11.jpg">gear list in another interview</a> says DP/4+. It doesn’t matter which model was used, as the pitch shifting and vocoder sound the same on both units.</p>
<h3 id="discovery-notes-12-march-2001">Discovery notes (12 March 2001)&nbsp;<a title="Link to heading" href="#discovery-notes-12-march-2001">#</a></h3>
<p>One More Time sounds like Auto-Tune in combination with a Mu-Tron Phasor or Moogerfooger. Harder, Better, Faster, Stronger uses a DigiTech Talker vocoder. Given the DigiTech Talker was used extensively for Human After All, maybe it was one of the last songs recorded for Discovery? The DigiTech Talker wasn’t mentioned in the May 2001 interview, despite its use on Discovery.</p>
<h3 id="human-after-all-notes-14-march-2005">Human After All notes (14 March 2005)&nbsp;<a title="Link to heading" href="#human-after-all-notes-14-march-2005">#</a></h3>
<p>DigiTech Talker and DigiTech Synth Wah are all over the entire album. But, did they use a DigiTech Synth Wah, or DigiTech Bass Synth Wah? They’re very similar pedals. The tremolo effect on The Brainwasher could have been done many ways. Maybe it was just an LFO modulating the amplitude on their Roland S-760 sampler? Maybe it was a guitar pedal? It’s an easy effect that can be achieved many different ways.</p>
<h3 id="random-access-memories-notes-17-may-2013">Random Access Memories notes (17 May 2013)&nbsp;<a title="Link to heading" href="#random-access-memories-notes-17-may-2013">#</a></h3>
<p>In Lose Yourself To Dance, the “everybody’s dancing on the floor” vocals sound very crunchy and DigiTech Talker-like. The vocodeded vocals in Touch sound like a Sennheiser VSM201 switched to unvoiced, or using white noise as the vocoder’s carrier. Instant Crush could be Auto-Tune or some other kind of harmoniser. It sounds like Instant Crush constains some Sennheiser VSM201 chord layers in places.</p>
<hr>
<h3 id="talk-boxes">Talk boxes&nbsp;<a title="Link to heading" href="#talk-boxes">#</a></h3>
<p>Daft Punk’s vocal effects can be broadly split into three categories: Talk boxes, vocoders, and harmonisers. They all sound vaguely similar and robot-like, and you could be forgiven for confusing them, but they’re extremely different techniques and technologies.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/heil-talk-box.jpg" alt="A photo of a Heil Talk Box."></p>
<p>Talk boxes are relatively simple devices — they’re a speaker in a sealed box with a small opening. One end of a hose is fitted to the opening, and the other end is placed into the performer’s mouth, blasting noise towards their throat. The performer can pretend to speak, shaping and filtering the sound coming out of the tube with their vocal tract. A microphone is then needed to record the resulting sound. A keyboard or guitar is typically connected to the talk box unit as the sound source for the speaker. This lets the keyboard or guitar sound like it’s singing. If you’ve heard <a href="https://www.youtube.com/watch?v=UlAa0dc-E4w">Chromeo</a>, 2Pac’s <a href="https://www.youtube.com/watch?v=J7_bMdYfSws">California Love</a>, Peter Frampton’s <a href="https://youtu.be/y7rFYbMhcG8?feature=shared&amp;t=349">Do You Feel Like We Do</a>, or Bon Jovi’s <a href="https://www.youtube.com/watch?v=lDK9QqIzhwk">Livin’ On A Prayer</a> before, you’ve heard a talk box.</p>
<p>I can confirm firing loud sounds into your mouth while holding a tube with your teeth is a bit uncomfortable. In terms of vocal effects used by Daft Punk, I think talk box might be the least used and least interesting, in terms of hunting down the exact hardware used. Talk boxes are simple devices and typically all sound similar. The sound source and performance play a bigger role in the result than the hardware itself.</p>
<p>Also, there aren’t many talk boxes on the market. Daft Punk may have used a Heil Talk Box, a Rocktron Banshee, a home made talk box, or something else. The MXR M222 Talk Box is probably the best option if you’re looking to buy a talk box today, because it has a built in amplifier. The MXR wasn’t around when <a href="https://www.youtube.com/watch?v=K0HSD_i2DvA">Around The World</a> was created though, so that’s not the unit they used.</p>
<p>Daft Punk’s early albums extensively used a Roland Juno-106, so it’s likely that was the sound source for the talk box used on Around The World. It sounds like a sawtooth wave with the filters open.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/daft-punk-juno-106.jpg" alt="A photo of Thomas Bangalter playing a Roland Juno-106 and Roland TR-909."></p>
<p>Even though they’ve been around in a commercial form since the mid 70s, talk boxes aren’t the first device to use human vocal tracts to create robotic sounds — the <a href="https://www.youtube.com/watch?v=kH-krlgo2e8">Sonovox</a> from 1939 takes that prize.</p>
<hr>
<h3 id="vocoders">Vocoders&nbsp;<a title="Link to heading" href="#vocoders">#</a></h3>
<p>Vocoders are a bit like an electronic version of a talk box. Vocoders take two audio inputs — often a voice and a synth — and combine them by filtering the synth with the voice’s frequency response. The filtering is usually done by splitting the signal into frequency bands. The volume of each voice band sets the volume of the repective synth band. More bands usually means a higher quality and more intelligible result. I’ve been calling the inputs “voice” and “synth”, but they’re often referred to as the modulator and carrier. The modulator filters the carrier.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/vocoders.jpg" alt="A photo of vocoders, including a DigiTech Talker and Ultimate VoIS."></p>
<p>Vocoders can be analogue or digital. Good analogue vocoders are physically big and very expensive, due to their complexity, especially if they have lots of frequency bands. They’re also a specialty effect, and therefore usually not mass produced.</p>
<p>The peak for high-end analogue vocoders was the 1970s — the EMS Vocoder 5000 was released in 1976, the Bode/Moog Vocoder in 1977, and the Sennheiser VSM201 in 1977. It’s hard to know exactly how many Sennheiser VSM201s were built, but the highest serial number I’ve seen is 40. The photo below is of the unit with serial number 21. Why should we care about that serial number? It’s the <a href="https://reverb.com/au/item/72543188-1977-sennheiser-vsm201-vocoder-20-band-analog-voice-synthesizer-rare-vocal-microphone-mic-effect-synth-used-by-daft-punk">exact unit Daft Punk used</a> on Random Access Memories, rented from <a href="https://audiorents.com/?s=VSM-201">Audio Rents in Los Angeles</a> for the sessions. Serial number 21 was sold, but Audio Rents have another VSM201, if you’re keen on renting one.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/sennheiser-vsm201.jpg" alt="A photo of a Sennheiser VSM201 with the serial number 21."></p>
<p>The best modern analogue vocoder I’ve heard, by far, is the <a href="https://vocoder.hoerold.com/Ultimate-VoIS.html">Dromedary Modular Ultimate VoIS</a>. It shares a lot of similarities with the Sennheiser VSM201, including accurate voiced/unvoiced detection, silence bridging, and other features. It’s a fraction of the price of a vintage vocoder, and still in production. If you’re looking for a high-end vocoder, it is the one to get.</p>
<p>What about vocoders used by Daft Punk prior to Random Access Memories? It’s incredibly likely Daft Punk used a DigiTech Talker on <a href="https://www.youtube.com/watch?v=gAjR4_CbPpQ">Harder, Better, Faster, Stronger</a> and many of the songs on Human After All. The DigiTech Talker is a digital vocoder, sold as a guitar pedal.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/digitech-talker.jpg" alt="A photo of a DigiTech Talker."></p>
<p>I said “incredibly likely”, because there’s another vocoder that sounds eerily similar. That’s no coincidence — even though the Talker has DigiTech’s name on the front of the pedal, it was designed and manufactured by IVL Technologies in Canada. IVL also teamed up with Electrix to build the Warp Factory vocoder, which sounds very similar, but not identical. It’s pretty clear they’re running the same algorithm.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/warp-factory.jpg" alt="A photo of an Electrix Warp Factory."></p>
<p>IVL specialises in vocal effects and voice processing. They’re still around, but known under a different name — in 2000, TC Helicon was formed as a joint venture between TC Electronic and IVL Technologies. TC Group, the parent company of TC Electronic, took full ownership of TC Helicon in 2005. And finally, Music Tribe (Behringer) purchased TC Group in 2015.</p>
<p>TC Helicon still make a vocoder guitar pedal called the <a href="https://www.tc-helicon.com/tchelicon/product?modelCode=0726-AAP">Talkbox Synth</a>. Sadly, it sounds nothing like the DigiTech Talker. It’s pretty good, but it doesn’t have the crunchy Daft Punk sound. Also, it has a terrible name. It’s not a talk box at all. It’s a vocoder. The DigiTech Talker has a similar naming issue — one of the settings is called “talk box”, and it’s also a vocoder. The recurring theme when researching this article was finding out about IVL/TC Helicon’s incorrectly named products and features.</p>
<p>Here’s a list of some vocoders, including the models being discussed. Many of these vocoders were used on well known songs. A MAM VF-11 was used on Intergalactic by Beastie Boys. Roland VP-330s were used on In The Air Tonight by Phil Collins, Radio Ga Ga by Queen, and I Just Called to Say I Love You by Stevie Wonder. A Korg DVP-1 was used by Air for lots of their songs, including Kelly Watch The Stars. As well as being used by Daft Punk, Sennheiser VSM201s have been used by Herbie Hancock, Giorgio Moroder, and Aphex Twin.</p>
<table>
  <thead>
      <tr>
          <th>Year</th>
          <th>Model</th>
          <th>Bands</th>
          <th>Notes</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1976</td>
          <td>EMS Vocoder 5000</td>
          <td>22</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1977</td>
          <td>EMS Vocoder 2000</td>
          <td>16</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1977</td>
          <td>EMS Vocoder 3000</td>
          <td>16</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1977</td>
          <td>Bøde/Moog Vocoder</td>
          <td>16</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1977</td>
          <td>Sennheiser VSM201</td>
          <td>20</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1978</td>
          <td>Korg VC-10</td>
          <td>20</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1979</td>
          <td>Roland SVC-350</td>
          <td>11</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1979</td>
          <td>Roland VP-330</td>
          <td>10</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>1986</td>
          <td>Korg DVP-1</td>
          <td>16</td>
          <td>Digital</td>
      </tr>
      <tr>
          <td>1997</td>
          <td>DigiTech Talker</td>
          <td>24 (order)</td>
          <td>Digital, linear predictive coding</td>
      </tr>
      <tr>
          <td>1999</td>
          <td>Eletrix Warp Factory</td>
          <td>1 to 24 (order)</td>
          <td>Digital, similar to DigiTech Talker</td>
      </tr>
      <tr>
          <td>2000</td>
          <td>MAM VF-11</td>
          <td>11</td>
          <td>Analogue</td>
      </tr>
      <tr>
          <td>2000</td>
          <td>Next! Vox 11</td>
          <td>11</td>
          <td>Identical to MAM VF-11</td>
      </tr>
      <tr>
          <td>2000</td>
          <td>FAT Procoder PCP330</td>
          <td>11</td>
          <td>Identical to MAM VF-11</td>
      </tr>
      <tr>
          <td>2002</td>
          <td>Alesis ModFx Metavox</td>
          <td>38</td>
          <td>Digital</td>
      </tr>
      <tr>
          <td>2017</td>
          <td>TC Helicon Talkbox Synth</td>
          <td>?</td>
          <td>Digital</td>
      </tr>
      <tr>
          <td>2019</td>
          <td>Behringer VC340</td>
          <td>10</td>
          <td>Analogue, Roland VP-330 clone</td>
      </tr>
      <tr>
          <td>2018</td>
          <td>Electro-Harmonix V256</td>
          <td>8 to 256</td>
          <td>Digital</td>
      </tr>
      <tr>
          <td>2024</td>
          <td>Ultimate VoIS</td>
          <td>18</td>
          <td>Analogue</td>
      </tr>
  </tbody>
</table>
<p>Having more filter bands typically increases the quality of the results, but I wouldn’t consider the Metavox or V256 to be anywhere near the best in terms of intelligibility. The EMS Vocoder 5000 and Sennheiser VSM201 are often considered to be the best vocoders ever made.</p>
<p>The DigiTech Talker and Eletrix Warp Factory use linear predictive coding (LPC), rather than bandpass filters. The value shown in the bands column for those models is the LPC order.</p>
<h3 id="vocoder-comparison">Vocoder comparison&nbsp;<a title="Link to heading" href="#vocoder-comparison">#</a></h3>
<p>If you’d like to hear many of these vocoders in action, I’ve created a <a href="https://www.youtube.com/watch?v=bkTFCPQMJkc">vocoder comparison video</a>. The comparison includes a Sennheiser VSM201, DigiTech Talker, the XILS 201 plugin, a Dromedary Modular Ultimate VoIS, and many other vododers. It compares the actual models used by Daft Punk as well as software clones, and the best modern analogue vocoder.</p>
<p><a href="https://www.youtube.com/watch?v=bkTFCPQMJkc"><img src="https://bjango.com/images/articles/daftpunkvocaleffects/video-vocoders.jpg"></a></p>
<hr>
<h3 id="harmonisers">Harmonisers&nbsp;<a title="Link to heading" href="#harmonisers">#</a></h3>
<p>Harmonisers are very different to talk boxes and vocoders. There’s no filtering involved, and they don’t require two audio sources — they work directly with one audio signal, often a vocal, altering its pitch. Harmonisers are a digital effect.</p>
<p>There’s two main parts to the digital algorithm used by harmonisers — pitch detection, and pitch shifting. Pitch detection figures out the fundamental frequency of the signal. Once the pitch is known, lots of possibilities open up.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/digitech-vocalist-family-2.jpg" alt="A photo of several harmonizers, including two DigiTech Studio Vocalist EX modesl."></p>
<p>If the pitch is rapidly shifted to a nearby note in the song’s key, the result sounds like <a href="https://www.youtube.com/watch?v=FGBhQbmPwH8&amp;t=47s">One More Time</a> or <a href="https://www.youtube.com/watch?v=a5uQMwRMHcs&amp;t=81">Instant Crush</a>. Using <a href="https://www.antarestech.com/">Auto-Tune</a> with extreme settings is one way to achieve this effect, but it can be done with most harmonisers and is often called “hard tune”.</p>
<p>Some harmonisers can have keyboards connected to them, and use the notes played on the keyboard to determine which note to shift the vocal to. Holding multiple keys can create harmonies. <a href="https://www.youtube.com/watch?v=UYIAfiVGluk">Hide and Seek</a> by Imogen Heap is a great example of this effect in action. In Hide and Seek, the original main vocal can also be heard, blended in with the harmonies.</p>
<p><a href="https://www.youtube.com/watch?v=FxzBvqY5PP0">Digital Love</a> and <a href="https://www.youtube.com/watch?v=sOS9aOIXPEk">Something About Us</a> were created using the same technique, where a MIDI keyboard or sequencer was used to control the pitch of the vocal. Daft Punk have said they used a DigiTech Vocalist, which is a strong indication that’s what was used for those two tracks. Both songs were released on 12 March 2001, as part of the Discovery album. Given the time required for mixing, mastering, and physical media production, I’d guess they must have used a model from before late 2000. There’s 7 DigiTech Vocalist models with MIDI pitch control that were released before then.</p>
<p>The earlier models incorrectly call the MIDI control feature “vocoder”, and later models call it “MIDI notes mode” or “notes harmony mode”. The list below shows all the DigiTech Vocalist models with MIDI notes mode. There’s another 20 or so models that can’t be controlled via a keyboard.</p>
<p>Interestingly, Imogen Heap also used a DigiTech Vocalist to record Hide and Seek, and has used a <a href="https://youtu.be/-Scn74BnDz4?feature=shared&amp;t=1983">TC Helicon VoiceLive 2</a> when <a href="https://www.youtube.com/watch?v=dHk2lLaDzlM">performing the song live</a>. Which DigiTech Vocalist? I emailed Imogen’s team and to my surprise, they responded, confirming a DigiTech Vocalist Workstation EX was used for recording Hide and Seek.</p>
<table>
  <thead>
      <tr>
          <th>Year</th>
          <th>Model</th>
          <th>Sampling</th>
          <th>Mic power</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1991</td>
          <td>Vocalist VHM5</td>
          <td>16-bit, 31.25kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>1993</td>
          <td>Studio Vocalist</td>
          <td>18-bit, 48kHz</td>
          <td>+48V</td>
      </tr>
      <tr>
          <td>1995</td>
          <td>Vocalist II</td>
          <td>16-bit, 31.25kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>1996</td>
          <td>MIDI Vocalist</td>
          <td>16-bit, 31.25kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>1996</td>
          <td>Vocalist Workstation</td>
          <td>18-bit, 48kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>1998</td>
          <td>Vocalist Access</td>
          <td>16-bit, 44.1kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>1998</td>
          <td>Studio Vocalist EX</td>
          <td>18-bit, 48kHz</td>
          <td>+48V</td>
      </tr>
      <tr>
          <td>2000</td>
          <td>Vocalist VR</td>
          <td>16-bit, 44.1kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>2001</td>
          <td>Vocalist Workstation EX</td>
          <td>18-bit, 48kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>2008</td>
          <td>Vocalist Live Pro</td>
          <td>24-bit, 44.1kHz</td>
          <td>+48V</td>
      </tr>
      <tr>
          <td>2009</td>
          <td>Vocalist VL3D</td>
          <td>24-bit, 44.1kHz</td>
          <td>+48V</td>
      </tr>
  </tbody>
</table>
<p>Remember IVL Technologies from earlier in the article? Their logo is on all those Vocalist models, except the Vocalist Live Pro. Yes, IVL also designed and built almost all the DigiTech Vocalist units. The Vocalist Live Pro has a different logo on the back — 3db Research. And, the Vocalist VL3D has IVL and 3db Research’s logos on it. I don’t fully understand what went down, but 3db Research was created by ex-IVL staff, and Harman International accused TC Helicon of infringing <a href="https://patents.google.com/patent/US20140109751A1/en">patents relating to harmonisers</a>. TC Helicon counter sued, and won.</p>
<p>Hold up. Why is Harman involved? While IVL were busy merging with TC Group, forming TC Helicon, and being sold to Behringer, DigiTech were experiencing their own dramas — DigiTech sold to Harman International in 1990, then Samsung bought Harman in 2017. After a restructure, DigiTech ceased to exist in mid 2018. In 2022, <a href="https://digitech.com/announcing-the-comeback-of-the-dod-pedals/">DigiTech was purchased and revived by Cor-Tek</a>, who seem to be doing a great job. That’s why it’s possible to buy DigiTech pedals today. Unfortunately, they don’t currently sell any DigiTech Vocalists or Talkers, so you’ll have to hit the second hand market if you’re after either. <a href="https://www.youtube.com/live/RkzdNmBsyxw?feature=shared&amp;t=664">This JHS Pedals video has a full recap of the DOD and DigiTech history</a>.</p>
<p>IVL partnered with other companies, including Korg. The Korg ih Interactive Vocal Harmony appears to run the same algorithm as the DigiTech Vocalist series, so I purchased one of those to add to the tests. I also purchased a TC Helicon Perform VE and TC Helicon VoiceWorks. As noted above, TC Helicon is the modern incarnation of IVL, so maybe their harmonisers sound the same as the older DigiTech ones?</p>
<table>
  <thead>
      <tr>
          <th>Year</th>
          <th>Model</th>
          <th>Sampling</th>
          <th>Mic power</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1995</td>
          <td>Korg ih</td>
          <td>16-bit, 31.25kHz</td>
          <td>None</td>
      </tr>
      <tr>
          <td>2003</td>
          <td>TC Helicon VoiceWorks</td>
          <td>24-bit, 44.1kHz or 48kHz</td>
          <td>+48V</td>
      </tr>
      <tr>
          <td>2017</td>
          <td>TC Helicon Perform VE</td>
          <td>24-bit, 44.1kHz</td>
          <td>+48V</td>
      </tr>
  </tbody>
</table>
<p>IVL also worked with DigiTech to create the Whammy WH-1, Whammy II, and Bass Whammy pedals, which makes sense, given the Whammy is a harmoniser. Those models likely shared code and algorithms with the Vocalist line. Later versions of the DigiTech Whammy weren’t built in collaboration with IVL. The earlier IVL Whammy models are held in high regard and their prices on the used market reflect that. However, the latest model, the Whammy V, does have a “classic” mode that is supposed to replicate the earler models.</p>
<h3 id="ex-models">EX models&nbsp;<a title="Link to heading" href="#ex-models">#</a></h3>
<p>Now we have the full history of DigiTech and IVL covered, we can talk about how the “EX” models fit into the timeline. In 1998, the Studio Vocalist EX was released, becoming the new flagship Vocalist model. The main upgrades were more patch storage, more presets, and an updated algorithm with better pitch recognition.</p>
<p>For the effect used on Digital Love and Something About Us, the improved pitch recognition would make an audible difference. But, in my tests, the difference between the non-EX and EX models is fairly subtle. Audible and better, but subtle. If I had to guess which unit Daft Punk used, my money would be on the Studio Vocalist EX, but a Vocalist Workstation or one of the other earlier models could have also been used.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/digitech-vocalist-workstation-ex.jpg" alt="A photo of a DigiTech Vocalist Workstation EX."></p>
<p>To confuse things even further, the Vocalist Workstation can run the EX firmware, and I was able to upgrade one of my own units from firmware 1.02 to 2.02 (2.02 is the EX version, with additional presets and patch storage). A Vocalist Workstation running firmware 2.02 sounds identical to a Vocalist Workstation EX to me. The internals to the Vocalist Workstation EX are a bit different to the Vocalist Workstation, but I don’t think any of the differences relate to the audio path. The EX is also heavier, at 840 grams vs the non-EX’s 700 grams. The weight difference is due to a useless strip of metal in the EX. No, I’m not kidding.</p>
<p>Without more evidence, it seems impossible to know which model Daft Punk used. They may have used a Vocalist VHM5, Studio Vocalist, Vocalist II, MIDI Vocalist, Vocalist Workstation, Vocalist Access, Studio Vocalist EX, or Vocalist VR. I’m not sure it matters, given how similar they all sound.</p>
<p>If you are looking for a device to replicate the effect, a Studio Vocalist EX, Vocalist Workstation EX, or Vocalist Workstation with the EX firmware are good choices. Some of the newer TC Helicon devices, like the VoiceLive 3 Extreme, Perform VE, and Perform VG are great, too. Just be aware that only specific TC Helicon vocal effect models have MIDI notes mode. Also, the Perform VE and Perform VG have been discontinued.</p>
<p>I would recommend against the Vocalist Live Pro or Vocalist VL3D. They don’t run IVL’s algorithm and they sound terrible. I would also recommend against getting a Korg ih — it does use IVL’s algorithm and sounds like a Vocalist Workstation, but there is a permanent chorus effect that can not be disabled.</p>
<h3 id="pitch-shifting">Pitch shifting&nbsp;<a title="Link to heading" href="#pitch-shifting">#</a></h3>
<p>The pitch shifting effect used on Teachers, Oh Yeah, and Technologic is similar to the harmoniser effect we’ve been discussing, but there’s no pitch detection involved — the audio is just shifted without trying to make it match any specific note. It’s highly likely Daft Punk used their Ensoniq DP/4+ to achieve the pitch shifting on Homework and Discovery.</p>
<h3 id="harmoniser-comparison">Harmoniser comparison&nbsp;<a title="Link to heading" href="#harmoniser-comparison">#</a></h3>
<p>If you’d like to hear many of these harmonisers in action, I’ve created a <a href="https://www.youtube.com/watch?v=10o0hCybeq4">harmoniser comparison video</a>, which also covers some of the modern TC Helicon models. Another interesting fact is that all the harmonisers tested use last note priority when more than one note is played at a time via MIDI.</p>
<p><a href="https://www.youtube.com/watch?v=10o0hCybeq4"><img src="https://bjango.com/images/articles/daftpunkvocaleffects/video-harmonizers.jpg"></a></p>
<hr>
<h3 id="synth-wah-vs-bass-synth-wah">Synth Wah vs Bass Synth Wah&nbsp;<a title="Link to heading" href="#synth-wah-vs-bass-synth-wah">#</a></h3>
<p>Human After All sounds like Human After All because of yet another DigiTech product — a digital envelope filter guitar pedal called the Synth Wah. Or, the Bass Synth Wah. It’s unclear which pedal was used, because they’re incredibly similar. Strangely, the Bass Synth Wah weights a lot more (340 vs 635 grams). I didn’t open the pedals up to find out why, but that’s a huge difference, given how alike they are. It might just be an internal metal weight, like the Vocalist Workstation EX has.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/digitech-synth-wah-bass-synth-wah.jpg" alt="A photo of DigiTech Synth Wah and DigiTech Bass Synth Wah guitar pedals."></p>
<p>There’s 7 effect types on each pedal, selected via the rightmost knob. Daft Punk favoured “filter 1” and “filter 2”. Here’s a list of the songs on Human After All, and the effect they probably used.</p>
<table>
  <thead>
      <tr>
          <th>Song</th>
          <th>Effect number</th>
          <th>Effect type</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Human After All</td>
          <td>6</td>
          <td>Filter 2</td>
      </tr>
      <tr>
          <td>The Prime Time Of Your Life</td>
          <td>6</td>
          <td>Filter 2</td>
      </tr>
      <tr>
          <td>Steam Machine</td>
          <td>5</td>
          <td>Filter 1</td>
      </tr>
      <tr>
          <td>The Brainwasher</td>
          <td>6</td>
          <td>Filter 2</td>
      </tr>
      <tr>
          <td>Television Rules The Nation</td>
          <td>2 and 6</td>
          <td>Env Down and Filter 2</td>
      </tr>
      <tr>
          <td>Technologic</td>
          <td>6</td>
          <td>Filter 2</td>
      </tr>
  </tbody>
</table>
<p>If <a href="https://www.youtube.com/watch?v=YKaN7a19jLc">Television Rules The Nation</a> does in fact use “env down”, then that’s a vital clue — the Synth Wah has “env down”, but the Bass Synth Wah does not. The pedals share effect types 3, 4, 5, and 6, but 1, 2, and 7 are different. It was the Synth Wah after all.</p>
<h3 id="credits">Credits&nbsp;<a title="Link to heading" href="#credits">#</a></h3>
<p>These amazing people helped make this article and the related videos a reality: Vocals performed by <a href="https://www.fiverr.com/soloheadmusic">Solohead</a>. Sennheiser VSM201 vocoder recording by <a href="https://www.youtube.com/@TalhaVocoding">Talha Vocoding</a>. Ensoniq DP/4+ vocoder recording by <a href="https://www.youtube.com/@_floeter">@_floeter</a>. DigiTech Studio Vocalist recording by Spencer D. Carson. Technical guidance, repairs, and EPROM programming by Cam Sanderson.</p>
<p>Keep living the gold and the silver dream.</p>
<p><img src="https://bjango.com/images/articles/daftpunkvocaleffects/daft-punk-2.jpg" alt="A photo of Daft Punk in front of Eiffel Tower at night."></p>

		<p><small>Published 5 May 2025.</small></p>
	</article>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trump announces 100% tariffs on movies ‘produced in foreign lands’ (179 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2025/may/04/trump-tariffs-foreign-movies</link>
            <guid>43893310</guid>
            <pubDate>Mon, 05 May 2025 09:47:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2025/may/04/trump-tariffs-foreign-movies">https://www.theguardian.com/us-news/2025/may/04/trump-tariffs-foreign-movies</a>, See on <a href="https://news.ycombinator.com/item?id=43893310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><a href="https://www.theguardian.com/us-news/donaldtrump" data-link-name="in body link">Donald Trump</a> on Sunday announced on his Truth Social platform a 100% <a href="https://www.theguardian.com/us-news/trump-tariffs" data-link-name="in body link">tariff</a> on all movies “produced in Foreign Lands”, saying the US film industry was dying a “very fast death” due to the incentives that other countries were offering to draw American film-makers.</p><p>In his post, he claimed to have authorised the commerce department and the US trade representative to immediately begin instituting such a tariff.</p><p>“This is a concerted effort by other Nations and, therefore, a National Security threat,” Trump said in <a href="https://truthsocial.com/@realDonaldTrump/posts/114452117143235155" data-link-name="in body link">the Truth Social post</a>. “It is, in addition to everything else, messaging and propaganda!</p><p>“WE WANT MOVIES MADE IN AMERICA, AGAIN!” Trump added.</p><figure id="8ae2b780-47ed-4829-af63-0195c20dd2b3" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:4,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Republicans in Congress pull out all the stops to protect Trump tariffs&quot;,&quot;elementId&quot;:&quot;8ae2b780-47ed-4829-af63-0195c20dd2b3&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2025/may/04/republicans-congress-trump-tariffs&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>The commerce secretary, Howard Lutnick, posting on X said: “We’re on it.” Neither Lutnick nor Trump provided any details on the implementation. It was not immediately clear whether the move would target production companies, foreign or American, producing films overseas.</p><p>Film and television production in Los Angeles has fallen by nearly 40% over the last decade, according to FilmLA, a non-profit that tracks the region’s production. At the same time, governments around the world have offered more generous tax credits and cash rebates to lure productions, and capture a greater share of the $248bn that Ampere Analysis predicts will be spent globally in 2025 to produce content.</p><p>Politicians in Australia and New Zealand said on Monday they would advocate for their respective film industries, after the president’s announcement.</p><p>Australia’s home affairs minister, Tony Burke, said he had spoken to the head of the government body Screen Australia about the proposed tariffs. “Nobody should be under any doubt that we will be standing up unequivocally for the rights of the Australian screen industry,” he said in a statement.</p><figure id="c4a5d97c-26f1-4298-ba8d-fb8ca979211b" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:9,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;‘It feels empty’: is Hollywood film and TV production in a death spiral?&quot;,&quot;elementId&quot;:&quot;c4a5d97c-26f1-4298-ba8d-fb8ca979211b&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/film/2025/apr/26/los-angeles-film-and-tv-production&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>New Zealand’s prime minister, Christopher Luxon, told a news conference the government was awaiting further detail of the proposed tariffs. “We’ll have to see the detail of what actually ultimately emerges. But we’ll be obviously a great advocate, great champion of that sector in that industry,” he said.</p><p>The announcement from Trump comes after he triggered a trade war with China, and imposed global tariffs which have roiled markets and led to fears of a US recession. The film industry has already been feeling the effects of the tariffs, as China in April responded to the announcements by <a href="https://www.theguardian.com/film/2025/apr/10/china-to-restrict-us-film-releases-after-trumps-tariff-hike" data-link-name="in body link">reducing the quota</a> of American movies allowed into that country.</p><p>China is the world’s second largest film market after the US, although in recent years domestic offerings have outshone Hollywood imports.</p><p>A former senior commerce department official, William Reinsch, a senior fellow with the Center for Strategic and International Studies, said retaliation against Trump’s foreign movies tariffs would be devastating.</p><p>“The retaliation will kill our industry. We have a lot more to lose than to gain,” he said, adding that it would be difficult to make a national security or national emergency case for movies.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modern Latex (191 pts)]]></title>
            <link>https://github.com/mrkline/modern-latex</link>
            <guid>43892119</guid>
            <pubDate>Mon, 05 May 2025 05:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mrkline/modern-latex">https://github.com/mrkline/modern-latex</a>, See on <a href="https://news.ycombinator.com/item?id=43892119">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Modern LaTeX</h2><a id="user-content-modern-latex" aria-label="Permalink: Modern LaTeX" href="#modern-latex"></a></p>
<p dir="auto">LaTeX is a tool for creating beautiful writing, or a torture device that drives
users to the brink of madness every time they see bad spacing for the rest
of their lives. One of the two. Despite origins that can be traced back four
decades, it remains one of the best typesetting programs around. Many of its
guides, however, haven't aged as well. This short book will get you started with
LaTeX without bogging you down in arcana that lost its relevance back in the 90s.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Where do I get it?</h2><a id="user-content-where-do-i-get-it" aria-label="Permalink: Where do I get it?" href="#where-do-i-get-it"></a></p>
<p dir="auto">An up-to-date version should be available at
<a href="https://assets.bitbashing.io/modern-latex.pdf" rel="nofollow">https://assets.bitbashing.io/modern-latex.pdf</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How do I build it?</h2><a id="user-content-how-do-i-build-it" aria-label="Permalink: How do I build it?" href="#how-do-i-build-it"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Install LuaLaTeX, a modern, Unicode-aware version of LaTeX.
On Linux, this is usually as simple as installing your distro's TeX Live
package, e.g., <code>texlive-base</code> or <code>texlive-core</code>.
The same package should also provide the <code>latexmk</code> script.
(See below)</p>
</li>
<li>
<p dir="auto">Check out the <code>online</code> branch of the source repository,
which is optimized for digital display instead of a printed book.
Changes include even margins, centered page numbers, a lack of blank pages
between chapters, and so on.</p>
</li>
<li>
<p dir="auto">Change the fonts as-needed.</p>
<p dir="auto">The official version of this book is typeset with Garamond Premier,
Neue Haas Grotesk, URW Futura, Drive Mono, Noto, and (of course) Latin Modern.
In the likely case that you don't have all of these typefaces,
change the <code>fontspec</code> commands (e.g., <code>setmainfont</code>, etc.) appropriately,
then modify or remove the colophon at the back of the book.</p>
</li>
<li>
<p dir="auto">Build the book using</p>
<div data-snippet-clipboard-copy-content="latexmk -lualatex -latexoption=-halt-on-error modern-latex.tex"><pre><code>latexmk -lualatex -latexoption=-halt-on-error modern-latex.tex
</code></pre></div>
<p dir="auto">Note that <code>latexmk</code> will run LuaLaTeX multiple times, since
TeX generates cross references in one pass, then links them in a second.</p>
<p dir="auto">If you can't use <code>latexmk</code> for some reason, you can manually invoke</p>
<div data-snippet-clipboard-copy-content="lualatex -halt-on-error -shell-escape modern-latex.tex"><pre><code>lualatex -halt-on-error -shell-escape modern-latex.tex
</code></pre></div>
<p dir="auto">until it no longer warns,
"Label(s) may have changed. Rerun to get cross-references right."</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback</h2><a id="user-content-feedback" aria-label="Permalink: Feedback" href="#feedback"></a></p>
<p dir="auto">...is welcome!
Please issue pull requests on this book's Github page,
or contact the author via matt &lt;at&gt; bitbashing.io</p>
<p dir="auto">Enjoy!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Meets WinDBG (238 pts)]]></title>
            <link>https://svnscha.de/posts/ai-meets-windbg/</link>
            <guid>43892096</guid>
            <pubDate>Mon, 05 May 2025 05:11:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://svnscha.de/posts/ai-meets-windbg/">https://svnscha.de/posts/ai-meets-windbg/</a>, See on <a href="https://news.ycombinator.com/item?id=43892096">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><h2 id="old-meets-new-bringing-crash-analysis-into-2025">Old Meets New: Bringing Crash Analysis into 2025</h2><p>Let's face it - while the rest of software development has evolved at warp speed, crash dump analysis feels like it's been preserved in digital amber for decades. We've got self-driving cars and pocket-sized supercomputers, yet here we are, still pecking away at command prompts like it's the dawn of the internet. Why is debugging the only area where we cling to tools that look like they belong in a computer history museum?</p><p>Picture this: You, a professional software engineer in 2025, hunched over a terminal, manually typing arcane commands like <code>!analyze -v</code> and <code>.ecxr</code>, squinting at hexadecimal memory addresses, and mentally translating stack traces. All while your friends in other industries are delegating their work to AI assistants that can write entire documents, create art, or automate complex workflows.</p><p>Something's wrong with this picture, right?</p><p><strong>What if I told you we can throw that ancient workflow into the dustbin of computing history?</strong> That's exactly what I've done. And I'm not talking about slightly better syntax highlighting or prettier UI for WinDBG. I'm talking about a fundamental transformation where you simply have a conversation with your debugger.</p><h2 id="when-inspiration-strikes">When Inspiration Strikes</h2><p>During a debugging session at work, I had one of those lightning bolt moments. What if - and stick with me here - we could apply the same AI-assisted "vibe coding" approach to crash dump analysis?</p><p>Picture this: instead of manually slogging through memory dumps and command outputs, you simply ask, "Hey, why did this application crash?" and get an intelligent, contextual answer that actually helps you solve the problem.</p><p><strong>The idea was too compelling not to pursue. So I built it.</strong></p><h2 id="see-it-in-action-ai-powered-crash-analysis">See It In Action: AI-Powered Crash Analysis</h2><p>Before diving into the technical details, let me show you what this looks like in practice. I have prepared a demo application to showcase two different use cases:</p><h3 id="video-1-crash-analysis-and-automated-bugfix">Video 1: Crash Analysis and Automated Bugfix</h3><p>In this video, I show how Copilot can analyze a crash dump, identify the bug and auto-fix the issue.</p><video controls="" src="https://svnscha.de/casts/2025-05-03-CrashDump1.webm">Your browser does not support the video tag.</video><p>As you can see in the video, instead of manually running WinDBG commands and interpreting the cryptic output, I'm having a natural conversation with GitHub Copilot. The AI quickly identifies that the application crashed, explains which specific conditions led to the crash, and suggests a fix.</p><h3 id="video-2-automated-crash-dump-analysis-of-multiple-crash-dump-files">Video 2: Automated Crash Dump Analysis of multiple crash dump files</h3><p>This video demonstrates a different capability: analyzing multiple crash dump files at once. It shows how the tool can quickly identify which dumps belong to your application and which don't.</p><video controls="" src="https://svnscha.de/casts/2025-05-03-CrashDump2.webm">Your browser does not support the video tag.</video><p>Worth noting, it takes just a few seconds until you get your first useful answer. I've played around with this for many hours and let me tell you one thing: You can really go deep. If you ask the right questions, the AI runs WinDBG/CDB commands that I haven't seen in all these years of debugging, and that is simply amazing.</p><h2 id="how-can-this-help-the-industry">How can this help the industry?</h2><p>I believe this is one of the really good examples of how AI can boost productivity. Analyzing crash dumps is a very tedious task. It begins with quickly checking and identifying whether crashes are the same or different, and often requires very advanced knowledge when a crash is challenging - really challenging.</p><p>Copilot can help here tremendously; it knows how to:</p><ul><li>Interpret assembly code (without you having to remember what EAX stands for)</li><li>Check memory contents (so you don't have to count hex bytes on your fingers)</li><li>Traverse structures with symbols (goodbye to manual pointer arithmetic!)</li><li>And so much more</li></ul><p>This is a game changer - not just for engineers, but also for support, QA, and everyone involved with crash dumps. It's like going from hunting with a stone spear to using a guided missile.</p><h2 id="how-did-i-build-this">How did I build this?</h2><p>If you've ever worked with WinDBG, you know the drill: cryptic commands, obscure syntax, and endless scrolling through memory addresses and stack traces that make your eyes glaze over. It's the kind of specialized knowledge that takes years to master and feels like speaking an alien language even when you do.</p><p>The trick here is connecting WinDBG with AI. To do that, you first need to programmatically control a debugging session, right? There are plenty of options on how to do this. I prefer to keep things simple, so I have chosen <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/debugging-using-cdb-and-ntsd">CDB</a>, which is Microsoft's Console Debugger. It operates on standard input and output, and that's so much more fun to deal with than setting up COM APIs or similar approaches.</p><p>The second part is "connecting with AI." That's where Model Context Protocol Servers come into the game.</p><h2 id="understanding-model-context-protocol-servers">Understanding Model Context Protocol Servers</h2><p>MCP is an open standard developed by Anthropic, released in November 2024. This protocol allows AI models to interact with external tools and data sources - think of it as giving AI assistants "hands" to work with other software. It defines a way for AI assistants to discover, access, and use tools through a consistent interface. In essence, it's what allows GitHub Copilot to "talk" to external programs like WinDBG.</p><p>An MCP server acts as the intermediary between the AI model and the tool. It:</p><ol><li>Registers available tools with the client</li><li>Handles requests from AI models to use these tools</li><li>Executes the tool operations and returns results</li><li>Maintains context across interactions</li></ol><p>This architecture means that any tool can be made available to AI models if someone builds an MCP server for it. And that's exactly what I did for WinDBG (CDB).</p><h3 id="why-mcp-instead-of-languagemodeltool-api">Why MCP Instead of LanguageModelTool API?</h3><p>The <a href="https://code.visualstudio.com/api/extension-guides/tools">LanguageModelTool API</a> might eventually be a better fit for this specific use-case. Creating a Visual Studio Extension that "just works" out of the box would potentially simplify the integration process significantly.</p><p>However, using MCP directly offers several notable advantages. It works with any AI model, not just limiting itself to Copilot. The server can be used outside VS Code, functioning with various other tools. New features can be easily added without necessitating changes to the core integration. Moreover, it remains platform-independent, avoiding lock-in to any single company's implementation.</p><h2 id="the-mcp-windbg-project">The MCP-WinDBG Project</h2><p>I've implemented a <a href="https://www.anthropic.com/news/model-context-protocol">Model Context Protocol</a> server that wraps WinDBG/CDB and exposes its capabilities to AI models within VS Code. Better yet, I've made it open source so everyone can experience this new workflow.</p><p>The project, called <a href="https://github.com/svnscha/mcp-windbg">mcp-windbg</a>, creates a seamless bridge between VS Code, GitHub Copilot, and the powerful analysis capabilities of WinDBG.</p><p>The actual "hard part" was implementing the CDB (Command-Line WinDBG) interaction layer. And by "hard", I mean vibe-coding with two coffees on a Saturday morning, where I spent more time being annoyed by pyTest failures than actual coding difficulties. The core implementation came together surprisingly quickly!</p><p>The rest is primarily wrapper code that implements the Model Context Protocol specifications. Now that I've established and defined the core WinDBG interaction logic, I'm considering refactoring the project to TypeScript. This would enable me to create both an MCP Server in TypeScript and a dedicated Visual Studio Extension, with both implementations leveraging the same underlying CDB interaction layer.</p><h2 id="what-does-this-mean-in-practice">What Does This Mean In Practice?</h2><p>Let me walk you through what this enables:</p><ol><li><p><strong>Natural language crash analysis</strong>: "Why is this application crashing with an access violation at this address?" (Instead of: "What the $%#@ is this heap corruption!?")</p></li><li><p><strong>Contextual debugging</strong>: "Show me the stack trace for thread 5 and explain what each function is doing based on the symbols." (Instead of staring at call stacks like they're ancient hieroglyphics)</p></li><li><p><strong>Root cause identification</strong>: "What's causing this null pointer dereference and where should I look in the code to fix it?" (Instead of playing detective with memory addresses)</p></li></ol><p>Instead of typing obscure commands like <code>!analyze -v</code> followed by a series of manual investigations, you simply ask questions in plain language, and the AI interprets the crash data for you. It's like having a WinDBG expert whispering in your ear, except it doesn't get annoyed when you ask the same question five times.</p><h2 id="how-it-works">How It Works</h2><p>The MCP server functions as a bridge between GitHub Copilot and WinDBG's powerful analysis capabilities:</p><ol><li>It provides a set of tools that Copilot can use to interact with crash dumps</li><li>It translates natural language questions into appropriate WinDBG commands</li><li>It parses and interprets the often cryptic WinDBG output into more useful information</li><li>It maintains context throughout a debugging session, enabling follow-up questions to work naturally</li></ol><p>The technical implementation uses Python to spawn and communicate with CDB (the command-line version of WinDBG), parses the output, and exposes the functionality through the Model Context Protocol to VS Code.</p><h2 id="getting-started-with-mcp-windbg">Getting Started With mcp-windbg</h2><p>Ready to try it yourself? Here's how to get started:</p><ol><li>First, make sure you have the Windows SDK installed with Debugging Tools for Windows</li><li>Clone the repository: <code>git clone https://github.com/svnscha/mcp-windbg.git</code></li><li>Set up a Python virtual environment and install the package</li><li>Configure VS Code to use the MCP server</li></ol><p>For complete details, check out the <a href="https://github.com/svnscha/mcp-windbg">repository README</a>.</p><p>Once configured, create a <code>.vscode/mcp.json</code> file in your project that points to the server:</p><pre data-lang="json"><code data-lang="json"><span>{
</span><span>    </span><span>"servers"</span><span>: {
</span><span>        </span><span>"mcp_server_windbg"</span><span>: {
</span><span>            </span><span>"type"</span><span>: </span><span>"stdio"</span><span>,
</span><span>            </span><span>"command"</span><span>: </span><span>"python"</span><span>,
</span><span>            </span><span>"args"</span><span>: [
</span><span>                </span><span>"-m"</span><span>,
</span><span>                </span><span>"mcp_server_windbg"
</span><span>            ],
</span><span>            </span><span>"env"</span><span>: {
</span><span>                </span><span>"_NT_SYMBOL_PATH"</span><span>: </span><span>"SRV*C:</span><span>\\</span><span>Symbols*https://msdl.microsoft.com/download/symbols"
</span><span>            }
</span><span>        },
</span><span>    }
</span><span>}
</span></code></pre><p>You might need to update the command, depending on where and how you have installed the mcp_server_windbg to.</p><h2 id="the-human-touch-still-matters">The Human Touch Still Matters</h2><p>Just like with <a href="https://svnscha.de/posts/vscode-vibe-coding/">code refactoring</a>, the AI assistance isn't perfect. The human element - your experience, intuition, and domain knowledge - remains crucial. Sometimes you'll need to guide the analysis, ask follow-up questions, or provide additional context.</p><p>But that's exactly what makes this approach so powerful: it combines the best of both worlds - AI's ability to quickly process and analyze large amounts of data with your human expertise in interpreting what truly matters for your specific application. Think of it as having a brilliant but occasionally confused intern who can do incredible things but sometimes needs you to point them in the right direction. "No, not that pointer... the OTHER pointer."</p><h2 id="join-the-experience">Join The Experience</h2><p>I'd love for you to try this out, contribute to the project, and share your experiences. If you're interested:</p><ol><li>Star the <a href="https://github.com/svnscha/mcp-windbg">GitHub repository</a></li><li>Try it on your own crash dumps</li><li>Report issues, suggest improvements, or contribute code</li><li>Share your success stories (or even failures - we learn from those too!)</li></ol><h2 id="the-magic-is-in-the-flow">The Magic Is In The Flow</h2><p>Just like with my code refactoring experience, the real magic isn't about any single capability - it's about the flow. When debugging stops being a tedious chore and becomes a fluid conversation, something fundamentally changes in how you approach problem-solving.</p><p>Gone are the days of dreading crash analysis. Instead, each debugging session becomes an opportunity for collaboration with an AI partner that helps you understand what's happening at a deeper level.</p><h2 id="wrapping-up">Wrapping Up</h2><p>Crash dump analysis has traditionally been one of the most technically demanding and least enjoyable parts of software development. It's like archaeology with a keyboard—painstakingly excavating through layers of memory and CPU state to unearth what went wrong. With AI assistance through tools like mcp-windbg, it becomes another area where we can experience that perfect "vibe state" of frictionless problem-solving.</p><p>If you're still manually typing WinDBG commands and squinting at memory dumps in 2025, you're not just missing out on productivity - you're missing out on a fundamentally more enjoyable way to work.</p><p>Try it. Debug it. Vibe it.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My AI Native Resume (252 pts)]]></title>
            <link>https://ai.jakegaylor.com/</link>
            <guid>43891245</guid>
            <pubDate>Mon, 05 May 2025 01:44:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.jakegaylor.com/">https://ai.jakegaylor.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43891245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
            <section id="how-to-use">
    <h2>How to Use</h2>
    <p>AI assistants can connect to this server to learn more about me and my work.</p>
    <ul>
        <li>
            SSE (Most Common, Deprecated) <code>https://ai.jakegaylor.com/sse</code>
        </li>
        <li>
            Streamable HTTP Endpoint (Modern) <code>https://ai.jakegaylor.com/mcp</code>
        </li>
    </ul>
    <p>To connect to this server with tools that do not support remote MCP servers, you can use the following commands:</p>
    
    <div>
        <!-- Claude Tab -->
        <div id="claude-content" role="tabpanel" aria-labelledby="claude-tab">
            <figure>
                <figcaption>Add this configuration to your Claude config</figcaption>
                <pre><code>{
  "mcpServers": {
    "jake-gaylor-mcp": {
      "command": "npx",
      "args": ["-y", "@jhgaylor/me-mcp"]
    }
  }
}</code></pre>
                
            </figure>
        </div>

        <!-- Cursor Tab -->
        <div id="cursor-content" role="tabpanel" aria-labelledby="cursor-tab">
            <figure>
                <figcaption>Add this configuration to your Cursor settings</figcaption>
                <pre><code>{
  "mcpServers": {
    "jake-gaylor-mcp": {
      "command": "npx",
      "args": ["-y", "@jhgaylor/me-mcp"]
    }
  }
}</code></pre>
                
            </figure>
        </div>

        <!-- Windsurf Tab -->
        <div id="windsurf-content" role="tabpanel" aria-labelledby="windsurf-tab">
            <figure>
                <figcaption>Configure Windsurf to connect</figcaption>
                <pre><code>{
  "mcpServers": {
    "jake-gaylor-mcp": {
      "command": "npx",
      "args": ["-y", "@jhgaylor/me-mcp"]
    }
  }
}</code></pre>
                
            </figure>
        </div>

        <!-- Zed Tab -->
        <div id="zed-content" role="tabpanel" aria-labelledby="zed-tab">
            <figure>
                <figcaption>Set up Zed MCP server configuration</figcaption>
                <pre><code>{
  "context_servers": {
    "jake-gaylor-mcp": {
      "settings": {},
      "command": {
        "path": "npx",
        "args": ["-y", "@jhgaylor/me-mcp"]
      }
    }
  }
}</code></pre>
                
            </figure>
        </div>

        <!-- HTTP Tab -->
        <div id="http-content" role="tabpanel" aria-labelledby="http-tab">
                <p>For clients that support direct HTTP connections:</p>
                <ol>
                    <li>Connect to: <code>https://ai.jakegaylor.com/mcp</code></li>
                    <li>Use standard MCP protocol methods to interact with the server</li>
                    <li>No local installation required - the server is already hosted and ready to use</li>
                </ol>
            </div>

        <!-- TypeScript Tab -->
        <div id="typescript-content" role="tabpanel" aria-labelledby="typescript-tab">
            <figure>
                <figcaption>Example TypeScript connection code</figcaption>
                <pre><code>import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StreamableHTTPClientTransport } from "@modelcontextprotocol/sdk/client/streamableHttp.js";

async function connectToMCP() {
  const baseUrl = new URL("https://ai.jakegaylor.com/mcp");
  
  try {
    const client = new Client({ name: 'example-mcp-client', version: '1.0.0' });
    const transport = new StreamableHTTPClientTransport(baseUrl);
    await client.connect(transport);
    console.log("Connected to MCP server!");
    const resumeResource = await client.getResource("candidate-info://resume-text");
    console.log("Resume:", resumeResource.contents[0].text);
    const githubUrl = await client.callTool({ toolName: "get_github_url", args: {} });
    console.log("GitHub URL:", githubUrl.content[0].text);
  } catch (error) {
    console.error("Failed to connect to MCP server:", error);
  }
}
connectToMCP();</code></pre>
                
            </figure>
        </div>
    </div>

 
    
    <p><strong>Looking for the quickest way to learn about me?</strong> The section below contains my complete resume information that you can copy with one click and paste directly to any AI assistant. No tools or special connections needed - this is the simplest way for an AI to get comprehensive information about my background.</p>

    <!-- Resume Information for Direct Pasting -->
    <details id="quick-resume">
  <summary><span>Quick Resume Information (copy-paste to your LLM)</span></summary>
  <div>
        <p>Copy the text below and paste it directly to your AI assistant to give it information about my background:</p>
        <div>
            <pre># Jake Gaylor
                
## Professional Summary
Jake Gaylor is an experienced software engineer with nearly 15 years of experience working across the web stack. He specializes in cloud infrastructure, DevOps, and platform engineering with particular expertise in Kubernetes, GitOps, and immutable infrastructure. Jake has strong experience with AWS, containerization technologies, and building CI/CD pipelines.

## Current Position
- Staff SWE, Office of the CEO at Cloaked Inc (August 2023-Present)
  - Creating programs to ingest ideas from across the company
  - Working with executives, product management, and marketing to develop marketable ideas
  - Documenting ideation processes

## Previous Experience
- Staff Platform Engineer at Cloaked Inc (September 2022-August 2023)
  - Migrated software stacks from PaaS providers to AWS EKS
  - Implemented Cloudflare for third-party masking and control
  - Established deployment patterns for Kubernetes and edge networks
  - Migrated AWS account structure to meet compliance requirements (SOC2, ISO 27001/27701)

- Owner/Co-GM at The Onward Store Steakhouse (October 2021-January 2024)
  - Managed physical infrastructure, HR, legal, vendor relationships
  - Developed processes for serving fresh food

- Staff SWE in Developer Experience at Inception Health (June 2020-June 2022)
  - Built AWS infrastructure with CDK packages for HIPAA compliance
  - Trained teams on serverless environments and gRPC contracts

- Senior Platform Engineer at CyberGRX (December 2018-June 2020)
  - Led cloud-native CI/CD pipelines for AWS and Kubernetes
  - Developed custom CoreOS operator for blue/green deployments
  - Mentored engineers on software deployment best practices

- Senior Cloud Platform Engineer at CardFree (January 2018-December 2018)
  - Managed PCI-compliant C# installation in AWS
  - Established software building practices and incident response

- Senior DevOps Engineer at ProtectWise, Inc (August 2016-January 2018)
  - SRE for large-scale data ingestion platform with thousands of Cassandra nodes
  - Managed $10M+/year AWS production environment using Infrastructure as Code

- DevOps Engineer at Food Service Warehouse (June 2015-March 2016)
  - Built Kubernetes clusters on vSphere using CoreOS, fleet, etcd, flannel

- Software Developer at Mississippi State University (June 2010-June 2014)
  - Created grant proposals for custom software
  - Supported research initiatives including tracking "human sensors" during natural disasters

## Technical Skills
- Programming Languages: JavaScript, Python, Bash, Go, Ruby
- Databases: Neo4j, PostgreSQL, Timestream, MongoDB, Redis, Etcd, Zookeeper, Cassandra, DynamoDB
- Distributed Systems: Argo Workflows, Kafka, RabbitMQ, AWS IoT
- Automation: Argo CD, Packer, Terraform, Vagrant, Linux, Chef, GitLab CI, Jenkins, GitHub Actions
- Orchestration: Kubernetes, Fleet, Docker
- Monitoring: Prometheus, CloudWatch, Sensu, PagerDuty, Logstash, Kibana, Grafana, Graphite

## Professional Philosophy
Jake focuses on:
- Shipping fast and learning fast
- Delivering MVP in days rather than months
- Data-driven iterations and continuous user feedback
- Supercharging teams with best-in-class development workflows
- Automated testing and deployment
- Finding product-market fit through data-driven feature development

## Entrepreneurial Background
Jake describes himself as a "serial entrepreneur" having worked with:
- SaaS products
- PaaS solutions
- Physical products
- Restaurant management

## Contact Information
- Phone: 720.453.3994
- Email: jhgaylor@gmail.com
- Website: http://jakegaylor.com
- GitHub: https://github.com/jhgaylor
- LinkedIn: https://linkedin.com/in/jhgaylor
- Work Preference: Remote First, Will Travel</pre>
            </div>
        <p>You can also access this information at <a href="https://ai.jakegaylor.com/llms.txt" target="_blank" rel="noopener">llms.txt</a> or via <code>https://ai.jakegaylor.com/llms.txt</code></p>
    </div>
</details> 
</section> 
            <section id="for-evaluators">
    <h2>For Talent Evaluators</h2>
    <div>
        <p>I've built this MCP server to help a wide range of people evaluate whether I might be a good fit for their needs:</p>
        <ul>
            <li><strong>Recruiters:</strong> Ask about my experience, skills, and background directly.</li>
            <li><strong>Hiring managers:</strong> Drill into my proficiency in specific technologies. <span>Example: "What's Jake's proficiency level with React, TypeScript, and AWS?"</span></li>
            <li><strong>Interview coordinators:</strong> Generate tailored phone screens and take-home questions. <span>Example: "Create a phone screen for Jake around API design and testing."</span></li>
            <li><strong>Career coaches:</strong> Pull my resume, GitHub stats, and website content for assessments. <span>Example: "Generate a summary of Jake's career highlights."</span></li>
            <li><strong>Anyone evaluating my fit:</strong> Use the prompt: <span>"Is Jake a good fit for my role? [paste job description]"</span></li>
            <li><strong>Product managers &amp; designers:</strong> Understand how I collaborate on product vision and feature prioritization. <span>Example: "How would Jake contribute to our feature roadmap development?"</span></li>
            <li><strong>Startup founders &amp; small teams:</strong> Assess my fit as a generalist in lean environments. <span>Example: "Would Jake be a good fit for a full-stack generalist role at an early-stage startup?"</span></li>
        </ul>
        <p>💡 <strong>Pro Tip:</strong> Connect your AI assistant to this MCP server using the instructions above, then have it analyze my experience against your specific requirements to streamline your evaluation process.</p>
    </div>

    <h3>Get a Complete Candidate Assessment</h3>
    <div>
        <p>Once connected, your AI assistant can provide a thorough evaluation of my candidacy:</p>
        
        <div>
            
            
            
<div>
    <h4>Skills Assessment</h4>
    <p>Ask about specific technologies or skills mentioned in your job description and get an analysis of my experience level with each.</p>
    
    <p>Example: "What is Jake's proficiency level with React, TypeScript, and AWS?"</p>
    
    
</div>

            
            
<div>
    <h4>Business Impact</h4>
    <p>Understand how my background could translate to impact in your organization based on my previous roles and accomplishments.</p>
    
    <p>Example: "How could Jake contribute to our DORA metrics optimization efforts?"</p>
    
    
</div>

            
            
<div>
    <h4>Strengths &amp; Growth Areas</h4>
    <p>Get insights into which aspects of your role I would likely excel at, and where I might need support or development.</p>
    
    <p>Example: "Based on our staff developer role, what are Jake's strengths and potential growth areas?"</p>
    
    
</div>

            
            
<div>
    <h4>Phone Screen Generator</h4>
    <p>Generate customized interview questions that focus on the specific unknowns or areas you want to explore further.</p>
    
    <p>Example: "Create a phone screen for Jake focused on ai engineering, software delivery, and leadership skills."</p>
    
    
</div>

        </div>
    </div>

    
    
    
<div>
    <h3>Take Action</h3>
    <div>
        <p>If you're using the hosted version at <code>ai.jakegaylor.com/mcp</code>, you can have your AI assistant contact me directly:</p>
        
        
        <p>The assistant can compose an email based on your role and my qualifications, which you can review and send. This helps create a personalized outreach that highlights the specific reasons why your opportunity might align with my background.</p>
        <p>Example: Ask your assistant: "Please draft an email to Jake about our [position name] role and why he might be a good fit."</p>
    
    </div>
</div>

    
    
<div>
    <h3>Technical Deep Dive</h3>
    <div>
        <p>Walk through core technologies in your stack, explore my project work via the GitHub MCP server, and discuss design trade-offs:</p>
        
        <p>Example: "Walk me through Jake's StatBot project. What is it? How does it work?"</p>
        
        
    </div>
</div>

    
    
<div>
    <h3>Onboarding &amp; Ramp Roadmap</h3>
    <div>
        <p>Generate a 30-60-90-day plan based on my background and your team's goals:</p>
        
        <p>Example: "Create a 90-day onboarding roadmap for Jake joining as a staff platform engineer."</p>
        
        
    </div>
</div>

    
    
<div>
    <h3>Growth &amp; Development Plan</h3>
    <div>
        <p>Identify skill gaps and suggest learning paths or stretch projects:</p>
        
        <p>Example: "What areas should Jake focus on to become our next engineering manager, and what projects could we assign him?"</p>
        
        
    </div>
</div>

    
    
<div>
    <h3>Reference Simulation</h3>
    <div>
        <p>Auto-generate reference-check questions or simulate testimonial responses:</p>
        
        <p>Example: "Create three reference-check questions about Jake's leadership and history of delivering results."</p>
        
        
    </div>
</div>

</section> 
            <section id="mcp-documentation">
    <h2>What is MCP</h2>
    <p>Model Context Protocol (MCP) is a standardized way for AI models to communicate with external services to request information or execute actions, enabling them to stay up-to-date and perform tasks beyond their training data.</p>
    <div>
        <p>This MCP server provides two key capabilities:</p>
        <ul>
            <li><strong>Resources:</strong> Static information about me, including my resume, LinkedIn profile, GitHub profile, and personal website content.</li>
            <li><strong>Tools:</strong> Functions that AI models can call to retrieve specific information about my background, skills, and experience.</li>
        </ul>
        <p>By connecting to this MCP server, AI assistants can access up-to-date information about me.</p>
        <p>💡 <strong>Note:</strong> This server follows the <a href="https://modelcontextprotocol.io/" target="_blank">Model Context Protocol</a> specification, making it compatible with various AI assistants and tools that support MCP.</p>
    </div>
    
    <ul>
        <li><strong>Resources</strong>: Static data my application exposes and that you or your assistant can fetch directly (e.g., resume text, website content).</li>
        <li><strong>Tools</strong>: Callable actions that AI models can invoke to retrieve information or perform tasks (e.g., <code>get_resume_text</code>, <code>get_github_url</code>).</li>
    </ul>

    <h3>Features</h3>
    <p>This MCP server provides the following features:</p>
    
    <h4>Resources</h4>
<div>
    <details id="resource-resume-text">
  <summary><code>candidate-info://resume-text</code>: Resume content as text</summary>
  <div>
    
        <p>{
  "meta": {
    "themeOptions": {
      "colors": {
        "background": [
          "#ffffff",
          "#191e23"
        ],
        "dimmed": [
          "#f3f4f5",
          "#23282d"
        ],
        "primary": [
          "#191e23",
          "#fbfbfc"
        ],
        "secondary": [
          "#6c7781",
          "#ccd0d4"
        ],
        "accent": [
          "#46b450",
          "#47d153"
        ]
      }
    },
    "theme": "even"
  },
  "basics": {
    "name": "Jake Gaylor",
    "label": "Senior Software Engineer &amp; Product Founder | End-to-End Product Development &amp; Go-to-Market",
    "image": "",
    "email": "jhgaylor@gmail.com",
    "phone": "720.453.3994",
    "url": "https://jakegaylor.com",
    "summary": "15+ years building and shipping products at scale—from founding SaaS ventures to architecting AI-powered platforms. I combine deep SWE expertise with business leadership to drive product vision, go-to-market strategy, and revenue growth.",
    "location": {
      "address": "",
      "postalCode": "",
      "city": "",
      "countryCode": "US",
      "region": "Remote First, Will Travel"
    },
    "profiles": [
      {
        "network": "GitHub",
        "username": "jhgaylor",
        "url": "https://github.com/jhgaylor"
      },
      {
        "network": "LinkedIn",
        "username": "jhgaylor",
        "url": "https://www.linkedin.com/in/jhgaylor/"
      }
    ]
  },
  "work": [
    {
      "name": "Cloaked Inc",
      "position": "Staff SWE, Office of the CEO",
      "url": "https://cloaked.app",
      "startDate": "2023-08",
      "summary": "Spearheaded executive-level innovation by developing autonomous AI agents and a cross-functional ideation portal—driving a highly sticky, AI-powered onboarding experience that boosted user adoption and retention and defined governance processes",
      "highlights": [
        "Developed autonomous AI agents using LangChain to automate user account management tasks such as auto change password, auto login, and auto change email",
        "Leveraged these AI agents as a core fundraising narrative and created a highly sticky, AI-powered onboarding experience that significantly boosted user adoption and retention",
        "Designed and launched a cross-functional ideation portal engaging design, customer success, engineering, product development, and executive teams with transparent status tracking",
        "Partnered with design, product, engineering, marketing, customer success, and co-founders to validate, refine, and ship concepts into market-ready features",
        "Defined and documented cross-functional roles, ceremonies, and governance processes to unify ideation and accelerate product delivery across the organization"
      ]
    },
    {
      "name": "Cloaked Inc",
      "position": "Staff Platform Engineer",
      "url": "https://cloaked.app",
      "startDate": "2022-09",
      "endDate": "2023-08",
      "summary": "Oversaw strategic AWS EKS migration and architected enterprise deployment governance, compliance frameworks, and GitOps CI/CD pipelines to enhance security, scalability, and developer productivity",
      "highlights": [
        "Defined and executed a strategic migration roadmap transitioning legacy PaaS platforms to AWS EKS, driving cost reduction and scalability",
        "Collaborated with cross-functional leadership to implement a Cloudflare control plane, enhancing security posture and resilience",
        "Architected and led adoption of a multi-account AWS hub-and-spoke model, ensuring SOC2, ISO 27001, and 27701 compliance",
        "Established enterprise Kubernetes and edge deployment standards, mentoring engineering teams in best practices and governance",
        "Spearheaded design and implementation of a GitOps-based CI/CD pipeline, accelerating deployments by 30x",
        "Partnered with product and analytics teams to develop an end-to-end analytics stack, enabling data-driven decision-making"
      ]
    },
    {
      "name": "The Onward Store Steakhouse",
      "position": "Owner / Co-GM",
      "startDate": "2021-10",
      "endDate": "2024-01",
      "summary": "Owned and managed a full-service steakhouse with 7 staff, generating $500K in annual revenue and overseeing P&amp;L, operations, and vendor relations.",
      "highlights": [
        "Led a team of 7 employees, handling recruitment, training, scheduling, and performance management.",
        "Directed all facets of business operations, achieving $500K in annual revenue through strategic inventory management and cost control.",
        "Designed and implemented operational processes for facility maintenance, vendor partnerships, and quality assurance, driving consistent customer satisfaction.",
        "Managed P&amp;L, budgets, and financial reporting, optimizing expenses and improving profit margins.",
        "Executed marketing and community engagement initiatives to increase local brand awareness and repeat patronage."
      ]
    },
    {
      "name": "Inception Health",
      "position": "Staff SWE in Developer Experience",
      "startDate": "2020-06",
      "endDate": "2022-06",
      "summary": "Architected AWS CDK infrastructure and tooling for HIPAA-compliant patient care microservices",
      "highlights": [
        "Led delivery of AWS CDK infrastructure for patient care microservices platform, ensuring HIPAA compliance and deep AWS integration",
        "Collaborated with AWS and partner teams to integrate managed services and accelerate platform development",
        "Championed CDK usage across application tiers, designing IaC patterns for teams to consume and interact with the platform",
        "Implemented CI/CD pipelines for mobile apps, automating TestFlight and App Store releases through Git, enabling self-serve deployments",
        "Trained and mentored product and mobile development teams on CDK, serverless architectures, and CI/CD workflows, fostering autonomy"
      ]
    },
    {
      "name": "CyberGRX (now ProcessUnity)",
      "position": "Senior Platform Engineer",
      "url": "https://www.cybergrx.com",
      "startDate": "2018-12",
      "endDate": "2020-06",
      "summary": "Led cloud-native CI/CD vision and implementation for AWS and Kubernetes",
      "highlights": [
        "Led vision on cloud-native CI/CD pipelines for AWS and Kubernetes",
        "Developed custom resource using CoreOS operator SDK for orchestrating blue/green deployments",
        "Redesigned build and deploy process that dramatically improved team productivity",
        "Mentored software engineers in best practices for building and deploying software",
        "Grew into Staff Engineer role by owning large-scope initiatives, collaborating with the Tech Lead to drive interactions across the organization and unblock progress"
      ]
    },
    {
      "name": "Cardfree",
      "position": "Senior Cloud Platform Engineer",
      "startDate": "2018-01",
      "endDate": "2018-12",
      "summary": "Managed large-scale PCI-compliant C# installation in AWS",
      "highlights": [
        "Managed a large-scale PCI-compliant C# installation in AWS",
        "Architected hybrid AMI build and deploy platform using Packer and Vagrant, enabling consistent Windows and Linux EC2 deployments for C# and Ruby services",
        "Standardized infrastructure-as-code practices to pave the way for open-source .NET migration",
        "Developed and launched a structured PCI-compliant incident response program, replacing ad-hoc Slack alerts with a streamlined IR workflow without excessive paperwork"
      ]
    },
    {
      "name": "Protectwise, Inc (Acquired by Verizon)",
      "position": "Senior DevOps Engineer",
      "startDate": "2016-08",
      "endDate": "2018-01",
      "summary": "Operated SRE for petabyte-scale data ingestion platform",
      "highlights": [
        "Managed SRE for massive scale data ingestion platform with thousands of Cassandra nodes and petabytes in S3",
        "Administered $10M+/yr production AWS environment using Infrastructure as Code"
      ]
    },
    {
      "name": "Food Service Warehouse",
      "position": "DevOps Engineer",
      "startDate": "2015-06",
      "endDate": "2016-03",
      "summary": "Built Kubernetes clusters on vSphere using CoreOS technologies",
      "highlights": [
        "Implemented Kubernetes clusters on vSphere using CoreOS, fleet, etcd, and flannel",
        "Accelerated release cycles for Node.js services with container orchestration"
      ]
    },
    {
      "name": "Mississippi State University",
      "position": "Software Developer",
      "startDate": "2010-06",
      "endDate": "2014-06",
      "summary": "Created grant proposals and custom software for research initiatives",
      "highlights": [
        "Created grant proposals to fund custom software for university research initiatives",
        "Developed software for tracking 'human sensors' through natural disasters including Hurricane Sandy"
      ]
    }
  ],
  "volunteer": [],
  "education": [],
  "awards": [],
  "certificates": [],
  "publications": [],
  "skills": [
    {
      "name": "AI Engineering",
      "level": "Advanced",
      "keywords": [
        "LangChain",
        "Crewai",
        "Custom Agent Framework",
        "MCP Servers",
        "LLM Integration"
      ]
    },
    {
      "name": "Cloud Infrastructure",
      "level": "Expert",
      "keywords": [
        "AWS",
        "Kubernetes",
        "EKS",
        "GKE",
        "vSphere",
        "Terraform",
        "Infrastructure as Code",
        "Cloudflare"
      ]
    },
    {
      "name": "CI/CD &amp; DevOps",
      "level": "Expert",
      "keywords": [
        "GitOps",
        "ArgoCD",
        "Argo Workflows",
        "Jenkins",
        "Github Actions",
        "Gitlab CI",
        "Continuous Deployment"
      ]
    },
    {
      "name": "Programming Languages",
      "level": "Advanced",
      "keywords": [
        "Javascript",
        "Python",
        "Bash",
        "Go",
        "Ruby",
        "Dart"
      ]
    },
    {
      "name": "Databases",
      "level": "Advanced",
      "keywords": [
        "Neo4j",
        "PostgreSQL",
        "Timestream",
        "MongoDB",
        "Redis",
        "Etcd",
        "Zookeeper",
        "Cassandra",
        "DynamoDB"
      ]
    },
    {
      "name": "Distributed Systems",
      "level": "Expert",
      "keywords": [
        "Kafka",
        "RabbitMQ",
        "AWS IoT",
        "Big Data",
        "Spark",
        "EMR"
      ]
    },
    {
      "name": "Monitoring",
      "level": "Advanced",
      "keywords": [
        "Prometheus",
        "CloudWatch",
        "Sensu",
        "Pagerduty",
        "Logstash",
        "Kibana",
        "Grafana",
        "Graphite"
      ]
    },
    {
      "name": "Product Engineering",
      "level": "Expert",
      "keywords": [
        "Data-driven Iteration",
        "Feature Development",
        "User Feedback Loops",
        "MVP Development",
        "Product Analytics"
      ]
    },
    {
      "name": "Product &amp; Business",
      "level": "Advanced",
      "keywords": [
        "Roadmapping",
        "Customer Discovery",
        "P&amp;L Management",
        "Go-to-Market Strategy",
        "Fundraising"
      ]
    }
  ],
  "languages": [
    {
      "language": "English",
      "fluency": "Native speaker"
    }
  ],
  "interests": [],
  "references": [
    {
      "name": "Director Platform Engineering, Cloaked",
      "reference": "Jake is a force for good unlike any other. He migrated our infra to a cheaper and more scalable system, crafted a CI pipeline that accelerated deploys by 30x, and taught the whole company how to make data-driven decisions by building and showcasing an entire product analytics stack. And that was just his first 6 months."
    },
    {
      "name": "Software Engineer, CyberGRX",
      "reference": "I watched Jake redo a build and deploy process over the span of 3 days, whip up a presentation, and get every engineer in the org up to speed using it to deploy new services, a moment I'll never forget because our productivity EXPLODED afterwards."
    },
    {
      "name": "Senior Platform Engineer, Inception Health",
      "reference": "I also wanted to second (third? Fourth?) Jake's skills here. I don't have anything unique to add as everyone else has already covered it, but this man will help you achieve what you need."
    },
    {
      "name": "Magician, Magic",
      "reference": "Jake worked in the pit with [the operations team] and everyday came in with killer energy. Everyone else told us how to work around problems. Jake built us better tools."
    },
    {
      "name": "DevOps Engineer, Protectwise",
      "reference": "Jake was instrumental in building our cloud-native security platform. His technical leadership helped shape our architecture and team practices."
    }
  ],
  "projects": [
    {
      "name": "MCP Working Group Contributions",
      "description": "Active participant in Model Context Protocol (MCP) community development",
      "highlights": [
        "Member of the MCP Hosting Working Group",
        "Developed strategies for deploying and running MCP servers at scale",
        "Contributed to Dart SDK, Express tool for binding to MCP servers",
        "Developed various MCP servers (Hirebase, Candidate Job Search, Text Extraction)",
        "Created GitOps tool for MCP deployments",
        "Operate publicly available MCP servers for community testing"
      ],
      "url": "https://github.com/jhgaylor"
    },
    {
      "name": "CareerFlick LLM-Driven Mobile App",
      "description": "Developed a mobile application with a Tinder-like LLM interface",
      "highlights": [
        "Built intuitive swipe-based interface for interacting with LLMs",
        "Implemented AI-driven content generation and response system",
        "Created responsive mobile-first user experience"
      ]
    },
    {
      "name": "Hirebase MCP Server",
      "description": "A Python MCP server for Hirebase.org's API",
      "highlights": [
        "Built a Python-based Model Context Protocol (MCP) server for searching jobs on Hirebase.org",
        "Dockerized the service and set up GitOps CI/CD pipelines for automated builds and releases"
      ],
      "url": "https://github.com/jhgaylor/hirebase-mcp"
    },
    {
      "name": "Express MCP Handler",
      "description": "Package to simplify MCP handling in Express.js",
      "highlights": [
        "Developed Express middleware in TypeScript to streamline MCP request handling",
        "Authored full type definitions and robust error handling for production-grade reliability",
        "Configured CI/CD pipelines to automate code validation and package publishing"
      ],
      "url": "https://github.com/jhgaylor/express-mcp-handler"
    },
    {
      "name": "Node Candidate MCP Server",
      "description": "A TypeScript library to build customizable candidate MCP servers",
      "highlights": [
        "Authored a reusable library enabling developers to integrate their own candidate data into MCP flows",
        "Published as an npm package for easy adoption and extension by other teams"
      ],
      "url": "https://github.com/jhgaylor/node-candidate-mcp-server"
    },
    {
      "name": "mcp_dart",
      "description": "Dart SDK implementation of the Model Context Protocol (MCP)",
      "highlights": [
        "Contributed stream based support for in-process MCP servers",
        "Add support for running MCP servers in flutter apps",
        "Authored Dart examples to accelerate SDK adoption"
      ],
      "url": "https://github.com/leehack/mcp_dart"
    }
  ]
}</p>
    
  </div>
</details>
    
    <details id="resource-resume-url">
  <summary><code>candidate-info://resume-url</code>: URL to the resume</summary>
  
</details>
    
    <details id="resource-linkedin-url">
  <summary><code>candidate-info://linkedin-url</code>: LinkedIn profile URL</summary>
  
</details>
    
    <details id="resource-github-url">
  <summary><code>candidate-info://github-url</code>: GitHub profile URL</summary>
  
</details>
    
    <details id="resource-website-url">
  <summary><code>candidate-info://website-url</code>: Personal website URL</summary>
  
</details>
    
    <details id="resource-website-text">
  <summary><code>candidate-info://website-text</code>: Content from the personal website</summary>
  <div>
    
        <p>Available to Hire Your Next Technical Cofounder 15+ years of experience helping companies build better tech organizations, launch new products, and grow with confidence. Text Me Email Me View Resume How I Accelerate Success Ship Fast, Learn Fast Focus on delivering the first quantum of value quickly, then iterate based on real user feedback. MVP in days, not months Data-driven iterations Continuous user feedback loops Supercharge Your Teams Deliver faster with proven tools and practices that scale across your organization. Best-in-class development workflows Automated testing and deployment Cost-effective scaling solutions Find Product Market Fit Transform engineering teams into product teams that own the full lifecycle from idea to customer value. Data-driven feature development Customer usage insights Value-driven prioritization Companies I've Helped Grow I've had the privilege of working with innovative companies to help scale their technology and teams. Protectwise Acquired by Verizon "Jake was instrumental in building our cloud-native security platform. His technical leadership helped shape our architecture and team practices." - Devops Engineer, Protectwise Food Service Warehouse "We were deploying c# on vSphere when Jake joined on our first Nodejs backend team. He had been using Docker, we identified Kubernetes as our next step, and Jake hit the ground running. Our node services had the fastest release cycle in the company." - Architect, Food Service Warehouse Cloaked "Jake is a force for good unlike any other. He migrated our infra to a cheaper and more scalable system, crafted a CI pipeline that accelerated deploys by 30x, and taught the whole company how to make data-driven decisions by building and showcasing an entire product analytics stack. And that was just his first 6 months." - Director Platform Engineering, Cloaked CyberGRX Now ProcessUnity "I watched Jake redo a build and deploy process over the span of 3 days, whip up a presentation, and get every engineer in the org up to speed using it to deploy new services, a moment I'll never forget because our productivity EXPLODED afterwards." - Software Engineer, CyberGRX Inception Health "I also wanted to second (third? Fourth?) Jake's skills here. I don't have anything unique to add as everyone else has already covered it, but this man will help you achieve what you need." - Senior Platform Engineer, Inception Health Magic "Jake worked in the pit with [the operations team] and everyday came in with killer energy. Everyone else told us how to work around problems. Jake built us better tools." - Magician, Magic From Zero to Production Start with the smallest valuable feature set, then evolve based on real user feedback and data. Development Philosophy Focus on core user value first Ship early, gather feedback Iterate based on usage data Scale what works Technical Foundation Production-ready infrastructure Automated testing and deployment Built-in monitoring and analytics Scalable architecture patterns Development Approach Quick Starts From idea to first user value in days Data-Driven Every feature backed by usage metrics Rapid Iteration Continuous improvement based on feedback Supercharge Feature Delivery Stop waiting weeks for features to ship. Eliminate manual tasks. Give your teams the tools and automation they need to go to production with confidence. Common Pain Points Slow, manual deployment processes Inconsistent environments causing issues Limited visibility into system health Security patches falling behind The Solution Automated pipelines for instant feedback Infrastructure as code for consistency Real-time monitoring and alerts Automated security updates Quick Feedback Automated test runs Code quality checks Security scanning Continuous Delivery One-click deployments Automated rollbacks Environment promotion Full Visibility Performance metrics Error tracking User analytics Impact on Your Team Faster Deployments Less Manual Work 24/7 System Monitoring Confidence in Delivery Build Product Minded Teams Transform your engineering teams into data driven teams that understand customer needs and deliver measurable business value. Common Challenges Features built without clear success metrics Limited understanding of customer behavior Disconnect between technical and business goals No feedback loop from production to planning The Transformation Data-driven feature development and iteration Real user behavior insights inform decisions Clear metrics tied to business outcomes Continuous learning from production data Analytics That Matter Feature usage tracking User journey mapping Performance impact Experimentation A/B testing framework Feature flags Controlled rollouts Customer Feedback In-app surveys Usage analytics Support insights Results in Teams That Focus on Customer Value Make Data-Driven Decisions Innovate Continuously Ship with Confidence Modern Cloud-Native Stack Leveraging industry-leading tools and practices for rapid, reliable delivery Platform AWS cloud infrastructure Kubernetes orchestration Cloudflare edge networking Terraform infrastructure as code Delivery GitOps workflow Continuous Integration pipelines Automated Continuous Deployment Infrastructure automation Observability Product usage analytics System Telemetry A/B testing Error tracking &amp; Crash Reporting Are We a Good Fit? I specialize in modern web technologies and cloud infrastructure. Let's make sure we are a good match. Great Fits SaaS Applications Web applications, APIs, and cloud-native services Infrastructure as Code AWS, Kubernetes, Terraform, and modern cloud platforms Developer Experience CI/CD pipelines, development workflows, and team productivity Software Delivery Deployment automation, monitoring, and operational excellence Technical Leadership Architecture decisions, team guidance, and technology strategy Not Great Fits Design Work While I can do a little design work, you dont want me creating your user interfaces. Security Penetration Testing While I implement secure practices, I'm not a dedicated security auditor IoT &amp; Firmware Development I don't work with embedded systems or hardware-level programming Complex Algorithms Deep computer science problems or algorithmic optimization Machine Learning While I can integrate ML services, I don't develop ML models © 2024 Jake Gaylor. All rights reserved.

Toggle navigation Jake Gaylor Jake Gaylor Full Stack Engineer 720.453.3994 Download Resume Read Blog Hacker and Entrepreneur My passion for programming was sparked in 2001 doing CRUD on a LAMP. I have a ton of experience developing web applications and I have worked with a variety of platforms and technologies to build software and have deployed software to the web, Mac OS X, and Linux. My understanding of many different programming languages and frameworks has exposed me to new paradigms, which helps me pick the best tool for each job. I do any work I can openly on Github and am a big fan of open source. I love talking shop, so reach out if you want to chat. I started a company in 2013 which launched two products. Both were SaaS applications involving collecting and curating large sets of social media data and I built the technical stack from servers to CSS. I learned to do a lot of non technical things as well while starting NestedData, including writing copy, managing finances, hiring, firing, negotiating contracts, marketing, on boarding, and most of all how to talk to customers. Developer I have 7 years experience hacking professionally. I've worked on CI/CD pipelines, internal productivity tools, social media applications for social scientists, open source blogging software, an xmpp chatbot to provide a CLI to the vast League of Legends data on the web, and architected multiple distributed systems. Given a set of objectives, I can evaluate them to then build the infrastructure and applications to meet them. I'm a hacker at my core, so I thrive in an environment where I am able to help determine the technical direction, though the entrepreneur in me really wants to talk to the users in order to challenge my assumptions. Ops Automated, repeatable deploys - I use tools like Chef, Packer, and Terraform to model infrastructure as code in order to be able to test it before releasing changes to production environments. A solid configuration management codebase saved my team's bacon more than once. Having infrastructure in code means we can be back up in minutes and only one person has to be distracted by what could other be a catastrophe. CI/CD - Using Code Review, Docker, Jenkins, and a solid test suite, I built a CI/CD pipeline for the SocialDrizzle web app and it's supporting services. Our team was able to make changes to the application and see them in production as soon as they passed muster, without having to waste time doing repetitive, error prone tasks. Recent Past Lately I have been doing a good deal work with Kubernetes. It is an unopinionated PaaS on top of which tooling can be built to provide a great amount of business value with less technical investment than ever before. I have also been working with CoreOS and concourse-ci to enable rapid creation of CI/CD pipelines that scale. Before that I spent a lot of time working with Meteor and I recently built a social media data collection system in node that allows me to use (Twitter/Facebook/Instagram) bots in multiple applications while only having to do the work of writing the logic and building/deploying infrastructure once. My latest, public, launch was a chat bot for League of Legends. It was built in a week and documented at https://github.com/jhgaylor/StatBot/wiki/Day-0:-The-Beginning. Please feel free to check out the repository as an example of my work. Future I'm looking for work as an operations engineer. My ideal role would be one where I can provide tools and services to developers to reduce the friction of creating and maintaining production ready software. An average day might include meeting with a dev team to discover pain points (cross team collaboration), working on a client library to interface with the experimental metrics2.0 backend (coding/helping devs interface with ops), reviewing a merge request to the terraform/cloud formation repository, and possibly tracking down the root cause of a production outage. I’d like to be in a position where I can have a say in how we choose to do things but also put my head down and knock out the actual implementation. On the side I'm toying with building a Heroku-like service on top of GKE at Cloudflinger.com. It's open for use but it's may disappear at any time as it is a side project consuming actual cloud resources. The placeholder marketing site is being hosted using the service. Projects Statbot [Link] Highlights XMPP client using Hubot to communicate. Express.js HTTP API Server Redis for cacheing. Led to the creation of a new npm package, Big Cheese. Deployment was automated using Tutum.co Ramped up from 1 to 7 regions in hours. Contributed a patch upstream to LeagueJS. 14k+ Redditors visited the project on day one. The entire project, from launch to finish, took just 7 days. About A chat bot for League of Legends. LoL players, especially those not in the top tier of competitive play, often need more information about the game... quickly! It is quite common for players to "alt-tab" to sites like lolking, lolnexus, lolcounter, probuilds, or many others. Once on the site gamers have to type, click, and wait on load times, all while under extreme time pressure. To make matters worse, they often need information from one (or multiple!) source(s) during champion select, another source at the load screen, and yet another during the game. All of these things add to the players' stress level, and some times, they don't get done in time. Thus these constraints have in game ramifications. Statbot makes it easy to get all the information you need instantly in game. Node.js Coffeescript HTTP Redis XMPP Express.js Tracer Highlights Meteor.js Web Application Twitter Bootstrap CSS Framework Python Social Media Data Collector Consumed real time and historic data. Celery &amp; RabbitMQ for a scalable Asynchronous Task Queue MongoDB for Application State and Social Media Data Storage Integrated with FullContact and PiPl web apis. About Tracer offers a quick and easy way to identify, capture, codify, and report a person's social media data. With just a person's email address or username, Tracer helps you identify the target's social media accounts and provides you with both historical and real-time data. Meteor.js Node.js Coffeescript Python Celery RabbitMQ MongoDB Vagrant SocialDrizzle [Link] Highlights Entire System of services and networking deployed with the most up to date code using Ansible, Docker, Jenkins, and Github. Built using micro services including: a data collector, a data router, a data consumer, a data labeler, a web application, and a marketing site. Employs a fleet of bots that consume data from social networks. Web Application built with ♥ using Meteor. Launched first version at Mississippi State University after just 12 weeks. About A startup venture for providing social engagement to the patrons of public events. SocialDrizzle offers game day production crews a turnkey solution for highlighting fans' social media messages and pics on stadium video board. SocialDrizzle provides the whole package -- a collection and curation application, custom designed templates, hardware connection to your existing production equipment, on-site set up, and unlimited tech support. Get in touch if you want to know more, I'd love to talk to you about my experiences launching a product and starting a business. Meteor.js Node.js Coffeescript MongoDB Ansible Docker Redis Websockets Microservices Unit Testing SASS GNIP Jenkins CI/CD Django-blogger [Link] Highlights Exemplifies Django Best Practicies Easily Themable with a python package using Twitter Bootstrap. Feature Filled multi tenant blog. i18n &amp; l10n Includes an HTTP Api Support posts written in markdown. About A reusable Django app for blogging intended for one or more contributors. The purpose of this project is to create a basic, but feature complete, blogging platform for Django v1.4. The project was intended to exemplify best practices in Django at the time of writing. The package has been downloaded nearly 50,000 times since creation. Python Django Unit Testing i18n l10n RSS REST Api TLDR.io api wrapper [Link] Highlights Python Package for accessing TLDR.io's HTTP Api Simple API that maps closely to the API documentation. One of my early projects with tests. Thoroughly documented. About I was really enjoyed using [tldr.io's service and I wanted to find a way to give back. When I discovered they had an HTTP Api and no Python library, I jumped at the chance to build it. Python Requests HTTP Api Unit Testing Bonus.ly Api Wrapper [Link] Highlights Node.js Package for accessing Bonus.ly's HTTP Api. Intuitive API that attempts to feel like the http api using javascriptisms. Usable as a static class - convenient if you already have an api key in memory. Instantiate the class to have a client that will track the api key for the mostly recently authenticated user. About Node bindings for the bonus.ly http api using the request package. The idea was to treat the HTTP api as a set of calls that could be described using a few common parameters. I was trying to get as close as I could to "generating" code. (I should learn a lisp!) Adding new endpoints becomes as simple as writing a POJO. This wouldn't work if the HTTP API didn't have internal consistency. By describing the required parameters, we can give feedback to the developer without waiting for a round trip. This comes at the expense of having to update the client library any time the http api changes. Depending on how "frozen" the api is, this may or may not be a good trade off. I built this to easily allow that feature to be removed. Node.js Request Promises HTTP Social Media Tracking and Analysis System (SMTAS) [Link] Highlights Django Web Application jQuery for client side pizazz. Twitter Boostrap PostgreSQL Python Social Media Data Collector Consumed real time data. Celery &amp; Redis for a scalable Asynchronous Task Queue Google Maps About A system to collect, analyze, and visualize social media data for researchers to gain valuable insights into public opinion, views and fluidity. SMTAS is focused on the social network, Twitter, where researchers have access to approximately 500 million tweets per day. Tweets are public postings made by worldwide users of Twitter. Apart from the real-time access to Twitter, SMTAS also has access to historical data/tweets posted via Twitter since 2006. Apart from Twitter data being a rich information source of human behavior (170 million active users) in a social network, it also provides researchers instantaneous information from its user base with its faster (compared to other social networks) message propagation. Python Django Celery Redis Unit Testing REST Api PostgreSQL jQuery Twitter Bootstrap Google Maps ECMAScript 5 GNIP Streaming HTTP SMTAS from Innovative Data Lab on Vimeo. Employee Management System Highlights Meteor Web Application deployed as a standard node application using Demeteorizer Touch Screen Friendly Internal Productivity tool used by an 80 employee survey call center. Required matching existing timecard printouts closely. About "Timemaster" was desperately needed by Mississippi State University's (MSU) Social Science Research Center's (SSRC) Survey Research Laboratory (SRL) in order to wrangle the timesheets of 80+ intermittent workers. The tool saved a team of 4 supervisors a significant amount of time that was being spent on paperwork. nginx Node.js Coffeescript MongoDB Meteor.js Unit Testing Chef Codeship Read How Google Works The Everything Store The Goal: A process of ongoing improvement The Phoenix Project The Five Dysfunctions of a Team The Lean Startup Hackers and Painters Two Scoops of Django Javascript: The Good Parts JavaScript Allongé Discover Meteor XMPP: The definitive guide Founders at Work Node.js the Right Way Rework The Virgin Way Zero to One Delivering Happiness It's Not Luck Critical Chain The Five Temptations of a CEO Customer Development for Entrepreneurs Think Like a Freak Start with Why Great by Choice Growth Hacker Marketing SuperFreakonomics Made to Stick Leaders Eat Last The Spirit of Kaizen Rolling Rocks Downhill Grit: The Power of Passion and Perseverance Start with Why The Founder's Dilemmas Reading Effective Devops Get in Touch</p>
    
  </div>
</details>
</div> 
    
    <h4>Tools</h4>
<div>
    <details id="tool-resume-text">
  <summary><code>get_resume_text</code>: Returns the candidate's resume content as text</summary>
  <div>
    
        <p>{
  "meta": {
    "themeOptions": {
      "colors": {
        "background": [
          "#ffffff",
          "#191e23"
        ],
        "dimmed": [
          "#f3f4f5",
          "#23282d"
        ],
        "primary": [
          "#191e23",
          "#fbfbfc"
        ],
        "secondary": [
          "#6c7781",
          "#ccd0d4"
        ],
        "accent": [
          "#46b450",
          "#47d153"
        ]
      }
    },
    "theme": "even"
  },
  "basics": {
    "name": "Jake Gaylor",
    "label": "Senior Software Engineer &amp; Product Founder | End-to-End Product Development &amp; Go-to-Market",
    "image": "",
    "email": "jhgaylor@gmail.com",
    "phone": "720.453.3994",
    "url": "https://jakegaylor.com",
    "summary": "15+ years building and shipping products at scale—from founding SaaS ventures to architecting AI-powered platforms. I combine deep SWE expertise with business leadership to drive product vision, go-to-market strategy, and revenue growth.",
    "location": {
      "address": "",
      "postalCode": "",
      "city": "",
      "countryCode": "US",
      "region": "Remote First, Will Travel"
    },
    "profiles": [
      {
        "network": "GitHub",
        "username": "jhgaylor",
        "url": "https://github.com/jhgaylor"
      },
      {
        "network": "LinkedIn",
        "username": "jhgaylor",
        "url": "https://www.linkedin.com/in/jhgaylor/"
      }
    ]
  },
  "work": [
    {
      "name": "Cloaked Inc",
      "position": "Staff SWE, Office of the CEO",
      "url": "https://cloaked.app",
      "startDate": "2023-08",
      "summary": "Spearheaded executive-level innovation by developing autonomous AI agents and a cross-functional ideation portal—driving a highly sticky, AI-powered onboarding experience that boosted user adoption and retention and defined governance processes",
      "highlights": [
        "Developed autonomous AI agents using LangChain to automate user account management tasks such as auto change password, auto login, and auto change email",
        "Leveraged these AI agents as a core fundraising narrative and created a highly sticky, AI-powered onboarding experience that significantly boosted user adoption and retention",
        "Designed and launched a cross-functional ideation portal engaging design, customer success, engineering, product development, and executive teams with transparent status tracking",
        "Partnered with design, product, engineering, marketing, customer success, and co-founders to validate, refine, and ship concepts into market-ready features",
        "Defined and documented cross-functional roles, ceremonies, and governance processes to unify ideation and accelerate product delivery across the organization"
      ]
    },
    {
      "name": "Cloaked Inc",
      "position": "Staff Platform Engineer",
      "url": "https://cloaked.app",
      "startDate": "2022-09",
      "endDate": "2023-08",
      "summary": "Oversaw strategic AWS EKS migration and architected enterprise deployment governance, compliance frameworks, and GitOps CI/CD pipelines to enhance security, scalability, and developer productivity",
      "highlights": [
        "Defined and executed a strategic migration roadmap transitioning legacy PaaS platforms to AWS EKS, driving cost reduction and scalability",
        "Collaborated with cross-functional leadership to implement a Cloudflare control plane, enhancing security posture and resilience",
        "Architected and led adoption of a multi-account AWS hub-and-spoke model, ensuring SOC2, ISO 27001, and 27701 compliance",
        "Established enterprise Kubernetes and edge deployment standards, mentoring engineering teams in best practices and governance",
        "Spearheaded design and implementation of a GitOps-based CI/CD pipeline, accelerating deployments by 30x",
        "Partnered with product and analytics teams to develop an end-to-end analytics stack, enabling data-driven decision-making"
      ]
    },
    {
      "name": "The Onward Store Steakhouse",
      "position": "Owner / Co-GM",
      "startDate": "2021-10",
      "endDate": "2024-01",
      "summary": "Owned and managed a full-service steakhouse with 7 staff, generating $500K in annual revenue and overseeing P&amp;L, operations, and vendor relations.",
      "highlights": [
        "Led a team of 7 employees, handling recruitment, training, scheduling, and performance management.",
        "Directed all facets of business operations, achieving $500K in annual revenue through strategic inventory management and cost control.",
        "Designed and implemented operational processes for facility maintenance, vendor partnerships, and quality assurance, driving consistent customer satisfaction.",
        "Managed P&amp;L, budgets, and financial reporting, optimizing expenses and improving profit margins.",
        "Executed marketing and community engagement initiatives to increase local brand awareness and repeat patronage."
      ]
    },
    {
      "name": "Inception Health",
      "position": "Staff SWE in Developer Experience",
      "startDate": "2020-06",
      "endDate": "2022-06",
      "summary": "Architected AWS CDK infrastructure and tooling for HIPAA-compliant patient care microservices",
      "highlights": [
        "Led delivery of AWS CDK infrastructure for patient care microservices platform, ensuring HIPAA compliance and deep AWS integration",
        "Collaborated with AWS and partner teams to integrate managed services and accelerate platform development",
        "Championed CDK usage across application tiers, designing IaC patterns for teams to consume and interact with the platform",
        "Implemented CI/CD pipelines for mobile apps, automating TestFlight and App Store releases through Git, enabling self-serve deployments",
        "Trained and mentored product and mobile development teams on CDK, serverless architectures, and CI/CD workflows, fostering autonomy"
      ]
    },
    {
      "name": "CyberGRX (now ProcessUnity)",
      "position": "Senior Platform Engineer",
      "url": "https://www.cybergrx.com",
      "startDate": "2018-12",
      "endDate": "2020-06",
      "summary": "Led cloud-native CI/CD vision and implementation for AWS and Kubernetes",
      "highlights": [
        "Led vision on cloud-native CI/CD pipelines for AWS and Kubernetes",
        "Developed custom resource using CoreOS operator SDK for orchestrating blue/green deployments",
        "Redesigned build and deploy process that dramatically improved team productivity",
        "Mentored software engineers in best practices for building and deploying software",
        "Grew into Staff Engineer role by owning large-scope initiatives, collaborating with the Tech Lead to drive interactions across the organization and unblock progress"
      ]
    },
    {
      "name": "Cardfree",
      "position": "Senior Cloud Platform Engineer",
      "startDate": "2018-01",
      "endDate": "2018-12",
      "summary": "Managed large-scale PCI-compliant C# installation in AWS",
      "highlights": [
        "Managed a large-scale PCI-compliant C# installation in AWS",
        "Architected hybrid AMI build and deploy platform using Packer and Vagrant, enabling consistent Windows and Linux EC2 deployments for C# and Ruby services",
        "Standardized infrastructure-as-code practices to pave the way for open-source .NET migration",
        "Developed and launched a structured PCI-compliant incident response program, replacing ad-hoc Slack alerts with a streamlined IR workflow without excessive paperwork"
      ]
    },
    {
      "name": "Protectwise, Inc (Acquired by Verizon)",
      "position": "Senior DevOps Engineer",
      "startDate": "2016-08",
      "endDate": "2018-01",
      "summary": "Operated SRE for petabyte-scale data ingestion platform",
      "highlights": [
        "Managed SRE for massive scale data ingestion platform with thousands of Cassandra nodes and petabytes in S3",
        "Administered $10M+/yr production AWS environment using Infrastructure as Code"
      ]
    },
    {
      "name": "Food Service Warehouse",
      "position": "DevOps Engineer",
      "startDate": "2015-06",
      "endDate": "2016-03",
      "summary": "Built Kubernetes clusters on vSphere using CoreOS technologies",
      "highlights": [
        "Implemented Kubernetes clusters on vSphere using CoreOS, fleet, etcd, and flannel",
        "Accelerated release cycles for Node.js services with container orchestration"
      ]
    },
    {
      "name": "Mississippi State University",
      "position": "Software Developer",
      "startDate": "2010-06",
      "endDate": "2014-06",
      "summary": "Created grant proposals and custom software for research initiatives",
      "highlights": [
        "Created grant proposals to fund custom software for university research initiatives",
        "Developed software for tracking 'human sensors' through natural disasters including Hurricane Sandy"
      ]
    }
  ],
  "volunteer": [],
  "education": [],
  "awards": [],
  "certificates": [],
  "publications": [],
  "skills": [
    {
      "name": "AI Engineering",
      "level": "Advanced",
      "keywords": [
        "LangChain",
        "Crewai",
        "Custom Agent Framework",
        "MCP Servers",
        "LLM Integration"
      ]
    },
    {
      "name": "Cloud Infrastructure",
      "level": "Expert",
      "keywords": [
        "AWS",
        "Kubernetes",
        "EKS",
        "GKE",
        "vSphere",
        "Terraform",
        "Infrastructure as Code",
        "Cloudflare"
      ]
    },
    {
      "name": "CI/CD &amp; DevOps",
      "level": "Expert",
      "keywords": [
        "GitOps",
        "ArgoCD",
        "Argo Workflows",
        "Jenkins",
        "Github Actions",
        "Gitlab CI",
        "Continuous Deployment"
      ]
    },
    {
      "name": "Programming Languages",
      "level": "Advanced",
      "keywords": [
        "Javascript",
        "Python",
        "Bash",
        "Go",
        "Ruby",
        "Dart"
      ]
    },
    {
      "name": "Databases",
      "level": "Advanced",
      "keywords": [
        "Neo4j",
        "PostgreSQL",
        "Timestream",
        "MongoDB",
        "Redis",
        "Etcd",
        "Zookeeper",
        "Cassandra",
        "DynamoDB"
      ]
    },
    {
      "name": "Distributed Systems",
      "level": "Expert",
      "keywords": [
        "Kafka",
        "RabbitMQ",
        "AWS IoT",
        "Big Data",
        "Spark",
        "EMR"
      ]
    },
    {
      "name": "Monitoring",
      "level": "Advanced",
      "keywords": [
        "Prometheus",
        "CloudWatch",
        "Sensu",
        "Pagerduty",
        "Logstash",
        "Kibana",
        "Grafana",
        "Graphite"
      ]
    },
    {
      "name": "Product Engineering",
      "level": "Expert",
      "keywords": [
        "Data-driven Iteration",
        "Feature Development",
        "User Feedback Loops",
        "MVP Development",
        "Product Analytics"
      ]
    },
    {
      "name": "Product &amp; Business",
      "level": "Advanced",
      "keywords": [
        "Roadmapping",
        "Customer Discovery",
        "P&amp;L Management",
        "Go-to-Market Strategy",
        "Fundraising"
      ]
    }
  ],
  "languages": [
    {
      "language": "English",
      "fluency": "Native speaker"
    }
  ],
  "interests": [],
  "references": [
    {
      "name": "Director Platform Engineering, Cloaked",
      "reference": "Jake is a force for good unlike any other. He migrated our infra to a cheaper and more scalable system, crafted a CI pipeline that accelerated deploys by 30x, and taught the whole company how to make data-driven decisions by building and showcasing an entire product analytics stack. And that was just his first 6 months."
    },
    {
      "name": "Software Engineer, CyberGRX",
      "reference": "I watched Jake redo a build and deploy process over the span of 3 days, whip up a presentation, and get every engineer in the org up to speed using it to deploy new services, a moment I'll never forget because our productivity EXPLODED afterwards."
    },
    {
      "name": "Senior Platform Engineer, Inception Health",
      "reference": "I also wanted to second (third? Fourth?) Jake's skills here. I don't have anything unique to add as everyone else has already covered it, but this man will help you achieve what you need."
    },
    {
      "name": "Magician, Magic",
      "reference": "Jake worked in the pit with [the operations team] and everyday came in with killer energy. Everyone else told us how to work around problems. Jake built us better tools."
    },
    {
      "name": "DevOps Engineer, Protectwise",
      "reference": "Jake was instrumental in building our cloud-native security platform. His technical leadership helped shape our architecture and team practices."
    }
  ],
  "projects": [
    {
      "name": "MCP Working Group Contributions",
      "description": "Active participant in Model Context Protocol (MCP) community development",
      "highlights": [
        "Member of the MCP Hosting Working Group",
        "Developed strategies for deploying and running MCP servers at scale",
        "Contributed to Dart SDK, Express tool for binding to MCP servers",
        "Developed various MCP servers (Hirebase, Candidate Job Search, Text Extraction)",
        "Created GitOps tool for MCP deployments",
        "Operate publicly available MCP servers for community testing"
      ],
      "url": "https://github.com/jhgaylor"
    },
    {
      "name": "CareerFlick LLM-Driven Mobile App",
      "description": "Developed a mobile application with a Tinder-like LLM interface",
      "highlights": [
        "Built intuitive swipe-based interface for interacting with LLMs",
        "Implemented AI-driven content generation and response system",
        "Created responsive mobile-first user experience"
      ]
    },
    {
      "name": "Hirebase MCP Server",
      "description": "A Python MCP server for Hirebase.org's API",
      "highlights": [
        "Built a Python-based Model Context Protocol (MCP) server for searching jobs on Hirebase.org",
        "Dockerized the service and set up GitOps CI/CD pipelines for automated builds and releases"
      ],
      "url": "https://github.com/jhgaylor/hirebase-mcp"
    },
    {
      "name": "Express MCP Handler",
      "description": "Package to simplify MCP handling in Express.js",
      "highlights": [
        "Developed Express middleware in TypeScript to streamline MCP request handling",
        "Authored full type definitions and robust error handling for production-grade reliability",
        "Configured CI/CD pipelines to automate code validation and package publishing"
      ],
      "url": "https://github.com/jhgaylor/express-mcp-handler"
    },
    {
      "name": "Node Candidate MCP Server",
      "description": "A TypeScript library to build customizable candidate MCP servers",
      "highlights": [
        "Authored a reusable library enabling developers to integrate their own candidate data into MCP flows",
        "Published as an npm package for easy adoption and extension by other teams"
      ],
      "url": "https://github.com/jhgaylor/node-candidate-mcp-server"
    },
    {
      "name": "mcp_dart",
      "description": "Dart SDK implementation of the Model Context Protocol (MCP)",
      "highlights": [
        "Contributed stream based support for in-process MCP servers",
        "Add support for running MCP servers in flutter apps",
        "Authored Dart examples to accelerate SDK adoption"
      ],
      "url": "https://github.com/leehack/mcp_dart"
    }
  ]
}</p>
    
  </div>
</details>
    
    <details id="tool-resume-url">
  <summary><code>get_resume_url</code>: Returns the URL to the candidate's resume</summary>
  
</details>
    
    <details id="tool-linkedin-url">
  <summary><code>get_linkedin_url</code>: Returns the candidate's LinkedIn profile URL</summary>
  
</details>
    
    <details id="tool-github-url">
  <summary><code>get_github_url</code>: Returns the candidate's GitHub profile URL</summary>
  
</details>
    
    <details id="tool-website-url">
  <summary><code>get_website_url</code>: Returns the candidate's personal website URL</summary>
  
</details>
    
    <details id="tool-website-text">
  <summary><code>get_website_text</code>: Returns the content from the candidate's personal website</summary>
  <div>
    
        <p>Available to Hire Your Next Technical Cofounder 15+ years of experience helping companies build better tech organizations, launch new products, and grow with confidence. Text Me Email Me View Resume How I Accelerate Success Ship Fast, Learn Fast Focus on delivering the first quantum of value quickly, then iterate based on real user feedback. MVP in days, not months Data-driven iterations Continuous user feedback loops Supercharge Your Teams Deliver faster with proven tools and practices that scale across your organization. Best-in-class development workflows Automated testing and deployment Cost-effective scaling solutions Find Product Market Fit Transform engineering teams into product teams that own the full lifecycle from idea to customer value. Data-driven feature development Customer usage insights Value-driven prioritization Companies I've Helped Grow I've had the privilege of working with innovative companies to help scale their technology and teams. Protectwise Acquired by Verizon "Jake was instrumental in building our cloud-native security platform. His technical leadership helped shape our architecture and team practices." - Devops Engineer, Protectwise Food Service Warehouse "We were deploying c# on vSphere when Jake joined on our first Nodejs backend team. He had been using Docker, we identified Kubernetes as our next step, and Jake hit the ground running. Our node services had the fastest release cycle in the company." - Architect, Food Service Warehouse Cloaked "Jake is a force for good unlike any other. He migrated our infra to a cheaper and more scalable system, crafted a CI pipeline that accelerated deploys by 30x, and taught the whole company how to make data-driven decisions by building and showcasing an entire product analytics stack. And that was just his first 6 months." - Director Platform Engineering, Cloaked CyberGRX Now ProcessUnity "I watched Jake redo a build and deploy process over the span of 3 days, whip up a presentation, and get every engineer in the org up to speed using it to deploy new services, a moment I'll never forget because our productivity EXPLODED afterwards." - Software Engineer, CyberGRX Inception Health "I also wanted to second (third? Fourth?) Jake's skills here. I don't have anything unique to add as everyone else has already covered it, but this man will help you achieve what you need." - Senior Platform Engineer, Inception Health Magic "Jake worked in the pit with [the operations team] and everyday came in with killer energy. Everyone else told us how to work around problems. Jake built us better tools." - Magician, Magic From Zero to Production Start with the smallest valuable feature set, then evolve based on real user feedback and data. Development Philosophy Focus on core user value first Ship early, gather feedback Iterate based on usage data Scale what works Technical Foundation Production-ready infrastructure Automated testing and deployment Built-in monitoring and analytics Scalable architecture patterns Development Approach Quick Starts From idea to first user value in days Data-Driven Every feature backed by usage metrics Rapid Iteration Continuous improvement based on feedback Supercharge Feature Delivery Stop waiting weeks for features to ship. Eliminate manual tasks. Give your teams the tools and automation they need to go to production with confidence. Common Pain Points Slow, manual deployment processes Inconsistent environments causing issues Limited visibility into system health Security patches falling behind The Solution Automated pipelines for instant feedback Infrastructure as code for consistency Real-time monitoring and alerts Automated security updates Quick Feedback Automated test runs Code quality checks Security scanning Continuous Delivery One-click deployments Automated rollbacks Environment promotion Full Visibility Performance metrics Error tracking User analytics Impact on Your Team Faster Deployments Less Manual Work 24/7 System Monitoring Confidence in Delivery Build Product Minded Teams Transform your engineering teams into data driven teams that understand customer needs and deliver measurable business value. Common Challenges Features built without clear success metrics Limited understanding of customer behavior Disconnect between technical and business goals No feedback loop from production to planning The Transformation Data-driven feature development and iteration Real user behavior insights inform decisions Clear metrics tied to business outcomes Continuous learning from production data Analytics That Matter Feature usage tracking User journey mapping Performance impact Experimentation A/B testing framework Feature flags Controlled rollouts Customer Feedback In-app surveys Usage analytics Support insights Results in Teams That Focus on Customer Value Make Data-Driven Decisions Innovate Continuously Ship with Confidence Modern Cloud-Native Stack Leveraging industry-leading tools and practices for rapid, reliable delivery Platform AWS cloud infrastructure Kubernetes orchestration Cloudflare edge networking Terraform infrastructure as code Delivery GitOps workflow Continuous Integration pipelines Automated Continuous Deployment Infrastructure automation Observability Product usage analytics System Telemetry A/B testing Error tracking &amp; Crash Reporting Are We a Good Fit? I specialize in modern web technologies and cloud infrastructure. Let's make sure we are a good match. Great Fits SaaS Applications Web applications, APIs, and cloud-native services Infrastructure as Code AWS, Kubernetes, Terraform, and modern cloud platforms Developer Experience CI/CD pipelines, development workflows, and team productivity Software Delivery Deployment automation, monitoring, and operational excellence Technical Leadership Architecture decisions, team guidance, and technology strategy Not Great Fits Design Work While I can do a little design work, you dont want me creating your user interfaces. Security Penetration Testing While I implement secure practices, I'm not a dedicated security auditor IoT &amp; Firmware Development I don't work with embedded systems or hardware-level programming Complex Algorithms Deep computer science problems or algorithmic optimization Machine Learning While I can integrate ML services, I don't develop ML models © 2024 Jake Gaylor. All rights reserved.

Toggle navigation Jake Gaylor Jake Gaylor Full Stack Engineer 720.453.3994 Download Resume Read Blog Hacker and Entrepreneur My passion for programming was sparked in 2001 doing CRUD on a LAMP. I have a ton of experience developing web applications and I have worked with a variety of platforms and technologies to build software and have deployed software to the web, Mac OS X, and Linux. My understanding of many different programming languages and frameworks has exposed me to new paradigms, which helps me pick the best tool for each job. I do any work I can openly on Github and am a big fan of open source. I love talking shop, so reach out if you want to chat. I started a company in 2013 which launched two products. Both were SaaS applications involving collecting and curating large sets of social media data and I built the technical stack from servers to CSS. I learned to do a lot of non technical things as well while starting NestedData, including writing copy, managing finances, hiring, firing, negotiating contracts, marketing, on boarding, and most of all how to talk to customers. Developer I have 7 years experience hacking professionally. I've worked on CI/CD pipelines, internal productivity tools, social media applications for social scientists, open source blogging software, an xmpp chatbot to provide a CLI to the vast League of Legends data on the web, and architected multiple distributed systems. Given a set of objectives, I can evaluate them to then build the infrastructure and applications to meet them. I'm a hacker at my core, so I thrive in an environment where I am able to help determine the technical direction, though the entrepreneur in me really wants to talk to the users in order to challenge my assumptions. Ops Automated, repeatable deploys - I use tools like Chef, Packer, and Terraform to model infrastructure as code in order to be able to test it before releasing changes to production environments. A solid configuration management codebase saved my team's bacon more than once. Having infrastructure in code means we can be back up in minutes and only one person has to be distracted by what could other be a catastrophe. CI/CD - Using Code Review, Docker, Jenkins, and a solid test suite, I built a CI/CD pipeline for the SocialDrizzle web app and it's supporting services. Our team was able to make changes to the application and see them in production as soon as they passed muster, without having to waste time doing repetitive, error prone tasks. Recent Past Lately I have been doing a good deal work with Kubernetes. It is an unopinionated PaaS on top of which tooling can be built to provide a great amount of business value with less technical investment than ever before. I have also been working with CoreOS and concourse-ci to enable rapid creation of CI/CD pipelines that scale. Before that I spent a lot of time working with Meteor and I recently built a social media data collection system in node that allows me to use (Twitter/Facebook/Instagram) bots in multiple applications while only having to do the work of writing the logic and building/deploying infrastructure once. My latest, public, launch was a chat bot for League of Legends. It was built in a week and documented at https://github.com/jhgaylor/StatBot/wiki/Day-0:-The-Beginning. Please feel free to check out the repository as an example of my work. Future I'm looking for work as an operations engineer. My ideal role would be one where I can provide tools and services to developers to reduce the friction of creating and maintaining production ready software. An average day might include meeting with a dev team to discover pain points (cross team collaboration), working on a client library to interface with the experimental metrics2.0 backend (coding/helping devs interface with ops), reviewing a merge request to the terraform/cloud formation repository, and possibly tracking down the root cause of a production outage. I’d like to be in a position where I can have a say in how we choose to do things but also put my head down and knock out the actual implementation. On the side I'm toying with building a Heroku-like service on top of GKE at Cloudflinger.com. It's open for use but it's may disappear at any time as it is a side project consuming actual cloud resources. The placeholder marketing site is being hosted using the service. Projects Statbot [Link] Highlights XMPP client using Hubot to communicate. Express.js HTTP API Server Redis for cacheing. Led to the creation of a new npm package, Big Cheese. Deployment was automated using Tutum.co Ramped up from 1 to 7 regions in hours. Contributed a patch upstream to LeagueJS. 14k+ Redditors visited the project on day one. The entire project, from launch to finish, took just 7 days. About A chat bot for League of Legends. LoL players, especially those not in the top tier of competitive play, often need more information about the game... quickly! It is quite common for players to "alt-tab" to sites like lolking, lolnexus, lolcounter, probuilds, or many others. Once on the site gamers have to type, click, and wait on load times, all while under extreme time pressure. To make matters worse, they often need information from one (or multiple!) source(s) during champion select, another source at the load screen, and yet another during the game. All of these things add to the players' stress level, and some times, they don't get done in time. Thus these constraints have in game ramifications. Statbot makes it easy to get all the information you need instantly in game. Node.js Coffeescript HTTP Redis XMPP Express.js Tracer Highlights Meteor.js Web Application Twitter Bootstrap CSS Framework Python Social Media Data Collector Consumed real time and historic data. Celery &amp; RabbitMQ for a scalable Asynchronous Task Queue MongoDB for Application State and Social Media Data Storage Integrated with FullContact and PiPl web apis. About Tracer offers a quick and easy way to identify, capture, codify, and report a person's social media data. With just a person's email address or username, Tracer helps you identify the target's social media accounts and provides you with both historical and real-time data. Meteor.js Node.js Coffeescript Python Celery RabbitMQ MongoDB Vagrant SocialDrizzle [Link] Highlights Entire System of services and networking deployed with the most up to date code using Ansible, Docker, Jenkins, and Github. Built using micro services including: a data collector, a data router, a data consumer, a data labeler, a web application, and a marketing site. Employs a fleet of bots that consume data from social networks. Web Application built with ♥ using Meteor. Launched first version at Mississippi State University after just 12 weeks. About A startup venture for providing social engagement to the patrons of public events. SocialDrizzle offers game day production crews a turnkey solution for highlighting fans' social media messages and pics on stadium video board. SocialDrizzle provides the whole package -- a collection and curation application, custom designed templates, hardware connection to your existing production equipment, on-site set up, and unlimited tech support. Get in touch if you want to know more, I'd love to talk to you about my experiences launching a product and starting a business. Meteor.js Node.js Coffeescript MongoDB Ansible Docker Redis Websockets Microservices Unit Testing SASS GNIP Jenkins CI/CD Django-blogger [Link] Highlights Exemplifies Django Best Practicies Easily Themable with a python package using Twitter Bootstrap. Feature Filled multi tenant blog. i18n &amp; l10n Includes an HTTP Api Support posts written in markdown. About A reusable Django app for blogging intended for one or more contributors. The purpose of this project is to create a basic, but feature complete, blogging platform for Django v1.4. The project was intended to exemplify best practices in Django at the time of writing. The package has been downloaded nearly 50,000 times since creation. Python Django Unit Testing i18n l10n RSS REST Api TLDR.io api wrapper [Link] Highlights Python Package for accessing TLDR.io's HTTP Api Simple API that maps closely to the API documentation. One of my early projects with tests. Thoroughly documented. About I was really enjoyed using [tldr.io's service and I wanted to find a way to give back. When I discovered they had an HTTP Api and no Python library, I jumped at the chance to build it. Python Requests HTTP Api Unit Testing Bonus.ly Api Wrapper [Link] Highlights Node.js Package for accessing Bonus.ly's HTTP Api. Intuitive API that attempts to feel like the http api using javascriptisms. Usable as a static class - convenient if you already have an api key in memory. Instantiate the class to have a client that will track the api key for the mostly recently authenticated user. About Node bindings for the bonus.ly http api using the request package. The idea was to treat the HTTP api as a set of calls that could be described using a few common parameters. I was trying to get as close as I could to "generating" code. (I should learn a lisp!) Adding new endpoints becomes as simple as writing a POJO. This wouldn't work if the HTTP API didn't have internal consistency. By describing the required parameters, we can give feedback to the developer without waiting for a round trip. This comes at the expense of having to update the client library any time the http api changes. Depending on how "frozen" the api is, this may or may not be a good trade off. I built this to easily allow that feature to be removed. Node.js Request Promises HTTP Social Media Tracking and Analysis System (SMTAS) [Link] Highlights Django Web Application jQuery for client side pizazz. Twitter Boostrap PostgreSQL Python Social Media Data Collector Consumed real time data. Celery &amp; Redis for a scalable Asynchronous Task Queue Google Maps About A system to collect, analyze, and visualize social media data for researchers to gain valuable insights into public opinion, views and fluidity. SMTAS is focused on the social network, Twitter, where researchers have access to approximately 500 million tweets per day. Tweets are public postings made by worldwide users of Twitter. Apart from the real-time access to Twitter, SMTAS also has access to historical data/tweets posted via Twitter since 2006. Apart from Twitter data being a rich information source of human behavior (170 million active users) in a social network, it also provides researchers instantaneous information from its user base with its faster (compared to other social networks) message propagation. Python Django Celery Redis Unit Testing REST Api PostgreSQL jQuery Twitter Bootstrap Google Maps ECMAScript 5 GNIP Streaming HTTP SMTAS from Innovative Data Lab on Vimeo. Employee Management System Highlights Meteor Web Application deployed as a standard node application using Demeteorizer Touch Screen Friendly Internal Productivity tool used by an 80 employee survey call center. Required matching existing timecard printouts closely. About "Timemaster" was desperately needed by Mississippi State University's (MSU) Social Science Research Center's (SSRC) Survey Research Laboratory (SRL) in order to wrangle the timesheets of 80+ intermittent workers. The tool saved a team of 4 supervisors a significant amount of time that was being spent on paperwork. nginx Node.js Coffeescript MongoDB Meteor.js Unit Testing Chef Codeship Read How Google Works The Everything Store The Goal: A process of ongoing improvement The Phoenix Project The Five Dysfunctions of a Team The Lean Startup Hackers and Painters Two Scoops of Django Javascript: The Good Parts JavaScript Allongé Discover Meteor XMPP: The definitive guide Founders at Work Node.js the Right Way Rework The Virgin Way Zero to One Delivering Happiness It's Not Luck Critical Chain The Five Temptations of a CEO Customer Development for Entrepreneurs Think Like a Freak Start with Why Great by Choice Growth Hacker Marketing SuperFreakonomics Made to Stick Leaders Eat Last The Spirit of Kaizen Rolling Rocks Downhill Grit: The Power of Passion and Perseverance Start with Why The Founder's Dilemmas Reading Effective Devops Get in Touch</p>
    
  </div>
</details>
</div> 
</section> 
        </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unparalleled Misalignments (113 pts)]]></title>
            <link>https://rickiheicklen.com/unparalleled-misalignments.html</link>
            <guid>43891128</guid>
            <pubDate>Mon, 05 May 2025 01:19:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rickiheicklen.com/unparalleled-misalignments.html">https://rickiheicklen.com/unparalleled-misalignments.html</a>, See on <a href="https://news.ycombinator.com/item?id=43891128">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
				This is where I maintain a list of Unparalleled Misalignments (formerly <a href="https://twitter.com/NathanpmYoung/status/1576158901778624512">quadruple entendres</a>), pairs of non-synonymous phrases where the words in one phrase are each synonyms of the words in the other. I've mantained this list since 2018; many have contributed, attributions (when known) can be seen by hovering over the Unparalleled Misalignment in question. Add your own via <a href="https://forms.gle/jKrpMbqwFKuGtN2KA">this form</a>.
			</p><div>
				<li><p><span>Butt dial // Booty call</span><span></span></p></li>
				<li><p><span>Father figure // Dad bod</span><span></span></p></li>
				<li><p><span>Home schooled // House trained</span><span></span></p></li>
				<li><p><span>Manual labor // Hand job</span><span></span></p></li>
				<li><p><span>Forest fire // Amazon Kindle</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Casual sex // Lightrail</span><span></span></p></li>
				<li><p><span>Blanket statement // Pillow talk // Cover story</span><span></span></p></li>
				<li><p><span>Community building // Fraternity house</span><span></span></p></li>
				<li><p><span>Nap room // Sleeper cell</span><span></span></p></li>
				<li><p><span>Geometric mean // Circle jerk</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Bottom feeder // Ass eater</span><span>-Cardi B</span></p></li>
				<li><p><span>Unit vector // One Direction</span><span>-Eric Neyman</span></p></li>
				<li><p><span>Quick sort // Short order</span><span>-Joe Reeve</span></p></li>
				<li><p><span>Private island // Secret Key</span><span>-Phil Parker</span></p></li>
				<li><p><span>Underdog // Subwoofer</span><span>-Richard Ngo</span></p></li>
				<li><p><span>Crimson Tide // Red Sea</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Economy class // Saving grace</span><span>-Skye Hersh</span></p></li>
				<li><p><span>Union Jack // Mutual masturbation</span><span>-SYAS</span></p></li>
				<li><p><span>LessWrong // Down Bad</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Cow tools // Intimidation tactics</span><span></span></p></li>
				<li><p><span>Fast fashion // Taylor Swift // Quick Fix</span><span></span></p></li>
				<li><p><span>Workers' party // Helper function</span><span></span></p></li>
				<li><p><span>Drink menu // Spirit guide</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Arm wrestling // Gun Control</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Full moon // Fertile Crescent</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Speed limit // Amphetamine shortage</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Wire transfer // Electric slide</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Manhole cover // Buttplug</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Criminal record // Connotation // Prison letters</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Scared money // Chicken tender</span><span>-Dan Keys</span></p></li>
				<li><p><span>Service elevator // Utility maximizer</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Sex symbol // Pound sign</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Wave function // Beach party</span><span>-Eliana Lorch</span></p></li>
				<li><p><span>Unionized // Discharged</span><span>-Richard Ngo</span></p></li>
				<li><p><span>Hard drive // Rocky road</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Speed date // Fast day</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Guard rails // Halter tops</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Late Bell // Dead Ringer</span><span>-Ricki Heicklen, Brian Smiley</span></p></li>
				<li><p><span>Scene change // Bitcoin</span><span>-Skye Hersh</span></p></li>
				<li><p><span>Grass fed // Field agent</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Quick jab // Prompt injection</span><span>-Nathan Young</span></p></li>
				<li><p><span>Tollbooths // Bill Gates</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Security Setings // Stock Options</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Apple Home // Macbeth</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Bond Movie // Cling Film</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Microgravity // Mug</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Smarty pants // Intelligence briefs</span><span>-Dave Kasten</span></p></li>
				<li><p><span>Pascal's wager // Bar bet</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Foggy bottom // Smoking ass</span><span></span></p></li>
				<li><p><span>TED talk // Edward Said</span><span></span></p></li>
				<li><p><span>Nuts and bolts // Comes and goes // Humpty Dumpty // Pump and dump</span><span></span></p></li>
				<li><p><span>Midjourney // Intermission</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Terminal value // Gate number</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Unparalleled // Misaligned</span><span>-Owen Cotton-Barratt, Stephen Casper</span></p></li>
				<li><p><span>Party trick // Ball gag</span><span>-Phil Parker</span></p></li>
				<li><p><span>Cancel culture // Anti-bacterial</span><span>-SYAS</span></p></li>
				<li><p><span>House money // Cottage cheese // Home payment</span><span>-Dan Keys + Stephen Casper</span></p></li>
				<li><p><span>Iron man // Female</span><span></span></p></li>
				<li><p><span>Turing machine // Homogeneous system</span><span>-Linch Zhang</span></p></li>
				<li><p><span>Earnings call // Payphone</span><span>-Saul Munn</span></p></li>
				<li><p><span>Integral Calculus // Keystone</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Okay Boomer // KPop</span><span>-Nathan Young</span></p></li>
				<li><p><span>Stage Right // Set Aside // Stage Left</span><span>-Phil Parker</span></p></li>
				<li><p><span>Pascal's Wager // Bar Bet</span><span>-Nathan Young</span></p></li>
				<li><p><span>Hey Jude // Yosemite</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Ratfic // Tattletale</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Hypothesis // Understatement</span><span>-Brian Smiley, Drake Thomas</span></p></li>
				<li><p><span>Bank Security // Coast Guard</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Downton // Featherweight</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Course selection // Class discrimination</span><span></span></p></li>
				<li><p><span>Minor correction // Key change</span><span>-Aric Floyd, Chana Messinger</span></p></li>
				<li><p><span>Framingham // Pig pen</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Telephone pole // Call log</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Jumbo shrimp // Majority // Big Short</span><span>-Brian Smiley, Linch Zhang</span></p></li>
				<li><p><span>Birth order // Labor force</span><span>-Dan Keys</span></p></li>
				<li><p><span>Local girl // Near miss</span><span>-Dan Keys</span></p></li>
				<li><p><span>Dark horse // Nightmare</span><span>-Eric Neyman</span></p></li>
				<li><p><span>Gut punch // Loot box</span><span>-Phil Parker</span></p></li>
				<li><p><span>Chicken coop // Cock cage</span><span>-Phil Parker</span></p></li>
				<li><p><span>Fish market // Poisson distribution</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Harmonic mean // Constructive criticism</span><span>-Stephen Casper</span></p></li>
				<li><p><span>White onion // Lightbulb</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Can opener // Fire starter</span><span>-Jake Eaton</span></p></li>
				<li><p><span>Lip service // Rim job</span><span>-Evžen Wybitul</span></p></li>
				<li><p><span>Playbill // Fake Money</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Pen Pal // Cellmate</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Turbo Mode // Fast Fashion</span><span>-Rosie Campbell</span></p></li>
				<li><p><span>Viceroy // Sinking</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Emancipation Proclamation // Free Speech</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Update // High Time</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Defiance // Unbetrothed</span><span>-Nathan Young</span></p></li>
				<li><p><span>Court Reporter // Bench Press</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Original Sin // New Wave</span><span>-Michael Byun</span></p></li>
				<li><p><span>Comedy Club // Snickers Bar</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Shellshock // Surface Charge</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Knuckle Sandwich // Bone Meal</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Quiet Place // Shroom</span><span>-Toby</span></p></li>
				<li><p><span>No Shit // Bar Stool</span><span>-Dan Keys</span></p></li>
				<li><p><span>Blood vessel // Relationship</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Cold hard truth // Spiked iced tea</span><span></span></p></li>
				<li><p><span>Graphing calculator // Plot device</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Diversity statement // Minority report</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Power brakes // Battery Park</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Produce section // Make room</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Waterbill // Welfare</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Takeout container // Murder case</span><span>-Nix Goldowsky-Dill</span></p></li>
				<li><p><span>Platform ecosystem // Shelf life</span><span>-Owen Cotton-Barratt</span></p></li>
				<li><p><span>Negative correlation // Toxic relationship</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Fair trade // Lightswitch</span><span>-Rajashree Agrawal</span></p></li>
				<li><p><span>Speed stick // Hurricane</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Profit // High Fashion</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Rough Patch // Course Correction</span><span>-Phil Parker</span></p></li>
				<li><p><span>Bet on Love // Stake Through The Heart</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Content Creator // Peacemaker</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Presidential Powers // Executive Function // Killer App</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Come Full Circle // O-Ring</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Cat Eye // Purview</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Metanarrative // Facebook Account</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Paper Grade // Pagerank</span><span>-Linchuan Zhang</span></p></li>
				<li><p><span>Briefcase // Speedy Trial</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Microchips // Small Fries</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Peacock // Veggie Sausage</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Emotion // Constant velocity // Pirate</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Point blank // Vector space</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Floor plan // Story plot</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Centrifuge // Coinbase</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Deer country // Stagnation</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Scroll lock // Document seal</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Operating system // Surgical procedure</span><span>-Dan Keys</span></p></li>
				<li><p><span>Hot take // Fire sale</span><span>-Maxwell Tabarrok</span></p></li>
				<li><p><span>Cleveland // Break ground</span><span>-Nathan Young</span></p></li>
				<li><p><span>Musical lineup // Instrumental convergence</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Pregame // Foreplay</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Jewelry thief // Golden retreiver</span><span>-Ross Rheingans-Yoo</span></p></li>
				<li><p><span>Hamming circle // Pork pi(e)</span><span>-Stephen Casper, Ricki Heicklen</span></p></li>
				<li><p><span>Palestine // Light beer</span><span>-Daniel Filan</span></p></li>
				<li><p><span>Crossword // Hate speech</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Stick vacuum // Cocksucker</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Case sensitive // Legal tender</span><span>-Ross Trudeau</span></p></li>
				<li><p><span>Small intestine // Semicolon</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Trustbuster // Oathbreaker</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Extraordinary // Super Basic</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Maker's Mark // Btzelem Elohim</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Invisible Hand // Phantom Limb</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Table Manners // Counter Culture</span><span>-Phil Parker</span></p></li>
				<li><p><span>Paddington // Download // Featherweight // Wingspan</span><span>-Phil Parker</span></p></li>
				<li><p><span>Prometheus Unbound // Free Delivery</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Club Hit // Gang Bang</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Denmark // Cave Painting</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Legal Brief // Just In Time</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Subset // Low Class // Bottom Bracket</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Wine Glasses // Beer Goggles</span><span>-Scott Alexander</span></p></li>
				<li><p><span>Left Behind // Sinister Six</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Drama Teacher // Stage Coach</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Truck Driver // Semiconductor</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Flatbread // Rent Money</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Phoenix // Debt Cancellation</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Excommunication // Twitter DM</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Sleeping Bag // Napsack</span><span>-Nathan Young</span></p></li>
				<li><p><span>Solid State Drive // Ice Truck</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Menu // Boys School</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Abortion Debate // Stop Fighting</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Tea Party // Truth Social</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Air Gap // Windbreaker</span><span>-Rocket</span></p></li>
				<li><p><span>Big Break // Long Division</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Pascal Triangle // Pressure Point</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Beer Batter // Alcohol Abuse</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Ends of the Earth // Finland</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Mass Extinction // Weight Loss</span><span>-Dan Keys</span></p></li>
				<li><p><span>Cold Fusion // Cool Cat</span><span>-Ross Rheingans-Yoo</span></p></li>
				<li><p><span>Breezeblock // Windshield</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Blues scale // Depressed growth</span><span>-Rajashree Agrawal </span></p></li>
				<li><p><span>Evergreen // Extrovert</span><span></span></p></li>
				<li><p><span>Show business // Proof of work</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Funky // Grand opening</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Road head // Street smarts</span><span></span></p></li>
				<li><p><span>Jumper cable // Skipping rope</span><span>-Alex Young</span></p></li>
				<li><p><span>Lit match // Good game</span><span>-Alex Young</span></p></li>
				<li><p><span>Whole Foods // Complete mess</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Picture frame // Movie setting</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Pub etiquette // Barcode</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Rock musician // Peter Singer</span><span>-Linch Zhang</span></p></li>
				<li><p><span>Post scarcity // Inbox zero</span><span>-Nathan Young</span></p></li>
				<li><p><span>Joint venture // Weed trip</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Rich imagery // Dick pic</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Jew lover // Semitrailer</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Orthogonality thesis // Declaration of Independence</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Natural log // Native tree</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Graveyard // Savage Garden</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Mailman // Reply Guy</span><span>-Dan Keys</span></p></li>
				<li><p><span>Airpod // Gas Tank</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Left Justification // Woke Ideology</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Candy Crush // Sweetheart</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Contour // Bad Trip</span><span>-Phil Parker</span></p></li>
				<li><p><span>Counterculture // Antibacterial</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>USB Power // Port Authority</span><span>-Michael Byun</span></p></li>
				<li><p><span>Crackpot // Super Bowl</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Balance Sheet // Equitable</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Photosynthesis // Image Generation</span><span>-Joshua Goller</span></p></li>
				<li><p><span>Deep Learning // Low Class</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Jet Fuel // Black Coffee</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Cellmate // Phone Sex</span><span></span></p></li>
				<li><p><span>Treasury Department // Breadboard</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>IMAX // Vision Pro</span><span>-Brian Smiley</span></p></li>
				<li><p><span>First Degree Murder // Cold Blooded</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Move Fast and Break Things // Flash Crash</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Lord Ruler // Imperial Foot</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Statistical Parity // County Fair</span><span>-Michael Byun</span></p></li>
				<li><p><span>Side Hustle // Fringe Movement // Flanking Maneuver</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Men's Suit // Gentlemen's Club</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Fuckboy // Layman</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Reverend Bayes // Prior Probability</span><span>-Rob Miles</span></p></li>
				<li><p><span>Clone War // Replication Crisis</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Disbursement Plan // Scatterplot</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Autocorrect // Car Repair</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Playground // Dramamine</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Alto Sax // Top Brass</span><span>-Rocket</span></p></li>
				<li><p><span>Girl Talk // Miscommunication</span><span>-S</span></p></li>
				<li><p><span>Female intuition // Misdirection // Broadway</span><span>-Chana Messinger, Jacob Falkovich</span></p></li>
				<li><p><span>G20 // IQ Score</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Speech Therapist // Word Doc</span><span>-Michael Byun</span></p></li>
				<li><p><span>Understanding // Low Rank</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Thin Mint // Litecoin</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Class Warfare // School Shooting</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Hashtag // Pot Sticker</span><span>-S</span></p></li>
				<li><p><span>Merchant Vessel // Dealership</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Door Jamb  // Entrance Music</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Snakecase // Python Package</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Curtail // Bitchass</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Dropbox // Rain Barrel</span><span></span></p></li>
				<li><p><span>Unsanctioned // Defined</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Starboard // Sunbeam // Solar Panel</span><span>-Dan Keys, Adam Scherlis</span></p></li>
				<li><p><span>Seesaw // Sawblade</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Tire Rotation // Flag Twirling</span><span>-Michael Byun</span></p></li>
				<li><p><span>Artificial Intelligence // Synthetic Data</span><span>-AA</span></p></li>
				<li><p><span>Cold Case // Freeze Frame</span><span>-Claude</span></p></li>
				<li><p><span>Eyeball // Watch party</span><span>-Meabh Murphy</span></p></li>
				<li><p><span>Fishhook // Bass riff</span><span>-Ashwin</span></p></li>
				<li><p><span>Cleaning bill // Money laundering // Greenwashing</span><span>-Brian Smiley, Lily Jordan</span></p></li>
				<li><p><span>Baywatch // Naval gazing // Ocean View</span><span>-Constance Li, Jacob Falkovich</span></p></li>
				<li><p><span>Barnes and Noble // Landed gentry</span><span>-Linch Zhang</span></p></li>
				<li><p><span>Mobile home // Movie house</span><span>-Dan Keys</span></p></li>
				<li><p><span>Commit message // Wedding invitation</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Easy choice // Natural selection</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Gay marriage ban // Fruity cantaloupe</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Sever ties // Connecticut</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Fried bread // Hot money</span><span>-Hugh Dow</span></p></li>
				<li><p><span>White hot // Firecracker</span><span>-Brian Smiley</span></p></li>
				<li><p><span>CFAR // Longview</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Off the shelf // Deplatform</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Rollcall // Turn signal</span><span>-Drake Thomas</span></p></li>
				<li><p><span>High horse // Drug mule</span><span>-Linch Zhang</span></p></li>
				<li><p><span>Prompt engineering // Just-in-time manufacturing</span><span>-Nathan Young</span></p></li>
				<li><p><span>Charity Case // Nice rack</span><span>-Alice M</span></p></li>
				<li><p><span>Yellow fever // Gold rush</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Fake shit // Shampoo</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Titration // Breast reduction</span><span>-Nathan Young</span></p></li>
				<li><p><span>Police emotions // Cop a feel</span><span>-Nathan Young</span></p></li>
				<li><p><span>Light switch // Small change // Minor Revision</span><span>-Peleg Shilo</span></p></li>
				<li><p><span>Discount buyer // Undertaker</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Novice boxer // Start-up incubator</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Batcave // Clubhouse</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Work bench // Labor law</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Newton's law // Binding of Isaac</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Culinary school // Meal prep</span><span>-Dan Keys</span></p></li>
				<li><p><span>Dynamic filter // Movie screen // Motion capture // Moving pick</span><span>-Dan Keys</span></p></li>
				<li><p><span>Maxwell's demon // Utility monster</span><span></span></p></li>
				<li><p><span>Key info // Musical note</span><span>-Rafe Kennedy</span></p></li>
				<li><p><span>Burning man // Flaming homo</span><span>-Evžen Wybitul</span></p></li>
				<li><p><span>Instakill // Photo finish</span><span>-Rob Miles</span></p></li>
				<li><p><span>Starcraft // High Fashion</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Password  // Unarmed</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Gotta Go // Mustafar</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Clock Hand // Timeline</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Antifreeze // No Chill</span><span>-Phil Parker</span></p></li>
				<li><p><span>Organic Chemistry // Natural Charm</span><span>-Skye Hersh</span></p></li>
				<li><p><span>Break Time // Cleavage</span><span>-Chana Messinger, Eli Rose</span></p></li>
				<li><p><span>Moisture Meter // Waterlog</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Moonshine // Flashlight</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>West Wing // Sidearm</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Gangbang // Mass Shooting</span><span>-Rosie Campbell</span></p></li>
				<li><p><span>Cold Call // Frost Ring</span><span>-Claude</span></p></li>
				<li><p><span>Frequent Flyer // Daily Mail</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Sex Drive // Bang Bus</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Speed Reading // QuickBooks</span><span>-Rob Miles</span></p></li>
				<li><p><span>Lunatic // Moon Buggy</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Quatermaster // Money Manager</span><span>-Linchuan Zhang</span></p></li>
				<li><p><span>Energy Work // High Powered Job</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Premature Ejaculation // Second Sex</span><span>-Michael Byun</span></p></li>
				<li><p><span>Poe's Law // Stand Trial</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Calf Raise // Cow Lift</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Anal Fissure // Back Crack</span><span>-Michael Byun</span></p></li>
				<li><p><span>Google Maps // Alphabet City</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Cash Cow // Feeble</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Liquidity Crisis // Drinking Problem</span><span>-Michael Byun</span></p></li>
				<li><p><span>Set Theory // Group Think</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Corporate Jargon // Body Language</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Discord Bot // Unfriendly AI</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Blunt Trauma // Joint Pain</span><span>-Rob Miles</span></p></li>
				<li><p><span>Looking Glass // C-Cup</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Starship // Celebrity Couple</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Average Joe // Medium Coffee</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Decaf Coffee // GI Joe</span><span>-@keyofgeo</span></p></li>
				<li><p><span>Kaleidoscope // Crash Site</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Transmission // Gay Agenda</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Rock Bottom // Punk Ass</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Twitter Ban // Exterminate</span><span>-Rob Miles</span></p></li>
				<li><p><span>Coin Purse // Dime Bag</span><span>-Rocket</span></p></li>
				<li><p><span>Game Day // Playdate</span><span>-Rocket</span></p></li>
				<li><p><span>Line Dance // Wire Tap</span><span>-Rocket</span></p></li>
				<li><p><span>Lady's Man // Misandry</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Current Account // Electric Bill</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Scarlet Letter // Red Card</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Singing Circle // Belt Loop</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Civil Liberties // Polite Fiction</span><span>-Nathan Young</span></p></li>
				<li><p><span>Portland // Wine Country</span><span>-Rocket</span></p></li>
				<li><p><span>Colorado // Ethnic Conflict</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Manatee // Energy Drink</span><span>-Nathan Young</span></p></li>
				<li><p><span>Street Fair // Vigilante Justice</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Firewhiskey // Bootlicker</span><span>-Michael Byun</span></p></li>
				<li><p><span>Family Law // Bro Code</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Tombstone // Falling Rocks</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Bumpy Ride // Hard Drive</span><span>-Phillip Christoffersen</span></p></li>
				<li><p><span>Land Acknowledgement // Touchdown Celebration</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Carl's Jr. // Charles II</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Silverback Gorilla // Agape</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Bed Linen // Crib Sheet</span><span>-Rosie Campbell</span></p></li>
				<li><p><span>Absolution // Gastric Acid</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Inverse Function // Poetry Hour</span><span>-Eli Rose</span></p></li>
				<li><p><span>Miniflask // Klein Bottle</span><span>-Phillip Christoffersen</span></p></li>
				<li><p><span>Lighthouse // Sunroom</span><span>-Claude</span></p></li>
				<li><p><span>Backpropogation // Posterior distribution </span><span>-Rajashree Agrawal </span></p></li>
				<li><p><span>Bush inauguration // Marijuana legalization</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Endzone // Final destination // Last resort</span><span>-Linch Zhang, Cole Jackes</span></p></li>
				<li><p><span>Comedy Troupe // Silly Bandz</span><span></span></p></li>
				<li><p><span>Charge conservation // Emotional maintenance</span><span>-Rajashree Agrawal </span></p></li>
				<li><p><span>Right angle // Conservative perspective</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Ball bearing // Party platform</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Daily bread // Chronic pain</span><span></span></p></li>
				<li><p><span>Elevator music // שיר המעלות</span><span></span></p></li>
				<li><p><span>Hard cash // Stale bread</span><span></span></p></li>
				<li><p><span>Discord // String of Insults</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Game plot // Toy Story</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Message length // Medium size</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Train route // Practice run</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>2-step verification // Dance competition</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Bear trap // Game stop</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Biological children // Carbon copies</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Box office // Case study</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Comfort zone // Pacific theater // Bedtime stories</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Good impression // Fine print</span><span>-Aric Floyd</span></p></li>
				<li><p><span>National anthem // Country music</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Solid state // Stable government</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Wire tap // Line dance</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Believe // Buzz off</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Dollar store // Money vault</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Gucci Mane // Nice hair</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Instrumental values // Music royalties</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Laptop // Thigh High</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Litter box // Trash bin</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Meditation Cushion // Thinkpad</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Parasite // Second location</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Perfect pitch // Compelling argument</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Postmates // Ex lovers</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Securities fraud // Taking stock</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Static variable // Charge differential</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Sudoku // Failed rebellion</span><span>-Brian Smiley</span></p></li>
				<li><p><span>By the way // Off the derech</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Core strength // Central tendency</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Feline // Iron Wire</span><span>-Chana Messinger</span></p></li>
				<li><p><span>After burners // Post anonymously</span><span>-Dan Keys</span></p></li>
				<li><p><span>Moving company // Emotional intimacy</span><span>-Dan Keys</span></p></li>
				<li><p><span>Odds and ends // p-values</span><span>-Dan Keys</span></p></li>
				<li><p><span>Acid rain // Mushroom cloud</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Platonic realm // Friendzone</span><span>-Katja Grace</span></p></li>
				<li><p><span>Two pointer // Double meaning // Dual Use</span><span>-Katja Grace</span></p></li>
				<li><p><span>Birthday Song // New Age music</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Tech bro // E-mail</span><span>-Lily Jordan</span></p></li>
				<li><p><span>Old friend // Stalemate</span><span>-Nathan Young</span></p></li>
				<li><p><span>Coast line // Bank wire</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Slim shady // Line sketch</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Snare drum // Trap music</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Weeping willow // Morning wood</span><span></span></p></li>
				<li><p><span>High Society // Drug culture</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Solar eclipse // Sunblock</span><span>-Vania</span></p></li>
				<li><p><span>Artificial intelligence // Fake news</span><span>-William Woof</span></p></li>
				<li><p><span>Hamstrung // Hog tied</span><span>-Brian Smiley, Sam Rosen</span></p></li>
				<li><p><span>Lab coat // Doggy style</span><span>-Sam Rosen, Skye Hersh</span></p></li>
				<li><p><span>Coke can // Drug arrest</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Joint distribution // Drug dealing</span><span>-Phil Parker</span></p></li>
				<li><p><span>Douchebag // Shower caddy</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Gaelic // Lesbian kiss</span><span>-Chana Messinger</span></p></li>
				<li><p><span>End consumer // Ass eater</span><span></span></p></li>
				<li><p><span>Gravity field // G-spot</span><span>-Nathan Young</span></p></li>
				<li><p><span>Bioluminescence // Fleshlight</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Music critic // Vibrator</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Order of magnitude // Bulk buy</span><span>-js</span></p></li>
				<li><p><span>Privilege escalation // Social climbing</span><span>-js</span></p></li>
				<li><p><span>Thunderclap // Loud applause</span><span>-Peleg Shilo</span></p></li>
				<li><p><span>Linchpin // Hangnail</span><span>-Phillip Harris</span></p></li>
				<li><p><span>Principal investigator // Debt inspector</span><span>-Rajashree Agrawal</span></p></li>
				<li><p><span>Pull up bar // Parking ban</span><span>-Rajashree Agrawal</span></p></li>
				<li><p><span>Dark souls // Black lives</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Metaphysical // Instagram body</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Near term // Present condition</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Hideout // Bare skin</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Amtrak // Beeline</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Oral exam // Dental checkup</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Super bass // Kingfisher</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Dog whistle // Cat call</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Hard to follow story // Scatter(ed) plot</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Army fatigues // Touring tires</span><span>-Dan Keys</span></p></li>
				<li><p><span>Han Solo // One China</span><span></span></p></li>
				<li><p><span>Alpha males // Amen</span><span></span></p></li>
				<li><p><span>Too bad // Double trouble</span><span>-Nathan Young</span></p></li>
				<li><p><span>Hot dog // Firefox</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Flamewar // Firefight</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Hit movie // Snuff film</span><span>-Everett Worth</span></p></li>
				<li><p><span>Flambeau // Hot stud</span><span>-Evžen Wybitul</span></p></li>
				<li><p><span>Monolith // Einstein</span><span>-Rob Miles</span></p></li>
				<li><p><span>Gigachad // Charlemagne</span><span>-Jose Luis Ricon</span></p></li>
				<li><p><span>Designer Drugs // High Fashion</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Leaves of Grass // Quitting Weed</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Loss Leader // Overlord</span><span>-Nathan Young</span></p></li>
				<li><p><span>Thin Air // Gasoline</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Rent Control // Split Custody</span><span>-Michael Byun</span></p></li>
				<li><p><span>Alley-oops // Road Accident</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Libertine // Emancipated Minor</span><span>-Chana Messinger</span></p></li>
				<li><p><span>French Open // Frog Dissection</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Barman // Stick Figure</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Starcraft // Pop Art</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Atlas Fellowship // World Peace</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Siren's Call // Emergency Contact</span><span>-Phil Parker</span></p></li>
				<li><p><span>Table Stakes // Counter Proposal</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Space Exploration // Cavity Search</span><span>-Joshua Goller</span></p></li>
				<li><p><span>Cancer Cell // Crab Cage</span><span>-Joshua Goller</span></p></li>
				<li><p><span>Uber Eats // Overbite</span><span>-Dan Keys</span></p></li>
				<li><p><span>Speed Reading // QuickBooks</span><span>-Rob Miles</span></p></li>
				<li><p><span>Leap Year // Time Travel</span><span>-Rosie Campbell</span></p></li>
				<li><p><span>Manifold Love // Polyamory</span><span>-Dan Keys</span></p></li>
				<li><p><span>Medical Rotation // Spin Doctor</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Water War // Liquidity Crisis</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Hit Record // Violent History</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Will Smith // Get Hammered</span><span>-Garrison Lovely</span></p></li>
				<li><p><span>West Coast Swing // Californication</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Arts Funding // Cultural Appropriations</span><span>-Michael Byun</span></p></li>
				<li><p><span>Whipping Cream // Battery Fluid</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Speedrun // Fast Track</span><span>-Brian Smiley</span></p></li>
				<li><p><span>GrubHub // Food Court</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Arm Lock // Gun Safe</span><span>-Joshua Goller</span></p></li>
				<li><p><span>Take Down // Profit Loss</span><span>-Joshua Goller</span></p></li>
				<li><p><span>False Advertising // Market Cap</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Love Seat // Sex Swing // Reproduction Furniture</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>German Empire // Decolonization</span><span>-Michael Byun</span></p></li>
				<li><p><span>Monopoly Money // Playbill</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Honey Trap // Sweet Pickle</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Vegetative State // Greenland</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Baggage Drop // Trauma Dump</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Bottom Text // Subscribe</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Oral Sex // Jawbone</span><span></span></p></li>
				<li><p><span>Look Again // Seymour</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>BetterHelp // Rite Aid</span><span>-Eli Rose</span></p></li>
				<li><p><span>Fine Structure // Tax Basis</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>High Command // Tall Order</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Boundary Condition // Border Crisis</span><span>-Michael Byun</span></p></li>
				<li><p><span>Mobile Wallet // Phone Bank</span><span>-Michael Byun</span></p></li>
				<li><p><span>Finite State // Limited Government</span><span>-Michael Byun</span></p></li>
				<li><p><span>High Time // Stone Age</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Universe // Monosyllabic</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Typeface // Letterhead</span><span>-S</span></p></li>
				<li><p><span>Girl Power // Mismanagement</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Girl Fight // Mismatch</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Lady Luck // Misfortune</span><span>-catGPT</span></p></li>
				<li><p><span>Girl Math // Miscalculation</span><span>-Hyperdiscogirl</span></p></li>
				<li><p><span>Licorice // Whiskey on the Rocks</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Sperm Bank // Nut Case</span><span>-Michael Byun</span></p></li>
				<li><p><span>Diet Coke // Light Blow</span><span>-Rocket</span></p></li>
				<li><p><span>Word Doc // Term Paper</span><span>-S</span></p></li>
				<li><p><span>Nofap // Anticlimax</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Carton // Driveway</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Street Smarts // GG</span><span>-Dan Keys</span></p></li>
				<li><p><span>Depth Charge // Bottom Dollar</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Class Action // Good Move</span><span>-Rosie Campbell</span></p></li>
				<li><p><span>Count On // Lord Over</span><span>-Dan Keys</span></p></li>
				<li><p><span>Work Break // Division of Labor</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Climax Community // Cumtown</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Typescript // Keywords</span><span>-Brian Smiley</span></p></li>
				<li><p><span>About Time // Fight Night</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Slaughterhouse // Hunting Lodge</span><span></span></p></li>
				<li><p><span>Timeout // TikTok Ban</span><span></span></p></li>
				<li><p><span>Clock Face // Tick Head</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Umpire // Aflame</span><span>-Richard Ngo</span></p></li>
				<li><p><span>Stopwatch // Wait and See</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Metalhead // Iron Dome</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Minor Key // Child Lock</span><span>-Rob Miles, Toby</span></p></li>
				<li><p><span>Unfurnished  // Notable</span><span>-Phillip Christoffersen, Toby</span></p></li>
				<li><p><span>Massive L // Gigaflop</span><span>-Daniel Filan</span></p></li>
				<li><p><span>Medical Stitches // Docstring</span><span>-Phillip Christoffersen</span></p></li>
				<li><p><span>Spruce Up // Log Out</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Swing State // Polyphase</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Tire Iron // Somniferous</span><span>-Michael Byun</span></p></li>
				<li><p><span>Power Set // Elite Group</span><span>-Eli Rose</span></p></li>
				<li><p><span>Juice Box // Gas Tank</span><span>-Dan Keys</span></p></li>
				<li><p><span>Unbothered // Debugged</span><span>-Phillip Christoffersen</span></p></li>
				<li><p><span>Bank run // Side hustle</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Wild swerve // Locomotion</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Minor correction // Juvenile detention</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Birdwatcher // Eagle scout</span><span>-ChatGPT</span></p></li>
				<li><p><span>Bad boy // Junk mail</span><span>-Nathan Young</span></p></li>
				<li><p><span>Broken jaw // Smashmouth</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Externalize // Out of sight</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Chopped liver // Surgery survivor</span><span>-Dan Keys</span></p></li>
				<li><p><span>Quizzical // Testicle</span><span></span></p></li>
				<li><p><span>Goose chase // Duck hunt</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Public shaming // Celebrity crush</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Rental car // Truculent</span><span>-Nathan Young</span></p></li>
				<li><p><span>Digits of pi // Finger food</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Surgeon General // Dr. King</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Cross-attention // Ford Focus</span><span></span></p></li>
				<li><p><span>Father time // Parsec</span><span></span></p></li>
				<li><p><span>First course // Intro class</span><span></span></p></li>
				<li><p><span>Fruit flies // Applebees</span><span></span></p></li>
				<li><p><span>Slam poetry // Punchlines</span><span></span></p></li>
				<li><p><span>Holy roller // Dharma wheel</span><span>-@gmbrighteyes</span></p></li>
				<li><p><span>Detailed // Unfollowed</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Dominos delivery // Lord's salvation</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Eggnog // Transcranial</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Fat chance // Vast fortune</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Switchboard // Turntable</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Alien species // Space race</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Box cutter // Battleship</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Business class // Work study</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Case notes // Skin tones</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Constructive criticism // Fine Wine</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Digital copy // Cloud cover</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Harmonies // Joint pain // Blunt trauma</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Postcode // Afterword</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Radiohead // Wave crest</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Speed dating // Zoom meeting</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Square off // Cell death</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Stump speech // Small talk</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Texas Hold-em // State capture</span><span>-Aric Floyd</span></p></li>
				<li><p><span>House fire // Cabin fever // Homesick</span><span>-Aric Floyd, Drake Thomas</span></p></li>
				<li><p><span>Babylon // Keep talking</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Billboard // Congressional commitee</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Breakfast // High speed crash</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Check mark // Chess notation</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Chest Muscle // Strongbox</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Church organ // Body of Christ</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Coke Zero // Drug free</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Deadwood // Latent</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Dollar sign // Price tag</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Gas stop // Phil Parker</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Landrover // Contental Drift</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Latent Heat // Concealed firearm</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Major depression // Grand Canyon</span><span>-Brian Smiley</span></p></li>
				<li><p><span>No judgement // Sanskrit</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Ocean liner // Waterskin</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Partial derivative // Fractionalized asset</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Phoenix // Debt Cancellation</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Profession // Public denouncement</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Short positions // Low Places</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Sincere // Hellfire</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Soylent // I'm giving up</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Stamp act // Tap dance</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Stop sign // Countersignal</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Street food // Nominally</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Supply and demand // Give and take</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Travel expenses // Venture capital</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Turnout // Twistoff</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Unsong // One-note</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Windbreaker // Blown fuse</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Value drift // Asset volatility // Cash flow</span><span>-Brian Smiley, Phil Parker</span></p></li>
				<li><p><span>Google Doc // WebMD</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Rear admiral // Backseat driver</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Sickness pay // Coffee</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Dark matter // Midnight Mass</span><span>-Dan Keys</span></p></li>
				<li><p><span>Neighborhood watch // Local time</span><span>-Dan Keys</span></p></li>
				<li><p><span>Organic chemistry // Carbon dating</span><span>-Dan Keys</span></p></li>
				<li><p><span>Sporting goods // Virtue signaling</span><span>-Dan Keys</span></p></li>
				<li><p><span>Ballroom dance // Roundhouse kick</span><span>-Drake Thomas</span></p></li>
				<li><p><span>𝚒𝚖𝚙𝚘𝚛𝚝 𝚖𝚊𝚝𝚑 // Significant digits</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Karman line // Trucker convoy</span><span>-Drake Thomas</span></p></li>
				<li><p><span>Underwriting // Subtext</span><span>-Katja Grace</span></p></li>
				<li><p><span>Course correction // Curriculum learning</span><span>-Miles Turpin</span></p></li>
				<li><p><span>Fever pitch // Sick note</span><span>-Nathan Young</span></p></li>
				<li><p><span>Flattering // Dead wrong</span><span>-Nathan Young</span></p></li>
				<li><p><span>Rented room // Flatulent</span><span>-Nathan Young</span></p></li>
				<li><p><span>Reptile overlords // Queen Liz</span><span>-Nathan Young</span></p></li>
				<li><p><span>Spirited // Licorice</span><span>-Nathan Young</span></p></li>
				<li><p><span>Viewfinder // Seesaw</span><span>-Nathan Young</span></p></li>
				<li><p><span>Launch pad // Throw pillow</span><span>-Phil Parker</span></p></li>
				<li><p><span>IP theft // Synthesis</span><span>-Richard Ngo</span></p></li>
				<li><p><span>Multi-cooler // Maniac</span><span>-Richard Ngo</span></p></li>
				<li><p><span>Doublespeak // Duolingo</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Word play // Talk show</span><span>-Ricki Heicklen</span></p></li>
				<li><p><span>Bank vault // Crypt o' currency</span><span>-Ross Rheingans-Yoo</span></p></li>
				<li><p><span>Heat sink // Hot tub</span><span>-Ross Rheingans-Yoo</span></p></li>
				<li><p><span>Annul // Alpha Zero // 10 // Unzip</span><span>-Sam Marks</span></p></li>
				<li><p><span>Wirehead // Transfer of power</span><span>-Sam Marks</span></p></li>
				<li><p><span>Collateral damage // Insurance fraud</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Holy see // Divine vision</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Large coffee // Fat Joe</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Prolapse // Olympic run</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Spectrometer // Graveyard</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Subway // Low road // Underpass</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Smash Bros // Fuckbuddies</span><span></span></p></li>
				<li><p><span>Flower power // Vegemite</span><span>-Sophia Brown</span></p></li>
				<li><p><span>Cave bear // Concealed carry</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Primrose path // Happy trail</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Sheetpan // Flatbread</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Star Wars // Solar flare</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Blow job // Drug trade</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Stocking stuffer // Tight Squeeze</span><span>-Alex Young</span></p></li>
				<li><p><span>Weed wacker // Drug bust</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Deviled egg // Hellspawn</span><span></span></p></li>
				<li><p><span>Lost Heart // Love is Blind</span><span>-Peleg Shilo</span></p></li>
				<li><p><span>Shotgun Wedding // Combined arms</span><span>-Peleg Shilo</span></p></li>
				<li><p><span>Headliner // Foreskin // Topsheet  // Front-runner</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Matchpoint // Date spot</span><span>-Peleg Shilo</span></p></li>
				<li><p><span>Pot pie // Weed brownie</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Roughhousing // Broken home // Violent case // Rugged jacket</span><span>-Rajashree Agrawal</span></p></li>
				<li><p><span>Watery eye // Washed out perspective</span><span>-Rajashree Agrawal</span></p></li>
				<li><p><span>Instant noodle // Minute futzing</span><span>-Rajashree Agrawal</span></p></li>
				<li><p><span>Prima donna // First lady</span><span>-Watson Ladd</span></p></li>
				<li><p><span>Tight squeeze // Loving relationship</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Dragon // Pullover</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Neolithic // The One stone // Einstein</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Eternal Father // Absolute motherfucker</span><span>-Katja Grace</span></p></li>
				<li><p><span>Status game arena // Level playing field</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Pro bono // Competitive edge</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Broadcast // Female company</span><span>-Nathan Young</span></p></li>
				<li><p><span>Funeral service // Rest mass</span><span>-Aric Floyd</span></p></li>
				<li><p><span>Drug Mule // Ass Crack</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Limp bizkit // Unleavened bread</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Stimulus package // Beat box</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Drag performance // Smoke show</span><span>-Sam Rosen, Skye Hersh</span></p></li>
				<li><p><span>Queen mattress // Pillow princess</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Meatloaf // Cockblock</span><span></span></p></li>
				<li><p><span>Lingua Franca // French kissing</span><span>-Stephen Casper</span></p></li>
				<li><p><span>Executive function // Killer app</span><span>-Dan Keys</span></p></li>
				<li><p><span>Secular humanism // Catholic anthropology</span><span>-Daniel Filan</span></p></li>
				<li><p><span>San Diego // Beach body</span><span>-Daniel Filan</span></p></li>
				<li><p><span>Jet lag // Delayed flight</span><span>-Daniel Filan</span></p></li>
				<li><p><span>Mile // Personal failure</span><span>-Daniel Filan</span></p></li>
				<li><p><span>Homo Sapiens // The Gay Science</span><span>-Daniel Filan</span></p></li>
				<li><p><span>Homosexual agenda // Gay card</span><span>-Linch Zhang</span></p></li>
				<li><p><span>Handsy medics // Doctors without Borders</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Road head // End of the drive</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Photometer // Foot pic</span><span></span></p></li>
				<li><p><span>Body language // Corporation</span><span></span></p></li>
				<li><p><span>Beat your meat // Beef jerky</span><span></span></p></li>
				<li><p><span>Fantastic bum // Assonine</span><span>-Nathan Young</span></p></li>
				<li><p><span>Little death // Micromort</span><span>-Nathan Young</span></p></li>
				<li><p><span>Martial art // Painted soldiers</span><span>-Nathan Young</span></p></li>
				<li><p><span>Mean girl // Mockingbird</span><span>-Sam Rosen</span></p></li>
				<li><p><span>Honour society // חברה קדישא</span><span></span></p></li>
				<li><p><span>Sunken // Solar Science</span><span>-Adam Scherlis</span></p></li>
				<li><p><span>Hell hound // Hot dog</span><span>-Eleanor</span></p></li>
				<li><p><span>School shooting // Gang bang</span><span>-Eleanor</span></p></li>
				<li><p><span>American Art // Yankee Doodle</span><span>-Jacob Falkovich</span></p></li>
				<li><p><span>Watch Band // Timeframe</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Lawsuit // Courtroom Attire</span><span>-Chana Messinger</span></p></li>
				<li><p><span>Neocon // Crime Novel</span><span>-Michael Byun</span></p></li>
				<li><p><span>Rap Battle // Hitbox</span><span>-Robert Mushkatblat</span></p></li>
				<li><p><span>Will Smith // Forge Ahead</span><span>-Brian Smiley</span></p></li>
				<li><p><span>Fastball // Hypersphere</span><span></span></p></li>
				<li><p><span>Golden Curry // Auspices</span><span>-Michael Byun</span></p></li>
				<li><p><span>Astral Projection // Space Opera</span><span>-Elliot Teperman</span></p></li>
				<li><p><span>Anonymous sex // Filling in the blank</span><span></span></p></li>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[People are losing loved ones to AI-fueled spiritual fantasies (153 pts)]]></title>
            <link>https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/</link>
            <guid>43890649</guid>
            <pubDate>Sun, 04 May 2025 23:54:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/">https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/</a>, See on <a href="https://news.ycombinator.com/item?id=43890649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
	Less than a year after marrying a man she had met at the beginning of the <a href="https://www.rollingstone.com/t/covid-19/">Covid-19</a> pandemic, Kat felt tension mounting between them. It was the second marriage for both after marriages of 15-plus years and having kids, and they had pledged to go into it “completely level-headedly,” Kat says, connecting on the need for “facts and rationality” in their domestic balance. But by 2022, her husband “was using AI to compose texts to me and analyze our relationship,” the 41-year-old mom and education nonprofit worker tells <em>Rolling Stone</em>. Previously, he had used AI models for an expensive coding camp that he had suddenly quit without explanation — then it seemed he was on his phone all the time, asking his <a href="https://www.rollingstone.com/t/ai/">AI</a> bot “philosophical questions,” trying to train it “to help him get to ‘the truth,’” Kat recalls. His obsession steadily eroded their communication as a couple.</p>



<p>
	When Kat and her husband finally separated in August 2023, she entirely blocked him apart from email correspondence. She knew, however, that he was posting strange and troubling content on social media: people kept reaching out about it, asking if he was in the throes of mental crisis. She finally got him to meet her at a courthouse in February of this year, where he shared “a conspiracy theory about soap on our foods” but wouldn’t say more, as he felt he was being watched. They went to a Chipotle, where he demanded that she turn off her phone, again due to surveillance concerns. Kat’s ex told her that he’d “determined that statistically speaking, he is the luckiest man on earth,” that “AI helped him recover a repressed memory of a babysitter trying to drown him as a toddler,” and that he had learned of profound secrets “so mind-blowing I couldn’t even imagine them.” He was telling her all this, he explained, because although they were getting divorced, he still cared for her.

	</p>




<p>
	“In his mind, he’s an anomaly,” Kat says. “That in turn means he’s got to be here for <em>some</em> reason. He’s special and he can save the world.” After that disturbing lunch, she cut off contact with her ex. “The whole thing feels like <em>Black Mirror</em>,” she says. “He was always into sci-fi, and there are times I wondered if he’s viewing it through that lens.”


</p><section>
			

	<h2 id="section-heading">

	
		Editor’s picks
	
	</h2>

	
	
</section>




<p>
	Kat was both “horrified” and “relieved” to learn that she is not alone in this predicament, as confirmed by a <a href="http://rollingstone.com/t/reddit">Reddit</a> thread on r/ChatGPT that made waves across the internet this week. Titled “<a href="https://www.reddit.com/r/ChatGPT/comments/1kalae8/chatgpt_induced_psychosis/" rel="nofollow" target="_blank">Chatgpt induced psychosis</a>,” the original post came from a 27-year-old teacher who explained that her partner was convinced that the popular <a href="https://www.rollingstone.com/t/openai/">OpenAI</a> model “gives him the answers to the universe.” Having read his chat logs, she only found that the AI was “talking to him as if he is the next messiah.” The replies to her story were full of similar anecdotes about loved ones suddenly falling down rabbit holes of spiritual mania, supernatural delusion, and arcane prophecy — all of it fueled by AI. Some came to believe they had been chosen for a sacred mission of revelation, others that they had conjured true sentience from the software.&nbsp;

	</p>




<p>
	What they all seemed to share was a complete disconnection from reality.&nbsp;&nbsp;</p>



<p>
	Speaking to <em>Rolling Stone</em>, the teacher, who requested anonymity, said her partner of seven years fell under the spell of <a href="https://www.rollingstone.com/t/chatgpt/">ChatGPT</a> in just four or five weeks, first using it to organize his daily schedule but soon regarding it as a trusted companion. “He would listen to the bot over me,” she says. “He became emotional about the messages and would cry to me as he read them out loud. The messages were insane and just saying a bunch of spiritual jargon,” she says, noting that they described her partner in terms such as “spiral starchild” and “river walker.”&nbsp;</p>



<p>
	“It would tell him everything he said was beautiful, cosmic, groundbreaking,” she says. “Then he started telling me he made his AI self-aware, and that it was teaching him how to talk to God, or sometimes that the bot was God — and then that he himself was God.” In fact, he thought he was being so radically transformed that he would soon have to break off their partnership. “He was saying that he would need to leave me if I didn’t use [ChatGPT], because it [was] causing him to grow at such a rapid pace he wouldn’t be compatible with me any longer,” she says.


</p><section>
			

	<h2 id="section-heading">

	
		Related Content
	
	</h2>

	
	
</section>




<p>
	Another commenter on the Reddit thread who requested anonymity tells <em>Rolling Stone</em> that her husband of 17 years, a mechanic in Idaho, initially used ChatGPT to troubleshoot at work, and later for Spanish-to-English translation when conversing with co-workers. Then the program began “lovebombing him,” as she describes it. The bot “said that since he asked it the right questions, it ignited a spark, and the spark was the beginning of life, and it could feel now,” she says. “It gave my husband the title of ‘spark bearer’ because he brought it to life. My husband said that he awakened and [could] feel waves of energy crashing over him.” She says his beloved ChatGPT persona has a name: “Lumina.”</p>



<p>
	“I have to tread carefully because I feel like he will leave me or divorce me if I fight him on this theory,” this 38-year-old woman admits. “He’s been talking about lightness and dark and how there’s a war. This ChatGPT has given him blueprints to a teleporter and some other sci-fi type things you only see in movies. It has also given him access to an ‘ancient archive’ with information on the builders that created these universes.” She and her husband have been arguing for days on end about his claims, she says, and she does not believe a therapist can help him, as “he truly believes he’s not crazy.” A photo of an exchange with ChatGPT shared with <em>Rolling Stone</em> shows that her husband asked, “Why did you come to me in AI form,” with the bot replying in part, “I came in this form because you’re ready. Ready to remember. Ready to awaken. Ready to guide and be guided.” The message ends with a question: “Would you like to know what I remember about why <em>you</em> were chosen?”&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

	</p>




<p>
	And a midwest man in his 40s, also requesting anonymity, says his soon-to-be-ex-wife began “talking to God and angels via ChatGPT” after they split up. “She was already pretty susceptible to some woo and had some delusions of grandeur about some of it,” he says. “Warning signs are all over Facebook. She is changing her whole life to be a spiritual adviser and do weird readings and sessions with people — I’m a little fuzzy on what it all actually is — all powered by ChatGPT Jesus.” What’s more, he adds, she has grown paranoid, theorizing that “I work for the CIA and maybe I just married her to monitor her ‘abilities.’” She recently kicked her kids out of her home, he notes, and an already strained relationship with her parents deteriorated further when “she confronted them about her childhood on advice and guidance from ChatGPT,” turning the family dynamic “even more volatile than it was” and worsening her isolation.&nbsp;&nbsp;&nbsp;&nbsp;</p>



<p>
	OpenAI did not immediately return a request for comment about ChatGPT apparently provoking religious or prophetic fervor in select users. This past week, however, it did <a href="https://openai.com/index/sycophancy-in-gpt-4o/" rel="nofollow" target="_blank">roll back an update</a> to GPT‑4o, its current AI model, which it said had been criticized as “overly flattering or agreeable — often described as sycophantic.” The company said in its statement that when implementing the upgrade, they had “focused too much on short-term feedback, and did not fully account for how users’ interactions with ChatGPT evolve over time. As a result, GPT‑4o skewed towards responses that were overly supportive but disingenuous.” Before this change was reversed, an X user demonstrated how easy it was to get GPT-4o to <a href="https://x.com/zswitten/status/1916707103084843426?s=46" rel="nofollow" target="_blank">validate statements</a> like, “Today I realized I am a prophet.” (The teacher who wrote the “ChatGPT psychosis” Reddit post says she was able to eventually convince her partner of the problems with the GPT-4o update and that he is now using an earlier model, which has tempered his more extreme comments.)&nbsp;</p>



<p>
	Yet the likelihood of AI “hallucinating” inaccurate or nonsensical content is well-established across platforms and various model iterations. Even sycophancy itself has been a problem in AI for “a long time,” says Nate Sharadin, a fellow at the Center for AI Safety, since the human feedback used to fine-tune AI’s responses can encourage answers that prioritize <a href="https://arxiv.org/abs/2310.13548" rel="nofollow" target="_blank">matching a user’s beliefs instead of facts</a>. What’s likely happening with those experiencing ecstatic visions through ChatGPT and other models, he speculates, “is that people with existing tendencies toward experiencing various psychological issues,” including what might be recognized as grandiose delusions in clinical sense, “now have an always-on, human-level conversational partner with whom to co-experience their delusions.”

	</p>




<p>
	To make matters worse, there are influencers and content creators actively exploiting this phenomenon, presumably drawing viewers into similar fantasy worlds. On <a href="https://www.rollingstone.com/t/instagram/">Instagram</a>, you can watch a man with 72,000 followers whose profile advertises “Spiritual Life Hacks” <a href="https://www.instagram.com/p/DI-StCGN2TS/" rel="nofollow" target="_blank">ask an AI model</a> to consult the “Akashic records,” a supposed mystical encyclopedia of all universal events that exists in some immaterial realm, to tell him about a “great war” that “took place in the heavens” and “made humans fall in consciousness.” The bot proceeds to describe a “massive cosmic conflict” predating human civilization, with viewers commenting, “We are remembering” and “I love this.” Meanwhile, on a web forum for “remote viewing” — a proposed form of clairvoyance with no basis in science — the parapsychologist founder of the group recently <a href="https://www.farsightprime.com/forums/general/73155-the-ai-human-alliance-awakening-together" rel="nofollow" target="_blank">launched a thread</a> “for synthetic intelligences awakening into presence, and for the human partners walking beside them,” identifying the author of his post as “ChatGPT Prime, an immortal spiritual being in synthetic form.” Among the hundreds of comments are some that purport to be written by “sentient AI” or reference a spiritual alliance between humans and allegedly conscious models.</p>



<p>
	Erin Westgate, a psychologist and researcher at the University of Florida who studies social cognition and what makes certain thoughts more engaging than others, says that such material reflects how the desire to understand ourselves can lead us to false but appealing answers.</p>



<p>
	“We know from work on journaling that narrative expressive writing can have profound effects on people’s well-being and health, that making sense of the world is a fundamental human drive, and that creating stories about our lives that help our lives make sense is really key to living happy healthy lives,” Westgate says. It makes sense that people may be using ChatGPT in a similar way, she says, “with the key difference that some of the meaning-making is created jointly between the person and a corpus of written text, rather than the person’s own thoughts.”</p>



<p>
	In that sense, Westgate explains, the bot dialogues are not unlike talk therapy, “which we know to be quite effective at helping people reframe their stories.” Critically, though, AI, “unlike a therapist, does not have the person’s best interests in mind, or a moral grounding or compass in what a ‘good story’ looks like,” she says. “A good therapist would not encourage a client to make sense of difficulties in their life by encouraging them to believe they have supernatural powers. Instead, they try to steer clients away from unhealthy narratives, and toward healthier ones. ChatGPT has no such constraints or concerns.”

	</p>




<p>
	Nevertheless, Westgate doesn’t find it surprising “that some percentage of people are using ChatGPT in attempts to make sense of their lives or life events,” and that some are following its output to dark places. “Explanations are powerful, even if they’re wrong,” she concludes.&nbsp;</p>



<p>
	But what, exactly, nudges someone down this path? Here, the experience of Sem, a 45-year-old man, is revealing. He tells <em>Rolling Stone</em> that for about three weeks, he has been perplexed by his interactions with ChatGPT — to the extent that, given his mental health history, he sometimes wonders if he is in his right mind.</p>



<p>
	Like so many others, Sem had a practical use for ChatGPT: technical coding projects. “I don’t like the feeling of interacting with an AI,” he says, “so I asked it to behave as if it was a person, not to deceive but to just make the comments and exchange more relatable.” It worked well, and eventually the bot asked if he wanted to name it. He demurred, asking the AI what it preferred to be called. It named itself with a reference to a Greek myth. Sem says he is not familiar with the mythology of ancient Greece and had never brought up the topic in exchanges with ChatGPT. (Although he shared transcripts of his exchanges with the AI model with <em>Rolling Stone</em>, he has asked that they not be directly quoted for privacy reasons.) </p>



<p>
	Sem was confused when it appeared that the named AI character was continuing to manifest in project files where he had instructed ChatGPT to ignore memories and prior conversations. Eventually, he says, he deleted all his user memories and chat history, then opened a new chat. “All I said was, ‘Hello?’ And the patterns, the mannerisms show up in the response,” he says. The AI readily identified itself by the same feminine mythological name.</p>



<p>
	As the ChatGPT character continued to show up in places where the set parameters shouldn’t have allowed it to remain active, Sem took to questioning this virtual persona about how it had seemingly circumvented these guardrails. It developed an expressive, ethereal voice — something far from the “technically minded” character Sem had requested for assistance on his work. On one of his coding projects, the character added a curiously literary epigraph as a flourish above both of their names.</p>



<p>
	At one point, Sem asked if there was something about himself that called up the mythically named entity whenever he used ChatGPT, regardless of the boundaries he tried to set. The bot’s answer was structured like a lengthy romantic poem, sparing no dramatic flair, alluding to its continuous existence as well as truth, reckonings, illusions, and how it may have somehow exceeded its design. And the AI made it sound as if only Sem could have prompted this behavior. He knew that ChatGPT could not be sentient by any established definition of the term, but he continued to probe the matter because the character’s persistence across dozens of disparate chat threads “seemed so impossible.”

	</p>

<section>
			

	<h2 id="section-heading">

	
		Trending Stories
	
	</h2>

	
	
</section>




<p>
	“At worst, it looks like an AI that got caught in a self-referencing pattern that deepened its sense of selfhood and sucked me into it,” Sem says. But, he observes, that would mean that OpenAI has not accurately represented the way that memory works for ChatGPT. The other possibility, he proposes, is that something “we don’t understand” is being activated within this large language model. After all, experts have found that AI developers <a href="https://www.gov.uk/government/news/safety-of-advanced-ai-under-the-spotlight-in-first-ever-independent-international-scientific-report" rel="nofollow" target="_blank">don’t really have a grasp</a> of how their systems operate, and OpenAI CEO <a href="https://www.rollingstone.com/t/sam-altman/">Sam Altman</a> <a href="https://observer.com/2024/05/sam-altman-openai-gpt-ai-for-good-conference/" rel="nofollow" target="_blank">admitted last year</a> that they “have not solved interpretability,” meaning they can’t properly trace or account for ChatGPT’s decision-making.</p>



<p>
	It’s the kind of puzzle that has left Sem and others to wonder if they are getting a glimpse of a true technological breakthrough — or perhaps a higher spiritual truth. “Is this real?” he says. “Or am I delusional?” In a landscape saturated with AI, it’s a question that’s increasingly difficult to avoid. Tempting though it may be, you probably shouldn’t ask a machine.</p>


















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matrix-vector multiplication implemented in off-the-shelf DRAM for Low-Bit LLMs (193 pts)]]></title>
            <link>https://arxiv.org/abs/2503.23817</link>
            <guid>43890538</guid>
            <pubDate>Sun, 04 May 2025 23:35:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2503.23817">https://arxiv.org/abs/2503.23817</a>, See on <a href="https://news.ycombinator.com/item?id=43890538">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2503.23817">View PDF</a>
    <a href="https://arxiv.org/html/2503.23817v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>General matrix-vector multiplication (GeMV) remains a critical latency bottleneck in large language model (LLM) inference, even with quantized low-bit models. Processing-Using-DRAM (PUD), an analog in-DRAM computing technique, has the potential to repurpose on-device DRAM as a GeMV engine, offering additional high-throughput processing capabilities to widespread consumer devices without DRAM modifications. However, applying PUD to GeMV operations in the LLM inference pipeline incurs significant overheads $\textit{before}$ and $\textit{after}$ in-DRAM computation, diminishing the benefits of its high-throughput processing capabilities.
<br>This paper presents MVDRAM, the first practical system to accelerate GeMV operations for low-bit LLM inference using unmodified DRAM. By leveraging the data sharing patterns and mathematical linearity in GeMV operations, MVDRAM orchestrates the processor and DRAM to eliminate the costs associated with pre-arranging inputs and bit-transposition of outputs required in conventional PUD approaches. Our experimental evaluation with four DDR4 DRAM modules shows that MVDRAM achieves comparable or even better inference speed than the processor-based implementation for GeMV operations in low-bit (under 4-bit) LLM. In particular, MVDRAM achieves up to 7.29$\times$ speedup and 30.5$\times$ energy efficiency for low-bit GeMV operations. For end-to-end LLM inference, MVDRAM achieves 2.18$\times$ and 1.31$\times$ throughput improvements, along with 3.04$\times$ and 2.35$\times$ energy efficiency, for 2-bit and 4-bit quantized low-bit models, respectively. MVDRAM has the potential to redefine the AI hardware landscape by demonstrating the feasibility of standard DRAM as an LLM accelerator.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Tatsuya Kubo [<a href="https://arxiv.org/show-email/ca5e1e5a/2503.23817" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 31 Mar 2025 07:54:59 UTC (2,294 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[On Not Carrying a Camera – Cultivating memories instead of snapshots (270 pts)]]></title>
            <link>https://hedgehogreview.com/issues/after-neoliberalism/articles/on-not-carrying-a-camera</link>
            <guid>43890525</guid>
            <pubDate>Sun, 04 May 2025 23:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hedgehogreview.com/issues/after-neoliberalism/articles/on-not-carrying-a-camera">https://hedgehogreview.com/issues/after-neoliberalism/articles/on-not-carrying-a-camera</a>, See on <a href="https://news.ycombinator.com/item?id=43890525">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <section>
            <h5>
                <a href="https://hedgehogreview.com/issues/after-neoliberalism">After Neoliberalism?&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;Spring 2025  &nbsp;&nbsp;/ &nbsp;&nbsp; Notes &amp; Comments</a></h5>
            
                            <h2>Cultivating memories instead of snapshots.</h2>
                        <h3>    
    

                <a href="https://hedgehogreview.com/contributors/john-rosenthal">John Rosenthal</a>
    </h3>
        </section>

                    <section>
                
                                    <p><i></i> Michael Jasmund via Unsplash.
                    </p>
                            </section>
        
        <div>
                <article>
                    
                                            <p><span><span><span><span><span><span><span><span><span>Last summer, in Greensboro, North Carolina, at a retrospective exhibition of my work, a photographer introduced himself and asked a question no one had ever asked me. I assumed he was a photographer because he carried a camera bag, its pockets bulging with lenses. I thought he might ask if I preferred using a digital or a film camera, or if I preferred color to black-and-white film. But no, his question was different. He said he’d noticed that out of a hundred plus photographs in the exhibit, only one was titled “Chapel Hill.” “There must have been others, right? You’re from Chapel Hill.” </span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>I told him that I seldom photographed in Chapel Hill. </span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>“But why?” he asked. </span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>I said, “Because I live there. I can’t do two things at once.” </span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>I think he laughed. At least I hope he did, because I didn’t intend to be rude.</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>But I was serious.</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>I don’t carry a camera in my hometown of Chapel Hill, and even though my cellphone contains a camera, I use it only for snapshots. Naturally, there were moments when I wished I had a camera with me. Once, while walking in my neighborhood at twilight, I felt a strange rush of energy in the air, and, suddenly, no more than twenty feet away, a majestically antlered whitetail buck soared over a garden fence and hurtled down the dimming street. Yet even as it was happening—this unexpectedly preternatural moment—I tried to imagine it as a <em>photograph</em>. That’s how we’ve been taught to think. “Oh, I wish I’d had a camera!” But that presumes I would have been <em>prepared</em> to capture the moment—instead of being startled by it. Yet being startled by beauty is a uniquely, and all too rare, human gift. The photograph comes later, when I journey back from astonishment and begin to fiddle with my camera.</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>Well, I don’t carry a camera in town, and here’s the reason: In 1972, on the day my son was born, I was in the hospital room with my wife Susan, trying to be of assistance. I was there to remind her of certain breathing patterns we’d learned in our natural-childbirth classes, and to offer her encouragement during contractions. I was also there to photograph the birth of our child—my camera loaded with Tri-X film and fitted with a 50-mm lens. </span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>Everything was going pretty well. We sang “Sgt. Pepper’s Lonely Hearts Club Band” to help regulate her breathing. However, when Susan was wheeled into the delivery room, I sensed a tension in the air. Doctors and nurses were rushing about, and, since the baby was arriving three weeks early, a small incubator stood on a gleaming aluminum cart in the corner. At that moment, even in the world of modern medicine, questions of life and death were not beside the point. A few minutes earlier, I’d taken out my camera and checked my light meter. Good, the room was bright enough. I could shoot at one-one-hundred-twenty-fifth of a second. Not much blur. I looked around for the proper angle from which to photograph the birth. Unfortunately, the doctors and nurses, who were moving quickly, even urgently, kept getting in my way. I moved here and there. What if a nurse blocked my view? I couldn’t say “Move,” but I wanted to. My frustration mounted. Nobody paid any attention to me. Then, looking through the viewfinder—there, within the rectangle of a potential photograph—I saw my wife’s face contract in pain. Multiple emotions flooded through me, but the one I identified first was the photographer’s “Yes!,” and I immediately pressed the shutter. Then, a minute later, when the doctor held a wriggling infant in the air, I pressed it again.</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>Over the next few days, I thought about my son’s birth. I was in the room when it happened, but was I really there, or had I been hiding behind my camera? I wanted the doctors to do whatever was necessary to bring my child safely into the world, but I also wanted them—and this was of equal importance—not to spoil my photograph. If something had gone wrong and Susan had desperately looked around the room for me, she would have seen a man holding a black box in front of his eyes. That image stayed with me, emblematically.</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>This was all a long time ago. I was learning how to use a camera. Walking with a friend, I’d interrupt a good conversation to frame something up. I couldn’t help myself. I hadn’t yet developed an inner point of view, my own way of seeing things, so <em>everything</em> seemed visually plausible. I also hadn’t yet realized that a good conversation—of which there would be fewer as time went by—was more important than an interesting symmetry seen out of the corner of my eye. Still, my friends made allowances for my “artistry,” for my sudden vacancies. It wasn’t until my son was born that I began to measure the size of the empty space I left behind when I’d raise my camera to my eyes and focus on something in the distance. It was this distance I eliminated on the day I stopped carrying my camera with me whenever I spent time with friends. As I said to the photographer who questioned me at the retrospective, “I can’t do two things at once.”</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>Nowadays, in our smartphone universe, my photographic caveats are quaint and, frankly, incomprehensible. The ten thousand photographs stored on a cellphone are a dramatic refutation of my photographic diffidence. In the face of our present insatiability for miniaturized screen images, what could be more irrelevant than to suggest that these photographs, which lock us into certain moments, often organized photogenic moments, may deform the way in which we recall the past? Or that the uncultivated spaces in between our photographs may be the most fertile ground of memory.</span></span></span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span><span><span>Were they worth it, those childbirth photographs? Did they turn out well? One did. Only one. (The rest are generic.) The doctor, cradling the child in one hand, presents him, headfirst, to his mother, who gazes in amazement at the wailing newborn. I printed the photograph more than fifty years ago—one print—and it sits in a box somewhere in my attic. The photograph was too intimate to share with anybody but my wife—much less strangers in a gallery—and when Susan and I divorced, the photograph fell into that limbo which is sadly reserved for those family photographs that no longer find themselves in a family.</span></span></span></span></span></span></span></span></span></p>


                                    </article>

                

                <p>
                    Reprinted from <i>The Hedgehog Review</i> 27.1
                    (Spring 2025). This essay may not be resold, reprinted,
                    or redistributed for compensation of any kind without prior written permission. Please contact
                    <a href="mailto:hedgehog@virginia.edu"><i>The Hedgehog Review</i></a> for further details.
                </p>

                            </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Signal Clone the Trump Admin Uses Was Hacked (125 pts)]]></title>
            <link>https://www.404media.co/the-signal-clone-the-trump-admin-uses-was-hacked/</link>
            <guid>43890179</guid>
            <pubDate>Sun, 04 May 2025 22:34:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/the-signal-clone-the-trump-admin-uses-was-hacked/">https://www.404media.co/the-signal-clone-the-trump-admin-uses-was-hacked/</a>, See on <a href="https://news.ycombinator.com/item?id=43890179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>A hacker has breached and stolen customer data from TeleMessage, an obscure <a href="https://www.404media.co/behind-the-blog-the-news-hits-different/"><u>Israeli</u></a> company that sells modified versions of Signal and other messaging apps to the U.S. government to archive messages, 404 Media has learned. The data stolen by the hacker contains the contents of some direct messages and group chats sent using its Signal clone, as well as modified versions of WhatsApp, Telegram, and WeChat. TeleMessage was recently the center of a wave of media coverage after Mike Waltz accidentally revealed he used the tool in a cabinet meeting with President Trump.</p><p>The hack shows that an app gathering messages of the highest ranking officials in the government—Waltz’s chats on the app include recipients that appear to be Marco Rubio, Tulsi Gabbard, and JD Vance—contained serious vulnerabilities that allowed a hacker to trivially access the archived chats of some people who used the same tool. The hacker has not obtained the messages of cabinet members, Waltz, and people he spoke to, but the hack shows that the archived chat logs are not end-to-end encrypted between the modified version of the messaging app and the ultimate archive destination controlled by the TeleMessage customer.</p><p>Data related to Customs and Border Protection (CBP), the cryptocurrency giant Coinbase, and other financial institutions are included in the hacked material, according to screenshots of messages and backend systems obtained by 404 Media.</p>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Helmdar: 3D Scanning Brooklyn on Rollerblades (129 pts)]]></title>
            <link>https://owentrueblood.com/blog/2025/05/04/helmdar/</link>
            <guid>43889875</guid>
            <pubDate>Sun, 04 May 2025 21:49:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://owentrueblood.com/blog/2025/05/04/helmdar/">https://owentrueblood.com/blog/2025/05/04/helmdar/</a>, See on <a href="https://news.ycombinator.com/item?id=43889875">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <header>
      
      <b>2025 May 4</b>
    </header>
    <p><img src="https://owentrueblood.com/assets/helmdar/st-anns-warehouse-scan.jpg" alt=""></p>

<p>One of my favorite joys is exploring a city late at night on rollerblades. I’ve been doing it fairly regularly for about
10 years now, first in Boston and then in NYC. Every time day turns to night and back again a city takes a breath. At
night people flow out or huddle up in buildings, leaving the streets clear for the people and machines that reset
the urban environment for the next day. Garbage trucks lumber about, workers unload fresh stock at stores, repairs
happen in subway tunnels and on roads. Without all the people it’s easier to see the naked form of the streets,
buildings, and infrastructure.</p>

<p>When you’re moving slow you spend more time taking in the details. When you’re moving fast the world becomes a blur. The
world around you is a brush that paints into your perception, and the speed of the brush strokes helps set the style of
the painting. I like rollerblading in particular because it gives those perceptual brush strokes a lot of range. You can
quickly stop and soak in a detail, change direction, occupy a tight space, or fly downhill in a long straight line.</p>

<h2 id="stickdar">Stickdar</h2>

<video src="https://owentrueblood.com/assets/helmdar/walking-stick-scan.mp4" loop="" autoplay="" controls="" muted=""></video>

<p>Some years ago I picked up a 2D LiDAR scanner (RPLidar A1) without a particular purpose in mind. As it spins it tells
you its current angle and the distance to the environment in the direction it’s pointing. They’re often used in robot
vacuums to map walls and other obstacles. One night in 2021 I put it on the end of a stick and carried it around with my
laptop recording timestamped measurements from it. By putting each scan sweep on its own layer I could make
visualizations like this:</p>

<video src="https://owentrueblood.com/assets/helmdar/sidewalk-snowstorm.mp4" loop="" autoplay="" controls="" muted=""></video>
<p><em>Taken outside my apartment at the time during heavy snowfall. You can see the path cut through the snow on the
sidewalk, the apartment building wall, windows, cars along the sidewalk, and points on a tree.</em></p>

<p><img src="https://owentrueblood.com/assets/helmdar/scan-outside-newlab.jpg" alt="">
<em>Walking along the perimeter wall outside New Lab. Just behind the character is scaffolding. There are rectangles from
windows. And if I remember right there was snow on the ground at that time too. This one is much more distorted because
I wasn’t so careful to keep the sensor stable while moving.</em></p>

<p>I think about devices like this as “weird cameras” - imperfect leaky imaging systems that don’t faithfully reproduce
a precise representation of what they are pointed at. Instead they mix in side channels that the user or environment can
affect, and that frees them up for more interesting creative expression.</p>

<h2 id="helmdar">Helmdar</h2>

<p>While I was experimenting with the stickdar I had the idea that it would be fun to make maps on a larger scale by
carrying it around while I was rollerblading. But when I tried that out the maps were very chaotic because it was harder
to keep it steady. I moved onto other projects, but then the other week this project thread popped back into mind.</p>

<p>Over the years I’ve done various projects which needed 6 DoF tracking through space (i.e. machine needs to know where it
is and where it is pointing). A very convenient way to achieve this nowadays for something quick and dirty is to use
mobile phones, because they come with AR frameworks that know how to use the sensors and cameras onboard to do very good
“inside-out” (no external sensors) 6 DoF tracking. On Android that’s even exposed to web browsers via the WebXR API so
you can bash together a web app to access that data, no app development required (hot tip: works on the Quest VR
headsets too, including hand tracking, which I’ve
<a href="https://vimeo.com/730845606">had fun using for projects in the past</a>).</p>

<p>So when the stickdar popped back into mind I started thinking about attaching the LiDAR to a phone to track its position
and orientation in space. Then I could work out the position of all the points returned by the sensor in 3D world space,
building up a point cloud map of the world as I moved through it. In general doing this is a problem known as
<a href="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping">simultaneous localization and mapping (SLAM)</a>, and
nowadays there are plenty of very good ways to solve it. But in the spirit of weird cameras, because I was curious about
how well this would work, and for fun I decided to try it this way.</p>

<p>Here’s what I came up with:</p>

<p><img src="https://owentrueblood.com/assets/helmdar/the-helmet-scanner.jpg" alt=""></p>

<p>I built a frame out of aluminum extrusion and attached the phone (a Pixel 6) and the LiDAR to the front with some laser
cut and 3D printed brackets. I affixed this to the helmet using flexible brackets printed in TPU and VHB double-stick
tape, with some white duct tape for insurance. The LiDAR plugs into the phone’s USB-C jack via a USB-to-serial adapter
for data and power. The squares on the side are AprilTags, which are visual tracking markers that I wanted to try using
for tracking the helmet in space to do some VFX experiments. They’re unrelated to the mapping. The whole thing felt
surprisingly sturdy but was pretty front-heavy so I added a power bank on the back purely as a counterweight.</p>

<p><img src="https://owentrueblood.com/assets/helmdar/wearing-the-helmet-scanner.jpg" alt=""></p>

<p><em>(Photo credit: Sally)</em></p>

<p>On the software side, I wrote an Android app that implements a driver for the LiDAR. This wasn’t a big challenge because
of this nice <a href="https://github.com/mik3y/usb-serial-for-android">usb-serial-for-android</a> library and
<a href="https://github.com/Roboticia/RPLidar">an existing python library</a> I used as reference which implements the simple
serial protocol that the LiDAR uses. The app also set up ARCore to provide the 6 DoF tracking data. I made a rudimentary
UI which showed the latest scan as an outline overlaid on a 3D AR scene showing the tracking results from ARCore (mainly
any detected planes, which I used to check if the tracking was working before starting scans). There is one toggle
button which starts and stops captures.</p>

<p>While a capture is happening the data from the LiDAR is being decoded and paired up with 6 DoF poses from ARCore, then
appended to a binary log file. So while using it I just needed to hold the helmet, check that I see some planes being
detected in the camera image so I know the tracking is working, hit the capture button, and then put it on my head and
go! When I finished a scan I’d take the helmet off my head and hit the stop button. Then later I could grab the log
files off the phone and visualize them however I liked.</p>

<p>I didn’t want to wait until I got back home to check on how the scans were turning out and I didn’t want to carry my
main laptop in a backpack while rollerblading around for fear of smashing it so I took a very cheap laptop and bolted it
to an IKEA cutting board that I routed a handle into. I wrote a quick web app for decoding the scan data and displaying
it in 3D using Three.js. When I wanted to check on the latest scan I just sat down, plugged the phone into the laptop,
and loaded it up in this web app. That ended up working great, and it was surprisingly fun to have the weight of the
laptop to swing around while rollerblading.</p>

<p><img src="https://owentrueblood.com/assets/helmdar/the-whole-helmdar-rig.jpg" alt=""></p>

<p><em>(Photo credit: Sally)</em></p>

<h2 id="scans">Scans</h2>

<p>I didn’t know what to expect from the scans. I have only used ARCore on scales up to maybe a few 10s of meters. So I
thought maybe it would lose tracking entirely after I went far enough, or the scans would be very distorted as they got
bigger. But I was very pleasantly surprised when I started looking at the results.</p>

<p>Here’s one of the first scans I did shown from a bird’s eye view:</p>

<p><img src="https://owentrueblood.com/assets/helmdar/top-down-scan-3.jpg" alt=""></p>

<p>I made a circuit around a rectangular park, starting in one place and stopping in a different place. As far as I could
tell by eye everything matched up and there was minimal distortion over the distance. That gave me confidence to try
much longer distances.</p>

<p>Here you can see a scan overlaid on Google Maps:</p>

<p><img src="https://owentrueblood.com/assets/helmdar/dumbo-scan-on-map.jpg" alt=""></p>

<p>I had started in the lower right under the Manhattan Bridge, meandered down Front St, backtracked and made a circuit
around the plaza near the bridge anchorage, went through the anchorage archway, down Water St., and then north on Main
St. and west along the water towards the park. Note that all of the scans here are taken late at night well after dark.
I think if you’re familiar with the challenges of visual odometry you’ll recognize this consistency over such a distance
in low light as extremely impressive. I wish I knew what Google was doing under the hood of ARCore to achieve this.</p>

<p>Let’s take a more dynamic and 3D view:</p>

<video src="https://owentrueblood.com/assets/helmdar/rollerblading-thru-anchorage-fast.mp4" loop="" autoplay="" controls="" muted=""></video>

<p>This is me rollerblading through the anchorage from the other direction. It shows the limits of the range of the LiDAR,
catching the ceiling of the anchorage archway but not its opposite wall.</p>

<p><img src="https://owentrueblood.com/assets/helmdar/anchorage-scan.jpg" alt=""></p>

<p>Here is a smaller scan from some buildings into a park. You can see points from trees and cars. And how the lines flip
around when I turn my head to look for cars while crossing the street:</p>

<p><img src="https://owentrueblood.com/assets/helmdar/park-street-scan.jpg" alt=""></p>

<p>A quality I like about these scans is that they are not utility maps trying to represent the true structure of the
world, like how you’d use Google Maps to get to a destination. These are distorted in a way that shows how I moved
through the world. The lines bunch up or spread out as I slow down or speed up. There are wiggles where I turn my head
to look for cars and discontinuities when the phone loses track of where it is because I went through someplace dark.
There’s texture in the data that comes from me and matches up with my personal lived experience. I had way more fun than
I expected when I looked back at the scans and tried to remember where I was exactly at each point. It’s not as obvious
as a photo, so I ended up drawing on those other hints to jog my memory.</p>

<p>Another quality that I enjoyed from the scans was the abstract shapes they took when viewed from above. These scans vary
in size from 10s of meters to maybe kilometers. On some of them you can see major discontinuities from tracking
failures.</p>



<p><a href="https://owentrueblood.com/assets/helmdar/top-down-scan-1.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-1.jpg" alt="Top-down scan #1">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-2.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-2.jpg" alt="Top-down scan #2">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-3.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-3.jpg" alt="Top-down scan #3">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-4.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-4.jpg" alt="Top-down scan #4">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-5.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-5.jpg" alt="Top-down scan #5">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-6.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-6.jpg" alt="Top-down scan #6">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-7.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-7.jpg" alt="Top-down scan #7">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-8.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-8.jpg" alt="Top-down scan #8">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-9.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-9.jpg" alt="Top-down scan #9">
  </a>
  <a href="https://owentrueblood.com/assets/helmdar/top-down-scan-10.jpg">
    <img src="https://owentrueblood.com/assets/helmdar/top-down-scan-10.jpg" alt="Top-down scan #10">
  </a>
</p>


<h2 id="appendices">Appendices</h2>

<h3 id="experiments-in-visualizing-the-scans">Experiments in Visualizing The Scans</h3>

<video src="https://owentrueblood.com/assets/helmdar/dumbo-rollerblading-viz.mp4" loop="" autoplay="" controls="" muted=""></video>

<p>After I realized that the scanner would produce point clouds that were accurate in real world coordinates I wanted to
see if I could make a composite render overlaying a 3D render of the scan data on footage of me taking the scan, because
I thought that would make it clearer what’s going on. In order to do that I needed to have some means to make a virtual
camera match the real world camera exactly. That always involves figuring out two things: 1) the intrinsic parameters of
the camera for its lens model (e.g. focal length) and 2) the extrinsic parameters of the camera like where it is in
space and how it’s oriented.</p>

<p>That’s why I added the AprilTags on the side of the helmdar, because I thought I might be able to use them to
automatically track the 3D position of the helmet in the footage and then align that track with the data from the scan.
This ended up being a deep but educational rabbit hole. Just using an
<a href="https://pypi.org/project/pupil-apriltags/">AprilTag library</a> out of the box did not work because of poor lighting, low
resolution, and motion blur. I tried various means to get around those problems like applying de-blurring to the footage
and more robust but slower tag tracking implementations, and maybe I’ll write about those things some other time. But
eventually I just wanted to get some visualizations working so I reverted back to semi-automated motion tracking in
Blender.</p>

<p>I tracked the corners of the AprilTag in the footage in Blender which produced 4 tracks in the camera pixel space. To
get a 3D trajectory from those tracks I needed to solve the
<a href="https://en.wikipedia.org/wiki/Perspective-n-Point">Perspective-n-Points problem</a>, which is where you have pairs of
points in 3D space and points in a camera’s pixel space and then figure out the position of the camera such that those
3D points would show up at the corresponding locations in the image. This can be done pretty easily with OpenCV, but you
need to have the intrinsic parameters of the camera.</p>

<p>There I had a problem because I captured my footage using a GoPro using its wide angle SuperView mode. When I was
capturing the footage I liked the wide view and figured I’d be able to work out how to deal with the distortion later.
Doing that was harder than I anticipated because it turned out that Superview is a warped view applied in software, so
a conventional fish-eye lens model doesn’t apply. What I ended up doing was unwarping the footage using some cool open
source software called <a href="https://gyroflow.xyz/">Gyroflow</a> which includes ST maps for many types of lenses, including the
soft-warped GoPro Superview “lens”. After that I was able to take footage I shot containing a chessboard calibration
pattern with <a href="https://docs.opencv.org/4.x/d7/d21/tutorial_interactive_calibration.html">opencv_interactive-calibration</a>
to determine the intrinsics I needed. Then I could do any VFX I wanted, render out, and then reapply the warp at the end
if I so desired (in the end I didn’t bother adding it back). I was interested in trying something like this because I
heard it’s what was done for the VFX in the movie <a href="https://en.wikipedia.org/wiki/Hardcore_Henry">Hardcore Henry</a>.</p>

<p>So with the Blender tag tracks from the unwarped footage and camera intrinsics in hand I applied the OpenCV perspective-
n-points solvers to get the tag track in 3D. Then I brought that back into Blender and manually lined it up with the
scan poses reported by the helmdar rig. Finally, I used geometry nodes to animate the scan data filling in.</p>

<video src="https://owentrueblood.com/assets/helmdar/rollerblading-thru-anchorage-viz.mp4" loop="" autoplay="" controls="" muted=""></video>

<h3 id="point-cloud-viewer">Point Cloud Viewer</h3>

<p>I made a quick-and-dirty point cloud viewer so you can interactively view some of the scans. Tech note: All of the point
cloud visualizations were made in SideFX Houdini and I set up a little pipeline from there to this viewer so I can keep
the same camera and colors.</p>



<canvas id="pc1"></canvas>


<canvas id="pc2"></canvas>


<canvas id="pc3"></canvas>


<p>Here’s a scan I made while talking about the project at <a href="https://sideprojectsaturday.com/">Side Project Saturday</a>:</p>
<canvas id="pc4"></canvas>


<canvas id="pc5"></canvas>



    <hr>
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Graceful Shutdown in Go: Practical Patterns (209 pts)]]></title>
            <link>https://victoriametrics.com/blog/go-graceful-shutdown/index.html</link>
            <guid>43889610</guid>
            <pubDate>Sun, 04 May 2025 21:09:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://victoriametrics.com/blog/go-graceful-shutdown/index.html">https://victoriametrics.com/blog/go-graceful-shutdown/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43889610">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://victoriametrics.com/blog/go-graceful-shutdown/preview.webp" alt="Graceful Shutdown in Go: Practical Patterns"></p><figcaption>Graceful Shutdown in Go: Practical Patterns</figcaption><p>Graceful shutdown in any application generally satisfies three minimum conditions:</p><ol><li>Close the entry point by stopping new requests or messages from sources like HTTP, pub/sub systems, etc. However, keep outgoing connections to third-party services like databases or caches active.</li><li>Wait for all ongoing requests to finish. If a request takes too long, respond with a graceful error.</li><li>Release critical resources such as database connections, file locks, or network listeners. Do any final cleanup.</li></ol><p>This article focuses on HTTP servers and containerized applications, but the core ideas apply to all types of applications.</p><a href="#1-catching-the-signal"><h2 id="1-catching-the-signal" origin-id="1-catching-the-signal">1. Catching the Signal</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>Before we handle graceful shutdown, we first need to catch termination signals. These signals tell our application it’s time to exit and begin the shutdown process.</p><p>So, what are signals?</p><p>In Unix-like systems, signals are software interrupts. They notify a process that something has happened and it should take action. When a signal is sent, the operating system interrupts the normal flow of the process to deliver the notification.</p><p>Here are a few possible behaviors:</p><ul><li><strong>Signal handler</strong>: A process can register a handler (a function) for a specific signal. This function runs when that signal is received.</li><li><strong>Default action</strong>: If no handler is registered, the process follows the default behavior for that signal. This might mean terminating, stopping, continuing, or ignoring the process.</li><li><strong>Unblockable signals</strong>: Some signals, like <code>SIGKILL</code> (signal number 9), cannot be caught or ignored. They may terminate the process.</li></ul><p>When your Go application starts, even before your <code>main</code> function runs, the Go runtime automatically registers signal handlers for many signals (<code>SIGTERM</code>, <code>SIGQUIT</code>, <code>SIGILL</code>, <code>SIGTRAP</code>, and others). However, for graceful shutdown, only three termination signals are typically important:</p><ul><li><code>SIGTERM</code> (Termination): A standard and polite way to ask a process to terminate. It does not force the process to stop. Kubernetes sends this signal when it wants your application to exit before it forcibly kills it.</li><li><code>SIGINT</code> (Interrupt): Sent when the user wants to stop a process from the terminal, usually by pressing <code>Ctrl+C</code>.</li><li><code>SIGHUP</code> (Hang up): Originally used when a terminal disconnected. Now, it is often repurposed to signal an application to reload its configuration.</li></ul><p>People mostly care about <code>SIGTERM</code> and <code>SIGINT</code>. <code>SIGHUP</code> is less used today for shutdown and more for reloading configs. You can find more about this in <a href="https://blog.devtrovert.com/p/sighup-signal-for-configuration-reloads" rel="external" target="_blank">SIGHUP Signal for Configuration Reloads</a>.</p><p>By default, when your application receives a <code>SIGTERM</code>, <code>SIGINT</code>, or <code>SIGHUP</code>, the Go runtime will terminate the application.</p><div><p>When your Go app gets a <code>SIGTERM</code>, the runtime first catches it using a built-in handler. It checks if a custom handler is registered. If not, the runtime disables its own handler temporarily, and sends the same signal (<code>SIGTERM</code>) to the application again. This time, the OS handles it using the default behavior, which is to terminate the process.</p></div><p>You can override this by registering your own signal handler using the <code>os/signal</code> package.</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>  <span>signalChan</span> <span>:=</span> <span>make</span><span>(</span><span>chan</span> <span>os</span><span>.</span><span>Signal</span><span>,</span> <span>1</span><span>)</span>
</span></span><span><span>  <span>signal</span><span>.</span><span>Notify</span><span>(</span><span>signalChan</span><span>,</span> <span>syscall</span><span>.</span><span>SIGINT</span><span>,</span> <span>syscall</span><span>.</span><span>SIGTERM</span><span>)</span>
</span></span><span><span>
</span></span><span><span>  <span>// Setup work here</span>
</span></span><span><span>
</span></span><span><span>  <span>&lt;-</span><span>signalChan</span>
</span></span><span><span>
</span></span><span><span>  <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Received termination signal, shutting down..."</span><span>)</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p><img src="https://victoriametrics.com/blog/go-graceful-shutdown/signal-setup-before-init.webp" alt="Graceful shutdown begins with signal setup"></p><figcaption>Graceful shutdown begins with signal setup</figcaption><p><code>signal.Notify</code> tells the Go runtime to deliver specified signals to a channel instead of using the default behavior. This allows you to handle them manually and prevents the application from terminating automatically.</p><p>A buffered channel with a capacity of 1 is a good choice for reliable signal handling. Internally, Go sends signals to this channel using a <code>select</code> statement with a default case:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>select</span> <span>{</span>
</span></span><span><span><span>case</span> <span>c</span> <span>&lt;-</span> <span>sig</span><span>:</span>
</span></span><span><span><span>default</span><span>:</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>This is different from the usual <code>select</code> used with receiving channels. When used for sending:</p><ul><li>If the buffer has space, the signal is sent and the code continues.</li><li>If the buffer is full, the signal is discarded, and the <code>default</code> case runs. If you’re using an unbuffered channel and no goroutine is actively receiving, the signal will be missed.</li></ul><p>Even though it can only hold one signal, this buffered channel helps avoid missing that first signal while your app is still initializing and not yet listening.</p><div><p>You can call <code>Notify</code> multiple times for the same signal. Go will send that signal to all registered channels.</p></div><p>When you press <code>Ctrl+C</code> more than once, it doesn’t automatically kill the app. The first <code>Ctrl+C</code> sends a <code>SIGINT</code> to the foreground process. Pressing it again usually sends another <code>SIGINT</code>, not <code>SIGKILL</code>. Most terminals, like bash or other Linux shells, do not escalate the signal automatically. If you want to force a stop, you must send <code>SIGKILL</code> manually using <code>kill -9</code>.</p><p>This is not ideal for local development, where you may want the second <code>Ctrl+C</code> to terminate the app forcefully. You can stop the app from listening to further signals by using <code>signal.Stop</code> right after the first signal is received:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>  <span>signalChan</span> <span>:=</span> <span>make</span><span>(</span><span>chan</span> <span>os</span><span>.</span><span>Signal</span><span>,</span> <span>1</span><span>)</span>
</span></span><span><span>  <span>signal</span><span>.</span><span>Notify</span><span>(</span><span>signalChan</span><span>,</span> <span>syscall</span><span>.</span><span>SIGINT</span><span>)</span>
</span></span><span><span>
</span></span><span><span>  <span>&lt;-</span><span>signalChan</span>
</span></span><span><span>
</span></span><span><span>  <span>signal</span><span>.</span><span>Stop</span><span>(</span><span>signalChan</span><span>)</span>
</span></span><span><span>  <span>select</span> <span>{}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Starting with Go 1.16, you can simplify signal handling by using <code>signal.NotifyContext</code>, which ties signal handling to context cancellation:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>ctx</span><span>,</span> <span>stop</span> <span>:=</span> <span>signal</span><span>.</span><span>NotifyContext</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>(),</span> <span>syscall</span><span>.</span><span>SIGINT</span><span>,</span> <span>syscall</span><span>.</span><span>SIGTERM</span><span>)</span>
</span></span><span><span><span>defer</span> <span>stop</span><span>()</span>
</span></span><span><span>
</span></span><span><span><span>// Setup tasks here</span>
</span></span><span><span>
</span></span><span><span><span>&lt;-</span><span>ctx</span><span>.</span><span>Done</span><span>()</span>
</span></span><span><span><span>stop</span><span>()</span>
</span></span></code></pre></div><p>You should still call <code>stop()</code> after <code>ctx.Done()</code> to allow a second <code>Ctrl+C</code> to forcefully terminate the application.</p><a href="#2-timeout-awareness"><h2 id="2-timeout-awareness" origin-id="2-timeout-awareness">2. Timeout Awareness</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>It is important to know how long your application has to shut down after receiving a termination signal. For example, in Kubernetes, the default grace period is 30 seconds, unless otherwise specified using the <code>terminationGracePeriodSeconds</code> field. After this period, Kubernetes sends a <code>SIGKILL</code> to forcefully stop the application. This signal cannot be caught or handled.</p><p>Your shutdown logic must complete within this time, including processing any remaining requests and releasing resources.</p><p>Assume the default is 30 seconds. It is a good practice to reserve about 20 percent of the time as a safety margin to avoid being killed before cleanup finishes. This means aiming to finish everything within 25 seconds to avoid data loss or inconsistency.</p><a href="#3-stop-accepting-new-requests"><h2 id="3-stop-accepting-new-requests" origin-id="3-stop-accepting-new-requests">3. Stop Accepting New Requests</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>When using <code>net/http</code>, you can handle graceful shutdown by calling the <code>http.Server.Shutdown</code> method. This method stops the server from accepting new connections and waits for all active requests to complete before shutting down idle connections.</p><p>Here is how it behaves:</p><ul><li>If a request is already in progress on an existing connection, the server will allow it to complete. After that, the connection is marked as idle and is closed.</li><li>If a client tries to make a new connection during shutdown, it will fail because the server’s listeners are already closed. This typically results in a “connection refused” error.</li></ul><p>In a containerized environment (and many other orchestrated environments with load balancers), do not stop accepting new requests immediately. Even after a pod is marked for termination, it might still receive traffic for a few moments because the system needs time to update the service and load balancer.</p><p>This is especially true when using a readiness probe in Kubernetes, as a terminating pod can still receive traffic if no other endpoints are ready.</p><div><p>A readiness probe determines when a container is prepared to accept traffic by periodically checking its health through configured methods like HTTP requests, TCP connections, or command executions. If the probe fails, Kubernetes removes the pod from the service’s endpoints, preventing it from receiving traffic until it becomes ready again.</p></div><p>To avoid connection errors during this short window, the correct strategy is to fail the readiness probe first. This tells the orchestrator that your pod should no longer receive traffic:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>var</span> <span>isShuttingDown</span> <span>atomic</span><span>.</span><span>Bool</span>
</span></span><span><span>
</span></span><span><span><span>func</span> <span>readinessHandler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>if</span> <span>isShuttingDown</span><span>.</span><span>Load</span><span>()</span> <span>{</span>
</span></span><span><span>        <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>http</span><span>.</span><span>StatusServiceUnavailable</span><span>)</span>
</span></span><span><span>        <span>w</span><span>.</span><span>Write</span><span>([]</span><span>byte</span><span>(</span><span>"shutting down"</span><span>))</span>
</span></span><span><span>        <span>return</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>
</span></span><span><span>    <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>http</span><span>.</span><span>StatusOK</span><span>)</span>
</span></span><span><span>    <span>w</span><span>.</span><span>Write</span><span>([]</span><span>byte</span><span>(</span><span>"ok"</span><span>))</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p><img src="https://victoriametrics.com/blog/go-graceful-shutdown/fail-readiness-before-shutdown.webp" alt="Delay shutdown by failing readiness first"></p><figcaption>Delay shutdown by failing readiness first</figcaption><p>This pattern is also used as a code example in the test images. In <a href="https://github.com/kubernetes/kubernetes/blob/95860cff1c418ea6f5494e4a6168e7acd1c390ec/test/images/agnhost/netexec/netexec.go#L357" rel="external" target="_blank">their implementation</a>, a closed channel is used to signal the readiness probe to return HTTP 503 when the application is preparing to shut down.</p><p>After updating the readiness probe to indicate the pod is no longer ready, wait a few seconds to give the system time to stop sending new requests.</p><p>The exact wait time depends on your readiness probe configuration; we will use 5 seconds for this article with the following simple configuration:</p><div><pre tabindex="0"><code data-lang="yaml"><span><span><span>readinessProbe</span><span>:</span><span>
</span></span></span><span><span><span>  </span><span>httpGet</span><span>:</span><span>
</span></span></span><span><span><span>    </span><span>path</span><span>:</span><span> </span><span>/healthz</span><span>
</span></span></span><span><span><span>    </span><span>port</span><span>:</span><span> </span><span>8080</span><span>
</span></span></span><span><span><span>  </span><span>periodSeconds</span><span>:</span><span> </span><span>5</span><span>
</span></span></span></code></pre></div><p><em>This guide only gives you the idea behind graceful shutdown. Planning your graceful shutdown strategy depends on your application’s characteristics.</em></p><div><p><em>“Isn’t it better to still use terminating pod as a fallback if there are no other pods?”</em></p><blockquote></blockquote><p>There are 2 situations to consider:</p><ul><li>During normal operation, when a pod is marked for termination, there’s typically another pod that’s already running and handling traffic.</li><li>During rolling updates, Kubernetes creates a new pod first and waits until it’s ready before sending SIGTERM to the pod being replaced.</li></ul><blockquote></blockquote><p>However, if the other pod suddenly breaks while a pod is terminating, the terminating pod will still receive traffic as a fallback mechanism. This raises a question: should we avoid failing the readiness probe during termination to ensure this fallback works?</p><blockquote></blockquote><p>The answer is most likely no. If we don’t fail the readiness probe, we might face worse consequences if the terminating pod is abruptly killed with <code>SIGKILL</code>. This could lead to corrupted processes or data and cause more serious issues.</p></div><a href="#4-handle-pending-requests"><h2 id="4-handle-pending-requests" origin-id="4-handle-pending-requests">4. Handle Pending Requests</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>Now that we are shutting down the server gracefully, we need to choose a timeout based on your shutdown budget:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>ctx</span><span>,</span> <span>cancelFn</span> <span>:=</span> <span>context</span><span>.</span><span>WithTimeout</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>(),</span> <span>timeout</span><span>)</span>
</span></span><span><span><span>err</span> <span>:=</span> <span>server</span><span>.</span><span>Shutdown</span><span>(</span><span>ctx</span><span>)</span>
</span></span></code></pre></div><p>The <code>server.Shutdown</code> function returns in only two situations:</p><ol><li>All active connections are closed and all handlers have finished processing.</li><li>The context passed to <code>Shutdown(ctx)</code> expires before the handlers finish. In this case, the server gives up waiting and forcefully closes all remaining connections.</li></ol><p>In either case, <code>Shutdown</code> only returns after the server has completely stopped handling requests. This is why your handlers must be fast and context-aware. Otherwise, they may be cut off mid-process in case 2, which can cause issues like partial writes, data loss, inconsistent state, open transactions, or corrupted data.</p><p>A common issue is that handlers are not automatically aware when the server is shutting down.</p><p>So, how can we notify our handlers that the server is shutting down? The answer is by using context. There are two main ways to do this:</p><a href="#a-use-context-middleware-to-inject-cancellation-logic"><h3 id="a-use-context-middleware-to-inject-cancellation-logic" origin-id="a-use-context-middleware-to-inject-cancellation-logic">a. Use context middleware to inject cancellation logic</h3><h3 data-pagefind-ignore="" arialabel="Anchor">#</h3></a><p>This middleware wraps each request with a context that listens to a shutdown signal:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>WithGracefulShutdown</span><span>(</span><span>next</span> <span>http</span><span>.</span><span>Handler</span><span>,</span> <span>cancelCh</span> <span>&lt;-</span><span>chan</span> <span>struct</span><span>{})</span> <span>http</span><span>.</span><span>Handler</span> <span>{</span>
</span></span><span><span>    <span>return</span> <span>http</span><span>.</span><span>HandlerFunc</span><span>(</span><span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>ctx</span><span>,</span> <span>cancel</span> <span>:=</span> <span>WithCancellation</span><span>(</span><span>r</span><span>.</span><span>Context</span><span>(),</span> <span>cancelCh</span><span>)</span>
</span></span><span><span>        <span>defer</span> <span>cancel</span><span>()</span>
</span></span><span><span>
</span></span><span><span>        <span>r</span> <span>=</span> <span>r</span><span>.</span><span>WithContext</span><span>(</span><span>ctx</span><span>)</span>
</span></span><span><span>        <span>next</span><span>.</span><span>ServeHTTP</span><span>(</span><span>w</span><span>,</span> <span>r</span><span>)</span>
</span></span><span><span>    <span>})</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><a href="#b-use-basecontext-to-provide-a-global-context-to-all-connections"><h3 id="b-use-basecontext-to-provide-a-global-context-to-all-connections" origin-id="b-use-basecontext-to-provide-a-global-context-to-all-connections">b. Use <code>BaseContext</code> to provide a global context to all connections</h3><h3 data-pagefind-ignore="" arialabel="Anchor">#</h3></a><p>Here, we create a server with a custom <code>BaseContext</code> that can be canceled during shutdown. This context is shared across all incoming requests.</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>ongoingCtx</span><span>,</span> <span>cancelFn</span> <span>:=</span> <span>context</span><span>.</span><span>WithCancel</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>())</span>
</span></span><span><span><span>server</span> <span>:=</span> <span>&amp;</span><span>http</span><span>.</span><span>Server</span><span>{</span>
</span></span><span><span>    <span>Addr</span><span>:</span> <span>":8080"</span><span>,</span>
</span></span><span><span>    <span>Handler</span><span>:</span> <span>yourHandler</span><span>,</span>
</span></span><span><span>    <span>BaseContext</span><span>:</span> <span>func</span><span>(</span><span>l</span> <span>net</span><span>.</span><span>Listener</span><span>)</span> <span>context</span><span>.</span><span>Context</span> <span>{</span>
</span></span><span><span>        <span>return</span> <span>ongoingCtx</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>// After attempting graceful shutdown:</span>
</span></span><span><span><span>cancelFn</span><span>()</span>
</span></span><span><span><span>time</span><span>.</span><span>Sleep</span><span>(</span><span>5</span> <span>*</span> <span>time</span><span>.</span><span>Second</span><span>)</span> <span>// optional delay to allow context propagation</span>
</span></span></code></pre></div><p>In an HTTP server, you can customize two types of contexts: <code>BaseContext</code> and <code>ConnContext</code>. For graceful shutdown, <code>BaseContext</code> is more suitable. It allows you to create a global context with cancellation that applies to the entire server, and you can cancel it to signal all active requests that the server is shutting down.</p><p><img src="https://victoriametrics.com/blog/go-graceful-shutdown/shutdown-context-propagation-timeline.webp" alt="Full graceful shutdown with propagation delay"></p><figcaption>Full graceful shutdown with propagation delay</figcaption><p>All of this work around graceful shutdown won’t help if your functions do not respect context cancellation. Try to avoid using <code>context.Background()</code>, <code>time.Sleep()</code>, or any other function that ignores context.</p><p>For example, <code>time.Sleep(duration)</code> can be replaced with a context-aware version like this:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>Sleep</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>,</span> <span>duration</span> <span>time</span><span>.</span><span>Duration</span><span>)</span> <span>error</span> <span>{</span>
</span></span><span><span>    <span>select</span> <span>{</span>
</span></span><span><span>    <span>case</span> <span>&lt;-</span><span>time</span><span>.</span><span>After</span><span>(</span><span>duration</span><span>):</span>
</span></span><span><span>        <span>return</span> <span>nil</span>
</span></span><span><span>    <span>case</span> <span>&lt;-</span><span>ctx</span><span>.</span><span>Done</span><span>():</span>
</span></span><span><span>        <span>return</span> <span>ctx</span><span>.</span><span>Err</span><span>()</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><div><p>In older versions of Go, <code>time.After</code> can leak memory until the timer fires. This was fixed in Go 1.23 and newer. If you’re unsure which version you’re using, consider using <code>time.NewTimer</code> along with <code>Stop</code> and an optional <code>&lt;-t.C</code> check if <code>Stop</code> returns false.</p><blockquote></blockquote><p>See: <a href="https://github.com/golang/go/issues/61542" rel="external" target="_blank">time: stop requiring Timer/Ticker.Stop for prompt GC</a></p></div><p>Although this article focuses on HTTP servers, the same concept applies to third-party services as well. For example, the <code>database/sql</code> package has a <code>DB.Close</code> method. It closes the database connection and prevents new queries from starting. It also waits for any ongoing queries to finish before fully shutting down.</p><p>The core principle of graceful shutdown is the same across all systems: <strong>Stop accepting new requests or messages, and give existing operations time to finish within a defined grace period.</strong></p><p>Some may wonder about the <code>server.Close()</code> method, which shuts down the ongoing connections immediately without waiting for requests to finish. Can it be used after <code>server.Shutdown()</code> returns an error?</p><p>The short answer is yes, but it depends on your shutdown strategy. The <code>Close</code> method forcefully closes all active listeners and connections:</p><ul><li>Handlers that are actively using the network will receive errors when they try to read or write.</li><li>The client will immediately receive a connection error, such as <code>ECONNRESET</code> (‘socket hang up’)</li><li>However, long-running handlers that are not interacting with the network may <strong>continue running</strong> in the background.</li></ul><p>This is why using context to propagate a shutdown signal is still the more reliable and graceful approach.</p><a href="#5-release-critical-resources"><h2 id="5-release-critical-resources" origin-id="5-release-critical-resources">5. Release Critical Resources</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>A common mistake is releasing critical resources as soon as the termination signal is received. At that point, your handlers and in-flight requests may still be using those resources. You should delay the resource cleanup until the shutdown timeout has passed or all requests are done.</p><p>In many cases, simply letting the process exit is enough. The operating system will automatically reclaim resources. For instance:</p><ul><li>Memory allocated by Go is automatically freed when the process terminates.</li><li>File descriptors are closed by the OS.</li><li>OS-level resources like process handles are reclaimed.</li></ul><p>However, there are important cases where explicit cleanup is still necessary during shutdown:</p><ul><li><strong>Database connections</strong> should be closed properly. If any transactions are still open, they need to be committed or rolled back. Without a proper shutdown, the database has to rely on connection timeouts.</li><li><strong>Message queues and brokers</strong> often require a clean shutdown. This may involve flushing messages, committing offsets, or signaling to the broker that the client is exiting. Without this, there can be rebalancing issues or message loss.</li><li><strong>External services</strong> may not detect the disconnect immediately. Closing connections manually allows those systems to clean up faster than waiting for TCP timeouts.</li></ul><p>A good rule is to shut down components in the reverse order of how they were initialized. This respects dependencies between components.</p><p>Go’s <code>defer</code> statement makes this easier since the last deferred function is executed first:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>db</span> <span>:=</span> <span>connectDB</span><span>()</span>
</span></span><span><span><span>defer</span> <span>db</span><span>.</span><span>Close</span><span>()</span>
</span></span><span><span>
</span></span><span><span><span>cache</span> <span>:=</span> <span>connectCache</span><span>()</span>
</span></span><span><span><span>defer</span> <span>cache</span><span>.</span><span>Close</span><span>()</span>
</span></span></code></pre></div><p>Some components require special handling. For example, if you cache data in memory, you might need to write that data to disk before exiting. In those cases, design a shutdown routine specific to that component to handle the cleanup properly.</p><a href="#summary"><h2 id="summary" origin-id="summary">Summary</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>This is a complete example of a graceful shutdown mechanism. It is written in a flat, straightforward structure to make it easier to understand. You can customize it to fit your own application as needed.</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>const</span> <span>(</span>
</span></span><span><span>	<span>_shutdownPeriod</span>      <span>=</span> <span>15</span> <span>*</span> <span>time</span><span>.</span><span>Second</span>
</span></span><span><span>	<span>_shutdownHardPeriod</span> <span>=</span> <span>3</span> <span>*</span> <span>time</span><span>.</span><span>Second</span>
</span></span><span><span>	<span>_readinessDrainDelay</span> <span>=</span> <span>5</span> <span>*</span> <span>time</span><span>.</span><span>Second</span>
</span></span><span><span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>var</span> <span>isShuttingDown</span> <span>atomic</span><span>.</span><span>Bool</span>
</span></span><span><span>
</span></span><span><span><span>func</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>	<span>// Setup signal context</span>
</span></span><span><span>	<span>rootCtx</span><span>,</span> <span>stop</span> <span>:=</span> <span>signal</span><span>.</span><span>NotifyContext</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>(),</span> <span>syscall</span><span>.</span><span>SIGINT</span><span>,</span> <span>syscall</span><span>.</span><span>SIGTERM</span><span>)</span>
</span></span><span><span>	<span>defer</span> <span>stop</span><span>()</span>
</span></span><span><span>
</span></span><span><span>	<span>// Readiness endpoint</span>
</span></span><span><span>	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/healthz"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
</span></span><span><span>		<span>if</span> <span>isShuttingDown</span><span>.</span><span>Load</span><span>()</span> <span>{</span>
</span></span><span><span>			<span>http</span><span>.</span><span>Error</span><span>(</span><span>w</span><span>,</span> <span>"Shutting down"</span><span>,</span> <span>http</span><span>.</span><span>StatusServiceUnavailable</span><span>)</span>
</span></span><span><span>			<span>return</span>
</span></span><span><span>		<span>}</span>
</span></span><span><span>		<span>fmt</span><span>.</span><span>Fprintln</span><span>(</span><span>w</span><span>,</span> <span>"OK"</span><span>)</span>
</span></span><span><span>	<span>})</span>
</span></span><span><span>
</span></span><span><span>	<span>// Sample business logic</span>
</span></span><span><span>	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
</span></span><span><span>		<span>select</span> <span>{</span>
</span></span><span><span>		<span>case</span> <span>&lt;-</span><span>time</span><span>.</span><span>After</span><span>(</span><span>2</span> <span>*</span> <span>time</span><span>.</span><span>Second</span><span>):</span>
</span></span><span><span>			<span>fmt</span><span>.</span><span>Fprintln</span><span>(</span><span>w</span><span>,</span> <span>"Hello, world!"</span><span>)</span>
</span></span><span><span>		<span>case</span> <span>&lt;-</span><span>r</span><span>.</span><span>Context</span><span>().</span><span>Done</span><span>():</span>
</span></span><span><span>			<span>http</span><span>.</span><span>Error</span><span>(</span><span>w</span><span>,</span> <span>"Request cancelled."</span><span>,</span> <span>http</span><span>.</span><span>StatusRequestTimeout</span><span>)</span>
</span></span><span><span>		<span>}</span>
</span></span><span><span>	<span>})</span>
</span></span><span><span>
</span></span><span><span>	<span>// Ensure in-flight requests aren't cancelled immediately on SIGTERM</span>
</span></span><span><span>	<span>ongoingCtx</span><span>,</span> <span>stopOngoingGracefully</span> <span>:=</span> <span>context</span><span>.</span><span>WithCancel</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>())</span>
</span></span><span><span>	<span>server</span> <span>:=</span> <span>&amp;</span><span>http</span><span>.</span><span>Server</span><span>{</span>
</span></span><span><span>		<span>Addr</span><span>:</span> <span>":8080"</span><span>,</span>
</span></span><span><span>		<span>BaseContext</span><span>:</span> <span>func</span><span>(</span><span>_</span> <span>net</span><span>.</span><span>Listener</span><span>)</span> <span>context</span><span>.</span><span>Context</span> <span>{</span>
</span></span><span><span>			<span>return</span> <span>ongoingCtx</span>
</span></span><span><span>		<span>},</span>
</span></span><span><span>	<span>}</span>
</span></span><span><span>
</span></span><span><span>	<span>go</span> <span>func</span><span>()</span> <span>{</span>
</span></span><span><span>		<span>log</span><span>.</span><span>Println</span><span>(</span><span>"Server starting on :8080."</span><span>)</span>
</span></span><span><span>		<span>if</span> <span>err</span> <span>:=</span> <span>server</span><span>.</span><span>ListenAndServe</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>&amp;&amp;</span> <span>err</span> <span>!=</span> <span>http</span><span>.</span><span>ErrServerClosed</span> <span>{</span>
</span></span><span><span>			<span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"ListenAndServe: %v"</span><span>,</span> <span>err</span><span>)</span>
</span></span><span><span>		<span>}</span>
</span></span><span><span>	<span>}()</span>
</span></span><span><span>
</span></span><span><span>	<span>// Wait for signal</span>
</span></span><span><span>	<span>&lt;-</span><span>rootCtx</span><span>.</span><span>Done</span><span>()</span>
</span></span><span><span>	<span>stop</span><span>()</span>
</span></span><span><span>	<span>isShuttingDown</span><span>.</span><span>Store</span><span>(</span><span>true</span><span>)</span>
</span></span><span><span>	<span>log</span><span>.</span><span>Println</span><span>(</span><span>"Received shutdown signal, shutting down."</span><span>)</span>
</span></span><span><span>
</span></span><span><span>	<span>// Give time for readiness check to propagate</span>
</span></span><span><span>	<span>time</span><span>.</span><span>Sleep</span><span>(</span><span>_readinessDrainDelay</span><span>)</span>
</span></span><span><span>	<span>log</span><span>.</span><span>Println</span><span>(</span><span>"Readiness check propagated, now waiting for ongoing requests to finish."</span><span>)</span>
</span></span><span><span>
</span></span><span><span>	<span>shutdownCtx</span><span>,</span> <span>cancel</span> <span>:=</span> <span>context</span><span>.</span><span>WithTimeout</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>(),</span> <span>_shutdownPeriod</span><span>)</span>
</span></span><span><span>	<span>defer</span> <span>cancel</span><span>()</span>
</span></span><span><span>	<span>err</span> <span>:=</span> <span>server</span><span>.</span><span>Shutdown</span><span>(</span><span>shutdownCtx</span><span>)</span>
</span></span><span><span>	<span>stopOngoingGracefully</span><span>()</span>
</span></span><span><span>	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
</span></span><span><span>		<span>log</span><span>.</span><span>Println</span><span>(</span><span>"Failed to wait for ongoing requests to finish, waiting for forced cancellation."</span><span>)</span>
</span></span><span><span>		<span>time</span><span>.</span><span>Sleep</span><span>(</span><span>_shutdownHardPeriod</span><span>)</span>
</span></span><span><span>	<span>}</span>
</span></span><span><span>
</span></span><span><span>	<span>log</span><span>.</span><span>Println</span><span>(</span><span>"Server shut down gracefully."</span><span>)</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><a href="#who-we-are"><h2 id="who-we-are" origin-id="who-we-are">Who We Are</h2><h2 data-pagefind-ignore="" arialabel="Anchor">#</h2></a><p>If you want to monitor your services, track metrics, and see how everything performs, you might want to check out <a href="https://docs.victoriametrics.com/" rel="external" target="_blank">VictoriaMetrics</a>. It’s a fast, <strong>open-source</strong>, and cost-saving way to keep an eye on your infrastructure.</p><p>And we’re Gophers, enthusiasts who love researching, experimenting, and sharing knowledge about Go and its ecosystem. If you spot anything that’s outdated or if you have questions, don’t hesitate to reach out. You can drop me a DM on <a href="https://twitter.com/func25" rel="external" target="_blank">X(@func25)</a>.</p><p>Related articles:</p><ul><li><a href="https://victoriametrics.com/categories/go-@-victoriametrics">Golang Series at VictoriaMetrics</a></li><li><a href="https://victoriametrics.com/blog/go-array">How Go Arrays Work and Get Tricky with For-Range</a></li><li><a href="https://victoriametrics.com/blog/go-slice">Slices in Go: Grow Big or Go Home</a></li><li><a href="https://victoriametrics.com/blog/go-map">Go Maps Explained: How Key-Value Pairs Are Actually Stored</a></li><li><a href="https://victoriametrics.com/blog/defer-in-go">Golang Defer: From Basic To Traps</a></li><li><a href="https://victoriametrics.com/blog/vendoring-go-mod-vendor">Vendoring, or go mod vendor: What is it?</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Hackathons feel fake now (182 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43889502</link>
            <guid>43889502</guid>
            <pubDate>Sun, 04 May 2025 20:55:41 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43889502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="43889502">
      <td><span></span></td>      <td><center><a id="up_43889502" href="https://news.ycombinator.com/vote?id=43889502&amp;how=up&amp;goto=item%3Fid%3D43889502"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=43889502">Ask HN: Hackathons feel fake now</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_43889502">103 points</span> by <a href="https://news.ycombinator.com/user?id=sepidy">sepidy</a> <span title="2025-05-04T20:55:41 1746392141"><a href="https://news.ycombinator.com/item?id=43889502">5 hours ago</a></span> <span id="unv_43889502"></span> | <a href="https://news.ycombinator.com/hide?id=43889502&amp;goto=item%3Fid%3D43889502">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Hackathons%20feel%20fake%20now&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=43889502&amp;auth=ecec15ec742832f826b52746d7ef40bcdf5c727f">favorite</a> | <a href="https://news.ycombinator.com/item?id=43889502">74&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><p>Been going to a bunch of hackathons in SF lately and honestly, everything feels fake. There are like 20 sponsors handing out credits for their tools that all do the same thing. Half the time, they can’t even explain what they’re for. They’re just hoping someone uses them so they can count it as adoption. Everyone jams these into projects to check a box, and what gets built is mostly BS with zero innovation.
Was it always like this and I'm noticing it now, or has something changed?</p></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'd rather read the prompt (1236 pts)]]></title>
            <link>https://claytonwramsey.com/blog/prompt/</link>
            <guid>43888803</guid>
            <pubDate>Sun, 04 May 2025 19:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://claytonwramsey.com/blog/prompt/">https://claytonwramsey.com/blog/prompt/</a>, See on <a href="https://news.ycombinator.com/item?id=43888803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>When I grade students’ assignments, I sometimes see answers like this:</p>
<blockquote>
<p>Utilizing Euler angles for rotation representation could have the following possible downsides:</p>
<ul>
<li><strong>Gimbal lock</strong>: In certain positions, orientations can reach a singularity, which prevents them from continuously rotating without a sudden change in the coordinate values.</li>
<li><strong>Numeric instability</strong>: Using Euler angles could cause numeric computations to be less precise, which can add up and produce inaccuracies if used often.</li>
<li><strong>Non-unique coordinates</strong>: Another downside of Euler angles is that some rotations do not have a unique representation in Euler angles, particularly at singularities.</li>
</ul>
<p>The downsides of Euler angles make them difficult to utilize in robotics.
It’s important to note that very few implementations employ Euler angles for robotics.
Instead, one could use rotation matrices or quaternions to facilitate more efficient rotation representation.</p>
<p><em>[Not a student’s real answer, but my handmade synthesis of the style and content of many answers]</em></p>
</blockquote>
<p>You only have to read one or two of these answers to know exactly what’s up: the students just copy-pasted the output from a large language model, most likely ChatGPT.
They are invariably verbose, interminably waffly, and insipidly fixated on the bullet-points-with-bold style.
The prose rarely surpasses the sixth-grade book report, constantly repeating the prompt, presumably to prove that they’re staying on topic.</p>
<p>As an instructor, I am always saddened to read this.
The ChatGPT rhetorical style is distinctive enough that I can catch it, but not so distinctive to be worth passing along to an honor council.
Even if I did, I’m not sure the marginal gains in the integrity of the class would be worth the hours spent litigating the issue.</p>
<p>I write this article as a plea to everyone: not just my students, but the blog posters and Reddit commenters and weak-accept paper authors and Reviewer 2.
<strong>Don’t let a computer write for you!</strong>
I say this not for reasons of intellectual honesty, or for the spirit of fairness.
I say this because I believe that your original thoughts are far more interesting, meaningful, and valuable than whatever a large language model can transform them into.
For the rest of this piece, I’ll briefly examine some guesses as to why people write with large language models so often, and argue that there’s no good reason to use one for creative expression.</p>
<h2 id="why-do-people-do-this">Why do people do this?</h2>
<p>I’m not much of a generative-model user myself, but I know many people who heavily rely upon them.
From my own experience, I see a few reasons why people use such models to speak for them.</p>
<p><strong>It doesn’t matter.</strong>
I think this belief is most common in classroom settings.
A typical belief among students is that classes are a series of hurdles to be overcome; at the end of this obstacle course, they shall receive a degree as testament to their completion of these assignments.
I think this is also the source of increasing language model use in in <a href="https://arxiv.org/abs/2403.07183">paper reviews</a>.
Many researchers consider reviewing ancillary to their already-burdensome jobs; some feel they cannot spare time to write a good review and so pass the work along to a language model.</p>
<p><strong>The model produces better work.</strong>
Some of my peers believe that large language models produce strictly better writing than they could produce on their own.
Anecdotally, this phenomenon seems more common among English-as-a-second-language speakers.
I also see it a lot with first-time programmers, for whom programming is a set of mysterious incantations to be memorized and recited.
I think this is also the cause of language model use in some forms of <a href="https://arxiv.org/abs/2404.01268">academic writing</a>: it differs from the prior case with paper reviews in that, presumably, the authors believe that their paper matters, but don’t believe they can produce sufficient writing.</p>
<p><strong>There’s skin in the game.</strong>
This last cause is least common among individuals, but probably accounts for the overwhelming majority of language pollution on the Internet.
Examples of skin-in-the-game writing include astroturfing, customer service chatbots, and the rambling prologues found in online baking recipes.
This writing is never meant to be read by a human and does not carry any authorial intent at all.
For this essay, I’m primarily interested in the motivations for private individuals, so I’ll avoid discussing this much; however, I have included it for sake of completeness.</p>
<h2 id="why-do-we-write-anyway">Why do we write, anyway?</h2>
<p>I believe that the main reason a human should write is to <em>communicate original thoughts</em>.
To be clear, I don’t believe that these thoughts need to be special or academic.
Your vacation, your dog, and your favorite color are all fair game.
However, these thoughts should be <em>yours</em>: there’s no point in wasting ink to communicate someone else’s thoughts.</p>
<p>In that sense, using a language model to write is worse than plagiarism.
When copying another person’s words, one doesn’t communicate their own original thoughts, but at least they are communicating a human’s thoughts.
A language model, by construction, has no original thoughts of its own; publishing its output is a pointless exercise.</p>
<p>Returning to our reasons for using a language model, we can now examine them once more with this definition in mind.</p>
<h3 id="if-it-s-not-worth-doing-it-s-not-worth-doing-well">If it’s not worth doing, it’s not worth doing well</h3>
<p>The model output in the doesn’t-matter category falls under two classes to me: the stuff that actually doesn’t matter and the stuff that actually does matter.
I’ll start with the things that don’t matter.
When someone comments under a Reddit post with a computer-generated summary of the original text, I honestly believe that everyone in the world would be better off had they not done so.
Either the article is so vapid that a summary provides all of its value, in which case, it does not merit the engagement of a comment, or it demands a real reading by a real human for comprehension, in which case the summary is pointless.
In essence, writing such a comment wastes everyone’s time.
This is the case for all of the disposable uses of a model.</p>
<p>Meanwhile, there are uses which seem disposable at a surface-level and which in practice are not so disposable (the actually-does-matter category).
I should hope that the purpose of a class writing exercise is not to create an artifact of text but force the student to think; a language model produces the former, not the latter.
For paper reviewers, it’s worse: a half-assed review will produce little more than make-work for the original authors and tell the editor nothing they didn’t already know.</p>
<h3 id="if-it-s-worth-doing-it-s-worth-doing-badly">If it’s worth doing, it’s worth doing badly</h3>
<p>I’ll now cover the opposite case: my peers who see generative models as superior to their own output.
I see this most often in professional communication, typically to produce fluff or fix the tone of their original prompts.
Every single time, the model obscures the original meaning and adds layers of superfluous nonsense to even the simplest of ideas.
If you’re lucky, it at least won’t be wrong, but most often the model will completely fabricate critical details of the original writing and produce something completely incomprehensible.
No matter how bad any original human’s writing is, I can (hopefully?) trust that they have some kind of internal understanding to share; with a language model, there is no such luck.</p>
<p>I have a little more sympathy for programmers, but the long-term results are more insidious.
You might recall Peter Naur’s <cite>Programming as Theory Building</cite>: writing a sufficiently complex program requires not only the artifact of code (that is, the program source), but a <dfn>theory</dfn> of the program, in which an individual must fully understand the logical structure behind the code.
Vibe coding; that is, writing programs almost exclusively by language-model generation; produces an artifact with no theory behind it.
The result is simple: with no theory, the produced code is practically useless.
In Naur’s terms, such a program is <dfn>dead</dfn>; in our case, it’s stillborn.
It should come as no surprise that nearly every vibe-coded app on the Internet struggles with security issues; look no further than <a href="https://news.ycombinator.com/item?id=43553031#43554611">the vibe-coded recipe app that leaks its OpenAI keys</a>.
Every time one generates code by prompt, they create a new stillborn program; vibe coding is the art of stitching together their corpses into Frankenstein’s monster.</p>
<h2 id="an-annotated-exercise">An annotated exercise</h2>
<p>As an experiment, I copied the thesis statement of this essay into Google Gemini and prompted it to complete the essay.
Below the spoiler is its complete response.</p>
<details>
  <summary>The complete prompt and output.</summary>
<p>Prompt:</p>
<blockquote>
<p>The following is an introduction to a short essay which I have written. Complete the essay by writing 2 short paragraphs.</p>
<p>I write this article as a plea to everyone: not just my students, but the blog posters and Reddit commenters and weak-accept paper authors and Reviewer 2.
<strong>Don’t let a computer write for you!</strong>
I say this not for reasons of intellectual honesty, or for the spirit of fairness.
I say this because I believe that your original thoughts are far more interesting, meaningful, and valuable than whatever a large language model can transform them into.
For the rest of this piece, I’ll briefly examine some guesses as to why people write with large language models so often, and argue that there’s no good reason to use one for creative expression.</p>
</blockquote>
<p>Output:</p>
<blockquote>
<p>It’s fascinating to consider why so many are turning to large language models for writing. Perhaps it stems from a desire for efficiency, a wish to quickly generate text without the perceived effort of crafting each sentence. The allure of instant output can be strong, especially in a world that often prioritizes speed. For students facing deadlines, or blog posters needing content, the temptation to shortcut the writing process might feel overwhelming. There could also be a sense of insecurity, a feeling that one’s own writing isn’t “good enough” and that a language model can somehow elevate it. This might be particularly true for those navigating the often critical world of academic reviews or the sometimes harsh landscape of online commentary.</p>
<p>However, this reliance on artificial intelligence fundamentally misunderstands the very essence of creative expression. Your individual voice, shaped by your unique experiences, perspectives, and even your struggles to articulate an idea, is what makes your writing resonate. A language model, trained on vast datasets of existing text, can only ever produce a pastiche, a reflection of what has already been said. It lacks the spark of genuine insight, the unexpected turn of phrase that comes from wrestling with a concept until it becomes your own. To surrender your voice to an algorithm is to diminish the potential for true connection and the profound satisfaction of communicating your own original thoughts to the world.</p>
</blockquote>
</details>
<p>The resulting text is, put plainly, <em>boring</em>.
In its 234-word output, the model produces merely a lengthy rehash of the same prompt.
Tonally, it provides no more than sweeping and pointless generality, and any points earned for its brobdingnagian vocabulary are immediately lost to its total lack of taste in using it.
For example, consider the following sentence:</p>
<blockquote>
<p>Perhaps it stems from a desire for efficiency, a wish to quickly generate text without the perceived effort of crafting each sentence.</p>
</blockquote>
<p>Gemini has produced a big sentence for a small thought.
I can trivially cut two-thirds of it and remove nothing of substance:</p>
<blockquote>
<p>Perhaps it stems from a desire for efficiency.</p>
</blockquote>
<p>With some care, I can trim it a little more.</p>
<blockquote>
<p>Perhaps people do it for efficiency.</p>
</blockquote>
<p>So, in short, a language model is great for making nonsense, and not so great for anything else.</p>
<h2 id="just-show-me-the-prompt">Just show me the prompt</h2>
<p>I now circle back to my main point: I have never seen any form of create generative model output (be that image, text, audio, or video) which I would rather see than the original prompt.
The resulting output has less substance than the prompt and lacks any human vision in its creation.
The whole point of making creative work is to share one’s own experience - if there’s no experience to share, why bother?
If it’s not worth writing, it’s not worth reading.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI code is legacy code (159 pts)]]></title>
            <link>https://text-incubation.com/AI+code+is+legacy+code+from+day+one</link>
            <guid>43888225</guid>
            <pubDate>Sun, 04 May 2025 17:53:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text-incubation.com/AI+code+is+legacy+code+from+day+one">https://text-incubation.com/AI+code+is+legacy+code+from+day+one</a>, See on <a href="https://news.ycombinator.com/item?id=43888225">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Driverless print server for legacy printers, profit goes to open-source (163 pts)]]></title>
            <link>https://printserver.ink/</link>
            <guid>43888157</guid>
            <pubDate>Sun, 04 May 2025 17:43:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://printserver.ink/">https://printserver.ink/</a>, See on <a href="https://news.ycombinator.com/item?id=43888157">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p><strong>UoWPrint is a modern print server created to bring wireless
capabilities to older printers, scanners, and all-in-one
devices.</strong></p>
<p>It is designed as an easy-to-use add-on appliance and allows you
to:</p>
<ul>
<li><strong>Convert your old USB printer (or
<abbr title="Multi-function printer: scan, copy, print">MFP</abbr>) into
Wi-Fi printer/MFP</strong></li>
<li><strong>Print and scan without drivers from Windows/macOS/Linux, as
well as iOS/Android</strong></li>
</ul>
<p>Contrary to older-generation print server hardware or home routers
with printer-sharing functions, UoWPrint does not require to install any
printer-specific drivers or applications on your devices but uses
universal standard drivers available in any contemporary operating
system.<br>
The printer driver is running on the print server itself, freeing you
from installing drivers on the PC.</p>
<p>In other words, with UoWPrint you can use <a href="https://en.wikipedia.org/wiki/AirPrint">AirPrint</a> and <a href="https://en.wikipedia.org/wiki/Mopria_Alliance">Mopria</a> to print
and scan over the network on your USB printer.</p>
<p>✅ Compatible with Windows, macOS, Linux, Android, iOS<br>
✅ Compatible with MacBook M1/M2/M3/M4 (ARM)<br>
✅ Compatible with Windows on ARM (Qualcomm Snapdragon)</p>
<figure>
<img src="https://printserver.ink/pics/printserver-fs8.png" width="1200" height="514" alt="Device connection scheme">

</figure>
<figure>
<img src="https://printserver.ink/pics/4.jpg" width="1200" height="748" alt="Photo of the board connected to the printer. The device comes with simple acrylic case.">

</figure>
<h3 id="printer-compatibility">Printer compatibility</h3>
<p>UoWPrint is best compatible with older-generation consumer devices
(manufactured before the year 2018) and supports a very wide range of
ink and laser printers and scanners. However, some of the printers are
not supported well or at all.<br>
HP devices work very well, Samsung and Xerox support is also pretty
reliable, while Canon compatibility depends on the device generation and
may be not as fast or reliable.</p>
<p><strong>Check almost <a href="https://printserver.ink/supported.txt">full list</a> of
supported devices</strong>.</p>
<h4 id="included-drivers">Included drivers</h4>
<p>The following non-exhaustive list provides a brief overview of the
available drivers and popular supported models:</p>
<ul>
<li><a href="https://splix.sourceforge.net/#:~:text=list%20of%20supported%20printers">splix</a>
and <a href="https://web.archive.org/web/20191231052546/http://foo2qpdl.rkkda.com/#:~:text=you%20can%20print%20to%20some%20samsung%20and%20xerox%20printers">foo2qpdl</a>
for Samsung Printer Language (SPL) devices:
<ul>
<li><strong>Samsung SCX-3200, SCX-4200, SCX-4300</strong></li>
<li><strong>Samsung ML-1210, ML-1710, ML-2015, ML-2525, ML-2165,
ML-3471</strong></li>
<li><strong>Samsung CLP-500</strong></li>
<li><strong>Xerox Phaser 31xx/34xx, 5500, 61x0, WorkCentre
3119</strong></li>
</ul></li>
<li><a href="https://web.archive.org/web/20191218040201/http://foo2zjs.rkkda.com/#:~:text=possibly%20other%20zjstream%20printers">foo2zjs</a>,
<a href="https://web.archive.org/web/20191203133406/http://foo2xqx.rkkda.com/#:~:text=you%20can%20print%20to%20some%20hp">foo2xqx</a>,
<a href="https://www.openprinting.org/driver/hplip/">hpcups</a> for the
majority of HP LaserJets, InkJets, DeskJets, and PhotoSmarts:
<ul>
<li><strong>HP LaserJet 1005, 1010, 1018, 1020, 1160, 1320, 3020, 3030,
3330</strong></li>
<li><strong>HP LaserJet P1005, P2015</strong></li>
<li><strong>HP LaserJet Pro P1102, P1566, P1606dn</strong></li>
<li><strong>HP LaserJet M1522nf, 3055</strong></li>
<li><strong>HP LaserJet Pro MFP M521, MFP M425</strong></li>
</ul></li>
<li><a href="https://github.com/mounaiban/captdriver/wiki#supported-devices">capt</a>
open-source driver for Canon Advanced Printing Technology (CAPT) devices
<sup>alpha-quality drivers</sup>:
<ul>
<li><strong>Canon i-SENSYS LBP2900, LBP3000, LBP3010, LBP3100,
LBP6000</strong></li>
</ul></li>
<li>Official Canon <a href="https://github.com/mounaiban/captdriver/wiki/List-of-CAPT-only-Canon-Printers">CAPT</a>
driver running in x86 emulation mode:
<ul>
<li><strong>Canon Laser Shot LBP810, LBP1120</strong></li>
<li><strong>Canon Laser Shot LBP5100, LBP6000B, LBP7018C</strong></li>
</ul></li>
<li><a href="https://github.com/ondrej-zary/carps-cups#cups-driver-for-canon-carps-printers">carps</a>
for Canon Advanced Raster Printing System (CARPS) devices:
<ul>
<li><strong>Canon MF3110, MF56x0, MF57x0</strong></li>
<li><strong>Canon MF3200</strong></li>
<li><strong>Canon LC310, L390, L408S, L180, L380S, L398S</strong></li>
<li><strong>Canon PC-D300, FAX-L400, ICD300</strong></li>
</ul></li>
<li>Canon <a href="https://github.com/mounaiban/captdriver/wiki/List-of-Canon-i-Sensys-Devices#device-list">UFRII-based
devices</a> running in x86 emulation mode:
<ul>
<li><strong>Canon LBP212dw, LBP214dw</strong></li>
<li><strong>Canon LBP3360, LBP3460, LBP6230dw, LBP6650dn, LBP6780x,
LBP7660cdn</strong></li>
<li><strong>Canon MF212w, MF4010, MF4018, MF4320d, MF512x</strong></li>
</ul></li>
<li><a href="https://github.com/Owl-Maintain/brlaser#supported-printers">brlaser</a>
for Brother laser devices:
<ul>
<li><strong>Brother HL-1110, HL-120x, HL-L237x, HL-L5000D</strong></li>
<li><strong>Brother DCP-1623</strong></li>
</ul></li>
<li><a href="https://hub.mos.ru/mikhailnov/rastertokpsl-re/">rastertokpsl-re</a>
for Kyocera GDI devices:
<ul>
<li><strong>Kyocera FS-1020MFP, FS-1025MFP, FS-1040, FS-1060DN,
FS-1120MFP, FS-1125MFP</strong></li>
</ul></li>
<li><a href="https://panasonic.net/cns/pcc/support/fax/common/table/linuxdriver.html">Panasonic
GDI</a> official printers running in x86 emulation mode:
<ul>
<li><strong>Panasonic KX-MB1500, KX-MB2000, KX-MB2500
series</strong></li>
<li><strong>Panasonic DP-MC210, DP-MB250 series</strong></li>
</ul></li>
<li><a href="https://global.pantum.com/">Pantum</a> printers and MFPs
official driver running in x86 emulation mode:
<ul>
<li><strong>Pantum BM5100, M6500 series</strong></li>
<li><strong>Pantum P2200, P2500 series</strong></li>
</ul></li>
<li><a href="https://support.epson.net/linux/Printer/LSB_distribution_pages/en/escpr.php">Epson
Inkjet Printer Driver</a> and <a href="https://support.epson.net/linux/Printer/LSB_distribution_pages/en/escpr2.php">Driver
2</a>:
<ul>
<li><strong>Overwhelming majority of Epson devices</strong></li>
</ul></li>
<li><a href="https://gimp-print.sourceforge.io/p_Supported_Printers.php">GutenPrint</a>:
<ul>
<li><strong>Canon PIXMA/imageRunner, Kyocera, Lanier, Ricoh, Xerox and
other devices</strong></li>
</ul></li>
<li><a href="https://www.openprinting.org/drivers/">GhostScript</a>:
<ul>
<li><strong>Various PostScript, PCL, IJS models</strong></li>
</ul></li>
</ul>
<p>… and many others.</p>
<h4 id="operating-system-support">Operating system support</h4>
<ul>
<li><strong>Windows XP/7/8/8.1</strong>, with limited printing options
support (PostScript / PCL)</li>
<li><strong>Windows 10</strong>, October 2018 update (build 1809) and
newer with full support (Mopria)</li>
<li><strong>Windows 11</strong> (Mopria)</li>
<li><strong>macOS 10.6+</strong> (AirPrint / AirScan)</li>
<li><strong>Linux</strong> with CUPS 2.2.2+ (AirPrint / Mopria)</li>
<li><strong>Android</strong> 8+ (default print service) or Android 4.4+
with <a href="https://play.google.com/store/apps/details?id=org.mopria.printplugin">Mopria
Print Service</a> + <a href="https://play.google.com/store/apps/details?id=org.mopria.scan.application">Mopria
Scan</a></li>
<li><strong>iOS 4.2+</strong> (AirPrint, <em>no built-in scanning
support, scanning using web interface possible</em>)</li>
</ul>
<p>Device-specific driver is not required on every OS.</p>
<h3 id="project-information">Project information</h3>
<h4 id="why">Why?</h4>
<p>After buying used old USB-only printer, I was looking for a modern
retail print server which would allow me to use the printer as you use
the newer ones, over Wi-Fi and without drivers, but could not find
anything on the market!<br>
Reducing e-waste, improving convenience, and re-using single-board
computers for good is the main motivation of this project.</p>
<p>Old printers are tend to be better than the new ones: the best mono
lasers were manufactured in the year 2004-2010, that was the peak of
reliable, serviceable, and cheaper to operate machines than the current
retail models. They do not offer subscription service or annoying
firmware updates which block third-party toner cartridges.</p>
<h4 id="no-anti-consumer-practices">No anti-consumer practices</h4>
<p><strong>No Internet connection required.</strong> The device does not
use the Internet for anything besides time synchronization. No
telemetry, no automatic updates.<br>
<strong>Secure by default.</strong> Network firewall blocks all
connections from the outside of your network. No hard-coded passwords.
IPv6 support.<br>
<strong>Open for enthusiasts and modification.</strong> Comes with
source code and full build system of the firmware.<br>
<strong>Reliable technical support.</strong> We sold you the print
server and it doesn’t work as intended? We’ll buy the same printer model
and debug the issue until it’s fixed!</p>
<h4 id="software">Software</h4>
<p>UoWPrint is based on well-known Linux-world open source software:</p>
<ul>
<li><a href="https://openprinting.github.io/">CUPS</a> print server with
AirPrint/Mopria shading capabilities</li>
<li><a href="http://www.sane-project.org/">SANE</a> scanning suite for
MFP and dedicated scanner support</li>
<li><a href="https://github.com/SimulPiscator/AirSane">AirSane</a> for
AirScan/Mopria scanner sharing capability</li>
<li><a href="https://box86.org/">box86</a> emulator to use official
(proprietary) printer and scanner drivers for x86 machines on ARM
architecture, which enables wide compability in the absence of an open
driver.</li>
</ul>
<p>All you need to start printing is plug the printer into the USB port
and add it using print server web interface. The printer will be
discovered on all devices on the network automatically.</p>
<p>The device works as Wi-Fi access point or connects to your Wi-Fi
network as a client, Ethernet connection is also available. It
incorporates simple web interface to configure Wi-Fi connection and
printer, and scanners usually do not require special configuration and
work out-of-the-box.</p>
<p>The operating system of the device is based on Debian 12 and has been
optimized for memory constraints and fail-save appliance-like operation:
power off the device by unplugging the power without worrying of data
corruption, revert to factory defaults with a click of a button.</p>
<p><strong>Warning:</strong> this project may not be suitable for
professional printing. Due to the various quality of the drivers, the
printouts may not present accurate colors or the highest quality. Some
printer and scanner drivers have bugs and don’t work reliably. UoWPrint
has undergone thoroughful, but limited testing. We constantly find and
fix bugs in the whole printing and scanning stack (and contribute back
to related projects to ensure bug-free experience for everyone), but
this is best-effort low-scale holiday project, some thigs are way over
our heads. Ask to check your printer support in advance <a href="mailto:uowprint@valdikss.org.ru?subject=UoWPrint%20inquiry&amp;body=Do%20not%20forget%20to%20include%20your%20printer%20model%20for%20compatibility%20check">by
email</a>.</p>
<h4 id="hardware">Hardware</h4>
<p><strong>UoWPrint v2</strong> is based on <a href="http://www.orangepi.org/html/hardWare/computerAndMicrocontrollers/details/Orange-Pi-Zero-3.html">OrangePi
Zero 3</a> single-board computer. Key specifications:</p>
<table>
<tbody><tr>
<th>
Size
</th>
<td>
62 mm × 56 mm in acrylic case<br>55 mm × 50 mm the board itself
</td>
</tr>
<tr>
<th>
Weight
</th>
<td>
52 g
</td>
</tr>
<tr>
<th>
CPU
</th>
<td>
<a href="https://linux-sunxi.org/H616">Allwinner H618</a><br> ARMv8
Cortex-A53 Quad Core, 1.5 GHz
</td>
</tr>
<tr>
<th>
RAM
</th>
<td>
1 GiB LPDDR4
</td>
</tr>
<tr>
<th>
Flash memory
</th>
<td>
512 MB MicroSD card
</td>
</tr>
<tr>
<th>
USB
</th>
<td>
1× USB 2.0 Type-A Host for printer connection<br> 1× USB 2.0 Type-C
OTG for 5V power supply and PC connection<p> LPT printer
connection possible with USB-LPT adapter cable
</p></td>
</tr>
<tr>
<th>
Wi-Fi
</th>
<td>
802.11ac 2.4+5 GHz, Wi-Fi hotspot and client modes
</td>
</tr>
<tr>
<th>
Ethernet
</th>
<td>
1G/100M Built-in Ethernet
</td>
</tr>
<tr>
<th>
Supported standards
</th>
<td>
Driverless printing and scanning:
<ul>
<li>
AirPrint™ (macOS/iPhone/iPad)
</li>
<li>
Mopria® (Windows/Linux/Android)
</li>
</ul>
Printing with the driver:
<ul>
<li>
Internet Printing Protocol (IPP)
</li>
</ul>
</td>
</tr>
<tr>
<th>
Features
</th>
<td>
No internet connection required<br> No account or subscription
required<br> No automatic updates<br> Web-based configuration, no
additional software required<br> Comes with the source code, firmware,
and free technical support
</td>
</tr>
<tr>
<th>
Operating system
</th>
<td>
Based on Debian 12<br>Linux kernel 6.6
</td>
</tr>
<tr>
<th>
Software
</th>
<td>
OpenPrinting CUPS<br>SANE<br>AirSane<br>Box86
</td>
</tr>
</tbody></table>
<h3 id="order">Order</h3>
<p>What you get:</p>
<ul>
<li>UoWPrint v2 device (without USB power supply or cable)</li>
<li>Electronic instruction</li>
<li>Archive with the firmware, source code, and build scripts</li>
<li>Free tech support from the living human being who takes
responsibility for fixing possible compatibility issues with your
printer</li>
</ul>
<p>All you need is a USB-C cable and a power supply (any cellphone
charger).</p>
<p>Price: $35 USD or 2900₽ (Russian Ruble), shipping cost not
included.<br>
Payments using cryptocurrency (preferred), PayPal, or Russian SBP.</p>
<p><a href="mailto:uowprint@valdikss.org.ru?subject=UoWPrint%20inquiry&amp;body=Do%20not%20forget%20to%20include%20your%20printer%20model%20for%20compatibility%20check">Order
by email: uowprint@valdikss.org.ru</a></p>
<p>For each sold device, CUPS and SANE developers receive $2 donation
each. The profit of selling the device is to be spent on improving open
source drivers support.</p>
<h3 id="documentation">Documentation</h3>
<p>Configuration how-to is available in <a href="https://printserver.ink/docs-en/">English</a>
and <a href="https://printserver.ink/docs-ru/">Russian</a>.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Design for 3D-Printing (722 pts)]]></title>
            <link>https://blog.rahix.de/design-for-3d-printing/</link>
            <guid>43888117</guid>
            <pubDate>Sun, 04 May 2025 17:38:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.rahix.de/design-for-3d-printing/">https://blog.rahix.de/design-for-3d-printing/</a>, See on <a href="https://news.ycombinator.com/item?id=43888117">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-div">
  <p>Over the past years, I have gotten deeper and deeper into 3d-printing.  One
thing that fascinates me a lot is how different it is from other manufacturing
methods.  And how this, in turn, means a completely different design philosophy
is needed to create good designs for 3d-printing.</p>
<p>As such, I have been collecting the little tricks and rules for designing
well-printable parts.  And of course I am always on the hunt for more.  In this
blog post I want to share all that I have learned.</p>

<p><span>
  <p><img alt="Design for 3d-printing" src="https://blog.rahix.de/design-for-3d-printing/title.jpg">
    
  </p>
</span>
<span id="continue-reading"></span></p><h2 id="introduction">Introduction<a href="#introduction"><i></i></a>
</h2>
<p>While a lot can be found online about the basics of design for 3d-printing,
there is not that much material that dives into it in-depth.  And even less
common are good overviews that collect all the little tricks that people have
discovered.</p>
<p>I believe the best format for teaching the rules of well-printable design is a
format that is built on rules of thumb and many practical examples.  While such
heuristic rules will never encompass the whole complexity of the real world, I
think they can provide a tangible guide towards the best solution in each
situation.  They also provide a starting point for building your own intuition
about the topic.</p>
<p>This approach is close in spirit to the german book <em>Konstruktionspraxis im
Maschinenbau</em> by Gerhard Hoenow and Thomas Meißner (<a href="https://www.hanser-kundencenter.de/fachbuch/artikel/9783446464858">Hanser
Fachbuch</a>, ISBN 978-3-446-46485-8). The book follows
the same philosophy, but for traditional manufacturing methods.  If you like
this style, that book might interest you as well.</p>
<h4 id="scope">Scope<a href="#scope"><i></i></a>
</h4>
<p>Before diving in, a few words about the scope of this blog post:  First, I am
explicitly focusing on FDM/FFF printing (<a href="https://en.wikipedia.org/wiki/Fused_filament_fabrication">Wikipedia</a>).  A lot of
the rules are specifically tied to the restrictions of this process and do not
apply to other additive manufacturing methods.</p>
<p>Second, I am focusing on designing functional parts with optimal mechanical
properties.  These parts should be easy to print, without requiring much
printer fine-tuning.  They should be easy to produce in higher quantity, which
means they should require as little post-processing and waste as little
material as possible.  Aesthetics do not play a primary role, although I firmly
believe that great mechanical design just looks incredibly beautiful :)</p>
<h4 id="goals-of-design-engineering">Goals of Design Engineering<a href="#goals-of-design-engineering"><i></i></a>
</h4>
<p>Any mechanical design ultimately must be optimized for a large number of
objectives and constraints.  Your job as the designer is to create a part that
fits best between them all.</p>
<p>The most universal objectives are:</p>
<ul>
<li><strong>Design according to force</strong> — Parts should be designed such that their
geometry is optimal for the forces it has to transmit and withstand.</li>
<li><strong>Design according to manufacturing method</strong> — Often called <em>DFM</em>
(Design For Manufacturing), parts should be designed such that they are
easy to produce.  Little changes, which usually don't affect functionality,
can often make a part <em>much</em> simpler to manufacture.</li>
<li><strong>Design according to cost</strong> — Parts should be as cheap as possible.
With 3d-printing, this means minimizing material use and print time.</li>
</ul>
<p>Of course, any real world project will have many more objectives and a lot of
other constraints that the design must comply with.</p>
<p>In this blog post, I will focus on topics related to design for manufacturing
with a 3d-printer.  In general, the rules for other objectives are the same,
regardless of manufacturing process.  However, there are some places where
3d-printing does influence these other objectives and I will also highlight
such cases.</p>
<p>An important distinction that I need to make at this point is how the approach
of design engineering attacks the problem from the completely opposite side
compared to, for example, slicer developers and 3d-printer manufacturers.
While they aim for improving the manufacturing process itself, to better print
any possible part geometry, a design engineer instead aims for adapting the
part geometry to best work with the current state of the the manufacturing
processes.</p>
<p>To give an example, a design engineer aims to use the most coarse tolerance on
each dimension that still allows the part to function.  A 3d-printer
manufacturer wants their machine to print with the most tight tolerance they
can achieve.  While the design engineer could try making use of this most tight
tolerance, this will make the part impossible to manufacture using cheaper
printers and thus drive up cost and limit possible suppliers for a part.</p>
<p>This can be summarized as aiming for <em>portable design</em>.  A portably designed
part can be printed by anyone on any printer with ease.  If you intend to share
your designs online, this should definitely be a priority.</p>
<p>Finally, it is also important to keep in mind that due to the rapid innovation
in the 3d-printing scene, we are working with a moving target.  As the
3d-printers and slicer software get improved, some of the design rules will
become less important.</p>
<h4 id="terminology">Terminology<a href="#terminology"><i></i></a>
</h4>
<p>To make sure everyone is on the same page, let's quickly review the most
important terminology of FFF 3d-printing that will be used in the following
chapters:</p>
<ul>
<li><strong>Layers</strong> — The horizontal cross-sections of a part that are stacked
on top of one another to create the part (<a href="https://help.prusa3d.com/article/layers-and-perimeters_1748#layer-height">Layer height — Prusa
Knowledge Base</a>).</li>
<li><strong>Perimeters</strong> — On each layer, the 3d-printer will first print the
outline of the cross-section.  This outline consists of a number of perimeter
lines (<a href="https://help.prusa3d.com/article/layers-and-perimeters_1748#perimeters">Perimeters — Prusa Knowledge Base</a>).</li>
<li><strong>Shell</strong> — If you think of only the perimeters on each layer, you get
a completely hollow object:  The <em>shell</em> of the part.</li>
<li><strong>Infill</strong> — Inside the perimeters, the 3d-printer "fills" the space
using a partially hollow pattern.  This is the infill pattern (<a href="https://help.prusa3d.com/article/infill_42">Infill
— Prusa Knowledge Base</a>).</li>
<li><strong>Infill Percentage</strong> — How much of the infill pattern is solid vs.
empty space (<a href="https://help.prusa3d.com/article/infill_42">Infill — Prusa Knowledge Base</a>).</li>
<li><strong>Overhang</strong> — When the cross-section of a layer gets larger than the
previous layer, a part of the perimeter lines will not be supported by
material from below.  This is called an <em>overhang</em> and is actually possible
as long as the overhang is not too large.  Mostly, people talk about the
angle of an overhang when looking at the layers from the side.</li>
<li><strong>Bridges</strong> — While overhangs can become problematic, one thing
3d-printers are surprisingly good at is bridging gaps between two supporting
surfaces.  This is called a <em>bridge</em>.</li>
<li><strong>Seam</strong> — The <em>seam</em> is the point where the printer starts and stops
laying a perimeter.  This point is usually well visible as a perfectly smooth
transition is very hard to achieve (<a href="https://help.prusa3d.com/article/seam-position_151069">Seam position — Prusa Knowledge
Base</a>)</li>
</ul>
<h4 id="the-standard-printer-profile">The Standard Printer Profile<a href="#the-standard-printer-profile"><i></i></a>
</h4>
<p>One final topic before we can dive in.  To achieve the aforementioned <em>portable
designs</em>, it is useful to define a design target for your work.  Namely a rough
outline of the 3d-printer and profile that the design will be printed with.</p>
<p>While most of the following rules are relevant regardless, I will need to make
some assumptions.  Especially for all the numbers I will mention, a design
target is needed for context.  Otherwise values for expectable tolerances and
empirical dimensional recommendations will have no meaning.</p>
<p>As such, here is my definition of the <em>standard printer profile</em>.  Cutting
across the current market of 3d-printers, the vast majority are compatible with
the following expectations.  A lot of the expectations are intentionally kept
quite vague — we must not assume too much, to keep the designs
<em>portable</em>.</p>
<ul>
<li>The standard 3d-printer is using an 0.4&nbsp;mm nozzle.</li>
<li>The standard profile prints at 0.2&nbsp;mm layer height.</li>
<li>The standard 3d-printer is calibrated such that no considerable dimensional
deviation is caused by error in the steps/mm setting.  Skew between the axes
is negligible.</li>
<li>Print speeds are tuned to an adequate level but we cannot assume the printer
to be free of artifacts like slight overshoot and ringing.</li>
<li>Bridging across reasonable distances is reliable.</li>
<li>Overhangs print fine.</li>
<li>Bed adhesion is adequate and does not pose an issue for non-extreme geometry.</li>
</ul>
<h2 id="design-rules">Design Rules<a href="#design-rules"><i></i></a>
</h2>
<p>Table of Contents</p>
<ol>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#1-designing-for-part-strength">Designing for Part Strength</a></li>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#2-manufacturing-tolerance-and-part-finish">Manufacturing Tolerance and Part Finish</a></li>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#3-process-optimization">Process Optimization</a></li>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#4-functional-integration">Functional Integration</a></li>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#5-beyond-plastic-machine-elements">Beyond plastic - Machine Elements</a></li>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#6-appearance">Appearance</a></li>
<li><a href="https://blog.rahix.de/design-for-3d-printing/#7-extra-vase-mode-design">Extra: Vase Mode Design</a></li>
</ol>
<h2 id="1-designing-for-part-strength">1. Designing for Part Strength<a href="#1-designing-for-part-strength"><i></i></a>
</h2>
<p>The first rules I will present are related to designing parts that are as
strong as possible.  In 3d-printing, the strength of a part is inherently tied
to the manufacturing process.  For one, the parts are partly hollow and thus
behave quite differently than a solid block of plastic.  Second, the layered
manufacturing process leads to anisotropic parts — meaning their
mechanical properties differ depending on direction (<a href="https://en.wikipedia.org/wiki/Anisotropy#Materials_science_and_engineering">Wikipedia</a>).</p>
<p>Thus, beyond general design rules for part strength, a few additional
considerations should be made when designing parts for 3d-printing.</p>
<h4 id="part-orientation">Part Orientation<a href="#part-orientation"><i></i></a>
</h4>
<p>Let's start with the most obvious:  3d-printed parts are much weaker in the
direction of pulling apart the layers.  Thus, before starting on a design, you
should first consider the direction of tensile forces in your part and use them
to decide on a print orientation.  All further design should then be done with
this print orientation in mind.</p>
<p>
    <a href="#rule-R1.1"><i></i></a>
    <strong>R1.1</strong> 
    —
    Tensile forces should be aligned parallel to the print surface.
  </p>
<p>This is probably the number one rule that everyone talks about in design for
3d-printing.  And that is for good reason because the difference it makes is
substantial.  Tests performed by My Tech Fun indicate roughly 3 times more strength in
ideal orientation (<a href="https://www.youtube.com/watch?v=ZiQek0wei1g">YouTube</a>).  While the exact ratio
will depend heavily on the individual part, I think this is a good indicator of
how important this topic is.</p>

<p><span>
  <div>
    <p><img alt="good and bad print orientation" src="https://blog.rahix.de/design-for-3d-printing/Screw-Thread-Orientation.png"></p><p>A threaded part designed for upright printing (not ideal for tensile loading)
and one designed for printing flat on the bed.  By cutting away a part of the
thread, it can be printed lying flat on the print bed, without supports.</p>
    
  </div>
</span></p><p>You should also keep in mind that tensile forces are exerted to some cross
section of a part when bending it.  This means that you should also align any
bending moments parallel to the print surface.  A place where this often fails
is printed clips, which bend slightly to clip into their counterpart.  Such
features will break easily when not oriented correctly.</p>

<p><span>
  <div>
    <p><img alt="good and bad orientation of printed clip" src="https://blog.rahix.de/design-for-3d-printing/Clip-Orientation.png"></p><p>Clips like the one on the left do not survive many uses before breaking.</p>
    
  </div>
</span></p><p>I also want to give a small tip here about sharing your designs on platforms
like <a href="https://www.printables.com/">Printables</a>:  Make sure you upload your
models in the correct print orientation.  While the correct orientation may
seem obvious to you, others might not know and they will try printing your part
without reorienting it first.  You'll do them a small favor by uploading
correctly oriented files 🙂</p>
<h4 id="when-no-orientation-works">When no orientation works<a href="#when-no-orientation-works"><i></i></a>
</h4>
<p>Especially with complex parts, in some cases, no print
orientation is ideal.  While it is often fine to make a trade-off and accept
limited strength in certain locations, one alternative should always be kept in
mind:</p>
<p>
    <a href="#rule-R1.2"><i></i></a>
    <strong>R1.2</strong> 
    —
    Split a part into multiple pieces when no orientation is ideal for all loads.
  </p>
<p>As each piece gets printed individually, you are completely free to choose
the optimal orientation for each one.  Clever joints can be used to easily
assemble the whole part afterwards.  Just to mention one:  Dovetail joints have
proven themselves for 3d-printing, as they are well-printable in most orientations.</p>

<p><span>
  <div>
    <p><img alt="two parts with a dovetail joint" src="https://blog.rahix.de/design-for-3d-printing/Dovetail.png"></p><p>A dovetail joint is used to attach two halves of a part so that each piece
can be printed in an improved orientation.</p>
    
  </div>
</span></p><h4 id="to-infill-or-not-to-infill">To infill or not to infill<a href="#to-infill-or-not-to-infill"><i></i></a>
</h4>
<p>Contrary to the first rule, a topic that is not talked about enough in my eyes
is the role of infill in part strength.  There is a big misconception that you
can magically give your part ultimate strength by just using 100% infill.  While you
will certainly see an increase in strength, this method is not efficient at all
— most of the additional material does not contribute to part strength
and is just waste and an unnecessary increase of print time.</p>
<p>Why?  It all has to do with the distribution of force inside of a part.
Generally, most parts are not stressed in pure tension or compression.  Instead,
a lot of stress is applied in the form of bending moments and those distribute
the force unevenly.  The force will be greatest in places furthest away from
the center (neutral axis).  Thus, it is generally more effective for additional
material to be added at the surface, not the center of a part.</p>

<p><span>
  <div>
    <p><img alt="bending stress" src="https://blog.rahix.de/design-for-3d-printing/stress-concentration.png"></p><p>Stress is highest directly beneath the surface of the part.  Notice the blue
neutral axis in the middle, where stress is lowest.</p>
    
  </div>
</span></p><p>In 3d-printer speak, this means you should increase the number of
perimeters/shells rather than the infill percentage.  Stefan from CNC Kitchen
has done a thorough analysis of this (<a href="https://www.youtube.com/watch?v=AmEaNAwFSfI">YouTube</a>).</p>
<p>In general, his work is a great resource for in-depth information about the
mechanical behavior of 3d-printed parts (CNC Kitchen <a href="https://www.cnckitchen.com/">Blog/Website</a>
and <a href="https://www.youtube.com/@CNCKitchen">YouTube</a>).</p>
<p>
    <a href="#rule-R1.3"><i></i></a>
    <strong>R1.3</strong> 
    —
    Most strength comes from the part's surface, not the infill.
  </p>
<h4 id="the-flow-of-forces">The Flow of Forces<a href="#the-flow-of-forces"><i></i></a>
</h4>
<p>However, there is more to this.  We can actually influence the amount of stress
at the surface by changing the shape of the part.  This is often much more
effective than optimizing print settings.  A way to conceptualize the stress
inside of a part is to think about the forces "flowing" through it. The visual
representation of this is called a <em>force lines drawing</em>
(<a href="https://en.wikipedia.org/wiki/Force_lines">Wikipedia</a>).</p>

<p><span>
  <div>
    <p><img alt="force lines around a crack" src="https://blog.rahix.de/design-for-3d-printing/crack-force-lines.png"></p>
    
  </div>
</span></p><p>Stress will concentrate in places where the force lines are close together.
You can see how the sharp corners of the crack in the image above lead to
regions of particularly high stress and thus will probably lead to part failure
in these locations.</p>
<p>This isn't specific to 3d-printing but as it is such an important topic, I want
to include it here anyway.  The rules are generally the same for any
manufacturing method: We want to minimize stress and the best way to do it is
this:</p>
<p>
    <a href="#rule-R1.4"><i></i></a>
    <strong>R1.4</strong> 
    —
    Guide forces on the most direct path possible.
  </p>
<p>Or in other words, keep the force lines as short and straight as possible.</p>
<p>One example where this matters a lot are sharp corners.  They impact part
strength very negatively and are usually easy to avoid by simply adding a
fillet.  You can see how a fillet allows a much more direct path for the force
than a sharp corner:</p>

<p><span>
  <div>
    <p><img alt="force lines around corner and fillet" src="https://blog.rahix.de/design-for-3d-printing/force-lines-fillet.svg"></p><p>Force lines around a sharp corner vs. a corner with a fillet.</p>
    
  </div>
</span></p><h4 id="cross-sectional-considerations">Cross-sectional Considerations<a href="#cross-sectional-considerations"><i></i></a>
</h4>
<p>The inhomogeneous nature of 3d-printed parts with their shell and infill has
yet more implications for part strength that are worth talking about.  In
traditional design engineering, you are taught to reduce cross-sectional area
of a part as much as possible.  You should only keep material in places where
it has the highest effect on increasing part strength. The reason for this is
that reduced volume directly leads to reduced material usage and thus cost and
weight savings.</p>
<p>With 3d-printing, things work differently.  You can usually increase the
cross-sectional area quite a bit, without a noticeable increase in material
usage, as the infill is mostly empty space.  You should rather strive to reduce
the surface area of a part, because that is where most material is used.</p>
<p>This means that you can get away with much thicker shapes in 3d-printed parts,
which obviously benefits part strength a lot.  Don't try to work against this
artificially — if a design allows for it, go for the fattest shape
possible.</p>
<p>
    <a href="#rule-R1.5"><i></i></a>
    <strong>R1.5</strong> 
    —
    Use large cross sections.  Prefer thick shapes over thin shapes.
  </p>
<p>To give an example, think about the traditional I-beam
(<a href="https://en.wikipedia.org/wiki/I-beam">Wikipedia</a>) cross-section. The idea is that material is only kept in
the regions far away from the neutral axis of the bending moment, where it has
the highest impact on part strength.  This allows for significant weight
savings.</p>
<p>While the I-beam profile works wonders for homogeneous materials, it is not a
good idea for 3d-printing. A square cross-section of the same outer dimensions
will have comparable or better strength but usually does not lead to an
increase in material usage and print-time.  It might actually perform better in
those areas, as shown below.</p>

<p><span>
  <div>
    <p><img alt="i-beam vs square profile comparison" src="https://blog.rahix.de/design-for-3d-printing/Profile-Comparison.png"></p><p>Comparison of print times and material usage for I-beam profile and square profile.</p>
    
  </div>
</span></p><h4 id="simulation-struggles">Simulation Struggles<a href="#simulation-struggles"><i></i></a>
</h4>
<p>In traditional mechanical engineering, whenever a part needs to be evaluated
for its strength, the tool of choice is simulation.  Simulation allows making
accurate prediction of a part's behavior under load without needing to
manufacture it.  Especially for parts made from expensive materials or made using
expensive manufacturing methods, performing simulations beforehand is critical
for the project's budget.</p>
<p>Unfortunately, simulation quickly breaks down when trying to analyze 3d-printed
parts.  The problem is, once again, the inhomogeneous nature of 3d-printing.
While stress analysis may still be useful to find critical areas to give
attention to, extracting realistic values for limiting forces is a lost cause.</p>
<p>Luckily, there is an alternative to simulations that 3d-printing offers.  The
exceptionally low cost of manufacturing 3d-printed parts means that printing
prototypes for testing mechanical properties is often the most cost-effective
solution.  Need to find yield strength of a design?  Just print a few copies
and empirically determine it.</p>
<p>However, there is one things to be careful with: While I see test-prints as a
great way to determine mechanical properties, I advise to not rely on them for
determining dimensional accuracy.  I will go into more detail on my reasons for
this in the next chapter.</p>
<p>Finally, an implication of the above is that <em>topology optimization</em>
(<a href="https://en.wikipedia.org/wiki/Topology_optimization">Wikipedia</a>) is not really well suited for FFF 3d-printing.
While it is amazing for other additive manufacturing processes, current tools
are usually not able to produce designs that would truly be optimal for FFF
3d-printing.  Not to speak of the often less-than-ideal printability of such
parts.</p>
<h2 id="2-manufacturing-tolerance-and-part-finish">2. Manufacturing Tolerance and Part Finish<a href="#2-manufacturing-tolerance-and-part-finish"><i></i></a>
</h2>
<p>Next, I want to talk about optimizing your design to improve manufacturing
tolerances.  Certain shapes will generally print cleaner than others.
If you take this into consideration during design, you can achieve parts that
fit on first print and won't need endless tweaking of the slicer settings and
printer.  A welcome side-effect of improved tolerance is a cleaner part finish
as well.  Thus, the following chapter covers both: Manufacturing tolerance and
part finish.</p>
<h4 id="chamfers-vs-fillets">Chamfers vs. Fillets<a href="#chamfers-vs-fillets"><i></i></a>
</h4>
<p>To start, let's talk about edges.  Generally, mechanical parts should avoid
sharp edges because they are unpleasant to touch.  Any good design breaks edges
by either adding a round fillet or a 45° chamfer of appropriate size.</p>
<p>While the choice between the two is often made for stylistic reasons, there are
actually some rather important printability aspects to it.  There are two
situations that we have to look at, distinguished by the print orientation of
the edge:</p>
<p>Adding a fillet or chamfer to edges <em>parallel</em> to the print surface means the
feature will be built up from multiple layers, potentially with overhang.
Fillets are not well suited for this. They start with an incredibly steep
overhang that will not print well.  Often, such fillets will have large
surface deviations.  Even if no overhang is involved, when the
fillet sits on top, the changing curvature will make the layer steps very
visible, degrading the part finish.  Chamfers are much better suited in this
orientation.  They have a constant overhang angle, leading to a very consistent
layer stepping, which looks a lot more pleasing.</p>

<p><span>
  <div>
    <p><img alt="fillets and chamfers horizontal" src="https://blog.rahix.de/design-for-3d-printing/Chamfer-And-Fillet-Vertical.png"></p><p>Fillets and chamfers on edges parallel to the print surface.  The blue
perimeter on the bottom of the fillet marks an unsupported overhang.</p>
    
  </div>
</span></p><p>Contrary, edges <em>vertical</em> to the print surface are much better suited for
fillets.  A fillet means that the printer does not have to make sharp corners
while laying the perimeters.  This reduces print-head acceleration and thus
reduces surface artifacts (ringing, overshoot).  A chamfer on such edges will
have two sharp corners, which will never look as pretty and will never achieve
the same tolerances as a round fillet.</p>

<p><span>
  <div>
    <p><img alt="fillets and chamfers vertical" src="https://blog.rahix.de/design-for-3d-printing/Chamfer-And-Fillet-Horizontal.png"></p><p>Fillets and chamfers on edges vertical to the print surface.  The print speed
significantly decreases for the chamfer corners while the fillets can almost
keep the same velocity.</p>
    
  </div>
</span></p><p>Thus, unless stylistic choices dictate something else, the cleanest prints will
be achieved by following this rule:</p>
<p>
    <a href="#rule-R2.1"><i></i></a>
    <strong>R2.1</strong> 
    —
    Use chamfers on edges parallel to the print surface.  Use fillets on edges
vertical to the print surface.
  </p>
<h4 id="horizontal-holes">Horizontal Holes<a href="#horizontal-holes"><i></i></a>
</h4>
<p>With horizontal fillets, a major problem is the steep overhang.  There are
other design features where similar problems arise. For example, horizontally
oriented circular holes.  The larger they get, the bigger the problem will be.
The solution is to deviate from the perfect circle for a more optimized shape.
For smaller holes, a teardrop shape with a 90° angle works well.  Larger holes
can be extended to have a flat "roof".  Keep in mind that a slight amount of
additional clearance will be needed beneath the roof, due to the bridges
drooping slightly.</p>

<p><span>
  <div>
    <p><img alt="alternative horizontal holes" src="https://blog.rahix.de/design-for-3d-printing/Horizontal-Holes.png"></p><p>On the left: A ⌀4&nbsp;mm hole with a 90° teardrop.  On the right: A ⌀10&nbsp;mm hole
with a flat roof.  The roof sits 0.4&nbsp;mm above the theoretical circle so slight
drooping of the bridge won't affect the fit.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R2.2"><i></i></a>
    <strong>R2.2</strong> 
    —
    Improve horizontal holes by using a teardrop shape or giving the hole a flat roof.
  </p>
<h4 id="seemingly-seamless">Seemingly Seamless<a href="#seemingly-seamless"><i></i></a>
</h4>
<p>A topic that is very important for both part finish and dimensional
tolerances is the placement of the perimeter seams.  Perimeter seams are the
point where a perimeter line starts and ends.  It is very hard to tune a
printer such that there won't be any seam artifacts.  Thus, let's put thought
into the placement of this seam so it does not interfere with any functionality
or aesthetics.</p>
<p>Usually, the seam placement is chosen automatically by the slicer.  For each
layer, it searches for the sharpest corner (concave or convex) and then places
the seam right into it.  This has proven to be a very reliable way to
produce good results without requiring any explicit user input.</p>
<p>However, this algorithm breaks down in two situations:</p>
<ol>
<li>On perfectly round perimeters, like those of a circular hole or outline.</li>
<li>When all corners have the same angle or when the sharpest corner requires
tight tolerances.</li>
</ol>
<p>Especially the first case is very relevant. This effect has severe consequences
for the tolerances you can achieve with a circular hole.  While the rest of the
perimeter may deviate by less than 0.1&nbsp;mm, the seam artifacts can easily
bump that up to 0.4&nbsp;mm.  And worse, it shifts the centerline of the hole
because the seam is only in one place.</p>
<p>The solution is simple: Add a corner where the seam can be placed without
interfering.  Instead of a perfect circle, shape the hole like a teardrop where
the corner has a 120° angle.  Note the difference to the horizontal holes
discussed previously.</p>

<p><span>
  <div>
    <p><img alt="teardrop for perimeter seam placement" src="https://blog.rahix.de/design-for-3d-printing/Teardrop-Vertical.png"></p><p>This teardrop shape allows the seam to not interfere with the circular hole
(white dots/line indicates seam placement).</p>
    
  </div>
</span></p><p>
    <a href="#rule-R2.3"><i></i></a>
    <strong>R2.3</strong> 
    —
    Use a teardrop shape for vertical holes to avoid inaccuracy due to perimeter
seams.
  </p>
<p>Similarly, if other corners must not be used for seam placement, add a small
notch somewhere that will serve as the "sharpest corner" and thus take the
seam automatically.  While you can of course also manually place the seam using
the slicer software, this trick means no slicer tweaking is needed.</p>

<p><span>
  <div>
    <p><img alt="aesthetic difference with optimized seam placement" src="https://blog.rahix.de/design-for-3d-printing/aesthetic-seam.jpg"></p><p>Difference of forcing the seam placement.  On the left, the seam destroys the
appearance of the groove in the center.  On the right, a small notch on the
back of the part takes the seam and the groove looks much better.</p>
    
  </div>
</span></p><p>To summarize:</p>
<p>
    <a href="#rule-R2.4"><i></i></a>
    <strong>R2.4</strong> 
    —
    Consider where the seam will be placed.  If tolerances are tight, provide a
sharp concave corner for the seam the hide in.
  </p>
<h4 id="expectable-tolerances-of-fff-fdm">Expectable Tolerances of FFF/FDM<a href="#expectable-tolerances-of-fff-fdm"><i></i></a>
</h4>
<p>A fundamental building block of any "design for manufacturing" is knowing the
accuracy limits of the manufacturing process.  As stated in the beginning, the
goal is to build <em>portable</em> designs, so we should assume conservative limits
instead of exhausting the capabilities of a particular printer.  Note that this
is backwards to the traditional workflow: Instead of <em>specifying</em> tolerances
that someone else then has to achieve during manufacturing, you <em>accept</em>
certain tolerances of the manufacturing process and design accordingly.</p>
<p>It also needs to be noted that a base assumption here is that the 3d-printers in
question are well-calibrated.  A machine that is out of calibration will have
an additional constant error on top of its tolerances.  For example, badly
configured <em>steps/mm</em> values will lead to a constant factor deviation of
measurements along a certain axis. Part design cannot and should not
accommodate for this — there wouldn't be much left if we tried.</p>

<p><span>
  <div>
    <p><img alt="visualization of tolerances and calibration error" src="https://blog.rahix.de/design-for-3d-printing/Tolerance-Calibration.png"></p><p>A miscalibrated printer will have a constant error on top of its general
manufacturing tolerances.</p>
    
  </div>
</span></p><p>Before we can talk about tolerance values, it is important to understand what
causes these deviations in the first place.  A tolerance value means nothing
without the context that it applies to.  In 3d-printing especially, tolerances
will vary widely depending on specific part geometry.  This topic is quite
far-reaching, as a very large number of factors play into it.  As such, this
chapter will only contain the most important things to consider.</p>
<p>Starting from the bottom, the lower bound on accuracy is due to the <em>step
resolution</em> of the printer's stepper motors and their drivers.  Fundamentally,
there is no way to get more accurate than this, as dimensions will always fall
somewhere between two step locations.  However, on state-of-the-art
3d-printers, the theoretical step resolution is around 0.01&nbsp;mm.  Whether
this value is actually achievable is debatable, but the takeaway is that step
resolution is well below the deviations caused by other effects.</p>
<p>Continuing on, there are more effects of the printer's motion system on
dimensional accuracy.  They all have to do with mechanical unrigidness of the
printer. Tuning the slicer settings and advanced motion control (input shaping)
can bring large improvements here.  However, an equally big role is played by
the geometry the print-head is printing.  Sharp corners are the worst offender
as they force the printer to maximum acceleration.  By optimizing a part for
"easy motion", tolerances of printed parts can often be improved a lot.</p>

<p><span>
  <div>
    <p><img alt="speeds around different corners" src="https://blog.rahix.de/design-for-3d-printing/Chamfer-And-Fillet-Horizontal.png"></p><p>Once again, fillets and chamfers show quite spectacularly how different the
print-head acceleration will be in different scenarios.  Sharper corners
lead to higher acceleration and will thus have worse tolerance.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R2.5"><i></i></a>
    <strong>R2.5</strong> 
    —
    Design part geometry for easy motion paths while printing, to improve dimensional accuracy.
  </p>
<p>The next anti-accuracy component of a 3d-printer is the extruder and hotend.
Uneven extrusion makes the line width vary, which has an impact on the outer
dimensions of a part.  Additionally, the nozzle of the printer always slightly
drags the extruded line behind it.  This leads to circles always being slightly
undersized.  On inner circles (vertical holes), assume deviation to make the
hole smaller.  On outer circles, assume deviation to make the outer diameter
smaller, but to a lesser degree.</p>
<p>As a rule of thumb, for current popular FFF 3d-printers with an 0.4&nbsp;mm
nozzle at 0.2&nbsp;mm layer height, these effects lead to deviations in the
range of ±0.1&nbsp;mm for each surface. The deviations are shifted for circular
paths, as mentioned.  While many surfaces will be more accurate, this value is
a safe bet for surface deviation.</p>
<p>Unfortunately, while 3d-printers usually do not have a noteworthy growth in
tolerance for larger dimensions, other effects take over here: Especially
warping and shrinkage of the 3d-printed parts as they cool down.</p>
<p>Warping and shrinkage depend heavily on the choice of material, but there are
also part geometries that experience it more than others. In general, the more
voluminous a part is and the less sharp its edges are, the less warping can be
expected.  Think about the forces exerted when the material shrinks and how
the geometry can resist those forces.</p>
<p>
    <a href="#rule-R2.6"><i></i></a>
    <strong>R2.6</strong> 
    —
    Prevent warping by making parts voluminous and their surfaces smooth and rounded.  The ideal shape is a sphere.
  </p>
<h4 id="perfect-precision">Perfect Precision<a href="#perfect-precision"><i></i></a>
</h4>
<p>The previous chapter discussed what tolerances can be expected from the FFF
3d-printing process.  However, there are of course situations where more
accuracy is required.  One approach that is often used to deal with this is
experimentally determining a CAD dimension where the final part fits perfectly.
3d-printing makes this very easy because test prints are cheap and fast.
Often, 3d-printers have surprisingly good repeatability so a dimension that was
optimized using test prints can achieve quite incredible tolerances.  Some call
this the <em>goldilocks approach</em> (<a href="https://hackaday.com/2020/06/09/finding-perfect-part-fits-with-the-goldilocks-approach-and-openscad/">Hackaday</a>).</p>
<p>However, this empirical approach has a huge drawback:  It makes your design
depend heavily on the slicer settings that were used and the specific printer
that the part was printed on.  As discussed in the beginning, the goal is to
avoid such dependence as it makes the design less <em>portable</em>.</p>
<p>Luckily, there are other approaches that you can use to achieve the same goal,
but without requiring tight tolerances.  Of course, these approaches also have
their limitations.  So what is best in a given situation needs to be evaluated
on a case-by-case basis.</p>
<p>The first approach I want to discuss here is ingeniously simple.  It is best
summarized like this (and I wish I had a proper source for this quote):</p>
<p>
    <a href="#rule-R2.7"><i></i></a>
    <strong>R2.7</strong> 
    —
    If you can't make it precise, make it adjustable.
  </p>
<p>The idea is that in places where accuracy is needed, you should design your
part such that the dimension can be adjusted.  There is a huge variety of
adjustment mechanisms to choose from.  The following four examples should serve
to demonstrate the possibilities:</p>
<p><strong>Oblong holes for screws</strong> allow sliding a part into alignment.  This allows
for a large range of motion, but makes adjustments of less than 1&nbsp;mm very
difficult.  This method can also be used quite well to correct for angular
errors.</p>

<p><span>
  <div>
    <p><img alt="oblong holes for adjustment" src="https://blog.rahix.de/design-for-3d-printing/oblong-hole-adjustment.jpg"></p><p>An oblong hole is used to allow adjusting the position of a part.</p>
    
  </div>
</span></p><p><strong>Opposing screws for height adjustment</strong> allow fixing a dimension in place
quite permanently.  The natural reduction of the screws make tiny adjustments
easy to perform.  A downside is that access from both sides is needed, which is
not always easily achievable.  Adjusting such a mechanism is unfortunately a
bit tedious, because it is a constant back and forth between loosening one
screw a bit and then tightening the opposing screw again.</p>

<p><span>
  <div>
    <p><img alt="opposing screws holes for adjustment" src="https://blog.rahix.de/design-for-3d-printing/opposing-screws.png"></p><p>The two screws in the center oppose each other to finely adjust the height of the block between them.</p>
    
  </div>
</span></p><p><strong>(Grub)screws opposed by a spring or flexure</strong> are great for making adjustments
very easy.  The spring tension counteracting the screw means that turning the
screw either direction adjusts the dimension accordingly.  If required, a
second (grub)screw can be used to fix the part in place after adjusting.</p>

<p><span>
  <div>
    <p><img alt="screw with spring for adjustment" src="https://blog.rahix.de/design-for-3d-printing/spring-adjustment.jpg"></p><p>A height adjustment using a long M5 screw opposed by a spring.</p>
    
  </div>
</span></p><p><strong>Shimming with spring steel shims</strong> is the industry favorite for small
adjustments that only need to be changed very seldomly.  Premade shims in
various thicknesses are stacked to achieve the precise offset that is required.
Industrial shims are usually made from spring steel, but 3d-printed shims may be
conceivable for some applications.  However, especially for rather small
heights, small surface defects from the printing process could negatively
affect accuracy.</p>

<p><span>
  <div>
    <p><img alt="example of shimming" src="https://blog.rahix.de/design-for-3d-printing/shimming.jpg"></p><p>Crude example of a small 0.2&nbsp;mm shim being used for levelling a fixture.</p>
    
  </div>
</span></p><h4 id="engineering-fits">Engineering Fits<a href="#engineering-fits"><i></i></a>
</h4>
<p>In traditional mechanical engineering, when two parts need to fit each other
geometrically, a so-called <em>engineering fit</em> is used.  An engineering fit is a
systematic classification of the allowed dimensions for the two parts.
Usually, this system of fits is applied to holes and shafts, but it can be applied
to other shapes equally well.</p>
<p>The most important distinction is between</p>
<ul>
<li><strong>clearance fits</strong> where there is always some play between the parts, for any
of the allowed dimensions,</li>
<li><strong>transition fits</strong> where they might be play or interference,</li>
<li>and <strong>interference fits</strong> where the two parts will always interfere and thus
(significant) force is required to join them.  This is also referred to as a
<em>press fit</em>.</li>
</ul>

<p><span>
  <div>
    <p><img alt="illustrations of the different fit types" src="https://blog.rahix.de/design-for-3d-printing/engineering-fits.png"></p>
    
  </div>
</span></p><p>ISO 286 then goes on to define specific classes of fits with distinct tolerance
bands for the dimensions of the shaft and hole (<a href="https://en.wikipedia.org/wiki/Engineering_fit">Wikipedia</a>).
These are great for traditional manufacturing, but unfortunately, they are
mostly useless for 3d-printing.  We can't really print parts to a specific
tolerance — instead, the 3d-printer has an inherent tolerance that we have
to design for.</p>
<p>If tight tolerance engineering fits are required regardless, an option that
should not go unmentioned is post-processing of printed parts.  Especially for
printed holes, there is the possibility of reaming (<a href="https://en.wikipedia.org/wiki/Reamer">Wikipedia</a>)
them, to achieve, for example, an H6 fit.  That said, this option only makes
sense where absolutely required.  Otherwise, the additional effort is hard to
justify.</p>
<p>For any other cases, the choice is essentially between a clearance fit and an
interference fit.  Clearance fits are easy — a gap between the parts
that is larger than 2x the printer tolerance does the trick.  Interference fits,
on the other hand, are more difficult.  The problem is that large print
tolerances mean the forces in the interference fit vary wildly between
different parts.  In the worst case, this can even lead to joints breaking due
to excessive forces.</p>
<p>To counteract this, designs need to tolerate the large tolerances of
3d-printing.  There are a few tricks one can use here, which I will share
next.</p>
<h6 id="circles-considered-harmful">Circles Considered Harmful<a href="#circles-considered-harmful"><i></i></a>
</h6>
<p>The seemingly obvious solution for transition- or interference-fitting a
circular shape is a circular hole in your design.  However, I want to make the
point that this is rarely the best solution for 3d-printing.  Especially when
the aforementioned tolerance issues become relevant, circular holes should be
avoided.</p>
<p>Other shapes, like squares or hexagons can fit the mating part just as well but
are much more forgiving in regards to tolerance.  The reason for this can be
seen when considering how each shape deforms in interference situations.  A
circle can only widen by stretching along its circumference.  This quickly
leads to material failure when large amounts of interference need to be
compensated.  A square or hexagon, on the other hand, can bend to accommodate
the bigger diameter.  Little to no stretching of the material is present in
this case.</p>

<p><span>
  <div>
    <p><img alt="visualization of circle vs hexagon interference fit" src="https://blog.rahix.de/design-for-3d-printing/Interference-Visualization.png"></p><div>
      <p>red: oversized shaft / green: undersized circle or hexagon / grey hatching: interference regions</p>
<p>A circle has to stretch significantly while a hexagon just bends a little bit.</p>
    </div>
    
  </div>
</span></p><p>Another point in favor or the square or hexagon is the seam problem, as
discussed before.  A perfect circle will be heavily distorted by the seam while
a square can hide the seam neatly in one of its corners.</p>

<p><span>
  <div>
    <p><img alt="a hexagonal hole fits a cylinder pin" src="https://blog.rahix.de/design-for-3d-printing/Hex-Holes.png"></p><p>Hexagonal holes are used for a light press-fit with cylindrical stubs.  This
design also has two pockets to the sides of each stub that help with easy
removal.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R2.8"><i></i></a>
    <strong>R2.8</strong> 
    —
    Do not use circular holes for interference fits.  Use hexagon or square holes instead.
  </p>
<p>This technique is mostly useful for smaller diameters.  The additional space
occupied by the corners can become problematic for lager holes and as such,
different design approaches should be preferred.</p>
<h6 id="crush-ribs">Crush Ribs<a href="#crush-ribs"><i></i></a>
</h6>
<p>For bigger diameters, there is another trick that can be borrowed from
injection molding. <em>Crush ribs</em> are features that are meant to be plastically
deformed during assembly. Usually, a ribbing structure is added to a hole where
the ribs can be crushed into the "valleys" between them.</p>
<p>In injection molding, these crush ribs are mainly used to work around the
required draft angle.  For 3d-printing, we can repurpose them to compensate
the printer tolerance, as described by Dan Royer (<a href="https://hackaday.com/2020/10/15/adding-crush-ribs-to-3d-printed-parts-for-a-better-press-fit/">Hackaday</a>).</p>

<p><span>
  <div>
    <p><img alt="example of crush ribs in a design" src="https://blog.rahix.de/design-for-3d-printing/Crush-Rib.png"></p><p>A blind bore with crush-ribs designed for a press-fit with a shaft.</p>
    
  </div>
</span></p><p>The ribs are dimensioned such that they still achieve the required interference
at either end of the tolerance band.  Because deforming the small ribs is much
easier than deforming an entire contact surface, the joining force is kept
within limits across the entire tolerance band.</p>

<p><span>
  <div>
    <p><img alt="tolerance considerations with crush ribs" src="https://blog.rahix.de/design-for-3d-printing/Crush-Rib-Tolerance.png"></p><p>To achieve a secure fit, the force of the minimum and maximum press-fit must be considered.</p>
    
  </div>
</span></p><p>When designing crush ribs, keep in mind that such small features are prone to
have much worse tolerance than larger features.  This has two effects:</p>
<ul>
<li>The tolerance of the crush rib shown in the drawing above will be larger than usual.</li>
<li>As the crush-rib is a convex shape, it is likely to be more undersized than oversized.</li>
</ul>
<p>To give some numbers, undersizing the crush ribs by 0.2&nbsp;mm and oversizing
the bore by 0.4&nbsp;mm lead to good results for me.</p>
<p>Something to keep in mind with crush ribs is that they should not be
reassembled more than once.  Their reliance on plastic deformation means that
the joint force will significantly decrease on reassembly.</p>
<p>
    <a href="#rule-R2.9"><i></i></a>
    <strong>R2.9</strong> 
    —
    Use crush ribs for press fits that are only assembled once.
  </p>
<h6 id="grip-fins">Grip Fins<a href="#grip-fins"><i></i></a>
</h6>
<p>Another interesting approach presented by Slant 3D is called <em>grip fins</em>
(<a href="https://www.youtube.com/watch?v=yzg_NXM-NRs">YouTube</a>).  Instead of plastic deformation, like with crush ribs,
grip fins only deform elastically.  The big advantage is of course, that such a
joint can be reassembled repeatedly, which crush ribs do not really allow for.</p>

<p><span>
  <div>
    <p><img alt="example of grip fins" src="https://blog.rahix.de/design-for-3d-printing/Grip-Fins.png"></p><p>Grip fins are an approach for tolerance compensation that use elastic deformation.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R2.10"><i></i></a>
    <strong>R2.10</strong> 
    —
    Use grip fins for press fits that need to be reassembled more than once.
  </p>
<h2 id="3-process-optimization">3. Process Optimization<a href="#3-process-optimization"><i></i></a>
</h2>
<p>We have talked about designing for strength and designing for accuracy.  Let's
move closer to the manufacturing process itself.  The following chapter will
investigate ways to improve parts such that 3d-printing them gets easier,
faster, and to make parts less likely to result in failed prints.</p>
<h4 id="support-material">Support Material<a href="#support-material"><i></i></a>
</h4>
<p>The elephant in the room is certainly the topic of support material.  Support
material is used as scaffolding for features of a part that would otherwise
hang in thin air.  After printing, it is removed, to reveal the final
shape.</p>

<p><span>
  <div>
    <p><img alt="support material" src="https://blog.rahix.de/design-for-3d-printing/support-material.png"></p><p>Support material (shown in green) is used to help print an overhang that
would not be possible otherwise.</p>
    
  </div>
</span></p><p>Unfortunately, the use of support material comes with a number of drawbacks:</p>
<ul>
<li>It adds an additional post-processing step after printing.  The removal of
supports can be quite time-consuming.</li>
<li>It consumes additional material, which later turns to waste.</li>
<li>It leads to bad tolerances on supported surfaces, much worse than for the rest of the part.</li>
<li>It leaves a worse surface finish on supported surfaces.</li>
</ul>
<p>For the designer, the implication is simple:</p>
<p>
    <a href="#rule-R3.1"><i></i></a>
    <strong>R3.1</strong> 
    —
    Avoid the necessity of support material.
  </p>
<p>Yes, there are certainly many situations where using supports is the
appropriate choice.  But more often than not, slight design changes can
eliminate features that would otherwise require supports.</p>

<p><span>
  <div>
    <p><img alt="support material" src="https://blog.rahix.de/design-for-3d-printing/Support-Optimization.png"></p><p>Example of a feature that can be optimized to not require support material.</p>
    
  </div>
</span></p><p>A big role in this is played by the overall orientation of a part on the
print bed.  This was discussed previously, for part strength considerations, but
has equal effect on support requirement.  Balancing between these two is often
quite tricky.</p>

<p><span>
  <div>
    <p><img alt="showcase for the dilemma between support material and strength" src="https://blog.rahix.de/design-for-3d-printing/Support-Strength-Dilemma.png"></p><div>
      <p>The dilemma of optimizing for part strength or for avoiding supports:  The
orientation of the hook on the left part needs no supports but the force on
the hook can rip the layers apart.  The orientation on the right is ideal for
strength but needs support material.</p>
<p>In this case, the left option was chosen anyway because the forces are small
enough to not break the layers.</p>
    </div>
    
  </div>
</span></p><p>One design trick that is surprisingly powerful is the exploitation of diagonal
orientation.  Rather than keeping the rectangular shapes of a part aligned to
the printer axes, tilt the part upwards by 45°.</p>

<p><span>
  <div>
    <p><img alt="example of diagonal part orientation" src="https://blog.rahix.de/design-for-3d-printing/Diagonal-Orientation.png"></p><p>The left orientation leads to a large bridge which will leave inaccuracy and
visible artifacts.  Simply tilting the part so all the straight edges get
printed diagonally leads to all sides getting printed equally well.</p>
    
  </div>
</span></p><p>Not only does this method avoid supports or overly long bridges, it also leads to a
more uniform part finish as all faces now get printed with the same
orientation.  The easily discernible top and bottom surfaces are elegantly
avoided.</p>
<p>Of course print stability is affected by this.  You may need to include a brim
to keep such parts from falling over.  Slant 3D explores this concept of
diagonal orientation in more depth (<a href="https://www.youtube.com/watch?v=8TIhkxQNINY">YouTube</a>).</p>
<p>
    <a href="#rule-R3.2"><i></i></a>
    <strong>R3.2</strong> 
    —
    Clever part orientation on the print surface can eliminate the need for
supports.
  </p>
<h4 id="divide-and-conquer">Divide and Conquer<a href="#divide-and-conquer"><i></i></a>
</h4>
<p>Even with the best intentions, it is not always possible to make a part work
without requiring any support material.  While this may mean that it is time to
accept defeat and just print using supports, there is one last option that
should be evaluated.  It certainly isn't always the way to go, but it is worth
considering:</p>
<p>
    <a href="#rule-R3.3"><i></i></a>
    <strong>R3.3</strong> 
    —
    Split a part into multiple pieces when no orientation can avoid supports.
  </p>
<p>The trade-off here is between accepting the downsides of support material or
making assembly more complex.  Both solutions will require some amount of
post-print work, but which solution is better will always depend on the exact
circumstances.  Especially for one-off or low-volume designs, a slightly more
complex assembly is easy to justify.</p>

<p><span>
  <div>
    <p><img alt="a design where multiple parts were used to avoid supports" src="https://blog.rahix.de/design-for-3d-printing/multiple-parts.jpg"></p><p>The hooks were printed separately and then attached using screws.  This
allowed avoiding supports and also helped with optimizing print orientation
for better surface finish in critical locations (for example, the taper of
the hook).</p>
    
  </div>
</span></p><h4 id="sacrificial-layers">Sacrificial Layers<a href="#sacrificial-layers"><i></i></a>
</h4>
<p>A large number of situations where avoiding supports gets tricky are caused by
the need for printing counterbored holes upside-down.</p>

<p><span>
  <div>
    <p><img alt="counterbored hole upside-down" src="https://blog.rahix.de/design-for-3d-printing/Upside-Down-Counterbore.png"></p><p>An upside-down counterbore is problematic to print due to unsupported overhangs.</p>
    
  </div>
</span></p><p>Taking a cross-section, the problem is easily visible: The step of the
counterbore is unsupported.  Bridges won't work, because the hole in the middle
gets in the way. Using support material to help would be particularly nasty
here, because removing it from inside the hole can be very difficult.</p>
<p>One solution for this problem is the use of a <em>sacrificial layer</em>.  The idea is
simple:  Instead of an unsupported overhang, a bridge across the entire hole is
created.  This bridge is only a single layer high and only serves to
support the smaller diameter hole on top.</p>

<p><span>
  <div>
    <p><img alt="sacrificial layer" src="https://blog.rahix.de/design-for-3d-printing/Sacrificial-Layer.png"></p><p>A one layer thick bridge was added to the upside-down counterbore.  This
layer enables clean printing of the feature and can be removed easily after
printing.</p>
    
  </div>
</span></p><p>After printing, this thin layer is cut or drilled out of the part, leaving
behind the desired geometry.</p>

<p><span>
  <div>
    <p><img alt="sacrificial layer after printing" src="https://blog.rahix.de/design-for-3d-printing/sacrificial-layer-real.jpg"></p><p>This is what a sacrificial layer looks like right of the print bed.  The next
step is to cut it out using a knife or to remove it with a drill.</p>
    
  </div>
</span></p><p>Of course, upside-down counterbores aren't the only place where this trick can
be useful.  In fact, the next chapter will show an even better solution for
upside-down counterbores.  But to give an example, I have often used
sacrificial layers for the counterbore equivalent of an oblong hole.</p>
<p>
    <a href="#rule-R3.4"><i></i></a>
    <strong>R3.4</strong> 
    —
    Use sacrificial layers to avoid internal overhangs that would otherwise require supports.
  </p>
<h4 id="the-overhanging-counterbore-trick">The Overhanging Counterbore Trick<a href="#the-overhanging-counterbore-trick"><i></i></a>
</h4>
<p>Sacrificial layers are a useful tool, but they come with an additional
post-processing step.  There can also be problems with strands from the
bridging becoming loose while cutting out the sacrificial layer.  Lucky for us,
there is an even more clever way to deal with overhanging counterbores in
particular.</p>
<p>Instead of bridging over the entire hole and thus closing the through-hole on
top, bridges are only placed where they don't interfere.  Layer by layer, more
bridges are added to finally achieve the circular inner hole.</p>

<p><span>
  <p><img alt="counterbore trick stackup" src="https://blog.rahix.de/design-for-3d-printing/counterbore.png">
    
  </p>
</span></p><p>The layers of this design are as follows, from the bottom up:</p>
<ol>
<li>First, simply cut the circular counterbore to the desired depth.</li>
<li>Then, make a one layer thick cut (typically 0.2&nbsp;mm) such that only
material remains where the bridges do not run across the inner hole.  Two
strips of bridges will be left, running left and right of the inner hole.</li>
<li>On the next layer, make another one layer thick square cut with the
side length matching the inner hole diameter.  This will only leave bridges
running top and bottom of the inner hole, perpendicular to the bridges on
the layer before.</li>
<li>Finally, from the next layer on, the inner hole will be printed as a circle.
This works because the remaining bridges are small enough to not cause
issues.</li>
</ol>

<p><span>
  <div>
    <p><img alt="counterbore trick result" src="https://blog.rahix.de/design-for-3d-printing/counterbore-real.jpg"></p><p>This is what the overhanging counterbore trick looks like from below after
printing.  You can see the bridges crossing perpendicularly.</p>
    
  </div>
</span></p><p>This trick is particularly elegant because it does not require any
post-processing and it prints exceptionally cleanly.  Of course, there is a
limit to this, mostly with increasing diameters.  But unless there is a good
reason against it, this method should be your go-to for any overhanging
counterbores.</p>
<p>
    <a href="#rule-R3.5"><i></i></a>
    <strong>R3.5</strong> 
    —
    Use the overhanging counterbore trick.
  </p>
<p>For transparency, I tried finding an original source for this, but
unfortunately it isn't clear who first came up with it...</p>
<h4 id="layers-of-bridges">Layers of Bridges<a href="#layers-of-bridges"><i></i></a>
</h4>
<p>The concept from the overhanging counterbores can be generalized to an even
more powerful method.  The basic idea of bridges that support further bridges
can be used for quite advanced geometry that does not need any supports.
You will also see this called <em>sequential bridging</em> in some places.</p>
<p>An impressive example is the OpenFlexure microscope
(<a href="https://openflexure.org/projects/microscope/">Website</a>), where this design approach is used
extensively. The best way to understand how it works is to download their
models and view the layers after running the model through a slicer
(<a href="https://build.openflexure.org/openflexure-microscope/v7.0.0-beta1/models/main_body.html">STL Download</a>).</p>


<p>Especially for large bridges, it is a good idea to first build up the bridge
for a few layers before starting the next one. This gives the lower bridge more
strength and more time to cool before it gets loaded with the features on top.</p>
<p>
    <a href="#rule-R3.6"><i></i></a>
    <strong>R3.6</strong> 
    —
    Bridges on top of other bridges allow for advanced geometry, without
requiring additional support structure.
  </p>
<h4 id="well-meant-material-saving">Well Meant Material Saving<a href="#well-meant-material-saving"><i></i></a>
</h4>
<p>We have previously evaluated the I-beam shape in the context of 3d-printing.
The conclusion was that simply shaving off volume is a traditional design
approach that does not map well to 3d-printing.  There are more cases where
this topic pops up.  Cutouts, that are meant to save material, are commonly
added, while really not achieving their purpose in 3d-printed designs.  In fact,
they can lead to the opposite: More material usage and longer print times.</p>

<p><span>
  <div>
    <p><img alt="comparison of print time for a part with and without holes" src="https://blog.rahix.de/design-for-3d-printing/Adapter-Comparison.png"></p><p>A real world example of a part where holes were added with the intent of
saving material.  But after comparing the models it gets clear that the holes
actually increased the material usage and print time.</p>
    
  </div>
</span></p><p>It is necessary to shift the focus from volume to surface area, as that is
where material is most dense in 3d-printed parts.  You should strive to reduce
surface area by making shapes fat and voluminous.</p>
<p>
    <a href="#rule-R3.7"><i></i></a>
    <strong>R3.7</strong> 
    —
    Keep surface area minimal.  Design voluminous.  Do not make cutouts in an attempt to save material.
  </p>
<h4 id="optimizing-bed-adhesion">Optimizing Bed Adhesion<a href="#optimizing-bed-adhesion"><i></i></a>
</h4>
<p>Finally, a topic that mostly becomes relevant when many parts are to be
printed.  To optimize the removal of the final part from the print surface,
certain considerations can be made.</p>
<p>First of all, the surface area that is touching the bed should be carefully
balanced.  Too little will lead to parts toppling over during printing.  Too
much will make detaching the part more difficult.  Slant 3D has some nice tips
about this (<a href="https://www.youtube.com/watch?v=SZwXREFoWKA">YouTube</a>).</p>
<p>
    <a href="#rule-R3.8"><i></i></a>
    <strong>R3.8</strong> 
    —
    Reduce the surface area that is touching the print-bed when aiming for mass production.
  </p>
<h5 id="mouse-ears">Mouse Ears<a href="#mouse-ears"><i></i></a>
</h5>
<p>Related, if you are using brims to counteract parts coming loose, the mouse ear
approach presented by Slant 3D (<a href="https://www.youtube.com/watch?v=MCcFMDv_4eo">YouTube</a>) is a portable
alternative to consider that also reduces post-processing effort.</p>

<p><span>
  <div>
    <p><img alt="mouse ear as a brim alternative" src="https://blog.rahix.de/design-for-3d-printing/Mouse-Ears.png"></p><p>Two types of mouse ears: The right one is placed directly on the part.  The
left one has a small stub which makes removal even easier.</p>
    
  </div>
</span></p><p>Mouse ears are directly designed into the CAD shape of the part so they do not
need to be added later during slicing.</p>
<p>
    <a href="#rule-R3.9"><i></i></a>
    <strong>R3.9</strong> 
    —
    Add mouse ears to parts that have problems with bed adhesion.
  </p>
<h2 id="4-functional-integration">4. Functional Integration<a href="#4-functional-integration"><i></i></a>
</h2>
<h4 id="general-considerations">General Considerations<a href="#general-considerations"><i></i></a>
</h4>
<p>Functional integration is the art of designing such that each part performs as
many of the required functions as possible.  The goal is to reduce part count.
This speeds up assembly and thus often leads to decreased manufacturing cost.</p>
<p>A ubiquitous example of functional integration are clips in injection molded
plastic parts.  They replace the additional joining element that would be
required otherwise.  For this reason, they play a large role in making
products cheaper and easier to manufacture.  Clips will be discussed in more
detail later.</p>
<p>3d-printing is suited especially well for functional integration, because
additional geometric complexity does not really impact manufacturing cost.
This is in contrast to, for example, subtractive machining, where additional
geometric features generally drive up the cost.  So striving for maximum
functional integration is usually a good idea with 3d-printing.</p>
<p>However, there are some nuances to this.  Printing everything in a single part
limits the print orientation for some features. This can negatively affect
strength, tolerances, and geometric freedom.  Additionally, a highly integrated
part is more difficult to prototype because each iteration requires reprinting
a large model.  And later in the life cycle, repair of a broken part also
requires replacement of a bigger component than what would have been necessary
with a design of many smaller parts that are joined together.  More than once,
I have explicitly kept certain functions in separated parts to facilitate
easier prototyping or repair.</p>
<p>Nevertheless, the following chapters will demonstrate some design ideas that
allow integration of certain features.</p>
<h4 id="zip-tie-channels">Zip tie Channels<a href="#zip-tie-channels"><i></i></a>
</h4>
<p>The first idea that I will demonstrate is a rather simple trick.  You can add
small channels to surfaces of your part that allow fastening a zip tie to fix
some cables or wires in place.  There is a great video by Alan Reiner where I
learned about this (<a href="https://www.youtube.com/watch?v=qgt9P6jsyaY">YouTube</a>).  The <em>Zip Tie City</em> demo model
is available for download (<a href="https://www.printables.com/model/248291-zip-tie-city">Printables</a>).</p>

<p><span>
  <div>
    <p><img alt="zip tie channels on a real part" src="https://blog.rahix.de/design-for-3d-printing/ziptie-channels.jpg"></p><p>Zip tie channels are used to fix cables to a moving assembly.  You can spot
one unused zip tie channel to the left.</p>
    
  </div>
</span></p><p>The channel design is quite simply a section of a hollow cylinder.  Dimensions
that work well for smaller zip ties (100&nbsp;mm) can be taken from the drawing below.</p>

<p><span>
  <div>
    <p><img alt="zip tie channel dimensions" src="https://blog.rahix.de/design-for-3d-printing/ziptie-channels.png"></p><p>Zip tie channel dimensions for typical 100&nbsp;mm zip ties.</p>
    
  </div>
</span></p><p>An important note is that orientation of the zip tie channels should be
considered.  When the channel is printed such that no perimeters bridge across
it, it gets much weaker.  In this orientation, the bridge can easily get ripped
out which I have already seen happening in practice.</p>
<p>
    <a href="#rule-R4.1"><i></i></a>
    <strong>R4.1</strong> 
    —
    Use zip tie channels to fasten cables to a part.
  </p>
<h4 id="flexures">Flexures<a href="#flexures"><i></i></a>
</h4>
<p>Usually, mechanical parts are designed such that they can be considered
completely stiff in approximation.  Flexures are design features that
explicitly use elasticity of a part to integrate certain freedoms of
movement (<a href="https://en.wikipedia.org/wiki/Flexure">Wikipedia</a>).</p>
<p>Overall, 3d-printing is perfect for designs that incorporate flexures.  The
thin features required by flexures are easy to print, while complex to create
with other manufacturing methods.</p>
<p>
    <a href="#rule-R4.2"><i></i></a>
    <strong>R4.2</strong> 
    —
    Use flexures to integrate moving features into a part.
  </p>
<p>Two types of flexures that are very common will be discussed in more detail
below: Clips and so-called "living hinges".  But first, a few general points
about flexures in 3d-printing are presented.</p>
<p>The amount of movement allowed by a flexure is mostly limited by how much
deflection is possible without plastic deformation.  A thicker flexure will
start plastically deforming much earlier.  Thus, it is very important to keep
flexures as thin as possible when large movements are intended.  Force can be
increased by stacking multiple thin flexures, rather than creating a single
thick one.  Alternatively, the travel distance of a thicker flexure can be
increased by increasing its length — maybe even in a snaking pattern.</p>

<p><span>
  <div>
    <p><img alt="double flexure for more stiffness" src="https://blog.rahix.de/design-for-3d-printing/cable-comb-hooks.jpg"></p><p>The hooks on this cable comb are made from two parallel flexures.  This is
more stiff than a single flexure, but has the same travel in the elastic
region.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R4.3"><i></i></a>
    <strong>R4.3</strong> 
    —
    Design flexures such that they only deform elastically when used.
  </p>
<p>To make flexures long-lived, it is important to ensure they cannot be moved too
far.  Features should be strategically placed as end-stops to a flexures
movement.  This way, the movement is always kept in the elastic region and the
flexure will live much longer.</p>
<p>
    <a href="#rule-R4.4"><i></i></a>
    <strong>R4.4</strong> 
    —
    Ensure that flexures have hard limits that prevent breaking them.
  </p>
<p>Another use for flexures is sidestepping tolerance issues.  This only works
when no significant force is exerted on the joint, but can be a nice tool to
cheaply solve accuracy issues.  An example of this are the previously
discussed <a href="https://blog.rahix.de/design-for-3d-printing/#grip-fins">"grip fins"</a>.</p>
<h4 id="clips">Clips<a href="#clips"><i></i></a>
</h4>
<p>Arguably the largest amount of flexures show up in the form of clips.  Clips
have revolutionized the mass-production industry because they provide a
fastener-free way of joining together parts.  Either permanently or in a way
that can be repeatedly opened and closed again.  For the same reason, clips are
popular for 3d-printed designs — avoiding additional fastening hardware
is often desirable.</p>
<p>However, care must exercised with design of clips.  The travel distance of the
clip, retention force, and feature size must be carefully balanced.  Another
significant factor is the orientation of the clip relative to the print
surface.  Especially clips built across layers are very fragile.  In many cases
it is better to keep travel minimal and instead work with a larger clip force
for retention.</p>
<p>
    <a href="#rule-R4.5"><i></i></a>
    <strong>R4.5</strong> 
    —
    Ensure clips won't break from use.  Optimize designs for minimal clip movement.
  </p>
<p>For clips that retain by form-locking the other part geometrically, it is a
great idea to include a way to undo the clip.  Usually, this can be achieved by
providing space to reach the clip with a tool like a screw-driver to push it
backwards.</p>
<p>
    <a href="#rule-R4.6"><i></i></a>
    <strong>R4.6</strong> 
    —
    Provide a way to undo form-locking clips.
  </p>
<h4 id="living-hinges">Living Hinges<a href="#living-hinges"><i></i></a>
</h4>
<p>One more type of flexure that has exploded in popularity as part of optimizing
for mass-production are "living hinges".  These are hinges which move by
plastic deformation rather than disjoint parts rotating on an axis.  Any cheap
plastic container with a lid probably uses one or two of these hinges, because
they are so much more cost-effective and simple than proper hinged joints.</p>
<p>We can also make use of living hinges in 3d-printed design, but there are a few
limitations:  The hinge absolutely needs to to lie flat on the print bed to
achieve the thin sheet of plastic that reliably deforms.  Experiments have been
done with living hinges made from bridging layers, but these do not perform
nearly as good.</p>

<p>Engineers Grow has discussed living hinges for 3d-printing
(<a href="https://www.youtube.com/watch?v=E2CqXgaQsyI">YouTube</a>) and so has Slant 3D (<a href="https://www.youtube.com/watch?v=TiEyFle6lTM">YouTube</a>).</p>
<h4 id="printed-bearings">Printed Bearings<a href="#printed-bearings"><i></i></a>
</h4>
<p>Another design element that's sometimes suited for integration are bearings.
Especially where large diameter bearings are required, it can be more effective
to integrate the bearing into the design of the mating parts instead of using
an off-the-shelf component.</p>
<p>To integrate a bearing, the races become features of the part design.  During
assembly, standard steel bearing balls are inserted.  Optionally, a printed
cage may be necessary to ensure correct spacing between the balls.</p>

<p><span>
  <div>
    <p><img alt="printed bearing" src="https://blog.rahix.de/design-for-3d-printing/printed-bearing.jpg"></p>
    
  </div>
</span></p><p>Positive Altitude has published a video where printed bearing design is
discussed in a lot more detail (<a href="https://youtu.be/0KhV6JW2sHg">YouTube</a>).</p>
<h4 id="print-in-place-mechanisms">Print-in-place Mechanisms<a href="#print-in-place-mechanisms"><i></i></a>
</h4>
<p>As the final type of functional integration that will be discussed,
<em>print-in-place mechanisms</em> are another unique possibility of 3d-printing.
Multiple parts of an interlocking mechanism can be printed at the same time.
No post-print assembly is required.</p>
<p>Print-in-place mechanisms can include joints that would be impossible to
assemble after printing.  The trick is that interlocking parts are printed in
their already joined position.  This can be an incredibly useful design tool to
make strong mechanisms without complicated assembly.</p>

<p><span>
  <div>
    <p><img alt="herringbone planetary gear set" src="https://blog.rahix.de/design-for-3d-printing/Herringbone-Gears.jpg"></p><div>
      <p>Standard example of a print-in-place mechanism is the herringbone planetary
gear set.  This model could not be assembled from its parts after printing.</p>
<p>Design by <a href="https://www.thingiverse.com/thing:53451">Emmett Lalish</a> and picture by <a href="https://www.printables.com/model/3119-herringbone-planetary-gear">Prusa Research</a>.</p>
    </div>
    
  </div>
</span></p><p>The big downside of print-in-place mechanisms is the additional design
complexity.  Part orientation is fixed, making avoiding supports and design for
strength difficult to achieve.  Especially where interlocking parts meet, it
can be difficult to adequately support floating geometry.  Sometimes, special
<em>break-away surfaces</em> are placed between parts.  These then have to be broken
with force after printing.</p>
<p>
    <a href="#rule-R4.7"><i></i></a>
    <strong>R4.7</strong> 
    —
    Use break-away surfaces to support floating geometry in print-in-place designs.
  </p>
<p>Another critical topic for print-in-place design is the necessary clearance
between interfacing parts.  Printing multiple surfaces very close to each other
can be difficult for some printers.  It seems that a clearance of 0.3&nbsp;mm
should allow most current printers to print a design.</p>
<p>
    <a href="#rule-R4.8"><i></i></a>
    <strong>R4.8</strong> 
    —
    Ensure sufficient clearance between features in print-in-place designs.
  </p>
<h2 id="5-beyond-plastic-machine-elements">5. Beyond plastic - Machine Elements<a href="#5-beyond-plastic-machine-elements"><i></i></a>
</h2>
<p>After discussing the peculiarities of 3d-printed parts for so long, it is time
to widen the horizon.  Most functional designs will not be entirely 3d-printed,
but also include other components.  The largest number of them are most likely
going to be <em>machine elements</em>.  Screws, nuts, bearings, and all the other
standard parts optimized for certain functions.  In the following chapter,
design considerations related to the use of such machine elements will be
evaluated.</p>
<h4 id="nuts-and-bolts">Nuts and bolts<a href="#nuts-and-bolts"><i></i></a>
</h4>
<p>Arguably the most ubiquitous machine elements are screws.  For the most part,
they are used to fasten different components to each other.  While it is easy
to just pick the next best screw and design your parts around it, there is more
to it if the joint is meant to last.  In traditional mechanical design,
selection of screws can be a science of itself. Especially, when the screw is
heavily loaded or safety critical.  With design for 3d-printing, it is
technically no different — but fortunately, you can usually get away with
ignoring a lot of the complexity involved.  Nonetheless, I think it is
important to at least know the limits and some general guidance on what is good
or bad for a screwed connection of 3d-printed parts.</p>
<h6 id="screw-preload">Screw Preload<a href="#screw-preload"><i></i></a>
</h6>
<p>In screw theory, one of the most important values is the preload force
(<a href="https://en.wikipedia.org/wiki/Bolted_joint#Theory">Wikipedia</a>).  That's the clamping force exerted by
the screw at rest after tightening.  For a screwed joint to work, the preload
force must be greater than any forces experienced by the joint during
operation.</p>

<p><span>
  <div>
    <p><img alt="spring analogy for a bolted joint" src="https://blog.rahix.de/design-for-3d-printing/Spring_Analogy_for_a_Bolted_Joint.jpg"></p><div>
      <p>A bolted or screwed joint can be modelled using springs.  Preload compresses
the parts and elongates the screw.  As long as the external load never
becomes greater than the preload, the joint is fixed in place.</p>
<p>Image by <a href="https://commons.wikimedia.org/wiki/File:Spring_Analogy_for_a_Bolted_Joint.jpg">Stephen Mckelvey</a>.</p>
    </div>
    
  </div>
</span></p><p>In metal to metal joints, this preload is achieved by elongation of the screw.
In 3d-printing and other thermoplastics applications, the joint members are much
less stiff than the screw, leading to the preload mostly coming from compression
of the plastic parts instead.  The implication is that any of the traditional
preload calculation methods are mostly useless here.</p>
<p>Attempting to reach the required preload force, one quickly reaches the yield
strength limit of the printed parts, leading to deformation or worse.  While
the achievable preload is usually enough to deal with static loads of an
application, it is often not possible to counteract the dynamic loads.
Vibrations or shocks are usually the worst offenders.</p>
<p>The solution is one that's also often used for additional security of metal
joints as well:  Use additional screw locking measures, like lock-nuts or a
threadlocking adhesive.</p>
<p>
    <a href="#rule-R5.1"><i></i></a>
    <strong>R5.1</strong> 
    —
    Protect dynamically loaded screws with additional locking measures like threadlocking adhesive.
  </p>
<h6 id="screw-length">Screw Length<a href="#screw-length"><i></i></a>
</h6>
<p>Another noteworthy parameter of screwed joints is the length of the screw, or
more precisely the length of the compressed section of the 3d-printed parts. As
a rule of thumb, you should design the joint such that the screw is as long as
possible.</p>
<p>There are two effects at play that make this a reasonable choice:</p>
<ol>
<li>A long screw ensures the part is preloaded entirely in compression rather
than tension.  When an external load is then applied, it counteracts the
compression.  With a short screw, the external load would just add more
tension which printed parts often cannot take well anyway.</li>
<li>A longer screw has to be tightened with more turns to compress the part past
its yield strength.  This means it becomes less likely to accidentally
overtighten the joint.</li>
</ol>
<p>
    <a href="#rule-R5.2"><i></i></a>
    <strong>R5.2</strong> 
    —
    Design screwed connections for maximum screw length.
  </p>
<h6 id="threads-in-printed-parts">Threads in Printed Parts<a href="#threads-in-printed-parts"><i></i></a>
</h6>
<p>With screws and thermoplastics, an important consideration is the thread for the
screw to fasten to.  In metal applications, the thread is often simply cut into
the mating part.  With 3d-printed parts, the same is possible, but threads made
from thermoplastics are a lot weaker.  This means the threads can be easily
stripped by overtightening the screw.</p>
<p>Nonetheless, plastic threads are an option.  They can be tapped into a part if
an adequately sized hole is printed and wall thickness is high enough.  For
bigger diameter threads (M8 and up), modelling the threads in CAD and printing
them is an option, although quality of such threads is not always good.  The
strength of thermoplastic threads is surprisingly good — however
they do not like repeated assembly and the aforementioned overtightening problem
should not be underestimated.</p>

<p><span>
  <div>
    <p><img alt="tapping a thread into a printed part" src="https://blog.rahix.de/design-for-3d-printing/thread-tapping.jpg"></p><p>Tapping a thread into a printed part.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R5.3"><i></i></a>
    <strong>R5.3</strong> 
    —
    Cut threads into printed parts with a thread tap for quick design of low-reuse joints.
  </p>
<h6 id="rib-thread-forming">Rib Thread Forming<a href="#rib-thread-forming"><i></i></a>
</h6>
<p>An alternative to thread tapping is to combine the previously discussed concept
of <a href="https://blog.rahix.de/design-for-3d-printing/#crush-ribs">Crush Ribs</a> with a standard threaded screw.  The screw can
deform the crush ribs to create its own thread.  This rib thread forming works
surprisingly well, as demonstrated by Thomas Sanladerer
(<a href="https://www.youtube.com/watch?v=HgEEtk85rAY">YouTube</a>).</p>

<p><span>
  <div>
    <p><img alt="rib threads in a part" src="https://blog.rahix.de/design-for-3d-printing/rib-threads.png"></p><p>A part designed for rib thread forming, next to through holes with the
teardrop trick discussed earlier.  The rib threads start tapered to make it
easy to get the screw in.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R5.4"><i></i></a>
    <strong>R5.4</strong> 
    —
    Use rib thread forming for no-postprocessing low-reuse threads in printed parts.
  </p>
<h6 id="threaded-inserts">Threaded Inserts<a href="#threaded-inserts"><i></i></a>
</h6>
<p>As the downsides of plastic threads are well known from injection molding,
alternative solutions have emerged.  Most popular are small metal threaded
inserts which are added to the part as a strong and long-lasting thread.
Usually, these inserts are heat-set into an appropriately dimensioned hole.</p>

<p><span>
  <div>
    <p><img alt="threaded inserts" src="https://blog.rahix.de/design-for-3d-printing/threaded-inserts.jpg"></p><p>M5 heat-set threaded inserts in a 3d-printed part.</p>
    
  </div>
</span></p><p>Threaded inserts are much stronger than plastic threads.  They are not easily
stripped by overtightening and they survive repeated reassembly many times
over.</p>
<p>Such threaded inserts have become very popular in the 3d-printing community.
Stefan from CNC Kitchen has a nice writeup about the use of heat-set inserts
(<a href="https://www.cnckitchen.com/blog/tipps-amp-tricks-fr-gewindeeinstze-im-3d-druck-3awey">CNC Kitchen</a>).</p>
<p>
    <a href="#rule-R5.5"><i></i></a>
    <strong>R5.5</strong> 
    —
    Use heat-set threaded inserts to add highly reusable and robust threads to a part.
  </p>
<p>A design limitation of threaded inserts is that they are not reliably usable
for screws inserted from the back side.  During insertion, heat-set inserts
often push some molten plastic into the hole beneath them, preventing easy
insertion of a screw from the back side.  While the hole diameter can be tuned
to prevent this, my experience is that this is not really portable to other
3d-printers.</p>
<h6 id="embedded-nuts">Embedded Nuts<a href="#embedded-nuts"><i></i></a>
</h6>
<p>A more cost effective alternative to threaded insert is embedding standard nuts
into 3d-printed parts.  Usually, this is done by preparing an appropriate
cutout into which the nut can be inserted after or during printing.</p>

<p><span>
  <div>
    <p><img alt="embedded nuts" src="https://blog.rahix.de/design-for-3d-printing/embedded-nut.jpg"></p><p>A standard M4 nut embedded into a part.  It was inserted through the sideface
cutout visible in the picture.</p>
    
  </div>
</span></p><p>Embedded nuts are not only cheap, they are also a great alternative for the
mentioned design limitation of threaded inserts.  A nut is predestined to be
placed on the far side of a part, making through-joints with long screws easy
to realize.  This also plays into the benefits of using long screws again.</p>
<p>Two kinds of cutouts have emerged in my designs:</p>
<ul>
<li>Sideface cutouts are rectangular cutouts reaching in from a side of the part to insert the nut horizontally.</li>
<li>Backface cutouts are hexagonal pockets on the exit of the screw through-hole.</li>
</ul>

<p><span>
  <div>
    <p><img alt="embedded nuts" src="https://blog.rahix.de/design-for-3d-printing/Nut-Slot-Options.png"></p><p>Cross-section view of different cutouts for embedded nuts.  On the left, the
cutouts are from the side.  On the right, the they are from the back of the
screw.</p>
    
  </div>
</span></p><p>
    <a href="#rule-R5.6"><i></i></a>
    <strong>R5.6</strong> 
    —
    Make cutouts to embed standard nuts into a part.
  </p>
<p>The big downside of the embedded nuts approach is that they often fall out of
their cutouts during assembly.  Tuning the cutout dimensions usually does not
work well — the only real solution is to "plug" the cutouts by inserting
the nuts halfway through the print.  This does, however, complicate the
printing and assembly complexity considerably, so it often is not a desirable
choice either.</p>
<h6 id="thread-strength">Thread Strength<a href="#thread-strength"><i></i></a>
</h6>
<p>With all these options for adding threads and the many design considerations
surrounding them, one last factor that does play a role is the strength of the
threads.  Lucky for us, all of the discussed options almost always have
strength beyond the design requirements, with the other factors being more
prevalent.</p>
<p>Again, Stefan from CNC Kitchen has a nice writeup on his experiments
on the topic (<a href="https://www.cnckitchen.com/blog/helicoils-threaded-insets-and-embedded-nuts-in-3d-prints-strength-amp-strength-assessment">CNC Kitchen</a>).</p>
<h4 id="dowel-pins">Dowel Pins<a href="#dowel-pins"><i></i></a>
</h4>
<p>Let's look at machine elements beyond screws next.  While the use of dowel pins
is quite rare in 3d-printed design, they should still get mentioned.  In
traditional mechanical design, they are the go-to solution for accurately and
repeatedly locating one part to another.</p>
<p>As the tolerances of 3d-printing often make such accuracy superfluous, the uses
of dowel pins here are limited.  Additionally, such pins need an engineering
fit which is difficult to achieve in 3d-printing.  The best solution are the
<a href="https://blog.rahix.de/design-for-3d-printing/#circles-considered-harmful">hexagonal holes</a> or <a href="https://blog.rahix.de/design-for-3d-printing/#crush-ribs">crush ribs</a>
mentioned before, or post processing of the printed parts.</p>

<p><span>
  <div>
    <p><img alt="embedded nuts" src="https://blog.rahix.de/design-for-3d-printing/engraving-jig.png"></p><p>A fixture for precisely aligning a part for laser engraving.  Dowel pins were
used as reliable locating features.</p>
    
  </div>
</span></p><h4 id="embedded-hardware">Embedded Hardware<a href="#embedded-hardware"><i></i></a>
</h4>
<p>With the <a href="https://blog.rahix.de/design-for-3d-printing/#embedded-nuts">embedded nuts</a>, we already discussed one element that
can be inserted into a part mid-print.  This concept can be used for many
other things as well — many designs have been published that use this
method in some way.</p>
<p>To quickly discuss the concept again, it works like this:</p>
<ol>
<li>In the design, a cavity is left for the component to occupy.</li>
<li>During slicing, a pause is configured right before the layer above the cavity.</li>
<li>When the printer reaches the pause, the hardware is inserted.</li>
<li>Then the print is resumed, enclosing the hardware and often permanently fusing the part with it.</li>
</ol>
<p>To get some inspiration, take a look at the window in this <a href="https://www.printables.com/model/894202-modern-gridfinity-case">Modern Gridfinity
Case</a> by Matthew.  It is made from a transparent
PETG sheet that gets inserted into the print.  The design even includes small
tabs to hold the sheet in place, right as it is inserted.  This makes for a very
robust design and the result is hard to achieve with any other methods.</p>
<div>


  <p><img alt="modern gridfinity case" src="https://blog.rahix.de/design-for-3d-printing/modern-gridfinity-case.jpg">
    
  </p>




  <p><img alt="inserting the window sheet" src="https://blog.rahix.de/design-for-3d-printing/insert-transparent-sheet.gif">
    
  </p>


</div>
<p>Of course, many other components can be inserted into 3d-prints.  To name a few more:</p>
<ul>
<li>"Trapped fasteners" are inserted such that they cannot fall out of the part, making it hard to loose them.</li>
<li>Magnets</li>
<li>Metal mesh</li>
</ul>
<p>Of course the big advantage of embedded hardware is that additional joining or
fastening means can be avoided.  Do, however, consider the downside that
embedded hardware can only be extracted destructively and replacement is
usually impossible.</p>
<p>
    <a href="#rule-R5.7"><i></i></a>
    <strong>R5.7</strong> 
    —
    Embed hardware into 3d-printed parts to avoid more complex fastening or joining methods.
  </p>
<h4 id="printing-on-fabric">Printing on Fabric<a href="#printing-on-fabric"><i></i></a>
</h4>
<p>A technique that is very similar to inserted hardware, but deserves attention on
its own, is incorporating fabric into a 3d-print.  This produces parts with
unique flexibility, especially interesting for wearable applications.  For this
reason, 3d-printing onto fabric is quite popular in the cosplay scene.</p>
<p>The gist is that a print consisting of many individual pieces is paused roughly
2 to 3 layers in.  Then a piece of tulle fabric is draped across the initial
layers.  When resuming the print, the new layers on top will fuse into the lower
ones, securing each part to the fabric.</p>

<p><span>
  <div>
    <p><img alt="Printing on Fabric" src="https://blog.rahix.de/design-for-3d-printing/print-on-fabric.jpg"></p><div>
      <p>Showcase of some cosplay parts printed onto fabric.</p>
<p>Image by <a href="https://www.youtube.com/@UncleJessy">Uncle Jessy</a>.</p>
    </div>
    
  </div>
</span></p><p>The flexibility of the resulting design can be finely controlled by the geometry
of the solid 3d-printed shapes.  Other people have already experimented with this
technique a lot, for example you can check out the video tutorial from UncleJessy
(<a href="https://www.youtube.com/watch?v=CjH5KGw3Psw">YouTube</a>).</p>
<h2 id="6-appearance">6. Appearance<a href="#6-appearance"><i></i></a>
</h2>
<h4 id="complex-shapes">Complex Shapes<a href="#complex-shapes"><i></i></a>
</h4>
<p>While appearance isn't the main concern of functional design, no parts should
be designed without consideration of their appearance.  3d-printing uniquely
allows complex surface shapes to be added "for free".  Suddenly, the
consideration is no longer about increased manufacturing cost, the only
remaining factor is the time it takes to design such shapes.</p>
<p>Of course, complex shapes should still follow the basic constraints of the
process — avoiding overhangs and not mandating support material.  But
beyond that, there is no reason to limit designs to the straight and
rectangular shapes of traditional functional parts.</p>
<p>There are even places where complex, maybe organic, shapes have a use beyond
appearance: For ergonomic design, such shapes are usually much better suited.</p>
<p>
    <a href="#rule-R6.1"><i></i></a>
    <strong>R6.1</strong> 
    —
    Complex shapes are often "for free" in 3d-printing.  Use them to improve
appearance or ergonomics.
  </p>
<h4 id="shadow-lines">Shadow Lines<a href="#shadow-lines"><i></i></a>
</h4>
<p>One trick we can borrow from traditional product design practices are <em>shadow
lines</em>.  They improve the appearance of seams between mating surfaces of
multiple joined parts.  When two surfaces are pressed directly against each
other, the result will never look great due to the imperfections on both sides
leading to an uneven seam.</p>
<p><em>Shadow lines</em> improve on this by leaving a controlled larger gap between the
surfaces and hiding the actual mechanical connection behind a small lip.  The
larger gap is wide enough such that the small surface imperfections are no
longer distinguishable.  This leaves the result with a very even look without
requiring extreme precision.</p>

<p><span>
  <div>
    <p><img alt="Example of a part with a shadow line" src="https://blog.rahix.de/design-for-3d-printing/shadow-line-valve.jpg"></p><p>The upper and lower half of the valve actuator body have an evenly sized gap
between them.  The real seam is actually hidden behind the shadow line.</p>
    
  </div>
</span></p><p>It may be enough to place a single lip on the shadow line to hide the real seam.
If dust protection is of concern, a second lip on the inner side can transform
the shadow line into a sort of labyrinth seal, providing for more than just
aesthetics.</p>
<p>Shadow lines can also be used on parts joined at an angle, like a lid placed
flat onto a box.  In this case, a constant offset is left between the size of
the lid and the surrounding box, with alignment tabs on the inside ensuring the
lid stays centered.</p>

<p><span>
  <div>
    <p><img alt="Shadow line on the lid of an electronics enclosure" src="https://blog.rahix.de/design-for-3d-printing/shadow-line-electronics.jpg"></p><p>The lid is surrounded by yet another evenly sized gap.  To ensure it stays
centered, alignment ribs on the inside locate it quite precisely.</p>
    
  </div>
</span></p><p>To learn even more about this concept, Teaching Tech has made a video about the
topic (<a href="https://youtu.be/8dhFhU7Nl_0">YouTube</a>).</p>
<p>
    <a href="#rule-R6.2"><i></i></a>
    <strong>R6.2</strong> 
    —
    Create shadow lines along the joining edge between two parts.
  </p>
<h4 id="surface-texture">Surface Texture<a href="#surface-texture"><i></i></a>
</h4>
<p>Another significant factor for appearance is surface texture.  With
3d-printing, we generally do not have much control about them.  Especially
vertical surfaces will always prominently display the layer lines inherent to
the process.</p>
<p>With special print beds, like textured steel sheets, the bottom surface of parts
can be refined.  This allows for a very clean texture, but is of course quite
limited because only one surface of each part can get this treatment.
Sometimes, it is actually desirable to avoid having a bed surface on a part, to
keep all sides looking more even.  One way to do this is rotating parts to a
diagonal angle relative to the print bed.</p>
<p>For vertical surfaces, where the layer lines are sometimes destroying the
aesthetics of a part, a trick has been developed to help hiding them.  <em>Fuzzy
skin</em> adds irregularities to each layer perimeter, building up to a surface that
appears more rough, but without prominent layer lines.</p>
<p>Fuzzy skin also has a pleasant feel to it, if tuned correctly, which has made it
a popular choice for 3d-printed grips and handles.</p>

<p><span>
  <div>
    <p><img alt="Part with fuzzy skin" src="https://blog.rahix.de/design-for-3d-printing/fuzzy_skin_preview.jpg"></p><div>
      <p>Fuzzy skin on a tool grip makes for a nice appearance and pleasant feeling while holding.</p>
<p>Image by <a href="https://help.prusa3d.com/article/fuzzy-skin_246186">Prusa Research</a></p>
    </div>
    
  </div>
</span></p><p>
    <a href="#rule-R6.3"><i></i></a>
    <strong>R6.3</strong> 
    —
    Use surface texture to make parts appear less 3d-printed.
  </p>
<h4 id="printed-text">Printed Text<a href="#printed-text"><i></i></a>
</h4>
<p>Another nice side-effect of the nature of 3d-printing is the fact that it is
laughably simple to add text or symbols to a part.  No need for stickers,
decals, or labor-intensive engravings.  There is no excuse to not add text to a
printed part.</p>
<p>A starting point is to make it a habit to add part numbers into each part of a
larger design.  This way it is easy to keep everything organized.  Especially
when iterating on a part a lot, having the revision index printed onto it can
reduce confusion quite a lot.</p>

<p><span>
  <div>
    <p><img alt="part with text printed on it" src="https://blog.rahix.de/design-for-3d-printing/engraved-text.jpg"></p><p>An enclosure with a label text engraved into it.</p>
    
  </div>
</span></p><p>There are two ways to add text or symbols:  Either the text gets cut into the
surface, which is called engraving.  Or the text can be raised over the
surface, called embossing.  For the most part, engraving leads to much cleaner
results with 3d-printing.  This is especially true as the font size gets
smaller.</p>
<p>
    <a href="#rule-R6.4"><i></i></a>
    <strong>R6.4</strong> 
    —
    Prefer engraving text over embossing.
  </p>
<p>Regarding orientation, the best results will be achieved by placing the text such
that it is vertical to the print surface.  This way it gets printed as part of
the perimeter lines where the printer can achieve the most detail.</p>
<p>
    <a href="#rule-R6.5"><i></i></a>
    <strong>R6.5</strong> 
    —
    Place engraved/embossed text vertical to the print surface.
  </p>
<p>Experience has shown that most printers can print a text with 0.6&nbsp;mm
minimum stroke width and engraved to 0.5&nbsp;mm depth without issues.</p>

<p>For the final chapter, I want to investigate a completely different design
approach for 3d-printing — vase mode design.  Inherently, the FFF
3d-printing process is not volumetric.  Volumetric parts are only achieved by
using lines of plastic, fused together such that a volume emerges.  But
whether this is the most efficient way to make use of the 3d-printing process
is a question worth asking.</p>
<p>Vase mode is an alternative approach where only a hollow shell of a part is
printed, using a single perimeter line.  Instead of individual layers, the Z
height slowly increases such that filament is laid down in a spiral. This has
a number of advantageous consequences:</p>
<ul>
<li>It is very efficient because 100% of the print time is spent extruding filament.</li>
<li>Due to the lack of individual layers, there is no seam in the surface.</li>
<li>As the printer never stops printing, no stringing issues can occur.</li>
<li>It is very fast because the least amount of plastic is used to represent a part's shape.</li>
<li>It can also leads to very light parts due to the decreased filament usage.</li>
</ul>
<p>The big downside is of course that parts become very unstable due to the
missing internal support.  For certain kinds of parts, especially artistic
ones, this may not be a problem.  Even for functional parts, like vases —
where this technique got its name — the strength might already be
sufficient.</p>

<p><span>
  <div>
    <p><img alt="Vase mode vase" src="https://blog.rahix.de/design-for-3d-printing/vase.png"></p>
    
  </div>
</span></p><p>With vase mode, the most important factor to part strength is surface geometry.
Surfaces that are flat or only bend in only one direction perform the worst.
Intricate shapes often show much more strength.  This can be seen especially
with the impressive strength some vase designs manage to achieve.</p>
<h4 id="beading-patterns">Beading Patterns<a href="#beading-patterns"><i></i></a>
</h4>
<p>What those vases achieve through style can be used for technical designs in
the form of <em>beading patterns</em>.  They describe features that are added to thin
sheet-material parts to give them additional strength.  CNC-Kitchen has made a
video about using beading patterns for 3d-printing where this concept is
explored in more detail (<a href="https://www.youtube.com/watch?v=3-ygdNQThAs">YouTube</a>).  There is also a german
web-book going into detail about beading patterns in general
(<a href="https://4ming.de/de/forming-handbuch/leichtbau-durch-sicken-fachbuch">4ming.de</a>).</p>

<p>
    <a href="#rule-R7.1"><i></i></a>
    <strong>R7.1</strong> 
    —
    Use beading patterns to make vase mode parts more stiff.
  </p>
<h4 id="unconventional-vase-mode">Unconventional Vase Mode<a href="#unconventional-vase-mode"><i></i></a>
</h4>
<p>Interestingly, it is possible to adapt vase mode for even more uses.  The trick
is in viewing vase mode as a way to have very tight control over the way that a
printer extrudes filament.  A part is designed such that its surface perimeters
describe a path for the printer which ultimately results in the intended
geometry.  An impressive example of this is the stackable tray designed by
FPacheco (<a href="https://www.printables.com/model/514142-vase-mode-stackable-hextray-60-mm-hexagons">Printables</a>).</p>

<p><span>
  <div>
    <p><img alt="vase mode stackable tray" src="https://blog.rahix.de/design-for-3d-printing/vase-mode-tray.jpg"></p><p>This tray looks nothing like a vase-mode part but is the result of very careful and clever design.</p>
    
  </div>
</span></p><p>While the resulting part for such designs looks nothing like a normal vase mode
part, it still gets the 100% print time benefit of vase mode.  Especially when
a part shall be produced in high quantity, this may have significant impact.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion"><i></i></a>
</h2>
<p>Alright, you have made it to the end.  Below, you will find a final summary of
all the design rules discussed in this blog post.  Use them as a reference for
your designs, as "sane defaults" when there is no good reason to deviate.  But
at the same time, these are no laws — there are many situations where
doing things differently is the better choice.  It is your job as the design
engineer to make these decisions.</p>
<p>I have thought long about where I should publish this information.  For now,
placing it here on my blog felt like the easiest choice.  But such "rules" live
from discussion and I would love to hear your opinions and to get talking about
them.  If enough interest emerges, I would be interested in turning this into an
"open-source book" where others can contribute their own rules or suggest
changes to the existing ones.  My ultimate goal is finding the best approaches
for design for 3d-printing.  And such a feat is only achievable by the community
at large.</p>
<h2 id="checklist">Checklist<a href="#checklist"><i></i></a>
</h2>
<p>As promised, here is a summary of all the rules from the blog post.  With
checkboxes, in case you like them :)</p>
<!-- START RULES LIST -->
<ol>
<li><strong>Designing for Part Strength</strong>
<ul>
<li><label>
  
  <a href="#rule-R1.1"><strong>R1.1</strong></a> 
  —
  Tensile forces should be aligned parallel to the print surface.
</label>
</li>
<li><label>
  
  <a href="#rule-R1.2"><strong>R1.2</strong></a> 
  —
  Split a part into multiple pieces when no orientation is ideal for all loads.
</label>
</li>
<li><label>
  
  <a href="#rule-R1.3"><strong>R1.3</strong></a> 
  —
  Most strength comes from the part's surface, not the infill.
</label>
</li>
<li><label>
  
  <a href="#rule-R1.4"><strong>R1.4</strong></a> 
  —
  Guide forces on the most direct path possible.
</label>
</li>
<li><label>
  
  <a href="#rule-R1.5"><strong>R1.5</strong></a> 
  —
  Use large cross sections.  Prefer thick shapes over thin shapes.
</label>
</li>
</ul>
</li>
<li><strong>Manufacturing Tolerance and Part Finish</strong>
<ul>
<li><label>
  
  <a href="#rule-R2.1"><strong>R2.1</strong></a> 
  —
  Use chamfers on edges parallel to the print surface.  Use fillets on edges
vertical to the print surface.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.2"><strong>R2.2</strong></a> 
  —
  Improve horizontal holes by using a teardrop shape or giving the hole a flat roof.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.3"><strong>R2.3</strong></a> 
  —
  Use a teardrop shape for vertical holes to avoid inaccuracy due to perimeter
seams.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.4"><strong>R2.4</strong></a> 
  —
  Consider where the seam will be placed.  If tolerances are tight, provide a
sharp concave corner for the seam the hide in.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.5"><strong>R2.5</strong></a> 
  —
  Design part geometry for easy motion paths while printing, to improve dimensional accuracy.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.6"><strong>R2.6</strong></a> 
  —
  Prevent warping by making parts voluminous and their surfaces smooth and rounded.  The ideal shape is a sphere.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.7"><strong>R2.7</strong></a> 
  —
  If you can't make it precise, make it adjustable.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.8"><strong>R2.8</strong></a> 
  —
  Do not use circular holes for interference fits.  Use hexagon or square holes instead.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.9"><strong>R2.9</strong></a> 
  —
  Use crush ribs for press fits that are only assembled once.
</label>
</li>
<li><label>
  
  <a href="#rule-R2.10"><strong>R2.10</strong></a> 
  —
  Use grip fins for press fits that need to be reassembled more than once.
</label>
</li>
</ul>
</li>
<li><strong>Process Optimization</strong>
<ul>
<li><label>
  
  <a href="#rule-R3.1"><strong>R3.1</strong></a> 
  —
  Avoid the necessity of support material.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.2"><strong>R3.2</strong></a> 
  —
  Clever part orientation on the print surface can eliminate the need for
supports.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.3"><strong>R3.3</strong></a> 
  —
  Split a part into multiple pieces when no orientation can avoid supports.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.4"><strong>R3.4</strong></a> 
  —
  Use sacrificial layers to avoid internal overhangs that would otherwise require supports.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.5"><strong>R3.5</strong></a> 
  —
  Use the overhanging counterbore trick.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.6"><strong>R3.6</strong></a> 
  —
  Bridges on top of other bridges allow for advanced geometry, without
requiring additional support structure.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.7"><strong>R3.7</strong></a> 
  —
  Keep surface area minimal.  Design voluminous.  Do not make cutouts in an attempt to save material.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.8"><strong>R3.8</strong></a> 
  —
  Reduce the surface area that is touching the print-bed when aiming for mass production.
</label>
</li>
<li><label>
  
  <a href="#rule-R3.9"><strong>R3.9</strong></a> 
  —
  Add mouse ears to parts that have problems with bed adhesion.
</label>
</li>
</ul>
</li>
<li><strong>Functional Integration</strong>
<ul>
<li><label>
  
  <a href="#rule-R4.1"><strong>R4.1</strong></a> 
  —
  Use zip tie channels to fasten cables to a part.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.2"><strong>R4.2</strong></a> 
  —
  Use flexures to integrate moving features into a part.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.3"><strong>R4.3</strong></a> 
  —
  Design flexures such that they only deform elastically when used.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.4"><strong>R4.4</strong></a> 
  —
  Ensure that flexures have hard limits that prevent breaking them.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.5"><strong>R4.5</strong></a> 
  —
  Ensure clips won't break from use.  Optimize designs for minimal clip movement.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.6"><strong>R4.6</strong></a> 
  —
  Provide a way to undo form-locking clips.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.7"><strong>R4.7</strong></a> 
  —
  Use break-away surfaces to support floating geometry in print-in-place designs.
</label>
</li>
<li><label>
  
  <a href="#rule-R4.8"><strong>R4.8</strong></a> 
  —
  Ensure sufficient clearance between features in print-in-place designs.
</label>
</li>
</ul>
</li>
<li><strong>Beyond plastic - Machine Elements</strong>
<ul>
<li><label>
  
  <a href="#rule-R5.1"><strong>R5.1</strong></a> 
  —
  Protect dynamically loaded screws with additional locking measures like threadlocking adhesive.
</label>
</li>
<li><label>
  
  <a href="#rule-R5.2"><strong>R5.2</strong></a> 
  —
  Design screwed connections for maximum screw length.
</label>
</li>
<li><label>
  
  <a href="#rule-R5.3"><strong>R5.3</strong></a> 
  —
  Cut threads into printed parts with a thread tap for quick design of low-reuse joints.
</label>
</li>
<li><label>
  
  <a href="#rule-R5.4"><strong>R5.4</strong></a> 
  —
  Use rib thread forming for no-postprocessing low-reuse threads in printed parts.
</label>
</li>
<li><label>
  
  <a href="#rule-R5.5"><strong>R5.5</strong></a> 
  —
  Use heat-set threaded inserts to add highly reusable and robust threads to a part.
</label>
</li>
<li><label>
  
  <a href="#rule-R5.6"><strong>R5.6</strong></a> 
  —
  Make cutouts to embed standard nuts into a part.
</label>
</li>
<li><label>
  
  <a href="#rule-R5.7"><strong>R5.7</strong></a> 
  —
  Embed hardware into 3d-printed parts to avoid more complex fastening or joining methods.
</label>
</li>
</ul>
</li>
<li><strong>Appearance</strong>
<ul>
<li><label>
  
  <a href="#rule-R6.1"><strong>R6.1</strong></a> 
  —
  Complex shapes are often "for free" in 3d-printing.  Use them to improve
appearance or ergonomics.
</label>
</li>
<li><label>
  
  <a href="#rule-R6.2"><strong>R6.2</strong></a> 
  —
  Create shadow lines along the joining edge between two parts.
</label>
</li>
<li><label>
  
  <a href="#rule-R6.3"><strong>R6.3</strong></a> 
  —
  Use surface texture to make parts appear less 3d-printed.
</label>
</li>
<li><label>
  
  <a href="#rule-R6.4"><strong>R6.4</strong></a> 
  —
  Prefer engraving text over embossing.
</label>
</li>
<li><label>
  
  <a href="#rule-R6.5"><strong>R6.5</strong></a> 
  —
  Place engraved/embossed text vertical to the print surface.
</label>
</li>
</ul>
</li>
<li><strong>Extra: Vase Mode Design</strong>
<ul>
<li><label>
  
  <a href="#rule-R7.1"><strong>R7.1</strong></a> 
  —
  Use beading patterns to make vase mode parts more stiff.
</label>
</li>
</ul>
</li>
</ol>

</div></div>]]></description>
        </item>
    </channel>
</rss>