<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 19 Mar 2024 21:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What does Alan Kay think about LLMs? (120 pts)]]></title>
            <link>https://www.quora.com/What-does-Alan-Kay-think-about-programming-and-teaching-programming-with-copilots-and-LLMs-of-today</link>
            <guid>39758391</guid>
            <pubDate>Tue, 19 Mar 2024 17:48:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quora.com/What-does-Alan-Kay-think-about-programming-and-teaching-programming-with-copilots-and-LLMs-of-today">https://www.quora.com/What-does-Alan-Kay-think-about-programming-and-teaching-programming-with-copilots-and-LLMs-of-today</a>, See on <a href="https://news.ycombinator.com/item?id=39758391">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The New Inflection (145 pts)]]></title>
            <link>https://inflection.ai/the-new-inflection</link>
            <guid>39757368</guid>
            <pubDate>Tue, 19 Mar 2024 16:23:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://inflection.ai/the-new-inflection">https://inflection.ai/the-new-inflection</a>, See on <a href="https://news.ycombinator.com/item?id=39757368">Hacker News</a></p>
<div id="readability-page-1" class="page"><div justify="center" id=""><p>From day one at Inflection, we’ve been driven by a simple mission: to create a personal intelligence for everyone. To do this, we trained one of the <a href="https://inflection.ai/inflection-2-5" target="_blank" rel="noopener noreferrer">best LLMs in the world</a>, and created our first personal AI, Pi, which couples extraordinary EQ with industry leading IQ, and is now used by millions of people a week.</p>
<p>As an AI studio we have <a href="https://inflection.ai/company" target="_blank" rel="noopener noreferrer">long planned</a> to make our technology available to developers and enterprises. And over the last year, we’ve heard countless times that people haven’t been able to replicate the unique conversational style of Pi with publicly available models, and would love to get access to our model and fine tuning infrastructure. There is a huge opportunity for Inflection here.</p>
<p>Our plan going forward is to lean into our AI studio business, where custom generative AI models are crafted, tested and fine tuned for commercial customers. Our success at training, tailoring and improving the performance of large AI models makes us uniquely well placed to be the AI platform for businesses around the world.</p>
<p>As part of this, we’re thrilled to announce that we will now host Inflection-2.5 on Microsoft Azure helping us get it into the hands of creators everywhere. We’ll also be ensuring it comes to other cloud hosting platforms in the near future. The API itself isn’t available today, but will be up and running very soon. To sign up for early access and help us test it, please register your interest <a href="https://docs.google.com/forms/d/e/1FAIpQLScM9Iz1KzaRlfgDrYrldoPDnXbhO5LW3-hqmQCd56YpheEN7g/viewform" target="_blank" rel="noopener noreferrer">here</a>. Between API access and select high-level partnerships with great customers, our AIs can now spread to even larger new user bases while helping put cutting-edge AI capabilities in the hands of thousands of developers.</p>
<p>This renewed emphasis on our API also comes with some important changes in the company. Today we are also announcing that two of our three co-founders, Mustafa and Karén, will be leaving Inflection to start Microsoft AI, a new division at Microsoft that will bring together their consumer AI efforts, as well as Copilot, Bing and Edge. We’re grateful for all their amazing work in getting Inflection to this stage, and wish them luck for this new chapter.</p>
<p>We are delighted to welcome a new CEO, <a href="https://www.linkedin.com/in/seanwhite/" target="_blank" rel="noopener noreferrer">Sean White</a>, who has decades of experience working at the cutting edge of technology, research and business. He is a visionary leader poised to take Inflection into this new era. Our third co-founder, Reid Hoffman will continue on our board and remains excited to take these next steps in building personal intelligence for everyone.</p>
<p>We are hugely proud of what we’ve achieved with Pi. There will be no immediate changes to the service and we’re committed to ensuring that users get ongoing access to great AI experiences in the future. Our privacy and data policies to ensure users are protected remain in place and unchanged. As ever, no data will be shared with any third parties without users' explicit consent.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Start Google (277 pts)]]></title>
            <link>https://paulgraham.com/google.html</link>
            <guid>39756865</guid>
            <pubDate>Tue, 19 Mar 2024 15:36:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/google.html">https://paulgraham.com/google.html</a>, See on <a href="https://news.ycombinator.com/item?id=39756865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/how-to-start-google-1.gif" width="171" height="18" alt="How to Start Google"><span size="2" face="verdana">March 2024<p><i>(This is a talk I gave to 14 and 15 year olds about what to do now
if they might want to start a startup later. Lots of schools think
they should tell students something about startups. This is what I
think they should tell them.)</i></p><p>Most of you probably think that when you're released into the
so-called real world you'll eventually have to get some kind of
job. That's not true, and today I'm going to talk about a trick you
can use to avoid ever having to get a job.</p><p>The trick is to start your own company. So it's not a trick for
avoiding <i>work</i>, because if you start your own company you'll
work harder than you would if you had an ordinary job. But you will
avoid many of the annoying things that come with a job, including
a boss telling you what to do.</p><p>It's more exciting to work on your own project than someone else's.
And you can also get a lot richer. In fact, this is the standard
way to get 
</p><a href="https://paulgraham.com/richnow.html"><u>really rich</u></a>. If you look at the lists of the richest
people that occasionally get published in the press, nearly all of
them did it by starting their own companies.<p>Starting your own company can mean anything from starting a barber
shop to starting Google. I'm here to talk about one extreme end of
that continuum. I'm going to tell you how to start Google.</p><p>The companies at the Google end of the continuum are called startups
when they're young. The reason I know about them is that my wife
Jessica and I started something called Y Combinator that is basically
a startup factory. Since 2005, Y Combinator has funded over 4000
startups. So we know exactly what you need to start a startup,
because we've helped people do it for the last 19 years.</p><p>You might have thought I was joking when I said I was going to tell
you how to start Google. You might be thinking "How could <i>we</i>
start Google?" But that's effectively what the people who did start
Google were thinking before they started it. If you'd told Larry
Page and Sergey Brin, the founders of Google, that the company they
were about to start would one day be worth over a trillion dollars,
their heads would have exploded.</p><p>All you can know when you start working on a startup is that it
seems worth pursuing. You can't know whether it will turn into
a company worth billions or one that goes out of business. So when I
say I'm going to tell you how to start Google, I mean I'm going to
tell you how to get to the point where you can start a company that
has as much chance of being Google as Google had of being Google.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span><p>How do you get from where you are now to the point where you can
start a successful startup? You need three things. You need to be
good at some kind of technology, you need an idea for what you're
going to build, and you need cofounders to start the company with.</p><p>How do you get good at technology? And how do you choose which
technology to get good at? Both of those questions turn out to have
the same answer: work on your own projects. Don't try to guess
whether gene editing or LLMs or rockets will turn out to be the
most valuable technology to know about. No one can predict that.
Just work on whatever interests you the most. You'll work much
harder on something you're interested in than something you're doing
because you think you're supposed to.</p><p>If you're not sure what technology to get good at, get good at
programming. That has been the source of the median startup for the
last 30 years, and this is probably not going to change in the next
10.</p><p>Those of you who are taking computer science classes in school may
at this point be thinking, ok, we've got this sorted. We're already
being taught all about programming. But sorry, this is not enough.
You have to be working on your own projects, not just learning stuff
in classes. You can do well in computer science classes without
ever really learning to program. In fact you can graduate with a
degree in computer science from a top university and still not be
any good at programming. That's why tech companies all make you
take a coding test before they'll hire you, regardless of where you
went to university or how well you did there. They know grades and
exam results prove nothing.</p><p>If you really want to learn to program, you have to work on your
own projects. You learn so much faster that way. Imagine you're
writing a game and there's something you want to do in it, and you
don't know how. You're going to figure out how a lot faster than
you'd learn anything in a class.</p><p>You don't have to learn programming, though. If you're wondering
what counts as technology, it includes practically everything you
could describe using the words "make" or "build." So welding would
count, or making clothes, or making videos. Whatever you're most
interested in. The critical distinction is whether you're producing
or just consuming. Are you writing computer games, or just playing
them? That's the cutoff.</p><p>Steve Jobs, the founder of Apple, spent time when he was a teenager
studying calligraphy — the sort of beautiful writing that
you see in medieval manuscripts. No one, including him, thought
that this would help him in his career. He was just doing it because
he was interested in it. But it turned out to help him a lot. The
computer that made Apple really big, the Macintosh, came out at
just the moment when computers got powerful enough to make letters
like the ones in printed books instead of the computery-looking
letters you see in 8 bit games. Apple destroyed everyone else at
this, and one reason was that Steve was one of the few people in
the computer business who really got graphic design.</p><p>Don't feel like your projects have to be <i>serious</i>. They can
be as frivolous as you like, so long as you're building things
you're excited about. Probably 90% of programmers start out building
games. They and their friends like to play games. So they build
the kind of things they and their friends want. And that's exactly
what you should be doing at 15 if you want to start a startup one
day.</p><p>You don't have to do just one project. In fact it's good to learn
about multiple things. Steve Jobs didn't just learn calligraphy.
He also learned about electronics, which was even more valuable.
Whatever you're interested in. (Do you notice a theme here?)</p><p>So that's the first of the three things you need, to get good at
some kind or kinds of technology. You do it the same way you get
good at the violin or football: practice. If you start a startup
at 22, and you start writing your own programs now, then by the
time you start the company you'll have spent at least 7 years
practicing writing code, and you can get pretty good at anything
after practicing it for 7 years.</p><p>Let's suppose you're 22 and you've succeeded: You're now really
good at some technology. How do you get 
</p><a href="https://paulgraham.com/startupideas.html"><u>startup ideas</u></a>? It might
seem like that's the hard part. Even if you are a good programmer,
how do you get the idea to start Google?<p>Actually it's easy to get startup ideas once you're good at technology.
Once you're good at some technology, when you look at the world you
see dotted outlines around the things that are missing. You start
to be able to see both the things that are missing from the technology
itself, and all the broken things that could be fixed using it, and
each one of these is a potential startup.</p><p>In the town near our house there's a shop with a sign warning that
the door is hard to close. The sign has been there for several
years. To the people in the shop it must seem like this mysterious
natural phenomenon that the door sticks, and all they can do is put
up a sign warning customers about it. But any carpenter looking at
this situation would think "why don't you just plane off the part
that sticks?"</p><p>Once you're good at programming, all the missing software in the
world starts to become as obvious as a sticking door to a carpenter.
I'll give you a real world example. Back in the 20th century,
American universities used to publish printed directories with all
the students' names and contact info. When I tell you what these
directories were called, you'll know which startup I'm talking
about. They were called facebooks, because they usually had a picture
of each student next to their name.</p><p>So Mark Zuckerberg shows up at Harvard in 2003, and the university
still hasn't gotten the facebook online. Each individual house has
an online facebook, but there isn't one for the whole university.
The university administration has been diligently having meetings
about this, and will probably have solved the problem in another
decade or so. Most of the students don't consciously notice that
anything is wrong. But Mark is a programmer. He looks at this
situation and thinks "Well, this is stupid. I could write a program
to fix this in one night. Just let people upload their own photos
and then combine the data into a new site for the whole university."
So he does. And almost literally overnight he has thousands of
users.</p><p>Of course Facebook was not a startup yet. It was just a... project.
There's that word again. Projects aren't just the best way to learn
about technology. They're also the best source of startup ideas.</p><p>Facebook was not unusual in this respect. Apple and Google also
began as projects. Apple wasn't meant to be a company. Steve Wozniak
just wanted to build his own computer. It only turned into a company
when Steve Jobs said "Hey, I wonder if we could sell plans for this
computer to other people." That's how Apple started. They weren't
even selling computers, just plans for computers. Can you imagine
how lame this company seemed?</p><p>Ditto for Google. Larry and Sergey weren't trying to start a company
at first. They were just trying to make search better. Before Google,
most search engines didn't try to sort the results they gave you
in order of importance. If you searched for "rugby" they just gave
you every web page that contained the word "rugby." And the web was
so small in 1997 that this actually worked! Kind of. There might
only be 20 or 30 pages with the word "rugby," but the web was growing
exponentially, which meant this way of doing search was becoming
exponentially more broken. Most users just thought, "Wow, I sure
have to look through a lot of search results to find what I want."
Door sticks. But like Mark, Larry and Sergey were programmers. Like
Mark, they looked at this situation and thought "Well, this is
stupid. Some pages about rugby matter more than others. Let's figure
out which those are and show them first."</p><p>It's obvious in retrospect that this was a great idea for a startup.
It wasn't obvious at the time. It's never obvious. If it was obviously
a good idea to start Apple or Google or Facebook, someone else would
have already done it. That's why the best startups grow out of
projects that aren't meant to be startups. You're not trying to
start a company. You're just following your instincts about what's
interesting. And if you're young and good at technology, then your
unconscious instincts about what's interesting are better than your
conscious ideas about what would be a good company.</p><p>So it's critical, if you're a young founder, to build things for
yourself and your friends to use. The biggest mistake young founders
make is to build something for some mysterious group of other people.
But if you can make something that you and your friends truly want
to use — something your friends aren't just using out of
loyalty to you, but would be really sad to lose if you shut it down
— then you almost certainly have the germ of a good startup
idea. It may not seem like a startup to you. It may not be obvious
how to make money from it. But trust me, there's a way.</p><p>What you need in a startup idea, and all you need, is something
your friends actually want. And those ideas aren't hard to see once
you're good at technology. There are sticking doors everywhere.
</p><span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>Now for the third and final thing you need: a cofounder, or cofounders.
The optimal startup has two or three founders, so you need one or
two cofounders. How do you find them? Can you predict what I'm going
to say next? It's the same thing: projects. You find cofounders by
working on projects with them. What you need in a cofounder is
someone who's good at what they do and that you work well with, and
the only way to judge this is to work with them on things.</p><p>At this point I'm going to tell you something you might not want
to hear. It really matters to do well in your classes, even the
ones that are just memorization or blathering about literature,
because you need to do well in your classes to get into a good
university. And if you want to start a startup you should try to
get into the best university you can, because that's where the best
cofounders are. It's also where the best employees are. When Larry
and Sergey started Google, they began by just hiring all the smartest
people they knew out of Stanford, and this was a real advantage for
them.</p><p>The empirical evidence is clear on this. If you look at where the
largest numbers of successful startups come from, it's pretty much
the same as the list of the most selective universities.</p><p>I don't think it's the prestigious names of these universities that
cause more good startups to come out of them. Nor do I think it's
because the quality of the teaching is better. What's driving this
is simply the difficulty of getting in. You have to be pretty smart
and determined to get into MIT or Cambridge, so if you do manage
to get in, you'll find the other students include a lot of smart
and determined people.
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>You don't have to start a startup with someone you meet at university.
The founders of Twitch met when they were seven. The founders of
Stripe, Patrick and John Collison, met when John was born. But
universities are the main source of cofounders. And because they're
where the cofounders are, they're also where the ideas are, because
the best ideas grow out of projects you do with the people who
become your cofounders.</p><p>So the list of what you need to do to get from here to starting a
startup is quite short. You need to get good at technology, and the
way to do that is to work on your own projects. And you need to do
as well in school as you can, so you can get into a good university,
because that's where the cofounders and the ideas are.</p><p>That's it, just two things, build stuff and do well in school.</p><p><b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
The rhetorical trick in this sentence is that the "Google"s
refer to different things. What I mean is: a company that has as
much chance of growing as big as Google ultimately did as Larry and
Sergey could have reasonably expected Google itself would at the
time they started it. But I think the original version is zippier.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
Making something for your friends isn't the only source of
startup ideas. It's just the best source for young founders, who
have the least knowledge of what other people want, and whose own
wants are most predictive of future demand anyway.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
Strangely enough this is particularly true in countries like
the US where undergraduate admissions are done badly. US admissions
departments make applicants jump through a lot of arbitrary hoops
that have little to do with their intellectual ability. But the
more arbitrary a test, the more it becomes a test of mere determination
and resourcefulness. And those are the two most important qualities
in startup founders. So US admissions departments are better at
selecting founders than they would be if they were better at selecting
students.<span color="888888"><b>Thanks</b> to Carolynn Levy, Jessica Livingston and Harj 
Taggar for reading drafts of this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Intermediate Certificates (123 pts)]]></title>
            <link>https://letsencrypt.org/2024/03/19/new-intermediate-certificates.html</link>
            <guid>39756434</guid>
            <pubDate>Tue, 19 Mar 2024 15:02:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2024/03/19/new-intermediate-certificates.html">https://letsencrypt.org/2024/03/19/new-intermediate-certificates.html</a>, See on <a href="https://news.ycombinator.com/item?id=39756434">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<article>
		<p>On Wednesday, March 13, 2024, Let’s Encrypt generated 10 new Intermediate CA Key Pairs, and issued 15 new Intermediate CA Certificates containing the new public keys. These new intermediate certificates provide smaller and more efficient certificate chains to Let’s Encrypt Subscribers, enhancing the overall online experience in terms of speed, security, and accessibility.</p>
<p>First, a bit of history. In September, 2020, Let’s Encrypt issued a <a href="https://letsencrypt.org/2020/09/17/new-root-and-intermediates">new root and collection of intermediate certificates</a>. Those certificates helped us improve the privacy and efficiency of Web security by making ECDSA end-entity certificates widely available. However, those intermediates are approaching their expiration dates, so it is time to replace them.</p>
<p>Our new batch of intermediates are very similar to the ones we issued in 2020, with a few small changes. We’re going to go over what those changes are and why we made them.</p>

<p>We created 5 new 2048-bit RSA intermediate certificates named in sequence from R10 through R14. These are issued by ISRG Root X1. You can think of them as direct replacements for our existing R3 and R4 intermediates.</p>
<p>We also created 5 new P-384 ECDSA intermediate certificates named in sequence from E5 through E9. Each of these is represented by two certificates: one issued by ISRG Root X2 (exactly like our existing E1 and E2), and one issued (or cross-signed) by ISRG Root X1.</p>
<p>You can see details of all of the certificates on our <a href="https://letsencrypt.org/certificates/">updated hierarchy page</a>.</p>
<p><img src="https://letsencrypt.org/images/blog/ChainofTrust2024CeremonyBlogPost.png" alt=""></p>
<h2 id="rotating-issuance">Rotating Issuance</h2>
<p>Rotating the set of intermediates we issue from helps keep the Internet agile and more secure. It encourages automation and efficiency, and discourages outdated practices like key pinning. “Key Pinning” is a practice in which clients — either ACME clients getting certificates for their site, or apps connecting to their own backend servers — decide to trust only a single issuing intermediate certificate rather than delegating trust to the system trust store. Updating pinned keys is a manual process, which leads to an increased risk of errors and potential business continuity failures.</p>
<p>Intermediates usually change only every five years, so this joint is exercised infrequently and client software keeps making the same mistakes. Shortening the lifetime from five years to three years means we will be conducting another ceremony in just two years, ahead of the expiration date on these recently created certificates. This ensures we exercise the joint more frequently than in the past.</p>
<p>We also issued <em>more</em> intermediates this time around. Historically, we’ve had two of each key type (RSA and ECDSA): one for active issuance, and one held as a backup for emergencies. Moving forward we will have five: two conducting active issuance, two waiting in the wings to be introduced in about one year, and one for emergency backup. Randomizing the selected issuer for a given key type means it will be impossible to predict which intermediate a certificate will be issued from. We are very hopeful that these steps will prevent intermediate key pinning altogether, and help the WebPKI remain agile moving forward.</p>
<p>These shorter intermediate lifetimes and randomized intermediate issuance shouldn’t impact the online experience of the general Internet user. Subscribers may be impacted if they are pinning one of our intermediates, though this should be incredibly rare.</p>
<h2 id="providing-smaller-chains">Providing Smaller Chains</h2>
<p>When we issued ISRG Root X2 in 2020, we decided to cross-sign it from ISRG Root X1 so that it would be trusted even by systems that didn’t yet have ISRG Root X2 in their trust store. This meant that Subscribers who wanted issuance from our ECDSA intermediates would have a choice: they could either have a very short, ECDSA-only, but low-compatibility chain terminating at ISRG Root X2, or they could have a longer, high-compatibility chain terminating at ISRG Root X1. At the time, this tradeoff (TLS handshake size vs compatibility) seemed like a reasonable choice to provide, and we provided the high-compatibility chain by default to support the largest number of configurations.</p>
<p>ISRG Root X2 is now trusted by most platforms, and we can now offer an improved version of the same choice. The same very short, ECDSA-only chain will still be available for Subscribers who want to optimize their TLS handshakes at the cost of some compatibility. But the high-compatibility chain will be drastically improving: instead of containing two intermediates (both E1 and the cross-signed ISRG Root X2), it will now contain only a single intermediate: the version of one of our new ECDSA intermediates cross-signed by ISRG Root X1.</p>
<p>This reduces the size of our default ECDSA chain by about a third, and is an important step towards removing our <a href="https://docs.google.com/forms/d/e/1FAIpQLScCWnApP2eUk4cA6y5cFOENlm5S2StVedrqYNzeNdTPoArzwA/viewform">ECDSA allow-list</a>.</p>
<h2 id="other-minor-changes">Other Minor Changes</h2>
<p>We’ve made two other tiny changes that are worth mentioning, but will have no impact on how Subscribers and clients use our certificates:</p>
<ul>
<li>
<p>We’ve changed how the Subject Key ID field is calculated, from a SHA-1 hash of the public key, to a <a href="https://datatracker.ietf.org/doc/html/rfc7093#section-2">truncated SHA-256 hash</a> of the same data. Although this use of SHA-1 was not cryptographically relevant, it is still nice to remove one more usage of that <a href="https://shattered.io/">broken algorithm</a>, helping move towards a world where cryptography libraries don’t need to include SHA-1 support at all.</p>
</li>
<li>
<p>We have removed our CPS OID from the Certificate Policies extension. This saves a few bytes in the certificate, which can add up to a lot of bandwidth saved over the course of billions of TLS handshakes.</p>
</li>
</ul>
<p>Both of these mirror two <a href="https://community.letsencrypt.org/t/enabling-sha256-subject-key-identifiers-for-end-entity-certificates/211453/4">identical</a> <a href="https://community.letsencrypt.org/t/small-change-to-end-entity-certificates-cps-url-and-oid-will-not-be-included-from-june-15/198206/5">changes</a> that we made for our Subscriber Certificates in the past year.</p>
<h2 id="deployment">Deployment</h2>
<p>We intend to put two of each of the new RSA and ECDSA keys into rotation in the next few months. Two of each will be ready to swap in at a future date, and one of each will be held in reserve in case of an emergency. Read more about the strategy in our December 2023 post on the <a href="https://community.letsencrypt.org/t/lets-encrypt-new-intermediate-certificates/209498">Community Forum</a>.</p>
<p>Not familiar with the forum? It’s where Let’s Encrypt publishes updates on our <a href="https://community.letsencrypt.org/c/issuance-tech-questions/12">Issuance Tech</a> and <a href="https://community.letsencrypt.org/c/api-announcements/18">APIs</a>. It’s also where you can go for troubleshooting help from community experts and Let’s Encrypt staff. <a href="https://community.letsencrypt.org/">Check it out</a> and subscribe to alerts for technical updates.</p>
<p>We hope that this has been an interesting and informative tour around our new intermediates, and we look forward to continuing to improve the Internet, one certificate at a time.</p>
<p>We depend on contributions from our community of users and supporters in order to provide our services. If your company or organization would like to <a href="https://www.abetterinternet.org/sponsor/">sponsor</a> Let’s Encrypt please email us at <a href="mailto:sponsor@letsencrypt.org">sponsor@letsencrypt.org</a>. We ask that you make an <a href="https://letsencrypt.org/donate/">individual contribution</a> if it is within your means.</p>

	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Godspeed is a fast, 100% keyboard oriented todo app for Mac (160 pts)]]></title>
            <link>https://godspeedapp.com/</link>
            <guid>39756325</guid>
            <pubDate>Tue, 19 Mar 2024 14:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://godspeedapp.com/">https://godspeedapp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39756325">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Causal 2.0 – Modern Financial Planning for Startups (167 pts)]]></title>
            <link>https://causal.app</link>
            <guid>39755858</guid>
            <pubDate>Tue, 19 Mar 2024 14:06:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://causal.app">https://causal.app</a>, See on <a href="https://news.ycombinator.com/item?id=39755858">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><h2>Modern financial planning</h2></p><div><h4>Know your runway, plan your growth, and get back to building your business.</h4></div><div id="w-node-_91886231-9d7f-5602-643a-69f0db31642b-7aaf274e"><a href="#"><img src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/646df0ef933b939f7e8e497e_Homepage%20Hero%20Screenshot.png" loading="lazy" sizes="(max-width: 479px) 87vw, (max-width: 767px) 92vw, 94vw" width="1049" alt="" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/646df0ef933b939f7e8e497e_Homepage%20Hero%20Screenshot-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/646df0ef933b939f7e8e497e_Homepage%20Hero%20Screenshot-p-800.png 800w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/646df0ef933b939f7e8e497e_Homepage%20Hero%20Screenshot-p-1080.png 1080w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/646df0ef933b939f7e8e497e_Homepage%20Hero%20Screenshot.png 2472w"><div><p><img src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65c27274ca6082d2d7b15fcf_Triangle.svg" loading="lazy" alt=""></p></div></a></div></div><div><p><h2>Spend less time in spreadsheets, and more time on your business</h2></p><div><div><p><img src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7ad524f9e4d4bd2c45d_Feature%3DFormulas.png" loading="lazy" sizes="(max-width: 479px) 89vw, (max-width: 767px) 86vw, 28vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7ad524f9e4d4bd2c45d_Feature%3DFormulas-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7ad524f9e4d4bd2c45d_Feature%3DFormulas.png 728w" alt=""></p><h4>Formulas made for humans</h4><p>Model anything with human-readable formulas — no #REFs or VLOOKUPs.</p></div><div><p><img src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166447926f5f42e3af_Feature%3DIntegrations.png" loading="lazy" sizes="(max-width: 479px) 89vw, (max-width: 767px) 86vw, 28vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166447926f5f42e3af_Feature%3DIntegrations-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166447926f5f42e3af_Feature%3DIntegrations-p-800.png 800w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166447926f5f42e3af_Feature%3DIntegrations-p-1080.png 1080w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166447926f5f42e3af_Feature%3DIntegrations.png 1456w" alt=""></p><h4>Connected to your stack</h4><p>Pull live data from your accounting system, HRIS, CRM, data warehouse, and more.</p></div><div><p><img src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166f2c57641a7dc5ff_Feature%3DScenarios.png" loading="lazy" sizes="(max-width: 479px) 89vw, (max-width: 767px) 86vw, 28vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166f2c57641a7dc5ff_Feature%3DScenarios-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166f2c57641a7dc5ff_Feature%3DScenarios-p-800.png 800w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166f2c57641a7dc5ff_Feature%3DScenarios-p-1080.png 1080w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb166f2c57641a7dc5ff_Feature%3DScenarios.png 1456w" alt=""></p><h4>Plan for every scenario</h4><p>Spin up new scenarios in 1 click and compare them side-by-side.</p></div></div></div><div><div data-current="Reporting" data-easing="ease" data-duration-in="300" data-duration-out="100"><div data-w-tab="Reporting"><div><h2>"How did we spend so much on contractors last quarter?"</h2><p>1/5</p></div><div><div><p>Pull your historicals directly from QuickBooks/Xero, and drill down into the transactions behind each number without having to jump between browser tabs or chase your accountant.<br></p></div><p><img sizes="(max-width: 479px) 92vw, (max-width: 767px) 91vw, 30vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb161d9b9fcc1c71ba4e_Feature%3DDrilldown-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb161d9b9fcc1c71ba4e_Feature%3DDrilldown-p-800.png 800w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb161d9b9fcc1c71ba4e_Feature%3DDrilldown-p-1080.png 1080w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb161d9b9fcc1c71ba4e_Feature%3DDrilldown.png 1456w" alt="" src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adcb161d9b9fcc1c71ba4e_Feature%3DDrilldown.png" loading="lazy"></p></div></div><div data-w-tab="Forecasting"><div><h2>“How can we <em>actually</em> 3x revenue next year?”</h2><p>2/5</p></div><div><div><p>It’s well and good setting an ambitious top-down target, but you also need a credible bottom-up plan to get there. Get started with one of our templates and forecast your business in as much detail as you need.<br></p></div><p><img sizes="(max-width: 479px) 92vw, (max-width: 767px) 91vw, 30vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7ad524f9e4d4bd2c45d_Feature%3DFormulas-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7ad524f9e4d4bd2c45d_Feature%3DFormulas.png 728w" alt="" src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7ad524f9e4d4bd2c45d_Feature%3DFormulas.png" loading="lazy"></p></div></div><div data-w-tab="Hiring plans"><div><h2>“What’s our runway if we hire 3 more engineers?”</h2><p>3/5</p></div><div><div><p>Headcount is your biggest expense, so you should know how your current team and planned hires are affecting your bottom line. Start with one of our templates and customise it with your own hiring scenarios.<br></p></div><p><img sizes="(max-width: 479px) 92vw, (max-width: 767px) 91vw, 30vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7b67aa1e2b14f46ce8c_Feature%3DScenarios-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7b67aa1e2b14f46ce8c_Feature%3DScenarios.png 728w" alt="" src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65abc7b67aa1e2b14f46ce8c_Feature%3DScenarios.png" loading="lazy"></p></div></div><div data-w-tab="Budgeting"><div><h2>“How are we tracking against our plan for the year?”</h2><p>4/5</p></div><div><div><p>Save versions of your model and compare them side-by-side against the actuals to understand variances. Causal puts this whole process on autopilot —&nbsp;no more manual work in rolling your model forward each month.<br></p></div><p><img sizes="(max-width: 479px) 92vw, (max-width: 767px) 91vw, 30vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65ca1bb521453d03f9316559_BvA-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65ca1bb521453d03f9316559_BvA-p-800.png 800w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65ca1bb521453d03f9316559_BvA-p-1080.png 1080w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65ca1bb521453d03f9316559_BvA.png 1456w" alt="" src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65ca1bb521453d03f9316559_BvA.png" loading="lazy"></p></div></div><div data-w-tab="Consolidation"><div><h2>“How is the business performing across all entities?”</h2><p>5/5</p></div><div><div><p>Connect to all of your QuickBooks/Xero entities and Causal will do the currency conversion and consolidation work for you, letting you get a complete picture of your business without any manual work.</p></div><p><img sizes="(max-width: 479px) 92vw, (max-width: 767px) 91vw, 30vw" srcset="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adca6a398892a4a89c6fad_Feature%3DCurrency-p-500.png 500w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adca6a398892a4a89c6fad_Feature%3DCurrency-p-800.png 800w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adca6a398892a4a89c6fad_Feature%3DCurrency-p-1080.png 1080w, https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adca6a398892a4a89c6fad_Feature%3DCurrency.png 1456w" alt="" src="https://assets-global.website-files.com/61e8494b1e8e024a7113bd50/65adca6a398892a4a89c6fad_Feature%3DCurrency.png" loading="lazy"></p></div></div></div><p>→</p></div><div><h2>Connect to your QuickBooks/Xero,<br>and let our AI do the work</h2><p><a href="https://my.causal.app/register" target="_blank">Get started for free →</a></p><div><div><p>01</p><h4>Connect your data</h4><p>Authenticate with QuickBooks/Xero to pull your P&amp;L&nbsp;and Balance Sheet into Causal.</p><p>2 minutes</p></div><div><p>02</p><h4>Run the&nbsp;wizard</h4><p>Our AI&nbsp;wizard will analyse your chart of accounts and generate a financial model for you.</p><p>1 minute</p></div><div><p>03</p><h4>Customise your model</h4><p>Adjust assumptions and formulas, and spin up different scenarios.</p><p>3 minutes</p></div><div><p>04</p><h4>Share with your team</h4><p>Share beautiful dashboards with  your team, with live editing and commenting.</p><p>2 minutes</p></div></div></div><div><p><h2>Bring your business data, wherever it lives.</h2></p></div><div><h2>Put finance on autopilot today</h2><p><a href="https://my.causal.app/register">Get started free →</a></p><div><div><h4><span>1</span>00x</h4><p>fewer formulas vs the same model in Excel/Sheets</p></div><div><h4>20hrs</h4><p>saved per month eliminating manual processes</p></div><div><h4>$50k+</h4><p>saved of unproductive  time per year</p></div></div></div><div><div><p><h2>Don’t just take our word for it</h2></p></div><div><h3>What people are saying</h3><div role="list"><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Mike Overell" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/63fd4204cf1aa8839e9869c7_0i9NYWKh_400x400.jpg"></p><div><p>The rate of product improvements from <a href="https://twitter.com/CausalHQ">@CausalHQ</a> is incredible.</p><p>Classdojo runs all forecasts, scenarios, and financial planning in it, without a single FTE in the function 🤯</p></div></div><nav><div><p><img loading="lazy" alt="Mike Overell" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/63fd4204cf1aa8839e9869c7_0i9NYWKh_400x400.jpg"></p></div><div><p>The rate of product improvements from <a href="https://twitter.com/CausalHQ">@CausalHQ</a> is incredible.</p><p>Classdojo runs all forecasts, scenarios, and financial planning in it, without a single FTE in the function 🤯</p></div></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Jeremy Higgs" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5b500d68fc2832b5e519_4ViSkMPP_400x400.jpeg"></p><p>I’ve been using <a href="https://twitter.com/CausalHQ">@CausalHQ</a> for the past two weeks to rebuild our financial model, and it’s such a breath of fresh air compared to the fragile, static models that I ended up making in Excel/Sheets.</p></div><nav><div><p><img loading="lazy" alt="Jeremy Higgs" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5b500d68fc2832b5e519_4ViSkMPP_400x400.jpeg"></p></div><p>I’ve been using <a href="https://twitter.com/CausalHQ">@CausalHQ</a> for the past two weeks to rebuild our financial model, and it’s such a breath of fresh air compared to the fragile, static models that I ended up making in Excel/Sheets.</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Zuhayeer Musa" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5ab4b60fbe82aabbc422_0Hu6fzCv_400x400.jpeg"></p><p>If you haven’t yet checked out <a href="https://twitter.com/CausalHQ">@CausalHQ</a>, it’s an incredible way to create live-updating forecasts with built-in tools for modeling uncertainty</p></div><nav><div><p><img loading="lazy" alt="Zuhayeer Musa" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5ab4b60fbe82aabbc422_0Hu6fzCv_400x400.jpeg"></p></div><p>If you haven’t yet checked out <a href="https://twitter.com/CausalHQ">@CausalHQ</a>, it’s an incredible way to create live-updating forecasts with built-in tools for modeling uncertainty</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Dries Vaesen" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5a41b60fbe376abbc20d_V0GxkBmz_400x400.jpeg"></p><p>Been playing around with <a href="https://twitter.com/CausalHQ">@CausalHQ</a> for the last hour or so and I'm very impressed by the simplicity yet thoughtfulness of the features and interactions. Great job!</p></div><nav><div><p><img loading="lazy" alt="Dries Vaesen" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5a41b60fbe376abbc20d_V0GxkBmz_400x400.jpeg"></p></div><p>Been playing around with <a href="https://twitter.com/CausalHQ">@CausalHQ</a> for the last hour or so and I'm very impressed by the simplicity yet thoughtfulness of the features and interactions. Great job!</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Tyler Tringas" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d59f8439bcf21130d6a9d_XBVpLgf-_400x400.jpeg"></p><p>I’m a bit of a spreadsheet/model-building nerd and I’ve been super impressed with <a href="https://twitter.com/CausalHQ">@CausalHQ</a>. Among other things I think we’ll rebuild a dynamic version of our founder-break-even calculator. Should be fun.</p></div><nav><div><p><img loading="lazy" alt="Tyler Tringas" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d59f8439bcf21130d6a9d_XBVpLgf-_400x400.jpeg"></p><div><h6>Tyler Tringas</h6><p>@tylertringas</p></div></div><p>I’m a bit of a spreadsheet/model-building nerd and I’ve been super impressed with <a href="https://twitter.com/CausalHQ">@CausalHQ</a>. Among other things I think we’ll rebuild a dynamic version of our founder-break-even calculator. Should be fun.</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="ben 🌐³ bryandigital.io 🔮👀📐🏗️🚀✨🟣" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d596ac3925a8c7550af50_OXjXu8o6_400x400.jpeg"></p><div><p>One of my favourite web apps: <a href="https://www.causal.app/">http://causal.app</a></p><p>Quickly &amp; easily create financial models + automatically generate dynamic presentations based on those models. Brilliant work by <a href="https://twitter.com/CausalHQ">@CausalHQ</a></p></div></div><nav><div><p><img loading="lazy" alt="ben 🌐³ bryandigital.io 🔮👀📐🏗️🚀✨🟣" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d596ac3925a8c7550af50_OXjXu8o6_400x400.jpeg"></p><div><h6>ben 🌐³ bryandigital.io 🔮👀📐🏗️🚀✨🟣</h6><p>@bryandigitalio</p></div></div><div><p>One of my favourite web apps: <a href="https://www.causal.app/">http://causal.app</a></p><p>Quickly &amp; easily create financial models + automatically generate dynamic presentations based on those models. Brilliant work by <a href="https://twitter.com/CausalHQ">@CausalHQ</a></p></div></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Matt 🏴󠁧󠁢󠁷󠁬󠁳󠁿" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d58f0c1a96097f76bc8f7_PAcQCoYn_400x400.jpeg"></p><div><p>On a demo with <a href="https://twitter.com/CausalHQ">@CausalHQ</a> via @makerpad </p><p>It is a game changer for modeling. CFOs and PMs will be chomping at the bit to get their hands on it. </p><p>👏</p></div></div><nav><div><p><img loading="lazy" alt="Matt 🏴󠁧󠁢󠁷󠁬󠁳󠁿" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d58f0c1a96097f76bc8f7_PAcQCoYn_400x400.jpeg"></p><div><h6>Matt 🏴󠁧󠁢󠁷󠁬󠁳󠁿</h6><p>@makermattevans</p></div></div><div><p>On a demo with <a href="https://twitter.com/CausalHQ">@CausalHQ</a> via @makerpad </p><p>It is a game changer for modeling. CFOs and PMs will be chomping at the bit to get their hands on it. </p><p>👏</p></div></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Danae Shell" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d58b3a6484f37f374f6e2_GJfB9xOZ_400x400.jpeg"></p><p>Y'all, I have built a LOT of financial models in my day and <a href="https://twitter.com/CausalHQ">@CausalHQ</a> just made it super easy to build one up from scratch. WAY easier than my spreadsheets. I am obsessed!</p></div><nav><div><p><img loading="lazy" alt="Danae Shell" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d58b3a6484f37f374f6e2_GJfB9xOZ_400x400.jpeg"></p></div><p>Y'all, I have built a LOT of financial models in my day and <a href="https://twitter.com/CausalHQ">@CausalHQ</a> just made it super easy to build one up from scratch. WAY easier than my spreadsheets. I am obsessed!</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Matt Mazzeo" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5854624fddb9802ae910_dDMKej74_400x400.jpeg"></p><div><p>Need to build a model? This product is stunning. </p><p>👊👊 <a href="https://twitter.com/CausalHQ">@CausalHQ</a></p></div></div><nav><div><p><img loading="lazy" alt="Matt Mazzeo" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5854624fddb9802ae910_dDMKej74_400x400.jpeg"></p></div><div><p>Need to build a model? This product is stunning. </p><p>👊👊 <a href="https://twitter.com/CausalHQ">@CausalHQ</a></p></div></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="😵" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d57fe9b947476de815164_A0RFkH6r_400x400.jpeg"></p><p>if you use spreadsheets, you should be using <a href="https://twitter.com/CausalHQ">@causalhq</a> instead. don't play yourself!</p></div><nav><div><p><img loading="lazy" alt="😵" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d57fe9b947476de815164_A0RFkH6r_400x400.jpeg"></p></div><p>if you use spreadsheets, you should be using <a href="https://twitter.com/CausalHQ">@causalhq</a> instead. don't play yourself!</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Vithu G. Namasivayam" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5775850eca99cceed0e5_-y-GmQKN_400x400.jpeg"></p><p>Non-codey people that love math should try <a href="https://twitter.com/CausalHQ">@CausalHQ</a>. I feel like a data scientist using it when I am in fact neither a data nor a scientist.</p></div><nav><div><p><img loading="lazy" alt="Vithu G. Namasivayam" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5775850eca99cceed0e5_-y-GmQKN_400x400.jpeg"></p><div><h6>Vithu G. Namasivayam</h6><p>@VithuNamas</p></div></div><p>Non-codey people that love math should try <a href="https://twitter.com/CausalHQ">@CausalHQ</a>. I feel like a data scientist using it when I am in fact neither a data nor a scientist.</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Ben Sehl" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d569f007942bb31e0de7c_2fjfB5K4_400x400.jpeg"></p><p>If you ever do any modeling/forecasting — I seriously can’t recommend <a href="https://twitter.com/CausalHQ">@CausalHQ</a> enough. It is such a great product.</p></div><nav><div><p><img loading="lazy" alt="Ben Sehl" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d569f007942bb31e0de7c_2fjfB5K4_400x400.jpeg"></p></div><p>If you ever do any modeling/forecasting — I seriously can’t recommend <a href="https://twitter.com/CausalHQ">@CausalHQ</a> enough. It is such a great product.</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Colin Plamondon" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5048fb3be6332c51f467_75e17ZHX_400x400.jpeg"></p><div><p>Throwing together probabilistic models w/ <a href="https://twitter.com/CausalHQ">@CausalHQ</a> is futuristic as hell. </p><p>I was writing a project spec last night. CAC vs. price vs. conversion rates - Causal stuff.</p><p>Within 45m I was exploring scenarios in a detailed, data-backed way.</p><p>Craziest part? It embeds in Notion 🤯</p></div></div><nav><div><p><img loading="lazy" alt="Colin Plamondon" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620d5048fb3be6332c51f467_75e17ZHX_400x400.jpeg"></p><div><h6>Colin Plamondon</h6><p>@colinplamondon</p></div></div><div><p>Throwing together probabilistic models w/ <a href="https://twitter.com/CausalHQ">@CausalHQ</a> is futuristic as hell. </p><p>I was writing a project spec last night. CAC vs. price vs. conversion rates - Causal stuff.</p><p>Within 45m I was exploring scenarios in a detailed, data-backed way.</p><p>Craziest part? It embeds in Notion 🤯</p></div></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Sar Haribhakti" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620a83874e2aec5b0fcf284a_bWI63HA1_400x400.jpeg"></p></div><nav><div><p><img loading="lazy" alt="Sar Haribhakti" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620a83874e2aec5b0fcf284a_bWI63HA1_400x400.jpeg"></p></div></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="Kieran McHugh" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620a79fdba6d094410b82e36_YhuBDlxu_400x400.jpeg"></p><p>Preparing a financial model for Daybridge in <a href="https://twitter.com/CausalHQ">@CausalHQ</a> and I must say it’s a phenomenal piece of software with a boatload of potential. Magical to watch things reload in real time. I need to know their tech stack!</p></div><nav><div><p><img loading="lazy" alt="Kieran McHugh" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/620a79fdba6d094410b82e36_YhuBDlxu_400x400.jpeg"></p></div><p>Preparing a financial model for Daybridge in <a href="https://twitter.com/CausalHQ">@CausalHQ</a> and I must say it’s a phenomenal piece of software with a boatload of potential. Magical to watch things reload in real time. I need to know their tech stack!</p></nav></div><div data-hover="false" data-delay="0" role="listitem"><div><p><img loading="lazy" alt="kempsterrrr.eth | (🧱, 🚀) ᵍᵐ" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/6208e9c1f0c89029a13729dd__wosnH7h_400x400.jpeg"></p><div><p>strong recommend <a href="https://twitter.com/CausalHQ">@CausalHQ</a> for interactive financial modelling. for matter any modelling.</p><p>breath of fresh air from trying to do these things in excel</p></div></div><nav><div><p><img loading="lazy" alt="kempsterrrr.eth | (🧱, 🚀) ᵍᵐ" src="https://assets-global.website-files.com/61eff6b3236cf9057b6c1fac/6208e9c1f0c89029a13729dd__wosnH7h_400x400.jpeg"></p><div><h6>kempsterrrr.eth | (🧱, 🚀) ᵍᵐ</h6><p>@kempsterrrr</p></div></div><div><p>strong recommend <a href="https://twitter.com/CausalHQ">@CausalHQ</a> for interactive financial modelling. for matter any modelling.</p><p>breath of fresh air from trying to do these things in excel</p></div></nav></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java 22 Released (231 pts)]]></title>
            <link>https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008827.html</link>
            <guid>39755471</guid>
            <pubDate>Tue, 19 Mar 2024 13:22:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008827.html">https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008827.html</a>, See on <a href="https://news.ycombinator.com/item?id=39755471">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>Mark Reinhold</b> 
    <a href="mailto:jdk-dev%40openjdk.org?Subject=Re%3A%20Java%2022%20/%20JDK%2022%3A%20General%20Availability&amp;In-Reply-To=%3C20240319132004.DAD846C4EC2%40eggemoggin.niobe.net%3E" title="Java 22 / JDK 22: General Availability">mark.reinhold at oracle.com
       </a><br>
    <i>Tue Mar 19 13:20:07 UTC 2024</i>
    <ul>
        <li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008818.html">Tier1 failure: test machine short of memory?
</a></li>
        <li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008828.html">Java 22 / JDK 22: General Availability
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/date.html#8827">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/thread.html#8827">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/subject.html#8827">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/author.html#8827">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>JDK 22, the reference implementation of Java 22, is now Generally
Available.  We shipped build 36 as the second Release Candidate of
JDK 22 on 16 February, and no P1 bugs have been reported since then.
Build 36 is therefore now the GA build, ready for production use.

GPL-licensed OpenJDK builds from Oracle are available here:

  <a href="https://jdk.java.net/22">https://jdk.java.net/22</a>

Builds from other vendors will no doubt be available soon.

This release includes twelve JEPs [1], including the final versions of
the Foreign Function &amp; Memory API (454) and Unnamed Variables &amp; Patterns
(456):

  423: Region Pinning for G1
  447: Statements before super(...) (Preview)
  454: Foreign Function &amp; Memory API
  456: Unnamed Variables &amp; Patterns
  457: Class-File API (Preview)
  458: Launch Multi-File Source-Code Programs
  459: String Templates (Second Preview)
  460: Vector API (Seventh Incubator)
  461: Stream Gatherers (Preview)
  462: Structured Concurrency (Second Preview)
  463: Implicitly Declared Classes and Instance Main Methods (Second Preview)
  464: Scoped Values (Second Preview)

This release also includes, as usual, hundreds of smaller enhancements
and thousands of bug fixes.

Thank you to everyone who contributed this release, whether by designing
and implementing features or enhancements, by fixing bugs, or by
downloading and testing the early-access builds!

- Mark


[1] <a href="https://openjdk.org/projects/jdk/22/">https://openjdk.org/projects/jdk/22/</a>
</pre>



<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008818.html">Tier1 failure: test machine short of memory?
</a></li>
	<li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/008828.html">Java 22 / JDK 22: General Availability
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/date.html#8827">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/thread.html#8827">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/subject.html#8827">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/jdk-dev/2024-March/author.html#8827">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://mail.openjdk.org/mailman/listinfo/jdk-dev">More information about the jdk-dev
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[USB hubs, printers, Java, and more seemingly broken by macOS 14.4 update (155 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/03/usb-hubs-printers-java-and-more-seemingly-broken-by-macos-14-4-update/</link>
            <guid>39755358</guid>
            <pubDate>Tue, 19 Mar 2024 13:10:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/03/usb-hubs-printers-java-and-more-seemingly-broken-by-macos-14-4-update/">https://arstechnica.com/gadgets/2024/03/usb-hubs-printers-java-and-more-seemingly-broken-by-macos-14-4-update/</a>, See on <a href="https://news.ycombinator.com/item?id=39755358">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      pobody's nerfect    —
</h4>
            
            <h2 itemprop="description">Issues seem to be related to security fixes made in Apple's latest OS.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/sonoma-light-800x500.jpg" alt="USB hubs, printers, Java, and more seemingly broken by macOS 14.4 update">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 44:single/related:9eaea15ff7b90fe849d8bb6d3fe64379 --><!-- empty -->
<p>A couple of weeks ago, Apple <a href="https://arstechnica.com/gadgets/2024/03/visionos-1-1-tries-to-make-personas-less-unsettling-plus-other-apple-os-updates/">released macOS Sonoma 14.4</a> with the usual list of bug fixes, security patches, and a couple of minor new features. Since then, users and companies have been complaining of a long list of incompatibilities, mostly concerning broken external accessories like USB hubs and printers&nbsp;but also extending to software like Java.</p>
<p>MacRumors has <a href="https://www.macrumors.com/2024/03/18/do-not-update-macos-sonoma-14-4/">a good rundown</a> of the list of issues, which has been steadily getting longer as people have run into more problems. It started with reports of malfunctioning USB hubs, sourced from users on <a href="https://www.reddit.com/r/MacOS/comments/1b9volo/usb_hub_on_monitor_no_longer_working_on_macbook/">Reddit</a>, the <a href="https://discussions.apple.com/thread/255518397?answerId=260266531022&amp;sortBy=best#260266531022">Apple Support Communities forums</a>, and <a href="https://forums.macrumors.com/threads/sonoma-14-4-breaks-usb-c-monitor-with-hubs.2421678/">elsewhere</a>—USB hubs built into various displays stopped functioning for Mac users after the 14.4 update.</p>

<p>Other issues surfaced in the days after people started reporting problems with their USB hubs, including <a href="https://discussions.apple.com/thread/255522015?sortBy=best">some instances</a> of broken printer drivers, <a href="https://blogs.oracle.com/java/post/java-on-macos-14-4">unexpected app crashes</a> for some Java users, and problems launching apps that rely on the PACE anti-piracy software (<a href="https://help.ilok.com/faq_licenses.html#sonoma_14_4_plugins">and iLok hardware dongles</a>) to authenticate.</p>
<p>At least some of the problems seem localized to Apple Silicon Macs. In fact, iLok recommends running digital audio software in Rosetta mode as a temporary stopgap while Apple works on a fix. According to iLok, Apple has acknowledged this particular bug and is working on an update, but "[has] not indicated a timeline."</p>                                            
                                                        
<p>The USB hub issue may be related to the USB security prompts that Apple <a href="https://arstechnica.com/gadgets/2022/10/macos-13-ventura-the-ars-technica-review/16/#h2">introduced in macOS 13 Ventura</a>, asking users to confirm whether they wanted to connect to USB-C accessories that they were connecting to their Mac for the first time. Some users have been able to <a href="https://discussions.apple.com/thread/255518397?answerId=255518397021#255518397021">get their USB hubs working again</a> after the 14.4 update by making macOS request permission to connect to the accessory every time the accessory is plugged in; the default behavior is supposed to recognize USB devices that you've already connected to once.</p>
<p>Scanning Apple's <a href="https://developer.apple.com/documentation/macos-release-notes/macos-14_4-release-notes">release notes</a> or <a href="https://support.apple.com/en-us/HT214084">security update disclosures</a> for the update doesn't reveal any smoking guns, but many of the security bugs were addressed with "improved checks" and "improved access permissions," and it's certainly possible that some legitimate accessories and software were broken by one or more of these changes. <a href="https://blogs.oracle.com/java/post/java-on-macos-14-4">The Oracle blog post about the Java problems</a> refers to memory access issues that seem to be causing the crashes, though that may or may not explain the problems people are having with external accessories. The blog post also indicates that these bugs weren't present in the public developer betas of macOS 14.4.</p>
<p>My desktop M2 Mac Studio setup, which is connected to a 4K Gigabyte M28U with a built-in USB hub, hasn't exhibited any unusual behavior since the update, so it's also possible that these issues aren't affecting every user of every Mac. If you haven't updated yet, it may be worth waiting until Apple releases fixes for some or all of these issues, even if you don't think you'll be affected.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astronaut Thomas Stafford has died (139 pts)]]></title>
            <link>https://apnews.com/article/apollo-10-astronaut-tom-stafford-18600e218bd145ce99a3605b35df7b8c</link>
            <guid>39755267</guid>
            <pubDate>Tue, 19 Mar 2024 13:00:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/apollo-10-astronaut-tom-stafford-18600e218bd145ce99a3605b35df7b8c">https://apnews.com/article/apollo-10-astronaut-tom-stafford-18600e218bd145ce99a3605b35df7b8c</a>, See on <a href="https://news.ycombinator.com/item?id=39755267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>WASHINGTON (AP) — Astronaut Thomas P. Stafford, who commanded a dress rehearsal flight for the 1969 moon landing and the first U.S.-Soviet space linkup, died Monday. He was 93. </p><p>Stafford, a retired Air Force three-star general, took part in four space missions. Before Apollo 10, he flew on two Gemini flights, including the first rendezvous of two U.S. capsules in orbit. He died in a hospital near his Space Coast Florida home, said Max Ary, director of the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.staffordmuseum.org/" target="_blank" rel="noopener">Stafford Air &amp; Space Museum</a></span> in Weatherford, Oklahoma.</p><p>Stafford was one of 24 NASA astronauts who flew to the moon, but he did not land on it. Only seven of them are still alive.</p><p>“Today General Tom Stafford went to the eternal heavens which he so courageously explored as a Gemini and Apollo astronaut as well as a peacemaker in Apollo Soyuz,” NASA Administrator Bill Nelson said via X, formerly known as Twitter. “Those of us privileged to know him are very sad but grateful we knew a giant.”</p>
    

<p>After he put away his flight suit, Stafford was the go-to guy for NASA when it sought independent advice on everything from human Mars missions to safety issues to returning to flight after the 2003 space shuttle Columbia accident. He chaired an oversight group that looked into how to fix the then-flawed Hubble Space Telescope, earning a NASA public service award.</p>



<p>“Tom was involved in so many things that most people were not aware of, such as being known as the ‘Father of Stealth’,” Ary said in an email. Stafford was in charge of the famous “Area 51” desert base that was the site of many UFO theories, but the home of testing of Air Force stealth technologies.</p>
    
<p>The Apollo 10 mission in May 1969 set the stage for Apollo 11’s historic mission two months later. Stafford and Gene Cernan took the lunar lander nicknamed Snoopy within 9 miles (14 kilometers) of the moon’s surface. Astronaut John Young stayed behind in the main spaceship dubbed Charlie Brown.</p>
    

<p>“The most impressive sight, I think, that really changed your view of things is when you first see Earth,” Stafford recalled in a 1997 oral history, talking about the view from lunar orbit.</p><p>Then came the moon’s far side: “The Earth disappears. There’s this big black void.” </p><p>Apollo 10’s return to Earth set the world’s record for fastest speed by a crewed vehicle at 24,791 mph (39,897 kph).</p><p>After the moon landings ended, NASA and the Soviet Union decided on a joint docking mission and Stafford, a one-star general at the time, was chosen to command the American side. It meant intensive language training, being followed by the KGB while in the Soviet Union, and lifelong friendships with cosmonauts. The two teams of space travelers even went to Disney World and rode Space Mountain together before going into orbit and joining ships.</p><p>“We have capture,” Stafford radioed in Russian as the Apollo and Soyuz spacecraft hooked up. His Russian counterpart, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/bccf6f678de1469382936ccd0e202e9e">Alexei Leonov</a></span>, responded in English: “Well done, Tom, it was a good show. I vote for you.”</p><p>The 1975 mission included two days during which the five men worked together on experiments. After, the two teams toured the world together, meeting President Gerald Ford and Soviet leader Leonid Brezhnev.</p>
    

<p>“It helped prove to the rest of the world that two completely opposite political systems could work together,” Stafford recalled at a 30th anniversary gathering in 2005.</p><p>The two crews became so close that years later Leonov arranged for Stafford to be able to adopt two Russian boys when Stafford was in his 70s.</p><p>“We are too old to adopt, but they were too old to be adopted,” Stafford told The Oklahoman in 2004. “They just added so much meaning to our life, and just because you’re retiring doesn’t mean you don’t have anything left to give.”</p><p>Later, Stafford was a central part of discussions in the 1990s that brought Russia into the partnership building and operating the International Space Station.</p><p>Growing up in Weatherford, Oklahoma, Stafford said he would look up and see giant DC-3 airplanes fly overhead on early transcontinental routes. </p>
    

<p>“I wanted to fly since I was 5 or 6 years old seeing those airplanes,” he told NASA historians.</p><p>Stafford went to the U.S. Naval Academy where he graduated in the top 1% of his class and flew in the backseat of some airplanes and loved it. He volunteered for the Air Force and had hoped to fly combat in the Korean War. But by the time he got his wings, the war ended. He went to the Air Force’s experimental test pilot school, graduated first in his class there and stayed on as an instructor.</p><p>In 1962, NASA selected Stafford for its second set of astronauts, which included Neil Armstrong, Frank Borman and Pete Conrad.</p><p>Stafford was assigned along with Wally Schirra to Gemini 6. Their original mission was to rendezvous with an empty spaceship. But their 1965 launch was scrubbed when the spaceship exploded soon after liftoff. NASA improvised and in December, Gemini 6 rendezvoused with but didn’t dock with two astronauts aboard Gemini 7.</p>
    

<p>Stafford’s next flight in 1966 was with Cernan on Gemini 9. Cernan’s spacewalk, connected to a jet-pack like device, didn’t go well. Cernan complained that the sun and machine made him extra hot and hurt his back. Then his visor fogged up and he couldn’t see.</p><p>“Call it quits, Gene. Get out of there,” Stafford, the commander, told Cernan. Stafford talked him back in, saying “move your hand over, start to float up ... stick your hand up ... just walk hand over hand.”</p><p>In all, Stafford logged 507 hours in space and flew four different types of spacecraft and 127 types of aircraft and helicopters.</p><p>After the Apollo-Soyuz mission, Stafford returned to the Air Force and worked in research and commanded the Air Force Flight Test Center before retiring in 1979 as a three-star general.</p><p>Stafford’s Air Force duties not only had him run the military’s top flight school and experimental plane testing base, but he was commanding general of Area 51. A biography from his museum said, that while Stafford was in charge of Area 51 and later as the development and acquisition chief at the Pentagon he “wrote the specs and established the program that led to the development of the F-117 Stealth Fighter, and later, the B-2 Stealth Bomber.”</p><p>Stafford became an executive for an Oklahoma-based transportation company and later moved to Florida, near Cape Canaveral.</p><p>He is survived by his wife. Linda, two sons, two daughters and two stepchildren, according to the museum.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Not sure you're talking to a human? Create a human check (153 pts)]]></title>
            <link>https://r-u-human.com/</link>
            <guid>39755084</guid>
            <pubDate>Tue, 19 Mar 2024 12:39:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://r-u-human.com/">https://r-u-human.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39755084">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Inside the Massive Alleged AT&T Data Breach (183 pts)]]></title>
            <link>https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/</link>
            <guid>39754330</guid>
            <pubDate>Tue, 19 Mar 2024 10:19:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/">https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/</a>, See on <a href="https://news.ycombinator.com/item?id=39754330">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>I hate having to use that word - "alleged" - because it's so inconclusive and I know it will leave people with many unanswered questions. But sometimes, "alleged" is just where we need to begin and over the course of time, proper attribution is made and the dots are joined. We're here at "alleged" for two very simple reasons: one is that AT&amp;T is saying "the data didn't come from us", and the other is that I have no way of proving otherwise. But I have proven, with sufficient confidence, that the data is real and the impact is significant. Let me explain:</p><p>Firstly, just as a primer if you're new to this story, <a href="https://www.bleepingcomputer.com/news/security/att-says-leaked-data-of-70-million-people-is-not-from-its-systems/?ref=troyhunt.com" rel="noreferrer">read BleepingComputer's piece on the incident</a>. What it boils down to is in August 2021, someone with a proven history of breaching large organisations <a href="https://www.bleepingcomputer.com/news/security/atandt-denies-data-breach-after-hacker-auctions-70-million-user-database/?ref=troyhunt.com" rel="noreferrer">posted what they claimed were 70 million AT&amp;T records to a popular hacking forum</a> and asked for a very large amount of money should anyone wish to purchase the data. From that story:</p><blockquote>From the samples shared by the threat actor, the database contains customers' names, addresses, phone numbers, Social Security numbers, and date of birth.</blockquote><p>Fast forward two and a half years and the successor to this forum saw a post this week alleging to contain the entire corpus of data. Except that rather than put it up for sale, someone has decided to just dump it all publicly and make it easily accessible to the masses. This isn't unusual: "fresh" data has much greater commercial value and is often tightly held for a long period before being released into the public domain. The Dropbox and LinkedIn breaches, for example, occurred in 2012 before being broadly distributed in 2016 and just like those incidents, the alleged AT&amp;T data is now in <em>very</em> broad circulation. It is undoubtedly in the hands of thousands of internet randos.</p><p>AT&amp;T's position on this is pretty simple:</p><blockquote>AT&amp;T continues to tell BleepingComputer today that they still see no evidence of a breach in their systems and still believe that this data did not originate from them.</blockquote><p>The old adage of "absence of evidence is not evidence of absence" comes to mind (just because they can't find evidence of it doesn't mean it didn't happen), but as I said earlier on, I (and others) have so far been unable to prove otherwise. So, let's focus on what we <em>can</em> prove, starting with the accuracy of the data.</p><p>The linked article talks about the author verifying the data with various people he knows, as well as other well-known infosec identities verifying its accuracy. For my part, I've got 4.8M <a href="https://haveibeenpwned.com/?ref=troyhunt.com" rel="noreferrer">Have I Been Pwned</a> (HIBP) subscribers I can lean on to assist with verification, and it turns out that 153k of them are in this data set. What I'll typically do in a scenario like this is reach out to the 30 newest subscribers (people who will hopefully recall the nature of HIBP from their recent memory), and ask them if they're willing to assist. I linked to the story from the beginning of this blog post and got a handful of willing respondents for whom I sent their data and asked two simple questions:</p><ol><li>Does this data look accurate?</li><li>Are you an AT&amp;T customer and if not, are you a customer of another US telco?</li></ol><p>The first reply I received was simple, but emphatic:</p><figure><img src="https://pbs.twimg.com/media/GI_kjAfbQAA1eHV?format=jpg&amp;name=900x900" alt="Image" loading="lazy" width="880" height="184"></figure><p>This individual had their name, phone number, home address and most importantly, their social security number exposed. Per the linked story, social security numbers and dates of birth exist on most rows of the data in encrypted format, but two supplemental files expose these in plain text. Taken at face value, it looks like whoever snagged this data also obtained the private encryption key and simply decrypted the vast bulk (but not all of) the protected values.</p><figure><img src="https://pbs.twimg.com/media/GI_kxrkbYAAzxjz?format=jpg&amp;name=large" alt="Image" loading="lazy" width="1290" height="290"></figure><p>The above example simply didn't have plain text entries for the encrypted data. Just by way of raw numbers, the file that aligns with the "70M" headline actually has 73,481,539 lines with 49,102,176 unique email addresses. The file with decrypted SSNs has 43,989,217 lines and the decrypted dates of birth file only has 43,524 rows. The last file, for example, has rows that look just like this:</p>

<pre><code>.encrypted_value='*0g91F1wJvGV03zUGm6mBWSg==' .decrypted_value='1996-07-18'</code></pre>

<p>That encrypted value is precisely what appears in the large file hence providing an easy way of matching all the data together. But those numbers also obviously mean that not every impacted individual had their SSN exposed, and <em>most</em> individuals didn't have their date of birth leaked.</p><figure><img src="https://pbs.twimg.com/media/GI_xf24asAEPboF?format=jpg&amp;name=medium" alt="Image" loading="lazy" width="1188" height="495"></figure><p>As I'm fond of saying, there's only one thing worse than your data appearing on the dark web: it's appearing on the clear web. And that's precisely where it is; the forum this was posted to isn't within the shady underbelly of a Tor hidden service, it's out there in plain sight on a public forum easily accessed by a normal web browser. And the data is real.</p><p>That last response is where most people impacted by this will now find themselves - "what do I do?" Usually I'd tell them to get in touch with the impacted organisation and request a copy of their data from the breach, but if AT&amp;T's position is that it didn't come from them then they may not be much help. (Although if you are a current or previous customer, you can certainly request a copy of your personal information regardless of this incident.) I've personally also used identity theft protection services since as far back as the 90's now, simply to know when actions such as credit enquiries appear against my name. In the US, this is what services like <a href="https://www.aura.com/identity-theft-protection?ref=troyhunt.com" rel="noreferrer">Aura</a> do and it's become common practice for breached organisations to provide identity protection subscriptions to impacted customers (full disclosure: Aura is a previous sponsor of this blog, although we have no ongoing or upcoming commercial relationship).</p><p>What I can't do is send you your breached data, or an indication of what fields you had exposed. Whilst I did this in that handful of aforementioned cases as part of the breach verification process, this is something that happens entirely manually and is infeasible en mass. HIBP only ever stores email addresses and never the additional fields of personal information that appear in data breaches. In case you're wondering why that is, we got a solid reminder only a couple of months ago when <a href="https://www.troyhunt.com/the-data-breach-personal-stash-ecosystem/" rel="noreferrer">a service making this sort of data available to the masses had an incident that exposed tens of <em>billions</em> of rows of personal information</a>. That's just an unacceptable risk for which the old adage of "you cannot lose what you do not have" provides the best possible fix.</p><p>As I said in the intro, this is not the conclusive end I wanted for this blog post... yet. As impacted HIBP subscribers receive their notifications and particularly as those monitoring domains learn of the aliases in the breach (many domain owners use unique aliases per service they sign up to), we may see a more conclusive outcome to this incident. That may not necessarily be confirmation that the data did indeed originate from AT&amp;T, it could be that it came from a third party processor they use or from another entity altogether that's entirely unrelated. The truth is somewhere there in the data, I'll add any relevant updates to this blog post if and when it comes out.</p><p>As of now, all 49M impacted email addresses are <a href="https://haveibeenpwned.com/?ref=troyhunt.com" rel="noreferrer">searchable within HIBP</a>.</p>
<section>
<a href="https://www.troyhunt.com/tag/have-i-been-pwned-3f/">Have I Been Pwned</a>
<a href="https://www.troyhunt.com/tag/security/">Security</a>
</section>
</section><div>
<section>
<a href="https://twitter.com/share?text=Troy%20Hunt%3A%20Inside%20the%20Massive%20Alleged%20AT%26T%20Data%20Breach&amp;url=https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/"><i></i> Tweet</a>
<a href="https://www.facebook.com/sharer/sharer.php?u=https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/"><i></i> Post</a>
<a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/"><i></i> Update</a>
<a href="mailto:?subject=Troy%20Hunt%3A%20Inside%20the%20Massive%20Alleged%20AT%26T%20Data%20Breach&amp;body=https://www.troyhunt.com/inside-the-massive-alleged-att-data-breach/"><i></i> Email</a>
<a href="https://feeds.feedburner.com/TroyHunt"> RSS</a>
</section>
<div>
<h5 itemprop="author" itemscope="" itemtype="http://schema.org/Person">Troy Hunt</h5>
<p>Hi, I'm Troy Hunt, I write this blog, create courses for Pluralsight and am a Microsoft Regional Director and MVP who travels the world speaking at events and training technology professionals <a href="https://www.troyhunt.com/about"></a></p>
</div>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan brings negative interest rates era to an end with first hike in 17 years (129 pts)]]></title>
            <link>https://www.cnn.com/2024/03/18/business/japan-boj-negative-interest-rate-ended-intl-hnk/index.html</link>
            <guid>39753740</guid>
            <pubDate>Tue, 19 Mar 2024 07:51:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/03/18/business/japan-boj-negative-interest-rate-ended-intl-hnk/index.html">https://www.cnn.com/2024/03/18/business/japan-boj-negative-interest-rate-ended-intl-hnk/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39753740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cltxp8csu000n3b6h252rdvd7@published" data-name="GettyImages-1558501878.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.666875" data-original-height="1067" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=original" data-editable="lede" data-freewheel-lede="true" data-optimizely-image="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=original" data-optimizely-caption="A pedestrian walks past the Bank of Japan building in Tokyo." data-optimizely-credit="Richard A. Brooks/AFP/Getty Images">
       <picture><source height="383" width="680" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=16x9&amp;q=h_383,w_680,c_fill/f_webp" type="image/webp"><source height="653" width="1160" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=16x9&amp;q=h_653,w_1160,c_fill/f_webp" type="image/webp"><source height="605" width="1075" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=16x9&amp;q=h_605,w_1075,c_fill/f_webp" type="image/webp"><source height="833" width="1480" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=16x9&amp;q=h_833,w_1480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1558501878.jpg?c=16x9&amp;q=h_833,w_1480,c_fill" alt="A pedestrian walks past the Bank of Japan building in Tokyo." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1067" width="1600"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">Hong Kong</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxnayif001974p81ldv6c0p@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Japan has ended its negative interest rate policy, marking a historic shift away from an aggressive monetary easing program that was implemented years ago to fight chronic deflation.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxu43ch00003b6hhjuzn06x@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            As part of the decision, the <a href="https://www.cnn.com/2023/07/28/investing/japan-boj-yield-curve-intl-hnk/index.html">Bank of Japan</a> (BOJ) raised interest rates for the first time in 17 years, lifting its short-term rate to “around zero to 0.1%” from minus 0.1%, according to a statement posted on its website on Tuesday.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxvdb8300033b6h3d96m0s9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The BOJ has battled deflation and economic stagnation since the late 1990s.&nbsp;Over the years, it&nbsp;has&nbsp;sought to encourage prices to rise by using a combination of conventional and unconventional monetary policies, including zero or negative interest rates and large-scale asset purchases.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxvik5500003b6hpsfpag44@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Japan’s economy has recovered moderately, although some weakness has been seen in part,” it said in the statement Tuesday.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxw7j2z000n3b6hmt5rn9bl@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Recent data and anecdotal information have shown that the virtuous cycle between wages and prices has become “more solid,”<strong> </strong>it added.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxxoaz200003b6h0pan65ob@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            As inflation rose and interest rates elsewhere went up, pressure had grown on the BOJ to wind down its negative interest rate policy (NIRP).
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxxoe5800023b6hnx1haumz@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Last week, major unions and companies, including Toyota (<a href="https://www.cnn.com/markets/stocks/TM">TM</a>), announced better-than-expected wage hikes. Central bankers had been saying they wanted to see robust growth in wages before they can start to normalize interest rates.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxutiu900083b6hrfzi994p@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Though small, the landmark interest rate hike was the first since 2007. Until Tuesday, the BOJ had been the last central bank in the world to employ negative interest rates.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxxr00g00043b6h98xwbul3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The Bank of Japan has today ended an era of exceptional monetary policy accommodation,” Morgan Stanley analysts said Tuesday in a research note. “This can be characterized as a virtuous cycle of rising nominal GDP growth, wages, prices and corporate profits.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxu7fbc00043b6hq06erzom@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            As part of its exit from NIRP, the BOJ also announced that it would abandon its yield curve control (YCC) policy, which was introduced in 2016 to keep the yield on 10-year Japanese government bonds around 0% to maintain accommodative financial conditions.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxuhgko00063b6hp64n7mn2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Meanwhile, it would end purchases of exchange-traded funds and Japanese real estate investment trusts (J-REITs).
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxxt0lg00083b6hgzob0rwk@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Japan’s benchmark Nikkei 225 index seesawed during the trading day. It reversed morning losses to edge higher after the news of the rate hike, and then slipped into negative territory again. It closed up 0.7%.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxydcl4000l3b6huemsjr2i@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The broader Topix index ended 1.1% higher.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwa8e8000p3b6hdvcnox08@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The Japanese economy will continue growing at a pace “above its potential growth rate,” as a virtuous cycle from income to spending gradually intensifies, the BOJ said in the statement.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwbf5m000r3b6hmw8zzdlb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The inflation rate in the country is also likely to be above 2% through fiscal 2024, it said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwmlvv00103b6hzhoimkqg@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            However, it pledged to keep buying long-term government bonds<strong> </strong>at “broadly the same amount” as before, and indicated that financial conditions will remain accommodative “for the time being.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxy8a9a000j3b6hlizcb920@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Accommodative is a term used to describe monetary policy that adjusts to adverse market conditions and usually involves keeping interest rates low to spur growth and employment.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxx1ayr001n3b6ha9wh9gqo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            That suggests the BOJ will not embark on an aggressive tightening cycle of the sort that other major central banks, such as the United States, have engaged in in recent years to control inflation.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwn4eg00123b6hp4tvy77p@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “There are extremely high uncertainties surrounding Japan’s economic activity and prices,” the BOJ said, adding that the risks include developments in overseas economies, commodity prices and domestic firm’s wage-setting behavior.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwkwht000x3b6hpv19g34k@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Under these circumstances, it is necessary to pay due attention to developments in financial and foreign exchange markets and their impact on Japan’s economic activity and prices,” it added.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxv9efa000e3b6hpgaa0vah@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The Japanese yen weakened after the BOJ’s move. It slid 1% to 150.69 per US dollar by Tuesday evening.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwusvo00193b6hi53pz7u9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Analysts said the BOJ’s move might have been priced in by equities and currency markets.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxx9bj1001t3b6hlfeqg42g@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Policy normalization was expected by [our] economists and consensus,” the Morgan Stanley analysts said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwyfca001h3b6h59b6bl3w@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In future, analysts from Capital Economics say they don’t believe the BOJ will raise its policy rate any further.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxwywps001j3b6hkz63pafh@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “We suspect that wage growth among smaller firms won’t be quite as strong as among those firms participating in the Shunto [wage negotiations],” they said in a research report on Tuesday.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxx0jxv001l3b6hd3ge1tnt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “With wage growth peaking this year, we still expect inflation to fall below the&nbsp;BOJs target by the end of the year so the bank won’t feel the need to lift its policy rate any further.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cltxz3fhn00003b6him0gde5r@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            <em>This story has been updated with additional information.</em>
    </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BootLogo: Logo language in 508 bytes of x86 machine code (188 pts)]]></title>
            <link>https://github.com/nanochess/bootLogo</link>
            <guid>39753650</guid>
            <pubDate>Tue, 19 Mar 2024 07:32:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nanochess/bootLogo">https://github.com/nanochess/bootLogo</a>, See on <a href="https://news.ycombinator.com/item?id=39753650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div data-snippet-clipboard-copy-content=" _                 _   _
| |               | | | |
| |__   ___   ___ | |_| |     ___   __ _  ___
| '_ \ / _ \ / _ \| __| |    / _ \ / _` |/ _ \
| |_) | (_) | (_) | |_| |___| (_) | (_| | (_) |
|_.__/ \___/ \___/ \__\_____/\___/ \__, |\___/
                                __/ |
                               |___/"><pre><code> _                 _   _
| |               | | | |
| |__   ___   ___ | |_| |     ___   __ _  ___
| '_ \ / _ \ / _ \| __| |    / _ \ / _` |/ _ \
| |_) | (_) | (_) | |_| |___| (_) | (_| | (_) |
|_.__/ \___/ \___/ \__\_____/\___/ \__, |\___/
                                __/ |
                               |___/
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">bootLogo interpreter in 512 bytes (boot sector or COM file)</h3><a id="user-content-bootlogo-interpreter-in-512-bytes-boot-sector-or-com-file" aria-label="Permalink: bootLogo interpreter in 512 bytes (boot sector or COM file)" href="#bootlogo-interpreter-in-512-bytes-boot-sector-or-com-file"></a></p>
<p dir="auto"><em>by Oscar Toledo G. Mar/18/2024</em></p>
<p dir="auto"><a href="http://nanochess.org/" rel="nofollow">http://nanochess.org</a></p>
<p dir="auto"><a href="https://github.com/nanochess">https://github.com/nanochess</a></p>
<p dir="auto">This is a small interpreter of Logo language.</p>
<p dir="auto">It's compatible with the 8088 processor (the original IBM PC), but it requires a VGA-compatible card.</p>
<p dir="auto">If you want to assemble it, you must download the Netwide Assembler (NASM) from <a href="http://www.nasm.us/" rel="nofollow">www.nasm.us</a></p>
<p dir="auto">Use this command line:</p>
<div data-snippet-clipboard-copy-content="nasm -f bin bootlogo.asm -Dcom_file=1 -o bootlogo.com
nasm -f bin bootlogo.asm -Dcom_file=0 -o bootlogo.img"><pre><code>nasm -f bin bootlogo.asm -Dcom_file=1 -o bootlogo.com
nasm -f bin bootlogo.asm -Dcom_file=0 -o bootlogo.img
</code></pre></div>
<p dir="auto">Tested with VirtualBox for macOS running Windows XP running this interpreter, it also works with DOSBox and probably with QEMU:</p>
<div data-snippet-clipboard-copy-content="qemu-system-x86_64 -fda bootlogo.img"><pre><code>qemu-system-x86_64 -fda bootlogo.img
</code></pre></div>
<p dir="auto">Enjoy it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">User's manual</h2><a id="user-content-users-manual" aria-label="Permalink: User's manual" href="#users-manual"></a></p>
<p dir="auto">Line entry is done with the keyboard, finish the line with Enter.</p>
<p dir="auto">Backspace can be used to correct mistakes.</p>
<p dir="auto">The following commands are implemented:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLEARSCREEN</h3><a id="user-content-clearscreen" aria-label="Permalink: CLEARSCREEN" href="#clearscreen"></a></p>
<p dir="auto">Clears the screen and returns the turtle to the center, and pointing to the north. This command can only be used alone.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FD 40</h3><a id="user-content-fd-40" aria-label="Permalink: FD 40" href="#fd-40"></a></p>
<p dir="auto">Move the turtle 40 pixels ahead. Caveat: If you use zero, it will be taken as 65536 pixels.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">BK 40</h3><a id="user-content-bk-40" aria-label="Permalink: BK 40" href="#bk-40"></a></p>
<p dir="auto">Move the turtle 40 pixels backward. Caveat: If you use zero, it will be taken as 65536 pixels.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">RT 25</h3><a id="user-content-rt-25" aria-label="Permalink: RT 25" href="#rt-25"></a></p>
<p dir="auto">Rotate the turtle  25 degrees clockwise.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LT 25</h3><a id="user-content-lt-25" aria-label="Permalink: LT 25" href="#lt-25"></a></p>
<p dir="auto">Rotate the turtle 25 degrees counterclockwise.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">REPEAT 10 FD 10</h3><a id="user-content-repeat-10-fd-10" aria-label="Permalink: REPEAT 10 FD 10" href="#repeat-10-fd-10"></a></p>
<p dir="auto">Repeat 10 times FD 10</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">REPEAT 10 [FD 10 RT 20]</h3><a id="user-content-repeat-10-fd-10-rt-20" aria-label="Permalink: REPEAT 10 [FD 10 RT 20]" href="#repeat-10-fd-10-rt-20"></a></p>
<p dir="auto">Repeat 10 times FD 10 RT 20. Repeat can be nested. If you miss the final ] character then bootLogo will crash.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PU</h3><a id="user-content-pu" aria-label="Permalink: PU" href="#pu"></a></p>
<p dir="auto">Pen up. The turtle doesn't draw for following commands.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PD</h3><a id="user-content-pd" aria-label="Permalink: PD" href="#pd"></a></p>
<p dir="auto">Pen down. The turtle draws again.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">QUIT</h3><a id="user-content-quit" aria-label="Permalink: QUIT" href="#quit"></a></p>
<p dir="auto">Exit to command line (only .COM version)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nanochess/bootLogo/blob/master/example3.png"><img src="https://github.com/nanochess/bootLogo/raw/master/example3.png" alt="bootLogo command sequence"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nanochess/bootLogo/blob/master/example4.png"><img src="https://github.com/nanochess/bootLogo/raw/master/example4.png" alt="Result of bootLogo command sequence"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<ul dir="auto">
<li>jcmeyrignac for an idea to make smaller the number decoding.</li>
<li>Jim Leonard (MobyGamer) for making me thinking about a higher-precision sin function.</li>
<li>raulamd for reminding me that cubicDoom had a smaller sin function.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">More on this?</h2><a id="user-content-more-on-this" aria-label="Permalink: More on this?" href="#more-on-this"></a></p>
<p dir="auto">Do you want to learn 8086/8088 assembler? Get my book Programming Boot Sector Games containing an 8086/8088 crash course!</p>
<p dir="auto">Now available from Lulu:</p>
<p dir="auto"><a href="http://www.lulu.com/shop/oscar-toledo-gutierrez/programming-boot-sector-games/paperback/product-24188564.html" rel="nofollow">Paperback book</a></p>
<p dir="auto"><a href="http://www.lulu.com/shop/oscar-toledo-gutierrez/programming-boot-sector-games/hardcover/product-24188530.html" rel="nofollow">Hard-cover book</a></p>
<p dir="auto"><a href="https://nanochess.org/store.html" rel="nofollow">eBook</a></p>
<p dir="auto">These are some of the example programs documented profusely
in the book:</p>
<ul dir="auto">
<li>Guess the number.</li>
<li>Tic-Tac-Toe game.</li>
<li>Text graphics.</li>
<li>Mandelbrot set.</li>
<li>F-Bird game.</li>
<li>Invaders game.</li>
<li>Pillman game.</li>
<li>Toledo Atomchess.</li>
<li>bootBASIC language.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[20 Years of "Not Even Wrong" (260 pts)]]></title>
            <link>https://www.math.columbia.edu/~woit/wordpress/?p=13864</link>
            <guid>39753115</guid>
            <pubDate>Tue, 19 Mar 2024 05:08:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13864">https://www.math.columbia.edu/~woit/wordpress/?p=13864</a>, See on <a href="https://news.ycombinator.com/item?id=39753115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p>The <a href="https://www.math.columbia.edu/~woit/wordpress/?p=1">first entry on this blog</a> was 20 years ago yesterday, <a href="https://www.math.columbia.edu/~woit/wordpress/?p=2">first substantive one</a> was 20 years ago tomorrow (first <a href="https://www.math.columbia.edu/~woit/wordpress/?p=3">one that drew attacks on me as an incompetent</a> was two days later). Back when I started this up, blogging was all the rage, and lots of other blogs about fundamental physics were starting around the same time.  Almost all of these have gone dormant, with Sabine Hossenfelder’s Backreaction one notable exception. She and some others (like Sean Carroll) have largely moved to video, which seems to be the thing to do to communicate with as many people as possible.  There are people who do “micro-blogging” on Twitter, with the descendant of Lubos Motl’s blog <a href="https://twitter.com/stringking42069">StringKing42069 on Twitter</a>.  I remain mystified why anyone thinks it’s a good idea to discuss complex issues of theoretical physics in the Twitter format, flooded with all sorts of random stupidity.</p>
<p>Looking back on what I was writing 20 years ago it seems to me to have held up well, and there is very little that I would change.  The LHC experiments have told us that the Standard Model Higgs is there, and that supersymmetry is not, but these were always seen as the most likely results.</p>
<p>My point of view on things has changed since then, especially in recent years.  When I started the blog I was 20 years past my Ph.D., in the middle of some sort of an odd career.  Today I’m 66, 40 years past the Ph.D., much closer to the end of a career and a life than to a beginning.  In 2004 I was looking at nearly twenty years of domination of fundamental theory by a speculative idea that to me had never looked promising and by then was clearly a failure.  20 years later this story has become highly disturbing.  The refusal to admit failure and move on has to a large degree killed off the field as a serious science. </p>
<p>The technical difficulties involved in reaching higher energy scales at this point makes it all too likely that I’m not going to see any significant new data about what the world looks like above the TeV scale during my lifetime.   Without experiment to keep it honest, fundamental theory has seriously gone off the rails in a way which looks to me irreparable.  With the Standard Model so extremely successful and no hints from experiment about how to improve it, it’s now been about 50 years that this has been a subject in which it is very difficult to make progress.  I’ve always been an admitted elitist: in the face of a really hard problem, only a very talented person trained as well as possible and surrounded by the right intellectual environment is likely to be able to get somewhere.</p>
<p>My background has been at the elite institutions that are supposed to be providing this kind of training and working environment.  Harvard and Princeton gave me this sort of training in 1975-1984 and I think did a good job of it at the time, but from what I can tell things are now quite different.  40 years of training generations of students in a failed research program has taken its toll on the subject.  I remember well what it was like to be an ambitious student at these places, determined to get  as quickly as possible to the frontiers of knowledge, which in those times meant learning gauge field theory.  These days it unfortunately means putting a lot of effort into reading Polchinski, and becoming expert in the technology of failed ideas.</p>
<p>One recent incident that destroyed my remaining hopes for the institutions I had always still had some faith in was <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13770">the program discussed here</a>, which made me physically ill.  It made it completely clear that the leaders of this subject will never admit what has happened, no matter how bad it gets.   Also having a lot of impact on me was the <a href="https://www.math.columbia.edu/~woit/wordpress/?cat=34">Wormhole Publicity Stunt</a>, which showed that the problem is not just refusing to face up to the past, but willingness to sign onto an awful view of the future, as long as it brings in funding and can be sold as vindication of the past.  <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13229">Watching the director of the IAS explain that this was comparable to the 1919 experimental evidence for GR</a> surely made more than a few of those in attendance at least queasy.  This particular stunt may have jumped the shark, but what’s likely coming next looks no better (replace quantum computing with AI).</p>
<p>The strange thing is that while the wider world and the subject I care most about have been descending into an ever more depressing environment of tribalistic behavior and intellectual collapse, on a personal level things are going very well.  In particular I’m ever more optimistic about some new ideas and enjoying trying to make progress with them, seeing several promising directions. Whatever years I have available to think about these things are looking like they should be intellectually rewarding ones.  Locally, I’m looking forward to what the next twenty years will bring (if I make it through them…), while on a larger scale I’m dreading seeing what will happen.</p>
<p><strong>Update</strong>: For a place with extensive comments about this blog posting, see <a href="https://news.ycombinator.com/item?id=39753115">Hacker News</a>.</p>
											</div><div><p>
							This entry was posted in <a href="https://www.math.columbia.edu/~woit/wordpress/?cat=1" rel="category">Uncategorized</a>. Bookmark the <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13864" title="Permalink to 20 Years of Not Even Wrong" rel="bookmark">permalink</a>.													</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Garnet – A new remote cache-store from Microsoft Research (319 pts)]]></title>
            <link>https://github.com/microsoft/garnet</link>
            <guid>39752504</guid>
            <pubDate>Tue, 19 Mar 2024 02:56:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/microsoft/garnet">https://github.com/microsoft/garnet</a>, See on <a href="https://news.ycombinator.com/item?id=39752504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Garnet</h2><a id="user-content-garnet" aria-label="Permalink: Garnet" href="#garnet"></a></p>
<p dir="auto"><a href="https://github.com/microsoft/garnet/actions/workflows/ci.yml"><img src="https://github.com/microsoft/garnet/actions/workflows/ci.yml/badge.svg?branch=main" alt=".NET CI"></a>
<a href="https://aka.ms/garnet-discord" rel="nofollow"><img src="https://camo.githubusercontent.com/c82c5e4834a8243cab1300c0557a9fcf60d0099c576e2ee057ba20656b80e31f/68747470733a2f2f646973636f72646170702e636f6d2f6170692f6775696c64732f313231333933373435323237323538323637362f7769646765742e706e673f7374796c653d736869656c64" alt="Discord Shield" data-canonical-src="https://discordapp.com/api/guilds/1213937452272582676/widget.png?style=shield"></a></p>
<p dir="auto">Garnet is a new remote cache-store from Microsoft Research, that offers several unique benefits:</p>
<ul dir="auto">
<li>Garnet adopts the popular <a href="https://redis.io/docs/reference/protocol-spec/" rel="nofollow">RESP</a> wire protocol as a starting point, which makes it possible to use Garnet from unmodified Redis clients available in
most programming languages of today, such as <a href="https://github.com/StackExchange/StackExchange.Redis">StackExchange.Redis</a> in C#.</li>
<li>Garnet offers much better throughput and scalability with many client connections and small batches, relative to comparable open-source cache-stores, leading to cost savings for large apps and services.</li>
<li>Garnet demonstrates extremely low client latencies (often less than 300 microseconds at the 99.9th percentile) using commodity cloud (Azure) VMs with accelerated TCP enabled, which is critical to real-world scenarios.</li>
<li>Based on the latest .NET technology, Garnet is cross-platform, extensible, and modern. It is designed to be easy to develop for and evolve, without sacrificing performance in the
common case. We leveraged the rich library ecosystem of .NET for API breadth, with open opportunities for optimization. Thanks to our careful use of .NET, Garnet achieves
state-of-the-art performance on both Linux and Windows.</li>
</ul>
<p dir="auto">This repo contains the code to build and run Garnet. For more information and documentation, check out our website at <a href="https://microsoft.github.io/garnet" rel="nofollow">https://microsoft.github.io/garnet</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feature Summary</h2><a id="user-content-feature-summary" aria-label="Permalink: Feature Summary" href="#feature-summary"></a></p>
<p dir="auto">Garnet implements a wide range of APIs including raw strings (e.g., gets, sets, and key expiration), analytical (e.g., HyperLogLog and Bitmap), and object (e.g., sorted sets and lists)
operations. It can handle multi-key transactions in the form of client-side RESP transactions and our own server-side stored procedures in C# and allows users to define custom
operations on both raw strings and new object types, all in the convenience and safety of C#, leading to a lower bar for developing custom extensions.</p>
<p dir="auto">Garnet uses a fast and pluggable network layer, enabling future extensions such as leveraging kernel-bypass stacks. It supports secure transport layer security (TLS) communications using
the robust <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.security.sslstream" rel="nofollow">SslStream</a> library of .NET, as well as basic access control. Garnet’s storage layer, called Tsavorite, was
forked from our prior open-source project <a href="https://github.com/microsoft/FASTER">FASTER</a>, and includes strong database features such as thread scalability, tiered storage support
(memory, SSD, and cloud storage), fast non-blocking checkpointing, recovery, operation logging for durability, multi-key transaction support, and better memory management and reuse.
Finally, Garnet supports a cluster mode of operation with support for sharding, replication, and dynamic key migration.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/18355833/313800351-851be90b-e43a-40ca-ae56-7dc087cf6adc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA4ODA0OTcsIm5iZiI6MTcxMDg4MDE5NywicGF0aCI6Ii8xODM1NTgzMy8zMTM4MDAzNTEtODUxYmU5MGItZTQzYS00MGNhLWFlNTYtN2RjMDg3Y2Y2YWRjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE5VDIwMjk1N1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNmOGEzNTdlMDQ1Yjg4MmVhZTZjYzRmOTVhNTVhMzc4YmNhYWEyOTNmMTExNWQwMWU5ZmVjZTg0ZjU2MGY1NTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ybq2p4QZyKG1FY3uhTvNKEVrOXISR6o_mMKCp-nyCxc"><img src="https://private-user-images.githubusercontent.com/18355833/313800351-851be90b-e43a-40ca-ae56-7dc087cf6adc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA4ODA0OTcsIm5iZiI6MTcxMDg4MDE5NywicGF0aCI6Ii8xODM1NTgzMy8zMTM4MDAzNTEtODUxYmU5MGItZTQzYS00MGNhLWFlNTYtN2RjMDg3Y2Y2YWRjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE5VDIwMjk1N1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNmOGEzNTdlMDQ1Yjg4MmVhZTZjYzRmOTVhNTVhMzc4YmNhYWEyOTNmMTExNWQwMWU5ZmVjZTg0ZjU2MGY1NTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ybq2p4QZyKG1FY3uhTvNKEVrOXISR6o_mMKCp-nyCxc" width="350"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance Preview</h2><a id="user-content-performance-preview" aria-label="Permalink: Performance Preview" href="#performance-preview"></a></p>
<p dir="auto">We illustrate a few key results on our <a href="https://microsoft.github.io/garnet/docs/benchmarking/overview" rel="nofollow">website</a> comparing Garnet to leading open-source cache-stores.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design Highlights</h2><a id="user-content-design-highlights" aria-label="Permalink: Design Highlights" href="#design-highlights"></a></p>
<p dir="auto">Garnet’s design re-thinks the entire cache-store stack – from receiving packets on the network, to parsing and processing database operations, to performing storage interactions. We build on
top of years of our <a href="https://microsoft.github.io/FASTER/docs/td-research-papers/" rel="nofollow">prior research</a>. Below is Garnet’s overall architecture.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/18355833/313767776-8d89f719-f86b-4b1f-81d1-1ae7bd450001.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA4ODA0OTcsIm5iZiI6MTcxMDg4MDE5NywicGF0aCI6Ii8xODM1NTgzMy8zMTM3Njc3NzYtOGQ4OWY3MTktZjg2Yi00YjFmLTgxZDEtMWFlN2JkNDUwMDAxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE5VDIwMjk1N1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA5N2NiMjYxMWY1YWZiMDJiYWYxMDEyYTc3ZjkxZDA4NTFiMGZkMmNmZjI2NTIwZTljN2IxZjYzYjg3MjAxMzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.aco7Z0tgyXT5XYytiKFGY4yL8siw7mi8TERZ5Fvao94"><img src="https://private-user-images.githubusercontent.com/18355833/313767776-8d89f719-f86b-4b1f-81d1-1ae7bd450001.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA4ODA0OTcsIm5iZiI6MTcxMDg4MDE5NywicGF0aCI6Ii8xODM1NTgzMy8zMTM3Njc3NzYtOGQ4OWY3MTktZjg2Yi00YjFmLTgxZDEtMWFlN2JkNDUwMDAxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE5VDIwMjk1N1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA5N2NiMjYxMWY1YWZiMDJiYWYxMDEyYTc3ZjkxZDA4NTFiMGZkMmNmZjI2NTIwZTljN2IxZjYzYjg3MjAxMzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.aco7Z0tgyXT5XYytiKFGY4yL8siw7mi8TERZ5Fvao94" width="400"></a>
</p>
<p dir="auto">Garnet’s network layer inherits a shared memory design inspired by our prior research on <a href="https://www.microsoft.com/en-us/research/publication/achieving-high-throughput-and-elasticity-in-a-larger-than-memory-store/" rel="nofollow">ShadowFax</a>. TLS
processing and storage interactions are performed on the IO completion thread, avoiding thread switching overheads in the common case. This approach allows CPU cache coherence to bring the data to the network, instead of traditional
shuffle-based designs, which require data movement on the server.</p>
<p dir="auto">Garnet’s storage design consists of two Tsavorite key-value stores whose fates are bound by a unified operation log. The first store, called the “main store,” is optimized for raw string operations and manages memory carefully to
avoid garbage collection. The second, and optional, “object store” is optimized for complex objects and custom data types, including popular types such as Sorted Set, Set, Hash, List, and Geo. Data types in the object store
leverage the .NET library ecosystem for their current implementations. They are stored on the heap in memory (which makes updates very efficient) and in a serialized form on disk. In the future, we plan to investigate using a
unified index and log to ease maintenance.</p>
<p dir="auto">A distinguishing feature of Garnet’s design is its narrow-waist Tsavorite storage API, which is used to implement the large, rich, and extensible RESP API surface on top. This API consists of read, upsert, delete, and atomic
read-modify-write operations, implemented with asynchronous callbacks for Garnet to interject logic at various points during each operation. Our storage API model allows us to cleanly separate Garnet’s parsing and query
processing concerns from storage details such as concurrency, storage tiering, and checkpointing. Garnet uses two-phase locking for multi-key transactions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cluster Mode</h3><a id="user-content-cluster-mode" aria-label="Permalink: Cluster Mode" href="#cluster-mode"></a></p>
<p dir="auto">In addition to single-node execution, Garnet supports a cluster mode, which allows users to create and manage a sharded and replicated deployment. Garnet also supports an efficient and dynamic key migration scheme
to rebalance shards. Users can use standard Redis cluster commands to create and manage Garnet clusters, and nodes perform gossip to share and evolve cluster state. Cluster is still work in progress.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Next Steps</h2><a id="user-content-next-steps" aria-label="Permalink: Next Steps" href="#next-steps"></a></p>
<p dir="auto">Head over to our <a href="https://microsoft.github.io/garnet" rel="nofollow">documentation</a> site, or jump directly to the <a href="https://microsoft.github.io/garnet/docs/getting-started" rel="nofollow">getting started</a> or
<a href="https://microsoft.github.io/garnet/docs/welcome/releases" rel="nofollow">releases</a> section.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the <a href="https://opensource.org/licenses/MIT" rel="nofollow">MIT License</a>, see the <a href="https://github.com/microsoft/garnet/blob/main/LICENSE">LICENSE</a> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Privacy</h2><a id="user-content-privacy" aria-label="Permalink: Privacy" href="#privacy"></a></p>
<p dir="auto">Privacy information can be found at <a href="https://privacy.microsoft.com/en-us/privacystatement" rel="nofollow">https://privacy.microsoft.com/en-us/</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit <a href="https://cla.opensource.microsoft.com/" rel="nofollow">https://cla.opensource.microsoft.com</a>.</p>
<p dir="auto">When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.</p>
<p dir="auto">This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow">Microsoft Open Source Code of Conduct</a>.
For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow">Code of Conduct FAQ</a> or
contact <a href="mailto:opencode@microsoft.com">opencode@microsoft.com</a> with any additional questions or comments.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Trademarks</h2><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
<a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general" rel="nofollow">Microsoft's Trademark &amp; Brand Guidelines</a>.
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.</p>
<p dir="auto">Redis is a registered trademark of Redis Ltd. Any rights therein are reserved to Redis Ltd. Any use by Microsoft is for referential
purposes only and does not indicate any sponsorship, endorsement or affiliation between Redis and Microsoft.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A star system 3,000 light-years away is predicted to become visible soon (171 pts)]]></title>
            <link>https://blogs.nasa.gov/Watch_the_Skies/2024/02/27/view-nova-explosion-new-star-in-northern-crown/</link>
            <guid>39752168</guid>
            <pubDate>Tue, 19 Mar 2024 01:40:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.nasa.gov/Watch_the_Skies/2024/02/27/view-nova-explosion-new-star-in-northern-crown/">https://blogs.nasa.gov/Watch_the_Skies/2024/02/27/view-nova-explosion-new-star-in-northern-crown/</a>, See on <a href="https://news.ycombinator.com/item?id=39752168">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2185">
	<!-- .entry-header -->

	
	
	<div>
		<p>A star system, located 3,000 light-years away from Earth, is predicted to become visible to the unaided eye soon. This could be a once-in-a-lifetime viewing opportunity as the nova ouburst only occurs about every 80 years. T Coronae Borealis, or T CrB, last exploded in 1946 and astronomers believe it will do so again between February and September 2024.</p>
<figure id="attachment_2186" aria-describedby="caption-attachment-2186"><img decoding="async" src="https://blogs.nasa.gov/Watch_the_Skies/wp-content/uploads/sites/193/2024/02/NovaCygni_ArtistConcept_watermarked.gif" alt="" width="780" height="438"><figcaption id="caption-attachment-2186">A red giant star and white dwarf orbit each other in this animation of a nova. The red giant is a large sphere in shades of red, orange, and white, with the side facing the white dwarf the lightest shades. The white dwarf is hidden in a bright glow of white and yellows, which represent an accretion disk around the star. A stream of material, shown as a diffuse cloud of red, flows from the red giant to the white dwarf. The animation opens with the red giant on the right side of the screen, co-orbiting the white dwarf. When the red giant moves behind the white dwarf, a nova explosion on the white dwarf ignites, filling the screen with white light. After the light fades, a ball of ejected nova material is shown in pale orange. A small white spot remains after the fog of material clears, indicating that the white dwarf has survived the explosion.<br>Credit: NASA’s Goddard Space Flight Center</figcaption></figure>
<p>The star system, normally magnitude +10, which is far too dim to see with the unaided eye, will jump to magnitude +2 during the event. This will be of similar brightness to the North Star, Polaris.</p>
<p>Once its brightness peaks, it should be visible to the unaided eye for several days and just over a week with binoculars before it dims again, possibly for another 80 years.</p>
<p>As we wait for the nova, become familiar with the constellation Corona Borealis, or the Northern Crown — a small, semicircular arc near Bootes and Hercules. This is where the outburst will appear as a “new” bright star.</p>
<figure id="attachment_2187" aria-describedby="caption-attachment-2187"><img decoding="async" loading="lazy" src="https://blogs.nasa.gov/Watch_the_Skies/wp-content/uploads/sites/193/2024/02/FindHercules_NSN896.jpg" alt="" width="780" height="439" srcset="https://blogs.nasa.gov/Watch_the_Skies/wp-content/uploads/sites/193/2024/02/FindHercules_NSN896.jpg 896w, https://blogs.nasa.gov/Watch_the_Skies/wp-content/uploads/sites/193/2024/02/FindHercules_NSN896-300x169.jpg 300w, https://blogs.nasa.gov/Watch_the_Skies/wp-content/uploads/sites/193/2024/02/FindHercules_NSN896-768x432.jpg 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"><figcaption id="caption-attachment-2187">A conceptual image of how to find Hercules and his mighty globular clusters in the sky created using a planetarium software. Look up after sunset during summer months to find Hercules! Scan between Vega and Arcturus, near the distinct pattern of Corona Borealis. Once you find its stars, use binoculars or a telescope to hunt down the globular clusters M13 and M92. If you enjoy your views of these globular clusters, you’re in luck – look for another great globular, M3, in the nearby constellation of Boötes.<br>Credit: NASA</figcaption></figure>
<p>This recurring nova is only one of five in our galaxy. This happens because T CrB is a binary system with a <a href="https://science.nasa.gov/universe/stars/types/#white-dwarfs">white dwarf</a> and <a href="https://science.nasa.gov/universe/stars/types/#red-giants">red giant</a>. The stars are close enough that as the red giant becomes unstable from its increasing temperature and pressure and begins ejecting its outer layers, the white dwarf collects that matter onto its surface. The shallow dense atmosphere of the white dwarf eventually heats enough to cause a runaway thermonuclear reaction – which produces the nova we see from Earth.</p>
<p>Follow <a href="https://twitter.com/NASAUniverse">@NASAUniverse</a> for updates about the outburst.</p>
<p><em>By Lauren Perkins</em><br>
<em>NASA’s</em><em> Marshall Space Flight Center</em></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gaining kernel code execution on an MTE-enabled Pixel 8 (270 pts)]]></title>
            <link>https://github.blog/2024-03-18-gaining-kernel-code-execution-on-an-mte-enabled-pixel-8/</link>
            <guid>39752051</guid>
            <pubDate>Tue, 19 Mar 2024 01:20:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.blog/2024-03-18-gaining-kernel-code-execution-on-an-mte-enabled-pixel-8/">https://github.blog/2024-03-18-gaining-kernel-code-execution-on-an-mte-enabled-pixel-8/</a>, See on <a href="https://news.ycombinator.com/item?id=39752051">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
  
<p>In this post, I’ll look at <a href="https://developer.arm.com/Arm%20Security%20Center/Mali%20GPU%20Driver%20Vulnerabilities#Technical-Specifications">CVE-2023-6241</a>, a vulnerability in the Arm Mali GPU that I reported to Arm on November 15, 2023 and was fixed in the Arm Mali driver version <a href="https://developer.arm.com/downloads/-/mali-drivers/valhall-kernel">r47p0</a>, which was released publicly on December 14, 2023. It was fixed in Android in the <a href="https://source.android.com/docs/security/bulletin/2024-03-01">March security update</a>. When exploited, this vulnerability allows a malicious Android app to gain arbitrary kernel code execution and root on the device. The vulnerability affects devices with newer Arm Mali GPUs that use the <a href="https://community.arm.com/arm-community-blogs/b/graphics-gaming-and-vr-blog/posts/new-suite-of-arm-mali-gpus">Command Stream Frontend (CSF)</a> feature, such as Google’s Pixel 7 and Pixel 8 phones. What is interesting about this vulnerability is that it is a logic bug in the memory management unit of the Arm Mali GPU and it is capable of bypassing <a href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/enhancing-memory-safety">Memory Tagging Extension (MTE)</a>, a new and powerful mitigation against memory corruption that was first supported in Pixel 8. In this post, I’ll show how to use this bug to gain arbitrary kernel code execution in the Pixel 8 from an untrusted user application. I have confirmed that the exploit works successfully even with kernel MTE enabled by following <a href="https://outflux.net/blog/archives/2023/10/26/enable-mte-on-pixel-8/">these instructions</a>.</p>
<h2 id="arm64-mte">Arm64 MTE<a href="#arm64-mte" aria-label="Arm64 MTE"></a></h2>
<p>MTE is a very well documented feature on newer Arm processors that uses hardware implementations to check for memory corruption. As there are already many good articles about MTE, I’ll only briefly go through the idea of MTE and explain its significance in comparison to other mitigations for memory corruption. Readers who are interested in more details can, for example, consult <a href="https://lwn.net/Articles/834289/">this article</a> and the <a href="https://developer.arm.com/documentation/102925/latest/">whitepaper</a> released by Arm.</p>
<p>While the Arm64 architecture uses 64 bit pointers to access memory, there is usually no need to use such a large address space. In practice, most applications use a much smaller address space (usually 52 bits or less). This leaves the highest bits in a pointer unused. The main idea of memory tagging is to use these higher bits in an address to store a “tag” that can then be used to check against the other tag stored in the memory block associated with the address. The helps to mitigate common types of memory corruptions as follows:</p>
<p>In the case of a linear overflow, a pointer is used to dereference an adjacent memory block that has a different tag compared to the one stored in the pointer. By checking these tags at dereference time, the corrupted dereference can be detected. For use-after-free type memory corruptions, as long as the tag in a memory block is cleared every time it is freed and a new tag reassigned when it is allocated, dereferencing an already freed and reclaimed object will also lead to a discrepancy between pointer tag and the tag in memory, which allows use-after-free to be detected.</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image1_d13e94.png?w=1024&amp;resize=1024%2C795" alt="" width="1024" height="795" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image1_d13e94.png?w=1040 1040w, https://github.blog/wp-content/uploads/2024/03/image1_d13e94.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image1_d13e94.png?w=768 768w, https://github.blog/wp-content/uploads/2024/03/image1_d13e94.png?w=1024&amp;resize=1024%2C795 1024w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></p>
<p><em>(The above image is from <a href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/enhancing-memory-safety">Memory Tagging Extension: Enhancing memory safety through architecture</a> published by Arm.)</em></p>
<p>The main reason that memory tagging is different from previous mitigations, such as <a href="https://source.android.com/docs/security/test/kcfi">Kernel Control Flow Integrity (kCFI)</a> is that, unlike other mitigations, which disrupts later stages of an exploit, MTE is a very early stage mitigation that tries to catch memory corruption when it first happens. As such, it is able to stop an exploit in a very early stage before the attacker has gained any capabilities and it is therefore very difficult to bypass. It introduces checks that effectively turns an unsafe memory language into one that is memory safe, albeit probabilistically.</p>
<p>In theory, memory tagging can be implemented in software alone, by making the memory allocator assign and remove tags everytime memory is allocated or free, and by adding tag checking logic when dereferencing pointers. Doing so, however, incurs a performance cost that makes it unsuitable for production use. As a result, hardware implementation is needed to reduce the performance cost and to make memory tagging viable for production use. The hardware support was introduced in the <a href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-a-profile-architecture-2018-developments-armv85a">v8.5a version</a> of the ARM architecture, in which extra hardware instructions (called MTE) were introduced to perform tagging and checking. For Android devices, most chipsets that support MTE use Arm v9 processors (instead of Arm v8.5a), and currently there are only a handful of devices that support MTE.</p>
<p>One of the limitations of MTE is that the number of available unused bits is small compared to all possible memory blocks that can ever be allocated. As such, tag collision is inevitable and many memory blocks will have the same tag. This means that a corrupted memory access may still succeed by chance. In practice, even when using only 4 bits for the tag, the success rate is reduced to 1/16, which is still a fairly strong protection against memory corruption. Another limitation is that, by leaking pointer and memory block values using side channel attack such as Spectre, an attacker may be able to ensure that a corrupted memory access is done with the correct tag and thus bypasses MTE. This type of leak, however, is mostly only available to a local attacker. The series of articles, <a href="https://googleprojectzero.blogspot.com/2023/08/mte-as-implemented-part-1.html">MTE As Implemented</a> by Mark Brand, includes an in-depth study of the limitations and impact of MTE on various attack scenarios.</p>
<p>Apart from having hardware that uses processors that implements Arm v8.5a or above, software support is also required to enable MTE. Currently, only Google’s Pixel 8 allows users to <a href="https://googleprojectzero.blogspot.com/2023/11/first-handset-with-mte-on-market.html">enable MTE in the developer options</a> and MTE is disabled by default. Extra steps are also required to <a href="https://outflux.net/blog/archives/2023/10/26/enable-mte-on-pixel-8/">enable MTE in the kernel</a>.</p>
<h2 id="the-arm-mali-gpu">The Arm Mali GPU<a href="#the-arm-mali-gpu" aria-label="The Arm Mali GPU"></a></h2>
<p>The Arm Mali GPU can be integrated in various devices, (for example, see “Implementations” in <a href="https://en.wikipedia.org/wiki/Mali_(GPU)">Mali (GPU) Wikipedia entry</a>). It has been an attractive target on Android phones and has been targeted by in-the-wild exploits multiple times. The current vulnerability is closely related to <a href="https://github.blog/2023-04-06-pwning-pixel-6-with-a-leftover-patch/">another issue</a> that I reported and is a vulnerability in the handling of a type of GPU memory called JIT memory. I’ll now briefly explain JIT memory and explain the vulnerability CVE-2023-6241.</p>
<h2 id="jit-memory-in-arm-mali">JIT memory in Arm Mali<a href="#jit-memory-in-arm-mali" aria-label="JIT memory in Arm Mali"></a></h2>
<p>When using the Mali GPU driver, a user app first needs to create and initialize a <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_defs.h#2061"><code>kbase_context</code></a> kernel object. This involves the user app opening the driver file and using the resulting file descriptor to make a series of <code>ioctl</code> calls. A <code>kbase_context</code> object is responsible for managing resources for each driver file that is opened and is unique for each file handle.</p>
<p>In particular, the <code>kbase_context</code> manages different types of memory that are shared between the GPU device and user space applications. User applications can either map their own memory to the memory space of the GPU so the GPU can access this memory, or they can allocate memory from the GPU. Memory allocated by the GPU is managed by the <code>kbase_context</code> and can be mapped to the GPU memory space and also mapped to user space. A user application can also use the GPU to access mapped memory by submitting commands to the GPU. In general, memory needs to be either allocated and managed by the GPU (native memory) or imported to the GPU from user space, and then mapped to the GPU address space before it can be accessed by the GPU. A memory region in the Mali GPU is represented by the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.h#649"><code>kbase_va_region</code></a>. Similar to virtual memory in the CPU, a memory region in the GPU may not have its entire range backed by physical memory. The <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.h#655"><code>nr_pages</code></a> field in a <code>kbase_va_region</code> specifies the virtual size of the memory region, whereas <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.h#661"><code>gpu_alloc-&gt;nents</code></a> is the actual number of physical pages that are backing the region. I’ll refer to these pages as the backing pages of the region from now on. While the virtual size of a memory region is fixed, its physical size can change. From now on, when I use terminologies such as resize, grow and shrink regarding a memory region, what I mean is that the physical size of the region is resizing, growing or shrinking.</p>
<p>The JIT memory is a type of native memory whose lifetime is managed by the kernel driver. User applications request the GPU to allocate and free JIT memory by sending relevant commands to the GPU. While most commands, such as those using GPU to perform arithmetic and memory accesses are executed on the GPU itself, there are some commands, such as the ones used for managing JIT memory, that are implemented in the kernel and executed on the CPU. These are called software commands (in contrast to hardware commands that are executed on the GPU (hardware)). On GPUs that use the Command Stream Frontend (CSF), software commands and hardware commands are placed on different types of command queues. To submit a software command, a <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/csf/mali_kbase_csf_kcpu.h#296"><code>kbase_kcpu_command_queue</code></a> is needed and it can be created by using the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_core_linux.c#2312"><code>KBASE_IOCTL_KCPU_QUEUE_CREATE</code></a> <code>ioctl</code>. A software command can then be queued using the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_core_linux.c#2324"><code>KBASE_IOCTL_KCPU_QUEUE_ENQUEUE</code></a> command. To allocate or free JIT memory, commands of type <code>BASE_KCPU_COMMAND_TYPE_JIT_ALLOC</code> and <code>BASE_KCPU_COMMAND_TYPE_JIT_FREE</code> can be used.</p>
<p>The <code>BASE_KCPU_COMMAND_TYPE_JIT_ALLOC</code> command uses <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.c#4332"><code>kbase_jit_allocate</code></a> to allocate JIT memory. Similarly, the command <code>BASE_KCPU_COMMAND_TYPE_JIT_FREE</code> can be used to free JIT memory. As explained in the section “<a href="https://github.blog/2023-01-23-pwning-the-all-google-phone-with-a-non-google-bug/#the-life-cycle-of-jit-memory">The life cycle of JIT memory</a>” in one of my previous posts, when JIT memory is freed, it goes into a memory pool managed by the <code>kbase_context</code> and when <code>kbase_jit_allocate</code> is called, it first looks into this memory pool to see if there is any suitable freed JIT memory that can be reused:</p>
<pre><code>
struct kbase_va_region *kbase_jit_allocate(struct kbase_context *kctx,
    const struct base_jit_alloc_info *info,
    bool ignore_pressure_limit)
{
  ...
  kbase_gpu_vm_lock(kctx);
  mutex_lock(&amp;kctx-&gt;jit_evict_lock);
  /*
   * Scan the pool for an existing allocation which meets our
   * requirements and remove it.
   */
  if (info-&gt;usage_id != 0)
    /* First scan for an allocation with the same usage ID */
    reg = find_reasonable_region(info, &amp;kctx-&gt;jit_pool_head, false);
  ...
}
</code></pre>
<p>If an existing region is found and its virtual size matches the request, but its physical size is too small, then <code>kbase_jit_allocate</code> will attempt to allocate more physical pages to back the region by calling <code>kbase_jit_grow</code>:</p>
<pre><code>
struct kbase_va_region *kbase_jit_allocate(struct kbase_context *kctx,
    const struct base_jit_alloc_info *info,
    bool ignore_pressure_limit)
{
    ...
    /* kbase_jit_grow() can release &amp; reacquire 'kctx-&gt;reg_lock',
     * so any state protected by that lock might need to be
     * re-evaluated if more code is added here in future.
     */
    ret = kbase_jit_grow(kctx, info, reg, prealloc_sas,
             mmu_sync_info);
   ...
}
</code></pre>
<p>If, on the other hand, no suitable region is found, <code>kbase_jit_allocate</code> will allocate JIT memory from scratch:</p>
<pre><code>
struct kbase_va_region *kbase_jit_allocate(struct kbase_context *kctx,
    const struct base_jit_alloc_info *info,
    bool ignore_pressure_limit)
{
    ...
  } else {
    /* No suitable JIT allocation was found so create a new one */
    u64 flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_GPU_RD |
        BASE_MEM_PROT_GPU_WR | BASE_MEM_GROW_ON_GPF |
        BASE_MEM_COHERENT_LOCAL |
        BASEP_MEM_NO_USER_FREE;
    u64 gpu_addr;
        ...
    mutex_unlock(&amp;kctx-&gt;jit_evict_lock);
    kbase_gpu_vm_unlock(kctx);
    reg = kbase_mem_alloc(kctx, info-&gt;va_pages, info-&gt;commit_pages, info-&gt;extension,
              &amp;flags, &amp;gpu_addr, mmu_sync_info);
   ...
}
</code></pre>
<p>As we can see from the comment above the call to <code>kbase_jit_grow</code>, <code>kbase_jit_grow</code> can temporarily drop the <code>kctx-&gt;reg_lock</code>:</p>
<pre><code>
static int kbase_jit_grow(struct kbase_context *kctx,
 const struct base_jit_alloc_info *info,
 struct kbase_va_region *reg,
 struct kbase_sub_alloc **prealloc_sas,
 enum kbase_caller_mmu_sync_info mmu_sync_info)
{
    ...
  if (!kbase_mem_evictable_unmake(reg-&gt;gpu_alloc))
    goto update_failed;
    ...
  old_size = reg-&gt;gpu_alloc-&gt;nents;                      //commit_pages - reg-&gt;gpu_alloc-&gt;nents;    //&lt;---------2.
  pages_required = delta;
    ...
  while (kbase_mem_pool_size(pool) mem_partials_lock);
    kbase_gpu_vm_unlock(kctx);                        //&lt;---------- lock dropped.
    ret = kbase_mem_pool_grow(pool, pool_delta);
    kbase_gpu_vm_lock(kctx);
        ...
}
</code></pre>
<p>In the above, we see that <code>kbase_gpu_vm_unlock</code> is called to temporarily drop the <code>kctx-&gt;reg_lock</code>, while <code>kctx-&gt;mem_partials_lock</code> is also dropped during a call to <code>kbase_mem_pool_grow</code>. In the Mali GPU, the <code>kctx-&gt;reg_lock</code> is used for protecting concurrent accesses to memory regions. So, for example, when <code>kctx-&gt;reg_lock</code> is held, the physical size of the memory region cannot be changed by another thread. In <a href="https://github.blog/2023-04-06-pwning-pixel-6-with-a-leftover-patch/">GHSL-2023-005</a> that I reported previously, I was able to trigger a race so that the JIT region was shrunk by using the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem_linux.c#2224"><code>KBASE_IOCTL_MEM_COMMIT</code></a> <code>ioctl</code> from another thread while <code>kbase_mem_pool_grow</code> was running. This change in the size of the JIT region caused <code>reg-&gt;gpu_alloc-&gt;nents</code> to change after <code>kbase_mem_pool_grow</code>, meaning that the actual value of <code>reg-&gt;gpu_alloc-&gt;nents</code> was then different from the value that was cached in <code>old_size</code> and <code>delta</code> (1. and 2. in the above). As these values were later used to allocate and map the JIT region, using these stale values caused inconsistency in the GPU memory mapping, causing GHSL-2023-005.</p>
<pre><code>
static int kbase_jit_grow(struct kbase_context *kctx,
 const struct base_jit_alloc_info *info,
 struct kbase_va_region *reg,
 struct kbase_sub_alloc **prealloc_sas,
 enum kbase_caller_mmu_sync_info mmu_sync_info)
{
    ...
   //grow memory pool
    ...
    //delta use for allocating pages
    gpu_pages = kbase_alloc_phy_pages_helper_locked(reg-&gt;gpu_alloc, pool,
            delta, &amp;prealloc_sas[0]);
    ...
    //old_size used for growing gpu mapping
    ret = kbase_mem_grow_gpu_mapping(kctx, reg, info-&gt;commit_pages,
            old_size);
    ...
}
</code></pre>
<p>After GHSL-2023-005 was patched, it was no longer possible to change the size of JIT memory using the <code>KBASE_IOCTL_MEM_COMMIT ioctl</code>.</p>
<h2 id="the-vulnerability">The vulnerability<a href="#the-vulnerability" aria-label="The vulnerability"></a></h2>
<p>Similar to virtual memory, when an address in a memory region that is not backed by a physical page is accessed by the GPU, a memory access fault happens. In this case, depending on the type of the memory region, it may be possible to allocate and map a physical page on the fly to back the fault address. A GPU memory access fault is handled by the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mmu/mali_kbase_mmu.c#974"><code>kbase_mmu_page_fault_worker</code></a>:</p>
<pre><code>
void kbase_mmu_page_fault_worker(struct work_struct *data)
{
    ...
    kbase_gpu_vm_lock(kctx);
    ...
  if ((region-&gt;flags &amp; GROWABLE_FLAGS_REQUIRED)
      != GROWABLE_FLAGS_REQUIRED) {
    kbase_gpu_vm_unlock(kctx);
    kbase_mmu_report_fault_and_kill(kctx, faulting_as,
        "Memory is not growable", fault);
    goto fault_done;
  }

  if ((region-&gt;flags &amp; KBASE_REG_DONT_NEED)) {
    kbase_gpu_vm_unlock(kctx);
    kbase_mmu_report_fault_and_kill(kctx, faulting_as,
        "Don't need memory can't be grown", fault);
    goto fault_done;
  }

    ...
  spin_lock(&amp;kctx-&gt;mem_partials_lock);
  grown = page_fault_try_alloc(kctx, region, new_pages, &amp;pages_to_grow,
      &amp;grow_2mb_pool, prealloc_sas);
  spin_unlock(&amp;kctx-&gt;mem_partials_lock);
    ...
}
</code></pre>
<p>Within the fault handler, a number of checks are performed to ensure that the memory region is allowed to grow in size. The two checks that are relevant to JIT memory are the checks for the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_defs.h#111"><code>GROWABLE_FLAGS_REQUIRED</code></a> and the <code>KBASE_REG_DONT_NEED</code> flags. The <code>GROWABLE_FLAGS_REQUIRED</code> is defined as follows:</p>
<pre><code>#define GROWABLE_FLAGS_REQUIRED (KBASE_REG_PF_GROW | KBASE_REG_GPU_WR)
</code></pre>
<p>These flags are added to a JIT region when it is created by <code>kbase_jit_allocate</code> and are never changed:</p>
<pre><code>
struct kbase_va_region *kbase_jit_allocate(struct kbase_context *kctx,
    const struct base_jit_alloc_info *info,
    bool ignore_pressure_limit)
{
    ...
  } else {
    /* No suitable JIT allocation was found so create a new one */
    u64 flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_GPU_RD |
        BASE_MEM_PROT_GPU_WR | BASE_MEM_GROW_ON_GPF |      //jit_evict_lock);
    kbase_gpu_vm_unlock(kctx);
    reg = kbase_mem_alloc(kctx, info-&gt;va_pages, info-&gt;commit_pages, info-&gt;extension,
              &amp;flags, &amp;gpu_addr, mmu_sync_info);
   ...
}
</code></pre>
<p>While the <code>KBASE_REG_DONT_NEED</code> flag is added to a JIT region when it is freed, it is removed in <code>kbase_jit_grow</code> well before the <code>kctx-&gt;reg_lock</code> and <code>kctx-&gt;mem_partials_lock</code> are dropped and <code>kbase_mem_pool_grow</code> is called:</p>
<pre><code>
static int kbase_jit_grow(struct kbase_context *kctx,
 const struct base_jit_alloc_info *info,
 struct kbase_va_region *reg,
 struct kbase_sub_alloc **prealloc_sas,
 enum kbase_caller_mmu_sync_info mmu_sync_info)
{
  ...
  if (!kbase_mem_evictable_unmake(reg-&gt;gpu_alloc))    //&lt;----- Remove KBASE_REG_DONT_NEED
  goto update_failed;
    ...
  while (kbase_mem_pool_size(pool) mem_partials_lock);
    kbase_gpu_vm_unlock(kctx);
    ret = kbase_mem_pool_grow(pool, pool_delta);      //&lt;----- race window: fault handler grows region
    kbase_gpu_vm_lock(kctx);
        ...
}
</code></pre>
<p>In particular, during the race window marked in the above snippet, the JIT memory reg is allowed to grow when a page fault happens.</p>
<p>So, by accessing unmapped memory in the region to create a fault on another thread while <code>kbase_mem_pool_grow</code> is running, I can cause the JIT region to be grown by the GPU fault handler while <code>kbase_mem_pool_grow</code> runs. This then changes <code>reg-&gt;gpu_alloc-&gt;nents</code> and invalidates <code>old_size</code> and <code>delta</code> in 1. and 2. below:</p>
<pre><code>
static int kbase_jit_grow(struct kbase_context *kctx,
 const struct base_jit_alloc_info *info,
 struct kbase_va_region *reg,
 struct kbase_sub_alloc **prealloc_sas,
 enum kbase_caller_mmu_sync_info mmu_sync_info)
{
    ...
  if (!kbase_mem_evictable_unmake(reg-&gt;gpu_alloc))
    goto update_failed;
    ...
  old_size = reg-&gt;gpu_alloc-&gt;nents;                      //commit_pages - reg-&gt;gpu_alloc-&gt;nents;    //&lt;---------2.
  pages_required = delta;
    ...
  while (kbase_mem_pool_size(pool) mem_partials_lock);
    kbase_gpu_vm_unlock(kctx);
    ret = kbase_mem_pool_grow(pool, pool_delta);  //gpu_alloc-&gt;nents changed by fault handler
    kbase_gpu_vm_lock(kctx);
        ...
   //delta use for allocating pages
    gpu_pages = kbase_alloc_phy_pages_helper_locked(reg-&gt;gpu_alloc, pool,   //commit_pages,         //&lt;----- 4.
            old_size);
    ...
}
</code></pre>
<p>As a result, when <code>delta</code> and <code>old_size</code> are used in 3. and 4. to allocate backing pages and to map the pages to the GPU memory space, their values are invalid.</p>
<p>This is very similar to what happened with GHSL-2023-005. As <code>kbase_mem_pool_grow</code> involves large memory allocations, this race can be won very easily. There is, however, one very big difference here: With GHSL-2023-005, I was able to shrink the JIT region while in this case, I was only able to grow the JIT region. To understand why this matters, let’s have a brief recap of how my exploit for GHSL-2023-005 worked.</p>
<p>As mentioned before, the physical size, or the number of backing pages of a <code>kbase_va_region</code> is stored in the field <code>reg-&gt;gpu_alloc-&gt;nents</code>. A <code>kbase_va_region</code> has two <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.h#315"><code>kbase_mem_phy_alloc</code></a> objects: the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.h#660"><code>cpu_alloc</code></a> and <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem.h#660"><code>gpu_alloc</code></a> that are responsible for managing its backing pages. For Android devices, these two fields are configured to be the same. Within <code>kbase_mem_phy_alloc</code>, the field <code>pages</code> is an array that contains the physical addresses of the backing pages, while <code>nents</code> specifies the length of the <code>pages</code> array:</p>
<pre><code>
struct kbase_mem_phy_alloc {
    ...
  size_t                nents;
  struct tagged_addr    *pages;
    ...
}
</code></pre>
<p>When <code>kbase_alloc_phy_pages_helper_locked</code> is called, it allocates memory pages and appends the physical addresses represented by these pages to the array <code>pages</code>, so the new pages are added to the index <code>nents</code> onwards. The new size is then stored to <code>nents</code>. For example, when it is called in <code>kbase_jit_grow</code>, <code>delta</code> is the number of pages to add:</p>
<pre><code>
static int kbase_jit_grow(struct kbase_context *kctx,
 const struct base_jit_alloc_info *info,
 struct kbase_va_region *reg,
 struct kbase_sub_alloc **prealloc_sas,
 enum kbase_caller_mmu_sync_info mmu_sync_info)
{
    ...
   //delta use for allocating pages
    gpu_pages = kbase_alloc_phy_pages_helper_locked(reg-&gt;gpu_alloc, pool,
            delta, &amp;prealloc_sas[0]);
    ...
}
</code></pre>
<p>In this case, <code>delta</code> pages are inserted at the index <code>nents</code> in the array <code>pages</code> of <code>gpu_alloc</code>:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image13.png?w=955&amp;resize=955%2C274" alt="" width="955" height="274" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image13.png?w=955&amp;resize=955%2C274 955w, https://github.blog/wp-content/uploads/2024/03/image13.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image13.png?w=768 768w" sizes="(max-width: 955px) 100vw, 955px" data-recalc-dims="1"></p>
<p>After the backing pages are allocated and inserted into the <code>pages</code> array, the new pages are mapped to the GPU address space by calling <code>kbase_mem_grow_gpu_mapping</code>. The virtual address of a <code>kbase_va_region</code> in the GPU memory space is managed by the <code>kbase_va_region</code> itself and is stored in the fields <code>start_pfn</code> and <code>nr_pages</code>:</p>
<pre><code>
struct kbase_va_region {
    ...
  u64 start_pfn;
    ...
  size_t nr_pages;
    ...
}
</code></pre>
<p>The start of the virtual address of a <code>kbase_va_region</code> is stored in <code>start_pfn</code> (as a page frame, so the actual address is <code>start_pfn &gt;&gt; PAGE_SIZE</code>) while <code>nr_pages</code> stores the size of the region. These fields remain unchanged after they are set. Within a <code>kbase_va_region</code>, the initial <code>reg-&gt;gpu_alloc-&gt;nents</code> pages in the virtual address space are backed by the physical memory stored in the <code>pages</code> array of <code>gpu_alloc-&gt;pages</code>, while the rest of the addresses are not backed. In particular, the virtual addresses that are backed are always contiguous (so, no gaps between backed regions) and always start from the start of the region. For example, the following is possible:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image2_5395a6.png?w=825&amp;resize=825%2C267" alt="" width="825" height="267" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image2_5395a6.png?w=825&amp;resize=825%2C267 825w, https://github.blog/wp-content/uploads/2024/03/image2_5395a6.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image2_5395a6.png?w=768 768w" sizes="(max-width: 825px) 100vw, 825px" data-recalc-dims="1"></p>
<p>While the following case is not allowed because the backing does not start from the beginning of the region:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image18.png?w=843&amp;resize=843%2C270" alt="" width="843" height="270" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image18.png?w=843&amp;resize=843%2C270 843w, https://github.blog/wp-content/uploads/2024/03/image18.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image18.png?w=768 768w" sizes="(max-width: 843px) 100vw, 843px" data-recalc-dims="1"></p>
<p>and this following case is also not allowed because of the gaps in the addresses that are backed:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image19.png?w=834&amp;resize=834%2C260" alt="" width="834" height="260" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image19.png?w=834&amp;resize=834%2C260 834w, https://github.blog/wp-content/uploads/2024/03/image19.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image19.png?w=768 768w" sizes="(max-width: 834px) 100vw, 834px" data-recalc-dims="1"></p>
<p>In the case when <code>kbase_mem_grow_gpu_mapping</code> is called in <code>kbase_jit_grow</code>, the GPU addresses between <code>(start_pfn + old_size) * 0x1000</code> to <code>(start_pfn + info-&gt;commit_pages) * 0x1000</code> are mapped to the newly added pages in <code>gpu_alloc-&gt;pages</code>, which are the pages between indices <code>pages + old_size</code> and <code>pages + info-&gt;commit_pages</code> (because <code>delta = info-&gt;commit_pages - old_size</code>):</p>
<pre><code>
static int kbase_jit_grow(struct kbase_context *kctx,
 const struct base_jit_alloc_info *info,
 struct kbase_va_region *reg,
 struct kbase_sub_alloc **prealloc_sas,
 enum kbase_caller_mmu_sync_info mmu_sync_info)
{
    ...
    old_size = reg-&gt;gpu_alloc-&gt;nents;
    delta = info-&gt;commit_pages - reg-&gt;gpu_alloc-&gt;nents;
    ...
    //old_size used for growing gpu mapping
    ret = kbase_mem_grow_gpu_mapping(kctx, reg, info-&gt;commit_pages,
            old_size);
    ...
}
</code></pre>
<p>In particular, <code>old_size</code> here is used to specify both the GPU address where the new mapping should start, and also the offset from the <code>pages</code> array where backing pages should be used.</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image11.png?w=826&amp;resize=826%2C445" alt="" width="826" height="445" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image11.png?w=826&amp;resize=826%2C445 826w, https://github.blog/wp-content/uploads/2024/03/image11.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image11.png?w=768 768w" sizes="(max-width: 826px) 100vw, 826px" data-recalc-dims="1"></p>
<p>If <code>reg-&gt;gpu_alloc-&gt;nents</code> changes after <code>old_size</code> and <code>delta</code> are cached, then these offsets may become invalid. For example, if the <code>kbase_va_region</code> was shrunk and <code>nents</code> decreased after <code>old_size</code> and <code>delta</code> were stored, then <code>kbase_alloc_phy_pages_helper_locked</code> will insert <code>delta</code> pages to <code>reg-&gt;gpu_alloc-&gt;pages + nents</code>:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image12.png?w=947&amp;resize=947%2C345" alt="" width="947" height="345" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image12.png?w=947&amp;resize=947%2C345 947w, https://github.blog/wp-content/uploads/2024/03/image12.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image12.png?w=768 768w" sizes="(max-width: 947px) 100vw, 947px" data-recalc-dims="1"></p>
<p>Similarly, <code>kbase_mem_grow_gpu_mapping</code> will map the GPU addresses starting from <code>(start_pfn + old_size) * 0x1000</code>, using the pages that are between <code>reg-&gt;gpu_alloc-&gt;pages + old_size</code> and <code>reg-&gt;gpu_alloc-&gt;pages + nents + delta</code> (dotted lines in the figure below). This means that the pages between <code>pages-&gt;nents</code> and <code>pages-&gt;old_size</code> don’t end up getting mapped to any GPU addresses, while some addresses end up having no backing pages:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/image17.png?w=960&amp;resize=960%2C540" alt="" width="960" height="540" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/image17.png?w=960&amp;resize=960%2C540 960w, https://github.blog/wp-content/uploads/2024/03/image17.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/image17.png?w=768 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></p>
<h2 id="exploiting-ghsl-2023-005">Exploiting GHSL-2023-005<a href="#exploiting-ghsl-2023-005" aria-label="Exploiting GHSL-2023-005"></a></h2>
<p>GHSL-2023-005 enabled me to shrink the JIT region but CVE-2023-6241 does not give me that capability. To understand how to exploit this issue, we need to know a bit more about how GPU mappings are removed. The function <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mmu/mali_kbase_mmu.c#2908"><code>kbase_mmu_teardown_pgd_pages</code></a> is responsible for removing address mappings from the GPU. This function essentially walks through a GPU address range and removes the addresses from the GPU page table by marking them as invalid. If it encounters a high level page table entry (PTE), which covers a large range of addresses, and finds that the entry is invalid, then it’ll skip removing the entire range of addresses covered by the entry. For example, a level 2 page table entry covers a range of 512 pages, so if a level 2 page table entry is found to be invalid (1. in the below), then <code>kbase_mmu_teardown_pgd_pages</code> will assume the next 512 pages are covered by this level 2 and hence are all invalid already. As such, it’ll skip removing these pages (2. in the below).</p>
<pre><code>
static int kbase_mmu_teardown_pgd_pages(struct kbase_device *kbdev, struct kbase_mmu_table *mmut,
          u64 vpfn, size_t nr, u64 *dirty_pgds,
          struct list_head *free_pgds_list,
          enum kbase_mmu_op_type flush_op)
{
        ...
        for (level = MIDGARD_MMU_TOPLEVEL;
                level ate_is_valid(page[index], level))
                break; /* keep the mapping */
            else if (!mmu_mode-&gt;pte_is_valid(page[index], level)) {  //&lt;------ 1.
                /* nothing here, advance */
                switch (level) {
                ...
                case MIDGARD_MMU_LEVEL(2):
                    count = 512;            // nr)
                    count = nr;
                goto next;
            }
        ...
next:
        kunmap(phys_to_page(pgd));
        vpfn += count;
        nr -= count;
</code></pre>
<p>The function <code>kbase_mmu_teardown_pgd_pages</code> is called either when a <code>kbase_va_region</code> is shrunk or when it is deleted. As explained in the previous section, the virtual addresses in a <code>kbase_va_region</code> that are mapped and backed by physical pages must be contiguous from the start of the <code>kbase_va_region</code>. As a result, if any address in the region is mapped, then the start address must be mapped and hence the high level page table entry covering the start address must be valid (if no address in the region is mapped, then <code>kbase_mmu_teardown_pgd_pages</code> would not even be called):</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-5.png?w=855&amp;resize=855%2C341" alt="" width="855" height="341" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-5.png?w=855&amp;resize=855%2C341 855w, https://github.blog/wp-content/uploads/2024/03/unnamed-5.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-5.png?w=768 768w" sizes="(max-width: 855px) 100vw, 855px" data-recalc-dims="1"></p>
<p>In the above, the level 2 PTE that covers the start address of the region is mapped and so it is valid, therefore in this case, if <code>kbase_mmu_teardown_pgd_pages</code> ever encounters an unmapped high level PTE, the rest of the addresses in the <code>kbase_va_region</code> must have already been unmapped and can be skipped safely.</p>
<p>In the case where a region is shrunk, the address where the unmapping starts lies within the <code>kbase_va_region</code>, and the entire range between this start address and the end of the region will be unmapped. If the level 2 page table entry covering this address is invalid, then the start address must be in a region that is not mapped, and hence the rest of the address range to unmap must also not have been mapped. In this case, skipping of addresses is again safe:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-6.png?w=852&amp;resize=852%2C336" alt="" width="852" height="336" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-6.png?w=852&amp;resize=852%2C336 852w, https://github.blog/wp-content/uploads/2024/03/unnamed-6.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-6.png?w=768 768w" sizes="(max-width: 852px) 100vw, 852px" data-recalc-dims="1"></p>
<p>So, as long as regions are only mapped from their start addresses and have no gaps in the mappings, <code>kbase_mmu_teardown_pgd_pages</code> will behave correctly.</p>
<p>In the case of GHSL-2023-005, it is possible to create a region that does not meet these conditions. For example, by shrinking the entire region to size zero during the race window, it is possible to create a region where the start of the region is unmapped:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-7.png?w=960&amp;resize=960%2C540" alt="" width="960" height="540" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-7.png?w=960&amp;resize=960%2C540 960w, https://github.blog/wp-content/uploads/2024/03/unnamed-7.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-7.png?w=768 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></p>
<p>When the region is deleted, and <code>kbase_mmu_teardown_pgd_pages</code> tries to remove the first address, because the level 2 PTE is invalid, it’ll skip the next 512 pages, some of which may actually have been mapped:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-8.png?w=848&amp;resize=848%2C469" alt="" width="848" height="469" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-8.png?w=848&amp;resize=848%2C469 848w, https://github.blog/wp-content/uploads/2024/03/unnamed-8.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-8.png?w=768 768w" sizes="(max-width: 848px) 100vw, 848px" data-recalc-dims="1"></p>
<p>In this case, addresses in the “incorrectly skipped” region will remain mapped to some entries in the <code>pages</code> array in the <code>gpu_alloc</code>, which are already freed. And these “incorrectly skipped” GPU addresses can be used to access already freed memory pages.</p>
<h2 id="exploiting-cve-2023-6241">Exploiting CVE-2023-6241<a href="#exploiting-cve-2023-6241" aria-label="Exploiting CVE-2023-6241"></a></h2>
<p>The situation, however, is very different when a region is grown during the race window. In this case, <code>nents</code> is larger than <code>old_size</code> when <code>kbase_alloc_phy_pages_helper_locked</code> and <code>kbase_mem_grow_gpu_mapping</code> are called, and <code>delta</code> pages are being inserted at index <code>nents</code> of the <code>pages</code> array:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-9.png?w=769&amp;resize=769%2C330" alt="" width="769" height="330" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-9.png?w=769&amp;resize=769%2C330 769w, https://github.blog/wp-content/uploads/2024/03/unnamed-9.png?w=300 300w" sizes="(max-width: 769px) 100vw, 769px" data-recalc-dims="1"></p>
<p>The <code>pages</code> array contains the correct number of pages to backup both the jit grow and the fault access, and is in fact exactly how it should be when <code>kbase_jit_grow</code> is called after the page fault handler.</p>
<p>When <code>kbase_mem_grow_gpu_mapping</code> is called, <code>delta</code> pages are mapped to the GPU from <code>(start_pfn + old_size) * 0x1000</code>. As the total number of backing pages has now increased by <code>fh + delta</code>, where <code>fh</code> is the number of pages added by the fault handler, this leaves the last <code>fh</code> pages in the <code>pages</code> array unmapped.</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-10.png?w=799&amp;resize=799%2C504" alt="" width="799" height="504" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-10.png?w=799&amp;resize=799%2C504 799w, https://github.blog/wp-content/uploads/2024/03/unnamed-10.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-10.png?w=768 768w" sizes="(max-width: 799px) 100vw, 799px" data-recalc-dims="1"></p>
<p>This, however, does not seem to create any problem either. The memory region still only has its start addresses mapped and there is no gap in the mapping. The pages that are not mapped are simply not accessible from the GPU and will get freed when the memory region is deleted, so it isn’t even a memory leak issue.</p>
<p>However, not all is lost. As we have seen, when a GPU page fault happens, if the cause of the fault is that the address is not mapped, then the fault handler will try to add backing pages to the region and map these new pages to the extent of the region. If the fault address is, say <code>fault_addr</code>, then the minimum number of pages to add is <code>new_pages = fault_addr/0x1000 - reg-&gt;gpu_alloc-&gt;nents</code>. Depending on the <code>kbase_va_region</code>, some padding may also be added. In any case, these new pages will be mapped to the GPU, starting from the address <code>(start_pfn + reg-&gt;gpu_alloc-&gt;nents) * 0x1000</code>, so as to preserve the fact that only the addresses at the start of a region are mapped.</p>
<p>This means that, if I trigger another GPU fault in the JIT region that was affected by the bug, then some new mappings will be added <em>after</em> the region that is not mapped.</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-11.png?w=960&amp;resize=960%2C540" alt="" width="960" height="540" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-11.png?w=960&amp;resize=960%2C540 960w, https://github.blog/wp-content/uploads/2024/03/unnamed-11.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-11.png?w=768 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></p>
<p>This creates a gap in the GPU mappings, and I’m starting to get something that looks exploitable.</p>
<p>Note that as <code>delta</code> has to be non zero to trigger the bug, and as <code>delta + old_size</code> pages at the start of the region are mapped, it is still not possible to have the start of the region unmapped like in the case of GHSL-2023-005. So, my only option here is to shrink the region and have the resulting size lie somewhere inside the unmapped gap.</p>
<p>The only way to shrink a JIT region is to use the <code>BASE_KCPU_COMMAND_TYPE_JIT_FREE</code> GPU command to “free” the JIT region. As explained before, this does not actually free the <code>kbase_va_region</code> itself, but rather puts it in a memory pool so that it may be reused on subsequent JIT allocation. Prior to this, <code>kbase_jit_free</code> will also shrink the JIT region according to the <code>initial_commit</code> size of the region, as well as the <code>trim_level</code> that is configured in the <code>kbase_context</code>:</p>
<pre><code>
void kbase_jit_free(struct kbase_context *kctx, struct kbase_va_region *reg)
{
    ...
  old_pages = kbase_reg_current_backed_size(reg);
  if (reg-&gt;initial_commit initial_commit,
      div_u64(old_pages * (100 - kctx-&gt;trim_level), 100));
    u64 delta = old_pages - new_size;
    if (delta) {
      mutex_lock(&amp;kctx-&gt;reg_lock);
      kbase_mem_shrink(kctx, reg, old_pages - delta);
      mutex_unlock(&amp;kctx-&gt;reg_lock);
    }
  }
  ...
}
</code></pre>
<p>Either way, I can control the size of this shrinking. With this in mind, I can arrange the region in the following way:</p>
<ol>
<li>Create a JIT region and trigger the bug. Arrange the GPU fault so that the fault handler adds <code>fault_size</code> pages, enough pages to cover at least one level 2 PTE.
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-12.png?w=822&amp;resize=822%2C529" alt="" width="822" height="529" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-12.png?w=822&amp;resize=822%2C529 822w, https://github.blog/wp-content/uploads/2024/03/unnamed-12.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-12.png?w=768 768w" sizes="(max-width: 822px) 100vw, 822px" data-recalc-dims="1"></p>
<p>After the bug is triggered, only the initial <code>old_size + delta</code> pages are mapped to the GPU address space, while the <code>kbase_va_region</code> has <code>old_size + delta + fault_size</code> backing pages in total.</p>
</li>
<li>
<p>Trigger a second fault at an offset greater than the number of backing pages, so that pages are appended to the region and mapped after the unmapped regions created in the previous step.</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-13.png?w=812&amp;resize=812%2C525" alt="" width="812" height="525" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-13.png?w=812&amp;resize=812%2C525 812w, https://github.blog/wp-content/uploads/2024/03/unnamed-13.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-13.png?w=768 768w" sizes="(max-width: 812px) 100vw, 812px" data-recalc-dims="1"></p>
</li>
<li>
<p>Free the JIT region using <code>BASE_KCPU_COMMAND_TYPE_JIT_FREE</code>, which will call <code>kbase_jit_free</code> to shrink the region and remove pages from it. Control the size of this trimming either so that the region size after shrinking (<code>final_size</code>) of the backing store lies somewhere within the unmapped region covered by the first level 2 PTE.</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-14.png?w=824&amp;resize=824%2C529" alt="" width="824" height="529" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-14.png?w=824&amp;resize=824%2C529 824w, https://github.blog/wp-content/uploads/2024/03/unnamed-14.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-14.png?w=768 768w" sizes="(max-width: 824px) 100vw, 824px" data-recalc-dims="1"></p>
</li>
</ol>
<p>When the region is shrunk, <code>kbase_mmu_teardown_pgd_pages</code> is called to unmap the GPU address mappings, starting from <code>region_start + final_size</code> all the way up to the end of the region. As the entire address range covered by the first level 2 PTE is unmapped, when <code>kbase_mmu_teardown_pgd_pages</code> tries to unmap <code>region_start + final_size</code>, the condition <code>!mmu_mode-&gt;pte_is_valid</code> is met at a level 2 PTE and so the unmapping will skip the next 512 pages, starting from <code>region_start + final_size</code>. However, since addresses belonging to the next level 2 PTE are still mapped, these addresses will be skipped incorrectly (the orange region in the next figure), leaving them mapped to pages that are going to be freed:</p>
<p><img decoding="async" src="https://github.blog/wp-content/uploads/2024/03/unnamed-15.png?w=827&amp;resize=827%2C524" alt="" width="827" height="524" loading="lazy" srcset="https://github.blog/wp-content/uploads/2024/03/unnamed-15.png?w=827&amp;resize=827%2C524 827w, https://github.blog/wp-content/uploads/2024/03/unnamed-15.png?w=300 300w, https://github.blog/wp-content/uploads/2024/03/unnamed-15.png?w=768 768w" sizes="(max-width: 827px) 100vw, 827px" data-recalc-dims="1"></p>
<p>Once the shrinking is completed, the backing pages are freed and the addresses in the orange region will retain access to already freed pages.</p>
<p>This means that the freed backing page can now be reused as any kernel page, which gives me plenty of options to exploit this bug. One possibility is to use my previous <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#breaking-out-of-the-context">technique</a> to replace the backing page as <a href="https://www.kernel.org/doc/gorman/html/understand/understand006.html">page table global directories (PGD)</a> of our GPU <code>kbase_context</code>.</p>
<p>To recap, let’s take a look at how the backing pages of a <code>kbase_va_region</code> are allocated. When allocating pages for the backing store of a <code>kbase_va_region</code>, the <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem_pool.c#772"><code>kbase_mem_pool_alloc_pages</code></a> function is used:</p>
<pre><code>
int kbase_mem_pool_alloc_pages(struct kbase_mem_pool *pool, size_t nr_4k_pages,
    struct tagged_addr *pages, bool partial_allowed)
{
    ...
  /* Get pages from this pool */
  while (nr_from_pool--) {
    p = kbase_mem_pool_remove_locked(pool);     //next_pool) {
    /* Allocate via next pool */
    err = kbase_mem_pool_alloc_pages(pool-&gt;next_pool,      //&lt;----- 2.
        nr_4k_pages - i, pages + i, partial_allowed);
        ...
  } else {
    /* Get any remaining pages from kernel */
    while (i != nr_4k_pages) {
      p = kbase_mem_alloc_page(pool);     //&lt;------- 3.
            ...
        }
        ...
  }
    ...
}
</code></pre>
<p>The input argument <code>kbase_mem_pool</code> is a memory pool managed by the <code>kbase_context</code> object associated with the driver file that is used to allocate the GPU memory. As the comments suggest, the allocation is actually done in tiers. First the pages will be allocated from the current <code>kbase_mem_pool</code> using <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem_pool.c#241"><code>kbase_mem_pool_remove_locked</code></a> (1 in the above). If there is not enough capacity in the current <code>kbase_mem_pool</code> to meet the request, then <code>pool-&gt;next_pool</code>, is used to allocate the pages (2 in the above). If even <code>pool-&gt;next_pool</code> does not have the capacity, then <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem_pool.c#316"><code>kbase_mem_alloc_page</code></a> is used to allocate pages directly from the kernel via the buddy allocator (the page allocator in the kernel).</p>
<p>When freeing a page, provided that the memory region is not evicted, the same happens in the opposite direction: <a href="https://android.googlesource.com/kernel/google-modules/gpu/+/refs/heads/android-gs-shusky-5.15-android14-qpr1/mali_kbase/mali_kbase_mem_pool.c#991"><code>kbase_mem_pool_free_pages</code></a> first tries to return the pages to the <code>kbase_mem_pool</code> of the current <code>kbase_context</code>, if the memory pool is full, it’ll try to return the remaining pages to <code>pool-&gt;next_pool</code>. If the next pool is also full, then the remaining pages are returned to the kernel by freeing them via the buddy allocator.</p>
<p>As noted in my post <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#breaking-out-of-the-context">Corrupting memory without memory corruption</a>, <code>pool-&gt;next_pool</code> is a memory pool managed by the Mali driver and shared by all the <code>kbase_context</code>. It is also used for allocating <a href="https://www.kernel.org/doc/gorman/html/understand/understand006.html">page table global directories (PGD)</a> used by GPU contexts. In particular, this means that by carefully arranging the memory pools, it is possible to cause a freed backing page in a <code>kbase_va_region</code> to be reused as a PGD of a GPU context. (The details of how to achieve this can be found <a href="https://github.blog/2022-07-27-corrupting-memory-without-memory-corruption/#breaking-out-of-the-context">here</a>.)</p>
<p>Once the freed page is reused as a PGD of a GPU context, the GPU addresses that retain access to the freed page can be used to rewrite the PGD from the GPU. This then allows any kernel memory, including kernel code, to be mapped to the GPU. This then allows me to rewrite kernel code and hence execute arbitrary kernel code. It also allows me to read and write arbitrary kernel data, so I can easily rewrite credentials of my process to gain root, as well as to disable SELinux.</p>
<p>The exploit for Pixel 8 can be found <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/Android/Mali/CVE_2023_6241">here</a> with some setup notes.</p>
<h2 id="how-does-this-bypass-mte">How does this bypass MTE?<a href="#how-does-this-bypass-mte" aria-label="How does this bypass MTE?"></a></h2>
<p>So far, I’ve not mentioned any specific measures to bypass MTE. In fact, MTE does not affect the exploit flow of this bug at all. While MTE protects against dereferences of pointers against inconsistent memory blocks, the exploit does not rely on any of such dereferencing at all. When the bug is triggered, it creates inconsistencies between the <code>pages</code> array and the GPU mappings of the JIT region. At this point, there is no memory corruption and neither the GPU mappings nor the <code>pages</code> array, when considered separately, contain invalid entries. When the bug is used to cause <code>kbase_mmu_teardown_pgd_pages</code>to skip removing GPU mappings, its effect is to cause physical addresses of freed memory pages to be retained in the GPU page table. So, when the GPU accesses the freed pages, it is in fact accessing their physical addresses directly, which does not involve any pointer dereferencing either. On top of that, I’m also not sure whether MTE has any effect on GPU memory accesses anyway. So, by using the GPU to access physical addresses directly, I’m able to completely bypass the protection that MTE offers. Ultimately, there is no memory safe code in the code that manages memory accesses. At some point, physical addresses will have to be used directly to access memory.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Conclusion"></a></h2>
<p>In this post, I’ve shown how CVE-2023-6241 can be used to gain arbitrary kernel code execution on a Pixel 8 with kernel MTE enabled. While MTE is arguably one of the most significant advances in the mitigations against memory corruptions and will render many memory corruption vulnerabilities unexploitable, it is not a silver bullet and it is still possible to gain arbitrary kernel code execution with a single bug. The bug in this post bypasses MTE by using a coprocessor (GPU) to access physical memory directly (Case 4 in <a href="https://googleprojectzero.blogspot.com/2023/08/mte-as-implemented-part-3-kernel.html">MTE As Implemented, Part 3: The Kernel</a>). With more and more hardware and software mitigations implemented on the CPU side, I expect coprocessors and their kernel drivers to continue to be a powerful attack surface.</p>

      
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dead Air on the Incident Call (127 pts)]]></title>
            <link>https://blog.danslimmon.com/2024/03/18/dead-air-on-the-incident-call/</link>
            <guid>39751636</guid>
            <pubDate>Tue, 19 Mar 2024 00:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.danslimmon.com/2024/03/18/dead-air-on-the-incident-call/">https://blog.danslimmon.com/2024/03/18/dead-air-on-the-incident-call/</a>, See on <a href="https://news.ycombinator.com/item?id=39751636">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2932">
	<div>
			
<p>When troubleshooting a high-impact software failure in a group, you have to be ready for shifts in tenor. One moment there’s a frenzy of coordination, and the next: absolute silence.</p>



<p>Silence is natural and often useful. But to be an effective <strong>incident commander</strong> – whose job is to keep the problem-solving effort moving forward – you must develop a keen ear for silence.</p>



<p>Silence can mean different things to different people in different situations. In this post, I’ll present a few incident scenarios and explore the role of the incident commander in breaking (or simply abiding in) dead air.</p>



<h2>“Any minute now”</h2>



<p>Sylvain (from the [s]upport team) has spun up an incident call after getting 3 consecutive reports of broken CSS on the production app. You are the incident commander, and Oscar (from [o]perations) has immediately volunteered to be the primary investigator. Deanna and Deepak (software [d]evs) are also on the call.</p>



<p>There’s some ambiguity about whether the CSS issue merits a status page post. Nobody has found a “smoking gun” showing that, for example, 404 errors are happening at an elevated rate. And now Oscar announces, “I’m seeing some log entries from the web server that look a little weird. I’m gonna look at those.” This is the beginning of a 5-minute silence.</p>



<p>During the silence, Deanna, Deepak, and Sylvain are all waiting, hoping that these log entries that Oscar just noticed turn out to be the smoking gun. They’re putting their eggs in the basket of Oscar’s intuition. Hopefully he’s seen this issue before, and any minute now he’ll say “Okay, I’m pushing a fix.”</p>



<p>The problem is, it’s equally possible that Oscar has latched onto a red herring (some salient but ultimately irrelevant observation). If there were a conversation in place of silence, then Deanna could be researching the error message, or Deepak might be able to immediately rule out the error as a cause of the broken CSS, or Sylvain could provide a detail from one of the customer tickets that would narrow the scope of the investigation. But instead, everybody’s twiddling their thumbs hoping for Oscar to emerge with a fix.</p>



<p>An incident commander is responsible for keeping the whole problem-solving effort moving forward. So it’s incumbent on you to interrupt this silence.</p>



<p>Try drawing more information out of Oscar:</p>



<ul>
<li>“Oscar, do you mind sharing your screen so Deepak and Deanna can see the weird log messages too?”</li>



<li>“What’s the error message, Oscar? Can you send a link to a log search?”</li>



<li>“Do we know when these log events started? Does that line up with when we started receiving these support tickets, Sylvain?”</li>
</ul>



<p>The more we audit each other’s thought processes, the more effective we are at joint problem-solving. An IC must make this happen.</p>



<h2>“LGTM”</h2>



<p>Sylvain has spun up an incident call after getting 3 consecutive reports of broken CSS on the production website. You are the incident commander.</p>



<p>Oscar has checked a bunch of graph dashboards and hasn’t found any evidence of a widespread system failure. He’s said as much. Now there’s relative silence on the call for five minutes.</p>



<p>Deanna and Deepak are basically in agreement with Oscar: there’s no evidence of a system health issue. To them, and to Oscar, it’s not really clear how strong a signal Sylvain has. It could just be a coincidence that these three reports all arrived in a row. The engineers on the call are thinking, <em>I guess we’ll keep poking at this, but we’re not even sure this is a real issue. We need more information.</em></p>



<p>Sylvain, on the other hand, is positive that something is wrong. Getting 3 support tickets in a row about the same behavior is very strong evidence to him. He’s presented his information to the investigators, and now he’s thinking, <em>Okay, they say it’s not a widespread issue. But I’m sure Oscar is getting to the bottom of it</em>.</p>



<p>There’s been a <a href="https://blog.danslimmon.com/2015/10/19/troubleshooting-chatops-ddx/">common ground breakdown</a>, and as a result, a silence that becomes more and more frustrating.</p>



<p>As incident commander, you should focus the group’s attention on observable symptoms by asking questions like:</p>



<ul>
<li>“Has anybody been able to reproduce these broken page-loads in a browser? Preferably with Dev Tools turned on?”</li>



<li>“Sylvain, I don’t have an intuition for support ticket frequencies. How unusual is it to get 3 reports of the same thing right in a row like this?”</li>



<li>“Can we find, in the access logs, just one example of a stylesheet request that returned a non-200 response?”</li>
</ul>



<h2>“Let’s see here…”</h2>



<p>Sylvain has spun up an incident call after getting 3 consecutive reports of broken CSS on the production website. You are the incident commander. The investigation has been going along, and Oscar is chasing down a hunch that a particular error message from the web server is related to the stylesheet failures. Deanna is digging into some code to help validate Oscar’s hunch.</p>



<p>Deepak joins the call. There’s no chatter, as everyone is waiting for Oscar and Deanna to come up with their findings. So Deepak reads the chat scrollback, which takes him about 5 minutes. It’s not until the end of those 5 minutes that Deepak understands what Oscar and Deanna are working on.</p>



<p>As it happens, Deepak has seen the web server error message in question before. He knows what it means, and he can explain why it’s a red herring. But for the 5 minutes it takes him to get up to speed by reading the chat scrollback, silence persists.</p>



<p>In order to keep a problem-solving effort moving forward, an incident commander should ensure that every new participant gets up-to-date knowledge of what the group is doing and why. At small scale (less than, say, 10 people on the call), you can do this verbally. For example, you could say to Deepak when he joins the call, “Hi Deepak. Right now, Oscar and Deanna are investigating a web server error message that might be related to failed stylesheet loads. You can see the error message in the chat.”</p>



<p>When there are more than 10 people, the verbal approach stops working. It becomes necessary to have a shared document of some sort, continuously updated by a “scribe.” It’s not sufficient for this document to be merely a timeline of events: it must highlight the <em>current state</em> of the joint diagnostic effort. I recommend <a href="https://blog.danslimmon.com/2024/03/08/clinical-troubleshooting-diagnose-any-production-issue-fast/">clinical troubleshooting</a> for this.</p>



<h2>“I need 5 minutes”</h2>



<p>When incident response is going right, everybody understands what’s being done by whom, and why. As information comes to light and our strategies evolve, it takes more or less constant communication to maintain this state. That’s why silence on an incident call is so often an indicator of trouble: when there’s silence, communication isn’t happening.</p>



<p>There is, however, a healthy kind of dead air.</p>



<p>Sometimes an investigator needs to go silent for a while to chase down a hunch, or collect some data, or research some question. As long as such a silence is negotiated in advance, with a specific time to reconvene, it can serve a crucial purpose. I call this <strong>functional dead air</strong>.</p>



<p>It’s the job of the incident commander to ensure that every nontrivial silence is functional. First, communicate what’s being done by whom, and why. Only then, do it.</p>



<hr>



<p><em>I offer half-day and full-day incident response training for engineers. </em><a href="mailto:dan.slimmon@gmail.com">Get in touch</a>!</p>
					</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interviewing at Canonical (107 pts)]]></title>
            <link>https://hachyderm.io/@sara/112117125241735836</link>
            <guid>39750181</guid>
            <pubDate>Mon, 18 Mar 2024 21:21:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hachyderm.io/@sara/112117125241735836">https://hachyderm.io/@sara/112117125241735836</a>, See on <a href="https://news.ycombinator.com/item?id=39750181">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>