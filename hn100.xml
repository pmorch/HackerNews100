(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 25 Oct 2024 21:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Company named "><SCRIPT SRC=HTTPS://MJT.XSS.HT> LTD" forced to change it (2020) (208 pts)]]></title>
            <link>https://www.theguardian.com/uk-news/2020/nov/06/companies-house-forces-business-name-change-to-prevent-security-risk</link>
            <guid>41948666</guid>
            <pubDate>Fri, 25 Oct 2024 19:20:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/uk-news/2020/nov/06/companies-house-forces-business-name-change-to-prevent-security-risk">https://www.theguardian.com/uk-news/2020/nov/06/companies-house-forces-business-name-change-to-prevent-security-risk</a>, See on <a href="https://news.ycombinator.com/item?id=41948666">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Companies House has forced a company to change its name after it belatedly realised it could pose a security risk.</p><p>The company now legally known as “THAT COMPANY WHOSE NAME USED TO CONTAIN HTML SCRIPT TAGS LTD” was set up by a British software engineer, who says he did it purely because he thought it would be “a fun playful name” for his consulting business.</p><p>He now says he didn’t realise that Companies House was actually vulnerable to the extremely simple technique he used, known as “cross-site scripting”, which allows an attacker to run code from one website on another.</p><p>The original name of the company was ““&gt;&lt;SCRIPT SRC=HTTPS://MJT.XSS.HT&gt; LTD”. By beginning the name with a quotation mark and chevron, any site which failed to properly handle the HTML code would have mistakenly thought the company name was blank, and then loaded and executed a script from the site XSS Hunter, which helps developers find cross-site scripting errors.</p><p>That script would have simply put up a harmless alert – but it serves as proof that a malicious attacker could instead have used the same weakness as a gateway to more damaging ends.</p><p>Similar names have been registered in the past, such as “; DROP TABLE “COMPANIES”;-- LTD”, a <a href="https://pizzey.me/blog/no-i-didnt-try-to-break-companies-house/" data-link-name="in body link">wry attempt</a> to carry out an attack known as SQL injection, <a href="https://xkcd.com/327/" data-link-name="in body link">inspired by a famous XKCD webcomic</a>, but this was the first such name to have prompted a response. Companies House has retroactively removed the original name from its data feeds, and all documentation referring to its original moniker now reads simply “Company name available on request”.</p><p>The director of the company, who asked not to be named, told the Guardian: “Government Digital Service - GDS - have a good reputation for security, and other companies with similarly playful names have been registered in the past, so I thought there probably wouldn’t be a problem.</p><p>“When I discovered there were some minor problems, I contacted Companies House and the <a href="https://www.theguardian.com/technology/2020/nov/03/covid-related-cybercrime-drives-attacks-on-uk-to-record-number" data-link-name="in body link">National Cyber Security Centre</a> immediately, and didn’t disclose the issue to anyone else.”</p><p>He did not realise it would be an issue, he said, because characters including &gt; and “ are explicitly allowed as company names, which suggested that the agency had put security measures in place to prevent such attacks.</p><p>A Companies House spokesperson said: “A company was registered using characters that could have presented a security risk to a small number of our customers, if published on unprotected external websites. We have taken immediate steps to mitigate this risk and have put measures in place to prevent a similar occurrence. We are confident that Companies House services remain secure.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Detecting when LLMs are uncertain (143 pts)]]></title>
            <link>https://www.thariq.io/blog/entropix/</link>
            <guid>41947566</guid>
            <pubDate>Fri, 25 Oct 2024 17:40:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thariq.io/blog/entropix/">https://www.thariq.io/blog/entropix/</a>, See on <a href="https://news.ycombinator.com/item?id=41947566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <div><p>This post tries to explain the new reasoning techniques developed by <a href="https://x.com/_xjdr">XJDR</a> in a new project called
<a href="https://github.com/xjdr-alt/entropix">Entropix</a>.</p><p>Entropix attempts to improve reasoning in models through being smarter at sampling during moments of uncertainty.</p><p>A big caveat, there have been no large scale evals yet for Entropix, so it’s not clear how much this helps in practice. But it does seem to introduce some promising techniques and mental models for reasoning.</p></div>
<h2 id="uncertainity-at-a-glance">Uncertainity at a glance</h2>
<p>Sampling is the process of choosing which token from the distribution of possible tokens (the logits) that a LLM chooses. You can tell how confident a model is in its predictions by looking at that distribution.</p>
<p>This is a <strong>confident</strong> model prediction for the next token:</p>
<p><img src="https://www.thariq.io/images/entropix/lowe-lowv.png" alt="Screenshot 2024-10-11 at 10.08.08 AM.png"></p><p>But in reality, models are not always so sure of their predictions. You will often run into cases where the next token prediction looks like this:</p>
<p><img src="https://www.thariq.io/images/entropix/lowe-highv.png" alt="Screenshot 2024-10-11 at 10.08.08 AM.png"><img src="https://www.thariq.io/images/entropix/highe-lowv.png" alt="Screenshot 2024-10-11 at 10.09.29 AM.png"></p>
<p>In these cases, the model is uncertain.</p>
<p>Entropix is a method for using <strong>adaptive sampling</strong> to make better decisions when the model is uncertain.</p>
<h3 id="what-does-uncertainity-mean-and-does-it-matter">What does uncertainity mean, and does it matter?</h3>
<p>This uncertainty in the logits might have many different underlying causes, and not all are bad.</p>
<p>Causes include:</p>
<ul>
<li>The tokens are synonyms or equivalent (e.g. good vs great)</li>
<li>There are branching paths (e.g. the AI could either write your program in Java or C)</li>
<li>The AI may genuinely not be sure what to do (it is ‘out of distribution’, it hasn’t seen this in its training data before).</li>
</ul>
<p>Entropix suggests that you should have <em>different methods</em> for choosing the next token, depending on how uncertain you are.</p>
<p>How do we do that? To start, we need to measure uncertainty.</p>
<h2 id="entropy-and-varentropy">Entropy and Varentropy</h2>
<p>The key tools that Entropix uses are two metrics that measure uncertainty: <strong>the entropy</strong> &amp; <strong>varentropy</strong> of the logits.</p>
<p>Entropy measures how different the predicted logits are from each other, i.e. how uncertain we are in the most probably outcome. In low entropy, we are pretty certain in a few of the logits. In high entropy, the distribution of the logits is more uniform and we are much less certain.</p>
<p>Varentropy is a different type of entropy metric. It gives us an idea of the “shape” of the uncertainty. High varentropy indicates that some of the values are highly different from others.</p>
<astro-island uid="ZPT0W8" prefix="r3" component-url="/_astro/SimpleExpandableBlock.-iQQRPjY.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;heading&quot;:[0,&quot;The Math&quot;]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;SimpleExpandableBlock&quot;,&quot;value&quot;:true}" await-children=""><template data-astro-template=""><p>Entropy &amp; Varentropy are based on the idea of <strong>surprisal</strong>.</p><p>Surprisal, also known as self-information, measures how unexpected or surprising an event is based on its probability. For an event x with probability P(x), the surprisal is:</p><div data-testid="react-katex"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(x) = -\log_2(P(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span></span></span></span></span></div><p>The more unlikely an event is, the higher its surprisal. For example, if P(x) = 1/8, the surprisal is 3 bits, while if P(x) = 1/2, the surprisal is only 1 bit.</p><p>Entropy is the expected value (weighted average) of surprisal across all possible outcomes.</p><div data-testid="react-katex"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">H = -\sum_{x \in X} P(x)\log_2(P(x)) = E[I(x)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3717em;vertical-align:-1.3217em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span></span></span></span></span></div><p>Varentropy is calculated as the variance of the surprisal:</p><div data-testid="react-katex"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>H</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>−</mo><mi>H</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V = \sum_{x \in X} P(x)(\log_2(P(x)) + H)^2 = E[(I(x) - H)^2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3717em;vertical-align:-1.3217em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mopen">(</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></div><p>High varentropy indicates that some of the values are highly different from others - in other words, some outcomes are much more surprising than others relative to the average surprisal (entropy).</p></template><!--astro:end--></astro-island>
<p>Combined, the two of us give 4 possible states:</p>
<ul>
<li>Low entropy, low varentropy: A very peaked distribution (one highly probable outcome).</li>
<li>Low entropy, high varentropy: A distribution with a few disparate peaks.</li>
<li>High entropy, low varentropy: A uniform or near-uniform distribution.</li>
<li>High entropy, high varentropy: A spread-out but uneven distribution.</li>
</ul>
<h2 id="adaptive-sampling-based-on-entropy--varentropy">Adaptive Sampling based on Entropy &amp; Varentropy</h2>
<p>Now that we have those metrics for uncertainty, we can use them to perform different types of sampling based on the situation.</p>
<h3 id="low-entropy-low-varentropy">Low Entropy, Low Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/lowe-lowv.png" alt="Low entropy, low varentropy"></p><p>This is usually the ideal case. The model is certain not only in what its first option would be, but also what it would choose if the first option was incorrect. Often times this means that the list is ordered in a neat way.</p>
<p>In this case, adaptive sampling would suggest the standard argmax sampling, e.g. choose the token with the highest probabilitly.</p>
<h3 id="low-entropy-high-varentropy">Low Entropy, High Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/lowe-highv.png" alt="Low entropy, high varentropy"></p><p>In this case, the model predicts a few options very highly.</p>
<p>This is a tricky case- it may be representing a whole new branch of output, or it may be representing a few options such as a synonym.</p>
<p>In this case, we may want to “<strong>branch</strong>” by predicting both logits, seeing what paths they take and comparing the results after some point. There are many ways to implement this branching, which deserves its own post.</p>
<p>Depending on the results of the branching, we could take different actions. If we get two branches with fairly equal confidence (as measured by their entropy and varentropy) but with different contents, we could formulate this as a question to the user.</p>
<h3 id="high-entropy-low-varentropy">High Entropy, Low Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/highe-lowv.png" alt="High entropy, low varentropy"></p><p>This state represents a possible low confidence state in the model. It may be seeing something that it doesn’t recognize at all, or all the options may be interchangeable with each other.</p>
<p>The best thing to do here is to help the model get to a higher confidence state. Entropix suggests using a <strong>“thinking” token</strong> here as the next token, e.g. <em>“Wait..”</em></p>
<p>A thinking token is a token that we insert into the output, to make the model realizes it needs to spend more compute time thinking about the answer before giving one.</p>
<p>For example, if the model is predicting <em>“The capital of Germany is Paris”</em> but it is not sure about the answer, it might insert a thinking token and predict <em>“The capital of Germany is Paris… Wait, no, it’s actually Berlin”</em></p>
<h3 id="high-entropy-high-varentropy">High Entropy, High Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/highe-highv.png" alt="High entropy, high varentropy"></p><p>The model has no clear favorite, but it is more certain in some outputs than others. This is a difficult place to be in. One way to think about is that any of the top options may be solid choices (e.g. they are synonyms to each other), and so we should just choose one at random (aka a higher temperature).</p>
<p>We could also branch, or insert thinking tokens like we have done in previous options.</p>
<h2 id="branching-vs-thinking-tokens">Branching vs Thinking Tokens</h2>
<p>Branching &amp; thinking tokens are two different ways of achieving more compute in an uncertain state.</p>
<p>Branching predictions involves following a few logits to see what other tokens they lead to. This is often called MCTS (Monte Carlo Tree Search) and is a method that has been often tried in LLMs to middling success. One of the tradeoffs of branching is that it requires using inference compute in a way where the branches cannot benefit from each others compute.</p>
<p>Thinking tokens are a way of achieving more compute in an uncertain state without sacrificing some of that compute to explore a branch that you might kill. Inserting “Wait…” causes the AI to realize that it might have made a mistake.</p>
<p>Branching vs thinking tokens is overall an open research question, and deserving of another post.</p>
<h2 id="attention-entropy">Attention Entropy</h2>
<p>It’s worth noting that there are other measures of entropy that we might take into account. Entropix uses them slightly to figure out how to modify temperature, but they might be other tools.</p>
<p><strong>Attention Entropy</strong> - How much are your attention heads tend to follow specific tokens, vs pay attention to a large number of tokens in the context.</p>
<p><strong>Attention Agreement</strong> - How much your attention heads are paying attention to the same tokens as each other, vs different ones.</p>
<p>If your heads have low entropy and high agreement, that can be another signal for you to be confident sampling the highest probability. Low agreement might indicate that different heads are contributing to different predictions, and it might be worth branching.</p>
<h2 id="does-this-matter">Does this matter?</h2>
<p>The insights in Entropix feel in many ways fairly easy to understand, and not entirely novel, which has been surprising to many.</p>
<p>Even if the evals don’t show a large benefit yet. But, inference-time techniques like this are easy to experiment with and could be a promising direction for open source hackers to improve reasoning without huge budgets.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Git repos on Cloudflare workers (102 pts)]]></title>
            <link>https://gitlip.com/blog/infinite-git-repos-on-cloudflare-workers</link>
            <guid>41947513</guid>
            <pubDate>Fri, 25 Oct 2024 17:34:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlip.com/blog/infinite-git-repos-on-cloudflare-workers">https://gitlip.com/blog/infinite-git-repos-on-cloudflare-workers</a>, See on <a href="https://news.ycombinator.com/item?id=41947513">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>How we built a scalable Git server on Cloudflare Workers using WebAssembly and Durable Objects.</p><div><div><p>We’re building<!-- --> <a href="https://gitlip.com/">Gitlip</a> <!-- -->- the collaborative devtool for the AI era. An all-in-one combination of Git-powered version control, collaborative coding and 1-click deployments. Our goal is to simplify the practical application of state-of-the-art AI models.</p><p>We’re preparing to raise a seed round soon. Reach out to<!-- --> <a href="https://x.com/nataliemarleny">@nataliemarleny</a> <!-- -->for more information.</p></div><p>In this post we will describe how we implemented infinite Git repos on Cloudflare using a new type of serverless database: a highly optimized Webassembly Git server that runs on Cloudflare Workers and scales horizontally. It allows us to easily host an infinite number of repositories. Additionally, since it runs on Cloudflare our Git server supports IPv6 by default. For comparison,<!-- --> <a href="https://github.com/orgs/community/discussions/10539">GitHub doesn’t yet support IPv6</a>.</p><p>Currently we are leveraging this technology to build a coding platform. We’re also considering creating a serverless Database as a Service (DBaaS) offering, which would allow anyone to create an arbitrary number of Git repositories in the cloud and use them in their own product. If you’d be interested in a DBaaS product like this, please reach out to<!-- --> <a href="https://x.com/nataliemarleny">@nataliemarleny</a>!</p><h3>Motivation</h3><p>Originally, while working on a note-taking application for developers based on Git, we encountered the need to host Git repositories efficiently. Wanting to avoid managing the servers ourselves, we experimented with a serverless approach. After researching, we couldn’t find anyone attempting something similar, so besides its potential usefulness, it also seemed like an interesting problem to solve.</p><p>We’re big fans of Cloudflare and their Workers platform and we were aware of<!-- --> <a href="https://developers.cloudflare.com/durable-objects/">Durable Objects</a>. In terms of the usage model, likely access patterns, and general philosophy, Durable Objects seemed like the perfect underlying storage for a project like this.</p><p>We consider Durable Objects a novel and revolutionary type of storage. It offers a key-value store that is transactional, strongly consistent, and persistent. It’s tightly integrated with the Workers runtime and is suitable for all sorts of coordination and application-data use cases. Given its usefulness, we fully expect that other cloud providers will offer a comparable type of storage alongside their serverless offerings in the future.</p><p>When we started our research, we knew that Cloudflare had built D1 (their SQLite database offering) on Durable Objects. In addition to our early experiments with Durable Objects, this made us confident that what we intended to implement was feasible, so we made it our goal to host a Git repository within a Durable Object.</p><h3>Git in Cloudflare Workers</h3><p>Cloudflare Workers is a serverless platform based on the V8 JavaScript engine, which can also execute Wasm binaries, so when attempting to run Git in this environment, we had somewhat limited options. We tried a few different approaches, but in the end, there were only two legitimate candidates:</p><ol><li><a href="https://github.com/libgit2/libgit2">libgit2</a> <!-- -->- a cross-platform, linkable Git library written in C,</li><li><a href="https://github.com/isomorphic-git/isomorphic-git">isomorphic-git</a> <!-- -->- a pure JavaScript implementation of Git.</li></ol><p>We judged that it would be easier to start with isomorphic-git, but that the initial up-front investment in making libgit2 work might pay off more significantly, since libgit2 is used much more widely and is more battle-hardened. Prior to our attempts, other developers had already made libgit2 work in Node.js and browsers (see<!-- --> <a href="https://github.com/petersalomonsen/wasm-git">wasm-git</a>), which further encouraged us that we were on the right path.</p><p>We ended up compiling libgit2 with Emscripten and packaging it for Cloudflare Workers.</p><p>Git uses the filesystem as its underlying storage, so the next step was to implement a filesystem on top of Durable Objects. A big hurdle we encountered at this point was how I/O is handled in modern JavaScript (using promises or async/await) versus how filesystem I/O is expected to work in Emscripten (synchronous system calls). Emscripten offers two mechanisms for using asynchronous JavaScript function calls in synchronous C functions:<!-- --> <a href="https://emscripten.org/docs/porting/asyncify.html">JSPI and Asyncify</a>. After extensive research, we rewrote significant parts of Emscripten to support asynchronous file system calls. We ended up creating our own Emscripten filesystem on top of Durable Objects, which we call DOFS. Having a filesystem on Durable Objects is very useful for running a Git server, but it also unlocks many other interesting possibilities (we will write about this in the future).</p><p><img src="https://gitlip.com/images/blog/infinite-git-repos-on-cloudflare-workers/image-00.svg" alt=""></p><h3>Implementing a Git server</h3><p>Compiling libgit2 to Wasm and implementing a filesystem on top of Durable Objects was a good start, but we needed to do more work to make the entire project useful. At this point, our Git implementation in Cloudflare Workers could store a repo in a Durable Object and communicate with the outside world via custom HTTP operations (read file, list branches etc.), but it couldn’t communicate using the Git protocol, so we couldn’t use the Git command-line tool to fetch or push.</p><p>libgit2 is an excellent Git library, but it only provides client functionality; server functionality is missing. We couldn’t find any other implementations of Git server functionality on the web to use as a reference. While Git itself implements the server commands receive-pack and upload-pack, porting them to libgit2 proved impossible. The main reason was that the required server commands depended on numerous other source files, and the interfaces between these files appeared poorly defined. Edward Thomson, the maintainer of libgit2, has written<!-- --> <a href="https://www.edwardthomson.com/blog/libgit2-in-2024-the-past.html#and-then-theres-the-server">an excellent article on the history of libgit2</a>, detailing Git’s issues in more depth.</p><p>We abandoned the porting efforts and ended up implementing the missing Git server functionality ourselves by leveraging libgit2’s core functionality, studying all available documentation, and painstakingly investigating Git’s behavior. We also created an extensive integration test suite to ensure the robustness and performance of our Git server.</p><h3>Reproducible builds</h3><p>Compiling native libraries like libgit2 for a specific target platform requires a significant amount of preparation, especially when the library itself needs to be compiled with a modified version of the compiler. We found it cumbersome to maintain the repeatability of the entire build process by manually invoking build commands for each component. Luckily, amazing software built for this exact purpose already exists - enter<!-- --> <a href="https://nixos.org/">Nix</a>, a declarative, purely functional build system which enables reproducible builds.</p><p>We’ve built our build system by utilizing Nix. This allowed us to reproducibly build patched Emscripten, patched libgit2, and the C implementation of our Git server from scratch by invoking just a single command. Not only that, but Nix has also enabled us to fine-tune this build process and make it configurable with flags passed to the build command. We can now build our Git server from scratch targeting the native platform (Linux or Mac), Node.js, or Cloudflare Workers. We can also easily configure whether we want the release or development build of the entire package tree. Additionally, Nix allows us to build only a subtree of packages, enabling us to intervene mid-build to make necessary modifications. The learning curve for Nix is steep, but well worth it. If you’re interested in a similarly powerful tool that’s easier to get started with,<!-- --> <a href="https://flox.dev/">flox is an excellent option</a>.</p><p>We discovered a beautiful, initially unintended consequence of building our package tree with Nix: with a little bit of effort, we could compile a broad array of interesting native libraries to WebAssembly using our modified Emscripten compiler. So far, we’ve compiled zlib, libarchive, and libmagic to Wasm and statically linked them with our Git server. As a result, our Git server can create archives in many different formats (we currently only use zip and tar.gz) and easily detect MIME types for a vast array of stored files.<!-- --> <a href="https://github.com/NixOS/nixpkgs">Nixpkgs</a> <!-- -->is full of Nix scripts for building various software packages, and it was reasonably straightforward to adjust some of them to build to Wasm.</p><p>Finally, we also compiled<!-- --> <a href="https://bellard.org/quickjs/">QuickJS</a> <!-- -->to Wasm using our Nix build system. We use our QuickJS-based service to run JavaScript files with full support for ES modules’ import/export statements in Cloudflare Workers on-demand (more in the next section).</p><h3>Composable capabilities</h3><p>One of the core design principles in our codebase is to invest effort in building powerful, composable capabilities and curate them carefully in our repository. Having a strong set of these capabilities opens up interesting combinations especially when using a platform like Cloudflare Workers, which makes composition easy.</p><p><span>Example #1:</span> We developed our Git server with the intention of serving a single repository from a Durable Object, but after accomplishing this, it was very easy to package the same HTTP endpoints and Wasm and expose it from a plain Worker instead of a Durable Object. This way, we gained the ability to run the same exact Git code in either a persistent context (clients connect to the same Durable Object) or an ephemeral context (clients connect to any Worker closest to them). There are use cases where executing Git functionality in an ephemeral context is useful, and where sending the request to a Durable Object would be the wrong choice. For example, when validating a branch or tag name in the Web UI, there’s no need to reimplement these Git-specific rules in JavaScript if we can expose the exact upstream libgit2 behavior in the ephemeral Worker closest to the Web UI user.</p><p><span>Example #2:</span> If you visit<!-- --> <a href="https://gitlip.com/@nataliemarleny/test-repo/ref/HEAD/main.js">https://gitlip.com/@nataliemarleny/test-repo/ref/HEAD/main.js</a>, you’ll see an option to execute this file by pressing ’play’ on the right. Alternatively, here’s a quick video:</p><p><video height="200" width="100%" controls=""><source src="https://gitlip.com/images/blog/infinite-git-repos-on-cloudflare-workers/video-00.mp4" type="video/mp4">Your browser does not support the video tag.</video></p><p>Several of our composable capabilities work together to achieve the final result:</p><ol><li>api receives the request to execute main.js from the HEAD of the repo.</li><li>api coordinates the services (using<!-- --> <a href="https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/">service bindings</a>).</li><li>git-server service receives a request for an archive of the HEAD of the repo and streams the tar.gz snapshot of the HEAD back to the api.</li><li>api forwards the tar.gz stream to the js-run service (QuickJS-based).</li><li>js-run service unpacks the archive stream into memory.</li><li>js-run service runs the requested file from memory (note that main.js imports fizzbuzz.js!) and streams the response back to the api.</li><li>api streams the response back to the user.</li></ol><p><img src="https://gitlip.com/images/blog/infinite-git-repos-on-cloudflare-workers/image-01.svg" alt=""></p><p>For now, executing JavaScript in an on-demand manner like this is just a showcase of what we can easily achieve with our stack of capabilities, but in the future, we plan to make this more powerful by adding support for importing NPM modules and more.</p><h3>Optimizations</h3><p>Achieving predictable performance from our Git server required applying several optimization techniques. We’ll outline the most important ones.</p><p>Like any other serverless platform, Cloudflare Workers come with their own<!-- --> <a href="https://developers.cloudflare.com/workers/platform/limits/">set of constraints</a>. For the purposes of running a Git server, the most important ones are the Worker size (total size of the deployed code), memory, and CPU limit.</p><p><a href="https://blog.cloudflare.com/workers-pricing-scale-to-zero/">In September 2023</a>, the Worker size limit on the Paid plan was increased from 1MB to 10MB, but Cloudflare still recommends keeping your entire deployment under 1MB for best performance. Our Wasm Git server, along with libgit2, all other libraries, and JavaScript glue code, fits in just 800kB, which we consider to be quite an achievement. We achieved this primarily by optimizing for code size during compilation and trimming the number of file formats our libmagic utility can detect.</p><p>The runtime limit of 128MB of memory initially posed a challenge. libgit2 makes heavy use of memory mapping when reading or writing objects to Git packfiles. Unfortunately, in a Wasm application compiled with Emscripten, memory mapping requires a completely new copy of the file in memory (even if the file is already in memory). This meant our Git server would copy the entire Git packfile into memory when reading even the smallest objects, causing the server’s performance to depend on the packfile size rather than the object size. We attempted to address this by modifying Emscripten, but it proved too difficult, so we opted to modify libgit2 instead. We removed all mmap equivalents and replaced them with read/write equivalents, and the results were incredible. We achieved performance independent of the packfile (repo) size. Note that memory mapping makes total sense in the typical settings for which libgit2 was designed.</p><p>Durable Objects are single-threaded, so one might think it would be difficult to efficiently serve concurrent requests to the same repository. Fortunately, the access patterns to a Git repository are well-suited for optimization with a cache. For this purpose we created a component called ConsistentCache, which wraps around Cloudflare’s HTTP Cache API (available in every Worker and Durable Object) and adds the necessary consistency guarantees. This component also deduplicates calls to the Git Wasm program, issuing a single call and relaying the response to all requestors in parallel. Using this technique, a significant number of requests to the Git server are fulfilled directly from the cache, and any modification to the repository purges this cache consistently.</p><p>Persistent storage in Durable Objects<!-- --> <a href="https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/#part-3-automatic-in-memory-caching">has its own built-in caching layer</a>, which improves overall performance and provides additional consistency guarantees. Unfortunately, all reads that hit this built-in cache are billed the same as accessing the underlying storage. libgit2 specifically, and Git more generally, often need to read small chunks of a file incrementally, resulting in a large number of small reads, which became somewhat expensive during testing. We decided to implement our own storage cache, called StorageEngine, and completely disable the built-in cache. This way, we pay nothing for most of the operations our Git server performs on DOFS, only incurring costs for the occasional flush that writes all inodes and file blocks to storage and for occasional reads that populate the StorageEngine.</p><p>Finally, we optimized the implementation of our bare Git repositories to always contain a very limited (mostly constant) number of directories. This allowed us to preload all directories and pack-index files from the persistent storage (depending on the repo between 20 and 60, each up to a few kB in size) every time the Durable Object is instantiated, effectively pre-warming the repository for any Git command it might receive.</p><pre><code>(log) StorageEngine.get (1/1): [HTTP_CACHE_LRU_MAP]
(log) StorageEngine.get (4/4): [NNID, ..., PRECACHE]
(log) StorageEngine.get (48/48): [N_1, ..., B_463_0]
(log) StorageEngine.get (0/1): [N_1]
(log) StorageEngine.get (0/1): [N_2]
(log) StorageEngine.get (0/1): [N_350]
(log) StorageEngine.get (0/1): [N_3]
(log) StorageEngine.get (0/1): [N_6]
(log) StorageEngine.get (0/1): [N_349]
(log) StorageEngine.get (0/1): [B_349_0]
(log) StorageEngine.get (0/1): [N_10]
(log) StorageEngine.get (0/1): [B_350_0]
(log) StorageEngine.get (0/1): [N_7]
(log) StorageEngine.get (0/1): [N_463]
(log) StorageEngine.get (0/1): [B_463_0]
(log) StorageEngine.get (0/1): [N_5]
(log) StorageEngine.get (0/1): [N_25]
(log) StorageEngine.get (0/1): [N_24]
(log) StorageEngine.get (0/1): [N_4]
(log) StorageEngine.get (0/1): [B_25_0]
... previous line repeated 263 more times
(log) StorageEngine.get (1/1): [B_24_0]
(log) StorageEngine.get (1/1): [B_24_15]
(log) StorageEngine.get (0/1): [B_25_0]
(log) StorageEngine.get (1/1): [B_24_9]
(log) StorageEngine.get (0/1): [B_24_9]
(log) StorageEngine.get (0/1): [B_25_0]
... previous line repeated 8 more times
(log) StorageEngine.get (1/1): [B_24_10]
(log) StorageEngine.get (0/1): [B_24_10]
(log) StorageEngine.get (0/1): [B_24_9]
... previous line repeated 10 more times
(log) StorageEngine.get (0/1): [B_24_10]
(log) StorageEngine.get (0/1): [B_25_0]
... previous line repeated 8 more times
(log) StorageEngine.get (1/1): [B_24_12]
(log) StorageEngine.get (0/1): [B_24_12]
... previous line repeated 30 more times
(log) StorageEngine._syncBufferFinal START
(log) StorageEngine.put (1): [HTTP_CACHE_LRU_MAP]
(log) StorageEngine._syncBufferFinal END
(log) StorageEngine._syncBufferFinal START
(log) StorageEngine._syncBatchPut (1): [HTTP_CACHE_LRU_MAP]
(log) StorageEngine._syncBufferFinal END</code></pre><p>The optimizations above, along with a few others, ensure that the performance of our Git servers is both reasonable and reliable. Small read and write operations (think a typical README.md) over HTTP complete in under 150 ms, even without caching and regardless of the repository size.</p><h3>Limitations</h3><p>For now, our Git server is well-suited for repositories up to about 100 MB in size, which is more than enough for our specific use case. Beyond 100 MB, we encounter a few issues:</p><ol><li>Single-threaded packing and unpacking of Git packfiles during clone, fetch, and push operations exceeds the time limit on requests to Workers if the packfiles are too large.</li><li><a href="https://github.com/whatwg/fetch/issues/1254">Fetch body streams are not full duplex</a>, which unfortunately means that while we can theoretically clone and push any repository in our Git server, we may not be able to fetch from it. This is because the fetch operation in Git’s smart protocol requires a full duplex channel for negotiating the optimal packfile to send. Fortunately, in repositories with up to 32 refs, this negotiation process never occurs.</li><li>Cloudflare Workers support only HTTPs for now - so we can’t support cloning, fetching and pushing over SSH without meaningfully complicating our infrastructure.</li></ol><p>We believe the above limitations are solvable in the long term, and that in the future, we could adjust our Git server to handle repositories of arbitrary size and support SSH.</p><h3>Demo</h3><p>To preview this in production, feel free to explore our Gitlip public profiles:</p><ol><li><a href="https://gitlip.com/@nataliemarleny">https://gitlip.com/@nataliemarleny</a></li><li><a href="https://gitlip.com/@plesiv">https://gitlip.com/@plesiv</a></li></ol><p>Please note that the current performance is constrained by the fact that our primary database is not hosted on Cloudflare, and calls to it dominate the latency of most requests. We expect to reduce the overall latency of most requests by 50% to 75% through further optimizations, which we’ll write about in the future.</p><h3>Future</h3><p>Having a serverless and infinitely horizontally scalable Git server infrastructure opens many possibilities for products built on top of it. We believe Git is underutilized for storage purposes, given its versioning capabilities and the fact that it stores plain files, which can be in any format suitable for the application.</p><p>An additional benefit of achieving a performant Git server in JavaScript and Wasm is the fact that our server already mostly works directly in the browser itself. This opens up exciting possibilities: imagine having a lightweight Git client as part of a<!-- --> <a href="https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps">PWA</a> <!-- -->which can shallowly clone a remote repository to allow local editing even when offline. We plan to explore this further down the line.</p><h3>Conclusion</h3><p>We’re just getting started! Stay up to date with our journey of building<!-- --> <a href="https://gitlip.com/">Gitlip</a> <!-- -->by following<!-- --> <a href="https://x.com/nataliemarleny">@nataliemarleny</a>.</p><p>None of this would be possible without the amazing open-source software and the even more amazing communities and companies that produce it, most notably: libgit2, Emscripten, Nix, and the Cloudflare Workers platform. We’re very grateful to work with such incredible tools.</p><p>Thanks to Edward Thomson (<a href="https://x.com/ethomson">@ethomson</a>), Sunil Pai (<a href="https://x.com/threepointone">@threepointone</a>), Chris Nicholas (<a href="https://x.com/ctnicholasdev">@ctnicholasdev</a>) and Tim Neutkens (<a href="https://x.com/timneutkens">@timneutkens</a>) for reading drafts of this post.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disposable vapes to be banned in England and Wales (137 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cd7n3zyp114o</link>
            <guid>41946401</guid>
            <pubDate>Fri, 25 Oct 2024 15:48:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cd7n3zyp114o">https://www.bbc.com/news/articles/cd7n3zyp114o</a>, See on <a href="https://news.ycombinator.com/item?id=41946401">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/f011/live/78234a20-9212-11ef-b047-4d31578ee4d2.jpg.webp" loading="eager" alt="EPA-EFE/REX/Shutterstock A young woman wearing a tracksuit top, Prada sunglasses and Airpods uses a blue-coloured disposable vape on a London street"><span>EPA-EFE/REX/Shutterstock</span></p></div><p data-component="caption-block"><figcaption>The government plans to introduce legislation to ban the sale of disposable vapes from 1 June 2025<!-- --></figcaption></p></figure><div data-component="text-block"><p>The sale of single-use disposable vapes will be banned in England and Wales from June next year, the government has confirmed. <!-- --></p><p>Ministers in England said the move, first announced in January by the previous government but not enacted before the general election, is intended to protect children's health and prevent environmental damage.<!-- --></p><p>The government said it had worked closely with the devolved nations and they would "align coming into force dates" on bans, with Wales <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/c7043578863o">already confirming it will follow suit<!-- --></a>.<!-- --></p><p>Vaping industry leaders have warned the move could fuel a rise in illegal sales of the products. <!-- --></p></div><div data-component="text-block"><p>Single-use vapes had been due to be banned in Scotland from April of next year - but the Scottish government has said the ban <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/cp8x1gyg0lro">will now be delayed until 1 June<!-- --></a> to align with England and Wales.<!-- --></p><p>The Department for Environment, Food, and Rural Affairs (Defra) said vape usage in England had grown by more than 400% between 2012 and 2023, with 9% of the British public now buying and using the products.<!-- --></p><p>The number of people who vape <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/c20jeey047xo">without ever having smoked has also increased<!-- --></a> considerably over recent years, driven mostly by young adults.<!-- --></p><p>It is illegal to sell any vape to anyone under 18, but disposable vapes - often sold in smaller, more colourful packaging than refillable ones - are a "key driver behind the alarming rise in youth vaping", the previous government said <!-- --><a target="_self" href="https://www.bbc.co.uk/news/uk-68123202">when it first set out its plan<!-- --></a>.<!-- --></p><p>Public health minister Andrew Gwynne said banning disposables would "reduce the appeal of vapes to children and keep them out of the hands of vulnerable young people".<!-- --></p><p>Vaping is substantially less harmful than smoking, but it has not been around for long enough for its long-term risks to be known, according to the NHS.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/3ecb/live/b7460a60-91ba-11ef-9a7d-071f318c341c.jpg.webp" loading="lazy" alt="Getty Images A stock image shows an assortment of disposable vapes strewn on a pink surface"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>The previous government said disposable vapes were a "key driver" behind a rise in youth vaping<!-- --></figcaption></p></figure><div data-component="text-block"><p>The ban will not apply to rechargeable or refillable devices. <!-- --></p><p>Single-use vapes are difficult to recycle and typically end up in landfill, where their batteries can leak harmful waste like battery acid, lithium, and mercury into the environment, the government said. <!-- --></p><p>Batteries thrown into household waste also cause <!-- --><a target="_self" href="https://www.bbc.co.uk/news/science-environment-63809620">hundreds of fires<!-- --></a> in bin lorries and waste-processing centres every year. <!-- --></p><p>Defra estimates almost five million single-use vapes were either littered or thrown into general waste each week last year, a nearly four-fold increase on the year before.<!-- --></p><p>In 2022, vapes were discarded containing a total of more than 40 tonnes of lithium, enough to power 5,000 electric vehicles, it said.<!-- --></p><p>Defra minister Mary Creagh, whose role focuses on reducing waste in the economy, said disposable vapes were "extremely wasteful and blight our towns and cities".<!-- --></p></div><div data-component="text-block"><p>Paediatric respiratory consultant Dr Claire Hogg told BBC Radio 5 Live that disposables had "lead to an absolute epidemic of nicotine addiction and a group of children... who are having disrupted sleep, disrupted concentration and really struggling with problems with addiction".<!-- --></p><p>She said her son had previously vaped and thought the ban was "brilliant news" as he had been "addicted to nicotine through false marketing" since he was around 14-years-old.<!-- --></p></div><div data-component="text-block"><p>Disposable vapes - often priced at about £5 - are usually cheaper upfront than many refillable vape kits - often priced at about £8-12 - and can be bought from non-specialist retailers.<!-- --></p><p>But the long-term costs associated with refillable kits are lower than for disposables.<!-- --></p><p>Ireland and Belgium have recently outlined plans to ban the products, while countries including New Zealand, Australia, South Korea, India and Brazil already have restrictions in place.<!-- --></p></div><p data-component="subheadline-block"><h2>'Black market'<!-- --></h2></p><div data-component="text-block"><p>John Dunne, director general of the UK Vaping Industry Association, told BBC Radio 4's Today programme that a ban would "fuel" illegal sales.<!-- --></p><p>"We have a black market in vaping products already that the authorities can't really keep up [with], so now this is going to be dropped right on their lap as well," he said.<!-- --></p><p>Mr Dunne said the association had called on the government to alternatively introduce a licensing scheme for retailers and distributors of the products, "which will include things like mandatory age verification processes".<!-- --></p><p>The government plans to introduce legislation to ban the sale of single-use vapes from 1 June 2025, allowing retailers time to sell their remaining stock. It will cover all single-use vapes, regardless of where they are imported from.<!-- --></p><p>Online shops and major retailing platforms will be expected to use "online takedown procedures" to stop illicit suppliers when the ban comes into force, the department for health and social care said.<!-- --></p><p>The devolved governments have previously announced an intention to bring in similar bans, and the UK government said it was working with them to align the dates on which the bans come into force. <!-- --></p><p>Welsh Deputy First Minister Huw Irranca-Davies said introducing the bans on the same date across the nations would enable "high levels of compliance and consistent approach to enforcement across the UK".<!-- --></p><p>The measure is separate from government plans to end smoking by banning the sale of cigarettes to anyone born after January 2009. <!-- --></p><p>Health Secretary Wes Streeting said on Monday a bill to enact that ban would be introduced to parliament before Christmas. <!-- --></p></div><!--$!--><!--/$--></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Smartphone buyers meh on AI, care much more about battery life (279 pts)]]></title>
            <link>https://www.cnet.com/tech/mobile/with-apple-intelligence-on-the-horizon-a-quarter-of-smartphone-owners-are-unimpressed-by-ai/</link>
            <guid>41946188</guid>
            <pubDate>Fri, 25 Oct 2024 15:26:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnet.com/tech/mobile/with-apple-intelligence-on-the-horizon-a-quarter-of-smartphone-owners-are-unimpressed-by-ai/">https://www.cnet.com/tech/mobile/with-apple-intelligence-on-the-horizon-a-quarter-of-smartphone-owners-are-unimpressed-by-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=41946188">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Key takeaways:<br></h2><ul><li>A quarter of smartphone owners (25%) don't find AI features helpful, 45% are reluctant to pay a monthly subscription fee for AI capabilities and 34% have privacy concerns.</li><li>A little over half (52%) of smartphone owners have no interest in purchasing a foldable phone.</li><li>The biggest motivation for US adult smartphone owners to upgrade their devices is longer battery life (61%), followed by more storage (46%) and better camera features (38%). Just 18% say their main motivator is AI integrations.</li></ul><p>As smartphone makers including Apple, Google and Samsung place a growing emphasis on AI features in their latest devices, a CNET survey found a quarter of smartphone owners don't find those capabilities particularly useful, and just 18% say AI integrations are their main motivator for upgrading their phone.&nbsp;</p><div><div><svg><use xlink:href="#play"></use></svg> <figure><div><picture> <img src="https://www.cnet.com/a/img/resize/8064e8a5614e1aebc4a7ea0af4180156fcdc4f36/hub/2024/09/05/153a53a9-5c5a-44fa-87ee-bd7781666d2a/240905-site-iphone-16-tears-fans-apart-1.jpg?auto=webp&amp;width=768" alt="" height="306" width="768"> </picture></div> <!----></figure></div> <p><strong>Watch this:</strong> The iPhone 16 Comes With AI Drama
      </p> <p><time><svg><use xlink:href="#play"></use></svg> <span>07:37</span></time></p></div><p>In fact, the biggest drivers for buying a new device, according to respondents, is longer battery life (61%), more storage (46%) and better camera features (38%).&nbsp;</p><p>This comes as Apple gears up for the public launch of its&nbsp;<a href="https://www.cnet.com/tech/mobile/what-is-apple-intelligence-everything-to-know-about-iphone-16-ai-features/" target="_self" rel="follow">Apple Intelligence</a> suite of AI features <a href="https://www.cnet.com/tech/services-and-software/apple-releases-final-ios-18-1-public-beta-with-apple-intelligence-how-to-download-it/" target="_self" rel="follow">next week</a>, which includes capabilities like a&nbsp;<a href="https://www.cnet.com/tech/services-and-software/wwdc-kicks-off-what-apple-calls-a-new-era-for-siri/" rel="follow" target="_self">smarter Siri</a>,&nbsp;<a href="https://www.cnet.com/tech/mobile/apple-intelligence-arrives-but-only-in-developer-beta-for-now/" rel="follow" target="_self">AI-powered writing tools</a>&nbsp;and&nbsp;<a href="https://www.cnet.com/tech/mobile/apple-intelligence-brings-ai-to-the-iphone-with-chatgpt-integration-and-more/" rel="follow" target="_self">ChatGPT integration</a>. Apple Intelligence will be available on <a href="https://www.cnet.com/tech/mobile/apple-iphone-15-pro-and-15-pro-max-review-love-at-first-zoom/" target="_self" rel="follow">iPhone 15 Pro models</a> and the <a href="https://www.cnet.com/tech/mobile/apple-iphone-16-and-16-plus-review-little-improvements-add-up/" target="_self" rel="follow">iPhone 16</a> lineup.</p><p>Google also leaned heavily into AI features when it unveiled the <a href="https://www.cnet.com/tech/mobile/google-pixel-9-review-chock-full-of-ai-but-thats-not-what-makes-it-great/" target="_self" rel="follow">Pixel 9</a> series in August, spending much of its keynote <a href="https://www.cnet.com/tech/mobile/at-googles-pixel-9-event-gemini-steals-the-spotlight/" target="_self" rel="follow">discussing new Gemini functions</a>&nbsp;like <a href="https://www.cnet.com/tech/services-and-software/at-google-io-gemini-really-wants-to-talk-with-you/" target="_self" rel="follow">Live</a>, which lets you have a natural-sounding, back-and-forth conversation with the virtual assistant. And at its July <a href="https://www.cnet.com/tech/mobile/samsungs-jam-packed-galaxy-unpacked-galaxy-ring-z-fold-6-and-all-the-new-products-announced/" target="_self" rel="follow">Unpacked</a> event, Samsung similarly touted <a href="https://www.cnet.com/tech/mobile/my-favorite-samsung-galaxy-ai-features/" target="_self" rel="follow">Galaxy AI</a>, which can simplify tasks like translating messages and editing photos.</p><p>While these new features rely on generative AI to produce text or images or to enhance digital assistants, AI itself has been embedded in smartphones for years. For instance, your phone's camera uses AI to process images and blur backgrounds in Portrait mode, and Siri and Google Assistant have always been AI-based (albeit using less advanced versions of the tech). But because this new wave of AI introduces ways to more explicitly accomplish tasks on your phone, rather than blending into existing features, it may take some time for people to warm up to.</p><h2>AI could soon cost you -- and not everyone is sold</h2><p>As tech giants continue to roll out these AI functions, consumers may soon have to pay the price if they want to keep using them. Samsung's website says its Galaxy AI features "will be provided for free until the end of 2025 on supported Samsung Galaxy devices." To utilize Gemini's full power across Google's apps, you'll need to subscribe to <a href="https://www.cnet.com/tech/services-and-software/google-gemini-advanced-review-dont-cancel-your-chatgpt-plus-subscription/" target="_self" rel="follow">Gemini Advanced</a>. And it's likely Apple could also someday&nbsp;<a href="https://www.cnet.com/tech/mobile/apple-intelligence-may-eventually-cost-you/" rel="follow" target="_self">charge for some of its AI-powered iPhone features</a>.</p><p>Many <a href="https://www.cnet.com/tech/mobile/subscription-fatigue-ai-phone-features-will-soon-cost-us-why-im-not-sold/" target="_self" rel="follow">consumers aren't sold</a>. Nearly half of smartphone owners say they're not willing to pay extra money to access AI on their phones. That's not much of a surprise, given how much subscription fatigue is already weighing people down. Another&nbsp;<a href="https://www.cnet.com/personal-finance/subscription-creep-costs-us-consumers-more-than-1000-a-year-cnet-survey-finds/" rel="follow" target="_self">CNET study</a>&nbsp;from April found that US adults spend an average of $91 on subscription services every month. Two-thirds of respondents said at least one of their subscriptions got more expensive within the last year. Adding yet another monthly fee, therefore, may not be so enticing.&nbsp;</p><p>Still, there are those who are eager to tap into AI on their phones, with Gen Zers and Millennials being the most enthused: 20% of respondents from each generation say they're excited about AI capabilities and find them helpful. Additionally, 15% of Gen Zers and 16% of Millennials use AI on their phones for tasks like photo editing, image creation and summarizing or writing text. Also, 20% of Gen Zers and 19% of Millennials regularly use an AI tool like ChatGPT or Google Gemini on their smartphones.&nbsp;</p><p>Privacy remains a key concern when it comes to AI, with one-third (34%) of smartphone owners flagging their unease in that department. Tech giants have placed a growing emphasis on privacy considerations during their AI-focused keynotes. At its&nbsp;<a href="https://www.cnet.com/news-live/apple-wwdc-6-10-2024-live-blog/" rel="follow" target="_self">Worldwide Developers Conference</a>&nbsp;in June, for instance, Apple noted many of its <a href="https://www.cnet.com/tech/mobile/apple-intelligence-brings-ai-to-the-iphone-with-chatgpt-integration-and-more/" target="_self" rel="follow">AI models run on-device</a>, which is generally considered more private, since information doesn't have to travel over the internet. When a task calls for more computational power, relevant data will be sent to <a href="https://www.cnet.com/tech/services-and-software/apple-says-its-ai-sets-a-new-standard-for-privacy-invites-security-experts-to-test-it/" target="_self" rel="follow">Apple Silicon servers</a>, and that data <a href="https://www.apple.com/gn/newsroom/2024/06/apple-extends-its-privacy-leadership-with-new-updates-across-its-platforms/" target="_blank" rel="noopener nofollow">won't be stored</a> or made accessible to Apple, the company says.&nbsp;</p><h2>The biggest reasons to upgrade a phone</h2><p>With AI being among the last reasons consumers want to upgrade their smartphones, other considerations like longer battery life, more storage and better camera features still dominate. Other motivators include phone display and screen size (32%); keeping the same ecosystem, like iOS or Android (24%); and phone color (10%).&nbsp;</p><p>With the high cost of devices (many flagship phones will cost you anywhere between $800 and $1,200), consumers may not want to <a href="https://www.cnet.com/tech/mobile/getting-a-new-iphone-every-2-years-is-making-less-sense-than-ever/" target="_self" rel="follow">upgrade their devices as frequently</a>. According to our survey, 44% claim they only get a new device when their current phone breaks or needs replacing. Further, 30% hang onto their devices for three years or longer, while 18% upgrade every two years and just 8% get a new phone every year.&nbsp;</p><p>Luckily for consumers, Apple didn't implement a price hike with the <a href="https://www.cnet.com/deals/best-iphone-16-deals/" target="_self" rel="follow">iPhone 16</a>. Still, iPhone users hold onto their devices for longer than other smartphone owners; one-third will will wait three years or more for an upgrade.</p><h2>Foldable phone hype just isn't there yet</h2><p>Companies like Google and Samsung have continued to roll out foldable phones, with the latest being the <a href="https://www.cnet.com/tech/mobile/googles-pixel-9-pro-fold-might-be-a-sequel-that-actually-delivers/" target="_self" rel="follow">Pixel 9 Pro Fold</a> and the&nbsp;<a href="https://www.cnet.com/tech/mobile/galaxy-z-flip-6-review-the-aha-moment-that-sold-me-until-i-saw-the-price/" target="_self" rel="follow">Galaxy Z Flip</a> and <a href="https://www.cnet.com/tech/mobile/samsung-galaxy-z-fold-6-review-steps-forward-and-backward/" target="_self" rel="follow">Fold 6</a>, respectively. But consumers still feel lukewarm about the concept of a foldable handheld device. Just over half (52%) of smartphone owners say they're not interested in buying a foldable phone, while 13% say they'd be interested sometime in the next two years.</p><p>That gives Apple, which has yet to enter the foldable phone space, the opportunity to tap into that interest. Experts have long speculated that a <a href="https://www.cnet.com/tech/mobile/iphone-flip-apples-foldable-phone-could-arrive-before-folding-macbook-or-ipad/" target="_self" rel="follow">foldable iPhone</a> could be what it takes to spur wider adoption of foldable smartphones. But it may be several years before that happens, if it ever does.</p><h2>Methodology&nbsp;</h2><p>All figures, unless otherwise stated, are from YouGov Plc. Total sample size was 2,484 adults, including 2,387 smartphone owners. Fieldwork was undertaken Aug. 28-30, 2024. The survey was carried out online. The figures have been weighted and are representative of all US adults (aged 18-plus).</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Battleships Logic Puzzle (126 pts)]]></title>
            <link>https://lukerissacher.com/battleships</link>
            <guid>41946036</guid>
            <pubDate>Fri, 25 Oct 2024 15:12:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lukerissacher.com/battleships">https://lukerissacher.com/battleships</a>, See on <a href="https://news.ycombinator.com/item?id=41946036">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p>
            Click squares to set where you think the ships and water are. <br>
            Numbers show how many ship parts are on that row or column.
        </p>


        

        <h2>Instructions</h2>
        <p>
            I find these puzzles to be a fun mindless activity while listening to podcasts, thought I'd
            share them. They're a version of the <a href="https://en.wikipedia.org/wiki/Battleship_(puzzle)" target="_blank">
                Battleship Logic Puzzle</a> - also known as Battleship Solitaire, Bimaru, or Yubotu.
        </p>
        <p>
            Various sized ships (shown on top of the puzzle) are hidden on the board. 
            To solve the puzzle, fill all squares correctly.
            Numbers show how many "boat squares" are in each row or column:
        </p>
        <div>
            <p><img src="https://lukerissacher.com/static/images/battleships/boat_count_1.png?v=1518898716">
            </p>
            <p><img src="https://lukerissacher.com/static/images/battleships/boat_count_2.png?v=1518898728">
            </p>
        </div>
        <p>
            Ships can't touch, not even diagonally. 
        </p>

        

        <h2>Strategy Tips</h2>
        <p>
            If you get stuck during a game, these rules / tips can help:
        </p>

        <p>
            <strong>Only-spots-left rule:</strong> if a row has e.g. 3 boat squares and
            all but 3 squares are water, the rest must be boats:
        </p>
        <div>
            <p><img src="https://lukerissacher.com/static/images/battleships/only_spots_left.png?v=1518899129">
            </p>
        </div>

        <p>
            <strong>The-rest-is-water rule:</strong> likewise, if a row already has the
            required number of boats (including 0), the rest is water:
        </p>
        <div>
            <p><img src="https://lukerissacher.com/static/images/battleships/rest_is_water.png?v=1518899297">
            </p>
        </div>
        <p>
            Tip: you can click on these numbers to auto-fill water.
        </p>

        <p>
            <strong>Water-on-corners rule:</strong> since ships can't touch diagonally,
            you can always set the corners around a boat square to water:
        </p>
        <div>
            <p><img src="https://lukerissacher.com/static/images/battleships/fill_corners.png?v=1518899520">
            </p>
        </div>

        <p>
            <strong>Surround-whole-boats rule:</strong> if you know where a 
            whole boat is, you can surround it completely with water:
        </p>
        <div>
            <p><img src="https://lukerissacher.com/static/images/battleships/surround.png?v=1518899945">
            </p>
        </div>

        <p>
            <strong>Only-place-it-could-fit rule:</strong> often there's only one spot
            left on the board that the largest ship could fit:
        </p>
        <div>
            <p><img src="https://lukerissacher.com/static/images/battleships/only_fit.png?v=1518900280">
            </p>
        </div>

        <p>Playable on mobile devices, for on-the-toilet fun.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A deep dive into Linux's new mseal syscall (124 pts)]]></title>
            <link>https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/</link>
            <guid>41945894</guid>
            <pubDate>Fri, 25 Oct 2024 14:58:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/">https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/</a>, See on <a href="https://news.ycombinator.com/item?id=41945894">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">

			
				
<article id="post-108435">
	<!-- .entry-header -->

	<div>
		<p><em>By Alan Cao</em></p>
<p>If you love exploit mitigations, you may have heard of a new system call named <code>mseal</code> landing into the Linux kernel’s 6.10 release, providing a protection called “memory sealing.” Beyond notes from the authors, very little information about this mitigation exists. In this blog post, we’ll explain what this syscall is, including how it’s different from prior memory protection schemes and how it works in the kernel to protect virtual memory. We’ll also describe the particular exploit scenarios that <code>mseal</code> helps stop in Linux userspace, such as stopping malicious permissions tampering and preventing memory unmapping attacks.</p>
<h3>What mseal is (and isn’t)</h3>
<p>Memory sealing allows developers to make memory regions immutable from illicit modifications during program runtime. When a virtual memory address (VMA) range is sealed, an attacker with a code execution primitive cannot perform subsequent virtual memory operations to change the VMA’s permissions or modify how it is laid out for their benefit.</p>
<p>If you’re like me and followed the <a href="https://lore.kernel.org/lkml/CAHk-=wh+6n6f0zuezKem+W=aytHMv2bib6Fbrg-xnWOoujFb6g@mail.gmail.com/">spicy discourse</a>&nbsp;surrounding this syscall in the kernel mailing lists, you may have observed that Chrome’s Security team introduced it to support their <a href="https://v8.dev/blog/control-flow-integrity">V8 CFI strategy</a>, initially for Linux-based ChromeOS. After some lengthy deliberation and several rewrites, it finally landed in the kernel, with plans to expand its use case beyond browsers with <a href="https://lwn.net/Articles/978010/">its integration into glibc, possibly in version 2.41</a>.</p>
<p><code>mseal</code>’s security guarantees are unlike Linux’s <code>memfd_create</code> and its <code>memfd_secret</code> variant, which provide file sealing. <code>memfd_create</code> and <code>memfd_secret</code> allow one to create RAM-backed anonymous files as an alternative to storing content to <code>tmpfs</code>, with <code>memfd_secret</code> taking it a step further by ensuring that the region of memory is accessible only to the process holding the file descriptor. This lets developers create “secure enclave”-style userspace mappings that can guard sensitive in-memory data.</p>
<p><code>mseal</code> digresses from prior memory protection schemes on Linux because it is a syscall tailored specifically for <em>exploit mitigation</em> against remote attackers seeking code execution rather than potentially local ones looking to exfiltrate sensitive secrets in-memory.</p>
<p>To understand <code>mseal</code>’s security mitigations, we must first study its implementation to understand how it operates. Luckily, <code>mseal</code> is simple to understand, so let’s look at how it works in the kernel!</p>
<h3>A look under the hood</h3>
<p><code>mseal</code> has a simple function signature:</p>
<pre><span>int</span> mseal(<span>unsigned</span> long start, size_t len, <span>unsigned long</span> flags)
</pre>
<ul>
<li><code>start</code> and <code>len</code> represent the start/end range of a valid VMA that we want to seal, and len must be properly page-aligned.</li>
<li><code>flags</code> are unused at the time of writing and must be set to 0.</li>
</ul>
<p>In the 6.12 kernel, its syscall definition calls <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/mseal.c#L212"><code>do_mseal</code></a>:</p>
<pre><span>static</span> <span>int</span> do_mseal(<span>unsigned long</span> start, size_t len_in, <span>unsigned long</span> flags)
{
    size_t len;
    <span>int</span> ret = <span>0</span>;
    <span>unsigned long</span> end;
    <span>struct</span> mm_struct *mm = current-&gt;mm;     <span>// [1]</span>

    <span>// ... Check flags == 0, check page alignment, and compute `end`</span>

    <span>if</span> (mmap_write_lock_killable(mm))          <span>// [2]</span>
        <span>return</span> -EINTR;

    /*
     * First pass, <span>this</span> helps to avoid
     * partial sealing in <span>case</span> of <span>error</span> in input address range,
     * e.g. ENOMEM <span>error</span>.
     */
    ret = check_mm_seal(start, end);            <span>// [3]</span>
    <span>if</span> (ret)
        <span>goto</span> out;

    /*
     * Second pass, <span>this</span> should success, unless there are errors
     * from vma_modify_flags, e.g. merge/split <span>error</span>, or process
     * reaching the max supported VMAs, however, those cases shall
     * be rare.
     */
    ret = apply_mm_seal(start, end);            <span>// [4]</span> 

out:
    mmap_write_unlock(current-&gt;mm);
    <span>return</span> ret;
}
</pre>
<p><code>do_mseal</code> will first compute an <code>end</code> offset from the provided length and lock the memory region <code>[2]</code> to prevent concurrent access to the page. The global <code>current</code> at <code>[1]</code> represents the current executing <code>task_struct</code> (i.e., the process invoking <code>mseal</code>). The referenced field is the <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/include/linux/mm_types.h#L790"><code>mm_struct</code></a> representing the task’s entire virtual memory address space. The critical field in <code>mm_struct</code> on which this syscall will operate is <code>mmap</code>, a list of <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/include/linux/mm_types.h#L667"><code>vm_area_struct</code></a> values. This represents a single contiguous memory region created by <code>mmap</code>, such as the stack or VDSO.</p>
<p>The <code>check_mm_seal</code> call at <code>[3]</code> ensures that the targeted memory map for sealing is a valid range by iterating over each VMA from <code>current-&gt;mm</code> to test boundary correctness.</p>
<pre><span>static</span> <span>int</span> check_mm_seal(<span>unsigned long</span> start, <span>unsigned long</span> end)
{
    <span>struct</span> vm_area_struct *vma;
    <span>unsigned long</span> nstart = start;

    VMA_ITERATOR(vmi, current-&gt;mm, start);

    /* going through each vma to check. */
    for_each_vma_range(vmi, vma, end) {
        <span>if</span> (vma-&gt;vm_start &gt; nstart)
            /* unallocated memory found. */
            <span>return</span> -ENOMEM;
        <span>if</span> (vma-&gt;vm_end &gt;= end)
            <span>return</span> <span>0</span>;

        nstart = vma-&gt;vm_end;
    }
    <span>return</span> -ENOMEM;
}
</pre>
<p>The magic happens in the <code>apply_mm_seal</code> call <code>[4]</code>, which walks over each VMA again and arranges for the targeted region to have an additional <code>VM_SEALED</code> flag through the <code>mseal_fixup</code> call:</p>
<pre><span>static</span> <span>int</span> apply_mm_seal(<span>unsigned long</span> start, <span>unsigned long</span> end)
{
    // ...
    nstart = start;
    for_each_vma_range(vmi, vma, end) {
        <span>int</span> <span>error</span>;
        <span>unsigned long</span> tmp;
        vm_flags_t newflags;

        newflags = vma-&gt;vm_flags | VM_SEALED;
        tmp = vma-&gt;vm_end;
        <span>if</span> (tmp &gt; end)
            tmp = end;
        <span>error</span> = mseal_fixup(vmi, vma, &amp;prev, nstart, tmp, newflags);
        <span>if</span> (<span>error</span>)
            <span>return error</span>;
        nstart = vma_iter_end(&amp;vmi);
    }
    <span>return</span> <span>0</span>;
}
</pre>
<p>To ensure that unwanted memory operations respect this new flag, the <code>mseal</code> patchset adds <code>VM_SEALED</code> checks to the following files:</p>
<pre><span> mm/madvise.c                                |   12 +
 mm/mmap.c                                   |   31 +-
 mm/mprotect.c                               |   10 +
 mm/mremap.c                                 |   31 +
 mm/mseal.c                                  |  307 ++++
</span></pre>
<p>For instance, <code>mprotect</code> and <code>pkey_mprotect</code> will enforce this check when it eventually invokes <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/mprotect.c#L614"><code>mprotect_fixup</code></a>:</p>
<pre><span>int</span>
mprotect_fixup(..., <span>struct</span> vm_area_struct *vma, ...)
{
    <span>// ...</span>
    <span>if</span> (!can_modify_vma(vma))
        <span>return</span> -EPERM;
    }
    <span>// ...</span>
}
</pre>
<p>To determine whether the syscall should continue, <code>can_modify_vma</code>—defined in <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/vma.h#L534"><code>mm/vma.h</code></a>—will test for the existence of <code>VM_SEALED</code> in the specified <code>vm_area_struct</code>:</p>
<pre><span>static inline</span> bool vma_is_sealed(<span>struct</span> vm_area_struct *vma)
{
    <span>return</span> (vma-&gt;vm_flags &amp; VM_SEALED);
}

/*
 * check <span>if</span> a vma is sealed <span>for</span> modification.
 * <span>return</span> true, <span>if</span> modification is allowed.
 */
<span>static inline</span> bool can_modify_vma(<span>struct</span> vm_area_struct *vma)
{
    <span>if</span> (unlikely(vma_is_sealed(vma)))
        <span>return</span> false;

    <span>return</span> true;
}
</pre>
<p>From the changes in other memory-management syscalls, we can determine the operations that are not permitted on a VMA after it is sealed:</p>
<ul>
<li>Changing permission bits with <code>mprotect</code> and <code>pkey_mprotect</code></li>
<li>Unmapping with <code>munmap</code></li>
<li>Replacement of a sealed map with <code>mmap</code>(<code>MAP_FIXED</code>) with another one that is mutable/unsealed</li>
<li>Expanding or shrinking its size with <code>mremap</code>. Shrinking to zero could create a refillable hole for a new mapping with no sealing, as it triggers an unmap altogether.</li>
<li>Migrating to a new destination with <code>mremap(MREMAP_MAYMOVE | MREMAP_FIXED)</code>. Note that sealing checks are imposed on both the source and destination VMAs. Also, the source VMA will be unmapped if <code>MREMAP_DONTUNMAP</code> is not supplied, but the <code>munmap</code> sealing check will still apply.</li>
<li>Calling <code>madvise</code> with the <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/mseal.c#L26-#L32">following destructive flags</a></li>
</ul>
<p>For now, one can invoke <code>mseal</code> on a 6.10+ kernel through a direct syscall invocation. Here’s a basic wrapper implementation to help you get started:</p>
<pre>#<span>include</span> &lt;sys/syscall.h&gt;
#<span>include</span> <span>&lt;unistd.h&gt;</span>

#define MSEAL_SYSCALL <span>462</span>

<span>long</span> mseal(<span>unsigned long</span> start, size_t len)
{
    <span>int</span> page_size;
    uintptr_t page_aligned_start;

    /* how large a page should be on our system (<span>default</span>: <span>4096</span> bytes) */
    page_size = getpagesize();

    /* page align the VMA range we want to seal */
    page_aligned_start = start &amp; ~(page_size - 1);
    <span>return</span> syscall(MSEAL_SYSCALL, page_aligned_start, len, <span>0</span>);
}
</pre>
<h3>What exploit techniques does mseal help mitigate?</h3>
<p>From the disallowed operations, we can discern two particular exploit scenarios that memory sealing will prevent:</p>
<ul>
<li>Tampering with a VMA’s permissions. Notably, not allowing executable permissions to be set can stop the revival of shellcode-based attacks.</li>
<li>“Hole-punching” through arbitrary unmapping/remapping of a memory region, mitigating data-only exploits that take advantage of refilling memory regions with attacker-controlled data.</li>
</ul>
<p>Let’s examine these scenarios in more detail, and the defense-in-depth strategies developers can employ in their software implementations.</p>
<h4>Hardening NX</h4>
<p>Even with the continued existence of code reuse techniques like ROP, attackers may prefer to gain shellcoding capability during exploitation; this can provide a stable and “easy win,” especially if constraints are imposed on the gadget chain. Here is a potential workflow to achieve this:</p>
<ul>
<li>Through some target functionality, spray shellcode onto a non-executable stack/heap region.</li>
<li>Exploit the target’s bug to kick off an initial ROP chain to call <code>mprotect</code> with <code>PROT_EXEC</code> to target the region holding the shellcode and turn off the NX bit.</li>
<li>Jump to it to revive old-school shellcoding!</li>
</ul>
<p>The exploit for <a href="https://packetstormsecurity.com/files/146795/MikroTik-RouterOS-SMB-Buffer-Overflow.html">CVE-2018-7445</a> targeting Mikrotik RouterOS’s SMB daemon is a notable example. A socket-based shellcode is sprayed onto the non-executable heap, and the crafted ROP chain from a stack overflow modifies heap memory permissions before executing shellcode.</p>
<p>The most straightforward use case for memory sealing is disallowing VMA permission modification; once that happens, exploits that want to take advantage of traditional shellcode won’t be able to switch off executable bits.</p>
<p>As mentioned, <code>mseal</code> will be introduced in glibc 2.41+, where the dynamic loader will apply sealing across a <a href="https://lwn.net/Articles/978010/">predetermined set of VMAs</a>. However, at the time of writing, this will <em>not be done automatically for the stack or heap</em>.</p>
<p>This is expected because these regions can expand during runtime. For instance, a heap allocator that wants to reclaim space will invoke the <code>brk</code> syscall, which could call <code>arch_unmap</code> and eventually <code>do_vmi_unmap</code> to perform shrinking. Of course, this would be disallowed under sealing and thus break dynamic memory allocation for the application altogether.</p>
<p>So, for now, the software developer is responsible for protecting these regions, as they have the context to determine when and where sealing should be applied appropriately.</p>
<p>Let’s use <code>mseal</code> to enhance the stack’s old-school NX (non-executable) protection. Here’s a simple example that emulates the scenario mentioned above:</p>
<pre><span>int</span> main(<span>void</span>)
{
    /* represents the stack that now contains /bin/sh shellcode we somehow sprayed */
    <span>unsigned char</span> exec_shellcode[] =
<span>"\xe1\x45\x8c\xd2\x21\xcd\xad\xf2\xe1\x65\xce\xf2\x01\x0d\xe0\xf2"
"\xe1\x8f\x1f\xf8\xe1\x03\x1f\xaa\xe2\x03\x1f\xaa\xe0\x63\x21\x8b"
"\xa8\x1b\x80\xd2\xe1\x66\x02\xd4";</span>

    <span>// vulnerability triggered, hijacked instruction pointer</span>

    /* ======= what our ROP chain would do: ======= */


    /* compute the start of the page <span>for</span> the shellcode */
    <span>void</span> (*exec_ptr)() =  (<span>void</span>(*)())&amp;exec_shellcode;
    <span>void</span> *exec_offset = (<span>void</span> *)((int64_t) exec_ptr &amp; ~(getpagesize() - 1));

    mprotect(exec_offset, getpagesize(), PROT_READ|PROT_WRITE|PROT_EXEC);

    /* <span>this</span> now works! */
    exec_ptr();
    <span>return</span> <span>0</span>;
}
</pre>
<p>As we’d expect, setting <code>PROT_EXEC</code> on the VMA permits <code>exec_shellcode</code> to become executable again:</p>
<pre><span>~ gcc stack_no_sealing.c -o stack_no_sealing
~ ./stack_no_sealing
$
</span></pre>
<p>Let’s introduce memory sealing on the stack-based <code>exec_offset</code> VMA range:</p>
<pre><span>int</span> main(<span>void</span>)
{
    /* represents the stack that now contains /bin/sh shellcode we somehow sprayed */
    <span>unsigned char</span> exec_shellcode[] =
"\xe1\x45\x8c\xd2\x21\xcd\xad\xf2\xe1\x65\xce\xf2\x01\x0d\xe0\xf2"
"\xe1\x8f\x1f\xf8\xe1\x03\x1f\xaa\xe2\x03\x1f\xaa\xe0\x63\x21\x8b"
"\xa8\x1b\x80\xd2\xe1\x66\x02\xd4";

    /* compute the start of the page <span>for</span> the shellcode */
    <span>void</span> (*exec_ptr)() =  (<span>void</span>(*)())&amp;exec_shellcode;
    <span>void</span> *exec_offset = (<span>void</span> *)((int64_t) exec_ptr &amp; ~(getpagesize() - 1));

    /* seal the stack page containing the shellcode! */
    <span>if</span> (mseal(exec_offset, getpagesize()) &lt; <span>0</span>)
        handle_error(<span>"mseal"</span>);

    <span>// vulnerability triggered, hijacked instruction pointer</span>

    /* ======= what our ROP chain would <span>do</span>: ======= */

    mprotect(exec_offset, getpagesize(), PROT_READ|PROT_WRITE|PROT_EXEC);
    /* segfault now, as no permission change actually occurred */
    exec_ptr();
    <span>return</span> <span>0</span>;
}
</pre>
<p>The aforementioned <code>can_modify_vma</code> check kicks in when <code>mprotect</code> is called, preventing the permission change from ever happening, and the attempt to shellcode now fails:</p>
<pre><span>~ gcc stack_with_sealing.c -o stack_with_sealing
~ ./stack_with_sealing
[1]    48771 segmentation fault (core dumped)  ./stack_with_sealing
</span></pre>
<p>A simple strategy to accommodate real-world software could involve sparingly introducing a macro-ized version of the <code>mseal</code> code snippet and iteratively sealing pages in select stack frames where untrusted data could reside for exploitation:</p>
<pre>#define SIMPLE_HARDEN_NX_SINGLE_PAGE(frame) \
  <span>do</span> { \
    <span>void</span> *frame_offset = (<span>void</span> *)((int64_t) &amp;frame &amp; ~(getpagesize() - 1)); \
    <span>if</span> (mseal(frame_offset, getpagesize()) == -1) { \
      handle_error("mseal"); \
    } \
  } <span>while</span>(<span>0</span>)

<span>int</span> frame_2(void)
{
    <span>int</span> frame_start = <span>0</span>;
    <span>unsigned char</span> another_untrusted_buffer[<span>1024</span>] = { <span>0</span> };
    SIMPLE_HARDEN_NX_SINGLE_PAGE(frame_start);
    <span>return</span> <span>0</span>;
}

<span>int</span> frame_1(<span>void</span>)
{
    <span>unsigned char</span> untrusted_buffer[<span>1024</span>] = { <span>0</span> };
    SIMPLE_HARDEN_NX_SINGLE_PAGE(untrusted_buffer);
    <span>return</span> frame_2();
}
</pre>
<p>Even if a sealed VMA is reused as a frame for another function with sealing logic, invoking <code>mseal</code> again would be considered a no-op, so no errors would emerge. Of course, developers should be mindful of edge cases like automatic stack expansion from aggressive usage or bespoke features like <a href="https://gcc.gnu.org/wiki/SplitStacks">stack splitting</a>.</p>
<p>Hopefully, as the integration of <code>mseal</code> into glibc continues, we’ll see tunables emerge that do not require any manual use of the syscall for the stack. Commenters in the LWN mailing list <a href="https://lwn.net/Articles/958956/">yearn for an automatic sealing that can be toggled for simpler applications</a>.</p>
<p>And with all this said, if an attacker doesn’t want to fully ROP and insists on bringing back shellcode nostalgia, they could always use their initial code reuse technique to mmap a fresh region that is executable. However, this is pretty laborious, as it now involves copying the exploit payload from a readable region to this new mapping.</p>
<h4>Mitigating unmapping-based, data-only exploitation</h4>
<p>Disallowing <code>mprotect</code> also prevents a sealed region from becoming writable, which is valuable if there are data variables that, when modified, could enhance an exploit primitive. However, during the inception of <code>mseal</code>, Chrome maintainers rationalized an easier and more powerful technique with the added benefit of circumventing CFI (control-flow integrity). They determined that if an attacker can pass a corrupted pointer to unmapping/remapping syscalls, they can “punch a hole” in memory that could be refilled with attacker-controlled data. This would not violate CFI guarantees, as forward- and backward-edge CFI would cover only tampered control-flow transitions (e.g., stack return addresses and function pointers).</p>
<p>This is incredibly enticing for a browser implementing a JIT compiler. V8’s Turbofan can create regions that switch between RW and RX, aiding the refill process and changing permissions. Thus, an attacker can take advantage of the JIT compilation process by emitting executable code from hot-path JavaScript into the unmapped region to overwrite critical data and then leverage modifications to yield code execution.</p>
<p>We argue this is a <em>data-only</em> exploitation technique, as it doesn’t involve directly hijacking control flow or requiring leaked pointers but rather tampering with particular data in memory that influences control flow to the attacker’s liking. In an era of mitigations like CFI, this has emerged as a pretty potent technique during exploitation. Thus, memory sealing can prevent these particular data-only techniques by disallowing hole-punching scenarios.</p>
<p>This particular data-only technique isn’t just for browsers with JIT compilers! A similar technique would be the <a href="https://maxwelldulin.com/BlogPost/House-of-Muney-Heap-Exploitation">House of Muney</a> for userspace heap exploitation. As Max Dulin points out in his post, Qualys used this technique to perform a <a href="https://www.qualys.com/2020/05/19/cve-2005-1513/remote-code-execution-qmail.txt">real-world exploit for an ancient bug in Qmail</a>.</p>
<p>This technique relies on the fact that for huge allocated chunks (greater than the <a href="https://www.gnu.org/software/libc/manual/html_node/Malloc-Tunable-Parameters.html"><code>M_MAP_THRESHOLD</code></a> tunable), <code>malloc</code> and <code>free</code> will directly invoke <code>mmap</code> and <code>munmap</code>, respectively, with no intermediate freelists that cache any freed chunks (which helps greatly simplify exploitation). Since size metadata exists at the top of allocated chunks, tampering it to a different page size and freeing it would cause a <code>munmap</code> on memory regions adjacent to the chunk. Dulin used the arbitrary <code>munmap</code> to target the <code>.gnu.hash</code> and <code>.dynsym</code> regions and after refilling them with another larger mmap chunk, enabled the overwriting of a single, yet-to-be-resolved PLT entry, reviving a GOT overwrite-style attack!</p>
<p>Dulin has a very well-done and annotated PoC for this attack <a href="https://github.com/mdulin2/house-of-muney/blob/master/munmap_rewrite.c">here</a>. Here’s an abridged version that goes up to the point where the unmapping and refill occur:</p>
<pre>#<span>include</span> <span>&lt;stdio.h&gt;</span>
#<span>include</span> <span>&lt;string.h&gt;</span>
#<span>include</span> <span>&lt;stdlib.h&gt;</span>
#<span>include</span> <span>&lt;malloc.h&gt;</span>

<span>// With this allocation size,
// malloc is now equivalent to mmap
// free is now equivalent to munmap</span>
#define THRESHOLD_SIZE <span>0x100000</span>

<span>int</span> main() {
    <span>long long</span> *bottom, *top, *refill;

    bottom = malloc(THRESHOLD_SIZE);
    memset(bottom, <span>'B'</span>, THRESHOLD_SIZE);

    <span>// [1] Allocation that we write into out-of-bounds from a prior chunk</span>
    top = malloc(THRESHOLD_SIZE);
    memset(top, <span>'A'</span>, THRESHOLD_SIZE);

    <span>// [2] Corrupts size field, ensuring page alignment + mmap bit is set</span>
    <span>// size to unmap = top + bottom + large arbitrary size</span>
    <span>int</span> unmap_size = (<span>0xfffffffd</span> &amp; top[<span>-1</span>]) + (<span>0xfffffffd</span> &amp; bottom[<span>-1</span>]) + <span>0x14000</span>;
    top[<span>-1</span>] = (unmap_size | <span>2</span>);

    <span>// Trigger munmap with corrupted chunk</span>
    free(top);

    <span>// [3] Refill with new and larger mmap chunk</span>
    refill = malloc(<span>0x5F0000</span>);
    memset(refill, <span>'X'</span>, <span>0x5F0000</span>);
    <span>return</span> <span>0</span>;
}
</pre>
<p>By the time we finish <code>[1]</code>, we can see that the <code>top</code> and <code>bottom</code> chunks now exist in a separate mapping below the heap, separated by 4096-byte padding. Note the adjacent libc mapping at <code>0xfffff7df0000</code>:</p>
<p><img fetchpriority="high" decoding="async" data-attachment-id="108462" data-permalink="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/figure_1-9/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2.png" data-orig-size="1999,554" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_1" data-image-description="" data-image-caption="" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-300x83.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1650x457.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1650x457.png" alt="" width="690" height="191" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1650x457.png 1650w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-300x83.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-768x213.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1536x426.png 1536w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2.png 1999w" sizes="(max-width: 690px) 100vw, 690px"></p>
<p>At <code>[2]</code>, we corrupt the <code>size</code> field of the chunk to a much larger page size and ensure that the <code>mmap</code> bit is set. When we break on the <code>munmap</code> occurring in the free <code>[3]</code>, the <code>size</code> argument passed has been changed, allowing an unmap into the adjacent region!</p>
<p><img decoding="async" data-attachment-id="108463" data-permalink="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/figure_2-9/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2.png" data-orig-size="1658,700" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_2" data-image-description="" data-image-caption="" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-300x127.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1650x697.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1650x697.png" alt="" width="690" height="291" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1650x697.png 1650w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-300x127.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-768x324.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1536x648.png 1536w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2.png 1658w" sizes="(max-width: 690px) 100vw, 690px"></p>
<p>After <code>[3]</code>, this can be confirmed by examining the contents of the previous libc mapping at <code>0xfffff7df0000</code>, now partially overwritten with <code>X</code>s:</p>
<p><img decoding="async" data-attachment-id="108464" data-permalink="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/figure_3-9/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png" data-orig-size="1522,336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure_3" data-image-description="" data-image-caption="" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2-300x66.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png" alt="" width="1522" height="336" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png 1522w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2-300x66.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2-768x170.png 768w" sizes="(max-width: 1522px) 100vw, 1522px"></p>
<p>This is a pretty nifty data-only technique that can operate even in the presence of CFI and does not require a prerequisite ASLR leak!</p>
<p>Luckily, the aforementioned set of VMAs in <code>mseal</code>’s glibc integration is expected to automatically mitigate this without any developer intervention, as mapped binary code and dynamic libraries become sealed from any remap/unmapping tricks like this. For additional hardening, a developer can selectively seal mmap allocations that they know will never expand or become unmapped during the lifetime of their program. This will have the added benefit of preventing the previous exploit scenario if attacker-controlled data can be expected to be written into the mmap chunks and may become writable/executable.</p>
<h3>Build stronger software with mseal</h3>
<p>There are likely many other use cases and scenarios that we didn’t cover. After all, <code>mseal</code> is the newest kid on the block in the Linux kernel! As the glibc integration completes and matures, we expect to see improved iterations for the syscall to meet particular demands, including fleshing out the ultimate use of the <code>flags</code> parameter.</p>
<p>Hardening software is complex, as navigating and evaluating new security mitigations can be challenging in understanding the risk and reward payoff. If this blog post is interesting to you, check out some of our escapades into other <a href="https://blog.trailofbits.com/2023/04/20/typos-that-omit-security-features-and-how-to-test-for-them/">security</a> <a href="https://blog.trailofbits.com/2016/12/27/lets-talk-about-cfi-microsoft-edition/">mitigations</a>. If you’re seeking guidance in integrating <code>mseal</code> or any other modern mitigations into your software, <a href="https://www.trailofbits.com/contact/">contact us</a>!</p>

			</div><!-- .entry-content -->

	
</article><!-- #post-108435 -->
						<!-- #nav-below -->
		
					<!-- #comments .comments-area -->

			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plastic chemical phthalate causes DNA breakage, chromosome defects, study finds (177 pts)]]></title>
            <link>https://medicalxpress.com/news/2024-10-plastic-chemical-phthalate-dna-breakage.html</link>
            <guid>41945372</guid>
            <pubDate>Fri, 25 Oct 2024 13:59:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2024-10-plastic-chemical-phthalate-dna-breakage.html">https://medicalxpress.com/news/2024-10-plastic-chemical-phthalate-dna-breakage.html</a>, See on <a href="https://news.ycombinator.com/item?id=41945372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/plastic-chemical-cause.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/plastic-chemical-cause.jpg" data-sub-html="BBP exposure causes chromosome organization defects in the female germline. Carnoy's fixed and DAPI-stained images of gonads at the pachytene stage following exposure to DMSO or BBP. Images represent examples of gonads with normal germline configuration (first panel) or various chromosome organization defects in the germline including laggers (second panel), aggregates (third panel), and gaps (fourth panel). Yellow arrowheads indicate the respective defect in each panel. N = 27–31 gonads. Three biological repeats. Scale bar, 5 μm. Credit: Henderson et al, 2024, <i>PLOS Genetics</i>, CC-BY 4.0 (creativecommons.org/licenses/by/4.0/)">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/plastic-chemical-cause.jpg" alt="Plastic chemical causes causes DNA breakage and chromosome defects in sex cells" title="BBP exposure causes chromosome organization defects in the female germline. Carnoy's fixed and DAPI-stained images of gonads at the pachytene stage following exposure to DMSO or BBP. Images represent examples of gonads with normal germline configuration (first panel) or various chromosome organization defects in the germline including laggers (second panel), aggregates (third panel), and gaps (fourth panel). Yellow arrowheads indicate the respective defect in each panel. N = 27–31 gonads. Three biological repeats. Scale bar, 5 μm. Credit: Henderson et al, 2024, PLOS Genetics, CC-BY 4.0 (creativecommons.org/licenses/by/4.0/)" width="800" height="341">
             <figcaption>
                BBP exposure causes chromosome organization defects in the female germline. Carnoy's fixed and DAPI-stained images of gonads at the pachytene stage following exposure to DMSO or BBP. Images represent examples of gonads with normal germline configuration (first panel) or various chromosome organization defects in the germline including laggers (second panel), aggregates (third panel), and gaps (fourth panel). Yellow arrowheads indicate the respective defect in each panel. N = 27–31 gonads. Three biological repeats. Scale bar, 5 μm. Credit: Henderson et al, 2024, <i>PLOS Genetics</i>, CC-BY 4.0 (creativecommons.org/licenses/by/4.0/)
            </figcaption>        </figure>
    </div><p>A new study conducted on roundworms finds that a common plastic ingredient causes breaks in DNA strands, resulting in egg cells with the wrong number of chromosomes. Monica Colaiácovo of Harvard Medical School led the study, which was published October 24 in the journal <i>PLOS Genetics</i>.</p>

                                        
                                                                                  
                                         

                                                                                    <p>Benzyl butyl phthalate (BBP) is a chemical that makes plastic more flexible and durable, and is found in many consumer products, including food packaging, personal care products and children's toys. Previous studies have shown that BBP interferes with the body's hormones and affects <a href="https://medicalxpress.com/tags/human+reproduction/" rel="tag">human reproduction</a> and development, but the details of how it impacts reproduction have been unclear.</p>
<p>In the new study, researchers tested a range of doses of BBP on the nematode Caenorhabditis elegans and looked for abnormal changes in egg cells. They saw that at levels similar to those detected in humans, BBP interferes with how newly copied chromosomes are distributed into the sex cells. Specifically, BBP causes oxidative stress and breaks in the DNA strands, which lead to <a href="https://medicalxpress.com/tags/cell+death/" rel="tag">cell death</a> and egg cells with the wrong number of chromosomes.</p>
<p>Based on these findings, the researchers propose that BBP exposure alters <a href="https://medicalxpress.com/tags/gene+expression/" rel="tag">gene expression</a> in ways that cause significant damage to the DNA, ultimately leading to lower quality egg cells with abnormal chromosomes. The study also showed that C. elegans metabolizes BBP in the same way as mammals, and is impacted at similar BBP levels that occur in humans, suggesting that C. elegans is an effective model for studying the impacts on people. Overall, the study underscores the toxic nature of this very common plastic ingredient and the damage it causes to animal reproduction.</p>
<p>The authors summarize, "Here, examining the female germline in the nematode C. elegans, this study found that a level of exposure within the range detected in human serum and urine, alters gene expression linking increased germline <a href="https://medicalxpress.com/tags/oxidative+stress/" rel="tag">oxidative stress</a> with compromised genomic integrity and errors in meiotic chromosome segregation."</p>

                                                                                
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Henderson AL, Karthikraj R, Berdan EL, Sui SH, Kannan K, Colaiácovo MP (2024) Exposure to benzyl butyl phthalate (BBP) leads to increased double-strand break formation and germline dysfunction in Caenorhabditis elegans, <i>PLoS Genetics</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1371/journal.pgen.1011434" target="_blank">DOI: 10.1371/journal.pgen.1011434</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Plastic chemical phthalate causes DNA breakage and chromosome defects in sex cells, new study finds (2024, October 24)
                                                 retrieved 25 October 2024
                                                 from https://medicalxpress.com/news/2024-10-plastic-chemical-phthalate-dna-breakage.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Category Theory Illustrated: Logic(2021) (165 pts)]]></title>
            <link>https://abuseofnotation.github.io/category-theory-illustrated/05_logic/</link>
            <guid>41945308</guid>
            <pubDate>Fri, 25 Oct 2024 13:54:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/">https://abuseofnotation.github.io/category-theory-illustrated/05_logic/</a>, See on <a href="https://news.ycombinator.com/item?id=41945308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!--<h1>Logic</h1> -->

        

        

<p>Now let’s talk about one more <em>seemingly</em> unrelated topic just so we can “surprise” ourselves when we realize it’s category theory. By the way, in this chapter there will be another surprise in addition to that, so don’t fall asleep.</p>

<p>Also, I will not merely transport you to a different branch of mathematics, but to an entirely different discipline - <em>logic</em>.</p>

<h2 id="what-is-logic">What is logic</h2>

<p>Logic is the science of the <em>possible</em>. As such, it is at the root of all other sciences, all of which are sciences of the <em>actual</em>, i.e. that which really exists. For example, if science explains how our universe works then logic is the part of the description which is also applicable to any other universe that is <em>possible to exist</em>. A scientific theory aims to be consistent with both itself and observations, while a logical theory only needs to be consistent with itself.</p>

<p>Logic studies the <em>rules</em> by which knowing one thing leads you to conclude (or <em>prove</em>) that some other thing is also true, regardless of the things’ domain (e.g. scientific discipline) and by only referring to their form.</p>

<p>On top of that, it (logic) tries to organize those rules in <em>logical systems</em> (or <em>formal systems</em> as they are also called).</p>

<h2 id="logic-and-mathematics">Logic and mathematics</h2>

<p>Seeing this description, we might think that the subject of logic is quite similar to the subject of set theory and category theory, as we described it in the first chapter - instead of the word “formal” we used another similar word, namely “abstract”, and instead of “logical system” we said “theory”. This observation would be quite correct - today most people agree that every mathematical theory is actually logic plus some additional definitions added to it. For example, part of the reason why <em>set theory</em> is so popular as a theory for the foundations of mathematics is that it can be defined by adding just one single primitive to the standard axioms of logic which we will see shortly - the binary relation that indicates <em>set membership</em>. Category theory is close to logic too, but in a quite different way.</p>

<h2 id="primary-propositions">Primary propositions</h2>

<p>A consequence of logic being the science of the possible is that in order to do anything at all in it, we should have an initial set of propositions that we accept as true or false. These are also called “premises”, “primary propositions” or “atomic propositions” as Wittgenstein dubbed them.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/balls.svg" alt="Balls"></p>

<p>In the context of logic itself, these propositions are abstracted away (i.e. we are not concerned about them directly) and so they can be represented with the colorful balls that you are familiar with.</p>

<h2 id="composing-propositions">Composing propositions</h2>

<p>At the heart of logic, as in category theory, is the concept of <em>composition</em> - if we have two or more propositions that are somehow related to one another, we can combine them into one using a logical operators, like “and”, “or” “follows” etc. The results would be new propositions, which we might call <em>composite propositions</em> to emphasize the fact that they are not primary.</p>

<p>This composition resembles the way in which two monoid objects are combined into one using the monoid operation. Actually, some logical operations do form monoids, like for example the operation <em>and</em>, with the proposition $true$ serving as the identity element.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_monoid.svg" alt="Logical operations that form monoids"></p>

<p>However, unlike monoids/groups, logics study combinations not just with one but with <em>many</em> logical operations and <em>the ways in which they relate to one another</em>, for example, in logic we might be interested in the law of distributivity of <em>and</em> and $or$ operations and what it entails.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_distributivity.svg" alt="The distributivity operation of &quot;and&quot; and &quot;or&quot;"></p>

<p>Important to note that $∧$ is the symbol for <em>and</em> and $∨$ is the symbol for $or$ (although the law above is actually valid even if <em>and</em> and $or$ are flipped).</p>

<h2 id="the-equivalence-of-primary-and-composite-propositions">The equivalence of primary and composite propositions</h2>

<p>When looking at the last diagram, it is important to emphasize that,  propositions that are composed of several premises (symbolized by gray balls, containing some other balls) are not in any way different from “primary” propositions (single-color balls) and that they compose in the same way (although in the leftmost proposition the green ball is wrapped in a gray ball to make the diagram prettier).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/balls_propositions.svg" alt="Balls as propositions"></p>

<h2 id="modus-ponens">Modus ponens</h2>

<p>As an example of a proposition that contains multiple levels of nesting (and also as a great introduction of the subject of logic in its own right), consider one of the oldest (it was already known by Stoics at 3rd century B.C.) and most famous propositions ever, namely the <em>modus ponens</em>.</p>

<p>Modus ponens is a proposition that is composed of two other propositions (which here we denote $A$ and $B$) and it states that if proposition $A$ is true and also if proposition $(A → B)$ is true (that is if $A$ implies $B$), then $B$ is true as well. For example, if we know that “Socrates is a human” and that “humans are mortal” (or “being human implies being mortal”), we also know that “Socrates is mortal.”</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/modus_ponens.svg" alt="Modus ponens"></p>

<p>Let’s dive into this proposition. We can see that it is composed of two other propositions in a $follows$ relation, where the proposition that follows ($B$) is primary, but the proposition from which $B$ follows is not primary (let’s call that one $C$ - so the whole proposition becomes $C → B$.)</p>

<p>Going one more level down, we notice that the $C$ propositions is itself composed of two propositions in an <em>and</em>, relationship - $A$ and let’s call the other one $D$ (so $A ∧ D$), where $D$ is itself composed of two propositions, this time in a $follows$ relationship - $A → B$. But all of this is better visualized in the diagram.</p>

<h2 id="tautologies">Tautologies</h2>

<p>We often cannot tell whether a given composite proposition is true or false without knowing the values of the propositions that it is made of. However, with propositions such as <em>modus ponens</em> we can: modus ponens is <em>always true</em>, regardless of whether the propositions that form it are true or false. If we want to be fancy, we can also say that it is <em>true in all models of the logical system</em>, a model being a set of real-world premises are taken to be signified by our propositions.</p>

<p>For example, our previous example will not stop being true if we <em>substitute</em> “Socrates” with any other name, nor if we substitute “mortal” for any other quality that humans possess.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/modus_ponens_variations.svg" alt="Variation of modus ponens"></p>

<p>Propositions that are always true are called <em>tautologies</em>. And their more-famous counterparts that are always false are called <em>contradictions</em>. You can turn each tautology into contradiction or the other way around by adding a “not”.</p>

<p>The simplest tautology is the so called law of identity, the statement that each proposition implies itself (e.g. “All bachelors are unmarried”). It may remind you of something.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/tautology_identity.svg" alt="Identity tautology"></p>

<p>Here are some more complex (less boring) tautologies (the symbol $¬$ means “not”/negation.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/tautology_list.svg" alt="Tautologies"></p>

<p>We will learn how to determine which propositions are a tautologies shortly, but first let’s see why is this important at all i.e. what are tautologies good for.</p>

<h2 id="axiom-schemasrules-of-inference">Axiom schemas/Rules of inference</h2>

<p>Tautologies are useful because they are the basis of <em>axiom schemas</em>/<em>rules of inference</em>. And <em>axiom schemas</em> or <em>rules of inference</em> serve as starting point from which we can generate other true logical statements by means of substitution.</p>

<p>Realizing that the colors of the balls in modus ponens are superficial, we may want to represent the general structure of modus ponens that all of its variations share.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/modus_ponens_schema.svg" alt="Modus ponens"></p>

<p>This structure (the one that looks like a coloring book in our example) is called <em>axiom schema</em>. And the propositions that are produced by it are <em>axioms</em>.</p>

<p>Note that the propositions that we plug into the schema don’t have to be primary. For example, having the proposition $a$ (that is symbolized below by the orange ball) and the proposition stating that $a$ implies $a \lor b$ (which is one of the tautologies that we saw above), we can plug those propositions into the <em>modus ponens</em> and prove that $a \lor b$ is true.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/modus_ponens_composite.svg" alt="Using modus ponens for rule of inference"></p>

<p><em>Axiom schemas</em> and <em>rules of inference</em> are almost the same thing except that rules of inference allow us to actually distill the conclusion from the premises. For example in the case above, we can use modus ponens as a rule of inference to proves that $a \lor b$ is true.</p>

<p>All axiom schemas can be easily applied as rules of inference and the other way around.</p>

<h2 id="logical-systems">Logical systems</h2>

<p>Knowing that we can use axiom schemas/rules of inference to generate new propositions, we might ask whether it is possible to create a small collection of such schemas/rules that is curated in such a way that it enables us to generate <em>all</em> other propositions. You would be happy (although a little annoyed, I imagine) to learn that there exist not only one, but many such collections. And yes, collections of this sort are what we call <em>logical systems</em>.</p>

<p>Here is one such collection which consists of the following five axiom schemes <em>in addition to the inference rule modus ponens</em> (These are axiom schemes, even though we use colors).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/min_hilbert.svg" alt="A minimal collection of Hilbert axioms"></p>

<p>Proving that this and other similar logical systems are complete (can really generate all other propositions) is due to Gödel and is known as “Gödel’s completeness theorem” (Gödel is so important that I specifically searched for the “ö” letter so I can spell his hame right.)</p>

<h2 id="conclusion">Conclusion</h2>

<p>We now have an idea about how do some of the main logical constructs (axioms, rules of inference) work. But in order to prove that they are true, and to understand <em>what they are</em>, we need to do so through a specific <em>interpretation</em> of those constructs.</p>

<p>We will look into two interpretations - one very old and the other, relatively recent. This would be a slight detour from our usual subject matter of points and arrows, but I assure you that it would be worth it. So let’s start.</p>

<h2 id="classical-logic-the-truth-functional-interpretation">Classical logic. The truth-functional interpretation</h2>

<blockquote>
  <p>Beyond the world that we inhabit and perceive every day, there exist the <em>world of forms</em> where reside all ideas and concepts that manifest themselves in the objects that we perceive e.g. beyond all the people that have ever lived, there lies the prototypical person, and we are people only insofar as we resemble that person, beyond all the things in the world that are strong, lies the ultimate concepts of strength, from which all of them borrow etc. And although, as mere mortals, we live in the world of appearances and cannot perceive the world of forms, we can, through philosophy, “recollect” with it and know some of its features.</p>
</blockquote>

<p>The above is a summary of a worldview that is due to the Greek philosopher Plato and is sometimes called Plato’s <em>theory of forms</em>. Originally, the discipline of logic represents an effort to think and structure our thoughts in a way that they apply to this world of forms i.e. in a “formal” way. Today, this original paradigm of logic is known as “classical logic”. Although it all started with Plato, most of it is due to the 20th century mathematician David Hilbert.</p>

<p>The existence of the world of forms implies that, even if there are many things that we, people, don’t know and would not ever know, at least <em>somewhere out there</em> there exists an answer to every question. In logic, this translates to <em>the principle of bivalence</em> that states that <em>each proposition is either true or false</em>. And, due to this principle, propositions in classical logic can be aptly represented in set theory by the boolean set, which contains those two values.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/boolean_set.svg" alt="The set of boolean values"></p>

<p>According to the classical interpretation, you can think of <em>primary propositions</em> as just a bunch of boolean values. <em>Logical operators</em> are functions that take a one or several boolean values and return another boolean value (and <em>composite propositions</em> are, just the results of the application of these functions).</p>

<p>Let’s review all logical operators in this semantic context.</p>

<h2 id="the-negation-operation">The <em>negation</em> operation</h2>

<p>Let’s begin with the negation operation. Negation is a unary operation, which means that it is a function that takes just <em>one</em> argument and (like all other logical operators) returns one value, where both the arguments and the return type are boolean values.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/negation.svg" alt="negation"></p>

<p>The same function can also be expressed in a slightly less-fancy way by this table.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>¬p</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>

<p>Tables like this one are called <em>truth tables</em> and they are ubiquitous in classical logic. They can be used not only for defining operators but for proving results as well.</p>

<h2 id="interlude-proving-results-by-truth-tables">Interlude: Proving results by truth tables</h2>

<p>Having defined the negation operator, we are in position to prove the first of the axioms of the logical system we saw, namely the <em>double negation elimination</em>. In natural language, this axiom is equivalent to the observation that saying “I am <em>not unable</em> to do X” is the same as saying  “I am <em>able</em> to do it”.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/double_negation_formula.svg" alt="Double negation elimination formula"></p>

<p>(despite its triviality, the double negation axiom is probably the most controversial result in logic, we will see why later.)</p>

<p>If we view logical operators as functions from and to the set of boolean values, than proving axioms involves composing several of those functions into one function and observing its output. More specifically, the proof of the formula above involves just composing the negation function with itself and verifying that it leaves us in the same place from which we started.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/double_negation_proof.svg" alt="Double negation elimination"></p>

<p>If we want to be formal about it, we might say that applying negation two times is equivalent to applying the <em>identity</em> function.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/boolean_identity.svg" alt="The identity function for boolean values"></p>

<p>If we are tired of diagrams, we can represent the composition diagram above as table as well.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>¬p</th>
      <th>¬¬p</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>

<p>Each proposition in classical logic can be proved with such diagrams/tables.</p>

<h2 id="the-and-and-or-operations">The <em>and</em> and <em>or</em> operations</h2>

<p>OK, <em>you</em> know what <em>and</em> means and <em>I</em> know what it means, but what about those annoying people that want everything to be formally specified (nudge, nudge). Well we already know how we can satisfy them - we just have to construct the boolean function that represents <em>and</em>.</p>

<p>Because <em>and</em> is a <em>binary</em> operator, instead of a single value the function would accept a <em>pair</em> of boolean values.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/and.svg" alt="And"></p>

<p>Here is the equivalent truth-table (in which $∧$ is the symbol for <em>and</em>.)</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>q</th>
      <th>p ∧ q</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>

<p>We can do the same for $or$, here is the table.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>q</th>
      <th>p ∨ q</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>

<p><strong>Task:</strong> Draw the diagram for <em>or</em>.</p>

<p>Using those tables, we can also prove some axiom schemas we can use later:</p>

<ul>
  <li>For <em>and</em> $p ∧ q → p$ and $p ∧ q → q$ “If I am tired and hungry, this means that I am hungry”.</li>
  <li>For <em>or</em>:  $p → p ∨ q$ and $q → p ∨ q$ “If I have a pen this means that I am either have a pen or a ruler”.</li>
</ul>

<h2 id="the-implies-operation">The <em>implies</em> operation</h2>

<p>Let’s now look into something less trivial: the <em>implies</em> operation, (also known as <em>material condition</em>). This operation binds two propositions in a way that the truth of the first one implies the truth of the second one (or that the first proposition is a <em>necessary condition</em> for the second.) You can read $p → q$ as “if $p$ is true, then $q$ must also be true.</p>

<p>Implies is also a binary function - it is represented by a function from an ordered pair of boolean values, to a boolean value.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>q</th>
      <th>p → q</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>

<p>Now there are some aspects of this which are non-obvious so let’s go through every case.</p>

<ol>
  <li>If $p$ is true and $q$ is also true, then $p$ does imply $q$ - obviously.</li>
  <li>If $p$ is true but $q$ is false then $q$ does not follow from $p$ - cause $q$ would have been true if it did.</li>
  <li>If $p$ is false but $q$ is true, then $p$ still does imply $q$. What the hell? Consider that by saying that $p$ implies $q$ we don’t say that the two are 100% interdependent e.g. the claim that “drinking alcohol causes headache” does not mean that drinking is the only source of headaches.</li>
  <li>And finally if $p$ is false but $q$ is false too, then $p$ still does imply $q$ (just some other day).</li>
</ol>

<p>It might help you to remember that in classical logic $p → q$ ($p$ implies $q$) is true when $\neg p ∨ q$ (either $p$ is false or $q$ is true.)</p>

<h2 id="the-if-and-only-if-operation">The <em>if and only if</em> operation</h2>

<p>Now, let’s review the operation that indicates that two propositions are equivalent (or, when one proposition is <em>a necessary and sufficient condition</em> for the other (which implies that the reverse is also true.)) This operation yields true when the propositions have the same value.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>q</th>
      <th>p ↔ q</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>

<p>But what’s more interesting about this operation is that it can be constructed using the <em>implies</em> operation - it is equivalent to each of the propositions implying the other one (so $p \leftrightarrow q$ is the same as $p \to q \land q \to p$) - something which we can easily prove by comparing some truth tables.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>q</th>
      <th>p → q</th>
      <th>q → p</th>
      <th>p → q ∧ q → p</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
  </tbody>
</table>

<p>Because of this, the equivalence operation is called “if and only if”, or “iff” for short.</p>

<h2 id="proving-results-by-axiomsrules-of-inference">Proving results by axioms/rules of inference</h2>

<p>Let’s examine the above formula, stating that $p → q$ is the same as $¬p ∨ q$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/hilbert_formula.svg" alt="Hilbert formula"></p>

<p>We can easily prove this by using truth tables.</p>

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>q</th>
      <th>p → q</th>
      <th>¬p</th>
      <th>q</th>
      <th>¬p ∨ q</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>True</td>
      <td>True</td>
      <td><strong>True</strong></td>
      <td>False</td>
      <td>True</td>
      <td><strong>True</strong></td>
    </tr>
    <tr>
      <td>True</td>
      <td>False</td>
      <td><strong>False</strong></td>
      <td>False</td>
      <td>False</td>
      <td><strong>False</strong></td>
    </tr>
    <tr>
      <td>False</td>
      <td>True</td>
      <td><strong>True</strong></td>
      <td>True</td>
      <td>True</td>
      <td><strong>True</strong></td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
      <td><strong>True</strong></td>
      <td>True</td>
      <td>False</td>
      <td><strong>True</strong></td>
    </tr>
  </tbody>
</table>

<p>But it would be much more intuitive if we do it using axioms and rules of inference. To do so, we start with the formula we have ($p → q$) plus the axiom schemas, and arrive at the formula we want to prove ($¬p ∨ q$).</p>

<p>Here is one way to do it. The formulas that are used at each step are specified at the right-hand side, the rule of inference is modus ponens.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/hilbert_proof.svg" alt="Hilbert proof"></p>

<p>Note that to really prove that the two formulas are equivalent we have to also do it the other way around (start with ($¬p ∨ q$) and ($p → q$)).</p>

<h2 id="intuitionistic-logic-the-bhk-interpretation">Intuitionistic logic. The BHK interpretation</h2>

<blockquote>
  <p>[…] logic is life in the human brain; it may accompany life outside the brain but it can never guide it by virtue of its own power. — L.E.J. Brouwer</p>
</blockquote>

<p>I don’t know about you, but I feel that the classical truth-functional interpretation of logic (althought it works and is correct in its own right) doesn’t fit well the categorical framework that we are using here: It is too “low-level”, it relies on manipulating the values of the propositions. According to it, the operations <em>and</em> and <em>or</em> are just 2 of the 16 possible binary logical operations and they are not really connected to each other (but we know that they actually are.)</p>

<p>For these and other reasons, in the 20th century a whole new school of logic was founded, called <em>intuitionistic logic</em>. If we view classical logic as based on <em>set theory</em>, then intuitionistic logic would be based on <em>category theory</em> and its related theories. If <em>classical logic</em> is based on Plato’s theory of forms, then intuitionism began with a philosophical idea originating from Kant and Schopenhauer: the idea that the world as we experience it is largely predetermined of out perceptions of it. Thus without absolute standards for truth, a proof of a proposition becomes something that you <em>construct</em>, rather than something you discover.</p>

<p>Classical and intuitionistic logic diverge from one another right from the start: because according to intuitionistic logic we are <em>constructing</em> proofs rather than <em>discovering</em> them as some universal truth, we are <em>off with the principle of bivalence</em>. That is, in intuitionistic logic we have no basis to claim that each statements is necessarily <em>true or false</em>. For example, there might be a statements that might not be provable not because they are false, but simply because they fall outside of the domain of a given logical system (the twin-prime conjecture is often given as an example for this.)</p>

<p>Anyway, intuitionistic logic is not bivalent, i.e. we cannot have all propositions reduced to true and false.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/true_false.svg" alt="The True/False dichotomy"></p>

<p>One thing that we still do have there are propositions that are “true” in the sense that a proof for them is given - the primary propositions. So with some caveats (which we will see later) the bivalence between true and false proposition might be thought out as similar to the bivalence between the existence or absense of a proof for a given proposition - there either is a proof of it or there isn’t.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/proved_unproved.svg" alt="The proved/unproved dichotomy"></p>

<p>This bivalence is at the heart of what is called the Brouwer–Heyting–Kolmogorov (BHK) interpretation of logic, something that we will look into next.</p>

<p>The original formulation of the BHK interpretation is not based on any particular mathematical theory. Here, we will first illustrate it using the language of set theory (just so we can abandon it a little later).</p>

<h2 id="the-and-and-or-operations-1">The <em>and</em> and <em>or</em> operations</h2>

<p>As the existence of a proof of a proposition is taken to mean that the proposition is true, the definitions of <em>and</em> is rather simple - the proof of $A ∧ B$ is just <em>a pair</em> containing a proof of $A$, and a proof of $B$ i.e. <em>a set-theoretic product</em> of the two (see chapter 2). The principle for determining whether the proposition is true or false is similar to that of primary propositions - if the pair of proofs of $A$ and  $B$ exist (i.e. if both proofs exist) then the proof of $A \land B$ can be constructed (and so $A \land B$ is “true”).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/bhk_and.svg" alt="And in the BHK interpretation"></p>

<p><strong>Question:</strong> what would be the <strong>or</strong> operation in this case?</p>

<h2 id="the-implies-operation-1">The <em>implies</em> operation</h2>

<p>Now for the punchline: in the BHK interpretation, the <em>implies</em> operation is just a <em>function</em> between proofs. Saying that $A$ implies $B$ ($A \to B$) would just mean that there exist a function which can convert a proof of $A$ to a proof of $B$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/bhk_implies.svg" alt="Implies in the BHK interpretation"></p>

<p>And, (it gets even more interesting) the <em>modus ponens</em> rule of inference is nothing more than the process of <em>functional application</em>. i.e. if we have a proof of $A$ and a function $A \to B$ we can call this function to obtain a proof of $B$.</p>

<p>(In order to define this formally, we also need to define functions in terms of sets i.e. we need to have a set representing $A \to B$ for each $A$ and $B$. We will come back to this later.)</p>

<h2 id="the-if-and-only-if-operation-1">The <em>if and only if</em> operation</h2>

<p>In the section on classical logic, we proved that two propositions $A$ and $B$ are equivalent if $A$ implies $B$ and $B$ implies $A$. But if the <em>implies</em> operation is just a function, then proposition are equivalent precisely when there are two functions, converting each of them to the other i.e. when the sets containing the propositions are <em>isomorphic</em>.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/bhk_iff.svg" alt="Implies in the BHK interpretation"></p>

<p>(Perhaps we should note that <em>not all set-theoretic functions are proofs</em>, only a designated set of them (which we call <em>canonical</em> functions) i.e. in set theory you can construct functions and isomorphisms between any pair of singleton sets, but that won’t mean that all proofs are equivalent.)</p>

<h2 id="the-negation-operation-1">The <em>negation</em> operation</h2>

<p>So according to BHK interpretation saying that $A$ is true, means that that we possess a proof of $A$ - simple enough. But it’s a bit harder to express the fact that $A$ is false: it is not enough to say that we <em>don’t have a proof</em> of $A$ (the fact that don’t have it, doesn’t mean it doesn’t exist). Instead, we must show that claiming that $A$ is true leads to a <em>contradiction</em>.</p>

<p>To express this, intuitionistic logic defines the constant $⊥$ which plays the role of <em>False</em> (also known as the “bottom value”). $⊥$ is defined as the proof of a formula that does not have any proofs. And the equivalent of false propositions are the ones that imply that the bottom value is provable (which is a contradiction). So $¬A$ is $A \to ⊥$.</p>

<p>In set theory, the $⊥$ constant is expressed by the empty set.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/bhk_false.svg" alt="False in the BHK interpretation"></p>

<p>And the observation that propositions that are connected to the bottom value are false is expressed by the fact that if a proposition is true, i.e. there exists a proof of it, then there can be no function from it to the empty set.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/bhk_false_function.svg" alt="False in the BHK interpretation"></p>

<p>The only way for there to be such function is if the set of proofs of the proposition is empty as well.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/bhk_false_function_2.svg" alt="False in the BHK interpretation"></p>

<p><strong>Task:</strong> Look up the definition of function and verify that there cannot exist a function from any set <em>to the empty set</em></p>

<p><strong>Task</strong> Look up the definition of function and verify that there does exist a function <em>from the empty set</em> to itself (in fact there exist a function from the empty set to any other set.</p>

<h2 id="the-law-of-excluded-middle">The law of excluded middle</h2>

<p>Although intuitionistic logic differs a lot from classical logic when it comes to its <em>semantics</em>, i.e. in the way the whole system is built (which we described above), it actually doesn’t differ so much in terms of <em>syntax</em>, i.e. if we try to deduce the axiom schemas/rules of inference that correspond to the definitions of the structures outlined above, we would see that they are virtually the same as the ones that define classical logic. There is, however, one exception concerning the <em>double negation elimination axiom</em> that we saw earlier, a version of which is known as <em>the law of excluded middle</em>.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/excluded_middle_formula.svg" alt="The formula of the principle of the excluded middle"></p>

<p>This law is valid in classical logic and is true when we look at its truth tables, but there is no justification for it terms of the BHK interpretation. Why? in intuitionistic logic saying that something is false amounts to <em>constructing a proof</em> that it is false (that it implies the bottom value) and there is no method/function/alghorithm that can either prove that a given proposition is either true and false.</p>

<p>The question of whether you can use the law of excluded middle spawned a heated debate between the classical logic proponent David Hilbert and the intuitionistic logic proponent L.E.J. Brouwer, known as <em>the Brouwer–Hilbert controversy</em>.</p>

<h2 id="logics-as-categories">Logics as categories</h2>

<p>Leaving the differences between intuitionistic and classical logics aside, the BHK interpretation is interesting because it provides that higher-level view of logic, that we need in order to construct a interpretation of it based on category theory.</p>

<p>Such higher-level interpretations of logic are sometimes called <em>algebraic</em> interpretations, <em>algebraic</em> being an umbrella term describing all structures that can be represented using category theory, like groups and orders.</p>

<h2 id="the-curry-howard-isomorphism">The Curry-Howard isomorphism</h2>

<p>Programmers might find the definition of the BHK interpretation interesting for other reason - it is very similar to a definition of a programming language: propositions are <em>types</em>, the <em>implies</em> operations are <em>functions</em>, <em>and</em> operations are composite types (objects), and <em>or</em> operations are <em>sum types</em> (which are currently not supported in most programming languages, but that’s a separate topic). Finally a proof of a given proposition is represented by a value of the corresponding type. 
<img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_curry.svg" alt="Logic as a programming language"></p>

<p>This similarity is known as the <em>Curry-Howard isomorphism</em>.</p>

<p><strong>Task:</strong> The Curry-Howard isomorphism is also the basis of special types of programming languages called “proof assistants” which help you verify logical proofs. Install a proof assistant and try to see how it works (I recommend the Coq Tutorial by Mike Nahas).</p>

<h2 id="cartesian-closed-categories">Cartesian closed categories</h2>

<p>Knowing about the Curry-Howard isomorphism and knowing also that programming languages can be described by category theory may lead us to think that <em>category theory is part of this isomorphism as well</em>. And we would be quite correct — this is why it is sometimes known as the Curry-Howard-<em>Lambek</em> isomorphism (Joachim Lambek being the person who formulated the categorical side). So let’s examine this isomorphism. As all other isomorphisms, it comes in two parts:</p>

<p>The first part is finding a way to convert a <em>logical system</em> into a category - this would not be hard for us, as sets form a category and the flavor of the BHK interpretation that we saw is based on sets.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/category_curry_logic.svg" alt="Logic as a category"></p>

<p><strong>Task:</strong> See whether you can prove that logic propositions and the “implies” relation form a category. What is missing?</p>

<p>The second part involves converting a category into a logical system - this is much harder. To do it, we have to enumerate the criteria that a given category has to adhere to, in order for it to be “logical”. These criteria have to guarantee that the category has objects that correspond to all valid logical propositions and no objects that correspond to invalid ones.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_curry_category.svg" alt="Logic as a category"></p>

<p>Categories that adhere to these criteria are called <em>cartesian closed categories</em>. To describe them here directly, but instead we would start with a similar but simpler structures that we already examined - orders.</p>

<h2 id="logics-as-orders">Logics as orders</h2>

<p>So, we already saw that a logical system along with a set of primary propositions forms a category.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_category.svg" alt="Logic as a preorder"></p>

<p>If we assume that there is only one way to go from proposition $A$, to proposition $B$ (or there are many ways, but we are not interested in the difference between them), then logic is not only a category, but a <em>preorder</em> in which the relationship “bigger than” is taken to mean “implies”, so ($A \to B$ is $A &gt; B$).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_preorder.svg" alt="Logic as a preorder"></p>

<p>Furthermore, if we count propositions that follow from each other (or sets of propositions that are proven by the same proof) as equivalent, then logic is a proper <em>partial order</em>.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_order.svg" alt="Logic as an order"></p>

<p>And so it can be represented by a Hasse diagram, in which $A \to B$ only if $A$ is below $B$ in the diagram.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_hasse.svg" alt="Logic as an order"></p>

<p>This is something quite characteristic of category theory — examining a concept in a more limited version of a category (in this case orders), in order to make things simpler for ourselves.</p>

<p>Now let’s examine the question that we asked before - exactly which <del>categories</del> orders represent logic and what laws does an order have to obey so it is isomorphic to a logical system? We will attempt to answer this question as we examine the elements of logic again, this time in the context of orders.</p>

<h2 id="the-and-and-or-operations-2">The and and or operations</h2>

<p>By now you probably realized that the <em>and</em> and <em>or</em> operations are the bread and butter of logic (although it’s not clear which is which). As we saw, in the BHK interpretation those are represented by set <em>products</em> and <em>sums</em>. The equivalent constructs in the realm of order theory are <em>meets</em> and <em>joins</em> (in category-theoretic terms <em>products</em> and <em>coproducts</em>.)</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/lattice_meet_join.svg" alt="Order meet and joing"></p>

<p>Logic allows you to combine any two propositions in and <em>and</em> or <em>or</em> relationship, so, in order for an order to be “logical” (to be a correct representation for a logical system,) <em>it has to have $meet$ and $join$ operations for all elements</em>. Incidentally we already know how such orders are called - they are called <em>lattices</em>.</p>

<p>And there is one important law of the  <em>and</em> and <em>or</em> operations, that is not always present in all lattices. It concerns the connection between the two, i.e. way that they distribute, over one another.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_distributivity.svg" alt="The distributivity operation of &quot;and&quot; and &quot;or&quot;"></p>

<p>Lattices that obey this law are called <em>distributive lattices</em>.</p>

<p>Wait, where have we heard about distributive lattices before? In the previous chapter we said that they are isomorphic to <em>inclusion orders</em> i.e. orders of sets, that contain a given collection of elements, and that contain <em>all combinations</em> of a given set of elements. The fact that they popped up again is not coincidental — “logical” orders are isomorphic to inclusion orders. To understand why, you only need to think about the BHK interpretation — the elements which participate in the inclusion are our prime propositions. And the inclusions are all combinations of these elements, in an <em>or</em> relationship (for simplicity’s sake, we are ignoring the <em>and</em> operation.)</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/logic_poset_inclusion.svg" alt="A color mixing poset, ordered by inclusion"></p>

<p>The <em>or</em> and <em>and</em> operations (or, more generally, the <em>coproduct</em> and the <em>product</em>) are, of course, categorically dual, which would explain why the symbols that represent them $\lor$ and $\land$ are the one and the same symbol, but flipped vertically.</p>

<p>And even the symbol itself looks like a representation of the way the arrows converge. This is probably not the case, as this symbol is used way before Hasse diagrams were a thing — for all we know the $\lor$ symbol is probably symbolizes the “u” in “uel” (the latin word for “or”) and the <em>and</em> symbol is just a flipped “u”) — but I still find the similarity fascinating.</p>

<h2 id="the-negation-operation-2">The <em>negation</em> operation</h2>

<p>In order for a distributive lattice to represent a logical system, it has to also have objects that correspond to the values <em>True</em> and <em>False</em> (which are written $\top$ and $\bot$). But, to mandate that these objects exist, we must first find a way to specify what they are in order/category-theoretic terms.</p>

<p>A well-known result in logic, called <em>the principle of explosion</em>, states that if we have a proof of <em>False</em> (which we write as $\bot$) i.e. if we have a statement “<em>False</em> is true” if we use the terminology of classical logic, then any and every other statement can be proven. And we also know that no true statement implies <em>False</em> (in fact in intuitionistic logic this is the definition of a true statement). Based on these criteria we know that the <em>False</em> object would look like this when compared to other objects:</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/lattice_false.svg" alt="False, represented as a Hasse diagram"></p>

<p>Circling back to the BHK interpretation, we see that the empty set fits both of these conditions.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/lattice_false_bhk.svg" alt="False, represented as a Hasse diagram"></p>

<p>Conversely, the proof of <em>True</em> which we write as $\top$, expressing the statement that “<em>True</em> is true”, is trivial and doesn’t say anything, so <em>nothing follows from it</em>, but at the same time it follows from every other statement.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/lattice_true.svg" alt="True, represented as a Hasse diagram"></p>

<p>So <em>True</em> and <em>False</em> are just the <em>greatest</em> and <em>least</em> objects of our order (in category-theoretic terms <em>terminal</em> and <em>initial</em> object.)</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/lattice_true_false.svg" alt="The whole logical system, represented as a Hasse diagram"></p>

<p>This is another example of the categorical concept of duality - $\top$ and $\bot$ are dual to each other, which makes a lot of sense if you think about it, and also helps us remember their symbols (althought if you are like me, you’ll spent a year before you stop wondering which one is which, every time I see them).</p>

<p>So in order to represent logic, our distributive lattice has to also be <em>bounded</em> i.e. it has to have greatest and least elements (which play the roles of <em>True</em> and <em>False</em>).</p>

<h2 id="the-implies-operation-2">The <em>implies</em> operation</h2>

<p>As we said, every lattice has representations of propositions implying one another (i.e. it has arrows), but to really represents a logical system it also has to have <em>function objects</em> i.e. there needs to be a rule that identifies a unique object $A → B$ for each pair of objects $A$ and $B$, such that all axioms of logic are followed.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/implies.svg" alt="Implies operation"></p>

<p>We will describe this object in the same way we described all other operations — by defining a structure consisting of a of objects and arrows in which $A → B$ plays a part. And this structure is actually a categorical reincarnation our favorite rule of inference, the <em>modus ponens</em>.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/implies_modus_ponens.svg" alt="Implies operation"></p>

<p>Modus ponens is the essence of the <em>implies</em> operation, and, because we already know how the operations that it contains (<em>and</em> and <em>implies</em>) are represented in our lattice, we can directly use it as a definition by saying that the object $A → B$ is the one for which modus ponens rule holds.</p>

<blockquote>
  <p>The function object $A → B$ is an object which is related to objects $A$ and $B$ in such a way that such that $A ∧ (A → B) → B$.</p>
</blockquote>

<p>This definition is not complete, however, because (as usual) $A → B$ is <em>not the only object</em> that fits in this formula. For example, the set $A → B ∧ C$ is also one such object, as is $A → B ∧ C ∧ D$ (not going to draw all the arrows here, because it will get too (and I mean too) messy).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/implies_modus_ponens_impostors.svg" alt="Implies operation with universal property"></p>

<p>So how do we set apart the real formula from all those “imposter” formulas? If you remember the definitions of the <em>categorical product</em> (or of its equivalent for orders, the <em>meet</em> operation) you would already know where this is going: we recognize that $A \to B$ is the upper <em>limit</em> of $A → B ∧ C$ and $A → B ∧ C ∧ D$ and all other imposter formulas that can be in the place of $X$ in $A ∧ X → B$. The relationship can be described in a variety of ways:</p>

<ul>
  <li>We can say that $A \to B$ is the most <em>trivial</em> result for which the formula $A ∧ X → B$ is satisfied and that all other results are <em>stronger</em>.</li>
  <li>We can say that all other results imply $A \to B$ but not the other way around.</li>
  <li>We can say that all other formulas lie <em>below</em> $A → B$ in the Hasse diagram.</li>
</ul>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/implies_universal_property.svg" alt="Implies operation with universal property"></p>

<p>So, after choosing the best way to express the relationship (they are all equivalent) we are ready to present our final definition:</p>

<blockquote>
  <p>The function object $A → B$ is the topmost object which is related to objects $A$ and $B$ in such a way that $A ∧ (A → B) → B$.</p>
</blockquote>

<p>The existence of this function object (called <em>exponential object</em> in category-theoretic terms) is the final condition for an order/lattice to be a representation of logic.</p>

<p>Note, by the way, that this definition of function object is valid specifically for intuinistic logic. For classical logic, the definition of  is simpler — there $A → B$ is just $\lnot A ∨ B$, because of the law of excluded middle.</p>

<h2 id="the-if-and-only-if-operation-2">The <em>if and only if</em> operation</h2>

<p>When we examined the <em>if and only if</em> operation can be defined in terms <em>implies</em>, that is $A \leftrightarrow B$ is equivalent to $A \to B \land B \to A$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/isomorphism.svg" alt="Implies identity"></p>

<p>We have something similar for categorical logic as well — We say that when two propositions are connected to each other, then, particularily when we speak of orders, they are isomorphic.</p>

<h2 id="a-taste-of-categorical-logic">A taste of categorical logic</h2>

<p>In the previous section we saw some definitions, here we will convince ourselves that they really capture the concept of logic correctly, by proving some results using categorical logic.</p>

<h2 id="true-and-false">True and False</h2>

<p>The join (or least upper bound) of the <em>topmost</em> object $\top$ (which plays the role of the value <em>True</em>) and any other object that you can think of, is… $\top$ itself (or something isomorphic to it, which, as we said, is the same thing). This follows trivially from the fact that the join of two objects must be bigger or equal than both of these objects, and that there is no other object that is bigger or equal to the $\top$ is $\top$ itself. This is simply because $\top$ (as any other object) is equal to itself and because there is by definition no object that is bigger than it.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/join_true.svg" alt="Implies identity"></p>

<p>This corresponds to the logical statement that $A \lor \top$ is equal to $\top$ i.e. it is true. Hence, the above observation is a proof of that statement, (an alternative to truth tables).</p>

<p><strong>Task</strong>: Think of the duel situation, with False. What does it imply, logically?</p>

<h2 id="and-and-or">And and Or</h2>
<p>Above, we saw that the join between any random object and the top object is the top object itself. But, does this situation only occur when the second object is $\top$? Wouldn’t the same thing happen if $\top$ it is replaced by any other object that is higher than the first one?</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/join_bigger_true.svg" alt="Implies identity"></p>

<p>The answer is “Yes”: when we are looking for the join of two object, we are looking for the <em>least</em> upper bound i.e. the <em>lowest</em> object that is above both of them. So, any time we have two objects and one is higher than the other, their join would be (isomorphic to) the higher object.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/join_bigger.svg" alt="Implies identity"></p>

<p>In other words, if $A \to B$, then $A \land B \leftrightarrow B$</p>

<h2 id="implies">Implies</h2>

<p>For our first example with implies, let’s take the formula $A → B$, and examine the case when $A$ and $B$ are the same object. We said that, $A → B$ ($A → A$ in our case) is the topmost object $X$ for which the criteria given by the formula $A ∧ X → B$ is satisfied. But in this case, the formula is satisfied for any $X$, (because it evaluates to $A ∧ X → A$, which is always true), i.e. the topmost object that satisfies it is… the topmost object there is i.e. (an object isomorphic to) $True$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/implies_identity.svg" alt="Implies identity"></p>

<p>Does this make sense? Of course it does: in fact, we just proved one of the most famous laws in logic (called the law of identity, as per Aristotel), namely that $A → A$ is always true, or that everything follows from itself.</p>

<p>And what happens if $A$ implies $B$ in any model, i.e. if $A \models B$ (semantic consequence)? In this case, $A$ would be below $B$ in our Hasse diagram (e.g. $A$ is the blue ball and $B$ is the orange one). Then the situation is somewhat similar to the previous case: $A ∧ X → B$ will be true, no matter what $X$ is (simply because $A$ already implies $B$, by itself). And so $A → B$ will again correspond to the $True$ object.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/05_logic/implies_b_follows.svg" alt="Implies when A follows from B"></p>

<p>This is again a well-known result in logic (if I am not mistaken, it will be a deduction theorem of some sort): if $A \models B$), then the statement $(A → B)$ will always be true.</p>

<!--
If and only if
---

Now for the a more complicated task: what would happen if $A$ is above $B$ i.e. if $B \models A$? What would the topmost object that fits the formula $(A ∧ X) → B$ then? Well, in this case there are many objects $A \land X$ that are also above $B$ and so they *don't* imply $B$. The highest such object that is below $B$ (so it can still imply $B$) would be... $B$ itself (as it literary sets the upper bound).

![Implies when B follows from A](../05_logic/implies_a_follows.svg)

Translated to logical language, this says that if we have $B \models A$, then the proof of $A → B$ coincides with the proof of $B$.
-->

<!--
Classical VS intuitionistic logic
===

So, we already formulated the definition of intuitionistic logic in terms of order/lattice --- it is represented by a lattice that is bounded (i.e. has greatest and least objects ($True$ and $False$)) and that has function objects (the law of distributivity which we mentioned earlier is always true for lattices that have function object).

More interestingly, a lattice can follow the laws of *classical logic*, as well. it has to be *bounded* and *distributive* and in addition to that it has to be *complemented* which is to say that each proposition $A$, there exist an a unique proposition $\neg A$ (such that $A ∨ \neg A = 1$ and $A ∧ \neg A = 0$). These lattices are called *boolean algebras*.

Constructive proofs
---

Intuitionistic logic is also called *constructive* logic, or constructive mathematics. And the proofs in intuitionistic logic are constructive.


Proving a negative
---

If classical logic is based on the belief that everything is either true or false, intuitionistic logic gives precedence to the famous common-sense principle that *you cannot prove a negative*.

which means that while you can given a true statement and follow the arrows to reach other true statements, false statements would remain unreachable.

Given a logical system, consisting of axioms and rules of inference, I define positive statements as statements of the type "X follows from the axioms" and negative statements as statements of type  "X does not follow from the axioms".

Given those definitions, a positive statement is proven by just applying the rules of inference to the axioms until you reach the statement you want to prove, while there is no general way to prove a negative statement.

![Path from truth](../05_logic/paths_truth.svg)


 https://www.algebraicjulia.org/blog/post/2021/09/cset-graphs-4/

https://personal.math.ubc.ca/~cytryn/teaching/scienceOneF10W11/handouts/OS.proof.4methods.html

https://en.wikibooks.org/wiki/Mathematical_Proof/Methods_of_Proof#Direct_proof
-->



        
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on the new Claude analysis JavaScript code execution tool (112 pts)]]></title>
            <link>https://simonwillison.net/2024/Oct/24/claude-analysis-tool/</link>
            <guid>41943662</guid>
            <pubDate>Fri, 25 Oct 2024 09:40:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2024/Oct/24/claude-analysis-tool/">https://simonwillison.net/2024/Oct/24/claude-analysis-tool/</a>, See on <a href="https://news.ycombinator.com/item?id=41943662">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2024/Oct/24/claude-analysis-tool/">

<p>24th October 2024</p>



<p>Anthropic <a href="https://www.anthropic.com/news/analysis-tool">released a new feature</a> for their <a href="http://claude.ai/">Claude.ai</a> consumer-facing chat bot interface today which they’re calling “the analysis tool”.</p>
<p>It’s their answer to OpenAI’s <a href="https://simonwillison.net/tags/code-interpreter/">ChatGPT Code Interpreter</a> mode: Claude can now chose to solve models by writing some code, executing that code and then continuing the conversation using the results from that execution.</p>
<p>You can enable the new feature on the <a href="https://claude.ai/new?fp=1">Claude feature flags page</a>.</p>
<p>I tried uploading a <code>uv.lock</code> dependency file (which uses TOML syntax) and telling it:</p>
<blockquote>
<p><code>Write a parser for this file format and show me a visualization of what's in it</code></p>
</blockquote>
<p>It gave me this:</p>
<p><img alt="Claude screenshot. I've uploaded a uv.lock file and prompted &quot;Write a parser for this file format and show me a visualization of what's in it&quot; Claude: I'll help create a parser and visualization for this lockfile format. It appears to be similar to a TOML-based lock file used in Python package management. Let me analyze the structure and create a visualization. Visible code: const fileContent = await window.fs.readFile('uv.lock', { encoding: 'utf8' }); function parseLockFile(content) ... On the right, an SVG visualization showing packages in a circle with lines between them, and an anyio package description" src="https://static.simonwillison.net/static/2024/analysis-uv-lock.jpg"></p>
<p>Here’s <a href="https://gist.github.com/simonw/b25198899f92bdd7f15830567a07e319">that chat transcript</a> and <a href="https://static.simonwillison.net/static/2024/uv-lock-vis/index.html">the resulting artifact</a>. I upgraded my <a href="https://observablehq.com/@simonw/convert-claude-json-to-markdown">Claude transcript export tool</a> to handle the new feature, and hacked around with <a href="https://simonwillison.net/2024/Oct/23/claude-artifact-runner/">Claude Artifact Runner</a> (manually editing the source to replace <code>fs.readFile()</code> with a constant) to build the React artifact separately.</p>
<p>ChatGPT Code Interpreter (and the under-documented <a href="https://ai.google.dev/gemini-api/docs/code-execution">Google Gemini equivalent</a>) both work the same way: they write Python code which then runs in a secure sandbox on OpenAI or Google’s servers.</p>
<p>Claude does things differently. It uses JavaScript rather than Python, and it executes that JavaScript directly in your browser—in a locked down <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers">Web Worker</a> that communicates back to the main page by intercepting messages sent to <code>console.log()</code>.</p>
<p>It’s implemented as a tool called <code>repl</code>, and you can prompt Claude like this to reveal some of the custom instructions that are used to drive it:</p>
<blockquote>
<p><code>Show me the full description of the repl function</code></p>
</blockquote>
<p>Here’s <a href="https://gist.github.com/simonw/348b4ef2289cb5b1dee9aea9863bbc01">what I managed to extract</a> using that. This is how those instructions start:</p>
<blockquote>
<p><strong>What is the analysis tool?</strong></p>
<p>The analysis tool <em>is</em> a JavaScript REPL. You can use it just like you would use a REPL. But from here on out, we will call it the analysis tool.</p>
<p><strong>When to use the analysis tool</strong></p>
<p>Use the analysis tool for:</p>
<ul>
<li>Complex math problems that require a high level of accuracy and cannot easily be done with “mental math”<ul>
<li>To give you the idea, 4-digit multiplication is within your capabilities, 5-digit multiplication is borderline, and 6-digit multiplication would necessitate using the tool.</li>
</ul>
</li>
<li>Analyzing user-uploaded files, particularly when these files are large and contain more data than you could reasonably handle within the span of your output limit (which is around 6,000 words).</li>
</ul>
</blockquote>
<p>The analysis tool has access to a <code>fs.readFile()</code> function that can read data from files you have shared with your Claude conversation. It also has access to the <a href="https://lodash.com/">Lodash</a> utility library and <a href="https://www.papaparse.com/">Papa Parse</a> for parsing CSV content. The instructions say:</p>
<blockquote>
<p>You can import available libraries such as lodash and papaparse in the analysis tool. However, note that the analysis tool is NOT a Node.js environment. Imports in the analysis tool work the same way they do in React. Instead of trying to get an import from the window, import using React style import syntax. E.g., you can write <code>import Papa from 'papaparse';</code></p>
</blockquote>
<p>I’m not sure why it says “libraries such as ...” there when as far as I can tell Lodash and papaparse are the <em>only</em> libraries it can load—unlike Claude Artifacts it can’t pull in other packages from its CDN.</p>
<p>The interaction between the analysis tool and Claude Artifacts is somewhat confusing. Here’s the relevant piece of the tool instructions:</p>
<blockquote>
<p>Code that you write in the analysis tool is <em>NOT</em> in a shared environment with the Artifact. This means:</p>
<ul>
<li>To reuse code from the analysis tool in an Artifact, you must rewrite the code in its entirety in the Artifact.</li>
<li>You cannot add an object to the <code>window</code> and expect to be able to read it in the Artifact. Instead, use the <code>window.fs.readFile</code> api to read the CSV in the Artifact after first reading it in the analysis tool.</li>
</ul>
</blockquote>
<p>A further limitation of the analysis tool is that any files you upload to it are currently added to the Claude context. This means there’s a size limit, and also means that only text formats work right now—you can’t upload a binary (as I found when I tried uploading <a href="https://github.com/sqlite/sqlite-wasm/tree/main/sqlite-wasm/jswasm">sqlite.wasm</a> to see if I could get it to use SQLite).</p>
<p>Anthropic’s Alex Albert says <a href="https://twitter.com/alexalbert__/status/1849501507005149515">this will change in the future</a>:</p>
<blockquote>
<p>Yep currently the data is within the context window—we’re working on moving it out.</p>
</blockquote>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Smarter Than 'Ctrl+F': Linking Directly to Web Page Content (200 pts)]]></title>
            <link>https://alfy.blog/2024/10/19/linking-directly-to-web-page-content.html</link>
            <guid>41943098</guid>
            <pubDate>Fri, 25 Oct 2024 07:41:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alfy.blog/2024/10/19/linking-directly-to-web-page-content.html">https://alfy.blog/2024/10/19/linking-directly-to-web-page-content.html</a>, See on <a href="https://news.ycombinator.com/item?id=41943098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Historically, we could link to a certain part of the page only if that part had an ID. All we needed to do was to link to the URL and add the <em>document fragment</em> (ID). If we wanted to link to a certain part of the page, we needed to anchor that part to link to it. This was until we were blessed with the <strong><a href="https://wicg.github.io/scroll-to-text-fragment/">Text fragments</a></strong>!</p>

<h3 id="what-are-text-fragments">What are Text fragments?</h3>

<p>Text fragments are a powerful feature of the modern web platform that allows for precise linking to specific text within a web page without the need to add an anchor! This feature is complemented by the <code>::target-text</code> CSS pseudo-element, which provides a way to style the highlighted text.</p>

<p>Text fragments work by appending a special syntax to the end of a URL; just like we used to append the ID after the hash symbol (<code>#</code>). The browser interprets this part of the URL, searches for the specified text on the page, and then scrolls to and highlights that text if it supports text fragments. If the user attempts to navigate the document by pressing tab, the focus will move on to the next focusable element after the text fragment.</p>
<h3 id="how-can-we-use-it">How can we use it?</h3>

<p>Here’s the basic syntax for a text fragment URL:</p>

<pre><code>
https://example.com/page.html#:~:text=[prefix-,]textStart[,textEnd][,-suffix]

</code></pre>

<p>Following the hash symbol, we add this special syntax <code>:~:</code> also known as <em>fragment directive</em> then <code>text=</code> followed by:</p>

<ol>
  <li><code>prefix-</code>: A text string preceded by a hyphen specifying what text should immediately precede the linked text. This helps the browser to link to the correct text in case of multiple matches. This part is not highlighted.</li>
  <li><code>textStart</code>: The beginning of the text you’re highlighting.</li>
  <li><code>textEnd</code>: The ending of the text you’re highlighting.</li>
  <li><code>-suffix</code>: A hyphen followed by a text string that behaves similarly to the prefix but comes after the text. Aslo helpful when multiple matches exist and doesn’t get highlighted with the linked text.</li>
</ol>

<p>For example, the following link:</p>

<pre><code>
https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments#:~:text=without%20relying%20on%20the%20presence%20of%20IDs

</code></pre>

<p>This text fragment we are using is “without relying on the presence of IDs” but it’s <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/encodeURIComponent">encoded</a>. If you follow <a href="https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments#:~:text=without%20relying%20on%20the%20presence%20of%20IDs">this link</a>, it should look like the following:</p>

<p><img src="https://alfy.blog/images/2024/02/screenshot-01.png" alt="Screenshot from Google Chrome showing how highlighted text fragment look in Google Chrome"></p>

<p>We can also highlight a range of text by setting the <code>startText</code> and the <code>endText</code>. Consider the following example from the same URL:</p>

<pre><code>
https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments#:~:text=using%20particular,don't%20control

</code></pre>

<p>The text fragment we are using is “using particular” followed by a comma then “don’t control”. If you follow <a href="https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments#:~:text=using%20particular,don't%20control">this link</a>, it should look like the following:</p>

<p><img src="https://alfy.blog/images/2024/02/screenshot-02.png" alt="Screenshot from Google Chrome showing highlighted text fragment with start text and end text"></p>

<p>We can also highlight multiple texts by using ampersands. Consider the following:</p>

<pre><code>
https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments#:~:text=using%20particular&amp;text=it%20allows

</code></pre>

<p>If you follow <a href="https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments#:~:text=using%20particular&amp;text=it%20allows">this link</a>, it should look like the following:</p>

<p><img src="https://alfy.blog/images/2024/02/screenshot-03.png" alt="Screenshot from Google Chrome showing different highlighted text fragment"></p>

<p>One of the interesting behaviors about text fragments, is if you’re linking to hidden content that’s discoverable through <em>find-in-page</em> feature (e.g. children of element with hidden attribute set to <code>until-found</code> or content of a closed details element), the hidden content will become visible. Let’s look at this behavior by linking to <a href="https://www.scottohara.me/blog/2022/09/12/details-summary.html">this article</a> from Scott O’Hara’s blog. The blog contains the details element that is closed by default.</p>

<p><img src="https://alfy.blog/images/2024/02/screenshot-04.png" alt="Screenshot from Scott O'Hara's blog showing a details section"></p>

<p>If we <a href="https://www.scottohara.me/blog/2022/09/12/details-summary.html#:~:text=Oh%20hi%20there.%20Forget%20your%20summary,%20didja">linked to the text fragment</a> inside the details element, it will open automatically:</p>

<pre><code>
https://www.scottohara.me/blog/2022/09/12/details-summary.html#:~:text=Oh%20hi%20there.%20Forget%20your%20summary,%20didja

</code></pre>

<p><img src="https://alfy.blog/images/2024/02/screenshot-05.png" alt="Screenshot from Scott O'Hara's blog showing a details section and it opens because it matches the text fragment inside the details section"></p>

<p><strong>Note</strong> that this behavior is <strong>only available in Google Chrome</strong> as it’s the only browser to support discoverable content.</p>

<h3 id="styling-highlighted-fragments">Styling highlighted fragments</h3>

<p>If the browser supports text fragments, we can change the style of the highlighted text by using the <code>::target-text</code> pseudo-element</p>

<pre><code>::target-text {
    background-color: yellow;
}
</code></pre>

<p>Note that we are only allowed to change the following properties:</p>

<ul>
  <li>color</li>
  <li>background-color</li>
  <li>text-decoration and its associated properties (including text-underline-position and text-underline-offset)</li>
  <li>text-shadow</li>
  <li>stroke-color, fill-color, and stroke-width</li>
  <li>custom properties</li>
</ul>

<h3 id="browser-support-and-fallback-behaviour">Browser support and fallback behaviour</h3>

<p>Text fragments are currently <a href="https://caniuse.com/mdn-html_elements_a_text_fragments">supported in all the browsers</a>. The pseudo-element <code>::target-text</code> is not yet supported is Safari but it’s now available in the Technology Preview version. If this feature is not supported in the browser, it will degrade gracefully and the page will load without highlighting or scrolling to the text.</p>

<p>The default style for the highlight is different based on the browser. The color of the highlight is different across the different browsers. The highlighted area is bigger in Safari spanning the whole line-height. In Firefox and Chrome, only the text is highlighted and the spaces between the lines are empty.</p>

<p><img src="https://alfy.blog/images/2024/02/comparison.png" alt="Demonstration of the differences in text highlight between the different browsers"></p>

<p>We can detect if the feature is supported or not using <code>document.fragmentDirective</code>. It will return an empty FragmentDirective object, if supported or will return undefined if it’s not.</p>

<h3 id="closing-thoughts">Closing thoughts</h3>

<p>My first encounter with text fragments was through links generated by Google Search results. Initially, I assumed it was a Chrome-specific feature and not part of a broader web standard. However, I soon realized that this functionality was actually built upon the open web, available to any browser that chooses to implement it.</p>

<p>I’d love to see this feature used more broadly, particularly by responsible generative AI systems. Imagine AI that can provide direct, context-sensitive links to the exact content you’re interested in, using text fragments for precise references. This would not only increase transparency but also improve the user experience when navigating AI-generated content.</p>

<p>Looking ahead, it would be fantastic if text fragments were more accessible to all users, not just those with technical knowledge. What if browsers offered built-in features that allowed non-technical users to highlight text and generate links to specific paragraphs with ease? This could be through a native browser feature or even a simple browser extension—either way, it would make deep linking a breeze for everyone.</p>

<p>Finally, I’d like to express my sincere thanks to <a href="https://hannaholukoye.com/">Hannah Olukoye</a> and <a href="https://meiert.com/">Jens Oliver Meiert</a> for the time they’ve taken to share their invaluable feedback and corrections.</p>

<h3 id="update-20th-oct-2024">Update, 20th Oct, 2024</h3>

<p>It turns out that the ability to generate a link to a specific piece of text is already built into Chromium-based browsers, as <a href="https://x.com/HosamSultan_">Hostam Sultan</a> <a href="https://x.com/HosamSultan_/status/1847768998349328553">clarified on X</a> (formerly Twitter). If you’re using Chrome, simply highlight some text, right-click, and you’ll find the “Copy link to highlight” option in the context menu.</p>

<h3 id="additional-resources">Additional resources</h3>

<ul>
  <li>URL Fragment Text Directives - <a href="https://wicg.github.io/scroll-to-text-fragment/">W3C Draft Community Group Report</a></li>
  <li>Text Fragments: <a href="https://developer.mozilla.org/en-US/docs/Web/URI/Fragment/Text_fragments">MDN</a></li>
  <li>Style Highlights: <a href="https://drafts.csswg.org/css-pseudo/#highlight-styling">CSSWG Draft</a></li>
  <li>Support for Text Fragments: <a href="https://caniuse.com/mdn-html_elements_a_text_fragments">CanIUse</a></li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The brain's waste clearing lymphatic system shown in people for first time (256 pts)]]></title>
            <link>https://www.nih.gov/news-events/nih-research-matters/brain-waste-clearance-system-shown-people-first-time</link>
            <guid>41942096</guid>
            <pubDate>Fri, 25 Oct 2024 03:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nih.gov/news-events/nih-research-matters/brain-waste-clearance-system-shown-people-first-time">https://www.nih.gov/news-events/nih-research-matters/brain-waste-clearance-system-shown-people-first-time</a>, See on <a href="https://news.ycombinator.com/item?id=41942096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-content">
                <h2>You are here</h2>          
                <div about="/news-events/nih-research-matters/brain-waste-clearance-system-shown-people-first-time" typeof="sioc:Item foaf:Document" role="main">

  
  <p><span property="dc:date" datatype="xsd:dateTime" content="2024-10-22T00:00:00-04:00">October 22, 2024</span></p><div><div><h3>At a Glance</h3>

<ul>
	<li>A study in five volunteers undergoing surgery confirmed the existence of channels that may help drain waste from the brain.</li>
	<li>The&nbsp;results highlight the importance of ongoing research to boost the functioning of this waste-clearance system, called the glymphatic system.</li>
</ul></div><p>Though less well-known than the body’s blood vessels, the lymphatic system is also vital to health. The network of lymphatic vessels threaded throughout the body removes dead cells and other waste from the bloodstream. It also helps transport the immune cells that fight infections.</p>

<p>It was once thought that the lymphatic system didn’t reach into the brain. But over the last dozen years, researchers have found a system of vessels containing cerebrospinal fluid in brain tissue in mice. These vessels appear to connect to the lymphatic system and to help clear toxins from the brain.</p>

<p>Studies suggest that age-related or physical damage to this brain waste-clearing system, called the glymphatic system, may contribute to the development of Alzheimer’s disease and other cognitive disorders.</p>

<p>Researchers have observed the real-time workings of the glymphatic system in mice. Studies using human brain samples taken after death found hints of such vessels. But to date, the existence of a functioning glymphatic system hadn’t been confirmed in living people.</p>

<p>In a new study, funded in part by NIH, researchers led by Dr. Juan Piantino from Oregon Health &amp; Science University recruited five volunteers who needed surgery to remove a brain tumor. During this surgery, the volunteers received an injection of a dye called gadolinium into their cerebrospinal fluid. They then underwent MRI scans to track the passage of dye into the brain. Results from the study were published on October 7, 2024, in the <em>Proceedings of the National Academy of Sciences</em>.</p>

<p>One volunteer underwent MRI using a technology called T2/FLAIR at 12 and 24 hours after surgery, and the other 4 underwent T2/FLAIR imaging at 24 and 48 hours after surgery.</p>

<p>The scans showed cerebrospinal fluid flowing into the brain through distinct channels—along the perivascular spaces, the fluid-filled spaces that run alongside blood vessels in the brain. These findings match earlier imaging results seen in mice. Dye could also be seen moving from these spaces into the functional tissue of the brain.&nbsp;</p>

<p>“This shows that cerebrospinal fluid doesn’t just get into the brain randomly, as if you put a sponge in a bucket of water,” Piantino says. “It goes through these channels.”</p>

<p>Other studies have suggested that the glymphatic system may be most active during sleep. These new results support the importance of efforts to boost or repair the glymphatic system, such as improving sleep quality for people at risk for Alzheimer’s disease and other dementias.</p>

<p>—by Sharon Reynolds</p></div><h2>Related Links</h2><ul><li><a href="https://www.nih.gov/news-events/nih-research-matters/study-shows-how-aura-may-lead-migraine-headache" target="_top">Study Shows How Aura May Lead to Migraine Headache</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/gaps-allow-substances-move-out-brain" target="_top">Gaps Allow Substances to Move in and Out of the Brain</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/immune-cells-control-waste-clearance-brain" target="_top">Immune Cells Control Waste Clearance in the Brain</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/boosting-brains-waste-removal-system-could-improve-alzheimers-outcomes" target="_top">Boosting Brain’s Waste Removal System Could Improve Alzheimer’s Outcomes</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/impaired-brain-drainage-aging-alzheimers" target="_top">Impaired Brain Drainage in Aging and Alzheimer’s</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/brain-cleaning-system-uses-lymphatic-vessels" target="_top">Brain Cleaning System Uses Lymphatic Vessels</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/lymphatic-vessels-discovered-central-nervous-system" target="_top">Lymphatic Vessels Discovered in Central Nervous System</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/how-sleep-clears-brain" target="_top">How Sleep Clears the Brain</a></li><li><a href="https://www.nih.gov/news-events/nih-research-matters/new-brain-cleaning-system-discovered" target="_top">New Brain Cleaning System Discovered</a></li><li><a href="https://www.ninds.nih.gov/health-information/public-education/brain-basics" target="_top">Brain Basics</a></li></ul><p><strong>References:&nbsp;</strong><a href="https://pubmed.ncbi.nlm.nih.gov/39374384/">The perivascular space is a conduit for cerebrospinal fluid flow in humans: A proof-of-principle report.</a> Yamamoto EA, Bagley JH, Geltzeiler M, Sanusi OR, Dogan A, Liu JJ, Piantino J. Proc Natl Acad Sci U S A. 2024 Oct 15;121(42):e2407246121. doi: 10.1073/pnas.2407246121. Epub 2024 Oct 7. PMID: 39374384.</p><p><strong>Funding:&nbsp;</strong>NIH’s National Heart, Lung, and Blood Institute (NHLBI); Medical Research Foundation of Oregon; North American Skull Base Society.</p>  
  
</div>
                
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cerebras Inference now 3x faster: Llama3.1-70B breaks 2,100 tokens/s (140 pts)]]></title>
            <link>https://cerebras.ai/blog/cerebras-inference-3x-faster</link>
            <guid>41941883</guid>
            <pubDate>Fri, 25 Oct 2024 03:04:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cerebras.ai/blog/cerebras-inference-3x-faster">https://cerebras.ai/blog/cerebras-inference-3x-faster</a>, See on <a href="https://news.ycombinator.com/item?id=41941883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we’re announcing the biggest update to Cerebras Inference since launch. Cerebras Inference now runs Llama 3.1-70B at an astounding 2,100 tokens per second – a 3x performance boost over the prior release. For context, this performance is:</p>
<ul>
<li>
<ul>
<li>16x faster than the fastest GPU solution</li>
<li>8x faster than GPUs running Llama3.1-3B, a model 23x smaller</li>
<li>Equivalent to a new GPU generation’s performance upgrade (H100/A100) in a single software release</li>
</ul>
</li>
</ul>
<p>Fast inference is the key to unlocking the next generation of AI apps. From voice, video, to advanced reasoning, fast inference makes it possible to build responsive, intelligent applications that were previously out of reach. From Tavus revolutionizing video generation to GSK accelerating drug discovery workflows, leading companies are already using Cerebras Inference to push the boundaries of what’s possible. Try Cerebras Inference using chat or API at inference.cerebras.ai.</p>
<h3>Benchmarks</h3>
<p>Cerebras Inference has been rigorously tested by Artificial Analysis, a third-party benchmarking organization. We reproduce their performance charts below.</p>
</div><p>In output speed per user, Cerebras Inference is in a league of its own – 16x faster than the most optimized GPU solution, 68x faster than hyperscale clouds, and 4-8x faster than other AI accelerators.</p><p>Time to first token is critical for real time applications. Cerebras is tied second place in first token latency, showing the advantage of a wafer-scale integrated solution vs. complex networked solutions.</p><p>Total response time – measuring a full turn of input and output – is a good proxy for multi-step agentic workflows. Here Cerebras Inference completes a full request in just 0.4 of a second vs. 1.1 to 4.2 seconds on GPU based solutions. For agents, this means getting up to 10x more work done in the same time. For reasoning models, this enables 10x more reasoning steps without increasing response time.</p><div><p>Cerebras Inference running Llama3.1 70B is now so fast that it outruns GPU based inference running Llama3.1 3B. The Wafer Scale Engine runs an AI model 23x larger at 8x speed for a combined 184x performance advantage.</p>
<h3>Optimized kernels, stack, and ML</h3>
<p>The first release of Cerebras Inference in August set new speed records and made Llama3.1-70B an instantaneous experience. While it was incredibly fast, it was the first implementation of inference on the Wafer Scale Engine and utilized only a fraction of its peak bandwidth, compute, and IO capacity. Today’s release is the culmination of numerous software, hardware, and ML improvements we made to our stack to greatly improve the utilization and real-world performance of Cerebras Inference.</p>
<p>We’ve re-written or optimized the most critical kernels such as MatMul, reduce/broadcast, element wise ops, and activations. Wafer IO has been streamlined to run asynchronously from compute. This release also implements speculative decoding, a widely used technique that uses a small model and large model in tandem to generate answers faster. As a result of this feature, you may observe a greater variance in output speed – 20% higher or lower than the 2,100 tokens/sec average is normal.</p>
<p>Model precision is unchanged – all models continue to use 16-bit original weights. Model output accuracy is likewise unchanged as verified by Artificial Analysis.</p>
<h3>What fast inference enables</h3>
<p>The impact of Cerebras Inference’s unprecedented speed is already transforming how organizations develop and deploy AI apps. In pharmaceutical research, Kim Branson, SVP of AI and ML at GSK, says: “With Cerebras’ inference speed, GSK is developing innovative AI applications, such as intelligent research agents, that will fundamentally improve the productivity of our researchers and drug discovery process.”</p>
<p>The dramatic speed improvement is game-changing for real-time AI applications, as demonstrated by LiveKit, which powers ChatGPT’s voice mode. As CEO Russ d’Sa explains: “When building voice AI, inference is the slowest stage in your pipeline. With Cerebras Inference, it’s now the fastest. A full pass through a pipeline consisting of cloud-based speech-to-text, 70B-parameter inference using Cerebras Inference, and text-to-speech, runs faster than just inference alone on other providers. This is a game changer for developers building voice AI that can respond with human-level speed and accuracy.”</p>
<p>Fast inference is the key enabler for next gen AI applications that leverage more test-time compute for greater model capability. As demonstrated by models like GPT-o1, the ability to perform extensive chain-of-thought reasoning directly translates to breakthrough performance in reasoning, coding, and research tasks. Using Cerebras Inference, models think deeply before responding without the typical minutes-long latency penalties. This makes Cerebras Inference the ideal platform for developers looking to build systems that deliver both greater runtime intelligence and responsive user experiences.</p>
<h3>Conclusion</h3>
<p>Today’s 3x performance improvement shows what’s possible when realizing the full potential of the Wafer Scale Engine for inference. At 2,100 tokens per second for Llama3.1-70B, we’ve delivered the equivalent of more than a hardware generation’s worth of performance in a single software release. Our team continues to optimize both software and hardware capabilities, and we will be expanding our model selection, context lengths, and API features in the coming weeks.</p>
<p><a href="http://chat.cerebras.ai/">Try chat</a><br>
<a href="https://www.businesswire.com/news/home/20241024856476/en/Cerebras-Triples-its-Industry-Leading-Inference-Performance-Setting-New-All-Time-Record">Press release</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenFeature – a vendor-agnostic, community-driven API for feature flagging (182 pts)]]></title>
            <link>https://github.com/open-feature</link>
            <guid>41941493</guid>
            <pubDate>Fri, 25 Oct 2024 01:26:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/open-feature">https://github.com/open-feature</a>, See on <a href="https://news.ycombinator.com/item?id=41941493">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemprop="text"><p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/open-feature/community/0e23508c163a6a1ac8c0ced3e4bd78faafe627c7/assets/logo/horizontal/white/openfeature-horizontal-white.svg">
    <img alt="OpenFeature Logo" src="https://raw.githubusercontent.com/open-feature/community/0e23508c163a6a1ac8c0ced3e4bd78faafe627c7/assets/logo/horizontal/black/openfeature-horizontal-black.svg">
  </picture></themed-picture>
</p>
<p dir="auto"><h2 dir="auto">Welcome to the OpenFeature project 👋</h2><a id="user-content-welcome-to-the-openfeature-project-" aria-label="Permalink: Welcome to the OpenFeature project 👋" href="#welcome-to-the-openfeature-project-"></a></p>
<p dir="auto">
  <a href="https://openfeature.dev/" rel="nofollow">OpenFeature</a> is an open specification that provides a vendor-agnostic, community-driven API for feature flagging that works with your favorite feature flag management tool or in-house solution.
</p>
<p dir="auto">
  <a href="https://openfeature.dev/docs/reference/intro" rel="nofollow">Learn More 📚</a>
  ·
  <a href="https://openfeature.dev/docs/tutorials/five-minutes-to-feature-flags" rel="nofollow">Get Started 🔭</a>
  ·
  <a href="https://openfeature.dev/community/CONTRIBUTOR_LADDER" rel="nofollow">Contribute 😍</a>
  ·
  <a href="https://openfeature.dev/ecosystem" rel="nofollow">Discover the Ecosystem 🧭</a>
</p>
<hr>
<p dir="auto"><h2 dir="auto">👋 Getting involved</h2><a id="user-content--getting-involved" aria-label="Permalink: 👋 Getting involved" href="#-getting-involved"></a></p>
<p dir="auto">There is a lot to do! If you're interested in getting involved, please join our <a href="https://github.com/open-feature/community?tab=readme-ov-file#discussions">Slack channel</a>, the <a href="https://github.com/open-feature/community?tab=readme-ov-file#mailing-list">mailing lists</a>, and <a href="https://github.com/open-feature/community?tab=readme-ov-file#community-meetings">attend the community meetings</a>.  We're a friendly, collaborative group and look forward to working together!</p>
<p dir="auto">Learn how to get involved in the <a href="https://openfeature.dev/community/CONTRIBUTOR_LADDER" rel="nofollow">OpenFeature Contributor Ladder</a>.</p>
<p dir="auto"><h2 dir="auto">🦺 Help keep our community safe, inviting, and inclusive</h2><a id="user-content--help-keep-our-community-safe-inviting-and-inclusive" aria-label="Permalink: 🦺 Help keep our community safe, inviting, and inclusive" href="#-help-keep-our-community-safe-inviting-and-inclusive"></a></p>
<p dir="auto">OpenFeature follows the <a href="https://github.com/cncf/foundation/blob/main/code-of-conduct.md">CNCF Community Code of Conduct</a>. Please abide by this Code of Conduct when interacting with all repositories under the OpenFeature umbrella and when interacting with people.</p>
<p dir="auto"><h2 dir="auto">👾 Reporting Security Incidents</h2><a id="user-content--reporting-security-incidents" aria-label="Permalink: 👾 Reporting Security Incidents" href="#-reporting-security-incidents"></a></p>
<p dir="auto">Please be mindful that Security-related issues should be reported through our <a href="https://github.com/open-feature/.github/blob/main/SECURITY.md">Security Policy</a> as Security-related issues and vulnerabilities can be exploited and we request confidentiality whenever possible.</p>
<hr>
<p dir="auto">OpenFeature is a <a href="https://cncf.io/" rel="nofollow">CNCF</a> <a href="https://www.cncf.io/projects/" rel="nofollow">incubating</a> project.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Consumer Watchdog Cautions Businesses on Surveillance of Workers (112 pts)]]></title>
            <link>https://www.wsj.com/articles/u-s-consumer-watchdog-cautions-businesses-on-surveillance-of-workers-8262bee3</link>
            <guid>41941052</guid>
            <pubDate>Fri, 25 Oct 2024 00:05:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/u-s-consumer-watchdog-cautions-businesses-on-surveillance-of-workers-8262bee3">https://www.wsj.com/articles/u-s-consumer-watchdog-cautions-businesses-on-surveillance-of-workers-8262bee3</a>, See on <a href="https://news.ycombinator.com/item?id=41941052">Hacker News</a></p>
Couldn't get https://www.wsj.com/articles/u-s-consumer-watchdog-cautions-businesses-on-surveillance-of-workers-8262bee3: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Bitwarden SDK relicensed from proprietary to GPLv3 (889 pts)]]></title>
            <link>https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b</link>
            <guid>41940580</guid>
            <pubDate>Thu, 24 Oct 2024 22:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b">https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b</a>, See on <a href="https://news.ycombinator.com/item?id=41940580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
      <tr data-position="0">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542HL1" data-line-number="..."></td>
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542HR1" data-line-number="..."></td>
    <td>@@ -1,6 +1,6 @@</td>
  </tr>

    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L1" data-line-number="1"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R1" data-line-number="1"></td>

  <td>
    <span data-code-marker=" ">[<span>workspace</span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L2" data-line-number="2"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R2" data-line-number="2"></td>

  <td>
    <span data-code-marker=" "><span>resolver</span> = <span><span>"</span>2<span>"</span></span></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L3" data-line-number="3"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>members</span> = [<span><span>"</span>crates/*<span>"</span></span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R3" data-line-number="3"></td>

  <td>
    <span data-code-marker="+"><span>members</span> = [<span><span>"</span>crates/*<span>"</span></span><span>, </span><span><span>"</span><span>bitwarden_license/*</span><span>"</span></span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L4" data-line-number="4"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R4" data-line-number="4"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L5" data-line-number="5"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R5" data-line-number="5"></td>

  <td>
    <span data-code-marker=" "><span><span>#</span> Global settings for all crates should be defined here</span></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L6" data-line-number="6"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R6" data-line-number="6"></td>

  <td>
    <span data-code-marker=" ">[<span>workspace</span>.<span>package</span>]</span></td>
</tr>




      <tr data-position="8">
    <td colspan="2">
        <a href="#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" id="expand-link-8-diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" aria-label="Expand All" data-url="/bitwarden/sdk-internal/blob_excerpt/c11128a804138f782b5abc159b658e3a4faf12fa?diff=unified&amp;in_wiki_context=&amp;last_left=6&amp;last_right=6&amp;left=27&amp;left_hunk_size=7&amp;mode=100644&amp;path=Cargo.toml&amp;right=27&amp;right_hunk_size=7" data-left-range="7-15" data-right-range="7-15">
          
        </a>
        <tool-tip id="tooltip-eb6421d3-fc5b-410b-915a-7bc615cd006b" for="expand-link-8-diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -27,7 +27,7 @@ bitwarden-exporters = { path = "crates/bitwarden-exporters", version = "=1.0.0"</td>
  </tr>

    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L27" data-line-number="27"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R27" data-line-number="27"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-fido</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-fido<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L28" data-line-number="28"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R28" data-line-number="28"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-generators</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-generators<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L29" data-line-number="29"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R29" data-line-number="29"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-send</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-send<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L30" data-line-number="30"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>bitwarden-sm</span> = { <span>path</span> = <span><span>"</span><span>crates</span>/bitwarden-sm<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R30" data-line-number="30"></td>

  <td>
    <span data-code-marker="+"><span>bitwarden-sm</span> = { <span>path</span> = <span><span>"</span><span>bitwarden_license</span>/bitwarden-sm<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L31" data-line-number="31"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R31" data-line-number="31"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-vault</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-vault<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L32" data-line-number="32"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R32" data-line-number="32"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L33" data-line-number="33"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R33" data-line-number="33"></td>

  <td>
    <span data-code-marker=" "><span><span>#</span> External crates that are expected to maintain a consistent version across all crates</span></span></td>
</tr>




  <tr data-position="">
    <td colspan="2">
          <a href="#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" id="expand-down-link--diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" aria-label="Expand Down" data-url="/bitwarden/sdk-internal/blob_excerpt/c11128a804138f782b5abc159b658e3a4faf12fa?diff=unified&amp;direction=down&amp;in_wiki_context=&amp;last_left=33&amp;last_right=33&amp;left=90&amp;left_hunk_size=&amp;mode=100644&amp;path=Cargo.toml&amp;right=90&amp;right_hunk_size=" data-left-range="34-89" data-right-range="34-89">
            
          </a>
          <tool-tip id="tooltip-2604fbf7-a6c0-4f9d-8ac6-fbd948d0e347" for="expand-down-link--diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Down</tool-tip>
    </td>
    <td></td>
  </tr>


                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ST Book, the Notebook Atari ST (111 pts)]]></title>
            <link>https://www.goto10retro.com/p/st-book-the-notebook-atari-st</link>
            <guid>41940266</guid>
            <pubDate>Thu, 24 Oct 2024 21:57:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.goto10retro.com/p/st-book-the-notebook-atari-st">https://www.goto10retro.com/p/st-book-the-notebook-atari-st</a>, See on <a href="https://news.ycombinator.com/item?id=41940266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>The first portable Atari ST computer was the Stacy, which I have previously written about (see: </span><a href="https://www.goto10retro.com/p/atari-stacy-vs-macintosh-portable" rel="">Atari STacy vs. Macintosh Portable</a><span>), but do you know about the ST Book, the notebook Atari ST?</span></p><p><span>Announced in October 1991, about the same time as the </span><a href="https://en.wikipedia.org/wiki/PowerBook_100" rel="">PowerBook 100</a><span> (the first Macintosh Notebook), the amazing ST Book is relatively unknown, probably because only about 1000 or so were made. I’m not even sure if it was ever actually sold in the US.</span></p><blockquote><p>The ST Book originally started its R&amp;D life as a pen-based computer and something called the STylus or ST Pad. That would have been something to see!</p></blockquote><p>To my mind, this is the rarest of the Atari ST computers and I daresay it will be practically impossible to find one today, and if you did I can’t even imagine what it would sell for.</p><p>Essentially the ST Book was an Atari STE squeezed into a tiny form factor.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d0d18bd-5a3c-4d6d-95e6-8f8acc4fce4c_1944x1944.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The 10.4” LCD display was monochrome, non-backlit and the same 640x400 resolution that the ST always had for its high-resolution, monochrome output. It used a high-contrast, passive-matrix screen like many early low-cost portables</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-150359588" href="https://www.goto10retro.com/p/st-book-the-notebook-atari-st#footnote-1-150359588" target="_self" rel="">1</a></span><span>, which meant you had to use it in a lighted area. The CPU was still a 68000 running at 8Mhz (the PowerBook 100 had a 68000 running at 16Mhz) and came with 1MB of RAM (a 4MB version was also available). Most ports were largely the same, although the MIDI ports were mini-sized.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic" width="1456" height="158" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:158,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:260308,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7844b877-95aa-4afc-8d07-1f6a86f6918d_4032x438.heic 1456w" sizes="100vw"></picture></div></a><figcaption>Ports, left-to-right: AC adapter, mini MIDI, DMA, serial, parallel.</figcaption></figure></div><p><span>The ST Book had TOS 2.06 in ROM, like the Mega STE. Its case color was the dark gray color of the </span><a href="https://www.goto10retro.com/p/i-picked-up-an-atari-portfolio" rel="">Atari Portfolio</a><span>, which would also be used for the </span><a href="https://www.goto10retro.com/p/atari-falcon030" rel="">Atari Falcon030</a><span>.</span></p><p>The keyboard looks really nice. It is certainly more compact than a regular ST keyboard, with no separate number pad (although you there was a keypad lock key to allow you to use some of the keys as a number pad). I really like the white color and it even has a dedicated “Atari” key on the bottom left, although I’m not sure what that would have been used for.</p><p>Although basically an STE, the ST Book did offer some interesting innovations:</p><ul><li><p><span>Light weight. The ST Book weighed only 4.2 pounds, which was remarkably light for a notebook back then. The PowerBook 100 was nearly a pound heavier at 5.1 pounds. The </span><a href="https://www.goto10retro.com/p/atari-stacy-vs-macintosh-portable" rel="">STacy</a><span> (and Mac Portable) weighed about 15 pounds!</span></p></li><li><p>No built-in floppy drive. Like the PowerBook 100, the ST Book eschewed the floppy drive to save weight. It did have a built-in 40MB IDE hard drive, the first ST to use IDE (which would also later show up in the Falcon030). To transfer files to it, you could use included software to connect it to another ST via parallel or serial cables and copy the files over. An external floppy drive that connected to the DMA port was also supposed to be available (The ST Book did not have a standard floppy port, which would have allowed existing floppy drives to be used with it, probably because the physical port would have been too large for the ST Book). The PowerBook 100 originally came with an external floppy drive.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic" width="1456" height="1381" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1381,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1289107,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb89fbc6d-3b69-40db-9dd7-106d8ea8f8b1_3024x2868.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></li><li><p>Vector Pad. At this point, track pads had not been invented. The STacy had a built-in trackball, which was common on portable computers. In fact, that’s what the PowerMac 100 used. The ST Book went with something more unique: a vector pad, which is probably more similar to that little “nub” stick you may have seen on some IBM ThinkBooks. You could slightly push the vector pad, a pressure-sensitive disc, in directions to move the mouse around. The more pressure you applied, the faster the mouse moved. This pad was placed in the top right, above the keyboard, which I think would have been incredibly awkward to work with.</p></li><li><p>Long battery life. The ST Book had a total power consumption of just 1.25 watts (the STacy was 6 watts). The hard drive is powered down when not in use, something that is common today, but was not back then. Special RAM was used that did not need to always be powered. The LCD screen had a “video saver” capability to update from its own RAM rather than main RAM and it could be blanked out to save power. The ST Book also had a save and resume feature, similar to the sleep option that all laptops have today. All of this meant the ST Book could get about 5 to 10 hours using its optional rechargeable NiCad battery. Amazingly, the ST Book could also run for a couple hours on seven AA batteries!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic" width="1456" height="876" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:876,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1518952,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24b334d5-d98c-4498-a664-a50d6e2096b2_4032x2427.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></li></ul><div data-attrs="{&quot;url&quot;:&quot;https://www.goto10retro.com/p/st-book-the-notebook-atari-st?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Please consider sharing this post to your retro computing friends!</p><p data-attrs="{&quot;url&quot;:&quot;https://www.goto10retro.com/p/st-book-the-notebook-atari-st?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.goto10retro.com/p/st-book-the-notebook-atari-st?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div><p>For all its innovations, the ST Book had some odd omissions.</p><p>Strangely, the ST Book did not have a great way to use an external mouse. To do so, you had to first connect an external Mega STE (or Mega ST) keyboard and then use the mouse connected to that. As far as I know those keyboards were never actually sold separately, so unless you already had a Mega STE or Mega ST you would have been stuck with using the vector pad.</p><p><span>There was also no way to connect an external monitor and thus no way to get color support. Apparently this was removed to save power. Although the ST Book did have an expansion connector, it did not have a standard cartridge port. Apparently it was technically possible to connect a cartridge to the expansion connector, but it seems unlikely that anyone ever did that. This meant that the popular </span><a href="https://www.goto10retro.com/p/gadgets-by-small-mac-emulation-on" rel="">Spectre Macintosh emulator</a><span> would not work with the ST Book.</span></p><p>Compatibility, apart from games, should have been about the same as the Mega STE.</p><p><span>From what I can tell the ST Book was originally priced at about $2000 (about $4600 in 2024). The PowerBook 100 originally sold for $2500 (about $5700 in 2024), but it came with the external floppy, NiCad battery pack and charger, all of which were optional with the ST Book</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-150359588" href="https://www.goto10retro.com/p/st-book-the-notebook-atari-st#footnote-2-150359588" target="_self" rel="">2</a></span><span>.</span></p><p><span>The </span><a href="https://www.atarimania.com/atari-magazine-issue-st-format-issue-34_1427.html" rel="">May 1992 issue of ST Format</a><span> had a great article about a pre-production ST Book that they were able to test. Overall, they really liked it, but did have complains about the vector pad, which they felt was difficult to use accurately.</span></p><figure data-drag-handle="" data-component-name="ImageGallery"><div><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0035038f-9f0a-4df5-b221-6dc2cbb47eb1_1100x1501.jpeg 424w, https://substackcdn.com/image/fetch/w_474,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0035038f-9f0a-4df5-b221-6dc2cbb47eb1_1100x1501.jpeg 474w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0035038f-9f0a-4df5-b221-6dc2cbb47eb1_1100x1501.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0035038f-9f0a-4df5-b221-6dc2cbb47eb1_1100x1501.jpeg 424w, https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0035038f-9f0a-4df5-b221-6dc2cbb47eb1_1100x1501.jpeg 474w" width="474"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856eb7ac-28dc-4c28-8d55-d46fb8d3cf07_1100x1511.jpeg 424w, https://substackcdn.com/image/fetch/w_474,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856eb7ac-28dc-4c28-8d55-d46fb8d3cf07_1100x1511.jpeg 474w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856eb7ac-28dc-4c28-8d55-d46fb8d3cf07_1100x1511.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856eb7ac-28dc-4c28-8d55-d46fb8d3cf07_1100x1511.jpeg 424w, https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856eb7ac-28dc-4c28-8d55-d46fb8d3cf07_1100x1511.jpeg 474w" width="474"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2781a50-bccb-494c-9e1b-db99c973aa2a_1100x1500.jpeg 424w, https://substackcdn.com/image/fetch/w_474,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2781a50-bccb-494c-9e1b-db99c973aa2a_1100x1500.jpeg 474w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2781a50-bccb-494c-9e1b-db99c973aa2a_1100x1500.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2781a50-bccb-494c-9e1b-db99c973aa2a_1100x1500.jpeg 424w, https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2781a50-bccb-494c-9e1b-db99c973aa2a_1100x1500.jpeg 474w" width="474"></picture></div><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02d19b59-fe6f-4900-9deb-a209573e410e_1100x1511.jpeg 424w, https://substackcdn.com/image/fetch/w_720,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02d19b59-fe6f-4900-9deb-a209573e410e_1100x1511.jpeg 720w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02d19b59-fe6f-4900-9deb-a209573e410e_1100x1511.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02d19b59-fe6f-4900-9deb-a209573e410e_1100x1511.jpeg 424w, https://substackcdn.com/image/fetch/w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02d19b59-fe6f-4900-9deb-a209573e410e_1100x1511.jpeg 720w" width="720"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7de3399-bbe7-4a1a-87f9-9456ced62d0a_1100x1496.jpeg 424w, https://substackcdn.com/image/fetch/w_720,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7de3399-bbe7-4a1a-87f9-9456ced62d0a_1100x1496.jpeg 720w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7de3399-bbe7-4a1a-87f9-9456ced62d0a_1100x1496.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7de3399-bbe7-4a1a-87f9-9456ced62d0a_1100x1496.jpeg 424w, https://substackcdn.com/image/fetch/w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7de3399-bbe7-4a1a-87f9-9456ced62d0a_1100x1496.jpeg 720w" width="720"></picture></div><figcaption>ST Format May 1992 story on the ST Book</figcaption></div></figure><p>The January 1992 issue of Atari Explorer had an interview with the creator of the ST Book, Tracy Hall.</p><p>Although I’ve summarized from both of them, I still recommend reading both of these articles.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png" width="1090" height="818" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:818,&quot;width&quot;:1090,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1237905,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fce3bf8-c4d4-47f3-bfb2-99b0426474cf_1090x818.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Photo from Atari Explorer</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png" width="1456" height="1230" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1230,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2651311,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69443b0a-e9af-4d60-89bc-9010eff2524d_1544x1304.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Photo from Atari Explorer</figcaption></figure></div><p>Because so few ST Books were made, it’s hard to really call it a flop. Rather, it was more like an interesting R&amp;D project from Atari that barely saw the light of day. Considering its price was rather close to the PowerBook 100, it’s hard to believe this would have sold well even if Atari had given it a full rollout.</p><p>If any readers have used (or actually own) an ST Book, please share your thoughts about it in the comments.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.goto10retro.com/p/st-book-the-notebook-atari-st/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.goto10retro.com/p/st-book-the-notebook-atari-st/comments" rel=""><span>Leave a comment</span></a></p></div></div>]]></description>
        </item>
    </channel>
</rss>