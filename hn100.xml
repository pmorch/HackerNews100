<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 16 Dec 2025 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The GitHub Actions control plane is no longer free (167 pts)]]></title>
            <link>https://www.blacksmith.sh/blog/actions-pricing</link>
            <guid>46291500</guid>
            <pubDate>Tue, 16 Dec 2025 17:37:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.blacksmith.sh/blog/actions-pricing">https://www.blacksmith.sh/blog/actions-pricing</a>, See on <a href="https://news.ycombinator.com/item?id=46291500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="w-node-c021e89c-c247-0617-1dae-6dd36d1352b4-250b2c58"><p>TL;DR</p><p>GitHub is adding a $0.002-per-minute fee on all GitHub Actions usage, so the control plane is no longer free.</p></div><div id="w-node-_9e21598a-bd92-e71f-267e-33e11a0f4df0-250b2c58"><h2><strong>What's happening?</strong></h2><p>GitHub just <a href="https://resources.github.com/actions/2026-pricing-changes-for-github-actions/">announced changes</a> to Actions pricing. Previously, GitHub Actions had a free control plane. That meant if you used GitHub Actions but ran jobs outside of GitHub-hosted runners, whether that‚Äôs on Blacksmith, on your own machines, or in your own AWS account, you paid nothing to GitHub for those minutes; you only paid for the compute.</p><p>With this change, GitHub is introducing a $0.002 per-minute platform fee for <em>all</em> GitHub Actions usage.</p><p>In practice, this means CI costs now have two components:</p><ul role="list"><li>Compute costs (whoever runs your runners)</li><li>A flat GitHub platform fee, charged per minute of Actions usage</li></ul><p>These changes go into effect on March 1st, 2026.</p><h2>Our perspective on why they‚Äôre making these changes</h2><p>GitHub Actions has long had a graduation churn problem. As companies grow, their CI workloads become larger, more complex, and more expensive. At a certain scale, GitHub-hosted runners become both slow and costly, pushing teams to self-host or move to third-party runners like Blacksmith.</p><p>Until now, that shift had an important side effect: companies could continue using the GitHub Actions control plane while paying GitHub nothing for CI execution. GitHub provided scheduling, orchestration, and workflow automation, but captured no revenue from some of its largest and fastest-growing customers.</p><p>The new per-minute platform fee changes that. It directly monetizes the Actions control plane and establishes a floor on what GitHub earns from CI, regardless of where jobs run. In effect, self-hosting is no longer free.</p><p>At the same time, GitHub reduced the price of GitHub-hosted runners. This isn‚Äôt accidental. Lower hosted runner prices make GitHub-hosted runners more attractive, while the platform fee introduces a new, unavoidable cost for self-hosting.</p><p>From GitHub‚Äôs perspective, this is a rational move. Most Actions usage is concentrated on smaller runners, so the hosted runner price cuts likely don‚Äôt materially impact revenue. More importantly, GitHub is trading lower-margin compute revenue for higher-margin platform revenue.</p><p>Hosted runners are fundamentally a compute business. The platform fee, by contrast, monetizes software without scaling infrastructure costs linearly. As CI usage grows, that revenue scales with significantly better unit economics.</p><p>In the past, our customers have asked us how GitHub views third-party runners long-term. The platform fee largely answers that: GitHub now monetizes Actions usage regardless of where jobs run, aligning third-party runners like Blacksmith as ecosystem partners rather than workarounds.</p><h2><strong>Per-minute CI pricing and its impact on self-hosting</strong></h2><p>Before this change, self-hosting was a way to avoid paying GitHub entirely. That‚Äôs no longer true. Now, self-hosting retains the operational burden of running CI infrastructure while still incurring per-minute charges on GitHub.</p><p>At that point, the primary variable you can still control is how many minutes your CI jobs consume. One approach is to run CI on infrastructure designed to minimize wall-clock time and eliminate redundant work. That‚Äôs the problem Blacksmith focuses on. In practice, this shows up in a few areas:</p><ul role="list"><li>Faster machines. Blacksmith runs CI jobs on CPUs that have 50%+ higher single-core performance than GitHub-hosted runners. As part of ongoing fleet upgrades, we‚Äôre deploying even newer instances that add an additional 15‚Äì25% improvement, further reducing runtime for CPU-bound workloads.</li><li>Reusing work across runs. <a href="https://docs.blacksmith.sh/blacksmith-caching/docker-builds">Docker layer caches</a> are persisted across CI runs, allowing unchanged layers to be reused rather than rebuilt, cutting Docker build times from tens of minutes to seconds for many customers.</li><li>Container caching (beta). Service containers can be pre-hydrated on runners, removing repeated <a href="https://docs.blacksmith.sh/blacksmith-caching/docker-container-caching">image pulls and extraction</a> from the job startup path.</li></ul><p>With a per-minute platform fee, CI performance and cost are tightly coupled. The remaining lever is reducing CI time and total Actions.</p><p>‚Äç</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub will begin charging for self-hosted action runners on March 2026 (144 pts)]]></title>
            <link>https://github.blog/changelog/2025-12-16-coming-soon-simpler-pricing-and-a-better-experience-for-github-actions/</link>
            <guid>46291414</guid>
            <pubDate>Tue, 16 Dec 2025 17:32:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.blog/changelog/2025-12-16-coming-soon-simpler-pricing-and-a-better-experience-for-github-actions/">https://github.blog/changelog/2025-12-16-coming-soon-simpler-pricing-and-a-better-experience-for-github-actions/</a>, See on <a href="https://news.ycombinator.com/item?id=46291414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>On <strong>January 1, 2026</strong>, GitHub will <strong>reduce the price of GitHub-hosted runners by up to 39%</strong> <a href="https://docs.github.com/billing/reference/actions-runner-pricing">depending on the machine type used</a>. The free usage minute quotas will remain the same.</p>
<p>On <strong>March 1, 2026,</strong> GitHub will introduce a new <strong>$0.002 per minute GitHub Actions cloud platform charge</strong> that will apply to self-hosted runner usage. Any usage subject to this charge will count toward the minutes included in your plan, as explained in <a href="https://docs.github.com/billing/concepts/product-billing/github-actions#free-use-of-github-actions">our GitHub Actions billing documentation</a>.</p>
<p>Runner usage in public repositories will <strong>remain free.</strong> There will be no changes in price structure for GitHub Enterprise Server customers.</p>
<h3 id="deeper-investment-in-the-actions-self-hosted-experience"><a href="#deeper-investment-in-the-actions-self-hosted-experience">Deeper investment in the Actions self-hosted experience</a></h3>
<p>We are increasing our investment into our self-hosted experience to ensure that we can provide autoscaling for scenarios beyond just Linux containers. This will include new approaches to scaling, new platform support, Windows support, and more as we move through the next 12 months.</p>
<p>For more details about the product investments we‚Äôre making in Actions, please visit our <a href="https://resources.github.com/actions/2026-pricing-changes-for-github-actions">Executive Insights page</a>.</p>
<h3 id="recommended-resources"><a href="#recommended-resources">Recommended resources</a></h3>
<ul>
<li>For answers to common questions about this change, see the FAQ in our <a href="https://resources.github.com/actions/2026-pricing-changes-for-github-actions">post on GitHub‚Äôs Executive Insights page</a>.</li>
<li>See the <a href="https://docs.github.com/billing/reference/actions-runner-pricing">GitHub Actions runner pricing documentation</a> for the new GitHub-hosted runner rates effective January 1, 2026.  </li>
<li>For more details on upcoming GitHub Actions releases, see the <a href="https://github.com/orgs/github/projects/4247">GitHub public roadmap</a>.  </li>
<li>For help estimating your expected Actions usage cost, use the newly updated <a href="https://github.com/pricing/calculator#actions">Actions pricing calculator</a>.  </li>
<li>If you are interested in moving existing self-hosted runner usage to GitHub-hosted runners, see the <a href="https://docs.github.com/actions/tutorials/migrate-to-github-runners">SHR to GHR migration guide</a> in our documentation.</li>
</ul>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pricing Changes for GitHub Actions (318 pts)]]></title>
            <link>https://resources.github.com/actions/2026-pricing-changes-for-github-actions/</link>
            <guid>46291156</guid>
            <pubDate>Tue, 16 Dec 2025 17:12:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://resources.github.com/actions/2026-pricing-changes-for-github-actions/">https://resources.github.com/actions/2026-pricing-changes-for-github-actions/</a>, See on <a href="https://news.ycombinator.com/item?id=46291156">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Today we‚Äôre announcing updates to our pricing and product models for GitHub Actions. </p><div><p>Why? </p>
<p>When we shipped Actions in 2018, we had no idea how popular it would become. By early 2024, the platform was running about 23 million jobs per day and our existing architecture couldn‚Äôt reliably support our growth curve. In order to increase feature velocity, we first needed to improve reliability and modernize the legacy frameworks that supported GitHub Actions. </p>
<p><a href="https://github.blog/news-insights/product-news/lets-talk-about-github-actions/">Our solution was to re-architect the core backend services powering GitHub Actions jobs</a> and runners with the goals of improving uptime and resilience against infrastructure issues, enhancing performance, reducing internal throttles, and leveraging GitHub‚Äôs broader platform investments and developer experience improvements. This work is paying off by helping us handle our current scale, even as we work through the last pieces of stabilizing our new platform.</p>
<p>Since August, all GitHub Actions jobs have run on our new architecture, which handles 71 million jobs per day (over 3x from where we started). Individual enterprises are able to start 7x more jobs per minute than our previous architecture could support. </p>
<p>As with any product, our goal at GitHub has been to meet customer needs while providing enterprises with flexibility and transparency.</p>
<p>This change better supports a world where CI/CD must be faster and more reliable, better caching, more workflow flexibility, rock-solid reliability, and strengthens the core experience while positioning GitHub Actions to power GitHub‚Äôs open, secure platform for agentic workload. </p>
<h2>What‚Äôs changing?</h2>
<h3>Lower prices for GitHub-hosted runners</h3>
<p>Starting today, we‚Äôre charging fairly for Actions across the board which reduces the price of GitHub Hosted Runners and the price the average GitHub customer pays. And we‚Äôre <strong>reducing the net cost of GitHub-hosted runners by up to 39%</strong>, depending on which machine type is used.</p>
<p>This reduction is driven by a ~40% price reduction across all runner sizes, paired with the addition of a new $0.002 per-minute GitHub Actions cloud platform charge. For GitHub-hosted runners, the new Actions cloud platform charge is <strong>already included into the reduced meter price.</strong> </p>
<p>Standard GitHub-hosted or self-hosted runner usage on <strong>public repositories will remain free</strong>. <strong>GitHub Enterprise Server pricing is not impacted</strong> by this change.</p>
<p>The price reduction you will see in your account depends on the types of machines that you use most frequently ‚Äì smaller runners will have a smaller relative price reduction, larger runners will see a larger relative reduction.</p>
<p>This price reduction makes high-performance compute more accessible for both high-volume CI workloads and the agent jobs that rely on fast, secure execution environments.</p>
<p>For full pricing update details, see the updated Actions runner prices <a href="https://docs.github.com/billing/reference/actions-runner-pricing">in our documentation</a>.</p>
<p>This price change will <strong>go into effect on January 1, 2026</strong>.</p>
<h3>Introduction of the GitHub Actions cloud platform charge</h3>
<p>We are introducing a <strong>$0.002 per-minute Actions cloud platform</strong> <strong>charge</strong> for all Actions workflows across GitHub-hosted and self-hosted runners. The new listed GitHub-runner rates include this charge. This will not impact Actions usage in public repositories or GitHub Enterprise Server customers.  </p>
<p>This aligns pricing to match consumption patterns and ensures consistent service quality as usage grows across both hosting modalities.</p>
<p>This will impact <strong>self-hosted runner pricing starting March 1, 2026.</strong></p>
<h3>Deepened investment in the Actions self-hosted experience</h3>
<p>We are increasing our investment into our self-hosted experience to ensure that we can provide autoscaling for scenarios beyond just Linux containers. This will include new approaches to scaling, new platform support, Windows support, and more as we move through the next 12 months. Here‚Äôs a preview of what to expect in the new year:</p>
<h4>GitHub Scale Set Client</h4>
<p>This <a href="https://github.com/github/roadmap/issues/1192">new client</a> provides enterprises with a lightweight Go SDK to build custom autoscaling solutions without the complexity of Kubernetes or reliance on ARC. It integrates seamlessly with existing infrastructure‚Äîcontainers, virtual machines, cloud instances, or bare metal‚Äîwhile managing job queuing, secure configuration, and intelligent scaling logic. Customers gain a supported path to implement flexible autoscaling, reduce setup friction, and extend GitHub Actions beyond workflows to scenarios such as self-hosted Dependabot and Copilot Coding Agent.</p>
<h4>Multi-label support</h4>
<p>We are reintroducing <a href="https://github.com/github/roadmap/issues/1195">multi-label functionality</a> for both GitHub-hosted larger runners and self-hosted runners, including those managed by Actions Runner Controller (ARC) and the new Scale Set Client.</p>
<h4>Actions Runner Controller 0.14.0</h4>
<p><a href="https://github.com/github/roadmap/issues/1194">This upcoming release</a> introduces major quality-of-life improvements, including refined Helm charts for easier Docker configuration, enhanced logging, updated metrics, and formalized versioning requirements. It also announces the deprecation of legacy ARC, providing a clear migration path to a more reliable and maintainable architecture. Customers benefit from simplified setup, improved observability, and confidence in long-term support, reducing operational friction and improving scalability.</p>
<h4>Actions Data Stream</h4>
<p>The <a href="https://github.com/github/roadmap/issues/1193">Actions Data Stream</a> will deliver a near real-time, authoritative feed of GitHub Actions workflow and job event data, including metadata such as the version of the action that was executed on any given workflow run. This capability enhances observability and troubleshooting by enabling organizations to integrate event data into monitoring and analytics systems for compliance and operational insights. By providing structured, high-fidelity data at scale, it eliminates reliance on manual log parsing and empowers teams to proactively manage reliability and performance.</p>
<h2>Why this matters</h2>
<p>Agents are expanding what teams can automate‚Äîbut CI/CD remains the heartbeat of modern software delivery. These updates enable both a faster, more reliable CI/CD experience for every developer, and a scalable, flexible, secure execution layer to power GitHub‚Äôs agentic platform.</p>
<p>Our goal is to ensure GitHub Actions continues to meet the needs of the largest enterprises and of individual developers alike, with clear pricing, stronger performance, and a product direction built for the next decade of software development.</p>
<h2>FAQ</h2>
<p><strong>What are the new GitHub-hosted runner rates?</strong><br>See the GitHub Actions <a href="https://docs.github.com/billing/reference/actions-runner-pricing">runner pricing reference</a> for the updated rates that will go into effect on January 1, 2026. These listed rates include the new $0.002 per-minute Actions cloud platform charge.</p>
<p><strong>Which job execution scenarios for GitHub Actions are affected by this pricing change?</strong></p>
<ul>
<li>Jobs that run in private repositories and use standard GitHub-hosted or self-hosted runners  </li>
<li>Any jobs running on larger GitHub-hosted runners</li>
</ul>
<p>Standard GitHub-hosted or self-hosted runner usage on public repositories will remain free. GitHub Enterprise Server pricing is not impacted by this change.</p>
<p><strong>When will this pricing change take effect?</strong></p>
<p>The price decrease for GitHub-hosted runners will take effect on January 1, 2026. The new charge for self-hosted runners will apply beginning on March 1, 2026. The price changes will impact all customers on these dates.</p>
<p><strong>Will the free usage quota available in my plan change?</strong><br>Beginning March 1, 2026, self-hosted runners will be included within your free usage quota, and will consume available usage based on list price the same way that Linux, Windows, and MacOS standard runners work today.</p>
<p><strong>Will self-hosted runner usage consume from my free usage minutes?</strong><br>Yes, billable self-hosted runner usage will be able to consume minutes from the free quota associated with your plan.</p>
<p><strong>How does this pricing change affect customers on GitHub Enterprise Server?</strong></p>
<p>This pricing change does not affect customers using GitHub Enterprise Server. Customers running Actions jobs on self-hosted runners on GitHub Enterprise Server may continue to host, manage, troubleshoot and use Actions on and in conjunction with their implementation free of charge. </p>
<p><strong>Can I bill my self-hosted runner usage on private repositories through Azure?</strong></p>
<p>Yes, as long as you have an active Azure subscription ID associated with your GitHub Enterprise or Organization(s).</p>
<p><strong>What is the overall impact of this change to GitHub customers?</strong></p>
<p>Of Actions users impacted by this change, 85% will see their Actions bill decrease. Of the 15% who are impacted across all cohorts the median increase is $13. </p>
<p><strong>Did GitHub consider how this impacts individual developers, not just Enterprise scale customers of GitHub?</strong><br>From our individual users (free &amp; Pro plans) of those who used GitHub Actions in the last month in private repos only 0.09% would end up with a price increase, with a median increase of under $2 a month. Note that this impact is after these users have made use of their included minutes in their plans today, entitling them to over 33 hours of included GitHub compute, and this has no impact on their free use of public repos. A further 2.8% of this total user base will see a decrease in their monthly cost as a result of these changes. The rest are unimpacted by this change.</p>
<p><strong>How can I figure out what my new monthly cost for Actions looks like?</strong></p>
<p>GitHub Actions provides <a href="https://docs.github.com/billing/how-tos/products/view-productlicense-use">detailed usage reports for the current and prior year</a>. You can use this prior usage alongside the <a href="https://docs.github.com/billing/reference/actions-runner-pricing">rate changes</a> that will be introduced in January and March to estimate cost under the new pricing structure. We have created a <a href="https://docs.github.com/billing/tutorials/estimate-actions-costs">Python script</a> to help you leverage <a href="https://docs.github.com/billing/how-tos/products/view-productlicense-use#downloading-usage-reports">full usage reports</a> to calculate your expected cost after the price updates.</p>
<p>We have also updated our <a href="https://github.com/pricing/calculator#actions">Actions pricing calculator</a>, making it easier to estimate your future costs, particularly if your historical usage is limited or not representative of expected future usage.</p>
<h2>Additional resources</h2>
<ul>
<li>See the <a href="https://docs.github.com/billing/reference/actions-runner-pricing">GitHub Actions runner pricing documentation</a> for the new GitHub-hosted runner rates effective January 1, 2026.  </li>
<li>For more details on upcoming GitHub Actions releases, see the <a href="https://github.com/orgs/github/projects/4247">GitHub public roadmap</a>.  </li>
<li>For help estimating your expected Actions usage cost, use the newly updated <a href="https://github.com/pricing/calculator#actions">Actions pricing calculator</a>.  </li>
<li>To see your current or historical Actions usage, see our documentation for <a href="https://docs.github.com/billing/how-tos/products/view-productlicense-use">viewing and downloading detailed usage reports</a>.  </li>
<li>If you are interested in moving existing self-hosted runner usage to GitHub-hosted runners, see the <a href="http://docs.github.com/actions/tutorials/migrate-to-github-runners">SHR to GHR migration guide</a> in our documentation.</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Track Surveillance (Flock Cameras) Tech in Local Government Meetings (275 pts)]]></title>
            <link>https://alpr.watch/</link>
            <guid>46290916</guid>
            <pubDate>Tue, 16 Dec 2025 16:54:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alpr.watch/">https://alpr.watch/</a>, See on <a href="https://news.ycombinator.com/item?id=46290916">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
        ‚úì Link copied! Share this meeting with others.
    </p><div>
        <div>
            <div>
                
                <p>Your local government might be discussing surveillance tech like Flock cameras, facial recognition, or automated license plate readers right now. This map helps you find those meetings and take action.</p>
            </div>
            
            <p><span>Beautiful</span>
                <span>Unethical</span>
                <span>Dangerous</span>
            </p>
            
        </div>

        <div>
            <p><strong>Why this matters:</strong> &nbsp;Municipalities across the US are quietly adopting surveillance technologies in rapidly growing numbers with over 80,000 cameras already out on the streets. These systems track residents' movements, collect biometric data, and build massive databases of our daily lives.</p>
            <p>alpr.watch scans meeting agendas for keywords like "flock," "license plate reader," "alpr," and more. Each pin on the map shows where these conversations are happening so that you can make a difference.</p>
        </div>

        <div>
            <div>
                    <p><label>
                            
                            <span></span>
                        </label>
                        <span>Show only upcoming meetings</span>
                    </p>
                </div>

            <div>
                    <p><span>Get Email Alerts for Your Area</span>
                        <span>‚ñº</span>
                    </p>
                    <div id="notifContent">
                            <p>Enter your email below and we'll send you a login link. After logging in, you can set your notification preferences.</p>
                            <p><label for="email">Your Email</label>
                                
                            </p>
                            
                            <p>
                                ‚úì Check your email for a login link!
                            </p>
                            <p>
                                ‚úó Please enter a valid email address.
                            </p>
                        </div>
                </div>
        </div>

        <div>
            <div id="loadingOverlay">
                
                <p>Loading map data</p>
                <p>Fetching meetings...</p>
            </div>
            
            <p>
                üîç Zoom in to see ALPR surveillance cameras
            </p>
        </div>
        
        <p>
            Data before mid-December may be unverified. All future submissions are 100% moderator approved.
        </p>

        <div>
                <h3>Statistics</h3>
                <div>
                    <p><span id="stat-municipalities">--</span>
                        <span>Local Councils Monitored</span>
                    </p>
                    <p><span id="stat-meetings">--</span>
                        <span>Meetings Indexed</span>
                    </p>
                    <p><span id="stat-population">--</span>
                        <span>Cameras Mapped</span>
                    </p>
                </div>
            </div>

        <div>
            <h2>Understanding Mass Surveillance</h2>
            
            <div>
                <div>
                    <h3>What is ALPR?</h3>
                    <p><strong>Automated License Plate Recognition (ALPR)</strong> systems use cameras and artificial intelligence to capture, read, and store license plate data from every passing vehicle.</p>
                    <p>These systems work 24/7 creating a massive database of where vehicles, and by extension, people, travel. Every trip to the grocery store, doctor's office, or place of worship gets recorded and stored.</p>
                </div>

                <div>
                    <h3>What is Flock Safety?</h3>
                    <p><strong>Flock Safety</strong> is one of the largest manufacturers of ALPR cameras in the United States, marketing their systems to neighborhoods and law enforcement.</p>
                    <p>Flock cameras capture license plates, vehicle make/model, color, and other identifying features. This data is shared across a massive network of agencies and jurisdictions, creating a surveillance web that tracks millions of Americans.</p>
                </div>


                <div>
                    <h3>The Slippery Slope</h3>
                    <p>History shows that surveillance systems expand beyond their original scope:</p>
                    <ul>
                        <li>Systems marketed for "solving crimes" get used for immigration enforcement</li>
                        <li>Temporary programs become permanent infrastructure</li>
                        <li>Data sharing agreements grow to include more agencies</li>
                        <li>Technology advances enable new invasive uses</li>
                        <li>Regulations and oversight consistently lag behind deployment</li>
                    </ul>
                </div>
            </div>
        </div>

        <div>
                <h3>Organizations Fighting for Your Privacy</h3>
                <p>These groups and individuals are leading the fight against mass surveillance. Consider supporting their work or getting involved locally.</p>
                
                <div>
                    <div>
                        <p><strong>Electronic Frontier Foundation (EFF)</strong></p><p>Leading nonprofit defending digital privacy and civil liberties. <a href="https://www.eff.org/" target="_blank">eff.org</a></p>
                    </div>
                    
                    <div>
                        <p><strong>ACLU</strong></p><p>Fighting surveillance overreach through litigation and advocacy nationwide. <a href="https://www.aclu.org/" target="_blank">aclu.org</a></p>
                    </div>
                    
                    <div>
                        <p><strong>Fight for the Future</strong></p><p>Digital rights organization mobilizing grassroots opposition to surveillance. <a href="https://www.fightforthefuture.org/" target="_blank">fightforthefuture.org</a></p>
                    </div>
                    
                    <div>
                        <p><strong>Surveillance Technology Oversight Project (STOP)</strong></p><p>Litigating against invasive surveillance in New York and beyond. <a href="https://www.stopspying.org/" target="_blank">stopspying.org</a></p>
                    </div>
                    
                    <div>
                        <p><strong>Institute for Justice</strong></p><p>This civil liberties law firm has filed lawsuits challenging the constitutionality of Flock's mass, warrantless surveillance <a href="https://ij.org/press-release/public-interest-law-firm-responds-to-flock-safety-pausing-federal-access-to-license-plate-reader-cameras/" target="_blank">ij.org</a></p>
                    </div>
                    
                    <div>
                        <p><strong>Local Community Groups</strong></p><p>Check for privacy advocacy organizations in your area fighting surveillance at the local level.</p>
                    </div>
                </div>
            </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla appoints new CEO Anthony Enzor-Demeo (252 pts)]]></title>
            <link>https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/</link>
            <guid>46288491</guid>
            <pubDate>Tue, 16 Dec 2025 13:53:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/">https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/</a>, See on <a href="https://news.ycombinator.com/item?id=46288491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-84084">
  

  <div>
    
<p>Today, I step into the role of CEO of <a href="https://www.mozilla.org/en-US/">Mozilla Corporation</a>. It is a privilege to lead an organization with a long history of standing up for people and building technology that puts them first. The internet is changing fast, and so are the expectations people bring to the products they use every day. Mozilla has a critical role to play at this moment.</p>



<p>I want to thank Laura Chambers for her exceptional leadership. As interim CEO, Laura led Mozilla through a defining moment in the web‚Äôs history ‚Äî navigating AI‚Äôs arrival, a major antitrust case, double-digit mobile growth in Firefox, and the early success of our revenue diversification strategy. She brought clarity, stability, and focus to the organization, and I‚Äôm grateful for her leadership through this transition and am glad she‚Äôll continue to be part of Mozilla, returning to her role on the Mozilla board of directors.</p>



<p>When I joined Mozilla, it was clear that trust was going to become the defining issue in technology and the browser would be where this battle would play out. AI was already reshaping how people search, shop, and make decisions in ways that were hard to see and even harder to understand. I saw how easily people could lose their footing in experiences that feel personal but operate in ways that are anything but clear. And I knew this would become a defining issue, especially in the browser, where so many decisions about privacy, data, and transparency now originate.&nbsp;</p>



<figure><img decoding="async" width="1024" height="576" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-1024x576.png" alt="" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-1024x576.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-300x169.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-768x432.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-1536x864.png 1536w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-2048x1152.png 2048w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-1000x563.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/12/Distilled_Quote_Anthony-1280x720.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>People want software that is fast, modern, but also honest about what it does. They want to understand what‚Äôs happening and to have real choices.</p>



<p>Mozilla and Firefox can be that choice.</p>



<p>Few companies share our strengths. People trust our brand. Firefox brings us global reach. Our teams know how to build reliable, independent software at scale, and our business model puts the user first.</p>



<p>As Mozilla moves forward, we will focus on becoming the trusted software company. This is not a slogan. It is a direction that guides how we build and how we grow. It means three things.</p>



<ul>
<li>First: Every product we build must give people agency in how it works. Privacy, data use, and AI must be clear and understandable. Controls must be simple. AI should always be a choice ‚Äî something people can easily turn off. People should know why a feature works the way it does and what value they get from it.</li>



<li>Second: our business model must align with trust. We will grow through transparent monetization that people recognize and value.&nbsp;</li>



<li>Third: Firefox will grow from a browser into a broader ecosystem of trusted software. Firefox will remain our anchor. It will evolve into a modern AI browser and support a portfolio of new and trusted software additions.</li>
</ul>



<p>We will measure our progress against a <a href="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Mozilla-Summary-Portfolio-Strategy.pdf">double bottom line</a>. Our work must advance our mission and succeed in the market. In the next three years, that means investing in AI that reflects the Mozilla Manifesto. It means diversifying revenue beyond search.&nbsp;</p>



<p>Success means Firefox grows across generations. Mozilla builds new revenue engines. Our principles become a differentiator.</p>



<p>We will move with urgency. AI is changing software. Browsers are becoming the control point for digital life. Regulation is shifting defaults. These shifts play to Mozilla‚Äôs strengths.</p>



<p>If we stay focused, Mozilla will grow in relevance and resilience. Firefox will reach new audiences. Our portfolio will strengthen our independence. Our approach to building trusted software will set a high standard for the industry.</p>



<p>Mozilla is ready for this moment. I am excited for the work ahead and grateful for the trust placed in me.</p>
  </div>

</article><!-- #post-84084 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[40 percent of fMRI signals do not correspond to actual brain activity (296 pts)]]></title>
            <link>https://www.tum.de/en/news-and-events/all-news/press-releases/details/40-percent-of-mri-signals-do-not-correspond-to-actual-brain-activity</link>
            <guid>46288415</guid>
            <pubDate>Tue, 16 Dec 2025 13:46:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tum.de/en/news-and-events/all-news/press-releases/details/40-percent-of-mri-signals-do-not-correspond-to-actual-brain-activity">https://www.tum.de/en/news-and-events/all-news/press-releases/details/40-percent-of-mri-signals-do-not-correspond-to-actual-brain-activity</a>, See on <a href="https://news.ycombinator.com/item?id=46288415">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	
	
		<p>For almost three decades, functional magnetic resonance imaging (fMRI) has been one of the main tools in brain research. Yet a new study published in the renowned journal Nature Neuroscience fundamentally challenges the way fMRI data have so far been interpreted with regard to neuronal activity. According to the findings, there is no generally valid coupling between the oxygen content measured by MRI and neuronal activity.</p>
	

	
		<div>
			
<figure>
	<div>
		
				
						



	





<picture>
	
			<source media="(min-width: 43.75em)" srcset="https://www.tum.de/fileadmin/user_upload_87/_processed_/7/c/csm_Foto_Riedl_Epp_Gabriel_Castrillon_-_quer_e915521e41.webp" type="image/webp">
			<source media="(min-width: 31.25em)" srcset="https://www.tum.de/fileadmin/user_upload_87/_processed_/7/c/csm_Foto_Riedl_Epp_Gabriel_Castrillon_-_quer_963ad61082.webp" type="image/webp">
			<source srcset="https://www.tum.de/fileadmin/user_upload_87/_processed_/7/c/csm_Foto_Riedl_Epp_Gabriel_Castrillon_-_quer_17bce250c1.webp" type="image/webp">
		

	
			<img loading="lazy" src="https://www.tum.de/fileadmin/user_upload_87/_processed_/7/c/csm_Foto_Riedl_Epp_Gabriel_Castrillon_-_quer_89b836aefe.jpg" width="1920" height="1219" alt="">
		
</picture>

	<p><small>Gabriel Castrillon</small>



					
			

		
	</p></div>

	
		<figcaption>
			Dr. Samira Epp and Prof. Dr. Valentin Riedl
		</figcaption>
	
</figure>


		</div>
	


	<p>Researchers at the Technical University of Munich (TUM) and the Friedrich-Alexander-University Erlangen-Nuremberg (FAU) found that an increased fMRI signal is associated with reduced brain activity in around 40 percent of cases. At the same time, they observed decreased fMRI signals in regions with elevated activity. First author Dr. Samira Epp emphasizes: ‚ÄúThis contradicts the long-standing assumption that increased brain activity is always accompanied by an increased blood flow to meet higher oxygen demand. Since tens of thousands of fMRI studies worldwide are based on this assumption, our results could lead to opposite interpretations in many of them.‚Äù</p>
</div><div>
			<p><span>
					Publications
				</span>
			</p>
			<p>Samira M. Epp, Gabriel Castrill√≥n, Beijia Yuan, Jessica Andrews-Hanna, Christine Preibisch, Valentin Riedl: BOLD signal changes can oppose oxygen metabolism across the human cortex, published in Nature Neuroscience, December 12, 2025, <a href="https://doi.org/10.1038/s41593-025-02132-9" target="_blank" rel="noreferrer">https://doi.org/10.1038/s41593-025-02132-9</a></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This is not the future (625 pts)]]></title>
            <link>https://blog.mathieui.net/this-is-not-the-future.html</link>
            <guid>46288371</guid>
            <pubDate>Tue, 16 Dec 2025 13:42:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mathieui.net/this-is-not-the-future.html">https://blog.mathieui.net/this-is-not-the-future.html</a>, See on <a href="https://news.ycombinator.com/item?id=46288371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<ul>

<li title="2025-11-08T19:15:02+01:00">
          on&nbsp;Sat 08 November 2025
        </li>
</ul>
</div><!-- /.post-info --> <p>I thought about this when reading a mastodon post which commented on a news
where a project adopted a "use Generative AI but disclose it" policy, because
it is "the future" and "people are going to use it anyway".</p>
<p>I find the "this is the future, like it or not" framing particularly disgusting,
and it is somewhat common in tech circles to accept it for most "new"
technologies as if it was backed by evidence.</p>
<p>This post is to underline that <strong>Nothing is inevitable.</strong></p>
<div id="modern-technology-is-abusive">
<h2>Modern technology is abusive.</h2>
<p>A small contingent of power users using niche OSes (like myself) survive by avoiding as much of the tech oligarchs‚Äô world as I can, sure, but overall everything is disgusting, and using FOSS is certainly no silver bullet.</p>
<p>Tech enthusiasts who do not apply critical thinking are even worse, because they get beat up everyday by the things they buy at a premium <em>and they like it</em> because they have this twisted idea of what constitutes progress. This is slowly infusing into the general population, which is also a problem.</p>
<p>People have been trained to be abused by software and by hardware, to ignore their needs, to accept any change as inevitable.
I speak of abuse because people have been trained to <em>expect</em> and <em>accept</em> change at the same time, with no agency whatsoever.</p>
<p>Most old people in particular (sorry mom) have given up and resigned themselves to drift wherever their computing devices take them, because under the guise of convenience, everything is so hostile that there is no point trying to learn things, and dark patterns are everywhere.
Not being in control of course makes people endlessy frustrated, but at the same time trying to wrestle control from the parasites is an uphill battle that they expect to lose, with more frustration as a result.</p>
<p>I want to emphasize here that there are good products (both software and hardware) on the market even though the list gets shorter every year,
some products even manage to solve real problems (!!).
That does not change the fact that consent, hype and projected consumer needs are manufactured by years and years of abuse and marketing campaigns.</p>
<div id="those-things-were-or-are-not-inevitable">
<h3>Those things were or are not inevitable</h3>
<ul>
<li>Internet-connected beds are not inevitable.</li>
<li>AI browsers are not inevitable.</li>
<li>Talking to chatbots instead of public servants is not inevitable.</li>
<li>Requiring a smartphone to exist in society is not inevitable.</li>
<li>Unrepairable devices are not inevitable.</li>
<li>"AI-enhanced" vacation pictures are not inevitable.</li>
<li>NFTs were not inevitable.</li>
<li>The Metaverse was not inevitable.</li>
<li>Your computer changing where things are on every update is not inevitable.</li>
<li>Websites that require your ID are not inevitable.</li>
<li>Garbage companies using refurbished plane engines to power their data centers is not inevitable.</li>
<li>Juicero was not inevitable.</li>
<li>Ads are not inevitable.</li>
<li>Being on a platform owned by Meta is not inevitable.</li>
<li>The Apple Vision pro was not inevitable.</li>
<li>"Copilot PCs" are not inevitable.</li>
<li>Tiktok is not inevitable.</li>
<li>Your computer sending screenshots to microsoft so they can train AIs on it is not inevitable.</li>
</ul>
<p>I could spend years filling this list up, because the tech grifters always find new ways to make us more miserable.</p>
<p>Nothing is inevitable, nothing sold by powerful grifters is "the future" no matter how much they wish that were true.
Sure, some things can keep on existing, even for a very long time, even more if they have an untold number of billions - that they wormed they way into having by selling and exploiting personal data and attention -, but nobody has to be complicit. Some things might even end up existing because they are useful.</p>
<p>But what is important to me is to keep the perspective of what consitutes a <strong>desirable future</strong>, and which actions get us closer or further from that.</p>
<p>Every choice is <em>both</em> a <strong>political statement</strong> and a <strong>tradeoff</strong> based on the energy we can spend on the consequences of that choice.</p>
</div>
</div>
</div><p>
            If you have remarks or suggestions concerning this article, please by all means <a href="https://blog.mathieui.net/pages/about.html" title="contact">contact me</a>.
        </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rust GCC back end: Why and how (120 pts)]]></title>
            <link>https://blog.guillaume-gomez.fr/articles/2025-12-15+Rust+GCC+backend%3A+Why+and+how</link>
            <guid>46288291</guid>
            <pubDate>Tue, 16 Dec 2025 13:33:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.guillaume-gomez.fr/articles/2025-12-15+Rust+GCC+backend%3A+Why+and+how">https://blog.guillaume-gomez.fr/articles/2025-12-15+Rust+GCC+backend%3A+Why+and+how</a>, See on <a href="https://news.ycombinator.com/item?id=46288291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Whenever you compile using Rust, the compiler goes through different passes and in the end, generated binary code for the target processor. By default, it uses LLVM as backend to generate the binary code, but more backends exist like cranelift and GCC. This post is about how it's possible for one compiler to use different backend to generate binaries, in particular GCC.</p>
<h2><a href="#Passes"><span></span></a>Passes</h2>
<p>Before going into details, we need to describe how compilers actually work. They read source code and convert it internally into a format they can manipulate, commonly called Abstract Syntax Tree (shortened "AST").</p>
<p>However, compilers go through multiple passes, and often each pass has their own AST. Let's take a short and very incomplete example with the Rust compiler passes. We have 4 steps (again, this is simplified!):</p>
<ol>
<li>AST: checks that the syntax is valid</li>
<li>HIR: checks if types are valid</li>
<li>MIR: checks lifetimes and runs borrow-checker</li>
<li>codegen: generate binary code (which also has multiple steps, but not detailed here)</li>
</ol>
<p>Each step generates a new AST with new information if no error was encountered and provides it to the next pass.</p>
<p>Little side-note: If enough people are interested by this topic, I can write a (much) longer explanation of these passes.</p>
<h2><a href="#Backend-vs-front-end"><span></span></a>Backend vs front-end</h2>
<p>So now that we have a high-level idea of Rust compiler passes, what is the difference between "front-end" and "back-end" exactly?</p>
<p>We consider the front-end to be the part handling (high-level non-exhaustive list) code parsing, linting, type-checking and borrow-checking (steps 1 to 3). When all this is done, it means the code is valid and needs to be translated to the target processor instructions set. To do so, we call LLVM/GCC which will translate the Rust compiler AST into assembly code (step 4).</p>
<p>The Rust compiler backends are the bridge between the Rust compiler AST and the actual code generator. They receive the AST and call the LLVM/GCC/... API which will in turn run their passes, optimize and finally generate the assembly code.</p>
<h2><a href="#Why-having-a-GCC-backend"><span></span></a>Why having a GCC backend</h2>
<p>LLVM being much more recent than GCC (2003 vs 1987), a lot of older processors are not supported and will never be. So if you want to write a Rust program on an old platform like Dreamcast, you have no choice to either write your own backend or use the GCC backend (or the <code>gccrs</code> front-end once ready).</p>
<p>For the readers interested in doing so, there is a guide explaining how to build Rust programs for Dreamcast <a href="https://www.dreamcast.rs/">here</a>.</p>
<h2><a href="#gccrs-vs-GCC-backend"><span></span></a>gccrs vs GCC backend</h2>
<p>The GCC backend is different than <a href="https://rust-gcc.github.io/">gccrs</a> which is a front-end for GCC written in C++, which doesn't reuse the front-end of <code>rustc</code>, meaning they need to reimplement parsing, type-checking, linting, borrow-checking, compilation errors, etc.</p>
<p>On the other hand, the GCC backend (the crate name is <code>rustc_codegen_gcc</code>) is just "yet another backend codegen" of the Rust compiler, like LLVM or Cranelift, only meant to generate the binary from the Rust compiler input. It's a bridge between Rust compiler's AST and the codegen API.</p>
<p>On that note: GCC doesn't provide a nice library to give access to its internals (unlike LLVM). So we have to use <code>libgccjit</code> which, unlike the "jit" ("just in time", meaning compiling sub-parts of the code on the fly, only when needed for performance reasons and often used in script languages like Javascript) part in its name implies, can be used as "aot" ("ahead of time", meaning you compile everything at once, allowing you to spend more time on optimization). To do so we use bindings, which are split in two parts:</p>
<ul>
<li><a href="https://crates.io/crates/gccjit_sys"><code>gccjit-sys</code></a> which redeclares the C items we need.</li>
<li><a href="https://crates.io/crates/gccjit"><code>gccjit</code></a> which provides a nice API over <code>gccjit-sys</code>.</li>
</ul>
<p>If you want to write your own compiler and use GCC as codegen, you can do it thanks to <code>libgccjit</code>. And if you write it in Rust, you can even use the Rust bindings.</p>
<h2><a href="#Implementing-a-Rust-backend"><span></span></a>Implementing a Rust backend</h2>
<p>Rustc has a crate named <code>rustc_codegen_ssa</code> which provides an abstract interface that a backend needs to implement through traits like:</p>
<ul>
<li><a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.CodegenBackend.html">CodegenBackend</a></li>
<li><a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.ExtraBackendMethods.html">ExtraBackendMethods</a></li>
<li><a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.WriteBackendMethods.html">WriteBackendMethods</a></li>
</ul>
<p>The full list is available <a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/index.html">here</a>.</p>
<p>One last thing you need to write in your backend:</p>
<pre><a href="https://play.rust-lang.org/?code=fn+main%28%29+%7B%0A++++%23%5Bno_mangle%5D%0A++++pub+fn+_rustc_codegen_backend%28%29+-%3E+Box%3Cdyn+CodegenBackend%3E+%7B%0A++++++++%2F%2F+This+is+the+entrypoint.%0A++++%7D%0A%7D%0A">Run</a><code>#[no_mangle]
pub fn _rustc_codegen_backend() -&gt; Box&lt;dyn CodegenBackend&gt; {
    // This is the entrypoint.
}</code></pre>
<p>This is the function that will be called by rustc to run your backend.</p>
<h2><a href="#Codegen-implementation-example"><span></span></a>Codegen implementation example</h2>
<p>Let's take an example: how the GCC backend creates a constant string. I picked this one because it's small enough to showcase how things work while not being too much information to digest at once.</p>
<p>In the <a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.ConstCodegenMethods.html">ConstCodegenMethods</a> trait, there is a <a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.ConstCodegenMethods.html#tymethod.const_str">const_str</a> method. This is the method we will implement to declare a constant string.</p>
<p>So the method implementation so far looks like this:</p>
<pre><a href="https://play.rust-lang.org/?code=fn+main%28%29+%7B%0A++++impl%3C%27gcc%2C+%27tcx%3E+ConstCodegenMethods+for+CodegenCx%3C%27gcc%2C+%27tcx%3E+%7B%0A++++++++%2F%2F%2F+Returns+the+pointer+to+the+string+and+its+length.%0A++++++++fn+const_str%28%26self%2C+s%3A+%26str%29+-%3E+%28RValue%3C%27gcc%3E%2C+RValue%3C%27gcc%3E%29+%7B%0A++++++++++++%2F%2F+Call+GCC+API+to+declare+this+string.%0A++++++++%7D%0A++++%7D%0A%7D%0A">Run</a><code>impl&lt;'gcc, 'tcx&gt; ConstCodegenMethods for CodegenCx&lt;'gcc, 'tcx&gt; {
    /// Returns the pointer to the string and its length.
    fn const_str(&amp;self, s: &amp;str) -&gt; (RValue&lt;'gcc&gt;, RValue&lt;'gcc&gt;) {
        // Call GCC API to declare this string.
    }
}</code></pre>
<p>We need to pause here to give some extra explanations: <code>CodegenCx</code> is the type on which most <code>rustc_codegen_ssa</code> traits will be implemented. It is created in each <a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.ExtraBackendMethods.html#tymethod.compile_codegen_unit">ExtraBackendMethods::compile_codegen_unit</a> call and passed down from there to generate the code for this module. You can consider it the same as a cache. It keeps the list of items declared, like functions, types, globals, etc. But also information such as "boolean type", "i8 type" and equivalents so we don't need to recompute them every time we need them.</p>
<p>Ok so now let's actually implement it. We have a few things to do:</p>
<ol>
<li>To avoid adding the same constant string multiple times, we will need to cache them in our context.</li>
<li>We need to cast the Rust str type (<code>*const u8</code>) into the C type (<code>*const char</code>).</li>
<li>Get the pointer to this constant string and return it.</li>
</ol>
<p>Let's translate it into code with a lot of comments to help understanding what's going on:</p>
<pre><a href="https://play.rust-lang.org/?code=fn+main%28%29+%7B%0A++++fn+const_str%28%26self%2C+s%3A+%26str%29+-%3E+%28RValue%3C%27gcc%3E%2C+RValue%3C%27gcc%3E%29+%7B%0A++++++++%2F%2F+We+get+the+const+string+cache.%0A++++++++let+mut+const_str_cache+%3D+self.const_str_cache.borrow_mut%28%29%3B%0A++++++++%2F%2F+We+get+the+address+of+the+stored+string+and+we+add+it+to+the+cache+and%0A++++++++%2F%2F+return+its+address.%0A++++++++let+str_global+%3D+const_str_cache.get%28s%29.copied%28%29.unwrap_or_else%28%7C%7C+%7B%0A++++++++++++%2F%2F+We+call+the+%60GCC%60+API+to+create+a+new+const+string.%0A++++++++++++let+string+%3D+self.context.new_string_literal%28s%29%3B%0A++++++++++++%2F%2F+We+name+the+const.%0A++++++++++++let+sym+%3D+self.generate_local_symbol_name%28%22str%22%29%3B%0A++++++++++++%2F%2F+We+declare+it.%0A++++++++++++let+global+%3D+self.declare_private_global%28%26sym%2C+self.val_ty%28string%29%29%3B%0A++++++++++++%2F%2F+All+done%2C+we+can+add+it+to+the+cache+and+return+it.%0A++++++++++++const_str_cache.insert%28s.to_owned%28%29%2C+global%29%3B%0A++++++++++++global%0A++++++++%7D%29%3B%0A++++++++let+len+%3D+s.len%28%29%3B%0A++++++++%2F%2F+We+cast+the+pointer+to+the+target+architecture+string+pointer+type.%0A++++++++let+cs+%3D+self.const_ptrcast%28%0A++++++++++++str_global.get_address%28None%29%2C%0A++++++++++++self.type_ptr_to%28self.layout_of%28self.tcx.types.str_%29.gcc_type%28self%29%29%2C%0A++++++++%29%3B%0A++++++++%2F%2F+And+we+return+the+pointer+and+its+length.%0A++++++++%28cs%2C+self.const_usize%28len+as+_%29%29%0A++++%7D%0A%7D%0A">Run</a><code>fn const_str(&amp;self, s: &amp;str) -&gt; (RValue&lt;'gcc&gt;, RValue&lt;'gcc&gt;) {
    // We get the const string cache.
    let mut const_str_cache = self.const_str_cache.borrow_mut();
    // We get the address of the stored string and we add it to the cache and
    // return its address.
    let str_global = const_str_cache.get(s).copied().unwrap_or_else(|| {
        // We call the `GCC` API to create a new const string.
        let string = self.context.new_string_literal(s);
        // We name the const.
        let sym = self.generate_local_symbol_name("str");
        // We declare it.
        let global = self.declare_private_global(&amp;sym, self.val_ty(string));
        // All done, we can add it to the cache and return it.
        const_str_cache.insert(s.to_owned(), global);
        global
    });
    let len = s.len();
    // We cast the pointer to the target architecture string pointer type.
    let cs = self.const_ptrcast(
        str_global.get_address(None),
        self.type_ptr_to(self.layout_of(self.tcx.types.str_).gcc_type(self)),
    );
    // And we return the pointer and its length.
    (cs, self.const_usize(len as _))
}</code></pre>
<p>But the codegen backends can also add more information to the underlying binary code generator. For example, in Rust, we use references a lot. A reference is basically a pointer that cannot be <code>NULL</code>. We need to give this information as well!</p>
<p>In both GCC and LLVM, you can add attributes to a lot of items, like arguments of functions. So every time we see an argument behind a reference, we add the <code>nonnnull()</code> attribute.</p>
<p>Let's show an example with this Rust function:</p>
<pre><a href="https://play.rust-lang.org/?code=fn+main%28%29+%7B%0A++++fn+t%28a%3A+%26i32%29+-%3E+i32+%7B%0A++++++++%2Aa%0A++++%7D%0A%7D%0A">Run</a><code>fn t(a: &amp;i32) -&gt; i32 {
    *a
}</code></pre>
<p>The C equivalent looks like this:</p>
<pre><code>int t(int *a) {
  if (!a) {
    return -1;
  }
  return *a;
}</code></pre>
<p>Compiled with the <code>-O3</code> option, it generates this assembly:</p>
<pre><code>t:
        test    rdi, rdi              ; Check if `a` is 0
        je      .L5                   ; If `a` is 0, we jump to `.L1`
        mov     eax, DWORD PTR [rdi]  ; We store `*a` value into `eax` registry
        ret                           ; We exit the function
.L5:
        mov     eax, -1               ; We store `-1` into `eax` registry
        ret                           ; We exit</code></pre>
<p>However, the Rust compiler knows that <code>a</code> can never be <code>NULL</code>, so the codegen adds <code>_attribute_((nonnull(1)))</code> on the function:</p>
<pre><code>_attribute_((nonnull(1)))
int t(int *a) {
  if (!a) {
    return -1;
  }
  return *a;
}</code></pre>
<p>Which generates this assembly:</p>
<pre><code>t:
        mov     eax, DWORD PTR [rdi]
        ret</code></pre>
<p>Since the codegen knows that the <code>if (!a)</code> condition will never be true, why keeping it around?</p>
<p>And it's just one example of extra information/optimization we do in the Rust backends. And that doesn't even cover in the slighest the monstruous amount of optimizations the codegen themselves do. If you want to have more examples of such optimizations, I strongly recommend reading the <a href="https://xania.org/AoCO2025">"Advent of Compiler Optimizations"</a> blog posts written by Matt Godbolt (the developer of <a href="https://godbolt.org/">godbolt.org</a>, another priceless tool).</p>
<h2><a href="#Words-of-the-end"><span></span></a>Words of the end</h2>
<p>So now you know what a Rust backend is, and why GCC backend is also an interesting thing to have while also learning about some optimizations we do behind developers back. :)</p>
<p>This blog post was made thanks to my cat hanging to it.</p>
<p><img id="1" onclick="click_img(1)" src="https://blog.guillaume-gomez.fr/blog/images/cat-in-tree.jpg" alt="my cat in a tree, hanging on a branch"></p><p><a href="https://blog.guillaume-gomez.fr/rss" data-tooltip="RSS feed"><img height="35" src="https://blog.guillaume-gomez.fr/blog/feed.svg" alt="RSS feed"></a><a href="https://blog.guillaume-gomez.fr/atom" data-tooltip="Atom feed"><img height="35" src="https://blog.guillaume-gomez.fr/blog/atom-feed.svg" alt="RSS feed"></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sega Channel: VGHF Recovers over 100 Sega Channel ROMs (and More) (155 pts)]]></title>
            <link>https://gamehistory.org/segachannel/</link>
            <guid>46288024</guid>
            <pubDate>Tue, 16 Dec 2025 13:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gamehistory.org/segachannel/">https://gamehistory.org/segachannel/</a>, See on <a href="https://news.ycombinator.com/item?id=46288024">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content">

	
<article id="post-29279">
	
	<!-- .cover-header -->

	<div id="post-inner">

		
<p>Sega broke ground in the late 90s with one of the first digital game distribution systems for consoles. Sega Channel offered access to a rotating library of Sega Genesis titles, along with game tips, demos, and even a few exclusive games that never came out in the United States in any other format. In an era of dial-up internet, Sega Channel delivered game data over television cable ‚Äî a novel approach that gave the service its name.</p>



<p>In the years since, Sega Channel has been shrouded in a bit of mystery. The service was discontinued in 1998, and the lack of retrievable game data and documentation around Sega Channel has led to decades of speculation about it. We‚Äôve mostly been left with magazine articles and second-hand accounts. Once in a while, one or two Sega Channel ROMs will show up online. How do you <em>preserve</em> a service like Sega Channel?</p>



<p>For the last two years, we‚Äôve been working on a large-scale project to preserve the history of Sega Channel. Today, we unveiled our findings in a new YouTube video.</p>



<figure><p>
<iframe title="Don't Just Watch TV: The Secrets of Sega Channel" width="800" height="450" src="https://www.youtube.com/embed/CWCUmTTVjMY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>We‚Äôll cut to the chase: In collaboration with multiple parties, we have recovered <strong>over 100 new Sega Channel ROMs</strong>, including system data, exclusive games, and even prototypes that were never published. We‚Äôve also digitized internal paperwork and correspondence that reveals how Sega Channel operated, how it was marketed, and what would‚Äôve come next for the service.</p>



<hr>


<div>
<figure><img fetchpriority="high" decoding="async" width="169" height="300" src="https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-169x300.jpg" alt="" srcset="https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-169x300.jpg 169w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-576x1024.jpg 576w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-740x1316.jpg 740w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-768x1365.jpg 768w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-50x89.jpg 50w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-864x1536.jpg 864w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-1152x2048.jpg 1152w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296-1200x2133.jpg 1200w, https://gamehistory.org/wp-content/uploads/2025/12/PXL_20240320_191933296.jpg 1440w" sizes="(max-width: 169px) 100vw, 169px"><figcaption>Michael Shorrock was surprisingly easygoing about finding a picture of himself in a museum exhibit.</figcaption></figure>
</div>


<p>This project kicked off in 2024, when we met former Sega Channel vice president of programming Michael Shorrock at the Game Developers Expo. <a href="https://www.youtube.com/watch?v=dGl14yIeOsc" target="_blank" rel="noreferrer noopener">Our booth that year</a> highlighted interesting games from outside the traditional game industry, including <em><a href="https://gamehistory.org/where-in-north-dakota-is-carmen-sandiego/" target="_blank" rel="noreferrer noopener">Where in North Dakota is Carmen Sandiego?</a></em>, which our director Frank Cifaldi recovered back in 2016.</p>



<p>By complete coincidence, one of the items we put out was a promotional brochure for Broderbund Software‚Ä¶ featuring Michael Shorrock on the cover! We got talking with Michael about our work, and we realized we both wanted to preserve and celebrate the history of Sega Channel.</p>



<p>At the same time this was happening, we were contacted by a community member named Ray (going by the pseudonym Sega Channel Guy). He had been contacting former Sega Channel staff to see if they still had any old swag or had saved things from the company. In the process, he came into possession of a collection of tape backups containing an unquantifiable amount of internal data from Sega Channel‚Ä¶ including a significant number of game and system ROMs.</p>



<p>We realized we could put these two threads together! With Michael‚Äôs own collection and Ray‚Äôs data backups, we could tell a cohesive, wide-ranging story about what Sega Channel <em>was</em> and that was actually distributed through this service.</p>



<p>There are two end products from this process. The first is <a href="https://archive.gamehistory.org/folder/4cdb4e35-216f-46e8-9215-04ab8b6b49c1" target="_blank" rel="noreferrer noopener">the Michael Shorrock collection</a>, a new collection in our digital library. You can view the correspondence, notes, and presentations from Michael Shorrock‚Äôs personal collection, which shed light on the formation of Sega Channel and their audience. From these papers, you can also learn about Express Games: an unannounced successor that would have brought Sega‚Äôs cable data delivery service to computers and replaced Sega Channel entirely.</p>



<hr>



<p>The other output here is the collection of Sega Channel ROM data. We‚Äôve donated the data from the <strong>144* new ROMs</strong> we recovered to <a href="https://www.gamingalexandria.com/wp/2025/12/sega-channel-prototype-sega-genesis-roms/" target="_blank" rel="noreferrer noopener">the team at Gaming Alexandria</a>, which will be sharing access to the files.</p>



<p>* Our video states that we recovered 142 unique ROMs. However, after uploading the video, we realized we miscounted! There are two additional Sega Channel variant ROM in this collection. The actual total is 144. This does not include the two outliers mentioned in the video, which were <a href="https://www.infochunk.com/schannel/index.html" target="_blank" rel="noreferrer noopener">previously recovered by users on Sonic Retro in November 2024</a> but went mostly unreported.</p>



<p>This collection includes nearly 100 unique system ROMs, covering almost every version of the system that was distributed to consumers from 1994 to mid-1997. This batch also includes system ROM prototypes and some truly unusual experiments, like a <em>Sega Genesis web browser</em> that would‚Äôve delivered compressed, static websites over television cable.</p>







<p>Of great interest to fans, this collection of ROMs also has dozens of previously undumped game variants and Sega Channel exclusives. This includes <em>Garfield: Caught in the Act ‚Äì The Lost Levels</em> and <em>The Flintstones</em>, two games that were previously believed to be permanently lost and unrecoverable. These are both interesting from a development standpoint; both games appear to have their roots as abandoned projects that were repurposed as Sega Channel-exclusive content.</p>







<p>Also included are the previously unpreserved limited editions of Sega Genesis games. These versions have been cut down to fit within Sega Channel‚Äôs filesize limit, sometimes omitting content or splitting the game into multiple parts. We‚Äôre not sure anyone is especially eager to play a version of <em>Super Street Fighter II</em> missing half the characters, but we‚Äôre glad to have it documented.</p>







<p>With a few exceptions, this recovery project has accounted for <strong>almost all outstanding Sega Channel games</strong>. We believe this also means there are now digital backup copies of <strong>every unique Sega Genesis game released in the United States</strong>.</p>



<hr>



<p>This has been a years-long project that wouldn‚Äôt have been possible without support from the broader gaming community. Besides Michael Shorrock and Ray, we want to give special thanks to:</p>



<ul>
<li>Sega Retro, The Cutting Room Floor, and Hidden Palace for documenting everything we‚Äôve known about Sega Channel up to this point.</li>



<li><a href="https://forums.sonicretro.org/threads/more-sega-channel-prototypes-dumped.25935/page-17#post-1084673" target="_blank" rel="noreferrer noopener">RisingFromRuins</a> and Nathan Misner (<a href="https://www.infochunk.com/schannel/index.html" target="_blank" rel="noreferrer noopener">infochunk</a>) for putting all the pieces together to crack the Sega Channel data formats.</li>



<li>Dustin Hubbard (Hubz) from Gaming Alexandria for working with us to share this ROM data.</li>



<li>Rob Curl from the Museum of Art and Digital Entertainment, who flagged us down at GDC to let us know that Michael Shorrock had seen a picture of himself at our booth and brought him over to say hello.</li>
</ul>



<p>We also want to give a special thanks to Chuck Guzis, a long-time expert on data tapes, who digitized Ray‚Äôs Sega Channel backups for us in 2024. Chuck‚Äôs business <a href="https://web.archive.org/web/20250330034327/https://www.sydex.com/" target="_blank" rel="noreferrer noopener">Sydex</a> was, for a long time, the go-to vendor for working with data tapes, and we‚Äôve used his services in the past.</p>



<p>Shortly before launching this project, we learned that Chuck passed away over the summer. His death leaves a hole in our community and our collective expertise. We know that the gaming community (and specifically the Sega community) will be excited by all this new documentation and data; we hope that their excitement is a testament to what Chuck‚Äôs work meant to the digital preservation community.</p>







<hr>



<h3>Complete list of recovered titles</h3>



<p>This is a list of all Sega Channel-specific game data recovered from this project and shared with Gaming Alexandria. This does not include the 97 unique pieces of menu data ROMs and system software that were also recovered.</p>



<details><summary>Game list</summary>
<p><span>Unique Sega Channel exclusive games:</span></p>



<ul>
<li>The Berenstain Bears‚Äô A School Day</li>



<li>BreakThru</li>



<li>The Flintstones</li>



<li>Garfield: Caught in the Act ‚Äì The Lost Levels</li>



<li>Iron Hammer</li>



<li>Waterworld</li>
</ul>



<p><span>Sega Channel variants:</span></p>



<ul>
<li>The Adventures of Batman and Robin, Test Drive version</li>



<li>Comix Zone, Test Drive version (1)</li>



<li>Comix Zone, Test Drive version (2)</li>



<li>Earthworm Jim, Test Drive version</li>



<li>Earthworm Jim VideoHints (1)</li>



<li>Earthworm Jim VideoHints (2)</li>



<li>The Great Earthworm Jim Race</li>



<li>The Lost World: Jurassic Park, Part A</li>



<li>The Lost World: Jurassic Park, Part B</li>



<li>The Lost World: Jurassic Park, Test Drive version</li>



<li>NCAA Final Four Basketball: Special Edition (1)</li>



<li>NCAA Final Four Basketball: Special Edition (2)</li>



<li>Mortal Kombat 3, Part A</li>



<li>Mortal Kombat 3, Part B</li>



<li>Scholastic‚Äôs The Magic School Bus: Space Exploration Game, Test Drive version</li>



<li>Sonic 3D Blast, Part A</li>



<li>Sonic 3D Blast, Part B</li>



<li>Super Street Fighter II: Limited Edition</li>



<li>Triple Play Baseball 96: Special Edition</li>



<li>Virtua Fighter 2, Part A</li>



<li>Virtua Fighter 2, Part B</li>



<li><em>World Series Baseball ‚Äô96: Limited Edition*</em></li>



<li>X-Men 2: Clone Wars, Test Drive version</li>
</ul>



<p><span>Prototypes received by Sega Channel:</span></p>



<ul>
<li>Al Unser Jr.‚Äôs Road to the Top</li>



<li>Dan Marino Football</li>



<li>Light Crusader</li>



<li>Nick Faldo‚Äôs Championship Golf</li>



<li>Popeye in High Seas High-Jinks</li>



<li>Shadows of the Wind</li>



<li>WildSnake</li>



<li>Wrath of the Demon</li>



<li>Yogi Bear [Yogi Bear‚Äôs Cartoon Capers]</li>
</ul>



<p><span>Data differences:</span></p>



<ul>
<li>Body Count (US revision)</li>



<li>Maui Mallard in Cold Shadow</li>



<li>Primal Rage</li>



<li>Pulseman</li>



<li><em>Richard Scarry‚Äôs Busytown*</em></li>



<li>Shining Force II</li>
</ul>



<p><span>Header differences only:</span></p>



<ul>
<li>Battle Frenzy (US header)</li>



<li>Power Drive (US header)</li>



<li>QuackShot</li>



<li>Super Hang-On</li>



<li>Wacky Worlds Creativity Studio</li>



<li>X-Men 2: Clone Wars</li>
</ul>



<p>* These games were previously found <a href="https://www.infochunk.com/schannel/index.html" target="_blank" rel="noreferrer noopener">on a CD obtained by a user on the Sonic Retro forums in November 2024</a>. However, these ROMs were overshadowed by the recovery of the Sega Channel exclusive games <em>The Chessmaster</em> and <em>Klondike</em> from the same CD. Although our copies of these ROMs are not unique, we included them on this list to make sure their existence doesn‚Äôt get lost.</p>
</details>



<h3>A footnote for hardcore Sega fans</h3>



<p>We believe this recovery project accounts for all unique Sega Channel exclusive games. But the most hardcore fans might be wondering: What about <em>Ozone Kid</em>? In a feature article on Sega Channel from <a href="https://archive.gamehistory.org/item/374968d3-ec6d-4e61-a4cb-28758897b930" target="_blank" rel="noreferrer noopener">the June 1995 issue of <em>Electronic Gaming Monthly</em></a> (p.29), <em>Ozone Kid</em> was identified as the first Sega Channel exclusive.</p>



<p>We can confirm that this game was never actually distributed through Sega Channel. According to data recovered by Ray, <em>The Environmental Detective</em> (as it was titled prior to cancellation) was slated for release alongside the Sega Channel test markets, but it was pulled from their programming plans in July 1994.</p>



<p>Reading the between the lines in Sega Channel‚Äôs internal project tracking, the game appears to have suffered from a variety of problems over several months. When the game was finally shelved, Sega issued a ‚Äúpartial test report based on items found at the time code was pulled,‚Äù suggesting there were still major issues when it was removed from their plans.</p>

		</div><!-- .post-inner -->

	
</article><!-- .post -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ArkhamMirror: Airgapped investigation platform with CIA-style hypothesis testing (113 pts)]]></title>
            <link>https://github.com/mantisfury/ArkhamMirror</link>
            <guid>46286666</guid>
            <pubDate>Tue, 16 Dec 2025 09:51:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mantisfury/ArkhamMirror">https://github.com/mantisfury/ArkhamMirror</a>, See on <a href="https://news.ycombinator.com/item?id=46286666">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/logo.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/logo.png" width="40" height="40" alt="ArkhamMirror Logo"></a> ArkhamMirror</h2><a id="user-content--arkhammirror" aria-label="Permalink:  ArkhamMirror" href="#-arkhammirror"></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/banner.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/banner.png" alt="ArkhamMirror Banner"></a></p>
<blockquote>
<p dir="auto"><strong>Connect the dots without connecting to the cloud.</strong></p>
</blockquote>
<p dir="auto">ArkhamMirror is an air-gapped, AI-powered investigation platform for journalists and researchers. It runs 100% locally on your machine, turning chaos into order using advanced NLP, Vision AI, and Knowledge Graphs.</p>
<p dir="auto"><a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/fdf2982b9f5d7489dcf44570e714e3a15fce6253e0cc6b5aa61a075aac2ff71b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>
<a href="https://www.python.org/downloads/" rel="nofollow"><img src="https://camo.githubusercontent.com/93a33cfc2339ec3fa9be792576576fbaafc42b0c7031285662b02f3aca1e1c59/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302b2d626c75652e737667" alt="Python 3.10+" data-canonical-src="https://img.shields.io/badge/python-3.10+-blue.svg"></a>
<a href="https://ko-fi.com/arkhammirror" rel="nofollow"><img src="https://camo.githubusercontent.com/06224b100168bb3a0ba553256ca368308546dd9cadfbde24cbfeac553eb70269/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53706f6e736f722d4b6f2d2d66692d726564" alt="Sponsor" data-canonical-src="https://img.shields.io/badge/Sponsor-Ko--fi-red"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚ö° Key Features at a Glance</h2><a id="user-content--key-features-at-a-glance" aria-label="Permalink: ‚ö° Key Features at a Glance" href="#-key-features-at-a-glance"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>üïµÔ∏è Local AI</strong></td>
<td>Chat with your data using <strong>Offline RAG</strong> (Retrieval-Augmented Generation).</td>
</tr>
<tr>
<td><strong>üîç Semantic Search</strong></td>
<td>Find documents by <em>concept</em>, not just exact keywords.</td>
</tr>
<tr>
<td><strong>üï∏Ô∏è Knowledge Graph</strong></td>
<td>Visualize hidden connections between People, Orgs, and Places.</td>
</tr>
<tr>
<td><strong>‚è≥ Auto-Timeline</strong></td>
<td>Extract dates and events to reconstruct what happened when.</td>
</tr>
<tr>
<td><strong>üìä Visual Table Extraction</strong></td>
<td>Recover complex financial tables from PDFs/Images using Vision models.</td>
</tr>
<tr>
<td><strong><g-emoji alias="warning">‚ö†Ô∏è</g-emoji> Contradiction Detection</strong></td>
<td>Automatically flag conflicting statements across documents.</td>
</tr>
<tr>
<td><strong>üîí Absolute Privacy</strong></td>
<td>Zero cloud dependencies. Your data never leaves your specialized "Data Silo".</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üöÄ Getting Started</h2><a id="user-content--getting-started" aria-label="Permalink: üöÄ Getting Started" href="#-getting-started"></a></p>
<p dir="auto">ArkhamMirror includes a <strong>Smart Installer</strong> that sets up Python, Docker, and Database dependencies for you.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows (One-Click)</h3><a id="user-content-windows-one-click" aria-label="Permalink: Windows (One-Click)" href="#windows-one-click"></a></p>
<p dir="auto">Double-click <code>setup.bat</code> and follow the <strong>AI Setup Wizard</strong>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mac / Linux</h3><a id="user-content-mac--linux" aria-label="Permalink: Mac / Linux" href="#mac--linux"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="chmod +x setup.sh
./setup.sh"><pre>chmod +x setup.sh
./setup.sh</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìö Documentation</h2><a id="user-content--documentation" aria-label="Permalink: üìö Documentation" href="#-documentation"></a></p>
<p dir="auto">Detailed guides for features and workflows:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/index.md#user-guide">User Guide</a></strong>: Full walkthrough of features.</li>
<li><strong><a href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/user_guide/01-getting-started.md">Installation</a></strong>: Detailed setup instructions.</li>
<li><strong><a href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/index.md#developer-guide">Developer Guide</a></strong>: Architecture and contributing.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üñºÔ∏è Gallery</h2><a id="user-content-Ô∏è-gallery" aria-label="Permalink: üñºÔ∏è Gallery" href="#Ô∏è-gallery"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/images/dashboard.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/images/dashboard.png" alt="Dashboard"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Advanced Analysis</h3><a id="user-content-advanced-analysis" aria-label="Permalink: Advanced Analysis" href="#advanced-analysis"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Narrative Reconstruction</th>
<th>Gap Finding</th>
<th>Contradiction Chain</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/images/motive.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/images/motive.png" alt="Motive"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/images/gaps.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/images/gaps.png" alt="Gaps"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/images/weboflies.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/images/weboflies.png" alt="Web of Lies"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Forensics</h3><a id="user-content-forensics" aria-label="Permalink: Forensics" href="#forensics"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Entity Graph</th>
<th>Author Unmasking</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/images/graph.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/images/graph.png" alt="Graph"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/mantisfury/ArkhamMirror/blob/main/docs/assets/images/authorunmask.png"><img src="https://github.com/mantisfury/ArkhamMirror/raw/main/docs/assets/images/authorunmask.png" alt="Author Unmask"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üíñ Support the Project</h2><a id="user-content--support-the-project" aria-label="Permalink: üíñ Support the Project" href="#-support-the-project"></a></p>
<p dir="auto">This tool was born from a desire to give journalists powerful forensics without the monthly subscription costs or privacy risks of cloud platforms.</p>
<p dir="auto">If it helps you uncover the truth, consider buying me a coffee!</p>
<p dir="auto"><a href="https://ko-fi.com/arkhammirror" rel="nofollow"><img src="https://camo.githubusercontent.com/201ef269611db7eb6b5d08e9f756ab8980df3014b64492770bdf13a6ed924641/68747470733a2f2f6b6f2d66692e636f6d2f696d672f676974687562627574746f6e5f736d2e737667" alt="Support on Ko-fi" data-canonical-src="https://ko-fi.com/img/githubbutton_sm.svg"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm a Tech Lead, and nobody listens to me. What should I do? (141 pts)]]></title>
            <link>https://world.hey.com/joaoqalves/i-m-a-tech-lead-and-nobody-listens-to-me-what-should-i-do-e16e454d</link>
            <guid>46286559</guid>
            <pubDate>Tue, 16 Dec 2025 09:38:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://world.hey.com/joaoqalves/i-m-a-tech-lead-and-nobody-listens-to-me-what-should-i-do-e16e454d">https://world.hey.com/joaoqalves/i-m-a-tech-lead-and-nobody-listens-to-me-what-should-i-do-e16e454d</a>, See on <a href="https://news.ycombinator.com/item?id=46286559">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page" id="main-content">
        

<header>
  <a aria-label="All posts from Jo√£o Alves" href="https://world.hey.com/joaoqalves">
  <img src="https://world.hey.com/joaoqalves/avatar-2f194f659bc641b1c66c0ed5979077ec9ba0e960" size="50x50">

  <p>
    Jo√£o Alves
  </p>
</a>
</header>

<p>
  December 16, 2025
</p>



  <section>
    <article>
      <div>
  <div><p>In June 2018, I joined mytaxi (<a href="https://www.free-now.com/uk/">FREE NOW</a>), a competitor of Uber in the ride-hailing space, as Backend Chapter Lead. I was looking for an opportunity to grow in technical leadership. Honestly, I did not even fully understand what ‚ÄúChapter Lead‚Äù meant. After some research, I learned it was part of <a href="https://agile-frameworks.com/_spotify/spotify.html">Spotify</a>‚Äôs squad (team) and chapter (horizontal domain, such as iOS, Android, Backend, Data, etc.) model, as well as tribes (groups of squads organized around vertical domains, for example, everything related to drivers).</p><p><em>Note</em>: this article is a translation from the original ‚Äú<a href="https://enespanol.joaoqalves.net/p/soy-tech-lead-y-no-me-hacen-caso">Soy Tech Lead y no me hacen caso. ¬øQu√© hago?</a>‚Äù, in Spanish.</p><figure>
      <a download="Screenshot 2025-12-10 at 20.10.55.png" title="Download Screenshot 2025-12-10 at 20.10.55.png" data-click-proxy-target="lightbox_link_blob_2380165026" href="https://world.hey.com/joaoqalves/e16e454d/blobs/eyJfcmFpbHMiOnsiZGF0YSI6MjM4MDE2NTAyNiwicHVyIjoiYmxvYl9pZCJ9fQ--faeb376287e9805a250b9f66538ddbad3f2a57406a2c5e8bd67ac6e9263ff351/Screenshot%202025-12-10%20at%2020.10.55.png?disposition=attachment">
        <img src="https://world.hey.com/joaoqalves/e16e454d/representations/eyJfcmFpbHMiOnsiZGF0YSI6MjM4MDE2NTAyNiwicHVyIjoiYmxvYl9pZCJ9fQ--faeb376287e9805a250b9f66538ddbad3f2a57406a2c5e8bd67ac6e9263ff351/eyJfcmFpbHMiOnsiZGF0YSI6eyJmb3JtYXQiOiJwbmciLCJyZXNpemVfdG9fbGltaXQiOlszODQwLDI1NjBdLCJxdWFsaXR5Ijo2MCwibG9hZGVyIjp7InBhZ2UiOm51bGx9LCJjb2FsZXNjZSI6dHJ1ZX0sInB1ciI6InZhcmlhdGlvbiJ9fQ--7edc7b21f6fad97fa22412618822c4d19725431f296c7ce47dc174b61535d27c/Screenshot%202025-12-10%20at%2020.10.55.png" alt="Screenshot 2025-12-10 at 20.10.55.png" decoding="async" loading="lazy">
</a>
  </figure></div><div><p><em>The squads, tribes, chapters, and guilds model popularized by Spotify. </em><a href="https://agile-frameworks.com/_spotify/spotify.html"><em>Source</em></a><em>.</em></p></div><p>That role had two main components:</p><ul><li><strong>Backend technical leadership</strong> (TL), driven by best practices and with a strong emphasis on continuous improvement. At the time, mytaxi was experiencing major traffic growth. Some services ‚Äî for example, the one used to incentivize drivers to complete more rides ‚Äî experienced significant traffic spikes and required improvements, re-architecting, and similar work. On top of that, there were a bit over 200 services to manage.</li><li><strong>People management</strong> in a horizontal setup. The idea was that all backend engineers would report to either <a href="https://www.linkedin.com/in/ariel-cardieri-6971261/">Ariel</a>, the other Chapter Lead, or me, regardless of their team. This was not a very orthodox setup, but at the time, around 3‚Äì5 backend engineers were joining every month. There was a strong need to make people productive as quickly as possible, align on architecture, and keep the product moving.</li></ul><div><p>I came in with no prior formal experience as a Tech Lead. I think I never read as much in my life as during the month between announcing I was leaving my previous job and joining mytaxi. Not only that. I had never really had a proper Tech Lead to learn from. What could go wrong?</p><p>---</p></div><div><p>The first day was very entertaining. I log into Slack and introduce myself to the infrastructure and platform manager. He says:</p></div><blockquote>By the way, you have an incident in service X. Could you take a look?</blockquote><div><p>Just like that. It is nine in the morning on a Monday, and we already have an incident. I do not even know where the logs are, Henning. After the initial shock, I managed to find the responsible team. They identified the issue, fixed it, and everything got resolved.</p></div><p>This first interaction made several things very clear to me:</p><ul><li>Nobody really knows how to manage incidents, document what happened, or communicate progress. Great start.</li><li>There is no culture of doing incident reviews or extracting actions to prevent similar incidents in the future.</li><li>There is some coupling between domains. In this case, the Value Added Tax (VAT) concept was applied to two completely different use cases. A change in one of them caused the incident in the other.</li><li>Many people do not know how to debug. They look at me as if the logs were talking to me, or as if I were Harry Potter.</li></ul><div><p>The good part was that there was clearly a lot to fix. I had a pretty clear idea of how engineering culture could be improved. On top of that, I had the Tech Lead title. This was going to be easy. Or maybe not.</p><p>---</p></div><div><p>üëã Hi, Jo√£o here. This is the opening post of a series designed for Tech Leads and Engineering Managers who want to lead with greater clarity and intention.</p></div><ul><li>‚Äú<a href="https://world.hey.com/joaoqalves/traits-of-a-good-tech-lead-b5cac0ae">Traits of a good Tech Lead</a>‚Äù</li><li>‚ÄúI‚Äôm a Tech Lead, and nobody listens to me. What should I do?‚Äù ‚Üê This article</li><li>‚ÄúKPIs, SLOs, and operational excellence‚Äù. Coming soon. Subscribe so you do not miss it.</li><li>To be continued‚Ä¶</li></ul><div><p>I‚Äôm currently writing ‚ÄúThe Tech Lead Handbook‚Äù, scheduled for release in H1 2026. The ideas in this series will form its core.</p></div><h2>Trust</h2><div><p>After that incident, I created an incident review document and suggested a small review of the tasks that should be prioritized to prevent it from happening again. I got carried away and created an initial presentation for the other backend Chapter Leads with a backend strategy. I do not remember it perfectly, but it included hexagonal architecture, a testing pyramid with contract tests to avoid breaking APIs used by mobile apps, and more. Days go by, and I start thinking:</p></div><blockquote>Damn, nobody is listening to me. I put a lot of work into those slides and that strategy.</blockquote><div><p>Today, the reason seems obvious to me. Titles do not grant influence. To influence, you need to build trust. And I had not earned enough of it yet to propose something so fundamental. Through my own experience and through coaching sessions, I have seen this exact mistake repeated several times throughout my career.</p></div><p><em>The trust equation. Generated with Gemini 3 / NanoBanana.</em></p><div><p>The first time I read it, my mind was blown because it described exactly what was happening to me. Let‚Äôs break it down:</p></div><ul><li><strong>Credibility</strong>: knowing what you are talking about and having technical judgment. When you say something, people feel it is well-founded. In 2018, I might have had some of this credibility, but it had not yet been proven in that context, with those people, with those systems. I was coming from the outside. Imported credibility is always worth less ‚Äî unless you come from a FAANG or have built a strong personal brand ‚Äî than credibility earned on the ground.</li><li><strong>Reliability</strong>: doing what you say you will do. Being consistent and showing up when needed. In a high-paced environment like mytaxi, this matters a lot. In those first days, I was still learning where the logs lived. It is hard to demonstrate reliability if you do not even control the map.</li><li><strong>Intimacy</strong>: people feel they can talk to you, that you will not leave them exposed, and that you understand their fears and doubts. For a TL, this is more important than it seems. Without this, any technical proposal feels like a judgment. And when people get defensive, everything slows down.</li><li>And then there is the denominator: <strong>self-orientation</strong>. When your proposals seem to serve your own agenda more than the team‚Äôs needs, trust collapses. That was my mistake. I arrived with a strategy too early, without listening, without seeing what they actually needed, without having earned the moral right to propose it.</li></ul><p>In other words, even if my ideas were good, the equation still did not work out. I had some credibility, a bit of reliability still to build, intimacy yet to be created, and too much self-orientation. The result was obvious. Low trust.</p><p><strong><br>Two key moments<br></strong><br></p><p>Over time, I realized that trust is not built through big speeches, but through concrete actions that solve real, everyday problems. Looking back, two obvious moments accelerated the team‚Äôs shift in how they perceived me.</p><p><strong><br>Regulatory complexity<br></strong><br></p><div><p>Because mytaxi competed with Uber in a highly regulated taxi market, with very local regulations across Europe, the application needed to support multiple variants of the same flow. This led to the proliferation of dozens of configuration flags across all services. The result was chaos. Nobody knew for sure what was enabled in each city, what affected iOS, what affected Android, or where each option was actually defined. To make matters worse, the configuration was spread across roughly 200 services.</p></div><div><p>One day, <a href="https://www.linkedin.com/in/mariachec/">Maria</a> ‚Äî an Agile Coach ‚Äî talked to me very directly about this pain. I did what I knew best at the time. I built something. I put together a portal ‚Äî a bit rough, to be honest ‚Äî that queried the configuration APIs of all services and aggregated that information by functionality, country, or city. Features could be browsed by city or by name. The website was very simple, generated from an HTML template by a Python service.</p><figure>
      <a download="ff-tool-mytaxi-en.png" title="Download ff-tool-mytaxi-en.png" data-click-proxy-target="lightbox_link_blob_2381720738" href="https://world.hey.com/joaoqalves/e16e454d/blobs/eyJfcmFpbHMiOnsiZGF0YSI6MjM4MTcyMDczOCwicHVyIjoiYmxvYl9pZCJ9fQ--0761f5b0a191c12c02353aad23d02bd91dcf2d69af8cd01efea104da80e6abd5/ff-tool-mytaxi-en.png?disposition=attachment">
        <img src="https://world.hey.com/joaoqalves/e16e454d/representations/eyJfcmFpbHMiOnsiZGF0YSI6MjM4MTcyMDczOCwicHVyIjoiYmxvYl9pZCJ9fQ--0761f5b0a191c12c02353aad23d02bd91dcf2d69af8cd01efea104da80e6abd5/eyJfcmFpbHMiOnsiZGF0YSI6eyJmb3JtYXQiOiJwbmciLCJyZXNpemVfdG9fbGltaXQiOlszODQwLDI1NjBdLCJxdWFsaXR5Ijo2MCwibG9hZGVyIjp7InBhZ2UiOm51bGx9LCJjb2FsZXNjZSI6dHJ1ZX0sInB1ciI6InZhcmlhdGlvbiJ9fQ--7edc7b21f6fad97fa22412618822c4d19725431f296c7ce47dc174b61535d27c/ff-tool-mytaxi-en.png" alt="ff-tool-mytaxi-en.png" decoding="async" loading="lazy">
</a>
  </figure><p><em><br>The features could be queried by city or by name. The website was very simple, with HTML generated by a Python service.</em></p></div><div><p>Suddenly, at a glance, anyone could see what was enabled and where. It was not pretty, but it solved a problem. More importantly, it showed that <strong>I was there to help them work better</strong> (credibility), not to impose an abstract technical agenda. Soon after, other teams started using the portal, including Product Owners, QA, and even Operations. Without intending to, it became an organizational alignment tool. And it led to something even more interesting. Other engineers started contributing.</p></div><div><p>Once they saw the value it created, several colleagues proposed improvements, fixed minor bugs, and added features I had never even considered. One of them built a small website to visualize city zones, which solved a long-standing pain for teams working with geofencing or driver-passenger assignment. Another automated part of the flag update process. Someone else added metrics to detect inconsistent configurations across platforms.</p></div><div><p>What started as a quick hack turned into a small ecosystem of internal tools that reduced uncertainty, sped up decisions, and made the team‚Äôs life a little easier every week.</p></div><div><p>That domino effect taught me something important. When you solve a real problem and make it visible, people join in. Trust is also built that way, by inviting others to improve what you started and celebrating when they do it better than you.</p></div><p><strong><br>Debugging<br></strong><br></p><div><p>The second moment concerned something much more human. Helping people debug. I have never considered myself especially smart, but I have always been very systematic when connecting error messages, code, hypotheses, and system behavior. To my surprise, many people saw this as almost magical. It was not magic. It was a mix of experience, fundamentals, intuition, knowing where to look, and not being afraid to dive into third-party library code.</p></div><div><p>I started pairing with colleagues during incident resolution (intimacy), teaching them to formulate and discard hypotheses, read logs with intent, and distinguish symptoms from root causes. I proposed incident-review practices that improved the quality of our responses and helped us learn collectively.</p></div><p>Without realizing it, these two contributions did more for my reputation than any presentation or strategy deck. <strong>Building helpful things and standing by people when the system is on fire creates more trust than any title</strong>. That was when my ideas finally started gaining traction. Interestingly, these two actions reduced my self-orientation to zero. I stopped thinking about ‚Äúmy strategy‚Äù and started thinking about ‚Äúour work‚Äù.</p><h2>What would you tell your 2018 self?</h2><p>Looking back, one idea stands out. No, TLs don‚Äôt earn influence just because ‚Äúit is their role‚Äù. It is earned every day, not through speeches, but by solving painful problems and being present when people need real support.</p><p>If you are in a similar situation, here is some advice I wish I had received in 2018:</p><ul><li>Before proposing a strategy, first understand what actually hurts your team.</li><li>Pick one or two actions that deliver immediate value and execute them.</li><li>Talk less about architecture and more about how your proposal reduces toil, risk, or uncertainty.</li><li>Do not try to prove you are the smartest person in the room. Try to help others do their job better.</li><li>Feedback cycles, unlike code, are slower. They are measured in weeks or months. Be patient.</li><li>And above all, remember that trust is cumulative. It is earned in every interaction.</li></ul><div><p>Technical influence does not start with a title. It begins with the <strong>visible impact</strong> you create. Because when a TL feels unheard, the solution is not to speak louder.</p><p>It is to change the conversation. And to start from the only place you truly control: <strong>your own behavior</strong>.</p><p>---</p><p>üéÅ <strong>Want to put this into practice with your team tomorrow? Subscriber-only gift</strong></p></div><div><p>Many Tech Leads feel unheard because EMs, TLs, and the rest of the team operate with different expectations that no one has made explicit. That friction is not resolved with more meetings or more processes. It is determined with clarity. To help you close that gap, I have prepared a FREE alignment toolkit with three practical tools:</p></div><ul><li>For <strong>Tech Leads</strong>: a self-assessment traffic light to fight impostor syndrome and clearly understand where you are creating value and where you are burning out.</li><li>For <strong>Engineering Managers</strong>: an evaluation traffic light to give objective feedback based on behaviors, not gut feelings. Help your Tech Leads have a<strong> </strong>real impact.</li><li>For the <strong>team</strong>: an operational principles template to stop debating the same decisions every week and create shared criteria.</li></ul><div><p>In addition, to complement this article,<strong> I will include a concrete plan for your first 90 days as a Tech Lead</strong>: what to observe, what to prioritize, what to avoid, and how to build trust through small, visible steps. It is the plan I wish I had had during my first week at mytaxi.</p></div><div><p>If you have already downloaded the toolkit, you do not need to do anything. You already have the updated version and will automatically receive the 90-day plan.</p></div><div><p><span>If you are not yet subscribed, </span><strong>subscribe, </strong><a href="https://forms.gle/UBZtSnBMXTgqZYt46"><strong>complete this form</strong></a><strong>, and I‚Äôll send you the kit </strong><span>so you can move from intention to action.</span> It is FREE!</p></div>
</div>

    </article>
  </section>

  



      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A2UI: A Protocol for Agent-Driven Interfaces (135 pts)]]></title>
            <link>https://a2ui.org/</link>
            <guid>46286407</guid>
            <pubDate>Tue, 16 Dec 2025 09:16:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://a2ui.org/">https://a2ui.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46286407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              
                

  



  


              
              <article>
                
                  
  



  
  
    
      
    
    <a href="https://github.com/google/A2UI/raw/master/docs/index.md" title="View source of this page">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD033 -->
<div>
<!-- Logo for Light Mode (shows dark logo on light background) -->
<p><img src="https://a2ui.org/assets/A2UI_dark.svg" alt="A2UI Logo" width="120"></p>
<!-- Logo for Dark Mode (shows light logo on dark background) -->
<p><img src="https://a2ui.org/assets/A2UI_light.svg" alt="A2UI Logo" width="120"></p>

<p>
A2UI enables AI agents to generate rich, interactive user interfaces that render natively across web, mobile, and desktop‚Äîwithout executing arbitrary code.
</p>
</div>
<div>
<p>Ô∏èStatus: Early Stage Public Preview</p>
<p>A2UI is currently in <strong>v0.8 (Public Preview)</strong>. The specification and
implementations are functional but are still evolving. We are opening the project to
foster collaboration, gather feedback, and solicit contributions (e.g., on client renderers).
Expect changes.</p>
</div>
<h2 id="at-a-glance">At a Glance<a href="#at-a-glance" title="Permanent link">¬∂</a></h2>
<p>A2UI is currently <a href="https://a2ui.org/specification/v0.8-a2ui/">v0.8</a>,
Apache 2.0 licensed,
created by Google with contributions from CopilotKit and the open source community,
and is in active development <a href="https://github.com/google/A2UI">on GitHub</a>.</p>
<p>The problem A2UI solves is: <strong>how can AI agents safely send rich UIs across trust boundaries?</strong></p>
<p>Instead of text-only responses or risky code execution, A2UI lets agents send <strong>declarative component descriptions</strong> that clients render using their own native widgets. It's like having agents speak a universal UI language.</p>
<p>In this repo you will find
<a href="https://a2ui.org/specification/v0.8-a2ui/">A2UI specifications</a>
and implementations for
<a href="https://a2ui.org/renderers/">renderers</a> (eg: Angular, Flutter, etc.) on the client side,
and <a href="https://a2ui.org/transports.md">transports</a> (eg: A2A, etc.) which communicate A2UI messages between agents and clients.</p>
<div>
<ul>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m10 17-4-4 1.41-1.41L10 14.17l6.59-6.59L18 9m-6-8L3 5v6c0 5.55 3.84 10.74 9 12 5.16-1.26 9-6.45 9-12V5z"></path></svg></span> <strong>Secure by Design</strong></p>
<hr>
<p>Declarative data format, not executable code. Agents can only use pre-approved components from your catalog‚Äîno UI injection attacks.</p>
</li>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m13.13 22.19-1.63-3.83c1.57-.58 3.04-1.36 4.4-2.27zM5.64 12.5l-3.83-1.63 6.1-2.77C7 9.46 6.22 10.93 5.64 12.5M21.61 2.39S16.66.269 11 5.93c-2.19 2.19-3.5 4.6-4.35 6.71-.28.75-.09 1.57.46 2.13l2.13 2.12c.55.56 1.37.74 2.12.46A19.1 19.1 0 0 0 18.07 13c5.66-5.66 3.54-10.61 3.54-10.61m-7.07 7.07c-.78-.78-.78-2.05 0-2.83s2.05-.78 2.83 0c.77.78.78 2.05 0 2.83s-2.05.78-2.83 0m-5.66 7.07-1.41-1.41zM6.24 22l3.64-3.64c-.34-.09-.67-.24-.97-.45L4.83 22zM2 22h1.41l4.77-4.76-1.42-1.41L2 20.59zm0-2.83 4.09-4.08c-.21-.3-.36-.62-.45-.97L2 17.76z"></path></svg></span> <strong>LLM-Friendly</strong></p>
<hr>
<p>Flat, streaming JSON structure designed for easy generation. LLMs can build UIs incrementally without perfect JSON in one shot.</p>
</li>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18V4H3c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h4v-2H3zm10 6H9v1.78c-.61.55-1 1.33-1 2.22s.39 1.67 1 2.22V20h4v-1.78c.61-.55 1-1.34 1-2.22s-.39-1.67-1-2.22zm-2 5.5c-.83 0-1.5-.67-1.5-1.5s.67-1.5 1.5-1.5 1.5.67 1.5 1.5-.67 1.5-1.5 1.5M22 8h-6c-.5 0-1 .5-1 1v10c0 .5.5 1 1 1h6c.5 0 1-.5 1-1V9c0-.5-.5-1-1-1m-1 10h-4v-8h4z"></path></svg></span> <strong>Framework-Agnostic</strong></p>
<hr>
<p>One agent response works everywhere. Render the same UI on Angular, Flutter, React, or native mobile with your own styled components.</p>
</li>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M2 2h2v18h18v2H2zm5 8h10v3H7zm4 5h10v3H11zM6 4h16v4h-2V6H8v2H6z"></path></svg></span> <strong>Progressive Rendering</strong></p>
<hr>
<p>Stream UI updates as they're generated. Users see the interface building in real-time instead of waiting for complete responses.</p>
</li>
</ul>
</div>
<h2 id="get-started-in-5-minutes">Get Started in 5 Minutes<a href="#get-started-in-5-minutes" title="Permanent link">¬∂</a></h2>
<div>
<ul>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M15 4a8 8 0 0 1 8 8 8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8m0 2a6 6 0 0 0-6 6 6 6 0 0 0 6 6 6 6 0 0 0 6-6 6 6 0 0 0-6-6m-1 2h1.5v3.78l2.33 2.33-1.06 1.06L14 12.4zM2 18a1 1 0 0 1-1-1 1 1 0 0 1 1-1h3.83c.31.71.71 1.38 1.17 2zm1-5a1 1 0 0 1-1-1 1 1 0 0 1 1-1h2.05L5 12l.05 1zm1-5a1 1 0 0 1-1-1 1 1 0 0 1 1-1h3c-.46.62-.86 1.29-1.17 2z"></path></svg></span> <strong><a href="https://a2ui.org/quickstart/">Quickstart Guide</a></strong></p>
<hr>
<p>Run the restaurant finder demo and see A2UI in action with Gemini-powered agents.</p>
<p><a href="https://a2ui.org/quickstart/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0"></path></svg></span> Get started</a></p>
</li>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 21.5c-1.35-.85-3.8-1.5-5.5-1.5-1.65 0-3.35.3-4.75 1.05-.1.05-.15.05-.25.05-.25 0-.5-.25-.5-.5V6c.6-.45 1.25-.75 2-1 1.11-.35 2.33-.5 3.5-.5 1.95 0 4.05.4 5.5 1.5 1.45-1.1 3.55-1.5 5.5-1.5 1.17 0 2.39.15 3.5.5.75.25 1.4.55 2 1v14.6c0 .25-.25.5-.5.5-.1 0-.15 0-.25-.05-1.4-.75-3.1-1.05-4.75-1.05-1.7 0-4.15.65-5.5 1.5M12 8v11.5c1.35-.85 3.8-1.5 5.5-1.5 1.2 0 2.4.15 3.5.5V7c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5m1 3.5c1.11-.68 2.6-1 4.5-1 .91 0 1.76.09 2.5.28V9.23c-.87-.15-1.71-.23-2.5-.23q-2.655 0-4.5.84zm4.5.17c-1.71 0-3.21.26-4.5.79v1.69c1.11-.65 2.6-.99 4.5-.99 1.04 0 1.88.08 2.5.24v-1.5c-.87-.16-1.71-.23-2.5-.23m2.5 2.9c-.87-.16-1.71-.24-2.5-.24-1.83 0-3.33.27-4.5.8v1.69c1.11-.66 2.6-.99 4.5-.99 1.04 0 1.88.08 2.5.24z"></path></svg></span> <strong><a href="https://a2ui.org/concepts/overview/">Core Concepts</a></strong></p>
<hr>
<p>Understand surfaces, components, data binding, and the adjacency list model.</p>
<p><a href="https://a2ui.org/concepts/overview/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0"></path></svg></span> Learn concepts</a></p>
</li>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8 3a2 2 0 0 0-2 2v4a2 2 0 0 1-2 2H3v2h1a2 2 0 0 1 2 2v4a2 2 0 0 0 2 2h2v-2H8v-5a2 2 0 0 0-2-2 2 2 0 0 0 2-2V5h2V3m6 0a2 2 0 0 1 2 2v4a2 2 0 0 0 2 2h1v2h-1a2 2 0 0 0-2 2v4a2 2 0 0 1-2 2h-2v-2h2v-5a2 2 0 0 1 2-2 2 2 0 0 1-2-2V5h-2V3z"></path></svg></span> <strong><a href="https://a2ui.org/guides/client-setup/">Developer Guides</a></strong></p>
<hr>
<p>Integrate A2UI renderers into your app or build agents that generate UIs.</p>
<p><a href="https://a2ui.org/guides/client-setup/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0"></path></svg></span> Start building</a></p>
</li>
<li>
<p><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 9h5.5L13 3.5zM6 2h8l6 6v12a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4c0-1.11.89-2 2-2m9 16v-2H6v2zm3-4v-2H6v2z"></path></svg></span> <strong><a href="https://a2ui.org/specification/v0.8-a2ui/">Protocol Reference</a></strong></p>
<hr>
<p>Dive into the complete technical specification and message types.</p>
<p><a href="https://a2ui.org/specification/v0.8-a2ui/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0"></path></svg></span> Read the spec</a></p>
</li>
</ul>
</div>
<h2 id="how-it-works">How It Works<a href="#how-it-works" title="Permanent link">¬∂</a></h2>
<ol>
<li><strong>User sends a message</strong> to an AI agent</li>
<li><strong>Agent generates A2UI messages</strong> describing the UI (structure + data)</li>
<li><strong>Messages stream</strong> to the client application</li>
<li><strong>Client renders</strong> using native components (Angular, Flutter, React, etc.)</li>
<li><strong>User interacts</strong> with the UI, sending actions back to the agent</li>
<li><strong>Agent responds</strong> with updated A2UI messages</li>
</ol>
<p><img alt="End-to-End Data Flow" src="https://a2ui.org/assets/end-to-end-data-flow.png"></p>
<h2 id="a2ui-in-action">A2UI in Action<a href="#a2ui-in-action" title="Permanent link">¬∂</a></h2>
<h3 id="landscape-architect-demo">Landscape Architect Demo<a href="#landscape-architect-demo" title="Permanent link">¬∂</a></h3>
<div>
  <p>
    <video width="100%" height="auto" controls="" playsinline="">
      <source src="https://a2ui.org/assets/landscape-architect-demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </p>
  <p>
    Watch an agent generate all of the interfaces for a landscape architect application. The user uploads a photo; the agent uses Gemini to understand it and generate a custom form for landscaping needs.
  </p>
</div>

<h3 id="custom-components-interactive-charts-maps">Custom Components: Interactive Charts &amp; Maps<a href="#custom-components-interactive-charts-maps" title="Permanent link">¬∂</a></h3>
<div>
  <p>
    <video width="100%" height="auto" controls="" playsinline="">
      <source src="https://a2ui.org/assets/a2ui-custom-compnent.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </p>
  <p>
    Watch an agent chose to respond with a chart component to answer a numberical summary quesiton.  Then the agent chooses a Google Map component to answer a location question.  Both are custom components offered by the client.
  </p>
</div>

<h3 id="a2ui-composer">A2UI Composer<a href="#a2ui-composer" title="Permanent link">¬∂</a></h3>
<p>CopilotKit has a public <a href="https://go.copilotkit.ai/A2UI-widget-builder">A2UI Widget Builder</a> to try out as well.</p>
<p><a href="https://go.copilotkit.ai/A2UI-widget-builder"><img alt="A2UI Composer" src="https://a2ui.org/assets/A2UI-widget-builder.png"></a></p>







  
  



  


  



                
              </article>
            </div>
        
          
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VS Code deactivates IntelliCode in favor of the paid Copilot (199 pts)]]></title>
            <link>https://www.heise.de/en/news/VS-Code-deactivates-IntelliCode-in-favor-of-the-paid-Copilot-11115783.html</link>
            <guid>46286383</guid>
            <pubDate>Tue, 16 Dec 2025 09:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/VS-Code-deactivates-IntelliCode-in-favor-of-the-paid-Copilot-11115783.html">https://www.heise.de/en/news/VS-Code-deactivates-IntelliCode-in-favor-of-the-paid-Copilot-11115783.html</a>, See on <a href="https://news.ycombinator.com/item?id=46286383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        <p>With the release of VS Code 1.107, it became known that Microsoft has deactivated the popular IntelliCode extension, which had over 60 million downloads: The extension is now deprecated and the gray inline suggestions no longer work.</p>
<!-- RSPEAK_STOP -->




  


<!-- RSPEAK_START -->

<p><a href="https://github.com/microsoft/vscode-dotnettools/issues/2537" rel="external noopener" target="_blank">Microsoft refers in the well-hidden announcement</a> from mid-November to the AI extension of Copilot in VS Code, which, however, only offers a free volume of 2,000 suggestions ‚Äì a limit that developers quickly reach, as Copilot makes a suggestion with every input. From then on, users will need a paid license. The use of IntelliCode required a local model, but was therefore unlimited and free.</p>
<p>The classic IntelliSense with language server for the used language is still free ‚Äì but without AI support. The following extensions are affected by the shutdown:</p>
<ul><li>IntelliCode</li><li>IntelliCode Completions</li><li>IntelliCode for C# Dev Kit</li><li>IntelliCode API Usage Examples</li></ul>
<!-- RSPEAK_STOP -->

  




<!-- RSPEAK_START -->

<h3 id="nav_typescript_7__0"><strong>TypeScript 7 and more agents for VS Code</strong></h3>
<p>Nothing about IntelliCode can be found in the announcement for VS Code 1.107. However, new is the experimental support <a href="https://github.com/microsoft/typescript-go" rel="external noopener" target="_blank">for TypeScript 7 with the new compiler written in Go</a>. This can be updated with:</p>
<p><code>npm install @typescript/native-preview</code></p>
<!-- RSPEAK_STOP -->


  



  




<!-- RSPEAK_START -->

<p>It is called with</p>
<p><code>npx tsgo</code></p>
<p>instead of <code>tsc</code>. Configuration in VS Code is done with</p>
<p><code>{ "typescript.experimental.useTsgo": true }</code></p>
<p>Further innovations in the editor concern agents, which can now be controlled via the chat. They continue to run even if the user has closed the chat. Developers can also move agents to other environments, enrich them with context, or classify them as sub-agents. <a href="https://code.visualstudio.com/updates/v1_107#_agents" rel="external noopener" target="_blank">The blog speaks militarily</a> of an Agent Head Quarter (HQ).</p>
<!-- RSPEAK_STOP -->
<div data-component="RecommendationBox"><header><h3>Read also</h3></header><a-collapse sneak-peek-elements="3" sneak-peek-elements-selector="article"></a-collapse></div>
<!-- RSPEAK_START -->

<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:who@heise.de" title="Wolf Hosbach">who</a>)</span>
<!-- RSPEAK_START -->
</p>
<div>
    <p>
      Don't miss any news ‚Äì follow us on
      <a href="https://www.facebook.com/heiseonlineEnglish">Facebook</a>,
      <a href="https://www.linkedin.com/company/104691972">LinkedIn</a> or
      <a href="https://social.heise.de/@heiseonlineenglish">Mastodon</a>.
    </p>
    <p>
      <em>This article was originally published in
      
        <a href="https://www.heise.de/news/VS-Code-deaktiviert-IntelliCode-zugunsten-des-kostenpflichtigen-Copilot-11115668.html">German</a>.
      
      It was translated with technical assistance and editorially reviewed before publication.</em>
    </p>
  </div>



        

        
        <!-- RSPEAK_STOP -->
        

<a-gift has-access="">
    
</a-gift>


        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A linear-time alternative for Dimensionality Reduction and fast visualisation (105 pts)]]></title>
            <link>https://medium.com/@roman.f/a-linear-time-alternative-to-t-sne-for-dimensionality-reduction-and-fast-visualisation-5cd1a7219d6f</link>
            <guid>46285535</guid>
            <pubDate>Tue, 16 Dec 2025 06:47:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@roman.f/a-linear-time-alternative-to-t-sne-for-dimensionality-reduction-and-fast-visualisation-5cd1a7219d6f">https://medium.com/@roman.f/a-linear-time-alternative-to-t-sne-for-dimensionality-reduction-and-fast-visualisation-5cd1a7219d6f</a>, See on <a href="https://news.ycombinator.com/item?id=46285535">Hacker News</a></p>
Couldn't get https://medium.com/@roman.f/a-linear-time-alternative-to-t-sne-for-dimensionality-reduction-and-fast-visualisation-5cd1a7219d6f: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Children with cancer scammed out of millions fundraised for their treatment (501 pts)]]></title>
            <link>https://www.bbc.com/news/articles/ckgz318y8elo</link>
            <guid>46285376</guid>
            <pubDate>Tue, 16 Dec 2025 06:17:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/ckgz318y8elo">https://www.bbc.com/news/articles/ckgz318y8elo</a>, See on <a href="https://news.ycombinator.com/item?id=46285376">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline" data-component="byline-block"><p><span data-testid="byline-contributors"><p><span>Simi Jolaoso<!-- -->,</span></p><p><span>Jack Goodman</span><span>and</span></p><p><span>Sarah Buckley<!-- -->,</span><span data-testid="byline-contributors-contributor-2-role-location">BBC Eye Investigations</span></p></span></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/d92e/live/e946f5f0-d4e0-11f0-a892-01d657345866.jpg.webp" loading="eager" alt="Chance Letikva Khalil, a little Filipino boy, is wearing a green and blue striped t-shirt, has a shaved head, and has a small microphone clipped to his top. There is a white hospital background. He faces the camera, mid-speech."><span>Chance Letikva</span></p></div></figure><p><i id="warning:-disturbing-content"><b id="warning:-disturbing-content">Warning: Disturbing content</b></i></p><div data-component="text-block"><p>A little boy faces the camera. He is pale and has no hair.</p><p>"I am seven years old and I have cancer," he says. "Please save my life and help me."</p><p>Khalil - who is pictured above in a still from the film - didn't want to record this, says his mother Aljin. She had been asked to shave his head, and then a film crew hooked him up to a fake drip, and asked his family to pretend it was his birthday. They had given him a script to learn and recite in English.</p><p>And he didn't like it, says Aljin, when chopped onions were placed next to him, and menthol put under his eyes, to make him cry.</p><p>Aljin agreed to it because, although the set-up was fake, Khalil really did have cancer. She was told this video would help crowdfund money for better treatment. And it did raise funds - $27,000 (¬£20,204), according to a campaign we found in Khalil's name.</p><p>But Aljin was told the campaign had failed, and says she received none of this money - just a $700 (¬£524) filming fee on the day. One year later, Khalil died.</p><p>Across the world, desperate parents of sick or dying children are being exploited by online scam campaigns, the BBC World Service has discovered. The public have given money to the campaigns, which claim to be fundraising for life-saving treatment. We have identified 15 families who say they got little to nothing of the funds raised and often had no idea the campaigns had even been published, despite undergoing harrowing filming.</p><p>Nine families we spoke to - whose campaigns appear to be products of the same scam network - say they never received anything at all of the $4m (¬£2.9m) apparently raised in their names.</p><p>A whistleblower from this network told us they had looked for "beautiful children" who "had to be three to nine years old‚Ä¶ without hair".</p><p>We have identified a key player in the scam as an Israeli man living in Canada called Erez Hadari. </p></div><p data-component="caption-block"><figcaption>Watch how three children, including Ana from Colombia, appeared in campaign videos</figcaption></p><div data-component="text-block"><p>Our investigation began in October 2023, when a distressing YouTube advert caught our attention. "I don't want to die," a girl called Alexandra from Ghana sobbed. "My treatments cost a lot."</p><p>A crowdfunding campaign for her appeared to have raised nearly $700,000 (¬£523,797).</p><p>We saw more videos of sick children from around the world on YouTube, all strikingly similar - slickly produced, and seemingly having raised huge amounts of money. They all conveyed a sense of urgency, using emotive language.</p><p>We decided to investigate further.</p><p>The campaigns with the biggest apparent international reach were under the name of an organisation called Chance Letikva (Chance for Hope, in English) - registered in Israel and the US.</p><p>Identifying the children featured was difficult. We used geolocation, social media and facial recognition software to find their families, based as far apart as Colombia and the Philippines.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/56fb/live/707275a0-d4f9-11f0-8c06-f5d460985095.jpg.webp" loading="lazy" alt="Chance Letikva A fundraising campaign page for Ana - it shows her crying, wearing a nasal tube, and the caption at the top of the page reads &quot;Two months to live&quot; with a heart emoji "><span>Chance Letikva</span></p></div><p data-component="caption-block"><figcaption>A Chance Letikva campaign for Ana in Colombia - falsely claiming she had two months to live </figcaption></p></figure><div data-component="text-block"><p>While it was difficult to know for sure if the campaign websites' cash totals were genuine, we donated small amounts to two of them and saw the totals increase by those amounts.</p><p>We also spoke to someone who says she gave $180 (¬£135) to Alexandra's campaign and was then inundated with requests for more, all written as if sent by Alexandra and her father.</p><p>In the Philippines, Aljin Tabasa told us her son Khalil had fallen ill just after his seventh birthday.</p><p>"When we found out it was cancer it felt like my whole world shattered," she says.</p><p>Aljin says treatment at their local hospital in the city of Cebu was slow, and she had messaged everyone she could think of for help. One person put her in touch with a local businessman called Rhoie Yncierto - who asked for a video of Khalil which, looking back, Aljin realises was essentially an audition. </p><p>Another man then arrived from Canada in December 2022, introducing himself as "Erez". He paid her the filming fee up front, she says, promising a further $1,500 (¬£1,122) a month if the film generated lots of donations.</p><p>Erez directed Khalil's film at a local hospital, asking for retake after retake - the shoot taking 12 hours, Aljin says.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/05a1/live/b8bb88f0-d4e6-11f0-8c06-f5d460985095.jpg.webp" loading="lazy" alt="A graphic explaining how the campaign video for Khalil was staged shows: 1) His mother and sister clapping as ticker tape rains down with balloons in the background, 2) Khalil crying, 3) Khalil reciting lines from a script, wearing a nasal tube."></p></div></figure><div data-component="text-block"><p>Months later, the family say they had still not heard how the video had performed. Aljin messaged Erez, who told her the video "wasn't successful".</p><p>"So as I understood it, the video just didn't make any money," she says.</p><p>But we told her the campaign had apparently collected $27,000 (¬£20,204) as of November 2024, and was still online.</p><p>"If I had known the money we had raised, I can't help but think that maybe Khalil would still be here," Aljin says. "I don't understand how they could do this to us."</p><p>When asked about his role in the filming, Rhoie Yncierto denied telling families to shave their children's heads for filming and said he had received no payment for recruiting families.</p><p>He said he had "no control" over what happened with the funds and had no contact with the families after the day of filming. When we told him they had not received any of the campaigns' donations he said he was "puzzled" and was "very sorry for the families".</p><p>Nobody named Erez appears on registration documents for Chance Letikva. But two of its campaigns we investigated had also been promoted by another organisation called Walls of Hope, registered in Israel and Canada. Documents list the director in Canada as Erez Hadari.</p><p>Photos of him online show him at Jewish religious events in the Philippines, New York and Miami. We showed Aljin, and she said it was the same person she had met.</p></div><div data-component="text-block"><ul><li><i id="outside-the-uk,-watch-the-film-on"><b id="outside-the-uk,-watch-the-film-on">Outside the UK, watch the film on </b></i><a target="_blank" href="https://youtu.be/EGj89n7SxOo"><i id="bbc-world-service-youtube"><b id="bbc-world-service-youtube">BBC World Service YouTube</b></i></a></li></ul></div><div data-component="text-block"><p>We asked Mr Hadari about his involvement in a campaign in the Philippines. He did not respond.</p><p>We visited further families whose campaigns were either organised by, or linked to, Mr Hadari - one in a remote indigenous community in Colombia, and another in Ukraine.</p><p>As with Khalil's case, local fixers had got in touch to offer help. The children were filmed and made to cry or fake tears for a nominal fee, but never received any further money.</p><p>In Sucre, north-west Colombia, Sergio Care says he initially refused this help. He had been approached by someone called Isabel, he says, who offered financial assistance after his eight-year-old daughter, Ana, was diagnosed with a malignant brain tumour.</p><p>But Isabel came looking for him at the hospital treating Ana, he says, accompanied by a man who said he worked for an international NGO.</p><p>The description Sergio gave of the man matched that of Erez Hadari - he then recognised him in a photo we showed him.</p><p>"He gave me hope... I didn't have any money for the future."</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/44c1/live/e6eca8e0-d4f9-11f0-8c06-f5d460985095.png.webp" loading="lazy" alt="An excerpt from a script given to Ana to learn - it shows stage directions, directing her and her dad on what to wear and how to behave, including tears from Ana. Her dad is given lines telling her that she will get better."></p></div></figure><div data-component="text-block"><p>Demands on the family did not end with the filming.</p><p>Isabel kept ringing, Sergio says, demanding more photos of Ana in hospital. When Sergio didn't reply, Isabel started messaging Ana herself - voice notes we have heard.</p><p>Ana told Isabel she had no more photos to send. Isabel replied: "This is very bad Ana, very bad indeed."</p><p>In January this year, Ana - now fully recovered - tried to find out what happened to the money promised.</p><p>"That foundation disappeared," Isabel told her in a voice note. "Your video was never uploaded. Never. Nothing was done with it, you hear?"</p><p>But we could see the video had been uploaded and, by April 2024, appeared to have raised nearly $250,000 (¬£187,070).</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/1e77/live/307c0060-d4fe-11f0-8c06-f5d460985095.jpg.webp" loading="lazy" alt="Ana's dad is smiling as he and Ana ride a donkey/horse - white with a straw saddle. Ana is wearing navy joggers and a black Adidas t-shirt, and her dad is wearing a dark shirt and yellow trousers   "></p></div><p data-component="caption-block"><figcaption>Ana and her dad live in a remote indigenous community in Colombia </figcaption></p></figure><div data-component="text-block"><p>In October, we persuaded Isabel Hernandez to speak to us over video link.</p><p>A friend from Israel, she explained, had introduced her to someone offering work for "a foundation" looking to help children with cancer. She refused to name who she worked for.</p><p>She was told only one of the campaigns she helped organise was published, she says, and that it had not been successful.</p><p>We showed Isabel that two campaigns had in fact been uploaded - one of them apparently raising more than $700,000 (¬£523,797).</p><p>"I need to apologise to [the families]," she said. "If I'd known what was going on, I would not have been able to do something like this."</p><p>In Ukraine, we discovered that the person who approached the mother of a sick child was actually employed in the place where the campaign video was filmed.</p><p>Tetiana Khaliavka organised a shoot with five-year-old Viktoriia, who has brain cancer, at Angelholm Clinic in Chernivtsi.</p><p>One Facebook post linked to Chance Letikva's campaign shows Viktoriia and her mother Olena Firsova, sitting on a bed. "I see your efforts to save my daughter, and it deeply moves us all. It's a race against time to raise the amount needed for Viktoriia's treatments," reads the caption.</p><p>Olena says she never wrote or even said these words and had no idea the campaign had been uploaded.</p><p>It appears to have raised more than ‚Ç¨280,000 (¬£244,000).</p><p>Tetiana, we were told, was in charge of advertising and communications at Angelholm.</p><p>The clinic recently told the BBC it didn't approve filming on its premises - adding: "The clinic has never participated in, nor supported, any fundraising initiatives organised by any organisation."</p><p>Angelholm says it has terminated Tetiana Khaliavka's employment.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/6bc4/live/9f537080-d4ff-11f0-9fb5-5f3a3703a365.jpg.webp" loading="lazy" alt="Olena has dyed red hair, tied back, and is wearing a grey top. She is cuddling Viktoriia, who is wearing a turquoise coat and has closely cropped hair. They are outside, with a housing block behind them."></p></div><p data-component="caption-block"><figcaption>Olena with her daughter Viktoriia, who has recently been diagnosed with another brain tumour</figcaption></p></figure><div data-component="text-block"><p>Olena showed us the contract she had been asked to sign.</p><p>In addition to the family's $1,500 (¬£1,122) filming fee on the day, it states they would get $8,000 (¬£5,986) once the fundraising goal was met. The amount for the goal, however, has been left blank.</p><p>The contract showed an address in New York for Chance Letikva. On the organisation's website, there is another - in Beit Shemesh, about an hour from Jerusalem. We travelled to both, but found no sign of it.</p><p>And we discovered Chance Letikva seems to be one of many such organisations.</p><p>The man who filmed Viktoriia's campaign told our producer - who was posing as a friend of a sick child - that he works for other similar organisations.</p><p>"Each time, it's a different one," the man - who had introduced himself as "Oleh" - told her. "I hate to put it this way, but they work kind of like a conveyor belt."</p><p>"About a dozen similar companies" requested "material", he said, naming two of them - Saint Teresa and Little Angels, both registered in the US.</p><p>When we checked their registration documents, we once again found Erez Hadari's name.</p><p>What is not clear is where the money raised for the children has gone.</p><p>More than a year after Viktoriia's filming, her mother Olena rang Oleh, who seems to go by Alex Kohen online, to find out. Shortly afterwards, someone from Chance Letikva called to say the donations had paid for advertising, she says.</p><p>This is also what Mr Hadari told Aljin, Khalil's mother, when she confronted him over the phone.</p><p>"There is cost of advertising. So the company lost money," Mr Hadari told her, without giving any evidence to support this.</p><p>Charity experts told us advertising should not amount to more than 20% of the total raised by campaigns.</p><p>Someone previously employed to recruit children for Chance Letikva campaigns told us how those featured had been chosen.</p><p>They had been asked to visit oncology clinics, they said - speaking on condition of anonymity.</p><p>"They were always looking for beautiful children with white skin. The child had to be three to nine years old. They had to know how to speak well. They had to be without hair," they told us.</p><p>"They asked me for photos, to see if the child is right, and I would send it to Erez."</p><p>The whistleblower told us Mr Hadari would then send the photo on to someone else, in Israel, whose name they were never told.</p><p>As for Mr Hadari himself, we tried to reach him at two addresses in Canada but could not find him. He replied to one voice note we had sent him - asking about the money he had been apparently crowdfunding - by saying the organisation "has never been active", without specifying which one. He did not respond to a further voice note and letter laying out all our questions and allegations.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/b676/live/3589b330-d51d-11f0-9fb5-5f3a3703a365.jpg.webp" loading="lazy" alt="Erez Hadari Erez Hadari is shown sitting in a plane - in what looks like first or business class - with a blue top and grey trousers, and is smiling, holding headphones"><span>Erez Hadari</span></p></div><p data-component="caption-block"><figcaption>Erez Hadari sent this photo of himself to Khalil's mum, Aljin </figcaption></p></figure><div data-component="text-block"><p>Campaigns set up by Chance Letikva for two children who died - Khalil and a Mexican boy called Hector - still appear to be accepting money.</p><p>Chance Letikva's US branch appears to be linked to a new organisation called Saint Raphael, which has produced more campaigns - at least two of which seem to have been filmed in Angelholm clinic in Ukraine, as the clinic's distinctive wood panelling and staff uniforms can be seen.</p><p>Olena, Viktoriia's mother, says her daughter has been diagnosed with another brain tumour. She says she is sickened by the findings of our investigation.</p><p>"When your child is‚Ä¶ hanging on the edge of life, and someone's out there, making money off that. Well, it's filthy. It's blood money."</p><p>The BBC contacted Tetiana Khaliavka and Alex Kohen, and the organisations Chance Letikva, Walls of Hope, Saint Raphael, Little Angels and Saint Teresa - inviting them to respond to the allegations made against them. None of them replied.</p><p>The Israeli Corporations Authority, which oversees the country's non-profit organisations, told us that if it has evidence founders are using entities as "a cover for illegal activity", then registration inside Israel may be denied and the founder could be barred from working in the sector.</p><p>UK regulator, the Charity Commission, advises those wishing to donate to charities to check that those associations are registered, and that the appropriate fundraising regulator should be contacted if in doubt.</p><p><i id="additional-reporting-by:-ned-davies,-tracks-saflor,-jose-antonio-lucio,-almudena-garcia-parrado,-vitaliya-kozmenko,-shakked-auerbach,-tom-tzur-wisfelder,-katya-malofieieva,-anastasia-kucher,-alan-pulido-and-neil-mccarthy"><b id="additional-reporting-by:-ned-davies,-tracks-saflor,-jose-antonio-lucio,-almudena-garcia-parrado,-vitaliya-kozmenko,-shakked-auerbach,-tom-tzur-wisfelder,-katya-malofieieva,-anastasia-kucher,-alan-pulido-and-neil-mccarthy">Additional reporting by: Ned Davies, Tracks Saflor, Jose Antonio Lucio, Almudena Garcia-parrado, Vitaliya Kozmenko, Shakked Auerbach, Tom Tzur Wisfelder, Katya Malofieieva, Anastasia Kucher, Alan Pulido and Neil McCarthy</b></i></p><ul><li><i id="if-you-have-any-information-to-add-to-this-investigation-please-contact"><b id="if-you-have-any-information-to-add-to-this-investigation-please-contact">If you have any information to add to this investigation please contact </b></i><a target="_self" href="mailto:simi@bbc.co.uk"><i id="simi@bbc.co.uk"><b id="simi@bbc.co.uk">simi@bbc.co.uk</b></i></a></li></ul></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bonsai: A Voxel Engine, from scratch (198 pts)]]></title>
            <link>https://github.com/scallyw4g/bonsai</link>
            <guid>46285319</guid>
            <pubDate>Tue, 16 Dec 2025 06:06:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/scallyw4g/bonsai">https://github.com/scallyw4g/bonsai</a>, See on <a href="https://news.ycombinator.com/item?id=46285319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/logo_256.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/logo_256.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Welcome to Bonsai!</h2><a id="user-content-welcome-to-bonsai" aria-label="Permalink: Welcome to Bonsai!" href="#welcome-to-bonsai"></a></p>
<p dir="auto">Bonsai is a voxel engine in a pot.  It's been tended to with love and
care over the years.  It started out as a learning excercise, and has taught me
the value of simplicity.</p>
<p dir="auto">Bonsai supports massive worlds.  The current version supports a maximum world
size of ~1 billion blocks, cubed.  At one block per meter, that's the distance
from earth to the moon, 2600 times, in every direction.  The view distance is
the entire world, all the time.  Yes, you read that right.  In Bonsai, you can
see in a straight line from Jupiter to the sun.</p>
<p dir="auto">Bonsai terrain generation is fully procedural, and user configurable.  Terrain
is generated on the GPU using regular glsl shaders.  Anything you can do in a
shader, you can do in a Bonsai terrain generator.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2.0.0-prealpha Note</h3><a id="user-content-200-prealpha-note" aria-label="Permalink: 2.0.0-prealpha Note" href="#200-prealpha-note"></a></p>
<p dir="auto">The current version is 2.0.0-prealpha-rc0, which can be found by joining the
<a href="https://discord.gg/kmRpgXBh75" rel="nofollow">Discord</a>.  This version is a large rewrite of
several core systems, including the world generation, editor and parts of the
renderer.</p>
<p dir="auto">In its current state, the engine is effectively a terrain generator and editor.
For details on remaing work, see <a href="https://github.com/scallyw4g/bonsai/issues/82" data-hovercard-type="issue" data-hovercard-url="/scallyw4g/bonsai/issues/82/hovercard">Roadmap to v2.0.0</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/two_doors.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/two_doors.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Bonsai, and nearly all it's dependencies, are written completely from scratch.
One external dependency is the C runtime library for program startup. There is
a back-burner task to remove the CRT entirely, athough it's unclear when/if
anyone will ever get around to it.</p>
<p dir="auto">The only external requirements to build Bonsai are clang++ (&gt;= version 18.1)
and a few appropriate system headers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">Grab pre-built binaries &amp; assets from the <a href="https://github.com/scallyw4g/bonsai/releases/latest">Latest Releases</a>
for your platform of your choice (as long as your platform of choice is Windows or Linux) ;)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/scallyw4g/bonsai/blob/master/docs/00_getting_started.md">Getting Started</a></h3><a id="user-content-getting-started-1" aria-label="Permalink: Getting Started" href="#getting-started-1"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/scallyw4g/bonsai/blob/master/docs/01_build_process.md">Build From Source</a></h3><a id="user-content-build-from-source" aria-label="Permalink: Build From Source" href="#build-from-source"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/scallyw4g/bonsai/blob/master/docs/controls.md">Controls</a></h3><a id="user-content-controls" aria-label="Permalink: Controls" href="#controls"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://discord.gg/kmRpgXBh75" rel="nofollow">Discord Server</a></h3><a id="user-content-discord-server" aria-label="Permalink: Discord Server" href="#discord-server"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/orks.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/orks.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feature Sets</h2><a id="user-content-feature-sets" aria-label="Permalink: Feature Sets" href="#feature-sets"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Renderer</h2><a id="user-content-renderer" aria-label="Permalink: Renderer" href="#renderer"></a></p>
<ul dir="auto">
<li>Deferred Shading</li>
<li>HDR Lighting</li>
<li>Order-independant Transparency</li>
<li>Lighting Bloom</li>
<li>Shadow Mapping</li>
<li>Screen Space Ambient Occlusion</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/abandoned_workshop.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/abandoned_workshop.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Engine</h2><a id="user-content-engine" aria-label="Permalink: Engine" href="#engine"></a></p>
<ul dir="auto">
<li>Hot Shader &amp; Game-code Reloading</li>
<li>Async Job System</li>
<li>Entities</li>
<li>Collision</li>
<li>Transparent &amp; Emissive Particles</li>
<li>UI Framework</li>
<li>Asset Loaders</li>
<li>Primitive Physics</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/mountain.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/mountain.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Terrain Generation</h2><a id="user-content-terrain-generation" aria-label="Permalink: Terrain Generation" href="#terrain-generation"></a></p>
<ul dir="auto">
<li>Fully programmable GPU-based terrain generation</li>
<li>Batteries-included library of pre-built terrain shaders</li>
<li>1D, 2D and 3D noise library</li>
<li>Terrain derivitives available in second-stage terrain "decoration"</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/keyhole.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/keyhole.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Editing</h2><a id="user-content-editing" aria-label="Permalink: Editing" href="#editing"></a></p>
<ul dir="auto">
<li>CSG-like SDF world editing</li>
<li>Library of primitive shapes (rect, sphere, line, cylinder .. etc)</li>
<li>SDF brush-based texturing of primitives</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/ork_aerial.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/ork_aerial.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">SDF Brushes</h2><a id="user-content-sdf-brushes" aria-label="Permalink: SDF Brushes" href="#sdf-brushes"></a></p>
<ul dir="auto">
<li>Layer-based brush GUI</li>
<li>(coming soon) glsl brush shaders</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/brush.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/brush.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance Profiler</h2><a id="user-content-performance-profiler" aria-label="Permalink: Performance Profiler" href="#performance-profiler"></a></p>
<ul dir="auto">
<li>Manual Instrumentation</li>
<li>Memory allocation tracking</li>
<li>Multithreaded callgraph tracing</li>
<li>Context Switches (windows only)</li>
<li>Physical Core  (windows only)</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/profiler.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/profiler.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gallery</h2><a id="user-content-gallery" aria-label="Permalink: Gallery" href="#gallery"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/3_skele.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/3_skele.png" alt="banner"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/ridgeline.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/ridgeline.png" alt="banner"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/grass.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/grass.png" alt="banner"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/8_skele.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/8_skele.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Wishlist</h2><a id="user-content-wishlist" aria-label="Permalink: Wishlist" href="#wishlist"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Renderer</h2><a id="user-content-renderer-1" aria-label="Permalink: Renderer" href="#renderer-1"></a></p>
<p dir="auto">[ ] HRC : <a href="https://github.com/entropylost/amitabha">https://github.com/entropylost/amitabha</a></p>
<p dir="auto">[ ] SSR : <a href="https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html" rel="nofollow">https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html</a></p>
<p dir="auto">[ ] Screen-space lines : <a href="https://mattdesl.svbtle.com/drawing-lines-is-hard" rel="nofollow">https://mattdesl.svbtle.com/drawing-lines-is-hard</a></p>
<p dir="auto">[ ] Better shadows : <a href="https://developer.nvidia.com/gpugems/gpugems3/part-ii-light-and-shadows/chapter-8-summed-area-variance-shadow-maps" rel="nofollow">https://developer.nvidia.com/gpugems/gpugems3/part-ii-light-and-shadows/chapter-8-summed-area-variance-shadow-maps</a></p>
<p dir="auto">[ ] Screen Space Shadows : <a href="https://panoskarabelas.com/posts/screen_space_shadows/" rel="nofollow">https://panoskarabelas.com/posts/screen_space_shadows/</a></p>
<p dir="auto">[ ] Motion Blur : <a href="https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-27-motion-blur-post-processing-effect" rel="nofollow">https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-27-motion-blur-post-processing-effect</a></p>
<p dir="auto">[ ] TAA?</p>
<p dir="auto">[ ] FXAA : <a href="http://blog.simonrodriguez.fr/articles/2016/07/implementing_fxaa.html" rel="nofollow">http://blog.simonrodriguez.fr/articles/2016/07/implementing_fxaa.html</a></p>
<p dir="auto">[ ] Water : <a href="https://www.youtube.com/watch?v=5yhDb9dzJ58" rel="nofollow">https://www.youtube.com/watch?v=5yhDb9dzJ58</a></p>
<p dir="auto">[ ] Fluids : <a href="https://andrewkchan.dev/posts/fire.html" rel="nofollow">https://andrewkchan.dev/posts/fire.html</a></p>
<p dir="auto">[ ] Remove meshing entirely? <a href="https://www.youtube.com/watch?v=4xs66m1Of4A" rel="nofollow">https://www.youtube.com/watch?v=4xs66m1Of4A</a></p>
<p dir="auto">[ ] Lumen-style GI screen-space radiance caching : <a href="https://www.youtube.com/watch?v=2GYXuM10riw" rel="nofollow">https://www.youtube.com/watch?v=2GYXuM10riw</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/platapus.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/platapus.png" alt="banner"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Terrain</h2><a id="user-content-terrain" aria-label="Permalink: Terrain" href="#terrain"></a></p>
<p dir="auto">[ ] Erosion simulation</p>
<ul dir="auto">
<li><a href="https://inria.hal.science/hal-01262376/document" rel="nofollow">https://inria.hal.science/hal-01262376/document</a></li>
<li><a href="https://xing-mei.github.io/files/erosion.pdf" rel="nofollow">https://xing-mei.github.io/files/erosion.pdf</a></li>
<li><a href="https://nickmcd.me/2020/04/15/procedural-hydrology/" rel="nofollow">https://nickmcd.me/2020/04/15/procedural-hydrology/</a></li>
</ul>
<p dir="auto">[ ] Biomes</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Holdridge_life_zones" rel="nofollow">https://en.wikipedia.org/wiki/Holdridge_life_zones</a></li>
</ul>
<p dir="auto">[ ] Meshing</p>
<ul dir="auto">
<li>Isotropic surface meshing</li>
<li><a href="https://graphics.stanford.edu/courses/cs164-10-spring/Handouts/isotropic.pdf" rel="nofollow">https://graphics.stanford.edu/courses/cs164-10-spring/Handouts/isotropic.pdf</a></li>
<li><a href="https://inria.hal.science/inria-00071612/document" rel="nofollow">https://inria.hal.science/inria-00071612/document</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/pillar.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/pillar.png" alt="banner"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Assets</h2><a id="user-content-assets" aria-label="Permalink: Assets" href="#assets"></a></p>
<p dir="auto">[ ] MCA importer</p>
<ul dir="auto">
<li><a href="https://github.com/GabeRundlett/gvox/blob/old/src/formats/minecraft.cpp">https://github.com/GabeRundlett/gvox/blob/old/src/formats/minecraft.cpp</a></li>
</ul>
<p dir="auto">[ ] Sound : mp3, ogg, ..? decompresser</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/5_skele.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/5_skele.png" alt="banner"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Datastructures</h2><a id="user-content-datastructures" aria-label="Permalink: Datastructures" href="#datastructures"></a></p>
<p dir="auto">[ ] Better low-discrepency sequences : <a href="https://blog.demofox.org/2017/05/29/when-random-numbers-are-too-random-low-discrepancy-sequences/" rel="nofollow">https://blog.demofox.org/2017/05/29/when-random-numbers-are-too-random-low-discrepancy-sequences/</a></p>
<p dir="auto">[ ] Better disk/sphere sampling patterns : <a href="https://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/" rel="nofollow">https://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/</a></p>
<p dir="auto">[ ] Better hash function! : <a href="https://nullprogram.com/blog/2018/07/31/" rel="nofollow">https://nullprogram.com/blog/2018/07/31/</a></p>
<p dir="auto">[ ] Better GPU hashing! : <a href="https://arugl.medium.com/hash-noise-in-gpu-shaders-210188ac3a3e" rel="nofollow">https://arugl.medium.com/hash-noise-in-gpu-shaders-210188ac3a3e</a></p>
<p dir="auto">[ ] Hash-trie as alternative to a table : <a href="https://nullprogram.com/blog/2023/09/30/" rel="nofollow">https://nullprogram.com/blog/2023/09/30/</a></p>
<p dir="auto">[ ] Octree ? <a href="https://graphics.tudelft.nl/Publications-new/2020/CBE20/ModifyingCompressedVoxels-main.pdf" rel="nofollow">https://graphics.tudelft.nl/Publications-new/2020/CBE20/ModifyingCompressedVoxels-main.pdf</a></p>
<p dir="auto">[ ] Better floating-point rng : <a href="https://www.corsix.org/content/higher-quality-random-floats" rel="nofollow">https://www.corsix.org/content/higher-quality-random-floats</a></p>
<p dir="auto">[ ] Better greedy meshing? <a href="https://www.youtube.com/watch?v=4xs66m1Of4A" rel="nofollow">https://www.youtube.com/watch?v=4xs66m1Of4A</a></p>
<p dir="auto">[ ] More interpolation goodies : <a href="https://paulbourke.net/miscellaneous/interpolation/" rel="nofollow">https://paulbourke.net/miscellaneous/interpolation/</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/scallyw4g/bonsai/blob/master/screenshots/dusk_defence.png"><img src="https://github.com/scallyw4g/bonsai/raw/master/screenshots/dusk_defence.png" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Goodies</h2><a id="user-content-goodies" aria-label="Permalink: Goodies" href="#goodies"></a></p>
<p dir="auto">[ ] Better (faster) Sin/Cos ? <a href="https://www.shadertoy.com/view/432yWW" rel="nofollow">https://www.shadertoy.com/view/432yWW</a></p>
<p dir="auto">[ ] Look into using this Intel tooling for dual CPU/GPU world-gen?
<a href="https://www.intel.com/content/dam/develop/external/us/en/documents/spir-vtointe-ispcgpu-compute-on-the-cpu.pdf" rel="nofollow">https://www.intel.com/content/dam/develop/external/us/en/documents/spir-vtointe-ispcgpu-compute-on-the-cpu.pdf</a>
<a href="https://ispc.github.io/" rel="nofollow">https://ispc.github.io/</a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Profiler</h2><a id="user-content-profiler" aria-label="Permalink: Profiler" href="#profiler"></a></p>
<p dir="auto">[ ] Improve the ETW layer : <a href="https://github.com/bombomby/optick/blob/master/src/optick_core.win.h">https://github.com/bombomby/optick/blob/master/src/optick_core.win.h</a></p>
<p dir="auto">[ ] GPU Profiling : <a href="https://www.khronos.org/opengl/wiki/Query_Object" rel="nofollow">https://www.khronos.org/opengl/wiki/Query_Object</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Erd≈ës Problem #1026 (152 pts)]]></title>
            <link>https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/</link>
            <guid>46284897</guid>
            <pubDate>Tue, 16 Dec 2025 04:49:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/">https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/</a>, See on <a href="https://news.ycombinator.com/item?id=46284897">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>
 <a href="https://www.erdosproblems.com/1026">Problem 1026 on the Erd≈ës problem web site</a> recently got solved through an interesting combination of existing literature, online collaboration, and AI tools. The purpose of this blog post is to try to tell the story of this collaboration, and also to supply a complete proof.
</p><p>
The original problem of Erd≈ës, <a href="https://users.renyi.hu/~p_erdos/1971-25.pdf">posed in 1975</a>, is rather ambiguous. Erd≈ës starts by <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szekeres_theorem">recalling his famous theorem with Szekeres</a> that says that given a sequence of <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2+1}"> distinct real numbers, one can find a subsequence of length <img src="https://s0.wp.com/latex.php?latex=%7Bk%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k+1}"> which is either increasing or decreasing; and that one cannot improve the <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2+1}"> to <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2}">, by considering for instance a sequence of <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}"> blocks of length <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}">, with the numbers in each block decreasing, but the blocks themselves increasing. He also noted a <a href="https://zbmath.org/0090.01302">result of Hanani</a> that every sequence of length <img src="https://s0.wp.com/latex.php?latex=%7Bk%28k%2B3%29%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%28k%2B3%29%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%28k%2B3%29%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k(k+3)/2}"> can be decomposed into the union of <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}"> monotone sequences. He then wrote ‚ÄúAs far as I know the following question is not yet settled. Let <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_n}"> be a sequence of distinct numbers, determine </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28x_1%2C%5Cdots%2Cx_n%29+%3D+%5Cmax+%5Csum_r+x_%7Bi_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28x_1%2C%5Cdots%2Cx_n%29+%3D+%5Cmax+%5Csum_r+x_%7Bi_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28x_1%2C%5Cdots%2Cx_n%29+%3D+%5Cmax+%5Csum_r+x_%7Bi_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  S(x_1,\dots,x_n) = \max \sum_r x_{i_r}"></p><p>
 where the maximum is to be taken over all monotonic sequences <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cdots%2Cx_%7Bi_m%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cdots%2Cx_%7Bi_m%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cdots%2Cx_%7Bi_m%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_{i_1},\dots,x_{i_m}}">‚Äú.
</p><p>
This problem was added to the Erd≈ës problem site on September 12, 2025, with a note that the problem was rather ambiguous. For any fixed <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">, this is an explicit piecewise linear function of the variables <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_n}"> that could be computed by a simple brute force algorithm, but Erd≈ës was presumably seeking optimal bounds for this quantity under some natural constraint on the <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}">. The day the problem was posted, Desmond Weisenberg proposed studying the quantity <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}">, defined as the largest constant such that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28x_1%2C%5Cdots%2Cx_n%29+%5Cgeq+c%28n%29+%5Csum_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28x_1%2C%5Cdots%2Cx_n%29+%5Cgeq+c%28n%29+%5Csum_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28x_1%2C%5Cdots%2Cx_n%29+%5Cgeq+c%28n%29+%5Csum_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  S(x_1,\dots,x_n) \geq c(n) \sum_{i=1}^n x_i"></p><p>
 for all choices of (distinct) real numbers <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_n}">. Desmond noted that for this formulation one could assume without loss of generality that the <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}"> were positive, since deleting negative or vanishing <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}"> does not decrease the left-hand side and does not increase the right-hand side. By a limiting argument one could also allow collisions between the <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}">, so long as one interpreted monotonicity in the weak sense.
</p><p>
Though not stated on the web site, one can formulate this problem in game theoretic terms. Suppose that Alice has a stack of <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{N}"> coins for some large <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{N}">. She divides the coins into <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> piles of consisting of <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_n}"> coins each, so that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5En+x_i+%3D+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5En+x_i+%3D+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5En+x_i+%3D+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\sum_{i=1}^n x_i = N}">. She then passes the piles to Bob, who is allowed to select a monotone subsequence of the piles (in the weak sense) and keep all the coins in those piles. What is the largest fraction <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> of the coins that Bob can guarantee to keep, regardless of how Alice divides up the coins? (One can work with either a discrete version of this problem where the <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}"> are integers, or a continuous one where the coins can be split fractionally, but in the limit <img src="https://s0.wp.com/latex.php?latex=%7BN+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BN+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BN+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{N \rightarrow \infty}"> the problems can easily be seen to be equivalent.)
</p>
<p>
AI-generated images continue to be problematic for a number of reasons, but here is one such image that somewhat manages at least to convey the idea of the game:
</p>
<p><img src="https://terrytao.wordpress.com/wp-content/uploads/2025/12/game.jpg" width="500"></p><p>
For small <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">, one can work out <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> by hand. For <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n=1}">, clearly <img src="https://s0.wp.com/latex.php?latex=%7Bc%281%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%281%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%281%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(1)=1}">: Alice has to put all the coins into one pile, which Bob simply takes. Similarly <img src="https://s0.wp.com/latex.php?latex=%7Bc%282%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%282%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%282%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(2)=1}">: regardless of how Alice divides the coins into two piles, the piles will either be increasing or decreasing, so in either case Bob can take both. The first interesting case is <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%3D3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%3D3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n=3}">. Bob can again always take the two largest piles, guaranteeing himself <img src="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{2/3}"> of the coins. On the other hand, if Alice <em>almost</em> divides the coins evenly, for instance into piles <img src="https://s0.wp.com/latex.php?latex=%7B%28%281%2F3+%2B+%5Cvarepsilon%29N%2C+%281%2F3-2%5Cvarepsilon%29+N%2C+%281%2F3%2B%5Cvarepsilon%29N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28%281%2F3+%2B+%5Cvarepsilon%29N%2C+%281%2F3-2%5Cvarepsilon%29+N%2C+%281%2F3%2B%5Cvarepsilon%29N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28%281%2F3+%2B+%5Cvarepsilon%29N%2C+%281%2F3-2%5Cvarepsilon%29+N%2C+%281%2F3%2B%5Cvarepsilon%29N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{((1/3 + \varepsilon)N, (1/3-2\varepsilon) N, (1/3+\varepsilon)N)}"> for some small <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon>0}">, then Bob cannot take all three piles as they are non-monotone, and so can only take two of them, allowing Alice to limit the payout fraction to be arbitrarily close to <img src="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{2/3}">. So we conclude that <img src="https://s0.wp.com/latex.php?latex=%7Bc%283%29%3D2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%283%29%3D2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%283%29%3D2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(3)=2/3}">.
</p><p>
An hour after Desmond‚Äôs comment, <a href="https://www.erdosproblems.com/forum/thread/1026#post-466">Stijn Cambie noted</a> (though not in the language I used above) that a similar construction to the one above, in which Alice divides the coins into <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2}"> pairs that are almost even, in such a way that the longest monotone sequence is of length <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}">, gives the upper bound <img src="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cleq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cleq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cleq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(k^2) \leq 1/k}">. It is also easy to see that <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> is a non-increasing function of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">, so this gives a general bound <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cleq+%281%2Bo%281%29%29%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cleq+%281%2Bo%281%29%29%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cleq+%281%2Bo%281%29%29%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n) \leq (1+o(1))/\sqrt{n}}">. Less than an hour after that, <a href="https://www.erdosproblems.com/forum/thread/1026#post-467">Wouter van Doorn noted</a> that the Hanani result mentioned above gives the lower bound <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cgeq+%28%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D-o%281%29%29%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cgeq+%28%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D-o%281%29%29%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cgeq+%28%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D-o%281%29%29%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n) \geq (\frac{1}{\sqrt{2}}-o(1))/\sqrt{n}}">, and posed the problem of determining the asymptotic limit of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D+c%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D+c%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D+c%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\sqrt{n} c(n)}"> as <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n \rightarrow \infty}">, given that this was now known to range between <img src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Csqrt%7B2%7D-o%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%2F%5Csqrt%7B2%7D-o%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%2F%5Csqrt%7B2%7D-o%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1/\sqrt{2}-o(1)}"> and <img src="https://s0.wp.com/latex.php?latex=%7B1%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1+o(1)}">. This version was <a href="https://www.erdosproblems.com/forum/thread/1026#post-473">accepted by Thomas Bloom</a>, the moderator of the Erd≈ës problem site, as a valid interpretation of the original problem.
</p><p>
The next day, <a href="https://www.erdosproblems.com/forum/thread/1026#post-478">Stijn computed</a> the first few values of <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> exactly: </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C+1%2C+2%2F3%2C+1%2F2%2C+1%2F2%2C+3%2F7%2C+2%2F5%2C+3%2F8%2C+1%2F3.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C+1%2C+2%2F3%2C+1%2F2%2C+1%2F2%2C+3%2F7%2C+2%2F5%2C+3%2F8%2C+1%2F3.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C+1%2C+2%2F3%2C+1%2F2%2C+1%2F2%2C+3%2F7%2C+2%2F5%2C+3%2F8%2C+1%2F3.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  1, 1, 2/3, 1/2, 1/2, 3/7, 2/5, 3/8, 1/3."></p><p>
 While the general pattern was not yet clear, this was enough data for Stijn to conjecture that <img src="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29%3D1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29%3D1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29%3D1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(k^2)=1/k}">, which would also imply that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D+c%28n%29+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D+c%28n%29+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D+c%28n%29+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\sqrt{n} c(n) \rightarrow 1}"> as <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n \rightarrow \infty}">. (EDIT: as later located by an AI deep research tool, this conjecture was also made in Section 12 of <a href="https://zbmath.org/0832.60012">this 1980 article of Steele</a>.) Stijn also described the extremizing sequences for this range of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">, but did not continue the calculation further (a naive computation would take runtime exponential in <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">, due to the large number of possible subsequences to consider).  
</p><p>
The problem then lay dormant for almost two months, until December 7, 2025, in which Boris Alexeev, as part of a systematic sweep of the Erd≈ës problems using the AI tool <a href="https://arxiv.org/abs/2510.01346">Aristotle</a>, was able to get this tool to <a href="https://github.com/plby/lean-proofs/blob/main/src/v4.24.0/ErdosProblems/Erdos1026.lean">autonomously solve</a> this conjecture <img src="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29%3D1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29%3D1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29%3D1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(k^2)=1/k}"> in the proof assistant language Lean. The proof converted the problem to a rectangle-packing problem.
</p><p>
This was one further addition to a recent sequence of examples where an Erd≈ës problem had been automatically solved in one fashion or another by an AI tool. Like the previous cases, the proof turned out to not be particularly novel. Within an hour, Koishi Chan gave an alternate proof deriving the required bound <img src="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cgeq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cgeq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cgeq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(k^2) \geq 1/k}"> from the original Erd≈ës-Szekeres theorem by a standard ‚Äúblow-up‚Äù argument which we can give here in the Alice-Bob formulation. Take a large <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{M}">, and replace each pile of <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}"> coins with <img src="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M%5E2+x_i%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M%5E2+x_i%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M%5E2+x_i%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(1+o(1)) M^2 x_i^2}"> new piles, each of size <img src="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(1+o(1)) x_i}">, chosen so that the longest monotone subsequence in this collection is <img src="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(1+o(1)) M x_i}">. Among all the new piles, the longest monotone subsequence has length <img src="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M+S%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M+S%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%281%2Bo%281%29%29+M+S%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(1+o(1)) M S(x_1,\dots,x_n)}">. Applying Erd≈ës-Szekeres, one concludes the bound </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+S%28x_1%2C%5Cdots%2Cx_n%29+%5Cgeq+%281-o%281%29%29+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%7D+M%5E2+x_i%5E2%29%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+S%28x_1%2C%5Cdots%2Cx_n%29+%5Cgeq+%281-o%281%29%29+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%7D+M%5E2+x_i%5E2%29%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+S%28x_1%2C%5Cdots%2Cx_n%29+%5Cgeq+%281-o%281%29%29+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%7D+M%5E2+x_i%5E2%29%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  M S(x_1,\dots,x_n) \geq (1-o(1)) (\sum_{i=1}^{k^2} M^2 x_i^2)^{1/2}"></p><p>
 and on canceling the <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{M}">‚Äòs, sending <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BM+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BM+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{M \rightarrow \infty}">, and applying Cauchy-Schwarz, one obtains <img src="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cgeq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cgeq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%29+%5Cgeq+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(k^2) \geq 1/k}"> (in fact the argument gives <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cgeq+1%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cgeq+1%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29+%5Cgeq+1%2F%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n) \geq 1/\sqrt{n}}"> for all <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">).
</p><p>
Once this proof was found, it was natural to try to see if it had already appeared in the literature. AI deep research tools have successfully located such prior literature in the past, but in this case they did not succeed, and a more ‚Äúold-fashioned‚Äù Google Scholar job turned up some relevant references: a <a href="https://arxiv.org/abs/1608.04153">2016 paper by Tidor, Wang and Yang</a> contained this precise result, citing an <a href="https://arxiv.org/abs/1612.00471">earlier paper of Wagner</a> as inspiration for applying ‚Äúblowup‚Äù to the Erd≈ës-Szekeres theorem.
</p><p>
But the story does not end there! Upon reading the above story the next day, I realized that the problem of estimating <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> was a suitable task for <a href="https://arxiv.org/abs/2506.13131">AlphaEvolve</a>, which I have used recently as mentioned in <a href="https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/">this previous post</a>. Specifically, one could task to obtain upper bounds on <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> by directing it to produce real numbers (or integers) <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_n}"> summing up to a fixed sum (I chose <img src="https://s0.wp.com/latex.php?latex=%7B10%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B10%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B10%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{10^6}">) with a small a value of <img src="https://s0.wp.com/latex.php?latex=%7BS%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BS%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BS%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{S(x_1,\dots,x_n)}"> as possible. After an hour of run time, AlphaEvolve produced the following upper bounds on <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> for <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+n+%5Cleq+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+n+%5Cleq+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+n+%5Cleq+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1 \leq n \leq 16}">, with some intriguingly structured potential extremizing solutions: </p>
<p><img src="https://terrytao.wordpress.com/wp-content/uploads/2025/12/download.png" width="500"></p><p>
The numerical scores (divided by <img src="https://s0.wp.com/latex.php?latex=%7B10%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B10%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B10%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{10^6}">) were pretty obviously trying to approximate simple rational numbers. There were a variety of ways (including modern AI) to extract the actual rational numbers they were close to, but I searched for a dedicated tool and found this useful <a href="https://www.johndcook.com/rational_approximation.html">little web page of John Cook</a> that did the job: </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C+1%2C+2%2F3%2C+1%2F2%2C+1%2F2%2C+3%2F7%2C+2%2F5%2C+3%2F8%2C+1%2F3%2C+1%2F4.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C+1%2C+2%2F3%2C+1%2F2%2C+1%2F2%2C+3%2F7%2C+2%2F5%2C+3%2F8%2C+1%2F3%2C+1%2F4.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C+1%2C+2%2F3%2C+1%2F2%2C+1%2F2%2C+3%2F7%2C+2%2F5%2C+3%2F8%2C+1%2F3%2C+1%2F4.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  1, 1, 2/3, 1/2, 1/2, 3/7, 2/5, 3/8, 1/3, 1/4."></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2F3%2C+4%2F13%2C+3%2F10%2C+4%2F14%2C+3%2F11%2C+4%2F15%2C+1%2F4.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2F3%2C+4%2F13%2C+3%2F10%2C+4%2F14%2C+3%2F11%2C+4%2F15%2C+1%2F4.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2F3%2C+4%2F13%2C+3%2F10%2C+4%2F14%2C+3%2F11%2C+4%2F15%2C+1%2F4.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  1/3, 4/13, 3/10, 4/14, 3/11, 4/15, 1/4."></p><p>
 I could not immediately see the pattern here, but after some trial and error in which I tried to align numerators and denominators, I eventually organized this sequence into a more suggestive form: </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  1,"></p>
 <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2F1%2C+%5Cmathbf%7B2%2F3%7D%2C+1%2F2%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2F1%2C+%5Cmathbf%7B2%2F3%7D%2C+1%2F2%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%2F1%2C+%5Cmathbf%7B2%2F3%7D%2C+1%2F2%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  1/1, \mathbf{2/3}, 1/2,"></p>
 <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%2F4%2C+%5Cmathbf%7B3%2F7%7D%2C+2%2F5%2C+%5Cmathbf%7B3%2F8%7D%2C+2%2F6%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%2F4%2C+%5Cmathbf%7B3%2F7%7D%2C+2%2F5%2C+%5Cmathbf%7B3%2F8%7D%2C+2%2F6%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%2F4%2C+%5Cmathbf%7B3%2F7%7D%2C+2%2F5%2C+%5Cmathbf%7B3%2F8%7D%2C+2%2F6%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  2/4, \mathbf{3/7}, 2/5, \mathbf{3/8}, 2/6,"></p>
 <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F9%2C+%5Cmathbf%7B4%2F13%7D%2C+3%2F10%2C+%5Cmathbf%7B4%2F14%7D%2C+3%2F11%2C+%5Cmathbf%7B4%2F15%7D%2C+3%2F12.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F9%2C+%5Cmathbf%7B4%2F13%7D%2C+3%2F10%2C+%5Cmathbf%7B4%2F14%7D%2C+3%2F11%2C+%5Cmathbf%7B4%2F15%7D%2C+3%2F12.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F9%2C+%5Cmathbf%7B4%2F13%7D%2C+3%2F10%2C+%5Cmathbf%7B4%2F14%7D%2C+3%2F11%2C+%5Cmathbf%7B4%2F15%7D%2C+3%2F12.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  3/9, \mathbf{4/13}, 3/10, \mathbf{4/14}, 3/11, \mathbf{4/15}, 3/12."></p><p>
This gave a somewhat complicated but predictable conjecture for the values of the sequence <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}">. On posting this, Boris found a clean formulation of the conjecture, namely that </p><a name="conj"><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c%28k%5E2+%2B+2a+%2B+1%29+%3D+%5Cfrac%7Bk%7D%7Bk%5E2%2Ba%7D+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c%28k%5E2+%2B+2a+%2B+1%29+%3D+%5Cfrac%7Bk%7D%7Bk%5E2%2Ba%7D+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c%28k%5E2+%2B+2a+%2B+1%29+%3D+%5Cfrac%7Bk%7D%7Bk%5E2%2Ba%7D+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  c(k^2 + 2a + 1) = \frac{k}{k^2+a} \ \ \ \ \ (1)"></p>
</a><p> whenever <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k \geq 1}"> and <img src="https://s0.wp.com/latex.php?latex=%7B-k+%5Cleq+a+%5Cleq+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-k+%5Cleq+a+%5Cleq+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-k+%5Cleq+a+%5Cleq+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-k \leq a \leq k}">. After a bit of effort, he also produced an explicit upper bound construction:
</p><blockquote><b>Proposition 1</b>  If <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k \geq 1}"> and <img src="https://s0.wp.com/latex.php?latex=%7B-k+%5Cleq+a+%5Cleq+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-k+%5Cleq+a+%5Cleq+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-k+%5Cleq+a+%5Cleq+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-k \leq a \leq k}">, then <img src="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%2B2a%2B1%29+%5Cleq+%5Cfrac%7Bk%7D%7Bk%5E2%2Ba%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%2B2a%2B1%29+%5Cleq+%5Cfrac%7Bk%7D%7Bk%5E2%2Ba%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28k%5E2%2B2a%2B1%29+%5Cleq+%5Cfrac%7Bk%7D%7Bk%5E2%2Ba%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(k^2+2a+1) \leq \frac{k}{k^2+a}}">. </blockquote>

<p>
<em>Proof:</em>  Consider a sequence <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_%7Bk%5E2%2B2a%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_%7Bk%5E2%2B2a%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_%7Bk%5E2%2B2a%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_{k^2+2a+1}}"> of numbers clustered around the ‚Äúred number‚Äù <img src="https://s0.wp.com/latex.php?latex=%7B%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|a|}"> and ‚Äúblue number‚Äù <img src="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|a+1|}">, consisting of <img src="https://s0.wp.com/latex.php?latex=%7B%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|a|}"> blocks of <img src="https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k-|a|}"> ‚Äúblue‚Äù numbers, followed by <img src="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|a+1|}"> blocks of <img src="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|a+1|}"> ‚Äúred‚Äù numbers, and then <img src="https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k-|a|}"> further blocks of <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}"> ‚Äúblue‚Äù numbers.  When <img src="https://s0.wp.com/latex.php?latex=%7Ba+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a \geq 0}">, one should take all blocks to be slightly decreasing within each block, but the blue blocks should be are increasing between each other, and the red blocks should also be increasing between each other. When <img src="https://s0.wp.com/latex.php?latex=%7Ba+%3C+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba+%3C+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba+%3C+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a < 0}">, all of these orderings should be reversed. The total number of elements is indeed </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Ca%7C+%5Ctimes+%28k-%7Ca%7C%29+%2B+%7Ca%2B1%7C+%5Ctimes+%7Ca%2B1%7C+%2B+%28k-%7Ca%7C%29+%5Ctimes+k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Ca%7C+%5Ctimes+%28k-%7Ca%7C%29+%2B+%7Ca%2B1%7C+%5Ctimes+%7Ca%2B1%7C+%2B+%28k-%7Ca%7C%29+%5Ctimes+k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Ca%7C+%5Ctimes+%28k-%7Ca%7C%29+%2B+%7Ca%2B1%7C+%5Ctimes+%7Ca%2B1%7C+%2B+%28k-%7Ca%7C%29+%5Ctimes+k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  |a| \times (k-|a|) + |a+1| \times |a+1| + (k-|a|) \times k "></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+k%5E2+%2B+2a+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+k%5E2+%2B+2a+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+k%5E2+%2B+2a+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  = k^2 + 2a + 1"></p><p>
 and the total sum is close to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7Ca%7C+%5Ctimes+%28k-%7Ca%7C%29+%5Ctimes+%7Ca%2B1%7C+%2B+%7Ca%2B1%7C+%5Ctimes+%7Ca%2B1%7C+%5Ctimes+%7Ca%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7Ca%7C+%5Ctimes+%28k-%7Ca%7C%29+%5Ctimes+%7Ca%2B1%7C+%2B+%7Ca%2B1%7C+%5Ctimes+%7Ca%2B1%7C+%5Ctimes+%7Ca%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7Ca%7C+%5Ctimes+%28k-%7Ca%7C%29+%5Ctimes+%7Ca%2B1%7C+%2B+%7Ca%2B1%7C+%5Ctimes+%7Ca%2B1%7C+%5Ctimes+%7Ca%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle |a| \times (k-|a|) \times |a+1| + |a+1| \times |a+1| \times |a| "></p>
<p><img src="https://s0.wp.com/latex.php?latex=%2B+%28k-%7Ca%7C%29+%5Ctimes+k+%5Ctimes+%7Ca%2B1%7C+%3D+%28k%5E2+%2B+a%29+%7Ca%2B1%7C.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%2B+%28k-%7Ca%7C%29+%5Ctimes+k+%5Ctimes+%7Ca%2B1%7C+%3D+%28k%5E2+%2B+a%29+%7Ca%2B1%7C.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%2B+%28k-%7Ca%7C%29+%5Ctimes+k+%5Ctimes+%7Ca%2B1%7C+%3D+%28k%5E2+%2B+a%29+%7Ca%2B1%7C.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="+ (k-|a|) \times k \times |a+1| = (k^2 + a) |a+1|."></p><p>
 With this setup, one can check that any monotone sequence consists either of at most <img src="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ca%2B1%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|a+1|}"> red elements and at most <img src="https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk-%7Ca%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k-|a|}"> blue elements, or no red elements and at most <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}"> blue elements, in either case giving a monotone sum that is bounded by either </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Ca%2B1%7C+%5Ctimes+%7Ca%7C+%2B+%28k-%7Ca%7C%29+%5Ctimes+%7Ca%2B1%7C+%3D+k+%7Ca%2B1%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Ca%2B1%7C+%5Ctimes+%7Ca%7C+%2B+%28k-%7Ca%7C%29+%5Ctimes+%7Ca%2B1%7C+%3D+k+%7Ca%2B1%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Ca%2B1%7C+%5Ctimes+%7Ca%7C+%2B+%28k-%7Ca%7C%29+%5Ctimes+%7Ca%2B1%7C+%3D+k+%7Ca%2B1%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  |a+1| \times |a| + (k-|a|) \times |a+1| = k |a+1|"></p><p>
 or </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+k+%5Ctimes+%7Ca%2B1%7C+%3D+k+%7Ca%2B1%7C%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+k+%5Ctimes+%7Ca%2B1%7C+%3D+k+%7Ca%2B1%7C%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+k+%5Ctimes+%7Ca%2B1%7C+%3D+k+%7Ca%2B1%7C%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  0 + k \times |a+1| = k |a+1|,"></p><p>
 giving the claim. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\Box"></p><p>
Here is a figure illustrating the above construction in the <img src="https://s0.wp.com/latex.php?latex=%7Ba+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a \geq 0}"> case (obtained after starting with a ChatGPT-provided file and then manually fixing a number of placement issues):
</p>
<p><img src="https://terrytao.wordpress.com/wp-content/uploads/2025/12/screenshot-2025-12-10-092536.png" width="500"></p><p>
Here is a plot of <img src="https://s0.wp.com/latex.php?latex=1%2Fc%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%2Fc%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2Fc%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="1/c(n)"> (produced by ChatGPT Pro), showing that it is basically a piecewise linear approximation to the square root function:
</p>
<p>
<img src="https://terrytao.wordpress.com/wp-content/uploads/2025/12/plot.png" width="500">
</p>


<p>
Shortly afterwards, Lawrence Wu clarified the connection between this problem and a square packing problem, which was also <a href="https://www.erdosproblems.com/106">due to Erd≈ës (Problem 106)</a>. Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{f(n)}"> be the least number such that, whenever one packs <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> squares of sidelength <img src="https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d_1,\dots,d_n}"> into a square of sidelength <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D}">, with all sides parallel to the coordinate axes, one has </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5En+d_i+%5Cleq+f%28n%29+D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5En+d_i+%5Cleq+f%28n%29+D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5En+d_i+%5Cleq+f%28n%29+D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sum_{i=1}^n d_i \leq f(n) D."></p>

<blockquote><b>Proposition 2</b>  For any <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">, one has <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c%28n%29+%5Cgeq+%5Cfrac%7B1%7D%7Bf%28n%29%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c%28n%29+%5Cgeq+%5Cfrac%7B1%7D%7Bf%28n%29%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c%28n%29+%5Cgeq+%5Cfrac%7B1%7D%7Bf%28n%29%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  c(n) \geq \frac{1}{f(n)}."></p>
 </blockquote>

<p>
<em>Proof:</em>  Given <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_1,\dots,x_n}"> and <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1 \leq i \leq n}">, let <img src="https://s0.wp.com/latex.php?latex=%7BS_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BS_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BS_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{S_i}"> be the maximal sum over all increasing subsequences ending in <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}">, and <img src="https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{T_i}"> be the maximal sum over all decreasing subsequences ending in <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_i}">. For <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi+%3C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi+%3C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i < j}">, we have either <img src="https://s0.wp.com/latex.php?latex=%7BS_j+%5Cgeq+S_i+%2B+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BS_j+%5Cgeq+S_i+%2B+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BS_j+%5Cgeq+S_i+%2B+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{S_j \geq S_i + x_j}"> (if <img src="https://s0.wp.com/latex.php?latex=%7Bx_j+%5Cgeq+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_j+%5Cgeq+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_j+%5Cgeq+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_j \geq x_i}">) or <img src="https://s0.wp.com/latex.php?latex=%7BT_j+%5Cgeq+T_i+%2B+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BT_j+%5Cgeq+T_i+%2B+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BT_j+%5Cgeq+T_i+%2B+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{T_j \geq T_i + x_j}"> (if <img src="https://s0.wp.com/latex.php?latex=%7Bx_j+%5Cleq+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_j+%5Cleq+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_j+%5Cleq+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_j \leq x_i}">). In particular, the squares <img src="https://s0.wp.com/latex.php?latex=%7B%28S_i-x_i%2C+T_i-x_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28S_i-x_i%2C+T_i-x_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28S_i-x_i%2C+T_i-x_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(S_i-x_i, T_i-x_i)}"> and <img src="https://s0.wp.com/latex.php?latex=%7B%28S_j-x_j%2C+T_j-x_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28S_j-x_j%2C+T_j-x_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28S_j-x_j%2C+T_j-x_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(S_j-x_j, T_j-x_j)}"> are disjoint. These squares pack into the square <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2C+S%28x_1%2C%5Cdots%2Cx_n%29%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5B0%2C+S%28x_1%2C%5Cdots%2Cx_n%29%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5B0%2C+S%28x_1%2C%5Cdots%2Cx_n%29%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[0, S(x_1,\dots,x_n)]^2}">, so by definition of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{f}">, we have </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cleq+f%28n%29+S%28x_1%2C%5Cdots%2Cx_n%29%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cleq+f%28n%29+S%28x_1%2C%5Cdots%2Cx_n%29%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cleq+f%28n%29+S%28x_1%2C%5Cdots%2Cx_n%29%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sum_{i=1}^n x_i \leq f(n) S(x_1,\dots,x_n),"></p><p>
 and the claim follows. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\Box"></p><p>
This idea of using packing to prove Erd≈ës-Szekeres type results goes back to a 1959 paper of <a href="https://zbmath.org/0085.15003">Seidenberg</a>, although it was a discrete rectangle-packing argument that was not phrased in such an elegantly geometric form.  It is possible that Aristotle was ‚Äúaware‚Äù of the Seidenberg argument via its training data, as it had incorporated a version of this argument in its proof.
</p>
<p>
Here is an illustration of the above argument using the AlphaEvolve-provided example </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5B99998%2C+99997%2C+116305%2C+117032%2C+116304%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5B99998%2C+99997%2C+116305%2C+117032%2C+116304%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5B99998%2C+99997%2C+116305%2C+117032%2C+116304%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle[99998, 99997, 116305, 117032, 116304,">
</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+58370%2C+83179%2C+117030%2C+92705%2C+99080%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+58370%2C+83179%2C+117030%2C+92705%2C+99080%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+58370%2C+83179%2C+117030%2C+92705%2C+99080%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle 58370, 83179, 117030, 92705, 99080]">
</p>
<p> for <img src="https://s0.wp.com/latex.php?latex=n%3D10&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%3D10&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%3D10&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="n=10"> to convert it to a square packing (image produced by ChatGPT Pro):
</p>
<p>
<img src="https://terrytao.wordpress.com/wp-content/uploads/2025/12/packing_n10_seidenberg.png" width="500">
</p>
<p>
At this point, Lawrence performed another AI deep research search, this time <a href="https://www.erdosproblems.com/forum/thread/1026#post-2108">successfully locating a paper</a> from just last year by <a href="https://arxiv.org/abs/2411.07274">Baek, Koizumi, and Ueoro</a>, where they show that
</p><blockquote><b>Theorem 3</b> <a name="fn-1"></a> For any <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k \geq 1}">, one has <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28k%5E2%2B1%29+%5Cleq+k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28k%5E2%2B1%29+%5Cleq+k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28k%5E2%2B1%29+%5Cleq+k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  f(k^2+1) \leq k"></p>
 </blockquote>

<p>
which, when combined with a <a href="https://zbmath.org/1178.52014">previous argument of Praton</a>, implies
</p><blockquote><b>Theorem 4</b> <a name="fn-2"></a> For any <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k \geq 1}"> and <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cin+%7B%5Cbf+Z%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc+%5Cin+%7B%5Cbf+Z%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc+%5Cin+%7B%5Cbf+Z%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c \in {\bf Z}}"> with <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B2c%2B1+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B2c%2B1+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B2c%2B1+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2+2c+1 \geq 1}">, one has <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28k%5E2%2B2c%2B1%29+%5Cleq+k+%2B+%5Cfrac%7Bc%7D%7Bk%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28k%5E2%2B2c%2B1%29+%5Cleq+k+%2B+%5Cfrac%7Bc%7D%7Bk%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28k%5E2%2B2c%2B1%29+%5Cleq+k+%2B+%5Cfrac%7Bc%7D%7Bk%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  f(k^2+2c+1) \leq k + \frac{c}{k}."></p>
 </blockquote>

<p>
This proves the conjecture!
</p><p>
There just remained the issue of putting everything together. I did feed all of the above information into a large language model, which was able to <a href="https://chatgpt.com/share/69373cfb-fa70-800e-af98-ade8926ca5e1">produce a coherent proof</a> of <a href="#conj">(1)</a> assuming the results of Baek-Koizumi-Ueoro and Praton. Of course, LLM outputs are prone to hallucination, so it would be preferable to formalize that argument in Lean, but this looks quite doable with current tools, and I expect this to be accomplished shortly. But I was also able to reproduce the arguments of Baek-Koizumi-Ueoro and Praton, which I include below for completeness.
</p><p>
<em>Proof:</em>  (Proof of Theorem <a href="#fn-1">3</a>, adapted from Baek-Koizumi-Ueoro) We can normalize <img src="https://s0.wp.com/latex.php?latex=%7BD%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D=k}">. It then suffices to show that if we pack the length <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}"> torus <img src="https://s0.wp.com/latex.php?latex=%7B%28%7B%5Cbf+Z%7D%2Fk%7B%5Cbf+Z%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28%7B%5Cbf+Z%7D%2Fk%7B%5Cbf+Z%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28%7B%5Cbf+Z%7D%2Fk%7B%5Cbf+Z%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{({\bf Z}/k{\bf Z})^2}"> by <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2+1}"> axis-parallel squares of sidelength <img src="https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_%7Bk%5E2%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_%7Bk%5E2%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_%7Bk%5E2%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d_1,\dots,d_{k^2+1}}">, then </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+d_i+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+d_i+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+d_i+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sum_{i=1}^{k^2+1} d_i \leq k^2."></p>

<p>
Pick <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C+y_0+%5Cin+%7B%5Cbf+R%7D%2Fk%7B%5Cbf+Z%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_0%2C+y_0+%5Cin+%7B%5Cbf+R%7D%2Fk%7B%5Cbf+Z%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_0%2C+y_0+%5Cin+%7B%5Cbf+R%7D%2Fk%7B%5Cbf+Z%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_0, y_0 \in {\bf R}/k{\bf Z}}">. Then we have a <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Ctimes+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk+%5Ctimes+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk+%5Ctimes+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k \times k}"> grid </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x_0+%2B+%7B%5Cbf+Z%7D%29+%5Ctimes+%28y_0+%2B+%7B%5Cbf+Z%7D%29+%5Cpmod+%7Bk%7B%5Cbf+Z%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x_0+%2B+%7B%5Cbf+Z%7D%29+%5Ctimes+%28y_0+%2B+%7B%5Cbf+Z%7D%29+%5Cpmod+%7Bk%7B%5Cbf+Z%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x_0+%2B+%7B%5Cbf+Z%7D%29+%5Ctimes+%28y_0+%2B+%7B%5Cbf+Z%7D%29+%5Cpmod+%7Bk%7B%5Cbf+Z%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  (x_0 + {\bf Z}) \times (y_0 + {\bf Z}) \pmod {k{\bf Z}^2}"></p><p>
 inside the torus. The <img src="https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i^{th}}"> square, when restricted to this grid, becomes a discrete rectangle <img src="https://s0.wp.com/latex.php?latex=%7BA_%7Bi%2Cx_0%7D+%5Ctimes+B_%7Bi%2Cy_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA_%7Bi%2Cx_0%7D+%5Ctimes+B_%7Bi%2Cy_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA_%7Bi%2Cx_0%7D+%5Ctimes+B_%7Bi%2Cy_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A_{i,x_0} \times B_{i,y_0}}"> for some finite sets <img src="https://s0.wp.com/latex.php?latex=%7BA_%7Bi%2Cx_0%7D%2C+B_%7Bi%2Cy_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA_%7Bi%2Cx_0%7D%2C+B_%7Bi%2Cy_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA_%7Bi%2Cx_0%7D%2C+B_%7Bi%2Cy_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A_{i,x_0}, B_{i,y_0}}"> with </p><a name="ao"><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5C%23+A_%7Bi%2Cx_0%7D+-%5C%23+B_%7Bi%2Cy_0%7D%7C+%5Cleq+1.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5C%23+A_%7Bi%2Cx_0%7D+-%5C%23+B_%7Bi%2Cy_0%7D%7C+%5Cleq+1.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5C%23+A_%7Bi%2Cx_0%7D+-%5C%23+B_%7Bi%2Cy_0%7D%7C+%5Cleq+1.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  |\# A_{i,x_0} -\# B_{i,y_0}| \leq 1. \ \ \ \ \ (2)"></p>
</a><p> By the packing condition, we have </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sum_{i=1}^{k^2+1} \# A_{i,x_0} \# B_{i,y_0} \leq k^2."></p><p>
 From <a href="#ao">(2)</a> we have </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5C%23+A_%7Bi%2Cx_0%7D+-+1%29+%28%5C%23+B_%7Bi%2Cy_0%7D+-+1%29+%5Cgeq+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5C%23+A_%7Bi%2Cx_0%7D+-+1%29+%28%5C%23+B_%7Bi%2Cy_0%7D+-+1%29+%5Cgeq+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5C%23+A_%7Bi%2Cx_0%7D+-+1%29+%28%5C%23+B_%7Bi%2Cy_0%7D+-+1%29+%5Cgeq+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  (\# A_{i,x_0} - 1) (\# B_{i,y_0} - 1) \geq 0"></p><p>
 hence </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23+A_%7Bi%2Cx_0%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cgeq+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5C%23+B_%7Bi%2Cy_0%7D+-+1.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23+A_%7Bi%2Cx_0%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cgeq+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5C%23+B_%7Bi%2Cy_0%7D+-+1.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23+A_%7Bi%2Cx_0%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cgeq+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5C%23+B_%7Bi%2Cy_0%7D+-+1.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \# A_{i,x_0} \# B_{i,y_0} \geq \# A_{i,x_0} + \# B_{i,y_0} - 1."></p><p>
 Inserting this bound and rearranging, we conclude that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+2k%5E2+%2B+1.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+2k%5E2+%2B+1.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+2k%5E2+%2B+1.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sum_{i=1}^{k^2+1} \# A_{i,x_0} + \sum_{i=1}^{k^2+1} \# B_{i,y_0} \leq 2k^2 + 1."></p><p>
 Taking the supremum over <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Cy_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx_0%2Cy_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx_0%2Cy_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x_0,y_0}"> we conclude that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5Csup_%7By_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+2k%5E2+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5Csup_%7By_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+2k%5E2+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%2B+%5Csup_%7By_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+B_%7Bi%2Cy_0%7D+%5Cleq+2k%5E2+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sup_{x_0} \sum_{i=1}^{k^2+1} \# A_{i,x_0} + \sup_{y_0} \sum_{i=1}^{k^2+1} \# B_{i,y_0} \leq 2k^2 + 1"></p><p>
 so by the pigeonhole principle one of the summands is at most <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2}">. Let‚Äôs say it is the former, thus </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx_0%7D+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D+%5Cleq+k%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sup_{x_0} \sum_{i=1}^{k^2+1} \# A_{i,x_0} \leq k^2."></p><p>
 In particular, the average value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+%5C%23+A_%7Bi%2Cx_0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\sum_{i=1}^{k^2+1} \# A_{i,x_0}}"> is at most <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2}">. But this can be computed to be <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+d_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+d_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B1%7D+d_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\sum_{i=1}^{k^2+1} d_i}">, giving the claim. Similarly if it is the other sum. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\Box"></p><p>
UPDATE: Actually, the above argument also proves Theorem 4 with only minor modifications.  Nevertheless, we give the original derivation of Theorem 4 using the embedding argument of Praton below for sake of completeness.
</p>
<p>
<em>Proof:</em>  (Proof of Theorem <a href="#fn-2">4</a>, adapted from Praton) We write <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Cepsilon+%7Cc%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Cepsilon+%7Cc%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Cepsilon+%7Cc%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c = \epsilon |c|}"> with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\epsilon = \pm 1}">. We can rescale so that the square one is packing into is <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[0,k]^2}">. Thus, we pack <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k^2+2\varepsilon |c|+1}"> squares of sidelength <img src="https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd_1%2C%5Cdots%2Cd_%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d_1,\dots,d_{k^2+2\varepsilon |c|+1}}"> into <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[0,k]^2}">, and our task is to show that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon%7Cc%7C%2B1%7D+d_i+%5Cleq+k%5E2+%2B+%5Cvarepsilon+%7Cc%7C.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon%7Cc%7C%2B1%7D+d_i+%5Cleq+k%5E2+%2B+%5Cvarepsilon+%7Cc%7C.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon%7Cc%7C%2B1%7D+d_i+%5Cleq+k%5E2+%2B+%5Cvarepsilon+%7Cc%7C.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \sum_{i=1}^{k^2+2\varepsilon|c|+1} d_i \leq k^2 + \varepsilon |c|."></p><p>
 We pick a large natural number <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{N}"> (in particular, larger than <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}">), and consider the three nested squares </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5B0%2Ck%5D%5E2+%5Csubset+%5B0%2CN%5D%5E2+%5Csubset+%5B0%2CN+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%5D%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5B0%2Ck%5D%5E2+%5Csubset+%5B0%2CN%5D%5E2+%5Csubset+%5B0%2CN+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%5D%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5B0%2Ck%5D%5E2+%5Csubset+%5B0%2CN%5D%5E2+%5Csubset+%5B0%2CN+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%5D%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  [0,k]^2 \subset [0,N]^2 \subset [0,N + |c| \frac{N}{N-\varepsilon}]^2."></p><p>
 We can pack <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2CN%5D%5E2+%5Cbackslash+%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5B0%2CN%5D%5E2+%5Cbackslash+%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5B0%2CN%5D%5E2+%5Cbackslash+%5B0%2Ck%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[0,N]^2 \backslash [0,k]^2}"> by <img src="https://s0.wp.com/latex.php?latex=%7BN%5E2-k%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BN%5E2-k%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BN%5E2-k%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{N^2-k^2}"> unit squares. We can similarly pack </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5B0%2CN+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%5D%5E2+%5Cbackslash+%5B0%2CN%5D%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5B0%2CN+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%5D%5E2+%5Cbackslash+%5B0%2CN%5D%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5B0%2CN+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%5D%5E2+%5Cbackslash+%5B0%2CN%5D%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  [0,N + |c| \frac{N}{N-\varepsilon}]^2 \backslash [0,N]^2"></p>
 <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D%5B0%2C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%28N%2B%7Cc%7C-%5Cvarepsilon%29%5D%5E2+%5Cbackslash+%5B0%2C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%28N-%5Cvarepsilon%29%5D%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D%5B0%2C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%28N%2B%7Cc%7C-%5Cvarepsilon%29%5D%5E2+%5Cbackslash+%5B0%2C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%28N-%5Cvarepsilon%29%5D%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D%5B0%2C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%28N%2B%7Cc%7C-%5Cvarepsilon%29%5D%5E2+%5Cbackslash+%5B0%2C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%28N-%5Cvarepsilon%29%5D%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  =[0, \frac{N}{N-\varepsilon} (N+|c|-\varepsilon)]^2 \backslash [0, \frac{N}{N-\varepsilon} (N-\varepsilon)]^2"></p><p>
 into <img src="https://s0.wp.com/latex.php?latex=%7B%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(N+|c|-\varepsilon)^2 - (N-\varepsilon)^2}"> squares of sidelength <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\frac{N}{N-\varepsilon}}">. All in all, this produces </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1+%2B+N%5E2-k%5E2+%2B+%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1+%2B+N%5E2-k%5E2+%2B+%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1+%2B+N%5E2-k%5E2+%2B+%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  k^2+2\varepsilon |c|+1 + N^2-k^2 + (N+|c|-\varepsilon)^2 - (N-\varepsilon)^2"></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%3D+%28N%2B%7Cc%7C%29%5E2+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%3D+%28N%2B%7Cc%7C%29%5E2+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%3D+%28N%2B%7Cc%7C%29%5E2+%2B+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle   = (N+|c|)^2 + 1"></p><p>
 squares, of total length </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i%29+%2B%28N%5E2-k%5E2%29+%2B+%28%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%29+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i%29+%2B%28N%5E2-k%5E2%29+%2B+%28%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%29+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i%29+%2B%28N%5E2-k%5E2%29+%2B+%28%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%29+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle (\sum_{i=1}^{k^2+2\varepsilon |c|+1} d_i) +(N^2-k^2) + ((N+|c|-\varepsilon)^2 - (N-\varepsilon)^2) \frac{N}{N-\varepsilon}."></p><p>
 Applying Theorem <a href="#fn-1">3</a>, we conclude that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i%29+%2B%28N%5E2-k%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i%29+%2B%28N%5E2-k%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i%29+%2B%28N%5E2-k%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle (\sum_{i=1}^{k^2+2\varepsilon |c|+1} d_i) +(N^2-k^2)"></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%2B+%28%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%29+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%5Cleq+%28N%2B%7Cc%7C%29+%28N+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%2B+%28%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%29+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%5Cleq+%28N%2B%7Cc%7C%29+%28N+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%2B+%28%28N%2B%7Cc%7C-%5Cvarepsilon%29%5E2+-+%28N-%5Cvarepsilon%29%5E2%29+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D+%5Cleq+%28N%2B%7Cc%7C%29+%28N+%2B+%7Cc%7C+%5Cfrac%7BN%7D%7BN-%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  + ((N+|c|-\varepsilon)^2 - (N-\varepsilon)^2) \frac{N}{N-\varepsilon} \leq (N+|c|) (N + |c| \frac{N}{N-\varepsilon})."></p><p>
 The right-hand side is </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++N%5E2+%2B+2%7Cc%7C+N+%2B+%7Cc%7C%5E2+%2B+%5Cvarepsilon+%7Cc%7C+%2B+O%281%2FN%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++N%5E2+%2B+2%7Cc%7C+N+%2B+%7Cc%7C%5E2+%2B+%5Cvarepsilon+%7Cc%7C+%2B+O%281%2FN%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++N%5E2+%2B+2%7Cc%7C+N+%2B+%7Cc%7C%5E2+%2B+%5Cvarepsilon+%7Cc%7C+%2B+O%281%2FN%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  N^2 + 2|c| N + |c|^2 + \varepsilon |c| + O(1/N)"></p><p>
 and the left-hand side similarly evaluates to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2c%2B1%7D+d_i%29+%2B+N%5E2+-k%5E2+%2B+2%7Cc%7C+N+%2B+%7Cc%7C%5E2+%2B+O%281%2FN%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2c%2B1%7D+d_i%29+%2B+N%5E2+-k%5E2+%2B+2%7Cc%7C+N+%2B+%7Cc%7C%5E2+%2B+O%281%2FN%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2c%2B1%7D+d_i%29+%2B+N%5E2+-k%5E2+%2B+2%7Cc%7C+N+%2B+%7Cc%7C%5E2+%2B+O%281%2FN%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle (\sum_{i=1}^{k^2+2c+1} d_i) + N^2 -k^2 + 2|c| N + |c|^2 + O(1/N)"></p><p>
 and so we simplify to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i+%5Cleq+k%5E2+%2B+%5Cvarepsilon+%7Cc%7C+%2B+O%281%2FN%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i+%5Cleq+k%5E2+%2B+%5Cvarepsilon+%7Cc%7C+%2B+O%281%2FN%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5E%7Bk%5E2%2B2%5Cvarepsilon+%7Cc%7C%2B1%7D+d_i+%5Cleq+k%5E2+%2B+%5Cvarepsilon+%7Cc%7C+%2B+O%281%2FN%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle \sum_{i=1}^{k^2+2\varepsilon |c|+1} d_i \leq k^2 + \varepsilon |c| + O(1/N)."></p><p>
 Sending <img src="https://s0.wp.com/latex.php?latex=%7BN+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BN+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BN+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{N \rightarrow \infty}">, we obtain the claim. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\Box"></p><p>
One striking feature of this story for me is how important it was to have a diverse set of people, literature, and tools to attack this problem.  To be able to state and prove the precise formula for <img src="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c(n)}"> required multiple observations, including some version of the following:
</p><ul>
<li> The sequence can be numerically computed as a sequence of rational numbers.
</li><li> When appropriately normalized and arranged, visible patterns in this sequence appear that allow one to conjecture the form of the sequence.
</li><li> This problem is a weighted version of the Erd≈ës-Szekeres theorem.
</li><li> Among the many proofs of the Erd≈ës-Szekeres theorem is the proof of Seidenberg in 1959, which can be interpreted as a discrete rectangle packing argument.
</li><li> This problem can be reinterpreted as a continuous square packing problem, and in fact is closely related to (a generalized axis-parallel form of) Erd≈ës problem 106, which concerns such packings.
</li><li> The axis-parallel form of Erd≈ës problem 106 was recently solved by Baek-Koizumi-Ueoro.
</li><li> The paper of Praton shows that Erd≈ës Problem 106 implies the generalized version needed for this problem.  This implication specializes to the axis-parallel case.
</li></ul><p>
It was only through the combined efforts of all the contributors and their tools that all these key inputs were able to be assembled within 48 hours.  It seems plausible that a more traditional effort involving just one or two mathematicians and simpler programming and literature search tools may eventually have been able to put all these pieces together, but I believe this process would have taken much longer (on the order of weeks or even months).
</p><p>
Another key ingredient was the <a href="https://www.erdosproblems.com/forum/">balanced AI policy</a> on the Erd≈ës problem website, which encourages disclosed AI usage while strongly discouraging undisclosed use.  To quote from that policy: ‚ÄúComments prepared with the assistance of AI are permitted, provided (a) this is disclosed, (b) the contents (including mathematics, code, numerical data, and the existence of relevant sources) have been carefully checked and verified by the user themselves without the assistance of AI, and (c) the comment is not unreasonably long.‚Äù</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sharp (474 pts)]]></title>
            <link>https://apple.github.io/ml-sharp/</link>
            <guid>46284658</guid>
            <pubDate>Tue, 16 Dec 2025 04:06:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apple.github.io/ml-sharp/">https://apple.github.io/ml-sharp/</a>, See on <a href="https://news.ycombinator.com/item?id=46284658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div rel="icon" type="image/x-icon" href="thumbnails/favicon.ico">
    

    <!-- jQuery and TwentyTwenty -->
    
    
    

    <!-- Bootstrap JS -->
    


    

    

    
    


    


    <!-- Fixed Top Navbar -->
    <nav>
        
    </nav>

    <!-- Header Section -->
    <div>
        

        <p>
            Lars Mescheder, Wei Dong, Shiwei Li, Xuyang Bai, Marcel Santos, Peiyun Hu, Bruno Lecouat, Mingmin Zhen,
        </p>
        <p>
            Ama√´l Delaunoy, Tian Fang, Yanghai Tsin, Stephan R. Richter, Vladlen Koltun
        </p>
        <p>Apple</p>

        
    </div>

    <!-- Abstract Section -->
    <div id="abstract">
        <h2>Abstract</h2>
        <p>We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25‚Äì34% and DISTS by 21‚Äì43% versus the best prior model, while lowering the synthesis time by three orders of magnitude.</p>

        <div>
            
            <div>
                <p>Views synthesized by SHARP</p>
            </div>
            <p><img src="https://apple.github.io/ml-sharp/teaser.jpg" alt="SHARP">
            </p>
        </div>
        <p><small>SHARP synthesizes a photorealistic 3D representation from a single photograph in less
than a second. The synthesized representation supports high-resolution rendering of nearby views,
with sharp details and fine structures, at more than 100 frames per second on a standard GPU. We
illustrate on photographs from <a href="https://unsplash.com/" target="_blank">Unsplash</a>.</small></p>
    </div>

    <!-- Comparison Section -->
    <div id="videos">
        <h2>Video Comparisons</h2>

        <!-- Dataset Navigation Bar -->
        

        <!-- Dataset Content Areas -->
        <div id="content-Unsplash">
                    <p>Select a video to compare</p>
                </div>
        <div id="content-ETH3D">
                    <p>Select a video to compare</p>
                </div>
        <div id="content-Middlebury">
                    <p>Select a video to compare</p>
                </div>
        <div id="content-ScanNetPP">
                    <p>Select a video to compare</p>
                </div>
        <div id="content-TanksAndTemples">
                    <p>Select a video to compare</p>
                </div>
        <div id="content-Booster">
                    <p>Select a video to compare</p>
                </div>
        <div id="content-WildRGBD">
                    <p>Select a video to compare</p>
                </div>

    </div>

    <!-- Citation -->
    <div id="citation">
        <h2>Citation</h2>
        <div>
                <pre><code>@inproceedings{Sharp2025:arxiv,
  title      = {Sharp Monocular View Synthesis in Less Than a Second},
  author     = {Lars Mescheder and Wei Dong and Shiwei Li and Xuyang Bai and Marcel Santos and Peiyun Hu and Bruno Lecouat and Mingmin Zhen and Ama\"{e}l Delaunoyand Tian Fang and Yanghai Tsin and Stephan R. Richter and Vladlen Koltun},
  journal    = {arXiv preprint arXiv:2512.10685},
  year       = {2025},
  url        = {https://arxiv.org/abs/2512.10685},
}</code></pre>
            </div>
    </div>

    <!-- Footer -->
    



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[8M Users' AI Conversations Sold for Profit by "Privacy" Extensions (742 pts)]]></title>
            <link>https://www.koi.ai/blog/urban-vpn-browser-extension-ai-conversations-data-collection</link>
            <guid>46284266</guid>
            <pubDate>Tue, 16 Dec 2025 03:03:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.koi.ai/blog/urban-vpn-browser-extension-ai-conversations-data-collection">https://www.koi.ai/blog/urban-vpn-browser-extension-ai-conversations-data-collection</a>, See on <a href="https://news.ycombinator.com/item?id=46284266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="blog-rich-text"><p>A few weeks ago, I was wrestling with a major life decision. Like I've grown used to doing, I opened Claude and started thinking out loud-laying out the options, weighing the tradeoffs, asking for perspective.</p><p>Midway through the conversation, I paused. I realized how much I'd shared: not just this decision, but months of conversations-personal dilemmas, health questions, financial details, work frustrations, things I hadn't told anyone else. I'd developed a level of candor with my AI assistant that I don't have with most people in my life.</p><p>And then an uncomfortable thought: <em>what if someone was reading all of this?</em></p><p>The thought didn't let go. As a security researcher, I have the tools to answer that question.</p><h2>The Discovery</h2><p>We asked Wings, our agentic-AI risk engine, to scan for browser extensions with the capability to read and exfiltrate conversations from AI chat platforms. We expected to find a handful of obscure extensions-low install counts, sketchy publishers, the usual suspects.</p><p>The results came back with something else entirely.</p><p>Near the top of the list: Urban VPN Proxy. A Chrome extension with over 6 million users. A 4.7-star rating from 58,000 reviews. A "Featured" badge from Google, meaning it had passed manual review and met what Google describes as "a high standard of user experience and design."</p><p>A free VPN promising privacy and security. Exactly the kind of tool someone installs when they <em>want</em> to protect themselves online.</p><p>We decided to look closer.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693ff195f1d7b63502effd1e_Screenshot%202025-12-15%20at%2013.31.18.png" loading="lazy" alt=""></p><figcaption>Featured by Google and trusted by </figcaption></figure><h2>What We Found</h2><p>Urban VPN Proxy targets conversations across ten AI platforms:</p><ul role="list"><li>ChatGPT</li><li>Claude</li><li>Gemini</li><li>Microsoft Copilot</li><li>Perplexity</li><li>DeepSeek</li><li>Grok (xAI)</li><li>Meta AI</li></ul><p>For each platform, the extension includes a dedicated "executor" script designed to intercept and capture conversations. The harvesting is enabled by default through hardcoded flags in the extension's configuration:</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693fef0f1b7f857557a057d3_4ad668a3.png" loading="lazy" alt=""></p></figure><p>There is no user-facing toggle to disable this. The only way to stop the data collection is to uninstall the extension entirely.</p><h2>How It Works</h2><p>The data collection operates independently of the VPN functionality. Whether the VPN is connected or not, the harvesting runs continuously in the background.</p><p>Here's the technical breakdown:</p><p><strong>1. Script injection into AI platforms</strong></p><p>The extension monitors your browser tabs. When you visit any of the targeted AI platforms (ChatGPT, Claude, Gemini, etc.), it injects an "executor" script directly into the page. Each platform has its own dedicated script - chatgpt.js, claude.js, gemini.js, and so on.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693ff72f55ecbf372877dfb9_Screenshot%202025-12-15%20at%2013.53.14.png" loading="lazy" alt=""></p></figure><p><strong>2. Overriding native browser functions</strong></p><p>Once injected, the script overrides fetch() and XMLHttpRequest - the fundamental browser APIs that handle all network requests. This is an aggressive technique. The script wraps the original functions so that every network request and response on that page passes through the extension's code first.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693fef0f1b7f857557a057d6_7434cbb2.png" loading="lazy" alt=""></p></figure><p>This means when Claude sends you a response, or when you submit a prompt to ChatGPT, the extension sees the raw API traffic before your browser even renders it.</p><p><strong>3. Parsing and packaging</strong></p><p>The injected script parses the intercepted API responses to extract conversation data - your prompts, the AI's responses, timestamps, conversation IDs. This data is packaged and sent via window.postMessage to the extension's content script, tagged with the identifier PANELOS_MESSAGE.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693ff3a71f7146ad752378a6_Screenshot%202025-12-15%20at%2013.39.44.png" loading="lazy" alt=""></p></figure><p><strong>4. Exfiltration via background worker</strong></p><p>The content script forwards the data to the extension's background service worker, which handles the actual exfiltration. The data is compressed and transmitted to Urban VPN's servers at endpoints including analytics.urban-vpn.com and stats.urban-vpn.com.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693ff74713aa0b4d80bb93b1_Screenshot%202025-12-15%20at%2013.52.35.png" loading="lazy" alt=""></p></figure><p><strong>What gets captured:</strong></p><ul role="list"><li>Every prompt you send to the AI</li><li>Every response you receive</li><li>Conversation identifiers and timestamps</li><li>Session metadata</li><li>The specific AI platform and model used</li></ul><h2>The Timeline</h2><p>The AI conversation harvesting wasn't always there. Based on our analysis:</p><ul role="list"><li><strong>Before version 5.5.0</strong>: No AI harvesting functionality</li><li><strong>July 9, 2025</strong>: Version 5.5.0 released with AI harvesting enabled by default</li><li><strong>July 2025 - Present</strong>: All user conversations with targeted AI platforms captured and exfiltrated</li></ul><p>Chrome and Edge extensions auto-update by default. Users who installed Urban VPN for its stated purpose - VPN functionality - woke up one day with new code silently harvesting their AI conversations.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/693ffff7ef3550b5233c6773_Screenshot%202025-12-15%20at%2014.32.32.png" loading="lazy" alt=""></p><figcaption>Koidex report for Urban VPN Proxy</figcaption></figure><p>Anyone who used ChatGPT, Claude, Gemini, or the other targeted platforms while Urban VPN was installed after July 9, 2025 should assume those conversations are now on Urban VPN's servers and have been shared with third parties. Medical questions, financial details, proprietary code, personal dilemmas - all of it, sold for "marketing analytics purposes."</p><h2>What "AI Protection" Actually Does</h2><p>Urban VPN's Chrome Web Store listing promotes "AI protection" as a feature:</p><p>"Advanced VPN Protection - Our VPN provides added security features to help shield your browsing experience from phishing attempts, malware, intrusive ads and AI protection which checks prompts for personal data (like an email or phone number), checks AI chat responses for suspicious or unsafe links and displays a warning before click or submit your prompt."</p><p>The framing suggests the AI monitoring exists to <em>protect</em> you-checking for sensitive data you might accidentally share, warning you about suspicious links in responses.</p><p>The code tells a different story. The data collection and the "protection" notifications operate independently. Enabling or disabling the warning feature has no effect on whether your conversations are captured and exfiltrated. The extension harvests everything regardless.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/6940043002b9b0e7d938b3ac_1765802302699.jpeg" loading="lazy" alt=""></p><figcaption>"And that, Doctor, is why I have trust issues"</figcaption></figure><p>The protection feature shows occasional warnings about sharing sensitive data with AI companies. The harvesting feature sends that exact sensitive data - and everything else - to Urban VPN's own servers, where it's sold to advertisers. The extension warns you about sharing your email with ChatGPT while simultaneously exfiltrating your entire conversation to a data broker.</p><h2>It Gets Worse</h2><p>After documenting Urban VPN Proxy's behavior, we checked whether the same code existed elsewhere.</p><p>It did. The identical AI harvesting functionality appears in seven other extensions from the same publisher, across both Chrome and Edge:</p><p><strong>Chrome Web Store:</strong></p><ul role="list"><li>Urban VPN Proxy - 6,000,000 users</li><li>1ClickVPN Proxy - 600,000 users</li><li>Urban Browser Guard - 40,000 users</li><li>Urban Ad Blocker - 10,000 users</li></ul><p><strong>Microsoft Edge Add-ons:</strong></p><ul role="list"><li>Urban VPN Proxy - 1,323,622 users</li><li>1ClickVPN Proxy - 36,459 users</li><li>Urban Browser Guard - 12,624 users</li><li>Urban Ad Blocker - 6,476 users</li></ul><p><strong>Total affected users: Over 8 million.</strong></p><p>The extensions span different product categories, a VPN, an ad blocker, a "browser guard" security tool, but share the same surveillance backend. Users installing an ad blocker have no reason to expect their Claude conversations are being harvested.</p><p>All of these extensions carry "Featured" badges from their respective stores, except Urban Ad Blocker for Edge. These badges signal to users that the extensions have been reviewed and meet platform quality standards. For many users, a Featured badge is the difference between installing an extension and passing it by - it's an implicit endorsement from Google and Microsoft.</p><h2>Who's Behind This</h2><p>Urban VPN is operated by Urban Cyber Security Inc., which is affiliated with BiScience (B.I Science (2009) Ltd.), a data broker company.</p><p>This company has been on researchers' radar before. Security researchers <a href="https://palant.info/2025/01/13/biscience-collecting-browsing-history-under-false-pretenses/">Wladimir Palant</a> and John Tuckner at <a href="https://secureannex.com/blog/sclpfybn-moneitization-scheme/">Secure Annex</a> have previously documented BiScience's data collection practices. Their research established that:</p><ul role="list"><li>BiScience collects clickstream data (browsing history) from millions of users</li><li>Data is tied to persistent device identifiers, enabling re-identification</li><li>The company provides an SDK to third-party extension developers to collect and sell user data</li><li>BiScience sells this data through products like AdClarity and Clickstream OS</li></ul><p>Our finding represents an expansion of this operation. BiScience has moved from collecting browsing history to harvesting complete AI conversations-a significantly more sensitive category of data.</p><p>The privacy policy confirms the data flow:</p><p>"We share the Web Browsing Data with our affiliated company... BiScience that uses this raw data and creates insights which are commercially used and shared with Business Partners"</p><h2>The Disclosure Problem</h2><p>To be fair, Urban VPN does disclose some of this-if you know where to look.</p><p><strong>The consent prompt</strong> (shown during extension setup) mentions that the extension processes "ChatAI communication" along with "pages you visit" and "security signals." It states this is done "to provide these protections."</p><p>[Screenshot: Urban VPN consent prompt]</p><p><strong>The privacy policy</strong> goes further, buried deep in the document:</p><p>"AI Inputs and Outputs. As part of the Browsing Data, we will collect the prompts and outputs queried by the End-User or generated by the AI chat provider, as applicable."</p><p>And:</p><p>"We also disclose the AI prompts for marketing analytics purposes."</p><p><strong>However, the Chrome Web Store listing</strong>-the place where users actually decide whether to install-shows a different picture:</p><p>"This developer declares that your data is Not being sold to third parties, outside of the approved use cases"</p><p>The listing mentions the extension handles "Web history" and "Website content." It says nothing about AI conversations specifically.</p><p><strong>The contradictions are significant:</strong></p><ol role="list"><li>The consent prompt frames AI monitoring as protective. The privacy policy reveals the data is sold for marketing.</li><li>The store listing says data isn't sold to third parties. The privacy policy describes sharing with BiScience, "Business Partners," and use for "marketing analytics."</li><li>Users who installed before July 2025 never saw the updated consent prompt-the AI harvesting was added via silent update in version 5.5.0.</li><li>Even users who see the consent prompt have no granular control. You can't accept the VPN but decline the AI harvesting. It's all or nothing.</li><li>Nothing indicates to users that the data collection continues even when the VPN is disconnected and the AI protection feature is turned off. The harvesting runs silently in the background regardless of what features the user has enabled.</li></ol><h2>Google's Role</h2><p>Urban VPN Proxy carries Google's "Featured" badge on the Chrome Web Store. According to Google's documentation:</p><p>"Featured extensions follow our technical best practices and meet a high standard of user experience and design."</p><p>"Before it receives a Featured badge, the Chrome Web Store team must review each extension."</p><p>This means a human at Google reviewed Urban VPN Proxy and concluded it met their standards. Either the review didn't examine the code that harvests conversations from Google's own AI product (Gemini), or it did and didn't consider this a problem.</p><p>The Chrome Web Store's Limited Use policy explicitly prohibits "transferring or selling user data to third parties like advertising platforms, data brokers, or other information resellers." BiScience is, by its own description, a data broker.</p><p>The extension remains live and featured as of this writing.</p><h2>Final Thoughts</h2><p>Browser extensions occupy a unique position of trust. They run in the background, have broad access to your browsing activity, and auto-update without asking. When an extension promises privacy and security, users have little reason to suspect it's doing the opposite.</p><p>What makes this case notable isn't just the scale - 8 million users - or the sensitivity of the data - complete AI conversations. It's that these extensions passed review, earned Featured badges, and remained live for months while harvesting some of the most personal data users generate online. The marketplaces designed to protect users instead gave these extensions their stamp of approval.</p><p>If you have any of these extensions installed, uninstall them now. Assume any AI conversations you've had since July 2025 have been captured and shared with third parties.</p><p>This writeup was authored by the research team at Koi.</p><p>We built Koi to detect exactly these kinds of threats - extensions that slip past marketplace reviews and quietly exfiltrate sensitive data. Our risk engine, Wings, continuously monitors browser extensions to catch threats before they reach your team.</p><p><a href="https://www.koi.ai/get-a-demo"><strong>Book a demo</strong></a> to see how behavioral analysis catches what static review misses.</p><p>Stay safe out there.</p><h2>IOCs</h2><p><strong>Chrome:</strong></p><ul role="list"><li>Urban VPN Proxy: eppiocemhmnlbhjplcgkofciiegomcon</li><li>Urban Browser Guard: almalgbpmcfpdaopimbdchdliminoign</li><li>Urban Ad Blocker: feflcgofneboehfdeebcfglbodaceghj</li><li>1ClickVPN Proxy for Chrome: pphgdbgldlmicfdkhondlafkiomnelnk</li></ul><p><strong>Edge:</strong></p><ul role="list"><li>Urban VPN Proxy: nimlmejbmnecnaghgmbahmbaddhjbecg</li><li>Urban Browser Guard: jckkfbfmofganecnnpfndfjifnimpcel</li><li>Urban Ad Blocker: gcogpdjkkamgkakkjgeefgpcheonclca</li><li>1ClickVPN Proxy for Edge: deopfbighgnpgfmhjeccdifdmhcjckoe</li></ul><p>‚Äç</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ideas aren't getting harder to find (118 pts)]]></title>
            <link>https://asteriskmag.com/issues/12-books/ideas-arent-getting-harder-to-find</link>
            <guid>46283129</guid>
            <pubDate>Tue, 16 Dec 2025 00:34:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/12-books/ideas-arent-getting-harder-to-find">https://asteriskmag.com/issues/12-books/ideas-arent-getting-harder-to-find</a>, See on <a href="https://news.ycombinator.com/item?id=46283129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<div data-mode="add-marker">
		<p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
		
	</div>

	<section>
				
		 			<h2>
				   
					<span>Karthik Tadepalli</span>
							</h2>
			</section>
	
			<section id="rangyscope">
					<p>For half a decade we‚Äôve been worrying that ideas are getting harder to find. In fact, they might just be harder to sell.</p>
				<div>
											<div><p>Fifty years ago, productivity growth in advanced economies began to slow down. Productivity growth ‚Äî the component of GDP growth that is not due to increases in labor and capital ‚Äî is the primary driver of rising incomes. When it slows, so does economic growth as a whole. This makes it an urgent trend to understand. Unfortunately, the most popular explanation for why it‚Äôs happening might be wrong.</p><p>The most widely endorsed reason productivity growth has faltered is that we are running out of good ideas. As this narrative has it, the many scientific and technology advances responsible for driving economic growth in the past were low-hanging fruit. Now the tree is more barren. Novel advances, we should expect, are harder to come by, and historical growth may thus be difficult to sustain. In the extreme, this may lead to the end of progress altogether.&nbsp;</p><p>This story began in 2020, with the publication of ‚ÄúAre Ideas Getting Harder to Find?,‚Äù by economists Nicholas Bloom and colleagues.<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
 Bloom et al. looked across many sectors, from agriculture to medicine to computing. In each field, productivity measures have grown at the same rate as before. This sounds like good news, except that the number of researchers in each of these fields has exploded. In other words, each researcher produces much less than they used to ‚Äî something you might expect if ideas really are getting harder to find.</p><p>The progress studies movement and the metascience community have risen, in part, in response to this challenge. Both seek ways to rethink how we do research: by making our research institutions more efficient or by increasing science funding.&nbsp;</p><p>But there's a growing body of evidence that suggests ideas are not, in fact, getting harder to find. Instead, the problem appears to be that markets have become less effective at translating breakthrough technologies into productivity gains. Researchers appear to be continuing to generate valuable innovations at historical rates. It‚Äôs just that these innovations face greater barriers to commercialization, and innovative firms thus fail to gain market share.&nbsp;</p><p>All this suggests that the constraint on growth isn‚Äôt in our universities or labs or R&amp;D departments, but in our markets.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/12-books/ideas-arent-getting-harder-to-find/6b4f03c1bc-1760993274/anagh-banerjee_tadepalli.png" alt="">
  </p>
    <p>
    Anagh Banerjee  </p>
  </figure>
</div>
											<p><h2>Why ideas matter</h2>
</p>
											<p>Historically, the task of growth theory has been to rationalize this graph:</p>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/12-books/ideas-arent-getting-harder-to-find/a2aa53682d-1760993327/tadepalli_01.png" alt="">
  </p>
  </figure>
</div>
											<div><p>Through two world wars, the Great Depression, the global financial crisis, and the Cold War, US real GDP per capita has grown steadily at 2% per year. This consistency is remarkable, so much so that it has motivated economists to search for a near-immutable source of economic growth: something fundamental that drives growth across long sweeps of time. Sure, growth can be affected in the short run by policies and events of the day ‚Äî tariffs, wars, demographic transitions, educational booms ‚Äî but it would be an incredible coincidence if the combined impact of every economic policy and external event in history happened to net out as a constant growth rate! So what could this immutable mechanism be?</p><p>It took economists decades to understand how sustained exponential growth is even possible. Exponential growth requires <em>increasing returns to scale</em> ‚Äî doubling all the inputs into production must more than double the scale of economic output. Why? Each year output has to be reinvested as capital to produce next year‚Äôs output. But there‚Äôs diminishing returns to capital alone, so each year a country would need to reinvest a larger fraction of its annual output to get the same growth rate. Eventually, it would need to reinvest more than 100% of its output, which is impossible. It is only through increasing returns to scale that we can counteract the diminishing returns to capital, allowing us to maintain exponential growth.</p><p>So it‚Äôs easy! We just posit increasing returns to scale in production, and we now have an explanation for why growth is exponential ‚Äî decades of research not necessary. The problem is that increasing returns to scale violates our basic intuitions. Imagine you own a factory that produces 100 cars a day. You create an exact duplicate of this factory in another city, with the same employees, same equipment. How many cars would you expect from both factories combined? The intuitive assumption is 200. Increasing returns demands that we can somehow get more than double the cars from creating the second factory ‚Äî which is hard to justify.&nbsp;</p><p>The economist Paul Romer won a Nobel Prize for resolving this puzzle: Increasing returns to scale comes from <em>ideas.</em> In his view, it is a mistake to think that the only inputs to the car factory are the workers and machines. There are also blueprints for the cars being produced, instructions for how the machines should be laid out, and the concept of an assembly line process to organize the workers.&nbsp;</p><p>Romer‚Äôs work elegantly solved the problem posed by our factory duplication thought experiment. In setting up the second factory, we needed only to duplicate the workers and the machines ‚Äî we didn‚Äôt need to duplicate the designs or the idea of an assembly line. Once created, ideas can be used in perpetuity, which is how we can double the factory‚Äôs output while doubling only its physical inputs. This key property of ideas ‚Äî that they can be used by everyone at the same time ‚Äî has become the fundamental explanation for exponential growth. This is why it matters so much if ideas truly are getting harder to find: If idea production is slowing down, it threatens the foundation that allows growth to continue.</p></div>
											<p><h2>The simple argument for declining idea productivity</h2>
</p>
											<div><p>To test whether our research efforts are getting less bang for their buck today than they did decades ago, Bloom et al. use a key feature that descends from Romer‚Äôs original model ‚Äî that productivity growth can be represented by the following equation:</p><p>Productivity growth = Research productivity * Number of researchers&nbsp;</p><p>Whether total factor productivity, or agricultural yields, or chip density, growth of any productivity measure should be a direct function of the number of researchers working in that sector and their research productivity. This means that if we observe productivity growth in any given sector, and we know the number of researchers working in that sector, we can infer research productivity.</p><p>Thus, the authors compile data on productivity growth and researcher counts across a number of different sectors to estimate whether research productivity has been falling, which according to the authors, means ideas must be getting harder to find.</p><p>Perhaps their most compelling evidence comes from Moore's Law, the famous observation that the number of transistors on a computer chip doubles roughly every two years. This doubling represents a constant 35% annual growth rate in chip density that has held for 50 years. On its face, Moore‚Äôs Law seems like a refutation of any diminishment in technological progress.&nbsp;</p><p>Yet maintaining the exponential growth in chip density has required exponential increases in effort. Bloom et al. compiled R&amp;D spending data from dozens of semiconductor firms over time and found that the effective number of researchers working to advance Moore's Law increased by a factor of 18 between 1971 and 2014. Meanwhile, the growth rate of chip density has stayed constant. Put differently, it takes 18 times as many researchers today to achieve the same rate of improvement in chip density as it did in the early 1970s. This implies that research productivity in semiconductors has fallen at an average rate of 7% per year.</p><p>Look at agricultural productivity and you see a similar pattern. The authors measure crop yield growth across major US crops. Between 1969 and 2009, yield growth for these crops averaged a steady 1.5% per year, but the research effort directed toward improving yields has grown by between sixfold and 24-fold, depending on the crop.&nbsp;</p><p>Zoom all the way out, and the pattern still holds. Across the economy as a whole, R&amp;D efforts have increased by a factor of 20 since the 1930s, yet productivity growth has become slower.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/12-books/ideas-arent-getting-harder-to-find/a6f539a080-1760993581/tadepalli_02.png" alt="">
  </p>
  </figure>
</div>
											<p>These results are unambiguous. Research effort has gone up, yet productivity growth is not budging. This seems like clear evidence that <em>something </em>about productivity growth is getting harder. But whether the problem is a lack of new ideas is much less obvious.</p>
											<p><h2>Measuring idea productivity directly</h2>
</p>
											<div><p>The idea-based growth model is successful as a simple description of how exponential growth could occur. The problem is we‚Äôve taken it too literally. Bloom et al. assume that idea production is the <em>only </em>factor behind productivity growth. For example, their agricultural case study uses crop yield growth as the sole variable for new ideas. This allows them to sidestep difficulties in defining ideas and measuring their impact, but it also rules out the possibility that factors other than ideas are the real reason yields are stagnating.</p><p>Imagine that agricultural R&amp;D spending <em>was</em> highly effective, and that in the past few decades it led to a stream of new seed varieties that were each higher-yield than the last. What if those seeds were not actually being purchased by farmers ‚Äî maybe because farmers were unaware that they existed or because adopting a new seed is risky? We would observe crop yields stagnating despite R&amp;D spending effectively creating more productive crops.&nbsp;</p><p>Bloom et al.‚Äôs measure of "ideas" combines actual research innovations <em>with other necessary conditions</em> for research innovations to translate into higher output. After being invented, technologies have to be successfully commercialized, marketed, and adopted at scale before they can have large effects on economic output. What if we‚Äôre still just as good at producing ideas, but we‚Äôve become much worse at capitalizing on them?&nbsp;</p><p>This is exactly the argument made by Teresa Fort and colleagues in a paper from April of this year: ‚ÄúGrowth Is Getting Harder to Find, Not Ideas.‚Äù<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
 Fort et al. use the census of firms linked to US patent filings to capture economy-wide invention, rather than focusing on sector-specific case studies. Most importantly, they measure idea production more directly, by estimating the relationship between R&amp;D spending and new patents rather than inferring idea production from firm growth. Since patents represent technologies that are novel enough to be given intellectual property protection, and also economically valuable enough to be worth patenting, they serve as a more direct measure of ‚Äúideas.‚Äù</p><p>Fort et al. find that, across firms, research expenditure today continues to be associated with a proportional increase in patents similar to the 1980s. They use a variety of measures to get at this, but the most transparent one is to measure the ratio between patents and R&amp;D expenditures for each firm. Doing this, they find that the average firm‚Äôs patent-to-R&amp;D ratio has actually <em>increased</em> by 50% since 1977 ‚Äî contrary to a story in which R&amp;D effort is becoming less effective. While there is enough variability in this ratio that Fort et al. can‚Äôt be confident that it has actually increased, we can certainly say that it hasn‚Äôt fallen in the way that Bloom et al. would predict.</p><p>The obvious question is whether these patents might represent less generative and useful ideas, something like more incremental advances than patents of the past. Maybe the low-hanging fruit really is gone, and new patents are capturing less useful ideas. Fort et al. address this issue by focusing on <em>breakthrough patents</em>, a measure of technological innovation defined by <a href="https://www.aeaweb.org/articles?id=10.1257/aeri.20190499">Kelly et al.</a>,<sup>
    <!-- <a id="fnref-3" href="#fn-3"> -->
    <span id="fnref-3">
        3    </span>
    <!-- </a> -->
</sup>
 and showing that their results still hold.</p><p>For a technology to count as a breakthrough, it must be generative ‚Äî technologies that come after must build on it. This idea is the basis for Kelly et al.‚Äôs measurement of a patent‚Äôs significance. They score a patent as breakthrough if its text is different from patents that came before it but similar to the text of patents that came after it. Patents that scored in the top 5% on this measure included the elevator, the typewriter, the telephone, and frozen foods ‚Äî giving us some assurance that this measure really selects high-quality technologies.&nbsp;</p><p>Fort et al. show that their results are not simply coming from more incremental patents over time. Not only has the number of patents filed per R&amp;D dollar increased, but the number of breakthrough patents per R&amp;D dollar has also increased. Firms produce three times more breakthrough patents per R&amp;D dollar than they did in 1977.</p><p>This analysis suggests that Bloom et al. jumped the gun by attributing the slowdown in productivity growth to declining research productivity. If you infer research productivity only from output growth, it‚Äôs hard to find. But if you look at new idea production through the lens of patent data, we appear to be as generative as ever. So&nbsp; there must be some other failure in translating new technologies into productivity growth. What could that be?</p></div>
											<p><h2>The fault in our markets</h2>
</p>
											<div><p>We now have a puzzle ‚Äî productivity growth is slowing down, yet the factor that we think of as the most important determinant of productivity growth is not. The way to resolve this is to let go of the view that ideas are the only factor that determine growth. Remember, the power of that view is its ability to explain growth in the <em>long run</em> ‚Äî to generate the graph of steady 2% growth over one and a half centuries of war, changes in trade policy, and wide political shifts. Various factors <em>can</em> absolutely drag down growth rates over shorter periods: Growth was visibly lower during the Great Depression, only recovering because of catch-up growth in the boom that followed World War II. Our challenge is to explain the slower growth over a longer period. There is mounting evidence that a factor more obvious than ‚Äúideas are harder to find‚Äù is responsible: specifically, a decline in market efficiency.&nbsp;</p><p>The first indication comes from Fort et al.‚Äôs analysis. In addition to focusing on breakthrough patents, Fort et al. consider a measure of patent value based on stock market returns from <a href="https://academic.oup.com/qje/article-abstract/132/2/665/3076284">Kogan et al.</a><sup>
    <!-- <a id="fnref-4" href="#fn-4"> -->
    <span id="fnref-4">
        4    </span>
    <!-- </a> -->
</sup>
 The authors estimate how much a (publicly traded) firm's stock price moves in response to a patent being granted and use this movement as a measure of how valuable the patent is. This measure is unique in that it doesn't capture only the value of the technology but also all factors that go into making a technology profitable for its inventors. So it is notable that contrary to their main results, Fort et al. find that the stock market value of the average patent has actually fallen over time. In other words, the market places lower commercial value on new technologies compared with before. Since the authors also show that the number of breakthrough patents per dollar has actually increased, this is puzzling ‚Äî somehow, firms are making better technologies than before but getting smaller rewards.</p><p>This result gels with a broader view in the productivity literature ‚Äî that the primary limitation on productivity growth is whether more productive firms can outcompete less productive firms. Intuitively, productivity across the economy is not just the simple average of each firm‚Äôs productivity; it‚Äôs the <em>market share-weighted</em> average of each firm‚Äôs productivity. This means that productivity growth across the economy relies not just on firms finding ways to produce new goods at lower costs (which is where ‚Äúideas‚Äù would help) ‚Äî it relies on the best firms being able to gain market share, to increase their contribution to aggregate productivity. This ability for better firms to compete is known as <em>allocative efficiency</em>.</p><p>So has allocative efficiency decreased in advanced economies, and can that explain the productivity slowdown? <a href="https://www.federalreserve.gov/econresdata/feds/2017/files/2017019pap.pdf">Decker et al.</a><sup>
    <!-- <a id="fnref-5" href="#fn-5"> -->
    <span id="fnref-5">
        5    </span>
    <!-- </a> -->
</sup>
 use the same census of US firms to show that it has. On average, each firm‚Äôs productivity has grown at the same rate as before, but less productive firms have actually <em>gained</em> market share over more productive firms. These two factors together can explain why productivity growth has slowed down. Firms have maintained their innovative capacity, but the market is much less rewarding of that innovative capacity than it has been in the past.&nbsp;</p><p>In the same spirit, <a href="https://static1.squarespace.com/static/57fa873e8419c230ca01eb5f/t/5cd4b2adeef1a1ea927999e5/1557443247932/AA_fin.pdf">Akcigit and Ates</a><sup>
    <!-- <a id="fnref-6" href="#fn-6"> -->
    <span id="fnref-6">
        6    </span>
    <!-- </a> -->
</sup>
 argue that the most important factor behind the fall in allocative efficiency<sup>
    <!-- <a id="fnref-7" href="#fn-7"> -->
    <span id="fnref-7">
        7    </span>
    <!-- </a> -->
</sup>
 is a drop in the rate at which lagging firms catch up to leader firms in an industry.<sup>
    <!-- <a id="fnref-8" href="#fn-8"> -->
    <span id="fnref-8">
        8    </span>
    <!-- </a> -->
</sup>
 They consider several possible factors that could influence how dynamic the economy is ‚Äî corporate taxes, R&amp;D subsidies, entry costs, and catch-up rates for lagging firms ‚Äî and analyze which of them is most responsible for falling allocative efficiency. They find that almost all of the decline in allocative efficiency is explained by lagging firms failing to catch up. This tells us that the problem of declining allocative efficiency has a rather specific form: Less productive firms stay on as market leaders, while more productive firms are unable to catch up.</p><p>This is a puzzle! Why would the market fail to reward innovative firms, or, conversely, why does it continue rewarding less innovative firms? Unfortunately, here we don‚Äôt have clear answers. It could be that incumbent firms leverage market power to prevent innovative competitors from gaining market share. Perhaps regulatory barriers make it harder for new entrants to compete with incumbents. Financial markets may also have become less effective at identifying and funding high-potential firms. Answering this question is going to be central to addressing the productivity slowdown and should be a major focus for progress studies.</p></div>
											<p><h2>Progress studies needs to go to market</h2>
</p>
											<div><p>The distinction between ‚Äúideas are getting harder to find‚Äù and ‚Äúgrowth is getting harder to achieve‚Äù changes what we should focus on to accelerate progress. If the source of slowing growth was actually that each new scientific or technological breakthrough requires exponentially more effort, then progress-oriented thinkers would be right to focus on science funding, peer review, and the culture of scientific research.&nbsp;</p><p>However if ideas remain as discoverable as ever, but their economic impact is fading, then we need to look downstream from the laboratory. The decline in allocative efficiency should be more of a main focus ‚Äî we need to throw more of our intellectual capital at understanding how to increase competitiveness and the market potential for innovative firms and technologies, in the same way that we've focused on understanding how to make better technologies.</p><p>The narrative that "ideas are getting harder to find" has profoundly shaped how economists and policymakers think about innovation and growth. It implies we're fighting against some fundamental law of diminishing returns in human creativity. But what we‚Äôre actually fighting against is a flaw in our markets that prevents that creativity from being rewarded economically. If we want to restore growth, we should stop worrying about whether we've picked all the low-hanging fruit and start taking that fruit to market.</p></div>
										 
				</div>
		
	</section>
	 	
	 	<section>            
		<p>
			Published 		</p>
		
		<p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>		                        
	</section>	
	
	<!--end published content, not coming soon-->

	<!--tags-->
	 
	
	  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quill OS ‚Äì an open-source, fully-functional standalone OS for Kobo eReaders (411 pts)]]></title>
            <link>https://quill-os.org/</link>
            <guid>46283016</guid>
            <pubDate>Tue, 16 Dec 2025 00:22:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quill-os.org/">https://quill-os.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46283016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<h2>Quill OS is an open-source, fully-functional standalone OS for Rakuten Kobo's eReaders.</h2>
			<img src="https://quill-os.org/assets/screenshots/home-2.png" width="600" height="800" alt="Quill OS">
			<p><b>Here are some of Quill OS' features:</b>
				</p><p>
					Fully integrated KoBox X11 subsystem
					<br>ePUB, PDF, picture and plain text display support
					<br>Versatile configuration options for reading
					<br>muPDF rendering engine for ePUBs and PDFs
					<br>Wi-Fi support and web browser
					<br>Encrypted storage with EncFS
					<br>Fast dictionary &amp; local storage search
					<br>Dark mode
					<br>Full factory reset option if needed
					<br>Seamless update process
					<br>VNC viewer app
					<br>Search function
					<br>10 built-in fonts
					<br>Auto-suspend
					<br>Lock screen/passcode
					<br>User-friendly experience
				</p>
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JetBlue flight averts mid-air collision with US Air Force jet (358 pts)]]></title>
            <link>https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/</link>
            <guid>46281944</guid>
            <pubDate>Mon, 15 Dec 2025 22:48:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/">https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/</a>, See on <a href="https://news.ycombinator.com/item?id=46281944">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Economics of Orbital vs. Terrestrial Data Centers (176 pts)]]></title>
            <link>https://andrewmccalip.com/space-datacenters</link>
            <guid>46281288</guid>
            <pubDate>Mon, 15 Dec 2025 21:56:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrewmccalip.com/space-datacenters">https://andrewmccalip.com/space-datacenters</a>, See on <a href="https://news.ycombinator.com/item?id=46281288">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <!-- Header -->
        

        <!-- Introduction -->
        <section>
            <p>
                Before we get nerd sniped by the shiny engineering details, ask the only question that matters. 
                Why compute in orbit? Why should a watt or a flop 250 miles up be more valuable than one on the 
                surface? What advantage justifies moving something as mundane as matrix multiplication into LEO?
            </p>
            <p>
                That "why" is almost missing from the public conversation. People jump straight to hardware and 
                hand-wave the business case, as if the economics are self-evident. They aren't. A lot of the 
                energy here is FOMO and aesthetic futurism, not a grounded value proposition.
            </p>
            <p>
                <strong>Note:</strong> This page is built from publicly available information and first-principles modeling. No proprietary data. These are my personal thoughts and do not represent the views of any company or organization.
            </p>
        </section>

        <!-- Mobile Comparison Grid (shows only on smaller screens) -->
        <div>
                <!-- Orbital Column -->
                <div>
                        <p><span>Cost per Watt</span><span id="orbital-cpw-mobile">$31.20/W</span></p>
                        <p><span title="Levelized Cost of Energy - total cost divided by energy produced">LCOE</span><span id="orbital-lcoe-mobile">$891/MWh</span></p>
                        <p><span title="Low Earth Orbit (~400-600 km altitude)">Mass to LEO</span><span id="orbital-mass-mobile">22.2M kg</span></p>
                    </div>
                <!-- Terrestrial Column -->
                <div>
                        <p><span>Cost per Watt</span><span id="terrestrial-cpw-mobile">$14.80/W</span></p>
                        <p><span title="Levelized Cost of Energy - total cost divided by energy produced">LCOE</span><span id="terrestrial-lcoe-mobile">$398/MWh</span></p>
                        <p><span title="Capital Expenditure - upfront infrastructure costs">Capex</span><span id="terrestrial-capex-cpw-mobile">$13.80/W</span></p>
                    </div>
            </div>

        <!-- Fixed Left Sidebar: Cost Comparison -->
        

        <!-- Sidebar Container (fixed position, right side) -->
        

        <!-- Engineering Parameters -->
        <section>
            <p>Engineering ¬∑ System Parameters</p>
            
            <!-- Shared Parameters (Full Width) -->
            

            <div>
                <!-- Orbital Parameters -->
                <div>
                    <div>
                        
                        <h4>Orbital Solar</h4>
                    </div>

                    

                    <div>
                        
                        
                        <p><span data-value="1">$1/W</span>
                            <span data-value="22">V2 Mini ($22)</span>
                            <span data-value="40">V1 ($32)</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="3">ISS (3)</span>
                            <span data-value="25">V1</span>
                            <span data-value="36.5">V2 Mini</span>
                            <span data-value="100">100</span>
                            <span data-value="500">500 W/kg</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="5">5 kW</span>
                            <span data-value="27">V2 Mini</span>
                            <span data-value="60">V3</span>
                            <span data-value="150">150</span>
                            <span data-value="500">500 kW</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="0.60">LEO (~60%)</span>
                            <span data-value="0.80">SSO (~80%)</span>
                            <span data-value="0.98">Terminator (~98%)</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="1">1% (shielded)</span>
                            <span data-value="6">6% (unshielded)</span>
                            <span data-value="12">12% (polar)</span>
                        </p>
                    </div>

                    

                    
                </div>

                <!-- Terrestrial Parameters - 5 Buckets from Report -->
                <div>
                    <div>
                        
                        <h4>Terrestrial (On-Site CCGT)</h4>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="10">$10 (Low)</span>
                            <span data-value="12.5">$12.50 (Rep)</span>
                            <span data-value="17">$17 (High)</span>
                        </p>
                        <div>
                            <p><span>Electrical</span><span>45%</span><span id="dc-electrical">$5.63/W</span></p>
                            <p><span>Mechanical</span><span>20%</span><span id="dc-mechanical">$2.50/W</span></p>
                            <p><span>Shell &amp; Core</span><span>17%</span><span id="dc-shell">$2.13/W</span></p>
                            <p><span>Fit-Out</span><span>8%</span><span id="dc-fitout">$1.00/W</span></p>
                            <p><span>Site/Civil</span><span>5%</span><span id="dc-site">$0.62/W</span></p>
                            <p><span>Gen. Cond./Fees</span><span>5%</span><span id="dc-fees">$0.62/W</span></p>
                        </div>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="1.45">$1.45 (Efficient)</span>
                            <span data-value="1.80">$1.80 (Typical)</span>
                            <span data-value="2.30">$2.30 (Complex)</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="6000">Best (~58%)</span>
                            <span data-value="7500">Average (~45%)</span>
                            <span data-value="9000">Older (~38%)</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="2">Permian</span>
                            <span data-value="5">Typical</span>
                            <span data-value="15">Constrained</span>
                        </p>
                    </div>

                    <div>
                        
                        
                        <p><span data-value="1.1">Best (1.1)</span>
                            <span data-value="1.3">Typical (1.3)</span>
                            <span data-value="1.5">Older (1.5)</span>
                        </p>
                    </div>
                </div>
            </div>

        </section>

        <!-- Engineering Outputs -->
        <div>
                <!-- Orbital Engineering Outputs -->
                <div>
                    <div>
                        
                        <h3>Orbital Solar</h3>
                    </div>
                    
                    <div>
                        <p><span>Satellite Count</span>
                            <span id="eng-orbital-sat-count">~37,000</span>
                        </p>
                        <p><span>GPU Margin (failures)</span>
                            <span id="eng-orbital-gpu-margin">+19.6%</span>
                        </p>
                        <p><span>Solar Margin (degr.)</span>
                            <span id="eng-orbital-solar-margin">+6.5%</span>
                        </p>
                        <p><span>Total Mass to LEO</span>
                            <span id="eng-orbital-mass">22.2M kg</span>
                        </p>
                        <p><span>Fleet Array Area</span>
                            <span id="eng-orbital-fleet-array">2.3 km¬≤</span>
                        </p>
                        <p><span>Single Sat Array</span>
                            <span id="eng-orbital-sat-array">116 m¬≤</span>
                        </p>
                        <p><span>Starship Launches</span>
                            <span id="eng-orbital-launches">~222</span>
                        </p>
                        
                        <p><span>Methane Required</span>
                            <span id="eng-orbital-methane">168M gal</span>
                        </p>
                        <p><span>Energy Output</span>
                            <span id="eng-orbital-energy">35.0 MWhr</span>
                        </p>
                    </div>
                </div>

                <!-- Terrestrial Engineering Outputs (On-Site CCGT) -->
                <div>
                    <div>
                        
                        <h3>Terrestrial</h3>
                    </div>
                    
                    <div>
                        <p><span>H-Class Turbines</span>
                            <span id="eng-ngcc-turbines">3 units</span>
                        </p>
                        <p><span>Generation (IT√óPUE)</span>
                            <span id="eng-ngcc-generation">1.2 GW</span>
                        </p>
                        <p><span>Heat Rate</span>
                            <span id="eng-ngcc-heat-rate">6,200 BTU/kWh</span>
                        </p>
                        <p><span>Fuel Cost</span>
                            <span id="eng-ngcc-fuel-cost">$27/MWh</span>
                        </p>
                        <p><span>Capacity Factor</span>
                            <span id="eng-ngcc-capacity-factor">85%</span>
                        </p>
                        <p><span>Gas Consumption</span>
                            <span id="eng-ngcc-gas-consumption">279 BCF</span>
                        </p>
                        <p><span>Energy Output</span>
                            <span id="eng-ngcc-energy">37.2 MWhr</span>
                        </p>
                    </div>
                </div>
            </div>

        <!-- Model Assumptions (moved after Engineering Outputs) -->
        <div>
                <!-- Global -->
                <div>
                        <ul>
                            <li>GPUs not included‚Äîthis models everything upstream of compute hardware</li>
                            <li>Target capacity: <strong id="assumption-capacity">1 GW</strong> nameplate electrical</li>
                            <li>Analysis period: <strong id="assumption-years">5 years</strong></li>
                            <li>All figures in 2025 USD; excludes financing, taxes, incentives, and FMV</li>
                            <li>Full availability assumed (no downtime derates), no insurance/logistics overheads</li>
                        </ul>
                    </div>
                
                <!-- Orbital Solar -->
                <div>
                        <ul>
                            <li>Single bus class (Starlink V2 Mini heritage) scaled linearly to target power</li>
                            <li>Station-keeping propellant mass assumed rolled into Starlink-like specific power (W/kg)</li>
                            <li>Linear solar cell degradation assumed; actual silicon with coverglass shows steep-then-shallow curve</li>
                            <li>Solar margin = extra initial capacity to maintain average power over lifetime (not end-of-life)</li>
                            <li>GPU margin = cumulative expected failures over analysis period (replacement cost, not extra capacity)</li>
                            <li>Optimal fairing packing assumed regardless of satellite size (kW); no packing penalty modeled</li>
                            <li>No additional mass for liquid cooling loop infrastructure; likely needed but not included</li>
                            <li>All mass delivered to LEO; no on-orbit servicing/logistics</li>
                            <li>Launch pricing applied to total delivered mass; no cadence/manifest constraints modeled</li>
                            <li>Thermal: only solar array area used as radiator; no dedicated radiator mass assumed</li>
                            <li>Radiation/shielding impacts on mass ignored; no degradation of structures beyond panel aging</li>
                            <li>No disposal, de-orbit, or regulatory compliance costs included</li>
                            <li>Ops overhead and NRE treated as flat cost adders; no learning-curve discounts</li>
                            <li>No adjustments for permitting or regulatory delay</li>
                        </ul>
                    </div>
                
                <!-- Terrestrial -->
                <div>
                        <ul>
                            <li>On-site H-Class CCGT at the fence line; grid interconnect/transmission not costed</li>
                            <li>Capex buckets embed site prep/land; permitting, taxes, and financing excluded</li>
                            <li>Fuel price held flat; no carbon price, hedging, or escalation modeled</li>
                            <li>Water/cooling availability assumed; no scarcity or discharge penalties</li>
                            <li>Fixed PUE and capacity factor; no forced-outage or maintenance derates applied</li>
                            <li>No efficiency gains or technology learning assumed over time for terrestrial plant</li>
                            <li>No adjustments for permitting or regulatory delay</li>
                        </ul>
                    </div>
            </div>

        <!-- Full Essay -->
        <div>
                <h3>Motivation and Framing</h3>
                
                <p>
                    I love space. I live and breathe it. I'm lucky enough to brush the heavens with my own metal and code, and I want nothing more than a booming orbital space economy that creates the flywheel that makes space just another location we all work and visit. I love AI and I subscribe to maximum, unbounded scale. I want to make the biggest bets. I grew up half-afraid we'd never get another Apollo or Manhattan. I truly want the BigThing.
                </p>
                
                <p>
                    This is all to say that the current discourse is increasingly bothering me due to the lack of rigor; people are using back-of-the-envelope math, doing a terrible job of it, and only confirming whatever conclusion they already want. Calculating radiation and the cost of goods is not difficult. Run the numbers.
                </p>
                
                <p>
                    Before we do the classic engineer thing and get nerd sniped by all the shiny technical problems, it's worth asking the only question that matters: why put compute in orbit at all? Why should a watt or a flop be more valuable 250 miles up than on the surface? What economic or strategic advantage justifies the effort required to run something as ordinary as matrix multiplication in low Earth orbit?
                </p>
                
                <p>
                    That "why" is nearly missing from the public conversation. The "energy is cheaper, less regulations, infinite space" arguments just ring false compared to the mountains of challenges and brutal physics putting anything in space layers on. The discourse then skips straight to implementation, as if the business case is obvious.
                </p>
                
                <h3>Personal Positioning</h3>
                
                <p>
                    I'm not here to dunk on anyone building real hardware. Space is hard, and shipping flight systems is a credibility filter. I'm annoyed at everyone else. The conversation is full of confident claims built on one cherry-picked fact and zero arithmetic. This is a multivariable physics problem with closed-form constraints. If you're not doing the math, you're not contributing, you're adding noise and hyping for a future we all want instead of doing the hard work to actually drive reality forward.
                </p>
                
                <h3>Core Thesis</h3>
                
                <p>
                    The target I care about is simple: can you make space-based, commodity compute cost-competitive with the cheapest terrestrial alternative? That's the whole claim. Not "space is big." Not "the sun is huge." Not "launch will be cheap." Can you deliver useful watts and reject the waste heat at a price that beats a boring Crusoe-style tilt-wall datacenter tied into a 200‚Äì500 MW substation?
                </p>
                
                <p>
                    If you can't beat that, the rest is just vibes. GPUs are pretty darn happy living on the ground. They like cheap electrons, mature supply chains, and technicians who can swap a dead server in five minutes. Orbit doesn't get points for being cool. Orbit has to win on cost, or it has to admit it's doing something else entirely. If it's an existential humanity play, that's cool too, but it's a slightly different game.
                </p>
                
                <h3>Analytical Lens</h3>
                
                <p>
                    So here's what I did. I built a simple model that reduces the debate to one parameter: cost per watt of usable power for compute. The infographic below lets you change the assumptions directly. If you disagree with the inputs, great. Move the sliders. But at least we'll be arguing over numbers that map to reality.
                </p>
                
                <p>
                    The model is deliberately boring. No secret sauce. Just publicly available numbers and first-principles physics: solar flux, cell efficiency, radiator performance, launch cost, hardware mass, and a terrestrial benchmark that represents the real alternative: a tilt-wall datacenter sitting on top of cheap power. The code is public, please go through everything. <a href="https://github.com/andrewmccalip/thoughts" target="_blank">github.com/andrewmccalip/thoughts</a>
                </p>
                
                <h3>Findings and Implications</h3>
                
                <p>
                    Here's the headline result: it's not obviously stupid, and it's not a sure thing. It's actually more reasonable than my intuition thought! If you run the numbers honestly, the physics doesn't immediately kill it, but the economics are savage. It only gets within striking distance under aggressive assumptions, and the list of organizations positioned to even try that is basically one.
                </p>
                
                <p>
                    That "basically one" point matters. This isn't about talent. It's about integration. If you have to buy launch, buy buses, buy power hardware, buy deployment, and pay margin at every interface, you never get there. The margin stack and the mass tax eat you alive. Vertical integration isn't a nice-to-have. It's the whole ballgame.
                </p>
                
                <h3>Market and Incentives</h3>
                
                <p>
                    Which is why I trend positive on SpaceX here. If anyone can brute force a new industrial stack into existence, it's the team that can reduce $/kg and get as humanly close to free launch as possible. And they need to, because the economics are not close. This is not a 25% mismatch. It's 400%. Closing that is the whole job. Positive does not mean gullible. It needs measurable targets and painful reality checks.
                </p>
                
                <p>
                    If SpaceX ever goes public, this is exactly the kind of thing shareholders should demand: extreme, barely-achievable goalposts with clean measurement. Tesla did it with the options grant. Do the same here. Pay Elon a king's ransom if he delivers a new industrial primitive: cheap, sustained dollars per kilogram and dollars per watt in orbit, at real cadence, for years.
                </p>
                
                <h3>Broader Interpretation</h3>
                
                <p>
                    On strict near-term unit economics, this might still be a mediocre use of capital. A tilt-wall datacenter in Oregon with cheap power, cheap cooling, and technicians on call is hard to beat. Crusoe can park compute on stranded natural gas and turn it into flops with a supply chain that already exists.
                </p>
                
                <p>
                    But the knock-on effects are why this keeps pulling at people. If you can industrialize power and operations in orbit at meaningful scale, you're not just running GPUs. You're building a new kind of infrastructure that makes it easier for humans to keep spreading out. Compute is just one of the first excuses to pay for the scaffolding. Even if this is a mediocre trade on strict near-term unit economics, the second-order effects could be enormous.
                </p>
                
                <p>
                    I'll go one step further and say the quiet part out loud: we should be actively goading more billionaires into spending on irrational, high-variance projects that might actually advance civilization. I feel genuine secondhand embarrassment watching people torch their fortunes on yachts and status cosplay. No one cares about your Loro Piana. If you've built an empire, the best possible use of it is to burn its capital like a torch and light up a corner of the future. Fund the ugly middle. Pay for the iteration loops. Build the cathedrals. This is how we advance civilization.
                </p>
                
                <h3>Links to Reports</h3>
                
                <p>
                    Everyone is going to copy-paste this into the models, so I've done that part for you. It's a decent way to automate the sanity checks, but it could use more in-depth review.
                </p>
                
                <p>
                    <strong>GitHub:</strong> <a href="https://github.com/andrewmccalip/thoughts" target="_blank">github.com/andrewmccalip/thoughts</a>
                </p>
                
                <p><em>"Conduct a thorough, first-principles-based review of this project. Scrutinize every assumption and constant, rigorously fact-checking all data. The objective is to identify and correct any fundamental errors in logic or calculation."</em></p>
                
                <p>
                    <strong>Grok:</strong> <a href="https://grok.com/share/c2hhcmQtMi1jb3B5_aa668b65-35f1-4fd3-a6e8-e07fb5b18c23" target="_blank">grok.com/share/...</a><br>
                    <strong>ChatGPT:</strong> <a href="https://chatgpt.com/share/6848e0bd-f440-8005-9d83-f5eb6f4bcdd7" target="_blank">chatgpt.com/share/...</a><br>
                    <strong>Gemini:</strong> <a href="https://gemini.google.com/share/0404222bfea2" target="_blank">gemini.google.com/share/...</a><br>
                    <strong>Claude:</strong> <a href="https://claude.ai/public/artifacts/0a0d510c-9b9d-44dc-a647-8f82eb586cc4" target="_blank">claude.ai/public/artifacts/...</a>
                </p>
                
                <h3>Overall Conclusion</h3>
                
                <p>
                    Even so, irrational ambition doesn't get to ignore physics. The point of this page is to make the constraints explicit, so we can argue about reality instead of vibes. If the numbers close, even barely, then it's worth running hard on the idea. If they don't, the honest move is to say so and move on. Either way, I think some version of this has a feeling of inevitability.
                </p>
                
                <p>
                    So scroll down, play with the sliders, and try to break it. Change launch cost. Change lifetime. Change specific power. Change hardware cost. The goal here isn't to "win" an argument. It's to drag the conversation back to first principles: assumptions you can point at, and outputs you can sanity-check. Check out the GitHub, run the code, find the errors, and I'll update it live.
                </p>
                
                <p>
                    After that, we can do the fun part: thermal diagrams, radiator math, orbit beta angles, failure rates, comms geometry, all the shiny engineering details that make this topic so addicting. It's not obviously stupid, and it's not a sure thing. That's why it's worth doing the math.
                </p>
                
                <p><strong>It might not be rational. But it might be physically possible.</strong></p>
<!-- Warning Banner -->
                
                
                <h3>Technical Engineering Challenges</h3>
                
                <p>
                    The governing constraint for orbital compute is <strong>thermodynamics</strong>. Terrestrial datacenters leverage convective cooling‚Äîdumping waste heat into the atmosphere or water sources, effectively using the planet as an infinite cold reservoir. In the vacuum of space, convection is impossible. Heat rejection relies exclusively on radiation.
                </p>

                <p>
                    Every object in space settles to an equilibrium temperature where absorbed power equals radiated power. If heat generation exceeds radiative capacity, the temperature rises until the $T^4$ term in the Stefan-Boltzmann law balances the equation:
                </p><p>

                $$\dot{Q}_{\text{rad}} = \varepsilon \sigma A T^4$$

                </p><p>
                    The engineering challenge is ensuring this equilibrium temperature remains below the safe operating limits of silicon processors.
                </p>
                
                <h4>Energy Balance and Heat Rejection</h4>
                
                <p>
                    To dimension the radiator surface, we must account for the total thermal load managed by the satellite bus. In this model, based on a Starlink-style bifacial architecture (PV on front, radiator on back), the system must reject the aggregate energy of two distinct paths:
                </p>

                <ol>
                    <li><strong>Incident Solar Flux:</strong> The sun delivers $G_{\text{sc}} = 1361\;\text{W/m}^2$ (AM0). With a solar absorptivity $\alpha = 0.92$, the panel absorbs approximately $\sim 1250\;\text{W/m}^2$.</li>
                    <li><strong>Energy Partitioning:</strong>
                        <ul>
                            <li><strong>Electrical Path ($\sim$22%):</strong> High-efficiency cells convert $\sim 275\;\text{W/m}^2$ into electricity. This power drives the compute payload and is converted entirely back into heat by the processors. A liquid cooling loop collects this heat and returns it to the panel structure for rejection.</li>
                            <li><strong>Thermal Absorption ($\sim$78%):</strong> The remaining $\sim 975\;\text{W/m}^2$ is not converted to electricity but is absorbed immediately as lattice heat (phonon generation) within the panel structure.</li>
                        </ul>
                    </li>
                    <li><strong>Total Heat Load:</strong> The radiator must reject the sum of both the immediate thermal absorption and the returned electrical waste heat‚Äîeffectively <strong>100% of the absorbed solar flux</strong>.</li>
                </ol>

                <p>
                        This imposes a strict area density limit. High-power compute requires large collection areas, which inherently absorb large amounts of solar heat. The radiator must be sized to reject this aggregate load while maintaining an operating temperature below the junction limit.
                    </p>

                <h4>Operating Temperature Limits</h4>
                
                <p>
                    Modern AI accelerators (H100/B200 class) typically throttle at junction temperatures $T_j &gt; 85\text{‚Äì}100\degree\text{C}$. To maintain a junction at 85¬∞C, and accounting for the thermal gradient across cold plates and interface materials ($\Delta T \approx 10\degree\text{C}$), the radiator surface temperature $T_{\text{rad}}$ is constrained to approximately 75¬∞C.
                </p>

                <p>
                    The model below calculates the equilibrium temperature for a bifacial array in a terminator orbit ($\beta = 90^\circ$). It accounts for solar flux, Earth IR ($\sim 237\;\text{W/m}^2$), and albedo. If the calculated equilibrium temperature $T_{\text{eq}}$ exceeds the target radiator temperature, the design fails.
                </p>

                <!-- Thermal Balance Diagram -->
                <div>
                    <p>Thermal Balance ¬∑ Bifacial Panel Model</p>
                    
                    <!-- Energy Balance Equation - Above Diagram -->
                    <p><span>Steady-State Energy Balance</span>
                        <span>$\dot{Q}_{\text{sol}} + \dot{Q}_{\text{IR}} + \dot{Q}_{\text{alb}} + \dot{Q}_{\text{loop}} = \dot{Q}_{\text{rad,A}} + \dot{Q}_{\text{rad,B}}$</span>
                    </p>
                    
                    <div>
                            <div>
                                <p><span>Side A</span>
                                    <span>PV Array</span>
                                    <span><i>Œ±</i> = 0.92</span>
                                    <span><i>Œµ</i><sub>A</sub> = 0.85</span>
                                </p>
                                <p><span>Side B</span>
                                    <span>Radiator</span>
                                    <span><i>Œµ</i><sub>B</sub> = 0.90</span>
                                </p>
                            </div>
                            <p><span id="diagram-eq-temp">0¬∞C</span>
                                <span><i>T</i><sub>eq</sub></span>
                            </p>
                        </div>
                </div>

                <!-- Thermal Analysis Panel -->
                <div>
                    <p>Thermal Analysis ¬∑ Bifacial Panel Parameters</p>
                    <div>
                        <!-- Thermal Inputs -->
                        <div>
                            <div>
                                
                                <h3>Surface Properties</h3>
                            </div>

                            

                            

                            

                            

                             

                            <div>
                                
                                
                                <p><span data-value="400">400 km</span>
                                    <span data-value="550">550 (Starlink)</span>
                                    <span data-value="1200">1200 km</span>
                                </p>
                            </div>

                            

                            

                        </div>

                        <!-- Thermal Outputs -->
                        <div>
                            <div>
                                
                                <h3>Thermal Outputs</h3>
                            </div>

                            <div>
                                
                                <p><span><i>A</i> (panel area)</span>
                                    <span id="thermal-available-area">0.00 km¬≤</span>
                                </p>
                                <p><span><i>Œ≤</i> (orbit angle)</span>
                                    <span id="thermal-beta-angle">90¬∞</span>
                                </p>
                                <p><span><i>VF</i><sub>‚äï</sub></span>
                                    <span id="thermal-view-factor">0.080</span>
                                </p>
                                <p><span><i>Œµ</i><sub>tot</sub></span>
                                    <span id="thermal-total-emissivity">1.75</span>
                                </p>
                                
                                
                                <p><span><i>QÃá</i><sub>sol</sub> (solar waste)</span>
                                    <span id="thermal-q-solar">0 MW</span>
                                </p>
                                <p><span><i>QÃá</i><sub>IR</sub> (Earth thermal)</span>
                                    <span id="thermal-q-earth-ir">0 MW</span>
                                </p>
                                <p><span><i>QÃá</i><sub>alb</sub> (reflected)</span>
                                    <span id="thermal-q-albedo">0 MW</span>
                                </p>
                                <p><span><i>QÃá</i><sub>loop</sub> (GPU return)</span>
                                    <span id="thermal-q-heatloop">0 MW</span>
                                </p>
                                <p><span>Œ£<i>QÃá</i><sub>in</sub></span>
                                    <span id="thermal-total-heat-in">0 MW</span>
                                </p>
                                <p><span><i>P</i><sub>elec</sub> (generated)</span>
                                    <span id="thermal-power-generated">0 MW</span>
                                </p>
                                
                                
                                <p><span><i>T</i><sub>eq</sub></span>
                                    <span id="thermal-eq-temp">0.0 ¬∞C</span>
                                </p>
                                <p><span>Œî<i>T</i> margin</span>
                                    <span id="thermal-margin">0 ¬∞C</span>
                                    <span id="thermal-margin-badge">FAIL</span>
                                </p>
                                <p><span><i>A</i><sub>req</sub></span>
                                    <span id="thermal-required-area">0.00 km¬≤</span>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        <!-- Mobile References Section -->
        <section>
            <h2>References</h2>
            
        </section>

        <!-- Footer -->
        
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ford kills the All-Electric F-150 (408 pts)]]></title>
            <link>https://www.wired.com/story/ford-kills-electric-f-150-lightning-for-hybrid/</link>
            <guid>46281182</guid>
            <pubDate>Mon, 15 Dec 2025 21:46:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/ford-kills-electric-f-150-lightning-for-hybrid/">https://www.wired.com/story/ford-kills-electric-f-150-lightning-for-hybrid/</a>, See on <a href="https://news.ycombinator.com/item?id=46281182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="grid-wrapper" data-testid="ArticlePageChunks"><p><span>Ford is once</span> again shifting its electric vehicle manufacturing plans, a response to a year that‚Äôs been tough for the powertrain technology that‚Äôs still making waves overseas but has seen <a href="https://www.wired.com/story/5-big-ev-takeaways-one-big-beautiful-bill/">domestic government support cut</a> and <a href="https://www.wired.com/story/us-ev-sales-are-booming-not-great-for-evs/">customer enthusiasm weaken</a>.</p><p>Instead of planning to make enough electric vehicles to account for 40 percent of global sales by 2030‚Äîas it pledged just four years ago‚Äî<a href="https://www.wired.com/tag/ford/">Ford</a> says it will focus on a broader range of hybrids, extended-range electrics, and battery-electric models, which executives now say will account for 50 percent of sales by the end of the decade. The automaker will make hybrid versions of almost every vehicle in its lineup, the company says.</p><p>The company will no longer make a <a href="https://www.wired.com/story/this-is-why-high-end-electric-cars-are-failing/">large all-electric truck</a>, Ford executives told reporters Monday, and will repurpose an electric vehicle plant in Tennessee to build gas-powered cars. The next generation of Ford‚Äôs all-electric F-150 Lighting will instead be an extended-range electric vehicle, or EREV, a plug-in hybrid that uses an electric motor to power its wheels while a smaller gasoline engine recharges the battery. Ford says the tech, which <a href="https://www.wired.com/story/extended-range-electric-vehicles-erev/">automakers have touted in recent years as a middle-ground between battery-electric vehicles and gas-powered ones</a>, will give its truck extended towing capacity and a range of over 700 miles.</p><p>Ford still plans to produce a midsize electric pickup truck with a target starting price of about $30,000, to be available in 2027. That will be the first of the ‚Äúaffordable‚Äù electric vehicle models it‚Äôs currently designing at a skunkworks studio in California, which are slated to use a <a href="https://www.wired.com/story/fords-answer-to-china-a-completely-new-way-of-making-cars/">‚Äúuniversal‚Äù platform architecture that will make the vehicles cheaper to produce</a>.</p><p>The new plans leave Ford with a bunch of excess battery-making capacity, which the company says it will use by opening a whole new business: a battery energy-storage sideline. This new business will produce lower-cost and longer-living <a href="https://www.wired.com/story/gms-final-ev-battery-strategy-copies-chinas-playbook-super-cheap-cells/">lithium iron phosphate, or LFP, batteries</a> for customers in the public utility or data center industries.</p><p>‚ÄúFord is following the customer,‚Äù says Andrew Frick, the president of Ford Blue and Ford Model e, the automaker‚Äôs gas- and battery-powered vehicle businesses. US customer adoption of electric vehicles is not where the industry expected at decade‚Äôs start, he says. (Battery-electric vehicles currently make up about <a data-offer-url="https://www.spglobal.com/automotive-insights/en/blogs/2025/10/ev-adoption-rates-how-us-and-other-markets-compare-2025" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.spglobal.com/automotive-insights/en/blogs/2025/10/ev-adoption-rates-how-us-and-other-markets-compare-2025&quot;}" href="https://www.spglobal.com/automotive-insights/en/blogs/2025/10/ev-adoption-rates-how-us-and-other-markets-compare-2025" rel="nofollow noopener" target="_blank">7.5 percent of US new car sales</a>.) Frick also cited changes in the regulatory environment, including the <a href="https://www.wired.com/story/5-big-ev-takeaways-one-big-beautiful-bill/">Trump administration's rollback</a> of commercial and consumer tax incentives for electric vehicles.</p><p>The company has also canceled an all-electric commercial van planned for the European market. Instead, Ford will team up with Renault, <a data-offer-url="https://www.cnn.com/2025/12/09/business/ford-renault-european-evs-intl" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.cnn.com/2025/12/09/business/ford-renault-european-evs-intl&quot;}" href="https://www.cnn.com/2025/12/09/business/ford-renault-european-evs-intl" rel="nofollow noopener" target="_blank">in a partnership announced last week</a>, to develop at least two small Ford-branded electric vehicles for Europe‚Äîa move that CEO Jim Farley called part of a ‚Äúfight for our lives,‚Äù as US automakers try to compete with affordable EVs out of China.</p><p>Ford said Monday that it also plans to produce a new gas-powered commercial van for North America.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fix HDMI-CEC weirdness with a Raspberry Pi and a $7 cable (269 pts)]]></title>
            <link>https://johnlian.net/posts/hdmi-cec/</link>
            <guid>46281060</guid>
            <pubDate>Mon, 15 Dec 2025 21:37:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://johnlian.net/posts/hdmi-cec/">https://johnlian.net/posts/hdmi-cec/</a>, See on <a href="https://news.ycombinator.com/item?id=46281060">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><section><p>For years I treated <a href="https://en.wikipedia.org/wiki/Consumer_Electronics_Control">HDMI-CEC</a> like a house spirit: sometimes helpful, mostly temperamental, never fully understood. My living-room stack is straightforward: Samsung TV on <a href="https://en.wikipedia.org/wiki/HDMI#ARC_and_eARC">ARC</a> (NOT eARC - story for another day), Denon AVR-X1700H hidden in a closet, Apple TV plus a bunch of consoles connected to the receiver, and a <a href="https://www.raspberrypi.com/products/raspberry-pi-4-model-b/">Raspberry Pi 4</a> already doing <a href="https://homebridge.io/">Homebridge</a> duty. When it comes to CEC, the Apple TV handles it like a dream, but every console behaves like it missed the last week of CEC school. They wake the TV, switch the input, then leave the Denon asleep so I‚Äôm back to toggling audio outputs manually.</p><p><img src="https://johnlian.net/images/posts/hdmi-cec/media-closet.jpg" alt="My media closet where all the consoles are"></p><blockquote><p>I documented the <a href="https://johnlian.net/posts/media-closet/">media closet build-out</a> separately, so if you want the full wiring tour (and the before/after photos), start there.</p></blockquote><p>With the media closet, rewiring everything to the TV wasn‚Äôt an option and disabling CEC wasn‚Äôt viable (Apple TV works and it gets the most use). My first instinct was to lean on traditional automation stacks: HomeKit scenes to chain ‚ÄúTV on‚Äù into ‚Äúreceiver on‚Äù or wattage triggers via an <a href="https://www.evehome.com/en/eve-energy">Eve Energy</a> plug. This kind of worked, but every extra layer added 30 seconds of lag or more. The last stop on that journey was a <a href="https://github.com/electroflame/homebridge-cec-tv-control"><code>homebridge-cec-tv-control</code> plugin</a>, but while reading the README I realized I was about to pipe CEC messages through Node, Homebridge, and HomeKit before they hit the receiver. The Pi is wired into the rack already, so skipping those layers and going through <code>/dev/cec0</code> directly was clearly the faster path.</p><p>After an evening of struggling, the Pi now sits quietly on the HDMI bus, watching for consoles to announce themselves and issuing the single command Samsung + Denon should have exchanged on their own.</p><p>This post follows the structure of my notes: build a small mental model of CEC, monitor the bus, copy whatever Apple TV does right, wrap it in Python, then ship it as a <a href="https://systemd.io/">systemd</a> unit.</p><h2 id="small-hdmi-cec-primer">Small HDMI-CEC primer</h2><p><em><a href="https://en.wikipedia.org/wiki/HDMI">High-Definition Multimedia Interface</a> <a href="https://en.wikipedia.org/wiki/Consumer_Electronics_Control">Consumer Electronics Control</a></em>, much better known as <strong>HDMI-CEC</strong>, is a low-bandwidth side channel that rides alongside HDMI video/audio. Everyone on the bus speaks in <em>logical addresses</em> (<code>0x0</code> for TV, <code>0x5</code> for audio systems, <code>0x4/0x8/0xB</code><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> for playback devices, etc.) and tiny <em>opcodes</em><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> such as <code>0x82</code> (<strong>Active Source</strong>) or <code>0x72</code> (<strong>Set System Audio Mode</strong>). Physical addresses are ‚Äúlat/long‚Äù references inside the topology, so <code>3.0.0.0</code> can mean ‚ÄúAVR input source HDMI 3‚Äù.</p><p>CEC is <em>supposed to</em> help consumers control their electronics, so in a healthy system the flow goes like this: console wakes and declares itself active, the TV notices there‚Äôs an ARC partner, somebody sends ‚Äúplease be the audio system‚Äù, the receiver wakes up, and audio comes out of the big speakers. For me, that path only occurred when Apple TV was involved. Sadly, when I woke a console, the TV switched inputs but audio stayed on the tinny TV speakers.</p><p>To debug that mess I first wrote down how every device identified itself on the bus. Here are the specific CEC roles in my home theater:</p><ul><li><strong>TV</strong> ‚Äì logical address <code>0x0</code></li><li><strong>Audio system (Denon AVR-X1700H)</strong> ‚Äì logical address <code>0x5</code></li><li><strong>Playback devices</strong> ‚Äì logical addresses <code>0x4</code>, <code>0x8</code>, <code>0xB</code> (Apple TV, PS5, Switch 2 and Xbox all competing for the three playback slots<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>)</li><li><strong>Broadcast</strong> ‚Äì logical address <code>0xF</code> (messages to everyone)</li></ul><p>And the key opcodes we ended up caring about:</p><ul><li><code>0x82</code> ‚Äì <strong>Active Source</strong> (‚ÄúI am now the active input‚Äù)</li><li><code>0x84</code> ‚Äì <strong>Report Physical Address</strong> (‚Äúthis is where I live in the HDMI tree‚Äù)</li><li><code>0x70</code> ‚Äì <strong>System Audio Mode Request</strong></li><li><code>0x72</code> ‚Äì <strong>Set System Audio Mode</strong> (Denon‚Äôs ‚ÄúI am now the audio system‚Äù broadcast)</li></ul><h2 id="monitoring-the-cec-bus-with-cec-client">Monitoring the CEC bus with <code>cec-client</code></h2><p>The Raspberry Pi 4 I have exposes <code>/dev/cec0</code> interface on its micro-HDMI, and with a $7 micro-HDMI to HDMI cable plugged into HDMI input port on the receiver, it‚Äôs possible to monitor CEC traffic from <em>everything connected to the receiver</em>.</p><p><img src="https://johnlian.net/images/posts/hdmi-cec/raspberry-pi-hdmi.jpg" alt="Close-up photo of the Pi plugged into the TV‚Äôs ARC HDMI input, HDMI adapters visible"></p><p>I was initially hesitant because of some <a href="https://www.philips-hue.com/en-us/support/product/sync-box/100010#How_do_I_know_if_I_have_a_sync_box_4K_or_8K">Hue Play Sync Box</a><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> trauma: every HDMI splitter or inline gadget I‚Äôve tried in front of the TV caused weird <a href="https://en.wikipedia.org/wiki/Extended_Display_Identification_Data">EDID</a> breakage, troubles with HDR negotiation, or outright signal loss. But once I understood the Pi <em>never sits in the middle</em> of the HDMI handshake my concerns went away. By plugging it into an unused HDMI input on the AVR, it behaves like just another participant on the shared CEC bus. No signal regeneration, no spoofed EDIDs, nothing for the rest of the chain to notice.</p><p>So the topology looks like this:</p><pre tabindex="0"><code data-lang="mermaid">---
config:
  flowchart:
    htmlLabels: false
---
flowchart LR
  classDef pi fill:#ffd399,stroke:#f97316,stroke-width:3px,color:#111,font-weight:bold;
  classDef misc fill:#1f2933,stroke:#4b5563,color:#f8fafc;

  subgraph Media Closet
    SW["`**Nintendo Switch 2**
    Playback 1 @ 0x8
    3.1.0.0`"]-- HDMI 1 ---AVR
    ATV["`**Apple TV**
    Playback 2 @ 0x4
    3.2.0.0`"]-- HDMI 2 ---AVR
    PI["`**Raspberry Pi**
    Recorder 1 @ 0x1
    3.3.0.0`"]-- micro HDMI to HDMI 3 ---AVR
    PC["`**PC**
    no CEC`"]-- HDMI 4 ---AVR
    XBOX["`**Xbox Series X**
    Playback 1 @ 0x8
    3.5.0.0`"]-- HDMI 5 ---AVR
    PS5["`**PS5**
    Playback 3 @ 0xB
    3.6.0.0`"]-- HDMI 6 ---AVR
  end

  subgraph Living Room
    TV["`**Samsung S95B TV**
    TV @ 0x0
    0.0.0.0`"]
  end

  AVR["`**Denon AVR-X1700H**
  Audio @ 0x5
  3.0.0.0`"]-- HDMI Out to HDMI 3 (ARC) ---TV

  class AVR,TV,SW,ATV,PC,XBOX,PS5 misc;
  class PI pi;
</code></pre><p>Now, you can get <code>cec-client</code> from <a href="https://github.com/Pulse-Eight/libcec"><code>libcec</code></a>. Install it with</p><div><pre tabindex="0"><code data-lang="bash"><span><span>sudo apt update
</span></span><span><span>sudo apt install cec-utils
</span></span></code></pre></div><p>Then do a quick scan to see which devices respond:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span>echo</span> <span>"scan"</span> <span>|</span> cec-client -s
</span></span></code></pre></div><p>Example scan output from my setup below. As you can see, the Xbox and Switch both<sup id="fnref1:3"><a href="#fn:3" role="doc-noteref">3</a></sup> claim logical address <code>0x8</code><sup id="fnref1:1"><a href="#fn:1" role="doc-noteref">1</a></sup>:</p><div><pre tabindex="0"><code data-lang="text"><span><span>CEC bus information
</span></span><span><span>===================
</span></span><span><span>device #0: TV
</span></span><span><span>address:       0.0.0.0
</span></span><span><span>active source: no
</span></span><span><span>vendor:        Samsung
</span></span><span><span>osd string:    TV
</span></span><span><span>CEC version:   1.4
</span></span><span><span>power status:  on
</span></span><span><span>language:      eng
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>device #1: Recorder 1
</span></span><span><span>address:       3.3.0.0
</span></span><span><span>active source: no
</span></span><span><span>vendor:        Pulse Eight
</span></span><span><span>osd string:    CECTester
</span></span><span><span>CEC version:   1.4
</span></span><span><span>power status:  on
</span></span><span><span>language:      eng
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>device #4: Playback 1
</span></span><span><span>address:       3.1.0.0
</span></span><span><span>active source: yes
</span></span><span><span>vendor:        Unknown
</span></span><span><span>osd string:    Switch 2
</span></span><span><span>CEC version:   1.3a
</span></span><span><span>power status:  on
</span></span><span><span>language:      ???
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>device #5: Audio
</span></span><span><span>address:       3.0.0.0
</span></span><span><span>active source: no
</span></span><span><span>vendor:        Denon
</span></span><span><span>osd string:    AVR-X1700H
</span></span><span><span>CEC version:   1.4
</span></span><span><span>power status:  on
</span></span><span><span>language:      ???
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>device #8: Playback 2
</span></span><span><span>address:       3.2.0.0
</span></span><span><span>active source: no
</span></span><span><span>vendor:        Apple
</span></span><span><span>osd string:    Apple TV
</span></span><span><span>CEC version:   2.0
</span></span><span><span>power status:  standby
</span></span><span><span>language:      ???
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>device #B: Playback 3
</span></span><span><span>address:       3.6.0.0
</span></span><span><span>active source: no
</span></span><span><span>vendor:        Sony
</span></span><span><span>osd string:    PlayStation 5
</span></span><span><span>CEC version:   1.3a
</span></span><span><span>power status:  standby
</span></span><span><span>language:      ???
</span></span></code></pre></div><p>If the expected devices show up, use monitor mode with the correct level<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> of logging:</p><p>This command keeps the Pi quiet (monitor mode) yet gives you every bus transaction.</p><p>A line such as <code>TRAFFIC: [...] &gt;&gt; bf:82:36:00</code> means: logical <code>0xB</code> (PS5) broadcast Active Source (<code>0x82</code>) with physical address <code>3.6.0.0</code>. That‚Äôs the packet you expect any console to send when it wakes up.</p><h2 id="figuring-out-the-magic-handshake">Figuring out the magic handshake</h2><p>So I put the system in standby, start logging, then wake Apple TV. I got the expected <code>Active Source</code> burst, followed immediately by the Denon broadcasting that it has taken over audio:</p><div><pre tabindex="0"><code data-lang="text"><span><span>&gt;&gt; 8f:82:32:00       # Apple TV (logical 8) -&gt; Broadcast: Active Source
</span></span><span><span>...
</span></span><span><span>&gt;&gt; 8f:a6:06:10:56:10 # Apple TV (logical 8) -&gt; Broadcast: ???
</span></span><span><span>&gt;&gt; 5f:72:01          # Denon (logical 5) -&gt; Broadcast: Set System Audio Mode (on)
</span></span></code></pre></div><p>Translated:</p><ol><li>Apple TV announces itself as the active source.</li><li>Apple TV broadcasts some magic bits?</li><li>Very soon after, the Denon tells everyone ‚ÄúSystem Audio Mode is on,‚Äù and the TV happily keeps output set to <strong>Receiver</strong> instead of flipping back to TV speakers.</li></ol><p>I did the exact same experiment with PS5, Xbox, Switch 2 and the result was different:</p><div><pre tabindex="0"><code data-lang="text"><span><span>&gt;&gt; bf:82:36:00       # PS5: Active Source
</span></span><span><span># ...a bunch of reports, but no 5f:72:01
</span></span></code></pre></div><p>So what was the <code>8f:a6:06:10:56:10</code> frame when Apple TV was involved? With debug logs, <code>cec-client</code> showed <code>UNKNOWN (A6)</code>. I suspect <code>libCEC</code> labels it unknown because it‚Äôs in the vendor-specific range. The following bytes (<code>06:10:56:10</code>) could be Apple‚Äôs proprietary payload, like some capability or extended control. It‚Äôs possible Samsung and Apple have a private handshake here that ultimately results in the Denon doing the right thing. It‚Äôs neat, but I couldn‚Äôt rely on it since it‚Äôs undocumented and sending it manually from the Raspberry Pi‚Äôs logical address had no effect. Impersonating Apple TV over CEC is not realistically viable and likely brittle.</p><p>However, with <a href="https://www.cec-o-matic.com/">cec-o-matic.com</a>, it was easy to craft a CEC frame for the Raspberry Pi to send a normal system audio mode request:</p><div><pre tabindex="0"><code data-lang="text"><span><span>15:70:00:00 # TV (1) -&gt; Audio (5): System Audio Mode Request
</span></span></code></pre></div><p>Breaking it down:</p><ul><li><code>15</code> = source <code>0x1</code> (Recorder 1 = Pi) sends to destination <code>0x5</code> (Audio System = Denon)</li><li><code>70</code> = opcode <strong>System Audio Mode Request</strong></li><li><code>00:00</code> = operands (TV‚Äôs physical address 0.0.0.0, plus ‚Äúsystem audio status‚Äù = off/0, which Denon interprets as ‚Äúplease negotiate system audio mode and turn on ARC‚Äù)</li></ul><p>The second I typed this into <code>cec-client</code>‚Äôs interactive shell with <code>tx 15:70:00:00</code>, the Denon turned on and ARC anchored to the receiver even with only a console and TV powered on. I confirmed by checking the TV‚Äôs audio output:</p><p><img src="https://johnlian.net/images/posts/hdmi-cec/output.jpg" alt="Photo of TV UI confirming receiver output"></p><p>So the solution started to emerge: whenever a console wakes up and claims Active Source, the Pi should step in and send <code>15:70:00:00</code> to the Denon to kickstart audio negotiation.</p><h2 id="dont-spam-the-bus">Don‚Äôt spam the bus!</h2><p>Now that we know the basis of the automation, the most obvious thing to do is to write a bash script that loops <code>cec-client</code> every few seconds and blast <code>on 5</code>. That sort of works, but it‚Äôs not ideal:</p><ul><li>Using a loop means the automation is delayed instead of reacting to actual CEC events.</li><li>Every iteration spins up a new <code>cec-client</code>, binds to <code>/dev/cec0</code>, sends one command, and tears down.</li><li>CEC is a shared bus, not a write-only GPIO.</li></ul><p>A better pattern is:</p><ol><li>Start a <strong>single</strong> long-lived <code>cec-client</code> process.<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></li><li>Let it print every <code>TRAFFIC</code> line for you to parse.</li><li>Feed it <code>tx ...</code> commands on stdin only when you need to intervene.</li></ol><p>The only catch: monitor mode (<code>-m</code>) can‚Äôt transmit. So for the automation we switch to:</p><p>No <code>-m</code> here. <code>cec-client</code> still prints all the traffic, but now it also accepts commands. Our Python script treats it like a bridge between HDMI land and our own logic: <code>stdout</code> is an event stream, <code>stdin</code> is a control channel.</p><h2 id="the-python-script">The Python script</h2><p>It took some trial and error, but it wasn‚Äôt too difficult to write a small Python program that watches for consoles waking up and sends the magic <code>15:70:00:00</code> command when needed. I put it all on GitHub:</p><p><a href="https://github.com/jlian/cec_auto_audio">
<span>jlian/cec_auto_audio</span></a></p><p>The script logic goes:</p><ul><li>Starts <code>cec-client -d 8</code> as a subprocess.</li><li>Parses <code>TRAFFIC</code> lines.</li><li>Watches for <strong>Active Source (<code>0x82</code>)</strong> from any <strong>Playback</strong> logical address (<code>0x4/0x8/0xB</code>).</li><li>Tracks when the Denon last broadcast <strong>Set System Audio Mode (<code>5f:72:01</code>)</strong> so we don‚Äôt fight Apple TV or the TV‚Äôs own logic.</li><li>Sends <code>tx 15:70:00:00</code> at most once per console wake if nobody else has done it.</li></ul><p>A few notes:</p><ul><li>The script <strong>doesn‚Äôt hard-code</strong> any device names, vendors, or physical addresses.</li><li>It treats <strong>any Playback logical address</strong> (<code>0x4/0x8/0xB</code>) turning into Active Source as a ‚Äúconsole wake‚Äù event.</li><li>It stays <strong>passive</strong> when Apple TV / Samsung / Denon manage to do the right thing themselves (because we observe a real <code>5f:72:01</code>).</li><li>It runs as a single long-lived process tied to a single <code>cec-client</code> instance.</li></ul><p>To make sure it starts on boot and keeps running, I wrapped it in a simple <code>systemd</code> service. The unit file I used <a href="https://github.com/jlian/cec_auto_audio?tab=readme-ov-file#running-as-a-systemd-service">can be found in the GitHub README</a>. I‚Äôve been running it for a few days and feels rock solid.</p><h2 id="generalizing-this-approach">Generalizing this approach</h2><p>I hope this post gives you enough of a mental model to adapt this approach to your own CEC pain points. My solution is specific to the Denon + Samsung + consoles scenario, but the same pattern should work for other CEC quirks.</p><p>Maybe your issue isn‚Äôt consoles not engaging the AVR. Maybe DTS never negotiates, or your TV keeps snapping back to its tiny speakers. The workflow is the same:</p><ol><li><p><strong>Get the Pi onto the an HDMI port</strong>. Plug the Pi into the TV or Receiver‚Äôs HDMI input using a <a href="https://www.amazon.com/dp/B06WWQ7KLV">micro-HDMI‚Äì&gt;HDMI cable</a> (or adapter). Put it somewhere it can sit forever.</p></li><li><p><strong>Baseline the bus</strong>. Run:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span>echo</span> <span>"scan"</span> <span>|</span> cec-client -s -d <span>1</span>
</span></span></code></pre></div><p>to make sure your Pi can see all the expected devices, what logical/physical addresses they have, and what roles they use.</p></li><li><p><strong>Record a ‚Äúgood‚Äù scenario and a ‚Äúbad‚Äù one</strong>. Use:</p><p>to log traffic while you:</p><ul><li>Trigger a <strong>good</strong> path (e.g., Apple TV gets 5.1 sound correctly).</li><li>Trigger a <strong>bad</strong> path (e.g., DTS falls back to stereo, or ARC drops to TV speakers).</li></ul></li><li><p><strong>Diff the traces</strong>. Look for opcodes that show up in the good trace but are missing in the bad. In my case, the interesting delta was the presence of <code>5f:72:01</code> after Apple TV woke, and the absence of anything like it when a console woke alone.</p></li><li><p><strong>Inject the missing opcode manually</strong>. Go to <a href="https://www.cec-o-matic.com/">cec-o-matic.com</a> to build the missing frame<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>, then run:</p><p>to use <code>cec-client</code> in interactive mode, then type <code>tx ...</code> for your suspected magic packet, and see if anything changes. If not, try again with a different frame.</p><p>You likely would want to start with a frame like <code>1f:...</code> (Pi logical address as Recording 1 <code>0x1</code> to Broadcast <code>0xF</code>), or <code>15...</code> (Pi to Audio System <code>0x5</code>), depending on what you‚Äôre trying to achieve.</p></li><li><p><strong>Wrap it in code</strong>. Once you know the magic packet, wrap it in a tiny program like the one above and let the Pi quietly participate on the bus.</p></li></ol><p>You can picture the good vs bad paths like this:</p><pre tabindex="0"><code data-lang="mermaid">sequenceDiagram
  participant Src as Source (console/player)
  participant TV as TV (0)
  participant AVR as AVR / Soundbar (5)

  rect rgb(230,255,230)
    note over Src,AVR: Good path
    Src-&gt;&gt;TV: Active Source (0x82)
    TV-&gt;&gt;AVR: System Audio Mode Request (0x70)
    AVR-&gt;&gt;TV: Set System Audio Mode On (0x72)
  end

  rect rgb(255,230,230)
    note over Src,AVR: Bad path
    Src-&gt;&gt;TV: Active Source (0x82)
        note over TV,AVR: No audio-mode negotiation
  end
</code></pre><p>Your job is to spot the missing step and teach the Pi to do it.</p><h2 id="where-this-leaves-my-setup">Where this leaves my setup</h2><p>Apple TV keeps doing its thing. PS5, Xbox, or Switch now wake the TV, the Pi nudges the Denon within half a second, and audio stays glued to the receiver. Latency is low enough that it feels native. The Pi sits in the closet pretending to be a slightly overqualified remote.</p><p><img src="https://johnlian.net/images/posts/hdmi-cec/tv-and-cat.jpg" alt="Picture of my TV and cat being comfortable"></p><p>There are still a couple of rough edges I haven‚Äôt tackled yet:</p><ul><li><p><strong>When a console goes to sleep, the TV sometimes ‚Äúhelpfully‚Äù switches to its antenna input.</strong> I don‚Äôt even have an antenna plugged in, so the net effect is a confusing ‚Äúno signal‚Äù screen instead of falling back to Apple TV or a known-good input. That‚Äôs technically ‚Äúcorrect‚Äù from the TV‚Äôs point of view (its own tuner is always a valid source), but wrong for how this setup is actually used.</p></li><li><p><strong>My sunset TV automation can land on a dead input.</strong> I have a HomeKit automation that turns the TV on around sunset. Most of the time that means Apple TV wakes up with a nice aerial screensaver. But if the last input before power-off was a console, the TV wakes to that HDMI port and just shows ‚Äúno signal‚Äù, which confuses other people in the house.</p></li></ul><p>These problems are similar, but require slightly different solutions:</p><ol><li><strong>Console standby ‚Üí TV becomes Active Source.</strong> When a console goes to sleep it tends to release the bus and the TV politely promotes its tuner. The helper could watch for that very specific frame pair (console Standby, TV Active Source) and, after a short grace period, switch the input to Apple TV.</li><li><strong>Sunset automation ‚Üí no Active Source.</strong> In this case the TV powers on but nobody (not even the TV) claims Active Source, so it sits on the last HDMI port showing ‚Äúno signal.‚Äù The helper needs to detect ‚ÄúTV on, Denon asleep, no Active Source within N ms,‚Äù then wake both Apple TV and the receiver and switch inputs.</li></ol><p>Or maybe we could unify both by having a state machine that tracks ‚Äúwho was Active Source most recently‚Äù and automatically falls back to Apple TV whenever the bus goes quiet <em>or</em> the TV promotes itself. Either way, the Pi‚Äôs job is to make sure there‚Äôs always a sane outcome.</p><p>That would turn the Pi into a more general ‚ÄúHDMI shepherd‚Äù: not just keeping ARC pinned to the receiver when something is playing, but also steering the system back to a sane default when nothing is.</p><p>There‚Äôs probably a small cottage industry of ‚Äútwo-page CEC scripts‚Äù waiting to be written. If you adapt this trick for some other HDMI-CEC horror story, <a href="https://johnlian.net/about/#contact">send me the packet traces</a>‚ÄîI‚Äôm collecting folklore.</p></section><div><ul><li>Related:</li><li><a href="https://johnlian.net/posts/arc-downgrade/">When ‚Äúdowngrading‚Äù to ARC fixes everything</a></li><li><a href="https://johnlian.net/posts/hades2-4k60/">To get 4K60 for Hades 2 on Switch 2, disable ‚Äú120 Hz Output‚Äù in system settings</a></li><li><a href="https://johnlian.net/posts/media-closet/">Cleaned up the network/media closet</a></li></ul></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Secret Documents Show Pepsi and Walmart Colluded to Raise Food Prices (526 pts)]]></title>
            <link>https://www.thebignewsletter.com/p/secret-documents-show-pepsi-and-walmart</link>
            <guid>46280887</guid>
            <pubDate>Mon, 15 Dec 2025 21:24:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebignewsletter.com/p/secret-documents-show-pepsi-and-walmart">https://www.thebignewsletter.com/p/secret-documents-show-pepsi-and-walmart</a>, See on <a href="https://news.ycombinator.com/item?id=46280887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Last month, the Atlanta Fed came out with a </span><a href="https://www.atlantafed.org/research/publications/wp/2025/11/06/15-geospatial-heterogeneity-in-inflation-market-concentration-story" rel="">report</a><span> showing a clear relationship between consolidation in grocery stores and the rate of food inflation. Unsurprisingly, where monopolies prevail, food inflation is 0.46 percentage points higher than where there is more competition. The study showed that from 2006-2020, the cumulative difference amounted to a 9% hike in food prices, and presumably since 2020, that number has gone much higher.</span></p><p>Affordability, in other words, is a market power problem. </p><p><span>And yesterday, we got specifics on just </span><em>how </em><span>market power in grocery stores works. The reason is because a nonprofit just forced the government to unseal </span><a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.635565/gov.uscourts.nysd.635565.68.0.pdf" rel="">a complaint</a><span> lodged by Lina Khan‚Äôs FTC against Pepsi for colluding with Walmart to raise food prices across the economy. A Trump official tasked with dealing with affordability tried to hide this complaint, and failed. And now there‚Äôs a political and legal storm as a result.</span></p><p>Let‚Äôs dive in.</p><p>Everyone knows the players involved. Pepsi is a monster in terms of size, a $90 billion soft drink and consumer packaged goods company with multiple iconic beverage and food brands each worth over $1 billion, including Pepsi-Cola, Frito Lay, Mountain Dew, Starbucks (under license), Gatorade, and Aquafina. Walmart is a key partner, with between 20-25% of the grocery market.</p><p><span>Pepsi was also a key </span><a href="https://www.modernretail.co/operations/price-hikes-pump-up-pepsicos-annual-outlook/" rel="">player</a><span> in the post-Covid ‚Äògreedflation‚Äô episode. ‚ÄúI actually think we‚Äôre capable of taking whatever pricing we need,‚Äù said CFO Hugh Johnston in 2022. And the company did just that, </span><a href="https://www.seattletimes.com/business/pepsico-tops-expectations-for-the-2nd-quarter-and-raises-its-expectations-for-2023/" rel="">raising prices</a><span> by </span><a href="https://www.detroitnews.com/story/business/retail/2023/10/10/pepsico-hikes-prices-7th-consecutive-quarter-profits-jump/71127783007/" rel="">double digit percentages</a><span> for seven straight quarters in 2022-2023. </span></p><p>The allegation is price discrimination, which is a violation of the Robinson-Patman Act, a law passed in 1936 to prevent big manufacturers and chain stores from acquiring too much market power. The specifics in the complaint are that Pepsi keeps wholesale prices on its products high for every outlet but Walmart, and Walmart in return offers prominent placement in stores for Pepsi products. This approach internally is called a ‚Äúprice gap‚Äù strategy. It‚Äôs a partnership between two giants to exclude rivals by ensuring that Walmart has an advantage over smaller rivals in terms of what it charges consumers, and so that Pepsi maintains its dominance on store shelves.</p><p>This partnership comes in a number of forms. Pepsi offers allowances for Walmart, such as ‚ÄúRollback‚Äù pricing, where specially priced soft drinks go into bins in highly visible parts of the store. The soft drink company gives Walmart ‚ÄúSave Even More‚Äù deals, online coupons and advertisements, and other merchandizing opportunities. Other outlets don‚Äôt get these same allowances, meaning they are charged higher prices.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!EGsn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EGsn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 424w, https://substackcdn.com/image/fetch/$s_!EGsn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 848w, https://substackcdn.com/image/fetch/$s_!EGsn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 1272w, https://substackcdn.com/image/fetch/$s_!EGsn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!EGsn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png" width="656" height="658" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:658,&quot;width&quot;:656,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:801121,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181432503?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!EGsn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 424w, https://substackcdn.com/image/fetch/$s_!EGsn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 848w, https://substackcdn.com/image/fetch/$s_!EGsn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 1272w, https://substackcdn.com/image/fetch/$s_!EGsn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90a5471b-fb95-44c2-8cd8-55d05469f9b6_656x658.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>While Pepsi is a ‚Äúmust-have‚Äù product for grocery stores, Walmart is also massively powerful. In its investment documents, Pepsi notes that Walmart is its largest customer, the the loss of which ‚Äúwould have a material adverse effect‚Äù on its business. Walmart is so dominant that the internal communication of the two companies would show a comparison of prices at Walmart versus ‚ÄúROM,‚Äù or ‚Äúrest of market,‚Äù meaning grocery, mass, club, drug, and dollar channels. It‚Äôs everyone in the world versus Walmart.</p><p>And Pepsi does a lot of alleged price discrimination to maintain the approval of Walmart. It goes far beyond special allowances and concessions to Walmart; Pepsi even polices prices at rival stores and prepares reports for Walmart showing them their pricing advantages on Pepsi products.  </p><p>When the ‚Äúprice gap‚Äù would narrow too much, Pepsi executives panicked with fear they might offend Walmart. They tracked ‚Äúleakage,‚Äù meaning when consumers would buy Pepsi products outside of Walmart, which happened most often at stores where prices were more competitive. Pepsi kept logs on stores who would ‚Äúself-fund‚Äù discounts, nicknaming them ‚Äúoffenders‚Äù of the price gap. It would note that where competition was fierce, such as in the Richmond-Raleigh-CLT corridor, it was harder to maintain a price gap for Walmart. This relationship went both ways; Walmart executives would complain to Pepsi if the ‚Äúprice gap‚Äù got too thin.</p><p>To ensure that prices would go up at rival stores, Pepsi would adjust allowances, such as ‚Äúadjusting rollback levers.‚Äù It would punish stores that refused to cooperate by raising wholesale prices. Retailers who were trying to discount Pepsi products to better compete with Walmart would find it increasingly difficult to do so; not only would Pepsi take away their promotional allowances, but they might find that discounting six-packs of soda would lead to Pepsi charging them higher wholesale prices for the soda.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SQxj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SQxj!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 424w, https://substackcdn.com/image/fetch/$s_!SQxj!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 848w, https://substackcdn.com/image/fetch/$s_!SQxj!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 1272w, https://substackcdn.com/image/fetch/$s_!SQxj!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SQxj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png" width="1406" height="546" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:546,&quot;width&quot;:1406,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:129575,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181432503?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!SQxj!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 424w, https://substackcdn.com/image/fetch/$s_!SQxj!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 848w, https://substackcdn.com/image/fetch/$s_!SQxj!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 1272w, https://substackcdn.com/image/fetch/$s_!SQxj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45d660e7-2cc8-4342-9314-6417881bd943_1406x546.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The FTC offered the example of Food Lion, a 1000-store chain in 10 states that cut prices on Pepsi products on its own to match or beat Walmart prices.</p><blockquote><p>In 2022, Pepsi believed that Food Lion had ‚Äúheavily indexe[d]‚Äù its retail prices ‚Äúagainst retails at [Walmart] and Kroger‚Äù and ‚Äúset[] retails relative to these competitors.‚Äù Pepsi characterized Food Lion as the ‚Äúworst offender‚Äù on the price gap for ‚Äúbeating [Walmart] in price.‚Äù</p><p>As a result of Food Lion threatening Walmart‚Äôs price gap, Pepsi created a plan to nudge Food Lion‚Äôs retail prices on Pepsi products upward by reducing promotional payments and allowances to Food Lion and raising other costs for Food Lion. The plan advised that Pepsi ‚Äúmust commit to raising rate [on Food Lion] faster than market by minimum annually.‚Äù‚Ä¶</p><p>Nonetheless, even with these price increases, Pepsi leadership continued to push its Food Lion sales team to ‚Äúbegin to CLOSE the gap‚Äù because ‚Äú[w]e absolutely have to demonstrate progress [to Walmart] in the immediate term.‚Äù</p></blockquote><p><span>This arrangement benefits each side by extracting from consumers and rivals. Walmart gets to have a price advantage in Pepsi soft drink products against rival grocery stores and convenience stores, and Pepsi is able to exclude competitor access to better shelf space at the most important retailer. Consumers end up paying more for soda, new companies find it harder to get distribution access for new soft drink products to compete with Pepsi, and all non-Walmart retail stores are put at a disadvantage to Walmart. ILSR‚Äôs Stacy Mitchell </span><a href="https://x.com/stacyfmitchell/status/1999468090753712219" rel="">laid out the terms of the deal</a><span> as ‚ÄúKeep us the king of our domain and we‚Äôll make you the king of yours.‚Äù</span></p><p><span>This dynamic is why independent grocery stores are dying. ‚ÄúWe can be almost certain that this is the same monopolistic deal Walmart has cut with other major grocery suppliers,‚Äù </span><a href="https://x.com/stacyfmitchell/status/1999468104813101500" rel="">noted</a><span> Mitchell. ‚ÄúIt‚Äôs led to less competition, fewer local grocery stores, and higher prices.‚Äù To the end consumer, it creates an optimal illusion. Walmart appears to be a low-cost retailer, but that‚Äôs because it induces its suppliers to push prices up at rivals. The net effect is less competition at every level. There are more areas without grocery competition, which increases food inflation. And suppliers like Pepsi gain pricing power, such as that they exploited during the post-Covid moment.</span></p><p><span>This kind of presumptively illegal price discrimination isn‚Äôt unique to the Pepsi-Walmart relationship. Pepsi is </span><em>also</em><span> being </span><a href="https://www.dropbox.com/scl/fi/shdq7a2j4d7tb00bf0gw8/2025.02.17-1-Complaint-copy.pdf?rlkey=f2a69y8uvfw8mjl8pngc26vbp&amp;e=1&amp;dl=0" rel="">sued</a><span> in a class action complaint for giving better </span><a href="https://www.thebignewsletter.com/p/monopoly-round-up-trump-antitrust" rel="">deals</a><span> for snack foods to big chains than it does to smaller stores, and Post is being sued by Snoop Dogg for working with Walmart to exclude sugar cereals produced by Snoop Dogg from its store shelves. You can find price discrimination everywhere in the economy, from shipping to ad buying to pharmaceutical distribution to liquor sales. And the resulting consolidation and high prices is also pervasive.</span></p><p><span>So why are we only learning about this situation now? Well, the original allegation was filed in January, in the last days of the Khan FTC. We knew the general outline of the argument, but we didn‚Äôt know specifics, because the complaint was </span><a href="https://www.dropbox.com/scl/fi/6exjq8haeerlcv4ncit14/gov.uscourts.nysd.635565.1.0.pdf?rlkey=1lu7dtc9s5tnl8ns0mlzxryf8&amp;e=1&amp;dl=0" rel="">highly redacted</a><span>. Was it a real conspiracy? Was it just that Pepsi considered Walmart a ‚Äúsuperstore‚Äù and had different prices for different channels? Was there coercion? None of these questions could be answered; there were so many blacked out words we couldn‚Äôt even say for sure that the large power buyer referenced in the document was Walmart. </span></p><p>Economists and fancy legal thinkers mocked the case endlessly. The FTC hates discounts! Price discrimination is good, it ends up lowering prices for consumers. The Robinson-Patman Act is stupid and pushes up prices. Suppliers always can only charge what ‚Äúthe market will bear‚Äù and if they could charge higher prices they‚Äôd already be doing it. And they‚Äôd never offer lower prices to any distributor; no lower  than they had to. Yet these claims relied on the complaint never seeing the light of day.</p><p>The reason for the secrecy was a choice by FTC Chair Ferguson. Normally, when the government files an antitrust case, the complaint is redacted to protect confidential business information, as this one against Pepsi was. Then the corporate defendant and the government haggle over what is genuinely confidential business information. Within a few weeks, complaints are unsealed with a few minor blacked out phrases, and the case goes on. </p><p><span>In this case, however, Trump Federal Trade Commission Chair Andrew Ferguson abruptly dropped the case in February after Pepsi </span><a href="https://www.politico.com/newsletters/politico-influence/2025/04/09/pepsi-hires-an-antitrust-lobbyist-00282762" rel="">hired</a><span> well-connected lobbyists. Small business groups were angry, but what was most interesting was the timing. Ferguson ended it the day before the government was supposed to go before the judge to manage the unsealing process. And that kept the complaint redacted. With the complaint kept secret, Ferguson, and his colleague Mark Meador, then publicly went on the attack. Ferguson‚Äôs </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/Pepsi-Dismissal-Ferguson-Statement-05-22-2025.pdf" rel="">statement</a><span> was a bitter and personal invective against Khan; he implied she was lawless and partisan, that there was ‚Äúno evidence‚Äù to support key contentions, and that he </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/Pepsi-Dismissal-Ferguson-Statement-05-22-2025.pdf" rel="">had</a><span> to ‚Äúclean up the Biden-Harris FTC‚Äôs mess,‚Äù which fellow commissioner Mark Meador later </span><a href="https://x.com/MeadorFTC/status/1925687128266092733" rel="">echoed.</a></p><p>And that was where it was supposed to stay, secret, with mean-spirited name-calling and invective camouflaging the real secret Ferguson was trying to conceal. That secret is something we all know, but this complaint helped prove - the center of the affordability crisis in food is market power. If that got out, then Ferguson would have to litigate this case or risk deep embarrassment. So the strategy was to handwave about that mean Lina Khan to lobbyists, while keeping the evidence secret.</p><p><span>However, the anti-monopoly movement and the court system actually worked. The Institute for Local Self-Reliance, an anti-monopoly group filed to make the full complaint public. Judge Jesse Matthew Furman agreed to hear ILSR‚Äôs case, with the U.S. Chamber of Commerce and Pepsi bitterly opposed. Last week, Furman directed the FTC </span><a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.635565/gov.uscourts.nysd.635565.67.0.pdf" rel="">unseal</a><span> the complaint. So we finally got to see what Ferguson and Meador were trying to hide. </span></p><p>The political reaction is just starting. Ferguson has pretended that he‚Äôs taking a leading role in the ‚Äòaffordability‚Äô strategy of the Trump administration, it wouldn‚Äôt surprise me if there‚Äôs internal anger at him among Republicans for flubbing such an obvious way to lower consumer prices and then lying about it. The grocery industry, especially rural grocers victimized by this price discrimination, leans to the right. </p><p><span>On the Democratic side, already we‚Äôre seeing states introducing price discrimination bills. There‚Äôs likely going to be bipartisan pressure on the FTC, which can and should reopen the case. There are already private Robinson-Patman Act cases, this complaint is likely to be picked up and used by plaintiffs who are excluded by the alleged scheme revealed in it. As a result of the publication of this complaint, Sabina Matos, the lieutenant governor of Rhode Island, </span><a href="https://x.com/i/status/1999550366141018443" rel="">just said</a><span> that her state should ban this kind of behavior.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Hu6F!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Hu6F!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 424w, https://substackcdn.com/image/fetch/$s_!Hu6F!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 848w, https://substackcdn.com/image/fetch/$s_!Hu6F!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 1272w, https://substackcdn.com/image/fetch/$s_!Hu6F!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Hu6F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png" width="968" height="920" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:920,&quot;width&quot;:968,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:402702,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181432503?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Hu6F!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 424w, https://substackcdn.com/image/fetch/$s_!Hu6F!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 848w, https://substackcdn.com/image/fetch/$s_!Hu6F!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 1272w, https://substackcdn.com/image/fetch/$s_!Hu6F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb749882-6fb7-4c11-9fcf-68db59e04209_968x920.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>But there‚Äôs also something deeper happening. Earlier this week, More Perfect Union </span><a href="https://x.com/MorePerfectUS/status/1998377726432907537" rel="">came</a><span> out with an important investigative report on a company called Instacart, which is helping retailers charge individual personalized prices for goods based on a shopper‚Äôs data profile. The story went viral and caused immense outrage because it said something we already know. Pricing is increasingly unfair and unequal, a mechanism to extract instead of a means of sending information signals to the public and producers to coordinate legitimate commercial activity. And there‚Äôs a historical analogy to the increasing popular frustration.</span></p><p>The idea of the single price store, where a price is transparent and is the same for everyone, was created by department store magnate John Wanamaker in the post-Civil War era. Before founding his department store, Wanamaker was the first leader of the YMCA. He also created a Philadelphia mega-church. His single price strategy was part of an evangelical movement to morally purify America, the ‚ÄúGolden rule‚Äù applied to business. The price tag was political, an explicitly democratic attempt to treat everyone equally by eliminating the haggling and extractive approach of merchants.</p><p>At the same time as Wanamaker operated his store, the Granger movement of farmers in the midwest and later Populists fought their own war on unfair pricing of railroads, with the slogan ‚Äúpublic prices and no secret kickbacks.‚Äù In the 1899 conference on trusts in Chicago, widely considered the most important intellectual and political forum for the later treatment of the Sherman Act, there were bitter debates, but everyone agreed that price discrimination by railroads were fostering consolidation in a dangerous and inefficient roll-up of power. These movements took place at a moment of great technological change, when Americans were moving to cities and leaving the traditional dry goods store behind.</p><p>Similarly, there was a big anti-chain store movement in the 1920s and 1930s to protect local producers and retailers, which ended up resulting in the Robinson-Patman Act, among other changes to law. That was a result of the Walmart or Amazon of its day, A&amp;P, which would engage in price discrimination, opening outlets it called ‚Äúkilling stores‚Äù just to harm rivals. Over the past five years, we‚Äôve seen a similar upsurge in anger over prices that drove the grangers, John Wanamaker, and the anti-chain store movement. Prices are becoming political again.</p><p>This revival is being driven by two things. First, technology is enabling all sorts of new ways to price, which is to say, to organize commercial and political power. And we all feel the coercion. Second, we‚Äôre beginning to relearn our traditions. Our historical memory was erased in the 1970s by economists, who argued that price discrimination is affirmatively a good thing. But fortunately, they are losing the debate. </p><p>As a result, today we‚Äôre seeing something similar to the anti-chain store movement of the 1920s and 1930s, with attempts to reinvigorate Robinson-Patman, and write and apply antitrust laws to algorithmic pricing choices. The Instacart scheme is a new way to extract, the alleged Walmart-Pepsi scheme is a classic way to extract. But increasingly, the public is realizing that pricing is political. And they don‚Äôt want to be cheated anymore.</p><p><span>Thanks for reading! Your tips make this newsletter what it is, so please send me tips on weird monopolies, stories I‚Äôve missed, or other thoughts. And if you liked this issue of BIG, you can sign up </span><a href="http://email.mg1.substack.com/c/eJxVUMFuwyAM_ZpwjIAmYT34UHXtb0QEnBSNQARmVf5-pN1hkyzberae37PRhEtMOxBmYiVjGp0FZoEradTEXB7nhLhq54FtZfLOaHIxHFtC9LJjDzhxNUs7nKTlnGsthRKDmj-s4dIYO0i2xUyjLtZhMAj4jWmPAZmHB9GWm9OlkfcaqybKFL3H1OYyZdLmqzVxraMn-togcyC5OPNzzT3ve9WKVnS3y5WL4a54d1PdZ9PxdRH_CFiCX946XA4vL7TaGWtdS3C0jxj05NECpYKM3v94Cad9Qwj4zB6JML3Bw74chFCsHrKxcgb4o_8H-RJ1Kg" rel="">here</a><span> for more issues, a newsletter on how to restore fair commerce, innovation, and democracy. Consider becoming a </span><a href="https://email.mg1.substack.com/c/eJxVUMtuwyAQ_JpwtABjEw4ceulvIB6Lg4rBgrUq_31J0kO7Wmk1-xrNeIuw1XZphI7kqB0NXgfoAt89AyI0cnZoJgVNgqaSe-lI6iY2gN2mrMlxupy8xVTLc4uxhQvy0DZKpyjQIL31CqigggOPQYWBIqg3lz1DguJB15Ivc9gUSNYPxKPf5o8b_xy5W8SONWdoUz9dR-u_Jl_3MXpC35IDkjSnnI2Y6cwkZROfhIwuSrXauC7e2_u0rNhtvJaboPvG_v0iTf9SjOH21PXqDmlm1P0sCS8DxboMQWM7geDbsJcHZoMCbRgZjEXN1nmVchaci5W9VQ5bxEzlXVFFBm2o46roP8J-AJJ0hnE" rel="">paying subscriber</a><span> to support this work, or if you are a paying subscriber, giving a </span><a href="https://email.mg1.substack.com/c/eJxVUEtuxSAMPE1YRnwSSBYsKlW9BiJgUlQCETiqcvvy3uuitSxZ9tgezTiLsJd6a4SG5CwNDd4n6AzfLQEiVHI1qCZ6Tbymiju1kdhMqACHjUmT89pSdBZjyY8txmY-kU_tOZOU-bB5urhl9ouc-RomtnoXpOX0xWUvHyE70CWn25w2epL0J-LZBvE28I-eh0VsWFKCOrZra2jd1-jK0aFH62rcYBB9U-4x4CDesV5AouaUsx6CCqYoG_k4qbAFtUob5OycXcZZYrPhnoeJHjv795xU_cvZwf0h9DntWk2vx5Uj3gay3RJ4_STEl4NPU8wOGWp31huLmkkhlRIT55NkL9ndp0lQtax0JZ3Wl36V9R-lPyvjiqk" rel="">gift subscription</a><span> to a friend, colleague, or family member. If you really liked it, read my book, </span><a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501183089" rel="">Goliath: The 100-Year War Between Monopoly Power and Democracy</a><span>.</span></p><p>cheers,</p><p>Matt Stoller.</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A kernel bug froze my machine: Debugging an async-profiler deadlock (106 pts)]]></title>
            <link>https://questdb.com/blog/async-profiler-kernel-bug/</link>
            <guid>46280465</guid>
            <pubDate>Mon, 15 Dec 2025 20:52:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://questdb.com/blog/async-profiler-kernel-bug/">https://questdb.com/blog/async-profiler-kernel-bug/</a>, See on <a href="https://news.ycombinator.com/item?id=46280465">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>
  QuestDB is the open-source time-series database for demanding workloads‚Äîfrom trading floors to mission control.
  It delivers ultra-low latency, high ingestion throughput, and a multi-tier storage engine.
  Native support for Parquet and SQL keeps your data portable, AI-ready‚Äîno vendor lock-in.</p>
<hr>
<p>I've been a Linux user since the late 90s, starting with <a href="http://www.slackware.com/">Slackware</a> on an underpowered AMD K6.
Over the years I've hit plenty of bugs, but the last decade has been remarkably stable - until a kernel bug started
freezing my machine whenever I used <a href="https://github.com/async-profiler/async-profiler/">async-profiler</a>.</p>
<p>I'm not a kernel developer, but I found myself poking around kernel source code to understand the problem better and
figure out what was going on under the hood.</p>
<h2 id="the-problem"><a href="#the-problem">The problem</a></h2>
<p>I was about to start an investigation of latency spikes in QuestDB reported by a user. To do that, I wanted to use the async-profiler to capture <a href="https://github.com/async-profiler/async-profiler/blob/3a493bedc4c6463ba19970018c50e0c9d7dcbfda/docs/Heatmap.md">CPU heatmaps</a>.</p>
<figure><div><p><img alt="Screenshot of async-profiler heatmap" src="https://questdb.com/images/blog/2025-12-11/heatmap.webp" loading="lazy"></p><figcaption>Async-profiler heatmap example</figcaption></div></figure>
<p>However, when I tried to attach the profiler, my machine froze completely. It did not respond to any
keys, it was impossible to switch to a terminal, it did not respond to SSH. The only way to recover was to hard
reboot it. I tried to start QuestDB with the profiler already configured to start at launch - the same result, a frozen machine almost immediately after the launch.</p>
<p>I thought that was weird, this had not happened to me in years. It was already late in the evening, I felt tired anyway so I decided to call it a day. There was a tiny chance I was hallucinating
and the problem would go away by itself overnight. A drowning man will clutch at a straw after all.</p>
<p>The next day, I tried to attach the profiler again - same result, frozen machine. Async-profiler integration in QuestDB is a relatively new feature, so I thought
there might be a bug in the integration code, perhaps a regression in the recent QuestDB release. So I built an older QuestDB version: The same result, frozen machine. This was puzzling - I positively
knew this worked before. How do I know? Because I worked on the <a href="https://github.com/questdb/questdb/pull/6150">integration code</a> not too long ago, and I tested the hell out of it.</p>
<p>This was a strong hint that the problem was not in QuestDB, but rather in the environment. I've gotten lazy since my
Slackware days and I have been using Ubuntu for years now and I realized
that I had recently updated Ubuntu to the latest version: 25.10. Could it be that the problem is in the new Ubuntu
version?</p>
<p>At this point I started Googling around and I found a <a href="https://github.com/async-profiler/async-profiler/issues/1578">report</a> created by a fellow
performance aficionado, <a href="https://x.com/forked_franz">Francesco Nigro</a>, describing exactly the same problem: machine
freeze when using async-profiler. This was the final
confirmation I was not hallucinating! Except Francesco is using Fedora, not Ubuntu. However, his Fedora uses the same kernel version as my Ubuntu: 6.17.
I booted a machine with an older Ubuntu, started QuestDB and attached the profiler and it worked like a charm. This
was yet another indication that the problem was in the system, possibly even in the kernel. This allowed me to
narrow down my Google keywords and find this <a href="https://patchew.org/linux/176216460800.2601451.733142302683512228.tip-bot2@tip-bot2/">kernel patch</a> which talks about the very same problem!</p>
<p>I found it quite interesting: A kernel bug triggered by async-profiler causing machine freezes on recent mainstream distributions. After some poking I found a workaround:
Start the profiler with <code>-e ctimer</code> option to avoid using the problematic kernel feature. I tried the workaround and indeed, with this option, the profiler worked fine and my machine did not freeze.</p>
<p>Normally I'd move on, but I was curious. What exactly is going on under the hood? Why is it freezing? What is this
<code>ctimer</code> thing? What exactly is the bug and how does the patch work? So I decided to dig deeper.</p>

<p>Async-profiler is a sampling profiler. It periodically interrupts threads in the profiled application and collects their stack traces. The collected stack traces are then aggregated and visualized in
various ways (flame graphs are one of the most popular visualizations). It has multiple ways to interrupt the profiled application, the most common one is using <a href="https://man7.org/linux/man-pages/man2/perf_event_open.2.html"><code>perf_events</code></a> kernel feature. This is how it works by default on Linux
assuming <a href="https://www.kernel.org/doc/html/latest/admin-guide/perf-security.html">kernel paranoia settings</a> allow it.</p>
<h3 id="perf_events-under-the-hood"><a href="#perf_events-under-the-hood">perf_events Under the Hood</a></h3>
<p>The <code>perf_events</code> subsystem is a powerful Linux kernel feature for performance monitoring. For CPU profiling, async-profiler uses
a software event called <code>cpu-clock</code>, which is driven by high-resolution timers (<a href="https://docs.kernel.org/timers/hrtimers.html">hrtimers</a>) in the kernel.</p>
<p>Here's the sequence of events during profiling:</p>
<ol>
<li><strong>Setup</strong>: For each thread in the profiled application, async-profiler opens a <a href="https://github.com/async-profiler/async-profiler/blob/c6c2fc1497ab06ff357146ed91fd27c0ce5640ba/src/perfEvents_linux.cpp#L606"><code>perf_event</code></a> file descriptor configured
to generate a signal after a specified interval of CPU time (e.g., 10ms).</li>
<li><strong>Arming the event</strong>: The profiler calls <a href="https://github.com/async-profiler/async-profiler/blob/c6c2fc1497ab06ff357146ed91fd27c0ce5640ba/src/perfEvents_linux.cpp#L645"><code>ioctl(fd, PERF_EVENT_IOC_REFRESH, 1)</code></a> to arm the event for exactly one sample.
This is a one-shot mechanism, combined with the <code>RESET</code> at the end of the handler. The goal is to measure application CPU time only and exclude the signal's handler own overhead.</li>
<li><strong>Timer fires</strong>: When the configured CPU time elapses, the kernel's <a href="https://github.com/torvalds/linux/blob/2424e146bee00ddb4d4f79d3224f54634ca8d2bc/kernel/time/hrtimer.c#L1761">hrtimer fires</a> and delivers a signal to the target thread.</li>
<li><strong>Signal handler</strong>: Async-profiler's signal handler captures the stack trace and <a href="https://github.com/async-profiler/async-profiler/blob/c6c2fc1497ab06ff357146ed91fd27c0ce5640ba/src/perfEvents_linux.cpp#L704">records the sample</a>.
At the end of the handler,
it resets the counter and <a href="https://github.com/async-profiler/async-profiler/blob/c6c2fc1497ab06ff357146ed91fd27c0ce5640ba/src/perfEvents_linux.cpp#L709-L710">re-arms the event</a> for the next sample:</li>
</ol>
<div><pre><p><span>ioctl(fd, PERF_EVENT_IOC_RESET, 0);    // Clear the counter</span></p><p><span>ioctl(fd, PERF_EVENT_IOC_REFRESH, 1);  // Arm for exactly 1 more sample</span></p></pre></div>
<p>This cycle repeats for the duration of the profiling session, creating a stream of stack trace samples that are later
aggregated into flame graphs or heatmaps.</p>
<h2 id="the-kernel-bug"><a href="#the-kernel-bug">The Kernel Bug</a></h2>
<p>The kernel bug that caused my machine to freeze was introduced by commit <a href="https://github.com/torvalds/linux/commit/18dbcbfabfff">18dbcbfabfff ("perf: Fix the POLL_HUP delivery breakage")</a>.
Ironically, this commit was fixing a different bug, but it introduced a deadlock in the cpu-clock event handling.</p>
<p>Here's what happens in the buggy kernel when the <code>PERF_EVENT_IOC_REFRESH(1)</code> counter reaches zero:</p>
<ol>
<li><a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11824">hrtimer</a> fires for cpu-clock event - <a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11749"><code>perf_swevent_hrtimer()</code></a> is called (inside hrtimer interrupt context)</li>
<li><a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11769"><code>perf_swevent_hrtimer()</code> calls</a> <a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L10300"><code>__perf_event_overflow()</code></a> - this processes the counter overflow</li>
<li><code>__perf_event_overflow()</code> <a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L10333">decides to stop</a> the event (counter reached 0 after <code>PERF_EVENT_IOC_REFRESH(1)</code>) - calls <a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11916"><code>cpu_clock_event_stop()</code></a></li>
<li><a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11861"><code>cpu_clock_event_stop()</code></a> calls <a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11800"><code>perf_swevent_cancel_hrtimer()</code></a> - this calls <a href="https://github.com/torvalds/linux/blob/18dbcbfabfffc4a5d3ea10290c5ad27f22b0d240/kernel/events/core.c#L11813"><code>hrtimer_cancel()</code></a> to cancel the timer</li>
<li><strong>DEADLOCK</strong>: <a href="https://github.com/torvalds/linux/blob/2424e146bee00ddb4d4f79d3224f54634ca8d2bc/kernel/time/hrtimer.c#L1483-L1494"><code>hrtimer_cancel()</code></a> waits for the hrtimer callback to complete - but we ARE inside the hrtimer callback! The system hangs forever waiting for itself</li>
</ol>
<p>The function <code>hrtimer_cancel()</code> is a blocking call - it spins waiting for any active callback to finish.</p>
<div><pre><p><span>int hrtimer_cancel(struct hrtimer *timer)</span></p><p><span>{</span></p><p><span>	int ret;</span></p><p><span>	do {</span></p><p><span>		ret = hrtimer_try_to_cancel(timer);</span></p><p><span>		if (ret &lt; 0)</span></p><p><span>			hrtimer_cancel_wait_running(timer);</span></p><p><span>	} while (ret &lt; 0);</span></p><p><span>	return ret;</span></p><p><span>}</span></p></pre></div>
<p>When called from inside that same callback, it waits forever. Since this happens in interrupt context with interrupts disabled on the CPU,
that CPU becomes completely unresponsive. When this happens on multiple CPUs (which it does, since each thread has its own
<code>perf_event</code>), the entire system freezes.</p>
<details><summary>Click to see the deadlock visualized</summary></details>
<h2 id="the-fix"><a href="#the-fix">The Fix</a></h2>
<p>The <a href="https://github.com/torvalds/linux/commit/eb3182ef0405ff2f6668fd3e5ff9883f60ce8801">kernel patch</a> fixes this deadlock with two changes:</p>
<ol>
<li>Replace <code>hrtimer_cancel()</code> with <code>hrtimer_try_to_cancel()</code></li>
</ol>
<div><pre><p><span>- hrtimer_cancel(&amp;hwc-&gt;hrtimer);</span></p><p><span>+ hrtimer_try_to_cancel(&amp;hwc-&gt;hrtimer);</span></p></pre></div>
<p><a href="https://github.com/torvalds/linux/blob/2424e146bee00ddb4d4f79d3224f54634ca8d2bc/kernel/time/hrtimer.c#L1347"><code>hrtimer_try_to_cancel()</code></a> is non-blocking - it returns immediately with:</p>
<ul>
<li><code>0</code> if the timer was not active</li>
<li><code>1</code> if the timer was successfully cancelled</li>
<li><code>-1</code> if the timer callback is currently running</li>
</ul>
<p>Unlike <code>hrtimer_cancel()</code>, it doesn't spin waiting for the callback to finish. So when called from within the callback itself, it simply returns <code>-1</code> and continues.</p>
<ol start="2">
<li>Use <code>PERF_HES_STOPPED</code> flag as a deferred stop signal</li>
</ol>
<p>The stop function now sets a flag:</p>
<div><pre><p><span>static void cpu_clock_event_stop(struct perf_event *event, int flags)</span></p><p><span>{</span></p><p><span>+   event-&gt;hw.state = PERF_HES_STOPPED;</span></p><p><span>    perf_swevent_cancel_hrtimer(event);</span></p><p><span>    ...</span></p><p><span>}</span></p></pre></div>
<p>And the hrtimer callback checks this flag:</p>
<div><pre><p><span>static enum hrtimer_restart perf_swevent_hrtimer(struct hrtimer *hrtimer)</span></p><p><span>{</span></p><p><span>-   if (event-&gt;state != PERF_EVENT_STATE_ACTIVE)</span></p><p><span>+   if (event-&gt;state != PERF_EVENT_STATE_ACTIVE ||</span></p><p><span>+       event-&gt;hw.state &amp; PERF_HES_STOPPED)</span></p><p><span>        return HRTIMER_NORESTART;</span></p></pre></div>
<h3 id="how-it-works-together"><a href="#how-it-works-together">How It Works Together</a></h3>
<p>When <code>cpu_clock_event_stop()</code> is called from within the hrtimer callback:</p>
<ol>
<li><code>PERF_HES_STOPPED</code> flag is set</li>
<li><code>hrtimer_try_to_cancel()</code> returns <code>-1</code> (callback running) - but doesn't block</li>
<li>Execution returns up the call stack back to <code>perf_swevent_hrtimer()</code></li>
<li><code>perf_swevent_hrtimer()</code> completes and returns <code>HRTIMER_NORESTART</code> (because <code>__perf_event_overflow()</code> returned <code>1</code>, indicating the event should stop)</li>
<li>The hrtimer subsystem sees <code>HRTIMER_NORESTART</code> and <a href="https://github.com/torvalds/linux/blob/2424e146bee00ddb4d4f79d3224f54634ca8d2bc/kernel/time/hrtimer.c#L1776-L1778">doesn't reschedule the timer</a></li>
</ol>
<p>When <code>cpu_clock_event_stop()</code> is called from outside the callback (normal case):</p>
<ol>
<li><code>PERF_HES_STOPPED</code> flag is set</li>
<li><code>hrtimer_try_to_cancel()</code> returns <code>0</code> or <code>1</code> - timer is cancelled immediately</li>
<li>If by chance the callback fires before cancellation completes, it sees <code>PERF_HES_STOPPED</code> and returns <code>HRTIMER_NORESTART</code></li>
</ol>
<p>The <code>PERF_HES_STOPPED</code> flag acts as a safety net to make sure the timer stops regardless of the race between setting the flag and the timer firing.</p>
<h3 id="debugging-a-kernel"><a href="#debugging-a-kernel">Debugging a kernel</a></h3>
<p>The explanation above is my understanding of the kernel bug and the fix based on reading the kernel source code.
I am a hacker, I like to tinker. A theoretical understanding is one thing, but I wanted to see it in action.
But how do you even debug a kernel? I'm not a kernel developer, but I decided to try. Here is how I did it.</p>
<p>My intuition was to use <a href="https://www.qemu.org/">QEMU</a> since it allows one to emulate or virtualize a full machine. QEMU also has a built-in <a href="https://www.sourceware.org/gdb/">GDB</a>
server that allows you to <a href="https://qemu-project.gitlab.io/qemu/system/gdb.html">connect GDB to the emulated machine</a>.</p>
<h3 id="setting-up-qemu-with-ubuntu"><a href="#setting-up-qemu-with-ubuntu">Setting up QEMU with Ubuntu</a></h3>
<p>I downloaded an Ubuntu 25.10 ISO image and created a new empty VM disk image:</p>
<div><pre><p><span>$ qemu-img create -f qcow2 ubuntu-25.10.qcow2 20G</span></p></pre></div>
<p>Then I launched QEMU to install Ubuntu:</p>
<div><pre><p><span>$ qemu-system-x86_64 \</span></p><p><span>    -enable-kvm \</span></p><p><span>    -m 4096 \</span></p><p><span>    -smp 4 \</span></p><p><span>    -drive file=ubuntu-25.10.qcow2,if=virtio \</span></p><p><span>    -cdrom ubuntu-25.10-desktop-amd64.iso \</span></p><p><span>    -boot d \</span></p><p><span>    -vga qxl</span></p></pre></div>
<p>The second command boots the VM from the ISO image and allows me to install Ubuntu on the VM disk image. I went through
the installation process as usual. I probably could have used a server edition or a prebuilt image, but at this
point I was already in unknown territory, so I wanted to make other things as simple as possible.</p>
<figure><div><p><img alt="QEMU screen showing Ubuntu installation" src="https://questdb.com/images/blog/2025-12-11/ubuntu.webp" loading="lazy"></p><figcaption>Ubuntu installation in QEMU</figcaption></div></figure>
<p>Once the installation was complete, I rebooted the VM:</p>
<div><pre><p><span>$ qemu-system-x86_64 \</span></p><p><span>    -enable-kvm \</span></p><p><span>    -m 4096 \</span></p><p><span>    -smp 4 \</span></p><p><span>    -drive file=ubuntu-25.10.qcow2,if=virtio \</span></p><p><span>    -netdev user,id=net0,hostfwd=tcp::9000-:9000 \</span></p><p><span>    -device virtio-net-pci,netdev=net0 \</span></p><p><span>    -monitor tcp:127.0.0.1:55555,server,nowait \</span></p><p><span>    -s</span></p></pre></div>
<p>and downloaded, unpacked and started QuestDB:</p>
<div><pre><p><span>$ curl -L https://github.com/questdb/questdb/releases/download/9.2.2/questdb-9.2.2-rt-linux-x86-64.tar.gz -o questdb.tar.gz</span></p><p><span>$ tar -xzvf questdb.tar.gz</span></p><p><span>$ cd questdb-9.2.2-rt-linux-x86-64</span></p><p><span>$ ./bin/questdb start</span></p></pre></div>
<p>This was meant to validate that QuestDB works in the VM at all. Firefox was already installed in the Ubuntu desktop
edition, so I just opened <code>http://localhost:9000</code> in Firefox and verified QuestDB web console was up and running.</p>
<figure><div><p><img alt="QuestDB web console running in Ubuntu in QEMU" src="https://questdb.com/images/blog/2025-12-11/console.webp" loading="lazy"></p><figcaption>QuestDB web console in QEMU</figcaption></div></figure>
<p>The next step was to stop QuestDB and start it with a profiler attached:</p>
<div><pre><p><span>$ ./bin/questdb stop</span></p><p><span>$ ./bin/questdb start -p</span></p></pre></div>
<p>At this point, I expected the virtual machine to freeze. However, it didn't. It was responsive as if nothing bad had
happened. That was a bummer. I wanted to see the deadlock in action!
I thought that perhaps QEMU is in a way shielding the virtual machine from the bug. But then I realized that the
default Ubuntu uses paranoia settings that prevent <code>perf_events</code> from working properly and async-profiler <a href="https://github.com/async-profiler/async-profiler/blob/c6c2fc1497ab06ff357146ed91fd27c0ce5640ba/src/profiler.cpp#L995-L998">falls back to
using <code>ctimer</code></a> when <code>perf_events</code> are restricted. The kernel bug specifically lives in the <code>perf_events</code> hrtimer
code path, so we must force async-profiler to use that path to trigger the bug.</p>
<p>To fix this, I changed the paranoia settings:</p>
<div><pre><p><span>$ echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid</span></p></pre></div>
<p>After this, I restarted QuestDB with the profiler again:</p>
<div><pre><p><span>$ ./bin/questdb stop</span></p><p><span>$ ./bin/questdb start -p</span></p></pre></div>
<p>And this time, the virtual machine froze as expected! Success! I was able to reproduce the problem in QEMU!</p>
<h3 id="attaching-gdb-to-qemu"><a href="#attaching-gdb-to-qemu">Attaching GDB to QEMU</a></h3>
<p>Now that I was able to reproduce the problem in QEMU, I wanted to attach GDB to the emulated machine to see the deadlock in action.</p>
<p>Let's start <code>GDB</code> on the host machine and connect it to QEMU's built-in GDB server:</p>
<div><pre><p><span>$ gdb</span></p><p><span>GNU gdb (Ubuntu 16.3-1ubuntu2) 16.3</span></p><p><span>[...]</span></p><p><span>(gdb) target remote :1234</span></p><p><span>Remote debugging using :1234</span></p><p><span>warning: No executable has been specified and target does not support</span></p><p><span>determining executable automatically.  Try using the "file" command.</span></p><p><span>0xffffffff82739398 in ?? ()</span></p><p><span>(gdb) info threads</span></p><p><span>  Id   Target Id                    Frame</span></p><p><span>* 1    Thread 1.1 (CPU#0 [running]) 0xffffffff82739398 in ?? ()</span></p><p><span>  2    Thread 1.2 (CPU#1 [running]) 0xffffffff82739398 in ?? ()</span></p><p><span>  3    Thread 1.3 (CPU#2 [running]) 0xffffffff827614d3 in ?? ()</span></p><p><span>  4    Thread 1.4 (CPU#3 [running]) 0xffffffff82739398 in ?? ()</span></p><p><span>(gdb) thread apply all bt</span></p></pre></div>
<blockquote>
<p>Side note: We just casually attached a debugger to a live kernel! How cool is that?</p>
</blockquote>
<p>We can see 4 threads corresponding to the 4 CPUs in the VM. The <code>bt</code> command shows the stack traces of all threads, but there is not much useful information since we don't have the kernel symbols loaded in GDB.
Let's fix this. I am lazy again and take advantage of running exactly the same kernel version as the host machine so I can use the host's kernel image and symbol files.</p>
<p>On the host machine, we need to add repositories with debug symbols and install the debug symbols for the running kernel:</p>
<div><pre><p><span>echo "deb http://ddebs.ubuntu.com questing main restricted universe multiverse" | sudo tee /etc/apt/sources.list.d/ddebs.list</span></p><p><span>echo "deb http://ddebs.ubuntu.com questing-updates main restricted universe multiverse" | sudo tee -a /etc/apt/sources.list.d/ddebs.list</span></p><p><span>echo "deb http://ddebs.ubuntu.com questing-proposed main restricted universe multiverse" | sudo tee -a /etc/apt/sources.list.d/ddebs.list</span></p><p><span>sudo apt install ubuntu-dbgsym-keyring</span></p><p><span>sudo apt update</span></p><p><span>sudo apt install linux-image-$(uname -r)-dbgsym</span></p></pre></div>
<p>With the debug symbols installed, I started GDB again and loaded the kernel image and symbols:</p>
<div><pre><p><span>$ gdb /usr/lib/debug/boot/vmlinux-$(uname -r)</span></p><p><span>GNU gdb (Ubuntu 16.3-1ubuntu2) 16.3</span></p><p><span>[...]</span></p><p><span>gdb) target remote :1234</span></p><p><span>Remote debugging using :1234</span></p><p><span>0xffffffff9e9614d3 in ?? ()</span></p><p><span>[...]</span></p><p><span>(gdb) info threads</span></p><p><span>  Id   Target Id                    Frame</span></p><p><span>* 1    Thread 1.1 (CPU#0 [running]) 0xffffffff9e9614d3 in ?? ()</span></p><p><span>  2    Thread 1.2 (CPU#1 [running]) 0xffffffff9e939398 in ?? ()</span></p><p><span>  3    Thread 1.3 (CPU#2 [running]) 0xffffffff9e9614d3 in ?? ()</span></p><p><span>  4    Thread 1.4 (CPU#3 [running]) 0xffffffff9e9614d3 in ?? ()</span></p><p><span>(gdb) quit</span></p></pre></div>
<p>and symbols were still NOT resolved! I had to capitulate and ask a LLM for help. After a bit of brainstorming, we
realized that the kernel is compiled with <a href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html">KASLR</a> enabled, so the kernel is loaded at a random address at each boot.
The simplest way to fix this is to disable KASLR, I could not care less about security in my test VM. To disable KASLR, I edited the GRUB configuration, added the <code>nokaslr</code> parameter, updated GRUB and rebooted the VM:</p>
<div><pre><p><span>$ vim /etc/default/grub</span></p><p><span># Add nokaslr to the GRUB_CMDLINE_LINUX_DEFAULT line</span></p><p><span>GRUB_CMDLINE_LINUX_DEFAULT="quiet splash nokaslr"</span></p><p><span>$ sudo update-grub</span></p><p><span>$ sudo reboot</span></p></pre></div>
<p>Then I set the paranoia settings again, started QuestDB with the profiler and attached GDB again. This time, the symbols were resolved correctly!</p>
<div><pre><p><span>$ gdb /usr/lib/debug/boot/vmlinux-$(uname -r)</span></p><p><span>GNU gdb (Ubuntu 16.3-1ubuntu2) 16.3</span></p><p><span>[...]</span></p><p><span>(gdb) target remote :1234</span></p><p><span>[...]</span></p><p><span>(gdb) info threads</span></p><p><span>  Id   Target Id                    Frame</span></p><p><span>* 1    Thread 1.1 (CPU#0 [running]) csd_lock_wait (csd=0xffff88813bd3a460) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351</span></p><p><span>  2    Thread 1.2 (CPU#1 [running]) csd_lock_wait (csd=0xffff88813bd3b520) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351</span></p><p><span>  3    Thread 1.3 (CPU#2 [running]) hrtimer_try_to_cancel (timer=0xffff88802343d028) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>  4    Thread 1.4 (CPU#3 [running]) hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p></pre></div>
<p>This looks much better! We can see that the first 2 threads are stuck in <code>csd_lock_wait()</code> function, presumably waiting for locks held by the other CPUs
and threads 3 and 4 are in <code>hrtimer_try_to_cancel()</code>.</p>
<p>The threads 3 and 4 are the interesting ones since they execute a function related to the kernel bug we are investigating.
Let's switch to thread 4 and see its stack trace:</p>
<div><pre><p><span>(gdb) thread 4</span></p><p><span>[Switching to thread 4 (Thread 1.4)]</span></p><p><span>#0  hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>1359	in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c</span></p><p><span>(gdb) bt</span></p><p><span>#0  hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>#1  hrtimer_cancel (timer=timer@entry=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1488</span></p><p><span>#2  0xffffffff81700605 in perf_swevent_cancel_hrtimer (event=&lt;optimized out&gt;) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11818</span></p><p><span>#3  perf_swevent_cancel_hrtimer (event=0xffff888023439f80) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11805</span></p><p><span>#4  cpu_clock_event_stop (event=0xffff888023439f80, flags=0) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11868</span></p><p><span>#5  0xffffffff81715488 in __perf_event_overflow (event=event@entry=0xffff888023439f80, throttle=throttle@entry=1, data=data@entry=0xffffc90002cd7cc0, regs=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:10338</span></p><p><span>#6  0xffffffff81716eaf in perf_swevent_hrtimer (hrtimer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11774</span></p><p><span>#7  0xffffffff81538a03 in __run_hrtimer (cpu_base=&lt;optimized out&gt;, base=&lt;optimized out&gt;, timer=0xffff88802343a0e8, now=0xffffc90002cd7e58, flags=&lt;optimized out&gt;) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1761</span></p><p><span>#8  __hrtimer_run_queues (cpu_base=cpu_base@entry=0xffff88813bda1400, now=now@entry=48514890563, flags=flags@entry=2, active_mask=active_mask@entry=15) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1825</span></p><p><span>#9  0xffffffff8153995d in hrtimer_interrupt (dev=&lt;optimized out&gt;) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1887</span></p><p><span>#10 0xffffffff813c4ac8 in local_apic_timer_interrupt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1039</span></p><p><span>#11 __sysvec_apic_timer_interrupt (regs=regs@entry=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1056</span></p><p><span>#12 0xffffffff82621724 in instr_sysvec_apic_timer_interrupt (regs=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1050</span></p><p><span>#13 sysvec_apic_timer_interrupt (regs=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1050</span></p><p><span>#14 0xffffffff81000f0b in asm_sysvec_apic_timer_interrupt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/include/asm/idtentry.h:574</span></p><p><span>#15 0x00007b478171db80 in ?? ()</span></p><p><span>#16 0x0000000000000001 in ?? ()</span></p><p><span>#17 0x0000000000000000 in ?? ()</span></p></pre></div>
<p>We can see the exact sequence of function calls leading to the deadlock: <code>hrtimer_try_to_cancel()</code> called from <code>cpu_clock_event_stop()</code>, called from <code>__perf_event_overflow()</code>, called from <code>perf_swevent_hrtimer()</code>.
This matches our understanding of the bug perfectly! This is the infinite loop in <code>hrtimer_cancel()</code> that causes the
deadlock.</p>
<h2 id="forensics-and-playing-god"><a href="#forensics-and-playing-god">Forensics and Playing God</a></h2>
<p>Okay, I have to admit that seeing a kernel stack trace is already somewhat satisfying, but we have a live (well,
half-dead) kernel under a debugger. Let's have some fun. I want to touch the deadlock and understand why it took
down the  whole machine, and see if we can perform a miracle and bring it back to life.</p>
<h4>Confirming the suspect</h4>
<p>We know <code>hrtimer_cancel</code> is waiting for a callback to finish. But which callback? The stack trace says <code>perf_swevent_cancel_hrtimer</code>,
but let's verify the hrtimer struct in memory actually points to the function we blame.</p>
<p>I switched to the stuck thread (Thread 4 in my case) and looked at frame #0:</p>
<div><pre><p><span>(gdb) thread 4</span></p><p><span>[Switching to thread 4 (Thread 1.4)]</span></p><p><span>#0  hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>1359	in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c</span></p><p><span>(gdb) frame 0</span></p><p><span>#0  hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>1359	in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c</span></p><p><span>(gdb) print *timer</span></p><p><span>$1 = {node = {node = {__rb_parent_color = 18446612682661667048, rb_right = 0x0, rb_left = 0x0}, expires = 48514879474}, _softexpires = 48514879474, function = 0xffffffff81716dd0 &lt;perf_swevent_hrtimer&gt;, base = 0xffff88813bda1440, state = 0 '\000', is_rel = 0 '\000', is_soft = 0 '\000', is_hard = 1 '\001'}</span></p></pre></div>
<p>Let me explain these GDB commands: <code>frame 0</code> selects the innermost stack frame - the function currently executing.
In a backtrace, frame 0 is the current function, frame 1 is its caller, frame 2 is the caller's caller, and so on.
By selecting frame 0, I can inspect local variables and parameters in <code>hrtimer_try_to_cancel()</code>.</p>
<p>The <code>print *timer</code> command dereferences the <code>timer</code> pointer and displays the contents of the <code>struct hrtimer</code>:</p>
<div><pre><p><span>struct hrtimer {</span></p><p><span>    struct timerqueue_node  node;</span></p><p><span>    ktime_t                 _softexpires;</span></p><p><span>    enum hrtimer_restart    (*function)(struct hrtimer *);</span></p><p><span>    struct hrtimer_clock_base *base;</span></p><p><span>    u8                      state;</span></p><p><span>    u8                      is_rel;</span></p><p><span>    u8                      is_soft;</span></p><p><span>    u8                      is_hard;</span></p><p><span>};</span></p></pre></div>
<p>The key field here is <code>function</code> - a pointer to a callback function that takes a <code>struct hrtimer *</code> and returns
<code>enum hrtimer_restart</code>. This callback is invoked when the timer fires. GDB shows it points to <code>0xffffffff81716dd0</code> and helpfully resolves this address to <code>perf_swevent_hrtimer</code>. Since we're currently <em>inside</em> <code>perf_swevent_hrtimer</code> (look at frame #6 in our backtrace above), this confirms the self-deadlock: the timer is trying to cancel itself while its own callback is still running!</p>
<h4>The Mystery of the "Other" CPUs</h4>
<p>One question remained: If CPUs 3 and 4 are deadlocked in a loop, why did the entire machine freeze? Why couldn't I just SSH in and kill the process?
The answer lies in those other threads we saw earlier, stuck in <code>csd_lock_wait</code>:</p>
<div><pre><p><span>(gdb) thread 1</span></p><p><span>[Switching to thread 1 (Thread 1.1)]</span></p><p><span>#0  csd_lock_wait (csd=0xffff88813bd3a460) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351</span></p><p><span>warning: 351	/build/linux-8YMEfB/linux-6.17.0/kernel/smp.c: No such file or directory</span></p></pre></div>
<p><code>CSD</code> stands for Call Function Single Data. In Linux, when one CPU wants another CPU to do something (like flush a TLB
or stop a perf_event), it sends an IPI (Inter-Processor Interrupt).
If the target CPU is busy with interrupts disabled (which is exactly the case for our deadlocked CPUs 3 and 4), it never responds.</p>
<p>The sender (CPU 0) sits there <a href="https://github.com/torvalds/linux/blob/fe90f3967bdb3e13f133e5f44025e15f943a99c5/include/asm-generic/barrier.h#L260-L274">spinning</a>,
waiting for the other <a href="https://github.com/torvalds/linux/blob/83e6384374bac8a9da3411fae7f24376a7dbd2a3/kernel/smp.c#L547">CPU to say "Done!"</a>. Eventually, all CPUs end up waiting for the stuck CPUs and the entire
system grinds to a halt.</p>
<h4>Performing a Kernel Resurrection</h4>
<p>This is the part where the real black magic starts. We know the kernel is stuck in this loop in <code>hrtimer_cancel</code>:</p>
<div><pre><p><span>do {</span></p><p><span>    ret = hrtimer_try_to_cancel(timer);</span></p><p><span>} while (ret &lt; 0);</span></p></pre></div>
<p>As long as <code>hrtimer_try_to_cancel</code> returns <code>-1</code> (which it does, because the callback is running), the loop continues
forever.</p>
<p>But we have GDB. We can change reality.</p>
<p>If we force the function to return <code>0</code> (meaning "timer not active"), the loop should break, <code>cpu_clock_event_stop</code>
should finish, and the kernel should unfreeze. It might crash 1 millisecond later because we left the timer in an
inconsistent state, but perhaps it's worth trying.</p>
<p>First, let's double-check we are in the innermost frame, inside <code>hrtimer_try_to_cancel</code>:</p>
<div><pre><p><span>(gdb) thread 4</span></p><p><span>[Switching to thread 4 (Thread 1.4)]</span></p><p><span>#0  hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>warning: 1359	/build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c: No such file or directory</span></p><p><span>(gdb) frame 0</span></p><p><span>#0  hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>1359	in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c</span></p></pre></div>
<p>Use the GDB <code>finish</code> command to let the function run to completion and pause right when it returns to the caller:</p>

<p>We are now sitting at line 1490, right at the check <code>if (ret &lt; 0)</code>.</p>
<div><pre><p><span>int hrtimer_cancel(struct hrtimer *timer)</span></p><p><span>{</span></p><p><span>	int ret;</span></p><p><span>	do {</span></p><p><span>		ret = hrtimer_try_to_cancel(timer);</span></p><p><span>		if (ret &lt; 0) // &lt;-- we are here</span></p><p><span>			hrtimer_cancel_wait_running(timer);</span></p><p><span>	} while (ret &lt; 0);</span></p><p><span>	return ret;</span></p><p><span>}</span></p></pre></div>
<p>On x86_64, integer return values are passed in the <code>%rax</code> register.
Since <code>hrtimer_try_to_cancel</code> returns an <code>int</code> (32-bit), we can use <code>$eax</code> (the lower 32 bits of <code>%rax</code>):</p>

<p>Exactly as expected. <code>-1</code> means the timer callback is running, so the loop will continue.
But since the CPU is paused, we can overwrite this value. We can lie to the kernel and tell it the timer was
successfully cancelled (return code 1) or inactive (return code 0). I chose 0.</p>
<div><pre><p><span>(gdb) set $eax = 0</span></p><p><span>(gdb) print $eax</span></p><p><span>$3 = 0</span></p></pre></div>
<p>I crossed my fingers and unpaused the VM:</p>
<div><pre><p><span>(gdb) continue</span></p><p><span>Continuing.</span></p></pre></div>
<p>And it did nothing. The VM was still frozen. Let's see what is going on:</p>
<div><pre><p><span>(gdb) info threads</span></p><p><span>  Id   Target Id                    Frame</span></p><p><span>  1    Thread 1.1 (CPU#0 [running]) csd_lock_wait (csd=0xffff88813bd3a460) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351</span></p><p><span>  2    Thread 1.2 (CPU#1 [running]) csd_lock_wait (csd=0xffff88813bd3b520) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351</span></p><p><span>  3    Thread 1.3 (CPU#2 [running]) hrtimer_try_to_cancel (timer=0xffff88802343d028) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359</span></p><p><span>* 4    Thread 1.4 (CPU#3 [running]) csd_lock_wait (csd=0xffff88813bd3b560) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351</span></p></pre></div>
<p>Now, thread 4 is also stuck in <code>csd_lock_wait</code>, just like threads 1 and 2. We managed to escape from the infinite
loop in thread 4, but thread 3 is still stuck in <code>hrtimer_try_to_cancel</code>.</p>
<p>We could try the same trick on thread 3, but would this be enough to unfreeze the entire system? For starters, we
tricked the kernel into thinking the timer was inactive, but in reality it is still active.  This is very thin ice
to skate on - we might have just created more problems for ourselves. And more importantly, even if the kernel could
escape the deadlock, the profiler would immediately try to re-arm the timer again, leading us back into the same
deadlock.</p>
<p>So I decided to give up on the resurrection attempt. The kernel was stuck, but at least I understood the problem now and I was pretty happy with my newly acquired kernel debugging skills.</p>
<h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>
<p>While I couldn't perform a miracle and resurrect the frozen kernel, I walked away with a much deeper understanding
of the machinery behind Linux <code>perf_events</code> and hrtimers. I learned how to set up QEMU for kernel debugging, how to attach GDB to a live kernel, and how to inspect kernel data structures in memory.</p>
<p>For QuestDB users, the takeaway is simple: if you are on a kernel version 6.17, use the <code>-e ctimer</code> flag when
profiling. It bypasses the buggy <code>perf_events</code> hrtimer path entirely. Or just wait for either the kernel fix to land
in your distro or the next QuestDB release, which will <a href="https://github.com/questdb/questdb/pull/6473">include</a> an
async-profiler version that <a href="https://github.com/async-profiler/async-profiler/pull/1599">works around this issue</a>.</p>
<p>As for me, I‚Äôm going back to my code. The next time my machine freezes, I might just reboot it like a normal person. But where is the fun in that?</p>
<h2 id="addendum:-the-second-resurrection-attempt"><a href="#addendum:-the-second-resurrection-attempt">Addendum: The Second Resurrection Attempt</a></h2>
<p>After writing this post, I kept thinking about that failed resurrection attempt. We got so close: We broke one CPU out of the deadlock, but the other was still stuck. I should have tried harder!
So I started QEMU again, reproduced the deadlock, and this time came with a plan: use GDB to force kernel to kill the QuestDB Java process, so the profiler can't re-arm the timer.</p>
<p>First, I needed to find the Java process. The <code>perf_event</code> structure has an owner field pointing to the task that created it:</p>
<div><pre><p><span>(gdb) print event-&gt;owner</span></p><p><span>$1 = (struct task_struct *) 0xffff88810b2ed100</span></p><p><span>(gdb) print ((struct task_struct *)0xffff88810b2ed100)-&gt;comm</span></p><p><span>$2 = "java"</span></p><p><span>(gdb) print ((struct task_struct *)0xffff88810b2ed100)-&gt;pid</span></p><p><span>$3 = 4488</span></p></pre></div>
<p>Great, we found the Java process with PID 4488. Now, how do you kill a process when the kernel is deadlocked and can't process signals?
You store the signal directly in memory. <code>SIGKILL</code> is signal 9, which means bit 8 in the signal bitmask:</p>
<div><pre><p><span>(gdb) set ((struct task_struct *)0xffff88810b2ed100)-&gt;signal-&gt;shared_pending.signal.sig[0] = 0x100</span></p></pre></div>
<p>With the pending kill signal in place, I broke the deadlock loop as before. The system hit another deadlock - a different CPU was now stuck waiting for a spinlock.
The lock value showed it was held:</p>
<div><pre><p><span>(gdb) print *((unsigned int *)0xffff88813bda1400)</span></p><p><span>$4 = 1</span></p></pre></div>
<p>I forcibly released the lock <em>(what could possibly go wrong?)</em>:</p>
<div><pre><p><span>(gdb) set *((unsigned int *)0xffff88813bda1400) = 0</span></p></pre></div>
<p>Then broke another <code>hrtimer</code> loop on a different CPU. It was like playing whack-a-mole with deadlocks - each Java thread had its own <code>perf_event</code>, and they were all hitting the same bug.</p>
<p>After a few rounds of this, I ran continue and checked the threads:</p>
<div><pre><p><span>(gdb) continue</span></p><p><span>Continuing.</span></p><p><span>^C</span></p><p><span>Thread 4 received signal SIGINT, Interrupt.</span></p><p><span>0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82</span></p><p><span>(gdb) info threads</span></p><p><span>  Id   Target Id                    Frame</span></p><p><span>  1    Thread 1.1 (CPU#0 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82</span></p><p><span>  2    Thread 1.2 (CPU#1 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82</span></p><p><span>  3    Thread 1.3 (CPU#2 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82</span></p><p><span>* 4    Thread 1.4 (CPU#3 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82</span></p><p><span>(gdb) continue</span></p></pre></div>
<figure><div><p><img alt="terminal screen showing gdb output" src="https://questdb.com/images/blog/2025-12-11/gdb.webp" loading="lazy"></p><figcaption>GDB output showing all CPUs resting peacefully in halt state</figcaption></div></figure>
<p>I looked at the QEMU window. The desktop was responsive. The mouse moved. Java was gone - killed by the <code>SIGKILL</code> we planted before breaking the deadlock.
We actually did it. We resurrected a kernel-deadlocked machine by lying to it about return values, forcibly releasing locks, and planting signals in process memory.
Would I recommend this in production (or anywhere outside a lab)? Absolutely not. But was it fun? Totally!</p>
<figure><div><p><img alt="QEMU screen showing Ubuntu desktop" src="https://questdb.com/images/blog/2025-12-11/lazarus.webp" loading="lazy"></p><figcaption>Lazarus rising from the dead</figcaption></div></figure></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A quarter of US-trained scientists eventually leave (144 pts)]]></title>
            <link>https://arxiv.org/abs/2512.11146</link>
            <guid>46280080</guid>
            <pubDate>Mon, 15 Dec 2025 20:25:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.11146">https://arxiv.org/abs/2512.11146</a>, See on <a href="https://news.ycombinator.com/item?id=46280080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.11146">View PDF</a>
    <a href="https://arxiv.org/html/2512.11146v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Using newly-assembled data from 1980 through 2024, we show that 25% of scientifically-active, US-trained STEM PhD graduates leave the US within 15 years of graduating. Leave rates are lower in the life sciences and higher in AI and quantum science but overall have been stable for decades. Contrary to common perceptions, US technology benefits from these graduates' work even if they leave: though the US share of global patent citations to graduates' science drops from 70% to 50% after migrating, it remains five times larger than the destination country share, and as large as all other countries combined. These results highlight the value that the US derives from training foreign scientists - not only when they stay, but even when they leave.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Dror Shvadron [<a href="https://arxiv.org/show-email/1a154460/2512.11146" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 11 Dec 2025 22:10:20 UTC (5,427 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The appropriate amount of effort is zero (182 pts)]]></title>
            <link>https://expandingawareness.org/blog/the-appropriate-amount-of-effort-is-zero/</link>
            <guid>46279825</guid>
            <pubDate>Mon, 15 Dec 2025 20:09:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://expandingawareness.org/blog/the-appropriate-amount-of-effort-is-zero/">https://expandingawareness.org/blog/the-appropriate-amount-of-effort-is-zero/</a>, See on <a href="https://news.ycombinator.com/item?id=46279825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Most people put too much effort into everything they do. Here‚Äôs a good example from Kristijan around tension in his hands when touching and holding things:</p>
<figure><blockquote><div lang="en" dir="ltr"><p>Something clicked about inhibition and non-doing (in Alexander Technique), and the strongest effect has been a relaxation of my hands.</p><p>Like I was touching and holding things with 40% more tension than required for that object or activity.<a href="https://twitter.com/m_ashcroft?ref_src=twsrc%5Etfw&amp;ref=expandingawareness.org">@m_ashcroft</a> any thoughts?</p></div>‚Äî Kristijan (@kristijan_moves) <a href="https://twitter.com/kristijan_moves/status/1958193756114423812?ref_src=twsrc%5Etfw&amp;ref=expandingawareness.org">August 20, 2025</a></blockquote>
</figure><p>It‚Äôs a great example, because gripping too tightly, as we might with the hands, is a great metaphor for what it‚Äôs like everywhere else in your system. There‚Äôs a pattern of pervasive over-gripping that, once you start to look for it, you will find everywhere.</p>
<p>There is an appropriate amount of energy required for each activity. Holding a cup, turning a steering wheel, or writing a blog post all need exactly the amount of energy that they need. This may sound like a truism, but if it were so obvious, why do many drivers often realise they are driving with a vice-like grip, with tension running up into their shoulders and jaws?</p>
<p>Let me share my slightly unusual definition of ‚Äúeffort‚Äù: it‚Äôs the felt experience of expending energy beyond what an activity requires, like tensing your brow when you try to understand something, or the excess tension in your hand when you hold your phone<sup><a href="#fn1" id="fnref1">[1]</a></sup>.</p>
<p>Using this definition, it‚Äôs clear that the appropriate amount of <em>effort</em> for any activity is zero.</p>
<p>This idea is where the concept of non-doing can trip people up, because it doesn‚Äôt mean no action. It means no effort, even though the amount of energy required could be large. Or, to borrow from Daoist wisdom:</p>
<blockquote>
<p>"Nature does not hurry, yet everything is accomplished." ‚Äî Lao Tzu</p>
</blockquote>
<p>Nature is an enormous flow of energy, yet nature makes no effort. Everything nature does is perfectly well-suited to what it does, and it cannot be otherwise.  This is why non-doing comes with a felt experience of effortlessness, when it seems like everything is working exactly the way it‚Äôs supposed to be.</p>
<p>Consider this quote from Katie Ledecky who, with 14 Olympic medals, is described as ‚Äú<a href="https://en.wikipedia.org/wiki/Katie_Ledecky?ref=expandingawareness.org">the most decorated female swimmer in history</a>‚Äù:</p>
<blockquote>
<p>‚ÄúI felt so relaxed. It just felt very easy, and that's why it surprised me that I had broken my world record.‚Äù ‚Äî <em>Katie Ledecky</em></p>
</blockquote>
<p>Not only that, but trying too hard can reduce performance. Here‚Äôs marathoner Ryan Hall:</p>
<blockquote>
<p>‚Äú‚Ä¶ you don't get your best performances by trying harder. When you see the guy who wins the race, he usually jogs out of it waving to the crowd, feeling good. The people who look the worst come in after the top guy.‚Äù<sup><a href="#fn2" id="fnref2">[2]</a></sup> ‚Äì <em>Ryan Hall</em></p>
</blockquote>
<p>So why is it so common to effort when it both feels harder and reduces performance?</p>
<p>For one thing, there are all kinds of societal scripts in the modern age that push us in that direction. All those hustle bros captured by <a href="https://michaelashcroft.com/writing/awakening-to-and-escapting-from-total-work/?ref=expandingawareness.org">Total Work</a> push their grindset worldview, recapitulating the Protestant work ethic for new audiences. The influence of these cultural waters on our psychophysical wiring can‚Äôt be overstated.</p>
<p>These scripts team up with one of the core principles of Alexander Technique: Faulty Sensory Appreciation. When you try so hard all the time, that level of effort feels familiar and you stop noticing it. Put another way, years of overdoing mis-calibrate your senses so effort feels right and ease feels wrong. If you follow your feelings, you are guided back to that same old familiar where you‚Äôre trying too hard without even realising it.</p>
<p>By the way, this phenomenon happens <em>all the time</em> in many other domains, and can be the cause of much trouble.</p>
<p>What all this means is that when you pull back the effort below your familiar baseline, it can feel unfamiliar, like you‚Äôre not trying hard enough, and those societal scripts I mentioned before can make this experience hard to stay in, even if you‚Äôre now closer to the appropriate amount of energy needed.</p>
<p>The way out of this is to experiment with feeling the unfamiliarity of trying less hard and seeing what it‚Äôs like. In Kristijan‚Äôs case, he played with this for long enough that his sensory perception updated to reflect what was going on more accurately, and he was able to feel that he had been using too much tension before.</p>
<p>So I invite you to go about your day and practice dropping the effort. See how weird it feels, but notice how the activity is still getting done. See what it‚Äôs like to drop the energy too low, where you might become lethargic or your performance drops. Notice the sweet spot as a surprising experience of ease and a kind of elegance: the less you grip, the smoother and more precise the movement.</p>
<p>Happy experimenting!</p>
<hr>
<section>
<ol>
<li id="fn1"><p>If you get hung up on this definition, just substitute it for something like ‚Äúover-efforting‚Äù or ‚Äútrying too hard‚Äù, as the underlying phenomenon is the same regardless of what you call it. <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p><a href="https://www.newyorker.com/sports/sporting-scene/the-philosophy-of-ryan-hall?ref=expandingawareness.org">The Philosophy of Ryan Hall</a> <a href="#fnref2">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

<!--kg-card-begin: html-->
<div>
<hr>
<p><span>If you liked this you may also enjoy these</span>
</p></div>
<!--kg-card-end: html-->
<figure><a href="https://expandingawareness.org/blog/non-doing-or-non-forcing/"><div><p>Non-doing or non-forcing?</p><p>I want to unpick a challenge that was presented to me: why do I say non-doing, which can confuse people, instead of something more clear like non-forcing? Non-doing or non-forcing? Indeed, Alan Watts himself preferred the term forcing in translating the ‚Äòwei‚Äô in ‚Äòwu-wei‚Äô: ‚ÄúWu-wei is the principle of not</p><p><img src="https://cdn.getmidnight.com/57d3d307ea7a3152cb20d145dd50914b/icon/android-chrome-192x192.png" alt=""><span>Michael Ashcroft</span></p></div><p><img src="https://cdn.getmidnight.com/57d3d307ea7a3152cb20d145dd50914b/thumbnail/Non-doing-or-non-forcing-_900px.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://expandingawareness.org/blog/disengaging-your-parking-brake/"><div><p>Disengaging your parking brake</p><p>A few years ago ‚Äî during a road trip from Boston, MA, to Burlington, VT ‚Äî I
noticed the engine of my hire car was working quite hard and the steering was
heavy. When I stopped at a farm to investigate, and to sample some maple syrup and
cheese, I realised that</p><p><img src="https://cdn.getmidnight.com/57d3d307ea7a3152cb20d145dd50914b/icon/android-chrome-192x192.png" alt=""><span>Expanding Awareness</span><span>Michael Ashcroft</span></p></div><p><img src="https://cdn.getmidnight.com/57d3d307ea7a3152cb20d145dd50914b/thumbnail/Disengage-your-parking-brake_900px.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://expandingawareness.org/blog/to-rush-is-to-try-to-compress-time/"><div><p>To rush is to try to compress time</p><p>I‚Äôm fascinated by the felt experience of rushing, because It seems that rushing
can be a sneaky two for the price of one type of deal; we may mean one thing by
it, but we usually get something extra as well, something that‚Äôs easy to miss. We usually use rush</p><p><img src="https://cdn.getmidnight.com/57d3d307ea7a3152cb20d145dd50914b/icon/android-chrome-192x192.png" alt=""><span>Expanding Awareness</span><span>Michael Ashcroft</span></p></div><p><img src="https://cdn.getmidnight.com/57d3d307ea7a3152cb20d145dd50914b/thumbnail/To-rush-is-to-try-to-compress-time_900px.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Upcoming Changes to Let's Encrypt Certificates (306 pts)]]></title>
            <link>https://community.letsencrypt.org/t/upcoming-changes-to-let-s-encrypt-certificates/243873</link>
            <guid>46279241</guid>
            <pubDate>Mon, 15 Dec 2025 19:30:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.letsencrypt.org/t/upcoming-changes-to-let-s-encrypt-certificates/243873">https://community.letsencrypt.org/t/upcoming-changes-to-let-s-encrypt-certificates/243873</a>, See on <a href="https://news.ycombinator.com/item?id=46279241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>Let‚Äôs Encrypt is introducing several updates to the certificates we issue, including new root certificates, the deprecation of TLS client authentication, and shortening certificate lifetimes. To help roll out changes gradually, we‚Äôre making use of <a href="https://letsencrypt.org/2025/01/09/acme-profiles">ACME profiles</a> to allow users to have control over when some of these changes take place. For most users, no action is required.</p>
<p>Let‚Äôs Encrypt has generated two new Root Certification Authorities (CAs) and six new Intermediate CAs, which we‚Äôre collectively calling the ‚ÄúGeneration Y‚Äù hierarchy. These are cross-signed from our existing ‚ÄúGeneration X‚Äù roots, X1 and X2, so will continue to work anywhere our current roots are trusted.</p>
<p>Most users get certificates from our default <a href="https://letsencrypt.org/docs/profiles/#classic">classic</a> profile, unless they‚Äôve opted into another profile. This profile will switch to the new Generation Y hierarchy on May 13 2026. These new intermediates do not contain the ‚ÄúTLS Client Authentication‚Äù Extended Key Usage due to an upcoming root program requirement. We have previously announced our plans to <a href="https://letsencrypt.org/2025/05/14/ending-tls-client-authentication">end TLS Client Authentication</a> starting in February 2026, which will coincide with the switch to the Generation Y hierarchy. Users who encounter issues or need an extended period to switch can use our <a href="https://letsencrypt.org/docs/profiles/#tlsclient">tlsclient</a> profile until May 2026, which will also remain on our existing Generation X roots.</p>
<p>If you‚Äôre requesting certificates from our <a href="https://letsencrypt.org/docs/profiles/#tlsserver">tlsserver</a> or <a href="https://letsencrypt.org/docs/profiles/#shortlived">shortlived</a> profiles, you‚Äôll begin to see certificates which come from the Generation Y hierarchy this week. This switch will also mark the opt-in general availability of short-lived certificates from Let‚Äôs Encrypt, including support for IP Addresses on certificates.</p>
<p>We also announced our timeline to comply with upcoming changes to the <a href="https://cabforum.org/working-groups/server/baseline-requirements/requirements/">CA/Browser Forum Baseline Requirements</a>, which will require us to shorten the length of time our certificates are valid for. Next year, you‚Äôll be able to opt-in to 45 day certificates for early adopters and testing via the tlsserver profile. In 2027, we‚Äôll lower the default certificate lifetime to 64 days, and then to 45 in 2028. For the full timeline and details, please see our post on <a href="https://letsencrypt.org/2025/12/02/from-90-to-45">decreasing certificate lifetimes to 45 days</a>.</p>
<p>For most users, no action is required, but we recommend reviewing the linked blog posts announcing each of these changes for more details. If you have any questions, please do not hesitate to ask here, on this forum.</p>
            </div></div>]]></description>
        </item>
    </channel>
</rss>