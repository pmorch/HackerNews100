<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 09 Mar 2025 00:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Kill your Feeds – Stop letting algorithms dictate what you think (563 pts)]]></title>
            <link>https://usher.dev/posts/2025-03-08-kill-your-feeds/</link>
            <guid>43302132</guid>
            <pubDate>Sat, 08 Mar 2025 18:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://usher.dev/posts/2025-03-08-kill-your-feeds/">https://usher.dev/posts/2025-03-08-kill-your-feeds/</a>, See on <a href="https://news.ycombinator.com/item?id=43302132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>
We are being boiled like frogs. It happened gradually, one algorithmic tweak at a time. What started as a way to connect with friends has become a system that gives the corporations that run social media control over what we consume and the ability to subtly shape how we think.
</p>
<p>We used to control apps like Facebook and Instagram with our own choices. They became daily comforts, making the world seem a little bit smaller and closer by bringing the people that we cared about together in to one place.</p>
<p>But from the perspective of these companies, that’s a problem. Our personal worlds, our friends, family, and connections, are finite. Once we’ve caught up, we put the app down. That’s bad for business.</p>
<p>Social media companies need us flicking through their apps as long as they can keep us there. More eyes on ads is more money. So they play the system a bit. You’ve lingered on enough photos of cute puppies, they know what you like.</p>
<p>Before long those feeds of finite content are replaced by infinite algorithmic content pulled from millions of users trying to optimise their posts to be picked up by the omnipotent algorithms. Algorithms which are completely opaque to us.</p>
<p>Sci-fi imagines megacorporations controlling our minds with brain implants. Some worry that companies are already listening in. But they don’t have to - they already control our eyes.</p>
<p>The creators of TikTok, Instagram etc. have gained control over exactly what we see. What we see strongly influences how we think. <a href="https://en.m.wikipedia.org/wiki/2021_Facebook_leak">They know</a> that their feeds make us angry, they know the negative effects on our mental health (particularly that of teens), and they know that they have an influence on our opinion.</p>
<p>With the power to shape what we see comes the power to shape what we believe. Whether through deliberate manipulation or the slow creep of algorithmic recommendations, engagement is fueled by outrage, and outrage breeds extremism. The result is a feedback loop that isolates users, reinforces beliefs, and deprioritises opposing viewpoints.</p>
<p>We live in times where being able to form our own opinion is more important than ever. Where knowing how to source and identify truthful information is a critical skill.</p>
<p>Our reliance on being spoon fed ideas is destroying those abilities, Alec of Technology Connections calls this <a href="https://youtu.be/QEJpZjg8GuA">algorithmic complacency</a>, referencing our increasing inability to look outside our algorithmically created bubble. The social media companies don’t care, the only person who has any interest in fixing this is you.</p>
<h2 id="take-the-power-back">Take the Power Back</h2>
<p>It’s time to take back control of how we think. We’ve identified the problem, now it’s time to take action.</p>
<p>We don’t all have the freedom, interest or willpower to delete social media from our lives entirely. It’s still where our friends are, an occasional distraction from reality and a source of entertainment. You don’t have to become a digital outcast to hold back this influence.</p>
<p>So what can we do?</p>
<ol>
<li>Go directly to the source - if you like a particular TikTok creator, Facebook page or YouTube channel, skip the feed and go directly to their pages. Consider bookmarking their profiles individually.</li>
<li>Learn to find information and entertainment without a feed - try to find a creator making videos or writing about a topic of interest without having to stumble across them in a feed.</li>
<li>Use platforms and platform features that let you control your experience - Instagram’s ‘Following’ feed, YouTube’s Subscriptions page, <a href="https://bsky.app/">Bluesky</a>, <a href="https://mastodon.social/">Mastodon</a> and <a href="https://zapier.com/blog/how-to-use-rss-feeds/">RSS feeds</a></li>
<li>Be mindful of engagement traps - recognise how algorithmic feeds are designed to keep you engaged and scrolling. Take a breath and stop the cycle.</li>
<li>Talk about it - if you’re reading this you a already know this is a problem. Your friends and family may not be aware of how their feeds are manipulating their attention and beliefs. Without intervention, the radicalisation of opinions, and the consequences we’re already seeing, will only escalate.</li>
</ol>
<p>The internet should serve you, not the other way around. Take back control. Kill your feeds before they kill your ability to think independently.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google will still have to break up its business, the Justice Department said (179 pts)]]></title>
            <link>https://www.engadget.com/big-tech/google-will-still-have-to-break-up-its-business-the-justice-department-said-150000739.html</link>
            <guid>43302097</guid>
            <pubDate>Sat, 08 Mar 2025 18:08:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/big-tech/google-will-still-have-to-break-up-its-business-the-justice-department-said-150000739.html">https://www.engadget.com/big-tech/google-will-still-have-to-break-up-its-business-the-justice-department-said-150000739.html</a>, See on <a href="https://news.ycombinator.com/item?id=43302097">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Google will have to break up its business, the Justice Department said in a filing, upholding the previous administration's proposal after a federal judge ruled last year that the company <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/big-tech/google-is-a-monopolist-in-search-us-judge-rules-in-antitrust-case-193358356.html" data-ylk="slk:illegally abused;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">illegally abused</a> a monopoly over the search industry. As <a data-i13n="cpos:2;pos:1" href="https://www.washingtonpost.com/technology/2025/03/07/google-doj-chrome-anthropic-break-up/" rel="nofollow noopener" target="_blank" data-ylk="slk:The Washington Post;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas"><em>The Washington Post</em></a> and <a data-i13n="cpos:3;pos:1" href="https://www.nytimes.com/2025/03/07/technology/trump-google-search-antitrust.html" rel="nofollow noopener" target="_blank" data-ylk="slk:The New York Times;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas"><em>The New York Times</em></a> have reported, the Justice Department reiterated in a new filing that Google will have to sell the Chrome browser. When the DOJ argued for its sale last year, it <a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/big-tech/department-of-justice-confirms-that-it-wants-google-to-sell-off-chrome-094929822.html" data-ylk="slk:said that selling Chrome;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas">said that selling Chrome</a> "will permanently stop Google’s control of this critical search access point and allow rival search engines the ability to access the browser that for many users is a gateway to the internet."</p><p>The Justice Department also kept a Biden-era proposal that seeks to ban Google from paying companies like Apple, other smartphone manufacturers and Mozilla to make its search engine the default on their phones and browsers. It did remove a previous proposal that would compel Google to sell its stakes in AI startups, however, after Anthropic told the government that it needs the company's money to continue operating. Instead of banning AI investments altogether, the government wants to require the company to notify federal and state officials before making investments in artificial intelligence. Earlier this year, the <em>Financial Times </em><a data-i13n="cpos:5;pos:1" href="https://www.engadget.com/ai/google-is-investing-another-billion-dollars-in-anthropic-145548826.html" data-ylk="slk:reported;cpos:5;pos:1;elm:context_link;itc:0;sec:content-canvas">reported</a> that Google was investing another billion dollars in Anthropic.</p><p>Google is expected to file its own proposal for its final set of alternative remedies. In the earlier one it <a data-i13n="cpos:6;pos:1" href="https://www.engadget.com/big-tech/google-proposes-alternative-remedies-for-its-search-monopoly-after-doj-demands-radical-changes-185253526.html" data-ylk="slk:filed in December;cpos:6;pos:1;elm:context_link;itc:0;sec:content-canvas">filed in December</a>, the company said that the Justice Department's original remedies went "overboard" and that they reflected an "interventionist agenda" that "goes far beyond what the Court's decision is actually about — [its] agreements with partners to distribute search." Google suggested allowing it continue paying partners like Apple and Mozilla to offer Google Search, but also to allow them to form agreements with other partners across different platforms. Apple could, for instance, offer different default search engines for iPhones and iPads. Meanwhile, browser companies could change default search engines every 12 months.</p><p>As <em>The Post</em> notes, the Justice Department's filing could be an indicator of how the Trump administration will handle antitrust cases involving tech companies. It could be strict on big tech like the Biden administration was despite tech leaders supporting the new President and his policies. Google donated to the Trump campaign when he ran last year and just recently <a data-i13n="cpos:7;pos:1" href="https://www.engadget.com/big-tech/google-is-reportedly-changing-course-on-its-diversity-initiatives-too-223644402.html" data-ylk="slk:halted efforts;cpos:7;pos:1;elm:context_link;itc:0;sec:content-canvas">halted efforts</a> to hire employees from diverse backgrounds. It said that it was "no longer set hiring targets to improve representation in its workforce." The House also recently <a data-i13n="cpos:8;pos:1" href="https://www.engadget.com/big-tech/house-republicans-subpoena-google-over-alleged-censorship-212115140.html" data-ylk="slk:subpoenaed;cpos:8;pos:1;elm:context_link;itc:0;sec:content-canvas">subpoenaed</a> Alphabet and its CEO Sundar Pichai for communications between the company and the Biden administration regarding COVID-19.</p><p>Judge Amit Mehta, the original judge who ruled that Google was a monopolist and had "acted as one to maintain its monopoly," will hear both the government's and the company's remedies and will decide on the final solutions for the case in April.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi Is Bringing Orion Web Browser to Linux (244 pts)]]></title>
            <link>https://www.omgubuntu.co.uk/2025/03/kag-orion-web-browser-coming-to-linux</link>
            <guid>43302073</guid>
            <pubDate>Sat, 08 Mar 2025 18:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.omgubuntu.co.uk/2025/03/kag-orion-web-browser-coming-to-linux">https://www.omgubuntu.co.uk/2025/03/kag-orion-web-browser-coming-to-linux</a>, See on <a href="https://news.ycombinator.com/item?id=43302073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
<p><strong>Kagi, the company behind a paid, private search engine</strong><sup data-fn="85d04576-418d-4a25-a22c-8a1b88ea1f05"><a id="85d04576-418d-4a25-a22c-8a1b88ea1f05-link" href="#85d04576-418d-4a25-a22c-8a1b88ea1f05">1</a></sup><strong> of the same name, has announced it’s bringing its Webkit-based <a href="https://kagi.com/orion/" target="_blank" rel="noreferrer noopener"><em>Orion</em> web browser</a> to Linux.</strong></p>



<p>In a post on BlueSky, Kagi said: <em>“We’re thrilled to announce that development of the Orion Browser for Linux has officially started!”</em>. </p>



<p><em>Orion</em> is currently only available on macOS and iOS but was built to be better than Apple’s own Safari, and best Google Chrome, Mozilla Firefox and other browsers in many areas.</p>



<p>Orion is a zero-telemetry browser; has built-in ad and tracking blocking; and reportedly offers lower memory usage, faster page speeds, and greater battery efficiency on Apple devices than other browsers. It also supports both Chrome and Firefox extensions.</p>


<div>
<figure><a href="https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1.jpg"><img decoding="async" width="840" height="441" src="https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-840x441.jpg" alt="Orion web browser" srcset="https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-840x441.jpg 840w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-300x158.jpg 300w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-768x403.jpg 768w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-1536x806.jpg 1536w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1.jpg 1920w " sizes="(max-width: 840px) 100vw, 840px"></a><figcaption>Orion Browser <span>on macOS</span> supports Chrome <em>and</em> Firefox Add-ons</figcaption></figure></div>


<p>Whether all of those USPs can be carried over to Linux—a less defined ‘platform’ than macOS if targeting things like power efficiency—remains to be seen. Kagi is hopeful; they say the Orion Linux build will have feature-parity with the macOS version by next year.</p>







<p>Obviously, Orion’s (current) closed-source nature will not endear it to everyone. Plenty of Linux users simply can’t countenance using <em>Steam</em>, <em>Spotify</em>, <em>Vivaldi</em>, <em>Slack</em>, <em>Discord</em>, <em>Google Chrome</em>, <em>WhatsApp</em> or other non-free apps, tools, or services.</p>



<p>—That’s fair; we’re free to choose the software that works for us on whatever level that matters, be it utility, integration, or indeed license model.</p>



<p>Yet, the idea of being able to run a fast, user-friendly, and flexible WebKit-based web browser on Linux is a promising development for choice, if nothing else. GNOME Web/Epiphany shows the promise WebKit offers – Orion may bring the polish.</p>



<p>Kagi has started work on open-sourcing <a href="https://github.com/OrionBrowser">many components</a>&nbsp;used in Orion and plans to open source more — the small team is the bottleneck; forking WebKit, porting hundreds of APIs, and building a browser from scratch takes resources.</p>



<p><em>“Properly maintaining an open-source project takes time and resources we’re short on at the moment, so if you want to contribute at this time, please consider becoming active on&nbsp;orionfeedback.org,” they add. </em></p>



<p>If you’re interested in learning more about Orion (for macOS) check out the <a href="https://kagi.com/orion/">Orion landing page</a> on the Kagi website, or read through a <a href="https://kagi.com/orion/faq.html" target="_blank" rel="noreferrer noopener">comprehensive FAQ</a>.  To sign-up for news on the upcoming Linux version, plug in an e-mail in the sign-up form.</p>



<p>The saying goes “if you’re not paying for the product, you are the product” —<em>unless open-source</em>, I tend to add if I hear someone say it! Alas, Mozilla’s recent faux-pas suggests that even noble projects aren’t immune to the shiny glint of <em>ick</em>.</p>



<p><em>Thanks Sambot!</em></p>


<ol><li id="85d04576-418d-4a25-a22c-8a1b88ea1f05">I haven’t tried Kagi Search but it’s tempting given how other search engines are <a href="https://wallethub.com/blog/google-quality-issues-report/147091" target="_blank" rel="noreferrer noopener">increasingly focused</a> on getting people to spend money, not find information.   <a href="#85d04576-418d-4a25-a22c-8a1b88ea1f05-link" aria-label="Jump to footnote reference 1">↩︎</a></li></ol>                                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Bankman-Fried thrown into solitary over Tucker Carlson interview: report (155 pts)]]></title>
            <link>https://gizmodo.com/sam-bankman-fried-thrown-into-solitary-over-tucker-carlson-interview-report-2000573371</link>
            <guid>43301702</guid>
            <pubDate>Sat, 08 Mar 2025 17:14:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/sam-bankman-fried-thrown-into-solitary-over-tucker-carlson-interview-report-2000573371">https://gizmodo.com/sam-bankman-fried-thrown-into-solitary-over-tucker-carlson-interview-report-2000573371</a>, See on <a href="https://news.ycombinator.com/item?id=43301702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              
              <p>Tucker Carlson’s interview with disgraced crypto CEO Sam Bankman-Fried, which was distributed <a href="https://gizmodo.com/sbf-suggests-dems-didnt-save-him-because-he-gave-money-to-republicans-too-2000572852">online Thursday,</a> appeared to be a transparent ploy to get media attention with the goal of ultimately scoring a pardon from President Donald Trump. But it sounds like SBF is now paying a price for the interview. The former billionaire has reportedly been tossed into solitary confinement because the interview wasn’t approved by the U.S. Bureau of Prisons, according to a new report from the New York Times.</p> <p>According to <a href="https://www.nytimes.com/2025/03/07/technology/sam-bankman-fried-pardon-trump.html">the Times</a>, the Bureau of Prisons has strict rules about how interviews are conducted with inmates, and the federal agency confirmed to the newspaper that it did not give permission for the interview with Carlson to go forward. We don’t know when the interview actually took place, though clues suggest it was Wednesday, the day before it was published online to social media platforms like Rumble and X. SBF is currently being held at the Metropolitan Detention Center in Brooklyn.</p> <p>It’s also not clear what kind of equipment was used to allow SBF and Carlson to communicate. It’s entirely possible SBF simply used a smuggled smartphone to talk with Carlson, and while that does seem like the most straightforward way to accomplish an interview like this, that’s purely speculative.&nbsp; SBF suggested in his chat with Carlson that he was really missing having high-tech devices at his disposal, though the topic only came up when the former Fox News host asked if the crypto executive was previously on stimulants before he entered prison. SBF blamed his erratic appearance in old interviews on being distracted by tech devices. Carlson took the opportunity to say that tech wasn’t healthy.</p> <p>The new report from the New York Times seems to confirm what anyone with a little bit of common sense assumed when Carlson’s interview dropped: SBF, who’s currently serving a 25-year sentence for fraud after his crypto company FTX collapsed in 2022, is angling for a pardon from President Trump.</p> <p>Bankman-Fried’s parents, Joe Bankman and Barbara Fried, are two law professors at Stanford and are reportedly consulting with Kory Langhofer, an Arizona lawyer who previously worked on Trump’s presidential campaigns in 2016 and 2020, according to the Times. Langhofer would presumably have deep connections in Trump World, but the newspaper reports they haven’t had direct contact with Trump. At least, not yet.</p>

 <p>But it seems like it could be an uphill climb for SBF and his family to get a pardon from Trump. The Times says the effort “does not appear to have gained traction,” and it’s easy to guess that SBF’s old associations with high-profile Democrats may be hurting his chances. However, SBF himself admitted once he was in jail that he was also secretly donating to Republicans before the implosion of FTX.</p> <p>SBF said in the Thursday episode of Carlson’s show that he doesn’t believe Democrats “saved” him while being prosecuted during the Joe Biden years because they knew he was giving to Republicans as well. Carlson kept acting throughout the interview as though it’s just normal and reasonable for wealthy people who donate to politicians to expect corrupt favors from those same people in their time of need. But SBF didn’t really take the bait, saying that it would have been “inappropriate” to ask for help.</p>

 <p>Trump recently <a href="https://gizmodo.com/trump-pardons-silk-road-founder-ross-ulbricht-2000553405">pardoned Ross Ulbricht</a>, the Silk Road founder convicted in 2015 who was serving a 40-year sentence for money laundering, among a host of other charges related to the darknet site. Ulbricht’s pardon was actually a campaign promise made by Trump in the lead up to the election, largely seen as a favor to the crypto community, which considers Ulbricht a hero.</p> <p>Bankman-Fried never explicitly asked for a pardon from Trump during his interview either, and it seems pretty clear at this point that no matter how desperate he is to get out of prison, he’s going to let things happen behind the scenes rather than go begging. But who knows what might happen in the future. SBF turned 33 on Thursday and has only served a couple of years of a 25-year sentence.</p>
                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You might not need Redis (145 pts)]]></title>
            <link>https://www.viblo.se/posts/no-need-redis/</link>
            <guid>43301432</guid>
            <pubDate>Sat, 08 Mar 2025 16:39:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.viblo.se/posts/no-need-redis/">https://www.viblo.se/posts/no-need-redis/</a>, See on <a href="https://news.ycombinator.com/item?id=43301432">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
  <a href="https://redis.io/">Redis</a> is arguably the most well regarded tech
  of all. My impression is that not even PostgreSQL has the same kind of
  positive aura around it. And of all tech available Redis is at the top of
  things you "need" to have in your tech stack. Maybe this will change with
  their latest
  <a href="https://redis.com/blog/redis-adopts-dual-source-available-licensing/">licencing change</a>, but that remains to be seen.
</p>
<p>
  It's not difficult to see why, Redis is after all a very well architected and
  impressive piece of technology and this post is not arguing against any
  technical merits of Redis. What I will argue is that despite no technical flaw
  in Redis itself you still might not need it!
</p>

<h2>My Experience</h2>
<p>
  In the last 3 places I worked (10+ years) I have seen the same pattern. A
  problem comes up, Redis is seen as a great fit and here we go.
</p>
<p>
  However, when looking closer at the actual use case it turns out that Redis
  didn't improve things, or did not fix the underlying problem. It just added
  complexity for complexity's sake.
</p>

<h2>First time, at Tantan</h2>
<p>
  First time Redis was proposed was at
  <a href="https://tantanapp.com/">Tantan</a>, the second largest dating app in
  China and a sort of Chinese Tinder. At the time we had 50-100 very powerful
  database servers running PostgreSQL.
</p>
<p>
  To not make this post too long I will simplify the architecture a bit: Each
  server stored a subset of the users 'swipes', sharded by the UserId so that a
  specific user only had data on one server. To add new swipes, the code would
  locate the server belonging to the user, and then run an insert SQL statement.
  If you are curious I have held a couple of talk of Tantan's DB architecture,
  see <a href="https://www.viblo.se/talks/">here</a> for a more in depth overview.
</p>
<p>
  The need arose to keep track of a little piece of additional data, namely the
  count of swipes. Basically a single integer value for each user, with two
  important properties: The value would be updated very often since 'swipe'
  where the most common action of a user, and the value would often be read, to
  always show the correct value.
</p>
<p>
  Our first thought (mine as well), where to put this data in Redis. A small
  amount of data, frequently updated and often requested felt like a perfect
  match for Redis. A single beefy Redis (many cores, lots of RAM type of
  machine) should be able to handle the load, so we would only need a couple
  (for redundancy). We bought (no cloud!) and installed the machines and started
  to configure Redis. While doing this a question rose in my mind - 'Why can't
  we just store this data on the shards in PostgreSQL, next to the swipes?'. The
  data itself would be microscopic in comparison and the additional load would
  also be microscopic in comparison to what these servers were already doing.
  After discussions in the team, they agreed! It would just add complexity to
  our relatively simple stack to add Redis!
</p>
<p>
  Guess what, after deployment the added load couldn't barely be seen on the db
  servers. Success!
</p>
<p>
  This is one of my favorite architecture moments. Something I think back to
  whenever someone proposes adding new tech, but the reasoning behind is not
  thought through all the way.
</p>

<h2>Second time, at Bannerflow</h2>
<p>
  After I left Tantan I joined a ad tech company called
  <a href="https://www.bannerflow.com/">Bannerflow</a>. There we built a "CMP",
  a web-platform for our enterprise users to create and publish ads online.
</p>
<p>
  At Bannerflow, one team were building a new set of microservices to configure
  and publish ads to social networks like Facebook. While there are certainly
  complexities in regard to how format the ads to fit the various social
  network's API contracts, get access etc., this was not a high load scenario
  like at Tantan.
</p>
<p>
  The team decided to add a Redis instance, for some cache of sorts. Note that
  this was for a system with a load not even 0.1% of Tantan's.
</p>
<p>
  Unfortunately, I will not be able to explain why Redis was (thought to be)
  needed in this post, because I don't know the reasoning either. After the
  initial developer left, no-one in the team could explain it to me when we
  discussed it! Looking at the code, or the number of calls or any other metric
  I could not see any reason, and we could agree that given a bit of spare time
  the best would be to remove it. (Now, running a managed Redis in Azure is not
  a lot of work, so I could not justify rearchitect it just for simplicity, but
  the long term plan was clear)
</p>
<p>
  I have to take this on me for not staying close enough to the team while they
  were designing and building the new feature, and despite skilled developers we
  had a (in this case) useless Redis sneaked in there. Lesson learned!
</p>

<h2>Third time, at MAJORITY</h2>
<p>
  And finally, as of 2024 I now work at the fintech company
  <a href="https://www.majority.com/">MAJORITY</a>. And surprise, surprise, they
  had just introduced Redis in the months before I joined!
</p>
<p>
  The first usage was to cache the result of an external API call to lookup
  geolocation of users, so that the service in question could process location
  requests quicker, and also run cheaper. What I think is interesting here is
  that it is very reasonable to want to cache this data, no objection here.
</p>
<p>
  What is less clear is what Redis added. By chance this specific service did
  two things for the lookup, one DB call (to a Azure SQL Database), and one
  Redis call. This made it very easy to compare and evaluate.
</p>
<p>
  The service in question had its own DB, sharing a DB cluster with other
  services. This specific DB had so low amount of load that it did not even show
  up when looking at the cluster load in Azure. Moving the Redis usage over to
  the DB would result in ~2x that load, which is a big
  <em>relative</em> increase, but in <em>absolute</em> numbers a very minor
  increased load on the DB when the original load was more or less 0!
</p>
<p>
  Of course, when a new tech is introduced into a tech stack, more and more
  parts will start using it. Same here. Soon the need arose to have locks shared
  between several instances of the same microservice. Since Redis was already in
  use, it was natural to use it for this as well.
</p>
<p>
  But, looking closer it was easy to see that these locks could just as well use
  the locking mechanism inside the main DB (Azure SQL). Some mentioned
  performance and to not put more load on the DB, but just as before it was not
  a high performance use case, actually not anywhere near even 1 lock per
  second.
</p>
<p>
  Just like in Bannerflow, the implementation were already done by the time I
  really understood it. And same as in Bannerflow, we decided to try and move
  away from Redis.
</p>

<h2>Ending</h2>
<p>
  Each of the three cases were unique, with different tech stacks, different
  domains and different load. But somehow they were still unified by the desire
  to use Redis!
</p>
<p>
  If you nod in agreement, or are at least open for more on the same topic,
  there's this quite well known talk by Dan McKinley I recommend to check out:
  <a href="https://boringtechnology.club/">Choose Boring Technology</a> By pure
  coincidence it's also about Redis...
</p>

<i>Victor 2024-03-12</i>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Undocumented backdoor found in Bluetooth chip used by a billion devices (301 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/undocumented-backdoor-found-in-bluetooth-chip-used-by-a-billion-devices/</link>
            <guid>43301369</guid>
            <pubDate>Sat, 08 Mar 2025 16:30:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/undocumented-backdoor-found-in-bluetooth-chip-used-by-a-billion-devices/">https://www.bleepingcomputer.com/news/security/undocumented-backdoor-found-in-bluetooth-chip-used-by-a-billion-devices/</a>, See on <a href="https://news.ycombinator.com/item?id=43301369">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="ESP32" height="900" src="https://www.bleepstatic.com/content/hl-images/2025/03/07/esp32.jpg" width="1600"></p>

<p>The ubiquitous ESP32 microchip made by Chinese manufacturer Espressif and used by over 1 billion units as of 2023 contains an undocumented backdoor that could be leveraged for attacks.</p>

<p>The undocumented commands allow spoofing of trusted devices, unauthorized data access, pivoting to other devices on the network, and potentially establishing long-term persistence.</p>

<p>This was discovered by Spanish researchers Miguel Tarascó Acuña and Antonio Vázquez Blanco of Tarlogic Security, who <a href="https://www.documentcloud.org/documents/25554812-2025-rootedcon-bluetoothtools/" target="_blank" rel="nofollow noopener">presented</a> their findings yesterday at <a href="https://reg.rootedcon.com/cfp/schedule/talk/5" target="_blank" rel="nofollow noopener">RootedCON</a> in Madrid.</p>

<p>The researchers warned that ESP32 is one of the world's most widely used chips for Wi-Fi + Bluetooth connectivity in IoT (Internet of Things) devices, so the risk of any backdoor in them is significant.</p>

<div>
<figure><img alt="Slide from the RootedCON presentation" height="600" src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/presentation.jpeg" width="800"><figcaption><strong>Slide from the RootedCON presentation</strong><br><em>Source: Tarlogic</em></figcaption></figure></div>

<h2>Discovering a backdoor in ESP32</h2>

<p>In their RootedCON presentation, the Tarlogic researchers explained that interest in Bluetooth security research has waned but not because the protocol or its implementation has become more secure.</p>

<p>Instead, most attacks presented last year didn't have working tools, didn't work with generic hardware, and used outdated/unmaintained tools largely incompatible with modern systems.</p>

<p>Tarlogic developed a new C-based USB Bluetooth driver that is hardware-independent and cross-platform, allowing direct access to the hardware without relying on OS-specific APIs.</p>

<p>Armed with this new tool, which enables raw access to Bluetooth traffic, Targolic discovered hidden vendor-specific commands (Opcode 0x3F) in the ESP32 Bluetooth firmware that allow low-level control over Bluetooth functions.</p>

<div>
<figure><img alt="ESP32 memory map" height="534" src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/diagram.jpg" width="751"><figcaption><strong>ESP32 memory map</strong><br><em>Source: Tarlogic</em></figcaption></figure></div>

<p>In total, they found 29 undocumented commands, collectively characterized as a "backdoor," that could be used for memory manipulation (read/write RAM and Flash), MAC address spoofing (device impersonation), and LMP/LLCP packet injection.</p>

<p>Espressif has not publicly documented these commands, so either they weren't meant to be accessible, or they were left in by mistake.</p>

<div>
<figure><img alt="Script that issues HCI commands" height="408" width="821" data-src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/demo.jpg" src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/demo.jpg"><figcaption><strong>Script that issues HCI commands</strong><br><em>Source: Tarlogic</em></figcaption></figure></div>

<p>The risks arising from these commands include&nbsp;malicious implementations on the OEM level and supply chain attacks.</p>

<p>Depending on how Bluetooth stacks handle HCI commands on the device, remote exploitation of the backdoor might be possible via malicious firmware or rogue Bluetooth connections.</p>

<p>This is especially the case if an attacker already has root access, planted malware, or pushed a malicious update on the device that opens up low-level access.</p>

<p>In general, though, physical access to the device's USB or UART interface would be far riskier and a more realistic attack scenario.</p>

<p>"In a context where you can compromise an IOT device with as ESP32 you will be able to hide an APT inside the ESP memory and perform Bluetooth (or Wi-Fi) attacks against other devices, while controlling the device over Wi-Fi/Bluetooth," explained the researchers to BleepingComputer.</p>

<p>"Our findings would allow to fully take control over the ESP32 chips and to gain persistence in the chip via commands that allow for RAM and Flash modification."</p>

<p>"Also, with persistence in the chip, it may be possible to spread to other devices because the ESP32 allows for the execution of advanced Bluetooth attacks."</p>

<p>BleepingComputer has contacted Espressif for a statement on the researchers' findings, but a comment wasn't immediately available.</p>

	   
           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discovering errors in Donald Knuth's TAOCP (111 pts)]]></title>
            <link>https://glthr.com/discovering-errors-in-donald-knuths-taocp</link>
            <guid>43301342</guid>
            <pubDate>Sat, 08 Mar 2025 16:27:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://glthr.com/discovering-errors-in-donald-knuths-taocp">https://glthr.com/discovering-errors-in-donald-knuths-taocp</a>, See on <a href="https://news.ycombinator.com/item?id=43301342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>As Donald Knuth <a target="_blank" href="https://www-cs-faculty.stanford.edu/~knuth/news.html">has just published</a> Volume 4, Fascicle 7 of <em>The Art of Computer Programming</em> (TAOCP), on constraint satisfaction, I would like to provide more information about the errors I discovered in 2019 in other volumes, for which I received two <a target="_blank" href="https://en.wikipedia.org/wiki/Knuth_reward_check">Knuth reward checks</a>. To date, my account balance on his “bank”, the Bank of San Serriffe, <a target="_blank" href="https://www-cs-faculty.stanford.edu/~knuth/boss.html">is still 0x$2.40</a> (hexadecimal dollars). 0x$2.00 for two errors, and 0x$0.40 for two “valuable suggestions.”</p>
<p>His response to my errors reports was faster than I expected: I emailed him four times to report different errors from December 18, 2019, to January 1, 2020 (although Knuth does not typically use email, <a target="_blank" href="https://www-cs-faculty.stanford.edu/~knuth/taocp.html">there is an email address reserved for reporting TAOCP errors</a>, which his assistant prints). He updated the errata on January 1 and responded with a postal mail on January 9, 2020.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741449823270/f986b0e9-3965-4064-b940-e5806c8011d5.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>The envelope contained my printed emails with his handwritten notes in pencil and two checks (dated December 24, 2019, and January 1, 2020).</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450804963/8e01e6e3-791c-4c2a-be48-d0627d634795.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741449848827/7b6fb504-d70f-4771-8380-a998b9392fa2.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>Some reward recipients have shared their letters online, here and there; however, I will paraphrase Knuth’s responses instead of reproducing them verbatim, as they are part of private correspondence (this can change in the future—per express authorization, for instance—; in that case, I will update this article to share a full scan of the letters). A notable exception is an excerpt of a letter containing generic information and a good anecdote: Knuth wished me a “<em>Joyeux Noël</em>” (French for “Happy Christmas”) because, probably without realizing it, I sent him an email on December 25.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741449873242/48a85378-ad42-4f28-9766-ce34ffae92f3.png?auto=compress,format&amp;format=webp" alt=""></p>
<hr>

<p>I was familiar with <a target="_blank" href="https://en.wikipedia.org/wiki/Knuth%27s_Algorithm_X">Algorithm X</a> before reviewing Volume 4 Pre-Fascicule 5c (published as Volume 4, Fascicule 5)—because <a target="_blank" href="https://en.wikipedia.org/wiki/Exact_cover">exact cover problems</a> are fantastic! I did not expect to find fundamental errors, as Algorithm X has probably been one of the sections most thoroughly reviewed by its creator.</p>
<p>At that time, I kept track of Algorithm X’s states manually (I was on a flight without a computer). I maintained a record of the memory state with pen and paper, an experience that allowed me to focus on the essential details and discover small errors and imprecisions that led to minor corrections.</p>
<h2 id="heading-reported-errors">Reported Errors</h2>
<h3 id="heading-local-variables-not-declared">Local Variables Not Declared</h3>
<p>While the local variables of the first algorithmic step, <code>cover(i)</code>, are identified as such, the variables of the subsequent steps are not.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741449975708/c6b68b0b-ed08-4be1-be8a-afd124182b52.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741449985590/bcbb0bd1-4cc6-4bfb-be27-077b6a69c5b9.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>Though this is not particularly problematic (this is trivially inferable from the context), Knuth recognized that it would have been beneficial to state this characteristic for each step explicitly. However, <strong>he decided against breaking up Algorithm X between different pages due to space constraints and, therefore, could not add clarifications for each step</strong>; he then appropriately quoted Voltaire: “<em>The secret of being a bore is to tell everything.</em>” Nevertheless, Knuth ultimately found an elegant solution (see below).</p>
<p><em>Reward: 32¢ (0x20¢)</em></p>
<h3 id="heading-unused-memory-fields">Unused Memory Fields</h3>
<p>When it was time to simulate the impact of the algorithm on the memory state, I was confused by this:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450032507/cc4b9308-f844-4892-9f6e-6c97923c89b7.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>My interpretation was that a program attempting to access one of these unused fields would fail, as I assimilated them as being in an uninitialized state. And indeed, my pen-and-paper program failed when reaching the hide step for the last spacer. Using the memory dump table as an example, covering one of the last nodes after some iterations leads to set <code>q</code> to 30 and, therefore, to <code>d ← DLINK(30)</code>. If an unused field means an uninitialized memory location, then the algorithm's execution should prematurely stop as, in this example, <code>DLINK(30) = —</code>. However, <strong>Knuth clarified that he did not explicitly state the variable was <em>uninitialized</em>; instead, it must be assumed to be initialized, but its value has no impact on the algorithm.</strong></p>
<p><em>Reward: 32¢ (0x20¢)</em></p>
<h3 id="heading-unused-variables">Unused Variables</h3>
<p>Finally, <code>N</code> and <code>Z</code> were set during the algorithm initialization step, but I did not need to utilize them when manually tracking the memory state.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450118831/c747ea0f-b896-422a-9adf-d38b8bb79a86.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>According to Knuth, they were, in fact, used in the exercises, notably exercise 83.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450128565/b1d90f0a-2a9a-49a4-aeb3-b07d1e0f8172.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>To ensure this was the case, he reviewed it and noticed an error: <code>N</code> should be <code>N₁</code>.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450237068/cc7b2f39-264a-417a-8adf-e23710e8ed1b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>He graciously rewarded me for helping him discover this error. (I transitively found this error, so to say.)</p>
<p><em>Reward: $2.56 (0x$1.00)</em></p>
<h2 id="heading-corrections">Corrections</h2>
<p>Corrections arising from my emails, all dated back to January 1, 2020, can be found in the <em>Errata for Volume 4 Fascicle 5, long-form</em> (available <a target="_blank" href="https://www-cs-faculty.stanford.edu/~knuth/taocp.html">here</a>). Specifically, they are listed on pages 5 and 13 of the downloadable compressed PostScript file.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450294503/f4408f9d-58fe-4061-958f-74b803127c9b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450300109/59a51bd1-fe77-477b-914c-8481f5283cc7.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>It appears that:</p>
<ul>
<li><p>Knuth clarified what “unused” field means by implicitly stating that they are implicitly but necessarily initialized but "<em>can contain anything</em>".</p>
</li>
<li><p>Instead of listing all local variables, he refers to <code>p</code>, <code>l</code>, <code>r</code> as being part of a <em>non-exhaustive</em> list of local variables (“<em>Undeclared variables like p, l, r are local</em>”).</p>
</li>
<li><p>Last, in his answer 83, he replaced <code>N</code> with <code>N₁</code>.</p>
</li>
</ul>
<h3 id="heading-small-aside-using-a-heartbeat-arrow-as-delimiter">Small Aside: Using a “HeartBeat-Arrow” as Delimiter</h3>
<p>Notice how Knuth uses a bespoke symbol (a “heartbeat-arrow”) to indicate the transition from the error to its correction:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450382338/8d04fd5a-8624-4bf4-80a7-73617f926bad.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>This is because he, as his corrections are inline/embedded (no table), he needed a symbol that is necessarily not already present in his books; otherwise, it could have been confused with a corrected symbol (typically, a simple right-pointing arrow, →, would have most probably been confused with a corrected material implication, and so forth). I believe this is an illustration of a <em>delimiter</em>, a special marker that cannot use the same symbols or structure as the regular text (<a target="_blank" href="https://glthr.com/first-order-second-order-expressions-and-delimiters-in-languages">in my previous blog post</a>, I develop this general idea).</p>
<hr>
<h2 id="heading-erroneous-reference-to-an-obscure-article">Erroneous Reference to an Obscure Article</h2>
<h2 id="heading-reported-error">Reported Error</h2>
<p>When reading the section on Hamiltonian paths in antiquity from Volume 4, pre-fascicule 8a, I stumbled upon the reference to a French article about icosahedral objects inscribed with Greek letters: P. Perdrizet, in <em>Bulletin de l’Institut français du Caire</em> 30 (1930), 1-16. I did not find this article in the journal, but instead <a target="_blank" href="https://gallica.bnf.fr/ark:/12148/btv1b53180372w">located it</a> in <em>Bulletin de l’Institut français d’archéologie orientale</em>.</p>
<p>Acknowledging the error, <strong>Knuth took the time to review some articles in this journal and strongly recommended a volume about Egyptian poetry:</strong> <a target="_blank" href="https://ignca.gov.in/Asi_data/31424.pdf"><strong></strong></a><strong><a href="https://ignca.gov.in/Asi_data/31424.pdf" target="_blank">ignca.gov.in/Asi_data/31424.pdf</a></strong>. Although he did not specify an article, I believe he referred to Vikentiev, V. (n.d.). The metrical scheme of the « Shipwrecked Sailor ». B<em>ulletin de l’Institut français d’archéologie orientale</em>, 35(1), 1–40. It is indeed remarkable for that time (see notably Planche 1, page 18 of the PDF).</p>
<p><em>Reward: $2.56 (0x$1.00)</em></p>
<h2 id="heading-correction">Correction</h2>
<p>There is no erratum, as it is a pre-fascicule that is directly edited.</p>
<p>Here is, as a substitute, a comparison of a version from November 2019, retrieved with Wayback machine, and the current one (March 2025):</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450614596/ca0f5785-98d5-4d08-9c09-55e380452950.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1741450622906/61ae981b-3c03-40d9-bd7f-7a50e76f6b84.png?auto=compress,format&amp;format=webp" alt=""></p>
<h2 id="heading-conclusion">Conclusion</h2>
<p>This event has left me with an immense sense of respect for Donald Knuth’s dedication to accuracy and attention to detail. It was an honor to contribute to the improvement of his work, even if it was just a small (to be honest: minuscule) part. I look forward to continuing my exploration of the latest published TAOCP volume, and discovering more errors to correct.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The program is the database is the interface (130 pts)]]></title>
            <link>https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/</link>
            <guid>43300528</guid>
            <pubDate>Sat, 08 Mar 2025 14:31:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/">https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/</a>, See on <a href="https://news.ycombinator.com/item?id=43300528">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <h2 id="draft">!!! DRAFT !!!</h2>
<p>I do my accounts each year with a simple script. Something like this:</p>
<pre data-lang="clj"><code data-lang="clj"><span>(ns </span><span>accounts
</span><span>  (</span><span>:require 
</span><span>    [clojure.string </span><span>:as </span><span>str]
</span><span>    [clojure.pprint </span><span>:as </span><span>pp]))
</span><span>
</span><span>;; converted from statement.csv
</span><span>(def </span><span>txs
</span><span>  [{</span><span>:date #inst "2022-05-13T11:01:56.532-00:00"
</span><span>    </span><span>:amount -3.30
</span><span>    </span><span>:text </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-12T10:41:56.843-00:00"
</span><span>    </span><span>:amount -3.30
</span><span>    </span><span>:text </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-12T00:01:03.264-00:00"
</span><span>    </span><span>:amount -72.79
</span><span>    </span><span>:text </span><span>"Card transaction of 72.79 CAD issued by Amazon.ca AMAZON.CA"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-10T10:33:04.011-00:00"
</span><span>    </span><span>:amount -20.00
</span><span>    </span><span>:text </span><span>"e-Transfer to: John Smith"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-11T17:12:43.098-00:00"
</span><span>    </span><span>:amount -90.00
</span><span>    </span><span>:text </span><span>"Card transaction of 90.00 CAD issued by Range Physiotherapy VANCOUVER"</span><span>}])
</span><span>
</span><span>(def </span><span>date-&gt;tag
</span><span>  {</span><span>#inst "2022-05-12T00:01:03.264-00:00" :things</span><span>})
</span><span>
</span><span>(def </span><span>text-&gt;tag 
</span><span>  {</span><span>"Coffee" </span><span>:eating-out
</span><span>   </span><span>"Range Physio" </span><span>:medical</span><span>})
</span><span>
</span><span>(defn </span><span>tx-&gt;tag </span><span>[tx]
</span><span>  (or
</span><span>    (date-&gt;tag (</span><span>:date </span><span>tx))
</span><span>    (first 
</span><span>      (for [[text tag] text-&gt;tag
</span><span>            </span><span>:when </span><span>(str/includes? (</span><span>:text </span><span>tx) text)]
</span><span>        tag))))
</span><span>
</span><span>(def </span><span>txs-with-tags
</span><span>  (vec 
</span><span>    (for [tx txs]
</span><span>      (assoc tx </span><span>:tag </span><span>(tx-&gt;tag tx)))))
</span><span>
</span><span>(def </span><span>total-per-tag
</span><span>  (reduce 
</span><span>    (fn [totals tx]
</span><span>      (update-in totals [(</span><span>:tag </span><span>tx)] #(+ (</span><span>:amount </span><span>tx) (or % </span><span>0</span><span>))))
</span><span>    {}
</span><span>    txs-with-tags))
</span><span>
</span><span>(def </span><span>untagged 
</span><span>  (vec
</span><span>    (for [tx txs-with-tags
</span><span>         </span><span>:when </span><span>(nil? (</span><span>:tag </span><span>tx))]
</span><span>      tx)))
</span><span>
</span><span>(pp/pprint 
</span><span>  [[</span><span>:untagged </span><span>untagged]
</span><span>   [</span><span>:total-per-tag </span><span>total-per-tag]])
</span></code></pre>
<p>There are many things about this which are nice.</p>
<ul>
<li>It's just a single file - easy to backup and version control.</li>
<li>It's composable - I can easily write code to answer unexpected questions (eg how much did I spend on currency conversions this year) or use the computed data in other calculations (eg runway projections).</li>
<li>It's easy - I just pretty-printed the data-structures I was already using instead of having to build a UI.</li>
</ul>
<p>But the workflow isn't always great. When I run the code above, I see:</p>
<pre data-lang="clj"><code data-lang="clj"><span>&gt; clj accounts.clj
</span><span>[[</span><span>:untagged
</span><span>  [{</span><span>:date #inst "2022-05-10T10:33:04.011-00:00"</span><span>,
</span><span>    </span><span>:amount -20.0</span><span>,
</span><span>    </span><span>:text </span><span>"e-Transfer to: John Smith"</span><span>,
</span><span>    </span><span>:tag nil</span><span>}]]
</span><span> [</span><span>:total-per-tag
</span><span>  {</span><span>:eating-out -3.3</span><span>, </span><span>:things -72.79</span><span>, </span><span>:medical -90.0</span><span>, </span><span>nil -20.0</span><span>}]]
</span></code></pre>
<p>That transfer to John Smith isn't covered by any of the tagging rules. So I select the date, switch to the editor window and paste the date into the date-&gt;tag definition:</p>
<pre data-lang="clj"><code data-lang="clj"><span>(def </span><span>date-&gt;tag
</span><span>  {</span><span>#inst "2022-05-12T00:01:03.264-00:00" :things
</span><span>   </span><span>#inst "2022-05-10T10:33:04.011-00:00" :eating-out</span><span>})
</span></code></pre>
<p>Now I see:</p>
<pre data-lang="clj"><code data-lang="clj"><span>&gt; clj accounts.clj
</span><span>[[</span><span>:untagged </span><span>[]]
</span><span> [</span><span>:total-per-tag
</span><span>  {</span><span>:eating-out -23.3</span><span>, </span><span>:things -72.79</span><span>, </span><span>:medical -90.0</span><span>}]]
</span></code></pre>
<p>Multiply this by a thousand transactions and it becomes tedious.</p>
<p>Pretty-printing also makes it difficult to decide the amount of detail I should print. Sometimes I want to see which transactions contribute to each tag total. But if I always print them all then it's hard to see the totals themselves without a lot of scrolling.</p>
<p>It's also hard to share this workflow with someone non-technical. I have to setup and maintain the correct environment on their machine, teach them how to use a text editor to change the tagging rules, how to interpret syntax errors, how to use git to share changes etc.</p>
<hr>
<p>I could solve these kinds of problems by writing a web app and storing <code>txs</code>, <code>date-&gt;tag</code> and <code>text-&gt;tag</code> in a database.</p>
<p>Then I could put controls on the transaction itself that allow changing the tag in place. And I could add an expandable section next to each total, so that it's easy to see the transactions for that tag when I want to but they don't take up space by default.</p>
<p>Plus sharing becomes trivial - everyone has a web browser.</p>
<p>But this is a big leap in effort:</p>
<ul>
<li>A database introduces a different data model - I have to translate between database data-types and my programming languages native data-types.</li>
<li>A database introduces a different language, or at least a new api that differs from the way I access native data-structures.</li>
<li>Rather than using a familiar text editor to read and change data, I can only access it via some query language or api.</li>
<li>I have to shuffle data back and forth between database and program at the correct times.</li>
<li>It isn't easy to version control the contents of the database.</li>
<li>Before I can add interactive elements, I have to map my existing data-structures to gui elements (eg to html and css) instead of just printing them.</li>
<li>I have to add an extra layer of state management to manage the state of the gui itself.</li>
<li>All of this work has to be repeated whenever I have a new question I want to answer.</li>
</ul>
<p>None of this is insurmountable, but it's definitely much more work than the original script.</p>
<p>So a simple script is low-effort but produces a low-quality experience. And a custom app can produce a high-quality experience but is high-effort.</p>
<hr>
<p>So I made a thing.</p>
<p>It is very hacky and easy to break. But it will hang together just long enough to convey the idea.</p>
<p>It's kind of like a notebook. There are cells where you can write code and the resulting values will be nicely rendered:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>;; converted from statement.csv
</span><span>(def txs
</span><span>  [{:date #inst "2022-05-13T11:01:56.532-00:00"
</span><span>    :amount -3.30
</span><span>    :text "Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"}
</span><span>   {:date #inst "2022-05-12T10:41:56.843-00:00"
</span><span>    :amount -3.30
</span><span>    :text "Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"}
</span><span>   {:date #inst "2022-05-12T00:01:03.264-00:00"
</span><span>    :amount -72.79
</span><span>    :text "Card transaction of 72.79 CAD issued by Amazon.ca AMAZON.CA"}
</span><span>   {:date #inst "2022-05-10T10:33:04.011-00:00"
</span><span>    :amount -20.00
</span><span>    :text "e-Transfer to: John Smith"}
</span><span>   {:date #inst "2022-05-11T17:12:43.098-00:00"
</span><span>    :amount -90.00
</span><span>    :text "Card transaction of 90.00 CAD issued by Range Physiotherapy VANCOUVER"}])
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs date-&gt;tag
</span><span>  {#inst "2022-05-12T00:01:03.264-00:00" :things})
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs keyword-&gt;tag
</span><span>  {"Coffee" :eating-out
</span><span>   "Range Physio" :medical})
</span></code></pre>
<p>Funtions render a little differently.</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn text-&gt;tag [text]
</span><span>  (first
</span><span>    (for [[keyword tag] keyword-&gt;tag
</span><span>          :when (clojure.string/includes? text keyword)]
</span><span>      tag)))
</span></code></pre>
<p>If you type <code>"Joe's Coffee Hut"</code> (including the <code>"</code>!) into the textbox above and hit the <code>text-&gt;tag</code> button, you'll see the result of running the <code>text-&gt;tag</code> function on that input.</p>
<p>Functions aren't limited to just returning values though. They can modify the values stored in other cells:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def txs-with-tags
</span><span>  (vec 
</span><span>    (for [tx txs]
</span><span>      (assoc tx 
</span><span>        :tag (or
</span><span>               (date-&gt;tag (:date tx))
</span><span>               (text-&gt;tag (:text tx)))
</span><span>        :actions [(fn ignore []
</span><span>                    (edit! 'date-&gt;tag assoc (:date tx) :ignore))
</span><span>                  (fn tag [tag] 
</span><span>                    (edit! 'date-&gt;tag assoc (:date tx) tag))]))))
</span></code></pre>
<p>If you type <code>:eating-out</code> into the one of the textboxes above and then hit the <code>tag</code> button, it will change the <code>date-&gt;tag</code> cell to contain an entry for the date of that transaction with the tag <code>:eating-out</code>.</p>
<p>And then any downstream cells will update, so you'll see the tag for that transaction change to <code>:eating-out</code>.</p>
<p>These actions are just values so they can be passed around like any other value. For example, if I make a list of untagged transactions then I'll still have access to the same actions:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def untagged
</span><span>  (vec
</span><span>    (for [tx txs-with-tags
</span><span>         :when (nil? (:tag tx))]
</span><span>      tx)))
</span></code></pre>
<p>We can also attach metadata to values to control how they render:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def hidden-vec
</span><span>  (with-meta
</span><span>    [1 2 3]
</span><span>    {:preimp/hidden true}))
</span></code></pre>
<p>If you click on the <code>+</code> above it will reveal the contents of the vec. This is useful for controlling the default level of detail.</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn hidden [v]
</span><span>  (with-meta v {:preimp/hidden true}))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def total-per-tag
</span><span>  (reduce 
</span><span>    (fn [totals tx]
</span><span>      (if (= :ignore (:tag tx))
</span><span>        totals
</span><span>        (update-in totals [(:tag tx)] 
</span><span>          (fn [total+txs]
</span><span>            (let [[total txs] (or total+txs [0 (hidden [])])]
</span><span>              [(+ total (:amount tx))
</span><span>               (conj txs (update-in tx [:actions] hidden))])))))
</span><span>    {}
</span><span>    txs-with-tags))
</span></code></pre>
<p>You can click on a <code>+</code> above to reveal the transactions for that tag.</p>
<hr>
<p>The demo on this page is ephemeral - you could do something similar in many notebook environments using mutable data-structures.</p>
<p>But the <a href="https://github.com/jamii/preimp">preimp repo</a> contains a server which persists the entire history of the notebook to disk, and also syncs changes between different clients to allow (coarse-grained) collaborative editing.</p>
<video controls="">
  <source src="https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/demo.mp4" type="video/mp4">
</video>
<p>The server also allows reading and writing cell values over http. Here's the script that I use to upload my bank statements:</p>
<pre data-lang="clj"><code data-lang="clj"><span>(ns </span><span>wise
</span><span>  (</span><span>:require </span><span>[clj-http.client </span><span>:as </span><span>client]
</span><span>            [clojure.data.json </span><span>:as </span><span>json]))
</span><span>
</span><span>(def </span><span>endpoints </span><span>{
</span><span>  </span><span>;; FILL ME IN
</span><span>})
</span><span>
</span><span>(defn </span><span>api-get </span><span>[user path]
</span><span>  (let [domain (get-in endpoints [user </span><span>:wise-domain</span><span>])
</span><span>        url (str domain </span><span>"/" </span><span>path)
</span><span>        response (client/get url {</span><span>:headers </span><span>{</span><span>"Authorization" </span><span>(str </span><span>"Bearer " </span><span>(get-in endpoints [user </span><span>:wise-token</span><span>]))}})]
</span><span>    (assert (= </span><span>200 </span><span>(</span><span>:status </span><span>response)))
</span><span>    (json/read-str (</span><span>:body </span><span>response))))
</span><span>
</span><span>(def </span><span>now </span><span>(java.time.Instant/now))
</span><span>
</span><span>(defn </span><span>get-transactions </span><span>[user]
</span><span>  (into []
</span><span>        (for [profile (api-get user </span><span>"v2/profiles"</span><span>)
</span><span>              </span><span>:let </span><span>[profile-id (get profile </span><span>"id"</span><span>)]
</span><span>              balance (api-get user (str </span><span>"v4/profiles/" </span><span>profile-id </span><span>"/balances?types=STANDARD"</span><span>))
</span><span>              </span><span>:let </span><span>[balance-id (get balance </span><span>"id"</span><span>)
</span><span>                    statement (api-get user (str </span><span>"/v1/profiles/" </span><span>profile-id </span><span>"/balance-statements/" </span><span>balance-id </span><span>"/statement.json?intervalStart=2022-01-01T00:00:00.000Z&amp;intervalEnd=" </span><span>now </span><span>"&amp;type=COMPACT"</span><span>))]
</span><span>              transaction (get statement </span><span>"transactions"</span><span>)]
</span><span>          transaction)))
</span><span>          
</span><span>(defn </span><span>update-preimp </span><span>[user]
</span><span>  (let [transactions (get-transactions user)
</span><span>        cell-name (symbol (str (name user) </span><span>"-wise-transactions"</span><span>))
</span><span>        cell-value (pr-str </span><span>`</span><span>(</span><span>~'</span><span>defs </span><span>~</span><span>cell-name </span><span>~</span><span>transactions))
</span><span>        body (json/write-str
</span><span>              {</span><span>:cell-id </span><span>(get-in endpoints [user </span><span>:cell-id</span><span>])
</span><span>               </span><span>:value </span><span>cell-value})]
</span><span>    (client/put
</span><span>     (get-in endpoints [user </span><span>:preimp-domain</span><span>])
</span><span>     (merge (get-in endpoints [user </span><span>:preimp-headers</span><span>]) {</span><span>:body </span><span>body}))))
</span><span>
</span><span>(defn </span><span>update-preimp-dev </span><span>[_]
</span><span>  (update-preimp </span><span>:sandbox</span><span>))
</span><span>
</span><span>(defn </span><span>update-preimp-prod </span><span>[_]
</span><span>  (update-preimp </span><span>:jamie</span><span>)
</span><span>  (update-preimp </span><span>:cynthia</span><span>))
</span></code></pre>
<p>Finally, you can export a preimp notebook to produce a perfectly valid clojurescript program.</p>

<p>You can run this program in the repl:</p>
<pre data-lang="clj"><code data-lang="clj"><span>&gt; clj -M -m cljs.main -i ./exported.cljs --repl --repl-env node 
</span><span>
</span><span>preimp.exported=&gt; (require </span><span>'</span><span>clojure.pprint)
</span><span>nil
</span><span>
</span><span>preimp.exported=&gt; (clojure.pprint/pprint txs-with-tags)
</span><span>[{</span><span>:date #inst "2022-05-13T11:01:56.532-00:00"</span><span>,
</span><span>  </span><span>:amount -3.3</span><span>,
</span><span>  </span><span>:text
</span><span>  </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>,
</span><span>  </span><span>:tag :coffee</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-12T10:41:56.843-00:00"</span><span>,
</span><span>  </span><span>:amount -3.3</span><span>,
</span><span>  </span><span>:text
</span><span>  </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>,
</span><span>  </span><span>:tag :coffee</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-12T00:01:03.264-00:00"</span><span>,
</span><span>  </span><span>:amount -72.79</span><span>,
</span><span>  </span><span>:text </span><span>"Card transaction of 72.79 CAD issued by Amazon.ca AMAZON.CA"</span><span>,
</span><span>  </span><span>:tag :things</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-10T10:33:04.011-00:00"</span><span>,
</span><span>  </span><span>:amount -20</span><span>,
</span><span>  </span><span>:text </span><span>"e-Transfer to: John Smith"</span><span>,
</span><span>  </span><span>:tag :eating-out</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-11T17:12:43.098-00:00"</span><span>,
</span><span>  </span><span>:amount -90</span><span>,
</span><span>  </span><span>:text
</span><span>  </span><span>"Card transaction of 90.00 CAD issued by Range Physiotherapy VANCOUVER"</span><span>,
</span><span>  </span><span>:tag :medical</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}]
</span><span>
</span><span>nil
</span></code></pre>
<hr>
<p>This tiny extension to the notebook model allows writing simple ugly crud apps with very little effort. You simply provide the logic and preimp gives you storage, sharing and UI for free. But the result is not an opaque image, nor is it tied to the preimp environment - you can export everything into a regular script and run it in the repl.</p>
<p>TODO rest of this section</p>
<p>required:
rich data model, which can be roundtripped through text
some way of attaching metadata to values, to control their rendering without interfering with execution in the repl</p>
<p>needed:
no declaration order
no mutable environment
no side-effects (other than edit!)
integrity constraints
perf (compiler latency) (thoughput only needs to be better than spreadsheet)</p>
<p>extensions:
much more ui options
selection (+ actions on the side)
dropdowns
understand types / destructuring
render values as copyable text (cf ?)
undo/vc (have whole history in db)
live repl, sandboxing
distribution - single binary, single-file db, optional server (like fossil)</p>
<p>research:
finer-grained collaboration (what data model?)
bidirectional editing / provenance</p>
<hr>
<p>We have to do the other demo too. You know the one.</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs next-id 2)
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs todos 
</span><span>  {0 {:text "make a cool demo" :status :done}
</span><span>   1 {:text "step 2: ???" :status :todo}})
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn new-todo [text] 
</span><span>  (edit! 'todos assoc next-id {:text text :status :todo})
</span><span>  (edit! 'next-id inc))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn named [name fn]
</span><span>  (with-meta fn {:preimp/named name}))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn status-toggle [id]
</span><span>  (let [status (get-in todos [id :status])
</span><span>        other-status (case status
</span><span>                       :done :todo
</span><span>                       :todo :done)]
</span><span>    (named (name status)
</span><span>      (fn [] (edit! 'todos assoc-in [id :status] other-status)))))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs filter :all)
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def toggle-filter
</span><span>  (named (str "viewing " (name filter))
</span><span>    (fn [] (edit! 'filter #(case filter 
</span><span>                             :all :todo
</span><span>                             :todo :done
</span><span>                             :done :all)))))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def filtered-todos
</span><span>  (vec
</span><span>    (for [[id todo] todos
</span><span>          :when (#{:all (:status todo)} filter)]
</span><span>      [(:text todo)
</span><span>       (hidden [(fn set-text [text]
</span><span>                  (edit! 'todos assoc-in [:id :text] text))
</span><span>                (status-toggle id)
</span><span>                (fn delete []
</span><span>                  (edit! 'todos dissoc id))])])))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def app
</span><span>  (vec
</span><span>    (apply list
</span><span>      new-todo
</span><span>      toggle-filter
</span><span>      filtered-todos)))
</span></code></pre>



<hr>
<p>TODO
spreadsheets don't have state problem, but not interactive (at least in same way)</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The DOJ still wants Google to sell off Chrome (151 pts)]]></title>
            <link>https://www.wired.com/story/the-doj-still-wants-google-to-divest-chrome/</link>
            <guid>43299886</guid>
            <pubDate>Sat, 08 Mar 2025 12:57:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/the-doj-still-wants-google-to-divest-chrome/">https://www.wired.com/story/the-doj-still-wants-google-to-divest-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=43299886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The US Department of Justice wants <a href="https://www.wired.com/tag/google">Google</a> to sell off its <a href="https://www.wired.com/tag/chrome">Chrome browser</a> as part of its final remedy proposal in a <a href="https://www.wired.com/story/google-search-antitrust-monopoly-ruling/">landmark antitrust case</a>.</p><p>The proposal, filed Friday afternoon, says that Google must “promptly and fully divest Chrome, along with any assets or services necessary to successfully complete the divestiture, to a buyer approved by the Plaintiffs in their sole discretion, subject to terms that the Court and Plaintiffs approve.” It also would require Google to stop paying partners for preferential treatment of its search engine.</p><p>The DOJ also demands that Google provide prior notification of any new joint venture, collaboration, or partnership with any company that competes with Google in search or in search text ads. However, the company no longer has to divest its artificial intelligence investments, which was part of an initial set of recommendations issued by the plaintiffs last November. The company would still be required to give prior notification of future AI investments.</p><p>“Through its sheer size and unrestricted power, Google has robbed consumers and businesses of a fundamental promise owed to the public—their right to choose among competing services,” the DOJ statement accompanying the filing claims. “Google’s illegal conduct has created an economic goliath, one that wreaks havoc over the marketplace to ensure that—no matter what occurs—Google always wins.”</p><p>The DOJ formally brought its case against Google back in 2020, the most significant tech antitrust case since the DOJ’s years-long battle against Microsoft in the 1990s. The lawsuit alleged that Google has used anticompetitive tactics to protect its search dominance and forge contracts that ensure it’s the default search engine on web browsers and smartphones. Because of its hold on search, the lawsuit claimed, Google can adjust the auction system through which it sells ads and increase prices for advertisers, and rake in more revenue from that.</p><p>Google has argued that its overwhelming success in search—it has a nearly 90 percent share in the US market—stems from the company offering the best search technology. It also says consumers are easily able to change their default search engine, and that Google does face competition from Microsoft and others.</p><p>“DOJ’s sweeping proposals continue to go miles beyond the court’s decision, and would harm America’s consumers, economy and national security,” said Google spokesperson Peter Schottenfels in an emailed statement.</p><p>The case <a href="https://www.wired.com/story/is-googles-search-engine-smart-or-sneaky-a-trial-court-judge-will-decide/">went to trial in 2023</a>, and in August 2024 the US district judge for the District of Columbia, Amit Mehta, ruled that Google <a href="https://www.wired.com/story/google-search-antitrust-monopoly-ruling/">has maintained an illegal monopoly</a>, both in general search and general search text ads.</p><p>Much of the ruling centered on the contracts Google has with device makers and browser partners, which use Google as their default search technology. According to Mehta’s ruling, around 70 percent of search queries in the US happen through portals in which Google is the default search engine. Google then shares revenues with those partners, paying out billions of dollars to them, which disincentivizes smaller search rivals who can’t compete with those contracts, Mehta said.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>This past November, government attorneys <a data-offer-url="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1062.1_1.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1062.1_1.pdf&quot;}" href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1062.1_1.pdf" rel="nofollow noopener" target="_blank">submitted a detailed plan</a> to Mehta that included a spate of recommendations for how to best loosen Google’s stronghold on the US search market. These recommendations included that <a href="https://www.wired.com/story/doj-google-chrome-antitrust/">Google promptly divest Chrome</a>, its popular web browser; possibly divest Android; end its search partnership with Apple, in which Apple receives billions of dollars each year for its Safari browser to default to Google search; and give competitors access to Google’s data, for both search and ads, “that would otherwise provide Google an ongoing advantage from its exclusionary conduct.”</p><p>Kent Walker, Google’s president of global affairs and its chief legal officer, called the November proposal a “<a data-offer-url="https://blog.google/outreach-initiatives/public-policy/doj-search-remedies-nov-2024/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://blog.google/outreach-initiatives/public-policy/doj-search-remedies-nov-2024/&quot;}" href="https://blog.google/outreach-initiatives/public-policy/doj-search-remedies-nov-2024/" rel="nofollow noopener" target="_blank">radical interventionist agenda</a>” that would “endanger the security and privacy of millions of Americans” and stifle innovation. Walker said it would also “chill our investment in artificial intelligence, perhaps the most important innovation of our time, where Google plays a leading role.” Google has increasingly featured AI-powered results at the top of its search pages, despite sometimes uneven results.</p><p>In a <a data-offer-url="https://blog.google/outreach-initiatives/public-policy/google-remedies-proposal-dec-2024/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://blog.google/outreach-initiatives/public-policy/google-remedies-proposal-dec-2024/&quot;}" href="https://blog.google/outreach-initiatives/public-policy/google-remedies-proposal-dec-2024/" rel="nofollow noopener" target="_blank">counter-proposal filed by Google</a> in December, the company said it would structure its contracts to allow for multiple default search agreements across different devices, so that Apple’s iPhones and iPads might have different default search engines; change the length of its search revenue deals with hardware manufacturers to one year rather than locking them into long-term agreements; and allow more flexibility around search and Chrome for Android phone makers. It emphasized that its revenue partners, like Apple and Mozilla, “have the freedom to do deals with whatever search engine they think is best for their users.”</p><p>Essentially, Google has suggested that the company is willing to reevaluate its contracts with partners, but has argued—citing earlier antitrust cases as precedent—that it shouldn’t have to divest parts of its business, share its secret sauce with competitors, or restrict its investments in search and AI, all of which, it argues, would dampen innovation.</p><p>Today’s official remedy is notable in that it reinforces calls for a breakup of part of Google’s core business. For Google, it’s an opening salvo to what will likely be a years-long appeal process. Google has already said it plans to appeal whatever remedy is issued; arguments for the two proposals are scheduled for April in Mehta’s court.</p><p>The remedy will also mark the first major outcome of a US antitrust case under the new Trump administration. Paul Swanson, a litigation partner at Holland &amp; Hart LLP in Denver, Colorado, who focuses on technology and antitrust, says the government’s remedies may be part of a “maximalist opening position that they can then negotiate from.”</p><p>“The one through-line here is that this administration wants to be perceived as being tough on tech, but also not slow the growth of America’s tech industries,” Swanson says. “So they may signal more action than what they ultimately want.”</p><p><em>Update 3/7/25 and 6:44pm ET: This story has been updated with a statement from Google.</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discworld Rules (156 pts)]]></title>
            <link>https://contraptions.venkateshrao.com/p/discworld-rules</link>
            <guid>43299815</guid>
            <pubDate>Sat, 08 Mar 2025 12:48:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://contraptions.venkateshrao.com/p/discworld-rules">https://contraptions.venkateshrao.com/p/discworld-rules</a>, See on <a href="https://news.ycombinator.com/item?id=43299815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em><span>The </span><a href="https://contraptions.venkateshrao.com/p/contraptions-book-club" rel="">Contraptions Book club</a><span> March pick is </span><strong>Giordano Bruno and the Hermetic Tradition by Frances Yates</strong><span>. </span><a href="https://open.substack.com/chat/posts/09f4609d-7910-455b-b6b8-fb55a7bb80ee" rel="">Chat thread</a><span> here. We will discuss this the week of March 24th.</span></em></p><p><em><span>I’ll be co-hosting an online salon </span><strong><a href="https://lu.ma/5qh4qac2" rel="">Silicon Archipelago: A Salon On Open Distributed Southeast Asian Tech Futures</a><span> </span></strong><span>on Friday, March 14 (Southeast Asia time). This is a prequel for an in-person workshop on the same themes in Bangkok in late April (</span><a href="https://www.cmkl.ac.th/event/khlongs-and-subaks-open-distributed-ai-x-blockchain-protocols-in-southeast-asia" rel="">apply here</a><span> if interested — free but limited capacity, with some regional travel support available). I would appreciate any forwards to interesting techies, tech policy people, and tech culture people from the region.</span></em></p><p><em>The Lord of the Rings </em><span>is a great story, but I have to say, I’ve never understood the strange hold it seems to have on the imagination of a particular breed of technologists. </span></p><p><span>As a </span><em>story</em><span> it’s great. It is pure fantasy of course (in the </span><a href="https://protocolized.summerofprotocols.com/p/strange-new-rules" rel="">Chiang’s Law</a><span> sense of being about special people rather than strange rules), full of Chosen Ones doing Great Man (or Great Hobbit) things. As an extended allegory for society and technology it absolutely sucks and is also ludicrously wrong-headed. Humorless Chosen people presiding grimly over a world in terminal decline, fighting Dark Lords, playing out decline-and-fall scripts to which there is no alternative, no Plan B. </span></p><p>This is no way for a high-agency technological species to live, and thankfully it doesn’t have to be.</p><p><span>I mean, I get why politicians and economists might identify with the story. They enjoy little to no direct technological agency, harbor ridiculous Chosen One conceits, and operate in domains — political narratives and the dismal pseudoscience of economics —  that are natural intellectual monopolies or oligopolies. Domains that allow fantasies to be memed into existence (the technical term is </span><a href="https://www.full-stop.net/2020/10/21/features/essays/macon-holt/hyperstitional-theory-fiction/" rel="">hyperstitional theory-fictions</a><span>) for a while before they come crashing down to earth in flames, demonstrating yet again that no, you do not in fact get to create your own reality; that “reality is that which, when you stop believing in it, does not go away.”</span></p><p><span>There is a contrarian reading of </span><em>The Lord of the Rings </em><span>that argues that Sauron and Mordor are in fact the good guys, and represent technological progress, etc. But this is throwing good </span><s>money</s><span> narrativium after bad. Flipping the valence of a Chosen One story doesn’t make it any better. It’s still a Chosen One story with reversed roles. </span></p><p>No, you have to tell different sorts of stories altogether.</p><p><span>Such stories have, in fact, been told. They are Terry Pratchett’s </span><em>Discworld </em><span>stories. This post is an extended argument that as a lens for thinking about the world, </span><em>The</em><span> </span><em>Lord of the Rings, </em><span>is a work that you should “not set aside lightly, but throw across the room with great force,” and that in place of Middle Earth, you should install Terry Pratchett’s Discworld.</span></p><p><span>I won’t get into whether Discworld is better or worse as a fictional universe than Middle Earth. That is a matter of taste and which elements of craft you admire. But </span><em>as an allegory for technology and society, </em><span>Discworld is so radically, vastly superior, and LOTR is so terminally bad, it is not even a contest.</span></p><p><span>If you’re an actual, serious technologist, </span><em>Discworld </em><span>is where you should look for clues about how the world works, how it evolves in response to technological forces, and how humans should engage with those forces. It is catnip for actual technological curiosity, as opposed to validation of incuriously instrumental approaches to technology. If on the other hand, you’re really just a fantasist larping Chosen One stories bolstered by specious Straussian conceits, trying to meme your hyperstitional theory fictions into existence for a while, looting the commons with private-equity extraction engines until you get your Girardian comeuppance — by all means go for it. Though Margaret Thatcher and Neoliberalism are both dead, There Is No Alternative (TINA) — for </span><em>you. </em></p><p>The rest of humanity, thankfully, has more imaginative and generative models of reality to draw on. </p><p><span>Now, for those of you who haven’t read the </span><em>Discworld</em><span> series, it is basically the anti-</span><em>LOTR. </em><span>For starters, even though it is set in a pseudo-historical time rather than the future, and features all the common tropes of  fantasy, all that is in purely ironic mode.  </span><em>Discworld </em><span>is in fact the hardest of hard science fiction universes you can find. Entirely about strange rules rather than special people. </span></p><p>You just have to learn to look past the wizards, dragons, elves, and such. There is even a “Science of Discworld” meta-series to help with that.</p><p>The irony is not subtle. It’s in-your-face. For instance, the core world-building premise is that of a literal “flat earth” disc-shaped planet, resting on the back of four elephants that stand on the back of a giant turtle swimming through space. But this parody of the cosmologies of antiquity is put through its paces with deadpan faux-scientific earnestness. There’s an entire novel about how there was once a fifth elephant, whose fossilized remains are the basis of the fossil fuel industry of Discworld.</p><p>And it only gets sillier from there.</p><p><span>And the sillier it gets, the </span><em>better </em><span>it seems to model our own world (known as </span><em>Roundworld </em><span>in the Discworld cosmogony, a place Discworlders can and do travel to, generally causing mayhem). The wilder a Discworld plot, the more you learn about how technology, society, and progress in Roundworld actually work. </span></p><p>I have a rule-of-thumb: The more seriously you take Discworld, the smarter you get about Roundworld.</p><p>The silliness is a feature, not a bug. Our universe is a vast, crazy place, and we haven’t even begun to scratch the surface of the endless weirdness it harbors. As Douglas Adams noted, “If life is going to exist in a Universe of this size, then the one thing it cannot afford to have is a sense of proportion.” </p><p>Discworld is about curing yourself of the allure of a “sense of proportion.” There is no surer of way of becoming detached from reality and addicted to some notion of manufactured normalcy.</p><p><span>It is notable that one of the favorite rhetorical tricks of self-styled Special People is to point to something in incredulity and pretend to be aghast at how weird it is; how against “common sense” and “reasonable” and “first principles” understandings of the world. Those words and phrases are always suspicious, and </span><em>extra</em><span> suspicious — suspicious-squared as Pratchett might have said — when used by Chosen One types.</span></p><p><span>The </span><em>Lord of the Rings </em><span>on the other hand — the more seriously you take Middle Earth, the dumber you get about Roundworld. </span></p><p>Revealingly, Roundworld isn’t even modeled in the Middle Earth cosmology, except via vaguely racist and lazy allusions (In Middle Earth, I’m presumably one of those turbaned men-from-the-east riding an Oliphaunt and uncritically allied with Sauron). </p><p>If you double down on the LOTR brainrot, and add things like Ayn Rand and Rene Girard to the soup, you get a profoundly stupid vision of the world that it takes real genius to buy into. Which is what, as it happens, a lot of real geniuses (and I don’t mean this snarkily — Peter Thiel is a legit genius who happens to have bought into a really stupid vision of the world) have in fact done as of 2025, as they try to meme a revanchist Great Power world back into existence.</p><p>I’ve thought about this a lot in the last few months, and I’ve concluded the whole program is in fact exactly as stupid as it sounds, and will fail in profoundly stupid ways, doing a lot of irreversible damage (Brexit was a small scale model of what’s in store for us here in the US). </p><p>But to some extent I’ve made my peace with what’s coming, and have no desire to convince you that this is where things are headed. If you’ve bought into that, have fun being miserable in Middle Earth.</p><p>Instead, I want to sketch out for you how you can truly learn to think in pluralist there-are-many-alternatives ways.</p><p>The place to start is with the rules of Discworld.</p><p><span>If you haven’t read any Discworld novels, here is a map with a suggested reading order. I got it </span><a href="https://en.wikipedia.org/wiki/Discworld_(world)" rel="">from Wikipedia</a><span>, and literally checked off the books as I read them all a few years ago (except the Tiffany Aching ones). I recommend you do that too.</span></p><p><span>I read one Pratchett novel (</span><em>Thief of Time </em><span>I think) in college, but I’m glad I didn’t properly get into it till my mid-forties. These are books you cannot really appreciate if you’re too young. I read through the lot around 2017-19, during the first Trump admin, when I was in my early forties.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg" width="1456" height="1532" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1532,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:814386,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://contraptions.venkateshrao.com/i/158124604?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Pratchett believed you should start with </span><em>Sourcery, </em><span>and he is right, not just because it is early in the in-world chronology of one of the main sequences, but because it forcefully establishes what is  perhaps the central dogma of Discworld:</span></p><p><em><strong>People who think they are Special and Chosen are dangerous and bad for the world.</strong></em></p><p><span>The story revolves around Discworld’s satirical version of the Chosen One plot arc. Here is the premise according to the </span><a href="https://en.wikipedia.org/wiki/Sourcery" rel="">Wikipedia entry</a><span>:</span></p><blockquote><p><span>On the Discworld, "sourcerers"—wizards who are sources of magic, and thus immensely more powerful than normal wizards—were the main cause of the Great Mage Wars that left areas of the Disc uninhabitable. As eight is a powerful magical number on Discworld, men born as the eighth son of an eighth son are commonly wizards. Since sourcerers are born the eighth son of an eighth son </span><em>of an eighth son</em><span>, they are "wizards squared". To prevent the creation of sourcerers, therefore, wizards are not allowed to marry or have children.</span></p></blockquote><p><span>These “sourcerers” are one species of annoying Chosen Ones in Discworld. In the novel, the prevention mechanisms fail, and a sourcerer is born, and wreaks havoc for a while trying to do dumb Chosen One things until one of the main protagonists of the world, Rincewind, a hapless, mediocre wizard, manages to contain him. With a lot of help of course — the mediocre protagonists of Discworld rarely act alone and never in hero-mode. Most Discworld stories are, to a first approximation, </span><a href="https://www.amazon.com/Carrier-Theory-Fiction-Terra-Ignota/dp/1999675991" rel="">carrier-bag</a><span> stories.</span></p><p>Discworld is essentially a kind place though, so the antagonists are usually just contained and neutralized, and sometimes even redeemed. They’re not vengefully made an example of by protagonists. That’s a Chosen One move. Discworlders are kinder, even if it costs them. That’s a point we’ll say more about.</p><p>The Rincewind stories are one of four major sequences in the Discworld universe. These are:</p><ul><li><p><strong>Unseen University</strong><span>: Revolving around events at Unseen University in Ankh-Morpork, the setting for most stories, where Rincewind is a professor of geography. It is a den of complacent, mediocre, academic wizards who mostly don’t do anything. They rarely actually use magic for anything practical, not because of any lofty ideas of great power requiring great responsibility, but because they are lazy and magic is messy and causes more problems than it solves.  The other residents of Ankh-Morpork agree, and rarely call on them to do anything.</span></p></li><li><p><strong>The City Watch novels</strong><span>, featuring a stubbornly everyman chief of police, </span><a href="https://en.wikipedia.org/wiki/Sam_Vimes" rel="">Sam Vimes</a><span> (based on the historic Robert Peel who founded London’s police force) who in the universe stands for regicidal skepticisms of power and a plodding, quiet integrity that cannot be bought off or stopped. His ancestor killed the last despotic king of Ankh-Morpork, the city-state in which much of the action unfolds. One of Vimes’ lieutenants, the nice but ordinary Carrot, is in fact the True King, but harbors no ambitions of ascending to a throne in a restored monarchy.</span></p></li><li><p><strong>The Witches novels</strong><span>, featuring a milieu of witches in the countryside, with Granny Weatherwax as the no-nonsense elder. Like the wizards of Unseen University, they too don’t really make much actual use of magic, preferring to solve problems through wisdom and skeptical common sense, frequently battling Chosen One ambitions in their own ranks. The hold the wizards of Unseen University in affectionate contempt, as wild theorists doing weird experiments.</span></p></li><li><p><strong>The Death novels</strong><span>, featuring the regular scythe-wielding figure of </span><a href="https://en.wikipedia.org/wiki/Death_(Discworld)" rel="">Death</a><span>, who is really the steward of life itself on Discworld. He works tirelessly to keep life generative, messy, rich, and varied with his curatorial efforts. His primary antagonist is a bureaucracy, the Auditors of Reality, who hate life because it is messy, and would rather have a lifeless universe following predictable and well-behaved laws. </span></p></li></ul><p><span>The Auditors of Reality are particularly interesting. They are the Discworld edition of what I’ve called the Great Bureaucrat archetype elsewhere. Their ideology is something like the Wokism of Discworld, a deadening, stifling, faceless force of intersectional lifelessness. But as Discworld historigraphy correctly theorizes, the antidote to the dangers of Auditors of Reality is not individual Chosen Ones like sourcerers, over-ambitious witches, or kings claiming divine rights, but </span><em>Death </em><span>itself, understood  as a personification of the process of renewal, regeneration, and stewardship of the organic messiness of life.</span></p><p>I like this as acerbic commentary on the longevity fetish and Eternalism of the Tech Right. </p><p>I have no issues with individuals simply making an extreme sport of literally trying to live as long as possible. Bryan Johnson is a friend and occasional client of mine, and Vitalik Buterin, whom I have interactions with through my protocols work, is also a longevity maven. At more regular-people level, friends of this newsletter like Sarah Constantin are into longevity. </p><p><span>I don’t object to any of this, though personally I want no part of it. I think </span><em>thar be ossified Asimovian spacer worlds</em><span>. But if people want that kind of life and arrange their own affairs to try and get there, I have no quarrel with them.</span></p><p><span>What I have a problem with is people trying to live forever </span><em>as part of a Chosen One script </em><span>which involves them trying to carve up all of the world into the dead empires of a dystopian Great Game world run according to a totalizing script.</span></p><p>I prefer a world run by ordinary mortals who have embraced both their ordinariness and mortality.</p><p>While most core Discworld characters are either mediocre anti-heroes or parodied Chosen One antagonists, there is a big supporting cast of colorful characters who are neither, but not NPCs either. </p><p><span>The most important of these is the wise</span><em> (</em><span>but ordinary and mortal) despot who rules the city of Ankh-Morpork, Vetinari (an allusion to the Medicis). Vetinari’s style of governance is a cross between Daoist and LBJ in </span><em>Master of the Senate</em><span> mode. </span></p><p><span>He operates with an acute and finely tuned sense of the nature of power and how to wield it in the subtlest ways possible. As much as possible, he limits himself to the tiniest possible nudges, conducting the balance-of-power constituent forces of Ankh-Morpork like an orchestra, almost always working through others. His main job is keeping all the guilds of Ankh-Morpork, and its relations with foreign powers, in a stable balance of power (he himself is an alumnus of the Assassin’s Guild). He does this with pragmatism and compromise, nudging the arc of the moral universe to slouch towards utopia, but not at a pace it cannot handle. He is nearly always on the right side of history and social evolution, though sometimes he has to be convinced by more idealistic characters that the time is ripe for a particular change </span><em>now</em><span>, rather than later. He is no broad-based accelerationist, but he surreptitiously, selectively, and surgically helps accelerate currents of positive change that he must publicly appear to oppose.</span></p><p><span>The guilds are the load-bearing elements of Ankh-Morpork’s society. Not NPCs, but usually running as background processes, with Vetinari as system administrator, albeit one who is </span><em>very </em><span>wary of sudo-ing anything.</span></p><p><span>Vetinari is something like an anti-Chosen One. In the most Chosen One story, </span><em>Sourcery</em><span>, the sourcerer turns him into a lizard and puts him in a cage, and he remains out of the picture for the whole novel. That’s one reason things get so out of hand in that story: The main adult in the room is locked away from the action while the Chosen One tries to bull-doge a new reality into being. But in most stories, he adds a decisive nudge or two that allows the world to smoothly and elegantly switch tracks to better futures. </span></p><p><span>Within the rules of Discworld, you could say Vetinari only acts to the extent the system is underdetermined. While he is sovereign in the Schmittian sense — the one with the power to make exceptions — he only has this power to the extent he uses it to nudge the system towards doing what it most </span><em>wants</em><span> to do anyway. He counteracts destabilizing noise in the signal but does not impose his opinions on what Discworld wants to do.</span></p><p><span>Before I get to that, a word on what Discworld does </span><em>not </em><span>want.</span></p><p><span>The main thing Discworld does </span><em>not </em><span>want is to </span><em>be at the mercy of the gods </em><span>(and Chosen Ones with god-delusions)</span><em>.</em></p><p><span>There </span><em>are</em><span> gods on Discworld, but fortunately they are for the most part living in peaceful retirement in Dunmanifestin (“done manifesting”), making it a  </span><em>de facto </em><span>atheist universe. </span></p><p><span>Unlike most of the supporting cast of Discworld, the gods </span><em>are </em><span>NPCs. They don’t do anything, and don’t want to. Ontologically, they are creatures of pure belief, being stronger or weaker, or altogether non-existent, depending on the extent to which mortals believe in them. The only story revolving consequentially around gods is </span><em>Small Gods, </em><span>about a meme-stock god named GameStop, whose power crashes, and who ambitiously plans to pump himself back up to a new high. A parody Chosen One story crossed with Greek mythology tropes.</span></p><p><span>So the story of Discworld is explicitly </span><em>not </em><span>the story of what the gods have planned for it. They got it going and retired, leaving it to its own potentialities. Discworld is </span><em>free </em><span>in a theological sense. There is no Discworld eschatology.</span></p><p><span>Discworld is also not a story scripted by priestly intercessors. There </span><em>is </em><span>a class of time monks (who come across as vaguely Daoist/Buddhist and keep the machinery of time itself going). They are allies of Death, stewards of the messiness of life like him, helping keep the Auditors of Reality at bay. Their job is to keep</span><em> </em><span>history free and evolving through a timescape of many alternatives (not “free” in some narrative-captured sense).</span></p><p>There is also an array of occasional antagonists who periodically show up with grand Thielean “determinate optimism” type plans, convinced they know better than average shmucks, and threatening the freedom of Discworld for its own good. </p><p><span>These include monsters and dragons from the dungeon dimensions, and </span><em>elves</em><span>. </span></p><p>These last named are perhaps the closest thing Discworld has to unredeemed and unredeemable villains. </p><p><span>In Discworld, elves are evil in an insidious, feckless sort of way, being an invasive parasitic species with no imagination but a lot of superficial charm. Here is the essence of their nature, from the </span><a href="https://discworld.fandom.com/wiki/Elves" rel="">Discworld wiki</a><span>:</span></p><blockquote><p>[Elves] are not native to the Disc, but come from a "parasite universe", sometimes called Fairyland. This pocket dimension can latch onto different universes at certain times… </p><p>…Elves have no proper imagination or real emotions, and therefore such things fascinate them. Because they cannot create they steal musicians and artists. Because they cannot have children (although they are capable of breeding with humans, resulting in offspring with superficially elvish characteristics - skinny, pointy ears, a tendency to giggle and burn easily in the sun - but fundamentally human traits i.e. empathy) they steal children from the Disc to be their toys. Because they cannot feel empathy they enjoy the suffering of others. Even if an elf is, for reasons of its own, trying to be nice, its lack of understanding of humans mean there's always something "off" about it.</p><p>Mostly they get away with this, due to the illusion-creating glamour they cast. While elves are, as mentioned above, not musical, elfsong is perceived as beautiful by humans, and is highly hypnotic. Elves are generally seen as innately beautiful and stylish, but this is just another aspect of the glamour. Some of them are only vaguely humanoid.</p></blockquote><p>At one point, the elves migrate to Roundworld and cause havoc there, by killing the narrative vigor of history with their empty and superficial illusions, until Discworlders save the day. I like to pretend this actually happened.</p><p><span>The elves are among the most sophisticated bits of world-building by Pratchett, because they are the personification of </span><em>anti-narrative </em><span>forces in the cosmology. They commonly pose a threat by obscuring the rich potentialities of reality with illusory, degenerative bullshit.</span></p><p><span>The ontological antithesis of the elves is </span><em>narrativium</em><span>, the most common element on Discworld. It is a kind of meta-fictional conceit on Pratchett’s part, allowing his universe to be metamodern without being tedious about it. </span></p><p>Everything satirized and parodied in Discworld, all the ironically deployed tropes of fantasy, are accounted for as the workings of narrativium. That means in-world, all the effects of narrativium are made fun of, but not treated as existential threats. Within the meta-story of Discworld, narrativium adds some of the coherence and discipline that the Auditors of Reality yearn for, but not in a deadening, joyless way. Narrativium is life-affirming narrative irony embodied and embraced.</p><p><span>Narrativium allows Discworld to escape the tyranny of hegemonic TINA stories that insist on destroying all alternative stories. It allows Discworld to have a history, but not be </span><em>bound </em><span>by history. It allows Discworld to constantly entertain and choose among </span><em>many </em><span>futures, as an entire entangled reality. It allows Discworld to forcefully reject (and sometimes eject from reality) the efforts of Chosen Ones to capture reality.</span></p><p><span>Narrativium is </span><em>also </em><span>what allows Discworld to escape the tyranny of the idea that there are, or should be, </span><em>no </em><span>stories (or what is the same thing, the idea that all stories are equally valid and good). This is the fatal flaw in the worldview of the Auditors of Reality who, like their Roundworld counterparts, want to arrive at an always-already bureaucratic perfection and forget anything imperfect ever happened, erasing not just history, but time itself. Death and the Time Monks might do the work necessary to keep them at bay, but Narrativium is what makes Discworld unauditable in the first place.</span></p><p><span>Narrativium is the </span><em>elan vital </em><span>that allows Discworld to pursue what it </span><em>wants </em><span>as opposed to merely avoiding what it does </span><em>not </em><span>want. </span></p><p>The essential property of Narrativium is that it ensures that the history of Discworld will unfold in satisfying ways that make it a good story. This property is most on display in the fifth major sequence of novels in the map: the Industrial Revolution sequence, which feature one of the most interesting characters, Moist Von Lipwig, who is Vetinari’s fixer, nudging technological progress along.</p><p><span>Through these books, Discworld in general, and Ankh-Morpork in particular, repeatedly breaks free of its own past with the help of technological innovations. There is an industrial revolution driven by steam, a postal system emerges, a film industry is born. A great deal more of this sort of thing happens. Discworld evolves a </span><em>lot </em><span>between the earliest and latest books by in-world chronology. That’s what makes the stories a “literature of change” in Ted Chiang terms. These are not stories of heroes restoring changeless sacred realities after profane excursions.</span></p><p>The details of these developments usually feature absurd (and absurdly entertaining) twists on the corresponding Roundworld historical events, while largely staying true to the logic of Roundworld history. For example, film technology on Discworld relies on some faux-science built around small goblins who sit in the cameras painting really fast (magical, but in an inconsequential way).</p><p>And it’s all very satisfying, in ways the corresponding histories on Roundworld are not. The story also feels a lot more forcefully inevitable and necessary, but not in a restrictive or totalizing way. It is intensified rather than revisionist Roundworld history. </p><p>That’s what makes narrativium good to have around.</p><p>This process is one of generative discovery and continuously improvised contingency. The rule that governs this evolutionary process on Discworld, in Pratchett’s own words, is “Our minds make stories, and stories make our minds.”</p><p>This is the Pratchett version of “hyperstitional theory fiction” which applies with much greater force in Discworld, such that far more consequential things can be memed into existence. </p><p>In the most extreme case, as we’ve seen, the gods of Discworld themselves are memed into existence by belief, like over-powered versions of the subjects of Roundworld cults of personality. Roundworld religions, thankfully, don’t have this kind of power to create Roundworld gods of equal substance, since unlike the retiring and lazy Discworld gods, we tend to imagine very interventionist and opinionated gods for ourselves.</p><p><span>In the case of more real things that exist by themselves, rather than as incarnated memes, narrativium undergirds a sort of theory of relativity. I actually independently rediscovered Pratchett’s theory of narrativium in 2019, just before encountering his version, by transposing J. A. Wheeler’s description of General Relativity to narratives. I wrote up my theory </span><a href="https://www.ribbonfarm.com/2019/04/25/worlding-raga-5-world-how/" rel="">as part of an extended series</a><span> on Worlding co-authored with Ian Cheng (that’s Ian’s term for world-building):</span></p><blockquote><p><span>A bit of fun synchronicity. A few weeks ago, I came up with a snowcloned line inspired by a famous tldr of general relativity: </span><em>narratives tell archetypes how to evolve, archetypes tell narratives how to curve.</em><span> </span><a href="https://www.ribbonfarm.com/2019/04/25/worlding-raga-5-world-how/#1" rel=""><sup>1</sup></a><span> Right after, I found a Terry Pratchett quote that says almost the same thing, but less ponderously: “Our minds make stories, and stories make our minds.” I prefer my version though, since I like the synaptic link to physics it creates.</span></p></blockquote><p>Roundworld, sadly, does not have more than trace quantities of narrativium, which is why Roundworld histories are often so unsatisfying and so easily fall prey to Discworld elves, or humans possessed by them.</p><p><span>The presence of narrativium, and the dynamic of stories and minds creating each other, lends to Discworld history a legitimate </span><em>telos. </em><span>On Roundworld all historicism (except perhaps Fukuyama’s) are simply bad thinking. But on Discworld, it is actually meaningful to ask, </span><em>what does Discworld want?</em></p><p><span>The answer is that Discworld </span><em>wants </em><span>to evolve in a way that could be interpreted as progress in the most neutral, non-ideological sense possible — that of an infinite game, where the goal is not for some to win at the expense of others, but for </span><em>all </em><span>to continue to play, and gradually learn to play ever more nicely and kindly as abundance and meaning increase in the world.</span></p><p>The sentiment behind the aspiration is perhaps a mark of British culture at its best. The high conceit of Discworld is that the infinite game always prevails and cannot truly be derailed by even by the most powerful forces. The mediocre efforts of ordinary characters powered by narrativium is enough to keep the infinite game going.</p><p><span>This is why the denizens of Discworld can often act with a generosity of spirit even towards their worst villains. A generosity that we on Roundworld can find hard to conjure up. They </span><em>know </em><span>they are good guys and necessarily on the winning side, while we can only </span><em>hope.</em></p><p><span>One of my favorite lines from </span><em>Doctor Who </em><span>captures the spirit of the Discworld’s narrativium-powered infinite game perfectly: </span><em>always try to be nice, but never fail to be kind. </em></p><p><span>That’s a line from the regeneration speech of the twelfth Doctor (Peter Capaldi). Like Pratchett’s universe, the </span><em>Doctor Who </em><span>universe too tries to be about keeping the infinite game going, albeit not as elegantly (since the Doctor is a Special Person, making it a fantasy universe). </span></p><p><span>The plot device of regeneration that is limited to the Doctor in </span><em>Doctor Who </em><span>applies to all of Discworld. The whole </span><em>world</em><span> periodically regenerates into a new, richer, more complex form, through a process that looks very much like technological progress. </span></p><p><span>Discworld is </span><em>almost </em><span>perfect science fiction by Chiang’s Law; a world of strange rules rather than special people. Almost, but not quite. There is </span><em>one </em><span>big way in which Discworld is in fact fantasy: the </span><em>world </em><span>itself is a special world. A Chosen World.</span></p><p><span>The </span><em>telos </em><span>of Discworld that Roundworld lacks — it </span><em>wants </em><span>to evolve in open-ended ways that make it preternaturally resistant to capture by totalizing narratives — makes it special. </span></p><p>The history of Roundworld in recent centuries has, at least empirically, exhibited such tendencies, but unlike the denizens of Discworld, we cannot trust in that being the intrinsic nature of our world. Certainly those currently in power are trying to prove it isn’t.</p><p><span>Not so on Discworld. On Discworld, the arc of the moral universe </span><em>does </em><span>in fact have a particular disposition; not towards justice or liberalism or any other such tawdry Roundworld ideological conceit, but towards </span><em>greater generativity and complexity and more alternatives.</em><span> On Discworld, the show </span><em>actually </em><span>must go on, due to the laws of narrativium.</span></p><p>Or to put it another way, Discworld has an astounding, unbreakable resistance to Chosen Ones at any scale except the scale of the world itself. Discworld is powered by the anthropic principle on steroids. It keeps discovering new ways in which its entire reality is special.</p><p>This is one reason Discworld can afford to be such a kind world. As a world that is intrinsically pre-disposed to reject totalizing narratives and protect multiple possibilities in an ever-expanding garden of forking paths, reality is on the side of pluralism and against totalizing conceits.</p><p>This is why, on Discworld, even the weakest, most mediocre protagonists, when going up against a powerful Chosen One who wants to capture and enslave reality, can afford to be gracious. Even when they are at the lowest, and cowering before a Chosen One who thinks he has won. Because thanks to the narrativium levels in the environment, the protagonists know they will win, and need never despair. </p><p>The Discworld protagonist seems to know that though they must always scramble comically and improvise energetically to save it from the monstrous Chosen One of the Week, the arc of their moral universe bends in their favor. </p><p>Discworld is a world that knows what it wants, and how to get it. With some nudging along by Vetinari, Death, and Time Monks, and a lot of reluctant anti-heroic adventuring by the likes of Rincewind, Vimes, Granny Weatherwax, and Moist von Lipwig. Narrativium helps those who help themselves. </p><p><span>I </span><em>wish </em><span>this were true of Roundworld.</span></p><p>Unlike Discworld, our own Roundworld has no such specific disposition. The ideas that the arc of moral history on Roundworld bends towards justice, or that “reality” has a well-known liberal bias (a comforting premise of the late-lamented hyperstitional theory fiction of traditional American politics known as “normalcy”) that are popular with us are no more than thin, wishful fictions. Probably planted in our heads by the Discworld elves.</p><p>Roundworld does not want anything in particular, and no future is necessary. As Discworld scientists have discovered on their trips here, life and civilization have evolved and been destroyed multiple times on Roundworld, in a meaningless process of fragile evolution.</p><p><span>Unlike on Discworld, totalizing narratives of bleak “determinate optimism” can capture and destroy Roundworld. They can </span><em>actually </em><span>end history as surely as our Sun going nova. All it takes is a couple of idiots with their fingers on nuclear triggers, surrounding by admiring Yes Men reassuring them of their greatness.</span></p><p><span>But kindness is perhaps one bit of hyperstitial theory fiction that is worth believing in, even if it does not have any of the force of Discworld’s sympathetic magic to it. Kindness is a feature of our moral universe we can </span><em>pretend </em><span>we can meme it into bending towards. </span></p><p>Because kindness is worth it for its own sake, even if Roundworld lacks the narrativium leverage to turn it into a world-protecting force.</p><p>The idea that there are many alternatives is the second most politically loaded one I’ve ever put out, after the idea that with the right technological scaffolding, a proper reckoning with history is in fact possible and desirable, and not necessarily an exercise in bad-faith book-keeping of resentments and grievances. </p><p><span>Both these ideas currently only exist as talks. I haven’t written them up as essays. The reckoning-with-history idea is my </span><a href="https://www.youtube.com/watch?v=ow43pFm9GLQ" rel="">Bloodcoin</a><span> talk from 2018, and the TAMA idea is in my </span><a href="https://www.youtube.com/watch?v=FxBA_9dm6xk" rel="">Civilizational Hypercomplexity</a><span> talk from 2021. Not surprisingly, both talks rely on blockchain-based models of reality. Blockchains are the closest thing to narrativium we Roundworlders have invented. They may be infested with scams and memes, but they cannot be easily captured by Chosen Ones peddling stupid TINAs.</span></p><p><span>The funny thing is, I was never against the original TINA story, neoliberalism. I rather liked it philosophically, liked living in it, and owe basically everything good in my life to it. Now that it is basically over, I do regret its passing, since every TINA hyperstitional theory fiction jockeying to replace it is </span><em>much</em><span> worse. </span></p><p>But at least we’re exploring many alternatives for the moment and not locking into one. And at least the value of real attempts to reckon with history, of the sort I gesture at in the Bloodcoin talk, is becoming crystal clear, given the barrage of wild and transparently motivated confabulations we are now enduring. </p><p><span>This thought inspired </span><a href="https://substack.com/@contraptions/note/c-98520101" rel="">a note</a><span> yesterday:</span></p><blockquote><p>If you want peace, prepare for war. If you want war, prepare for peace.</p><p>If you want the benefits of war without the costs of peace, lie through your teeth about everything</p></blockquote><p>Vetinari, incidentally, did not believe the popular first epigram; he thought the truth was more banal — If you want peace, prepare for peace, if you want war, prepare for war. But I think he would agree with my second thought. Whatever the causal pattern linking war and peace, it is clear that those possessed by elves (or Auditors of Reality) lie through their teeth about everything to justify doing whatever they please, as Chosen Ones.</p><p><span>All that said, there is still the question of kindness — should you be kind, </span><em>especially </em><span>to those you disagree with, and </span><em>especially especially </em><span>when they are strong and threatening to destroy all you hold dear, while you are weak and unable to protect any of it?</span></p><p>Should you live by Discworld rules of kindness and grace, when all that might get you is contempt and destruction? </p><p>Or should you tell yourself stories that make your mind of sterner stuff? </p><p><span>The thought I began with, that </span><em>The Lord of the Rings, </em><span>whatever its merits as a fantasy tale,</span><em> </em><span>is brain-rot for the technological mind, is one that I find so obvious it feels barely worth stating. I only started there because I think that’s where our world’s collective head is at. We not only lack the narrativium protections of Discworld, most humans seem to actively </span><em>prefer </em><span>totalizing single narratives and surrendering to Chosen Ones. Fantasy — in the regular, LOTR sense — is vastly more popular than science fiction.</span></p><p><span>But a comparison that is </span><em>not </em><span>so obvious is between Discworld and Iain M. Banks </span><em>very </em><span>similar Culture novels. Though the milieus couldn’t be more different (space opera vs. steampunk absurdist ironic fantasy), both are science fiction in the Chiang sense — literatures of change set in worlds governed by strange rules.</span></p><p>The Culture is a galactic-scale post-scarcity anarcho-capitalist mongrel utopia under the benevolent protection of superintelligent spaceships. The closest fully realized fictional universe to that meme about fully automated luxury gay space communism.</p><p><span>The Culture though </span><em>is </em><span>neither communism nor capitalism, but a post-capitalist anarchist milieu with few technological peers. It is a superpower on a galactic scale that behaves like a superpower — imposing its values on less developed civilizations with opinionated, unilateralist prejudice. That the values happen to be ones I agree with doesn’t make the Cultures actions more palatable. They are often very troubling (and meant to be).</span></p><p><span>If Discworld has the laws of narrativium going for it, so that mediocrities can serve as stewards, the Culture has a powerful and unapologetically interventionist secret service called Special Circumstances, which operates by the opposite of </span><em>Star Trek</em><span>’s Prime Directive. It cheerfully and heavily interferes all over the place, where it judges that history is headed in the wrong directions. It appoints itself as the Schmittian sovereign making exceptions wherever it likes.</span></p><p>The Culture’s AIs and drones have no compunctions about killing and destruction — this is no gentle Three Laws of Robotics Asimovian universe. In fact, the series opens in the aftermath of a bloody war between the Culture and a peer civilization.</p><p>In the Culture, what is a natural property of reality in Discworld is enforced with extreme prejudice and violence. The entirety of the Culture is like an Assassin’s Guild, with the agents and minds of Special Circumstances acting collectively like a much more forceful Vetinari. </p><p>While life inside the Culture is something like a high-abundance version of an Ursula Le Guin style peaceful anarchy, its actions in foreign space resemble those of the CIA and KGB at the height of the Cold War, rolled into one. Fomenting revolutions, deposing leaders, assassinations — the whole shebang.</p><p><span>To bring it back our core question, that of kindness, the Culture is often kind, though rarely tender, and acts to make sure it’s never in a weak position. It only ever needs to consider the question of kindness from a position of overwhelming strength. The question is never </span><em>if </em><span>it can prevail, but whether it can do so in keeping with its values.</span></p><p>Should we play by Discworld Rules or Culture Rules in the coming years? Should we try to become strong before choosing to be kind, or should we choose kindness whether or not we happen to be strong or weak at any given time?</p><p>I don’t know, but I like that I have at least two good alternatives to ponder. That is the power of not being tied to one narrative with no alternatives being admissible. </p><p>I may never end up choosing, but I think either set of rules would be better than LOTR rules.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Volkswagen reintroducing physical controls for vital functions (240 pts)]]></title>
            <link>https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions</link>
            <guid>43298271</guid>
            <pubDate>Sat, 08 Mar 2025 07:25:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions">https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions</a>, See on <a href="https://news.ycombinator.com/item?id=43298271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>All future <a href="https://www.autocar.co.uk/car-review/volkswagen">Volkswagen</a> models will feature physical controls for the most important functions, design chief Andreas Mindt has said.</p>
<p>The German firm has been criticised over the past few&nbsp;years for moving many of the vital controls in its cars from physical buttons and dials to the infotainment touchscreen. Volkswagen also introduced haptic ‘sliders’ below the touchscreen for the heating and volume&nbsp;and it started using haptic panels instead of buttons for controls mounted on the steering wheel.</p>
<p>More recently, the firm has reintroduced physical steering wheel buttons and Mindt said it is committed to reintroducing physical buttons, starting with the production version of the <a href="https://www.autocar.co.uk/car-news/new-cars/2025-volkswagen-id-2-will-be-even-better-concept">ID 2all concept</a> that will arrive next year.</p>

<p>“From the ID 2all onwards, we will have physical buttons for the five most important functions – the volume, the heating on each side of the car, the fans and the hazard light – below the screen,” said Mindt. “They will be in every car that we make from now on. We understood this.</p>
<p>“We will never, ever make this mistake any more. On the steering wheel, we will have physical buttons. No guessing any more. There's feedback, it's real, and people love this. Honestly, it's a car. It's not a phone: it's a car.”</p>
<p>Mindt said VW will continue to offer cars with touchscreens, in part due to new legal requirements that, as in the US, will require all cars to feature a reversing camera.&nbsp;</p>
<p>“There are a lot of functions you have to deliver in certain areas, so the screen will be big and you will find a lot of HMI [human-machine interface] contents in the depths of the system,” he added. “But the five main things will always be on the first physical layer. That’s very important.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PayPal honey extension has again "featured" flag in Chrome web store (308 pts)]]></title>
            <link>https://chromewebstore.google.com/detail/paypal-honey-automatic-co/bmnlcjabgnpnenekpadlanbbkooimhnj/reviews</link>
            <guid>43298054</guid>
            <pubDate>Sat, 08 Mar 2025 06:43:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chromewebstore.google.com/detail/paypal-honey-automatic-co/bmnlcjabgnpnenekpadlanbbkooimhnj/reviews">https://chromewebstore.google.com/detail/paypal-honey-automatic-co/bmnlcjabgnpnenekpadlanbbkooimhnj/reviews</a>, See on <a href="https://news.ycombinator.com/item?id=43298054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="zpNSJe" jscontroller="Xi0ENb" jsaction="PzrbKe:PxDP6e;Dg2tk:I8BRrf;JIbuQc:qkhPf(Btxakc);rcuQ6b:u9qk0d;"><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjW0qfanKQCgx16_nZw0E3-Ma3uvLP6e7YLpjpam1Llw2XjgrGA=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjW0qfanKQCgx16_nZw0E3-Ma3uvLP6e7YLpjpam1Llw2XjgrGA=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i7"><span>Mike Thompson</span><span>Mar 8, 2025</span></h3></div><p jsname="f27TO">Horrible scam that steals money from affiliates and creators!</p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjUNoSqb7JbnrX6Ihy8kqgZpkMgEkxvFdQJETGH-qiWWOn2v4_WJ=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjUNoSqb7JbnrX6Ihy8kqgZpkMgEkxvFdQJETGH-qiWWOn2v4_WJ=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i8"><span>Meow Meows</span><span>Mar 7, 2025</span></h3></div><p jsname="f27TO">Scammers and thieves.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">1 person found this review to be helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjX_vh2SONY6MM2CDkh7VE4IZZySNLINAeBXXlFhmraPeHeM4CfSHw=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjX_vh2SONY6MM2CDkh7VE4IZZySNLINAeBXXlFhmraPeHeM4CfSHw=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i9"><span>Tim</span><span>Mar 7, 2025</span></h3></div><p jsname="f27TO">Garbage.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjVjfhlJig9NzU8ImbO5HMGz7J0KHWfBtrfDi1PqFDOLnS7Rvu5rig=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjVjfhlJig9NzU8ImbO5HMGz7J0KHWfBtrfDi1PqFDOLnS7Rvu5rig=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i10"><span>Notna</span><span>Mar 7, 2025</span></h3></div><p jsname="f27TO">Massive scam, steals money from your faviorte online creators and bloggers. Shame on you honey!</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">3 out of 3 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a/ACg8ocJXd2Qe_Li9R8T3Xq1xlx6pJI48S8Zgph4brUdrRrTcMYfv9w=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a/ACg8ocJXd2Qe_Li9R8T3Xq1xlx6pJI48S8Zgph4brUdrRrTcMYfv9w=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i11"><span>matt pabla</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">Honey is a huge scam, look it up. Sad....</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">4 out of 4 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjWJtlX6SnWcn0dI832pfgdeKV9Uz7XMdTYn_fT7xQv8DadrIQ=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjWJtlX6SnWcn0dI832pfgdeKV9Uz7XMdTYn_fT7xQv8DadrIQ=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i12"><span>Paul</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">scam</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">3 out of 3 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a/ACg8ocKqbwhOzEC66AOLXkWZ7wZ1XmTbXR5P_815KqY16nVdjI71QA=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a/ACg8ocKqbwhOzEC66AOLXkWZ7wZ1XmTbXR5P_815KqY16nVdjI71QA=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i13"><span>Jordan Dion-Duval</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">Scam, you save more by uninstalling it smh</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjWdcQORdqkLJdX5HovggtAujb9ucHesrZR0bq6yEOUK5Pc10Qa5=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjWdcQORdqkLJdX5HovggtAujb9ucHesrZR0bq6yEOUK5Pc10Qa5=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i14"><span>Michael500ca</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">They deleted my Honey Gold points because I hadn't used them in a while. Horrible rewards program. I am not going to use them anymore.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjWK3dPHc0IAHZvyTKuETCwDi_cMqxBjuWORLvNqX7XmtvRYyto=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjWK3dPHc0IAHZvyTKuETCwDi_cMqxBjuWORLvNqX7XmtvRYyto=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i15"><span>Darshan Kolesar</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">Although this doesn't scam you, it will scam affiliates. Many influencers live off of the money they get from affiliate codes, so please do not install this or use this in any way. I am very disappointed in PayPal for doing this, and I hope Google is competent enough to take down this extension from their store.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjXyUqD7mANi7DGIe0CWxUdivSEF6kmdgRO5byVoWCbCG7Kal20=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjXyUqD7mANi7DGIe0CWxUdivSEF6kmdgRO5byVoWCbCG7Kal20=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i16"><span>Xavier</span><span>Mar 5, 2025</span></h3></div><p jsname="f27TO">scam</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">4 out of 4 found this helpful</span></p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Falkon: A KDE Web Browser (172 pts)]]></title>
            <link>https://www.falkon.org</link>
            <guid>43297590</guid>
            <pubDate>Sat, 08 Mar 2025 04:51:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.falkon.org">https://www.falkon.org</a>, See on <a href="https://news.ycombinator.com/item?id=43297590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content" id="content"><div><div><div><h2>Privacy and security features enabled by default</h2><p>Falkon cares a lot about the security of your data and ship with an ads blocker enabled by default as well as a password manager. Additional configurations allows you to improve even more your security and privacy</p></div><div><picture><source srcset="https://www.falkon.org/images/adblocker_dark.png" media="(prefers-color-scheme: dark)"><img src="https://www.falkon.org/images/adblocker.png" alt=""></picture></div></div><div><div><h2>Customize your experience</h2><p>Falkon support theming so that you can choose how your browser looks. Multiple extensions are also available to help you make Falkon adapt to you.</p></div><div><picture><img src="https://www.falkon.org/images/themes.png" alt="Screenshot of Falkon with multiple themes"></picture></div></div></div><div><div><p><img src="https://www.falkon.org/images/plasma.svg" alt="" width="128" height="128"></p><h2>Integrated inside Plasma</h2><p>Falkon integrates inside Plasma and follows Plasma theming preferences.</p></div><div><p><img src="https://www.falkon.org/images/osi.svg" width="128" height="128" alt=""></p><h2>Open Source</h2><p>Falkon is Open Source and you can browse, edit and share the source code. Falkon is <a href="https://kde.org/">Made By KDE</a>, a community building high-quality projects that your are free to use. Check out all <a href="https://kde.org/products">our projects!</a></p></div></div><div><h2>Announcements</h2><div><div><p>Sunday, 15 December 2024</p><h3>Falkon 24.12 Release notes</h3><p>This release includes fixes for GreaseMonkey, VerticalTabs, Navigation bar (security icon), stability fixes, does not advertise the FTP support, fixes printing and more small fixes.
<a href="https://www.falkon.org/posts/2024/2024-12-15-falkon-24-12-release-notes/">Read More</a></p></div><div><p>Sunday, 29 September 2024</p><h3>Falkon 24.08 Release notes</h3><p>This release focuses on SiteSettings feature, so I will try to introduce it here.
<a href="https://www.falkon.org/posts/2024/2024-09-29-falkon-24-08-release-notes/">Read More</a></p></div><div><p>Saturday, 2 September 2023</p><h3>Falkon 23.08.0 released</h3><p>New Falkon version 23.08.0 is being released as part of KDE Gear.
Notable changes Zoom indicator to the AddressBar When the zoom level on the page is different than the default, show current zoom level in the address bar.
<a href="https://www.falkon.org/posts/2023/2023-09-02-falkon-23-08-0-release/">Read More</a></p></div><div><p>Friday, 21 April 2023</p><h3>Falkon 23.04.0 released</h3><p>New Falkon version 23.04.0 is being released as part of KDE Gear.
Notable changes There is a handful of changes in this release.
KWallet The format under which the passwords are stored has changed from Binary to Map. The passwords can now be viewed from within KWalletManager and even edited. While editing and adding new ones I would be careful with the data field and updated that as well. (This is some Falkon password internal mechanic) The Folder under which the passwords are stored changed from Falkon to FalkonPasswords. This was done to not overwrite the old passwords and potentialy ruin them during the migration to new format.
<a href="https://www.falkon.org/posts/2023/2023-04-21-falkon-23-04-0-release/">Read More</a></p></div></div><p><a href="https://www.falkon.org/posts/">📢 View all announcements</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An epic treatise on error models for systems programming languages (189 pts)]]></title>
            <link>https://typesanitizer.com/blog/errors.html</link>
            <guid>43297574</guid>
            <pubDate>Sat, 08 Mar 2025 04:46:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://typesanitizer.com/blog/errors.html">https://typesanitizer.com/blog/errors.html</a>, See on <a href="https://news.ycombinator.com/item?id=43297574">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
          <section>
	          
<p><strong>Target audience</strong>: Practitioners interested in programming language design
and familiar with representations of errors in at least a few different languages
such as error codes, checked/unchecked exceptions, tagged unions,
polymorphic variants etc.</p>
<p><strong>Estimated reading time</strong>: 60 to 90 mins.</p>
<p>In research papers on programming languages,
there is often a focus on sophisticated
type system features to rule out certain classes of errors,
whereas <em>error handling itself</em> receives
relatively little attention, despite its importance.<span><label for="sn-0"></label><span>This doesn’t seem too dissimilar to problems in the database community/literature, where less “cool” topics like better representation for strings receive relatively little attention compared to their importance. See also: <a href="http://databasearchitects.blogspot.com/2024/12/what-are-important-data-systems.html">What are important data systems problems, ignored by research?</a> and DuckDB creator Hannes Mühleisen’s <a href="https://www.youtube.com/watch?v=dv4A2LIFG80">CIDR 2023 keynote</a> on Developing Systems in Academia for related discussion.</span></span>
For example, in
<a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf">Simple testing can prevent most critical failures [PDF]</a><span><label for="sn-1"></label><span>Readers in a rush can skim sections 1 and 2 and read the ‘Findings’ in bold in section 4.</span></span> , Yuan et al.
found that in the context of distributed data-intensive systems:</p>
<ul>
<li><p>“Almost all catastrophic failures (92%) are the result of
incorrect handling of non-fatal errors explicitly signaled in software”
(Finding 10, p256)</p>
<ul>
<li>Out of these “35% [..] are caused by trivial mistakes in error
handling logic — ones that simply violate best programming practices;
and that can be detected without system specific knowledge.”
(Finding 11, p256)</li>
</ul></li>
</ul>
<p>In contrast, there is some excellent long-form writing on error models out
there by practitioners.</p>
<ul>
<li>Joe Duffy’s blog post on <a href="https://joeduffyblog.com/2016/02/07/the-error-model">the error model in Midori</a>:
This describes a variant of C# used to write a microkernel, drivers,
and a large amount of user code. Duffy describes a two-pronged error
model – “abandonment” (fail-fast error handling)
and a variation on checked exceptions (utilizing class hierarchies).</li>
<li><a href="https://github.com/swiftlang/swift/blob/main/docs/ErrorHandlingRationale.md">The design doc for Swift’s error model</a>: This discusses the pros and cons of error models in several
different languages.</li>
<li>The TigerBeetle docs on <a href="https://github.com/tigerbeetle/tigerbeetle/blob/main/docs/TIGER_STYLE.md#safety">“Tiger Style”</a>:
This describes how the TigerBeetle database tries to ensure various
forms of safety. The discussion on assertions in the Safety section
is particularly worth reading.</li>
<li><a href="https://rust-lang.github.io/rfcs/0236-error-conventions.html">Rust RFC 236 - Error conventions</a>:
This describes conventions for how Rust libraries
should use different error handling mechanisms
in different situations.</li>
<li>Joe Armstrong’s talk <a href="https://youtu.be/TTM_b7EJg5E?si=J321vwBsKhKwgy1s&amp;t=1293">The Do’s and Don’ts of Error Handling</a>:
Armstrong covers the key requirements for handling and recovering
from errors in distributed systems, based on his
<a href="https://erlang.org/download/armstrong_thesis_2003.pdf">PhD thesis from 2003</a> (PDF).<span><label for="sn-2"></label><span>By this point in time, Armstrong was about 52 years old, and had 10+ years of experience working on Erlang at Ericsson.</span></span></li>
</ul>
<p>Out of the above, Armstrong’s thesis is probably the most holistic,
but it’s grounding in Erlang means that it also does not take into
account one of the most widespread forms of static analysis we have today
– type systems. Here’s an excerpt from page 209:</p>
<blockquote>
<p>We can impose a type system on our programming language,
or we can impose a contract checking mechanism between any
two components in a message passing system. Of these two methods I
prefer the use of a contract checker</p>
</blockquote>
<p>In this post, I want to approach error models in a way that is both
<em>holistic</em> and <em>geared towards ecosystems of systems PLs</em>.</p>
<p>By <em>holistic</em>, I mean that I will approach error models from several different perspectives:</p>
<ul>
<li>From a “product” perspective: What are the core assumptions,
what are all the requirements and how are they informed by practical use cases.</li>
<li>From a type systems perspective: How can the type system assist
the programmer to accomplish what they want.</li>
<li>From a language design perspective: How API design guidelines,
conventions and tooling can be combined with type system features
to enable people to write more robust applications.</li>
</ul>
<p>By <em>geared towards ecosystems of systems PLs</em>,<span><label for="sn-3"></label><span>The term “systems programming language” inevitably seems to trigger people into rehashing the same “arguments” in comment sections – many people seem to like using it as a term for excluding other languages because they use reference counting or tracing GC as the default memory management strategy. I’m picking a definition here for the sake of this post. If you dislike this definition, you can either mentally replace all usages of “systems PL” with “language with XYZ memory management strategy” or you can stop reading the post.</span></span> I mean that the error
model must take into account the following needs:</p>
<ul>
<li>Graceful degradation in the presence of errors,
because the underlying platform and/or acceptance criteria
may offer limited recovery capabilities.</li>
<li>Optimizability – either by the compiler, the programmer or both
– as performance bottlenecks arise <em>within</em> the system
rather than from external sources.
This may involve trading off flexibility in error handling
for performance.</li>
<li>Facilitation of interoperability between and co-evolution of
libraries and applications.</li>
</ul>
<p>Some examples of such software include databases,
high-performance web servers, and interpreters.
I will be ignoring use cases
such as small-scale scripting for one-off tasks,
interactive data exploration etc.
I will also be ignoring ABI considerations, because
those can largely be resolved
by varying levels of indirection
in the run-time representation (e.g.&nbsp;see Swift).</p>
<p>The structure of this <del>thesis</del> blog post is as follows:</p>
<ul>
<li><a href="#section-1-key-definitions">Section 1</a> discusses definitions for important terms such as ‘error’,
‘error model’ etc.</li>
<li><a href="#section-2-key-theses">Section 2</a> goes over the primary theses about errors and how people reason
about them, along with examples.</li>
<li><a href="#section-3-key-criteria-for-an-error-model">Section 3</a> covers the key requirements for an error model,
and how these are justified based on the theses in Section 2.</li>
<li><a href="#section-4-an-immodest-proposal">Section 4</a> describes a hypothetical programming language Everr
and its error model.<span><label for="sn-4"></label><span>The reason for introducing a fake language
for the sake of discussion, instead of say proposing extensions
to an existing language, is that it offers a clean slate for combining
ideas across different existing languages without having to
worry about things like compatibility with existing
language features and/or idioms.</span></span></li>
<li><a href="#section-5-error-models-in-the-wild">Section 5</a> describes the error models of various existing
and upcoming programming languages.</li>
<li><a href="#section-6-everr-vs-the-world">Section 6</a> compares Everr with other languages based on the
requirements laid out in Section 3.</li>
<li><a href="#section-7-closing-thoughts">Section 7</a> concludes with some questions for you, an unorthodox choice
to introduce two new terms, a potpourri of metaphors, and some fluffy exhortations.</li>
</ul>
<p>For the die-hard <del>fans</del> readers, there is also an <a href="#appendix">Appendix</a> with 7 sections.</p>
<p>To this end, this post is fairly large, clocking in at 15K+ words
at the time of writing. You have been warned.</p>
<p>Still here? Let’s get started.</p>
<h2 id="section-1-key-definitions">Section 1: Key definitions</h2>
<p>For the sake of this post, I’m going to use the following definitions:</p>
<p><strong>Error</strong>: I’ll use this term in two ways:</p>
<ul>
<li>A program state that is undesirable or non-ideal in some way.</li>
<li>A value reifying an undesirable program state into something
that can be operated upon by the language’s constructs.
For example, errors may be represented as error codes (in C),
exceptions (in Java), <code>error</code> values (in Go), a <code>Result::Err</code> case
(in Rust) and so on. This value may or may not have some
<strong>metadata</strong> attached, such as a stack trace or some indicator
of progress made before hitting the error.</li>
</ul>
<p><strong>Error propagation</strong>: The act of passing an error received from
a function that was called to one’s own caller. During error propagation
one might want to attach more metadata, release some resources etc.</p>
<p><strong>Error handling</strong>: The act of inspecting an error value
and/or its metadata, and making some decision based on that.
For example, one might decide to log the error, propagate it,
discard it, or convert it to a different form.</p>
<p><strong>Error model</strong>: The overall system for representing, creating,
propagating, and handling errors in a programming language,
including best practices and common idioms.</p>
<p>In common parlance, this is just called “error handling”,
but it’s always felt a bit weird to me that seemingly very
different actions like declaring, propagating and inspecting
errors would get lumped together under “handling”. So I’m
borrowing this term from Duffy’s blog post instead.</p>
<p><strong>Exhaustive</strong>: An error (type) is said to be exhaustive when all
the possible data for that error is known up-front.
For example, conversion from an <code>Int64</code> value to a <code>UInt32</code>
value will only fail in a couple of ways: either the
value is negative, or it exceeds <code>2<sup>32</sup> - 1</code>.
Thus, such a conversion operation supports recording
an exhaustive error in case of failure.
In contrast, errors types from external systems,
such as third-party APIs, are typically non-exhaustive.</p>
<p>Exhaustiveness has two axes: fields and cases.<span><label for="sn-5"></label><span>I’m deliberately avoiding a discussion on records vs variants (or structs vs enums/tagged unions, or classes vs case classes) here; more on that in later sections.</span></span></p>
<hr>
<p>Hopefully, none of the above are too controversial.
Let’s keep moving.</p>
<h2 id="section-2-key-theses">Section 2: Key theses</h2>
<p>The rest of this post is going to be based on a few key theses:</p>
<ol type="1">
<li>Whether a program state is an error or not is contextual.</li>
<li>Whether an error can be recovered from or not is sometimes contextual.</li>
<li>Errors need to be able to carry metadata.</li>
<li>Robust error handling sometimes requires detailed understanding of possible error cases.</li>
<li>Errors and metadata in unstructured form are difficult to handle reliably.</li>
<li>Programs typically need to handle both exhaustive and non-exhaustive errors.</li>
<li>Programmers mostly operate with incomplete knowledge about errors.</li>
</ol>
<p>Let’s dig in to each of these one-by-one.</p>
<h3 id="thesis-1-whether-a-program-state-is-an-error-or-not-is-contextual">Thesis 1: Whether a program state is an error or not is contextual</h3>
<p>Let’s consider the classic example of opening a file.
You have some code trying to open a file and that file is not found.
Is that an error? Well, it depends!</p>
<p>For example, say you are writing a CLI application
that is doing a recursive lookup for a configuration file in ancestor
directories from the working directory.</p>
<p>Instead of first checking if the file exists
(e.g.&nbsp;using <a href="https://man7.org/linux/man-pages/man2/stat.2.html"><code>stat(2)</code></a> on Linux)
and then opening the file,
you write your code to open the file directly.<span><label for="sn-6"></label><span>You do this because the existence check + open strategy can still fail at the open stage with a ‘File not found’ error if some other process deleted the file in the middle of your operations.</span></span>
However, in this case, the file opening operation not succeeding
with a ‘File not found’ is not undesirable or incorrect in some way,
i.e., it is not an error, but it is part of normal operation.</p>
<p>Now consider the situation where the path to the
configuration file is obtained via a command-line argument.
In this case, if you get a ‘File not found’ error when opening the file,
it’s likely that the user made a mistake when providing
the command-line argument, so it would make sense to surface
the ‘File not found’ to the user.</p>
<h3 id="thesis-2-whether-an-error-can-be-recovered-from-or-not-is-sometimes-contextual">Thesis 2: Whether an error can be recovered from or not is sometimes contextual</h3>
<p>Some common examples of programming bugs that are often considered
as non-recoverable in the context of application languages
are out-of-bounds array accesses, unwrapping optionals
(or nil/null dereference) and out-of-memory – these are all
listed in the Swift docs and Joe Duffy’s blog post as examples.</p>
<p>Rust RFC 236 categorizes errors into three distinct types:
catastrophic errors, contract violations and obstructions.
Out of these, out-of-memory is considered as a catastrophic error,
whereas index out of bounds is considered a contract violation.<span><label for="sn-7"></label><span>Yes, I understand that this is a conventions RFC and that individual libraries may deviate from the conventions if they have a different set of needs. However, conventions strongly affect the design of language features and standard library APIs, so I think it’s worth discussing this here as well.</span></span>
For both of these, the RFC states that
“The basic principle of the conventions is that:
Catastrophic errors and programming errors (bugs) can and should only
be recovered at a coarse grain, i.e.&nbsp;a task boundary.”</p>
<p>I think it’s important to recognize that even for these errors,
the recoverability is contextual.
For example, in video game code, if there is an off-by-one error
in some rare cases in collision detection or lighting,
it’s possible that the game still works mostly fine,
and that’s good enough.</p>
<p>For out-of-memory in a web server, you may want to limit
the amount of memory a single task can consume,
to prevent the whole server from being terminated
when the server process runs out of memory.</p>
<p>Even if you don’t have per-request limits,
it’s possible that you breach the process-wide memory limit
<em>outside</em> of the context of a particular
task handling some request or background work.
If the server has the opportunity to recover from this,
it might be OK to shed load by
terminating the tasks for a few requests
(e.g.&nbsp;if they don’t use global state,
or only use it in a limited way that allows cleanup)
instead of terminating the entire process.</p>
<p>To be clear, I’m not saying that such examples represent
the majority of cases.
However, my point is that even for cases which <em>seem</em>
relatively cut-and-dry, there are situations where
the classification of an error into recoverable/non-recoverable
is not clear cut.</p>
<h3 id="thesis-3-errors-need-to-be-able-to-carry-metadata">Thesis 3: Errors need to be able to carry metadata</h3>
<p>Once code grows beyond a certain scale, understanding errors requires
collecting metadata about where/what/when/how/why. For example,
in a web server, you might care about tracking the following:</p>
<ul>
<li>A stack trace for the place where the error was originally created.</li>
<li>Severity of the error.</li>
<li>For data validation errors such as in validating JSON,
some ‘path’ within the larger structure
(at the time of the error),
as well as the value of the unexpected portion.</li>
<li>Retryability of operations, such as DB transactions or
<a href="https://grpc.io/docs/guides/retry/">RPC calls</a> in a framework like gRPC.</li>
</ul>
<p>Additionally, one needs to be able to have some logic
that can make use of this metadata (e.g.&nbsp;as methods on an error type,
if the language supports methods in some form),
such as something for generating key-value pairs for observability,
computing equality/hashes for checking sameness etc.</p>
<p><strong>Corollary</strong>: Error codes as the primary language-supported way
of error handling are inadequate for many use cases
(see also: <a href="https://github.com/ziglang/zig/issues/2647">Zig issue #2647 - Allow returning a value with an error</a>).</p>
<h3 id="thesis-4-robust-error-handling-sometimes-requires-detailed-understanding-of-possible-error-cases">Thesis 4: Robust error handling sometimes requires detailed understanding of possible error cases</h3>
<p>In <a href="https://dataintensive.net/"><em>Designing Data-Intensive Applications</em></a>, Martin Kleppman gives an excellent example of database transactions and retryability:</p>
<blockquote>
<p>popular object-relational-mapping (ORM) frameworks [..] don’t retry aborted transactions [..]. This is a shame, because the whole point of aborts is to enable safe retries.</p>
<p>Although retrying an aborted transaction is a simple and effective error handling mechanism, it isn’t perfect:</p>
<ul>
<li>If the transaction actually succeeded, but the network failed while the server tried to acknowledge the successful commit to the client [..], then retrying the transaction [is unsound without extra app-level de-duplication]</li>
<li>If the error is due to overload, retrying the transaction will make the problem worse [..]</li>
<li>It is only worth retrying after transient errors ([..] deadlock, isolation violation, temporary network interruptions, and failover); after a permanent error (e.g.&nbsp;constraint violation) a retry would be pointless</li>
</ul>
</blockquote>
<p>For a library or framework which provides APIs for interacting with a SQL database,
it is necessary to be able to distinguish the various cases of network errors and database errors
if it wants to support automatic retries for aborted transactions.</p>
<p>Of course, not all error handling needs this level of rigor in analyzing the various cases.
Depending on the context,
it might be OK to just log an error and keep going
if one is confident that
it won’t negatively impact the overall system.</p>
<p><strong>Corollary</strong>: An API specification language should probably
discourage hiding error information from return values
(see also: GraphQL’s <a href="https://graphql.org/learn/response/#request-errors">default machinery for error handling</a>).</p>
<h3 id="thesis-5-errors-and-metadata-in-unstructured-form-are-difficult-to-handle-reliably">Thesis 5: Errors and metadata in unstructured form are difficult to handle reliably</h3>
<p><img src="https://i.imgflip.com/9m5w3n.jpg" alt="Anakin and Padme meme. Anakin: I like using domain-specific types for return values. Padme: (smiling) For both success and failure, right? Anakin gives a blank stare. Padme (concerned): For both succcess and failure, right?"></p>
<p>I imagine this point is probably the least controversial.</p>
<p>Stuffing error case information and metadata into strings
makes an API harder to use for a client which cares about
error handling.</p>
<p>If you expose an API where the only way a conscentious user
can extract more data for an error is by parsing a string,
they’re going to write that error parser,
and all the options when you want to
change that error message are going to suck.
(see also: <a href="https://www.hyrumslaw.com/">Hyrum’s Law</a>).</p>
<p><strong>Corollary</strong>: A standard library should probably not encourage
people to easily attach arbitrary data to errors in a way that
cannot be recovered later (see also: Go’s <a href="https://pkg.go.dev/fmt#Errorf"><code>fmt.Errorf</code></a>
function which implicitly encourages users to create unstructured errors**.</p>
<h3 id="thesis-6-programs-typically-need-to-manage-both-exhaustive-and-non-exhaustive-errors">Thesis 6: Programs typically need to manage both exhaustive and non-exhaustive errors</h3>
<p>When a part of a program does not interact with any external systems,
but behaves like a pure function with a
well-understood set of possible behaviors,
using exhaustive error types allows one to model this certainty.</p>
<p>On the other hand, when interacting with external systems which
may change in the future, such as third-party APIs across a network,
OS APIs, databases etc., the program needs a way to model
and handle errors where all the cases and fields are not known up front.
In such situations, ideally, the addition of new error cases and/or fields
should not break existing third-party clients at a source level,
and lead to some reasonable dynamic behavior.</p>
<h3 id="thesis-7-programmers-mostly-operate-with-incomplete-knowledge-about-errors">Thesis 7: Programmers mostly operate with incomplete knowledge about errors</h3>
<p>Outside of safety critical contexts,
I think it’s fair to say that for most production systems,
most people working on them (myself included) have a fairly limited
picture of all the different things that could go wrong.</p>
<p>I suspect this is probably true even if one limits the scope
to just the situations where the underlying APIs are written
by oneself and just involve pure (but complex) computation,
as well as situations where all the inputs and system parameters
are within “acceptable” ranges.</p>
<p>To be clear, I mean this as an observation and not as a value judgement
– I think there are various contributing reasons for this;
competing priorities, high system complexity, poor docs,
minimal language/tooling support and perhaps even optimism.<span><label for="sn-8"></label><span>For more discussion on optimism specifically, see <a href="#appendix-a7-optimism">Appendix A7</a>.</span></span>
Discussing this more would probably take a full blog post or more by itself,
so I’m going to stop there.</p>
<h2 id="section-3-key-criteria-for-an-error-model">Section 3: Key criteria for an error model</h2>
<p>Based on the above theses and my personal experience, I believe
that an error model should be judged based on how well it
satisfies the following key criteria.<span><label for="sn-9"></label><span>If these sound a bit too abstract, I’ll be discussing them in more detail shortly.</span></span></p>
<ul>
<li><p>Error declarations must support:</p>
<ul>
<li><p><strong>Exhaustiveness annotation</strong>: The ability to mark a declaration
as being exhaustive (or not). This must support both axes: fields and cases.</p></li>
<li><p><strong>Case extension</strong>: The ability to extend errors with new cases
(at the declaration site itself) in a backward-compatible way,
if the error was declared to be non-exhaustive in terms of cases.</p></li>
<li><p><strong>Field extension</strong>: Analogous to the above but for fields.</p></li>
<li><p><strong>Case refinement</strong>: The ability to refine previously defined cases
into more fine-grained cases over time
(at the declaration site itself) in a backward-compatible way.</p></li>
</ul></li>
<li><p>Error propagation must support:</p>
<ul>
<li><p><strong>Explicit marking</strong>: The ability<span><label for="sn-10"></label><span>The choice of the word “ability” is intentional. Using an explicit marking discipline may or may not be the default, and may or may not be conventional, but following it must be possible.</span></span> to force code to be written
in a way such that:</p>
<ol type="1">
<li>Possible errors from primitive operations are indicated with explicit marks.</li>
<li>Propagating errors from an invoked operation to one’s own caller requires
an explicit mark.</li>
</ol>
<p>The absence of explicit marks must cause a localized static error.</p></li>
<li><p><strong>Structured metadata attachment</strong>: The ability to attach structured metadata
to an error. Attaching metadata must preserve the fact that the error
is still an error.</p></li>
<li><p><strong>Error combination</strong>: The ability to combine errors into a larger error.</p></li>
<li><p><strong>Erasure</strong>: The ability to abstract fine-grained errors into more
coarse-grained errors.</p></li>
</ul></li>
<li><p>Error handling must support:</p>
<ul>
<li><p><strong>Exhaustiveness checking</strong>:<span><label for="sn-11"></label><span>This needs to correctly account for access control rules. For example, in Rust, the <a href="https://doc.rust-lang.org/reference/attributes/type_system.html#the-non_exhaustive-attribute"><code>#[non_exhaustive]</code></a> attribute has no effect within the same crate.</span></span> For errors declared to be exhaustive,
the ability to match exhaustively against all cases.</p>
<p>Non-exhaustive matches for exhaustive errors must be diagnosed statically.</p>
<p>Additionally, for non-exhaustive errors, attempting an exhaustive match
against the known cases must be diagnosed statically.</p></li>
<li><p><strong>Structured metadata extraction</strong>: The ability to extract structured metadata
attached to an error (the dual of Structured metadata attachment).</p></li>
<li><p><strong>Error projection</strong>: The ability to inspect individual sub-errors out of a combined error (the dual of Error combination).</p></li>
<li><p><strong>Unerasure</strong>: The ability to unerase fine-grained information out of coarse-grained errors (the dual of Erasure).</p></li>
</ul></li>
</ul>
<ul>
<li><p>Criteria for error conventions:</p>
<ul>
<li><p><strong>Error category definitions</strong>: Different categories of errors
must be documented, so that the ecosystem can rely on centralized definitions.
These must be accompanied by examples of
when an error should be put in a certain category,
and when it may be considered as part of another category.</p></li>
<li><p><strong>Guidelines on error definitions</strong>: These should cover what ought to be
documented, which annotations should be considered and/or avoided,
as well as considerations for downstream users of libraries.</p></li>
<li><p><strong>Guidelines on error propagation</strong>: These should cover when it is appropriate
to return errors that are erased vs unerased.</p></li>
<li><p><strong>Guidelines on error handling</strong>: These should cover when it is and
is not appropriate to handle errors within and across library boundaries.</p></li>
</ul>
<p>Guidelines should generally be accompanied by rationale, as well as curated lists
of potential reasons to deviate from the guidelines.</p></li>
<li><p>Criteria for tooling:</p>
<ul>
<li><p><strong>Lint support</strong>: Certain classes of errors are likely best avoided through
lints/style checkers, rather than type system features.</p>
<ol type="1">
<li><p>(Important) A lint that prevents error values from being discarded using
standard shorthands (e.g.&nbsp;<code>_ = &lt;expr&gt;</code>), without an explicit annotation,
such as a comment or a call to an earmarked function
(to allow for ‘Find references’) etc.</p></li>
<li><p>(Nice-to-have) If exhaustiveness of cases/fields is the default at the
language level, then a lint to require manual exhaustiveness annotations
on every type.</p></li>
<li><p>(Nice-to-have) A lint for enforcing that fields and cases of error types
must be documented.</p></li>
</ol></li>
<li><p><strong>Editing support</strong>:</p>
<ol type="1">
<li>(Important) A structured flow for adding new error cases and fields.
The editing environment should identify locations which potentially
need changes – these will generally be locations which materialize
or handle errors of the same type.</li>
</ol></li>
</ul></li>
</ul>
<p>For each of these criteria, the following sub-sections
describe why they are useful.</p>
<h3 id="criteria-for-error-declarations">Criteria for error declarations</h3>
<p>Exhaustiveness annotation is necessary because of <a href="#thesis-6-programs-typically-need-to-manage-both-exhaustive-and-non-exhaustive-errors">Thesis 6</a> -
typical programs need to work with both exhaustive and non-exhaustive errors.
This should probably take the form of an <em>annotation</em> or similar, rather than two
entirely different type system features (e.g.&nbsp;subclasses for the non-exhaustive case
vs standard sum types for the exhaustive case), because:</p>
<ol type="1">
<li>It is possible for a non-exhaustive error to become exhaustive (if the underlying API stops evolving)</li>
<li>The small “conceptual diff” would probably be best reflected as a small syntax diff in code, rather than an entirely different way of organizing the program.</li>
</ol>
<p>Once one accepts that non-exhaustive errors are permitted,
for such errors to be usable across project boundaries,
it naturally follows that the language must support
adding new cases and fields to a non-exhaustive error type
without breaking source-level backward compatibility.</p>
<p>Lastly, when an API developer gains more knowledge<span><label for="sn-12"></label><span>Recall <a href="#thesis-7-programmers-mostly-operate-with-incomplete-knowledge-about-errors">Thesis 7</a> - Programmers mostly operate with incomplete knowledge about errors.</span></span> about a previously
broad error case, they need a way of communicating that to new clients without breaking
existing clients. This requires some way of expressing “this one case is now actually N other cases, where N &gt;= 2”
which is exactly how I described case refinement.</p>
<h3 id="criteria-for-error-propagation">Criteria for error propagation</h3>
<p>The ability to force code to be written using explicit marks for error
handling is valuable because it enables modular reasoning about control
flow and error handling, one function at a time.</p>
<p>Even if a programmer is able to magically keep track of which functions
can silently return which errors in their head,
they may stop working on the codebase,
and the next programmer working on the code
will need assistance in gradually assembling
a <a href="https://ingenieria-de-software-i.github.io/assets/bibliografia/programming-as-theory-building.pdf">new theory of the codebase</a>
they’ve inherited.</p>
<p>The ability to attach structured metadata is valuable because not all
errors can be described by simple primitive values,
and often, it is necessary to have contextual information
in order to debug why an error occurred
(e.g.&nbsp;where in the JSON file is there a missing <code>,</code> again, goddammit).</p>
<p>The ability to combine errors is valuable in the same way
that collections like arrays, sets and maps are valuable.</p>
<p>The ability to erase errors is valuable since not all code cares about
the details of an error. For example, code inside a supervisor task/process
might potentially only care about how to log an error.</p>
<h3 id="criteria-for-error-handling">Criteria for error handling</h3>
<p>Exhaustiveness checking is valuable because it provides clarity
that all cases have been handled. However, in some cases,
it is impossible to have that clarity, since:</p>
<ul>
<li>One might not have sufficient time to understand and analyze
all the cases.</li>
<li>If the error comes from a dependency:
<ul>
<li>One might be unable to change the code in the dependency</li>
<li>One might be unable to replace the dependency</li>
<li>One might not want to (or potentially, cannot)
lock to a certain version of the dependency.</li>
</ul></li>
</ul>
<p>This means that non-exhaustive errors must also get proper
treatment during exhaustiveness checking.</p>
<p>Features like structured metadata extraction,
error projection, and recovery are needed because
their corresponding duals only make sense when used
in concert with them.</p>
<hr>
<p>Now that we’ve covered a fair bit of ground related to error models themselves,
let’s switch gears and talk about what a language design
grounded in these observations could look like.</p>
<h2 id="section-4-an-immodest-proposal">Section 4: An immodest proposal</h2>
<p>I’m going to describe an error model in terms of a hypothetical
systems language Everr (“<strong>Ev</strong>olving <strong>err</strong>ors”)
and its ecosystem.
I’ll demonstrate Everr using examples.<span><label for="sn-13"></label><span>Normally, I’d hope that this is understood, but since this is the internet, I’m going to spell this out explicitly; the concrete syntax being used here is not the point. This is a language I literally just made up to illustrate some concepts.</span></span>
After that, we’ll see how well Everr’s error model compares
to existing mainstream languages with respect to the criteria
outlined in the previous section.</p>
<p>Here’s a rough summary of Everr’s core language constructs:</p>
<ul>
<li>Everr supports semantic attributes on declarations, similar to C++, Rust, Swift etc.</li>
<li>Everr supports structs (a.k.a. records / product types) and enums (a.k.a. variants / sum types).
These can be exhaustive or non-exhaustive.
<ul>
<li>Enums are second-class, like <a href="https://capnproto.org/language.html">Cap’n Proto</a>’s (tagged) union types.
However, they support dedicated sugar making them feel essentially first-class.</li>
</ul></li>
<li>Everr supports style pattern matching using a minor variation of
Cheng and Parreaux’s <a href="https://dl.acm.org/doi/10.1145/3689746">“Ultimate Conditional Syntax”</a>.</li>
<li>Everr has simple namespaces for grouping things,
similar to namespaces in C++ and modules in Rust.
Types themselves are not namespaces.<span><label for="sn-14"></label><span>This is largely for simplifying the description here. If types were allowed to function as namespaces, (or alternately, if namespaces were allowed to have type parameters), that would necessitate different syntax for referring to “outer” generic parameters vs introducing fresh generic parameters, and we’d end up going into the weeds.</span></span></li>
<li>Everr supports union types,<span><label for="sn-15"></label><span>When I say “union types”, I mean it in the type-theoretic sense, not in the sense of untagged unions as in C, C++ etc.</span></span> but only with a mandatory upper bound.
For brevity, I’ll refer to these as “bounded union types”.
Bounded union types come in two flavors – exhaustive and non-exhaustive.</li>
<li>Everr supports a Rust-like trait mechanism as well as a trait deriving mechanism.<span><label for="sn-16"></label><span>The exact mechanism powering trait derivations – whether they be hard-coded in the compiler, be implemented as macros, compiler plugins etc. – is not terribly important for this post, so I will ignore it.</span></span></li>
<li>Everr supports a delegation mechanism for field accesses
and method calls from one type to another.</li>
</ul>
<p>First, let’s do a tour of these core language features.
After that, I’ll describe Everr’s error model.</p>
<h3 id="a-tour-of-everr">A tour of Everr</h3>
<p>Everr has an <code>Optional</code> type for representing optional values:</p>
<pre><code>@exhaustive
enum Optional[A] {
    | None {}
    | Some { value: A }
}</code></pre>
<p>This is syntax sugar for the following code:</p>
<pre><code>namespace Optional {
    // ↓ None will never have new fields
    @exhaustive(fields)
    struct None {}

    // ↓ Some will never have new fields
    @exhaustive(fields)
    struct Some[A] { value: A }
}

// ↓ Optional will never have new fields
@exhaustive(fields)
struct Optional[A] {
    // ↓ Actual enum syntax, without the sugar
    case: @exhaustive(cases) enum {
        | type Optional.None
          // ↑ refers to struct None
        | type Optional.Some[A]
          // ↑ refers to struct Some[A]
    }
}</code></pre>
<p>So <code>Some</code> and <code>None</code> represent first-class types,<span><label for="sn-17"></label><span>For comparisons with Scala’s case classes and Rust’s proposed <a href="https://github.com/rust-lang/lang-team/issues/122">enum variant types</a>, see <a href="#appendix-a1-everr-type-system-discussion">Appendix A1</a>.</span></span>
not just cases of <code>Optional</code>.<span><label for="sn-18"></label><span>This kind of design does not preclude <a href="https://www.0xatticus.com/posts/understanding_rust_niche/">niche optimizations</a>, see <a href="#appendix-a2-niche-optimizations-with-second-class-enums">Appendix A2</a>.</span></span></p>
<p><code>Optional</code> values support pattern matching:</p>
<pre><code>fn demo0(x: Optional[Str]) -&gt; Str {
    if x.case is {
       Optional.None {} -&gt; return "Got None"
       // _ represents a value being discarded
       Optional.Some { value: _ } -&gt; return "Got Some"
    } // Compiler checks exhaustiveness for:
      // 1. Cases of Optional
      // 2. Fields of None
      // 3. Fields of Some
}</code></pre>
<p>Even though pattern matching <em>looks</em> like it happens against types directly,
internally it works like tagged union types in other languages,
so exhaustiveness checking is supported,
unlike pattern matching with open class hierarchies.</p>
<p>To reduce verbosity, Everr has some syntax sugar for pattern matching.</p>
<ul>
<li>Everr supports implicit projection of the field
named <code>case</code> to provide a more familiar syntax.<span><label for="sn-19"></label><span>This is the only special case (ahem) where Everr inserts a field projection operation implicitly.</span></span></li>
<li>To allow the user to omit the type name in common cases,
Everr supports looking up namespaces
with the same name as the type, so one can use “leading dot syntax”,
similar to Swift etc.</li>
</ul>
<p>Rewriting the code using the above sugar:</p>
<pre><code>fn demo1(x: Optional[Str]) -&gt; Str {
    if x is {
        .None {} -&gt; return "Got None"
        .Some { value: _ } -&gt; return "Got Some"
    }
}</code></pre>
<p>Neat! 😃 Things get more interesting
when Everr’s non-exhaustive enums come into the mix.</p>
<pre><code>@non-exhaustive
enum Dessert {
    | Cake { icing : Str }
    | IceCream {}
}</code></pre>
<p>The above type declaration desugars to:</p>
<pre><code>namespace Dessert {
    @non-exhaustive(fields)
    struct Cake { icing : Str }

    @non-exhaustive(fields)
    struct IceCream {}
}

@non-exhaustive(fields)
struct Dessert {
    case: @non-exhaustive(cases) enum {
        | type Dessert.IceCream
        | type Dessert.Cake
    }
}</code></pre>
<p>Here’s how one might write some string conversion functions
for these types in a different project.<span><label for="sn-20"></label><span>Everr’s rules around mandatory handling of future cases and fields are similar to the behavior of Rust’s <code>#[non_exhaustive]</code> – they only apply across access control boundaries.</span></span></p>
<pre><code>fn cake_to_str(cake: Dessert.Cake) -&gt; Str {
    if cake is Dessert.Cake { icing: i, !__ } {
        i.append(" cake");
        return i
    }
}</code></pre>
<p>There are two sigils here: <code>!</code> and <code>__</code>.</p>
<p><code>__</code> means “ignore any label-value pairs, if present”.
Since <code>Cake</code> has a <code>@non-exhaustive(fields)</code> annotation,
the <code>__</code> is mandatory, similar to mandatory catch-all
clauses for cases of an enum.</p>
<p><code>!</code> means “if the next identifier matches one or more known label-value pairs,
or one or more cases, please issue a warning”.<span><label for="sn-21"></label><span>This is a generalized version of <code>@unknown</code> in Swift (<a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/statements#Switching-Over-Future-Enumeration-Cases">docs for <span data-cites="unknown">@unknown</span></a>).</span></span>
Since <code>Cake</code> has a <code>@non-exhaustive(fields)</code> annotation, if a new field is
added to it in the future, then a warning will be issued inside
<code>cake_to_str</code>.</p>
<p>This design allows the author of the type to add new
fields without breaking source-level backward compataibility,
while still allowing the user of the type to opt-in to a “notification”
when the type definition changes.</p>
<p>Using the above function, one can write a function to convert
a <code>Dessert</code> to a string.</p>
<pre><code>fn dessert_to_str(d: Dessert) -&gt; Optional[Str] {
    if d is Dessert { case: dcase, !__ }
       and dcase is {                        // (1)
        .Cake c -&gt;
            return .Some { value: cake_to_str(c) }
        .IceCream { __ } -&gt;
            return .Some{value: "ice cream"} // (2)
        !_ -&gt; return .None{}                 // (3)
    }
}</code></pre>
<p>I know there’s a lot going on in the above code example,
so let’s take it step-by-step.</p>
<pre><code>    if d is Dessert { case: dcase, !__ }
       and dcase is {                        // (1)</code></pre>
<p>There are a few things going on here:</p>
<ul>
<li><p><code>dcase</code> is a new binding for the <code>case</code> field of <code>d</code>.
It is immediately matched on again after <code>and</code>,
using the aforementioned Ultimate Conditional Syntax.</p></li>
<li><p>The <code>__</code> matches the rest of the fields not covered by the pattern,
and their values are ignored.
Omitting <code>__</code> would trigger a compiler error,
since <code>Dessert</code> is a non-exhaustive struct.</p>
<p>Alternately, if one didn’t care about a new field being
added to <code>Dessert</code>, then one could directly use <code>if d.case is</code>.</p></li>
<li><p>Due to the <code>!</code>, the compiler will issue a warning
if the <code>__</code> matches one or more fields,
similar to the logic in <code>cake_to_str</code>.</p></li>
</ul>
<p>Let’s look at the branch (2):</p>
<pre><code>        .IceCream { __ } -&gt;
            return .Some{value: "ice cream"} // (2)</code></pre>
<p>Here again, <code>__</code> means that future fields are being ignored.
The absence of <code>!</code> means that this code will not issue any
warnings if the <code>IceCream</code> type has new fields in the future.</p>
<p>Lastly, since <code>d.case</code> has a non-exhaustive enum type,
a catch-all pattern is mandatory:</p>
<pre><code>        !_ -&gt; return .None{}                 // (3)</code></pre>
<p><code>_</code> means “ignore a single value” similar to other languages.
Due to the <code>!</code>, this line will trigger a compiler warning
if one or more new cases are added to <code>Dessert</code>.</p>
<p>Whew, that was a lot! Here’s an XKCD for a short break.</p>
<p><img src="https://imgs.xkcd.com/comics/in_the_trees.jpg"></p>
<p>Let’s continue. Suppose we have two people Alice and Bob
and we want to write two functions to describe which desserts
they like, in the same project as <code>Dessert</code>.<span><label for="sn-22"></label><span>If it were in a different project, the initialization syntax would not be available for non-exhaustive types.</span></span>
Here are their preferences:</p>
<ul>
<li>Alice likes cake with ganache on top, and also ice cream, but Alice is not open
to trying new desserts.</li>
<li>Bob likes cake with buttercream on top not ice cream. However,
Bob is open to trying new desserts if there are more options in the future.</li>
</ul>
<p>These preferences can be modeled using Everr’s bounded union types.</p>
<p>First, let’s model Alice’s preference.</p>
<pre><code>pub fn alice_likes() -&gt; Array[Dessert:union[.Cake | .IceCream]] {
    return Array.new(
        .Cake{icing: "ganache"},
        .IceCream{},
    )
}</code></pre>
<p>Here, <code>Dessert:union[.Cake | .IceCream]</code> represents an exhaustive (bounded) union type. It implies that values of types <code>Cake</code> and <code>IceCream</code> are allowed, and in the future, even if <code>Dessert</code> gains new cases, those will not be returned. Similar to exhaustive enums, if a caller tries to pattern match on the union value, they can match exhaustively, without needing a catch-all pattern.</p>
<p>Now let’s model Bob’s preference.</p>
<pre><code>pub fn bob_likes() -&gt; Array[Dessert:union+[.Cake]] {
    return Array.new(.Cake{icing: "buttercream"})
}
</code></pre>
<p>Here <code>Dessert:union+[.Cake]</code> represents a non-exhaustive (bounded) union type. It implies that only values of type <code>Cake</code> are allowed, but in the future, other cases of the top type – in this case, <code>Dessert</code> – may also appear. Similar to non-exhaustive enums, if a caller tries to pattern match on the union value, they must account for new cases being added (including <code>IceCream</code> if Bob changes his mind).</p>
<p>The exhaustiveness of a union type only applies to its cases. When pattern matching, one still needs to be explicit about handling unknown fields (using <code>__</code> or <code>!__</code>) since both <code>Cake</code> and <code>IceCream</code> have <code>@non-exhaustive(fields)</code>.</p>
<hr>
<p>Since enum cases have first-class struct types, different enums can share cases.</p>
<pre><code>enum BakeryItem {
    | Bread {}
    | type Dessert.Cake // OK
}</code></pre>
<p>This allows reuse of case types without needing to copy the case definition.</p>
<hr>
<p>Everr supports traits and trait derivations.
Everr has a built-in <code>UpCast</code> trait meant to represent O(1) conversions
from enum cases to a type containing the enum.</p>
<pre><code>trait UpCast[From, To] {
    fn up_cast(_: From) -&gt; To
}</code></pre>
<p>This trait is automatically implemented for enum cases.
So you’d have:</p>
<pre><code>impl UpCast[Dessert.Cake, Dessert] { ... }
impl UpCast[Dessert.IceCream, Dessert] { ... }

impl UpCast[BakeryItem.Bread, BakeryItem] { ... }
impl UpCast[Dessert.Cake, BakeryItem] { ... }</code></pre>
<p>Similar to interfaces in other languages, these can also be implemented by hand.</p>
<hr>
<p>Lastly, Everr supports a delegation mechanism across types.
For example, if you have code like:</p>
<pre><code>struct BakeryProduct {
    @delegate
    base: BakeryItem
    ingredients: Array[Ingredient]
    price: Money
}</code></pre>
<p>At usages of the <code>.</code> operator for field access and method calls
on a <code>BakeryProduct</code> value, the compiler first checks if
<code>BakeryProduct</code> has the field or method, and if not,
checks if <code>BakeryItem</code> has the field or method.</p>
<p>At most one field can have a <code>@delegate</code> annotation to maintain
predictability in the face of field re-ordering without needing
ad-hoc tie-breaking rules.</p>
<p>Because cases are represented through a special <code>.case</code> field,
pattern matching directly on a <code>BakeryProduct</code> value will work,
because <code>BakeryItem</code> has a <code>.case</code> field which allows pattern-matching.</p>
<hr>
<p>Okay, that concludes the tour of Everr’s core language features!
Now let’s talk about Everr’s error model.</p>
<h3 id="everrs-error-model---overview">Everr’s error model - Overview</h3>
<p>Everr’s error model is based on the core observation that the
handling and recovery from different errors is generally
context-dependent, so it provides flexibility and broad mechanisms
for different error handling strategies in different contexts.</p>
<p>There are two modes for error propagation and handling.</p>
<ul>
<li>Fail-slow error handling: This is done using the standard <code>Result</code> type,
which is an exhaustive enum equivalent to that in Rust and Swift.</li>
<li>Fail-fast error handling: This comes in two flavors:
<ul>
<li>Recoverable: This is done using <code>panic</code> and <code>catch panic</code>
primitives, similar to <code>panic</code>/<code>recover</code> in Go and
<code>panic!</code>/<code>catch_unwind</code> in Rust. Panicking and panic catching themselves
use memory pre-allocated at program startup to avoid out-of-memory
in the middle of a panic,
while accepting the risk of potentially needing to discard
some relevant data.</li>
<li>Non-recoverable, i.e.&nbsp;program termination. This is done using an
<code>exit</code> primitive.</li>
</ul></li>
</ul>
<p>OS signals are handled using callbacks and potentially
manifested using one of the above depending on the exact signal
and configuration.</p>
<p>Notably, there is no support for asynchronous termination of non-cooperative tasks
via asynchronous exceptions, such as that in Haskell, OCaml or Erlang.</p>
<p>For primitive operations, the defaults are as follows:</p>
<ul>
<li>Numeric operations on bounded integer types panic on failure,
prioritizing safety over performance.</li>
<li>Assertion failures trigger a panic.</li>
<li>Out-of-memory for the heap aborts the program.</li>
<li>Stack overflow aborts the program.</li>
</ul>
<p>However, these can be customized; more details on each of them soon.</p>
<p>One important aspect on how Everr code negotiates what is and is not allowed,
is through the designation of certain core language features as <em>capabilities</em>.
Examples of capabilities include heap allocation, panicking,
program termination and foreign function interface (FFI) usage.</p>
<p>Capabilities manifest at the boundaries of packages,
which are Everr’s units of distribution.
Each package has a manifest file, which supports specifying:</p>
<ul>
<li><p>The capabilities used by the given package, in addition to the defaults.
Each capability has three levels (other than <strong>Unavailable</strong>):</p>
<ul>
<li><p><strong>Implicit</strong>: All code is granted access to the capability, without needing
any annotation.</p></li>
<li><p><strong>Explicit</strong>: Code which uses the capability must have an explicit annotation.</p></li>
<li><p><strong>Binding</strong>: Code which uses the capability must have an explicit annotation,
and this annotation is considered part of the API contract;
weakening the annotation is considered a breaking change.</p>
<p>One can optionally configure the standard linter to enforce that
functions which do not use the capability also have an explicit annotation
indicating that the function is guaranteed to not use the capability
in the future or that it reserves the right to use the capability later on.</p></li>
</ul></li>
<li><p>The capabilities permitted for different dependencies.</p></li>
</ul>
<p>If that sounds a bit too abstract, don’t worry,
I’ll explain the capability system later with examples.</p>
<p>First, let’s discuss fail-slow and fail-fast error handling.</p>
<h3 id="fail-slow-error-handling">Fail-slow error handling</h3>
<p>For very basic operations where only a single failure is possible,
(e.g.&nbsp;a map lookup), the failure is exposed using the standard <code>Optional</code> type.
In most other cases, either the <code>Result</code> or <code>Hurdle</code> types are used.<span><label for="sn-23"></label><span><code>Result</code> and <code>Hurdle</code> are recognized specially by the standard Everr
linter, which issues warnings if <code>_</code> is used to ignore the <code>Fail</code> case the <code>problem</code> field.</span></span></p>
<pre><code>// Result represents computations where errors block progress.
//
// Most commonly used for short-circuiting logic.
@exhaustive
enum Result[A, E] {
    | Pass { value: A }
    | Fail { error: E }
}

// Hurdle represents computations where problems do not
// block progress, but they still need to be bubbled up,
// such as in the form of warnings.
@exhaustive
struct Hurdle[A, E] {
    data: A
    problem: E
}</code></pre>
<p>For the <code>E</code> type parameter, Everr programmers are recommended
to use domain-specific struct and enum types which define errors.
Since both enums and structs support exhaustiveness annotations,
it is easy to mark error types for future evolution.</p>
<p>Since enums are desugared to structs:</p>
<ul>
<li>It is possible to add a field common to all cases of an enum,
without breaking source-level backward compatibility.</li>
<li>It is possible to refine a coarse case into multiple sub-cases
by adding a <code>case: enum { ... }</code> field to the corresponding case.</li>
</ul>
<p>For example, say one has a float parsing function which returned
an error with the following type:</p>
<pre><code>@exhaustive(cases)
enum FloatParseError {
    | UnexpectedChar { byte_offset: UInt64 }
    | NotRepresentable {}
}</code></pre>
<p>Since this is marked specifically as being <code>@exhaustive(cases)</code>,
it means that adding new fields is allowed without it being
considered a breaking change.</p>
<p>One could add a field to the <code>NotRepresentable</code> case, and refine it,
without breaking backward compatibility:</p>
<pre><code>@exhaustive(cases)
enum FloatParseError {
    | UnexpectedChar { byte_offset: UInt64 }
    | NotRepresentable {
        // Represents the lower bound on the number of bits
        // that would be needed for a floating point type
        // to be able to represent the given value.
        min_bits_needed: UInt64
        case: @exhaustive enum {
            | TooSmall {}
            | TooLarge {}
        }
    }
}</code></pre>
<p>Once the type is refined, both of these forms of pattern-matching work.</p>
<pre><code>if err is {
    .UnexpectedChar { .. } -&gt; ..
    .NotRepresentable { __ } -&gt; ..
}
// or more fine-grained
if err is {
    .UnexpectedChar { .. } -&gt; ..
    .NotRepresentable nr and nr is {
        .TooSmall {} -&gt; ..
        .TooLarge {} -&gt; ..
    }
}</code></pre>
<p>Case refinement in Everr provides optionality without a-priori
factoring out enum definitions into separate enum and case struct
definitions, unlike typical languages in the ML family.
The cost of additional verbosity is paid when refinements are introduced.</p>
<hr>
<p>Errors can be propagated using a <code>try</code> operator,
which can be used at different granularities.
– it can be used for one-or-more statements,
or for a specific (tree of) expressions,
including individual call expressions.</p>
<pre><code>enum ABCError {
    | type SubError1
    | type SubError2
    | type SubError3
    | type SubError4
}

fn abc() -&gt; Result&lt;Int, ABCError&gt; {
    try {
        sub_op1(...)
        sub_op2(...)
    }
    let a = try sub_op3(...).some_method(...)
    let b = sub_op4(a).@try
    return ok(b.other_method())
}</code></pre>
<p><code>try</code> allows for a single level of automatic conversion of errors,
via the previously mentioned <code>UpCast</code> trait.
This is similar to <code>?</code> and <code>Try</code> in Rust.</p>
<p>Everr programmers are encouraged to define and use structured error types,
and attach metadata to errors by defining new struct fields.
Structs can be easily serialized
using the same mechanism as for trait derivation,
with minimal boilerplate.
This integrates well with observability libraries such as those
providing APIs for structured logging and tracing.</p>
<p>The Everr language server has a code action for defining error types for a given
function based on the error types of the functions that are called.
It also can intelligently suggest modifications to error cases
as the function body evolves over time, taking contextual rules such
as access control into consideration.</p>
<p>The Everr standard library exposes a standard type for call traces.<span><label for="sn-24"></label><span>A call trace covers different kinds of traces such as a stack trace, <a href="https://ziglang.org/documentation/master/#Error-Return-Traces">Zig-style error return trace</a>, as well as <a href="https://rust-lang.github.io/wg-async/design_docs/async_stack_traces.html">async stack traces</a>. While these are all recorded differently, they fall under the same concept (sequence of source code locations which describe “how did we get here”).</span></span></p>
<p>Even though the use of structured errors is encouraged,
the Everr standard library provides APIs for working
with unstructured errors.</p>
<ul>
<li>An <code>AnyErrorContext</code> type which exposes convenient APIs for:
<ul>
<li>Attaching key-value pairs.</li>
<li>Capturing and recording call traces.</li>
</ul></li>
<li>An <code>AnyError</code> type which pairs an error value along with an <code>AnyErrorContext</code> and zero-or-more child <code>AnyError</code> values (similar to <code>error</code> in Go). This exposes convenient APIs for:
<ul>
<li>Initialization from a specific struct/enum error type.</li>
<li>Merging several sub-errors into a larger error.</li>
<li>Tree traversal and inspection.</li>
</ul></li>
</ul>
<h3 id="fail-fast-error-handling">Fail-fast error handling</h3>
<p>Recoverable fail-fast error handling is done via panics,
which are similar to unchecked exceptions in languages like Java and C++.</p>
<p>Function declarations and types can optionally be annotated with a
<code>@panics</code> attribute which covers whether the function might panic,
it might panic when compiled in development mode
(but never in release mode), or never at all.</p>
<p>Panicking is a capability.
The default capability level for panicking is Implicit, so most
packages do not use <code>@panics</code> annotations.</p>
<p>For packages compiled with Explicit or Binding level for panic marking,
the Everr compiler checks if a function’s <code>@panics</code> annotation
(or lack thereof) matches with the annotations on other
functions that are called by it.</p>
<p>The standard linter recognizes functions with <code>@panics</code> annotations
and recommends adding a section to the function’s API docs
describing when the function might panic.</p>
<p>For the Binding level in particular, the standard linter
has an optional lint requires explicit <code>@panics(maybe)</code>
or <code>@panics(never)</code> annotations on all functions,
to avoid accidental API additions without <code>@panics</code>
annotations (which would prevent the implementation
from using assertions).</p>
<p>The Everr core libraries, including the standard library, use Explicit
panic marking.</p>
<p>A small portion of the Everr ecosystem, chiefly some minimal alternatives
to the standard library and related packages meant to be used in the
context of embedded systems, default to using the Binding level for panic marking.</p>
<p>Similar to panicking, program termination using the <code>exit</code> primitive
is treated as a capability; it has a matching <code>@exits</code> attribute.</p>
<p>However, unlike panicking, the default level for the termination capability
is Explicit, as it is fairly rare to require it in library code.</p>
<h3 id="primitives---bounded-integer-operations">Primitives - Bounded integer operations</h3>
<p>In Everr, numeric operations on bounded integer types panic on overflow.</p>
<p>One can opt-in to alternate behavior on overflow (commonly wrapping)
at the granularity of a package, one or more statements,
or an expression. Similar to <code>try</code>, this operates at a syntactic level.</p>
<pre><code>    let sum_plus_one = @math.wrap { 1 + vec.sum() }
    // Addition semantics in the sum() call itself are unaffected.</code></pre>
<p>When overflow behavior is overriden at the package level,
the Everr language server supports showing inlay hints
for the overflow behavior at function granularity.</p>
<h3 id="primitives---assertions">Primitives - Assertions</h3>
<p>Everr’s assertions are customizable.<span><label for="sn-25"></label><span>I’m deliberately not describing the exact APIs for assertions here as there is some room for building interesting APIs, such as <a href="https://antithesis.com/docs/best_practices/sometimes_assertions/">sometimes assertions</a>.</span></span>
By default, an assertion failure triggers a <code>panic</code>.
However, a binary package can customize the semantics of assertions,<span><label for="sn-26"></label><span>This customizability introduces some more complexity when considering the interaction with default capability levels and capability checking. I’ve not fully thought through the ramifications, but my gut feeling is that this is a solvable problem.</span></span>
by specifying an “assertion overlay” in its package manifest.
This acts as an override for the default assertion related APIs,
so every package in the dependency graph ends
up using one’s custom implementation of assertions.</p>
<p>The two most commonly used assertion overlays are:</p>
<ul>
<li>Profiling overlay: This helps collect metrics related to individual
assertions in production.</li>
<li>Toggling overlay: This helps disable assertions in dependencies,
either statically or dynamically.</li>
</ul>
<h3 id="out-of-memory-handling">Out-of-memory handling</h3>
<p>By default, out-of-memory for the heap results in program termination.</p>
<p>Heap usage is a capability, with the default level of Implicit.</p>
<p>Primitives which utilize heap allocation have fallible alternatives,
making it possible<span><label for="sn-27"></label><span>The design of ergonomic and performant APIs for using custom allocators while maintaining memory safety (or, at least, trying to reduce the number of footguns) is an open problem with several competing approaches. For more details, see Section 6 and Appendix A4.</span></span> to build APIs on top without having to rely on
heap allocation always being successful.</p>
<h3 id="stack-overflow-handling">Stack overflow handling</h3>
<p>By default, stack overflow results in program termination.</p>
<p>Recursion and usage of indirect calls are both considered capabilities,
with the default level of Implicit.</p>
<p>Code which cannot afford to have a stack overflow,
such as code following
<a href="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code">NASA’s rules for safety-critical code</a>,
can easily disable both of these features,
allowing the potential call graph of the program to be statically computed.</p>
<p>This allows computing the total stack usage of the program at the time
of compilation.</p>
<p>Stack usage is not guaranteed to be stable across minor or patch versions
of the Everr compiler, but since qualifying the compiler for safety-critical code
tends to be a time-consuming affair that is less frequent than compiler
releases, this is considered an acceptable trade-off.</p>
<p>For an alternative design which allows for more expressivity at the cost
of more implementation complexity, see Appendix A5.</p>
<h2 id="section-5-error-models-in-the-wild">Section 5: Error models in the wild</h2>
<p>The <a href="https://github.com/swiftlang/swift/blob/main/docs/ErrorHandlingRationale.md#survey">Swift Error Handling Rationale and Proposal</a>
doc I linked earlier covers the error model followed in
C, C++, Objective-C, Java, C#, Go, Rust and Haskell,
so I will not elaborate on those much more here.</p>
<p>Some older statically typed languages missing from that list include
D, OCaml and Ada. Some newer languages understandably missing include
Pony, Nim, Zig, Odin, Roc, Jai and Hare.</p>
<p>Scala does not market itself as a systems programming language,
but it’s type system offers interesting ways of expressing errors,
so it is included below. Other languages such as Dart, Kotlin,
Gleam and Unison are excluded because
I did not see any unusual or interesting ideas related to error
handling in their docs, and they seem to be more targeted towards
applications with less stringent performance requirements.</p>
<p>I’m going to try to summarize the error models very quickly here,
based on the language’s own docs. My summaries should not be considered
authoritiative, especially for pre-1.0 languages where conventions
are probably still in flux, and docs are perhaps more likely to be
out-of-date.</p>
<h3 id="d">D</h3>
<p>As of Feb 2025, the <a href="https://dlang.org/spec/errors.html">official D docs</a>
recommend using unchecked exceptions as the primary way of communicating errors.</p>
<p>However, <a href="https://youtu.be/XQHAIglE9CU?si=iYYy8R9GOEylPR6P&amp;t=1354">at DConf 2020</a>,
Walter Bright, the creator of D, stated that he thinks that
exceptions are obsolete.</p>
<p>Other noteworthy aspects:</p>
<ul>
<li>Functions can be marked <a href="https://dlang.org/spec/function.html#nothrow-functions">nothrow</a>.</li>
<li>The type <a href="https://dlang.org/phobos/object.html#.Exception">Exception</a>
is the base class for all “errors that are safe to catch and handle”.
Throwing an <code>Exception</code> is not allowed in <code>nothrow</code> functions.</li>
<li>The type <a href="https://dlang.org/phobos/object.html#.Error">Error</a>
is the base class of “all unrecoverable runtime errors”.
Throwing an <code>Error</code> is allowed in <code>nothrow</code> functions.</li>
<li>The default <code>assert</code> function/built-in throws an <code>Error</code>.</li>
</ul>
<h3 id="ocaml">OCaml</h3>
<p>Error propagation in OCaml comes in several flavors:</p>
<ul>
<li>Unchecked exceptions - These are widely used by the standard library.
Notably, assertion failures get converted to exceptions.</li>
<li>option and result types - Increasingly more library APIs have alternate
variants which return <code>option</code> or <code>result</code> in the failure case
rather than an exception.</li>
<li>Async exceptions are used for out-of-memory, stack overflow and
for OS signals like SIGINT.</li>
</ul>
<p>Additionally, OCaml supports <a href="https://ocaml.org/manual/5.3/bindingops.html">syntax sugar</a>
for short-circuiting evaluation/chaining of operations using <code>option</code> and <code>result</code>.</p>
<p>The <a href="https://ocaml.org/docs/error-handling">official OCaml docs</a> are probably
best described as being somewhat neutral in terms of prescribing a particular
error propagation strategy, but they do state:</p>
<blockquote>
<p>It tends to be considered good practice nowadays when a function can fail
in cases that are not bugs (i.e., not assert false, but network failures,
keys not present, etc.) to return type such as ’a option or (’a, ’b)
result (see next section) rather than throwing an exception.</p>
</blockquote>
<p>The book <a href="https://dev.realworldocaml.org/error-handling.html">Real World OCaml</a>
recommends using the <code>Base</code> library by Jane Street
in addition to the standard library. This library includes additional
helper types such as <code>Error.t</code> – a lazy string with various helper functions
for ease of construction – and helper functions such as <code>Or_Error.try_with</code>
to convert an exception throwing computation to a <code>result</code>.</p>
<p>Real World OCaml concludes:</p>
<blockquote>
<p>If you’re writing a rough-and-ready program where getting it done quickly is key and failure is not that expensive, then using exceptions extensively may be the way to go. If, on the other hand, you’re writing production software whose failure is costly, then you should probably lean in the direction of using error-aware return types.</p>
<p>[..] If an error occurs sufficiently rarely, then throwing an exception is often the right behavior.</p>
<p>Also, for errors that are omnipresent, error-aware return types may be overkill. A good example is out-of-memory errors, which can occur anywhere, and so you’d need to use error-aware return types everywhere to capture those.</p>
</blockquote>
<h3 id="ada">Ada</h3>
<p>Ada supports unchecked exceptions using values of a specific
type <code>exception</code> that can optionally carry a string payload.
If I understand correctly, exceptions have a notion of identity that is separate from the string payload.</p>
<p>The <a href="https://learn.adacore.com/courses/intro-to-ada/chapters/exceptions.html#predefined-exceptions">pre-defined exceptions</a> include:</p>
<ul>
<li><code>Constraint_Error</code> of out-of-bounds accesses, overflow, null dereference etc.</li>
<li><code>Storage_Error</code> for allocation failure and stack exhaustion</li>
</ul>
<p>In <a href="https://stackoverflow.com/q/63037858/2682729">one Stack Overflow discussion</a>, I found two different practitioners stating:</p>
<ul>
<li>“The reason for [not having a way to chain exceptions] is that the language has been designed for exceptions to be used scarcely”</li>
<li>“Ada exceptions are expected to be used for truly exceptional problems.”</li>
</ul>
<p>However, the <a href="https://en.wikibooks.org/wiki/Ada_Style_Guide/Program_Structure#Using_Exceptions_to_Help_Define_an_Abstraction">Ada style guide</a>
on Wikibooks has a guideline “Use Exceptions to Help Define an Abstraction”.
One of the code examples in this section is a stack where the <code>Pop</code> operation
raises an exception when the stack is empty.</p>
<p>I/O operations in the Ada standard library pervasively use exceptions.
I was not able to verify if there are other widely used standard library alternatives.</p>
<p>GNAT (Ada compiler toolchain in GCC) supports several settings for
restricting exception usage such as
<a href="https://docs.adacore.com/gnat_rm-docs/html/gnat_rm/gnat_rm/standard_and_implementation_defined_restrictions.html#no-exception-handlers"><code>No_Exception_Handlers</code></a>,
<a href="https://docs.adacore.com/gnat_rm-docs/html/gnat_rm/gnat_rm/standard_and_implementation_defined_restrictions.html#no-exception-propagation"><code>No_Exception_Propagation</code></a>,
and <a href="https://docs.adacore.com/gnat_rm-docs/html/gnat_rm/gnat_rm/standard_and_implementation_defined_restrictions.html#no-exceptions"><code>No_Exceptions</code></a>.
For example, <code>No_Exception_Propagation</code> requires functions to handle exceptions in callees.</p>
<h3 id="scala">Scala</h3>
<p>Scala 3 supports using <a href="https://www.scala-lang.org/api/3.x/scala/util/control/Exception$.html">unchecked exceptions</a>
as well as a tagged union type <a href="https://www.scala-lang.org/api/3.x/scala/util/Try.html">Try</a>
which enables easily catching exceptions and converting them to a sum type representation.</p>
<p>Some popular libraries such as Li Haoyi’s libraries for IO use exceptions
for errors such as a file not being found.</p>
<p>I’m guessing the more FP-oriented parts of the ecosystem probably use
case classes and/or Result to a greater extent, but I was not able to validate
this within 5~10 minutes of searching.</p>
<h3 id="nim">Nim</h3>
<p>Based on a quick skim of the Nim docs, I surmised the following:</p>
<ul>
<li>Nim supports <a href="https://nim-lang.org/docs/manual.html#effect-system-exception-tracking">exception handling</a>,
and this is used by standard library APIs such as for opening files.</li>
<li>Nim supports <code>raises</code> annotations on functions which indicate the types of
exceptions a function may throw (e.g.&nbsp;<code>{.raises: [ParseError]}</code>).</li>
<li>Nim supports a way to mandate explicit <code>raises</code> annotations across a module,
by putting <code>{.push raises: [].}</code> at the start of a module.
This setting ignores exceptions which inherit from <code>system.Defect</code>,
which is Nim’s way of signaling errors such as division by zero
and assertion failure.</li>
<li>Nim also has optional and result types.</li>
</ul>
<p>The <a href="https://nim-lang.org/docs/tut2.html#exceptions">Nim tutorial section on exceptions</a> states that</p>
<blockquote>
<p>A convention is that exceptions should be raised in exceptional cases,
they should not be used as an alternative method of control flow.</p>
</blockquote>
<p>The rest of the tutorial is descriptive –
it covers how to use different language features related to exceptions.</p>
<p>This <a href="https://status-im.github.io/nim-style-guide/errors.result.html">unofficial Nim style guide</a>
has more detailed recommendations on modeling and handling errors.
I was unable to find similar prescriptive language in
the official Nim docs.</p>
<hr>
<p>The below languages are pre-1.0 as of March 2025.<span><label for="sn-28"></label><span>The exception is Odin which currently uses date-based versioning. I’m assuming that as being equivalent to pre-1.0 in terms of stability guarantees given that Odin is less than 10 years old.</span></span></p>
<h3 id="pony">Pony</h3>
<p>The Pony tutorial has <a href="https://tutorial.ponylang.io/expressions/errors.html">a page on the <code>error</code> expression</a>,
which allows a function to abort execution until the enclosing <code>try</code> block.
All partial functions must be annotated with <code>?</code>.</p>
<p>As far as I can tell, there is no way to attach any data
when using the <code>error</code> statement.
If that is correct,
it means that the <code>error</code> primitive is similar
to an optional type which must be explicitly unwrapped.</p>
<p>Looking at unofficial sources,
based on <a href="https://journal.infinitenegativeutility.com/pony-errors-and-logging">this blog post</a>
and <a href="https://stackoverflow.com/questions/42845484/distinguishing-between-different-types-of-error-in-pony">StackOverflow discussion on distinguishing between different types of errors</a>,
it seems like the most common way is to do
error handling in Pony is using union types (e.g.&nbsp;<code>Int64 | OverflowError</code>).</p>
<p>As of Feb 2025, I could not find any official docs
further explaining how errors ought to be modeled and
how error handling should to be done, outside of the
<a href="https://www.ponylang.io/use/performance/pony-performance-cheat-sheet">performance cheat sheet</a>
which recommends avoiding <code>error</code>
and union types in performance-sensitive code,
both for different reasons.</p>
<p>Based on the docs, it looks like union types are compiled
using a <a href="https://tutorial.ponylang.io/expressions/match.html#matching-on-type-and-value">type ID pointer as the tag</a>
plus <a href="https://www.ponylang.io/use/performance/pony-performance-cheat-sheet/#boxing-machine-words">implicit boxing for the value</a>.<span><label for="sn-29"></label><span>This makes sense, as it allows implementing the natural subtyping relationship <code>T &lt;: (T | U)</code> to be implemented with zero run-time cost.</span></span></p>
<h3 id="zig">Zig</h3>
<p>The official Zig way to do error handling is by <a href="https://ziglang.org/documentation/master/#Error-Set-Type">defining “error sets”</a>:</p>
<pre><code>const FileOpenError = error{
    AccessDenied,
    OutOfMemory,
    FileNotFound,
};</code></pre>
<p>Error sets are structurally typed – identically named cases in different <code>error{...}</code>
declarations in different files are interchangeable.<span><label for="sn-30"></label><span>I’m curious to see how this decision pans out over time as the Zig ecosystem grows. Will library authors eventually start adding unique prefixes to library-specific errors, similar to prefixes in C and Objective-C, to avoid collisions?</span></span> This allows coercion of errors
from a subset to a superset, as well as merging using a <code>||</code> operator.</p>
<p><a href="https://github.com/ziglang/zig/issues/2647">Errors cannot not carry payloads</a>.
As a substitute, people use different patterns such as out parameters
and avoiding the standard error handling machinery.</p>
<p>Functions may write or omit the various error cases returned.</p>
<pre><code>// Inferred error set
pub fn parse_f32(...) !f32 { ... }

// Explicit error set
pub fn parse_f32(...) FloatParseError!f32 { ... }</code></pre>
<p>Here <code>FloatParseError!f32</code> is an <a href="https://ziglang.org/documentation/master/#Error-Union-Type">“error union type”</a>.</p>
<p>For handling an error union value returned from a function,
one can use <code>catch</code> keyword along with a default value or a code block.</p>
<p>Zig supports <code>try</code> as a shortcut for error propagation, which amounts
to being sugar for <code>catch |err| return err</code>.</p>
<p>Zig supports <a href="https://ziglang.org/documentation/master/#Non-exhaustive-enum">non-exhaustive enums</a>.
The docs do not explicitly mention support for non-exhaustive errors and structs
(but they do state that “An error set is like an enum”).</p>
<p>Zig programs are able to use a bevy of compile-time introspection facilities,
such as compile-time iteration over the fields of a struct.
The Zig docs do not state how compile-time introspection
interacts with non-exhaustive enums.</p>
<p>Zig uses whole program compilation. During this:</p>
<ul>
<li><p>Unique integer values are picked for different error cases.</p></li>
<li><p>The maximum height of the call graph is computed (recursion is capped to height 2),
and that is used for pre-allocating a buffer for <a href="https://ziglang.org/documentation/master/#Implementation-Details">error return traces</a>
in the Debug and ReleaseSafe modes.</p>
<ul>
<li>Return traces are implemented using a hidden function parameter.</li>
<li><code>catch</code> and <code>try</code> are integrated with return traces.</li>
</ul></li>
</ul>
<p>Zig has a <code>defer</code> statement for resource cleanup.
It also has an <code>errdefer</code> statement which runs a cleanup operation
only if the enclosing function returns an error.</p>
<p>Zig supports a customizable <code>@panic</code> operation.
By default, the implementation <a href="https://sourcegraph.com/github.com/ziglang/zig/-/blob/lib/std/debug.zig?L571">prints a stack trace and terminates the program</a>.
However, the “root file” (the one containing <code>main</code>) can
be used to override this implementation to do something else.</p>
<h3 id="odin">Odin</h3>
<p>Odin <a href="https://odin-lang.org/docs/overview/#unions">supports sum types</a> using the <code>union</code> keyword,
and C-style enums using the <code>enum</code> keyword.</p>
<p>The Odin docs do not have a dedicated section on the error model,
but the <a href="https://odin-lang.org/docs/overview/#union-tags">code examples in the docs</a>
showcase the usage of sum types for errors.</p>
<pre><code>Error :: union #shared_nil {
	File_Error,
	Memory_Error,
}

File_Error :: enum {
	None = 0,
	File_Not_Found,
	Cannot_Open_File,
}

Memory_Error :: enum {
	None = 0,
	Allocation_Failed,
	Resize_Failed,
}</code></pre>
<p>Similar to Go, all types in Odin have a <a href="https://odin-lang.org/docs/overview/#zero-values">zero value</a>.
Generally, <code>nil</code> is a valid value for sum types.<span><label for="sn-31"></label><span>This can be overriden with a <code>#no_nil</code> annotation on the declaration, in which case the sum type must have a default value.</span></span>
The <code>nil</code> values for the types for individual cases can be merged
using the <code>#shared_nil</code> keyword, which is used in the above example.</p>
<p>In 2018, the creator of Odin wrote a blog post
<a href="https://www.gingerbill.org/article/2018/09/05/exceptions-and-why-odin-will-never-have-them/">Exceptions — And Why Odin Will Never Have Them</a>.</p>
<blockquote>
<p>One of the consequences of exceptions is that errors can be raised anywhere and caught anywhere.
This means that the culture of pass the error up the stack for “someone else” to handle.
I hate this culture and I do not want to encourage it at the language level.
Handle errors there and then and don’t pass them up the stack.
You make your mess; you clean it.</p>
</blockquote>
<p>The Odin docs do not mention non-exhaustive structs or unions.</p>
<h3 id="roc">Roc</h3>
<p>Roc’s sum types are structural.</p>
<p>For error handling, Roc recommends the standard <code>Result</code> sum type,
and standard algebraic types for errors.</p>
<p>I searched for a bit, but could not tell if Roc supports some way
of representing non-exhaustive structs and enums.</p>
<p>Roc <a href="https://www.roc-lang.org/faq.html#option-type">deliberately does not define an <code>Optional</code> type</a>
and recommends the consistent use of <code>Result</code> for error handling instead.</p>
<p>Integer overflow in Roc translates to an irrecoverable program crash,
similar to Swift.</p>
<h3 id="jai">Jai</h3>
<p>I watched some of Jonathan Blow’s videos a few years back
and do not recall any particular discussion on the error model.</p>
<p>The <a href="https://pixeldroid.com/jailang/">unofficial Jai docs</a> do not
have any notable mentions of error handling.</p>
<h3 id="hare">Hare</h3>
<p>Hare supports declaring <a href="https://harelang.org/tutorials/introduction#user-defined-types">anonymous tagged union types</a> with implicit tags using <code>|</code>.</p>
<pre><code>type index = size;
type offs = size;

export fn main() void = {
	let z: (index | offs) = 1337: offs;
	assert(z is offs);
};</code></pre>
<p>Based on my reading of the docs, the <code>type A = B</code> syntax introduces
a <em>newtype</em> in Haskell-speak, not a type alias
unlike most other languages that I know of
using the same syntax (e.g.&nbsp;Rust, Go, Swift, Haskell, OCaml).<span><label for="sn-32"></label><span>In most languages, substitution of type aliases is expected to not affect program semantics. Recursive type aliases are also usually not permitted.</span></span></p>
<p>Hare’s tagged union types actually implement <em>union type</em> semantics
in the type-theoretic sense, not sum type semantics.
For more discussion, see Appendix A3.</p>
<p><a href="https://harelang.org/tutorials/introduction#defining-new-error-types">Error types in Hare</a>
can be declared using a prefix <code>!</code>.</p>
<pre><code>type error = !(io::error | invalid | unexpectedeof);</code></pre>
<p>Such an error type can be handled using <code>match</code>,
and supports implicit injection from individual component types.</p>
<p>For functions returning errors, apart from pattern matching,
the error can be propagated to the caller using post-fix <code>?</code>
and used to trigger a crash with post-fix <code>!</code>.</p>
<p>The Hare docs do not mention non-exhaustiveness for fields or cases.</p>
<h2 id="section-6-everr-vs-the-world">Section 6: Everr vs the World</h2>
<blockquote>
<p>The limits of my language mean the limits of my world.</p>
<p>– Ludwig Wittgenstein</p>
</blockquote>
<p>In this section, I’m going to compare Everr
against other existing programming languages
based on the key criteria outlined in Section 3.</p>
<p>I will be focused on <em>native support</em>, i.e.&nbsp;whether a language
supports a direct way of expressing a particular construct,
not whether it can be emulated using other constructs.</p>
<p>I recognize that some language prefer minimizing in-language
complexity in favor of pushing it out into libraries
and/or applications (e.g.&nbsp;by offering general purpose mechanisms
such as macros, compile-time reflection etc.).
However, as a trend, natively supported features
generally get special treatment in terms of syntax sugar,
recognition by tooling and dedicated error messages,
as well as more mentions in official documentation,
so it makes sense to focus on native support.</p>
<p>As the saying goes, “In theory, there is no difference
between theory and practice. In practice, there is.”
This is going to be a bit of an apples-to-wax apple comparison<span><label for="sn-33"></label><span>By “wax apple”, I mean an inedible apple-lookalike made out of wax, not the <a href="https://en.wikipedia.org/wiki/Syzygium_samarangense">wax apple</a> fruit.</span></span>
because there is no implementation of Everr,
so there is no real world evidence that these ideas
are workable without major changes.
All I have to offer is indirect evidence of “success” in
the form of usage of all the languages that Everr
<del>shamelessly copies</del> borrows ideas from.</p>
<p>With that big caveat, let’s proceed.</p>
<h3 id="error-declarations">Error declarations</h3>
<p>Languages using exceptions as the primary mode of error handling
generally lack a native way to enable exhaustiveness checking:
idiomatic error handling is non-exhaustive by construction.</p>
<p>In contrast, newer pre-1.0 languages such as Zig, Roc, Hare etc.
lack native support for non-exhaustive errors.</p>
<p>Older languages with algebraic data types such as Haskell and OCaml
do not have native support for non-exhaustiveness annotations
on data types.</p>
<p>Swift supports marking structs and enums as non-exhaustive,
but this is <a href="https://github.com/swiftlang/swift-evolution/blob/main/proposals/0192-non-exhaustive-enums.md#non-frozen-swift-enums-outside-the-standard-library">coupled to ‘Library Evolution’</a>,
which is Swift’s overarching feature
for maintaining ABI-compatibility guarantees.</p>
<p>Rust supports marking structs and enums as non-exhaustive,
and extending them with fields and cases respectively when
these annotations are used.
However, case refinement requires a-priori defining separate
structs for individual enum cases.</p>
<p>In languages with native support for algebraic data types,
generally sum types and product types are both first-class,
and sum types cannot carry shared fields.
This sometimes leads to soft recommendations of using
single-field structs instead of native enums to maintain
optionality in case one wants to ever add a field common
to all cases without breaking backward compatibility.</p>
<p>Scala should technically support case refinement very well
because case classes are first-class types that can be inherited from.
However, my understanding is that this is <a href="https://gist.github.com/chaotic3quilibrium/58e78a2e21ce43bfe0042bbfbb93e7dc">highly</a> <a href="https://users.scala-lang.org/t/simple-naive-and-wrong-more-than-you-wanted-to-know-about-case-classes/8300">frowned upon</a>.</p>
<p>Scala supports exhaustiveness annotations
along the cases axis using the <code>sealed</code> keyword.
However, the Scala docs do not mention support for non-exhaustiveness
annotations for fields of a case class.</p>
<p>Like Rust, Everr supports exhaustiveness annotations for fields and cases.</p>
<p>Like Cap’n Proto, Everr allows evolving a non-exhaustive enum to a
struct by adding shared fields without a source-level breaking change.</p>
<p>Everr supports case refinement, because cases are represented using
structs, and exhaustivity annotations from the outer type are propagated
to the structs for individual cases,
which allows addition of sub-cases using a <code>case</code> field.</p>
<h3 id="error-propagation---explicit-marking">Error propagation - Explicit marking</h3>
<p>Earlier, in the first sub-point under the bullet for ‘Error propagation’, I wrote:</p>
<blockquote>
<ul>
<li><strong>Explicit marking</strong>: The ability to force code to be written
in a way such that:
<ol type="1">
<li>Possible errors from primitive operations are indicated with explicit marks.</li>
<li>Propagating errors from an invoked operation to one’s own caller requires
an explicit mark.</li>
</ol>
The absence of explicit marks must cause a localized static error.</li>
</ul>
</blockquote>
<p>Let’s discuss the second bit first.</p>
<p>When exceptions are used for error handling, the most common
approach is that exceptions are silently propagated,
and that nearly any function may throw any exception.
This approach relies on programmers’ diligence
in reading, writing and maintaining doc comments.</p>
<p>Some languages which support finer control over exception propagation
are Java, D, Ada, Nim and C++.</p>
<p>My understanding is that the usage of checked exceptions in Java
is uncommon due to the added syntactic overhead, and the inability
to change code over time to return new error cases without jumping
through extra hoops.</p>
<p>Go and Rust have a panicking mechanism which is similar to exceptions,
and the typical recommendation is that these should only be used
for “exceptional” or “catastrophic” situations.</p>
<p>The Rust ecosystem has a <a href="https://blog.reverberate.org/2025/02/03/no-panic-rust.html">well-known “linker hack”</a>
which allows static enforcement over panic propagation
in optimized builds.</p>
<p>Swift, Pony, Zig, Roc and Odin do not have native support for any exception-like mechanism,
and require explicit propagation of errors (or crashing the program).</p>
<p>Rust, Swift and Zig have dedicated syntax for explicit error propagation.</p>
<ul>
<li>Rust has a post-fix <code>?</code> operator for short-circuiting control flow;
this is primarily used for error propagation.
Rust has an unstable feature <a href="https://doc.rust-lang.org/beta/unstable-book/language-features/try-blocks.html"><code>try_blocks</code></a>
to limit the scope of <code>?</code>.</li>
<li>Swift has a prefix <code>try</code> keyword which will bubble any errors
out of the enclosing function. This works at the level of
individual statements as well as sub-expressions.
Swift also supports <code>try?</code> for converting an error to <code>nil</code>
(an <code>Optional</code>), as well as <code>try!</code> for triggering a program crash
on encountering an error.</li>
<li>Zig has the <code>catch</code> and <code>try</code> keywords as explained earlier.</li>
</ul>
<p>Haskell’s <code>do</code> notation also provides similar functionality,
but it can require additional boilerplate depending on way effects
are being propagated (e.g.&nbsp;using effect types or monad transformers).</p>
<p>Some languages have on-going or recent work in a similar vein:</p>
<ul>
<li>Go has a <a href="https://github.com/golang/go/discussions/71460">on-going proposal</a>
for dedicated postfix <code>?</code> sugar for error propagation.
Apart from the sugar, programmers are recommended
to explicitly attach context to errors using
various standard library functions.</li>
<li>The OCaml docs note the trend towards increased use of explicit propagation.
The OCaml standard library also offers more APIs now with explicit errors.</li>
<li>OCaml’s sugar for error propagation helps in writing complex
logic without needing repeated explicit pattern matching.</li>
<li>C++23 added support for <code>std::expected</code>, analogous to Result in other languages.</li>
</ul>
<p>Error propagation in Everr is in some sense a blend of existing languages:</p>
<ul>
<li>It is flexible in allowing <code>try</code> in different places, like Swift.</li>
<li>It offers a third choice between function-wise propagation and
program termination, similar to exceptions.</li>
<li>It allows marking code as “cannot panic” like C++’s <code>noexcept</code>.</li>
</ul>
<p>Additionally, panicking being a capability, and capabilities supporting
different levels means that different levels of rigor can be used in
different contexts.</p>
<h3 id="error-propagation---primitive-operations">Error propagation - Primitive operations</h3>
<p>For overflow errors in integer operations, languages that tend
to offer control do so in the form of compiler flags and
standard library APIs rather than dedicated syntax.</p>
<p>Most languages use wrapping semantics for integer overflow,
with alternate semantics provided through standard library functions,
built-ins and/or types, if at all.</p>
<p>Some notable exceptions:</p>
<ul>
<li>Swift and Roc trigger a crash on overflow.</li>
<li>Rust triggers a panic on overflow in debug mode. This can be overriden
using compiler flags.</li>
<li>C++ treats signed integer overflow as undefined behavior – this can
be overriden to wrapping/trapping semantics using compiler flags.</li>
<li>In Zig, integer overflow triggers:
<ul>
<li>Undefined behavior in the <code>ReleaseFast</code> and <code>ReleaseSmall</code> build modes.</li>
<li>A panic in the <code>Debug</code> and <code>ReleaseSafe</code> build modes
(i.e.&nbsp;crash by default, but overridable).</li>
</ul></li>
</ul>
<p>Everr is somewhere between Swift and Rust in some sense;
it always triggers a panic, regardless of build mode.</p>
<hr>
<p>For heap allocation, most languages do not offer any reasonable
way of dealing with heap exhaustion apart from program termination.<span><label for="sn-34"></label><span>I recognize that on a shared system, the operating system is free to kill a process for consuming too much memory, and how much memory is “too much” can only be determined dynamically. However, at least in some contexts, such as servers, one often knows the amount of memory available at build time or program initialization time.</span></span></p>
<p>Zig and Odin are different from other languages here; allocators
are passed down ~everywhere as parameters (explicitly in Zig, and often
implicitly in Odin using the hidden <code>context</code> parameter).
This allows handling allocation failure at various levels.<span><label for="sn-35"></label><span>It would be interesting to examine what fraction of applications written in Zig and Odin actually have code paths for dedicated handling for out-of-memory errors, instead of just propagating it up the call stack and terminating the program. It would also be interesting to know what sub-fraction of that group has tests for the out-of-memory error handling code path, and how good that test coverage is.</span></span></p>
<p>Zig and Odin do not have any standard source-level markers for code
that is known to be memory safe vs code that is not.</p>
<p>Such discipline is possible in C++, Rust and other languages
to varying extents, but is less common.</p>
<ul>
<li>C++ standard types such as <code>std::string</code> and <code>std::vector</code> take
an optional type parameter for customizing the allocator.</li>
<li>Rust has an <a href="https://doc.rust-lang.org/std/alloc/trait.Allocator.html">unstable allocator_api</a> feature,
where the discussion <a href="https://github.com/rust-lang/rust/issues/32838">originally started in 2016</a>.
Rust also has a competing <a href="https://internals.rust-lang.org/t/pre-rfc-storage-api/18822">storage API</a>
proposal.</li>
</ul>
<p>Ada is somewhat unusual in that it allows returning
dynamically sized data through a secondary stack,
which can avoid the need for heap allocation in certain cases.</p>
<p>Older languages using tracing GCs have evolved to have features
which make it easier to write code free of heap allocations.
Unboxed types are now available to varying extents in Java,
C#, Haskell, OCaml etc.</p>
<p>Since I have not specified neither the memory management strategy
nor the type system for Everr, it doesn’t make sense to perform
a comparison of Everr with other languages for this particular point.</p>
<p>I believe Rust’s current approach of requiring you to use different
collection types
(e.g.&nbsp;<code>Vec</code>, <a href="https://docs.rs/bumpalo/latest/bumpalo/collections/vec/struct.Vec.html"><code>bumpalo::Vec</code></a>,
<a href="https://docs.rs/smallvec/latest/smallvec/struct.SmallVec.html"><code>smallvec::SmallVec</code></a>)
provides an OK sweet spot by putting the complexity
of dealing with different memory management strategies
onto users which need them, rather than on everyone.</p>
<p>See Appendix A4 for more details on some
interesting research in this space.</p>
<hr>
<p>I do not know of any non-research language which can statically
guarantee the absence of stack overflow.</p>
<p>The GNAT compiler for Ada supports
<a href="https://docs.adacore.com/gnat_ugn-docs/html/gnat_ugn/gnat_ugn/gnat_and_program_execution.html#static-stack-usage-analysis">static stack usage analysis</a>,
which allows gathering stack usage data.
Based on some searching, it is not clear if SPARK
can statically guarantee the absence of stack overflow.</p>
<p>Technically, one can employ techniques such as dynamic stack probing,
and then growing the stack using the heap
if it’s likely that one might need more space.
This approach is taken by the Rust <a href="https://github.com/rust-lang/stacker">stacker</a> crate.</p>
<p>Using the capability mechanism, by marking recursion
and indirect calls as capabilities, Everr can reduce
the risk of stack overflow, likely significantly so.
Similar to Ada, an Everr compiler can thus provide
concrete upper bounds on stack usage for functions
where these capabilities are turned off or not used.</p>
<p>See Appendix A5 for one potential idea on how a language
can rule out stack overflow statically while maintaining modularity.</p>

<p>Strictly speaking, structured metadata attachment, error combination and erasure
can be achieved in any mainstream language,
the question is really about how much boilerplate is needed.</p>
<p>For structured metadata attachment, in a language without inheritance,
adding more data to a type requires:</p>
<ol type="1">
<li>Duplicating the original type definition.</li>
<li>Updating the duplicate type definition to add a new field (or case).</li>
<li>Writing a conversion function from the old type to the new type.</li>
</ol>
<p>Depending on which type-aware compile-time metaprogramming facilities are available,
it should be possible to cut down on boilerplate for these kinds of operations
significantly. Languages such as Zig and Nim fall into this bucket.</p>
<p>When using metaprogramming for extending the types, programmers may
encounter difficulties in debugging metaprograms.
Metaprogramming also poses language design challenges by
requiring a clear design for how metaprograms interact with abstraction boundaries.
For example:</p>
<ul>
<li>Are private fields possible? As of Mar 2025, <a href="https://github.com/ziglang/zig/issues/9909">Zig says no</a> whereas Nim says yes.</li>
<li>If private fields are possible, is the metaprogram allowed to inspect private fields?
<ul>
<li>If the metaprogram can inspect private fields, how can the owner of the type definition
retain the ability to remove the private field?</li>
<li>If the metaprogram cannot inspect private fields, then how can it duplicate a type definition?</li>
</ul></li>
</ul>
<p>In theory, support for extensible records (similar to TypeScript and Elm) would
solve this problem cleanly. However, naively using structural extensible records
introduces compatibility hazards across library boundaries,
requires exposing the full structure
in type signatures (against encapsulation),
and increases type system complexity.</p>
<p>In Everr, you can “extend” a sum type defined in an upstream context such as:</p>
<pre><code>@exhaustive
enum ImageProcessingError {
    | DownloadingError { ... }
    | ProcessingError { ... }
    | StoringError { dbError: PgError }
      // Suppose 'PgError' represents a Postgres error which is a complex
      // data type with many fields and methods
}</code></pre>
<p>by defining a new type with specific information of interest:</p>
<pre><code>@exhaustive
struct DetailedStoringError {
    @delegate
    base: ImageProcessingError.StoringError,
    dbName: Str,
    dbURL: URL,
}</code></pre>
<p>and creating a replacement for the outer enum type:</p>
<pre><code>@exhaustive
enum DetailedImageProcessingError {
    | type ImageProcessingError.DownloadingError
    | type ImageProcessingError.ProcessingError
    | type DetailedStoringError
}</code></pre>
<p>this still requires duplicating the cases from the full <code>enum</code> definition,
but not any inline fields specified in it.<span><label for="sn-36"></label><span>Remapping the shared cases
still needs to be done “by hand” in a separate function or relying
on implicit injection from <code>T</code> to <code>A:union[.T | ...]</code>.</span></span></p>
<p>This relies on:</p>
<ul>
<li>The ability to share case types across enums.</li>
<li>The delegation mechanism to avoid duplicating the type definition
as well as explicit forwarding of methods.</li>
</ul>
<p>In languages with support for both union types and delegation
(e.g.&nbsp;via inheritance), such as Scala and Pony,
the same could be achieved with similar or less boilerplate.</p>
<p>Everr’s modeling can be copied over exactly to Odin,
because its tagged unions build on top of structs,
and it <a href="https://odin-lang.org/docs/overview/#using-statement-with-structs">supports delegation</a>.</p>
<p>In a language with sum types but without first-class enum case types
(e.g.&nbsp;Rust, Swift etc.) this requires making sure that you’re
defining dedicated structs for each enum case instead of
defining fields inline.</p>
<p>One way to get a fully static native solution with minimal boilerplate
would be to add support for defining new types using “diffs” from existing types.
While this would be independently useful
(e.g.&nbsp;simultaneously supporting multiple versions of a data format or API),
this introduces more complexities of its own,
and so I’ve chosen to omit that from this presentation.
For a sketch of how that could look like, and the complexities
such a system would have to deal with, see <a href="#appendix-a6-defining-new-types-using-diffs">Appendix A6</a>.</p>
<h3 id="error-handling">Error handling</h3>
<p>Error handling has four sub-criteria: exhaustiveness checking,
structured metadata extraction, error projection, and unerasure.</p>
<p>The latter three essentially amount to specific library calls
and support for field projection and method call syntax, which
are supported by ~most languages nowadays, including languages
which don’t identify themselves as “object-oriented”.</p>
<p>For exhaustiveness checking, most newer languages support it
in some form. The flexibility of pattern matching syntax
(or “switching” syntax) varies heavily based on language.
Depending on the language, the following features
may have varying levels of support:</p>
<ul>
<li>Nested patterns</li>
<li>Or patterns</li>
<li>Pattern guards (i.e.&nbsp;using arbitrary functions in a branch)</li>
</ul>
<p>Everr’s use of the the <a href="https://dl.acm.org/doi/10.1145/3689746">Ultimate Conditional Syntax</a> generalizes
all of these mechanisms, as well as allows more compact expression
of pattern matching by:</p>
<ul>
<li>Reducing the need for explicit temporaries by supporting “splits”</li>
<li>Allowing immediate inline use of bindings following <code>and</code>, without nesting,
generalizing <code>if let</code> style bindings in Rust and Swift.</li>
</ul>
<h3 id="error-conventions">Error conventions</h3>
<blockquote>
<p>Software development can be reduced to a single, iterative action. Almost everything we do in the course of a day — the pull requests, the meetings, the whiteboard diagrams, the hallway conversations — is an explanation. Our job is to explain, over and over, the meaning of our software: what it is, and what we expect it to become.</p>
<p>– Zach Tellman, <a href="https://explaining.software/archive/the-anatomy-of-an-explanation/">Explaining Software</a></p>
</blockquote>
<p>Language documentation generally takes a <em>descriptive</em> position on
error handling, describing all the different ways in which
error handling can be done, but avoids being prescriptive.</p>
<p>This means that projects often tend to follow either
(1) the path the standard library does OR
(2) the path which requires the least boilerplate.
Sometimes, these are the same.</p>
<p>The responsibility of <em>prescribing</em> error conventions for different
situations is generally left to style guides, managed by third parties.</p>
<p>Here’s a short, non-exhaustive list of plausible reasons for this phenomenon:</p>
<ul>
<li>Prescribing approaches is perceived to be “messy” as it requires deeply
understanding and taking into account many different contexts of usage.</li>
<li>Consensus building is both time-consuming and challenging, requiring
strong communication skills and high emotional energy.</li>
<li>Writing documentation is generally under-valued in practice compared
to programming. For example, language release notes typically mention
new features and APIs, not new docs.</li>
</ul>
<p>As ecosystems evolve over time, introducing conventions later in time
is more likely to face opposition, unless these conventions simply
codify existing practices as “best practice.”
This can be true even when evidence is presented in favor of newer conventions,
due to various <a href="https://en.wikipedia.org/wiki/Category:Cognitive_biases">cognitive biases</a>.</p>
<p>I belie
ve there is much more room for languages to provide clearer guidance
on appropriate contexts for using specific ways of defining, propagating
and handling errors.</p>
<p>I further believe that it is valuable to provide prescriptive guidance
earlier in a language’s lifespan than is common,
and to encourage thinking about guidance as an evolving artifact
grounded in evidence. For example, guidance can be accompanied by
short summaries of past evidence showing positive/zero/negative results
in relation to the guidance,
as well as explicit invitations for collecting further evidence.</p>
<h3 id="tooling">Tooling</h3>
<p>In principle, given sufficient resources, almost any kind of tooling can be
built for any language. The problem is that in practice,
“resources” are generally never “sufficient”, so it makes
sense to try to make it as easy as possible to build correct tools.</p>
<p>For this specific point,
I believe the Go ecosystem is a good example,<span><label for="sn-37"></label><span>Perhaps the point about “necessity is the mother of invention” applies here? From what I’ve heard, Java has excellent tools for heap profiling, whereas tooling for languages like Rust and C++ is much more lacking in comparison.</span></span>
where even though several bits of functionality considered
table-stakes in other ecosystems – such as exhaustiveness checking
– are not natively supported by the Go compiler,
it is easy to <a href="https://github.com/nishanths/exhaustive">create new linters</a>,
and then <a href="https://github.com/golangci/golangci-lint">integrate them with other linters</a>
and <a href="https://github.com/bazel-contrib/rules_go/blob/master/go/nogo.rst">build systems like Bazel</a>.</p>
<p>Standardizing on error propagation mechanisms in particular
across an ecosystem can also help motivate investment into
deterministic refactorings for simplifying repetitive tasks.
For example, in Everr, the language server could offer a refactoring
to attach metadata to an error by handling the boilerplate
of defining new error types etc.</p>
<hr>
<p>That’s the end of the comparison between the error models of
Everr and that of other languages.</p>
<p>While many languages offer different mechanisms for defining, propagating
and handling errors, there is not a language which is “strictly superior”
than the other ones along all of these axes.</p>
<p>I believe a design similar to that of Everr can potentially help
programmers express the different possibilities of error cases,
and how to handle them,
in a way that matches or improves upon most languages along most axes,
while preserving the ability to maintain code over long periods of time.</p>
<p>The next section is more philosophical than all the ones so far,
so if that’s not your cup of tea, you can stop reading here, no judgement. 😆</p>
<h2 id="section-7-closing-thoughts">Section 7: Closing thoughts</h2>
<p>In this section, I want to do something a bit different.
Before sharing my own thoughts, let me ask you some questions.</p>
<h3 id="questions-for-you">Questions for you</h3>
<p>Programmers accustomed to statically typed programming languages
are likely to raise an eyebrow if they encounter a codebase in the
same language where all functions return <code>Any</code> (or equivalent) upon success.</p>
<p>And yet, the use of untyped errors along with need for down-casting is widespread across languages.
For example, in Rust, a common recommendation is to use the <code>anyhow</code> crate in applications,
and in Go, functions which may fail return an <code>error</code> interface in the vast majority of cases.</p>
<p>Q: Why do you think this discrepancy exists?</p>
<hr>
<p>Much of the discourse around what consists of “good code” often avoids any detailed discussion of errors altogether. For example, in <em>A Philosophy of Software Design</em>,<span><label for="sn-38"></label><span>I’m discussing an example from <em>A Philosophy of Software Design</em> here because I’ve seen it widely recommended on forums such as Hacker News and Lobsters.</span></span> John Ousterhout writes:</p>
<blockquote>
<p>A module’s interface represents the complexity that the module imposes on the rest of the system: the smaller and simpler the interface, the less complexity that it introduces. [..]</p>
<p>The mechanism for file I/O provided by the Unix operating system and its descendants, such as Linux, is a beautiful example of a deep interface. There are only five basic system calls for I/O, with simple signatures:</p>
<pre><code>int open(const char *path, int flags, mode_t permissions);
ssize_t read(int fd, const void* buffer, size_t count);
ssize_t write(int fd, const void* buffer, size_t count);
off_t lseek(int fd, off_t offset, int referencePosition);
int close(int fd);</code></pre>
<p>[..] A modern implementation of the Unix I/O interface requires hundreds of thousands
of lines of code, which address complex issues [..] Deep modules such as Unix I/O
and garbage collectors provide powerful abstractions because they are easy to use,
yet they hide significant implementation complexity.</p>
<p>[..] If an interface has many features, but most developers only need to be
aware of a few of them, the effective complexity of that interface is just
the complexity of the commonly used features.</p>
</blockquote>
<p>One of the elephants in the room<span><label for="sn-39"></label><span>I have a deeper critique of the Unix file I/O API, but there is not enough space in this margin to write it. I may write a more detailed review of Ousterhout’s book some time later this year.</span></span> that Ousterhout ignores here is errors.
Let’s just consider <code>open</code>. If you look at man7.org, <code>open</code> can have the following different
error cases:</p>
<pre><code>EACCES, EBADF, EBUSY, EDQUOT,
EEXIST, EFAULT, EFBUBG, EINTR,
EINVAL, EISDIR, ELOOP, EMFILE,
ENAMETOOLONG, ENFILE, ENODEV, ENOENT,
ENOMEM, ENOSPC, ENOTDIR, ENXIO,
EOPNOTSUPP, EOVERFLOW, EPERM, EROFS,
ETXTBUSY, EWOULDBLOCK</code></pre>
<p>That’s 26 different error cases. Out of these, let’s look at when <code>EACCES</code> can be hit:</p>
<blockquote>
<p>The requested access to the file is not allowed, or search
permission is denied for one of the directories in the path
prefix of pathname, or the file did not exist yet and write
access to the parent directory is not allowed. (See also path_resolution(7).)</p>
<p>Where O_CREAT is specified, the <code>protected_fifos</code> or
<code>protected_regular sysctl</code> is enabled, the file already
exists and is a FIFO or regular file, the owner of the file
is neither the current user nor the owner of the containing
directory, and the containing directory is both world- or
group-writable and sticky. For details, see the
descriptions of <code>/proc/sys/fs/protected_fifos</code> and
<code>/proc/sys/fs/protected_regular</code> in <code>proc_sys_fs(5)</code>.</p>
</blockquote>
<p>If a kernel needs to return an <code>EACCES</code> error for any of these problems, it must detect them. Which means, at the time of detecting the error, it must have some contextual information about what failed. However, because of the API signature, the kernel cannot return this information to the caller. This means that either the kernel and caller need to separately cooperate on having a “side channel” for passing extra metadata, or the kernel can just drop the information.</p>
<p>Q: Have you ever hit an <code>EACCES</code> error when opening a file? What did you do to debug it the first time you hit it? What if you could go back to your past self, in the middle of debugging this for the first time, and tell them that a well-regarded book called <em>A Philosophy of Software Design</em> considers that as a “beautiful example of a deep API”, what do you think your past self’s reaction would be? How much does that matter?</p>
<h3 id="the-aesthetics-and-pragmatics-of-pl-design">The aesthetics and pragmatics of PL design</h3>
<blockquote>
<p>There are five essential components to learning a language:</p>
<ul>
<li>Syntax: [..]</li>
<li>Semantics: By semantics, we mean the rules that define the behavior of programs. [..] The dynamic semantics define the run-time behavior of a program as it is executed or evaluated. The static semantics define the compile-time checking that is done to ensure that a program is legal, beyond any syntactic requirements. The most important kind of static semantics is probably type checking: the rules that define whether a program is well typed or not.</li>
<li>Idioms: [..]</li>
<li>Libraries: [..]</li>
<li>Tools: [..]</li>
</ul>
<p>– Cornell CS 3110 <a href="https://www.cs.cornell.edu/courses/cs3110/2018sp/l/02-fun/notes.html">program course notes</a></p>
</blockquote>
<p>In some sense, program semantics has a sense of timelessness – they talk about <em>a program</em> and <em>a semantics</em>. But our programs (and their semantics) do change over time!</p>
<p>This leads to two different notions, which I’m going to call <em>evolution semantics</em> and <em>migration semantics</em> respectively.<span><label for="sn-40"></label><span>I believe there are no standard terms for these in the literature but happy to be corrected!</span></span> Here are some loose definitions:</p>
<ul>
<li><p>Evolution semantics: This covers the <em>interoperability</em> (or lack thereof) between program fragments and their static semantics as they evolve over time (e.g.&nbsp;as different versions). Some examples of work which would fall in this bucket:</p>
<ul>
<li><a href="https://github.com/obi1kenobi/cargo-semver-checks">cargo-semver-checks</a> which programmatically analyzes Rust crates for SemVer violations.</li>
<li><a href="https://github.com/swiftlang/swift/blob/main/docs/LibraryEvolution.rst">Swift’s Library Evolution feature</a>.</li>
<li><a href="https://research.swtch.com/vgo">Russ Cox’s writing on Go &amp; versioning</a>.</li>
</ul></li>
<li><p>Migration semantics: This covers the <em>interoperation</em> (or lack thereof) of running program fragments and their dynamic semantics as they evolve over time (e.g.&nbsp;as different versions). Some examples of work which would fall in this bucket:</p>
<ul>
<li>Various SQL constructs such as <a href="https://www.postgresql.org/docs/current/sql-altertable.html">ALTER TABLE</a>, and more generally, database migrations.</li>
<li>Debuggers which allow modification of control flow and/or data.</li>
<li>Hot reloading functionality found in many game and UI frameworks, and natively supported in Erlang.</li>
</ul></li>
</ul>
<p>I believe both of these areas are worth studying in their own right,
because reasoning about time is hard,
but reasoning about programs and their data over time
is increasingly important as our codebases and databases
grow older and larger.</p>
<p>“That’s all well and good,” you say, “but what does time have to do with error models?”
Please hold that thought for a moment.</p>
<hr>
<p>Perhaps while you’ve been reading this post, you might’ve had
the reaction that there is something unaesthetic, perhaps deeply so, about
Everr’s choice to make product types first-class and sum types second-class.</p>
<p>On the other hand, you might think of ML family languages as being more aesthetic,
putting sum types and product types on equal footing, mostly.<span><label for="sn-41"></label><span>I have to say “mostly” because a purist version of this would prevent inline record syntax for the cases of a sum type, such as in <a href="https://ocaml.org/manual/4.11/inlinerecords.html">pre-4.03 OCaml</a>.</span></span></p>
<p>I get that. To be honest, I had a similar reaction
when I first read about Cap’n Proto’s decision
to make records first-class and (tagged) union types second-class
(🧠: “Surely, there has to be a better way!”).
I also had a similar reaction when I first learnt
about the support for <code>IF EXISTS</code> in various SQL DDL
commands (🧠: “You can’t just extend syntax in ad-hoc ways like that!
That doesn’t seem orthogonal to other features!”).</p>
<p>There’s also something unaesthetic about having
implicit projection for a special field name <code>case</code>
(🧠: “Why should one field name be privileged over others!”).</p>
<p>The bounded union type syntax also has an unaesthetic quality
(🧠: “The presence of the type name ruins the symmetry present in typical union type syntax!”).
If we accept the frame of “programmers should be able to
read/write Everr code in their favourite editing environments,
which have text editing at the heart” as a premise,
then there needs to be some way of representing type syntax using ASCII characters,
and I do not have the audacity to suggest
that programmers write something like:</p>
<pre><code>       Dessert
 /----- union -----\
  .Cake | .IceCream</code></pre>
<p>Each of these decisions fulfills specific needs,
but many of them <em>still feel weird</em>,
perhaps with the exception of the Ultimate Conditional Syntax
(which I take zero credit for, because I literally just copied it from a paper).</p>
<p>Perhaps moreso than these individual decisions, you might’ve felt
an overall unaesthetic quality about the <em>kind of reasoning</em> used
throughout this post. Much of the reasoning is by case analysis,
instead of using induction or by providing a handful of core primitives
and combining them in elegant ways to address every challenge posed.</p>
<p>Everr’s language design itself reflects a pattern of accreting up and sanding down,
more like seeing an igloo or a sand castle being built over time,
and less like walking into a museum and having a Michelangelo sculpture come into view.</p>
<p>Can an igloo built by a novice be as beautiful as a Michelangelo sculpture?
Does the answer to that depend on whether you’re looking for shelter from an on-going blizzard?</p>
<hr>
<p>I believe the “lumpiness” in the landscape of computing –
be it heterogeneity in hardware,
the variations in the lifecycles of packages and the
interpersonal dynamics of package maintainers,
or all the “weird error cases” which defy easy classification
– is a omnipresent backdrop for the design for general-purpose PLs.</p>
<p>Which parts of this lumpy backdrop should be treated as a canvas to paint on
and which parts should be treated as something to be smoothened over
– that is a question of both one’s emotions and one’s values.</p>
<p>If we would like to paint certain parts of this canvas that are high up in the clouds,
and time is of the essence, perhaps, we need to be willing to stand on the shoulders
of Giants rather than insisting on climbing our way up all by ourselves.
Perhaps, it makes sense to befriend as many Giants as possible and try to cajole them into forming a Giant pyramid<span><label for="sn-42"></label><span>Grammar note: A Giant pyramid is necessarily a giant pyramid, because Giants are giant by definition, but a giant pyramid may not be a Giant pyramid, because it may be made of many individually small objects.</span></span> we can climb on.</p>
<p>Two such Giants which I believe are under-utilized in PL design today are:</p>
<ul>
<li>Special-purpose languages such as Cap’n Proto, where the design involves a fair number of considerations around time and evolution.</li>
<li>Tools which can help us formally reason about complex systems, such as:
<ul>
<li>Model checkers such as Alloy and TLA+. In particular, my initial experiments with Alloy makes me believe that Alloy can help with <a href="https://x.com/typesanitizer/status/1551575106194878464">modeling complex relationships across packages</a>, and potentially across time, without writing code.</li>
<li>Proof assistants.</li>
<li>Special-purpose tools such as <a href="https://www.ccs.neu.edu/home/stchang/pubs/cbtb-popl2020.pdf">Turnstile(+)</a> for type-checking and <a href="https://github.com/herd/herdtools7/">herdtools</a> for memory models.</li>
</ul></li>
</ul>
<p>While many of these tools are academic in origin, and thus have a steep usability curve, I think there is value in exploring them, as well as coming up with more user-friendly versions of them.</p>
<p>If you want to start somewhere and have a design problem, I think Alloy is likely a good place to start. Its syntax is easy to understand, and it comes with a visualizer out-of-the-box. You can also save the raw XML for counter-examples somewhere and visualize it using your own code.</p>
<p>Zooming back in to errors specifically, we now arrive at the final question.</p>
<h3 id="what-are-we-to-do">What are we to do?</h3>
<blockquote>
<p>All happy families are alike; each unhappy family is unhappy in its own way.</p>
<p>– Leo Tolstoy, Anna Karenina</p>
</blockquote>
<p>Pithy statements such as “only use exceptions for exceptional cases”
or <a href="https://wiki.c2.com/?LetItCrash">Let it crash</a>,
while catchy, do not do justice to the complexities
that programmers need to deal with when deciding how
to define, propagate, handle and reason about errors.</p>
<p>The fundamental nature of errors is that they are often multi-faceted,
and complex to reason about by virtue of being multi-faceted.
The wide variety of socio-technical contexts that software is created,
delivered and used in add further complexity.</p>
<p>It is important that we are able to reason about how software works,
but also about how it doesn’t quite work.
Reasoning enables better decision-making when we’re making a choice
on whether we should tweak, fix, disable or delete the software,
or maybe even just keep it as-is.</p>
<p>If we are to reason about and debug software
when it doesn’t work as expected,
our languages must empower us to do so.
While a programming language cannot magically help
fix all software issues at any scale,
I believe they can help move the needle,
by changing the often-implicit frame of reference
about how we think about errors.</p>
<p>I believe that it behooves us as an industry
to try to move the needle,
as increasingly more parts of the world
rely on software working correctly.</p>
<h2 id="appendix">Appendix</h2>
<h3 id="appendix-a1-everr-type-system-discussion">Appendix A1: Everr type system discussion</h3>
<p>Everr’s enums are closer to Scala’s case classes
rather than enums/sum types in languages like Rust, Swift,
Haskell and OCaml.</p>
<p>Similar to union types in other languages like Scala, Pony and TypeScript,
Everr’s union types (both the exhaustive and non-exhaustive variants)
satisfy commutativity, associativity and idempotence.
Additionally, an exhaustive union type is a subtype of the corresponding
non-exhaustive union type.</p>
<p>However, unlike Scala, Pony and TypeScript, Everr’s union types are more limited.
The elements of the union with a certain top type must either be:</p>
<ul>
<li>Base case: A type representing a case of the top type.</li>
<li>Recursive case: Another union type with the same top type
(interpreted via coalescing cases).</li>
</ul>
<p>Since Everr has no universal top type, arbitrary types cannot be unioned
together. This allows for an efficient run-time representation
(the same as enums) without needing whole-program analysis or a JIT,
while still providing the benefits of being able to deal with arbitrary subsets.</p>
<hr>
<p>Everr’s choice of making enum cases first-class and enums themselves second-class
is distinct from Rust’s proposed <a href="https://github.com/rust-lang/lang-team/issues/122">enum variant types</a>,
where enums continue to stay first-class but enum cases have second-class status.</p>
<p>Here are the major differences:</p>
<ul>
<li>In Everr, enum cases can separately carry type parameters, but Rust’s
enum variant types cannot.</li>
<li>In Everr, enum cases can separately implement different traits,
but Rust’s enum variant types cannot.</li>
<li>Going from an individual case type to the enum type requires attaching
a tag in Everr (but the <code>T:union[]</code> form shares the same layout as the enum).
In Rust, the enum variant type shares the same layout as the enum.</li>
<li>Everr supports arbitrary subsets of cases;
the initial Rust proposal does not support this. However, adding this would
be compatible with the Rust proposal.</li>
<li>Everr’s design allows composition of cases across enums, but Rust does not.</li>
</ul>
<hr>
<p>Everr’s delegation mechanism is similar to inheritance,
but without any association with subtyping,
and correspondingly there is no notion of up-casting or down-casting.</p>
<p>Imperative languages such as Go and Rust provide similar
functionality using different techniques: Go has <a href="https://gobyexample.com/struct-embedding">struct embedding</a>, and Rust has <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html#deref-coercion">Deref coercions</a>.</p>
<h3 id="appendix-a2-niche-optimizations-with-second-class-enums">Appendix A2: Niche optimizations with second-class enums</h3>
<p>Rust can do type layout optimization (also called “niche optimization”) by
considering excluded states. For example, the type: <code>Option&lt;NonZeroU8&gt;</code>
will take 8 bits, because the 0 state is reused by <code>None</code>.</p>
<p>In Everr, going from a type <code>MyEnum.MyCase</code> to <code>MyEnum:union[.MyCase]</code>
with zero or more other cases requires the compiler to generate
a function which attaches the corresponding enum tag.
For the <code>Optional</code> type discussed, one needs two such functions
for the two different cases, which will have the following signatures:</p>
<pre><code>fn _none_to_union[A](v: Optional.None) -&gt; Optional[A]:union[.None] {
    // implementation elided
}

fn _some_to_union[A](v: Optional.Some[A]) -&gt; Optional[A]:union[.Some[A]] {
    // implementation elided
}</code></pre>
<p>Since the generation of these functions is entirely under the compiler’s
control, it is possible for the compiler to directly generate specialized
versions of these functions for different types with different niches
during monomorphization, instead of attempting to generate one version.</p>
<p>This means that when a compiler sees an implicit conversion<span><label for="sn-43"></label><span>This is syntax-directed implicit conversion rather than being a subtyping rule, because it requires a change to the run-time representation. If it were a subtyping rule, and Everr were to support covariant and contravariant type parameters, that would require potentially-arbitrarily-expensive bridging conversions, <a href="https://forums.swift.org/t/generalization-of-implicit-conversions/51344">like Swift</a>.</span></span> from
<code>None</code> to <code>Optional[A]:union[.None]</code>, it can specialize the conversion
based on what <code>A</code> is instantiated to.</p>
<h3 id="appendix-a3-hare-type-system-discussion">Appendix A3: Hare type system discussion</h3>
<p>The Hare docs state that tagged union types are “commutative, associative, and reductive”
and that “the order of types, inclusion of the same type more than once,
or use of nested tagged unions has no effect on the final type.”</p>
<p>So Hare’s tagged unions implement <em>union types</em> in the type-theoretic sense,
not sum types, unlike most other languages with tagged unions.
<a href="https://harelang.org/documentation/faq.html#why-doesn-t-hare-have-generics">Hare does not support parametric polymorphism</a>,
so the choice to implement union type semantics via tagged unions:</p>
<ul>
<li>Offers a high degree of flexibility, like Scala, Pony and TypeScript,
by not requiring upper bounds (unlike Everr)
and allowing the union of arbitrary types (unlike Everr).</li>
<li>Does not require a uniform representation,
like Everr but unlike Scala, Pony and TypeScript.</li>
<li>Does not increase type system complexity significantly, because
there is no need for subtyping rules involving type inference
and polymorphism.</li>
</ul>
<h3 id="appendix-a4-safe-and-modular-memory-management">Appendix A4: Safe and modular memory management</h3>
<p>The research work on Verona has surfaced one potential direction
<a href="https://dl.acm.org/doi/pdf/10.1145/3622846">Reference Capabilities for Flexible Memory Management</a>:</p>
<blockquote>
<p>Verona is a concurrent object-oriented programming language
that organises all the objects in a program
into a forest of isolated regions.
Memory is managed locally for each region,
so programmers can control a program’s memory use by
adjusting objects’ partition into regions,
and by setting each region’s memory management strategy.</p>
</blockquote>
<p>The overall type system is more flexible than Rust’s in some ways,
but if you look closely, the paper points out that
field accesses may throw an exception if the region
corresponding to the field is already open. If I understand
correctly, this is similar to Rust’s <code>Cell</code> type which
does dynamic borrow-checking.</p>
<p>However, the paper also mentions that field a</p>
<blockquote>
<p>Entering a region borrows and/or buries the variable
or field referencing the bridge object.
In the case of a stack variable,
the variable is buried to prevent the region from being multiply opened</p>
<p>the case of a field, we instead resort to a dynamic check of the region’s state. If the region is closed,
it may be opened. If the region is already open, an exception is thrown</p>
</blockquote>
<p>I have not been able to absorb the paper deeply,</p>
<h3 id="appendix-a5-modular-static-analysis-for-stack-usage">Appendix A5: Modular static analysis for stack usage</h3>
<p>I believe it should be possible to support modular static analysis
for controlling stack usage without requiring eliminating indirect calls,
which can be useful with basic operations like <code>map</code>, <code>filter</code> etc.</p>
<p>The problem with an indirect call is that the stack usage for it will
be unknown. So the most direct “fix” is to equip calls with stack usage information.</p>
<p>Specifically, function types could be equipped with two kinds of stack usage budgets:</p>
<ul>
<li>Self budget: The maximum memory the function is allowed to use for temporaries.</li>
<li>Calls budget: The maximum stack usage for calls inside the function.</li>
</ul>
<p>When a function body is lowered to an IR
which makes temporaries explicit,
after some set of relatively stable baseline optimizations
(e.g.&nbsp;sparse conditional constant propagation and copy propagation, but no inlining),
a compiler can check the following:</p>
<ul>
<li>Does the self budget exceed the sum of stack usage for all temporaries assuming
no lifetime contraction/further optimization.</li>
<li>Does the calls budget exceed the total stack usage budget for each called function
(these calls may be indirect)</li>
</ul>
<p>Finally, after inlining and other optimizations but before generating assembly,
one could perform a validation check only for the total budget
(but not for the self and calls budgets, because of inlining).</p>
<p>In such a system, if you annotate <code>main</code> with a stack budget,
then you’d essentially trigger errors for each function call inside <code>main</code>
and so on until you’ve added stack budgets
for every function in the call graph.
Yes, this would necessitate writing your own
stack usage aware minimal standard library.</p>
<p>I believe such a system should be “workable” in practice in the limited
sense that compiler optimizations typically do not increase stack usage
of call trees, and the number of temporaries generally goes down
as the optimization crank is turned more. So I suspect that the final
validation check should fail not too often.</p>
<hr>
<p>Depending on the desired properties about where errors should be handled
(e.g.&nbsp;is it OK to emit errors after monomorphization?),
and which language features need to be supported in concert with stack budgets
(e.g.&nbsp;is it OK to only allow setting budgets on monomorphic functions?), one could:</p>
<ul>
<li>Potentially have the budget checks run on a polymorphic IR instead of
the post-monomorphization IR</li>
<li>Allow the budget to not just be an integer, but a more general expression,
allowing references to stack budgets of parameters, some basic numeric operations
like <code>+</code> etc.</li>
</ul>
<hr>
<p>I suspect that it’s not really possible to have a much simpler solution than
what I’ve described above <em>unless</em> one is willing to give up on (1) modularity
or (2) move the check to be dynamic.</p>
<p>Of course, one might ask: is this much complexity worth it “just” for statically
preventing stack overflows in a modular fashion?</p>
<p>For that, the answer is I don’t know.
If we believe existing languages,
the answer seems to largely be No.</p>
<h3 id="appendix-a6-defining-new-types-using-diffs">Appendix A6: Defining new types using diffs</h3>
<p>Say Everr supported type diffs. This could help reduce the boilerplate
involved in extending a type defined upstream from:</p>
<pre><code>@exhaustive
struct DetailedStoringError {
    @delegate
    base: ImageProcessingError.StoringError,
    dbName: Str,
    dbURL: URL,
}

@exhaustive
enum DetailedImageProcessingError {
    | type ImageProcessingError.DownloadingError
    | type ImageProcessingError.ProcessingError
    | type DetailedStoringError
}</code></pre>
<p>to something like:</p>
<pre><code>@exhaustive
enum DetailedImageProcessingError diff ImageProcessingError {
      | ...
    * | base: StoringError -&gt; DetailedStoringError {
          ...,
          + dbName: Str,
          + dbURL: URL,
        }
}</code></pre>
<p>Specifics of concrete syntax aside, it would technically be possible
to parse the syntax below and desugar it to
the one above. This may be particularly useful if there are lots of cases
in the upstream type being extended.</p>
<p>The Everr language server could show the desugared version as a large multi-line
“inlay hint” inside the editor.<span><label for="sn-44"></label><span>However, this runs into the further issue of how to represent the upstream type if the package containing the definition of the upstream type is not pinned to a specific version.</span></span></p>
<p>However, because this implicitly adds a <code>@delegate</code> attribute to preserve
the ability to do field projections and method calls,
chaining such type definitions makes it easy
to have multiple levels of delegation,
which can be confusing to debug (similar to deep inheritance hierarchies).
The interaction with the implicit project for <code>.case</code> also needs
to be thought through, and may be confusing.</p>
<p>On the other hand, forbidding multiple levels of definitions of
type diffs may be too restrictive if the target use case also needs
to cover code which needs to support 3+ versions of a data type over time.</p>
<p>This is only considering additive diffs. Subtractive diffs are likely
simpler – because <code>@delegate</code> cannot be involved without breaking abstraction
– but also less useful, since it’s more common to want
to create extended versions of third-party types in practice.</p>
<h3 id="appendix-a7-optimism">Appendix A7: Optimism</h3>
<p>Recently at work, I discovered that my assumption
that our DBs was configured so that queries which
are running fast would continue running fast
was proven wrong as the DBs went through a Postgres major version upgrade,
and the loss of statistics
– despite having <a href="https://www.postgresql.org/docs/current/runtime-config-autovacuum.html#GUC-AUTOVACUUM">autovacuum</a> turned on
– contributed to an incident.</p>
<p>The incident was resolved late on a Thursday night;
I was due to go on vacation the subsequent week.
When on vacation, when I had some time to kill,
I spent digging around mailing list threads,
Postgres source code, blog posts and asking Claude,
attempting to answer the question
“What are all the different possible situations
under which Postgres can have statistics that are
woefully out-of-date despite autovacuum being turned on,
and how can those be detected?”</p>
<p>When I came back, I noticed that nobody had really asked the same question,
at least in public. At first, I was puzzled,
“Surely, people are not just hoping that
this doesn’t happen again, right?”
Then I realized I was operating with a different mental model
altogether. My trust in Postgres’s ability to maintain
statistics had gone from confident to low (and the scarce
documentation did nothing to allay that fear),
whereas my colleagues were believing that
this was likely a one-off issue specific to major version upgrades.</p>
<p>Both of these beliefs make some sense in different ways.</p>
<ul>
<li><p>The more optimistic point-of-view assumes
that given that we did not have any such statistics related
issues earlier when running Postgres 12,
and that Postgres upgrades generally bring improvements,
it was likely that autovacuum in Postgres 16 is
at least as good and less buggy than Postgres 12.</p></li>
<li><p>The more pessimistic point-of-view assumes given the presence
of one undesirable behavior in the autovacuum daemon that
hadn’t yet been fixed despite Postgres being one of the most
mature and widely used DB systems in existence,
it was possible that more undesirable
behaviors in the same area were still lurking,
just waiting to be hit.</p></li>
</ul>
<p>When I was thinking about this, I was reminded of
<em>The Mythical Man Month</em>, where in the titular chapter,
Brooks devotes the very first section to discussing
programmers’ optimism.</p>
<blockquote>
<p>All programmers are optimists. [..]</p>
<p>In a single task, the assumption all will go well has
a probabilistic efect on the schedule. It might indeed go
as planned, for there is a probability distribution for
the delay that will be encountered, and “no delay” has a
fine probability. A large programming effort, however,
consists of many tasks, some chained end-to-end.
The probability that each will go well becomes vanishingly small.</p>
</blockquote>
<p>Here, Brooks is discussing optimism it in the context of planning.
Overall, the section is largely anecdotal and speculative about causes.
This point about optimism in the context of planning has been
<a href="https://blog.codinghorror.com/defeating-optimism/">repeated by Kent Beck and Jeff Atwood</a>.</p>
<p>However, the <a href="https://web.mit.edu/curhan/www/docs/Articles/biases/67_J_Personality_and_Social_Psychology_366,_1994.pdf">planning fallacy is common across professions</a>.</p>
<p>I’m curious: is there research showing programmers tend to be more optimistic than other professions? (🧠: “Am I the weird one?”)
And does this optimism apply when reasoning about error cases, and how programmers adjust their trust levels in particular bits of code as they discover bugs? I searched for a bit but didn’t get much, but if you’re reading this and know some research in this area, please let me know. 😃</p>
          </section>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-Source DocumentAI with Ollama (262 pts)]]></title>
            <link>https://rlama.dev/</link>
            <guid>43296918</guid>
            <pubDate>Sat, 08 Mar 2025 02:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rlama.dev/">https://rlama.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=43296918">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="features"><div><h3>Document Indexing</h3><p>Index any document folder for intelligent retrieval and querying.</p></div><div><h3>Multi-Format Support</h3><p>Support for text, code, PDF, DOCX, and many other document formats.</p></div><div><h3>Local Processing</h3><p>Process everything locally with Ollama models. No data leaves your machine.</p></div><div><h3>Interactive Sessions</h3><p>Create interactive RAG sessions to query your document knowledge base.</p></div><div><h3>Easy Management</h3><p>Simple commands to create, list, and delete your RAG systems.</p></div><div><h3>Developer Friendly</h3><p>Built with Go and designed for developers and technical users.</p></div></div><div id="examples"><pre tabindex="0"><code><span><span># Create a new RAG system named "documentation" using the llama3 model</span></span>
<span><span># and indexing all documents in the ./docs folder</span></span>
<span><span>rlama</span><span> rag</span><span> llama3</span><span> documentation</span><span> ./docs</span></span>
<span></span>
<span><span># You'll see progress as documents are processed</span></span>
<span><span>Processing</span><span> file:</span><span> docs/installation.md</span></span>
<span><span>Processing</span><span> file:</span><span> docs/commands.md</span></span>
<span><span>Processing</span><span> file:</span><span> docs/troubleshooting.pdf</span></span>
<span><span>...</span></span>
<span><span>RAG</span><span> system</span><span> "documentation"</span><span> created</span><span> successfully!</span></span>
<span></span></code></pre></div><div id="commands"><h2>Command Reference</h2><div><div><p>Create a new RAG system from documents</p><div><p>rlama rag [model] [rag-name] [folder-path]</p><div><p><span>Example:</span></p><!-- --><p>rlama rag llama3 documentation ./docs</p></div></div></div><div><p>Start an interactive session with a RAG system</p><div><p>rlama run [rag-name]</p><div><p><span>Example:</span></p><!-- --><p>rlama run documentation</p></div></div></div><div><p>List all available RAG systems</p></div><div><p>Delete a RAG system</p><div><p>rlama delete [rag-name] [--force/-f]</p><div><p><span>Example:</span></p><!-- --><p>rlama delete old-project --force</p></div></div></div><div><p>Update RLAMA to the latest version</p><div><p>rlama update [--force/-f]</p></div></div></div></div><div id="troubleshooting"><h2>Troubleshooting</h2><p>Common issues and their solutions</p></div><div id="formats"><h2>Supported File Formats</h2><div><div><h3>Text</h3><div><p>.txt</p><p>.md</p><p>.html</p><p>.json</p><p>.csv</p><p>.yaml</p><p>.yml</p><p>.xml</p></div></div><div><h3>Code</h3><div><p>.go</p><p>.py</p><p>.js</p><p>.java</p><p>.c</p><p>.cpp</p><p>.h</p><p>.rb</p><p>.php</p><p>.rs</p><p>.swift</p><p>.kt</p></div></div><div><h3>Documents</h3><div><p>.pdf</p><p>.docx</p><p>.doc</p><p>.rtf</p><p>.odt</p><p>.pptx</p><p>.ppt</p><p>.xlsx</p><p>.xls</p><p>.epub</p></div></div></div></div><div id="cta"><p>Ready to streamline your document question-answering?</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Take It Down Act: A Flawed Attempt to Protect Victims That'll Lead to Censorship (115 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship</link>
            <guid>43296886</guid>
            <pubDate>Sat, 08 Mar 2025 02:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship">https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship</a>, See on <a href="https://news.ycombinator.com/item?id=43296886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>Congress has begun debating the TAKE IT DOWN Act (</span><a href="https://www.congress.gov/bill/119th-congress/senate-bill/146"><span>S. 146</span></a><span>), a bill that seeks to speed up the removal of a troubling type of online content: non-consensual intimate imagery, or NCII. In recent years, concerns have also grown about the use of digital tools to alter or create such images, </span><a href="https://www.eff.org/deeplinks/2019/06/congress-should-not-rush-regulate-deepfakes"><span>sometimes called deepfakes</span></a><span>. <br></span></p>
<p><span>While protecting victims of these heinous privacy invasions is a legitimate goal, good intentions alone are not enough to make good policy. As currently drafted, the Act mandates a notice-and-takedown system that threatens free expression, user privacy, and due process, without addressing the problem it claims to solve. <br></span></p>
<h3><b>The Bill Will Lead To Overreach and Censorship</b></h3>
<p><span>S.B. 146&nbsp;mandates that websites and other online services remove flagged content within 48 hours and requires “reasonable efforts” to identify and remove known copies. Although this provision is designed to allow NCII victims to remove this harmful content, its broad definitions and lack of safeguards will likely lead to people misusing the notice-and-takedown system to remove lawful speech.</span></p>
<p><a href="https://act.eff.org/action/the-take-it-down-act-will-censor-legal-speech-without-helping-victims/">take action</a></p>
<p>"Take It Down" Has No real Safeguards<span>&nbsp;</span><span>&nbsp;</span></p>
<p><span>The takedown provision applies to a much broader category of content—potentially any images involving intimate or sexual content—than the narrower NCII definitions found elsewhere in the bill. The takedown provision also lacks critical safeguards against frivolous or bad-faith takedown requests. Lawful content—including satire, journalism, and political speech—could be wrongly censored. The legislation’s tight time frame requires that apps and websites remove content within 48 hours, meaning that online service providers, particularly smaller ones, will have to comply so quickly to avoid legal risk that they won’t be able to verify claims. Instead, automated filters will be used to catch duplicates, but these systems are </span><a href="https://www.eff.org/takedowns/automated-copyright-filter-cant-detect-infringement-or-irony"><span>infamous for flagging legal content</span></a><span>, from fair-use commentary to news reporting.</span></p>
<p><span>TAKE IT DOWN creates a far broader internet censorship regime than the Digital Millennium Copyright Act (DMCA), which has been </span><a href="https://www.eff.org/files/2020/09/04/mcsherry_statement_re_copyright_9.7.2020-final.pdf"><span>widely abused</span></a><span> to </span><a href="https://www.eff.org/takedowns"><span>censor legitimate speech</span></a><span>. But at least the DMCA has an anti-abuse provision and protects services from copyright claims should they comply.&nbsp;This bill contains none of those minimal speech protections and essentially greenlights misuse of its takedown regime.</span></p>
<h3><b>Threats To Encrypted Services <br></b></h3>
<p><span>The online services that do the best job of protecting user privacy could also be under threat from Take It Down. While the bill exempts email services, it does not provide clear exemptions for private messaging apps, cloud storage, and other end-to-end encrypted (E2EE) services. Services that use end-to-end encryption, by design, are </span><i><span>not able to access or view</span></i><span> unencrypted user content. <br></span></p>
<p><span>How could such services comply with the takedown requests mandated in this bill? Platforms may respond by abandoning encryption entirely in order to be able to monitor content—turning private conversations into surveilled spaces. <br></span></p>
<p><span>In fact, victims of NCII often rely on encryption for safety—to communicate with advocates they trust, store evidence, or escape abusive situations. The bill’s failure to protect encrypted communications could harm the very people it claims to help.</span></p>
<h3><b>Victims Of NCII Have Legal Options Under Existing Law</b></h3>
<p><span>An array of criminal and civil laws already exist to address NCII. In addition to 48 states that have specific laws </span><a href="https://www.findlaw.com/criminal/criminal-charges/revenge-porn-laws-by-state.html"><span>criminalizing the distribution of non-consensual pornography</span></a><span>, there are defamation, harassment, and extortion statutes that can all be wielded against people abusing NCII. Since 2022, NCII victims have also been able to bring </span><a href="https://www.justice.gov/atj/sharing-intimate-images-without-consent-know-your-rights"><span>federal civil lawsuits</span></a><span> against those who spread this harmful content. <br></span></p>
<p><span>As </span><a href="https://www.eff.org/deeplinks/2018/02/we-dont-need-new-laws-faked-videos-we-already-have-them"><span>we explained in 2018</span></a><span>: <br></span></p>
<blockquote><p><span>If a deepfake is used for criminal purposes, then criminal laws will apply. If a deepfake is used to pressure someone to pay money to have it suppressed or destroyed, extortion laws would apply. For any situations in which deepfakes were used to harass, harassment laws apply. There is no need to make new, specific laws about deepfakes in either of these situations.</span></p>
</blockquote>
<p><span><br></span><span>In many cases, civil claims could also be brought against those distributing the images under causes of action like False Light invasion of privacy. False light claims commonly address photo manipulation, embellishment, and distortion, as well as deceptive uses of non-manipulated photos for illustrative purposes. <br></span></p>
<p><span>A false light plaintiff (such as a person harmed by NCII) must prove that a defendant (such as a person who uploaded NCII) published something that gives a false or misleading impression of the plaintiff in such a way to damage the plaintiff’s reputation or cause them great offense.&nbsp;</span></p>
<p><span>Congress should focus on enforcing and improving these existing protections, rather than opting for a broad takedown regime that is bound to be abused. Private platforms can play a part as well, improving reporting and evidence collection systems.&nbsp; <br></span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feds Link $150M Cyberheist to 2022 LastPass Hacks (372 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/03/feds-link-150m-cyberheist-to-2022-lastpass-hacks/</link>
            <guid>43296656</guid>
            <pubDate>Sat, 08 Mar 2025 01:26:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/03/feds-link-150m-cyberheist-to-2022-lastpass-hacks/">https://krebsonsecurity.com/2025/03/feds-link-150m-cyberheist-to-2022-lastpass-hacks/</a>, See on <a href="https://news.ycombinator.com/item?id=43296656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>In September 2023, KrebsOnSecurity published findings from security researchers who concluded that a series of six-figure cyberheists across dozens of victims resulted from thieves cracking master passwords stolen from the password manager service <strong>LastPass</strong> in 2022. In a court filing this week, U.S. federal agents investigating a spectacular $150 million cryptocurrency heist said they had reached the same conclusion.</p>
<p><img decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2015/06/lastpass-580x132.png" alt="" width="580" height="132" srcset="https://krebsonsecurity.com/wp-content/uploads/2015/06/lastpass-580x132.png 580w, https://krebsonsecurity.com/wp-content/uploads/2015/06/lastpass.png 808w" sizes="(max-width: 580px) 100vw, 580px"></p>
<p>On March 6, federal prosecutors in northern California said they seized approximately $24 million worth of cryptocurrencies that were clawed back following a $150 million cyberheist on Jan. 30, 2024. The complaint refers to the person robbed only as “Victim-1,” but according to blockchain security research <strong>ZachXBT</strong> the theft was perpetrated against <strong>Chris Larsen</strong>, the co-founder of the cryptocurrency platform <strong>Ripple</strong>.</p>
<p>ZachXBT was the <a href="https://x.com/zachxbt/status/1752694489905528943" target="_blank" rel="noopener">first to report on the heist</a>, of which approximately $24 million was frozen by the feds before it could be withdrawn. This week’s action by the government merely allows investigators to officially seize the frozen funds.</p>
<p>But there is an important conclusion in this seizure document: It basically says the <strong>U.S. Secret Service</strong> and the <strong>FBI</strong> agree with the findings of <a href="https://krebsonsecurity.com/2023/09/experts-fear-crooks-are-cracking-keys-stolen-in-lastpass-breach/" target="_blank" rel="noopener">the LastPass breach story published here in September 2023</a>. That piece quoted security researchers who said they were witnessing six-figure crypto heists several times each month that they believed all appeared to be the result of crooks cracking master passwords for the password vaults stolen from LastPass in 2022.</p>
<p>“The Federal Bureau of Investigation has been investigating these data breaches, and law enforcement agents investigating the instant case have spoken with FBI agents about their investigation,” reads the seizure complaint, which was written by a U.S. Secret Service agent. “From those conversations, law enforcement agents in this case learned that the stolen data and passwords that were stored in several victims’ online password manager accounts were used to illegally, and without authorization, access the victims’ electronic accounts and steal information, cryptocurrency, and other data.”</p>
<p>The document continues:</p>
<p>“Based on this investigation, law enforcement had probable cause to believe the same attackers behind the above-described commercial online password manager attack used a stolen password held in Victim 1’s online password manager account and, without authorization, accessed his cryptocurrency wallet/account.”</p>
<p>Working with dozens of victims, security researchers <strong>Nick Bax</strong> and <strong>Taylor Monahan</strong> found that none of the six-figure cyberheist victims appeared to have suffered the sorts of attacks that typically preface a high-dollar crypto theft, such as the compromise of one’s email and/or mobile phone accounts, or SIM-swapping attacks.</p>
<p>They discovered the victims all had something else in common: Each had at one point stored their cryptocurrency seed phrase — the secret code that lets anyone gain access to your cryptocurrency holdings — in the “Secure Notes” area of their LastPass account prior to the 2022 breaches at the company.</p>
<p>Bax and Monahan found another common theme with these robberies: They all followed a similar pattern of cashing out, rapidly moving stolen funds to a dizzying number of drop accounts scattered across various cryptocurrency exchanges.</p>
<p>According to the government, a similar level of complexity was present in the $150 million heist against the Ripple co-founder last year.</p>
<p>“The scale of a theft and rapid dissipation of funds would have required the efforts of multiple malicious actors, and was consistent with the online password manager breaches and attack on other victims whose cryptocurrency was stolen,” the government wrote. “For these reasons, law enforcement agents believe the cryptocurrency stolen from Victim 1 was committed by the same attackers who conducted the attack on the online password manager, and cryptocurrency thefts from other similarly situated victims.”</p>
<p>Reached for comment, LastPass said it has seen no definitive proof — from federal investigators or others — that the cyberheists in question were linked to the LastPass breaches.</p>
<p>“Since we initially disclosed this incident back in 2022, LastPass has worked in close cooperation with multiple representatives from law enforcement,” LastPass said in a written statement. “To date, our law enforcement partners have not made us aware of any conclusive evidence that connects any crypto thefts to our incident. In the meantime, we have been investing heavily in enhancing our security measures and will continue to do so.”<span id="more-70634"></span></p>
<p>On August 25, 2022,&nbsp;<strong>LastPass CEO Karim Toubba</strong> told users the company had detected unusual activity in its software development environment, and that the intruders stole some source code and proprietary LastPass technical information. On Sept. 15, 2022, LastPass said an investigation into the August breach determined the attacker did not access any customer data or password vaults.</p>
<p>But on Nov. 30, 2022, LastPass notified customers about another, far more serious security incident that the company said leveraged data stolen in the August breach. LastPass disclosed that criminal hackers had compromised encrypted copies of some password vaults, as well as other personal information.</p>
<p>Experts say the breach would have given thieves “offline” access to encrypted password vaults, theoretically allowing them all the time in the world to try to crack some of the weaker master passwords using powerful systems that can attempt millions of password guesses per second.</p>
<p>Researchers found that many of the cyberheist victims had chosen master passwords with relatively low complexity, and were among LastPass’s oldest customers. That’s because legacy LastPass users were more likely to have master passwords that were protected with far fewer “iterations,” which refers to the number of times your password is run through the company’s encryption routines. In general, the more iterations, the longer it takes an offline attacker to crack your master password.</p>
<p>Over the years, LastPass forced new users to pick longer and more complex master passwords, and they increased the number of iterations on multiple occasions by several orders of magnitude. But researchers found strong indications that LastPass never succeeded in upgrading many of its older customers to the newer password requirements and protections.</p>
<p>Asked about LastPass’s continuing denials, Bax said that after the initial warning in our 2023 story, he naively hoped people would migrate their funds to new cryptocurrency wallets.</p>
<p>“While some did, the continued thefts underscore how much more needs to be done,” Bax told KrebsOnSecurity. “It’s validating to see the Secret Service and FBI corroborate our findings, but I’d much rather see fewer of these hacks in the first place. ZachXBT and <a href="https://x.com/_SEAL_Org/status/1868805837311074576" target="_blank" rel="noopener">SEAL 911&nbsp;reported yet another wave of thefts</a> as recently as December, showing the threat is still very real.”</p>
<p>Monahan said&nbsp;LastPass still hasn’t alerted their customers that their secrets—especially those stored in “Secure Notes”—may be at risk.</p>
<p>“Its been two and a half years since LastPass was first breached [and] hundreds of millions of dollars has been stolen from individuals and companies around the globe,” Monahan said. “They could have encouraged users to rotate their credentials. They could’ve prevented millions and millions of dollars from being stolen by these threat actors. But&nbsp; instead they chose to deny that their customers were are risk and blame the victims instead.”</p>
											</div></div>]]></description>
        </item>
    </channel>
</rss>