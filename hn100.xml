<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 31 Dec 2025 01:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[NYC Mayoral Inauguration bans Raspberry Pi and Flipper Zero alongside explosives (188 pts)]]></title>
            <link>https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/</link>
            <guid>46438828</guid>
            <pubDate>Tue, 30 Dec 2025 22:28:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/">https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/</a>, See on <a href="https://news.ycombinator.com/item?id=46438828">Hacker News</a></p>
Couldn't get https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's cash burn will be one of the big bubble questions of 2026 (145 pts)]]></title>
            <link>https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026</link>
            <guid>46438390</guid>
            <pubDate>Tue, 30 Dec 2025 21:44:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026">https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026</a>, See on <a href="https://news.ycombinator.com/item?id=46438390">Hacker News</a></p>
Couldn't get https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Professional software developers don't vibe, they control (105 pts)]]></title>
            <link>https://arxiv.org/abs/2512.14012</link>
            <guid>46437391</guid>
            <pubDate>Tue, 30 Dec 2025 20:06:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.14012">https://arxiv.org/abs/2512.14012</a>, See on <a href="https://news.ycombinator.com/item?id=46437391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.14012">View PDF</a>
    <a href="https://arxiv.org/html/2512.14012v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Brian Hempel [<a href="https://arxiv.org/show-email/67c67c82/2512.14012" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 16 Dec 2025 02:15:06 UTC (941 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything as Code: How We Manage Our Company in One Monorepo (169 pts)]]></title>
            <link>https://www.kasava.dev/blog/everything-as-code-monorepo</link>
            <guid>46437381</guid>
            <pubDate>Tue, 30 Dec 2025 20:05:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kasava.dev/blog/everything-as-code-monorepo">https://www.kasava.dev/blog/everything-as-code-monorepo</a>, See on <a href="https://news.ycombinator.com/item?id=46437381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>Last week, I updated our pricing limits. One JSON file. The backend started enforcing the new caps, the frontend displayed them correctly, the marketing site showed them on the pricing page, and our docs reflected the change—all from a single commit.</p>
<p>No sync issues. No "wait, which repo has the current pricing?" No deploy coordination across three teams. Just one change, everywhere, instantly.</p>
<p>At Kasava, our entire platform lives in a single repository. Not just the code—<em>everything</em>:</p>
<pre><code>kasava/                              # 5,470+ files TypeScript files
├── frontend/                       # Next.js 16 + React 19 application
│   └── src/
│       ├── app/                   # 25+ route directories
│       └── components/            # 45+ component directories
├── backend/                        # Cloudflare Workers API
│   └── src/
│       ├── services/              # 55+ business logic services
│       └── workflows/             # Mastra AI workflows
├── website/                        # Marketing site (kasava.ai)
├── docs/                           # Public documentation (Mintlify)
├── docs-internal/                  # 12+ architecture docs &amp; specs
├── marketing/
│   ├── blogs/                     # Blog pipeline (drafts → review → published)
│   ├── investor-deck/             # Next.js site showing investment proposal
│   └── email/                     # MJML templates for Loops.so campaigns
├── external/
│   ├── chrome-extension/          # WXT + React bug capture tool
│   ├── google-docs-addon/         # @helper AI assistant (Apps Script)
│   └── google-cloud-functions/
│       ├── tree-sitter-service/   # AST parsing for 10+ languages
│       └── mobbin-research-service/
├── scripts/                        # Deployment &amp; integration testing
├── infra-tester/                   # Integration test harness
└── github-simulator/               # Mock GitHub API for local dev

</code></pre>
<hr>
<h2>Why This Matters: AI-Native Development</h2>
<p>This isn't about abstract philosophies on design patterns for 'how we should work.' It's about velocity in an era where products change fast and context matters.</p>
<p>AI is all about context. And this monorepo <strong>is</strong> our company—not just the product.</p>
<p>When our AI tools help us write documentation, they have immediate access to the actual code being documented. When we update our marketing website, the AI can verify claims against the real implementation. When we write blog posts like this one, the AI can fact-check every code example, every number, every architectural claim against the source of truth.</p>
<p><strong>This means we move faster</strong>:</p>
<ul>
<li><strong>Documentation updates faster</strong> because the AI sees code changes and suggests doc updates in the same context</li>
<li><strong>Website updates faster</strong> because pricing, features, and capabilities are pulled from the same config files that power the app</li>
<li><strong>Blog posts ship faster</strong> because the AI can run self-referential checks—validating that our "5,470+ TypeScript files" claim is accurate by actually counting them</li>
<li><strong>Nothing goes out of sync</strong> because there's only one source of truth, and AI has access to all of it</li>
</ul>
<p>When you ask Claude to "update the pricing page to reflect the new limits," it can:</p>
<ol>
<li>Read the backend service that enforces limits</li>
<li>Check the frontend that displays them</li>
<li>Update the marketing site</li>
<li>Verify the docs are consistent</li>
<li>Flag any blog posts that might mention outdated numbers</li>
</ol>
<p>All in one conversation. All in one repository.</p>
<p>This is what "AI-native development" actually means: structuring your work so AI can be maximally helpful, not fighting against fragmentation.</p>
<p><strong>And it reinforces a shipping culture.</strong></p>
<p>Everything-as-code means everything ships the same way: <code>git push</code>. Want to update the website pricing page? <code>git push</code>. New blog post ready to go live? <code>git push</code>. Fix a typo in the docs? <code>git push</code>. Deploy a backend feature? <code>git push</code>.</p>
<p>No separate CMSs to log into. No WordPress admin panels. No waiting for marketing tools to sync. No "can someone with Contentful access update this?" The same Git workflow that ships code also ships content, documentation, and marketing. Everyone on the team can ship anything, and it all goes through the same review process, the same CI/CD, the same audit trail.</p>
<p>This uniformity removes friction and removes excuses. Shipping becomes muscle memory.</p>
<hr>
<h2>Why Everything in One Repo?</h2>
<h3>1. Atomic Changes Across Boundaries (That AI Can Understand)</h3>
<p>When a backend API changes, the frontend type definitions update in the same commit. When we add a new feature, the documentation can ship alongside it. No version mismatches. No "which version of the API does this frontend need?"</p>
<p><strong>AI can see and validate the entire change in context</strong>.</p>
<p>When we ask Claude to add a feature, it doesn't just write backend code. It sees the frontend that will consume it, the docs that need updating, and the marketing site that might reference it. All in one view. All in one conversation.</p>
<p><strong>Real example from our codebase—adding Asana integration:</strong></p>
<pre><code>commit: "feat: add Asana integration"
├── backend/src/services/AsanaService.ts
├── backend/src/routes/api/integrations/asana.ts
├── frontend/src/components/integrations/asana/
├── frontend/src/app/integrations/asana/
├── docs/integrations/asana.mdx
└── website/src/app/integrations/page.tsx
</code></pre>
<p>One PR. One review. One merge. Everything ships together.</p>
<p><strong>Another example—keeping pricing in sync:</strong></p>
<p>We have a single <code>billing-plans.json</code> that defines all plan limits and features:</p>
<pre><code><span>// frontend/src/config/billing-plans.json (also copied to website/src/config/)</span>
<span>{</span>
  <span>"plans"</span><span>:</span> <span>{</span>
    <span>"free"</span><span>:</span> <span>{</span> <span>"limits"</span><span>:</span> <span>{</span> <span>"repositories"</span><span>:</span> <span>1</span><span>,</span> <span>"aiChatMessagesPerDay"</span><span>:</span> <span>10</span> <span>}</span> <span>}</span><span>,</span>
    <span>"starter"</span><span>:</span> <span>{</span>
      <span>"limits"</span><span>:</span> <span>{</span> <span>"repositories"</span><span>:</span> <span>10</span><span>,</span> <span>"aiChatMessagesPerDay"</span><span>:</span> <span>100</span> <span>}</span>
    <span>}</span><span>,</span>
    <span>"professional"</span><span>:</span> <span>{</span>
      <span>"limits"</span><span>:</span> <span>{</span> <span>"repositories"</span><span>:</span> <span>50</span><span>,</span> <span>"aiChatMessagesPerDay"</span><span>:</span> <span>1000</span> <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre>
<p>The backend enforces these limits. The frontend displays them in settings. The marketing website shows them on the pricing page. When we change a limit, one JSON update propagates everywhere—no "the website says 50 repos but the app shows 25" bugs.</p>
<p><strong>And AI validates all of it.</strong> When we update <code>billing-plans.json</code>, we can ask Claude to verify that the backend, frontend, and website are all consistent. It reads all three implementations and confirms they match—or tells us what needs fixing.</p>
<h3>2. Cross-Project Refactoring</h3>
<p>Renaming a function? Your IDE finds all usages across frontend, backend, docs examples, and blog code snippets. One find-and-replace. One commit.</p>
<h3>3. Single Source of Truth</h3>
<ul>
<li><strong>Dependencies</strong>: Shared tooling configured once</li>
<li><strong>CI/CD</strong>: One pipeline to understand</li>
<li><strong>Search</strong>: Find anything with one <code>grep</code></li>
</ul>
<hr>
<h2>The Structure: What Lives Where</h2>
<h3>Core Application</h3>
<pre><code>frontend/                        # Customer-facing Next.js app
├── src/
│   ├── app/                    # Next.js 15 App Router
│   │   ├── analytics/         # Semantic commit analysis
│   │   ├── bug-reports/       # AI-powered bug tracking
│   │   ├── chat/              # AI assistant interface
│   │   ├── code-search/       # Semantic code search
│   │   ├── dashboard/         # Main dashboard
│   │   ├── google-docs-assistant/
│   │   ├── integrations/      # GitHub, Linear, Jira, Asana
│   │   ├── prd/               # PRD management
│   │   └── ...                # 25+ route directories total
│   ├── components/            # 45+ component directories
│   │   ├── ai-elements/      # AI-specific UI
│   │   ├── bug-reports/      # Bug tracking UI
│   │   ├── dashboard/        # Dashboard widgets
│   │   ├── google-docs/      # Google Docs integration
│   │   ├── onboarding/       # User onboarding flow
│   │   └── ui/               # shadcn/ui base components
│   ├── mastra/               # Frontend Mastra integration
│   └── lib/                  # SDK, utilities, hooks

backend/                        # Cloudflare Workers API
├── src/
│   ├── routes/               # Hono API endpoints
│   ├── services/             # 55+ business logic services
│   ├── workflows/            # Mastra AI workflows
│   │   ├── steps/           # Reusable workflow steps
│   │   └── RepositoryIndexingWorkflow.ts
│   ├── db/                   # Drizzle ORM schema
│   ├── durable-objects/      # Stateful edge computing
│   ├── workers/              # Queue consumers
│   └── mastra/               # AI agents and tools
</code></pre>
<p>These two talk to each other constantly. Having them in the same repo means:</p>
<ul>
<li>API changes include frontend updates</li>
<li>Type safety across the boundary</li>
<li>Shared testing utilities</li>
</ul>
<h3>Marketing Properties</h3>
<pre><code>website/                        # kasava.ai marketing site
├── src/
│   ├── app/                   # Landing pages, blog
│   ├── components/            # Shared marketing components
│   └── lib/                   # Utilities

marketing/
├── blogs/
│   ├── queue/
│   │   └── drafts/           # Ideas and drafts
│   ├── review/               # Ready for editing
│   └── published/            # Live on the site
├── investor-deck/            # Next.js presentation (not PowerPoint!)
└── email/
    ├── CLAUDE.md             # Email writing guidelines
    └── mjml/                 # 7+ email campaign loops
        ├── loop-1-welcome/
        ├── loop-2-github-connected/
        ├── loop-3-trial-conversion/
        └── ...
</code></pre>
<p>Yes, even blog posts are code. They're Markdown files with frontmatter, versioned in Git, reviewed in PRs. Email templates are MJML that version controls our entire customer communication system.</p>
<p>Even our investor deck is code — a Next.js 16 static site with 17 React slide components, keyboard navigation, and PDF export. No PowerPoint, no Google Slides. When we update metrics or messaging, it's a code change with full Git history, reviewed in a PR, and deployed with <code>git push</code>.</p>
<p><strong>Why this matters</strong>:</p>
<ul>
<li>Marketing can update copy without engineering</li>
<li>Changes are reviewed and tracked</li>
<li>Rollback is one <code>git revert</code> away</li>
<li>Email campaigns are testable and diffable</li>
</ul>
<h3>Documentation</h3>
<pre><code>docs/                           # Public docs (Mintlify)
├── index.mdx                  # Landing page
├── quickstart.mdx             # Getting started
├── demo-mode.mdx              # Demo mode guide
├── features/                  # Product features
│   ├── ai-chat.mdx
│   ├── code-intelligence.mdx
│   ├── code-search.mdx
│   └── prds.mdx
├── integrations/              # Integration guides
│   ├── github.mdx
│   ├── linear.mdx
│   ├── jira.mdx
│   └── asana.mdx
└── bug-tracking/              # Bug tracking docs

docs-internal/                  # Engineering knowledge base
├── GITHUB_CHAT_ARCHITECTURE.md
├── QUEUE_ARCHITECTURE_SUMMARY.md
├── UNIFIED_TASK_ANALYTICS_QUEUE.md
├── features/                  # Feature specs
├── migrations/                # Migration guides
├── plans/                     # Implementation plans
└── research/                  # Research notes
</code></pre>
<p>Public docs deploy automatically when we push. Internal docs are searchable alongside code—when someone asks "how does the queue work?", they find the actual architecture document, not a stale wiki page.</p>
<h3>External Services</h3>
<pre><code>external/
├── chrome-extension/          # WXT-based bug capture tool
│   ├── entrypoints/          # popup, content scripts, background
│   ├── lib/                  # Screen capture, console logging
│   ├── components/           # React UI components
│   └── wxt.config.ts         # WXT configuration
│
├── google-docs-addon/        # @helper mentions in Docs
│   ├── Code.gs              # Main Apps Script (18KB)
│   ├── Sidebar.html         # React-like UI (26KB)
│   ├── Settings.html        # Configuration UI
│   └── appsscript.json      # Manifest
│
└── google-cloud-functions/
    ├── tree-sitter-service/  # AST parsing
    │   └── Supports: JS, TS, Python, Go, Rust,
    │       Java, C, C++, Ruby, PHP, C#
    └── mobbin-research-service/  # UX research
</code></pre>
<p>These deploy to completely different platforms (Chrome Web Store, Google Apps Script, GCP) but live together because:</p>
<ul>
<li>They share API contracts with the main app</li>
<li>Changes often span boundaries</li>
<li>One team maintains everything</li>
</ul>
<h3>Development Infrastructure</h3>
<pre><code>github-simulator/              # Mock GitHub API for local dev
infra-tester/                  # Integration test harness
scripts/
├── google-cloud/             # GCP deployment scripts
├── test-credentials.ts       # Credential testing
└── test-webhook-integration.ts
</code></pre>
<p>Local development shouldn't require external services. Mock servers live with the code they simulate.</p>
<hr>
<h2>What Deploys Where</h2>
<table><thead><tr><th>Component</th><th>Tech Stack</th><th>Deploys To</th></tr></thead><tbody><tr><td>Frontend</td><td>Next.js 15, React 19, Tailwind v4</td><td>Vercel</td></tr><tr><td>Backend</td><td>Cloudflare Workers, Hono, Mastra</td><td>Cloudflare</td></tr><tr><td>Website</td><td>Next.js, custom components</td><td>Vercel</td></tr><tr><td>Investor Deck</td><td>Next.js, custom components</td><td>Vercel</td></tr><tr><td>Docs</td><td>Mintlify MDX</td><td>Mintlify</td></tr><tr><td>Chrome Extension</td><td>WXT, React, Tailwind</td><td>Chrome Web Store</td></tr><tr><td>Google Docs Add-on</td><td>Apps Script, HTML</td><td>Google Workspace Marketplace</td></tr><tr><td>Tree-sitter Service</td><td>Node.js, GCP Functions</td><td>Google Cloud</td></tr><tr><td>Email Templates</td><td>MJML</td><td>Loops.so</td></tr></tbody></table>
<hr>
<h2>How We Make It Work</h2>
<h3>No Workspaces (And That's Fine)</h3>
<p>We deliberately don't use npm/yarn workspaces. (Well, we do in <em>one</em> specific use case but that's for another post.) Each directory is its own independent npm project:</p>
<pre><code><span>cd</span> frontend &amp;&amp; npm install    <span># Frontend dependencies</span>
<span>cd</span> backend &amp;&amp; npm install     <span># Backend dependencies</span>
<span>cd</span> external/chrome-extension &amp;&amp; npm install  <span># Extension dependencies</span>
</code></pre>
<p>Why? Simplicity. No hoisting confusion. No "which version of React am I actually getting?" Each project is isolated and predictable.</p>
<h3>Selective CI/CD</h3>
<p>We run 5 GitHub Actions workflows, each triggered by specific paths:</p>
<pre><code><span># .github/workflows/frontend-tests.yml</span>
<span>name:</span> <span>Frontend</span> <span>Tests</span>
<span>on:</span>
  <span>push:</span>
    <span>paths:</span>
      <span>-</span> <span>"frontend/**"</span>
      <span>-</span> <span>".github/workflows/frontend-tests.yml"</span>
<span># Runs: type-check, lint, demo data validation, tests with coverage</span>
</code></pre>
<pre><code><span># .github/workflows/backend-tests.yml</span>
<span>name:</span> <span>Backend</span> <span>Tests</span>
<span>on:</span>
  <span>push:</span>
    <span>paths:</span>
      <span>-</span> <span>"backend/**"</span>
      <span>-</span> <span>".github/workflows/backend-tests.yml"</span>
<span># Runs: unit tests, integration tests, e2e tests</span>
</code></pre>
<pre><code><span># .github/workflows/tree-sitter-tests.yml</span>
<span>name:</span> <span>Tree-sitter</span> <span>Tests</span>
<span>on:</span>
  <span>push:</span>
    <span>paths:</span>
      <span>-</span> <span>"external/google-cloud-functions/tree-sitter-service/**"</span>
<span># Runs: parsing tests for all 10+ supported languages</span>
</code></pre>
<p>Change the Chrome extension? Only relevant tests run. Update the backend? Backend tests plus any integration tests that depend on it.</p>
<h3>The CLAUDE.md Convention</h3>
<p>Every major directory has a CLAUDE.md file that documents:</p>
<ul>
<li>What this code does</li>
<li>Tech stack and versions</li>
<li>Quick start commands</li>
<li>Architecture decisions</li>
<li>Common patterns</li>
</ul>
<pre><code>CLAUDE.md                          # Root-level overview
├── frontend/CLAUDE.md            # Next.js 15, React 19, Tailwind v4
├── backend/CLAUDE.md             # Cloudflare Workers, Hono, Mastra
├── external/chrome-extension/CLAUDE.md
├── external/google-cloud-functions/CLAUDE.md
└── marketing/email/CLAUDE.md     # MJML email guidelines
</code></pre>
<p>This isn't just for humans—AI coding assistants read these files. When Claude Code works on our frontend, it reads <code>frontend/CLAUDE.md</code> and knows we're using Next.js 15 with React 19, npm (not pnpm), and specific patterns.</p>
<h3>Consistent Tooling</h3>
<p>One configuration, everywhere:</p>
<pre><code>.prettierrc              # Formatting (all JS/TS)
.eslintrc               # Linting (shared rules)
tsconfig.json           # TypeScript base config
</code></pre>
<p>New developer? <code>npm install</code> in the directory you're working on. Everything works.</p>
<hr>
<h2>The Challenges (And How We Handle Them)</h2>
<h3>Challenge: Repository Size</h3>
<p><strong>Why it's not a problem (yet):</strong></p>
<ul>
<li>Clone time: ~20 seconds</li>
<li>Git operations: still snappy</li>
<li>We haven't needed sparse checkout, LFS, or shallow clones</li>
</ul>
<p><strong>When we might need to:</strong></p>
<ul>
<li>Large binary assets would go to R2/S3, not git</li>
<li>If we hit 1GB+, we'd look at shallow clones for CI</li>
<li>Truly independent services could be extracted</li>
</ul>
<h3>Challenge: Build Times</h3>
<p><strong>Problem</strong>: If everything is connected, does everything rebuild?</p>
<p><strong>Reality</strong>: No. Each project builds independently:</p>
<pre><code><span># Frontend build (only rebuilds frontend)</span>
<span>cd</span> frontend &amp;&amp; npm run build

<span># Backend build (only rebuilds backend)</span>
<span>cd</span> backend &amp;&amp; npm run build

<span># Extension build (only rebuilds extension)</span>
<span>cd</span> external/chrome-extension &amp;&amp; npm run build
</code></pre>
<p>We use Turbopack for frontend dev (fast HMR), Wrangler for backend dev (fast reload), and WXT for extension dev (fast rebuild).</p>
<h3>Challenge: Permission Boundaries</h3>
<p><strong>Problem</strong>: Not everyone should see everything.</p>
<p><strong>Our situation</strong>: We're a small team. Everyone can see everything. That's a feature, not a bug—it enables cross-pollination.</p>
<p><strong>If we grew and needed boundaries:</strong></p>
<ul>
<li>GitHub CODEOWNERS for review requirements</li>
<li>Branch protection rules</li>
<li>Potentially split truly sensitive codebases (but we'd resist this)</li>
</ul>
<h3>Challenge: Context Switching</h3>
<p><strong>Problem</strong>: Jumping between TypeScript (frontend), TypeScript (backend), Apps Script (Google add-on), and MJML (emails) feels disorienting.</p>
<p><strong>Solutions:</strong></p>
<ul>
<li>Consistent patterns across projects (same linting, same formatting)</li>
<li>CLAUDE.md files explain context immediately</li>
<li>IDE workspace configurations</li>
</ul>
<hr>
<h2>Conclusion</h2>
<p>Our monorepo isn't about following a trend. It's about removing friction between things that naturally belong together, something that is critical when related context is everything.</p>
<p>When a feature touches the backend API, the frontend component, the documentation, and the marketing site—why should that be four repositories, four PRs, four merge coordination meetings?</p>
<p>The monorepo isn't a constraint. It's a force multiplier.</p>
<hr>
<p><em>Kasava is built as a unified platform. <a href="https://kasava.dev/">See what we've built</a></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zpdf: PDF text extraction in Zig – 5x faster than MuPDF (105 pts)]]></title>
            <link>https://github.com/Lulzx/zpdf</link>
            <guid>46437288</guid>
            <pubDate>Tue, 30 Dec 2025 19:57:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Lulzx/zpdf">https://github.com/Lulzx/zpdf</a>, See on <a href="https://news.ycombinator.com/item?id=46437288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">zpdf (alpha stage - early version)</h2><a id="user-content-zpdf-alpha-stage---early-version" aria-label="Permalink: zpdf (alpha stage - early version)" href="#zpdf-alpha-stage---early-version"></a></p>
<p dir="auto">A PDF text extraction library written in Zig.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Memory-mapped file reading for efficient large file handling</li>
<li>Streaming text extraction with efficient arena allocation</li>
<li>Multiple decompression filters: FlateDecode, ASCII85, ASCIIHex, LZW, RunLength</li>
<li>Font encoding support: WinAnsi, MacRoman, ToUnicode CMap</li>
<li>XRef table and stream parsing (PDF 1.5+)</li>
<li>Configurable error handling (strict or permissive)</li>
<li>Multi-threaded parallel page extraction</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark</h2><a id="user-content-benchmark" aria-label="Permalink: Benchmark" href="#benchmark"></a></p>
<p dir="auto">Text extraction performance vs MuPDF 1.26 (<code>mutool convert -F text</code>) on Apple M4 Pro:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sequential</h3><a id="user-content-sequential" aria-label="Permalink: Sequential" href="#sequential"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Document</th>
<th>Pages</th>
<th>Size</th>
<th>zpdf</th>
<th>MuPDF</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf" rel="nofollow">C++ Standard Draft</a></td>
<td>2,134</td>
<td>8 MB</td>
<td>250 ms</td>
<td>968 ms</td>
<td><strong>3.9x</strong></td>
</tr>
<tr>
<td><a href="https://pandas.pydata.org/pandas-docs/version/1.4/pandas.pdf" rel="nofollow">Pandas Documentation</a></td>
<td>3,743</td>
<td>15 MB</td>
<td>395 ms</td>
<td>1,112 ms</td>
<td><strong>2.8x</strong></td>
</tr>
<tr>
<td><a href="https://cdrdv2.intel.com/v1/dl/getContent/671200" rel="nofollow">Intel SDM</a></td>
<td>5,252</td>
<td>25 MB</td>
<td>451 ms</td>
<td>2,099 ms</td>
<td><strong>4.7x</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parallel (default)</h3><a id="user-content-parallel-default" aria-label="Permalink: Parallel (default)" href="#parallel-default"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Document</th>
<th>Pages</th>
<th>Size</th>
<th>zpdf</th>
<th>MuPDF</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>C++ Standard Draft</td>
<td>2,134</td>
<td>8 MB</td>
<td>131 ms</td>
<td>966 ms</td>
<td><strong>7.4x</strong></td>
</tr>
<tr>
<td>Pandas Documentation</td>
<td>3,743</td>
<td>15 MB</td>
<td>218 ms</td>
<td>1,117 ms</td>
<td><strong>5.1x</strong></td>
</tr>
<tr>
<td>Intel SDM</td>
<td>5,252</td>
<td>25 MB</td>
<td>117 ms</td>
<td>2,098 ms</td>
<td><strong>17.9x</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Peak throughput: <strong>45,000 pages/sec</strong> (Intel SDM, parallel)</p>
<p dir="auto">Build with <code>zig build -Doptimize=ReleaseFast</code> for these results.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SIMD Acceleration</h3><a id="user-content-simd-acceleration" aria-label="Permalink: SIMD Acceleration" href="#simd-acceleration"></a></p>
<p dir="auto">zpdf uses SIMD-accelerated routines for hot paths:</p>
<ul dir="auto">
<li>Whitespace skipping (content streams are whitespace-heavy)</li>
<li>Delimiter detection (tokenization)</li>
<li>Keyword search (<code>stream</code>, <code>endstream</code>, <code>startxref</code>)</li>
<li>String boundary scanning</li>
</ul>
<p dir="auto">Auto-detects: NEON (ARM64), AVX2/SSE4.2 (x86_64), or scalar fallback.</p>
<p dir="auto"><em>Note: MuPDF's threading (<code>-T</code> flag) is for rendering/rasterization only. Text extraction via <code>mutool convert -F text</code> is single-threaded by design. zpdf parallelizes text extraction across pages.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Accuracy</h3><a id="user-content-accuracy" aria-label="Permalink: Accuracy" href="#accuracy"></a></p>
<p dir="auto">Text extraction accuracy vs MuPDF (reference) on US Constitution (85 pages):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Tool</th>
<th>Char Accuracy</th>
<th>WER</th>
<th>Time</th>
<th>vs MuPDF</th>
</tr>
</thead>
<tbody>
<tr>
<td>zpdf</td>
<td>99.6%</td>
<td>2.1%</td>
<td>2 ms</td>
<td><strong>24x faster</strong></td>
</tr>
<tr>
<td>MuPDF</td>
<td>100%</td>
<td>0%</td>
<td>54 ms</td>
<td>1x</td>
</tr>
<tr>
<td>Tika</td>
<td>97.4%</td>
<td>10.6%</td>
<td>1,307 ms</td>
<td>24x slower</td>
</tr>
<tr>
<td>pdftotext</td>
<td>57.0%</td>
<td>19.8%</td>
<td>90 ms</td>
<td>1.7x slower</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li><strong>Char Accuracy</strong>: Sequence similarity vs MuPDF baseline (higher = better)</li>
<li><strong>WER</strong>: Word Error Rate vs MuPDF baseline (lower = better)</li>
</ul>
<p dir="auto">MuPDF is the accuracy baseline (100%). zpdf is 650x faster than Tika with better accuracy.</p>
<p dir="auto">Run <code>PYTHONPATH=python python benchmark/accuracy.py</code> to reproduce.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>Zig 0.15.2 or later</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="zig build              # Build library and CLI
zig build test         # Run tests"><pre>zig build              <span><span>#</span> Build library and CLI</span>
zig build <span>test</span>         <span><span>#</span> Run tests</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Library</h3><a id="user-content-library" aria-label="Permalink: Library" href="#library"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const zpdf = @import(&quot;zpdf&quot;);

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    const doc = try zpdf.Document.open(allocator, &quot;file.pdf&quot;);
    defer doc.close();

    var buf: [4096]u8 = undefined;
    var writer = std.fs.File.stdout().writer(&amp;buf);
    defer writer.interface.flush() catch {};

    for (0..doc.pages.items.len) |page_num| {
        try doc.extractText(page_num, &amp;writer.interface);
    }
}"><pre><span>const</span> <span>zpdf</span> <span>=</span> <span>@import</span>(<span>"zpdf"</span>);

<span>pub</span> <span>fn</span> <span>main</span>() <span>!</span><span>void</span> {
    <span>var</span> <span>gpa</span> <span>=</span> <span>std</span>.<span>heap</span>.<span>GeneralPurposeAllocator</span>(.{}){};
    <span>defer</span> <span>_</span> <span>=</span> <span>gpa</span>.<span>deinit</span>();
    <span>const</span> <span>allocator</span> <span>=</span> <span>gpa</span>.<span>allocator</span>();

    <span>const</span> <span>doc</span> <span>=</span> <span>try</span> <span>zpdf</span>.<span>Document</span>.<span>open</span>(<span>allocator</span>, <span>"file.pdf"</span>);
    <span>defer</span> <span>doc</span>.<span>close</span>();

    <span>var</span> <span>buf</span>: [<span>4096</span>]<span>u8</span> <span>=</span> <span>undefined</span>;
    <span>var</span> <span>writer</span> <span>=</span> <span>std</span>.<span>fs</span>.<span>File</span>.<span>stdout</span>().<span>writer</span>(<span>&amp;</span><span>buf</span>);
    <span>defer</span> <span>writer</span>.<span>interface</span>.<span>flush</span>() <span>catch</span> {};

    <span>for</span> (0<span>..</span><span>doc</span>.<span>pages</span>.<span>items</span>.<span>len</span>) <span>|</span><span>page_num</span><span>|</span> {
        <span>try</span> <span>doc</span>.<span>extractText</span>(<span>page_num</span>, <span>&amp;</span><span>writer</span>.<span>interface</span>);
    }
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI</h3><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="zpdf extract document.pdf           # Extract all pages to stdout
zpdf extract -p 1-10 document.pdf   # Extract pages 1-10
zpdf extract -o out.txt document.pdf # Output to file
zpdf info document.pdf              # Show document info
zpdf bench document.pdf             # Run benchmark"><pre>zpdf extract document.pdf           <span><span>#</span> Extract all pages to stdout</span>
zpdf extract -p 1-10 document.pdf   <span><span>#</span> Extract pages 1-10</span>
zpdf extract -o out.txt document.pdf <span><span>#</span> Output to file</span>
zpdf info document.pdf              <span><span>#</span> Show document info</span>
zpdf bench document.pdf             <span><span>#</span> Run benchmark</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import zpdf

with zpdf.Document(&quot;file.pdf&quot;) as doc:
    print(doc.page_count)

    # Single page
    text = doc.extract_page(0)

    # All pages (parallel by default)
    all_text = doc.extract_all()

    # Page info
    info = doc.get_page_info(0)
    print(f&quot;{info.width}x{info.height}&quot;)"><pre><span>import</span> <span>zpdf</span>

<span>with</span> <span>zpdf</span>.<span>Document</span>(<span>"file.pdf"</span>) <span>as</span> <span>doc</span>:
    <span>print</span>(<span>doc</span>.<span>page_count</span>)

    <span># Single page</span>
    <span>text</span> <span>=</span> <span>doc</span>.<span>extract_page</span>(<span>0</span>)

    <span># All pages (parallel by default)</span>
    <span>all_text</span> <span>=</span> <span>doc</span>.<span>extract_all</span>()

    <span># Page info</span>
    <span>info</span> <span>=</span> <span>doc</span>.<span>get_page_info</span>(<span>0</span>)
    <span>print</span>(<span>f"<span><span>{</span><span>info</span>.<span>width</span><span>}</span></span>x<span><span>{</span><span>info</span>.<span>height</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto">Build the shared library first:</p>
<div dir="auto" data-snippet-clipboard-copy-content="zig build -Doptimize=ReleaseFast
PYTHONPATH=python python3 examples/basic.py"><pre>zig build -Doptimize=ReleaseFast
PYTHONPATH=python python3 examples/basic.py</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="src/
├── root.zig         # Document API and core types
├── capi.zig         # C ABI exports for FFI
├── parser.zig       # PDF object parser
├── xref.zig         # XRef table/stream parsing
├── pagetree.zig     # Page tree resolution
├── decompress.zig   # Stream decompression filters
├── encoding.zig     # Font encoding and CMap parsing
├── interpreter.zig  # Content stream interpreter
├── simd.zig         # SIMD string operations
└── main.zig         # CLI

python/zpdf/         # Python bindings (cffi)
examples/            # Usage examples"><pre><code>src/
├── root.zig         # Document API and core types
├── capi.zig         # C ABI exports for FFI
├── parser.zig       # PDF object parser
├── xref.zig         # XRef table/stream parsing
├── pagetree.zig     # Page tree resolution
├── decompress.zig   # Stream decompression filters
├── encoding.zig     # Font encoding and CMap parsing
├── interpreter.zig  # Content stream interpreter
├── simd.zig         # SIMD string operations
└── main.zig         # CLI

python/zpdf/         # Python bindings (cffi)
examples/            # Usage examples
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Comparison with MuPDF</h2><a id="user-content-comparison-with-mupdf" aria-label="Permalink: Comparison with MuPDF" href="#comparison-with-mupdf"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>zpdf</th>
<th>MuPDF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Text Extraction</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Reading order / layout analysis</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Two-column detection</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Paragraph grouping</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Word/line bounding boxes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Font Support</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>WinAnsi/MacRoman</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>ToUnicode CMap</td>
<td>Partial*</td>
<td>Yes</td>
</tr>
<tr>
<td>CID fonts (Type0)</td>
<td>Partial*</td>
<td>Yes</td>
</tr>
<tr>
<td>Embedded fonts</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Compression</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>FlateDecode, LZW, ASCII85/Hex</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>JBIG2, JPEG2000</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>PDF Features</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Incremental updates</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Encrypted PDFs</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Forms / Annotations</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Rendering</td>
<td>No</td>
<td>Yes</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><em>*ToUnicode/CID fonts: Works when CMap is embedded directly. References to compressed object streams not yet supported (affects some Greek, Chinese, Japanese, Korean PDFs).</em></p>
<p dir="auto"><strong>Use zpdf when:</strong> Speed matters, simple layouts, batch processing raw text.</p>
<p dir="auto"><strong>Use MuPDF when:</strong> Complex layouts, encrypted PDFs, non-Latin scripts.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">WTFPL</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FediMeteo: A €4 FreeBSD VPS Became a Global Weather Service (217 pts)]]></title>
            <link>https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/</link>
            <guid>46436889</guid>
            <pubDate>Tue, 30 Dec 2025 19:21:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/">https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/</a>, See on <a href="https://news.ycombinator.com/item?id=46436889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" itemprop="articleBody"><h2>Personal Introduction</h2><p>Weather has always significantly influenced my life. When I was a young athlete, knowing the forecast in advance would have allowed me to better plan my training sessions. As I grew older, I could choose whether to go to school on my motorcycle or, for safety reasons, have my grandfather drive me. And it was him, my grandfather, who was my go-to meteorologist. He followed all weather patterns and forecasts, a remnant of his childhood in the countryside and his life on the move. It's to him that I dedicate <a href="https://fedimeteo.com/">FediMeteo</a>.</p><p>The idea for <a href="https://fedimeteo.com/">FediMeteo</a> started almost by chance while I was checking the holiday weather forecast to plan an outing. Suddenly, I thought how nice it would be to receive regular weather updates for my city directly in my timeline. After reflecting for a few minutes, I registered a domain and started planning.</p><h2>Design Principles</h2><p>The choice of operating system was almost automatic. The idea was to separate instances by country, and FreeBSD jails are one of the most useful tools for this purpose.</p><p>I initially thought the project would generate little interest. I was wrong. After all, weather affects many of our lives, directly or indirectly. So I decided to structure everything in this way:</p><ul><li><p>I would use a test VPS to see how things would go. The VPS <em>was a small VM on a German provider with 4 shared cores, 4GB of RAM, 120GB of SSD disk space, and a 1Gbit/sec internet connection</em> and now is a 4 euro per month VPS in Milano, Italy - 4 shared cores, 8 GB RAM and 75GB disk space.</p></li><li><p>I would separate various countries into different instances, for both management and security reasons, as well as to have the possibility of relocating just some of them if needed.</p></li><li><p>Weather data would come from a reliable and open-source friendly source. I narrowed it down to two options: <a href="https://wttr.in/">wttr.in</a> and <a href="https://open-meteo.com/">Open-Meteo</a>, two solutions I know and that have always given me reliable results.</p></li><li><p>I would pay close attention to accessibility: forecasts would be in local languages, consultable via text browsers, with emojis to give an idea even to those who don't speak local languages, and everything would be accessible without JavaScript or other requirements. One's mother tongue is always more "familiar" than a second language, even if you're fluent.</p></li><li><p>I would manage everything according to Unix philosophy: small pieces working together. The more years pass, the more I understand how valuable this approach is.</p></li><li><p>The software chosen to manage the instances is <a href="https://codeberg.org/grunfink/snac2">snac</a>. Snac embodies my philosophy of minimal and effective software, perfect for this purpose. It provides clear web pages for those who want to consult via the web, "speaks" the ActivityPub protocol perfectly, produces RSS feeds for each user (i.e., city), has extremely low RAM and CPU consumption, compiles in seconds, and is stable. The developer is an extremely helpful and positive person, and in my opinion, this carries equal weight as everything else.</p></li><li><p>I would do it for myself. If there was no interest, I would have kept it running anyway, without expanding it. So no anxiety or fear of failure.</p></li></ul><h2>Technical Implementation</h2><p>I started setting up the first "pieces" during the days around Christmas 2024. The scheme was clear: each jail would handle everything internally. A Python script would download data, city by city, and produce markdown. The city coordinates would be calculated via the <a href="https://geopy.readthedocs.io/en/stable/">geopy</a> library and passed to <a href="https://wttr.in/">wttr.in</a> and <a href="https://open-meteo.com/">Open-Meteo</a>. No data would be stored locally. This approach gives the ability to process all cities together. Just pass the city and country to the script, and the markdown would be served. At that point, snac comes into play: without the need to use external utilities, the "snac note" command allows posting from stdin by specifying the instance directory and the user to post from. No need to make API calls with external utilities, having to manage API keys, permissions, etc.</p><h3>Setting Up for Italy</h3><p>To simplify things, I first structured the jail for Italy. I made a list of the main cities, normalizing them. For example, La Spezia became la_spezia. Forlì, with an accent, became forli - this for maximum compatibility since each city would be a snac user. I then created a script that takes this list and creates snac users via "snac adduser." At that point, after creating all the users, the script would modify the JSON of each user to convert the city name to uppercase, insert the bio (a standard text), activate the "bot" flag, and set the avatar, which was the same for all users at the time. This script is also able to add a new city: just run the script with the (normalized) name of the city, and it will add it - also adding it to the "cities.txt" file, so it will be updated in the next weather update cycle.</p><h3>Core Application Development</h3><p>I then created the heart of the service. A Python application (initially only in Italian, then multilingual, separating the operational part from the text) able to receive (via command line) the name of a city and a country code (corresponding to the file with texts in the local language). The script determines the coordinates and then, using API calls, requests the current weather conditions, those for the next 12 hours, and the next 7 days. I conducted experiments with both wttr.in and Open-Meteo, and both gave good results. However, I settled on Open-Meteo because, for my uses, it has always provided very reliable results. This application directly provides an output in Markdown since snac supports it, at least partially.</p><p>The cities.txt file is also crucial for updates. I created a script - post.sh, in pure sh, that scrolls through all cities, and for each one, launches the FediMeteo application and publishes its output using snac directly via command line. Once the job is finished, it makes a call to my instance of <a href="https://it-notes.dragas.net/2024/07/22/install-uptime-kuma-freebsd-jail/">Uptime-Kuma</a>, which keeps an eye on the situation. In case of failure, the monitoring will alert me that there have been no recent updates, and I can check.</p><p>At this point, the system cron takes care of launching post.sh every 6 hours. The requests are serialized, so the cities will update one at a time, and the posts will be sent to followers.</p><h2>Growth and Unexpected Success</h2><p>After listing all Italian provincial capitals, I started testing everything. It worked perfectly. Of course, I had to make some adjustments at all levels. For example, one of the problems encountered was that snac did not set the language of the posts, and some users could have missed them. The developer was very quick and, as soon as I exposed the problem, immediately modified the program so that the post could keep the system language, set as an environment variable in the sh script.</p><p>After two days, I decided to start adding other countries and announce the project. And the announcement was unexpectedly well received: there were many boosts, and people started asking me to add their cities or countries. I tried to do what I could, within the limits of my physical condition, as in those days, I had the flu that kept me at home with a fever and illness for several days. I started adding many countries in the heart of Europe, translating the main indications into local languages but maintaining emojis so that everything would be understandable even to those who don't speak the local language. There were some small problems reported by some users. One of them: not all weather conditions had been translated, so sometimes they appeared in Italian - as well as errors. In bilingual countries, I tried to include all local languages. Sometimes, unfortunately, making mistakes as I encountered dynamics unknown to me or difficult to interpret. For example, in Ireland, forecasts were published in Irish, but it was pointed out to me that not everyone speaks it, so I modified and published in English.</p><h3>A Turning Point</h3><p>The turning point was when FediFollows (<a href="https://social.growyourown.services/@FediFollows">@FediFollows@social.growyourown.services</a> - who also manages the site <a href="https://fedi.directory/">Fedi Directory</a>) started publishing the list of countries and cities, highlighting the project. Many people became aware of FediMeteo and started following the various accounts, the various cities. And from here came requests to add new countries and some new information, such as wind speed. Moreover, I was asked (rightly, to avoid flooding timelines) to publish posts as unlisted - this way, followers would see the posts, but they wouldn't fill local timelines. Snac didn't support this, but again, the snac dev came to my rescue in a few hours.</p><h2>Scaling Challenges</h2><p>But with new countries came new challenges. For example, in my original implementation, all units of measurement were in metric/decimal/Celsius - and this doesn't adapt well to realities like the USA. Moreover, focusing on Europe, almost all countries were located in a single timezone, while for larger countries (such as Australia, USA, Canada, etc.), this is totally different. So I started developing a more complete and global version and, in the meantime, added almost all of Europe. The new version would have to be backward compatible, would have to take into account timezone differences for each city, different measurements (e.g., degrees C and F), as well as, initially more difficult part, being able to separate cities with the same name based on states or provinces. I had already seen a similar problem with the implementation of support for Germany, so it had to be addressed properly.</p><p>The original goal was to have a VPS for each continent, but I soon realized that thanks to the quality of snac's code and FreeBSD's efficient management, even keeping countries in separate jails, the load didn't increase much. So I decided to challenge myself and the limits of the economical 4 euros per month VPS. That is, to insert as much as possible until seeing what the limits were. Limits that, to date, I have not yet reached. I would also soon exhaust the available API calls for Open-Meteo's free accounts, so I tried to contact the team and explain everything. I was positively surprised to read that they appreciated the project and provided me with a dedicated API key.</p><p>Compatible with my free time, I managed to complete the richer and more complete version of my Python program. I'm not a professional dev, I'm more oriented towards systems, so the code is probably quite poor in the eyes of an expert dev. But, in the end, it just needs to take an input and give me an output. It's not a daemon, it's not a service that responds on the network. For that, snac takes care of it.</p><h2>Expansion to North America</h2><p>So I decided to start with a very important launch: the USA and Canada. A non-trivial part was identifying the main cities in order to cover, state by state, all the territory. In the end, I identified more than 1200 cities. A number that, by itself, exceeded the sum of all other countries (at that time). And the program, now, is able to take an input with a separator (two underscores: __) between city and state. In this way, it's possible to perfectly understand the differences between city and state: new_york__new_york is an example I like to make, but there are many.</p><p>The launch of the USA was interesting: despite having had many previous requests, the reception was initially quite lukewarm, to my extreme surprise. The number of followers in Canada, in a few hours, far exceeded that of the USA. On the contrary, the country with the most followers (in a few days, more than 1000) was Germany. Followed by the UK - which I expected would have been the first.</p><h2>System Performance</h2><p>The VPS held up well. Except for the moments when FediFollows launched (after fixing some FreeBSD tuning, the service slowed slightly but didn't crash), the load remained extremely low. So I continued to expand: Japan, Australia, New Zealand, etc.</p><h2>Current Status</h2><p>At the time of the last update of this article (30 December 2025), the supported countries are 38: Argentina, Australia, Austria, Belgium, Brazil, Bulgaria, Canada, Croatia, Czechia, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, India, Ireland, Italy, Japan, Latvia, Lithuania, Malta, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Romania, Slovakia, Slovenia, Spain, Sweden, Switzerland, Taiwan, the United Kingdom, and the United States of America (with more regions coming soon!).</p><p>Direct followers in the Fediverse are around 7,707 and growing daily, excluding those who follow hashtags or cities via RSS, whose number I can't estimate. However, a quick look at the logs suggests there are many more.</p><p>The cities currently covered are 2937 - growing based on new countries and requests.</p><h2>Challenges Encountered</h2><p>There have been some problems. The most serious, by my fault, was the API key leak: I had left a debug code active and, the first time Open-Meteo had problems, the error message also included the API call - including the API key. Some users reported it to me (others just mocked) and I fixed the code and immediately reported everything to the Open-Meteo team, who kindly gave me a new API Key and deactivated the old one.</p><p>A further problem was related to geopy. It makes a call to Nominatim to determine coordinates. One of the times Nominatim didn't respond, my program wasn't able to determine the position and went into error. I solved this by introducing coordinate caching: now the program, the first time it encounters a city, requests and saves the coordinates. If present, they will be used in the future without making a new request via geopy. This is both lighter on their servers and faster and safer for us.</p><h2>Infrastructure Details</h2><p>And the VPS? It has no problems and is surprisingly fast and effective. FreeBSD 14.3-RELEASE, BastilleBSD to manage the jails. Currently, there are 39 jails - one for haproxy, the <a href="https://fedimeteo.com/">FediMeteo website</a>, so nginx, and the snac instance for <a href="https://fedimeteo.com/fedi/admin">FediMeteo announcements and support</a> - the other 38 for the individual instances. Each of them, therefore, has its autonomous ZFS dataset. Every 15 minutes, there is a local snapshot of all datasets. Every hour, the homepage is regenerated: a small script calculates the number of followers (counting, instance by instance, the followers of individual cities, since I don't publish except in aggregate to avoid possible triangulations and privacy leaks of users). Every hour, moreover, an external backup is made via <a href="https://it-notes.dragas.net/2022/05/30/how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-2/">zfs-autobackup</a> (on encrypted at rest dataset), and once a day, a further backup is made in my datacenter, on disks encrypted with geli. The occupied RAM is 501 MB (yes, exactly: 501 MB), which rises slightly when updates are in progress. Updates normally occur every 6 hours. I have tried, as much as possible, to space them out to avoid overloads in timelines (or on the server itself). Only for the USA, I added a sleep of 5 seconds between one city and another, to give snac the opportunity to better organize the sending of messages. It probably wouldn't be necessary, with the current numbers, but better safe than sorry. In this way, the USA is processed in about 2 and a half hours, but the other jails (thus countries) can work autonomously and send their updates.</p><p>The average load of the VPS (taking as reference both the last 24 hours and the last two weeks) is about 25%, as it rises to 70/75% when updates occur for larger instances (such as the USA), or when it is announced by FediFollows. Otherwise, it is on average less than 10%. So, the VPS still has huge margin, and new instances, with new nations, will still be inside it.</p><h2>Conclusion</h2><p>This article, although in some parts very conversational, aims to demonstrate how it's possible to build solid, valid, and efficient solutions without the need to use expensive and complex services. Moreover, this is the demonstration of how it's possible to have your online presence without the need to put your data in the hands of third parties or without necessarily having to resort to complex stacks. Sometimes, less is more.</p><p>The success of this project demonstrates, once again, that my grandfather was right: weather forecasts interest everyone. He worried about my health and, thanks to his concerns, we spent time together. In the same way, I see many followers and friends talking to me or among themselves about the weather, their experiences, what happens. Again, in my life, weather forecasts have helped sociality and socialization.</p><p>Thank you, Grandpa.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Now That He Has No Power, Mitt Romney Says "Tax the Rich" (106 pts)]]></title>
            <link>https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/</link>
            <guid>46436687</guid>
            <pubDate>Tue, 30 Dec 2025 19:00:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/">https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/</a>, See on <a href="https://news.ycombinator.com/item?id=46436687">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="post-content"><p>Why is it that powerful people typically wait until they have no power to take the right position and effectively admit they were wrong when they had more power to do something about it?</p>
<p>We see this happen so often that it’s barely noticeable anymore. There were the Iraq War proponents <a href="https://time.com/6107901/colin-powell-legacy/?utm_source=chatgpt.com" target="_blank" rel="noreferrer noopener">renouncing</a> their <a href="https://www.politico.com/story/2007/02/half-of-democratic-senators-regret-iraq-vote-002639" target="_blank" rel="noreferrer noopener">past actions</a>. There was Barack Obama <a href="https://www.npr.org/2009/07/24/106969104/single-payer-the-health-care-plan-not-on-the-table" target="_blank" rel="noreferrer noopener">marginalizing</a> single-payer health care as president and then <a href="https://thehill.com/policy/healthcare/405597-obama-calls-medicare-for-all-a-good-idea/" target="_blank" rel="noreferrer noopener">touting</a> Medicare for All after he left office. There was James Carville telling Democrats to <a href="https://www.nytimes.com/2025/02/25/opinion/democrats-trump-congress.html" target="_blank" rel="noreferrer noopener">play dead</a> and then recognizing the zeitgeist and saying they should actually <a href="https://www.nytimes.com/2025/11/24/opinion/democrats-platform-economic-rage.html" target="_blank" rel="noreferrer noopener">go populist</a>. There’s the Lincoln Project founder who, when he <a href="https://x.com/SteveSchmidtSES/status/1314649342901456898" target="_blank" rel="noreferrer noopener">had power</a>, helped install John Roberts and Sam Alito on the Supreme Court — and who now casts himself as a leader of the resistance. There was Dick Cheney creating the tyrannical executive power for someone like Donald Trump to use and then Cheney at the tail end of his life becoming a big critic of Trump.</p>
<p>Now comes Mitt Romney — who campaigned for president on tax cuts for the wealthy — publishing a <em>New York Times</em> <a href="https://www.nytimes.com/2025/12/19/opinion/romney-tax-the-rich.html?partner=slack&amp;smid=sl-share" target="_blank" rel="noreferrer noopener">op-ed</a> arguing for higher taxes on the rich.</p>
<p>The obvious news of the op-ed is that we’ve reached a point in which even American politics’ very own Gordon Gekko — a private equity mogul turned Republican politician — is now admitting the tax system has been rigged for his fellow oligarchs.</p>
<p>And, hey, that’s good. I believe in the politics of addition. I believe in welcoming converts to good causes in the spirit of “better late than never.” I believe there should be space for people to change their views for the better. And I appreciate Romney offering at least some pro forma explanation about what allegedly changed his thinking (sidenote: I say “allegedly” because it’s not like Romney only just now learned that the tax system was rigged — he was literally a cofounder of Bain Capital!).</p>
<p>And yet these kinds of reversals (without explicit apologies, of course) often come off as both long overdue but also vaguely inauthentic, or at least not as courageous and principled as they seem.</p>
<p>Reversals held until after people leave positions of power often seem less like genuine efforts to change policy and more like after-the-fact attempts to belatedly repair their personal legacies for posterity. Worse, our society so often rewards that not just with a “better late than never” welcome but with valorization — as if the political icon who was so wrong for so long actually has more credibility on the issue rather than the people who were right all along.</p>
<p>In doing that, we remove a deterrent against people doing horrible things when they have agency. They know they can use their power in all sorts of venal ways in the here and now — and then still be celebrated as principled truth-tellers when they are later given coveted space in fancy newspapers like the <em>New York Times</em> to fess up to their bad behavior and/or reverse their awful positions.</p>
<p>This is the standard legacy-washing playbook among America’s elite — and it works as a PR strategy, at least for a time. But <em>real</em> legacies — the legacy of what actually happened in history and who is actually responsible for those events — are forged not by what people say after the fact, but by what they actually do when they have power and when there are real stakes in their policy positions.</p>
<p>For example: John McCain’s <a href="https://www.levernews.com/master-plan-ep-6-the-maverick-vs-the-corruption_machine/">legacy</a> as a campaign finance reformer was earned not because he got singed by the Keating Five scandal, then retired, and then wrote some op-eds about how bad corruption is. He earned his legacy because he remained in the Senate after that scandal, changed his whole posture on corruption, and actually used his power to pass campaign finance legislation.</p>
<p>McCain stands out on that set of issues because he did the opposite of what we typically witness. So often when politicians have power — when there are real stakes and when they need to have courage — they don’t do the right thing and take the obviously correct/moral position. Instead, they champion the very policy they later try to cleanse from their brand.</p>
<p>Here the Romney example is illustrative: When he was in a position to actually sculpt the national political discourse, the Republican Party platform, and ultimately the tax policy of the United States of America, Romney decided to run for president on a tax cut plan that would “bestow most of its benefits on those with the highest incomes,” according to the <a href="https://taxpolicycenter.org/taxvox/romneys-tax-plan-big-benefits-wealthy-and-higher-deficits" target="_blank" rel="noreferrer noopener">Tax Policy Center</a>. He also decided to <a href="https://www.motherjones.com/politics/2023/10/mitt-romney-a-reckoning-mcckay-coppins-47-percent-tailspin-2012/" target="_blank" rel="noreferrer noopener">portray</a> the bottom 47 percent of income earners as America’s real tax scofflaws — not his fellow private equity tycoons, who get to exploit the carried interest loophole <a href="https://www.npr.org/sections/money/2012/01/19/145449117/carried-interest-why-mitt-romneys-tax-rate-is-15-percent" target="_blank" rel="noreferrer noopener">he exploited</a> and that he only now criticizes in his op-ed.</p>
<p>And during his Senate tenure, while Romney did occasionally&nbsp;<a href="https://www.taxnotes.com/featured-news/romney-bennet-plan-curb-stepped-basis-may-be-step-too-far/2019/12/16/2bprl" target="_blank" rel="noreferrer noopener">explore</a> closing some loopholes, I don’t recall him using his platform to champion the tax-the-billionaires cause, and I don’t recall him cosponsoring the&nbsp;<a href="https://www.congress.gov/bill/118th-congress/senate-bill/4123/cosponsors" target="_blank" rel="noreferrer noopener">major</a>&nbsp;bills to&nbsp;<a href="https://www.congress.gov/bill/117th-congress/senate-bill/1598/cosponsors" target="_blank" rel="noreferrer noopener">close</a>&nbsp;the tax <a href="https://www.congress.gov/bill/118th-congress/senate-bill/3317" target="_blank" rel="noreferrer noopener">loophole</a>&nbsp;that he and Wall Street tycoons&nbsp;<a href="https://archive.nytimes.com/dealbook.nytimes.com/2012/01/17/romney-disclosure-reignites-debate-over-carried-interest-tax/" target="_blank" rel="noreferrer noopener">benefited from</a>.</p>
<p>In short, when Romney had real power, he fortified the rigged tax system that he’s only now criticizing from the sidelines.</p>
<p>Notably, Romney doesn’t explicitly apologize for any of that in his essay. He avoids apology not because he’s an archetypical American man who, like <a href="https://www.dailymotion.com/video/x26yzgd" target="_blank" rel="noreferrer noopener">the Fonz</a>, can’t bring himself to say “Sorry” or “I was wrong.” He doesn’t offer contrition because that might remind us of what he actually did when he had power and there were <em>real</em> stakes in his declarations about tax policy.</p>
<p>And so, when I think of that history and that context, I don’t find myself thinking “Wow, even Mitt Romney agrees we shouldn’t cut taxes for rich people, which means he’s courageous and principled, and means that only now is that tax position credible and serious.”</p>
<p>I instead find myself thinking: “Mitt Romney kinda looks like the hot-dog-guy saying he’s trying to find the guy who did this to our tax policy, and the real courageous heroes on taxes are those who had the guts to try to actually use their power in public office to push for a fairer tax system when it wasn’t cool to do so.”</p>
<p>Again, yes: Better late than never that someone like Romney is finally admitting what was obvious to most Americans over the last fifty years. And better late than never when anyone finally comes over to the right side of history on any issue.</p>
<p>But where is the courage from powerful people when they actually have power to do something? The answer is it’s often nowhere, because they derive their own power and prominence by fortifying other elites’ power rather than challenging it.</p>
<p>That is their real legacy, no matter what they say after the fact.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A faster heart for F-Droid. Our new server is here (256 pts)]]></title>
            <link>https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html</link>
            <guid>46436409</guid>
            <pubDate>Tue, 30 Dec 2025 18:36:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html">https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html</a>, See on <a href="https://news.ycombinator.com/item?id=46436409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Donations are a key part of what keeps F-Droid independent and reliable and
our latest hardware update is a direct result of your support. Thanks to
donations from our incredible community, F-Droid has replaced one of its
most critical pieces of infrastructure, our core server hardware. It was
overdue for a refresh, and now we are happy to give you an update on the new
server and how it impacts the project.</p>

<p>This upgrade touches a core part of the infrastructure that builds and
publishes apps for the main F-Droid repository. If the server is slow,
everything downstream gets slower too. If it is healthy, the entire
ecosystem benefits.</p>

<h2 id="why-did-we-wait">Why did we wait?</h2>

<p>This server replacement took a bit longer than we would have liked. The
biggest reason is that sourcing reliable parts right now is genuinely
hard. Ongoing global trade tensions have made supply chains unpredictable,
and that hit the specific components we needed. We had to wait for quotes,
review, replan, and wait again when quotes turned out to have unexpected
long waits, before we finally managed to receive hardware that met our
requirements.</p>

<p>Even with the delays, the priority never changed. We were looking for the
right server set up for F-Droid, built to last for the long haul.</p>

<h2 id="a-note-about-the-host">A note about the host</h2>

<p>Another important part of this story is where the server lives and how it is
managed. F-Droid is not hosted in just any data center where commodity
hardware is managed by some unknown staff. We worked out a special
arrangement so that this server is physically held by a long time
contributor with a proven track record of securely hosting services. We can
control it remotely, we know exactly where it is, and we know who has
access. That level of transparency and trust is not common in
infrastructure, but it is central to how we think about resilience and
stewardship.</p>

<p>This was not the easiest path, and it required careful coordination and
negotiation. But we are glad we did it this way. It fits our values and our
threat model, and it keeps the project grounded in real people rather than
anonymous systems.</p>

<h2 id="old-hardware-new-momentum">Old hardware, new momentum</h2>

<p>The previous server was 12 year old hardware and had been running for about
five years. In infrastructure terms, that is a lifetime. It served F-Droid
well, but it was reaching the point where speed and maintenance overhead
were becoming a daily burden.</p>

<p>The new system is already showing a huge improvement. Stats of the running
cycles from the last two months suggest it can handle the full build and
publish actions much faster than before. E.g. this year, between January and
September, we published updates once every 3 or 4 days, that got down to
once every 2 days in October, to every day in November and it’s reaching
twice a day in December. <em>(You can see this in the frequency of index
publishing after October 18, 2025 in our <a href="https://gitlab.com/fdroid/f-droid.org-transparency-log/-/commits/master">f-droid.org transparency
log</a>)</em>.
That extra capacity gives us more breathing room and helps shorten the gap
between when apps are updated and when those updates reach users. We can now
build all the <a href="https://gitlab.com/fdroid/wiki/-/wikis/FAQ#finding-updates">auto-updated
apps</a> in the
<em>(UTC)</em> morning in one cycle, and all the newly included apps, fixed apps
and manually updated apps, through the day, in the evening cycle.</p>

<p>We are being careful here, because real world infrastructure always comes
with surprises. But the performance gains are real, and they are exciting.</p>

<h2 id="what-donations-make-possible">What donations make possible</h2>

<p>This upgrade exists because of community support, pooled over time, turned
into real infrastructure, benefiting everyone who relies on F-Droid.</p>

<p>A faster server does not just make our lives easier. It helps developers get
timely builds. It reduces maintenance risk. It strengthens the health of the
entire repository.</p>

<p>So thank you. Every <a href="https://f-droid.org/en/donate/">donation</a>, whether large
or small, is part of how this project stays reliable, independent, and
aligned with free software values.</p>

  </div>

</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Electrolysis can solve one of our biggest contamination problems (119 pts)]]></title>
            <link>https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html</link>
            <guid>46436127</guid>
            <pubDate>Tue, 30 Dec 2025 18:08:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html">https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html</a>, See on <a href="https://news.ycombinator.com/item?id=46436127">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
                
                    
    
    <!-- Panorama header -->
    

    <!-- Blog header -->
    
    <!-- Tags when not blog -->
    
        
    

    <!-- Articleheader -->
    <div>
    <p>
            ETH Zurich researchers have developed a process that can be used on site to render environmental toxins such as DDT and lindane harmless and convert them into valuable chemicals – a breakthrough for the remediation of contaminated sites and a sustainable circular economy.&nbsp;
        </p>
    

</div>

    <!-- Nav & News images -->
    

    <!-- Details -->
    

    <!-- ArticleLeadImage -->
    
        <div>
            <figure>
            <img alt="Patrik Domke is standing in front of a window in the laboratory. This window is covered with notes. He is holding a construction with a balloon in his hand." src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/articleLeadImage/image.imageformat.carousel.1046845309.png">
			<figcaption>
			    <p>
			      Removing insecticides from contaminated soils – Patrick Domke (pictured) and other ETH researchers found the solution in electrolysis.&nbsp; (Image: Hannes Cullum /  IVY Filmstudio GmbH)</p>
			  </figcaption>
			</figure>
    
          </div>
    

    <!-- Parsys 1 -->
    <div>

<div>
                
                	<h2>In brief</h2>
                
                
                <ul> 
 <li><p>Persistent organic pollutants such as DDT and lindane still pollute the environment and affect humans decades after their use.&nbsp;</p> </li> 
 <li><p>ETH researchers have developed a new electrochemical process that completely dehalogenates these long-lived toxins and converts them into valuable industrial chemicals.&nbsp;</p> </li> 
 <li><p>The method uses cheap equipment, prevents side reactions and could be used on contaminated landfills, soils or sludge.&nbsp;</p> </li> 
 <li><p>Mobile systems could be used on site in the future – an important step towards the remediation of contaminated sites and the creation of a sustainable circular economy.&nbsp;</p> </li> 
</ul>
            </div>
<div>
                
                
                <p>They were once considered miracle workers – insecticides such as lindane or DDT were produced and used millions of times during the 20th century. But what was hailed as progress led to a global environmental catastrophe: persistent organic pollutants (POPs) are so chemically stable that they remain in soil, water and organisms for decades. They accumulate in the fatty tissue of animals and thus enter the human food chain. Many of these substances were banned long ago, but their traces can still be found today – even in human blood.</p> 
<p>How to remediate such contaminated sites, be they soils, bodies of water or landfills, is one of the major unresolved questions of environmental protection. How can highly stable poisons be rendered harmless without creating new problems? Researchers at ETH Zurich, led by Bill Morandi, Professor of Synthetic Organic Chemistry, have now found a promising approach. Using an innovative electrochemical method, they are not only able to break down these long-lived pollutants but also to convert them into valuable raw materials for the chemical industry.</p> 
<h2>Converting pollutants into raw materials</h2> 
<p>A key distinction between this and previous work is that the carbon skeleton of the pollutants is recycled and made reusable, while the halide component is sequestered as a harmless inorganic salt. “The previous methods were also energetically inefficient,” says Patrick Domke, a doctoral student in Morandi’s group. He explains: “The processes were expensive and still led to outcomes that were harmful to the environment.”&nbsp;</p> 
<p>Together with electrochemistry specialist Alberto Garrido-Castro, a former postdoc in this group, Domke developed a process that renders the pollutants in question completely harmless. During this project, the two researchers were able to draw on the many years of experience of ETH professor Morandi, who has been working on the transformation of such compounds for years. “The key advance of this new technology is the use of alternating current to sequester the problematic halogen atoms as innocuous salts such as NaCl (table salt), while still generating valuable hydrocarbons,” says Morandi.&nbsp;</p> 
<h2>Using electricity to break down toxins&nbsp;&nbsp;</h2> 
<p>Electrolysis enables almost complete dehalogenation of pollutants under mild, environmentally friendly and cost-effective conditions. It cleaves the stable carbon-halogen bonds, leaving behind only harmless salts such as table salt and useful hydrocarbons such as benzene, diphenylethane or cyclododecatriene. These are actually sought-after intermediates in the chemical industry, for example, for plastics, varnishes, coatings and pharmaceutical applications. In this way, the technology not only contributes to the remediation of contaminated sites but also to the sustainable circular economy.</p>
            </div>
<div>
                        <figure>
            <img alt="Four small glass containers are standing on a shelf. They are labelled &quot;soil and HCL&quot;, the second from the left with NACL, the third with C6H6 and the last with clean soil." src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/wide_content/image/image.imageformat.1286.834672465.png">
			<figcaption>
			    <p>
			      The contaminated soil (soil + HCH) becomes table salt (NaCl), benzene (C<sub>6</sub>H<sub>6</sub>), and clean soil through electrolysis.&nbsp;&nbsp;(Image: Patrick Domke / ETH Zurich)</p>
			  </figcaption>
			</figure>
    
                    </div>
<div>
                
                
                <p>“What makes our process so special from a technical point of view is that we supply electricity using alternating current, similar to the electrical waveform delivered to households. It is one of the most cost-effective resources in chemistry,” explains Garrido-Castro. “Alternating current protects the electrodes from wear, which is why we can reuse them for many subsequent electrolysis cycles. In addition, the alternating current suppresses unwanted side reactions and the formation of poisonous chlorine gas, allowing the pollutant’s halogen atoms to be fully converted to inorganic salts.” The reactor used by the researchers consists of an undivided electrolysis cell in which dimethyl sulfoxide (DMSO) is used as a solvent – itself a by-product of the pulp process in paper production.&nbsp;</p> 
<h2>A fully thought-out circular economy</h2> 
<p>The process can be applied not only to pure substances but also to mixtures from contaminated soils. Soil or sludge can therefore be treated without pre-treatment or further separation processes. A prototype of the reactor has already been successfully tested on classic environmental toxins such as lindane and DDT. “Our system is mobile and can be assembled on site. This eliminates the need to transport these hazardous substances,” explains Domke.&nbsp;</p>
            </div>
<div tabindex="-1">
                            <p><img alt="Portrait photograph of Alberto Garrido-Castro " title="" src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/wide_content/citation/image.imageformat.fullwidth.1235311956.png">
    </p>
                            <blockquote>
                                <span>
                                  “Our motivation was to solve one of the biggest environmental problems of the last century. We cannot simply leave the pollution to future generations.”</span>
                                <div>
                                    <p><img alt="Portrait photograph of Alberto Garrido-Castro " title="" src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/wide_content/citation/image.imageformat.fullwidth.1235311956.png">
    </p>
                                    <p><cite>Alberto Garrido-Castro </cite>
                                </p></div>
                            </blockquote>
                        </div>

<div>
                
                	<h2>Spark Award 2025 – these projects have made it to the finals &nbsp;</h2>
                
                
                <p>On <b>27 November 2025</b> at <a href="https://ethz.ch/en/news-and-events/events/eth-open-i.html">ETH Zurich @ Open-i</a>, ETH Zurich will award the Spark Award for the best invention of the year for the 14th time. The criteria for this award are originality, patent strength and market potential.&nbsp;&nbsp;</p>
<p>Click here to find all the <a href="https://transfer.ethz.ch/impact/sparkaward.html">Spark Award nominees of 2025.</a> &nbsp;</p>
<p>Spark Award ceremony, <a href="https://ethz.ch/en/news-and-events/events/eth-open-i/program.html">Industry Day @ Open-i</a>, Thursday, 27 November 2025, 1.30 p.m., Zurich Convention Center. Registration is required. &nbsp;</p>
            </div>

</div>
    <!-- Socialsharing (display only) -->
    
    
        
            
            
            
        
        
    


    <!-- Parsys 2 -->
    

    <!-- Rightside Parsys -->
    

    <!-- Taglist -->
    
        
            
        
    

    <!-- Comments -->
    
    	
	    
    

                
                
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Vulnerability in Libsodium (195 pts)]]></title>
            <link>https://00f.net/2025/12/30/libsodium-vulnerability/</link>
            <guid>46435614</guid>
            <pubDate>Tue, 30 Dec 2025 17:24:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://00f.net/2025/12/30/libsodium-vulnerability/">https://00f.net/2025/12/30/libsodium-vulnerability/</a>, See on <a href="https://news.ycombinator.com/item?id=46435614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    
    <main id="main-content" role="main" aria-label="Main content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting" role="article">
  
  
  <div itemprop="articleBody">
    <p>Libsodium is now 13 years old!</p>

<p>I started that project to pursue Dan Bernstein’s desire to make cryptography simple to use. That meant exposing a limited set of high-level functions and parameters, providing a simple API, and writing documentation for users, not cryptographers. Libsodium’s goal was to expose APIs to perform operations, not low-level functions. Users shouldn’t even have to know or care about what algorithms are used internally. This is how I’ve always viewed libsodium.</p>

<p>Never breaking the APIs is also something I’m obsessed with. APIs may not be great, and if I could start over from scratch, I would have made them very different, but as a developer, the best APIs are not the most beautifully designed ones, but the ones that you don’t have to worry about because they don’t change and upgrades don’t require any changes in your application either. Libsodium started from the NaCl API, and still adheres to it.</p>

<p>These APIs exposed high-level functions, but also some lower-level functions that high-level functions wrap or depend on. Over the years, people started using these low-level functions directly. Libsodium started to be used as a toolkit of algorithms and low-level primitives.</p>

<p>That made me sad, especially since it is clearly documented that only APIs from builds with <code>--enable-minimal</code> are guaranteed to be tested and stable. But after all, it makes sense. When building custom protocols, having a single portable library with a consistent interface for different functions is far better than importing multiple dependencies, each with their own APIs and sometimes incompatibilities between them.</p>

<p>That’s a lot of code to maintain. It includes features and target platforms I don’t use but try to support for the community. I also maintain a large number of other open source projects.</p>

<p>Still, the security track record of libsodium is pretty good, with zero CVEs in 13 years even though it has gotten a lot of scrutiny.</p>

<p>However, while recently experimenting with adding support for batch signatures, I noticed inconsistent results with code originally written in Zig. The culprit was a check that was present in a function in Zig, but that I forgot to add in libsodium.</p>

<h2 id="the-bug">The bug</h2>

<p>The function <code>crypto_core_ed25519_is_valid_point()</code>, a low-level function used to check if a given elliptic curve point is valid, was supposed to reject points that aren’t in the main cryptographic group, but some points were slipping through.</p>

<h2 id="why-does-this-matter">Why does this matter?</h2>

<p>Edwards25519 is like a special mathematical playground where cryptographic operations happen.</p>

<p>It is used internally for Ed25519 signatures, and includes multiple subgroups of different sizes (order):</p>

<ul>
  <li>Order 1: just the identity (0, 1)</li>
  <li>Order 2: identity + point (0, -1)</li>
  <li>Order 4: 4 points</li>
  <li>Order 8: 8 points</li>
  <li>Order L: the “main subgroup” (L = ~2^252 points) where all operations are expected to happen</li>
  <li>Order 2L, 4L, 8L: very large, but not prime order subgroups</li>
</ul>

<p>The validation function was designed to reject points not in the main subgroup. It properly rejected points in the small-order subgroups, but not points in the mixed-order subgroups.</p>

<h2 id="what-went-wrong-technically">What went wrong technically?</h2>

<p>To check if a point is in the main subgroup (the one of order L), the function multiplies it by L. If the order is L, multiplying any point by L gives the identity point (the mathematical equivalent of zero). So, the code does the multiplication and checks that we ended up with the identity point.</p>

<p>Points are represented by coordinates. In the internal representation used here, there are three coordinates: X, Y, and Z. The identity point is represented internally with coordinates where X = 0 and Y = Z. Z can be anything depending on previous operations; it doesn’t have to be 1.</p>

<p>The old code only checked X = 0. It forgot to verify Y = Z. This meant some invalid points (where X = 0 but Y ≠ Z after the multiplication) were incorrectly accepted as valid.</p>

<p>Concretely: take any main-subgroup point Q (for example, the output of <code>crypto_core_ed25519_random</code>) and add the order-2 point (0, -1), or equivalently negate both coordinates. Every such Q + (0, -1) would have passed validation before the fix, even though it’s not in the main subgroup.</p>

<h2 id="the-fix">The fix</h2>

<p><a href="https://github.com/jedisct1/libsodium/commit/f2da4cd8cb26599a0285a6ab0c02948e361a674a">The fix</a> is trivial and adds the missing check:</p>

<div><pre><code><span>// OLD:</span>
<span>return</span> <span>fe25519_iszero</span><span>(</span><span>pl</span><span>.</span><span>X</span><span>);</span>
</code></pre></div>

<div><pre><code><span>// NEW:</span>
<span>fe25519_sub</span><span>(</span><span>t</span><span>,</span> <span>pl</span><span>.</span><span>Y</span><span>,</span> <span>pl</span><span>.</span><span>Z</span><span>);</span>
<span>return</span> <span>fe25519_iszero</span><span>(</span><span>pl</span><span>.</span><span>X</span><span>)</span> <span>&amp;</span> <span>fe25519_iszero</span><span>(</span><span>t</span><span>);</span>
</code></pre></div>

<p>Now it properly verifies both conditions: X must be zero and Y must equal Z.</p>

<h2 id="who-is-affected">Who is affected?</h2>

<p>You may be affected if you:</p>

<ul>
  <li>Use a point release &lt;= <code>1.0.20</code> or a version of <code>libsodium</code> released before December 30, 2025.</li>
  <li>Use <code>crypto_core_ed25519_is_valid_point()</code> to validate points from untrusted sources</li>
  <li>Implement custom cryptography using arithmetic over the Edwards25519 curve</li>
</ul>

<p>But don’t panic. Most users are not affected.</p>

<p>None of the high-level APIs (<code>crypto_sign_*</code>) are affected; they don’t even use or need that function. Scalar multiplication using <code>crypto_scalarmult_ed25519</code> won’t leak anything even if the public key is not on the main subgroup. And public keys created with the regular <code>crypto_sign_keypair</code> and <code>crypto_sign_seed_keypair</code> functions are guaranteed to be on the correct subgroup.</p>

<h2 id="recommendation">Recommendation</h2>

<p>Support for the Ristretto255 group was added to libsodium in 2019 specifically to solve cofactor-related issues. With Ristretto255, if a point decodes, it’s safe. No further validation is required.</p>

<p>If you implement custom cryptographic schemes doing arithmetic over a finite field group, using Ristretto255 is recommended. It’s easier to use, and as a bonus, low-level operations will run faster than over Edwards25519.</p>

<p>If you can’t update libsodium and need an application-level workaround, use the following function:</p>

<div><pre><code><span>int</span> <span>is_on_main_subgroup</span><span>(</span><span>const</span> <span>unsigned</span> <span>char</span> <span>p</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>])</span>
<span>{</span>
    <span>/* l - 1 (group order minus 1) */</span>
    <span>static</span> <span>const</span> <span>unsigned</span> <span>char</span> <span>L_1</span><span>[</span><span>crypto_core_ed25519_SCALARBYTES</span><span>]</span> <span>=</span> <span>{</span>
        <span>0xec</span><span>,</span> <span>0xd3</span><span>,</span> <span>0xf5</span><span>,</span> <span>0x5c</span><span>,</span> <span>0x1a</span><span>,</span> <span>0x63</span><span>,</span> <span>0x12</span><span>,</span> <span>0x58</span><span>,</span>
        <span>0xd6</span><span>,</span> <span>0x9c</span><span>,</span> <span>0xf7</span><span>,</span> <span>0xa2</span><span>,</span> <span>0xde</span><span>,</span> <span>0xf9</span><span>,</span> <span>0xde</span><span>,</span> <span>0x14</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x10</span>
    <span>};</span>
    <span>/* Identity point encoding: (x=0, y=1) */</span>
    <span>static</span> <span>const</span> <span>unsigned</span> <span>char</span> <span>ID</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>]</span> <span>=</span> <span>{</span>
        <span>0x01</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span>
    <span>};</span>
    <span>unsigned</span> <span>char</span> <span>t</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>];</span>
    <span>unsigned</span> <span>char</span> <span>r</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>];</span>
    <span>if</span> <span>(</span><span>crypto_scalarmult_ed25519_noclamp</span><span>(</span><span>t</span><span>,</span> <span>L_1</span><span>,</span> <span>p</span><span>)</span> <span>!=</span> <span>0</span> <span>||</span>
        <span>crypto_core_ed25519_add</span><span>(</span><span>r</span><span>,</span> <span>t</span><span>,</span> <span>p</span><span>)</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
        <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>sodium_memcmp</span><span>(</span><span>r</span><span>,</span> <span>ID</span><span>,</span> <span>sizeof</span> <span>ID</span><span>)</span> <span>==</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div>

<h2 id="fixed-packages">Fixed packages</h2>

<p>This issue was fixed immediately after discovery. All <code>stable</code> packages released after December 30, 2025 include the fix:</p>

<ul>
  <li>official tarballs</li>
  <li>binaries for Visual Studio</li>
  <li>binaries for MingW</li>
  <li>NuGet packages for all architectures including Android</li>
  <li><code>swift-sodium</code> xcframework (but <code>swift-sodium</code> doesn’t expose low-level functions anyway)</li>
  <li>Rust <code>libsodium-sys-stable</code></li>
  <li><code>libsodium.js</code></li>
</ul>

<p>A new point release is also going to be tagged.</p>

<p>If <code>libsodium</code> is useful to you, please keep in mind that it is maintained by one person, for free, in time I could spend with my family or on other projects. The best way to help the project would be to consider <a href="https://opencollective.com/libsodium/contribute">sponsoring it</a>, which helps me dedicate more time to improving it and making it great for everyone, for many more years to come.</p>

  </div>
  
  <!-- JSON-LD for Blog Post -->
  
</article>







    </main>
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toro: Deploy Applications as Unikernels (118 pts)]]></title>
            <link>https://github.com/torokernel/torokernel</link>
            <guid>46435418</guid>
            <pubDate>Tue, 30 Dec 2025 17:09:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/torokernel/torokernel">https://github.com/torokernel/torokernel</a>, See on <a href="https://news.ycombinator.com/item?id=46435418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">Toro<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8797ce828a9ef346ee3d86ab93bf27c8321aec24f327c89915da16df108b4911/68747470733a2f2f6170692e7472617669732d63692e6f72672f746f726f6b65726e656c2f746f726f6b65726e656c2e7376673f6272616e63683d6d6173746572"><img src="https://camo.githubusercontent.com/8797ce828a9ef346ee3d86ab93bf27c8321aec24f327c89915da16df108b4911/68747470733a2f2f6170692e7472617669732d63692e6f72672f746f726f6b65726e656c2f746f726f6b65726e656c2e7376673f6272616e63683d6d6173746572" alt="build passing" data-canonical-src="https://api.travis-ci.org/torokernel/torokernel.svg?branch=master"></a></h2><a id="user-content-toro" aria-label="Permalink: Toro" href="#toro"></a></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">Toro is a unikernel dedicated to deploy applications as microVMs. Toro leverages on virtio-fs and virtio-vsocket to provide a minimalistic architecture.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Support x86-64 architecture</li>
<li>Support up to 512GB of RAM</li>
<li>Support QEMU-KVM microvm and Firecracker</li>
<li>Cooperative and I/O bound threading scheduler</li>
<li>Support virtio-vsocket for networking</li>
<li>Support virtio-fs for filesystem</li>
<li>Fast boot up</li>
<li>Tiny image</li>
<li>Built-in gdbstub</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How try Toro?</h2><a id="user-content-how-try-toro" aria-label="Permalink: How try Toro?" href="#how-try-toro"></a></p>
<p dir="auto">You can try Toro by running the HelloWorld example using a Docker image that includes all the required tools. To do so, execute the following commands in a console (these steps require you to install before KVM and Docker):</p>
<div dir="auto" data-snippet-clipboard-copy-content="wget https://raw.githubusercontent.com/torokernel/torokernel/master/ci/Dockerfile
sudo docker build -t torokernel-dev .
sudo docker run --privileged --rm -it torokernel-dev
cd examples/HelloWorld
python3 ../CloudIt.py -a HelloWorld"><pre>wget https://raw.githubusercontent.com/torokernel/torokernel/master/ci/Dockerfile
sudo docker build -t torokernel-dev <span>.</span>
sudo docker run --privileged --rm -it torokernel-dev
<span>cd</span> examples/HelloWorld
python3 ../CloudIt.py -a HelloWorld</pre></div>
<p dir="auto">If these commands execute successfully, you will get the output of the HelloWorld example.
You can also pull the image from dockerhub instead of building it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo docker pull torokernel/torokernel-dev:latest
sudo docker run --privileged --rm -it torokernel/torokernel-dev:latest"><pre>sudo docker pull torokernel/torokernel-dev:latest
sudo docker run --privileged --rm -it torokernel/torokernel-dev:latest</pre></div>
<p dir="auto">You can share a directory from the host by running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo docker run --privileged --rm --mount type=bind,source=&quot;$(pwd)&quot;,target=/root/torokernel -it torokernel/torokernel-dev:latest"><pre>sudo docker run --privileged --rm --mount type=bind,source=<span><span>"</span><span><span>$(</span>pwd<span>)</span></span><span>"</span></span>,target=/root/torokernel -it torokernel/torokernel-dev:latest</pre></div>
<p dir="auto">You will find $pwd from host at <code>/root/torokernel</code> in the container.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How build Toro locally?</h2><a id="user-content-how-build-toro-locally" aria-label="Permalink: How build Toro locally?" href="#how-build-toro-locally"></a></p>
<p dir="auto">Execute the commands in <code>ci/Dockerfile</code> to install the required components locally. Then, Go to <code>torokernel/examples</code> and edit <code>CloudIt.py</code> to set the correct paths to Qemu and fpc. Optionally, you can install vsock-socat from <a href="https://github.com/stefano-garzarella/socat-vsock">here</a> and virtio-fs from <a href="https://gitlab.com/virtio-fs/virtiofsd.git" rel="nofollow">here</a>. You need to set the correct path to virtiofsd and socat.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run the HelloWorld Example</h2><a id="user-content-run-the-helloworld-example" aria-label="Permalink: Run the HelloWorld Example" href="#run-the-helloworld-example"></a></p>
<p dir="auto">Go to <code>examples/HelloWorld/</code> and execute:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 ../CloudIt.py -a HelloWorld"><pre>python3 ../CloudIt.py -a HelloWorld</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/torokernel/torokernel/wiki/images/helloworld.gif"><img src="https://github.com/torokernel/torokernel/wiki/images/helloworld.gif" alt="HelloWorld" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run the StaticWebServer Example</h2><a id="user-content-run-the-staticwebserver-example" aria-label="Permalink: Run the StaticWebServer Example" href="#run-the-staticwebserver-example"></a></p>
<p dir="auto">To run the StaticWebserver, you require virtiofsd and socat. To compile socat, execute the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:stefano-garzarella/socat-vsock.git
cd socat-vsock
autoreconf -fiv
./configure
make socat"><pre>git clone git@github.com:stefano-garzarella/socat-vsock.git
<span>cd</span> socat-vsock
autoreconf -fiv
./configure
make socat</pre></div>
<p dir="auto">Set the path to socat binary in CloudIt.py and then execute:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 ../CloudIt.py -a StaticWebServer -r -d /path-to-directory/ -f 4000:80"><pre>python3 ../CloudIt.py -a StaticWebServer -r -d /path-to-directory/ -f 4000:80</pre></div>
<p dir="auto">You have to replace the <code>/path-to-directory/</code> to a directory that containing the files, e.g., index.html. To try it, you can execute:</p>
<div data-snippet-clipboard-copy-content="wget http://127.0.0.1:4000/index.html"><pre><code>wget http://127.0.0.1:4000/index.html
</code></pre></div>
<p dir="auto">The <code>-f</code> parameter indicates a forwarding of the 4000 port from the host to the 80 port in the guest using vsock.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/torokernel/torokernel/wiki/images/staticwebser.gif"><img src="https://github.com/torokernel/torokernel/wiki/images/staticwebser.gif" alt="HelloWorld" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run the Intercore Communication example</h2><a id="user-content-run-the-intercore-communication-example" aria-label="Permalink: Run the Intercore Communication example" href="#run-the-intercore-communication-example"></a></p>
<p dir="auto">This example shows how cores can communicate by using the VirtIOBus device. In this example, core #0 sends a packet to every core in the system with the <strong>ping</strong> string. Each core responds with a packet that contains the message <strong>pong</strong>. This example is configured to use three cores. To launch it, simply executes the following commands in the context of the container presented above:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 ../CloudIt.py -a InterCoreComm"><pre>python3 ../CloudIt.py -a InterCoreComm</pre></div>
<p dir="auto">You will get the following output:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/torokernel/torokernel/wiki/images/intercom.gif"><img src="https://github.com/torokernel/torokernel/wiki/images/intercom.gif" alt="InterComm" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You have many ways to contribute to Toro. One of them is by joining the Google Group <a href="https://groups.google.com/forum/#!forum/torokernel" rel="nofollow">here</a>. In addition, you can find more information <a href="https://github.com/MatiasVara/torokernel/wiki/How-to-Contribute">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">GPLv3</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">References</h2><a id="user-content-references" aria-label="Permalink: References" href="#references"></a></p>
<p dir="auto">[0] A Dedicated Kernel named Toro. Matias Vara. FOSDEM 2015.</p>
<p dir="auto">[1] Reducing CPU usage of a Toro Appliance. Matias Vara. FOSDEM 2018.</p>
<p dir="auto">[2] Toro, a Dedicated Kernel for Microservices. Matias Vara and Cesar Bernardini. Open Source Summit Europe 2018.</p>
<p dir="auto">[3] Speeding Up the Booting Time of a Toro Appliance. Matias Vara. FOSDEM 2019.</p>
<p dir="auto">[4] Developing and Deploying Microservices with Toro Unikernel. Matias Vara. Open Source Summit Europe 2019.</p>
<p dir="auto">[5] Leveraging Virtio-fs and Virtio-vsocket in Toro Unikernel. Matias Vara. DevConfCZ 2020.</p>
<p dir="auto">[6] Building a Cloud Infrastructure to Deploy Microservices as Microvm Guests. Matias Vara. KVM Forum 2020.</p>
<p dir="auto">[7] Running MPI applications on Toro unikernel. Matias Vara. FOSDEM 2023.</p>
<p dir="auto">[8] Is Toro unikernel faster for MPI?. Matias Vara. FOSDEM 2024.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: 22 GB of Hacker News in SQLite (307 pts)]]></title>
            <link>https://hackerbook.dosaygo.com</link>
            <guid>46435308</guid>
            <pubDate>Tue, 30 Dec 2025 17:01:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackerbook.dosaygo.com">https://hackerbook.dosaygo.com</a>, See on <a href="https://news.ycombinator.com/item?id=46435308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <td>
        <p>
          Viewing HN on <span id="snapInfo">Someday, Month 00, 0000</span>. Times are relative to 11:59 PM.
        </p>
        
        <div><p>
          Made by <a href="https://github.com/DOSAYGO-STUDIO">DOSAYGO</a> · <a href="https://dosaygo-studio.github.io/HackerBook/">[GET THIS]</a>
        </p></div>
      </td>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Public Sans – A strong, neutral typeface (222 pts)]]></title>
            <link>https://public-sans.digital.gov/</link>
            <guid>46433579</guid>
            <pubDate>Tue, 30 Dec 2025 14:23:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://public-sans.digital.gov/">https://public-sans.digital.gov/</a>, See on <a href="https://news.ycombinator.com/item?id=46433579">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Official government website">
    <header>
      <div>
        <p><img src="https://public-sans.digital.gov/assets/uswds/img/us_flag_small.png" alt="U.S. flag">
        </p>
        <div>
          <p>
            An official website of the United States government
          </p>
          
        </div>
        </div>
    </header>
    <div id="gov-banner">
        <div>
          <p><img src="https://public-sans.digital.gov/assets/uswds/img/icon-dot-gov.svg" role="img" alt=""></p><p>
              <strong>Official websites use .gov</strong>
              <br>
              A <strong>.gov</strong> website belongs to an official government organization in the United States.
            </p>
        </div>
        <div>
          <p><img src="https://public-sans.digital.gov/assets/uswds/img/icon-https.svg" role="img" alt=""></p><p>
              <strong>Secure .gov websites use HTTPS</strong>
              <br>
              A <strong>lock</strong> (
<span><svg xmlns="http://www.w3.org/2000/svg" width="52" height="64" viewBox="0 0 52 64" role="img" aria-labelledby="banner-lock-title banner-lock-description"><title id="banner-lock-title">Lock</title><desc id="banner-lock-description">A locked padlock</desc><path fill="#000000" fill-rule="evenodd" d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z"></path></svg></span>
) or <strong>https://</strong> means you’ve safely connected to the .gov website. Share sensitive information only on official, secure websites.
            </p>
        </div>
      </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Win32 is the stable Linux ABI (165 pts)]]></title>
            <link>https://loss32.org/</link>
            <guid>46433035</guid>
            <pubDate>Tue, 30 Dec 2025 13:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loss32.org/">https://loss32.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46433035">Hacker News</a></p>
<div id="readability-page-1" class="page">
<img src="https://loss32.org/favicon.ico" id="logo" alt="A logo that consists of four quadrants: cyan blue in the top-left, magenta in the top-right, yellow in the bottom-left, blue in the bottom-right. There is also a vertical white line in the top-left quadrant, two vertical white lines in the top-right and bottom-left quadrants, and one vertical and one horizontal white line in the bottom-right quadrant.">
<p>The future of the Linux desktop can look like this:</p>
<img src="https://loss32.org/screenshot.png" id="screenshot" alt="A screenshot of an desktop where the windows and their content look like the Windows Classic theme. There is a taskbar with the WINE logo on the Start button. There is a file explorer window with the WINE logo in its top-left; there is a window for what looks like MS Paint; there is a window titled “About Paint for ReactOS”; there is a window for xeyes; and there is a window for xterm. Many clues on screen suggest everything is running in WINE on top of Debian.">
<p><a href="#help">Let's build it!</a></p>

<hr>

<h2>Win32/Linux?</h2>
<p> I'd just like to interject for a moment. What you're refering to as Linux, is in fact, Win32/Linux, or as I've recently taken to calling it, <del>loss32</del> Win32 plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning system made useful by WINE, the ReactOS userland, and other vital system components comprising a full OS as defined by Microsoft.

</p><h2>Okay, but seriously what is this?</h2>
<p>A dream of a Linux distribution where the entire desktop environment is Win32 software running under WINE. A completely free and open-source OS where you can just download <tt>.exe</tt> files and run them, for the power user who isn't necessarily a Unixhead, or just for someone who thinks this sounds fun.

</p><h2>Isn't this just ReactOS?</h2>
<p>ReactOS tries to reimplement the Windows NT kernel, and that has always been its Achilles heel, holding it back from a hardware compatibility and stability standpoint. The loss32 concept is to achieve a similar-feeling end result to ReactOS, but built on a more usable foundation, using components known to work well (the Linux kernel, WINE, everything that glues those together, and a sprinkling of ReactOS userland niceties). As a bonus, the OS would still technically be a Linux distro, so it would be possible to run Linux software when necessary, something ReactOS can't do.

</p><h2>Why build this?</h2>

<ul>
<li>The late-90's-to-early-2010's PC desktop experience was great for power users, especially creative users. Let's keep the dream alive.
</li><li>WINE has a lot of unfortunate rough edges that people only tolerate because they use WINE as a last resort. A desktop environment where everything runs in WINE will stimulate making WINE better for everyone, whether they're going to use this project or not.
</li><li>Win32 is the stable Linux ABI!
</li><li>Because we can.
</li></ul>

<h2>Win32 is the stable Linux ABI?!</h2>
<p>Yes. I can't tell you how many times the ability to just download a goddamn <tt>.exe</tt> file and run it in WINE has saved my ass. Seemingly every creative project I undertake eventually requires downloading <em>some</em> piece of software which is either impossible or impractical to rebuild myself, and whose Linux and macOS ports no longer work or never existed. There's more than three decades of Win32 software — <tt>.exe</tt> files! — that can run in WINE or (of course) on Windows. No other ABI has that kind of compatibility record. WINE can even run Win16 stuff too.

</p><p>The really cool thing about Win32 is it's also the <em>world's</em> stable ABI. There's lots of fields of software where the GNU/Linux and POSIX-y offerings available are quite limited and generally poor in quality, e.g. creative software and games. Win32 gives you access to a much larger slice of humanity's cultural inheritance.

</p><h2>Is that a real screenshot?</h2>
<p>Yes! That's just stable WINE running on Debian 13. There's a lot of rough edges you can't see in the screenshot that make it somewhat uncomfortable for use for the time being. The goal of the project is to fix many of the rough edges and package up this environment in an easily installable form.

</p><h2 id="help">How do I help?</h2>
<p>Thanks for asking! This website was written by <a href="https://hikari.noyu.me/">hikari_no_yume</a> on 2025-12-29, who is currently at 39C3 (I'm usually at the assembly called <tt>&amp;nbsp;</tt> – ask for me there!). You can <a href="mailto:hikari@noyu.me?subject=loss32">email me</a>, or you can lurk in <tt>#loss32</tt> on <tt>irc.libera.chat</tt>. I'd especially like to hear from you if you know things about or would be willing to help with:

</p><ul>
<li>How to package a desktop environment (e.g. on Debian) so that it will show up in the list of desktop environments on the login screen
</li><li>Wayland compositors that don't impose a desktop environment on you (currently I'm using the standalone version of mutter)
</li><li>WINE, especially its version of explorer.exe, shell32.dll stuff, HiDPI scaling, packaging, how it handles the Start Menu entries, …
</li><li>ReactOS, epecially its version of explorer.exe, shell32.dll stuff, how the ReactOS userland differs from WINE's, …
</li><li>Making a Linux distro generally
</li><li>Statically linking WINE to musl and freetype and so on and throwing out as much of the Linux userland as possible (mostly to make jokes about how it's not actually GNU/Linux if there's no GNU)
</li><li>Win32 programming
</li><li>Or anything you think might be useful for this project :)
</li></ul>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[No strcpy either (175 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/</link>
            <guid>46433029</guid>
            <pubDate>Tue, 30 Dec 2025 13:14:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/">https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/</a>, See on <a href="https://news.ycombinator.com/item?id=46433029">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

	<div id="primary" role="main">
			
<article id="post-28909">
	
		<p><img width="672" height="336" src="https://daniel.haxx.se/blog/wp-content/uploads/2025/10/sourcecode.jpg" alt="" decoding="async">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>Some time ago I mentioned that we went through the curl source code and eventually got rid of all <code>strncpy</code>() calls.</p>



<p>strncpy() is a weird function with a crappy API. It might not null terminate the destination and it <em>pads</em> the target buffer with zeroes. Quite frankly, most code bases are probably better off completely avoiding it because each use of it is a potential mistake.</p>



<p>In that particular rewrite when we made strncpy calls extinct, we made <em>sure</em> we would either copy the full string properly or return error. It is rare that copying a partial string is the right choice, and if it is, we can just as well <code>memcpy</code> it and handle the null terminator explicitly. This meant no case for using strlcpy or anything such either.</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;6953fde7adae0&quot;}" data-wp-interactive="core/image" data-wp-key="6953fde7adae0"><img decoding="async" width="2668" height="1501" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://daniel.haxx.se/blog/wp-content/uploads/2025/12/Screenshot-2025-12-29-at-17-08-28-curl-Project-status-dashboard.png" alt=""><figcaption>strncpy density in curl over time</figcaption></figure>
</div>


<h2>But strcpy?</h2>



<p>strcpy however, has its valid uses and it has a less bad and confusing API. The main challenge with strcpy is that when using it we do not specify the length of the target buffer nor of the source string.</p>



<p>This is normally not a problem because in a C program <code>strcpy</code> should only be used when we have full control of both.</p>



<p>But <em>normally</em> and <em>always</em> are not necessarily the same thing. We are but all human and we all do mistakes. Using strcpy implies that there is at least one or maybe two, buffer size checks done prior to the function invocation. In a good situation.</p>



<p>Over time however – let’s imagine we have code that lives on for decades – when code is maintained, patched, improved and polished by many different authors with different mindsets and approaches, those size checks and the function invoke may glide apart. The further away from each other they go, the bigger is the risk that something happens in between that nullifies one of the checks or changes the conditions for the strcpy.</p>



<h2>Enforce checks close to code</h2>



<p>To make sure that the size checks cannot be separated from the copy itself we introduced a string copy replacement function the other day that takes the <em>target buffer</em>, <em>target size</em>, <em>source buffer</em> and <em>source string length</em> as arguments and only if the copy can be made and the null terminator also fits there, the operation is done.</p>



<p>This made it possible to implement the replacement using memcpy(). Now we can completely ban the use of strcpy in curl source code, like we already did strncpy.</p>



<p>Using this function version is a little more work and more cumbersome than strcpy since it needs more information, but we believe the upsides of this approach will help us have an oversight for the extra pain involved. I suppose we will see how that will fare down the road. Let’s come back in a decade and see how things developed!</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;6953fde7addec&quot;}" data-wp-interactive="core/image" data-wp-key="6953fde7addec"><img loading="lazy" decoding="async" width="2668" height="1501" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://daniel.haxx.se/blog/wp-content/uploads/2025/12/Screenshot-2025-12-29-at-17-08-50-curl-Project-status-dashboard.png" alt=""><figcaption>strcpy density in curl over time</figcaption></figure>
</div>


<pre>void curlx_strcopy(char *dest,<br>                   size_t dsize,<br>                   const char *src,<br>                   size_t slen)<br>{<br>  DEBUGASSERT(slen &lt; dsize);<br>  if(slen &lt; dsize) {<br>    memcpy(dest, src, slen);<br>    dest[slen] = 0;<br>  }<br>  else if(dsize)<br>    dest[0] = 0;<br>}</pre>



<p><a href="https://github.com/curl/curl/blob/master/lib/curlx/strcopy.c">the strcopy source</a></p>



<h2>AI slop</h2>



<p>An additional minor positive side-effect of this change is of course that this should effectively prevent the AI chatbots to report strcpy uses in curl source code and insist it is insecure if anyone would ask (as people still apparently do). It has been proven numerous times already that strcpy in source code is like a honey pot for generating hallucinated vulnerability claims.</p>



<p>Still, this will just make them find something else to make up a report about, so there is probably no net gain. AI slop is not a game we can win.</p>
	</div><!-- .entry-content -->
	
	</article><!-- #post-28909 -->
		<nav>
		<h2>
			Post navigation		</h2>
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>curl, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The British empire's resilient subsea telegraph network (160 pts)]]></title>
            <link>https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html</link>
            <guid>46432999</guid>
            <pubDate>Tue, 30 Dec 2025 13:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html">https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html</a>, See on <a href="https://news.ycombinator.com/item?id=46432999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="2" id="Blog1">
<article>
<div>

<h3>
The British Empire's Resilient Subsea Telegraph Network
</h3>


<div id="post-body-484312278907445582">
<p>The British empire had largely completed its Red Line cable network by 1902. This network allowed news and messages to be delivered in a few minutes or several hours at most depending on the message queue's length. It spanned the globe and formed a network ring so traffic could be routed in the opposite direction in case of disruption. It was, as <a data-entity-urn="urn:li:fsd_profile:ACoAAA4yq5YBSeoQka__LIW-DUSY96qYhels8bY" data-guid="0" data-object-urn="urn:li:fsd_profile:ACoAAA4yq5YBSeoQka__LIW-DUSY96qYhels8bY" data-original-text="Dr. Michael Delaunay" data-test-ql-mention="true" href="https://www.linkedin.com/in/roderick-beck-94868948/recent-activity/all/#" spellcheck="false">Dr. Michael Delaunay</a> has argued, a highly resilient network. Besides the ring configuration, the network relied on multiple cables between any pair of given end points to ensure uptime. The British military believed it would be impossible for an enemy to cut enough cables on any route to sever all communications between any given pair of  end points. The Committee of Imperial Defense concluded that 57 cables must be shut down to isolate the British Isles from the Red Line network. The figure was 15 for Canada and 7 for South Africa. The Empire was self sufficient in terms of manufacturing the components for a subsea telegraph cable and repairing it. Its navy had no peers.&nbsp;</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxdPUjhIYaHDXjA8B4dWPTlz5TKHwnpqte-GoEjTBvZWTPhBx3_qHDi_3mIXODUB1G8M0iHBNA4B5PMBkSLJOVTfrHbVSrSe8eb6YGiHyPymziABkD9cWnf4ADsVuAFCo9gNXXcrNB4OViNqouOdMCBdLFFqhoOqe6ze6wvcLcwQpD9gvqbZF_UgP6-qk/s1100/1902AllRedLineMap.jpg" imageanchor="1"><img alt="Map of the British Empires Global Telegraph Network" data-original-height="649" data-original-width="1100" height="378" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxdPUjhIYaHDXjA8B4dWPTlz5TKHwnpqte-GoEjTBvZWTPhBx3_qHDi_3mIXODUB1G8M0iHBNA4B5PMBkSLJOVTfrHbVSrSe8eb6YGiHyPymziABkD9cWnf4ADsVuAFCo9gNXXcrNB4OViNqouOdMCBdLFFqhoOqe6ze6wvcLcwQpD9gvqbZF_UgP6-qk/w640-h378/1902AllRedLineMap.jpg" title="Map of the British Empires Global Telegraph Network" width="640"></a></p><br>
</div>

</div>


</article>
</div><div data-version="2" id="PopularPosts1">
<h3>
Popular posts from this blog
</h3>
<div role="feed">
<article role="article">
<h3><a href="https://subseacables.blogspot.com/2025/07/the-low-satellite-life-expectancy-of.html"> The Short Life Expectancy of Starlink's LEO Satellites</a></h3>

<div>
<p><a href="https://subseacables.blogspot.com/2025/07/the-low-satellite-life-expectancy-of.html">
<img alt="Image" sizes="72px" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWMYe9_pzc5BqF3HvoyzUWJSYunhu3xNOXCb_d2Ue0y0VZvhsqRCTaTLye2-ZkkzR_PWHefM5w8sNPwIwlTVG_FwxOTsiDbYFmMuf29xIPz6CHflw_APvWHPzoWNOfZm9wYo9St38ZH6B1zgn0PXPltaHAj3FhcUUgcBBvkF2b5PsWvmTsMnr444DE90A/w640-h426/falcon-9-1404x936.jpeg" srcset="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWMYe9_pzc5BqF3HvoyzUWJSYunhu3xNOXCb_d2Ue0y0VZvhsqRCTaTLye2-ZkkzR_PWHefM5w8sNPwIwlTVG_FwxOTsiDbYFmMuf29xIPz6CHflw_APvWHPzoWNOfZm9wYo9St38ZH6B1zgn0PXPltaHAj3FhcUUgcBBvkF2b5PsWvmTsMnr444DE90A/w72-h72-p-k-no-nu/falcon-9-1404x936.jpeg 72w, https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWMYe9_pzc5BqF3HvoyzUWJSYunhu3xNOXCb_d2Ue0y0VZvhsqRCTaTLye2-ZkkzR_PWHefM5w8sNPwIwlTVG_FwxOTsiDbYFmMuf29xIPz6CHflw_APvWHPzoWNOfZm9wYo9St38ZH6B1zgn0PXPltaHAj3FhcUUgcBBvkF2b5PsWvmTsMnr444DE90A/w144-h144-p-k-no-nu/falcon-9-1404x936.jpeg 144w">
</a>
</p>
<div>
<p>
According to FCC filings Starlink shut down almost 500 Starlink satellites during the first half of 2025. The company had them reenter the atmosphere where they burned up. What is striking is that these satellites were all less than 5 years old. The general consensus is that LEOs have a life expectancy ranging from 5 to 8 years. Shorter than expected life spans for the satellites will hit Starlink's income statement hard by increasing network depreciation and replacement needs. However, Starlink has managed to lower its LEO's manufacturing costs down to $500K versus initial figures around $1 million. So these production economies of scale might offset some of the higher than expected depreciation. However, there are also rocket launch costs as well. It costs Starlink about $3 million to put a satellite into orbit. The Falcon 9 costs $67 million per flight and delivers 23 LEOs into low Earth orbit. As a private company Starlink financials are a bit of mystery. The company press ...
</p>
</div>

</div>
</article>
<article role="article">
<h3><a href="https://subseacables.blogspot.com/2025/09/here-we-go-again-several-major-cables.html"> Here We Go Again: Several Major Cables Down Off Yemen</a></h3>

<div>
<p><a href="https://subseacables.blogspot.com/2025/09/here-we-go-again-several-major-cables.html">
<img alt="Image" sizes="72px" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg11Ssf5eFDtxAtUDVGnkhlCsmFop48R2dks5mUajwyMMBSHFO0d4xCAQsFtBKcx5K0c5zDW6m5DGwN7yc8XHApwsw4ehTuVdsdgN0zu-nGK9GSmXu0FeIGPJSyJeWUqgFg0zm1r8d1rliIV90GZ-YQFbQk0X5vQScD_oMgMR4ZLE9EDrPtJcA6rnyw2WY/w640-h402/Screenshot%202025-09-07%20204019.png" srcset="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg11Ssf5eFDtxAtUDVGnkhlCsmFop48R2dks5mUajwyMMBSHFO0d4xCAQsFtBKcx5K0c5zDW6m5DGwN7yc8XHApwsw4ehTuVdsdgN0zu-nGK9GSmXu0FeIGPJSyJeWUqgFg0zm1r8d1rliIV90GZ-YQFbQk0X5vQScD_oMgMR4ZLE9EDrPtJcA6rnyw2WY/w72-h72-p-k-no-nu/Screenshot%202025-09-07%20204019.png 72w, https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg11Ssf5eFDtxAtUDVGnkhlCsmFop48R2dks5mUajwyMMBSHFO0d4xCAQsFtBKcx5K0c5zDW6m5DGwN7yc8XHApwsw4ehTuVdsdgN0zu-nGK9GSmXu0FeIGPJSyJeWUqgFg0zm1r8d1rliIV90GZ-YQFbQk0X5vQScD_oMgMR4ZLE9EDrPtJcA6rnyw2WY/w144-h144-p-k-no-nu/Screenshot%202025-09-07%20204019.png 144w">
</a>
</p>
<div>
<p>
Three industry insiders have confirmed the 'epicenter' of the outages is in Yemen coastal waters at a depth of only one 100 meters. This strongly suggests fishing or more likely an anchor is responsible. Multiple sources have told me that neither Egyptian or Saudi Internet services has been degraded, but the Persian Gulf has been hit hard as well as Pakistan. This is consistent with the epicenter being off Yemen. It is also consistent with the cables reported down below. Four Cables Definitely Down: 1. EIG. 2. SWM4. 3. IMEWE. 4. Falcon Lower left map is SMW4. Center is EIG. Far right is IMEWE. Total capacity of these four cables is approximately 44 Tbps. Pakistan is heavily dependent on SWM4, EIG, and IMEWE. Scattered reports initially suggest AAE1 may also be down. But it is not.
</p>
</div>

</div>
</article>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Approachable Swift Concurrency (158 pts)]]></title>
            <link>https://fuckingapproachableswiftconcurrency.com/en/</link>
            <guid>46432916</guid>
            <pubDate>Tue, 30 Dec 2025 13:01:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fuckingapproachableswiftconcurrency.com/en/">https://fuckingapproachableswiftconcurrency.com/en/</a>, See on <a href="https://news.ycombinator.com/item?id=46432916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<div id="async-await">
<h2><a href="#async-await">Async Code: async/await</a></h2>
<p>Most of what apps do is wait. Fetch data from a server - wait for the response. Read a file from disk - wait for the bytes. Query a database - wait for the results.</p>
<p>Before Swift's concurrency system, you'd express this waiting with callbacks, delegates, or <a href="https://developer.apple.com/documentation/combine">Combine</a>. They work, but nested callbacks get hard to follow, and Combine has a steep learning curve.</p>
<p><code>async/await</code> gives Swift a new way to handle waiting. Instead of callbacks, you write code that looks sequential - it pauses, waits, and resumes. Under the hood, Swift's runtime manages these pauses efficiently. But making your app actually stay responsive while waiting depends on <em>where</em> code runs, which we'll cover later.</p>
<p>An <strong>async function</strong> is one that might need to pause. You mark it with <code>async</code>, and when you call it, you use <code>await</code> to say "pause here until this finishes":</p>
<pre><code><span>func</span> <span>fetchUser</span><span>(</span>id<span>:</span> <span>Int</span><span>)</span> <span>async</span> <span>throws</span> <span>-&gt;</span> <span>User</span> <span>{</span>
    <span>let</span> url <span>=</span> <span>URL</span><span>(</span>string<span>:</span> <span><span>"https://api.example.com/users/</span><span>\(</span><span>id</span><span>)</span><span>"</span></span><span>)</span><span>!</span>
    <span>let</span> <span>(</span>data<span>,</span> <span>_</span><span>)</span> <span>=</span> <span>try</span> <span>await</span> <span>URLSession</span><span>.</span>shared<span>.</span><span>data</span><span>(</span>from<span>:</span> url<span>)</span>  <span>// Suspends here</span>
    <span>return</span> <span>try</span> <span>JSONDecoder</span><span>(</span><span>)</span><span>.</span><span>decode</span><span>(</span><span>User</span><span>.</span><span>self</span><span>,</span> from<span>:</span> data<span>)</span>
<span>}</span>

<span>// Calling it</span>
<span>let</span> user <span>=</span> <span>try</span> <span>await</span> <span>fetchUser</span><span>(</span>id<span>:</span> <span>123</span><span>)</span>
<span>// Code here runs after fetchUser completes</span></code></pre>
<p>Your code pauses at each <code>await</code> - this is called <strong>suspension</strong>. When the work finishes, your code resumes right where it left off. Suspension gives Swift the opportunity to do other work while waiting.</p>
<h3>Waiting for <em>them</em></h3>
<p>What if you need to fetch several things? You could await them one by one:</p>
<pre><code><span>let</span> avatar <span>=</span> <span>try</span> <span>await</span> <span>fetchImage</span><span>(</span><span><span>"avatar.jpg"</span></span><span>)</span>
<span>let</span> banner <span>=</span> <span>try</span> <span>await</span> <span>fetchImage</span><span>(</span><span><span>"banner.jpg"</span></span><span>)</span>
<span>let</span> bio <span>=</span> <span>try</span> <span>await</span> <span>fetchBio</span><span>(</span><span>)</span></code></pre>
<p>But that's slow - each waits for the previous one to finish. Use <code>async let</code> to run them in parallel:</p>
<pre><code><span>func</span> <span>loadProfile</span><span>(</span><span>)</span> <span>async</span> <span>throws</span> <span>-&gt;</span> <span>Profile</span> <span>{</span>
    <span>async</span> <span>let</span> avatar <span>=</span> <span>fetchImage</span><span>(</span><span><span>"avatar.jpg"</span></span><span>)</span>
    <span>async</span> <span>let</span> banner <span>=</span> <span>fetchImage</span><span>(</span><span><span>"banner.jpg"</span></span><span>)</span>
    <span>async</span> <span>let</span> bio <span>=</span> <span>fetchBio</span><span>(</span><span>)</span>

    <span>// All three are fetching in parallel!</span>
    <span>return</span> <span>Profile</span><span>(</span>
        avatar<span>:</span> <span>try</span> <span>await</span> avatar<span>,</span>
        banner<span>:</span> <span>try</span> <span>await</span> banner<span>,</span>
        bio<span>:</span> <span>try</span> <span>await</span> bio
    <span>)</span>
<span>}</span></code></pre>
<p>Each <code>async let</code> starts immediately. The <code>await</code> collects the results.</p>
<div>
<h4>await needs async</h4>
<p>You can only use <code>await</code> inside an <code>async</code> function.</p>
</div>
  </div>
<div id="tasks">
<h2><a href="#tasks">Managing Work: Tasks</a></h2>
<p>A <strong><a href="https://developer.apple.com/documentation/swift/task">Task</a></strong> is a unit of async work you can manage. You've written async functions, but a Task is what actually runs them. It's how you start async code from synchronous code, and it gives you control over that work: wait for its result, cancel it, or let it run in the background.</p>
<p>Let's say you're building a profile screen. Load the avatar when the view appears using the <a href="https://developer.apple.com/documentation/swiftui/view/task(priority:_:)"><code>.task</code></a> modifier, which cancels automatically when the view disappears:</p>
<pre><code><span>struct</span> <span>ProfileView</span><span>:</span> <span>View</span> <span>{</span>
    <span>@State</span> <span>private</span> <span>var</span> avatar<span>:</span> <span>Image</span><span>?</span>

    <span>var</span> body<span>:</span> <span>some</span> <span>View</span> <span>{</span>
        avatar
            <span>.</span>task <span>{</span> avatar <span>=</span> <span>await</span> <span>downloadAvatar</span><span>(</span><span>)</span> <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<p>If users can switch between profiles, use <code>.task(id:)</code> to reload when the selection changes:</p>
<pre><code><span>struct</span> <span>ProfileView</span><span>:</span> <span>View</span> <span>{</span>
    <span>var</span> userID<span>:</span> <span>String</span>
    <span>@State</span> <span>private</span> <span>var</span> avatar<span>:</span> <span>Image</span><span>?</span>

    <span>var</span> body<span>:</span> <span>some</span> <span>View</span> <span>{</span>
        avatar
            <span>.</span><span>task</span><span>(</span>id<span>:</span> userID<span>)</span> <span>{</span> avatar <span>=</span> <span>await</span> <span>downloadAvatar</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<p>When the user taps "Save", create a Task manually:</p>
<pre><code><span>Button</span><span>(</span><span><span>"Save"</span></span><span>)</span> <span>{</span>
    <span>Task</span> <span>{</span> <span>await</span> <span>saveProfile</span><span>(</span><span>)</span> <span>}</span>
<span>}</span></code></pre>
<p>What if you need to load the avatar, bio, and stats all at once? Use a <a href="https://developer.apple.com/documentation/swift/taskgroup"><code>TaskGroup</code></a> to fetch them in parallel:</p>
<pre><code><span>try</span> <span>await</span> <span>withThrowingTaskGroup</span><span>(</span>of<span>:</span> <span>Void</span><span>.</span><span>self</span><span>)</span> <span>{</span> group <span>in</span>
    group<span>.</span>addTask <span>{</span> avatar <span>=</span> <span>try</span> <span>await</span> <span>downloadAvatar</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    group<span>.</span>addTask <span>{</span> bio <span>=</span> <span>try</span> <span>await</span> <span>fetchBio</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    group<span>.</span>addTask <span>{</span> stats <span>=</span> <span>try</span> <span>await</span> <span>fetchStats</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    <span>try</span> <span>await</span> group<span>.</span><span>waitForAll</span><span>(</span><span>)</span>
<span>}</span></code></pre>
<p>Tasks inside a group are <strong>child tasks</strong>, linked to the parent. A few things to know:</p>
<ul>
<li><strong>Cancellation propagates</strong>: cancel the parent, and all children get cancelled too</li>
<li><strong>Errors</strong>: a thrown error cancels siblings and rethrows, but only when you consume results with <code>next()</code>, <code>waitForAll()</code>, or iteration</li>
<li><strong>Completion order</strong>: results arrive as tasks finish, not the order you added them</li>
<li><strong>Waits for all</strong>: the group doesn't return until every child completes or is cancelled</li>
</ul>
<p>This is <strong><a href="https://developer.apple.com/videos/play/wwdc2021/10134/">structured concurrency</a></strong>: work organized in a tree that's easy to reason about and clean up.</p>
  </div>
<div id="execution">
<h2><a href="#execution">Where Things Run: From Threads to Isolation Domains</a></h2>
<p>So far we've talked about <em>when</em> code runs (async/await) and <em>how to organize</em> it (Tasks). Now: <strong>where does it run, and how do we keep it safe?</strong></p>
<div>
<h4>Most apps just wait</h4>
<p>Most app code is <strong>I/O-bound</strong>. You fetch data from a network, <em>await</em> a response, decode it, and display it. If you have multiple I/O operations to coordinate, you resort to <em>tasks</em> and <em>task groups</em>. The actual CPU work is minimal. The main thread can handle this fine because <code>await</code> suspends without blocking.</p>
<p>But sooner or later, you'll have <strong>CPU-bound work</strong>: parsing a giant JSON file, processing images, running complex calculations. This work doesn't wait for anything external. It just needs CPU cycles. If you run it on the main thread, your UI freezes. This is where "where does code run" actually matters.</p>
</div>
<h3>The Old World: Many Options, No Safety</h3>
<p>Before Swift's concurrency system, you had several ways to manage execution:</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>What it does</th>
<th>Tradeoffs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://developer.apple.com/documentation/foundation/thread">Thread</a></td>
<td>Direct thread control</td>
<td>Low-level, error-prone, rarely needed</td>
</tr>
<tr>
<td><a href="https://developer.apple.com/documentation/dispatch">GCD</a></td>
<td>Dispatch queues with closures</td>
<td>Simple but no cancellation, easy to cause thread explosion</td>
</tr>
<tr>
<td><a href="https://developer.apple.com/documentation/foundation/operationqueue">OperationQueue</a></td>
<td>Task dependencies, cancellation, KVO</td>
<td>More control but verbose and heavyweight</td>
</tr>
<tr>
<td><a href="https://developer.apple.com/documentation/combine">Combine</a></td>
<td>Reactive streams</td>
<td>Great for event streams, steep learning curve</td>
</tr>
</tbody>
</table>
<p>All of these worked, but safety was entirely on you. The compiler couldn't help if you forgot to dispatch to main, or if two queues accessed the same data simultaneously.</p>
<h3>The Problem: Data Races</h3>
<p>A <a href="https://developer.apple.com/documentation/xcode/data-race">data race</a> happens when two threads access the same memory at the same time, and at least one is writing:</p>
<pre><code><span>var</span> count <span>=</span> <span>0</span>

<span>DispatchQueue</span><span>.</span><span>global</span><span>(</span><span>)</span><span>.</span><span>async</span> <span>{</span> count <span>+=</span> <span>1</span> <span>}</span>
<span>DispatchQueue</span><span>.</span><span>global</span><span>(</span><span>)</span><span>.</span><span>async</span> <span>{</span> count <span>+=</span> <span>1</span> <span>}</span>

<span>// Undefined behavior: crash, memory corruption, or wrong value</span></code></pre>
<p>Data races are undefined behavior. They can crash, corrupt memory, or silently produce wrong results. Your app works fine in testing, then crashes randomly in production. Traditional tools like locks and semaphores help, but they're manual and error-prone.</p>
<div>
<h4>Concurrency amplifies the problem</h4>
<p>The more concurrent your app is, the more likely data races become. A simple iOS app might get away with sloppy thread safety. A web server handling thousands of simultaneous requests will crash constantly. This is why Swift's compile-time safety matters most in high-concurrency environments.</p>
</div>
<h3>The Shift: From Threads to Isolation</h3>
<p>Swift's concurrency model asks a different question. Instead of "which thread should this run on?", it asks: <strong>"who is allowed to access this data?"</strong></p>
<p>This is <a href="https://developer.apple.com/documentation/swift/isolation">isolation</a>. Rather than manually dispatching work to threads, you declare boundaries around data. The compiler enforces these boundaries at build time, not runtime.</p>
<div>
<h4>Under the hood</h4>
<p>Swift Concurrency is built on top of <a href="https://github.com/swiftlang/swift-corelibs-libdispatch">libdispatch</a> (the same runtime as GCD). The difference is the compile-time layer: actors and isolation are enforced by the compiler, while the runtime handles scheduling on a <a href="https://developer.apple.com/videos/play/wwdc2021/10254/">cooperative thread pool</a> limited to your CPU's core count.</p>
</div>
<h3>The Three Isolation Domains</h3>
<p><strong>1. MainActor</strong></p>
<p><a href="https://developer.apple.com/documentation/swift/mainactor"><code>@MainActor</code></a> is a <a href="https://developer.apple.com/documentation/swift/globalactor">global actor</a> that represents the main thread's isolation domain. It's special because UI frameworks (UIKit, AppKit, SwiftUI) require main thread access.</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>var</span> items<span>:</span> <span>[</span><span>Item</span><span>]</span> <span>=</span> <span>[</span><span>]</span>  <span>// Protected by MainActor isolation</span>
<span>}</span></code></pre>
<p>When you mark something <code>@MainActor</code>, you're not saying "dispatch this to the main thread." You're saying "this belongs to the main actor's isolation domain." The compiler enforces that anything accessing it must either be on MainActor or <code>await</code> to cross the boundary.</p>
<div>
<h4>When in doubt, use @MainActor</h4>
<p>For most apps, marking your ViewModels with <code>@MainActor</code> is the right choice. Performance concerns are usually overblown. Start here, optimize only if you measure actual problems.</p>
</div>
<p><strong>2. Actors</strong></p>
<p>An <a href="https://developer.apple.com/documentation/swift/actor">actor</a> protects its own mutable state. It guarantees that only one piece of code can access its data at a time:</p>
<pre><code><span>actor</span> <span>BankAccount</span> <span>{</span>
    <span>var</span> balance<span>:</span> <span>Double</span> <span>=</span> <span>0</span>

    <span>func</span> <span>deposit</span><span>(</span><span>_</span> amount<span>:</span> <span>Double</span><span>)</span> <span>{</span>
        balance <span>+=</span> amount  <span>// Safe: actor guarantees exclusive access</span>
    <span>}</span>
<span>}</span>

<span>// From outside, you must await to cross the boundary</span>
<span>await</span> account<span>.</span><span>deposit</span><span>(</span><span>100</span><span>)</span></code></pre>
<p><strong>Actors are not threads.</strong> An actor is an isolation boundary. The Swift runtime decides which thread actually executes actor code. You don't control that, and you don't need to.</p>
<p><strong>3. Nonisolated</strong></p>
<p>Code marked <a href="https://developer.apple.com/documentation/swift/nonisolated"><code>nonisolated</code></a> opts out of actor isolation. It can be called from anywhere without <code>await</code>, but it cannot access the actor's protected state:</p>
<pre><code><span>actor</span> <span>BankAccount</span> <span>{</span>
    <span>var</span> balance<span>:</span> <span>Double</span> <span>=</span> <span>0</span>

    <span>nonisolated</span> <span>func</span> <span>bankName</span><span>(</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span><span>"Acme Bank"</span></span>  <span>// No actor state accessed, safe to call from anywhere</span>
    <span>}</span>
<span>}</span>

<span>let</span> name <span>=</span> account<span>.</span><span>bankName</span><span>(</span><span>)</span>  <span>// No await needed</span></code></pre>
<div>
<h4>Approachable Concurrency: Less Friction</h4>
<p><a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a> simplifies the mental model with two Xcode build settings:</p>
<ul>
<li><strong><code>SWIFT_DEFAULT_ACTOR_ISOLATION</code></strong> = <code>MainActor</code>: Everything runs on MainActor unless you say otherwise</li>
<li><strong><code>SWIFT_APPROACHABLE_CONCURRENCY</code></strong> = <code>YES</code>: <code>nonisolated</code> async functions stay on the caller's actor instead of jumping to a background thread</li>
</ul>
<p>New Xcode 26 projects have both enabled by default. When you need CPU-intensive work off the main thread, use <code>@concurrent</code>.</p>
<pre><code>// Runs on MainActor (the default)
func updateUI() async { }

// Runs on background thread (opt-in)
@concurrent func processLargeFile() async { }</code></pre>
</div>
<div>
<h4>The Office Building</h4>
<p>Think of your app as an office building. Each <strong>isolation domain</strong> is a private office with a lock on the door. Only one person can be inside at a time, working with the documents in that office.</p>
<ul>
<li><strong><code>MainActor</code></strong> is the front desk - where all customer interactions happen. There's only one, and it handles everything the user sees.</li>
<li><strong><code>actor</code></strong> types are department offices - Accounting, Legal, HR. Each protects its own sensitive documents.</li>
<li><strong><code>nonisolated</code></strong> code is the hallway - shared space anyone can walk through, but no private documents live there.</li>
</ul>
<p>You can't just barge into someone's office. You knock (<code>await</code>) and wait for them to let you in.</p>
</div>
  </div>
<div id="sendable">
<h2><a href="#sendable">What Can Cross Isolation Domains: Sendable</a></h2>
<p>Isolation domains protect data, but eventually you need to pass data between them. When you do, Swift checks if it's safe.</p>
<p>Think about it: if you pass a reference to a mutable class from one actor to another, both actors could modify it simultaneously. That's exactly the data race we're trying to prevent. So Swift needs to know: can this data be safely shared?</p>
<p>The answer is the <a href="https://developer.apple.com/documentation/swift/sendable"><code>Sendable</code></a> protocol. It's a marker that tells the compiler "this type is safe to pass across isolation boundaries":</p>
<ul>
<li><strong>Sendable</strong> types can cross safely (value types, immutable data, actors)</li>
<li><strong>Non-Sendable</strong> types can't (classes with mutable state)</li>
</ul>
<pre><code><span>// Sendable - it's a value type, each place gets a copy</span>
<span>struct</span> <span>User</span><span>:</span> <span>Sendable</span> <span>{</span>
    <span>let</span> id<span>:</span> <span>Int</span>
    <span>let</span> name<span>:</span> <span>String</span>
<span>}</span>

<span>// Non-Sendable - it's a class with mutable state</span>
<span>class</span> <span>Counter</span> <span>{</span>
    <span>var</span> count <span>=</span> <span>0</span>  <span>// Two places modifying this = disaster</span>
<span>}</span></code></pre>
<h3>Making Types Sendable</h3>
<p>Swift automatically infers <code>Sendable</code> for many types:</p>
<ul>
<li><strong>Structs and enums</strong> with only <code>Sendable</code> properties are implicitly <code>Sendable</code></li>
<li><strong>Actors</strong> are always <code>Sendable</code> because they protect their own state</li>
<li><strong><code>@MainActor</code> types</strong> are <code>Sendable</code> because MainActor serializes access</li>
</ul>
<p>For classes, it's harder. A class can conform to <code>Sendable</code> only if it's <code>final</code> and all its stored properties are immutable:</p>
<pre><code><span>final</span> <span>class</span> <span>APIConfig</span><span>:</span> <span>Sendable</span> <span>{</span>
    <span>let</span> baseURL<span>:</span> <span>URL</span>      <span>// Immutable</span>
    <span>let</span> timeout<span>:</span> <span>Double</span>   <span>// Immutable</span>
<span>}</span></code></pre>
<p>If you have a class that's thread-safe through other means (locks, atomics), you can use <a href="https://developer.apple.com/documentation/swift/uncheckedsendable"><code>@unchecked Sendable</code></a> to tell the compiler "trust me":</p>
<pre><code><span>final</span> <span>class</span> <span>ThreadSafeCache</span><span>:</span> <span>@unchecked</span> <span>Sendable</span> <span>{</span>
    <span>private</span> <span>let</span> lock <span>=</span> <span>NSLock</span><span>(</span><span>)</span>
    <span>private</span> <span>var</span> storage<span>:</span> <span>[</span><span>String</span><span>:</span> <span>Data</span><span>]</span> <span>=</span> <span>[</span><span>:</span><span>]</span>
<span>}</span></code></pre>
<div>
<h4>@unchecked Sendable is a promise</h4>
<p>The compiler won't verify thread safety. If you're wrong, you'll get data races. Use sparingly.</p>
</div>
<div>
<h4>Approachable Concurrency: Less Friction</h4>
<p>With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a>, Sendable errors become much rarer:</p>
<ul>
<li>If code doesn't cross isolation boundaries, you don't need Sendable</li>
<li>Async functions stay on the caller's actor instead of hopping to a background thread</li>
<li>The compiler is smarter about detecting when values are used safely</li>
</ul>
<p>Enable it by setting <code>SWIFT_DEFAULT_ACTOR_ISOLATION</code> to <code>MainActor</code> and <code>SWIFT_APPROACHABLE_CONCURRENCY</code> to <code>YES</code>. New Xcode 26 projects have both enabled by default. When you do need parallelism, mark functions <code>@concurrent</code> and then think about Sendable.</p>
</div>
<div>
<h4>Photocopies vs. Original Documents</h4>
<p>Back to the office building. When you need to share information between departments:</p>
<ul>
<li><strong>Photocopies are safe</strong> - If Legal makes a copy of a document and sends it to Accounting, both have their own copy. They can scribble on them, modify them, whatever. No conflict.</li>
<li><strong>Original signed contracts must stay put</strong> - If two departments could both modify the original, chaos ensues. Who has the real version?</li>
</ul>
<p><code>Sendable</code> types are like photocopies: safe to share because each place gets its own independent copy (value types) or because they're immutable (nobody can modify them). Non-<code>Sendable</code> types are like original contracts: passing them around creates the potential for conflicting modifications.</p>
</div>
  </div>
<div id="isolation-inheritance">
<h2><a href="#isolation-inheritance">How Isolation Is Inherited</a></h2>
<p>You've seen that isolation domains protect data, and Sendable controls what crosses between them. But how does code end up in an isolation domain in the first place?</p>
<p>When you call a function or create a closure, isolation flows through your code. With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a>, your app starts on <a href="https://developer.apple.com/documentation/swift/mainactor"><code>MainActor</code></a>, and that isolation propagates to the code you call, unless something explicitly changes it. Understanding this flow helps you predict where code runs and why the compiler sometimes complains.</p>
<h3>Function Calls</h3>
<p>When you call a function, its isolation determines where it runs:</p>
<pre><code><span>@MainActor</span> <span>func</span> <span>updateUI</span><span>(</span><span>)</span> <span>{</span> <span>}</span>      <span>// Always runs on MainActor</span>
<span>func</span> <span>helper</span><span>(</span><span>)</span> <span>{</span> <span>}</span>                    <span>// Inherits caller's isolation</span>
<span>@concurrent</span> <span>func</span> <span>crunch</span><span>(</span><span>)</span> <span>async</span> <span>{</span> <span>}</span>  <span>// Explicitly runs off-actor</span></code></pre>
<p>With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a>, most of your code inherits <code>MainActor</code> isolation. The function runs where the caller runs, unless it explicitly opts out.</p>
<h3>Closures</h3>
<p>Closures inherit isolation from the context where they're defined:</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>func</span> <span>setup</span><span>(</span><span>)</span> <span>{</span>
        <span>let</span> closure <span>=</span> <span>{</span>
            <span>// Inherits MainActor from ViewModel</span>
            <span>self</span><span>.</span><span>updateUI</span><span>(</span><span>)</span>  <span>// Safe, same isolation</span>
        <span>}</span>
        <span>closure</span><span>(</span><span>)</span>
    <span>}</span>
<span>}</span></code></pre>
<p>This is why SwiftUI's <code>Button</code> action closures can safely update <code>@State</code>: they inherit MainActor isolation from the view.</p>
<h3>Tasks</h3>
<p>A <code>Task { }</code> inherits actor isolation from where it's created:</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>func</span> <span>doWork</span><span>(</span><span>)</span> <span>{</span>
        <span>Task</span> <span>{</span>
            <span>// Inherits MainActor isolation</span>
            <span>self</span><span>.</span><span>updateUI</span><span>(</span><span>)</span>  <span>// Safe, no await needed</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<p>This is usually what you want. The task runs on the same actor as the code that created it.</p>
<h3>Breaking Inheritance: Task.detached</h3>
<p>Sometimes you want a task that doesn't inherit any context:</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>func</span> <span>doHeavyWork</span><span>(</span><span>)</span> <span>{</span>
        <span>Task</span><span>.</span>detached <span>{</span>
            <span>// No actor isolation, runs on cooperative pool</span>
            <span>let</span> result <span>=</span> <span>await</span> <span>self</span><span>.</span><span>expensiveCalculation</span><span>(</span><span>)</span>
            <span>await</span> <span>MainActor</span><span>.</span>run <span>{</span>
                <span>self</span><span>.</span>data <span>=</span> result  <span>// Explicitly hop back</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<div>
<h4>Task.detached is usually wrong</h4>
<p>The Swift team recommends <a href="https://forums.swift.org/t/revisiting-when-to-use-task-detached/57929">Task.detached as a last resort</a>. It doesn't inherit priority, task-local values, or actor context. Most of the time, regular <code>Task</code> is what you want. If you need CPU-intensive work off the main actor, mark the function <code>@concurrent</code> instead.</p>
</div>
<div>
<h4>Walking Through the Building</h4>
<p>When you're in the front desk office (MainActor), and you call someone to help you, they come to <em>your</em> office. They inherit your location. If you create a task ("go do this for me"), that assistant starts in your office too.</p>
<p>The only way someone ends up in a different office is if they explicitly go there: "I need to work in Accounting for this" (<code>actor</code>), or "I'll handle this in the back office" (<code>@concurrent</code>).</p>
</div>
  </div>
<div id="putting-it-together">
<h2><a href="#putting-it-together">Putting It All Together</a></h2>
<p>Let's step back and see how all the pieces fit.</p>
<p>Swift Concurrency can feel like a lot of concepts: <code>async/await</code>, <code>Task</code>, actors, <code>MainActor</code>, <code>Sendable</code>, isolation domains. But there's really just one idea at the center of it all: <strong>isolation is inherited by default</strong>.</p>
<p>With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a> enabled, your app starts on <a href="https://developer.apple.com/documentation/swift/mainactor"><code>MainActor</code></a>. That's your starting point. From there:</p>
<ul>
<li>Every function you call <strong>inherits</strong> that isolation</li>
<li>Every closure you create <strong>captures</strong> that isolation</li>
<li>Every <a href="https://developer.apple.com/documentation/swift/task"><code>Task { }</code></a> you spawn <strong>inherits</strong> that isolation</li>
</ul>
<p>You don't have to annotate anything. You don't have to think about threads. Your code runs on <code>MainActor</code>, and the isolation just propagates through your program automatically.</p>
<p>When you need to break out of that inheritance, you do it explicitly:</p>
<ul>
<li><strong><code>@concurrent</code></strong> says "run this on a background thread"</li>
<li><strong><code>actor</code></strong> says "this type has its own isolation domain"</li>
<li><strong><code>Task.detached { }</code></strong> says "start fresh, inherit nothing"</li>
</ul>
<p>And when you pass data between isolation domains, Swift checks that it's safe. That's what <a href="https://developer.apple.com/documentation/swift/sendable"><code>Sendable</code></a> is for: marking types that can safely cross boundaries.</p>
<p>That's it. That's the whole model:</p>
<ol>
<li><strong>Isolation propagates</strong> from <code>MainActor</code> through your code</li>
<li><strong>You opt out explicitly</strong> when you need background work or separate state</li>
<li><strong>Sendable guards the boundaries</strong> when data crosses between domains</li>
</ol>
<p>When the compiler complains, it's telling you one of these rules was violated. Trace the inheritance: where did the isolation come from? Where is the code trying to run? What data is crossing a boundary? The answer is usually obvious once you ask the right question.</p>
<h3>Where to Go From Here</h3>
<p>The good news: you don't need to master everything at once.</p>
<p><strong>Most apps only need the basics.</strong> Mark your ViewModels with <code>@MainActor</code>, use <code>async/await</code> for network calls, and create <code>Task { }</code> when you need to kick off async work from a button tap. That's it. That handles 80% of real-world apps. The compiler will tell you if you need more.</p>
<p><strong>When you need parallel work</strong>, reach for <code>async let</code> to fetch multiple things at once, or <a href="https://developer.apple.com/documentation/swift/taskgroup"><code>TaskGroup</code></a> when the number of tasks is dynamic. Learn to handle cancellation gracefully. This covers apps with complex data loading or real-time features.</p>
<p><strong>Advanced patterns come later</strong>, if ever. Custom actors for shared mutable state, <code>@concurrent</code> for CPU-intensive processing, deep <code>Sendable</code> understanding. This is framework code, server-side Swift, complex desktop apps. Most developers never need this level.</p>
<div>
<h4>Start simple</h4>
<p>Don't optimize for problems you don't have. Start with the basics, ship your app, and add complexity only when you hit real problems. The compiler will guide you.</p>
</div>
  </div>
<div id="mistakes">
<h2><a href="#mistakes">Watch Out: Common Mistakes</a></h2>
<h3>Thinking async = background</h3>
<pre><code><span>// This STILL blocks the main thread!</span>
<span>@MainActor</span>
<span>func</span> <span>slowFunction</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>let</span> result <span>=</span> <span>expensiveCalculation</span><span>(</span><span>)</span>  <span>// Synchronous work = blocking</span>
    data <span>=</span> result
<span>}</span></code></pre>
<p><code>async</code> means "can pause." The actual work still runs wherever it runs. Use <code>@concurrent</code> (Swift 6.2) or <code>Task.detached</code> for CPU-heavy work.</p>
<h3>Creating too many actors</h3>
<pre><code><span>// Over-engineered</span>
<span>actor</span> <span>NetworkManager</span> <span>{</span> <span>}</span>
<span>actor</span> <span>CacheManager</span> <span>{</span> <span>}</span>
<span>actor</span> <span>DataManager</span> <span>{</span> <span>}</span>

<span>// Better - most things can live on MainActor</span>
<span>@MainActor</span>
<span>class</span> <span>AppState</span> <span>{</span> <span>}</span></code></pre>
<p>You need a custom actor only when you have shared mutable state that can't live on <code>MainActor</code>. <a href="https://www.massicotte.org/actors/">Matt Massicotte's rule</a>: introduce an actor only when (1) you have non-<code>Sendable</code> state, (2) operations on that state must be atomic, and (3) those operations can't run on an existing actor. If you can't justify it, use <code>@MainActor</code> instead.</p>
<h3>Making everything Sendable</h3>
<p>Not everything needs to cross boundaries. If you're adding <code>@unchecked Sendable</code> everywhere, step back and ask if the data actually needs to move between isolation domains.</p>
<h3>Using MainActor.run when you don't need it</h3>
<pre><code><span>// Unnecessary</span>
<span>Task</span> <span>{</span>
    <span>let</span> data <span>=</span> <span>await</span> <span>fetchData</span><span>(</span><span>)</span>
    <span>await</span> <span>MainActor</span><span>.</span>run <span>{</span>
        <span>self</span><span>.</span>data <span>=</span> data
    <span>}</span>
<span>}</span>

<span>// Better - just make the function @MainActor</span>
<span>@MainActor</span>
<span>func</span> <span>loadData</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>self</span><span>.</span>data <span>=</span> <span>await</span> <span>fetchData</span><span>(</span><span>)</span>
<span>}</span></code></pre>
<p><code>MainActor.run</code> is rarely the right solution. If you need MainActor isolation, annotate the function with <code>@MainActor</code> instead. It's clearer and the compiler can help you more. See <a href="https://www.massicotte.org/problematic-patterns/">Matt's take on this</a>.</p>
<h3>Blocking the cooperative thread pool</h3>
<pre><code><span>// NEVER do this - risks deadlock</span>
<span>func</span> <span>badIdea</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>let</span> semaphore <span>=</span> <span>DispatchSemaphore</span><span>(</span>value<span>:</span> <span>0</span><span>)</span>
    <span>Task</span> <span>{</span>
        <span>await</span> <span>doWork</span><span>(</span><span>)</span>
        semaphore<span>.</span><span>signal</span><span>(</span><span>)</span>
    <span>}</span>
    semaphore<span>.</span><span>wait</span><span>(</span><span>)</span>  <span>// Blocks a cooperative thread!</span>
<span>}</span></code></pre>
<p>Swift's cooperative thread pool has limited threads. Blocking one with <code>DispatchSemaphore</code>, <code>DispatchGroup.wait()</code>, or similar calls can cause deadlocks. If you need to bridge sync and async code, use <code>async let</code> or restructure to stay fully async.</p>
<h3>Creating unnecessary Tasks</h3>
<pre><code><span>// Unnecessary Task creation</span>
<span>func</span> <span>fetchAll</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>Task</span> <span>{</span> <span>await</span> <span>fetchUsers</span><span>(</span><span>)</span> <span>}</span>
    <span>Task</span> <span>{</span> <span>await</span> <span>fetchPosts</span><span>(</span><span>)</span> <span>}</span>
<span>}</span>

<span>// Better - use structured concurrency</span>
<span>func</span> <span>fetchAll</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>async</span> <span>let</span> users <span>=</span> <span>fetchUsers</span><span>(</span><span>)</span>
    <span>async</span> <span>let</span> posts <span>=</span> <span>fetchPosts</span><span>(</span><span>)</span>
    <span>await</span> <span>(</span>users<span>,</span> posts<span>)</span>
<span>}</span></code></pre>
<p>If you're already in an async context, prefer structured concurrency (<code>async let</code>, <code>TaskGroup</code>) over creating unstructured <code>Task</code>s. Structured concurrency handles cancellation automatically and makes the code easier to reason about.</p>
  </div>
<div id="glossary">
<h2><a href="#glossary">Cheat Sheet: Quick Reference</a></h2>
<table>
<thead>
<tr>
<th>Keyword</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>async</code></td>
<td>Function can pause</td>
</tr>
<tr>
<td><code>await</code></td>
<td>Pause here until done</td>
</tr>
<tr>
<td><code>Task { }</code></td>
<td>Start async work, inherits context</td>
</tr>
<tr>
<td><code>Task.detached { }</code></td>
<td>Start async work, no inherited context</td>
</tr>
<tr>
<td><code>@MainActor</code></td>
<td>Runs on main thread</td>
</tr>
<tr>
<td><code>actor</code></td>
<td>Type with isolated mutable state</td>
</tr>
<tr>
<td><code>nonisolated</code></td>
<td>Opts out of actor isolation</td>
</tr>
<tr>
<td><code>Sendable</code></td>
<td>Safe to pass between isolation domains</td>
</tr>
<tr>
<td><code>@concurrent</code></td>
<td>Always run on background (Swift 6.2+)</td>
</tr>
<tr>
<td><code>async let</code></td>
<td>Start parallel work</td>
</tr>
<tr>
<td><code>TaskGroup</code></td>
<td>Dynamic parallel work</td>
</tr>
</tbody>
</table>
<h2>Further Reading</h2>


  </div>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Times New American: A Tale of Two Fonts (211 pts)]]></title>
            <link>https://hsu.cy/2025/12/times-new-american/</link>
            <guid>46432862</guid>
            <pubDate>Tue, 30 Dec 2025 12:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hsu.cy/2025/12/times-new-american/">https://hsu.cy/2025/12/times-new-american/</a>, See on <a href="https://news.ycombinator.com/item?id=46432862">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>A less romantic truth is that aesthetic standards rarely travel alone; power tends to follow in their wake. An episode at the U.S. State Department this month makes exactly this point.</p>
<p>On December 9, Secretary of State Marco Rubio issued a memo titled “Return to Tradition” that <a href="https://www.nytimes.com/2025/12/09/us/politics/rubio-state-department-typeface.html">required</a> all State Department documents to switch back to 14-point Times New Roman, overturning a Biden-era <a href="https://www.washingtonpost.com/world/2023/01/18/state-department-times-new-roman-calibri/">directive</a> from 2023 that had turned to 15-point Calibri.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/2826e5fc02cb3a35ba040dce9a8b8c4f.jpg">
<figcaption>State Department correspondence in Calibri and Times New Roman (Credit: <em>The New York Times</em>)</figcaption>
</figure>
<p>Frankly, most people likely view both of these simply as “standard typefaces” without distinguishing much difference between them. So why would an institution of the State Department’s scale bother, twice in three years, to take a stance on something as seemingly trivial as a default typeface?</p>
<p>John Gruber, an Apple-sphere blogger with a well-known appetite for political commentary, obtained the <a href="https://daringfireball.net/misc/2025/12/state-department-return-to-tradition.text">full text</a> of Rubio’s memo and published it. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> (It is worth reading first.) Rubio’s rationale, in simplified form, has three parts. First, serif typefaces are said to better communicate professionalism, formality, and authority in official documents (¶¶ 6–8). Second, using a serif typeface is aligning with the White House, the courts, and the State Department’s own historical practice (¶ 9). Third, the 2023 decision was a “cosmetic” gesture associated with diversity, equity, inclusion, and accessibility (DEIA) politics, and the reversion a correction to that (¶ 10).</p>
<p>Commentary on American partisan politics is beyond the scope of this article. Still, in neutral terms, Trump’s second term has been marked by an <a href="https://www.pewresearch.org/short-reads/2025/12/16/trump-has-already-issued-more-executive-orders-in-his-second-term-than-in-his-first/">unusually rapid and sweeping effort</a> to repeal or reverse the prior administration’s policies, with DEIA among the earliest targets. The memo itself cites <a href="https://www.federalregister.gov/documents/2025/01/29/2025-01953/ending-radical-and-wasteful-government-dei-programs-and-preferencing">Executive Order 14151</a>, signed on the first day of the term, that instructed federal agencies to terminate all DEIA-related activities, offices, positions, policies, programs, and contracts.</p>
<p>That makes the political element of this typography decision fairly plain: it coheres with, and signals loyalty to, a broader anti-DEIA agenda. The remaining question is whether it is only politics. Put differently, how persuasive are Rubio’s first two, ostensibly nonpolitical claims about design and conventions? Or are they merely pretexts?</p>
<p>To recap, a <em>serif</em> typeface is one with extra decorative strokes, or “serifs,” at the ends of main strokes. A popular narrative links serifs to stone inscriptions: Roman craftsmen would sketch letter outlines on stone and carve along them; at stroke endings and corners, the chisel work flared outward, leaving the small protrusions we now call serifs. That lineage likely underwrites the memo’s association of serifs with “tradition,” “formality,” and “ceremony.”</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/60c7889a28a5b2c040d5a64ea32a7688.jpg">
<figcaption>A Roman stone inscription (Credit: <em>Wikipedia</em>)</figcaption>
</figure>
<p>However, most people don’t actually know this history, and many cannot reliably distinguish serif from sans-serif in the first place. The general public doesn’t perceive serif typefaces as professional and authoritative, <em>a priori</em>, before prioritizing their use in formal settings. Instead, people first observe that government, academia, and corporate workplaces disproportionately use serif faces — or are trained to use them — and only then infer that serifs must mean professionalism and authority.</p>
<p>Even if we limit ourselves to design and historical considerations, Times New Roman, despite being a serif typeface, possesses little of the “professional, solemn, and authoritative” aura. The typeface was designed in 1931 for <em>The Times</em> of London, and newspaper typefaces are typically engineered to print cleanly on cheap paper, conserve space, and support rapid scanning.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/0ef1b7bb8588fbdffff653d05a7b8c17.jpg">
<figcaption>Times New Roman on newsprint (<em>Wikipedia</em>)</figcaption>
</figure>
<p>Those goals are visible in the details. The strokes of Times New Roman are relatively thin (leaving tolerance for ink spread on newsprint), the letterforms are narrow, and the x-height (the height of the lowercase “x”) is comparatively large. There is nothing inherently wrong with such functional design; it simply doesn’t map neatly onto the “traditional” look of older serifs. On a modern, high-resolution display, the typeface can appear spindly, more utilitarian than ceremonial.</p>
<p>Indeed, the stronger explanation for Times New Roman’s long reign isn’t aesthetic excellence, but practicality and inertia. Times New Roman was among the small set of <a href="https://web.archive.org/web/20020511131315/http://www.melbpc.org.au/pcupdate/9303/9303article3.htm">typefaces bundled with early versions of Windows</a>. It was also promoted as “web-safe,” meaning webmasters could reasonably assume it would render properly across platforms. In the early era of digitalization, choosing Times New Roman was often less a deliberate endorsement than a default imposed by limited options. Over time, the habit hardened into a standard, and institutions began to require it without much reflection, effectively borrowing their own authority to confer authority upon the typeface.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/6cc62e4fe079ba6cdbfe404f902c86f4.png">
<figcaption>The font dialog on Windows 95 (Credit: <em>GUIdebook</em>)</figcaption>
</figure>
<p>Professionals who genuinely focus on typography have advised against Times New Roman. For example, type designer Matthew Butterick eloquently <a href="https://practicaltypography.com/a-brief-history-of-times-new-roman.html#:~:text=When%20Times%20New%20Ro%C2%ADman%20ap%C2%ADpears">comments</a>:</p>
<blockquote>
<p>When Times New Roman appears in a book, document, or advertisement, it connotes apathy. It says, “I submitted to the typeface of least resistance.” Times New Roman isn’t a typeface choice so much as the absence of a typeface choice, like the blackness of deep space isn’t a color. To look at Times New Roman is to gaze into the void.</p>
</blockquote>
<p>Similarly, the U.S. Court of Appeals for the Eighth Circuit, in its formatting advice for lawyers, specifically <a href="https://federalcourt.press/wp-content/uploads/2018/03/Eighth-Circuit-Checklist.pdf">cautions</a>:</p>
<blockquote>
<p>Typographic decisions should be made for a purpose. <em>The Times of London</em> chose the typeface Times New Roman to serve an audience looking for a quick read. Lawyers don’t want their audience to read fast and throw the document away; they want to maximize retention. Achieving that goal requires a different approach — different typefaces, different column widths, different writing conventions. Briefs are like books rather than newspapers. The most important piece of advice we can offer is this: read some good books and try to make your briefs more like them.</p>
</blockquote>
<p>As for the other U.S. official bodies Rubio cites in the memo, many don’t actually use Times New Roman either. The Supreme Court’s rules <a href="https://www.law.cornell.edu/rules/supct/rule_33">require</a> booklet-format filings to be set in the Century family, and its own opinions are typeset in Century Schoolbook from that family. Originating in the 19th century, the typeface features more expansive proportions, balanced stroke contrast, and an elegant form, exuding a far more assertive presence than Times New Roman. As the name suggests, it also began life as a textbook face, optimized for legibility. With proper typesetting, it reads far better than a haphazardly produced Word document set in Times New Roman.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/9c3f70b2e92f14cf0477dc2cb25b336c.png">
<figcaption>A U.S. Supreme Court opinion set in Century Schoolbook (the infamous <em>Dobbs</em> decision)</figcaption>
</figure>
<p>Looking at the legislature, the official PDFs of U.S. Congressional bills use <a href="https://en.wikipedia.org/wiki/Cheltenham_%28typeface%29">Cheltenham</a> for titles and <a href="https://typefacesinuse.com/typefaces/253/de-vinne-linotype">De Vinne</a> for body text. De Vinne, first released in 1902, shares similarities in style with Century Schoolbook but features stronger stroke contrast and more decorative serifs, giving it an “engraved” quality. Objectively speaking, this design borders on being a display typeface — imagine the logotype of <em>Harper’s Bazaar</em>, Didot — and is somewhat tiring to read in body text. But when it comes to conveying ceremony and solemnity, it’s far more qualified than Times New Roman. (After a bill is enacted into law, it will be typeset in New Century Schoolbook.)</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/7929f56f8523adfb86024959464adaee.png">
<figcaption>A U.S. House bill PDF page from the initial submission of the “One Big Beautiful” Bill</figcaption>
</figure>
<p>Even the Trump administration, to which Rubio pledges allegiance, contradicts the “serif tradition” by using a fashionable tall, high-contrast serif (<a href="https://github.com/Instrument/instrument-serif">Instrument Serif</a>) on the <a href="https://www.whitehouse.gov/">White House website</a>. It may look a bit mannered by government standards — an impression no less bolstered by its bombastic rhetoric — but it does manage to appear assertive and emphatic. Swap in Times New Roman and “AMERICA IS BACK” would read more like a mutter.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/8989ca4f8eace4c82d367731360d192b.png">
<figcaption>WhiteHouse.gov design in Trump’s second term</figcaption>
</figure>
<p>Thus, the design and historical reasons cited in Rubio’s memo don’t hold up. The formality and authority of serif typefaces are largely socially constructed, and Times New Roman’s origin story and design constraints don’t express these qualities. If Times New Roman carries authority at all, it’s primarily borrowed from the authority of institutions that have adhered to it. If the sincere goal were to “return to tradition” by returning to a serif, there are many choices with deeper pedigree and more fitting gravitas.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/c998e9b9e9f2d2a87fe9d13a9cd5b6b4.png">
<figcaption>Times New Roman compared with select serif typefaces with stronger reputations</figcaption>
</figure>
<p>At this point, it might sound as though the argument is trending toward a defense of the Department’s earlier choice: Calibri. Unfortunately, Calibri is also a poor fit for formal contexts. While seriousness and authority aren’t the exclusive province of serifs, Calibri does little to convey those traits.</p>
<p>Typographically, Calibri is a <em>humanist</em> sans-serif. Such typefaces tend to have open, rounded forms and generous apertures (look at the wide openings in letters like a, c, e, and s). Calibri takes that softness especially far: terminals are visibly rounded, and many letters appear almost handwritten, to the extent that its designer described its quality as “warm and soft.”</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/bd20435252554d90c4f09e14a8633c36.png">
<figcaption>Calibri specimen (Credit: Microsoft)</figcaption>
</figure>
<p>There’s nothing inherently wrong with this style, but one would hardly want an official document or legal contract to appear “warm and soft.” That is why I have long disliked Microsoft’s decision to make Calibri the default Office typeface starting with Office 2007. A default body typeface should be neutral and versatile, not exude a temperature. (Microsoft replaced Calibri with <a href="https://en.wikipedia.org/wiki/Aptos_%28typeface%29">Aptos</a> as the default in 2023, but inertia being what it is, Aptos still appears relatively rarely in the wild.)</p>
<p>To be fair, the State Department’s 2023 change was justified less as a matter of taste than as an accessibility and inclusion initiative. That is, to make documents easier to read for individuals with various physical and cognitive conditions. This goal is commendable in itself, but the means were, at best, loosely connected to the end, much like many inclusive measures that were once fashionable in U.S. politics and business in recent years.</p>
<p>First, Calibri was not designed with accessibility in mind. It was commissioned by Microsoft to promote its ClearType technology, with the design objective of appearing clear on the low-resolution displays of its time. This means it prioritizes smoothness under specific sub-pixel rendering techniques, rather than ensuring the glyphs are easy to tell apart. If accessibility were truly the goal, one might select a typeface created for that purpose. For example, Atkinson Hyperlegible addresses character differentiation by adding serifs, exaggerating shapes, and slanting strokes, making it legible even under low-vision conditions. In contrast, Calibri has no anti-ambiguity design: the uppercase <code>I</code> and lowercase <code>l</code> are nearly identical. So much for “accessibility.”</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/8a780297ed7d3d9af3a27977fbcab7f1.jpeg">
<figcaption>A publication set in Atkinson Hyperlegible (Credit: Studiokwi)</figcaption>
</figure>
<p>Furthermore, accessibility doesn’t depend solely on a document’s appearance but more on its internal structure and presentation mechanisms. For instance, the W3C’s <a href="https://www.w3.org/WAI/standards-guidelines/wcag/glance/">Web Content Accessibility Guidelines (WCAG)</a> state that accessible content should be perceivable, operable, understandable, and robust. This means that documents should have proper semantic structure (so tools like screen readers can interpret content correctly), support customizable layouts and fonts, and be compatible with various applications and devices. If these principles were met, the specific font used would matter little, as users can access the content with their preferred tools in their preferred manner. Conversely, if a document is technically crude, like a scanned PDF — as many official documents are — the use of an “inclusive” font is merely self-congratulatory.</p>
<p>If one insisted on a sans-serif for official writing, there are many better candidates than Calibri: Frutiger (common in airport wayfinding), Myriad (used by Apple for years), the cool and serious Univers (or a well-set Helvetica Neue), or contemporary neutral workhorses like Inter. If a “made in America” signal mattered, <a href="https://public-sans.digital.gov/">Public Sans</a> (funded under the 21st Century Integrated Digital Experience Act passed during Trump’s first term) and used by many U.S. government websites is also a good option.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/25ca7740c5eccb4aea031953d26ef037.png">
<figcaption>Calibri compared with several higher-regarded sans-serif typefaces</figcaption>
</figure>
<p>Therefore, Rubio’s criticism that the previous move was “cosmetic,” while being politically charged, isn’t entirely unfounded.</p>
<p>Taken together, the Department had previously pursued a defensible goal with a poorly matched design intervention and landed on an ill-fitting typeface. Now, for political motives, it has reversed that decision and returned to a bland, unremarkable default. Between the two, Times New Roman may be the lesser evil: it is more widely recognized, and it doesn’t clash with the official context as overtly as Calibri does. Still, Rubio, or whoever drafted the memo for him, could have been more candid. There was no need to dress up a political gesture with faux-erudite claims or to lavish praise on a mediocre typeface.</p>
<p>Because Times New Roman just will not make America great again.</p>


        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Non-Zero-Sum Games (323 pts)]]></title>
            <link>https://nonzerosum.games/</link>
            <guid>46432311</guid>
            <pubDate>Tue, 30 Dec 2025 11:42:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nonzerosum.games/">https://nonzerosum.games/</a>, See on <a href="https://news.ycombinator.com/item?id=46432311">Hacker News</a></p>
<div id="readability-page-1" class="page"><a name="Top"></a>
    
    

    <!-- For Facebook and LinkedIn -->
    <meta property="og:image" content="https://nonzerosum.games/Images/Social/alignment1.png">
    <meta property="og:title" content="NON-ZERO-SUM GAMES">
    <meta property="og:description" content="~ a world-help site ~">

    <!-- For Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@NonZeroSumJames">
    <meta name="twitter:image" content="https://nonzerosum.games/Images/Social/alignment1.png">
    <meta name="twitter:title" content="NON-ZERO-SUM GAMES">
    <meta name="twitter:description" content="~ a world-help site ~">
    



    <!-- Linking to Menu.html -->
    
    

    <h3>WELCOME TO</h3>
    
    <h2>a <strong>world</strong>-help site &amp; <a href="https://pod.link/1810797958">podcast</a></h2>

    <p><img id="animation-frame" src="https://nonzerosum.games/Images/Content/Frames_Rabbits_0000.png" alt="Animation Frame">
    </p>
    
    <p>Hi, I'm Non-Zero-Sum <a href="https://nonzerosum.games/aboutme.html">James</a>, your companion on this exploration of <a href="https://nonzerosum.games/whatarenonzerosumgames.html">win-win games</a> and how they are essential for a better future. <a href="https://nonzerosum.games/blog.html">Each week</a> we'll explore a new aspect of <a href="https://nonzerosum.games/gametheory.html">game theory</a>, <a href="https://nonzerosum.games/map-moralphilosophy.html">moral philosophy</a>, <a href="https://nonzerosum.games/map-ethicaleconomics.html">ethical economics</a> and <a href="https://nonzerosum.games/map-ai.html">artificial intelligence</a>—looking to solve the complex problems we face in our world <em><strong>together</strong></em>.</p>

    <a name="WhatsNew"></a>
<!-- NEW Section -->
<h3>WHAT'S NEW?</h3>
<br>
    

<h3>WHAT'S NEXT?</h3>
<p>All the posts are connected through the lens of non-zero-sum games, but they fall into a few broad categories. You can start your journey with whatever appeals to you:</p>



<br>
<blockquote>
  "It is well to remember that the entire universe, <em><strong>with one trifling exception</strong></em>, is composed of others."<br>—<b>John Holmes</b>
</blockquote>



    
    
    
<p>Your thoughts and contributions are welcome. Share, debate, and co-create in the comments.</p>


    
    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nicolas Guillou, French ICC judge sanctioned by the US and “debanked” (353 pts)]]></title>
            <link>https://www.lemonde.fr/en/international/article/2025/11/19/nicolas-guillou-french-icc-judge-sanctioned-by-the-us-you-are-effectively-blacklisted-by-much-of-the-world-s-banking-system_6747628_4.html</link>
            <guid>46432057</guid>
            <pubDate>Tue, 30 Dec 2025 11:13:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lemonde.fr/en/international/article/2025/11/19/nicolas-guillou-french-icc-judge-sanctioned-by-the-us-you-are-effectively-blacklisted-by-much-of-the-world-s-banking-system_6747628_4.html">https://www.lemonde.fr/en/international/article/2025/11/19/nicolas-guillou-french-icc-judge-sanctioned-by-the-us-you-are-effectively-blacklisted-by-much-of-the-world-s-banking-system_6747628_4.html</a>, See on <a href="https://news.ycombinator.com/item?id=46432057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">                                         <section id="habillagepub">             <header> <div>     <ul>  <li>   <a href="https://www.lemonde.fr/en/international/" aria-label="World">    <span>World</span>    <span>World</span>   </a>   </li>  <li>   <a href="https://www.lemonde.fr/en/france/" aria-label="France">    <span>France</span>    <span>France</span>   </a>   </li>  </ul>          <div>     <p><span> Six judges and three prosecutors at the International Criminal Court have been sanctioned by the Trump administration. In an interview with Le Monde, Guillou discusses the impact of these measures on his work and daily life. </span> </p> </div>   <section>      <a href="https://www.lemonde.fr/international/article/2025/11/19/nicolas-guillou-juge-francais-de-la-cpi-sanctionne-par-les-etats-unis-face-aux-attaques-les-magistrats-de-la-cour-tiendront_6654016_3210.html" hreflang="fr">  <span>Lire en français</span>  </a>  </section>                         </div> </header>     <p data-tracking="article-status">          <span>Subscribers only</span> </p>       <section> <article>                   <figure> <img src="https://img.lemde.fr/2025/11/18/0/0/4000/2668/664/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg" alt="French judge Nicolas Guillou is sworn in at the headquarters of the International Criminal Court in The Hague, Netherlands, on March 8, 2024." srcset=" https://img.lemde.fr/2025/11/18/0/0/4000/2668/320/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 320w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/556/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 556w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/640/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 640w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/664/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 664w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/960/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 960w,   https://img.lemde.fr/2025/11/18/0/0/4000/2668/1112/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1112w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/1328/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1328w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/1668/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1668w,   https://img.lemde.fr/2025/11/18/0/0/4000/2668/1992/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1992w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/2301/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 2301w,  ">     </figure>             <p>Nicolas Guillou, a French judge at the International Criminal Court (ICC), was sanctioned by the United States under a decision made by Donald Trump on August 20. The US Treasury Department justified the action, stating that "Guillou is being designated for ruling to authorize the ICC's issuance of arrest warrants for Israeli Prime Minister Benjamin Netanyahu and former Minister of Defense Yoav Gallant." Both men are indicted for war crimes and crimes against humanity for their roles in the destruction of the Gaza Strip.</p>                 <p>In total, six judges and three prosecutors from the ICC, including Chief Prosecutor Karim Khan, have been sanctioned by the US. In an interview with <em>Le Monde</em>, the judge explained the impact of these measures on his work and daily life. Without commenting on ongoing cases, he called on European authorities to activate a mechanism that could limit the impact of US restrictions.</p>           <h3>What is the purpose of the American sanctions mechanism?</h3>           <p>Initially, it was created to address human rights violations, counter terrorism and combat drug trafficking. Today, nearly 15,000 individuals are on the US sanctions list, mostly members of Al-Qaeda, the Islamic State group (IS), mafia organizations and the leaders of authoritarian regimes. Among this long list are nine ICC judges.</p>         <p><strong>You have 81.05% of this article left to read. The rest is for subscribers only.</strong></p>     </article>       </section>     </section>      <section id="js-capping" data-full="0" data-mini="0">  <section id="js-capping-content"> <p>Vous pouvez lire <i>Le Monde</i> sur un seul appareil à la fois</p>   <p>Ce message s’affichera sur l’autre appareil.</p> <a href="https://moncompte.lemonde.fr/" id="js-capping-yellow-button"> <span>Ajouter un compte</span> <span>Découvrir l’offre Famille</span> <span>Découvrir les offres multicomptes</span> </a> </section> <section id="js-capping-bottom">  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>En cliquant sur «&nbsp;&nbsp;» et en vous assurant que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</p> </li> <li> <p>Vous ignorez qui est l’autre personne ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous utilisez ce compte à plusieurs, <a href="https://moncompte.lemonde.fr/">créez un compte pour votre proche</a> (inclus dans votre abonnement). Puis connectez-vous chacun avec vos identifiants. <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ces identifiants ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous êtes bénéficiaire de l’abonnement, connectez-vous avec vos identifiants. <span>Si vous êtes 3 ou plus à utiliser l’abonnement, <a href="https://moncompte.lemonde.fr/">passez à l’offre Famille</a>.</span> <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ces identifiants ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous êtes bénéficiaire de l’abonnement, connectez-vous avec vos identifiants. <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ce compte ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous utilisez ce compte à plusieurs, <a href="https://moncompte.lemonde.fr/">passez à une offre multicomptes</a> pour faire profiter vos proches de votre abonnement avec leur propre compte. <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter Le Monde avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ce compte ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>En cliquant sur «&nbsp;&nbsp;» et en vous assurant que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> <li> <p>Vous ignorez qui est l’autre personne ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> </ul>  </section> </section> <section id="js-capping-old-article" data-full="0" data-mini="0"> <section id="js-capping-old-article-header"> <span></span> <p>Lecture restreinte</p> </section> <section id="js-capping-old-article-content"> <p>Votre abonnement n’autorise pas la lecture de cet article</p>  <p>Pour plus d’informations, merci de contacter notre service commercial.</p> </section> </section>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Netflix: Open Content (574 pts)]]></title>
            <link>https://opencontent.netflix.com/</link>
            <guid>46431560</guid>
            <pubDate>Tue, 30 Dec 2025 10:11:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opencontent.netflix.com/">https://opencontent.netflix.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46431560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="ZBtY8b" tabindex="-1" dir="ltr"><div id="h.INITIAL_GRID.t5w57pd7xu1k" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><p role="main" tabindex="0"><h2 id="h.hao2e5ffslk1" dir="ltr"><span><strong>OPEN SOURCE CONTENT</strong></span></h2></p></div><div id="h.424e02f0723faf59_3" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><p dir="ltr">At Netflix, we are always exploring ways to make our content look and sound even better. To provide a common reference for prototyping bleeding-edge technologies within entertainment, technology and academic circles without compromising the security of our original and licensed programming, we've developed test titles oriented around documentary, live action, and animation.</p><p dir="ltr">Many open source assets are available from each project listed below. Our hope is this will encourage more experimentation, learning, and discovery that will benefit the whole industry. Many of these titles are also streaming on Netflix and are best enjoyed with any HDR configured device with your Premium subscription.</p><p dir="ltr">You can download single files directly through your web browser, but for large files and long frame sequences, you may wish to use command line tools. Guidance is included below. Ad Blockers may cause errors in your downloading process, so try turning it off if you have issues.</p><p dir="ltr">Our open source content is available under the <span><a href="https://www.google.com/url?q=https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby%2F4.0%2Flegalcode&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3DDX6ldzWtAO5wOs5KkByf" target="_blank">Creative Commons Attribution 4.0 International Public License</a></span>.</p></div><div id="h.5c2279c0a0764436_0" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><p dir="ltr">We’ve had great success remastering titles like <em>Knights of Sidonia</em>, <em>Flavours of Youth</em> and <em>Godzilla</em> from SDR to HDR over the last few years. But what if we increase the resolution and create anime with HDR in mind from conception? Working with Japan's Production I.G, we set out to create the first 4K HDR Atmos anime short and discover what would need to change in anime workflows.</p><p dir="ltr">Read more about <em>Sol Levante</em> in the Netflix <span><a href="https://www.google.com/url?q=https%3A%2F%2Fnetflixtechblog.com%2Fbringing-4k-and-hdr-to-anime-at-netflix-with-sol-levante-fa68105067cd&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw31OTOl32tb3gNn46s-zEgf" target="_blank">Tech Blog</a></span>.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DSolLevante%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1Ecn23QB92g0bq0JsDR4nW" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">HDR10 2020 ST2084 UHD 24fps 1000nit</p></li><li dir="ltr"><p dir="ltr">DolbyVision PQ/P3 D65 UHD 24fps IMF</p></li><li dir="ltr"><p dir="ltr">Atmos ADM and DAMF files</p></li><li dir="ltr"><p dir="ltr">ProTools Final Mix Session and Mastered Session</p></li><li dir="ltr"><p dir="ltr">4K HDR 16bit P3/PQ D65 Dolby Vision 2.9 XML + VDM</p></li><li dir="ltr"><p dir="ltr">Animatics, storyboard, selected After Effects projects, PSDs, and TGA in-betweens.</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F81017017&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3GbhByygE0zMS0-F55mxIK" target="_blank">Watch Sol Levante on Netflix</a></span></p></div><div tabindex="-1" id="h.5c2279c0a0764436_9"><div id="h.5c2279c0a0764436_17" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr">A live action test piece, <em>Nocturne</em> was shot at 120fps and sought to investigate footage with spatially complex scenes that mimic other professionally generated content to challenge codecs on both the encoding and decoding sides. This piece was also mastered in Dolby Vision and Atmos.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DNocturne%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0k-lgAAtZucT-XwDgOdI9L" target="_blank">Assets Available to Download</a></span>: </p><ul><li dir="ltr"><p dir="ltr">120fps Video Display Master</p></li><li dir="ltr"><p dir="ltr">60fps Video Display Master</p></li><li dir="ltr"><p dir="ltr">ADM WAV File</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80987558&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0tcEiSwiKx5uRsnzPRfo3k" target="_blank">Watch Nocturne on Netflix</a></span></p></div><div id="h.5c2279c0a0764436_67" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkdlK74wPldvSS2xbYVel6Apl4kP1UT5QDPyRg1d1aNwyt0zhNiQnCDsEttn9n9lKtB7247J5Woif1RSYOoZ_-G8hANMwqBTZ221ZES9SqATfZ1B4Wd0PovROH9nIzQ_dzqB5_gQ-xOJJF7rjDH7HZJYls6DWxaxKsKKyT5eq8GUL5Kc9tJ39Fm4YFOnyLVSGLDLUMs2lMojMkc=w1280" role="img"></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_18"><div id="h.5c2279c0a0764436_68" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkck_Ug0KB82ES0N1B_6DNoJPsVHZzsLM-uJnD3n1rXGwL8NGk8RxvE38B6KkyP_IJKqID1uNLTMobwRUCYAJdaiHGG9KZSvYTyS9__B5hDwgw86ZkOcL0KLAD114XiILiXNUlL865RPtnqd1hbj1RlSNQRpO9UqqNcq0jCkRIt3TEYOcmhL0fUcPMBVORhVY-lAhcLPIsCXSIA=w1280" role="img"></p></div><div id="h.5c2279c0a0764436_26" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr">Upon noticing the contrast in dark shadows against the bright sky and sparks from a welder working on a new Netflix building, the encoding team acquired a Sony PMW-F55 and the AXS-R5 RAW recorder to shoot 16-bit RAW SQ and produce <em>Sparks</em>.</p><p dir="ltr">Sparks was shot 4K HFR and finished at 4000 nits using ACES. Read more about Sparks on the <span><a href="https://www.google.com/url?q=https%3A%2F%2Fnetflixtechblog.com%2Fengineers-making-movies-aka-open-source-test-content-f21363ea3781&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0FxnUO5CAJaNyyZfMyk8uR" target="_blank">Netflix Tech Blog</a></span>.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3Dsparks%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1JxkoD8D89veBk8dyGf9Pb" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">4K P3 PQ 4000nits Dolby Vision IMF</p></li><li dir="ltr"><p dir="ltr">HDR10 1000nit PQ 2020 image sequence</p></li><li dir="ltr"><p dir="ltr">4K P3/PQ 4000nits EXR</p></li><li dir="ltr"><p dir="ltr">4K P3/PQ 4000nits EXR Dolby Vision metadata</p></li><li dir="ltr"><p dir="ltr">ACES 59.94fps image sequence</p></li><li dir="ltr"><p dir="ltr">Original Camera Files</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80156943&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1xfgRA8JGGKutKDQwWWUW_" target="_blank">Watch Sparks on Netflix</a></span></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_27"><div id="h.5c2279c0a0764436_35" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span>Following the industry shift from “more pixels” to “better pixels,” we produced </span><span><em>Meridian, </em></span><span>our first test title to tell a story. </span><span><em>Meridian </em></span><span>was mastered in Dolby Vision high dynamic range (HDR) with a P3-D65 color space and PQ (perceptual quantizer) transfer function. It also contained a Dolby Atmos mix, multiple language tracks, and subtitles. You can read more about Meridian </span><span><a href="http://www.google.com/url?q=http%3A%2F%2Fvariety.com%2F2016%2Fdigital%2Fnews%2Fnetflix-meridian-imf-tools-open-source-1201859416%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw35I1RorUVcGxJ-b7K7k1pK" target="_blank">on Variety</a></span>.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DMeridian%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1UTIRtEMMmvGHiGd9cjiiE" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">UHD IMF</p></li><li dir="ltr"><p dir="ltr">Zipped UHD VDM</p></li><li dir="ltr"><p dir="ltr">UHD 4k 5994 HDR P3/PQ (mp4)</p></li><li dir="ltr"><p dir="ltr">UHD VDM Image Sequence</p></li><li dir="ltr"><p dir="ltr">Dolby Atmos Metadata File</p></li><li dir="ltr"><p dir="ltr">Atmos BWAV ADM</p></li><li dir="ltr"><p dir="ltr">TIFF Sequence</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80141336&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1XMqFuLvHCLgfh-c0dvqjT" target="_blank">Watch Meridian on Netflix</a></span></p></div><div id="h.5c2279c0a0764436_69" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkfpn_aZrb3HH-13XDuj1rQ2Gbp7QYyDeWJlhqw6Ham7o5KtG9_5mAAVjO5xVANNczBNLkyN3ruyaamztFmD3xwOX9cFmpdi4Ym_4vyzxs1HGbgUaaAwGoPaQmbTCEXWKXiFLVnl7S0E7RWH4C_XGmEf5nwkJzroCtyQQZOEQ2CMA8LzmjOsfrLq4Dv1-o3YZw8MXGI9PfknE14=w1280" role="img"></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_36"><div id="h.5c2279c0a0764436_70" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkctwJ-90C2LUXO20Q5HTyv2-cXWL8N9f66xpalqKpEgBTAoX9WYTEcMq7MYicWjjiQAt_gnU49PSa8YbhaljoOVfKn1SwTPmqa5groflbuxrGFavzMk3E9AEBXjQ-D4MfaJCNAUmJIGs6j6bDejYV9X48dgk1TswGFD9QBKMsrkRvz6sk6D2aNjwBgE94wROrhLGLgMzu5P2qk=w1280" role="img"></p></div><div id="h.5c2279c0a0764436_44" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span>We felt a need to include animated content in our test title library, so we partnered with Blender Foundation and Fotokem’s Keep Me Posted to re-grade Cosmos Laundromat, an award-winning short film in Dolby Vision HDR.</span></p><p dir="ltr"><span>Cosmos Laundromat is an Open Movie project created by </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fstudio.blender.org%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0ECNq0x9oqXh1tiiKD9h2x" target="_blank">Blender Studio</a></span><span> and directed by Mathieu Auvray. The film was made entirely in Blender, an open source 3D content creation tool. </span></p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DCosmosLaundromat%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1-fXfugSAUbfB6iedsZtZP" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">2k 24p HDR P3/PQ (mp4)</p></li><li dir="ltr"><p dir="ltr">EXR to TIFF Nuke Script File</p></li><li dir="ltr"><p dir="ltr">EXR Sequence</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80114804&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0hEUGziup-TVSYasKgibK4" target="_blank">Watch Cosmos Laundromat on Netflix</a></span></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_45"><div id="h.5c2279c0a0764436_53" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span><em>Chimera</em></span><span> is technically comparable to El Fuente, but its scenes are more representative of existing titles on Netflix. The dinner scene attempts to recreate a codec-challenging sequence from </span><span><em>House of Cards</em></span><span>.</span></p><p dir="ltr">Prior to <em>Chimera</em>, there wasn’t any open source 4K test material that exhibited real world live action material.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DChimera%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw2UBRKw_TqKUFN3-uRCzIEg" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">DCI 4k 2398p HDR P3/PQ</p></li><li dir="ltr"><p dir="ltr">DCI 4k 5994p HDR P3/PQ</p></li><li dir="ltr"><p dir="ltr">TIFF Sequence: DCI 4k 2398p</p></li><li dir="ltr"><p dir="ltr">TIFF Sequence: DCI 4k 5994p</p></li></ul></div><div id="h.5c2279c0a0764436_71" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkdxK4hymyHZSA6I1FVqikW6q33HgsCj0IkhoWBRbTqOb4zLmEXkAj117Pw3gma9zA6E6zMu2Pbe5_kpQP0By-aBQwdOTWZOfo4swXG_JIQjzNeT6xVX24Rc2y7ONRXOwzPfzBxBg3HyJx1_fvvS7ViWfLOPkRZDLd74EqLLzkxHJYyDOseAdHgz1uav09jIbDBquJhzU_3oRoU=w1280" role="img"></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_54"><div id="h.5c2279c0a0764436_72" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkfT0CozN_IwZyFcA1aKG6oS2FRu3yH4qcH7Tk6JNIy3eq_L_IlimCD2kwtiifDqPNSuEWEhaJWQhC12UB35DfxN3ggQcwN1Nga5sgK6lv4Vbz0ND_jXbA7DJUIAGyCfL3ByPSMY_y2Xk0UzFDF_bwvO8ES-tK6XxM9z3Rsf8YjGpEOQL5KoKAs-2la0rJitXTGau3JBoLz4ceM=w1280" role="img"></p></div><div id="h.5c2279c0a0764436_62" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span>As the demand for more pixels increased, so did appropriate test content. Documentary short </span><span><em>El Fuente </em></span><span>was shot in Mexico by a local DP at 4K at both 48 and 59.94 fps to meet increasing resolution and frame rate requirements. </span></p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DElFuente%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3CJ0dsnigs5uzK9PX3ZT30" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">Boat: 4096x2160 60fps 10bit 420 (YUV4Mpeg format)</p></li><li dir="ltr"><p dir="ltr">FoodMarket: 4096x2160 60fps 10bit 420 (YUV4Mpeg format)</p></li></ul></div></div><div id="h.424e02f0723faf59_7" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><h2 id="h.ybuehwfpw41c_l" dir="ltr" tabindex="-1"></h2><p dir="ltr">The assets on this page can be browsed on the Netflix OpenContent bucket here:</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3D&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw13gxO2u8ohKDF8n8ciAAHN" target="_blank">http://download.opencontent.netflix.com/</a></span></p><p dir="ltr">You can download single files directly through your web browser on each page, but for large files and long frame sequences, you may wish to use command line tools such as aws cli. <span><a href="https://www.google.com/url?q=https%3A%2F%2Fdocs.aws.amazon.com%2Fcli%2Flatest%2Fuserguide%2Finstalling.html&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3PGFJ8r8nYfq7XpBLgMOdA" target="_blank">Instructions are posted on their website</a></span>. After installation, you should be able to download the public assets. Try running these sample commands. If the download is interrupted, you can run the same command immediately and aws cli will resume the download where it left off.</p><p dir="ltr">Download a single file (0.7 kB):</p><p dir="ltr">Usage:   aws s3 cp --no-sign-request &lt;s3 URI&gt; &lt;local destination&gt;</p><p dir="ltr">Example: aws s3 cp --no-sign-request s3://download.opencontent.netflix.com/TechblogAssets/Sparks/sparks_license.txt .</p><p dir="ltr">Sync entire directory (1406.1 MB):</p><p dir="ltr">Usage:   aws s3 sync --no-sign-request &lt;s3 URI&gt; &lt;local destination&gt;</p><p dir="ltr">Example: aws s3 sync --no-sign-request s3://download.opencontent.netflix.com/TechblogAssets/CosmosLaundromat/encodes/ .</p><p dir="ltr">The download links on this page will bring you to the root directory for that title's assets. You may need to navigate around to find the folder you want.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HSBC blocks its app due to F-Droid-installed Bitwarden (231 pts)]]></title>
            <link>https://mastodon.neilzone.co.uk/@neil/115807834298031971</link>
            <guid>46431453</guid>
            <pubDate>Tue, 30 Dec 2025 09:57:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.neilzone.co.uk/@neil/115807834298031971">https://mastodon.neilzone.co.uk/@neil/115807834298031971</a>, See on <a href="https://news.ycombinator.com/item?id=46431453">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Go Away Python (319 pts)]]></title>
            <link>https://lorentz.app/blog-item.html?id=go-shebang</link>
            <guid>46431028</guid>
            <pubDate>Tue, 30 Dec 2025 08:50:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lorentz.app/blog-item.html?id=go-shebang">https://lorentz.app/blog-item.html?id=go-shebang</a>, See on <a href="https://news.ycombinator.com/item?id=46431028">Hacker News</a></p>
Couldn't get https://lorentz.app/blog-item.html?id=go-shebang: Error: getaddrinfo ENOTFOUND lorentz.app]]></description>
        </item>
        <item>
            <title><![CDATA[Charm Ruby – Glamorous Terminal Libraries for Ruby (126 pts)]]></title>
            <link>https://charm-ruby.dev/</link>
            <guid>46430558</guid>
            <pubDate>Tue, 30 Dec 2025 07:36:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://charm-ruby.dev/">https://charm-ruby.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=46430558">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <nav>
    
  </nav>

  <header>
    
    <div>
      <p><a href="https://marcoroth.dev/posts/glamorous-christmas" target="_blank" rel="noopener">
        <span>NEW</span>
        <span><span>Read the Introduction → </span>A Glamorous Christmas</span>
      </a></p><div>
<pre> ██████╗██╗  ██╗ █████╗ ██████╗ ███╗   ███╗
██╔════╝██║  ██║██╔══██╗██╔══██╗████╗ ████║
██║     ███████║███████║██████╔╝██╔████╔██║
██║     ██╔══██║██╔══██║██╔══██╗██║╚██╔╝██║
╚██████╗██║  ██║██║  ██║██║  ██║██║ ╚═╝ ██║
       ╚═════╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝  <span>RUBY</span>
</pre>
      </div>
      <div><p>
        Ruby bindings and ports of the beloved <a href="https://charm.sh/" target="_blank" rel="noopener">Charm</a> terminal libraries.</p><p>
        <span>Build glamorous TUIs, style terminal output, create beautiful forms,<br>
        and make your Ruby CLIs sparkle.</span></p></div>
      <p><code>gem install bubbletea lipgloss bubbles glamour</code>
      </p>
      
    </div>
  </header>

  <div id="libraries">
      <h2>The Library Collection</h2>

      <div>
        <h3>Build Terminal Apps</h3>
        <div>

          <article>
            <p>🫧</p>
            <h4>Bubbletea</h4>
            <p>Build terminal UIs from the future, today.</p>
            <p>A powerful TUI framework using the Elm Architecture. Handle keyboard, mouse, and window events with commands for side effects.</p>
            <p><code>gem "bubbletea"</code>
            </p>
            
          </article>

          <article>
            <p>🧩</p>
            <h4>Bubbles</h4>
            <p>The Bubble Tea component toolkit.</p>
            <p>Pre-built components: Spinner, Progress, Timer, TextInput, TextArea, Viewport, List, Table, FilePicker, and more.</p>
            <p><code>gem "bubbles"</code>
            </p>
            
          </article>

          <article>
            <p>🔲</p>
            <h4>Bubblezone</h4>
            <p>Track clickable regions in terminal UIs.</p>
            <p>Mark zones with IDs, check mouse coordinates, and handle click events in your Bubble Tea applications.</p>
            <p><code>gem "bubblezone"</code>
            </p>
            
          </article>

        </div>
      </div>

      <div>
        <h3>Style Your Output</h3>
        <div>

          <article>
            <p>💄</p>
            <h4>Lipgloss</h4>
            <p>Your terminal style and layout toolkit.</p>
            <p>Borders, padding, margins, colors (hex, ANSI, adaptive), tables, lists, trees, and layout utilities.</p>
            <p><code>gem "lipgloss"</code>
            </p>
            
          </article>

          <article>
            <p>✨</p>
            <h4>Glamour</h4>
            <p>The stylesheet-driven markdown renderer.</p>
            <p>Render markdown in your terminal with built-in themes (dark, light, dracula), custom styles via DSL, and emoji support.</p>
            <p><code>gem "glamour"</code>
            </p>
            
          </article>

          <article>
            <p>📊</p>
            <h4>NTCharts</h4>
            <p>Terminal charts for beautiful data viz.</p>
            <p>Sparkline, Barchart, LineChart, WaveLineChart, StreamLineChart (real-time), and TimeSeriesLineChart.</p>
            <p><code>gem "ntcharts"</code>
            </p>
            
          </article>

        </div>
      </div>

      <div>
        <h3>Interactive Tools</h3>
        <div>

          <article>
            <p>🤔</p>
            <h4>Huh?</h4>
            <p>Simple, powerful forms in the terminal.</p>
            <p>Input, Text, Select, MultiSelect, Confirm, Note, Spinner. Built-in validation, themes, and a block-based DSL.</p>
            <p><code>gem "huh", github: "marcoroth/huh-ruby"</code>
            </p>
            
          </article>

          <article>
            <p>🍬</p>
            <h4>Gum</h4>
            <p>A tool for glamorous shell scripts.</p>
            <p>Ruby wrapper with idiomatic API: input, write, choose, filter, confirm, file, pager, spin, style, format. Bundles the gum binary.</p>
            <p><code>gem "gum"</code>
            </p>
            
          </article>

          <article>
            <p>🎵</p>
            <h4>Harmonica</h4>
            <p>A physics-based animation library.</p>
            <p>Damped harmonic oscillator (Spring), projectile motion, Point &amp; Vector math, and frame rate helpers for smooth UI animations.</p>
            <p><code>gem "harmonica"</code>
            </p>
            
          </article>

        </div>
      </div>

    </div>

  <div id="getting-started">
      <h2>Getting Started</h2>

      <div>
        <div>
          <h3><span>##</span> Installation</h3>
          <p>Add the gems you need to your Gemfile:</p>
          <div>
            <pre><code><span># Gemfile</span>

<span># Core TUI framework</span>
gem <span>"bubbletea"</span>

<span># Styling</span>
gem <span>"lipgloss"</span>

<span># Components</span>
gem <span>"bubbles"</span>

<span># Markdown rendering</span>
gem <span>"glamour"</span>

<span># Shell scripts</span>
gem <span>"gum"</span>

<span># Animations</span>
gem <span>"harmonica"</span>

<span># Charts</span>
gem <span>"ntcharts"</span>

<span># Mouse tracking</span>
gem <span>"bubblezone"</span></code></pre>
          </div>

        </div>

        <div>
          <h3><span>##</span> Your First TUI</h3>
          <p>A simple Bubbletea app with Lipgloss styling:</p>
          <div>
            <pre><code><span>require</span> <span>"bubbletea"</span>
<span>require</span> <span>"lipgloss"</span>

<span>class</span> <span>HelloWorld</span>
  <span>include</span> <span>Bubbletea::Model</span>

  <span>def</span> <span>initialize</span>
    <span>@style</span> = <span>Lipgloss::Style</span>.new
      .border(<span>:rounded</span>)
      .border_foreground(<span>"#7D56F4"</span>)
      .padding(<span>1</span>, <span>2</span>)
  <span>end</span>

  <span>def</span> <span>init</span> = [<span>self</span>, <span>nil</span>]

  <span>def</span> <span>update</span>(message)
    <span>case</span> message
    <span>when</span> <span>Bubbletea::KeyMessage</span>
      <span>return</span> [<span>self</span>, <span>Bubbletea</span>.quit] <span>if</span> message.to_s == <span>"q"</span>
    <span>end</span>

    [<span>self</span>, <span>nil</span>]
  <span>end</span>

  <span>def</span> <span>view</span>
    <span>@style</span>.render(<span>"Hello, Charm Ruby!\n\nPress q to quit"</span>)
  <span>end</span>
<span>end</span>

<span>Bubbletea</span>.run(<span>HelloWorld</span>.new)</code></pre>
          </div>
        </div>
      </div>
    </div>

  <div id="examples">
      <h2>Examples</h2>

      <div>

        <div>
          <h4>Counter with Styling</h4>
          <div>
            <pre><code><span>require</span> <span>"bubbletea"</span>
<span>require</span> <span>"lipgloss"</span>

<span>class</span> <span>Counter</span>
  <span>include</span> <span>Bubbletea::Model</span>

  <span>def</span> <span>initialize</span>
    <span>@count</span> = <span>0</span>
    <span>@style</span> = <span>Lipgloss::Style</span>.new
      .bold(<span>true</span>)
      .foreground(<span>"#FF6B6B"</span>)
  <span>end</span>

  <span>def</span> <span>update</span>(message)
    <span>case</span> message
    <span>when</span> <span>Bubbletea::KeyMessage</span>
      <span>case</span> message.to_s
      <span>when</span> <span>"q"</span>, <span>"ctrl+c"</span>
        <span>return</span> [<span>self</span>, <span>Bubbletea</span>.quit]
      <span>when</span> <span>"up"</span> <span>then</span> <span>@count</span> += <span>1</span>
      <span>when</span> <span>"down"</span> <span>then</span> <span>@count</span> -= <span>1</span>
      <span>end</span>
    <span>end</span>

    [<span>self</span>, <span>nil</span>]
  <span>end</span>

  <span>def</span> <span>view</span>
    <span>@style</span>.render(<span>"Count: </span>#{<span>@count</span>}<span>\n\nPress q to quit"</span>)
  <span>end</span>
<span>end</span>

<span>Bubbletea</span>.run(<span>Counter</span>.new)</code></pre>
          </div>
        </div>

        <div>
          <h4>Spinner Component</h4>
          <div>
            <pre><code><span>require</span> <span>"bubbletea"</span>
<span>require</span> <span>"bubbles"</span>

<span>class</span> <span>LoadingApp</span>
  <span>include</span> <span>Bubbletea::Model</span>

  <span>def</span> <span>initialize</span>
    <span>@spinner</span> = <span>Bubbles::Spinner</span>.new
  <span>end</span>

  <span>def</span> <span>init</span>
    [<span>self</span>, <span>@spinner</span>.tick]
  <span>end</span>

  <span>def</span> <span>update</span>(message)
    <span>case</span> message
    <span>when</span> <span>Bubbletea::KeyMessage</span>
      <span>case</span> message.to_s
      <span>when</span> <span>"q"</span>, <span>"ctrl+c"</span>
        <span>return</span> [<span>self</span>, <span>Bubbletea</span>.quit]
      <span>end</span>
    <span>end</span>

    <span>@spinner</span>, command = <span>@spinner</span>.update(message)

    [<span>self</span>, command]
  <span>end</span>

  <span>def</span> <span>view</span>
    <span>"</span>#{<span>@spinner</span>.view}<span> Loading..."</span>
  <span>end</span>
<span>end</span>

<span>Bubbletea</span>.run(<span>LoadingApp</span>.new)</code></pre>
          </div>
        </div>

        <div>
          <h4>Terminal Form</h4>
          <div>
            <pre><code><span>require</span> <span>"huh"</span>

form = <span>Huh</span>.form(
  <span>Huh</span>.group(
    <span>Huh</span>.input
      .key(<span>"name"</span>)
      .title(<span>"What's your name?"</span>)
      .placeholder(<span>"Enter name..."</span>),

    <span>Huh</span>.select
      .key(<span>"color"</span>)
      .title(<span>"Favorite color?"</span>)
      .options(*<span>Huh</span>.options(
        <span>"Red"</span>, <span>"Green"</span>, <span>"Blue"</span>
      ))
  )
).with_theme(<span>Huh::Themes</span>.charm)

form.run

puts <span>"Hello, </span>#{form[<span>"name"</span>]}<span>!"</span></code></pre>
          </div>
        </div>

        <div>
          <h4>Styled Table</h4>
          <div>
            <pre><code><span>require</span> <span>"lipgloss"</span>

headers = [<span>"Name"</span>, <span>"Language"</span>, <span>"Stars"</span>]

rows = [
  [<span>"bubbletea"</span>, <span>"Ruby"</span>, <span>"✨"</span>],
  [<span>"lipgloss"</span>, <span>"Ruby"</span>, <span>"💄"</span>],
  [<span>"glamour"</span>, <span>"Ruby"</span>, <span>"✨"</span>]
]

table = <span>Lipgloss::Table</span>.new
  .headers(headers)
  .rows(rows)
  .border(<span>:rounded</span>)

puts table.render</code></pre>
          </div>
        </div>

        <div>
          <h4>Markdown Rendering</h4>
          <div>
            <pre><code><span>require</span> <span>"glamour"</span>

markdown = <span>&lt;&lt;~MD
  # Hello Glamour :sparkles:

  This is **bold** and *italic*.

  - Item one
  - Item two
  - Item three

  ```ruby
  puts "Hello, World!"
  ```
MD</span>

puts <span>Glamour</span>.render(markdown,
  style: <span>"dark"</span>,
  width: <span>80</span>,
  emoji: <span>true</span>
)</code></pre>
          </div>
        </div>

        <div>
          <h4>Real-time Charts</h4>
          <div>
            <pre><code><span>require</span> <span>"ntcharts"</span>

chart = <span>Ntcharts::Streamlinechart</span>.new(<span>60</span>, <span>12</span>)

loop <span>do</span>
  chart.push(<span>Math</span>.sin(<span>Time</span>.now.to_f) * <span>4</span> + <span>5</span>)

  print <span>"\e[H\e[2J"</span>
  puts chart.render
  sleep <span>0.1</span>
<span>end</span></code></pre>
          </div>
        </div>

      </div>
    </div>

  <div>
      <h2>The Ecosystem</h2>
      <div>
        <p>
          These Ruby gems are ports and bindings of the original Go libraries from
          <a href="https://charm.sh/" target="_blank" rel="noopener">Charm</a>.
          They bring the same elegant APIs and glamorous terminal experiences to Ruby developers.
        </p>
        <p>
          Some gems use native C extensions that link to compiled Go shared libraries,
          while others are pure Ruby implementations.
        </p>
        <p><span>Ruby 3.2+</span>
          <span>MIT License</span>
        </p>
      </div>
    </div>

  



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacking Washing Machines [video] (203 pts)]]></title>
            <link>https://media.ccc.de/v/39c3-hacking-washing-machines</link>
            <guid>46428496</guid>
            <pubDate>Tue, 30 Dec 2025 01:40:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/39c3-hacking-washing-machines">https://media.ccc.de/v/39c3-hacking-washing-machines</a>, See on <a href="https://news.ycombinator.com/item?id=46428496">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
<ol>
<li>
<a href="https://media.ccc.de/b">
browse
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress">
congress
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress/2025">
2025
</a>
</li>
<li>
<span></span>
event
</li>
</ol>
</div>

<main>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Severin+von+Wnuck-Lipinski">Severin von Wnuck-Lipinski</a> and
<a href="https://media.ccc.de/search?p=Hajo+Noerenberg">Hajo Noerenberg</a>

</p>

<a href="https://media.ccc.de/c/39c3/One" rel="tag">One</a>
<a href="https://media.ccc.de/c/39c3/Hardware" rel="tag">Hardware</a>
Playlists:
<a href="https://media.ccc.de/v/39c3-hacking-washing-machines/playlist">'39c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/39c3-hacking-washing-machines/audio">audio</a>

<!-- %h3 About -->
<p>Almost everyone has a household appliance at home, whether it's a washing machine, dishwasher, or dryer. Despite their ubiquity, little is publicly documented about how these devices actually work or how their internal components communicate. This talk takes a closer look at proprietary bus systems, hidden diagnostic interfaces, and approaches to cloud-less integration of appliances from two well-known manufacturers into modern home automation systems.</p>

<p>Modern home appliances may seem simple from the outside, but inside they contain complex electronic systems, proprietary communication protocols, and diagnostic interfaces rarely documented outside the manufacturer. In this talk, we'll explore the challenges of reverse-engineering these systems: from analyzing appliance control boards and internal communication buses to decompiling and modifying firmware to better understand device functionality.</p>

<p>We'll also look at the security mechanisms designed to protect diagnostic access and firmware readout, and how these protections can be bypassed to enable deeper insight into device operation. Finally, this talk will demonstrate how the results of this research can be used to integrate even legacy home appliances into popular home automation platforms.</p>

<p>This session combines examples and insights from the reverse-engineering of B/S/H/ and Miele household appliances.</p>

<p>Licensed to the public under http://creativecommons.org/licenses/by/4.0</p>

<h3>Download</h3>
<div>

<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>

</div>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</main>





</div>]]></description>
        </item>
    </channel>
</rss>