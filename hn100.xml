<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 02 Mar 2025 21:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Pentium contains a complicated circuit to multiply by three (116 pts)]]></title>
            <link>https://www.righto.com/2025/03/pentium-multiplier-adder-reverse-engineered.html</link>
            <guid>43233143</guid>
            <pubDate>Sun, 02 Mar 2025 18:04:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2025/03/pentium-multiplier-adder-reverse-engineered.html">https://www.righto.com/2025/03/pentium-multiplier-adder-reverse-engineered.html</a>, See on <a href="https://news.ycombinator.com/item?id=43233143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-3533328182698832872" itemprop="description articleBody">
<p>In 1993, Intel released the high-performance Pentium processor, the start of the long-running Pentium line.
I've been examining the Pentium's circuitry in detail and I came across a circuit to multiply by three, a complex circuit with thousands of
transistors. Why does the Pentium have a circuit to multiply specifically by three? Why is it so complicated? In this article, I examine
this multiplier—which I'll call the ×3 circuit—and explain its purpose and how it is implemented.</p>
<p>It turns out that this multiplier is a small part of the Pentium's floating-point multiplier circuit. In particular, the Pentium multiplies two
64-bit numbers using base-8 multiplication, which is faster than binary multiplication.<span id="fnref:speed"><a href="#fn:speed">1</a></span> However, multiplying by 3 needs to be handled as a special case.
Moreover, since the rest of the multiplication process can't start until the multiplication by 3 finishes, this circuit must be very fast.
If you've studied digital design, you may have heard of techniques such as carry lookahead, Kogge-Stone addition, and carry-select addition.
I'll explain how the ×3 circuit combines all these techniques to maximize performance.</p>
<p>The photo below shows the Pentium's thumbnail-sized silicon die under a microscope.
I've labeled the main functional blocks.
In the center is the integer execution unit that performs most instructions. On the left, the code and data caches improve memory performance. The floating point
unit, in the lower right, performs floating point operations.
Almost half of the floating point unit is occupied by the multiplier, which uses an array of adders to rapidly multiply two 64-bit numbers.
The focus of this article is the ×3 circuit, highlighted in yellow near the top of the multiplier.
As you can see, the ×3 circuit takes up a nontrivial amount of the Pentium die, especially considering that its task seems simple.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/pentium-labeled.jpg"><img alt="This die photo of the Pentium shows the location of the multiplier." height="524" src="https://static.righto.com/images/pentium-mult3/pentium-labeled-w500.jpg" title="This die photo of the Pentium shows the location of the multiplier." width="500"></a></p><p>This die photo of the Pentium shows the location of the multiplier.</p>
<h2>Why does the Pentium use base-8 to multiply numbers?</h2>
<p>Multiplying two numbers in binary is conceptually straightforward.
You can think of binary multiplication as similar to grade-school long multiplication, but with binary numbers instead of decimal numbers.
The example below shows how 5×6 is computed in binary: the three terms are added to produce the result.
Conveniently, each term is either the multiplicand (101 in this case) or 0, shifted appropriately, so computing the terms is easy.</p>
<pre>     101
    ×110
     ―――
     000    <span>i.e. 0×101</span>
    101     <span>i.e. 1×101</span>
  +101      <span>i.e. 1×101</span>
   ―――――
   11110
</pre>

<p>Unfortunately, this straightforward multiplication approach is slow. With the three-bit numbers above, there are three terms to add.
But if you multiply two 64-bit numbers, you have 64 terms to add, requiring a lot of time and/or circuitry.</p>
<p>The Pentium uses a more complicated approach, computing multiplication in base 8.
The idea is to consider the multiplier in groups of three bits, so instead of multiplying by 0 or 1 in each step, you multiply by a number from 0 to 7.
Each term that gets added is still in binary, but the number of terms is reduced by a factor of three.
Thus, instead of adding 64 terms, you add 22 terms, providing a substantial reduction in
the circuitry required.
(I'll describe the full details of the Pentium multiplier in a future article.<span id="fnref:details"><a href="#fn:details">2</a></span>)</p>
<p>The downside to radix-8 multiplication is that multiplying by a number from 0 to 7 is much more complicated than multiplying by 0 or 1, which is almost trivial.
Fortunately, there are some shortcuts.
Note that multiplying by 2 is the same as shifting the number to the left by 1 bit position, which is very easy in hardware—you wire each bit one position to the left.
Similarly, to multiply by 4, shift the multiplicand two bit positions to the left.</p>
<p>Multiplying by 7 seems inconvenient, but there is a trick, known as Booth's multiplication algorithm.
Instead of multiplying by 7, you add 8 times the number and subtract the number, ending up with 7 times the number.
You might think this requires two steps, but the trick is to multiply by one more in the digit to the left, so you get the factor of 8 without an additional step.
(A base-10 analogy is that if you want to multiply by 19, you can multiply by 20 and subtract the multiplicand.)
Thus, you can get the ×7 by subtracting.
Similarly, for a ×6 term, you can subtract a ×2 multiple and add ×8 in the next digit.
Thus, the only difficult multiple is ×3.
(What about ×5? If you can compute ×3, you can subtract that from ×8 to get ×5.)</p>
<p>To summarize, the Pentium's radix-8 Booth's algorithm is a fast way to multiply, but it requires a special circuit to produce the ×3 multiple
of the multiplicand.</p>
<h2>Implementing a fast ×3 circuit with carry lookahead</h2>
<p>Multiplying a number by three is straightforward in binary: add the number to itself, shifted to the left one position.
(As mentioned above, shifting to the left is the same as multiplying by two and is easy in hardware.)
Unfortunately, using a simple adder is too slow.</p>
<p>The problem with addition is that carries make addition slow.
Consider calculating 99999+1 by hand.
You'll start with 9+1=10, then carry the one, generating another carry, which generates another carry, and so forth, until you go through all the digits.
Computer addition has the same problem:
If you're adding two numbers, the low-order bits can generate a carry that then propagates through all the bits.
An adder that works this way—known as a ripple carry adder—will be slow because the carry has to ripple through
all the bits.
As a result, CPUs use special circuits to make addition faster.</p>
<p>One solution is the carry-lookahead adder. In this adder, all the carry bits are computed in parallel, before computing
the sums. Then, the sum bits can be computed in parallel, using the carry bits.
As a result, the addition can be completed quickly, without waiting for the carries to ripple through
the entire sum.</p>
<p>It may seem impossible to compute the carries without computing the sum first, but there's a way to do it.
For each bit position, you determine signals called "carry generate" and "carry propagate".
These signals can then be used to determine all the carries in parallel.
The <em>generate</em> signal indicates that the position generates a carry. For instance, if you add binary
<code>1xx</code> and <code>1xx</code> (where <code>x</code> is an arbitrary bit), a carry will be generated from the top bit,
regardless of the unspecified bits.
On the other hand, adding <code>0xx</code> and <code>0xx</code> will never generate a carry.
Thus, the <em>generate</em> signal is produced for the first case but not the second.</p>
<p>But what about <code>1xx</code> plus <code>0xx</code>? We might get a carry, for instance, <code>111+001</code>, but we might not,
for instance, <code>101+001</code>. In this "maybe" case, we set the <em>carry propagate</em> signal, indicating that a carry into the
position will get propagated out of the position. For example, if there is a carry out of
the middle position, <code>1xx+0xx</code> will have a carry from the top bit. But if there is no carry out of the middle position, then
there will not be a carry from the top bit. In other words, the <em>propagate</em> signal indicates that a carry into the top bit will be propagated out of the top
bit.</p>
<p>To summarize, adding <code>1+1</code> will generate a carry. Adding <code>0+1</code> or <code>1+0</code> will propagate a
carry.
Thus, the <em>generate</em> signal is formed at each position by <em>G<sub>n</sub> = A<sub>n</sub>·B<sub>n</sub></em>, where <em>A</em> and <em>B</em> are the inputs.
The <em>propagate</em> signal is <em>P<sub>n</sub> = A<sub>n</sub>+B<sub>n</sub></em>,
the logical-OR of the inputs.<span id="fnref:propagate"><a href="#fn:propagate">3</a></span></p>
<p>Now that the <em>propagate</em> and <em>generate</em> signals are defined, some moderately complex logic<span id="fnref:carry"><a href="#fn:carry">4</a></span> can compute the carry <em>C<sub>n</sub></em> into
each bit position.
The important thing is that all the carry bits can be computed in parallel, without waiting for the carry to ripple through each bit position.
Once each carry is computed, the sum bits can be computed in parallel: <em>S<sub>n</sub> = A<sub>n</sub> ⊕ B<sub>n</sub> ⊕ C<sub>n</sub></em>. In other words, the two input bits and the computed carry are combined with exclusive-or.
Thus, the entire sum can be computed in parallel by using carry lookahead.
However, there are complications.</p>
<h2>Implementing carry lookahead with a parallel prefix adder</h2>
<p>The carry bits can be generated directly from the <em>G</em> and <em>P</em> signals.
However, the straightforward approach requires too much hardware as the number of bits increases.
Moreover, this approach needs gates with many inputs, which are slow for electrical reasons.
For these reasons, the Pentium uses two techniques to keep the hardware requirements for carry lookahead tractable.
First, it uses a "parallel prefix adder" algorithm for carry lookahead across 8-bit chunks.<span id="fnref:parallel-prefix"><a href="#fn:parallel-prefix">7</a></span>
Second, it uses a two-level hierarchical approach for carry lookahead: the upper carry-lookahead circuit handles eight 8-bit chunks, using
the same 8-bit algorithm.<span id="fnref:bytes"><a href="#fn:bytes">5</a></span></p>
<p>The photo below shows the complete ×3 circuit;
you can see that the circuitry is divided into blocks of 8 bits.
(Although I'm calling this a 64-bit circuit, it really produces a 69-bit output: there are 5 "extra" bits on the left to avoid overflow and to provide additional bits for rounding.)</p>
<p><a href="https://static.righto.com/images/pentium-mult3/wide-view.jpg"><img alt="The full ×3 adder circuit under a microscope." height="65" src="https://static.righto.com/images/pentium-mult3/wide-view-w800.jpg" title="The full ×3 adder circuit under a microscope." width="800"></a></p><p>The full ×3 adder circuit under a microscope.</p>
<p>The idea of the parallel-prefix adder is to
produce the <em>propagate</em> and <em>generate</em> signals across ranges of bits, not just single bits as before.
For instance, the <em>propagate</em> signal <em>P<sub>32</sub></em> indicates that a carry in to bit 2 would be propagated out of bit 3,
(This would happen with <code>10xx+01xx</code>, for example.)
And <em>G<sub>30</sub></em> indicates that bits 3 to 0 generate a carry out of bit 3.
(This would happen with <code>1011+0111</code>, for example.)</p>
<p>Using some mathematical tricks,<span id="fnref:pg"><a href="#fn:pg">6</a></span> you can take the <em>P</em> and <em>G</em> values for two smaller ranges and merge them into
the <em>P</em> and <em>G</em> values for the combined range.
For instance, you can start with the <em>P</em> and <em>G</em> values for bits 0 and 1, and produce <em>P<sub>10</sub></em> and <em>G<sub>10</sub></em>, the <em>propagate</em> and <em>generate</em>
signals describing two bits.
These could be merged with <em>P<sub>32</sub></em> and <em>G<sub>32</sub></em> to produce <em>P<sub>30</sub></em> and <em>G<sub>30</sub></em>,
indicating if a carry is propagated across bits 3-0 or generated by bits 3-0.
Note that <em>G<sub>n0</sub></em> tells us if a carry is generated into bit <em>n+1</em> from all the lower bits, which is the <em>C<sub>n+1</sub></em> carry value that we
need to compute the final sum.
This merging process is more efficient than the "brute force" implementation of the carry-lookahead logic since
logic subexpressions can be reused.</p>
<p>There are many different ways that you can combine the <em>P</em> and <em>G</em> terms to generate the necessary terms.<span id="fnref:brent-kung"><a href="#fn:brent-kung">8</a></span>
The Pentium uses an approach called
<a href="https://en.wikipedia.org/wiki/Kogge%E2%80%93Stone_adder">Kogge-Stone</a>
that attempts to minimize the total delay while keeping the amount of circuitry reasonable.
The diagram below is the standard diagram that illustrates how a
Kogge-Stone adder works.
It's rather abstract, but I'll try to explain it.
The diagram shows how the <em>P</em> and <em>G</em> signals are merged to produce each output at the bottom. 
Each square box at the top generates the <em>P</em> and <em>G</em> signals for that bit.
Each line corresponds to both the <em>P</em> and the <em>G</em> signal.
Each diamond combines two ranges of <em>P</em> and <em>G</em> signals to generate new <em>P</em> and <em>G</em> signals for the combined
range.
Thus, the signals cover wider ranges of bits as they progress downward, ending with the <em>G<sub>n0</sub></em> outputs that indicate carries.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/kogge-stone.jpg"><img alt="A diagram of an 8-bit Kogge-Stone adder highlighting the carry out of bit 6 (green) and out of bit 2 (purple). Modification of the diagram by Robey Pointer, Wikimedia Commons." height="437" src="https://static.righto.com/images/pentium-mult3/kogge-stone-w500.jpg" title="A diagram of an 8-bit Kogge-Stone adder highlighting the carry out of bit 6 (green) and out of bit 2 (purple). Modification of the diagram by Robey Pointer, Wikimedia Commons." width="500"></a></p><p>A diagram of an 8-bit Kogge-Stone adder highlighting the carry out of bit 6 (green) and out of bit 2 (purple). Modification of the diagram by Robey Pointer, <a href="https://commons.wikimedia.org/wiki/File:Kogge-stone-8-bit.png">Wikimedia Commons</a>.</p>
<p>I've labeled a few of the intermediate signals so you can get an idea of how it works. Circuit "A" combines
<em>P<sub>7</sub></em> and <em>G<sub>7</sub></em> with <em>P<sub>6</sub></em> and <em>G<sub>6</sub></em> to produce the signals describing two bits: <em>P<sub>76</sub></em> and
<em>G<sub>76</sub></em>.
Similarly, circuit "B" combines
<em>P<sub>76</sub></em> and <em>G<sub>76</sub></em> with <em>P<sub>54</sub></em> and <em>G<sub>54</sub></em> to produce the signals describing four bits: <em>P<sub>74</sub></em> and
<em>G<sub>74</sub></em>.
Finally, circuit "C" produces the final outputs for bit 7: <em>P<sub>70</sub></em> and <em>G<sub>70</sub></em>.
Note that most of the intermediate results are used twice, reducing the amount of circuitry.
Moreover, there are at most three levels of combination circuitry, reducing the delay compared to a deeper network.</p>
<p>The key point is the <em>P</em> and <em>G</em> values are computed in parallel so the carry bits can all be computed in parallel,
without waiting for the carry to ripple through all the bits.
(If this explanation doesn't make sense, see my discussion of the Kogge-Stone adder
in the <a href="https://www.righto.com/2025/01/pentium-carry-lookahead-reverse-engineered.html">Pentium's division circuit</a> for a different—but maybe still confusing—explanation.)</p>
<h2>Recursive Kogge-Stone lookahead</h2>
<p>The Kogge-Stone approach can be extended to 64 bits, but the amount of circuitry and wiring becomes overwhelming.
Instead, the Pentium uses a recursive, hierarchical approach with two levels of Kogge-Stone lookahead.
The lower layer uses eight Kogge-Stone adders as described above, supporting 64 bits in total.</p>
<p>The upper layer uses a single eight-bit Kogge-Stone lookahead circuit, treating each of the lower chunks as a single bit.
That is, a lower chunk has a propagate signal <em>P</em> indicating that a carry into the chunk will be propagated out, as well as a generate signal <em>G</em>
indicating that the chunk generates a carry.
The upper Kogge-Stone circuit combines these chunked signals to determine if carries will be generated or propagated by groups of chunks.<span id="fnref:recursive"><a href="#fn:recursive">9</a></span></p>
<p>To summarize, each of the eight lower lookahead circuits computes the carries within an 8-bit chunk.
The upper lookahead circuit computes the carries into and out of each 8-bit chunk.
In combination, the circuits rapidly provide all the carries needed to compute the 64-bit sum.</p>
<h2>The carry-select adder</h2>
<p>Suppose you're on a game show: "What is 553 + 246 + <em>c</em>? In 10 seconds, I'll tell you if <em>c</em> is 0 or 1 and whoever gives the answer first wins $1000."
Obviously, you shouldn't just sit around until you get <em>c</em>. You should do the two sums now, so you can hit the buzzer as soon as <em>c</em> is announced.
This is the concept behind the carry-select adder: perform two additions—with a carry-in and without--and then supply the correct answer as soon as the
carry is available.
The carry-select adder requires additional hardware—two adders along with a multiplexer to select the result—but it overlaps the time to compute
the sum with the time to compute the carry.
In effect, the addition and the carry lookahead operations are performed in parallel, with the multiplexer combining the results from each.</p>
<p>The Pentium uses a carry-select adder for each 8-bit chunk in the ×3 circuit. The carry from the second-level carry-lookahead selects which sum should be produced for the chunk.
Thus, the time to compute the carry is overlapped with the time to compute the sum.</p>
<h2>Putting the adder pieces together</h2>
<p>The image below zooms in on an 8-bit chunk of the ×3 multiplier, implementing an 8-bit adder.
Eight input lines are at the top (along with some unrelated wires). Note that each
input line splits with a signal going to the adder on the left and a signal going to the right.
This is what causes the adder to multiply by 3: it adds the input and the input shifted one bit to the left, i.e. multiplied by two.
The top part of the adder has eight circuits to produce the <em>propagate</em> and <em>generate</em> signals.
These signals go into the 8-bit Kogge-Stone lookahead circuit. Although most of the adder consists of a circuit block repeated eight times, the
Kogge-Stone circuitry appears chaotic. 
This is because each bit of the Kogge-Stone circuit is different—higher bits are more complicated to compute than lower bits.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/block-poly-labeled.jpg"><img alt="One 8-bit block of the ×3 circuit." height="323" src="https://static.righto.com/images/pentium-mult3/block-poly-labeled-w500.jpg" title="One 8-bit block of the ×3 circuit." width="500"></a></p><p>One 8-bit block of the ×3 circuit.</p>
<p>The lower half of the circuit block contains an 8-bit carry-select adder. This circuit produces two sums, with multiplexers selecting the correct sum
based on the carry into the block.
Note that the carry-select adder blocks are narrower than the other circuitry.<span id="fnref:cell"><a href="#fn:cell">10</a></span>
This makes room for a Kogge-Stone block on the left. The second level Kogge-Stone circuitry is split up; the 8-bit carry-lookahead circuitry has one bit
implemented in each block of the adder, and produces the carry-in signal for that adder block.
In other words, the image above includes 1/8 of the second-level Kogge-Stone circuit.
Finally, eight driver circuits amplify the output bits before they are sent to the rest of the floating-point multiplier.</p>
<p>The block diagram below shows the pieces are combined to form the ×3 multiplier.
The multiplier has eight 8-bit adder blocks (green boxes, corresponding to the image above).
Each block computes eight bits of the total sum.
Each block provides
<em>P<sub>70</sub></em> and <em>G<sub>70</sub></em> signals to the second-level lookahead, which determines if each block receives a carry in.
The key point to this architecture is that everything is computed in parallel, making the addition fast.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/overall-diagram.jpg"><img alt="A block diagram of the multiplier." height="312" src="https://static.righto.com/images/pentium-mult3/overall-diagram-w600.jpg" title="A block diagram of the multiplier." width="600"></a></p><p>A block diagram of the multiplier.</p>
<p>In the diagram above, the first 8-bit block is expanded to show its contents. The 8-bit lookahead circuit generates the <em>P</em> and <em>G</em> signals that determine the
internal carry signals.
The carry-select adder contains two 8-bit adders that use the carry lookahead values.
As described earlier, one adder assumes that the block's carry-in is 1 and the second assumes the carry-in is 0. When the real carry in value is
provided by the second-level lookahead circuit, the multiplexer selects the correct sum.</p>
<p>The photo below shows how the complete multiplier is constructed from 8-bit blocks.
The multiplier produces a 69-bit output; there are 5 "extra" bits on the left.
Note that the second-level Kogge-Stone blocks are larger on the right than the left since the lookahead circuitry is more complex for higher-order bits.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/wide-view.jpg"><img alt="The full adder circuit. This is the same image as before, but hopefully it makes more sense at this point." height="65" src="https://static.righto.com/images/pentium-mult3/wide-view-w800.jpg" title="The full adder circuit. This is the same image as before, but hopefully it makes more sense at this point." width="800"></a></p><p>The full adder circuit. This is the same image as before, but hopefully it makes more sense at this point.</p>
<p>Going back to the full ×3 circuit above, you can see that the 
8 bits on the right have significantly simpler circuitry.
Because there is no carry-in to this block, the carry-select circuitry can be omitted.
The block's internal carries, generated by the Kogge-Stone lookahead circuitry, are added using exclusive-NOR gates.
The diagram below shows the implementation of an XNOR gate, using inverters and a multiplexer.</p>
<h2>The XNOR circuit</h2>
<p>I'll now describe one of the multiplier's circuits at the transistor level, in particular an XNOR gate.
It's interesting to look at XNOR because XNOR (like XOR) is a tricky gate to implement and different processors use very different approaches. 
For instance, the Intel 386 implements XOR from AND-NOR gates (<a href="https://www.righto.com/2023/12/386-xor-circuits.htmla">details</a>) while the
Z-80 uses pass transistors (<a href="https://www.righto.com/2013/09/understanding-z-80-processor-one-gate.html">details</a>).
The Pentium, on the other hand, uses a multiplexer.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/xnor-diagram.jpg"><img alt="An exclusive-NOR gate with the components labeled. This is a focus-stacked image." height="271" src="https://static.righto.com/images/pentium-mult3/xnor-diagram-w500.jpg" title="An exclusive-NOR gate with the components labeled. This is a focus-stacked image." width="500"></a></p><p>An exclusive-NOR gate with the components labeled. This is a focus-stacked image.</p>
<p>The diagram above shows one of the XNOR gates in the adder's low bits.<span id="fnref:low-bits"><a href="#fn:low-bits">11</a></span>
The gate is constructed from four inverters and a pass-transistor multiplexer.
Input B selects one of the multiplexer's two inputs: input A or input A inverted. The result is the XNOR function.
(Inverter 1 buffers the input, inverter 5 buffers the output, and inverter 4 provides the complemented B signal to drive the multiplexer.)</p>
<p>For the photo, I removed the top two metal layers from the chip, leaving the bottom metal layer, called M1. 
The doped silicon regions are barely visible beneath the metal.
When a polysilicon line crosses doped silicon, it forms the gate of a transistor.
This CMOS circuit has NMOS transistors at the top and PMOS transistors at the bottom.
Each inverter consists of two transistors, while the multiplexer consists of four transistors.</p>
<h2>The BiCMOS output drivers</h2>
<p>The outputs from the ×3 circuit require high current.
In particular, each signal from the ×3 circuit can drive up to 22 terms in the floating-point multiplier.
Moreover, the destination circuits
can be a significant distance from the ×3 circuit due to the size of the multiplier.
Since the ×3 signals are connected to many transistor gates through long wires, the capacitance is high, requiring high current to change the
signals quickly.</p>
<p>The Pentium is constructed with a somewhat unusual process called BiCMOS, which combines bipolar transistors and CMOS on the same chip.
The Pentium extensively uses BiCMOS circuits since they reduced signal delays by up to 35%.
Intel also used BiCMOS for the Pentium Pro, Pentium II, Pentium III, and Xeon processors.
However, as chip voltages dropped, the benefit from bipolar transistors dropped too and BiCMOS was eventually abandoned.</p>
<p>The schematic below shows a simplified BiCMOS driver that inverts its input.
A 0 input turns on the upper inverter, providing current into the bipolar (NPN) transistor's base.
This turns on the transistor, causing it to pull the output high strongly and rapidly.
A 1 input, on the other hand, will stop the current flow through the NPN transistor's base, turning it off.
At the same time, the lower inverter will pull the output low. (The NPN transistor can only pull the output high.)</p>
<p>Note the asymmetrical construction of the inverters. Since the upper inverter must provide a large current into the NPN transistor's base, it is designed to produce a strong (high-current)
positive output and a weak low output.
The lower inverter, on the other hand, is responsible for pulling the output low. Thus, it is constructed to produce a strong low output, while the
high output can be weak.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/bicmos-driver.jpg"><img alt="The basic circuit for a BiCMOS driver." height="150" src="https://static.righto.com/images/pentium-mult3/bicmos-driver-w200.jpg" title="The basic circuit for a BiCMOS driver." width="200"></a></p><p>The basic circuit for a BiCMOS driver.</p>
<p>The driver of the ×3 circuit goes one step further: it uses a BiCMOS driver to drive a second BiCMOS driver.
The motivation is that the high-current inverters have fairly large transistor gates, so they need to be driven with high current (but not as much as they produce, so there isn't an infinite regress).<span id="fnref:logical-effort"><a href="#fn:logical-effort">12</a></span></p>
<p>The schematic below shows the BiCMOS driver circuit that the ×3 multiplier uses.
Note the large, box-like appearance of the NPN transistors, very different from the regular MOS transistors.
Each box contains two NPN transistors sharing collectors: a larger transistor on the left and a smaller one on the right.
You might expect these transistors to work together, but the contiguous transistors are part of two
separate circuits.
Instead, the small NPN transistor to the left and the large NPN transistor to the right are part of the same circuit.</p>
<p><a href="https://static.righto.com/images/pentium-mult3/driver-diagram.jpg"><img alt="One of the output driver circuits, showing the polysilicon and silicon." height="292" src="https://static.righto.com/images/pentium-mult3/driver-diagram-w800.jpg" title="One of the output driver circuits, showing the polysilicon and silicon." width="800"></a></p><p>One of the output driver circuits, showing the polysilicon and silicon.</p>
<p>The inverters are constructed as standard CMOS circuits with PMOS transistors to pull the output high and NMOS transistors to pull the output low.
The inverters are carefully structured to provide asymmetrical current, making them more interesting than typical inverters.
Two pullup transistors have a long gate, making these transistors unusually weak.
Other parts of the inverters have multiple transistors in parallel, providing more current.
Moreover, the inverters have unusual layouts, with the NMOS and PMOS transistors widely separated to make the layout more efficient.
For more on BiCMOS in the Pentium, see my article on <a href="https://www.righto.com/2025/01/pentium-reverse-engineering-bicmos.html">interesting BiCMOS circuits in the Pentium</a>.</p>
<h2>Conclusions</h2>
<p>Hardware support for computer multiplication has a long history going back to the 1950s.<span id="fnref:history"><a href="#fn:history">13</a></span>
Early microprocessors, though, had very limited capabilities, so microprocessors such as the 6502 didn't have hardware support for multiplication;
users had to implement multiplication in software through shifts and adds.
As hardware advanced, processors provided multiplication instructions but they were still slow.
For example, the Intel 8086 processor (1978) implemented multiplication in microcode, performing a slow shift-and-add loop internally.
Processors became exponentially more powerful over time, as described by Moore's Law, allowing later processors to include dedicated multiplication hardware.
The 386 processor (1985) included a <a href="https://bitsavers.trailing-edge.com/components/intel/80386/231746-001_Introduction_to_the_80386_Apr86.pdf#page=9">multiply unit</a>, but it was still slow, taking up to 41 clock cycles for a multiplication instruction.</p>
<p>By the time of the Pentium (1993), microprocessors contained millions of transistors, opening up new possibilities for design.
With a seemingly unlimited number of transistors, chip architects could look at complicated new approaches to squeeze more performance out of a system.
This ×3 multiplier contains roughly 9000 transistors, a bit more than an entire Z80 microprocessor (1976).
Keep in mind that the ×3 multiplier is a small part of the floating-point multiplier, which is part of the floating-point unit in the
Pentium.
Thus, this small piece of a feature is more complicated than an entire microprocessor from 17 years earlier, illustrating
the incredible growth in processor complexity.</p>
<p>I plan to write more about the implementation of the Pentium, so
follow me on Bluesky (<a href="https://bsky.app/profile/righto.com">@righto.com</a>) or <a href="https://www.righto.com/feeds/posts/default">RSS</a> for updates. (I'm no longer on Twitter.)
The <a href="https://www.righto.com/2024/08/pentium-navajo-fairchild-shiprock.html">Pentium Navajo rug</a> inspired me to examine the Pentium in more detail.</p>
<h2>Footnotes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Speedrunners are vulnerability researchers, they just don't know it yet (122 pts)]]></title>
            <link>https://zetier.com/speedrunners-are-vulnerability-researchers/</link>
            <guid>43232880</guid>
            <pubDate>Sun, 02 Mar 2025 17:40:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zetier.com/speedrunners-are-vulnerability-researchers/">https://zetier.com/speedrunners-are-vulnerability-researchers/</a>, See on <a href="https://news.ycombinator.com/item?id=43232880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p><img src="https://zetier.com/wp-content/uploads/2025/02/speedrunners-are-vulnerability-researchers-featured-image.jpg" alt="/nl_img1">
			</p>
						
			<!-- wp:paragraph -->
<p>Thousands of video game enthusiasts are developing experience in the cybersecurity industry by accident. They have a fun hobby, pouring over the details of their favorite games, and they don't know they could be doing something very similar… by becoming a vulnerability researcher.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>That probably requires some backstory, especially from a cybersecurity company's blog!</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2 id="h-what-s-a-speedrun">What's a speedrun?</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Basically as soon as video games were released, people have been trying to beat them faster than their friends (or enemies) can. Gamers will do this for practically any game on the planet – but the most popular games, or the ones with the most cultural weight and cultish following, naturally end up with the fiercest competition. Speedrunners will run through their favorite game hundreds or thousands of times in order to get to get to the top of community-driven leaderboards for the fastest time… which puts incentives on that video game's community to find the <em>absolute fastest</em> way to clear the game, no matter how strange.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>"Any percent" speedruns, or "any%" more commonly, are usually one of the most popular categories of speedrun for any given game. In it, all rules are off and no weird behavior is disallowed: intentionally triggering bugs in the game, which the developers never intended for the players to be able to perform, often have the potential to shave double-digit percentages of time off existing routes by cutting out entire swathes of the game from having to be played at all. Why do 1 -&gt; 2 -&gt; 3 if you can do a cool trick and skip from 1 -&gt; 3 directly?</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>A lot of these glitches revolve around extremely precise movement… but for the most dedicated fans, they'll go even further.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2 id="h-glitch-hunting-is-reverse-engineering">Glitch hunting is reverse engineering</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Entire groups will spring up inside a game's speedrunning community dedicated to discovering new glitches, and oftentimes they'll apply <em>engineering</em> to it.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>These enthusiasts won't just try weird things in the game over and over (although that definitely helps!) – they'll use tools that are standard in the cybersecurity industry to pull apart how software works internally, such as <a href="https://hex-rays.com/ida-pro" target="_blank" rel="noreferrer noopener"><span>IDA Pro</span></a> or <a href="https://ghidra-sre.org/" target="_blank" rel="noreferrer noopener"><span>Ghidra</span></a>, to discover <em>exactly</em> what makes their target video game tick. On top of static analysis, they'll leverage dynamic analysis as well: glitch hunters will use dynamic introspection and debugging tools, like the Dolphin Emulator’s memory viewer or Cheat Engine, to get a GDB-like interface for figuring out the program's internal data structures and how information is recorded.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>And even further, they'll develop entirely new tooling: I've seen groups like the <em>Paper Mario: The Thousand Year Door</em> community reverse engineer game file formats and <a href="https://github.com/Cuyler36/Ghidra-GameCube-Loader" target="_blank" rel="noreferrer noopener"><span>create Ghidra program loaders</span></a>, or other groups completely re-implement Ghidra disassembled code in C so they can stick it under a <a href="https://en.wikipedia.org/wiki/Fuzzing" target="_blank" rel="noreferrer noopener"><span>fuzzer</span></a> in isolation. Some of the speedrun glitch hunters are incredibly technically competent, using the exact same tooling and techniques that people in the cybersecurity industry use for reverse engineering every day.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2 id="h-and-it-s-vulnerability-research">…And it’s vulnerability research</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Not only do these groups do reverse engineering, but they also are doing <em>vulnerability research.</em> Remember, they don't only try to figure out how games work, but they try to break the game in any way possible. These glitches end up looking stunningly similar to how memory corruption exploits work for any other computer program: they'll find <a href="https://arstechnica.com/information-technology/2015/08/how-security-flaws-work-the-buffer-overflow/" target="_blank" rel="noreferrer noopener"><span>buffer overflows</span></a>, <a href="https://cwe.mitre.org/data/definitions/416.html" target="_blank" rel="noreferrer noopener"><span>use-after-frees</span></a>, and incorrect state machine transitions in their target games.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>And perhaps most impressively, they'll <em>productize</em> their exploits, unlike a lot of people in the cybersecurity industry. Some vulnerability researchers will develop a proof-of-concept to demonstrate a bug – but never actually develop the technical chops on how that exploit would need to be developed further for an adversary to <em>use</em> it. They might intellectually know how to weaponize a buffer overflow, or a use-after-free, but speedrunning groups by necessity are actually <em>doing</em> it. Oftentimes, actually using these glitches requires working through extremely restrictive constraints, both for what inputs they have control over and what parts of the program they can influence.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><em>Super Mario World</em> runners will place items in extremely precise locations so that the X,Y coordinates <a href="https://www.youtube.com/watch?v=14wqBA5Q1yc" target="_blank" rel="noreferrer noopener"><span>form shellcode</span></a> they can jump to with a dangling reference. <em>Legend of Zelda: Ocarina of Time</em> players will do <a href="https://www.zeldaspeedruns.com/oot/srm/srm-overview" target="_blank" rel="noreferrer noopener"><span>heap grooming</span></a> and write a function pointer using the IEEE-754 floating point number bit representation so the game “wrong warps” directly to the end credit sequence... with nothing more than a game controller and a steady hand.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:image {"lightbox":{"enabled":false},"id":3997,"sizeSlug":"large","linkDestination":"custom"} -->
<figure><a href="https://www.youtube.com/watch?v=kpk2tdsPh0A" target="_blank" rel=" noreferrer noopener"><img src="https://zetier.com/wp-content/uploads/2025/02/super-mario-n64-glitch-1024x576.jpg" alt=""></a><figcaption><em>Screenshot from an in-depth technical explanation of a Super Mario 64 glitch. <a href="https://www.youtube.com/watch?v=kpk2tdsPh0A" target="_blank" rel="noreferrer noopener"><span>Watch on YouTube.</span></a></em></figcaption></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:heading -->

<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Some of the game communities will even take it a step further! Tool-assisted speedruns, or "TAS" runs, will perform glitches so precise that they can't reliably be performed by human beings <em>at all</em>. They'll leverage frame-by-frame input recordings in order to hit the right angle on a game controller's stick, every time; they'll hit buttons on the exact video game tick, every time. </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>And because they have such precise control over their actions in games, they'll likewise be able to consider game glitches with exacting precision. TAS authors are able to leverage inspecting the video game with memory debuggers to craft a use-after-free with the perfect heap spray, or <a href="https://tasvideos.org/5384S" target="_blank" rel="noreferrer noopener"><span>write multiple stages</span></a> of shellcode payload in their player inventory with button presses.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>There's even an entire event at the most popular speedrunning conference, Awesome Games Done Quick/AGDQ, called "TASbot." During it, a robot does all the inputs via a hard-wired controller to perform a tool-assisted speedrun in <em>real time</em> – so it can do things like get arbitrary code execution and use that to replace the video game with an entirely new one, using <a href="https://www.youtube.com/watch?v=jnZ2NNYySuE" target="_blank" rel="noreferrer noopener"><span>nothing but controller inputs</span></a>.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2 id="h-an-industry-exists">An industry exists!</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>The fact these people are so technically competent only throws in stark relief how disconnected some of them are from the larger cybersecurity industry. Speedrun glitch hunters will develop heap use-after-free exploits, with accompanied technical write-ups on the level of Google Project Zero… and in doing so, refer to it as an "item storage" glitch, because they developed the knowledge from first principles without ever reading a <a href="https://phrack.org/" target="_blank" rel="noreferrer noopener"><span>Phrack</span></a> article. They'll re-implement disassembled code from Ghidra in C for automated glitch discovery, but without any exposure to <a href="https://lcamtuf.coredump.cx/afl/" target="_blank" rel="noreferrer noopener"><span>American Fuzzy Lop</span></a> or the large academic body of work driving fuzzer research.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>And, critically for us here at Zetier, they don't know you can get paid to do a job <em>very</em> close to finding video game glitches, and so they don't know to apply to our reverse engineering or vulnerability research <a href="https://zetier.com/careers/" target="_blank" rel="noreferrer noopener"><span>job postings</span></a>. A lot of these video game glitch hunters, even the ones writing novel Ghidra loaders or runtime memory analysis scripts, don't think of what they're doing as anything more than a fun hobby; they might go become a normal software engineer, if that. Some of them will look up "IDA Pro" on LinkedIn and see a million malware analysis job postings. No offense to my malware analysis friends, but malware reverse engineering and vulnerability research are two very different roles!</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Vulnerability research in industry, unlike more “normal” malware analysis jobs, is usually in the form of an engineer spending significant time investigating exactly how a program works. Like video game glitch discovery, they don’t just care about <em>what</em> it does, but <em>how</em> it does it – and <em>why</em> the authors implemented it in that way, along with how that behavior may affect other parts of the program. Oftentimes, you end up building up a repertoire of small, innocuous “huh that’s weird”-style bugs that are individually useless… until you find some missing piece. And like game glitches, the most satisfying of discoveries on the job are from realizations that there’s a fundamental gap in thinking by the authors, where you don’t just find one glitch but an entire <em>family</em> of glitches, all from the same root cause.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:image {"lightbox":{"enabled":false},"id":4020,"sizeSlug":"large","linkDestination":"custom"} -->
<figure><a href="https://www.youtube.com/watch?v=PsIb3OZaYAs" target="_blank" rel=" noreferrer noopener"><img src="https://zetier.com/wp-content/uploads/2025/02/speedrunners-are-vulnerability-researchers-pokemon-commentary-1024x576.png" alt=""></a><figcaption><em>A glimpse of an arbitrary code execution (ACE) exploit</em> <em>walk-through</em>. <em><a href="https://www.youtube.com/watch?v=PsIb3OZaYAs" target="_blank" rel="noreferrer noopener"><span>See the video.</span></a></em></figcaption></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>I personally love reading the technical game glitch write-ups that come out of speedrunning communities. Lots of my coworkers, and other people in the industry, likewise enjoy them. I love glitch write-ups <em>because</em> they remind me of the great parts of my job: extremely deep dives into the internals of how programs work, and working around odd constraints. Exploiting vulnerabilities requires performing mental gymnastics in order to chain seemingly innocuous primitives, like <a href="https://archives.glitchcity.info/forums/board-110/thread-7770/page-0.html" target="_blank" rel="noreferrer noopener"><span>walking around</span></a> out-of-bounds in Pokemon, together to <em>do the thing</em> in a way that allows the author to express their creativity and mastery over a piece of software.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Talking to people in speedrunning communities who love pouring over Assembly, or figuring out exactly what the implications are for a 1-byte buffer overflow in a textbox, only for them to shrug and explain they're reluctantly working in a non-technical industry, comes across to me as a shame. If any of these descriptions speak to you, or bring to mind one of your friends, reach out to <a href="mailto:hello@zetier.com" target="_blank" rel="noreferrer noopener"><span>hello@zetier.com</span></a>. We'd love to chat.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3 id="h-let-the-interwebs-know-that-vulnerability-researchers-exist">Let the interwebs know that vulnerability researchers exist:</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p><em><strong> <span><a href="https://news.ycombinator.com/submit" target="_blank" rel="noreferrer noopener">Share this on HackerNews </a></span></strong></em><strong><a href="https://news.ycombinator.com/submit" target="_blank" rel="noreferrer noopener"><span>→</span></a></strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->

<!-- wp:paragraph -->

<!-- /wp:paragraph -->					
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek releases distributed DuckDB (240 pts)]]></title>
            <link>https://www.definite.app/blog/smallpond</link>
            <guid>43232410</guid>
            <pubDate>Sun, 02 Mar 2025 17:00:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.definite.app/blog/smallpond">https://www.definite.app/blog/smallpond</a>, See on <a href="https://news.ycombinator.com/item?id=43232410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>March 2, 2025</span><span>10 minute read</span></p><p>Mike Ritchie</p></div><div><p>I didn't have "DeepSeek releases distributed DuckDB" on my 2025 bingo card.</p>
<p>You may have stumbled across <a href="https://github.com/deepseek-ai/smallpond">smallpond</a> from Twitter/X/LinkedIn hype. From that hype, you might have concluded Databricks and Snowflake are dead 😂. Not so fast. The reality is, although this is interesting and powerful open source tech, it's unlikely to be widely used in analytics anytime soon. Here's a concise breakdown to help you cut through the noise.</p>
<p>We'll cover what <code>smallpond</code> and its companion, <code>3FS</code>, are, how you can (maybe) use them, and if they're suitable for your use case.</p>
<h3>What is <code>smallpond</code>?</h3>
<p><code>smallpond</code> is a lightweight, distributed data processing framework recently introduced by DeepSeek AI. It extends DuckDB—typically a high-performance, single-node analytics database—to handle larger datasets across multiple nodes. <code>smallpond</code> enables DuckDB to manage distributed workloads by using a distributed storage and compute system.</p>
<p>Key features:</p>
<ul>
<li><strong>Distributed Analytics</strong>: Allows DuckDB to handle larger-than-memory datasets by partitioning data and running analytics tasks in parallel.</li>
<li><strong>Open Source Deployment</strong>: If you can manage to get it running, 3FS would give you powerful and performant storage at a fraction of the cost of alternatives.</li>
<li><strong>Manual Partitioning</strong>: Data is manually partitioned by users, and <code>smallpond</code> distributes these partitions across nodes for parallel processing.</li>
</ul>
<h3>What is 3FS?</h3>
<p>3FS, or Fire-Flyer File System, is a high-performance parallel file system also developed by DeepSeek. It's optimized specifically for AI and HPC workloads, offering extremely high throughput and low latency by using SSDs and RDMA networking technology. Think of 3FS as the high-speed, distributed storage backend that <code>smallpond</code> leverages for fast, scalable analytics.</p>
<p>Key features:</p>
<ul>
<li><strong>High Performance</strong>: Achieves multi-terabyte-per-minute throughput, ideal for massive datasets.</li>
<li><strong>Optimized for AI workloads</strong>: Delivers consistent, high-speed data access, minimizing bottlenecks common in other storage systems.</li>
<li><strong>Open-source but Complex</strong>: Powerful yet requires specialized hardware and significant expertise to deploy effectively.</li>
</ul>
<h3>How Can I Use It?</h3>
<p>Using <code>smallpond</code> and 3FS depends largely on your data size and infrastructure:</p>
<ul>
<li><strong>Under 10TB</strong>: <code>smallpond</code> is likely unnecessary unless you have very specific distributed computing needs. A single-node DuckDB instance or simpler storage solutions will be simpler and possibly more performant.</li>
<li><strong>10TB to 1PB</strong>: <code>smallpond</code> begins to shine. You'd set up a cluster with several nodes, leveraging 3FS or another fast storage backend to achieve rapid parallel processing.</li>
<li><strong>Over 1PB (Petabyte-Scale)</strong>: <code>smallpond</code> and 3FS were explicitly designed to handle massive datasets. At this scale, you'd need to deploy a larger cluster with substantial infrastructure investments.</li>
</ul>
<p>Deployment typically involves:</p>
<ol>
<li>Setting up a compute cluster (AWS EC2, Google Compute Engine, or on-prem).</li>
<li>Deploying 3FS on nodes with high-performance SSDs and RDMA networking.</li>
<li>Installing <code>smallpond</code> via Python to run distributed DuckDB tasks across your cluster.</li>
</ol>
<p>Steps #1 and #3 are really easy. Step #2 is <strong>very</strong> hard. 3FS is new, so there's no guide on how you would set it up on AWS (if that's even possible). You could certainly deploy it on bare metal, but you'd be descending into a lower level of DevOps hell.</p>
<blockquote>
<p>Note: if you're in the 95% of companies in the under 10TB bucket, you should really try <a href="https://www.definite.app/">Definite</a>.</p>
</blockquote>
<p>I experimented with running <code>smallpond</code> with S3 swapped in for 3FS <a href="https://github.com/definite-app/smallpond">here</a>, but it's unclear what, if any, performance gains you'd get over scaling up a single node for moderate-sized data.</p>
<h3>Is <code>smallpond</code> for me?</h3>
<p><strong>tl;dr: probably not.</strong></p>
<p>Whether you'd want to use <code>smallpond</code> depends on several factors:</p>
<ul>
<li><strong>Your Data Scale</strong>: If your dataset is under 10TB, <code>smallpond</code> adds unnecessary complexity and overhead. For larger datasets (&gt;10TB), it provides substantial performance advantages.</li>
<li><strong>Infrastructure Capability</strong>: <code>smallpond</code> and 3FS require significant infrastructure and DevOps expertise. Without a dedicated team experienced in cluster management, this could be challenging.</li>
<li><strong>Analytical Complexity</strong>: <code>smallpond</code> excels at partition-level parallelism but is less optimized for complex distributed joins. For workloads requiring intricate joins across partitions, performance might be limited.</li>
</ul>
<h3>How Smallpond Works (Under the Hood)</h3>
<p><strong>Lazy DAG Execution</strong><br>
Smallpond uses lazy evaluation for operations like <code>map()</code>, <code>filter()</code>, and <code>partial_sql()</code>. It doesn't run these immediately. Instead, it builds a logical execution plan as a directed acyclic graph (DAG), where each operation becomes a node (e.g., <code>SqlEngineNode</code>, <code>HashPartitionNode</code>, <code>DataSourceNode</code>).</p>
<p>Nothing actually happens until you trigger execution explicitly with actions like:</p>
<ul>
<li><code>write_parquet()</code> — Writes data to disk</li>
<li><code>to_pandas()</code> — Converts results to a pandas DataFrame</li>
<li><code>compute()</code> — Forces computation explicitly</li>
<li><code>count()</code> — Counts rows</li>
<li><code>take()</code> — Retrieves a subset of rows</li>
</ul>
<p>This lazy evaluation is efficient because it avoids unnecessary computations and optimizes the workflow.</p>
<p><strong>From Logical to Execution Plan</strong><br>
When you finally trigger an action, the logical plan becomes an execution plan made of specific tasks (e.g., <code>SqlEngineTask</code>, <code>HashPartitionTask</code>). These tasks are the actual work units distributed and executed by Ray.</p>
<p><strong>Ray Core and Distribution</strong><br>
Smallpond’s distribution leverages Ray Core at the Python level, using partitions for scalability. Partitioning can be done manually, and Smallpond supports:</p>
<ul>
<li><strong>Hash partitioning</strong> (based on column values)</li>
<li><strong>Even partitioning</strong> (by files or row counts)</li>
<li><strong>Random shuffle partitioning</strong></li>
</ul>
<p>Each partition runs independently within its own Ray task, using DuckDB instances to process SQL queries. This tight integration with Ray emphasizes horizontal scaling (adding more nodes) rather than vertical scaling (larger, more powerful nodes). To use it at scale, you’ll need a Ray cluster. You can run one on your own infrastructure on a cloud provider (e.g. AWS), but if you just want to test this out, it'll be easier to get started with Anyscale (founded by Ray creators).</p>
<h3>Conclusion</h3>
<p><code>smallpond</code> and 3FS offer powerful capabilities for scaling DuckDB analytics across large datasets. However, their complexity and infrastructure demands mean they're best suited for scenarios where simpler solutions no longer suffice. If you're managing massive datasets and already have robust DevOps support, <code>smallpond</code> and 3FS could significantly enhance your analytics capabilities. For simpler scenarios, sticking with a single-node DuckDB instance or using managed solutions remains your best option.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lifestyle of out of touch execs who are pushing return to office (469 pts)]]></title>
            <link>https://twitter.com/EthanEvansVP/status/1895845734177452369</link>
            <guid>43232255</guid>
            <pubDate>Sun, 02 Mar 2025 16:47:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/EthanEvansVP/status/1895845734177452369">https://twitter.com/EthanEvansVP/status/1895845734177452369</a>, See on <a href="https://news.ycombinator.com/item?id=43232255">Hacker News</a></p>
Couldn't get https://twitter.com/EthanEvansVP/status/1895845734177452369: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Mark Cuban offers to fund 18f (331 pts)]]></title>
            <link>https://techcrunch.com/2025/03/01/mark-cuban-offers-to-fund-government-tech-unit-that-was-cut-in-the-middle-of-the-night/</link>
            <guid>43231062</guid>
            <pubDate>Sun, 02 Mar 2025 14:58:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/03/01/mark-cuban-offers-to-fund-government-tech-unit-that-was-cut-in-the-middle-of-the-night/">https://techcrunch.com/2025/03/01/mark-cuban-offers-to-fund-government-tech-unit-that-was-cut-in-the-middle-of-the-night/</a>, See on <a href="https://news.ycombinator.com/item?id=43231062">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Billionaire investor Mark Cuban waded into the latest government tech shake-up on Saturday, posting an unexpected offer of support for newly laid-off federal workers on the social network Bluesky.</p>

<p><br>His <a rel="nofollow" href="https://bsky.app/profile/mcuban.bsky.social/post/3lje6uqhmdc2w">message</a>, which quickly gained traction, urged the displaced engineers and designers to turn the upheaval to their advantage.</p>







<p><br>“If you worked for 18F and got fired, Group together to start a consulting company,” wrote Cuban. “It’s just a matter of time before DOGE needs you to fix the mess they inevitably created. They will have to hire your company as a contractor to fix it. But on your terms. I’m happy to invest and/or help.”</p>

<p><br>Cuban’s offer came after the government’s General Services Administration (GSA) abruptly gutted its 18F technology unit, which helps other government agencies build, buy, and share tech products. <a rel="nofollow" href="https://www.politico.com/news/2025/03/01/general-services-administration-cuts-tech-unit-00206860">Per Politico</a>, the layoffs affected roughly 70 individuals who learned the news around 1 a.m. Eastern time on Saturday. Among other things, the unit had reportedly built Login.gov, a secure and private way for the public to access services at government agencies, including Social Security and the Department of Veterans Affairs.</p>

<p><br>The early-morning layoffs tie to a Trump administration directive to shrink the federal workforce and slash spending at the behest of Elon Musk’s Department of Government Efficiency (DOGE). The cuts weren’t a first for 18F; according to Politico, two dozen more 18F employees were laid off in February when GSA cut probationary staffers.</p>

<p><br>Those impacted in the wee hours of Saturday morning <a rel="nofollow" href="https://www.politico.com/news/2025/02/28/federal-workers-told-once-again-to-justify-their-work-to-doge-00206853">also received</a> emails late Friday from DOGE with the subject line, “What did you do last week? Part II.”</p>

<p><br>According to Politico, the emails — prompting employees to list their weekly accomplishments by Monday — were widely distributed across multiple agencies, including the State Department, the IRS, and the NIH.</p>


<p><br>In the wake of these new layoffs, Cuban’s proposal presents an intriguing possibility: could the very workers pushed out of government help reshape the future of civic tech on their own terms? As DOGE moves to dismantle agencies, even Musk has acknowledged fallout tied to the speed with which his team is moving. On Wednesday, Musk shared that, “For example, with USAID, one of the things we <a rel="nofollow" href="https://www.nytimes.com/2025/02/27/health/musk-ebola-funding.html">accidentally canceled</a> — very briefly — was Ebola prevention.” (Public health experts have since said the government’s support has <a rel="nofollow" href="https://www.npr.org/sections/goats-and-soda/2025/02/27/g-s1-50929/elon-musk-ebola-usaid">not been fully restored</a>.)</p>

<p><br>The question now is whether some percentage of the government’s growing number of displaced former employees will seize the moment, banding together to build the startups that could one day sell their expertise back to the government. If so, it would represent a striking twist in the administration’s efforts to shrink the public workforce.</p>

<p><br>If Cuban has his way, at least one such unit may find itself inside a private company the government has no choice but to rely on. Another Bluesky user even had a branding idea for the startup, <a rel="nofollow" href="https://bsky.app/profile/qew2.bsky.social/post/3ljebrzhnwk2q">telling Cuban</a>, “Name the new company 18FU.”</p>
</div><div>
	
	
	
	

	
<div>
	<p>Loizos has been reporting on Silicon Valley since the late ’90s, when she joined the original Red Herring magazine. Previously the Silicon Valley Editor of TechCrunch, she was named Editor in Chief and General Manager of TechCrunch in September 2023. She’s also the founder of StrictlyVC, a daily e-newsletter and lecture series acquired by Yahoo in August 2023 and now operated as a sub brand of TechCrunch.</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/connie-loizos/" data-event="button" href="https://techcrunch.com/author/connie-loizos/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a modern Goodreads alternative (207 pts)]]></title>
            <link>https://kaguya.io/</link>
            <guid>43230994</guid>
            <pubDate>Sun, 02 Mar 2025 14:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kaguya.io/">https://kaguya.io/</a>, See on <a href="https://news.ycombinator.com/item?id=43230994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-sentry-component="MaxWidthWrapper" data-sentry-source-file="MaxWidthWrapper.tsx"><div data-sentry-component="ReviewCarousel" data-sentry-source-file="ReviewCarousel.tsx"><p data-sentry-component="ReviewCarouselHeader" data-sentry-source-file="ReviewCarousel.tsx"><h3>Recently Reviewed on Kaguya</h3></p><div><div><a href="https://kaguya.io/books/the-hundred-thousand-kingdoms/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-brightest-shadow/reviews/buu"></a></div><div><a href="https://kaguya.io/books/changing-faces-1/reviews/buu"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>Changing Faces</p><p>-<!-- --> <!-- -->Sarah Lin</p></div></a></div><div><a href="https://kaguya.io/books/metropolitan/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-praxis/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-rift-1/reviews/synedocheny"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>The Rift</p><p>-<!-- --> <!-- -->Walter Jon Williams</p></div></a></div><div><a href="https://kaguya.io/books/pandemic-6/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-knight/reviews/synedocheny"></a></div></div><div><div><a href="https://kaguya.io/books/the-hundred-thousand-kingdoms/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-brightest-shadow/reviews/buu"></a></div><div><a href="https://kaguya.io/books/changing-faces-1/reviews/buu"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>Changing Faces</p><p>-<!-- --> <!-- -->Sarah Lin</p></div></a></div><div><a href="https://kaguya.io/books/metropolitan/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-praxis/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-rift-1/reviews/synedocheny"><div data-sentry-component="BookCoverFallback" data-sentry-source-file="BookCoverFallback.tsx" href=""><p>The Rift</p><p>-<!-- --> <!-- -->Walter Jon Williams</p></div></a></div><div><a href="https://kaguya.io/books/pandemic-6/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/the-knight/reviews/synedocheny"></a></div><div><a href="https://kaguya.io/books/misquoting-muhammad-the-challenge-and-choices/reviews/nico"></a></div></div></div><section data-sentry-component="Features" data-sentry-source-file="Features.tsx"><h4>Kaguya lets you...</h4><div><div data-sentry-element="Card" data-sentry-source-file="Features.tsx" data-sentry-component="FeatureCard"><h3>Write Reviews</h3><p>Share your thoughts and insights by writing detailed reviews.</p></div><div data-sentry-element="Card" data-sentry-source-file="Features.tsx" data-sentry-component="FeatureCard"><h3>Rate Books</h3><p>Express your opinions by rating each book on a ten-star scale. </p></div><div data-sentry-element="Card" data-sentry-source-file="Features.tsx" data-sentry-component="FeatureCard"><p><img alt="feature icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" src="https://kaguya.io/icons/features/streamline_shelf-solid.svg"></p><div><h3>Organize Shelves</h3><p>Arrange your books with custom shelves to easily manage your library.</p></div></div></div></section><section><!--$?--><template id="B:0"></template><!--/$--><div data-sentry-component="Top10Books" data-sentry-source-file="Top10Books.tsx"><p><h3>Popular Books This Week</h3></p><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/the-martian"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>01</span></p><div><p><span>01</span></p><p><h4>The Martian</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/harry-potter-and-the-sorcerers-stone"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>02</span></p><div><p><span>02</span></p><p><h4>Harry Potter and the Sorcerer'...</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/ready-player-one"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>03</span></p><div><p><span>03</span></p><p><h4>Ready Player One</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/1984"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>04</span></p><div><p><span>04</span></p><p><h4>1984</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/sapiens-a-brief-history-of-humankind"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>05</span></p><div><p><span>05</span></p><p><h4>Sapiens: A Brief History of Hu...</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/the-three-body-problem"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>06</span></p><div><p><span>06</span></p><p><h4>The Three-Body Problem</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/the-hunger-games"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>07</span></p><div><p><span>07</span></p><p><h4>The Hunger Games</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/harry-potter-and-the-goblet-of-fire"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>08</span></p><div><p><span>08</span></p><p><h4>Harry Potter and the Goblet of...</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/neuromancer"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>09</span></p><div><p><span>09</span></p><p><h4>Neuromancer</h4></p></div></div></a><a data-sentry-element="Link" data-sentry-component="TopBookCard" data-sentry-source-file="Top10Books.tsx" href="https://kaguya.io/books/why-we-sleep-unlocking-the-power-of-sleep-and"><div data-sentry-element="Card" data-sentry-source-file="Top10Books.tsx"><p><span>10</span></p><div><p><span>10</span></p><p><h4>Why We Sleep: Unlocking the Po...</h4></p></div></div></a></div></div></section><div data-sentry-component="BookCarousel" data-sentry-source-file="BookCarousel.tsx"><div data-sentry-component="BookCarouselHeader" data-sentry-source-file="BookCarouselHeader.tsx"><p><a href="https://kaguya.io/list/popular">Top 100 Rated Books</a></p><a href="https://kaguya.io/list/popular"><span>See More</span><span>See All</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 320 512" height="12" width="12" xmlns="http://www.w3.org/2000/svg"><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"></path></svg></a></div><div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-martian"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-hobbit-or-there-and-back-again"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-fellowship-of-the-ring"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-clash-of-kings"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/sapiens-a-brief-history-of-humankind"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-game-of-thrones"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/red-rising"></a></div><div><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/enders-game"></a></div></div><div data-sentry-element="Carousel" data-sentry-source-file="MobileCarousel.tsx" role="region" aria-roledescription="carousel" data-sentry-component="MobileCarousel"><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-martian"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-hobbit-or-there-and-back-again"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/the-fellowship-of-the-ring"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-clash-of-kings"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/sapiens-a-brief-history-of-humankind"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-game-of-thrones"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/red-rising"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/enders-game"></a></div><div role="group" aria-roledescription="slide"><a data-sentry-element="Container" data-sentry-source-file="BookCover.tsx" href="https://kaguya.io/books/a-storm-of-swords"></a></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4.5: "Not a frontier model"? (130 pts)]]></title>
            <link>https://www.interconnects.ai/p/gpt-45-not-a-frontier-model</link>
            <guid>43230965</guid>
            <pubDate>Sun, 02 Mar 2025 14:47:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.interconnects.ai/p/gpt-45-not-a-frontier-model">https://www.interconnects.ai/p/gpt-45-not-a-frontier-model</a>, See on <a href="https://news.ycombinator.com/item?id=43230965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>As GPT-4.5 was being released, the first material the public got access to was OpenAI’s system card for the model that details some capability evaluations and mostly safety estimates. Before the </span><a href="https://www.youtube.com/watch?v=cfRYp0nItZ8" rel="">live stream</a><span> and official blog post, we knew things were going to be weird because of this line:</span></p><blockquote><p>GPT-4.5 is not a frontier model.</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png" width="1271" height="699" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:699,&quot;width&quot;:1271,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:85687,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc5b5a6-6b06-4680-bab5-66be2046d940_1271x699.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The </span><a href="https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf" rel="">updated system card</a><span> in the </span><a href="https://openai.com/index/introducing-gpt-4-5/" rel="">launch blog post</a><span> does not have this. Here’s the original system card if you need a reference:</span></p><p>Regardless, someone at OpenAI felt the need to put that in. The peculiarity here summarizes a lot of the release. Some questions are still really not answered, like “Why did OpenAI release this?” That game theory is not in my purview. </p><p><span>The main contradiction to the claims that it isn’t a frontier model is that </span><strong>this is the biggest model the general public has ever gotten to test</strong><span>. Scaling to this size of model did NOT make a clear jump in capabilities we are measuring. To summarize the arc of history, the jump from GPT-3.5 to GPT-4 made the experience with the models go from okay to good. The jump from GPT-4o (where we are now) to GPT-4.5 made the models go from great to really great.</span></p><p>Feeling out the differences in the latest models is so hard that many who are deeply invested and excited by AI’s progress are just as likely to lie to themselves about the model being better as they are to perceive real, substantive improvements. In this vein, I almost feel like I need to issue a mea culpa. I expected this round of scaling’s impacts to still be obvious before the brutal economic trade-offs of scaling kicked in. </p><p data-attrs="{&quot;url&quot;:&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.interconnects.ai/p/gpt-45-not-a-frontier-model?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>While we got this model, Anthropic has also unintentionally confirmed that their next models will be trained on an approximation of “10X the compute,” via a correction on </span></p><p><span>’s </span><a href="https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37" rel="">post on Claude 3.7</a><span>.</span></p><blockquote><p>Note: After publishing this piece, I was contacted by Anthropic who told me that Sonnet 3.7 would not be considered a 10^26 FLOP model and cost a few tens of millions of dollars to train, though future models will be much bigger.</p></blockquote><p><span>GPT-4.5 is a point on the graph that scaling is still coming, but trying to make sense of it in a day-by-day transition is hard. In many ways, zooming out, GPT-4.5 will be referred to in the same breath as </span><a href="https://www.interconnects.ai/p/reverse-engineering-openai-o1" rel="">o1</a><span>, </span><a href="https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai" rel="">o3</a><span>, and </span><a href="https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1" rel="">R1</a><span>, where it was clear that scaling pretraining alone was not going to give us the same level of breakthroughs. Now we really know </span><a href="https://www.latent.space/p/what-ilya-saw" rel="">what Ilya saw</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg" width="1200" height="900" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:900,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Shane Gu on X: \&quot;\&quot;Pre-training as we know it will end\&quot;. See my slide on  \&quot;online learning\&quot;. We are finally done with 0-80%, and let the journey of  80% to infinity start.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Shane Gu on X: &quot;&quot;Pre-training as we know it will end&quot;. See my slide on  &quot;online learning&quot;. We are finally done with 0-80%, and let the journey of  80% to infinity start." title="Shane Gu on X: &quot;&quot;Pre-training as we know it will end&quot;. See my slide on  &quot;online learning&quot;. We are finally done with 0-80%, and let the journey of  80% to infinity start." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a6f783-c5f2-4c30-911e-f7b9ed44b4a9_1200x900.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>All of this marks GPT-4.5 as an important moment in time for AI to round out other stories we’ve been seeing. GPT-4.5 likely finished training a long time ago — highlighted by how it has a date cutoff in 2023 still — and OpenAI has been using it internally to help train other models, but didn’t see much of a need to release it publicly.</p><p><em>In the following,</em><span> </span><em><span>I am going to make some estimates on the parameter counts of GPT-4.5 and GPT-4o. These are not based on any leaked information and should be taken with big error bars, but they are very useful for context</span><strong>.</strong></em></p><p><span>GPT-4.5 is a very big model. I’d bet it is well bigger than </span><a href="https://www.interconnects.ai/p/grok-3-and-an-accelerating-ai-roadmap" rel="">Grok 3</a><span>. We have seen this story before. For example, GPT-4 </span><a href="https://semianalysis.com/2023/07/10/gpt-4-architecture-infrastructure/" rel="">was roughly known to be a very big mixture of experts model with over 1T parameters total</a><span> and ~200B active parameters. Since then, rumors have placed the active parameters of models like GPT-4o or Gemini Pro at as low as 60B parameters. This type of reduction, along with infrastructure improvements, accounts for massive improvements in speed and price.</span></p><p>Estimates place GPT-4.5 as about an order of magnitude more compute than GPT-4. These are not based on any released numbers, but given a combination of a bigger dataset and parameters (5X parameters + 2X dataset size = 10X compute), the model could be in in the ballpark of 5-7T parameters total, which if it had a similar sparsity factor to GPT-4 would be ~600B active parameters. </p><p>With all of these new parameters, actually seeing performance improvements is hard. This is where things got very odd. The two “capabilities” OpenAI highlighted in the release are:</p><ol><li><p>Reduced hallucinations.</p></li><li><p>Improved emotional intelligence.</p></li></ol><p>Both of these have value but are hard to vibe test. </p><p><span>For example, </span><a href="https://openai.com/index/introducing-simpleqa/" rel="">SimpleQA</a><span> is a benchmark we at Ai2 are excited to add to our post-training evaluation suite to improve world knowledge of our models. OpenAI made and released this evaluation publicly. GPT-4.5 makes huge improvements here.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png" width="1301" height="541" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:541,&quot;width&quot;:1301,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:47370,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c0c2974-ace3-415b-a119-b8efc08980da_1301x541.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In another one of OpenAI’s evaluations, PersonQA, which is questions regarding individuals, the model is also state of the art. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png" width="880" height="165" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:165,&quot;width&quot;:880,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:24190,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5bc6576a-f9e9-46d1-b16c-ec2da59a455a_880x165.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And finally, also GPQA, the Google-proof knowledge evaluation that reasoning models actually excel at.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png" width="1111" height="528" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/df28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:528,&quot;width&quot;:1111,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:54872,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/158107244?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf28934e-8acb-4da2-b3fe-5781485d6471_1111x528.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>At the time of release, many prominent AI figures online were touting how GPT-4.5 is much nicer to use and better at writing. These takes should be taken in the context of your own testing. It’s not that simple. GPT-4.5 is also being measured as </span><a href="https://x.com/paulgauthier/status/1895221869844013108" rel="">middle of the pack</a><span> in most code and technical evaluations relative to Claude 3.7, R1, and the likes.</span></p><p><span>For an example on the writing and style side, Karpathy ran some </span><a href="https://x.com/karpathy/status/1895337579589079434" rel="">polls comparing GPT-4.5’s writing to GPT-4o-latest</a><span>, and </span><strong>most people preferred the smaller, older model</strong><span>. Given what we know about post-training and the prevalence of distilling from the most powerful model you have access to, it is likely that GPT-4o-latest is distilled from this new model, previously called Orion</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-158107244" href="https://www.interconnects.ai/p/gpt-45-not-a-frontier-model#footnote-1-158107244" target="_self" rel="">1</a></span><span>, and its drastically smaller size gives it a night and day difference on iteration speed, allowing for better post-training.</span></p><p>More on the character in that GPT-4o-latest model was covered in our previous post on character training.</p><div data-component-name="DigestPostEmbed"><a href="https://www.interconnects.ai/p/character-training" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6abd9e2-beb0-4959-a8ba-452577b30c10_1357x758.webp"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6abd9e2-beb0-4959-a8ba-452577b30c10_1357x758.webp" sizes="100vw" alt="Character training: Understanding and crafting a language model's personality" width="140" height="140"></picture></div></a></div><p>All of this is a big price to pay to help OpenAI reclaim their top spot on ChatBotArena — I expect GPT 4.5 to do this, but the results are not out yet.</p><p>I’ve been using GPT-4.5 in preparation for this. It took a second to get used to the slower speed, but it’s fine. I will keep using it for reliability, but it’s not worth paying more for. o1 Pro and the other paid offerings from OpenAI offer far more value than GPT-4.5.</p><p><span>When the original GPT-4 first launched, it was extremely expensive. In fact, </span><strong>GPT-4 was comparable in price to GPT-4.5 at launch</strong><span>. Here’s a </span><a href="https://help.openai.com/en/articles/7127956-how-much-does-gpt-4-cost" rel="">help post on the OpenAI forums</a><span>, </span><s>conveniently found by OpenAI DeepResearch with GPT-4.5</s><span> EDIT: DeepResearch always uses o3, the UX is a lie, that captures the context. GPT-4 launched in March 2023.</span></p><blockquote><p><span>We are excited to announce GPT-4 has </span><a href="https://openai.com/pricing" rel="">a new pricing model</a><span>, in which we have reduced the price of the prompt tokens.</span></p><p><span>For our models with </span><strong>128k</strong><span> context lengths (e.g. </span><code>gpt-4-turbo</code><span>), the price is:</span></p><ul><li><p>$10.00 / 1 million prompt tokens (or $0.01 / 1K prompt tokens)</p></li><li><p>$30.00 / 1 million sampled tokens (or $0.03 / 1K sampled tokens)</p></li></ul><p><span>For our models with </span><strong>8k</strong><span> context lengths (e.g. </span><code>gpt-4</code><span> and </span><code>gpt-4-0314</code><span>), the price is:</span></p><ul><li><p>$30.00 / 1 million prompt token (or $0.03 / 1K prompt tokens)</p></li><li><p>$60.00 / 1 million sampled tokens (or $0.06 / 1K sampled tokens)</p></li></ul><p><span>For our models with </span><strong>32k</strong><span> context lengths (e.g. </span><code>gpt-4-32k</code><span> and </span><code>gpt-4-32k-0314</code><span>), the price is:</span></p><ul><li><p>$60.00 / 1 million prompt tokens (or $0.06 / 1K prompt tokens)</p></li><li><p>$120.00 / 1 million sampled tokens (or $0.12 / 1K sampled tokens)</p></li></ul></blockquote><p><strong>GPT-4.5’s pricing</strong><span> launched at: </span></p><blockquote><p><span>Input:</span><br><span>$75.00 / 1M tokens</span></p><p><span>Cached input:</span><br><span>$37.50 / 1M tokens</span></p><p><span>Output:</span><br><span>$150.00 / 1M tokens</span></p></blockquote><p>OpenAI included language in the release that they may not keep this model in the API, likely forecasting low demand, as they wanted to hear from users if it enabled entirely new use-cases. </p><p>Many analysts think that Nvidia’s next generation of GPU, Blackwell, which comes with GPUs with far more memory per FLOP (enabling storing bigger models), are not priced into this. We can expect to see the same arc of pricing with 4.5 as we did with 4 to 4 Turbo to 4o. </p><ul><li><p>GPT-4 Turbo launched in November 2023 at $10 / 1M input and $30 / 1M output.</p></li><li><p>GPT-4o launched in May 2024 at $2.5 / 1M input and $10 / 1M output.</p></li></ul><p>These are huge reductions, about 10X.</p><p>These are products that OpenAI makes a healthy margin on, and there are no signs that that isn’t the case. The AI community collectively has grown so accustomed to incredible progress in making the technology more efficient that even a blip in the process, where bigger models are available, feels potentially bubble-popping.</p><p><a href="https://www.interconnects.ai/t/scaling" rel="">Scaling</a><span> language models is not dead. Still, reflecting on why this release felt so weird is crucial to staying sane in the arc of AI’s progress. We’ve entered the era where trade-offs among different types of scaling are real.</span></p><p>If forced to summarize all of this curtly, it would be: GPT-4.5 is, oddly, ahead of its time. </p><p><span>This means that the progression of AI needs to take a different tack, but we already knew this with the rapid progress of reasoning models. The true impact of GPT-4.5 is when it is integrated with </span><em>multiple</em><span> lines of rapid progress. </span></p><p>One of the flagship results in the DeepSeek R1 paper and related RL follow-up work in the AI community is that scaling RL training works better on bigger models. There is a lot of work to do to know all the domains that’ll be absorbed into this umbrella. Future models like o4 could be distilled from a reasoning model trained on GPT-4.5. In fact, this may already be the case. OpenAI’s current models likely would not be so good without GPT-4.5 existing.</p><p>In as soon as a year, most of the models we are working with will be GPT-4.5 scale and they will be fast. The “well-rounded” improvements they offer are going to help make many more applications more robust, but OpenAI and others in the AI labs have pushed scaling a bit further than the current serving infrastructure can support.</p><p>Frontier labs are not taking enough risk if they’re not going to try to push the limits of every direction of scaling they have. Though releasing the model isn’t needed, we have to guess why OpenAI actually wanted to do this. It’s likely that GPT-4.5 is being used in other internal systems for now and other external products soon, so releasing it is a natural step on the way to the next thing, rather than a detour.</p><p>GPT-4.5 is a frontier model, but its release is not an exciting one. AI progress isn’t free, and it takes a lot of hard work. Most people should only care when GPT-4.5 is integrated into more than just chat.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This Month in Ladybird February 2025 (115 pts)]]></title>
            <link>https://ladybird.org/newsletter/2025-02-28/</link>
            <guid>43230920</guid>
            <pubDate>Sun, 02 Mar 2025 14:41:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ladybird.org/newsletter/2025-02-28/">https://ladybird.org/newsletter/2025-02-28/</a>, See on <a href="https://news.ycombinator.com/item?id=43230920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>It’s been a short but productive month for the Ladybird project! We’ve merged 281 PRs from 35 contributors. Let’s take a look at some of the highlights!</p>

<p>Ladybird is fully funded through the generous support of companies and individuals who believe in the open web. This month, we’re excited to welcome the following new sponsors:</p>
<ul> 
<li> <a href="https://shopify.com/">Shopify</a> (renewed sponsorship) </li>
<li> <a href="https://proton.me/">Proton</a>, with $50,000 (<a href="https://proton.me/blog/2024-lifetime-fundraiser-results">raised with the help of their community</a> and a matching donation from <a href="https://protonvpn.com/">Proton VPN</a>) </li>
 </ul>
<p>We are incredibly grateful for their support! If you’re interested in sponsoring, <a href="mailto:contact@ladybird.org">contact us</a>.</p>
<h3 id="web-platform-tests-wpt"> Web Platform Tests (WPT) </h3>
<p>We’ve continued making improvements in WPT compliance: <strong> 9,836 </strong> more passing subtests than last month! This brings our total to <strong> 1,773,799 </strong>.</p>
<p>The low-hanging fruit is exhausted at this point, but the upward grind must continue!</p>
<p>Here’s the last month’s progress for all browsers:</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-wpt-graph.gif" alt=""></p>
<p>Let’s also zoom out and take a look at overall WPT progress since we started tracking it back in August of 2024:</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-wpt-all.png" alt=""></p>
<p>The dashed green line is Apple’s required 90% pass rate for eligibility as an alternative browser engine on iOS. That’s our next target. After that, the 3 major engines await…</p>
<h3 id="waiting-for-css-to-download-before-rendering"> Waiting for CSS to download before rendering </h3>
<p>We now delay the initial rendering of pages until we’ve loaded all the CSS referenced by <code>&lt;link&gt;</code> elements. This is an important part of preventing <a href="https://en.wikipedia.org/wiki/Flash_of_unstyled_content">FOUC (flash of unstyled content)</a>.</p>
<p>Pictured below are 3 stages of loading our GitHub repo in Ladybird while CSS is downloading. Before, we would render the first two stages. With these new changes, we hold off until we have enough to show you the final stage directly.</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-fouc.webp" alt=""></p>
<h3 id="openssl-adoption"> OpenSSL adoption </h3>
<p>The work on moving off of our own home-grown cryptography library and onto the battle-tested <a href="https://openssl-library.org/">OpenSSL</a> goes on. This month, we’ve ported the following features to OpenSSL and removed our own implementations:</p>
<ul> 
<li> TLS 1.2 </li>
<li> HKDF </li>
<li> PBKDF2 </li>
<li> Curve25519 </li>
<li> Ed25519 </li>
<li> Ed448 </li>
<li> X25519 </li>
<li> X448 </li>
 </ul>
<h3 id="curl-adoption"> curl adoption </h3>
<p>We’ve also continued migrating our networking stack to <a href="https://curl.se/">curl</a>. The latest piece of functionality to move onto curl is our <a href="https://websockets.spec.whatwg.org/">WebSockets</a> implementation.</p>
<p>Note that there are some features that curl’s WebSocket backend doesn’t support, such as per-message compression and WebSockets over HTTP/2.</p>
<h3 id="firefox-devtools-protocol-support"> Firefox DevTools protocol support </h3>
<p>We’re working on making it possible to use Firefox’s DevTools suite with Ladybird.</p>
<p>DevTools are not only vital to web development, but also crucial for browser developers to investigate websites that don’t yet work correctly.</p>
<p>Ladybird already had its own home-grown debug tooling, but by adding support for Firefox’s
DevTools protocol, we gain access to sophisticated tools very quickly.</p>
<p>We’ve only just begun this work, but we can already inspect a page’s layout and style,
and interact with the document from the DevTools console!</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-devtools.png" alt=""></p>
<h3 id="css-image-cursors"> CSS image cursors </h3>
<p>We now support custom images in the CSS <code>cursor</code> property, a rarely used but pretty fun feature!</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-sheep-cursor.png" alt=""></p>
<h3 id="new-css-pseudo-classes"> New CSS pseudo-classes </h3>
<p>We added a couple of new pseudo-classes this month:</p>
<ul> 
<li> <code>:valid</code> </li>
<li> <code>:invalid</code> </li>
<li> <code>:user-valid</code> </li>
<li> <code>:user-invalid</code> </li>
 </ul>
<p>These all apply to input elements that have valid or invalid values. They are commonly used to highlight form elements that need correcting.</p>
<p>Furthermore, <code>:open</code> now matches any input element that has a picker open. This is currently relevant for <code>&lt;input type="color"&gt;</code> and <code>&lt;input type="file"&gt;</code>.</p>
<h3 id="text-decorations-for-errors"> Text decorations for errors </h3>
<p>We added support for <code>text-decoration: spelling-error</code> and <code>text-decoration: grammar-error</code>, which mimic the underlines you see in typical word processors.</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-error-underlines.png" alt=""></p>
<h3 id="textencoderstream"> TextEncoderStream </h3>
<p>We’ve implemented the <a href="https://developer.mozilla.org/en-US/docs/Web/API/TextEncoderStream">streaming version of TextEncoder</a>, which converts the input to UTF-8 bytes.
This is used by the server-side rendering mode of React Router, which is used by ChatGPT:</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-chatgpt-mini.png" alt=""></p>
<h3 id="resource-timing"> Resource Timing </h3>
<p>We’ve implemented the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Performance_API/Resource_timing">Resource Timing API</a>, which allows a website to get timing information about the
network resources it requests. This was implemented as part of an initiative to support Cloudflare Turnstile, an anti-bot solution.</p>
<p>Resource Timing is also used by monitoring tools such as Sentry:</p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-resource-timing-sentry-1.png" alt=""></p>
<p><img src="https://ladybird.org/assets/img/newsletter-feb-2025-resource-timing-sentry-2.png" alt=""></p>
<h3 id="constraint-validation-api"> Constraint validation API </h3>
<p>We’ve started to implement the Constraint Validation API. This prevents a form from being submitted if it contains invalid data.</p>
<p>Currently, we have implemented the <code>required</code> attribute, which checks that the element has a value, and the <code>pattern</code> attribute, which checks that the element’s value matches the given regular expression.</p>
<h3 id="the-inert-attribute"> The <code>inert</code> attribute </h3>
<p>We now support the <code>inert</code> attribute, which can be added to any element to make it non-interactive, non-focusable, and non-findable. This is useful for modals, popups, and other content that should not be interacted with.</p>
<h3 id="style-invalidation-optimizations"> Style invalidation optimizations </h3>
<p>We’ve made several incremental optimizations to reduce unnecessary style recalculations.</p>
<p>The most significant change is that the presence of <code>:has()</code> selectors no longer triggers a full-page recalculation. Instead, only the relevant ancestor elements are updated, making the process much more efficient in the worst case.</p>
<h3 id="aarch64-linux-continuous-integration"> aarch64 Linux continuous integration </h3>
<p>We’ve been using GitHub Actions for PR testing for a long time,
but we only had x86_64 Linux and aarch64 macOS runners.</p>
<p>This month, we took advantage of GitHub’s <a href="https://github.blog/changelog/2025-01-16-linux-arm64-hosted-runners-now-available-for-free-in-public-repositories-public-preview/">new public aarch64 Linux runners</a>
to add a nightly aarch64 Linux job. Adding the job required fixing some rough edges in
aarch64 Linux support.</p>
<h3 id="credits"> Credits </h3>
<p>We’d like to thank everyone who contributed code this month:</p>
<p><em> Aliaksandr Kalenik, Alice Lee, Andreas Kling, Andrew Kaster, aplefull, AppleFlavored, David Hewitt, devgianlu, Felipe Muñoz Mazur, Francesco Gazzetta, Gingeh, Glenn Skrzypczak, InvalidUsernameException, Jaycadox, Jelle Raaijmakers, Jess, jg99, Kenneth Myhra, Lucas CHOLLET, Luke Warlow, Luke Wilde, Mehran Kamal, mikiubo, Piotr, Psychpsyo, R-Goc, rmg-x, Sam Atkins, Shannon Booth, sideshowbarker, stasoid, Tim Ledbetter, Timothy Flynn, Undefine, zoupingshi </em></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi Pico audio player (101 pts)]]></title>
            <link>http://lucstechblog.blogspot.com/2025/02/raspberry-pi-pico-audio-player.html</link>
            <guid>43230821</guid>
            <pubDate>Sun, 02 Mar 2025 14:29:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://lucstechblog.blogspot.com/2025/02/raspberry-pi-pico-audio-player.html">http://lucstechblog.blogspot.com/2025/02/raspberry-pi-pico-audio-player.html</a>, See on <a href="https://news.ycombinator.com/item?id=43230821">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5473818848082471537" itemprop="description articleBody">
<div><p><span><b><span><a href="http://lucstechblog.blogspot.com/p/index-of-my-stories.html">For an index to all my stories click this text.</a></span></b></span></p><p><span>After all the proceeding stories the time has come to build a complete stand-alone audio player with the Raspberry Pi Pico. The audio quality is not Hifi but it is really good !! Good enough as a player in your mancave, bedroom or even as a portable player. I have made a permanent setup and using it to play music and podcasts. My setup has a few neat extra features which will be described later on.&nbsp;</span></p></div><p><span>The programming is done in MicroPython with Thonny as the IDE.<p>You can use a Pico or a Pico-W for this project. The pin connections and the program are the same. </p><p>To build this I am going to list the parts that are needed first:</p><p>- A Raspberry Pi Pico or Pico W<br>- 3 push buttons<br>- 4 10K resistors.<br>- 2 1K resistors<br>- 4 2K2 resistors<br>- 2 47nF capacitors.<br>- 1 SD card module or SD card adapter<br>- 1 SSD1306 Oled display<br>- 1 large on several small breadboards<br>- Dupont wires for the breadboard</p><p>Extra</p><p>- An active speaker (like a computer speaker) or<br>- a pair of earplug headphones.<br>- a 3.5mm contra connector for the headphone or speakers<br>- an optional small amplifier so you do not need an active speaker<br>- a pair of small speakers when using the amplifier<br>- alligator clips for connecting to the headphone or speakers<br>- Power Bank or USB power supply</p><p>To get this working we need a lot of drivers for MicroPython. We need drivers for playing the sounds, we need drivers for the SD card, we need drivers for the SSD1306 oled screen.</p><p>I bundled all these drivers on my Github depositry. You can find them here:<br><b><a href="https://github.com/Lucvolders/MicroPython/tree/main/Libraries">https://github.com/Lucvolders/MicroPython/tree/main/Libraries</a></b></p><p>Next to that you need to know that this audio player only plays 8k WAV files. &nbsp;</p><p>I wrote several stories on each step that was needed to come to this project. I will list here the links to each step.</p><p>Converting audio files to an 8K WAV file with Audacity:<br><b><a href="http://lucstechblog.blogspot.com/2024/10/audacity-pico-audio-part-1.html">http://lucstechblog.blogspot.com/2024/10/audacity-pico-audio-part-1.html</a></b></p><p>Building the Raspberry Pi Pico audio hardware with just a few resistors and capacitors:<br><b><a href="http://lucstechblog.blogspot.com/2024/10/audio-on-pico-part-2-hardware.html">http://lucstechblog.blogspot.com/2024/10/audio-on-pico-part-2-hardware.html</a></b></p><p>Raspberry Pi pico audio playing software:<br><b><a href="http://lucstechblog.blogspot.com/2024/10/pico-audio-part-3.html">http://lucstechblog.blogspot.com/2024/10/pico-audio-part-3.html</a></b></p><p>SD card for the Raspberry Pi Pico (hardware):<br><b><a href="http://lucstechblog.blogspot.com/2025/01/pico-sdcard-part-1-hardware.html">http://lucstechblog.blogspot.com/2025/01/pico-sdcard-part-1-hardware.html</a></b></p><p>SD card for the Raspberry Pi Pico (software):<br><a href="http://lucstechblog.blogspot.com/2025/01/pico-sd-card-part-2-software.html"><b>http://lucstechblog.blogspot.com/2025/01/pico-sd-card-part-2-software.html</b></a></p><p>I did not write a story on the SSD1306 oled screen. But that is in my book: Raspberry Pi pico Simplified ;) There is a link to that book on the bottom of this page. The driver is however in my Github depositry.</p><p>These stories describe the hardware in details with breadboard setup. The stories also cover the origin of the MicroPython drivers and how to collect them and install them. Like said before I bundled all the drivers in my Github repositry here: <br><b><a href="https://github.com/Lucvolders/MicroPython/tree/main/Libraries">https://github.com/Lucvolders/MicroPython/tree/main/Libraries</a></b></p><p>I urge you to read these stories so you know what is going on.</p><p><span><b><span>The breadboard setup.</span></b></span></p><p>Here is the breadboard setup. There are some expansions possible like adding the digital thermometer which was discussed in this story:<br><b><a href="http://lucstechblog.blogspot.com/2024/11/pico-audio-part-4-talking-thermometer.html">http://lucstechblog.blogspot.com/2024/11/pico-audio-part-4-talking-thermometer.html</a></b></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnBaOE4zJVtp1RFZU-Y9I6-oUtVD_XVNrclq02B6-MZfidY1axLU2vESjatWkPBGq5_idlgh75uxxQheiRCWbQFPyD6hHZLsnX8lRf-NexTxeV_uvH2fbk2Wzheogk5KGBO83HMVoFBrC5MBYPyf_SJG7PxTEPMIwMKO36cKzck1ey3uL3PdbMjzek1g/s950/Pico-Audio-player-kl.png"><img data-original-height="937" data-original-width="950" height="632" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnBaOE4zJVtp1RFZU-Y9I6-oUtVD_XVNrclq02B6-MZfidY1axLU2vESjatWkPBGq5_idlgh75uxxQheiRCWbQFPyD6hHZLsnX8lRf-NexTxeV_uvH2fbk2Wzheogk5KGBO83HMVoFBrC5MBYPyf_SJG7PxTEPMIwMKO36cKzck1ey3uL3PdbMjzek1g/w640-h632/Pico-Audio-player-kl.png" width="640"></a></p><p>Please note that you are looking at the backside of the SD card. That is the side where the connector is soldered. If you are using an SD card module make sure to attach to the right pins.</p><p>As there might be some confusion from looking at the above picture I will show you all the connections here.</p><p><b>The Buttons</b></p><p>Button 01 is attached with a pull-up resistor to pin GP18<br>Button 02 is attached with a pull-up resistor to pin GP19<br>Button 03 is attached with a pull-up resistor to pin GP20</p><p><b>Audio</b></p><p>Audio left is attached to GP02<br>Audio right is attached to GP03</p><p><b>SSD1306</b></p><p>The oled screen is powered by VCC (3.3 Volt) and GND<br>SDA is attached to GP09<br>SCL is attached to GP08</p><p><b>SD-Card</b></p><p>The SD card is powered by VCC (3.3 Volt) and GND.</p><p>MISO is attached with a pull-up resistor to GP12<br>CS is attached to GP13<br>SCK is attached to GP14<br>MOSI is attached to GP15</p><p>You can find all the details about these connections in the previous stories in this series. Please pay special attention to the audio connections to the low-pass filter and the SD card connections.</p><p>As the pins where the hardware is attached have to be defined in MicroPython you can also find the pin numbers in the MicroPython program.</p><p><b><span>The audioplayer program</span></b></p><p>As you are used to on this weblog, I present the full code here which you can copy and paste into your favorite MicroPython editor.</p><!--HTML generated using hilite.me--></span></p><div><pre><span>'''</span>
<span>Audioplayer Plays 8k WAV files</span>
<span>With Oled screen for choosing audiofiles</span>

<span>Audio files on SD card</span>
<span>Button GP18 next number</span>
<span>Button GP19 previous number</span>
<span>Button GP20 play the song</span>
<span>'''</span>

<span># Import garbage collect</span>
<span>import</span> <span>gc</span>

<span>import</span> <span>os</span> <span>as</span> <span>os</span>
<span>import</span> <span>time</span>
<span>import</span> <span>machine</span>
<span>from</span> <span>machine</span> <span>import</span> <span>SPI,</span> <span>Pin,</span> <span>Timer</span>
<span>import</span> <span>sdcard</span>
<span>from</span> <span>wavePlayer</span> <span>import</span> <span>wavePlayer</span>

<span>import</span> <span>ssd1306</span>

<span>sda</span><span>=</span><span>machine</span><span>.</span><span>Pin(</span><span>8</span><span>)</span>
<span>scl</span><span>=</span><span>machine</span><span>.</span><span>Pin(</span><span>9</span><span>)</span>

<span>i2c</span><span>=</span><span>machine</span><span>.</span><span>I2C(</span><span>0</span><span>,sda</span><span>=</span><span>sda,</span> <span>scl</span><span>=</span><span>scl,freq</span><span>=</span><span>400000</span><span>)</span>
<span>print</span><span>(i2c</span><span>.</span><span>scan())</span>

<span>oled</span> <span>=</span> <span>ssd1306</span><span>.</span><span>SSD1306_I2C(</span><span>128</span><span>,</span> <span>64</span><span>,</span> <span>i2c)</span>

<span>player</span> <span>=</span> <span>wavePlayer()</span>

<span>spi</span> <span>=</span> <span>SPI(</span><span>1</span><span>,sck</span><span>=</span><span>Pin(</span><span>14</span><span>),</span> <span>mosi</span><span>=</span><span>Pin(</span><span>15</span><span>),</span> <span>miso</span><span>=</span><span>Pin(</span><span>12</span><span>))</span>
<span>cs</span> <span>=</span> <span>Pin(</span><span>13</span><span>)</span>
<span>sd</span> <span>=</span> <span>sdcard</span><span>.</span><span>SDCard(spi,</span> <span>cs)</span>

<span>os</span><span>.</span><span>mount(sd,</span> <span>'/storage'</span><span>)</span>

<span>but01</span><span>=</span><span>machine</span><span>.</span><span>Pin(</span><span>18</span><span>,</span> <span>machine</span><span>.</span><span>Pin</span><span>.</span><span>IN)</span>
<span>but02</span><span>=</span><span>machine</span><span>.</span><span>Pin(</span><span>19</span><span>,</span> <span>machine</span><span>.</span><span>Pin</span><span>.</span><span>IN)</span>
<span>but03</span><span>=</span><span>machine</span><span>.</span><span>Pin(</span><span>20</span><span>,</span> <span>machine</span><span>.</span><span>Pin</span><span>.</span><span>IN)</span>

<span>playnow</span> <span>=</span> <span>-</span><span>1</span>

<span>array</span><span>=</span><span>(os</span><span>.</span><span>listdir(</span><span>'/storage/Music'</span><span>))</span>
<span>numbers</span> <span>=</span> <span>len(array)</span>
<span>print</span> <span>(numbers)</span>

<span>oled</span><span>.</span><span>fill(</span><span>0</span><span>)</span>
<span>oled</span><span>.</span><span>show()</span>
<span>oled</span><span>.</span><span>text(</span><span>"Raspberry Audio"</span><span>,</span><span>0</span><span>,</span><span>0</span><span>)</span>
<span>oled</span><span>.</span><span>text(</span><span>"player"</span><span>,</span><span>40</span><span>,</span><span>10</span><span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>range(</span><span>0</span><span>,</span> <span>127</span><span>):</span>
    <span>oled</span><span>.</span><span>pixel(</span><span>0</span> <span>+</span> <span>i,</span> <span>20</span><span>,</span> <span>1</span><span>)</span>
<span>oled</span><span>.</span><span>show()</span>

<span>try</span><span>:</span> 
   <span>while</span> <span>True:</span>

      
      <span>if</span> <span>(but01</span><span>.</span><span>value()</span><span>==</span><span>0</span><span>):</span> 
          <span>print</span><span>(</span><span>"button 1 pressed"</span><span>)</span>
          <span>playnow</span> <span>=</span> <span>playnow</span> <span>+</span> <span>1</span>
          <span>if</span> <span>(playnow</span> <span>==</span> <span>numbers):</span>
              <span>playnow</span> <span>=</span> <span>0</span>
          <span>song</span> <span>=</span> <span>"/storage/Music/"</span><span>+</span><span>array[playnow]</span>
          <span>print</span><span>(type(song))</span>
          <span>help</span><span>=</span> <span>array[playnow]</span>
          <span>print</span><span>(</span><span>"Now playing "</span> <span>+</span> <span>help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>])</span>
          
          <span>oled</span><span>.</span><span>fill(</span><span>0</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"Raspberry Audio"</span><span>,</span><span>0</span><span>,</span><span>0</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"player"</span><span>,</span><span>40</span><span>,</span><span>10</span><span>)</span>
          <span>for</span> <span>i</span> <span>in</span> <span>range(</span><span>0</span><span>,</span> <span>127</span><span>):</span>
              <span>oled</span><span>.</span><span>pixel(</span><span>0</span> <span>+</span> <span>i,</span> <span>20</span><span>,</span> <span>1</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"This song is :"</span><span>,</span><span>0</span><span>,</span><span>25</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"                   "</span><span>,</span><span>0</span><span>,</span><span>35</span><span>)</span>
          <span>oled</span><span>.</span><span>text(help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>],</span><span>0</span><span>,</span><span>35</span><span>)</span>
          <span>oled</span><span>.</span><span>show()</span>
          <span>print</span><span>(playnow)</span>
          <span>time</span><span>.</span><span>sleep(</span><span>.</span><span>5</span><span>)</span>
          <span># test how much memory is free</span>
          <span>gc</span><span>.</span><span>collect()</span>
          <span>print</span><span>(gc</span><span>.</span><span>mem_free())</span>  
    
      <span>if</span> <span>(but02</span><span>.</span><span>value()</span><span>==</span><span>0</span><span>):</span>
          <span>#player.stop()</span>
          <span>print</span><span>(</span><span>"button 2 pressed"</span><span>)</span>
          
          <span>if</span> <span>(playnow</span> <span>==</span> <span>-</span><span>1</span> <span>or</span> <span>playnow</span> <span>==</span><span>0</span><span>):</span>
              <span>playnow</span> <span>=</span> <span>0</span>
          <span>else</span><span>:</span>
              <span>playnow</span> <span>=</span> <span>playnow</span> <span>-</span><span>1</span>
          <span>song</span> <span>=</span> <span>"/storage/Music/"</span><span>+</span><span>array[playnow]</span>
          <span>print</span><span>(type(song))</span>
          
          <span>help</span><span>=</span> <span>array[playnow]</span>
          <span>print</span><span>(</span><span>"Now playing "</span> <span>+</span> <span>help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>])</span>
          <span>oled</span><span>.</span><span>fill(</span><span>0</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"Raspberry Audio"</span><span>,</span><span>0</span><span>,</span><span>0</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"player"</span><span>,</span><span>40</span><span>,</span><span>10</span><span>)</span>
          <span>for</span> <span>i</span> <span>in</span> <span>range(</span><span>0</span><span>,</span> <span>127</span><span>):</span>
              <span>oled</span><span>.</span><span>pixel(</span><span>0</span> <span>+</span> <span>i,</span> <span>20</span><span>,</span> <span>1</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"This song is : "</span><span>,</span><span>0</span><span>,</span><span>25</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"                   "</span><span>,</span><span>0</span><span>,</span><span>35</span><span>)</span>
          <span>oled</span><span>.</span><span>text(help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>],</span><span>0</span><span>,</span><span>35</span><span>)</span>
          <span>oled</span><span>.</span><span>show()</span>
          <span>print</span><span>(playnow)</span>
          <span>time</span><span>.</span><span>sleep(</span><span>.</span><span>5</span><span>)</span>
          
      <span>if</span> <span>(but03</span><span>.</span><span>value()</span> <span>==</span><span>0</span><span>):</span>
          <span>help</span><span>=</span> <span>array[playnow]</span>
          <span>print</span><span>(</span><span>"Now playing "</span> <span>+</span> <span>help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>])</span>
          <span>oled</span><span>.</span><span>fill(</span><span>0</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"Raspberry Audio"</span><span>,</span><span>0</span><span>,</span><span>0</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"player"</span><span>,</span><span>40</span><span>,</span><span>10</span><span>)</span>
          <span>for</span> <span>i</span> <span>in</span> <span>range(</span><span>0</span><span>,</span> <span>127</span><span>):</span>
             <span>oled</span><span>.</span><span>pixel(</span><span>0</span> <span>+</span> <span>i,</span> <span>20</span><span>,</span> <span>1</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"Now playing:"</span><span>,</span><span>0</span><span>,</span><span>25</span><span>)</span>
          <span>oled</span><span>.</span><span>text(</span><span>"                   "</span><span>,</span><span>0</span><span>,</span><span>35</span><span>)</span>
          <span>oled</span><span>.</span><span>text(help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>],</span><span>0</span><span>,</span><span>35</span><span>)</span>
          <span>oled</span><span>.</span><span>show()</span>
          <span>player</span><span>.</span><span>play(song)</span>
   
<span>except</span> <span>KeyboardInterrupt</span><span>:</span>
   <span>player</span><span>.</span><span>stop()</span>
</pre></div>
 
  
  
  
  
  
  
  <p><span>All of this code has been explained in the previous chapters except a neat trick.<!--HTML generated using hilite.me--><div><pre><span>array</span><span>=</span><span>(os</span><span>.</span><span>listdir(</span><span>'/storage/Music'</span><span>))</span>
<span>numbers</span> <span>=</span> <span>len(array)</span>
<span>print</span> <span>(numbers)</span>
</pre></div><div><p>The audio files are stored in a subdirectory on the SD card with the name Music. This piece of code puts the directory entries (the music names) into an array and then prints that array on Thonny's console. The number of music tracks is put into the variable number. This variable tells us how many music tracks there are on the SD card.</p><!--HTML generated using hilite.me--></div><div><pre>          <span>print</span><span>(</span><span>"button 1 pressed"</span><span>)</span>
          <span>playnow</span> <span>=</span> <span>playnow</span> <span>+</span> <span>1</span>
          <span>if</span> <span>(playnow</span> <span>==</span> <span>numbers):</span>
              <span>playnow</span> <span>=</span> <span>0</span>
          <span>song</span> <span>=</span> <span>"/storage/Music/"</span><span>+</span><span>array[playnow]</span>
          <span>print</span><span>(type(song))</span>
          <span>help</span><span>=</span> <span>array[playnow]</span>
          <span>print</span><span>(</span><span>"Now playing "</span> <span>+</span> <span>help[</span><span>0</span><span>:</span><span>-</span><span>4</span><span>])</span>
</pre></div>

  
  
  
  <p>Pressing the first button increases the playnow variable. That variable points to the array that holds the directory items. The array entry is copied into the help variable and that is printed on the oled screen. This variable entry is the name of the music track that is going to be played if you press the third button.</p><p>If the increased number is higher as the number of array entries the number is set back to 0 which is the first array entry.</p><p>The same is done for the second button that decreases the variable so walks backwards through the array till it reaches 0. </p><p>The last button takes the array entry and plays it.</p><p><span><b><span>Operating the player.</span></b></span></p><p>First thing to do is saving this program into your Pico and naming it main.py When the Pico reboots MicroPython looks for a program with the name main.py and automatically starts that program. This way you can run this player stand-alone with a USB power supply or, for mobile use, with a power bank.</p><p>Once started the oled display shows the text:</p><p><b><span>Raspberry Audio<br>&nbsp;&nbsp; Player</span></b></p><p>This tells that the program is ready. Press the first button and the names of the music on your SD card in the subdirectory Music will be shown one by one.<br>By pressing the second button you can scroll backwards through the names.<br>Pressing the third button will play the song which name is on the oled screen.</p><p><b><span>Any flaws ??</span></b></p><p>Well yes actually there is a flaw. Once you start playing a song you can not stop it. You'll have to sit it out before you can choose another one. A work around solution would be adding another button and connect pin 30 to GND when the button is pressed. Pin 30 is RUN and acts as a reset pin. This would actually reset the pico so it physically reboots. You can find how to build a reset button here: http://lucstechblog.blogspot.com/2021/02/raspberry-pico-rest-button.html</p><p><span><b><span>Expansions.</span></b></span></p><p>I can think of a few.</p><p>- First possible expansion is, like discussed above, adding a reset button.<br>- The player plays a song and then waits till you choose another song and press a button. An expansion would be the possibility to start playing at a certain song and then the next ones in line would play automatic.<br>- An expansion would be adding a Dallas DS18B20 digital thermometer. You would also need to attach another button that gives you the option to toggle between the audio player and the talking thermometer. You can find the talking thermometer in this story : <b><a href="http://lucstechblog.blogspot.com/2024/11/pico-audio-part-4-talking-thermometer.html">http://lucstechblog.blogspot.com/2024/11/pico-audio-part-4-talking-thermometer.html</a></b><br>- You could add yet another button that would activate a talking clock. You can find the talking clock in this story: <a href="http://lucstechblog.blogspot.com/2024/11/pico-audio-part-5-talking-clock.html"><b>http://lucstechblog.blogspot.com/2024/11/pico-audio-part-5-talking-clock.html</b></a><br>- How about adding the talking clock and have the audio player play your favorite song at waking time.<br>- Remove the buttons (except a reset button) and use a rotary encoder to walk through the menu items/songs etc and choose the item you need.<br>- Add extra buttons that you can use as preset buttons for playing certain songs. You would add the possibility to program these buttons when you change the SD card for one with different music.</p><p>These are just a few ideas I came up with in a few minutes. I believe you can come up with a few of your own......</p><p>Please send me a mail if you have build this or something that was based on this project. I am always curious about what my readers come up with.</p><p>Till next time,<br>have fun</p><p><b><span>Luc Volders</span></b></p><br></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla flamed by Firefox fans after reneging on promises to not sell their data (290 pts)]]></title>
            <link>https://www.theregister.com/2025/03/02/mozilla_introduces_terms_of_use/</link>
            <guid>43229668</guid>
            <pubDate>Sun, 02 Mar 2025 12:13:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/03/02/mozilla_introduces_terms_of_use/">https://www.theregister.com/2025/03/02/mozilla_introduces_terms_of_use/</a>, See on <a href="https://news.ycombinator.com/item?id=43229668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Mozilla this week asked Firefox users to abide by new Terms of Use, and updated its Privacy Notice as well as an FAQ – only to quickly issue a clarification that it isn’t actually claiming ownership of user data.</p>
<p>Mind you, the language of the <a target="_blank" rel="nofollow" href="https://www.mozilla.org/about/legal/terms/firefox/">Terms of Use</a> document <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250226211527/https://www.mozilla.org/en-US/about/legal/terms/firefox/">initially suggested</a> as much:</p>

<p>But Mozilla subsequently removed those terms, and insisted it was just necessary boilerplate.</p>
<p>“On Wednesday we shared that we’re introducing a new Terms of Use (TOU) and Privacy Notice for Firefox,” said Ajit Varma, veep of Firefox Product, on Friday in <a target="_blank" rel="nofollow" href="https://blog.mozilla.org/en/products/firefox/update-on-terms-of-use/#:~:text=TL%3BDR%20Mozilla%20doesn't,would%20usually%20understand%20that%20word.">an update</a> to the open source browser maker's initial <a target="_blank" rel="nofollow" href="https://blog.mozilla.org/en/products/firefox/firefox-terms-of-use/">announcement</a> of the new terms.</p>
<blockquote>

<p>Our intent was just to be as clear as possible about how we make Firefox work</p>
</blockquote>
<p>“Since then, we’ve been listening to some of our community’s concerns with parts of the TOU, specifically about licensing. Our intent was just to be as clear as possible about how we make Firefox work, but in doing so we also created some confusion and concern.”</p>
<p>Varma said its contractual language has been updated in an effort to assuage concerns. For one thing, it now states "this does not give Mozilla any ownership" of the data you put into Firefox to use it.</p>
<p>While much of the confusion can be written off as an unforced error in communication – legalese is often misunderstood – the developer's privacy commitment has changed, in its wording at least. The answer to "what is Firefox?" on Mozilla's FAQ page about its browser <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250130092351/https://www.mozilla.org/en-US/firefox/faq/">used to read</a>:</p>

<p>Now it <a target="_blank" rel="nofollow" href="https://www.mozilla.org/en-US/firefox/faq/">just says</a>:</p>

<p>In other words, Mozilla is no longer willing to commit to not selling your personal data to advertisers.</p>
<p>A related change was also <a href="https://connect.mozilla.org/t5/discussions/information-about-the-new-terms-of-use-and-updated-privacy/m-p/87949/highlight/true#M33725" rel="nofollow">highlighted</a> by mozilla.org commenter jkaelin, who linked direct to the <a target="_blank" rel="nofollow" href="https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/faq.html">source code</a> for that FAQ page. To answer the question, "is Firefox free?" Moz used to say:</p>

<p>Now it simply reads:</p>

<p>Again, a pledge to not sell people's data has disappeared. Varma insisted this is the result of the fluid definition of “sell” in the context of data sharing and privacy.</p>
<p>“Mozilla doesn’t sell data about you (in the way that most people think about ‘selling data’), and we don’t buy data about you,” he said. “We changed our language because some jurisdictions define ‘sell’ more broadly than most people would usually understand that word.”</p>
<ul>

<li><a href="https://www.theregister.com/2024/11/13/mozillas_firefox_browser/">Mozilla's Firefox browser turns 20. Does it still matter?</a></li>

<li><a href="https://www.theregister.com/2024/09/25/mozilla_noyb_privacy_complaint/">Campaigners claim 'Privacy Preserving Attribution' in Firefox does the opposite</a></li>

<li><a href="https://www.theregister.com/2024/06/21/firefox_127_private_window/">Privacy features lose their way in latest Firefox update</a></li>

<li><a href="https://www.theregister.com/2024/12/12/firefox_do_not_track/">Firefox ditches Do Not Track because nobody was listening anyway</a></li>

<li><a href="https://www.theregister.com/2024/09/02/zen_firefox_fork_alpha/">Zen Browser is a no-Google zone that offers tiling nirvana</a></li>
</ul>
<p>Though the TOU – and its connected <a target="_blank" rel="nofollow" href="https://www.mozilla.org/en-US/privacy/firefox/">privacy policy</a> and <a target="_blank" rel="nofollow" href="https://www.mozilla.org/en-US/about/legal/acceptable-use/">acceptable use rules</a> – are written in clear, plain English, are short and readable, and in our opinion contain no huge surprises, Mozilla's earlier choice of wording sparked a backlash on <a href="https://connect.mozilla.org/t5/discussions/information-about-the-new-terms-of-use-and-updated-privacy/m-p/87735#M33600" rel="nofollow">its own</a> forums, as well as <a href="https://www.reddit.com/r/firefox/comments/1iyuvjf/introducing_a_terms_of_use_and_updated_privacy/" rel="nofollow">on Reddit</a> and other places.</p>
<p>Following that outcry, Varma's announcement on Wednesday about the new fine print was updated to include this disclaimer:</p>

<p>One might argue the new terms are the result of a December management shakeup. That month it was <a href="https://blog.mozilla.org/en/mozilla/new-executives/" rel="nofollow">announced</a> three executives were joining Mozilla, including Varma, the author of the above announcements, as a Firefox veep after previously looking after WhatsApp for Meta, and before that, Gmail, and its related tools for Google. The other two were Anthony Enzor-DeMeo, senior veep of Firefox, who previously held top roles at Wayfair, Better, and Roofstock; and Girish Rao, SVP of infrastructure, who was previously at Warner Bros Discovery, EA, Cisco, and Equinix.</p>
<p>Then in early February, Mozilla <a target="_blank" rel="nofollow" href="https://blog.mozilla.org/en/mozilla/leadership/peter-rojas-svp-new-products/">gained</a> Peter Rojas as a senior veep of new products; he has an interesting history spanning from co-founding Engadget to holding senior roles at Meta and AOL to investing in AI model warehouse Hugging Face and others.</p>

    

<p>These high-level appointments were announced by Laura Chambers, who <a href="https://www.theregister.com/2024/02/09/mozilla_ceo_mitchell_baker_departs/">hopped aboard</a> as CEO a year ago; the hiring came the month after <a href="https://www.theregister.com/2024/11/06/mozilla_foundation_layoffs/">deep staffing cuts</a> at the Mozilla Foundation – the non-profit that overseas the Mozilla Corporation that develops Firefox and other things.</p>
<h3>Competition</h3>
<p>Sadly, it looks like the <a href="https://www.jwz.org/blog/2024/10/mozillas-ceo-doubles-down-on-them-being-an-advertising-company-now/" rel="nofollow">assessment</a> of Moz by former Netscape coder Jamie Zawinski was not far off the mark. He also links to his own earlier criticisms, none of which we can really fault.</p>
<p>This seems like a good time to remind readers that there are other browsers out there based on the Firefox codebase, including <a href="https://www.theregister.com/2021/11/04/waterfox_firefox_fork/">our own go-to Waterfox</a>, as well as the <a href="https://www.theregister.com/2024/09/02/zen_firefox_fork_alpha/">tiling Zen browser</a> which has now reached beta.</p>

        

<p>Others that happen not to press our buttons quite so much, but may appeal more to you, include the security-centric <a href="https://librewolf.net/" rel="nofollow">LibreWolf</a> and the customization-heavy <a href="https://floorp.app/en" rel="nofollow">Floorp</a>. Other projects showing less recent activity are <a href="https://pulsebrowser.app/" rel="nofollow">Pulse</a> and <a href="https://thorium.rocks/mercury" rel="nofollow">Mercury</a>. Still in active development, but based on older versions of the Firefox codebase, are <a href="https://www.palemoon.org/" rel="nofollow">PaleMoon</a> and <a href="https://www.basilisk-browser.org/" rel="nofollow">Basilisk</a>.</p>
<p>Most venerable of all is the continuing fork of the original all-in-one Netscape suite, <a href="https://www.seamonkey-project.org/" rel="nofollow">Seamonkey</a>. We're sad to note that its release engineer William Andrew Gianopoulos <a href="https://www.chesmorefuneralhome.com/obituaries/william-andrew-gianopoulos/20284/" rel="nofollow">died</a> in January.</p>

        

<p>Whether or not one agrees with the outrage over the TOU changes, the fact remains that <a target="_blank" href="https://www.theregister.com/2024/06/18/mozilla_buys_anonym_betting_privacy/">Mozilla is now</a> in the <a target="_blank" rel="nofollow" href="https://www.anonymco.com/">advertising business</a>. Use that information as you wish. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[German tourist held indefinitely in San Diego area immigrant detention facility (115 pts)]]></title>
            <link>https://www.kpbs.org/news/border-immigration/2025/02/28/german-tourist-held-indefinitely-in-san-diego-area-immigrant-detention-facility</link>
            <guid>43229475</guid>
            <pubDate>Sun, 02 Mar 2025 11:48:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kpbs.org/news/border-immigration/2025/02/28/german-tourist-held-indefinitely-in-san-diego-area-immigrant-detention-facility">https://www.kpbs.org/news/border-immigration/2025/02/28/german-tourist-held-indefinitely-in-san-diego-area-immigrant-detention-facility</a>, See on <a href="https://news.ycombinator.com/item?id=43229475">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>It was meant to be a perfect reunion.</p><p>Amelia Lofving, a designer, had just moved to Los Angeles. Her friend Jessica Brösche, a tattoo artist from Germany, was spending the winter in Mexico.</p><p>The two planned to meet up in Tijuana, cross the border, and head to LA.</p><p>“We were going to have a month of just making art,” said the 37-year-old Lofving. “That was our plan.”</p><p>Brösche, 26, never made it to LA. She’s been in federal immigration custody since Jan. 25 — the day they tried to cross into the United States through the San Ysidro Port of Entry.</p><p>Brösche had her German passport, confirmation of her visa waiver to enter the country, along with a copy of her return ticket back to Berlin, Lofving said. A U.S. Customs and Border Protection (CBP) agent pulled Brösche aside for a secondary inspection.</p><p>“I look at her and go, ‘I’m going to wait right outside for you,’” Lofving recalled.</p><p>She didn’t know it then, but it would be 25 days before Lofving would see her friend again. Brösche would spend that time in federal detention, where she remains, waiting for a deportation flight back to Berlin.</p><h3>‘I can’t find Jessica’</h3><p>CBP agents at the border accused Brösche of planning to violate the terms of the <a href="https://esta.cbp.dhs.gov/esta" target="_blank" data-cms-ai="0">visa waiver program</a> by intending to work as a tattoo artist during her trip to LA, Lofving said.</p><p>KPBS independently confirmed that Brösche is in federal custody. CBP declined to comment on the specifics of the case, citing privacy concerns.</p><p>Lofving said a CBP agent told her Brösche would be deported back to Germany in a few days. “She’s like, ‘Jessica is going to call you in a couple of days from Germany,’” she said.</p><p>Lofving waited two days. No calls from Germany. She waited a week. Still no contact with Brösche.</p><p>Mutual friends also hadn’t heard from her. People started to freak out, Lofving said. No one knew where Brösche was.</p><p>“I’m a dumb artist, I don’t know what to do in these situations,” Lofving said. “I posted something online, ‘hey guys, help me out. I can’t find Jessica.’”</p><p>The posts generated hundreds of views. And some people answered the call.</p><p>Using the federal <a href="https://locator.ice.gov/odls/#/search" target="_blank" data-cms-ai="0"><u>Detainee Locator website</u></a>, online sleuths tracked Brösche to the Otay Mesa Detention Center, which is a U.S. Immigration and Customs Enforcement (ICE) facility run by the private contractor Core Civic.</p><p>Meanwhile, local resident Ashley Paschen found Brösche’s story while, “doom scrolling TikTok.”</p><p>“At the end of the video, she just asked is there anybody in the area that can put eyes on her and help?” said Paschen, who lives near the detention center.</p><p>Paschen said she’s not an activist and doesn’t consider herself the type of person who would normally get involved in a situation like this. But something about Brösche’s story grabbed her.</p><p>“I think it was just the mom in me,” she said. “Her mom hasn’t heard from her and doesn’t know where she is. At that point, no one had had any contact with her at all.”</p><p>Despite being a complete stranger, Paschen decided to visit Brösche at the detention center. She brought Brösche messages from family and friends. Paschen also told her that friends had already contacted the German embassy and were trying to get her out of there.</p><p>“She was blown away,” Paschen said.</p><h3>‘It was like a horror movie’</h3><p>A few weeks later, with Paschen’s help, Lofving was able to visit Brösche.</p><p>It was a tearful reunion, filled with hugs and Lofving repeatedly saying, “I’m sorry, I’m so sorry.”</p><p>Lofving said Brösche told her about her time in custody — and a particularly difficult nine-day period in what amounted to solitary confinement in a CBP holding cell.</p><p>“She says it was like a horror movie,” Lofving said. “There were people screaming from the rooms all around. They are feeding her through a little mailbox hole. She didn’t have a blanket, she didn’t have a pillow. It’s basically a yoga mat on the ground and a toilet on the corner.”</p><p>Spending that many days in one of CBP’s short-term detention facilities appears to be a violation of the agency's own internal detention standards, which, “generally limit detention in these facilities to 72 hours,” according to a <a href="https://www.oig.dhs.gov/sites/default/files/assets/2022-12/OIG-23-03-Dec22.pdf" target="_blank" data-cms-ai="0"><u>2023 report from the Office of Inspector General.</u></a></p><p>Inspectors conducted unannounced inspections of four short-term facilities in San Diego and El Centro. They found that of the 447 migrants detained in all four stations, 42% of them exceeded the 72-hour standard, with some being there for more than 20 days.</p><p>Brösche told friends that the prolonged confinement has impacted her mental health.</p><p>“After nine days, she says she started freaking out and punching the walls,” Lofving said. “There was blood everywhere.”</p><p>Brösche was transferred to the ICE Otay Mesa facility after that episode. She has been there since.</p><p>Lofving and Paschen say they still don’t know when Brösche will be released. Their questions to ICE have gone unanswered. The agency did not respond to an inquiry from KPBS.</p><h3>Costs to taxpayers</h3><p>Lofving said the episode is particularly absurd because Brösche’s original return flight to Berlin was on Feb. 15 — nearly two weeks ago.</p><p>“Why are American taxpayers spending thousands of dollars detaining tourists who are perfectly willing to leave,” she said.</p><p>The average cost of detaining a noncitizen adult is <a href="https://www.aila.org/library/featured-issue-immigration-detention-and-alternatives-to-detention#:~:text=Current%20Population%3A%20Per%20ICE%2C%20on,detaining%20an%20adult%20noncitizen%3A%20%24164.65." target="_blank" data-cms-ai="0"><u>$164 per day, according to an ICE memo</u></a>. Based on that average, a month of detention costs taxpayers $4,900.</p><p>An immigrant rights activist said Brösche’s story is an example of the country’s broken immigration system.</p><p>“It speaks to how inefficient this whole situation is,” said Pedro Rios, with the San Diego-based American Friends Service Committee. “There’s a lack of appreciation for how to make things run smoothly, and people are suffering in the process.”</p><p>KPBS was unable to reach the German consulates in LA and Washington D.C.</p><p>German officials told a <a href="https://www.bz-berlin.de/berlin/deutsche-in-us-abschiebehaft" target="_blank" data-cms-ai="0">Berlin-based news outlet</a>, “Our colleagues at the Consulate General in Los Angeles are in constant contact with U.S. authorities and family members regarding the case and are trying to find a solution.”</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trust in Firefox and Mozilla Is Gone – Let's Talk Alternatives (227 pts)]]></title>
            <link>https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/</link>
            <guid>43229378</guid>
            <pubDate>Sun, 02 Mar 2025 11:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/">https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/</a>, See on <a href="https://news.ycombinator.com/item?id=43229378">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <header>

            
            
            <p><time datetime="2025-03-01">
                2025-03-01
              </time>
            </p>
            
            
          
            
          </header>
          
    <section>
    <p>It’s been a long time coming, but the trust in Firefox and its mother organization, Mozilla, seems to be mostly gone, after a recent commit on the source code removed the <em>“we don’t sell your data”</em> promise, along with a change of <a href="https://www.mozilla.org/en-US/privacy/firefox/#notice">Privacy notice</a> and <a href="https://blog.mozilla.org/en/products/firefox/firefox-news/firefox-terms-of-use/">Terms of Use</a>.</p>
<h2 id="a-commit-too-far">A Commit Too Far</h2>
<p>You can see the changes in <a href="https://github.com/mozilla/bedrock/commit/d459addab846d8144b61939b7f4310eb80c5470e">this commit</a>.</p>
<p><img src="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/firefox-privacy-bye.jpg" alt=""></p>
<p>It’s been something like 10 years that <em>Mozilla</em> is no stranger to doing <em>shady things</em> and playing a double game with its users, one one hand pretending in its PR to be a “champion of privacy”, and at the same time deploying tracking services without asking its end users (the famous <em>studies</em>). I have seen multiple times privacy settings being reset to collect data when updating the browser. Adding you <em>sponsored links</em> by default, and all that kind of things.</p>
<p><img src="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/privacy.jpg" alt=""></p>
<p>At the same time, <em>Firefox</em> has lost a huge amount of market share over the years (most of it going to <em>Google Chrome</em>), and its presence on the desktop is now just a blip of what it used to be:</p>
<p><img src="https://boilingsteam.com/poll-trust-in-firefox-mozilla-is-gone/firefox-market-share-desktop.jpg" alt=""></p>
<p>Well, it was a good time to ask people what was their level of trust in <em>Mozilla</em> when it came to respecting their users. Most of our surveys get between 100 and 200 answers. This one skyrocketed to more than 700 hundred (thanks to numerous boosters on the <em>Fediverse</em>). And the result is unsurprising:</p>
<div>
<p>Do you trust Firefox (Mozilla) to respect and keep their users' interest at heart in the long run?</p>

<p>731 Answers - Poll closed on 2025-03-01</p>
<p>Always have, always will</p>

<p>I have my doubts right now</p>

<p>Nah, they lost my trust for good</p>

<p>I don't use or care about Firefox</p>


</div>
<p>For background, a lot of our followers are <em>Firefox</em> users, so this is likely to be somewhat representative of our of the core audience of <em>Firefox</em>. And it looks like trust has been completely shattered, with more than a third of respondents having no faith in <em>Mozilla</em> anymore, and the majority (54%) having serious doubts. When people are on the fence, it could go either way (losing trust, or regaining trust), but even if only half of these respondents end up not trusting <em>Mozilla</em>, this is a devastating blow.</p>
<p>Following the backlash, Mozilla has tried <a href="https://blog.mozilla.org/en/products/firefox/update-on-terms-of-use/">to backpedal with a clarification</a>. Unfortunately, the clarification confirms the initial fears. They are removing the mention of <em>not selling data</em> because of a wider meaning associated to the word <em>selling</em> in certain jurisdictions, such as in California:</p>
<blockquote>
<p>We never sell your data” is because, in some places, the LEGAL definition of “sale of data” is broad and evolving. As an example, the California Consumer Privacy Act (CCPA) defines “sale” as the “selling, renting, releasing, disclosing, disseminating, making available, transferring, or otherwise communicating orally, in writing, or by electronic or other means, a consumer’s personal information by [a] business to another business or a third party” in exchange for “monetary” or “other valuable consideration.”</p>
</blockquote>
<p>Well, if that’s what Mozilla is doing, then yes, it is clearly what most people would understand as <em>selling your data</em>, as in making some kind of profit or revenue from what they collect.</p>
<h2 id="alternatives-to-firefox">Alternatives to Firefox</h2>
<p>Now the talk is all about alternatives, and those of you who are looking for your next browser, here are some things you can consider. As you will see, you do not lack options.</p>
<h3 id="librewolf">Librewolf</h3>
<p>A hardened fork of Firefox, <em>LibreWolf</em> takes Firefox’s base (ESR) and dials up the privacy settings while removing telemetry and other potential leaks. It is pre-configured with strict anti-tracking, no telemetry, and uBlock Origin (an ad blocker) included out of the box.</p>
<p>Site: <a href="https://librewolf.net/">https://librewolf.net/</a></p>
<h3 id="waterfox">Waterfox</h3>
<p><em>Waterfox</em> is an open-source browser forked from <em>Firefox</em> (ESR), originally created by <em>Alex Kontos</em> in 2011 to optimize for 64-bit systems when <em>Firefox</em> lagged in that area. Over time, it evolved to emphasize privacy, speed, and user control. Unlike <em>Librewolf</em>, it does not ship with uBlock Origin under the hood, leaving you the freedom of installing your own extensions to maximize your privacy.</p>
<p>Site: <a href="https://www.waterfox.net/">https://www.waterfox.net/</a></p>
<h3 id="zen-browser">Zen Browser</h3>
<p>Forked from Firefox, <em>Zen Browser</em> builds on the latest stable <em>Firefox</em> releases (not strictly ESR like some forks). It uses the <em>Gecko</em> engine with minimal changes to the core, focusing instead on enhancing the user interface and experience, with a radical approach to clean up <em>Firefox</em>‘s UI. Development started in April 2024, with its first public alpha in July 2024. It entered beta in December 2024, emphasizing a modern, visually appealing design. It’s probably not your first choice if you are looking specifically for a focus on privacy, but let’s keep it in this list anyway.</p>
<p>Site: <a href="https://zen-browser.app/">https://zen-browser.app/</a></p>
<h3 id="gnome-web">Gnome Web</h3>
<p><em>GNOME Web</em> is the default browser for the <em>GNOME</em> desktop environment, built from the ground up by the <em>GNOME</em> project. It’s a lightweight, open-source browser that uses WebKitGTK (a WebKit port for Linux) as its rendering engine, unlike <em>Firefox</em>’s <em>Gecko</em> or <em>Chromium</em>’s <em>Blink</em>. Its focus is simplicity, integration with GNOME, and a clean browsing experience, with some privacy considerations baked in (no telemetry and some tracking protection). However, since it is not based on any of the major browsers, you don’t get to access something like uBlock Origin, so this may be something to factor in.</p>
<p>Site: <a href="https://apps.gnome.org/Epiphany/">https://apps.gnome.org/Epiphany/</a></p>
<h3 id="ungoogled-chromium">Ungoogled Chromium</h3>
<p>This is a stripped-down version of <em>Chromium</em> that removes all Google-related services, telemetry, and dependencies while keeping the browser functional. No Google tracking, no built-in data collection, and enhanced control over what the browser can access. It’s barebones and relies on you to configure it.</p>
<p>Site: <a href="https://github.com/ungoogled-software/ungoogled-chromium">https://github.com/ungoogled-software/ungoogled-chromium</a></p>
<h3 id="gnu-icecat">GNU Icecat</h3>
<p>Another <em>Firefox</em> fork (based on ESR), maintained by the <em>GNU Project</em>, <em>IceCat</em> focuses on free software purity and privacy. It also blocks trackers by default, disables proprietary plugins, and includes privacy extensions like HTTPS Everywhere and LibreJS (which checks for non-free JavaScript). It does not get as frequent updates as other browsers, but its development is still well alive with the latest version being released in January 2025. However it’s not super easy to install, as they do not provide binaries for every distro out there, so you have to compile it. Even on <a href="https://aur.archlinux.org/packages/icecat">Arch’s AUR</a> it seems that there will be problems to build it because of incompatibilities with clang and python.</p>
<p>Site: <a href="https://www.gnu.org/software/gnuzilla/">https://www.gnu.org/software/gnuzilla/</a></p>
<h3 id="pale-moon">Pale Moon</h3>
<p><em>Pale Moon</em> is an open-source web browser originally forked from an older version of Firefox (around 2011, based on Firefox 38 ESR). Developed by <em>Moonchild Productions</em>, it’s designed to maintain a lightweight, customizable experience while sticking to the classic Firefox interface and Gecko engine (though heavily modified). It diverges from <em>Firefox</em>’s modern direction, focusing on efficiency and user control rather than chasing the latest web trends.</p>
<p>Site: <a href="https://www.palemoon.org/">https://www.palemoon.org/</a></p>
<h3 id="brave">Brave</h3>
<p><em>Brave</em> is built on <em>Chromium</em> (the open-source base of <em>Google Chrome</em>) but strips out <em>Google</em>’s tracking elements. It’s designed with privacy and speed in mind, featuring a built-in ad blocker, tracker blocker, and script blocking. It follows the Mozilla Public License for all of its components. However it does integrate a system based on crypto tokens to reward the visits that you make to certain site creators, which is something you may want to avoid.</p>
<p>Site: <a href="https://brave.com/">https://brave.com/</a></p>
<h3 id="ladybird">Ladybird</h3>
<p><em>Ladybird</em> is a web browser project aiming to be a truly independent, user-focused alternative. It started as part of SerenityOS, a hobby operating system created by <em>Andreas Kling</em> in 2018, but forked into a standalone project in 2022. Unlike most modern browsers, <em>Ladybird</em> doesn’t rely on existing engines like <em>Blink</em> (Chromium), <em>WebKit</em> (Safari), or <em>Gecko</em> (Firefox). Instead, it’s building its own engine from scratch, called <em>LibWeb</em>, paired with a custom JavaScript engine, <em>LibJS</em>. The focus is on adhering to web standards, delivering good performance, stability, and security, all while prioritizing user privacy over monetization. It’s in pre-alpha, targeting a usable alpha release in 2026, and is backed by the <em>Ladybird Browser Initiative</em>, a nonprofit funded by donations (e.g., from <em>GitHub</em> co-founder <em>Chris Wanstrath</em> and <em>Shopify</em>). So it’s still early days, but it should become an interesting option to consider later in 2025 or next year.</p>
<p>Site: <a href="https://ladybird.org/">https://ladybird.org/</a></p>
<h2 id="the-future-is-bright">The Future is Bright</h2>
<p>While there is some alarmism about the decadence of <em>Mozilla</em> and <em>Firefox</em>, ultimately good things will come out of it. Investments into other alternatives will increase (like Ladybird) and the void will be replaced by other incumbents, especially since Privacy protections and Ad-blockers are values that attract a certain following. This will lead into a more fragmented market place, which should ultimately lead to stronger standards.</p>

    
    </section>
    
    </article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What, if anything, should I do about using Mozilla's Firefox (144 pts)]]></title>
            <link>https://neilzone.co.uk/2025/03/what-if-anything-should-i-do-about-using-mozillas-firefox/</link>
            <guid>43229267</guid>
            <pubDate>Sun, 02 Mar 2025 11:06:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neilzone.co.uk/2025/03/what-if-anything-should-i-do-about-using-mozillas-firefox/">https://neilzone.co.uk/2025/03/what-if-anything-should-i-do-about-using-mozillas-firefox/</a>, See on <a href="https://news.ycombinator.com/item?id=43229267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<article>
    <p>I currently use Firefox as one of my main browsers.</p>
<p>I have used it for a <em>long</em> time - 20 years now, including for a while the IceWeasel variant - and I like it as a browser.</p>
<p>(I use Firefox as a browser; I don’t use any of Mozilla’s services such as sync or VPN or whatever.)</p>
<p>Given Mozilla’s recent shenanigans (pro ad industry, AI, never feeling quite sure what settings have changed upon upgrade, terms of service, operating model, perhaps more), I want to revisit this choice.</p>
<p>But finding a sustainable, viable alternative Free/open source browser, in a state which I can use <em>today</em>, supporting the plugins that I use daily, which is not based on Chromium, is not easy.</p>
<p>Genuinely, I don’t know…</p>
<h2 id="librewolf">LibreWolf</h2>
<p>LibreWolf is, in a sense, an obvious choice, and I installed it and copied my Firefox profile across to give it a try.</p>
<p>I’ve only done limited testing so far - a couple of days of using it - and it seems to do what I want.</p>
<p>The biggest reason stopping me from jumping to that is that it is a tweaked version of Firefox. That’s not to denigrate the work that the LibreWolf team does to improve it, but, as far as I can tell, it is completely, utterly dependent on Firefox.</p>
<p>I don’t know how quickly LibreWolf gets security updates. (<em>Edit 2025-03-02: quite quickly, various people have told me.</em>) I don’t know how much work it will be for LibreWolf to keep up to date with whatever changes Mozilla makes.</p>
<p>If I stick with Firefox, perhaps I am better of sticking with Firefox itself? I genuinely don’t know.</p>
<h2 id="firefox-from-debians-own-repos">Firefox from Debian’s own repos</h2>
<p>At the moment, I am using Mozilla’s repositories for Firefox. I get the most up to date version of Firefox, automatically, and rapidly.</p>
<p>It is convenient.</p>
<p>It also means that, regularly, I have to check my settings to see if Mozilla has changed anything. So definite trade-offs there.</p>
<p>I could switch to use the version of Firefox in the Debian repositories, and accepting that it will be an older, but perhaps safer, version.</p>
<p>That’s an option.</p>
<h2 id="standalone-applications">Standalone applications</h2>
<p>My preference to date has been to use my browser, rather than installing some additional, purpose-specific, software (with some exceptions; I prefer an email client over webmail, for instance).</p>
<p>I do a lot of video conferencing, and I use Jitsi, Teams, Zoom etc. within my browser.</p>
<p>I spend a fair amount of time in the fediverse, and on my computer I use my browser rather than a standalone client. I’ve yet to find a standalone client with an interface to match Mastodon’s “Advanced” web UI. On my phone, I use Tusky, so that’s fine.</p>
<p>For at least some sites and services, I could look for standalone clients / applications instead, and reduce my dependency on a browser.</p>
<p>Sadly, for at least some cases, this probably means “bloated Electron client” and I suspect that I’d trust them less than I trust Mozilla right now.</p>
<h2 id="tor-browser">Tor Browser</h2>
<p>I use Tor Browser regularly, on both my laptop and my phone.</p>
<p>Tor Browser is built on Firefox, so I will need to keep an eye on that.</p>
<p>I will continue to use Tor Browser for the foreseeable future, but it is not suitable for all the sites and services I want to use.</p>
<h2 id="links">links</h2>
<p>When <a href="https://neilzone.co.uk/2024/11/using-only-a-linux-terminal-for-my-personal-computing-in-2024/">experimenting with terminal-only computing</a>, the web was one of the more challenging aspects.</p>
<p>I like <code>links</code>, as a TUI browser, and I’ll continue to use it a lot.</p>
<p>But it is not suitable for all sites that I need to use.</p>
<p><code>brow.sh</code> doesn’t solve the problem here, since it is Firefox on the backend.</p>
<h2 id="other-more-esoteric-options">Other, more esoteric, options?</h2>
<p><a href="https://www.gnu.org/software/gnuzilla/">IceCat</a>?</p>
<p><a href="https://www.palemoon.org/">Palemoon</a> forked Firefox a long time ago, and still gets regular updates, so perhaps this is an option.</p>
<p><a href="https://www.netsurf-browser.org/">NetSurf</a>?</p>
<p><a href="https://astian.org/midori-browser/">Midori</a>? Looks interesting, but I’m immediately put off by the screenshot which prominently shows links for Facebook, Google etc. And there have been no commits to <a href="https://github.com/midori-browser/core">its Github repo</a> for years.</p>
<h2 id="stick-with-mozilla-and-firefox-for-a-bit-longer">Stick with Mozilla and Firefox for a bit longer?</h2>
<p>The most <em>convenient</em> option for me is to stick with Mozilla’s Firefox, and see how it goes.</p>
<p>Right now, I’ve been <em>disappointed</em> with the direction, but not more than that.</p>
<p>I don’t feel ethically compromised using Firefox. (Should I? Perhaps I’m missing something. But I don’t think so.)</p>
<p>I could keep an eye on the direction of travel, and make another assessment in the future.</p>



  <div>
	<hr>   
	<h2>You may also like:</h2>
	
    
</div>


</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The A.I. Monarchy (178 pts)]]></title>
            <link>https://substack.com/home/post/p-156886169</link>
            <guid>43229245</guid>
            <pubDate>Sun, 02 Mar 2025 11:02:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://substack.com/home/post/p-156886169">https://substack.com/home/post/p-156886169</a>, See on <a href="https://news.ycombinator.com/item?id=43229245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tab="[object Object]"><p><h3 translated="">The app for independent voices</h3></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NIH.gov DNS servers down, making PubMed, BLAST, etc. unreachable (452 pts)]]></title>
            <link>https://www.nslookup.io/domains/www.nih.gov/dns-records/#authoritative</link>
            <guid>43229201</guid>
            <pubDate>Sun, 02 Mar 2025 10:50:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nslookup.io/domains/www.nih.gov/dns-records/#authoritative">https://www.nslookup.io/domains/www.nih.gov/dns-records/#authoritative</a>, See on <a href="https://news.ycombinator.com/item?id=43229201">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Crossing the uncanny valley of conversational voice (355 pts)]]></title>
            <link>https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice</link>
            <guid>43227881</guid>
            <pubDate>Sun, 02 Mar 2025 06:13:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice">https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice</a>, See on <a href="https://news.ycombinator.com/item?id=43227881">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2><span>Crossing the<!-- --> </span><span>uncanny valley of</span><span>conversational voice</span></h2><div><p>February 27, 2025</p><p><span>Brendan Iribe</span>,<!-- --> <span>Ankit Kumar</span>, and the Sesame team</p></div></div><div><p><span>How do we know when someone truly understands us? It is rarely just our words—it is in the subtleties of voice: the rising excitement, the thoughtful pause, the warm reassurance.<p>Voice is our most intimate medium as humans, carrying layers of meaning through countless variations in tone, pitch, rhythm, and emotion.</p><p>Today’s digital voice assistants lack essential qualities to make them truly useful. Without unlocking the full power of voice, they cannot hope to effectively collaborate with us. A personal assistant who speaks only in a neutral tone has difficulty finding a permanent place in our daily lives after the initial novelty wears off.</p><p>Over time this emotional flatness becomes more than just disappointing—it becomes exhausting.</p></span></p><div><h3>Achieving voice presence</h3><p><span>At Sesame, our goal is to achieve “voice presence”—the magical quality that makes spoken interactions feel real, understood, and valued. We are creating conversational partners that do not just process requests; they engage in genuine dialogue that builds confidence and trust over time. In doing so, we hope to realize the untapped potential of voice as the ultimate interface for instruction and understanding.</span></p></div><div><h3>Key components</h3><div><ul><li>Emotional intelligence: reading and responding to emotional contexts.</li><li>Conversational dynamics: natural timing, pauses, interruptions and emphasis.</li><li>Contextual awareness: adjusting tone and style to match the situation.</li><li>Consistent personality: maintaining a coherent, reliable and appropriate presence.</li></ul></div></div></div><div><div><h3>We’re not there yet </h3><p><span>Building a digital companion with voice presence is not easy, but we are making steady progress on multiple fronts, including personality, memory, expressivity and appropriateness. This demo is a showcase of some of our work in conversational speech generation. The companions shown here have been optimized for friendliness and expressivity to illustrate the potential of our approach.</span></p></div><div><h3>Conversational voice demo</h3><p>1. Microphone permission is required. 2. Calls are recorded for quality review but not used for ML training and are deleted within 30 days. 3. By using this demo, you are agreeing to our<!-- --> <a data-sentry-element="NextLink" data-sentry-source-file="Link.tsx" data-sentry-component="Link" href="https://www.sesame.com/terms">Terms of Use<!-- --> </a> <!-- -->and<!-- --> <a data-sentry-element="NextLink" data-sentry-source-file="Link.tsx" data-sentry-component="Link" href="https://www.sesame.com/privacy">Privacy Policy</a>. 4. We recommend using Chrome (Audio quality may be degraded in iOS/Safari 17.5).</p></div></div><div><p>Technical post</p><h2><span>Conversational</span><span> speech generation</span></h2><div><p>Authors</p><p><span>Johan Schalkwyk</span>,<!-- --> <span>Ankit Kumar</span>,<!-- --> <span>Dan Lyth</span>,<!-- --> <span>Sefik Emre Eskimez</span>, <span>Zack Hodari</span>,<!-- --> <span>Cinjon Resnick</span>,<!-- --> <span>Ramon Sanabria</span>,<!-- --> <span>Raven Jiang</span></p></div><div><p>To create AI companions that feel genuinely interactive, speech generation must go beyond producing high-quality audio—it must understand and adapt to context in real time. Traditional text-to-speech (TTS) models generate spoken output directly from text but lack the contextual awareness needed for natural conversations. Even though recent models produce highly human-like speech, they struggle with the one-to-many problem: there are countless valid ways to speak a sentence, but only some fit a given setting. Without additional context—including tone, rhythm, and history of the conversation—models lack the information to choose the best option. Capturing these nuances requires reasoning across multiple aspects of language and prosody.</p><p>To address this, we introduce the Conversational Speech Model (CSM), which frames the problem as an end-to-end multimodal learning task using transformers. It leverages the history of the conversation to produce more natural and coherent speech. There are two key takeaways from our work. The first is that CSM operates as a</p><!-- --> <p><span>single-stage model</span>, thereby improving efficiency and expressivity. The second is our</p><!-- --> <p><span>evaluation suite</span>, which is necessary for evaluating progress on contextual capabilities and addresses the fact that common public evaluations are saturated.</p></div></div><div><h3>Background</h3><p>One approach to modeling audio with transformers is to convert continuous waveforms into discrete audio token sequences using tokenizers. Most contemporary approaches (<a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2306.12925">[1]</a>,<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2107.03312">[2]</a>) rely on two types of audio tokens:</p><ol><li><span>Semantic tokens</span>: Compact speaker-invariant representations of semantic and phonetic features. Their compressed nature enables them to capture key speech characteristics at the cost of high-fidelity representation.</li><li><span>Acoustic tokens</span>: Encodings of fine-grained acoustic details that enable high-fidelity audio reconstruction. These tokens are often generated using Residual Vector Quantization (RVQ)<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2107.03312">[2]</a>. In contrast to semantic tokens, acoustic tokens retain natural speech characteristics like speaker-specific identity and timbre.</li></ol><p>A common strategy first models semantic tokens and then generates audio using RVQ or diffusion-based methods. Decoupling these steps allows for a more structured approach to speech synthesis—the semantic tokens provide a compact, speaker-invariant representation that captures high-level linguistic and prosodic information, while the second-stage reconstructs the fine-grained acoustic details needed for high-fidelity speech. However, this approach has a critical limitation; semantic tokens are a bottleneck that must fully capture prosody, but ensuring this during training is challenging.</p><p>RVQ-based methods introduce their own set of challenges. Models must account for the sequential dependency between codebooks in a frame. One method, the delay pattern (figure below)<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2309.08804">[3]</a>, shifts higher codebooks progressively to condition predictions on lower codebooks within the same frame. A key limitation of this approach is that the time-to-first-audio scales poorly because an RVQ tokenizer with N codebooks requires N backbone steps before decoding the first audio chunk. While suitable for offline applications like audiobooks, this delay is problematic in a real-time scenario.</p><p>Example of delayed pattern generation in an RVQ tokenizer with 4 codebooks</p></div><div><h3>Conversational Speech Model</h3><p>CSM is a multimodal, text and speech model that operates directly on RVQ tokens. Inspired by the RQ-Transformer<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2203.01941">[4]</a>, we use two autoregressive transformers. Different from the approach in<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2410.00037">[5]</a>, we split the transformers at the zeroth codebook. The first<span> multimodal backbone</span> processes interleaved text and audio to model the zeroth codebook. The second <span>audio decoder</span> uses a distinct linear head for each codebook and models the remaining N&nbsp;–&nbsp;1 codebooks to reconstruct speech from the backbone’s representations. The decoder is significantly smaller than the backbone, enabling low-latency generation while keeping the model end-to-end.</p><p>CSM model inference process. Text (T) and audio (A) tokens are interleaved and fed sequentially into the Backbone, which predicts the zeroth level of the codebook. The Decoder then samples levels 1 through N&nbsp;–&nbsp;1 conditioned on the predicted zeroth level. The reconstructed audio token (A) is then autoregressively fed back into the Backbone for the next step, continuing until the audio EOT symbol is emitted. This process begins again on the next inference request, with the interim audio (such as a user utterance) being represented by interleaved audio and text transcription tokens.</p><p>Both transformers are variants of the Llama architecture. Text tokens are generated via a Llama tokenizer<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2407.21783">[6]</a>, while audio is processed using Mimi, a split-RVQ tokenizer, producing one semantic codebook and N&nbsp;–&nbsp;1 acoustic codebooks per frame at 12.5&nbsp;Hz.<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2410.00037">[5]</a> <!-- -->Training samples are structured as alternating interleaved patterns of text and audio, with speaker identity encoded directly in the text representation.</p></div><div><h3>Compute amortization</h3><p>This design introduces significant infrastructure challenges during training. The audio decoder processes an effective batch size of B&nbsp;×&nbsp;S and N codebooks autoregressively, where B is the original batch size, S is the sequence length, and N is the number of RVQ codebook levels. This high memory burden even with a small model slows down training, limits model scaling, and hinders rapid experimentation, all of which are crucial for performance.</p><p>To address these challenges, we use a compute amortization scheme that alleviates the memory bottleneck while preserving the fidelity of the full RVQ codebooks. The audio decoder is trained on only a random 1/16 subset of the audio frames, while the zeroth codebook is trained on every frame. We observe no perceivable difference in audio decoder losses during training when using this approach.</p><p>Amortized training process. The backbone transformer models the zeroth level across all frames (highlighted in blue), while the decoder predicts the remaining N&nbsp;–&nbsp;31 levels, but only for a random 1/16th of the frames (highlighted in green). The top section highlights the specific frames modeled by the decoder for which it receives loss.</p></div><div><h3>Experiments</h3><p><span>Dataset</span>: We use a large dataset of publicly available audio, which we transcribe, diarize, and segment. After filtering, the dataset consists of approximately one million hours of predominantly English audio.</p><p><span>Model Sizes</span>: We trained three model sizes, delineated by the backbone and decoder sizes:</p><ul><li><span>Tiny</span>: 1B backbone, 100M decoder</li><li><span>Small</span>: 3B backbone, 250M decoder</li><li><span>Medium</span>: 8B backbone, 300M decoder</li></ul><p>Each model was trained with a 2048 sequence length (~2 minutes of audio) over five epochs.</p></div><div><h3>Samples</h3><p>Paralinguistics</p><p>Sentences from<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2402.08093">Base TTS</a></p><p>Foreign words</p><p>Sentences from<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2402.08093">Base TTS</a></p><p>Contextual expressivity</p><p>Samples from Expresso, continuation after chime</p><p>Pronunciation correction</p><p>Pronunciation correction sentence is a recording, all other audio is generated.</p><p>Conversations with multiple speakers</p><p>Single generation using audio prompts from two speakers</p></div><div><h3>Evaluation</h3><p>Our evaluation suite measures model performance across four key aspects: faithfulness to text, context utilization, prosody, and latency. We report both objective and subjective metrics—objective benchmarks include word error rate and novel tests like homograph disambiguation, while subjective evaluation relies on a Comparative Mean Opinion Score (CMOS) human study using the <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2308.05725">Expresso</a> <!-- -->dataset.</p></div><div><h3>Objective metrics</h3><p>Traditional benchmarks, such as word error rate (WER) and speaker similarity (SIM), have become saturated—modern models, including CSM, now achieve near-human performance on these metrics.</p><p>Objective metric results for Word Error Rate (top) and Speaker Similarity (bottom) tests, showing the metrics are saturated (matching human performance).</p><p>To better assess pronunciation and contextual understanding, we introduce a new set of phonetic transcription-based benchmarks.</p><ul><li><span>Text understanding through Homograph Disambiguation:</span> <!-- -->Evaluates whether the model correctly pronounced different words with the same orthography (e.g., “lead” /lɛd/ as in “metal” vs. “lead” /liːd/ as in “to guide”).</li><li><span>Audio understanding through Pronunciation Continuation Consistency:</span> <!-- -->Evaluates whether the model maintains pronunciation consistency of a specific word with multiple pronunciation variants in multi-turn speech. One example is “route” (/raʊt/ or /ruːt/), which can vary based on region of the speaker and context.</li></ul><p>Objective metric results for Homograph Disambiguation (left) and Pronunciation Consistency (right) tests, showing the accuracy percentage for each model’s correct pronunciation. Play.ht, Elevenlabs, and OpenAI generations were made with default settings and voices from their respective API documentation.</p><p>The graph above compares objective metric results across three model sizes. For Homograph accuracy we generated 200 speech samples covering 5 distinct homographs—lead, bass, tear, wound, row—with 2 variants for each and evaluated pronunciation consistency using<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://huggingface.co/facebook/wav2vec2-lv-60-espeak-cv-ft">wav2vec2-lv-60-espeak-cv-ft</a>. For Pronunciation Consistency we generated 200 speech samples covering 10 distinct words that have common pronunciation variants—aunt, data, envelope, mobile, route, vase, either, adult, often, caramel.</p><p>In general, we observe that performance improves with larger models, supporting our hypothesis that scaling enhances the synthesis of more realistic speech.</p></div><div><h3>Subjective metrics</h3><p>We conducted two Comparative Mean Opinion Score (CMOS) studies using the<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://arxiv.org/abs/2308.05725">Expresso</a> <!-- -->dataset to assess the naturalness and prosodic appropriateness of generated speech for CSM-Medium. Human evaluators were presented with pairs of audio samples—one generated by the model and the other a ground-truth human recording. Listeners rated the generated sample on a 7-point preference scale relative to the reference. Expresso’s diverse expressive TTS samples, including emotional and prosodic variations, make it a strong benchmark for evaluating appropriateness to context.</p><p>In the first CMOS study we presented the generated and human audio samples with no context and asked listeners to<!-- --> <span>“choose which rendition feels more like human speech.”</span> In the second CMOS study we also provide the previous 90 seconds of audio and text context, and ask the listeners to<!-- --> <span>“choose which rendition feels like a more appropriate continuation of the conversation.”</span> Eighty people were paid to participate in the evaluation and rated on average 15 examples each.</p><p>Subjective evaluation results on the Expresso dataset. No context: listeners chose<!-- --> <span>“which rendition feels more like human speech”</span> <!-- -->without knowledge of the context. Context: listeners chose<!-- --> <span>“which rendition feels like a more appropriate continuation of the conversation”</span> <!-- -->with audio and text context. 50:50 win–loss ratio suggests that listeners have no clear preference.</p><p>The graph above shows the win-rate of ground-truth human recordings vs CSM-generated speech samples for both studies. Without conversational context (top), human evaluators show no clear preference between generated and real speech, suggesting that naturalness is saturated. However, when context is included (bottom), evaluators consistently favor the original recordings. These findings suggest a noticeable gap remains between generated and human prosody in conversational speech generation.</p></div><div><h3>Open-sourcing our work</h3><p>We believe that advancing conversational AI should be a collaborative effort. To that end, we’re committed to open-sourcing key components of our research, enabling the community to experiment, build upon, and improve our approach. Our models will be available under an Apache 2.0 license.</p></div><div><h3>Limitations and future work</h3><p>CSM is currently trained on primarily English data; some multilingual ability emerges due to dataset contamination, but it does not perform well yet. It also does not take advantage of the information present in the weights of pre-trained language models.</p><p>In the coming months, we intend to scale up model size, increase dataset volume, and expand language support to over 20 languages. We also plan to explore ways to utilize pre-trained language models, working towards large multimodal models that have deep knowledge of both speech and text.</p><p>Ultimately, while CSM generates high quality conversational prosody, it can only model the text and speech content in a conversation—not the structure of the conversation itself. Human conversations are a complex process involving turn taking, pauses, pacing, and more. We believe the future of AI conversations lies in fully duplex models that can implicitly learn these dynamics from data. These models will require fundamental changes across the stack, from data curation to post-training methodologies, and we’re excited to push in these directions.</p></div><div><h3>Join us</h3><p>If you’re excited about building the most natural, delightful, and inspirational voice interfaces out there, reach out—we’re hiring. Check our<!-- --> <a target="_blank" rel="noopener noreferrer" data-sentry-element="NextLink" data-sentry-source-file="crossing_the_uncanny_valley_of_voice.tsx" href="https://jobs.ashbyhq.com/sesame">open roles</a>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knowing CSS is mastery to Front end Development (151 pts)]]></title>
            <link>https://helloanselm.com/writings/knowing-css-is-mastery-to-frontend-development</link>
            <guid>43227303</guid>
            <pubDate>Sun, 02 Mar 2025 04:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://helloanselm.com/writings/knowing-css-is-mastery-to-frontend-development">https://helloanselm.com/writings/knowing-css-is-mastery-to-frontend-development</a>, See on <a href="https://news.ycombinator.com/item?id=43227303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>There are countless articles why developers should not focus on Frameworks too much and instead learn to understand the underlying languages. But I think rarely we can find good reasons except that Frameworks come and go. To me, the main reason is different: You won’t be a master at frontend development if you don’t understand underlying mechanisms of a language.</p>
<p>A usual stack today is React together with countless layers in between the language and the framework itself. CSS as styling method is not used natively but via JavaScript tools that translate it into native CSS. For JavaScript we nowadays write an opinionated Framework language mix using TypeScript which by itself is translated to native JavaScript in the end again. And while we all know the comfort of these tools and languages, there are many things that make it easier if you understand a browser’s ecosystem:</p>
<ul>
<li>Debug JavaScript errors easier and also in foreign environments without a debugging browser extension installed</li>
<li>Debug CSS</li>
<li>Write custom CSS (and every project I’ve seen so far needs it somewhere)</li>
<li>Understand why errors occur that you may not find locally and only in client’s browsers</li>
</ul>
<p>In the past years I had various situations where TypeScript developers (they called themselves) approached me and asked whether I could help them out with CSS. <strong>I expected to solve a complex problem</strong> but for me — knowing CSS very well —&nbsp;it was always a simple, straightforward solution or code snippet:</p>
<ul>
<li><em>A multi-colored footer bar should not be an image, it’s a simple CSS background multi-step gradient</em> with one line of code. No need to scale an image, create an SVG, just CSS.  </li>
<li><em>Custom icons for an input field?</em> Welp, it’s not that easy for privacy reasons to add a pseudo-class here in certain cases. But there are many simple solutions and no need to include another bloated npm dependency that nobody understands what it does.  </li>
<li><em>Webfonts</em>: Dev: We can’t add another webfont style, we already serve 4MB of webfonts.<br>
→ Me: Alright, why don’t we serve it as Variable Font?<br>
→ Dev: Oh, what’s this?<br>
→ Check it out, we now load 218kb async, only one file and have all our styles we have and will ever need inside. </li>
</ul>
<p>Nowadays people can write great React and TypeScript code. Most of the time a component library like MUI, Tailwind and others are used for styling. However, nearly no one is able to judge whether the CSS in the codebase is good or far from optimal. It is magically applied by our toolchain into the HTML and we struggle to understand why the website is getting slower and slower.</p>
<p>Most of the performance basics I learned ten years ago are still the most relevant ones today. Yet, most developers don’t know about them because we use create-react-web-app or similar things. Put Cloudflare on top to boost performance and reduce costs. Yes, that works for your website and little project. </p>
<p><strong>What companies expect</strong> when they ask for a web dashboard serving real time data for their customers is different: It should be a robust, well working application that is easy to maintain. That means we need to combine the developer experience (React, TypeScript, all the little helpers) with the knowledge of how browsers and networks work. And only then we can boost performance, write accessible code, load dynamic data in a proper and safe way and provide fallbacks in case something goes wrong.</p>
<p><strong>In cases of emergency like an Incident with the service, I’ve seen the difference often enough</strong> between people who exactly know where to look at, start debugging and go further, and those who try to find out in panic what’s going on here, hoping that a restart or re-deployment with reinstalled dependencies will help bring the service back to life.</p>
<p><strong>And that means in the end again: If you know CSS, you also know the style framework. If you understand JavaScript, TypeScript is not a big problem for you. And that makes you a Senior or Principal.</strong></p>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The NIH is being slashed and burned, not "reformed" (194 pts)]]></title>
            <link>https://www.sensible-med.com/p/the-nih-is-being-slashed-and-burned</link>
            <guid>43227180</guid>
            <pubDate>Sun, 02 Mar 2025 04:09:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sensible-med.com/p/the-nih-is-being-slashed-and-burned">https://www.sensible-med.com/p/the-nih-is-being-slashed-and-burned</a>, See on <a href="https://news.ycombinator.com/item?id=43227180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><strong><span>Sensible Medicine continues to encourage criticism of our viewpoints. Vinay Prasad wrote recently that cutting </span><a href="https://www.sensible-med.com/p/cutting-nih-indirects-is-sensible" rel="">NIH funding was Sensible Medicine</a><span>. Dr. Leslie Bienen offers this rebuttal. It is an excellent read. JMM</span></strong></em></p><p>By Leslie Bienen </p><p><span>Since the NIH </span><a href="https://grants.nih.gov/grants/guide/notice-files/NOT-OD-25-068.html" rel="">order</a><span> on February 7</span><sup>th</sup><span> capping indirect funds to grantees at 15%, the “outrage machine” that is X is filled with mostly fact-free criticisms of the NIH and academic research. I explain here why I think the criticisms are flawed, and why a blanket 15% cap is a terrible idea.</span></p><p><strong>Any cap should be blocked because only Congress can legally change NIH funding formulas.</strong></p><p><span>On February 21</span><sup>st</sup><span> a federal judge </span><a href="https://www.nytimes.com/2025/02/21/us/politics/judge-nih-medical-research-cuts-universities.html?smid=em-share" rel="">extended a temporary stay </a><span>of the February 7</span><sup>th</sup><span> policy, as she should have. Many have debated the “right” number for capping indirect rates and whether it is 15, 25% or some other number. But few mention that the current cap is illegal. In 2017 Trump similarly tried and failed to impose a 10% cap on NIH indirect rates, and Congress responded with several appropriations bills specifying that only Congress can change formulas for determining indirect costs. S</span><a href="https://www.acenet.edu/Documents/AAU-ACE-APLU-Complaint-NIH-Funding.pdf" rel="">everal lawsuits</a><span> detail why NIH can’t change indirects itself, including that “Congress exercised its constitutional power of the purse and forbade the executive from expending appropriated funds” and that “the Guidance does not even acknowledge the statutes that expressly prohibit NIH from taking this step.” If Congress wants to change the cap, let them do it legally.</span></p><p><strong>Claims that 1) NIH funds mostly weak research, 2) cutting budgets will reduce the amount of weak research funded, or 3) NIH spends lots of money on DEI trainings are unsupported by evidence.</strong></p><ol><li><p>Finding a weak NIH-funded study and tweeting it does not prove that NIH funds mostly bad research. I can cite thousands of examples of excellent research funded by NIH—which would also be cherry picking. We do not have robust analyses of quality of NIH-funded studies or reliable metrics to assess strength of a funded study. In short, no one knows how much of NIH-funded research is weak.</p></li><li><p><span>There is no evidence that changing the </span><em>amount</em><span> of money dispensed will magically change how good the funded research is. We could end up with little research funded, all of it weak. To improve quality of funded research requires changing criteria or creating mechanisms that prioritize innovation, or replicability, or creating more randomized trial mechanisms.</span></p></li><li><p><span>The NIH data book shows exactly what the agency spends its </span><a href="https://report.nih.gov/nihdatabook/" rel="">47B budget</a><span> on: ~ 60,000 research grants plus intramural research and R and D awards and research centers. In 2023 approximately 3.3B went to “other” or “trainings”, or ~7% of the total. About 22% went to running the NIH (study sessions, salaries, etcetera).</span></p></li></ol><p><strong>The idea that universities are not “accountable” to the NIH for how they spend money is incorrect.</strong></p><p>Universities cannot spend indirect funds on anything they choose; the list of expenses is approved by the government and is renegotiated every few years. I have written thousands of pages of budget reports to NIH and in my experience, money, including salary money, is extremely closely accounted for. In addition, universities already prohibit luxury expenditures such as flying first class, as does the NIH, which requires medical waivers to fly Economy Plus.</p><p><strong>If Congress places an overall cap, it should be higher than 15%.</strong></p><p><span>In 1994, the Federal government capped administrative rates at 26%. That cap is still in effect. What fluctuates per university is the rate that goes to facilities. If universities spend more of their </span><em>own budget</em><span> on facilities devoted to research, then their facilities rate rises, in order to incentivize university spending on research building and equipment. This is why large wealthy research universities (somewhat counterintuitively) tend to have higher indirect rates than state universities that build fewer labs, e.g., or buy less new equipment.</span></p><p><span>To understand why 15% will result in major reductions in research, take Harvard’s rate of 69% as an example. Their facilities rate is 43% and the administrative rate is 26%, equaling 69%. The new 15% cap </span><em>would include both those numbers</em><span>. Thus, Harvard would now have 21% of the money for research they had with a 69% cap. Jeffrey Flier, former Dean of Harvard Medical School,</span><a href="https://www.sensible-med.com/p/a-conversation-with-professor-jeffrey" rel=""> estimated</a><span> this as a loss of ~$70 million at Harvard’s current level of NIH support. For many universities, even wealthy ones, this size budget hole is unfillable without significantly reducing research.</span></p><p><strong>Lower-endowment state universities will suffer disproportionately.</strong></p><p>Big state universities such as UCSF, Univ. of California, Berkeley, University of Illinois, and UCLA will be the hardest hit by lowering indirect rates so steeply. Smart policy reforms at NIH should protect state university research programs because they allow lower-income students access and exposure to careers and top scientists. Many of these universities are located in the South and Midwest and are vital to local economies and bring clinical trials and high-tech research labs which provide cutting edge health-care in places that would otherwise not have it.</p><p><strong>These cuts will undermine the US’s position as the dominant world leader in biomedical innovation.</strong></p><p><span>The USA is a global leader in biomedical research, partly because the NIH is the largest biomedical research funder in the world and a substantial percentage of biomedical innovations emerge from academic research. A </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8552459/#:~:text=Overall%2C%20academic%20inventors%20or%20founders,50%25%20of%20prostate%20cancer%20medicines." rel="">2020 analysis </a><span>found that academic researchers contributed to 37% of cancer medicines discovered from 2010-2019 and 29% of antiviral drugs such as for HIV and hepatic cancers. The National Science Board </span><a href="https://www.nsf.gov/nsb/news/news_summ.jsp?cntn_id=303449" rel="">reported</a><span> that half of basic research in the USA is done in universities. A </span><a href="https://www.bio.org/press-release/licensing-academic-patents-contributed-19-trillion-us-economy-supported-65-million" rel="">2022 report</a><span> from the Biotechnology Innovation Organization noted </span><em>academic patents alone</em><span> contributed $1.9 trillion and 6.5 million jobs to the US economy. The NIH </span><a href="https://www.nih.gov/about-nih/what-we-do/impact-nih-research/serving-society/direct-economic-contributions#:~:text=With%20an%20annual%20budget%20of,%2492.89%20billion%20in%20economic%20activity." rel="">estimates</a><span> its 47B budget generates 97B to the US economy. Claims that this number could be higher are not supported by evidence and do not negate that 97B is a lot of money.</span></p><p><span>There is evidence, however, that the US is slipping as a leader in biomedical research. China now leads the world in new patents for pharmaceuticals. American scientists have been awarded </span><a href="https://www.statista.com/statistics/262896/nobel-prize-laureates-in-medicine-by-nationality/" rel="">106 of the total 229</a><span> Nobel Prizes in Medicine or Physiology since the prize’s founding in 1901 but the UK now leads the world (31 total) after correcting for population. We should be shoring up our position not cheering as it plummets.</span></p><p><strong>Arguments that these chaotic and destructive changes will lead to a future better NIH are unconvincing given how changes were accomplished.</strong></p><p><span>It would be possible to improve the NIH, and research quality, without gutting academic research or laying off </span><a href="https://nymag.com/intelligencer/article/how-many-federal-employees-fired-jobs-cut-trump-doge.html" rel="">1800 people</a><span> solely because they were recently hired or promoted. Instead, the last few weeks’ chaos will make future meaningful reform </span><em>more</em><span> difficult as Dr. Jay Bhattacharya, whom I have </span><a href="https://www.norfolkgroup.org/" rel="">worked with</a><span> and greatly respect, will now inherit a demoralized and haphazardly reduced workforce. The recent layoffs are also penny wise and pound foolish as mostly younger and healthier people, the cheapest to employ and insure, are now gone.</span></p><p>It is hard not to conclude that these changes were a slash and burn operation or, more aptly, an operation to remove a nose to spite a face. Sadly, the face that is being spited is the American public’s and, to the extent that American innovation drives global biomedical research, the world’s.</p><p><em><strong><span>Leslie Bienen is a veterinarian, writer, and editor who researches and writes about disease, health policy, and topics that catch her fancy. She has published in The Atlantic, The NYT, Slate, USA Today, UnHerd, City Journal, Persuasion, WSJ, and elsewhere. Here is a </span><a href="https://lesliebienen.substack.com/" rel="">link to her Substack</a><span>. </span></strong></em></p><p><strong>She reports working with academic scientists across many disciplines on grants to federal agencies and philanthropic organizations.</strong></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla site down due to "overdue hosting payments" (159 pts)]]></title>
            <link>https://linuxmom.net/@vkc/114089626244932902</link>
            <guid>43226089</guid>
            <pubDate>Sun, 02 Mar 2025 01:20:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxmom.net/@vkc/114089626244932902">https://linuxmom.net/@vkc/114089626244932902</a>, See on <a href="https://news.ycombinator.com/item?id=43226089">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[I'm done with coding (154 pts)]]></title>
            <link>https://www.neelc.org/2025/03/01/im-done-with-coding/</link>
            <guid>43225901</guid>
            <pubDate>Sun, 02 Mar 2025 00:49:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.neelc.org/2025/03/01/im-done-with-coding/">https://www.neelc.org/2025/03/01/im-done-with-coding/</a>, See on <a href="https://news.ycombinator.com/item?id=43225901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>In my high school days, I was a huge server and networking person. My homelab was basically my identity, and not even a good one: consumer-level networking gear running Tomato and a then-7-year-old homebuilt desktop PC running FreeBSD.</p>



<p>Then I joined <a href="https://engineering.nyu.edu/">NYU’s Tandon School of Engineering</a> for Computer Science. It was a full 180 into software engineering. I didn’t just code for assignments, I started with <a href="https://github.com/neelchauhan/TorNova">toy</a> <a href="https://github.com/neelchauhan/OnionLauncher">projects</a> and went to <a href="https://gitlab.torproject.org/tpo/core/tor/-/commits/main?author=Neel%20Chauhan">major Tor contributions</a> writing very complex patches, had two internships and ultimately a job at Microsoft.</p>



<p>Primarily due to “Big Data” experience at NYU CUSP, Microsoft placed me on the <em><a href="https://www.microsoft.com/en-us/microsoft-viva/insights">Viva Insights</a></em> team. I’ve always hated the product, feeling it was unnecessary surveillance. I wanted out.</p>



<p>In fact, the disdain of Viva Insights was big enough to make me lose passion for coding and get into obsessive browsing and shopping because facing the music of working on a surveillance product would bother me even more. Open source work outside of package maintenance went to zero.</p>



<p>I’ve tried to discuss this with my mom, and she kept telling me how “lucky” I am for working at Microsoft saying “it’s big tech” and “you’re neurodivergent” and “you won’t survive at a smaller company.” She even bought into the marketing material telling me how it’s “not surveillance.”</p>



<p>I’ve decided that in the shitty job market, it’s not worth being a software engineer even if I make much less. Part of it is being “specialized” in over-glorified surveillance so even if I change employers, what’s the guarantee I won’t be working on another surveillance product. Assuming I can even get another job.</p>



<p>In fact, I’ll just live off dividend income and try to get my new IT startup <a href="https://www.fourplex.net/">Fourplex</a> off the ground. Sure, I won’t be able to buy shiny homelab equipment as often as I did in the past, but I at least have the guarantee I’m not working on an unethical product.</p>



<p>While six figures is certainly <em>nice</em>, it’s only nice if it’s ethically done. I’d much rather flip burgers or bag groceries than work on surveillance for six figures. After all, Edward Snowden had a “stable” federal government job (not so stable now thanks to “DOGE”) and he gave it up to stand up for the right to privacy.</p>



<p>And I care more for my values than the name or salary. It’s not like I use Windows at home, I haven’t since 2012. I kept self-hosting email <em>despite</em> having worked at Microsoft 365 and <a href="https://bgp.he.net/dns/neelc.org">still do even now</a>. And I sacrificed job performance for my values of strong privacy.</p>



<p>Little did I know that my father (who was previously a big Big Data and AI advocate) would come out to hate Viva Insights. He says it’s “bullshit” and nobody uses it. Even when I worked at Microsoft I <em>never</em> used it. Not even once. It’s bloatware. Microsoft is 100% better off porting Office apps to Linux (despite me using a Mac now) or beefing up cybersecurity.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The early days of Linux (2023) (429 pts)]]></title>
            <link>https://lwn.net/Articles/928581/</link>
            <guid>43225686</guid>
            <pubDate>Sun, 02 Mar 2025 00:18:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/928581/">https://lwn.net/Articles/928581/</a>, See on <a href="https://news.ycombinator.com/item?id=43225686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<b>LWN.net needs you!</b>
<p>
Without subscribers, LWN would simply not exist.  Please consider
       <a href="https://lwn.net/Promo/nst-nag2/subscribe">signing up for a subscription</a> and helping
       to keep LWN publishing.
</p></blockquote>

<p>
My name is Lars Wirzenius, and I was there when Linux started.  Linux
is now a global success, but its beginnings were rather more humble.
These are my memories of the earliest days of Linux, its creation, and the
start of its path to where it is today.
</p>

<p>
I
started my <a href="https://www.helsinki.fi/en/faculty-science/faculty/computer-science">computer science studies at the University
of Helsinki</a> in the fall of&nbsp;1988, and met Linus Torvalds, who was the
other new Swedish speaking student in computer science that year. Toward
the end of that first year, we had gotten access to a Unix server, and I
accidentally found <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a>, the discussion 
system, by mistyping <tt>rm</tt> as <tt>rn</tt>, the Usenet reader. I told
Linus about it and we spent way too much time exploring this.
</p>

<p>After the first year, we both went away to do the mandatory military
service, though in different places. We returned to our university
studies in the fall of&nbsp;1990, and both took the course on C and Unix
programming, which included a fair bit of theory of the Unix kernel
architecture as well. This led to us reading about other operating
system kernels, such as <a href="https://en.wikipedia.org/wiki/QNX">QNX</a> and
<a href="https://en.wikipedia.org/wiki/Plan_9_from_Bell_Labs">Plan&nbsp;9</a>. Linus
and I discussed with some enthusiasm how an operating system
should be built correctly. We had all the overconfidence of
20-year-old second-year university students. Everyone is better off
that this wasn't recorded for posterity.
</p>

<p>In January&nbsp;1991, Linus bought his first <a href="https://en.wikipedia.org/wiki/IBM_PC_compatible">PC</a> from a local
shop 
that assembled computers from parts. The PC had a&nbsp;386 CPU, which was
relatively 
fancy at that time, because
Linus wanted to explore multitasking. Also, since he came from a
<a href="https://en.wikipedia.org/wiki/Sinclair_QL">Sinclair QL</a>
with a&nbsp;32-bit Motorola&nbsp;68008 CPU, he wanted a&nbsp;32-bit CPU, and did
not want to step down to a&nbsp;16-bit one, so a&nbsp;286 was not an option.
Linus's first PC had a whopping&nbsp;4 megabytes of RAM and a hard drive.
</p>

<p>He got a copy of the game Prince of Persia, which occupied most
of his spare time for the next couple of months. He later also bought
a copy of <a href="https://en.wikipedia.org/wiki/Minix">MINIX</a>, because after
using Unix at the university, he wanted something like that at home as
well.
</p>

<h4>As and Bs</h4>

<p>After finishing the game, Linus started learning Intel assembly
language. One day he showed me a program that did multitasking. One
task or thread would write a stream of the letter "A" on the screen, the
other "B"; the context switches were visually obvious when the stream
of As became Bs. This was the first version of what would later become
known as the Linux kernel.
</p>

<p>Linus would later expand the program, and write most of it in C.
During this time, late spring of&nbsp;1991, I wrote an implementation of the C
<a href="https://linux.die.net/man/3/sprintf"><tt>sprintf()</tt></a> function
for him, as he hadn't yet learned how to write functions with variable
argument lists. I wanted to spare him the pain of having a different
function for every type of value to write out. The core of this code is
still in the kernel, <a href="https://elixir.bootlin.com/linux/v6.3-rc6/source/lib/vsprintf.c#L2911">as
<tt>snprintf()</tt></a>. 
</p>

<p>As time went on, Linus made his fledgling kernel better and kept
implementing new things. After a while, he had drivers for the keyboard and
the serial port, emulation of <a href="https://en.wikipedia.org/wiki/VT100">VT100</a> terminal escape sequences
for the screen, and could use it to dial via a modem to the university to
read Usenet from home. Science fiction!
One day, Linus accidentally attempted to use his hard drive to dial the
university, resulting in his master boot sector starting with
<a href="https://en.wikipedia.org/wiki/Hayes_AT_command_set">"ATDT"</a> and the
university modem-pool phone number. After recovering from this, he
implemented file permissions in his kernel.
</p>

<p>In August&nbsp;1991, Linus mentioned his new kernel in <a href="https://en.wikipedia.org/wiki/History_of_Linux#The_creation_of_Linux">public
for the first time</a>, in the <tt>comp.os.minix</tt> newsgroup. This
included the phrase "<q>I'm doing a (free) operating system (just a hobby,
won't be big and professional like gnu)</q>". Such humility.
The system was initially called Freax. A few weeks later, 
Linus asked Ari Lemmke, one of
the administrators of <tt>ftp.funet.fi</tt>, to do an upload of the first
tar archive. Ari chose the name Linux.  The initial
version still contains the original name embedded in <a href="https://elixir.bootlin.com/linux/0.01/source/kernel/Makefile">one of the
source files</a>.
</p>

<p>During this time, people were interested in trying out this new
thing, so Linus needed to provide an installation method and
instructions. Since he only had one PC, he came to visit to
install it on mine. Since his computer had been used to develop Linux,
which had simply
grown on top of his Minix installation, it had never actually been
installed before. Thus, mine was the first PC
where Linux was ever installed. While this was happening, I was taking
a nap, and I recommend this method of installing Linux: napping, while
Linus does the hard work.
</p>

<p>The first releases of Linux used a license that forbade commercial
use. Some of the early contributors suggested a change to a free-software
license. In the fall of&nbsp;1991, Richard Stallman visited 
Finland and I took Linus to a talk given by Stallman. This, the
pressure from contributors, and my nagging eventually convinced Linus
to choose the GNU GPL license instead, in early&nbsp;1992.
</p>

<p>Over the Christmas break, Linus implemented virtual memory in Linux.
This made Linux a much more practical operating system on cheap
machines with little memory.
</p>

<h4>1992</h4>

<p>The year&nbsp;1992 started with the famous <a href="https://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_debate">debate with Andrew
Tanenbaum</a>, who is a university professor and the author of MINIX. He had
some opinions about Linux and its architecture. Linus had opinions on
MINIX. The debate has been described as a flame war, but was actually
rather civil in hindsight.
</p>

<p>More importantly for the future success of Linux was that the X11
system was ported to it, making&nbsp;1992 the year of the Linux desktop.
</p>

<p>I had chosen to contribute on the community side, rather than to the
kernel directly, and helped answer questions, write documentation, and
such. I also ran a short-lived newsletter about Linux, which is mainly
interesting for publishing the <a href="https://liw.fi/linux-news/issue03/">first ever interview with
Linus</a>. The newsletter was effectively replaced by the
<tt>comp.os.linux.announce</tt> newsgroup.
</p>

<p>The first Linux distribution was also started in&nbsp;1992: 
<a href="https://en.wikipedia.org/wiki/Softlanding_Linux_System">Softlanding
Linux System</a> or SLS. The next year, SLS morphed into Slackware, which
inspired Ian Murdock to start Debian in&nbsp;1993, in order to explore a
more community-based development structure. A few other distributions would
follow in the 
years to come.
</p>

<p>In&nbsp;1993, both Linus and I got hired as teaching assistants at the
university. We got to share an office. That room had a PC, which Linus
took over, and used for Linux development. I was happy with a DEC
terminal for Usenet access.
</p>

<p>One day, Linus was bored and the PC at work felt slow. He spent the
day rewriting the Linux kernel command-line parser in assembly
language, for speed. (That was, of course, quite pointless, and the
parser would later be rewritten again in C, for portability. Its speed
does not matter.) A couple of years later, he spent days playing
Quake, ostensibly to stress-test kernel memory management, although
that was with a newer PC. Much fun was had in that room, and there were no
pranks 
whatsoever. None at all.
</p>

<p>At some point, Linux gained support for Ethernet and TCP/IP. That meant
one could read Usenet without having to use a modem. Alas, early Linux
networking code was occasionally a little rough, having been written
from scratch. At one point, Linux would send some broken packets that
took down all of the Sun machines on the network. As it was difficult to get
the Sun kernel fixed, Linux was banned from the university network
until its bug was fixed. Not having Usenet access from one's desk is a
great motivator.
</p>

<h4>1.0</h4>

<p>In the spring of&nbsp;1994 we felt that Linux was done. Finished. Nothing
more to add. One could use Linux to compile itself, to read Usenet, and
run many copies of the <tt>xeyes</tt> program at once.  We
decided to release version&nbsp;1.0 and arranged a <a href="https://www.youtube.com/watch?v=qaDpjlFpbfo">release event</a>. The
Finnish computer press was invited, and a TV station even sent a crew. Most
of the event consisted of ceremonially compiling Linux&nbsp;1.0 in the
background, while Linus and others spoke about what Linux was and what it
was good for. Linus explained that commercial Unix for a PC was so
expensive that it was easier to write your own.
</p>

<p>In&nbsp;1995 Linus and I did a software engineering course at the university,
which mostly consisted of a large practical project. This was built on top
of Linux, of course. I insisted that a version-control system be used. I
had witnessed students in earlier courses do the shouting kind of version
control: the students shared a source tree over NFS and shouted "I'm
editing this file" when they were changing something.  This did not seem
like an effective method to me, so I insisted on <a href="https://en.wikipedia.org/wiki/Concurrent_Versions_System">CVS</a>,
which I'd just learned about. This experience is why Linus dislikes CVS and
for years refused to use any version control beyond uploading tar balls to
FTP sites.
</p>

<p>That year was also when Linux was first ported to a new architecture
by Linus. He'd been given a DEC Alpha machine. I would later get the
machine to use as a terminal for reading Usenet. Other people ported
Linux to other architectures, but that did not result in me getting any
more machines to read Usenet on.
</p>

<p>In&nbsp;1997 Linus graduated and moved to the US to take a job at
<a href="https://en.wikipedia.org/wiki/Transmeta">Transmeta</a>. I took a
job at a different university in the Helsinki area.
</p>

<p>In the following years, many things happened. It turned out that there
were still a few missing features from Linux, so people worked on
those. The term "open source" was coined and IBM invested a ton of money in
Linux development. Netscape published a version of its web browser as
open source. Skipping a few details and many years, open source basically
took over the world. LWN was started and covered much of this history on a
week-by-week basis.
</p>

<p>In&nbsp;1991, Linus wrote that Linux "<q>won't be big and professional
like gnu</q>". 
In&nbsp;2023. Linux is running on every continent, on every ocean, on billions
of devices, in orbit, and on Mars. Not bad for what started as two threads,
writing streams of As and Bs on the screen.
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Wirzenius_Lars">Wirzenius, Lars</a></td></tr>
            </tbody></table><br clear="all">
<hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Flash games shaped the video game industry (2020) (217 pts)]]></title>
            <link>https://www.flashgamehistory.com/</link>
            <guid>43225560</guid>
            <pubDate>Sun, 02 Mar 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flashgamehistory.com/">https://www.flashgamehistory.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43225560">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
        There were many more Flash games. Millions more.
    </p><p>
        Played billions of times on thousands of different gaming websites.
    </p><p>
        It was creative chaos.
        <br>
        <span id="explosiveEmoji">🤯</span>
    </p><div id="story1">


            <p>
            

            Flash games were the gateway for many developers in the games industry, and served as an experimental
            playground
            for distilling games down to their most pure and engaging elements. The end-of-life of Flash in December
            2020 marks the end of one of the most creative periods in the history of gaming.

            </p><p>
            
            It all started in 1996, when the Flash player was first released. Originally it was intended for Web
            graphics
            and animations, but when it got its own programming language in 2000, developers started to use
            it to make games.
            </p><p>
            
            That was the same year we saw the rise of the first automated Flash games website, Newgrounds.
            Anyone could upload their games and they were published immediately.
            </p></div><div id="svgContainer">
        


        <div>

            <br>
            <!--
            <div style="font-size:calc(25px + 0.5vw);color:#999999">
                Flash games on Newgrounds
            </div>
            -->
            <p>
                The following graph shows the 2000 most popular Flash games on Newgrounds in chronological order.


                Each bubble represents a game and the area of the bubble corresponds to the number of times that game
                was
                played on Newgrounds.
            </p>
            </div>
        <svg>
        </svg>

        <p><span>Everything by everyone</span>
            <br>
            Websites like Newgrounds made it possible for anyone to publish their games without a studio
            or a publisher. Developers uploaded experimental games, artistic games, brutally violent games, funny games
            and
            activist games. It was the wild west of gaming and the creativity that came out of that environment was
            amazing.
            People made games just because they wanted to make games, not to turn a profit.
        </p>


        <div>
            <p><span>The Flash workflow</span>
            <br>
            Flash had a designer centric workflow that brought together art, animation, and coding.
            People that wouldn't have written code otherwise could gradually make their animations into games. An
            example is
            the game <span>Xiao Xiao</span>, which started as a simple stick figure animation
            that evolved into a fighting game.
            </p><p>
            
            Developers also didn't have to worry about the technical details of cross-platform support. A game written
            in Flash 20 years ago is still playable today, while games written for iOS or Android require regular
            updates to keep them working on new phones.
        </p></div>


        <p><span>Accessibility</span>
            <br>
            Anyone could play Flash games by just clicking a link. Playing and sharing games today is still not as easy
            as it was 20 years ago.
        </p>


        <p><span>Decentralization</span>
            <br>
            The <span>Fancy Pants Adventures</span> game was played a few million times on
            Newgrounds, but across all websites, it
            was played more than 300 million times. Most Flash games were featured on thousands of different websites.
            If a game
            didn't connect with the audience
            of one site, it could still reach many others. The Internet was a more decentralized place back then.
            Nowadays, games like the <span>McDonald's Videogame</span>, where you corrupt
            politicians and destroy the rainforest to make
            fast food, would most likely be banned from the App Store, cutting it off from a large percentage of
            players.
        </p>


        <p><span>Rapid iteration</span>
            <br>
            The culture around Flash games promoted original ideas and made it acceptable to fail.
            Most games were made in less than a few months, some even in just a few days.
            If your game didn't do well, you could just make another one. Game design evolved at a rapid pace.
        </p>

        <p><span>The beginning of the end for Flash</span><br>
            In 2010, two years after the release of the iPhone, Steve Jobs wrote an open letter explaining why Flash
            wouldn't be allowed on Apple's platform. Flash had security issues, drained
            the
            battery, and was built for desktop computers, not mobile devices with touch interfaces.
            <br>
            <a href="https://web.archive.org/web/20200104081626/https://www.apple.com/hotnews/thoughts-on-flash/" target="_blank">Read the letter</a>


        </p>


        <div>
            <p><span>Flash exodus</span><br>

            By 2012, the number of players on Flash game websites was declining and fewer and fewer games were being
            made in Flash.
            Many developers jumped ship to make mobile or console games, and former Flash game animators started Youtube
            channels.
            </p><p>
            
            It was not just the rise of the iPhone that was responsible for the decline of Flash. Ultimately, the
            Internet became a different place that had to support a wide variety of different devices.
        </p></div>


        
    </div><div id="quotes">
        

        <br>


        <div><p>

            “Being a creator of and steward for Flash as a platform was a privilege. I felt that we were building a
            pencil
            and it was the community of creators that was responsible for the creation of Flash as a creative form. Our
            job
            as stewards was to anticipate needs, listen and make sure it worked. The core idea of having an accessible
            system for creating interactive media content that works across a range of devices is still a powerful one.
            Just
            like pencil and paper is a powerful tool. I hope it will happen again. Many years ago, I had the idea of
            Flash
            Forever. How can we treat what is created in Flash as valuable information like a book? Sadly, the need to
            drive
            business growth by adding features and capabilities, trumped the need for permanence. It’s great that Flash
            still lives in the skills and experiences of the community of people who learned and grew with it.”
            </p><p>
                Jonathan Gay
                <br>
                Creator of Flash
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Flash_logo.png" width="140" height="140">
            </p>
        </div>


        <div><p>
            “Over the years, my companies have made a number of software tools, but Flash was by far the most
            impactful. For me, the most gratifying thing has been having Flash animators thank me for giving them a
            career. Not just a tool, but a career. But the person that really is the one to be thanked is Jonathan Gay,
            the visionary behind Flash from day one and all the way until Adobe acquired it. Jonathan is an amazing man,
            and I was lucky to start working with him from the time he was a 17-year old in high school.”


            </p><p>
                Charlie Jackson
                <br>
                Co-Founder of FutureWave Software
                <br>
                <a href="https://www.s-beach.com/blog" target="_blank">Blog</a>
                <a href="https://twitter.com/wiredcoach" target="_blank">Twitter</a>

            </p>
            <p><img src="https://www.flashgamehistory.com/img/FutureWave_logo.png" width="250" height="104">
            </p>
        </div>
        <div><p>

            “Having grown up tinkering with animation software while programming text-based games, Flash was the first
            program that merged art and code in a way that I always hoped could be possible. Even better, anything you
            made could be played instantly on any computer via the web.
            </p><p>
            
            It was a magical time of experimentation and a lot of goofing off with friends found over the Internet. The
            moment was especially ideal for newcomers and outsiders, who now had a low barrier to entry and no industry
            gatekeeping. The joy of that era embodies what Newgrounds seeks to achieve to this very day; a place where
            people with no experience can learn, create and share wonderful things together.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Newgrounds_logo.png" width="140" height="140">
            </p>
        </div>
        <div><p>
            “Flash made the online game industry evolve, flourish and then explode. We played a small part, but it was a
            huge part of my life. I saw our games being played close to 3 billion times, with some including Bowman
            being played hundreds of millions of times. It is with great sadness I am witness to the death of Flash.
            Flash games made me, my business and altered my life. They allowed me to connect with the world and feel
            slightly less alone.”


            </p><p>
                Frank Valzano
                <br>
                Creator of Bowman and FreeWorldGroup.com
                <br>
                <a href="http://www.freeworldgroup.com/games4/gameindex/bowman2.htm" target="_blank">Play
                    game</a>
                <a href="http://www.freeworldgroup.com/" target="_blank">Website</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Bowman.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “I owe my success as a game developer to Flash. My Rebuild series and my husband's Fantastic Contraption
            both
            started as Flash games played by millions of people freely in their browsers. That ease of sharing was so
            revolutionary - we went from buying games at the mall to just clicking a link! Flash gave all these small
            experimental games an instant audience, and gave rise to indie games as we know them today including my
            own.”

            </p>
            <p><img src="https://www.flashgamehistory.com/img/Rebuild.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “For me, Flash was an integral part of my game dev journey - a wonderful, eccentric piece of tech that I
            will always hold dear. I'd been making games using various tools and languages since I was a kid but when
            Flash arrived on the scene it was a 'lightbulb moment', because I was a little bit of an artist, a little
            bit of a coder and this bridged that gap perfectly.
            <br>

            There just weren't any tools that I know of that allowed animators to make creations and coders to bring
            them to life. The fact that it compiled into this one tiny SWF file that could be distributed everywhere,
            (fonts, sounds, graphics and all!) just meant games could go viral in an instant and reach millions of
            players - which is exactly what happened when I launched the first Swords and Sandals game way back in 2007.
            <br>

            It's funny, I still find myself defending Flash against the lumbering and dreary HTML5 pipeline that
            proclaimed itself successor - even now, HTML5 gaming struggles to hold a candle to what Flash could do a
            decade ago with a lack of decent vector animation and inconsistent performance across browers.
            </p><p>
            

            Ten years after Steve Jobs declared it dead tech I still have a bunch of games on Steam made with AIR ( a
            sort of desktop 'successor' to Flash ) that have sold well enough to allow me to build an indie games
            business and given me the freedom to continue the Swords and Sandals story - I owe Flash a huge debt, thanks
            for saving the universe (for me at least!)”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/SwordsAndSandals.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “The old Flash scene was an incredible place to learn gamedev: it was a lively and fun community, and the
            content was free to access, but devs could still get paid for "pretty much any project" through the
            (honestly, kind of insane) sponsorship market - which also ended up handling distribution and marketing for
            you. These combined into a perfect storm of weird and unrestrained experimentation in all directions. I
            didn't realize until it was already over, but it was a tech bubble for strange art!”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/CompanyOfMyself.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “I was coming out of art school right when Flash was becoming popular and for me it was a way to create
            something and put it out in the world with no mediation — a Flash website was accessible to anyone with a
            web-browser. I would get emails from people at libraries enjoying my work! And I didn’t really think of the
            things I was making as games — it seemed that a browser window could have absolutely anything inside of it,
            and it didn’t need to be explained as long as it was compelling. To me, that element of surprise (or
            sometimes, confusion) is really magical. It probably had as much to do with the time as the technology, but
            it’s a feeling I’ve tried to keep alive in my work ever since.”
            </p>

            <p><img src="https://www.flashgamehistory.com/img/Windosill.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “My background is in visual arts and design so Flash was the perfect gateway drug to game making. It allowed
            me
            to start from simple animations, and gradually add more complex gameplays release after release.
            I still miss its timeline-based logic, its IDE, and its sharp vector rendering.
            Flash's streamlined workflow and huge ecosystem meant that I could make a game responding to an urgent issue
            in
            a matter of days and immediately make it accessible to an audience of millions.
            Tools and communities change all the time but certain kinds of Flash games are almost impossible to make
            with
            other tools, and the exuberant, fast and dirty world of online games has been only partially replaced by
            platforms like http://itch.io.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/TheMcDonaldsVideogame.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash as a platform gave "outsiders" an accessible tool to make games, but this wasn't the most important
            aspect: it was reach. It was mindblowing to put my game on Kongregate and have *thousands* of people play it
            overnight. This combo "runs in browser + access to player community" put a beginner, unknown, south american
            developer in the spotlight and allowed me to have a career in game development. It was just sad that Flash
            was in the hands of Adobe, who didn't know what to do with it and let it wither. HTML5 is still no
            replacement because it lacks the toolchain, it was a calamity when it died.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/IWishIWereTheMoon.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash games at their best had such a raw, personal connection to their creators. When playing them you
            could feel artist’s hand, and the passion they poured into their work. Flash games and animations felt
            accessible, they had a way of making you think, ‘Hey, I could do that!' The effect was immediate and
            intoxicating. The first shape on your canvas, no matter how crude, had the potential to be given life.
            </p><p>
            
            For someone who made videos, stop motion animations, built contraptions, and generally felt the urge to just
            making something, Flash just felt like exactly what I needed. I’ve heard ‘I didn’t know Flash could do that’
            a few times in regards to The Fancy Pants Adventures, but in reality, the series was shaped heavily by
            Flash’s unique vector based, animation-centric workflow. I was able to build something that I felt was
            distinctly mine, while working around and also embracing my own strengths and weaknesses.
            </p><p>
            
            The insane reach, the community, the crazy creatives, nothing else comes close, and most people just have no
            clue how absolutely massive Flash was.
            </p><p>
            
            It’s still almost impossible for me to wrap my head around the fact that I was able to create something that
            had an impact in the world, and Flash made that possible.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/FancyPants.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash had a huge influence on me as a game developer and designer. Relatively accessible code and very easy
            online sharing made game making a social activity, even when I didn't know a lot of other designers in
            person.
            Folks I met through making Flash games starting almost 15 years ago are still people I count as my very best
            friends. I have no idea what my life or career would look like without Flash. I also feel very honored and
            privileged to have had a hand in thousands of Flash games over the years by sharing my Flash game engine
            Flixel
            with other developers. Flash ruled and I miss it a lot.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Canabalt.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Flash gave me the opportunity to be creative and ambitious with what I was making while I was still
            learning
            to use it. It taught me how I could make games with the most basic of coding ability, and then taught me
            something new with every little project I made. Once I started making games professionally, it gave me the
            tools to make something new and fresh on an almost monthly basis without ever feeling particularly
            restricted by the platform.
            </p><p>
            
            Unfortunately as technology advanced, Adobe either dragged or dug in their heels and refused to adapt.
            Casual gamers and our target audience moved to mobile platforms which we simply were not provided any
            meaningful tools to properly cater to until it was years too late and there were other engines and
            technologies better suited to it.
            </p><p>
            
            It became harder to make just a simple game and have it run well, and I found myself recommending to others
            to stay away or choose a different path.
            </p><p>
            
            What didn't change though, was the experience of making so many games in an industry that was just beginning
            to find its feet, and I find it influencing so many decisions I make now that I work as a designer at SEGA.
            </p><p>
            
            Making Flash games for Armor Games was one of the best experiences of my life, even if the fast pace
            sometimes did feel crushing, there was nothing more thrilling than releasing a game out to Armor, Newgrounds
            and Kongregate and seeing the mostly positive reviews roll in. I met some amazing people, and got the chance
            to do amazing things. I miss Flash, and the ease of prototyping something so quickly and easily and just
            having it work everywhere. I also miss all the players of the games I had, it was incredible seeing people
            react to something I'd created and I still every so often hear from people who played one of my games and
            it's the best feeling in the world.
            </p><p>
            
            I've heard from people that Apple helped kill of Flash by not supporting it on iPhone, but Adobe had years
            and years to adapt and constantly let the community down, and I wonder what the world of casual games would
            be like now if Flash was still a viable platform for developers to use. I have a suspicion that the
            democratisation of platform and development that was seen in the early flash days on web portals would mean
            a less stale corporate run culture around small free to play games these days.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/SHIFT.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “Flash was an incredible force in the democratization of game development and the initial spark of what was
            to become a thriving ecosystem of indie game developers. It provided access to a market of unprecedented
            scale where you could reach anybody with a web browser by giving them nothing but a hyperlink and a way for
            games to spread virally with less friction than ever before. For XGen this meant the ability to reach tens
            of millions of players with our games, to build lasting direct relationships with our fans and to share in
            their experiences.
            </p><p>
            
            The creativity and experimentation enabled by Flash as a platform and the distribution that it enabled
            brought the industry countless new ideas, fresh perspectives on what games can be, and even whole new
            genres. Massive worldwide sensations like Minecraft and so many others can trace their ancestral lineage
            back to concepts and experiments that originated in the world of Flash games. It's clear that we owe a lot
            of the game industry's brightest stars to these funny little games that brought us all so much joy and
            delight.”
            </p><p>
                Jordan Dubuc
                <br>
                Director of Operations at XGen Studios
                <br>
                XGen Studios created Motherload
                <br>
                <a href="http://www.xgenstudios.com/play/motherload" target="_blank">Play game</a>
                <a href="https://twitter.com/XGenStudios" target="_blank">Twitter</a>
                <a href="http://www.xgenstudios.com/" target="_blank">Website</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Motherload.png" width="250" height="167">
            </p>

        </div>

        <div><p>
            “Flash was a remarkable technology: an accessible programming tool that created games that you could play
            from almost any computer connected to the internet. Where Steam and Apple are often credited with
            democratising development, an incredible number of developers entering the industry around that time had
            already learned that anyone could make games that could become 'a hit' via Flash and the many Flash games
            portals around.
            </p><p>
            

            Each technology shapes the work created in it, through the things that are easy to achieve in it, the
            opportunities of what is possible in it, and the challenges from what is not possible in it. Flash was an
            incredibly fast 2D animation tool, and the limitations of the internet in the Flash era limited the filesize
            you could expect players to wait for. This gave Flash a primary aesthetic of fast, 2D action games - and
            seeking to stand out within that space, a huge amount of experimentation and iteration followed. As the
            community found tricks and shortcuts, new possibilities would open up, and new experiments would follow. The
            community turned into a self-growing organism, ever seeking the ever-expanding possibilities of the space -
            some excelled in animation, others in design, others in creation speed, others in humor, and again others in
            technology. Whatever your focus, there were others chasing that same dream, appreciating your efforts - and
            that felt exciting.
            </p><p>
            

            It wouldn't be an exaggeration that Vlambeer, and with it games as Super Crate Box, Ridiculous Fishing,
            LUFTRAUSERS, and Nuclear Throne, would not have existed without Flash. We made our first dollar via Flash,
            and earned the money we needed to keep the studio afloat for the first few years via Flash. I know for a
            fact that we're not the only one. Many people I would consider indie legends today would not have been able
            to create their defining works, or sustain their passion projects without messing around in Flash.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/RadicalFishing.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “I was doing a PhD in BioChemistry back in 2008. I was conducting experiements where I needed to press a
            button every 5 minutes for over 6 hours. I started playing flash games to pass the time. They were so
            simple, accessible and fun that after a while I was drawn to making one.<br>
            I followed some tutorials and code examples (thanks Keith Peters!) and made a couple of games. They were
            played hundreds of thousands of times and I was instantly hooked. I never finished the PhD. I could no
            longer motivate myself to spend years writing something that will be read by 1 or 2 people if I’m lucky when
            instead I could spend a week making something silly and fun that 100k+ people would play. I’ve been making
            web games for over a decade now and they’ve been played around a billion times. I will never forget the
            start of my journey. Thinking up a bonkers new game idea, throwing it together then putting it on Kongregate
            and Newgrounds to see what people think. It was the golden age of indie game development in my opinion. The
            most creative and fun ideas got the most attention no matter who made them. No need for a marketing budget
            and definitely no in-app purchases etc. I’ve closed my flash site now (TheGameHomepage.com) to focus on my
            new(er) HTML5 game site FreeGames.org. I’ve had a few hiatuses and a job in between but I’m still making web
            games 12 years later!”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/RedRemover.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “A lot of new indie studios were popping up all across Indonesia in 2010. The main driving factor was Flash
            games. Flash games and its sponsorship business model had opened doors for Indonesians to create games and
            earn
            a decent living from web-based games. For Indonesians, making Flash games were the closest thing to being a
            “real” game developer. There were no big AAA studios nor schools with game development courses in Indonesia
            back
            then, even now access to game development knowledge is still very limited. And to make things even harder,
            games
            are still considered “bad” and not a legit career path in the eyes of parents, teachers, and government
            officials in Indonesia.
            </p><p>
            
            Many Indonesians who dreamt of working in the games industry or wanted to create their own games turned to
            Flash
            games and started forming studios or teams, I was one of them. The best thing was, you don’t need a lot of
            capital to start making Flash games and you can earn a pretty decent living in Indonesia. To put things into
            perspective, a simple Flash game that a single developer worked on for less than a month could get US$500 -
            US$1000 in sponsorships and ads, while the standard salary for a university fresh graduate in Jakarta was
            about
            Rp 3,000,000/month (US$200/month in today’s currency), even less if you live outside of Jakarta. The higher
            quality Flash game could even earn US$20K and more.
            </p><p>
            
            In this era, Indonesian game developers released many notable games and hits, such as the Epic War series
            from
            Artlogic games, Infectonator and Necronator series from Toge Productions, Valthirian Arc series from Agate,
            and
            many more. These games were being played by millions of people worldwide and their success helped the growth
            of
            Indonesian games industry.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Infectonator.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “I started making Flash games when I was 18. It was just a hobby, because I loved video games, was a
            computer science student and always wanted to make my own game. Flash was the easiest tool to do it, and it
            also had a huge community which could actually play the game and provide some feedback.
            </p><p>
            
            And the feedback from players became the most valuable thing for me. It inspired me to move further, make
            bigger, better and more detailed games. For example, Feudalism III had an AI system equal to Final Fantasy
            XII or Dragon Age: Origins, with unique settings for every one of 184 types of units.
            The feedback also really helped to improve my English ;)
            </p><p>
            
            I’ve been making Flash games fulltime for 10 years (2004 – 2014), and it was the best part of my life. In
            2014, when the flash started slowly dying, I’ve accidentally found an opening in big company making AAA
            games. I’ve decided to give it a try – mostly because I was curious if my skills would interest them.
            Surprisingly, they did! Since then I was even promoted to a lead UI programmer. So, I’m still a game
            developer, but currently as a part of big team.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Feudalism.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “I basically grew up on Newgrounds and developed an interest in making my own games very early on. I begged
            my parents to buy Flash (I believe the first version I got was Macromedia Flash MX 2004) and they were very
            skeptical of the cost, a few hundred dollars IIRC, but they got it for me for my 13th birthday.
            </p><p>
            

            I made a few low quality games which are lost to the ether, and then I started releasing some slightly
            better games under the name IcyLime. I made Multitask in 2009 when I was 15. Actually it only took about 10
            days to make, and I figured it would get maybe a few hundred, or maybe even a thousand views.
            </p><p>
            

            Multitask ended up getting over 10 million views across different sites like Kongregate, Newgrounds,
            ArmorGames, and others. I was overwhelmed and had NO idea how to properly monetize it at the time so I gave
            away licenses for less than market value, but since then it has still made around $15,000. I then made a few
            other games including Multitask 2 before life took over, and I never had time to return.
            I credit Flash for guiding me to my career path as a software developer, although I no longer have as much
            of an interest in making games specifically.”
            </p><p>
                Creed Gallagher
                <br>
                Creator of Multitask
                <br>
                <a href="https://www.newgrounds.com/portal/view/506546" target="_blank">Play game</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Multitask.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Long before Mario Maker was a thing, N by Metanet Software offered a level editor, and I submitted a couple
            hundred of my own designs to nmaps.net, where the community would play them and give feedback. My college
            offered a quality game design program, but I unironically learned more from this one little community of
            players and designers.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Run.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “I was basically a kid during the Flash-era, and I feel like I grew up alongside it. I would always frequent
            Newgrounds as I was enthralled by all the amazing content people were uploading and the community around it
            all. I would mess-around on the computers at school slowly teaching myself both animation and scripting with
            dreams of also uploading my own content one-day.
            </p><p>
            
            The first 'game' I ever made was entirely based off someone else's scripts they had uploaded for public use.
            I kept tweaking the code and drawing art, learning as much as I could but honestly just having fun; the
            concept of being a real game developer just didn't exist in my mind. Eventually I released my first serious
            game and people loved it, and that blew me away. So I kept doing it. A decade later and I've since changed
            careers to pursuing game development professionally, still learning and still honestly just having fun.
            Flash made that possible.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/ColourMyWorld.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “Nitrome would not have existed without flash. It may on the surface only seem like a tool to make games but
            at the time we started there were few realistic options for small indies. The low barrier to entry was two
            fold in that the application was easy to learn to a standard that you could make a game and as a platform
            there has never been an easier way to get your game out there. We even made decent money from it for a
            while.
            </p><p>
            
            In total Nitrome made over 130 games in flash. Making that many games was a great learning tool for us. Some
            of the games were better than others but that was part of the process and making lots of game quickly meant
            we got better quickly too.
            </p><p>
            
            The demise of flash led Nitrome to stop making flash games and led to our future games finding homes on
            mobile console and PC. Though the tools we use is now Unity and the stores are different the main spirit of
            the games we make is still firmly rooted in what we learnt making flash games.
            </p><p>
            
            Nitrome recently began converting our entire catalogue of Flash games to be playable in HTML5. The player
            may soon be gone but the games themselves will live on we hope for a long time to come.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Nitrome_logo.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “Bob and I started making Flash games in early 2001. It was as much fun to make the games as it was to play
            them. However, we all knew the dark side of Flash games was how the games would be pirated to multiple
            sites. It wasn't until 2005 that we developed the concepts for MochiBot and MochiAds. Thus, Mochi Media was
            born.
            </p><p>
            
            Working so closely with the Flash games community was such an inspiration to us all. We saw how
            life-changing these games could be for people around the world. I've built lifelong friendships through the
            community and I miss the camaraderie we had in the forums.”
            </p><p>
                Jameson Hsu
                <br>
                Co-Founder of Mochi Media
                <br>
                <a href="https://twitter.com/jamesonh" target="_blank">Twitter</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/MochiMedia_logo.png" width="232" height="186">
            </p>
        </div>


        <div><p>
            “Nowadays the internet is synonymous with posting your own stuff, but in 2004 there was no Twitter,
            Facebook, Youtube or SoundCloud. NewGrounds (and DeviantArt) was years ahead of the curve letting you not
            just upload home-made games, cartoons and music, but also letting users watch, vote on, review, give
            feedback, follow creators, download and share the stuff they liked, then learn how to make their own games
            and meet musicians or artists to collaborate with. This was in 2002, when most people thought "the internet"
            was a thing you installed from an AOL disc.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/NoTimeToExplain.png" width="250" height="167">
            </p>
        </div>
        <div><p>
            “I think its amazing to see the sort of things that came out of a misfit tool like Flash, if you think
            beyond the game / cartoon creation aspect of it, there was a brief period where websites were being built in
            Flash. Pretty elaborate ones in its hay day. So to me (I'm a designer, by profession) it directly
            intertwined with my career for a brief moment. I hope that something down the road, whatever that road ends
            up being, has a scrappy tool like Flash that can allow quick iteration and collaboration. It makes me
            sad to think that the next generation of edgy teens wont have the outlet that we old heads had back then.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/CastleCrashingTheBeard.png" width="250" height="167">
            </p>

        </div>

        <div><p>
            “I'd like to think I would have found a path into games no matter what, but flash was the first thing that
            made
            it possible for me. Its ease of use combined with sites like Newgrounds meant that a kid at home could make
            silly games and reach thousands of players with them. Luckily I was able to gain traction with some of my
            early
            games and start to earn revenue from them. Unfortunately Flash as a tool wasn't really built to keep up with
            market shifts like mobile development and the acceptance of indie devs onto console platforms. Since then
            I've
            made the move to Unity and I still continue to make games as my full-time job today. Kids now can just start
            with an engine like Unity or Unreal of course, but my time with flash gave me a huge leg up when jumping
            into
            these modern tools.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/ANEscapeSeries.png" width="250" height="167">
            </p>
        </div>


        <div><p>
            “I first got into Flash because I watched some badly animated Counter Strike parody cartoons on Newgrounds.
            It was so entertaining but also so scrappy that it inspired me to download the program and play around with
            it myself. From then on, it was just a cycle of playing and being inspired by things coming out of the
            portal, working on my own stuff, begging for help on the forums, and submitting my own scrappy work.
            </p><p>
            
            The influence on my career was massive. I essentially learned how to program and make digital art from
            Flash, and these are the skills that have shaped my career since. I've stopped working on games for the past
            few years now. I jumped into visual machine learning research for a while, and now I am a software engineer
            at AWS. I still hold game development dearly to my heart. It is very fun and fulfilling work.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Sonny.png" width="250" height="167">
            </p>
        </div>

        <div><p>
            “I think that the Flash game scene circa 2006-2010 was a LOT more friendly to newcomers. The current mobile
            market is too noisy and everything goes through one gatekeeper. If mobile stores worked more like the Flash
            portals of that era, I think there would be a much more interesting and vibrant indie ecosystem on mobile.”
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Filler.png" width="250" height="169">
            </p>
        </div>


        <div><p>
            “We can keep records of the games, the animations, and the sheer level of work that was put into making
            media with its tech. That's what I've been working on for over two years. But the microcosm of intense
            creativity, easy to access software, notable but not crippling limitations, almost universal compatibility
            across the entire technological space of its time, widespread adoption by encouraging free consumption and
            sharing in an age where 'going viral' actually meant something, all combining to influence the entire
            entertainment industry with one strike after another? That's something that we'll never be able to recreate,
            only remember fondly. All driven by a bunch of guys sitting in their bedrooms who watched a bit too much
            Xiao Xiao. Flash wasn't just a massive platform for games, it's a bite-sized model of our industry - the
            talent, the drive, the creativity - and I couldn't be happier it happened. There will never be anything like
            it again, and that's the most depressing thing about it going away.”
            </p><p>
                Ben Latimore
                <br>
                Creator of Flashpoint: The webgame preservation project
                <br>
                <a href="https://twitter.com/BlueMaxima" target="_blank">Twitter</a>
                <a href="https://bluemaxima.org/flashpoint" target="_blank">Website</a>
            </p>
            <p><img src="https://www.flashgamehistory.com/img/Flashpoint_logo.png" width="130" height="130">
            </p>
        </div>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Letter to the American People (978 pts)]]></title>
            <link>https://18f.org/</link>
            <guid>43224350</guid>
            <pubDate>Sat, 01 Mar 2025 22:22:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://18f.org/">https://18f.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43224350">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
        <p>March 1, 2025</p>
<h2 id="a-letter-to-the-american-people" tabindex="-1"><strong>A letter to the American People:</strong></h2>
<p>For over 11 years, 18F has been proudly serving you to make government technology work better. We are non-partisan civil servants. 18F has worked on hundreds of projects, all designed to make government technology not just efficient but effective, and to save money for American taxpayers.</p>
<p>However, all employees at 18F – a group that the Trump Administration GSA Technology Transformation Services Director called "the gold standard" of civic tech – were terminated today at midnight ET.</p>
<h2 id="18f-was-doing-exactly-the-type-of-work-that-doge-claims-to-want-yet-we-were-eliminated" tabindex="-1">18F was doing exactly the type of work that DOGE claims to want – yet we were eliminated.</h2>
<p>When former Tesla engineer Thomas Shedd took the position of TTS director and met with TTS including 18F on February 3, 2025, he acknowledged that the group is <strong>the “gold standard” of civic technologists</strong> and that “you guys have been doing this far longer than I’ve been even aware that your group exists.” He repeatedly emphasized the importance of the work, and the value of the talent that the teams bring to government.</p>
<h2 id="despite-that-skill-and-knowledge-at-midnight-et-on-march-1-the-entirety-of-18f-received-notice-that-our-positions-had-been-eliminated" tabindex="-1">Despite that skill and knowledge, at midnight ET on March 1, the entirety of 18F received notice that our positions had been eliminated.</h2>
<p>The letter said that 18F "has been identified as part of this phase of GSA’s Reduction in Force (RIF) as non-critical”.</p>
<p>"This decision was made with explicit direction from the top levels of leadership within both the Administration and GSA," Shedd said in an email shortly after we were given notice.</p>
<p>This was a surprise to all 18F staff and our agency partners. Just yesterday we were working on important projects, including improving access to weather data with NOAA, making it easier and faster to get a passport with the Department of State, supporting free tax filing with the IRS, and other critical projects with organizations at the federal and state levels.</p>
<p>All of that work has now abruptly come to a halt. Since the entire staff was also placed on administrative leave, we have been locked out of our computers, and have no chance to assist in an orderly transition in our work. We don’t even have access to our personal employment data. We’re supposed to return our equipment, but can’t use our email to find out how or where.</p>
<h2 id="dismantling-18f-follows-the-gutting-of-the-original-us-digital-service-these-cuts-are-just-the-most-recent-in-a-series-of-a-sledgehammer-approach-to-the-critical-us-teams-supporting-it-infrastructure" tabindex="-1">Dismantling 18F follows the gutting of the original US Digital Service. These cuts are just the most recent in a series of a sledgehammer approach to the critical US teams supporting IT infrastructure.</h2>
<p>Before today’s RIF, DOGE members and GSA political appointees demanded and took access to IT systems that hold sensitive information. They ignored security precautions. Some who pushed back on this questionable behavior resigned rather than grant access. Others were met with reprisals like being booted from work communication channels.</p>

<p>We’re still absorbing what has happened. We’re wrestling with what it will mean for ourselves and our families, as well as the impact on our partners and the American people.</p>
<p>But we came to the government to fix things. And we’re not done with this work yet.</p>
<p>More to come.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefly Blue Ghost Mission 1 Lunar Landing (179 pts)]]></title>
            <link>https://plus.nasa.gov/scheduled-video/firefly-blue-ghost-mission-1-lunar-landing/</link>
            <guid>43224107</guid>
            <pubDate>Sat, 01 Mar 2025 21:53:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plus.nasa.gov/scheduled-video/firefly-blue-ghost-mission-1-lunar-landing/">https://plus.nasa.gov/scheduled-video/firefly-blue-ghost-mission-1-lunar-landing/</a>, See on <a href="https://news.ycombinator.com/item?id=43224107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

	<main id="primary">
		    <div id="fullscreen-player" aria-labelledby="modal-2-heading" aria-describedby="modal-2-description">
        <video id="main-video" controls="" preload="auto" width="auto" height="auto" poster="https://plus.nasa.gov/wp-content/uploads/2025/02/clps-blue-ghost-1-landing-key-art-r4-horizontal-program-tile-16-9-without-title.jpg?w=1024" title="Firefly Blue Ghost Mission 1 Lunar Landing">
            <source src="https://ntv1.akamaized.net/hls/live/2110242/landing030225/master.m3u8" type="application/x-mpegURL">
            <p> To view this video please enable JavaScript, and consider upgrading to a web browser that
                <a href="https://videojs.com/html5-video-support/" target="_blank">supports HTML5 video</a>
            </p>
        </video>
        <div>
                
                
                <p>With a suite of NASA science and technology on board, Firefly Aerospace is targeting no earlier than 3:34 a.m. EST Sunday, March 2, to land their Blue Ghost lunar lander […]</p>
            </div>
    </div>
<section>
	<article id="post-6417" data-start-time="1740900000" data-end-time="1740906660">
		<header>
			<figure>
				<img width="1024" height="576" src="https://plus.nasa.gov/wp-content/uploads/2025/02/clps-blue-ghost-1-landing-key-art-r4-horizontal-program-tile-16-9-without-title.jpg?w=1024" alt="Firefly Blue Ghost Mission 1 Lunar Landing">				<div id="countdown-container">
    <div id="countdownclock">
        <div>
            <p><span>00</span></p><p>Days</p>
        </div>
        <div>
            <p><span>00</span></p><p>Hours</p>
        </div>
        <div>
            <p><span>00</span></p><p>Min</p>
        </div>
        <div>
            <p><span>00</span></p><p>Sec</p>
        </div>
    </div>
    
    <div id="pastblock">  
        <p>This event has already occurred</p>
    </div>
</div>			</figure>
			<a href="#fullscreen-player" aria-controls="fullscreen-player" title="Open video player" data-open-modal=""><span>Open Video Player</span></a>
		</header>

		<div>
				<div>
					<p><span>Today</span> <span>2:20 am</span></p>
					<h2>Firefly Blue Ghost Mission 1 Lunar Landing</h2>
					<div>
						<ul>
															<li>
									<a href="#fullscreen-player" aria-controls="fullscreen-player" title="Open video player" data-open-modal="">Watch Livestream</a>
								</li>
														<li>
															
							</li>
							<li>
																
							</li>
						</ul>
					</div>
					<p>With a suite of NASA science and technology on board, Firefly Aerospace is targeting no earlier than 3:34 a.m. EST Sunday, March 2, to land their Blue Ghost lunar lander on the Moon. Blue Ghost is slated to touch down near Mare Crisium, in the northeast quadrant on the near side of the Moon, as part of NASA’s CLPS (Commercial Lunar Payload Services) initiative and Artemis campaign to establish a long-term lunar presence. Live coverage of the landing, jointly hosted by NASA and Firefly, will air on NASA+ starting at 2:20 a.m. EST, approximately 75 minutes before touch down on the Moon’s surface.</p><!-- .entry-content -->
				</div>
				<div>

					<table data-event-timestamp="1740900000">
						<thead>
							<tr>
								<th scope="row">Details</th>
							</tr>
						</thead><tbody>
							<tr>
								<th scope="row">Date</th>
								<td><span>Today</span></td>
							</tr>
							<tr>
								<th scope="row">Time</th>
								<td><span>2:20 am</span></td>
							</tr>
							<tr>
								<th scope="row">Timezone</th>
								<td><span><div><form><label for="city-location">Select Your Location or Timezone</label></form></div></span></td>
							</tr>
																				</tbody>
					</table>
				</div>

			</div>
	</article><!-- #post-6417 -->
</section>

	</main><!-- #main -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why can't we screenshot frames from DRM-protected video on Apple devices? (156 pts)]]></title>
            <link>https://daringfireball.net/2025/03/why_cant_we_screenshot_frames_from_drm-protected_video</link>
            <guid>43223985</guid>
            <pubDate>Sat, 01 Mar 2025 21:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/2025/03/why_cant_we_screenshot_frames_from_drm-protected_video">https://daringfireball.net/2025/03/why_cant_we_screenshot_frames_from_drm-protected_video</a>, See on <a href="https://news.ycombinator.com/item?id=43223985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">



<p>Nora Deligter, writing for Screen Slate in June 2023, “<a href="https://www.screenslate.com/articles/elegy-screenshot">Elegy for the Screenshot</a>”:</p>

<blockquote>
  <p>About five years ago, Catherine Pearson started taking screenshots
of every bouquet featured on <em>The Nanny</em> (1993–1999), the
six-season CBS sitcom that was then streaming on Netflix. She was
just becoming a florist, and she found the arrangements — ornate,
colorful, and distinctly tropical — inspirational. She now keeps
them in a folder on her desktop, alongside screenshots of flower
arrangements featured on <em>Poirot</em> (1989–2013), the British
detective drama. A few months ago, however, Pearson suddenly found
that when her fingers danced instinctively toward Command-Shift-3,
she was greeted by a black box where her flowers used to be, a
censored version of what she had meant to capture.</p>

<p>It was around this time when streaming platforms like Netflix, HBO
Max, Amazon Prime, and the Criterion Channel imposed a quiet
embargo on the screenshot. At first, there were workarounds: users
could continue to screenshot by using the browser Brave or by
downloading extensions or third-party tools like Fireshot. But
gradually, the digital-rights-management tech adapted and became
more sophisticated. Today, it is nearly impossible to take a
screenshot from the most popular streaming services, at least not
on a Macintosh computer. [...]</p>

<p>For PC users, this story takes a different, and happier, turn.
With the use of Snipping Tool — a utility exclusive to Microsoft
Windows, users are free to screen grab content from all streaming
platforms. This seems like a pointed oversight, a choice on the
part of streamers to exclude Mac users (though they make up a tiny
fraction of the market) because of their assumed cultural class.
This assumption isn’t unreasonable. Out of everyone interviewed
for this article, only one of them was a PC user.</p>
</blockquote>

<p>Deligter’s essay has been sitting in my long (and ever-growing) list of things to link to ever since she published it back in 2023. I referenced it in <a href="https://daringfireball.net/linked/2025/03/01/green-imessage-disappearing-messages">my post earlier today</a> re: <a href="https://blog.cryptographyengineering.com/2025/03/01/dear-apple-add-disappearing-messages-to-imessage-right-now/">Matthew Green’s entreaty to Apple</a> to add “disappearing messages” to iMessage, and re-reading it made me annoyed enough to finally write about it.</p>

<p>I’m not entirely sure what the technical answer to this is, but on MacOS, it seemingly involves the GPU and video decoding hardware. These DRM blackouts happen at such a low level that no high-level software — any sort of utility you might install — can route around them. I think Windows still offers easy screenshotting of frames from DRM video not because the streaming services somehow don’t care about what Windows users do (which, when you think about it, would be a weird thing <em>not</em> to care about, given Windows’s market share), but because Windows uses a less sophisticated imaging pipeline. Or perhaps rather than less <em>sophisticated</em>, it’s more accurate to say less <em>integrated</em>. These DRM blackouts on Apple devices (you can’t capture screenshots from DRM video on iPhones or iPads either) are enabled through the deep integration between the OS and the hardware, thus enabling the blackouts to be imposed at the hardware level. And I don’t think the streaming services opt into this screenshot prohibition other than by “protecting” their video with DRM in the first place. If a video is DRM-protected, you can’t screenshot it; if it’s not, you can.</p>

<p>On the Mac, it used to be the case that DRM video was blacked-out from screen capture in Safari, but not in Chrome (or the dozens of various Chromium-derived browsers). But at some point a few years back, you stopped being able to capture screenshots from DRM videos in Chrome, too — <em>by default</em>. But in Chrome’s Settings page, under System, if you disable “Use graphics acceleration when available” and relaunch Chrome, boom, you can screenshot everything in a Chrome window, including DRM video. You can go to the magic URL <code>chrome://gpu/</code> before and after toggling this setting to see a full report on the differences — as you’d expect, it turns off all hardware acceleration for video encoding/decoding, compositing, and more. You wouldn’t want to browse like this all the time (certainly not on battery power), but it’s a great trick to know for capturing stills from videos.</p>

<p>What I don’t understand is why Apple bothered supporting this in the first place for hardware-accelerated video (which is all video on iOS platforms — there is no workaround like using Chrome with hardware acceleration disabled on iPhone or iPad). No one is going to create bootleg copies of DRM-protected video one screenshotted still frame at a time — and even if they tried, they’d be capturing only the images, not the sound. And it’s not like this “feature” in MacOS and iOS has put an end to bootlegging DRM-protected video content. This “feature” accomplishes nothing of value for anyone, including the streaming services, but imposes a massive (and for most people, confusing and frustrating) hindrance on honest people simply trying to easily capture high-quality (as opposed to, say, using their damn phone to take a photograph of their reflective laptop display) screenshots of the shows and movies they’re watching.</p>



 <!-- PreviousNext -->
</div></div>]]></description>
        </item>
    </channel>
</rss>