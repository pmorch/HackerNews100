<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 29 Oct 2025 17:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HNInternal: Azure Outage (332 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=45748799</link>
            <guid>45748799</guid>
            <pubDate>Wed, 29 Oct 2025 16:08:35 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=45748799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="45749790"><td></td></tr><tr id="45750104"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45750104" href="https://news.ycombinator.com/vote?id=45750104&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>This is funny but also possibly true because: business/MBA types see these outages as a way to prove how critical some services are, leading to investors deciding to load up on the vendor's stock.</p></div></td></tr></tbody></table></td></tr><tr id="45750140"><td></td></tr><tr id="45749044"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749044" href="https://news.ycombinator.com/vote?id=45749044&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Update 16:57 UTC:</p><p>Azure Portal Access Issues</p><p>Starting at approximately 16:00 UTC, we began experiencing Azure Front Door issues resulting in a loss of availability of some services. In addition. customers may experience issues accessing the Azure Portal. Customers can attempt to use programmatic methods (PowerShell, CLI, etc.) to access/utilize resources if they are unable to access the portal directly. We have failed the portal away from Azure Front Door (AFD) to attempt to mitigate the portal access issues and are continuing to assess the situation.</p><p>We are actively assessing failover options of internal services from our AFD infrastructure. Our investigation into the contributing factors and additional recovery workstreams continues. More information will be provided within 60 minutes or sooner.</p><p>This message was last updated at 16:57 UTC on 29 October 2025</p><p>---</p><p>Update: 16:35 UTC:</p><p>Azure Portal Access Issues</p><p>Starting at approximately 16:00 UTC, we began experiencing DNS issues resulting in availability degradation of some services. Customers may experience issues accessing the Azure Portal. We have taken action that is expected to address the portal access issues here shortly. We are actively investigating the underlying issue and additional mitigation actions. More information will be provided within 60 minutes or sooner.</p><p>This message was last updated at 16:35 UTC on 29 October 2025</p><p>---</p><p>Azure Portal Access Issues</p><p>We are investigating an issue with the Azure Portal where customers may be experiencing issues accessing the portal. More information will be provided shortly.</p><p>This message was last updated at 16:18 UTC on 29 October 2025</p><p>---</p><p>Message from the Azure Status Page: <a href="https://azure.status.microsoft/en-gb/status" rel="nofollow">https://azure.status.microsoft/en-gb/status</a></p></div></td></tr></tbody></table></td></tr><tr id="45749996"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749996" href="https://news.ycombinator.com/vote?id=45749996&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Azure Network Availability Issues</p><p>Starting at approximately 16:00 UTC, we began experiencing Azure Front Door issues resulting in a loss of availability of some services. We suspect that an inadvertent configuration change as the trigger event for this issue. We are taking two concurrent actions where we are blocking all changes to the AFD services and at the same time rolling back to our last known good state.</p><p>We have failed the portal away from Azure Front Door (AFD) to mitigate the portal access issues. Customers should be able to access the Azure management portal directly.</p><p>We do not have an ETA for when the rollback will be completed, but we will update this communication within 30 minutes or when we have an update.</p><p>This message was last updated at 17:17 UTC on 29 October 2025</p></div></td></tr></tbody></table></td></tr><tr id="45750154"><td></td></tr><tr id="45750015"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45750015" href="https://news.ycombinator.com/vote?id=45750015&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>AFD is down quite often regionally in Europe for our services. In 50%+ the cases they just don‘t report it anywhere, even if its for 2h+.</p></div></td></tr></tbody></table></td></tr><tr id="45750063"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45750063" href="https://news.ycombinator.com/vote?id=45750063&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Spam those Azure tickets.  If you have a CSAM, build them a nice powerpoint telling the story of all your AFD issues (that's what they are there for).</p><p>&gt; In 50%+ the cases they just don‘t report it anywhere, even if its for 2h+.</p><p>I assume you mean publicly.  Are you getting the service health alerts?</p></div></td></tr></tbody></table></td></tr><tr id="45750117"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45750117" href="https://news.ycombinator.com/vote?id=45750117&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I got a service health alert an hour after it started, saying the portal was having issues. Pretty useless and misleading.</p></div></td></tr></tbody></table></td></tr><tr id="45749919"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749919" href="https://news.ycombinator.com/vote?id=45749919&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Whilst the status message acknowledge's the issue with Front Door (AFD), it seems as though the rest of the actions are about how to get Portal/internal services working without relying on AFD. For those of us using Front Door does that mean we're in for a long haul?</p></div></td></tr></tbody></table></td></tr><tr id="45749370"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749370" href="https://news.ycombinator.com/vote?id=45749370&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I'll be interested in the incident writeup since DNS is mentioned. It will be interesting in a way if it is similar to what happened at AWS.</p></div></td></tr></tbody></table></td></tr><tr id="45749618"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749618" href="https://news.ycombinator.com/vote?id=45749618&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>It's pretty unlikely. AWS published a public 'RCA' <a href="https://aws.amazon.com/message/101925/" rel="nofollow">https://aws.amazon.com/message/101925/</a>. A race condition in a DNS 'record allocator' causing all DNS records for DDB to be wiped out.</p><p>I'm simplifying a bit, but I don't think it's likely that Azure has a similar race condition wiping out DNS records on _one_ system than then propagates to all others. The similarity might just end at "it was DNS".</p></div></td></tr></tbody></table></td></tr><tr id="45749762"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45749762" href="https://news.ycombinator.com/vote?id=45749762&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>That RCA was fun. A distributed system with members that don't know about each other, don't bother with leader elections, and basically all stomp all over each other updating the records. It "worked fine" until one of the members had slightly increased latency and everything cascade-failed down from there. I'm sure there was missing (internal) context but it did not sound like a well-architected system at all.</p></div></td></tr></tbody></table></td></tr><tr id="45750112"><td></td></tr><tr id="45749776"><td></td></tr><tr id="45749640"><td></td></tr><tr id="45749055"><td></td></tr><tr id="45750056"><td></td></tr><tr id="45749250"><td></td></tr><tr id="45749704"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45749704" href="https://news.ycombinator.com/vote?id=45749704&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>From what I can tell, Downdetector just tracks traffic to their pages without actually checking if the site is down.</p><p>The other day during the AWS outage they "reported" OVH down too.</p></div></td></tr></tbody></table></td></tr><tr id="45749294"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45749294" href="https://news.ycombinator.com/vote?id=45749294&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>yea I saw that, but im not sure on how accurate that is. a few large apps/companies I know to be 100% on AWS in us-east-1 are cranking along just fine.</p></div></td></tr></tbody></table></td></tr><tr id="45749673"><td></td></tr><tr id="45749939"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749939" href="https://news.ycombinator.com/vote?id=45749939&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>yes, and it seems that at least for some login.microsoftonline.com is down too, which is part of the Entra login / SSO  flow.</p></div></td></tr></tbody></table></td></tr><tr id="45749144"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749144" href="https://news.ycombinator.com/vote?id=45749144&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Yeah, I am guessing it's just a placeholder till they get more info. I thought I saw somewhere that internally within Microsoft it's seen as a "Sev 1" with "all hands on deck" - Annoyingly I can't remember where I saw it, so if someone spots it before I do, please credit that person :D</p><p>Edit: Typo!</p></div></td></tr></tbody></table></td></tr><tr id="45749309"><td></td></tr><tr id="45750017"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45750017" href="https://news.ycombinator.com/vote?id=45750017&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Yet another reason to move away from Front Door.</p><p>We already had to do it for large files served from Blob Storage since they would cap out at 2MB/s when not in cache of the nearest PoP. If you’ve ever experienced slow Windows Store or X-Box downloads it’s probably the same problem.</p><p>I had a support ticket open for months about this and in the end the agent said “this is to be expected and we don’t plan on doing anything about it”.</p><p>We’ve moved to Cloudflare and not only is the performance great, but it costs less.</p><p>Only thing I need to move off Front Door is a static website for our docs served from Blob Storage, this incident will  make us do it sooner rather than later.</p></div></td></tr></tbody></table></td></tr><tr id="45750144"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45750144" href="https://news.ycombinator.com/vote?id=45750144&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>we are considering the same but because our website uses APEX domain we would need to move all DNS resolver to cloudfront right ? Does it have as a nice "rule set builder" as azure ?</p></div></td></tr></tbody></table></td></tr><tr id="45749332"><td></td></tr><tr id="45749788"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749788" href="https://news.ycombinator.com/vote?id=45749788&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>The Internet is supposed to be decentralized. The big three seem to have all the power now (Amazon, Microsoft, and Google) plus Cloudflare/Oracle.</p><p>How did we get here? Is it because of scale? Going to market in minutes by using someone else's computers instead of building out your own, like co-location or dedicated servers, like back in the day.</p></div></td></tr></tbody></table></td></tr><tr id="45749826"><td></td></tr><tr id="45749905"><td></td></tr><tr id="45749946"><td></td></tr><tr id="45749866"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749866" href="https://news.ycombinator.com/vote?id=45749866&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>A lot of money and years of marketing the cloud as the responsible business decision led us here. Now that the cloud providers have vendor lock-in, few will leave, and customers will continue to wildly overpay for cloud services.</p></div></td></tr></tbody></table></td></tr><tr id="45749985"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749985" href="https://news.ycombinator.com/vote?id=45749985&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Ahh, but you forget what it <i>used</i> to be like. Sites used to go down <i>all the time.</i></p><p>Now, they go down a lot less frequently, but when they do, it's more widespread.</p></div></td></tr></tbody></table></td></tr><tr id="45750078"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45750078" href="https://news.ycombinator.com/vote?id=45750078&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>&gt; How did we get here?</p><p>I think the response lies in the surrounding ecosystem.</p><p>If you have a company it's easier to scale your team if you use AWS (or any other established ecosystem). It's way easier to hire 10 engineers that are competent with AWS tools than it is to hire 10 engineers that are competent with the IBM tools.</p><p>And from the individuals perspective it also make sense to bet on larger platforms. If you want to increase your odds of getting a new job, learning the AWS tools gives you a better ROI than learning the IBM tools.</p></div></td></tr></tbody></table></td></tr><tr id="45749853"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749853" href="https://news.ycombinator.com/vote?id=45749853&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Thats the whole point, big players like AWS and MS can go down, but here we are still talking on the internet.</p><p>Decentralisation is winning it seems.</p></div></td></tr></tbody></table></td></tr><tr id="45750084"><td></td></tr><tr id="45749871"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749871" href="https://news.ycombinator.com/vote?id=45749871&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Consolidation is the inevitable outcome of free unregulated markets.</p><p>In our highly interconnected world, decentralization paradoxically requires a central authority to enforce decentralization by restricting M&amp;A, cartels, etc.</p></div></td></tr></tbody></table></td></tr><tr id="45750150"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45750150" href="https://news.ycombinator.com/vote?id=45750150&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I’ve been migrating our services off of Azure slowly for the past couple of years. The last internet facing things remaining are a static assets bucket and an analytics VM running Matomo. Working with Front Door has been an abysmal experience, and today was the push I needed to finally migrate our assets to Cloudflare.</p><p>I feel pretty justified in my previous decisions to move away from Azure. Using it feels like building on quicksand…</p></div></td></tr></tbody></table></td></tr><tr id="45749410"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749410" href="https://news.ycombinator.com/vote?id=45749410&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I noticed that Starbucks mobile ordering was down and thought “welp, I guess I’ll order a bagel and coffee on Grubhub”, then GrubHub was down. My next stop was HN to find the common denominator, and y’all did not disappoint.</p></div></td></tr></tbody></table></td></tr><tr id="45749715"><td></td></tr><tr id="45749980"><td></td></tr><tr id="45749813"><td></td></tr><tr id="45749639"><td></td></tr><tr id="45749688"><td></td></tr><tr id="45749903"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45749903" href="https://news.ycombinator.com/vote?id=45749903&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>you wouldn't believe some of the crap enterprise bigco mgmt put in place for disaster recovery.</p><p>they think that they are 'eliminating a single point of failure', but in reality, they end up adding multiple, complicated points of mostly failure.</p></div></td></tr></tbody></table></td></tr><tr id="45749680"><td></td></tr><tr id="45749659"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749659" href="https://news.ycombinator.com/vote?id=45749659&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Gonna build my application to be multicloud so that it requires multiple cloud platforms to be online at the same time. The RAID 0 of cloud computing.</p></div></td></tr></tbody></table></td></tr><tr id="45749773"><td></td></tr><tr id="45750148"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45750148" href="https://news.ycombinator.com/vote?id=45750148&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>All of my employers things are hosted on Azure and running just fine and didn't go down at all. Portal access has been fixed.</p><p>Doesn't seem to be too bad of an outage unless you were relying on Azure Front Door.</p></div></td></tr></tbody></table></td></tr><tr id="45749346"><td></td></tr><tr id="45749554"><td></td></tr><tr id="45749814"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749814" href="https://news.ycombinator.com/vote?id=45749814&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>&gt; [Satya Nadella] said that the company’s future opportunity was to bring AI to all eight billion people on the planet.</p><p>But what if I don't want AI brought to me?</p></div></td></tr></tbody></table></td></tr><tr id="45750147"><td></td></tr><tr id="45749924"><td></td></tr><tr id="45749992"><td></td></tr><tr id="45749909"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749909" href="https://news.ycombinator.com/vote?id=45749909&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Like most technology initiative these tech CEOs dream up: You're going to get it and swallow it, whether you want it or not.</p></div></td></tr></tbody></table></td></tr><tr id="45749977"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749977" href="https://news.ycombinator.com/vote?id=45749977&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I especially like how Nadella speaks of layoffs as some kind of uncontrollable natural disaster, like a hurricane, caused by no-one in particular. A kind of "God works in mysterious ways".</p><pre><code>    &gt; “Microsoft is being recognized and rewarded at levels never seen before,” Nadella wrote. “And yet, at the same time, we’ve undergone layoffs. This is the enigma of success in an industry that has no franchise value.”
     
    &gt; Nadella explained the disconnect between thriving financials and layoffs by stating that “progress isn’t linear” and that it is “sometimes dissonant, and always demanding.”
</code></pre><p>
I've read the whole memo and it's actually worse than those excerpts. Nadella doesn't even claim these were low performers:</p><pre><code>    &gt; These decisions are among the most difficult we have to make. They affect people we’ve worked alongside, learned from, and shared countless moments with—our colleagues, teammates, and friends.
</code></pre><p>
Ok, so Microsoft is thriving, these were friends and people "we've learned from", but they must go because... uh... "progress isn't linear". Well, thanks Nadella! That explains so much!</p></div></td></tr></tbody></table></td></tr><tr id="45749820"><td></td></tr><tr id="45749957"><td></td></tr><tr id="45749162"><td></td></tr><tr id="45749765"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749765" href="https://news.ycombinator.com/vote?id=45749765&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>There's a Family Dollar by my house that is down at least 2 full days per month because of bad inet connectivity. I live close enough that with a small tower on my roof i can get line of sight to theirs. I've thought about offering them a backup link off my home inet if they give me 50% of sales whenever its in use. It would be a pretty good deal for them, better some sales when their inet is down vs none.</p></div></td></tr></tbody></table></td></tr><tr id="45749986"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749986" href="https://news.ycombinator.com/vote?id=45749986&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>You'd think any SeriousBusiness would have a backup way to take customers' money. This is the one thing you always want to be able to do: accept payment. If they made it so they can't do that, they deserve the hit to their revenue. People should just walk out of the store with the goods if they're not being charged.</p><p>Why doesn't someone in the store at least have one of those manual kachunk-kachunk carbon copy card readers in the back that they can resuscitate for a few days until the technology is turned back on? Did they throw them all away?</p></div></td></tr></tbody></table></td></tr><tr id="45750073"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45750073" href="https://news.ycombinator.com/vote?id=45750073&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>The kachunk-kachunk credit card machines need raised digits on the cards, and I don't think most banks have been issuing those for years at this point. Mine have been smooth for at least 10 years.</p></div></td></tr></tbody></table></td></tr><tr id="45750027"><td></td></tr><tr id="45749805"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749805" href="https://news.ycombinator.com/vote?id=45749805&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>IIRC, the grocery chain I worked for used to have an offline mode to move customers out the door. But it meant that when the system came back online, if the customers card was denied, the customer got free groceries.</p></div></td></tr></tbody></table></td></tr><tr id="45749516"><td></td></tr><tr id="45749620"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749620" href="https://news.ycombinator.com/vote?id=45749620&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I knew an old guy in the '00s who specialized in cobal/fortran for working on tiller software. Guess he retired and they couldn't maintain it</p></div></td></tr></tbody></table></td></tr><tr id="45749752"><td></td></tr><tr id="45750088"><td></td></tr><tr id="45750057"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45750057" href="https://news.ycombinator.com/vote?id=45750057&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I absolutely love the utility aspect of LLMs but part of me is curious if moving faster by using AI is going to make these sorts of failure more and more often.</p></div></td></tr></tbody></table></td></tr><tr id="45750162"><td></td></tr><tr id="45749961"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749961" href="https://news.ycombinator.com/vote?id=45749961&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>They admit in their update blurb azure front door is having issues but still report azure front door as having no issues on their status page.</p><p>And it's very clear from these updates that they're more focused on the portal than the product, their updates haven't even mentioned fixing it yet, just moving off of it, as if it's some third party service that's down.</p></div></td></tr></tbody></table></td></tr><tr id="45750107"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45750107" href="https://news.ycombinator.com/vote?id=45750107&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>&gt; as having no issues on their status page</p><p>Unsubstantiated idea: So the support contract likely says there is a window between each reporting step and the status page is the last one and the one in the legal documents giving them several more hours before the clauses trigger.</p></div></td></tr></tbody></table></td></tr><tr id="45748903"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45748903" href="https://news.ycombinator.com/vote?id=45748903&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Ouch, and login.microsoftonline.com too - i.e. SSO using MS accounts. We'd just rolled that out across most (all?) of our internal systems...</p><p>And microsoft.com too - that's gotta hurt</p></div></td></tr></tbody></table></td></tr><tr id="45749902"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749902" href="https://news.ycombinator.com/vote?id=45749902&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>It is interesting to see the differential across different tenants in different geographies:</p><p>- on a US tenant I am unable to access login.microsoftonline.com and the login flow stalls on any SSO authentication attempt.</p><p>- on a European tenant, probably germany-west, I am able to login and access the Azure portal.</p></div></td></tr></tbody></table></td></tr><tr id="45749907"><td></td></tr><tr id="45749507"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749507" href="https://news.ycombinator.com/vote?id=45749507&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>SSO and 365 are working fine for us, but admin portals for Azure/365 are down. Our workloads in Azure don't seem to be impacted.</p></div></td></tr></tbody></table></td></tr><tr id="45749484"><td></td></tr><tr id="45749727"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749727" href="https://news.ycombinator.com/vote?id=45749727&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>We are very dependent on Azure and Microsoft Authentication and Microsoft 365 and haven’t had weekly or even monthly issues. I can think of maybe three issues this year.</p></div></td></tr></tbody></table></td></tr><tr id="45749468"><td></td></tr><tr id="45749906"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749906" href="https://news.ycombinator.com/vote?id=45749906&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>This is because Azure just copies everything AWS does. Google is a bit more innovative, they will have something else unexpected happen.</p></div></td></tr></tbody></table></td></tr><tr id="45750118"><td></td></tr><tr id="45749678"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749678" href="https://news.ycombinator.com/vote?id=45749678&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Maybe they are and no one realized yet.. :P</p><p>That said, I don't hear about GCP outages all that often. I do think AWS might be leading in outages, but that's a gut feeling, I didn't look up numbers.</p></div></td></tr></tbody></table></td></tr><tr id="45750070"><td></td></tr><tr id="45749885"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749885" href="https://news.ycombinator.com/vote?id=45749885&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>fairly certain they had a significant multi region outage within the past few years. I'll try to find some details to link.</p><p>Few customers....few voices to complain as well.</p></div></td></tr></tbody></table></td></tr><tr id="45749967"><td></td></tr><tr id="45749818"><td></td></tr><tr id="45749536"><td></td></tr><tr id="45749691"><td></td></tr><tr id="45749553"><td></td></tr><tr id="45750014"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45750014" href="https://news.ycombinator.com/vote?id=45750014&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>pretty interesting how datadog's uptime tracker (<a href="https://updog.ai/" rel="nofollow">https://updog.ai/</a>) says all the sites are fully available.</p><p>if that's true then it's a sign that Azure's control / data plane separation is doing it's job! at least for now</p></div></td></tr></tbody></table></td></tr><tr id="45749237"><td></td></tr><tr id="45749738"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749738" href="https://news.ycombinator.com/vote?id=45749738&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I've been doing it since 1998 in my bedroom with a dual T1 (and on to real DCs later). While I've had some outages for sure it makes me feel better I am not that divergent in uptime in the long run vs big clouds.</p></div></td></tr></tbody></table></td></tr><tr id="45749988"><td></td></tr><tr id="45749477"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749477" href="https://news.ycombinator.com/vote?id=45749477&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Pretty much all Azure services seem to be down. Their status page says it's only the portal since 16:00. It would be nice if these mega-companies could update their status page when they take down a large fraction of the Internet and thousands of services that use them.</p></div></td></tr></tbody></table></td></tr><tr id="45749505"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749505" href="https://news.ycombinator.com/vote?id=45749505&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>FWIW, all of our databases, VMs, AKS clusters, services, jobs etc - are all working fine. Which services are down for you, maybe we can build a list?</p></div></td></tr></tbody></table></td></tr><tr id="45749567"><td></td></tr><tr id="45749621"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749621" href="https://news.ycombinator.com/vote?id=45749621&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>All of our Azure workloads are up, but we don't use Azure Front Door. That seems to be the only impacted product, apart from the management portal.</p></div></td></tr></tbody></table></td></tr><tr id="45749993"><td></td></tr><tr id="45749913"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749913" href="https://news.ycombinator.com/vote?id=45749913&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Same playbook for AWS. When they admitted that Dynamo was inaccessible, they failed to provide context that their internal services are heavily dependent on Dynamo</p><p>It's only after the fact they are transparent about the impact</p></div></td></tr></tbody></table></td></tr><tr id="45749481"><td></td></tr><tr id="45749627"><td></td></tr><tr id="45749881"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749881" href="https://news.ycombinator.com/vote?id=45749881&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>LinkedIn has been acting funny for an hour or so, and some pages in the learn.microsoft.com domain have been failing for me too...</p></div></td></tr></tbody></table></td></tr><tr id="45749082"><td></td></tr><tr id="45749888"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749888" href="https://news.ycombinator.com/vote?id=45749888&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>&gt; Even the national digital id service is down.</p><p>Can't help but smirk as my country is ramming through "Digital ID" right now</p></div></td></tr></tbody></table></td></tr><tr id="45749875"><td></td></tr><tr id="45749736"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749736" href="https://news.ycombinator.com/vote?id=45749736&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Does (should, could) DownDetector also say what customer-facing services are down, when some infrastructure is unworking?  Or is that the info that the malefactors are seeking?</p></div></td></tr></tbody></table></td></tr><tr id="45749413"><td></td></tr><tr id="45749438"><td></td></tr><tr id="45749612"><td></td></tr><tr id="45749721"><td></td></tr><tr id="45749449"><td></td></tr><tr id="45749204"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749204" href="https://news.ycombinator.com/vote?id=45749204&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>i guess folks in azure wanted to show some solidarity with aws brethren</p><p>(couldn't resist adding it. i acknowledge this comment adds no value to the discussion)</p></div></td></tr></tbody></table></td></tr><tr id="45749613"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749613" href="https://news.ycombinator.com/vote?id=45749613&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Azure goes down all the time. On Friday we had an entire regional service down all day. Two weeks ago same thing different region. You only hear about it when it's something everyone uses like the portal, because in general nobody uses Azure unless they're held hostage.</p></div></td></tr></tbody></table></td></tr><tr id="45749672"><td></td></tr><tr id="45748863"><td></td></tr><tr id="45749701"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749701" href="https://news.ycombinator.com/vote?id=45749701&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>It is much more than azure. One of my kids needs a key for their laptop and can't reach that either. Great excuse though, 'Azure ate my homework'. What a ridiculous world we are building. Fuck MS and their account requirements for windows.</p></div></td></tr></tbody></table></td></tr><tr id="45749922"><td></td></tr><tr id="45749769"><td></td></tr><tr id="45749835"><td></td></tr><tr id="45749411"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749411" href="https://news.ycombinator.com/vote?id=45749411&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I am having a bunch of issues. It looks like their sites and azure are both affected.</p><p>I also got weird notification in VS2022 that my license key was upgraded to Enterprise, but we did not purchase anything.</p></div></td></tr></tbody></table></td></tr><tr id="45749648"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749648" href="https://news.ycombinator.com/vote?id=45749648&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Might be a failsafe, if you cant get a license status, and you're aware that MS is down, just default to the highest tier.</p></div></td></tr></tbody></table></td></tr><tr id="45749524"><td></td></tr><tr id="45748826"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45748826" href="https://news.ycombinator.com/vote?id=45748826&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>This is impacting the Azure CDN at azureedge.net. DNS A records for azureedge.net tenants are taking 2-6 seconds and often return nothing.</p></div></td></tr></tbody></table></td></tr><tr id="45749205"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749205" href="https://news.ycombinator.com/vote?id=45749205&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Quite close to the recent AWS outage. Let me take a look if its a major one similar to AWS.</p><p>Any guess on what's causing it?</p><p>In hindsight, I guess the foresight of some organizations to go multi-cloud was correct after all.</p></div></td></tr></tbody></table></td></tr><tr id="45749784"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749784" href="https://news.ycombinator.com/vote?id=45749784&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>We're multi-cloud and it really saved a few workloads last week with the AWS issue.</p><p>It's not easy though.</p></div></td></tr></tbody></table></td></tr><tr id="45749302"><td></td></tr><tr id="45749493"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45749493" href="https://news.ycombinator.com/vote?id=45749493&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Yeah, these things never happened when humans were trusted without sufficient review and oversight of changes to production.</p></div></td></tr></tbody></table></td></tr><tr id="45749386"><td></td></tr><tr id="45749434"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45749434" href="https://news.ycombinator.com/vote?id=45749434&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>I don't think it's meant to be serious. It's a comment on Microsoft laying off their staff and stuffing their Azure and Dotnet teams with AI product managers.</p></div></td></tr></tbody></table></td></tr><tr id="45749472"><td></td></tr><tr id="45749228"><td></td></tr><tr id="45749053"><td></td></tr><tr id="45749070"><td></td></tr><tr id="45749846"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749846" href="https://news.ycombinator.com/vote?id=45749846&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Anyone have betting odds on when Google will go down next? Are we looking at all 3 providers having outages in the span of 3 weeks?</p></div></td></tr></tbody></table></td></tr><tr id="45749500"><td></td></tr><tr id="45749768"><td></td></tr><tr id="45749018"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749018" href="https://news.ycombinator.com/vote?id=45749018&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Azure portal currently mostly not working (UK)... Downdetector reporting various Microsoft linked services are out (Minecraft, Microsoft 365, Xbox...)</p></div></td></tr></tbody></table></td></tr><tr id="45749512"><td></td></tr><tr id="45749186"><td></td></tr><tr id="45749266"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749266" href="https://news.ycombinator.com/vote?id=45749266&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>Yeah, I have non prod environments that don't use FD that are functioning. Routing through FD does not work. And a different app, nonprod doesn't use FD (and is working) but loads assets from the CDN (which is not working).</p><p>FD and CDN are global resources and are experiencing issues. Probably some other global resources as well.</p><p>Hate to say it, but DNS is looking like it's still the undisputed champ.</p></div></td></tr></tbody></table></td></tr><tr id="45749215"><td></td></tr><tr id="45749369"><td></td></tr><tr id="45749571"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749571" href="https://news.ycombinator.com/vote?id=45749571&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>microsoft.com is back -</p><p>edit: it worked once, then died again. So I guess - some resolvers, or FD servers may be working!</p></div></td></tr></tbody></table></td></tr><tr id="45748991"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45748991" href="https://news.ycombinator.com/vote?id=45748991&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>downdetector reports coincident cloudflare outage. is microsoft using cloudflare for management plane, or is there common infra? data center problem somewhere, maybe fiber backbone? BGP?</p></div></td></tr></tbody></table></td></tr><tr id="45749742"><td></td></tr><tr id="45749048"><td></td></tr><tr id="45749390"><td></td></tr><tr id="45749406"><td></td></tr><tr id="45749351"><td></td></tr><tr id="45749395"><td></td></tr><tr id="45749921"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45749921" href="https://news.ycombinator.com/vote?id=45749921&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>You just paste the outage error codes back to the LLM and pray it's still working and can fix whatever went wrong!</p></div></td></tr></tbody></table></td></tr><tr id="45750109"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45750109" href="https://news.ycombinator.com/vote?id=45750109&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>When all the people forget to code for themselves, every LLM will code itself out of existence with that one last bug. One, after another.</p></div></td></tr></tbody></table></td></tr><tr id="45749713"><td></td></tr><tr id="45749037"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45749037" href="https://news.ycombinator.com/vote?id=45749037&amp;how=up&amp;goto=item%3Fid%3D45748799"></a></center></td><td><br>
<div><p>My best guess at the moment is something global like the CDN is having problems affecting things everywhere. I'm able to use a legacy application we have that goes directly to resources in uswest3, but I'm not able to use our more modern application which uses APIM/CDN networks at all.</p></div></td></tr></tbody></table></td></tr><tr id="45749158"><td></td></tr><tr id="45749474"><td></td></tr><tr id="45748888"><td></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The end of the rip-off economy: consumers use LLMs against information asymmetry (126 pts)]]></title>
            <link>https://www.economist.com/finance-and-economics/2025/10/27/the-end-of-the-rip-off-economy</link>
            <guid>45748195</guid>
            <pubDate>Wed, 29 Oct 2025 15:32:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/finance-and-economics/2025/10/27/the-end-of-the-rip-off-economy">https://www.economist.com/finance-and-economics/2025/10/27/the-end-of-the-rip-off-economy</a>, See on <a href="https://news.ycombinator.com/item?id=45748195">Hacker News</a></p>
Couldn't get https://www.economist.com/finance-and-economics/2025/10/27/the-end-of-the-rip-off-economy: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[I made a 10¢ MCU Talk (102 pts)]]></title>
            <link>https://www.atomic14.com/2025/10/29/CH32V003-talking</link>
            <guid>45747112</guid>
            <pubDate>Wed, 29 Oct 2025 14:12:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.atomic14.com/2025/10/29/CH32V003-talking">https://www.atomic14.com/2025/10/29/CH32V003-talking</a>, See on <a href="https://news.ycombinator.com/item?id=45747112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
      <article>
        
        <section>
          
          <p><span></span> read
          </p>
          <a name="topofpage"></a>
          
          




          
          <div>
            <p><small>
                HELP <a href="https://www.atomic14.com/support/index.html">SUPPORT</a> MY WORK: If you're feeling flush then please stop by <a href="https://www.patreon.com/atomic14">Patreon</a> Or you can make a one off donation via <a href="https://ko-fi.com/atomic14">ko-fi</a>
              </small>
            </p>
            
            
            <div data-pagefind-body="">
            
            <blockquote>
  <p>TLDR: Yes, you can fit about 7 seconds of audio into 16K of flash and still have room for code. And you can even play LPC encoded audio on a 10 cent MCU.</p>
</blockquote>

<p>There’s quite a lot more detail in this video (and of course you can hear the audio!).</p>

<lite-youtube videoid="RZvX95aXSdM" playlabel="Talking 10 Cent MCU"></lite-youtube>

<p>In the <a href="https://www.atomic14.com/2025/10/12/CH32V003-music">previous project</a>, I had this ultra-cheap CH32V003 microcontroller playing simple tunes on a tiny SMD buzzer. It was just toggling a GPIO pin at musical note frequencies – 1-bit audio output – and it sounded surprisingly decent. That was a fun start, but now it’s time to push this little $0.10 MCU even further: can we make it actually talk?</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/ic.webp" alt="CH32V003"></p>

<p>Spoiler: Yes, we can! (well, there wouldn’t be much of a blog post if we couldn’t) This 8-pin RISC-V chip is now producing sampled audio data and spoken words. We’re really stretching the limits of what you can fit in 16 KB of flash.</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/16k.webp" alt="16K Flash, 2K RAM"></p>

<h2 id="from-beeps-to-actual-audio">From Beeps to Actual Audio</h2>

<p>Moving from simple beeps to real audio meant using the microcontroller’s PWM output as a rudimentary DAC. Instead of just on/off beeping, I’m driving a waveform at an 8 kHz sample rate using a high-frequency PWM on the output pin. The hardware is the same tiny board as before
 – but I’ve swapped the small SMD buzzer for a small speaker. The buzer works too, but it’s quieter and very tinny.</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/speaker.webp" alt="New Speaker"></p>

<p>The sample I wanted to test with is just over 6 seconds in length - it’s the iconic “Open the pod bay doors HAL…” sequence from 2001.</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/pod-bay-doors.webp" alt="Open the pod bay doors"></p>

<p>If we keep this audio at 16-bit PCM, 8kHZ, we’d need about 96KB – way beyond our 16 KB flash! And remember, that 16 KB has to hold both the audio data and our playback code. Clearly some aggressive compression is required.</p>

<table>
  <thead>
    <tr>
      <th>Format</th>
      <th>Sample Rate</th>
      <th>Bits/Sample</th>
      <th>Size</th>
      <th><strong>Fits in 16KB?</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CD Quality</td>
      <td>44.1 kHz</td>
      <td>16-bit</td>
      <td>529 KB</td>
      <td>❌ 33× too big!</td>
    </tr>
    <tr>
      <td>Phone Quality</td>
      <td>16 kHz</td>
      <td>16-bit</td>
      <td>192 KB</td>
      <td>❌ 12× too big!</td>
    </tr>
    <tr>
      <td>Basic PCM</td>
      <td>8 kHz</td>
      <td>8-bit</td>
      <td>48 KB</td>
      <td>❌ 3× too big!</td>
    </tr>
    <tr>
      <td><strong>4-bit ADPCM (IMA)</strong></td>
      <td><strong>8 kHz</strong></td>
      <td><strong>4-bit</strong></td>
      <td><strong>24 KB</strong></td>
      <td>❌ <strong>1.5× too big</strong></td>
    </tr>
    <tr>
      <td><strong>QOA (Quite OK Audio)</strong></td>
      <td><strong>8 kHz</strong></td>
      <td><strong>3.2-bit</strong></td>
      <td><strong>19 KB</strong></td>
      <td>❌ <strong>Still too big!</strong></td>
    </tr>
    <tr>
      <td><strong>2-bit ADPCM</strong></td>
      <td><strong>8 kHz</strong></td>
      <td><strong>2-bit</strong></td>
      <td><strong>12 KB</strong></td>
      <td>✅ <strong>Fits!</strong></td>
    </tr>
  </tbody>
</table>

<p>I considered a few encoding options for compressing the audio.</p>

<ul>
  <li><strong>8-bit PCM:</strong> Simply using 8-bit samples at 8 kHz cuts size in half (to ~47 KB for 6s), but that’s still about 3× too large for our flash.</li>
  <li><strong>4-bit ADPCM:</strong> Adaptive Differential PCM is a simple lossy compression that could quarter the size. In theory 6 seconds would be ~24 KB – much closer to fitting,</li>
  <li><strong><a href="https://qoaformat.org/">“Quite OK Audio” (QOA)</a>:</strong> This is nice codec that packs audio into about 3.2 bits per sample (roughly 1/5 the size of 16-bit PCM)</li>
  <li><strong>2-bit ADPCM:</strong> Going even further with ADPCM, using only 2 bits per sample gives a 4:1 compression relative to 8-bit audio – that’s 75% storage savings.</li>
</ul>

<p>2-bit ADPCM is definitely the winner here. Our 6-second clip shrinks to under 12 KB, which comfortably fits in flash with room for code. This looked like the winner, provided the audio quality was acceptable. The decoder for 2-bit ADPCM is also very lightweight (my implementation compiled to under just over 1K of code - 1340 bytes!). It’s definitely low quality - but it actually sounds surprisingly ok.</p>

<h2 id="how-does-2-bit-adpcm-work">How does 2-bit ADPCM work?</h2>

<p>It’s actually a very simple algorithm. Both the encoder and decoder maintain a predicted signal value and a step size index into a predefined table. Each 2-bit code tells the decoder how to adjust the current prediction and the step size index. In essence, we’re coding the difference between the real audio and our prediction, with only four possible levels (since 2 bits gives 4 values). After each sample, the algorithm adapts: if the prediction error was large, we move to a bigger step size (to allow larger changes); if the error was small, we use a smaller step size for finer resolution. This adaptive step is what makes it ADPCM (Adaptive Differential PCM).</p>

<p>Our codes are as follows:</p>

<ul>
  <li><code>00</code> (0): Go down by 1 step - subtract the step size from our current prediction</li>
  <li><code>01</code> (1): Go up by 1 step - add the step size to our current prediction</li>
  <li><code>10</code> (2): Go down by 2 steps - subtract the 2 x step size from our current prediction</li>
  <li><code>11</code> (3): Go up by 2 steps - add the 2 x step size to our current prediction</li>
</ul>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/audio.webp" alt="2-bit ADPCM Compression"></p>

<p>Even with this very high level of compression, the predicted waveform manages to track the original audio surprisingly well. The above graph shows a small snippet of the audio: the blue line is the original waveform and the yellow line is the ADPCM decoder’s output.</p>

<p>They’re not identical (and we wouldn’t expect them to be), but the general shape is preserved. When you play it back through the little speaker, it’s recognizable and surprisingly good.</p>

<p>To make my life easier, I built a quick conversion <a href="https://buzzer-studio.atomic14.com/">tool</a> to encode WAV files into this 2-bit ADPCM format. The tool lets me drag-and-drop a WAV, and it gives you the files with the data that can ve dropped into the firmware code.</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/buzzer-2-adpcm.webp" alt="2-bit ADPCM Buzzer Studio"></p>

<h2 id="lpc-speech-synthesis">LPC Speech Synthesis</h2>

<p>Six seconds of audio is cool, but what about longer phrases or even arbitrary speech? Storing anything much longer with raw or ADPCM audio would quickly fill the 16K of flash.</p>

<p>For my second experiment, I tried something different: instead of recorded waveform audio, I used an <a href="https://en.wikipedia.org/wiki/Texas_Instruments_LPC_Speech_Chips">old-school speech synthesis approach</a>. This leverages the fact that spoken language can be encoded very compactly by modeling the human voice, rather than storing the raw sound. Specifically, I integrated a library called <a href="https://github.com/going-digital/Talkie/tree/master/Talkie">Talkie</a>.</p>

<p>Talkie is a software implementation of the Texas Instruments LPC speech synthesis architecture from the late 1970s. This was implemented in a variety of chips, most commonly the TMS5220 and TMS5100 speech chips.</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/TMS_types.webp" alt="TMS5220 and TMS5100 Variants"></p>

<p>These were used in things like the original Speak &amp; Spell, arcade games like early Star Wars, and speech add-ons for home computers (e.g. the BBC Micro).</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/speak-spell.webp" alt="Speak and Spell"></p>

<p>The Talkie library (originally by <a href="https://github.com/going-digital/Talkie/tree/master/Talkie">Peter Knight</a>, later added to by <a href="https://learn.adafruit.com/bringing-back-the-voice-of-speak-spell/software">Adafruit</a>) comes with a big set of examples and vocabulary. It’s also possible to extract examples from old ROMs from arcade games.</p>

<p>Each phrase or word only takes a few hundred bytes or even less, so you can fit quite a lot of speech into a few kilobytes of flash. The trade-off is that the voice has a very computer-esque timbre – think of the Speak &amp; Spell’s voice. It’s clearly synthetic, but still understandable.</p>

<p>To say custom sentences not in the library, you either concatenate the available words/phonemes (which can be clunky), or you need to generate new LPC data. The original tools for this are a bit obscure – there’s BlueWizard (a classic Mac app) and PythonWizard (a command-line tool with TK GUI) which can analyze WAV files and produce LPC data.</p>

<p>I gave both a try with some success (and a few headaches setting them up). In the end, I cheated a bit and used an AI coding assistant to help me create a streamlined online tool for this.</p>

<p>The result is a little <a href="http://buzzer-studio.atomic14.com/">web app</a> where I can upload a recording of, say, my own voice, and it outputs the LPC data. It even lets me play back the synthesized voice in-browser to check it.</p>

<p><img src="https://www.atomic14.com/assets/article_images/2025-11-01/buzzer-lpc.webp" alt="LPC Encoder"></p>

<p>So there we have it – our 10¢ microcontroller now has a voice! By using 2-bit ADPCM compression, we can store short audio clips (up to around 8 seconds) even in 16 KB of flash, and play them back via PWM with decent fidelity.</p>

<p>And with the Talkie LPC speech synthesis, we can make the device “speak” lots of words and phrases with only a tiny memory footprint.</p>

<p>If you want to hear it for yourself, check out the video demo linked at the top of this post. In the video, you’ll see (and hear) the WarGames clip and the Star Wars quotes running on the hardware. It’s honestly amazing what these cheap little MCUs can do. We’re really pushing the boundaries of cheap hardware here.</p>

<p>You can find all my code on GitHub in this <a href="https://github.com/atomic14/ch32v003-audio">repository</a>.</p>

<lite-youtube videoid="RZvX95aXSdM" playlabel="Talking 10 Cent MCU"></lite-youtube>

            </div>
            
            
            
              <h2>Related Posts</h2>
                              
                
                <a href="https://www.atomic14.com/2025/10/12/CH32V003-music.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/2024/01/05/esp32-s3-no-pins.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/2024/01/26/16bit-handheld-teardown.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/2023/09/26/decoding-avi-files-for-fun-and-0-profit.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/2022/08/19/a-life-in-tech-part1.html">
                
                </a>
              
            
            
              <h2>Related Videos</h2>
                              
                
                <a href="https://www.atomic14.com/videos/posts/RZvX95aXSdM.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/videos/posts/RiiS4jjG6ME.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/videos/posts/LhZ9pWwnn6s.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/videos/posts/oZ39VCUvKjw.html">
                
                </a>
                              
                
                <a href="https://www.atomic14.com/videos/posts/G6MROvlLeKE.html">
                
                </a>
              
            
            <p><small>
                HELP <a href="https://www.atomic14.com/support/index.html">SUPPORT</a> MY WORK: If you're feeling flush then please stop by <a href="https://www.patreon.com/atomic14">Patreon</a> Or you can make a one off donation via <a href="https://ko-fi.com/atomic14">ko-fi</a>
              </small>
            </p>
          </div>
          
        </section>
        
        <div>
          <div>
            <h5><span>Written by</span></h5>
            <section>
              
              <h4>Chris Greening</h4>
              
              <hr>
              <p>Published <time datetime="2025-10-29 00:00">29 Oct 2025</time></p>
            </section>
          </div>
          
          <div>
            <h5><span>Supported by</span></h5>
            
          </div>
        </div>
      </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kafka is Fast – I'll use Postgres (175 pts)]]></title>
            <link>https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks</link>
            <guid>45747018</guid>
            <pubDate>Wed, 29 Oct 2025 14:06:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks">https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks</a>, See on <a href="https://news.ycombinator.com/item?id=45747018">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2 id="intro">Intro</h2>
<p>I feel like the tech world lives in two camps.</p>
<ol>
<li>One camp chases buzzwords.</li>
</ol>
<p>This camp tends to adopt whatever’s popular without thinking hard about whether it’s appropriate. They tend to fall for all the purported benefits the sales pitch gives them - real-time, infinitely scale, cutting-edge, cloud-native, serverless, zero-trust, AI-powered, etc.</p>
<p>You see this everywhere in the Kafka world: Streaming Lakehouse™️, Kappa™️ Architecture, Streaming AI Agents<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<p>This phenomenon is sometimes known as <em>resume-driven design</em>. Modern practices actively encourage this. Consultants push “innovative architectures” stuffed with vendor tech via “insight” reports<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>. System design interviews expect you to design Google-scale architectures that are inevitably at a scale 100x higher than the company you’re interviewing for would ever need. Career progression rewards you for replatforming to the Hot New Stack™️, not for being resourceful.</p>
<ol start="2">
<li>The other camp chases common sense</li>
</ol>
<p>This camp is far more pragmatic. They strip away unnecessary complexity and steer clear of overengineered solutions. They reason from first principles before making technology choices. They resist marketing hype and approach vendor claims with healthy skepticism.</p>
<p>Historically, it has felt like Camp 1 definitively held the upper hand in sheer numbers and noise. Today, it feels like the pendulum may be beginning to swing back, at least a tiny bit. Two recent trends are on the side of Camp 2:</p>
<p>Trend 1 - the “<a href="https://topicpartition.io/Small-Data" data-slug="Small-Data">Small Data</a>” movement. People are realizing two things - their data isn’t that big and their computers are becoming big too. You can rent a <a href="https://instances.vantage.sh/aws/ec2/x1e.xlarge">128-core, 4 TB of RAM instance</a> from AWS. AMD just released 192-core CPUs this summer. That ought to be enough for anybody.<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
<p>Trend 2 - the Postgres Renaissance. The space is seeing incredible growth and investment<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup>. In the last 2 years, the phrase <a href="https://github.com/Olshansk/postgres_for_everything">“Just Use Postgres (for everything)”</a> has gained a ton of popularity. The basic premise is that you shouldn’t complicate things with new tech when you don’t need to, and that Postgres alone solves most problems pretty well. Postgres competes with purpose-built solutions like:</p>
<ul>
<li>Elasticsearch (functionality supported by Postgres’ <code>tsvector</code>/<code>tsquery</code>)</li>
<li>MongoDB (<code>jsonb</code>)</li>
<li>Redis (<code>CREATE UNLOGGED TABLE</code>)</li>
<li>AI Vector Databases (<code>pgvector</code>, <code>pgai</code>)</li>
<li>Snowflake (<code>pg_mooncake</code>, <code>pg_duckdb</code>)</li>
</ul>
<p>and… Kafka (this blog).</p>
<p>The claim isn’t that Postgres is functionally equivalent to any of these specialized systems. The claim is that it handles 80%+ of their use cases with 20% of the development effort. (Pareto Principle)</p>
<p>When you combine the two trends, the appeal becomes obvious. Postgres is a battle-tested, well-known system that is simple, scalable and reliable. Pair it with today’s powerful hardware and you quickly begin to realize that, more often than not, you do not need the state-of-the-art highly optimized and complex distributed system in order to handle your organization’s scale.</p>
<p><a href="https://bento.me/stanislavkozlovski">Despite being somebody who is biased towards Kafka</a>, I tend to agree. Kafka is similar to Postgres in that it’s stable, mature, battle-tested and boasts a strong community. It also scales a lot further. Despite that, I don’t think it’s the right choice for a lot of cases. Very often I see it get adopted where <a href="https://www.reddit.com/r/apachekafka/comments/1o7gbyg/controlling_llm_outputs_with_kafka_schema/">it doesn’t make sense</a>.</p>
<p><strong>A 500 KB/s workload should not use Kafka.</strong> There is a scalability cargo cult in tech that always wants to choose “the best possible” tech for a problem - but this misses the forest for the trees. The “best possible” solution frequently isn’t a technical question - it’s a practical one. Adriano makes an airtight case for why you should opt for <strong>simple tech</strong> in his <a href="https://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology">PG as Queue blog</a> (2023) that originally inspired me to write this.</p>
<p>Enough background. In this article, we will do three simple things:</p>
<ol>
<li>Benchmark how far Postgres can scale for pub/sub messaging - <a href="#pg-as-a-pubsub"># PG as a Pub/Sub</a></li>
<li>Benchmark how far Postgres can scale for queueing - <a href="#pg-as-a-queue"># PG as a Queue</a></li>
<li>Concisely touch upon when Postgres can be a fit for these use cases - <a href="#should-you-use-postgres"># Should You Use Postgres?</a></li>
</ol>
<p>I am not aiming for an exhaustive in-depth evaluation. Benchmarks are messy af. Rather, my goal is to publish some reasonable data points which can start a discussion.</p>
<p><em>(while this article is for Postgres, feel free to replace it with your database of choice)</em></p>
<hr>
<h2 id="results-tldr">Results TL;DR</h2>
<p>If you’d like to skip straight to the results, here they are:</p>
<details>
  <summary>🔥 The Benchmark Results</summary>
<h3 id="pub-sub-results">Pub-Sub Results</h3>

































<div><table><thead><tr><th>Setup</th><th>✍️ <strong>Write</strong></th><th>📖 <strong>Read</strong></th><th>🔭 <strong>e2e Latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup> (p99)</strong></th><th>Notes</th></tr></thead><tbody><tr><td><strong>1× c7i.xlarge</strong></td><td><strong>4.8 MiB/s<br>5036 msg/s</strong></td><td><strong>24.6 MiB/s<br>25 183 msg/s</strong> (5x fanout)</td><td><strong>60 ms</strong></td><td>~60 % CPU; 4 partitions</td></tr><tr><td><strong>3× c7i.xlarge (replicated)</strong></td><td><strong>4.9 MiB/s<br>5015 msg/s</strong></td><td><strong>24.5 MiB/s<br>25 073 msg/s</strong> (5x fanout)</td><td><strong>186 ms</strong></td><td>~65 % CPU; cross-AZ RF≈2.5; 4 partitions</td></tr><tr><td><strong>1× c7i.24xlarge</strong></td><td><strong>238 MiB/s<br>243,000 msg/s</strong></td><td><strong>1.16 GiB/s<br>1,200,000 msg/s</strong> (5x fanout)</td><td><strong>853 ms</strong></td><td>~10 % CPU (idle); 30 partitions</td></tr></tbody></table></div>
<h3 id="queue-results">Queue Results</h3>





























<div><table><thead><tr><th>Setup</th><th>📬 <strong>Throughput (read + write)</strong></th><th>🔭 <strong>e2e Latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-2" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup> (p99)</strong></th><th>Notes</th></tr></thead><tbody><tr><td><strong>1× c7i.xlarge</strong></td><td><strong>2.81 MiB/s<br>2885 msg/s</strong></td><td><strong>17.7 ms</strong></td><td>~60 % CPU; read-client bottleneck</td></tr><tr><td><strong>3× c7i.xlarge (replicated)</strong></td><td><strong>2.34 MiB/s<br>2397 msg/s</strong></td><td><strong>920 ms ⚠️<sup><a href="#user-content-fn-19" id="user-content-fnref-19" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup></strong></td><td>replication lag inflated E2E latency</td></tr><tr><td><strong>1× c7i.24xlarge</strong></td><td><strong>19.7 MiB/s<br>20,144 msg/s</strong></td><td><strong>930 ms ⚠️<sup><a href="#user-content-fn-19" id="user-content-fnref-19-2" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup></strong></td><td>~50 % CPU; single-table bottleneck</td></tr></tbody></table></div>
<p>Make sure to at least read the last section of the article where we philosophize - <a href="#should-you-use-postgres"># Should You Use Postgres?</a></p>
</details>
<hr>
<h2 id="pg-as-a-pubsub">PG as a Pub/Sub</h2>
<p>There are dozens of blogs out there using Postgres as a <u>queue</u>, but interestingly enough I haven’t seen one use it as a pub-sub messaging system.</p>
<p>A quick distinction between the two because I often see them get confused:</p>
<ol>
<li>
<p><strong>Queues</strong> are meant for point-to-point communication. They’re widely used for asynchronous background jobs: worker apps (clients) process a task in the queue like sending an e-mail or pushing a notification. The event is consumed once and it’s done with. A message is immediately deleted (popped) off the queue once it’s consumed. Queues do not have strict ordering guarantees<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup>.</p>
</li>
<li>
<p><strong>Pub-sub</strong> messaging differs from the queue in that it is meant for one-to-many communication. This inherently means there is a large read fanout - more than one reader client is interested in any given message. Good pub-sub systems decouple readers from writers by storing data on disks. This allows them to not impose a max queue depth limit - something in-memory queues need to do in order to prevent them from going OOM.</p>
<p>There is also a general expectation that there is strict order - events should be read in the same order that they arrived in the system.</p>
</li>
</ol>
<p>Postgres’ main competitor here is Kafka, which is the standard in pub-sub today. Various (mostly-proprietary) alternatives exist.<sup><a href="#user-content-fn-13" id="user-content-fnref-13" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup></p>
<p>Kafka uses the Log data structure to hold messages. You’ll see my benchmark basically reconstructs a log from Postgres primitives.</p>
<p>Postgres doesn’t seem to have any popular libraries for pub-sub<sup><a href="#user-content-fn-27" id="user-content-fnref-27" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup> use cases, so I had to write my own. The Kafka-inspired workflow I opted for is this:</p>
<ol>
<li>Writers produce batches of messages per statement<sup><a href="#user-content-fn-20" id="user-content-fnref-20" data-footnote-ref="" aria-describedby="footnote-label">10</a></sup> (<code>INSERT INTO</code>). Each transaction carries one batch insert and targets a single <code>topicpartition</code> table<sup><a href="#user-content-fn-14" id="user-content-fnref-14" data-footnote-ref="" aria-describedby="footnote-label">11</a></sup></li>
<li>Each writer is sticky to one table, but in aggregate they produce to multiple tables.</li>
<li>Each message has a unique monotonically-increasing offset number. A specific row in a special <code>log_counter</code> table denotes the latest offset for a given <code>topicpartition</code> table.</li>
<li>Write transactions atomically update both the <code>topicpartition</code> data and the <code>log_counter</code> row. This ensures consistent offset tracking across concurrent writers.</li>
<li>Readers poll for new messages. They consume the <code>topicpartition</code> table(s) sequentially, starting from the lowest offset and progressively reading up.</li>
<li>Readers are split into consumer groups. Each group performs separate, independent reads and makes progress on the <code>topicpartition</code> tables.</li>
<li>Each group contains 1 reader per <code>topicpartition</code> table.</li>
<li>Readers store their progress in a <code>consumer_offsets</code> table, with a row for each <code>topicpartition,group</code> pair.</li>
<li>Each reader updates the latest processed offset (claiming the records), selects the records and processes them inside a single transaction.</li>
</ol>
<p>This ensures Kafka-like semantics - gapless, monotonically-increasing offsets and at-least-once/at-most-once processing. This test in particular uses at-least-once semantics, but neither choice should impact the benchmark results.</p>
<h2 id="pub-sub-setup">Pub-Sub Setup</h2>
<h4 id="table">Table</h4>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>CREATE</span><span> TABLE</span><span> log_counter</span><span> (</span></span>
<span data-line=""><span>  id           </span><span>INT</span><span> PRIMARY KEY</span><span>, </span><span>-- topicpartition table name id</span></span>
<span data-line=""><span>  next_offset  </span><span>BIGINT</span><span> NOT NULL</span><span>  -- next offset to assign</span></span>
<span data-line=""><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>for</span><span> i </span><span>in</span><span> NUM_PARTITIONS:</span></span>
<span data-line=""><span>  CREATE</span><span> TABLE</span><span> topicpartition</span><span>%d (</span></span>
<span data-line=""><span>    id          </span><span>BIGSERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span data-line=""><span>    -- strictly increasing offset (indexed by UNIQUE)</span></span>
<span data-line=""><span>    c_offset    </span><span>BIGINT</span><span> UNIQUE</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>    payload     </span><span>BYTEA</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>    created_at  </span><span>TIMESTAMPTZ</span><span> NOT NULL</span><span> DEFAULT</span><span> now</span><span>()</span></span>
<span data-line=""><span>  );</span></span>
<span data-line=""><span>  INSERT INTO</span><span> log_counter(id, next_offset) </span><span>VALUES</span><span> (%d, </span><span>1</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>CREATE</span><span> TABLE</span><span> consumer_offsets</span><span> (</span></span>
<span data-line=""><span>  group_id     </span><span>TEXT</span><span> NOT NULL</span><span>,     </span><span>-- consumer group identifier</span></span>
<span data-line=""><span>  -- topic-partition id (matches log_counter.id / topicpartitionN)</span></span>
<span data-line=""><span>  topic_id     </span><span>INT</span><span>  NOT NULL</span><span>,</span></span>
<span data-line=""><span>  -- next offset the consumer group should claim</span></span>
<span data-line=""><span>  next_offset  </span><span>BIGINT</span><span> NOT NULL</span><span> DEFAULT</span><span> 1</span><span>,</span></span>
<span data-line=""><span>  PRIMARY KEY</span><span> (group_id, topic_id)</span></span>
<span data-line=""><span>);</span></span></code></pre></figure>
<h4 id="writes">Writes</h4>
<p>The benchmark runs <code>N</code> writer goroutines. These represent writer clients.
Each one loops and atomically inserts <code>$BATCH_SIZE</code> records while updating the latest offset:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>WITH</span><span> reserve </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  UPDATE</span><span> log_counter</span></span>
<span data-line=""><span>  SET</span><span> next_offset </span><span>=</span><span> next_offset </span><span>+</span><span> $</span><span>1</span></span>
<span data-line=""><span>  WHERE</span><span> id </span><span>=</span><span> $</span><span>3</span><span>::</span><span>int</span></span>
<span data-line=""><span>  RETURNING (next_offset </span><span>-</span><span> $</span><span>1</span><span>) </span><span>AS</span><span> first_off</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>INSERT INTO</span><span> topicpartition%d(c_offset, payload)</span></span>
<span data-line=""><span>SELECT</span><span> r</span><span>.</span><span>first_off</span><span> +</span><span> p</span><span>.</span><span>ord</span><span> -</span><span> 1</span><span>, </span><span>p</span><span>.</span><span>payload</span></span>
<span data-line=""><span>FROM</span><span> reserve r,</span></span>
<span data-line=""><span>     unnest($</span><span>2</span><span>::</span><span>bytea</span><span>[]) </span><span>WITH</span><span> ORDINALITY </span><span>AS</span><span> p(payload, ord);</span></span></code></pre></figure>
<h4 id="reads">Reads</h4>
<p>The benchmark also runs <code>N</code> reader goroutines. Each reader is assigned a particular consumer group and partition. The group as a whole reads all partitions while each reader in the group reads only one partition at a time.</p>
<p>The reader loops, opens a transaction, optimistically claims <code>$BATCH_SIZE</code> records (by advancing the offset mark beyond them), selects them and processes the records.
If successful, it commits the transaction and through that advances the offset for the group.</p>
<p>It is a pull-based read (just like Kafka), rather than push-based. If the reader has no records to poll, it sleeps for a bit.</p>
<p>First it opens a transaction:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>BEGIN</span><span> TRANSACTION</span></span></code></pre></figure>
<p>Then it claims the offsets:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>WITH</span><span> counter_tip </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  SELECT</span><span> (next_offset </span><span>-</span><span> 1</span><span>) </span><span>AS</span><span> highest_committed_offset</span></span>
<span data-line=""><span>  FROM</span><span> log_counter</span></span>
<span data-line=""><span>  WHERE</span><span> id </span><span>=</span><span> $</span><span>3</span><span>::</span><span>int</span><span> -- partition id</span></span>
<span data-line=""><span>),</span></span>
<span data-line=""> </span>
<span data-line=""><span>-- select &amp; lock the particular group&lt;-&gt;topic_partition&lt;-&gt;offset pair</span></span>
<span data-line=""><span>to_claim </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  SELECT</span></span>
<span data-line=""><span>    c</span><span>.</span><span>group_id</span><span>,</span></span>
<span data-line=""><span>    c</span><span>.</span><span>next_offset</span><span> AS</span><span> n0, </span><span>-- old start offset pointer before update</span></span>
<span data-line=""><span>    -- takes the min of the batch size</span></span>
<span data-line=""><span>    -- or the current offset delta w.r.t the tip of the log</span></span>
<span data-line=""><span>    LEAST</span><span>(</span></span>
<span data-line=""><span>      $</span><span>2</span><span>::</span><span>bigint</span><span>, </span><span>-- BATCH_SIZE</span></span>
<span data-line=""><span>      GREATEST</span><span>(</span><span>0</span><span>,</span></span>
<span data-line=""><span>        (</span><span>SELECT</span><span> highest_committed_offset </span><span>FROM</span><span> counter_tip) </span><span>-</span><span> c</span><span>.</span><span>next_offset</span><span> +</span><span> 1</span><span>)</span></span>
<span data-line=""><span>    ) </span><span>AS</span><span> delta</span></span>
<span data-line=""><span>  FROM</span><span> consumer_offsets c</span></span>
<span data-line=""><span>  WHERE</span><span> c</span><span>.</span><span>group_id</span><span> =</span><span> $</span><span>1</span><span>::</span><span>text</span><span> AND</span><span> c</span><span>.</span><span>topic_id</span><span> =</span><span> $</span><span>3</span><span>::</span><span>int</span></span>
<span data-line=""><span>  FOR</span><span> UPDATE</span></span>
<span data-line=""><span>),</span></span>
<span data-line=""> </span>
<span data-line=""><span>-- atomically select + update the offset</span></span>
<span data-line=""><span>upd </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  UPDATE</span><span> consumer_offsets c</span></span>
<span data-line=""><span>  SET</span><span> next_offset </span><span>=</span><span> c</span><span>.</span><span>next_offset</span><span> +</span><span> t</span><span>.</span><span>delta</span></span>
<span data-line=""><span>  FROM</span><span> to_claim t</span></span>
<span data-line=""><span>  WHERE</span><span> c</span><span>.</span><span>group_id</span><span> =</span><span> t</span><span>.</span><span>group_id</span><span> AND</span><span> c</span><span>.</span><span>topic_id</span><span> =</span><span> $</span><span>3</span><span>::</span><span>int</span></span>
<span data-line=""><span>  RETURNING</span></span>
<span data-line=""><span>    t</span><span>.</span><span>n0</span><span> AS</span><span> claimed_start_offset, </span><span>-- start = the old next_offset</span></span>
<span data-line=""><span>    (</span><span>c</span><span>.</span><span>next_offset</span><span> -</span><span> 1</span><span>) </span><span>AS</span><span> claimed_end_offset </span><span>-- end   = new pointer - 1</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>SELECT</span><span> claimed_start_offset, claimed_end_offset</span></span>
<span data-line=""><span>FROM</span><span> upd;</span></span></code></pre></figure>
<p>Followed by selecting the claimed records:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>SELECT</span><span> c_offset, payload, created_at</span></span>
<span data-line=""><span>  FROM</span><span> topicpartition%d</span></span>
<span data-line=""><span>  WHERE</span><span> c_offset </span><span>BETWEEN</span><span> $</span><span>1</span><span> AND</span><span> $</span><span>2</span></span>
<span data-line=""><span>  ORDER BY</span><span> c_offset</span></span></code></pre></figure>
<p>Finally, the data gets processed by the business logic (no-op in our benchmark) and the transaction is closed:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>COMMIT</span><span>;</span></span></code></pre></figure>
<p>If you’re wondering <em>“why no <code>NOTIFY/LISTEN</code>?”</em> - my understanding of that feature is that it’s an optimization and cannot be fully relied upon, so polling is required either way<sup><a href="#user-content-fn-21" id="user-content-fnref-21" data-footnote-ref="" aria-describedby="footnote-label">12</a></sup>. Given that, I just copied Kafka’s relatively simple design.</p>
<h2 id="pub-sub-results-1">Pub-Sub Results</h2>
<p>The full code and detailed results are all published on GitHub at <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark">stanislavkozlovski/pg-queue-pubsub-benchmark</a>.
I ran three setups - a single-node 4 vCPU, a 3-node replicated 4 vCPU and a single-node 96 vCPU setup. Here are the summarized results for each:</p>
<h3 id="4-vcpu-single-node">4 vCPU Single Node</h3>
<p><small><em>The results are the average of three 2-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/pubsub/4vcpu/single_node/4vcpu.md">[full results link]</a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge</a> Postgres server /w 25GB gp3 9000 IOPS EBS volume</li>
<li>mostly default Postgres settings (synchronous commit, fsync);
<ul>
<li><code>autovacuum_analyze_scale_factor = 0.05</code> set on the partition tables too (unclear if it has an effect)</li>
</ul>
</li>
<li>each row’s payload is 1 KiB (1024 bytes)</li>
<li>4 topicpartition tables</li>
<li>10 writers (2 writers per partition on average)</li>
<li>5x read fanout via 5 consumer groups</li>
<li>20 reader clients total (4 readers per group)</li>
<li>write batch size: 100 records</li>
<li>read batch size: 200 records</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>
<p>write message rate: <strong>5036 msg/s</strong></p>
</li>
<li>
<p>write throughput: <strong>4.8 MiB/s</strong></p>
</li>
<li>
<p>write latency: 38.7ms p99 / 6.2ms p95</p>
</li>
<li>
<p>read message rate: <strong>25,183 msg/s</strong></p>
</li>
<li>
<p>read message throughput: <strong>24.6 MiB/s</strong></p>
</li>
<li>
<p>read latency: 27.3ms p99 (varied 8.9ms-47ms b/w runs); 4.67ms p95</p>
</li>
<li>
<p>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-3" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: <strong>60ms p99</strong> / 10.6ms p95</p>
</li>
<li>
<p>server kept at ~60% CPU;</p>
</li>
<li>
<p>disk was at ~1200 writes/s with iostat claiming 46 MiB/s</p>
</li>
</ul>
<p>These are pretty good results. It’s funny to think that the majority of people run a complex distributed system like Kafka for similar workloads<sup><a href="#user-content-fn-24" id="user-content-fnref-24" data-footnote-ref="" aria-describedby="footnote-label">13</a></sup>.</p>
<h3 id="4-vcpu-tri-node">4 vCPU Tri-Node</h3>
<p>Now, a replicated setup to more accurately mimic the durability and availability guarantees of Kafka.</p>
<p><small><em>The average of two 5-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/8164907ba0f1afa6bfec3b402950217f31952d2a/results/pubsub/4vcpu/three_node/4vcpu_replicated.md">[full results link]</a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li>3x <a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge</a> Postgres servers /w 25GB gp3 9000 IOPS EBS volume
<ul>
<li>each on a separate AZ (us-east-1a, us-east-1b, us-east-1c)</li>
<li>one <code>sync</code> replica and one <code>potential</code><sup><a href="#user-content-fn-22" id="user-content-fnref-22" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup> replica</li>
</ul>
</li>
<li>a few custom Postgres settings like <code>wal_compression</code>, <code>max_worker_processes</code>, <code>max_parallel_workers</code>, <code>max_parallel_workers_per_gather</code> and of course - <code>hot_standby</code>
<ul>
<li><code>autovacuum_analyze_scale_factor = 0.05</code> set on the partition tables too (unclear if it has an effect)</li>
</ul>
</li>
<li>each row’s payload is 1 KiB (1024 bytes)</li>
<li>4 topicpartition tables</li>
<li>10 writers (2 writers per partition on average)</li>
<li>5x read fanout via 5 consumer groups</li>
<li>readers only access the primary DB<sup><a href="#user-content-fn-25" id="user-content-fnref-25" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup>; readers are in the same AZ as the primary;</li>
<li>20 reader clients total (4 readers per group)</li>
<li>write batch size: 100 records</li>
<li>read batch size: 200 records</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>
<p>write message rate: <strong>5015 msg/s</strong></p>
</li>
<li>
<p>write throughput: <strong>4.9 MiB/s</strong></p>
</li>
<li>
<p>write latency: 153.45ms p99 / 6.8ms p95</p>
</li>
<li>
<p>read message rate: <strong>25,073 msg/s</strong></p>
</li>
<li>
<p>read message throughput: <strong>24.5 MiB/s</strong></p>
</li>
<li>
<p>read latency: 57ms p99; 4.91ms p95</p>
</li>
<li>
<p>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-4" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: <strong>186ms p99</strong> / 12ms p95</p>
</li>
<li>
<p>server kept at ~65% CPU;</p>
</li>
<li>
<p>disk was at ~1200 writes/s with iostat claiming 46 MiB/s</p>
</li>
</ul>
<p>Now these are astonishing results! Throughput was not impacted at all. Latency increased but not extremely. Our p99 e2e latency 3x’d (60ms vs 185ms), but the p95 barely moved from 10.6ms to 12ms.</p>
<p>This shows that a simple 3-node Postgres cluster can pretty easily sustain what is a very common Kafka workload - 5 MB/s ingest and 25 MB/s egress. Not only that, but for a cheap cost too. Just $11,514 per year.<sup><a href="#user-content-fn-26" id="user-content-fnref-26" data-footnote-ref="" aria-describedby="footnote-label">16</a></sup></p>
<p>Typically, you’d expect Postgres to run more expensive than Kafka at a certain scale, simply because it wasn’t designed to be efficient for this use case.
Not here though. Running Kafka yourself would cost the same. Running the same workload through a Kafka vendor will cost you at least $50,000 a year. 🤯</p>
<p>By the way, in Kafka it’s customary to apply client-side compression on your data. If we assume your messages were 5 KB in size and your clients applied a pretty regular compression ratio of 4x<sup><a href="#user-content-fn-28" id="user-content-fnref-28" data-footnote-ref="" aria-describedby="footnote-label">17</a></sup> - Postgres is actually handling 20 MB/s ingress and 100 MB/s egress.</p>
<h3 id="96-vcpu-single-node">96 vCPU Single Node</h3>
<p>Ok, let’s see how far Postgres will go.</p>
<p><small><em>The results are the average of three 2-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/8164907ba0f1afa6bfec3b402950217f31952d2a/results/pubsub/96vcpu/single_node/96vcpu.md">[full results link]</a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.24xlarge">c7i.24xlarge</a> (96 vCPU, 192 GiB RAM) Postgres server instance /w 250GB io2 12,000 IOPS EBS volume</li>
<li>modified Postgres settings (<code>huge_pages</code> on, other settings scaled to match the machine);
<ul>
<li>still kept fsync &amp; synchronous_commit on for durability.</li>
<li><code>autovacuum_analyze_scale_factor = 0.05</code> set on the partition tables too (unclear if it has an effect)</li>
</ul>
</li>
<li>each row’s payload is 1 KiB (1024 bytes)</li>
<li>30 topicpartition tables</li>
<li>100 writers (~3.33 writers per partition on average)</li>
<li>5x read fanout via 5 consumer groups</li>
<li>150 reader clients total (5 readers per group)</li>
<li>write batch size: 200 records</li>
<li>read batch size: 200 records</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>
<p>write message rate: <strong>243,000 msg/s</strong></p>
</li>
<li>
<p>write throughput: <strong>238 MiB/s</strong></p>
</li>
<li>
<p>write latency: 138ms p99 / 47ms p95</p>
</li>
<li>
<p>read message rate: <strong>1,200,000 msg/s</strong></p>
</li>
<li>
<p>read message throughput: <strong>1.16 GiB/s</strong></p>
</li>
<li>
<p>read latency: 24.6ms p99</p>
</li>
<li>
<p>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: <strong>853ms p99</strong> / 242ms p95 / 23.4ms p50</p>
</li>
<li>
<p>server kept at <strong>~10%</strong> CPU (basically idle);</p>
</li>
<li>
<p>bottleneck: The bottleneck was the write rate per partition. It seems like the test wasn’t able to write at a higher rate than 8 MiB/s (8k msg/s) per table with this design. I didn’t push further, but I do wonder now as I write this - how far would writes have scaled?</p>
<ul>
<li>Reads were trivial to scale. Adding more consumer groups was trivial - I tried with 10x fanout and still ran at low CPU. I didn’t include it because I didn’t feel the need to push to an unrealistic read-fanout extreme.</li>
</ul>
</li>
</ul>
<p>240 MiB/s ingress and 1.16 GiB/s egress are pretty good! The 96 vCPU machine was overkill for this test - it could have done a lot more, or we could have simply opted for a smaller machine. For what it’s worth, I do think it’s worth it to deploy a separate Kafka cluster at this scale. Kafka can save you a lot of money here because it can be more efficient in how it handles cross-zone network traffic with features like <a href="https://blog.2minutestreaming.com/p/diskless-kafka-topics-kip-1150">Diskless Kafka</a>.</p>
<h3 id="pub-sub-test-summary">Pub-Sub Test Summary</h3>
<p><small><em>The summarized table with the three test results can be found here <span>→</span> 👉 <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/tree/main/results#pubsub-results">stanislavkozlovski/pg-queue-pubsub-benchmark</a></em></small></p>
<p>These tests seem to show that Postgres is pretty competitive with Kafka at low scale.</p>
<p>You may have noticed none of these tests were particularly long-running. From my understanding, the value in longer-running tests is to test table vacuuming in Postgres, as that can have negative performance effects. In the pub-sub section, vacuuming doesn’t apply because the tables are append-only. My other reasoning for running shorter tests was to keep costs in check and not spend too much time<sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref="" aria-describedby="footnote-label">18</a></sup>.</p>
<p>In any case, no benchmark is perfect. My goal wasn’t to indisputably prove <code>$MY_CLAIM</code>. Rather, I want to start a discussion by showing that what’s possible is likely larger than what most people assume. I certainly didn’t assume I’d get such good numbers, especially with the pub-sub part.</p>
<hr>
<h2 id="pg-as-a-queue">PG as a Queue</h2>
<p>In Postgres, a queue can be implemented with <code>SELECT FOR UPDATE SKIP LOCKED</code>. This command selects an unlocked row and locks it. It also skips reading already-locked rows. That’s how mutual exclusion is achieved - a worker can’t get other workers’ jobs.</p>
<p>Postgres has a very popular <a href="https://github.com/pgmq/pgmq">pgmq</a> library that offers a slick queue API. To keep it simple and understand the end-to-end flow better, I decided to write my own queue. The basic version of it is very easy. My workflow is:</p>
<ol>
<li>add job (<code>INSERT</code>)</li>
<li>lock row &amp; take job (<code>SELECT FOR UPDATE SKIP LOCKED</code>)</li>
<li>process job (<code>{your business logic}</code>)</li>
<li>mark job as “done” (<code>UPDATE</code> a field or <code>DELETE &amp; INSERT</code> the row into a separate table)</li>
</ol>
<p>Postgres competes with RabbitMQ, AWS SQS, NATS, Redis<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="" aria-describedby="footnote-label">19</a></sup> and to an extent Kafka<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="" aria-describedby="footnote-label">20</a></sup> here.</p>
<h2 id="queue-setup">Queue Setup</h2>
<h4 id="table-1">Table</h4>
<p>We use a simple <code>queue</code> table. When an element is processed off the queue, it’s moved into the archive table.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>CREATE</span><span> TABLE</span><span> queue</span><span> (</span></span>
<span data-line=""><span>  id </span><span>BIGSERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span data-line=""><span>  payload </span><span>BYTEA</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>	created_at </span><span>TIMESTAMP</span><span> NOT NULL</span><span> DEFAULT</span><span> NOW</span><span>()</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>CREATE</span><span> TABLE</span><span> queue_archive</span><span> (</span></span>
<span data-line=""><span>  id </span><span>BIGINT</span><span>,</span></span>
<span data-line=""><span>  payload </span><span>BYTEA</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>  created_at </span><span>TIMESTAMP</span><span> NOT NULL</span><span>, </span><span>-- ts the event was originally created at</span></span>
<span data-line=""><span>  processed_at </span><span>TIMESTAMP</span><span> NOT NULL</span><span> DEFAULT</span><span> NOW</span><span>() </span><span>-- ts the event was processed at</span></span>
<span data-line=""><span>)</span></span></code></pre></figure>
<h4 id="writes-1">Writes</h4>
<p>We again run <code>N</code> writer client goroutines.
Each one simply loops and sequentially inserts a single random item into the table:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>INSERT INTO</span><span> queue</span><span> (payload) </span><span>VALUES</span><span> ($</span><span>1</span><span>)</span></span></code></pre></figure>
<p>It only inserts one message per statement, which is pretty inefficient at scale.</p>
<h4 id="reads-1">Reads</h4>
<p>We again run <code>M</code> reader client goroutines. Each reader loops and processes one message.
The processing is done inside a database transaction.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>BEGIN</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>SELECT</span><span> id, payload, created_at</span></span>
<span data-line=""><span>  FROM</span><span> queue</span></span>
<span data-line=""><span>  ORDER BY</span><span> id</span></span>
<span data-line=""><span>  FOR</span><span> UPDATE</span><span> SKIP</span><span> LOCKED</span></span>
<span data-line=""><span>  LIMIT</span><span> 1</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>-- Your business code "processes" the message. In the benchmark, it's a no-op.</span></span>
<span data-line=""> </span>
<span data-line=""><span>DELETE</span><span> FROM</span><span> queue</span><span> WHERE</span><span> id </span><span>=</span><span> $</span><span>1</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>INSERT INTO</span><span> queue_archive (id, payload, created_at, processed_at)</span></span>
<span data-line=""><span>  VALUES</span><span> ($</span><span>1</span><span>,$</span><span>2</span><span>,$</span><span>3</span><span>,</span><span>NOW</span><span>());</span></span>
<span data-line=""> </span>
<span data-line=""><span>COMMIT</span><span>;</span></span></code></pre></figure>
<p>Each reader again only works with one message at a time per transaction.</p>
<h2 id="queue-results-1">Queue Results</h2>
<p>I again ran the same three setups - a single-node 4 vCPU, a 3-node replicated 4 vCPU and a single-node 96 vCPU setup. Here are the summarized results for each:</p>
<h3 id="4-vcpu-single-node-1">4 vCPU Single Node</h3>
<p><small><em>The results are the average of two 15-minute tests. I also ran three 2-minute tests. They all performed similarly.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/queue/4vcpu/single_node/4vcpu.md">[full results link]</a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge</a> Postgres server /w 25GB gp3 9000 IOPS EBS volume</li>
<li>all default Postgres settings<sup><a href="#user-content-fn-16" id="user-content-fnref-16" data-footnote-ref="" aria-describedby="footnote-label">21</a></sup></li>
<li>each row’s payload is 1 KiB (1024 bytes)</li>
<li>10 writer clients, 15 reader clients</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>message rate: <strong>2885 msg/s</strong></li>
<li>throughput: <strong>2.81 MiB/s</strong></li>
<li>write latency: 2.46ms p99</li>
<li>read latency: 4.2ms p99</li>
<li>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-6" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: 17.72ms p99</li>
<li>server kept at ~60% CPU;</li>
</ul>
<p>What I found Postgres wasn’t good at was handling client count. The bottleneck in this setup was the read clients. Each client could not read more than ~192 messages a second because of its median read latency and sequential read nature.</p>
<p>Increasing client count boosted throughput but violated my ~60% CPU target. Trying to run 50 write and 50 read clients got to 4000 msg/s without increasing the queue depth but pegged the server’s CPU to 100%. I wanted to keep the benchmarks realistic for what you may run in production, rather than maxing out what a machine can do. This would be easily alleviated with a connection pooler (standard across all prod PG deployments) or a larger machine.</p>
<p>Another thing worth mentioning is that the workload could sustain a lot more writes than reads. If I didn’t throttle the benchmark, it would write at 12,000 msg/s and read at 2,800 msg/s. In the spirit of simplicity, I didn’t debug further and instead throttled my writes to see at what point I could get a stable 1:1 workload.</p>
<h3 id="4-vcpu-tri-node-1">4 vCPU Tri-Node</h3>
<p><small><em>A single 10-minute test.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/queue/4vcpu/three_node/4vcpu_replicated.md">[full results link]</a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li>3x <a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge</a> Postgres servers /w 25GB gp3 9000 IOPS EBS volume
<ul>
<li>each on a separate AZ (us-east-1a, us-east-1b, us-east-1c)</li>
<li>one <code>sync</code> replica and one <code>potential</code><sup><a href="#user-content-fn-22" id="user-content-fnref-22-2" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup> replica</li>
</ul>
</li>
<li>a few custom Postgres settings like <code>wal_compression</code>, <code>max_worker_processes</code>, <code>max_parallel_workers</code>, <code>max_parallel_workers_per_gather</code> and of course - <code>hot_standby</code></li>
<li>each row’s payload is 1 KiB (1024 bytes)</li>
<li>10 writer clients, 15 reader clients</li>
<li>readers only access the primary DB<sup><a href="#user-content-fn-25" id="user-content-fnref-25-2" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup>; readers are in the same AZ as the primary;</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>message rate: <strong>2397 msg/s</strong></li>
<li>throughput: <strong>2.34 MiB/s</strong></li>
<li>write latency: 3.3ms p99</li>
<li>read latency: 7.6ms p99</li>
<li>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-7" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: 920ms p99 ⚠️<sup><a href="#user-content-fn-19" id="user-content-fnref-19-3" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>; 536ms p95; 7ms p50</li>
<li>server kept at ~60% CPU;</li>
</ul>
<p>As expected, throughput and latency were impacted somewhat. But not that much. It’s still over 2000 messages a second, which is pretty good for an HA queue!</p>
<h3 id="96-vcpu-single-node-1">96 vCPU Single Node</h3>
<p><small><em>The average of three 2-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/queue/96vcpu/single_node/96vcpu.md">[full results link]</a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.24xlarge">c7i.24xlarge</a> Postgres server instance /w 250GB io2 12,000 IOPS EBS volume</li>
<li>modified Postgres settings (<code>huge_pages</code> on, other settings scaled to match the machine);
<ul>
<li>still kept fsync &amp; synchronous_commit on for durability.</li>
</ul>
</li>
<li>each row’s payload is 1 KiB (1024 bytes)</li>
<li>100 writer clients, 200 reader clients</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>message rate: <strong>20,144 msg/s</strong></li>
<li>throughput: <strong>19.67 MiB/s</strong></li>
<li>write latency: 9.42ms p99</li>
<li>read latency: 22.6ms p99</li>
<li>end-to-end latency: 930ms p99 ⚠️<sup><a href="#user-content-fn-19" id="user-content-fnref-19-4" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>; 709ms p95; 12.6ms p50</li>
<li>server at 40-60% CPU;</li>
</ul>
<p>This run wasn’t that impressive. There is some bottleneck in the single-table queue approach at this scale which I didn’t bother figuring out. I figured that it wasn’t important to reach absurd numbers on a single table, since all realistic scenarios would have multiple queues and never reach 20,000 msg/s on a single one. The 96 vCPU instance would likely scale far further were we to run a few separate queue tables in parallel.</p>
<h3 id="queue-test-summary">Queue Test Summary</h3>
<p><small><em>The summarized table with the three test results can be found here <span>→</span> 👉 <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/tree/main/results#queue-results">stanislavkozlovski/pg-queue-pubsub-benchmark</a></em></small></p>
<p>Even a modest Postgres node can durably push thousands of queue ops/sec, which already covers the scale 99% of companies ever hit with a single queue.
As I said earlier, the last 2 years have seen the Just Use Postgres slogan become mainstream. The <code>pgmq</code> <a href="https://github.com/pgmq/pgmq">library</a>’s star history captures this trend perfectly:
<img src="https://topicpartition.io/blog/images/pgmq_star_history.png" alt="pgmq"></p>
<hr>
<h2 id="should-you-use-postgres">Should You Use Postgres?</h2>
<p>Most of the time - <strong>yes</strong>. You should always default to Postgres until the constraints prove you wrong.</p>
<p>Kafka is obviously better optimized for pub-sub workloads. Queue systems are obviously better optimized for queue workloads. The point is that <strong>picking a technology based on technical optimization alone is a flawed approach</strong>. To throw an analogy:</p>
<blockquote>
<p>a Formula One car is optimized to drive faster, but I still use a sedan to go to work. I am way more comfortable driving my sedan than an F1 car.</p>
<p><small><em>(seriously, see <a href="https://www.youtube.com/watch?v=nsup4xKpb20">the steering wheel</a> on these things)</em></small></p>
</blockquote>
<p>The Postgres sedan comes with many quality-of-life comforts that the F1 Kafka does not:</p>
<ul>
<li>ability to debug messages with regular SQL</li>
<li>ability to delete, re-order or edit messages in place</li>
<li>ability to join pub-sub data with regular tables</li>
<li>ability to trivially read specific data via rich SQL queries (<code>ID=54</code>, <code>name="John"</code>, <code>cost&gt;1000</code>)</li>
</ul>
<p>Giving up these comforts is a justified sacrifice for your F1 car to go at 378 kmh (235 mph), but masochistic if you plan on driving at 25kmh (15 mph).</p>
<p>Donald Knuth warned us in 1974 - <strong>premature optimization</strong> is the root of all evil. Deploying Kafka at small scale is premature optimization.
The point of this article is to show you that this “small scale” number has grown further than what people remember it to be - it can comfortably mean many megabytes per second.</p>
<p>We are in a Postgres Renaissance for a reason: Postgres is <strong>frequently</strong> good enough. Modern NVMEs and cheap RAM allow it to scale absurdly high.</p>
<p>What’s the alternative?</p>
<h2 id="custom-solutions-for-everything">Custom Solutions for Everything?</h2>
<p>Naive engineers tend to adopt a specialized technology at the slightest hint of a need:</p>
<ul>
<li><em>Need a cache?</em> Redis, of course!</li>
<li><em>Search?</em> Let’s deploy Elasticsearch!</li>
<li><em>Offline data analysis?</em> BigQuery or Snowflake - that’s what our data analysts used at their last job.</li>
<li><em>No schemas?</em> We need a NoSQL database like MongoDB.</li>
<li><em>Have to crunch some numbers on S3?</em> Let’s use Spark!</li>
</ul>
<p>A good engineer thinks through the bigger picture.</p>
<ul>
<li><em>Does this new technology move the needle?</em></li>
<li><em>Is shaving a few milliseconds off our query worth the extra organizational complexity introduced with the change?</em></li>
<li><em>Will our users notice?</em></li>
</ul>
<p>At small scale, these systems hurt you more than they benefit you. Distributed systems - both in terms of node count and system cardinality - should be respected, feared, avoided and employed only as a weapon of last resort against particularly gnarly problems. Everything with a distributed system becomes more challenging and time-consuming.</p>
<p>The problem is <strong>the organizational overhead</strong>. The organizational overhead of adopting a new system, learning its nuances, configs, establishing monitoring, establishing processes around deployments and upgrades, attaining operational expertise on how to manage it, creating runbooks, testing it, debugging it, adopting its clients and API, using its UI, keeping up with its ecosystem, etc.</p>
<p>All of these are real organizational costs that can take months to get right, even if the system in question isn’t difficult (a lot are). Managed SaaS offerings trade off some of the organizational overhead for greater financial costs - but they still don’t remove it all. And until you reach the scale where the technology is necessary, you pay these extra <em>{financial, organizational}</em> costs for zero significant gain.</p>
<p>If the same can be done with tech for which you’ve already paid the organizational costs for (e.g Postgres), adopting something else prematurely is most definitely an anti-pattern. You don’t need web-scale technologies when you don’t have web-scale problems.</p>
<h2 id="mvi-a-better-alternative">MVI (a better alternative)</h2>
<p>What I think is a better approach is to search for the <strong>minimum viable infrastructure</strong> (MVI): build the smallest amount of system while still providing value.</p>
<ol>
<li>choose <strong>good-enough</strong> technology your org is already <strong>familiar</strong> with
<ul>
<li><em>good-enough</em> == meets your users’ needs without being too slow/expensive/insecure</li>
<li><em>familiar</em> == your org has prior experience, has runbooks/ops setups, monitoring, UI, etc</li>
</ul>
</li>
<li>solve a real problem with it</li>
<li>use the minimum set of features
<ul>
<li>the fewer features you use, the more flexibility you have to move off the infra in question in the future (e.g if locked in with a vendor)</li>
</ul>
</li>
</ol>
<p>Bonus points if that technology:</p>
<ul>
<li>is widely adopted so finding good engineers for it is trivial (Postgres - check)</li>
<li>has a strong and growing network effect (Postgres - check)</li>
</ul>
<p>The MVI approach reduces the surface area of your infra. The fewer moving parts you have, the fewer failure modes you worry about and the less glue code you have to maintain.</p>
<p>Unfortunately, it’s human nature to go against this. Just like startups suffer due to <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">MVP</a> bloat <em>(one more feature!)</em>, infra teams suffer due to MVI bloat <em>(one more system!)</em></p>
<h2 id="why-are-we-like-this">Why are we like this?</h2>
<p>I won’t pretend to be able to map out the exact path-dependent outcome, but my guess is this:</p>
<ol start="0">
<li>the zero interest rate era gave us abundant speculative money that was invested in any company that could grow fast</li>
<li>a lot of viral internet companies were growing at speeds that led old infra to become obsolete fast</li>
<li>this prompted the next wave of ZIRP investment - specialized data infrastructure companies (in a gold rush, sell shovels!); some of these data infra startups spun off directly from the high-growth companies themselves</li>
<li>each well-funded data infra vendor is financially motivated to evangelize their product and have you adopt it even when you don’t need to (<a href="https://topicpartition.io/blog/everyone-is-talking-their-book" data-slug="blog/everyone-is-talking-their-book">Everyone is Talking Their Book</a>). They had deep pockets for marketing and used them.</li>
<li>innovative infrastructure software got engineered. It was exciting - so engineers got <a href="https://xkcd.com/356/">nerd-sniped</a> into it</li>
<li>a <a href="https://www.youtube.com/watch?v=b2F-DItXtZs">web-scale</a> craze/cargo cult developed, where everybody believed they need to be able to scale from zero to millions of RPS because they may go viral any day.</li>
<li>a trend developed to copy whatever solutions the most successful, largest digital-native companies were using (Amazon, Google, Uber, etc.)</li>
<li>the trend became a self-perpetuating prophecy: these technologies became a sought-after skill on resumes
<ul>
<li>system design interview questions were adapted to test for knowledge of these systems</li>
<li>within an organization, engineers (knowingly or not) pushed for projects that are exciting and helped build their resumes;</li>
</ul>
</li>
</ol>
<p>This trend continues to grow while there is no strong competing force that is sufficiently motivated to push the opposite view. Even engineers inside a company, who ought to be motivated to keep things simple, have strong incentives to pursue extra complexity. It benefits their career by giving them a project to use as ammo for their next promotion and improves their resume (cool tech/story on there) for their next job-hop. Plus it’s simply more fun.</p>
<p>This is why I think we, as an industry, don’t always use the simplest solution available.</p>
<p>In most cases, Postgres is that simplest solution that is available.</p>
<h2 id="but-it-wont-scale">But It Won’t Scale!</h2>
<p>I want to wrap this article up, but one rebuttal I can’t miss addressing is the “it won’t scale argument”.</p>
<p>The argument goes something like this: “in today’s age we can go viral at a moment’s notice; these viral moments are very valuable for our business so we need to aggressively design in a way that keeps our app stable under traffic spikes”</p>
<p>I have three arguments against this:</p>
<h3 id="1-postgres-scales">1. Postgres Scales</h3>
<p>As of 2025, OpenAI <a href="https://news.ycombinator.com/item?id=44074702">still uses</a> an unsharded Postgres architecture with only one primary instance for writes<sup><a href="#user-content-fn-17" id="user-content-fnref-17" data-footnote-ref="" aria-describedby="footnote-label">22</a></sup>. OpenAI is <em><strong>the</strong></em> poster-child of rapid viral growth. They hold the record for <a href="https://www.researchgate.net/figure/Time-to-reach-100-million-users-for-different-technologies-in-months-after-initial_fig1_372212988">the fastest startup to reach 100 million users</a>.</p>
<p><a href="https://bohanzhang.me/">Bohan Zhang</a>, a member of OpenAI’s infrastructure team and co-founder of <a href="https://ottertune.com/">OtterTune</a> (a Postgres tuning service), can be quoted as saying<sup><a href="#user-content-fn-29" id="user-content-fnref-29" data-footnote-ref="" aria-describedby="footnote-label">23</a></sup>:</p>
<blockquote>
<p><em>“At OpenAI, we utilize an unsharded architecture with one writer and multiple readers, demonstrating that PostgreSQL can scale gracefully under massive read loads.”</em></p>
<p><em>“The main message of my talk was that if you are not too write heavy, you can scale Postgres to a very high read throughput with read replicas using only a single master! That is exactly the message that needs to be spelled out as that covers <strong>the vast majority</strong> of apps.”</em></p>
<p><em>“Postgres is probably the default choice for developers right now. You can use Postgres for a very long time. If you are building a startup with read-heavy workloads, just start with Postgres. If you hit a scalability issue, increase the instance size. You can scale it to a very large scale. If in the future the database becomes a bottleneck, congratulations. You have built a successful startup. It’s a good problem to have.”</em></p>
<p>(slightly edited for clarity and grammar)</p>
</blockquote>
<p>Despite their rapid growth to a user base of more than 800 million, OpenAI has still NOT opted for a web-scale distributed database. If they haven’t… why does your unproven project need to?</p>
<h3 id="2-you-have-more-time-to-scale-than-you-think">2. You Have More Time To Scale Than You Think</h3>
<p>Let’s say it’s a good principle to design/test for ~10x your scale. Here are the years of <em>consistent</em> growth rate it takes to get to 10x your current scale:</p>





































<div><table><thead><tr><th>annual growth</th><th>years to hit 10× scale</th></tr></thead><tbody><tr><td>10 %</td><td>24.16 y</td></tr><tr><td>25 %</td><td>10.32 y</td></tr><tr><td>50 %</td><td>5.68 y</td></tr><tr><td>75 %</td><td>4.11 y</td></tr><tr><td>100 %</td><td>3.32 y</td></tr><tr><td>150 %</td><td>2.51 y</td></tr><tr><td>200 %</td><td>2.10 y</td></tr></tbody></table></div>
<p>It goes to show that even at extreme growth levels, you still have years to migrate between solutions.
The majority of developers, though, work at companies in the 0-50% growth rate. They are more likely to have moved on to another job by the time the solution needs to change (if ever).</p>
<h3 id="3-its-overdesign">3. It’s Overdesign</h3>
<p>In an ideal world, you <em>would</em> build for scale and any other future problem you may hit in 10 years.</p>
<p>In the real world, you have finite bandwidth, so you have to build for the most immediate, highest ROI problem.</p>
<p><a href="https://lobste.rs/s/wshruu/small_data#c_kjygo0">Commenter snej on lobste.rs</a> captured it well:</p>
<blockquote>
<p>Planning your infrastructure around being able to handle that is sort of like buying a huge Marshall stack as your first guitar amp because your garage band might get invited to open for Coldplay.</p>
</blockquote>
<h2 id="conclusion">Conclusion</h2>
<p>Just use Postgres until it breaks.</p>
<hr>
<h3 id="disclaimers"><em>Disclaimers</em></h3>
<ul>
<li>
<p><em>Title inspiration comes from a great recent piece - <a href="https://dizzy.zone/2025/09/24/Redis-is-fast-Ill-cache-in-Postgres/">“Redis is fast - I’ll cache in Postgres”</a></em></p>
</li>
<li>
<p><em>I’m a complete Postgres noob. You may see a lot of dumb mistakes here. Feel free to call me out on them - I’m happy to learn. I used AI to help a lot with some of the PG tools to use. This both shows how inexperienced I am in the context and how easy it is to start. I am generally skeptical of AI’s promise (in the short-term), but there’s no denying it has made a large dent in democratizing niche/low-level knowledge.</em></p>
</li>
</ul>
<p>If you’d like to reach out to me, you can find me on <a href="https://www.linkedin.com/in/stanislavkozlovski/">LinkedIn</a> or <a href="https://x.com/BdKozlovski">X (Twitter)</a>.</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>Don’t worry if you don’t fully understand these terms. I work full-time in the industry that spews these things and I don’t have a great grasp either. It’s marketing slop. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>Gartner and others push embarrassing recommendations that aren’t tech driven. It’s frequently the opposite - they’re profit driven. Gartner makes $6.72B purely off a consulting service that charges organizations $50k <em>per seat</em> solely for access to reports that recommend these slop architectures. It’s not crazy to believe, hence many people are converging with the idea that it is a <a href="https://www.linkedin.com/posts/gergelyorosz_gartner-has-been-out-of-touch-with-tech-analysis-activity-7374374378240786432-9WsQ">pay-to-win racket</a> model. <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>Seriously, the improvement in hardware is something I find most senior engineers haven’t properly appreciated. Newest gen AMD CPUs boast <a href="https://www.amd.com/en/products/processors/server/epyc/9005-series.html">192 cores</a>. Modern SSDs can do <strong>5.5 million</strong> random reads a second, or ~28GB/s sequential reads. Both are a 10-20x improvement over the last 10 years alone. Single nodes are more powerful than ever. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>Just in the last 6 months - Snowflake acquired Crunchy Data for ~$250M, Databricks acquired Neon for ~$1 <strong>b</strong>illion;
In the last 12 months, Supabase more than <strong>5x’d</strong> its valuation from ($900M to $5B), raising $380M across <strong>three</strong> series (!!!). Within a single year! <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 4">↩</a></p>
</li>
<li id="user-content-fn-9">
<p>End-to-end latency here is defined as <code>now() - event_create_time</code>; In essence, it tracks how long a brand new persisted event takes to get consumed. It helps show cases where queue lag spikes like when consumers temporarily fall behind the write rate. <a href="#user-content-fnref-9" data-footnote-backref="" aria-label="Back to reference 5">↩</a> <a href="#user-content-fnref-9-2" data-footnote-backref="" aria-label="Back to reference 5-2">↩<sup>2</sup></a> <a href="#user-content-fnref-9-3" data-footnote-backref="" aria-label="Back to reference 5-3">↩<sup>3</sup></a> <a href="#user-content-fnref-9-4" data-footnote-backref="" aria-label="Back to reference 5-4">↩<sup>4</sup></a> <a href="#user-content-fnref-9-5" data-footnote-backref="" aria-label="Back to reference 5-5">↩<sup>5</sup></a> <a href="#user-content-fnref-9-6" data-footnote-backref="" aria-label="Back to reference 5-6">↩<sup>6</sup></a> <a href="#user-content-fnref-9-7" data-footnote-backref="" aria-label="Back to reference 5-7">↩<sup>7</sup></a></p>
</li>
<li id="user-content-fn-19">
<p>Some queue tests showed higher E2E latencies which I believe was due to a bug. In the pub-sub tests, I ensured readers start <em>before</em> the writers via a 1000ms sleep. For the queue tests, though, I didn’t do this. The result is that queue tests immediately spike queue depth at startup because the writers manage to get a head start before the readers. I believe the E2E latency is artificially high because of this flaw in the test. <a href="#user-content-fnref-19" data-footnote-backref="" aria-label="Back to reference 6">↩</a> <a href="#user-content-fnref-19-2" data-footnote-backref="" aria-label="Back to reference 6-2">↩<sup>2</sup></a> <a href="#user-content-fnref-19-3" data-footnote-backref="" aria-label="Back to reference 6-3">↩<sup>3</sup></a> <a href="#user-content-fnref-19-4" data-footnote-backref="" aria-label="Back to reference 6-4">↩<sup>4</sup></a></p>
</li>
<li id="user-content-fn-6">
<p>Actually, things are ordered in the happy path. Only during retries can you get out of order processing. e.g at t=0, client A reads task N; At t=1, client B reads task N+1 and processes it successfully; At t=2, A fails and is unable to process task N; At t=3, client B takes the next available task - which is N. B therefore executes the tasks in order [N+1, N], whereas proper order would have been [N, N+1] <a href="#user-content-fnref-6" data-footnote-backref="" aria-label="Back to reference 7">↩</a></p>
</li>
<li id="user-content-fn-13">
<p>Open-source projects include <a href="https://pulsar.apache.org/">Apache Pulsar</a> (open source), <a href="https://github.com/redpanda-data/redpanda/">RedPanda</a> (source-available), <a href="https://github.com/AutoMQ">AutoMQ</a> (a fork of Kafka) and a lot of proprietary offerings - <a href="https://aws.amazon.com/kinesis/">AWS Kinesis</a>, <a href="https://cloud.google.com/pubsub">Google Pub/Sub</a>, <a href="https://azure.microsoft.com/products/event-hubs">Azure Event Hubs</a>, <a href="https://www.confluent.io/confluent-cloud/kora/">Confluent Kora</a>, <a href="https://www.warpstream.com/">Confluent WarpStream</a>, <a href="https://buf.build/product/bufstream">Bufstream</a> to name a few. What’s common in 90% of these projects is that they all <strong><em>implement</em></strong> the Apache Kafka API, making Kafka undoubtedly the protocol standard in the space. There’s also an open-source project which exposes a Kafka API on top of a pluggable Postgres or S3 backend - <a href="https://github.com/tansu-io/tansu">Tansu</a> (Rust, btw :] ) <a href="#user-content-fnref-13" data-footnote-backref="" aria-label="Back to reference 8">↩</a></p>
</li>
<li id="user-content-fn-27">
<p>The most popular library I could find is <a href="https://github.com/imqueue/pg-pubsub">pg-pubsub</a> with 106 stars as of writing (Oct 2025). Its last commit was 3 months ago. <a href="#user-content-fnref-27" data-footnote-backref="" aria-label="Back to reference 9">↩</a></p>
</li>
<li id="user-content-fn-20">
<p>Batching messages per client is very important for scalability here. It is one of Kafka’s least-talked-about performance “tricks”. <a href="#user-content-fnref-20" data-footnote-backref="" aria-label="Back to reference 10">↩</a></p>
</li>
<li id="user-content-fn-14">
<p>These tables act as different log data structures. You can see them as separate <strong>topics</strong>, or <strong>partitions</strong> of one topic (shards). <a href="#user-content-fnref-14" data-footnote-backref="" aria-label="Back to reference 11">↩</a></p>
</li>
<li id="user-content-fn-21">
<p>Postgres stores all <code>NOTIFY</code> events in a single, global queue. If this queue becomes full, transactions calling <code>NOTIFY</code> will fail when committing. (<a href="https://lobste.rs/c/iix4ph">src</a>) <a href="#user-content-fnref-21" data-footnote-backref="" aria-label="Back to reference 12">↩</a></p>
</li>
<li id="user-content-fn-24">
<p>A <a href="https://cdn.prod.website-files.com/6659da8aecd70e0898c0d7ed/672fb52dc29ab4cdf8a59525_The-State-of-Streaming-Data_Report-by-Redpanda.pdf">report by RedPanda</a> found that ~55% of respondents use Kafka for &lt; 1 MB/s. Kafka-vendor Aiven <a href="https://aiven.io/blog/apache-kafkas-80-percent-problem">similarly shared</a> that 50% of their Kafka deployments have an ingest rate of below 10 MB/s. <a href="#user-content-fnref-24" data-footnote-backref="" aria-label="Back to reference 13">↩</a></p>
</li>
<li id="user-content-fn-22">
<p>This replication is equivalent to RF=2 in Kafka with one extra non-synchronous replica. Call it RF=2.5. The client receives a response when the one <code>sync</code> replica confirms the change. The other <code>potential</code> replica is replicating asynchronously without blocking the write path. It will become promoted to <code>sync</code> if the other one was to die. <a href="#user-content-fnref-22" data-footnote-backref="" aria-label="Back to reference 14">↩</a> <a href="#user-content-fnref-22-2" data-footnote-backref="" aria-label="Back to reference 14-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-25">
<p>The tests didn’t direct any read traffic to the standbys. This caused extra load on the primary - most production workloads would read from the standbys. Despite that, the results were still good! In my tests, I found that the extra read workload didn’t seem to have a negative effect on the database - it seems such tail reads were served exclusively from cache. <a href="#user-content-fnref-25" data-footnote-backref="" aria-label="Back to reference 15">↩</a> <a href="#user-content-fnref-25-2" data-footnote-backref="" aria-label="Back to reference 15-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-26">
<p>The node and its disk cost <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/main/results/pubsub/4vcpu/single_node/4vcpu.md#-cost">$1826 per year</a>. Since we run three of those, it’s $5478/yr. The networking in AWS costs $0.02/GB and our setup is replicating 4.9MB/s across two instances - that results in 294.74TB cross-zone networking per year. That’s $6036 per year in replication networking. Assuming your clients are in the same zone as the database they’re writing to / reading from, that networking is free. That results in an annual cost of $11,514. <a href="#user-content-fnref-26" data-footnote-backref="" aria-label="Back to reference 16">↩</a></p>
</li>
<li id="user-content-fn-28">
<p>We can realistically achieve a <a href="https://www.linkedin.com/pulse/subtle-art-cost-comparisons-tristan-stevens-tqtue">10x+ compression ratio</a> if operating on compressible data like logs (something Kafka is used for frequently). The only gotcha is that we need to compress larger batches - eg 25KB+ - so that requires a bit of a re-design in the pub-sub data model. <a href="#user-content-fnref-28" data-footnote-backref="" aria-label="Back to reference 17">↩</a></p>
</li>
<li id="user-content-fn-10">
<p>I had already spent enough business days working on this benchmark and re-running tests numerous, numerous times as I iterated on the benchmark and the methodology. On the larger instances, the cost accumulates fast and running longer tests at high MB/s rates requires deploying much larger and more expensive disks in order to store all the accumulated data. The effort spent matches the goal I have with the article. If any Postgres vendor wants to sponsor a more thorough investigation - let me know! <a href="#user-content-fnref-10" data-footnote-backref="" aria-label="Back to reference 18">↩</a></p>
</li>
<li id="user-content-fn-7">
<p>Surprisingly (to me), Redis is a very popular queue-like backend choice for background jobs. <a href="https://github.com/topics/background-jobs">Most popular open-source libraries</a> use it. Although I’m sure Postgres can do just as good a job, many devs will prefer to use an established library rather than build one from scratch or use something less well-maintained. I do think PG-backed libraries should get developed though! <a href="#user-content-fnref-7" data-footnote-backref="" aria-label="Back to reference 19">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>Kafka has historically never been a queue. To use it as one, you had to develop some difficult workarounds. Today, however, it is in the middle of implementing a first-class Queue-like interface (currently in <a href="https://cwiki.apache.org/confluence/display/KAFKA/Queues+for+Kafka+%28KIP-932%29+-+Preview+Release+Notes">Preview</a>) <a href="#user-content-fnref-8" data-footnote-backref="" aria-label="Back to reference 20">↩</a></p>
</li>
<li id="user-content-fn-16">
<p>Most importantly, synchronous commit and fsync are both on. This means every write is durably persisted to disk. <a href="#user-content-fnref-16" data-footnote-backref="" aria-label="Back to reference 21">↩</a></p>
</li>
<li id="user-content-fn-17">
<p>The optimizations they did to support this scale are cool, but not novel. See these two talks at a) <a href="https://www.youtube.com/watch?v=Ni1SGhNu-Q4">PGConf.dev 2025</a> (<a href="https://gist.github.com/stanislavkozlovski/d1283b784eed03a8dfe126297c11b7e6">my transcript</a>) and b) <a href="https://www.youtube.com/watch?v=NvY2kvi1Fa0">POSETTE</a> (<a href="https://gist.github.com/stanislavkozlovski/7853a1c0a73caba81de53f4e36c618f5">my transcript</a>) <a href="#user-content-fnref-17" data-footnote-backref="" aria-label="Back to reference 22">↩</a></p>
</li>
<li id="user-content-fn-29">
<p>From the talks <a href="https://www.youtube.com/watch?v=Ni1SGhNu-Q4">PGConf.dev 2025</a> (<a href="https://gist.github.com/stanislavkozlovski/d1283b784eed03a8dfe126297c11b7e6">my transcript</a>) and <a href="https://www.youtube.com/watch?v=NvY2kvi1Fa0">POSETTE</a> (<a href="https://gist.github.com/stanislavkozlovski/7853a1c0a73caba81de53f4e36c618f5">my transcript</a>) <a href="#user-content-fnref-29" data-footnote-backref="" aria-label="Back to reference 23">↩</a></p>
</li>
</ol>
</section></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From VS Code to Helix (151 pts)]]></title>
            <link>https://ergaster.org/posts/2025/10/29-vscode-to-helix/</link>
            <guid>45746478</guid>
            <pubDate>Wed, 29 Oct 2025 13:19:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ergaster.org/posts/2025/10/29-vscode-to-helix/">https://ergaster.org/posts/2025/10/29-vscode-to-helix/</a>, See on <a href="https://news.ycombinator.com/item?id=45746478">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-2q5oecfc=""> <nav><ol><li><a href="#automation-is-a-double-edged-sword">Automation is a double-edged sword</a></li><li><a href="#why-i-feared-using-helix">Why I feared using Helix</a></li><li><a href="#what-helped">What Helped</a><ol><li><a href="#just-do-it">Just Do It</a></li><li><a href="#better-docs">Better docs</a></li></ol></li><li><a href="#getting-the-most-of-markdown-and-astro-in-helix">Getting the most of Markdown and Astro in Helix</a><ol><li><a href="#markdown">Markdown</a></li><li><a href="#astro">Astro</a></li><li><a href="#yaml">YAML</a></li></ol></li><li><a href="#is-it-worth-it">Is it worth it?</a></li></ol></nav><p>I created the website you’re reading with VS Code. Behind the scenes I use Astro, a static site generator that gets out of the way while providing nice conveniences.</p>
<p>Using VS Code was a no-brainer: everyone in the industry seems to at least be familiar with it, every project can be opened with it, and most projects can get enhancements and syntactic helpers in a few clicks. In short: VS Code is free, easy to use, and widely adopted.</p>
<p>A Rustacean colleague kept singing <a href="https://helix-editor.com/">Helix</a>’s praises. I discarded it because he’s much smarter than I am, and I only ever use vim when I need to fiddle with files on a server. I like when things “Just Work” and didn’t want to bother learning how to use Helix nor how to configure it.</p>
<p>Today it has become my daily driver. Why did I change my mind? What was preventing me from using it before? And how difficult was it to get there?</p>
<h2 id="automation-is-a-double-edged-sword"><a href="#automation-is-a-double-edged-sword">Automation is a double-edged sword</a></h2>
<p>Automation and technology make work easier, this is why we produce technology in the first place. But it also means you grow more dependent on the tech you use. If the tech is produced transparently by an international team or a team you trust, it’s fine. But if it’s produced by a single large entity that can screw you over, it’s dangerous.</p>
<p>VS Code might be open source, but in practice it’s produced by Microsoft. Microsoft has a problematic relationship to consent and is shoving AI products down everyone’s throat. I’d rather use tools that respect me and my decisions, and I’d rather not get my tools produced by already monopolistic organizations.</p>
<p>Microsoft is also based in the USA, and the political climate over there makes me want to depend as little as possible on American tools. I know that’s a long, uphill battle, but we have to start somewhere.</p>
<p>I’m not advocating for a ban against American tech in general, but for more balance in our supply chain. I’m also not advocating for European tech either: I’d rather get open source tools from international teams competing in a race to the top, rather than from teams in a single jurisdiction. What is happening in the USA could happen in Europe too.</p>
<h2 id="why-i-feared-using-helix"><a href="#why-i-feared-using-helix">Why I feared using Helix</a></h2>
<p>I’ve never found vim particularly pleasant to use but it’s everywhere, so I figured I might just get used to it. But one of the things I never liked about vim is the number of moving pieces. By default, vim and neovim are very bare bones. They can be extended and completely modified with plugins, but I really don’t like the idea of having extremely customize tools.</p>
<p>I’d rather have the same editor as everyone else, with a few knobs for minor preferences. I am subject to choice paralysis, so making me configure an editor before I’ve even started editing is the best way to tank my productivity.</p>
<p>When my colleague told me about Helix, two things struck me as improvements over vim.</p>
<ol>
<li><strong>Helix’s philosophy is that everything should work out of the box.</strong> There are a few configs and themes, but everything should work similarly from one Helix to another. All the language-specific logic is handled in Language Servers that implement the <a href="https://en.wikipedia.org/wiki/Language_Server_Protocol">Language Server Protocol</a> standard.</li>
<li><strong>In Helix, first you select text, and then you perform operations onto it.</strong> So you can visually tell what is going to be changed before you apply the change. It fits my mental model much better.</li>
</ol>
<p>But there are major drawbacks to Helix too:</p>
<ol>
<li><strong>After decades of vim, I was scared to re-learn everything.</strong> In practice this wasn’t a problem at all because of the very visual way Helix works.</li>
<li><strong>VS Code “Just Works”, and Helix sounded like more work than the few clicks from VS Code’s extension store.</strong> This is true, but not as bad as I had anticipated.</li>
</ol>
<p>After a single week of usage, Helix was already very comfortable to navigate. After a few weeks, most of the wrinkles have been ironed out and I use it as my primary editor. So how did I overcome those fears?</p>
<h2 id="what-helped"><a href="#what-helped">What Helped</a></h2>
<h3 id="just-do-it"><a href="#just-do-it">Just Do It</a></h3>
<p><strong>I tried Helix.</strong> It can sound silly, but the very first step to get into Helix was not to overthink it. I just installed it on my mac with <code>brew install helix</code> and gave it a go. I was not too familiar with it, so I looked up <a href="https://docs.helix-editor.com/usage.html">the official documentation</a> and noticed there was a tutorial.</p>
<p>This tutorial alone is what convinced me to try harder. It’s an interactive and well written way to learn how to move and perform basic operations in Helix. I quickly learned how to move around, select things, surround them with braces or parenthesis. I could <em>see</em> what I was about to do before doing it. This has been epiphany. Helix just worked the way I wanted.</p>
<p><img alt="A screenshot of the Helix tutorial open in a terminal. It mostly consists of text in a 80 character wide column. As the user reads the text, they learn new commands to move around and edit text." loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1520px) 1520px, 100vw" data-astro-image="constrained" width="1520" height="1044" src="https://ergaster.org/_astro/helix-tutor.ke2dVx7w_WV66I.webp" srcset="https://ergaster.org/_astro/helix-tutor.ke2dVx7w_1YfIWi.webp 640w, https://ergaster.org/_astro/helix-tutor.ke2dVx7w_Z1tbanv.webp 750w, https://ergaster.org/_astro/helix-tutor.ke2dVx7w_ZUIAxz.webp 828w, https://ergaster.org/_astro/helix-tutor.ke2dVx7w_1n4RrQ.webp 1080w, https://ergaster.org/_astro/helix-tutor.ke2dVx7w_1WMsvp.webp 1280w, https://ergaster.org/_astro/helix-tutor.ke2dVx7w_WV66I.webp 1520w"></p>
<p>Better: I could get things done faster than in VS Code after a few minutes of learning. Being a lazy person, I never bothered looking up VS Code shortcuts. Because the learning curve for Helix is slightly steeper, you <em>have</em> to learn those shortcuts that make moving around feel so easy.</p>
<p>Not only did I quickly get used to Helix key bindings: my vim muscle-memory didn’t get in the way at all!</p>
<h3 id="better-docs"><a href="#better-docs">Better docs</a></h3>
<p>The built-in tutorial is a very pragmatic way to get started. You get results fast, you learn hands on, and it’s not that long. But if you want to go further, you have to look for docs. Helix <a href="https://docs.helix-editor.com/">has officials docs</a>. They seem to be fairly complete, but they’re also impenetrable as a new user. They focus on what the editor supports and not on what I will want to do with it.</p>
<p>After a bit of browsing online, I’ve stumbled upon <a href="https://helix-nikita-revencos-projects.vercel.app/start-here/basics">this third-party documentation website</a>. The domain didn’t inspire me a lot of confidence, but the docs are really good. They are clearly laid out, use-case oriented, and they make the most of Astro Starlight to provide a great reading experience. The author <a href="https://github.com/helix-editor/helix/pull/12127#issuecomment-2525902615">tried to upstream these docs, but that won’t happen</a>. It looks like they are upstreaming their docs to the current website. I hope this will improve the quality of upstream docs eventually.</p>
<p>After learning the basics and finding my way through the docs, it was time to ensure Helix was set up to help me where I needed it most.</p>
<h2 id="getting-the-most-of-markdown-and-astro-in-helix"><a href="#getting-the-most-of-markdown-and-astro-in-helix">Getting the most of Markdown and Astro in Helix</a></h2>
<p>In my free time, I mostly use my editor for three things:</p>
<ol>
<li>Write notes in markdown</li>
<li>Tweak my website with Astro</li>
<li>Edit yaml to faff around my Kubernetes cluster</li>
</ol>
<p>Helix is a “stupid” text editor. It doesn’t know much about what you’re typing. But it supports Language Servers that implement the Language Server Protocol. Language Servers understand the document you’re editing. They explain to Helix what you’re editing, whether you’re in a TypeScript function, typing a markdown link, etc. With that information, Helix and the Language Server can provide code completion hints, errors &amp; warnings, and easier navigation in your code.</p>
<p>In addition to Language Servers, Helix also supports plugging code formatters. Those are pieces of software that will read the document and ensure that it is consistently formatted. It will check that all indentations use spaces and not tabs, that there is a consistent number of space when indenting, that brackets are on the same line as the function, etc. In short: it will make the code pretty.</p>
<h3 id="markdown"><a href="#markdown">Markdown</a></h3>
<p>Markdown is not really a programming language, so it might seem surprising to configure a Language Server for it. But if you remember what we said earlier, Language Servers can provide code completion, which is useful when creating links for example. <a href="https://github.com/artempyanykh/marksman">Marksman</a> does exactly that!</p>
<p>Since Helix <a href="https://docs.helix-editor.com/lang-support.html">is pre-configured to use marksman for markdown files</a> we only need to install marksman and make sure it’s in our <code>PATH</code>. Installing it with homebrew is enough.</p>

<p>We can check that Helix is happy with it with the following command</p>
<div><figure><pre data-language="console"><code><div><p><span>$ hx --health markdown</span></p></div><div><p><span>Configured language servers:</span></p></div><div><p><span><span>  </span></span><span>✓ marksman: /opt/homebrew/bin/marksman</span></p></div><div><p><span>Configured debug adapter: None</span></p></div><div><p><span>Configured formatter: None</span></p></div><div><p><span>Tree-sitter parser: ✓</span></p></div><div><p><span>Highlight queries: ✓</span></p></div><div><p><span>Textobject queries: ✘</span></p></div><div><p><span>Indent queries: ✘</span></p></div></code></pre></figure></div>
<p>But Language Servers can also help Helix display errors and warnings, and “code suggestions” to help fix the issues. It means Language Servers are a perfect fit for… grammar checkers! Several grammar checkers exist. The most notable are:</p>
<ul>
<li><a href="https://ltex-plus.github.io/ltex-plus/">LTEX+</a>, the Language Server used by <a href="https://languagetool.org/">Language Tool</a>. It supports several languages must is quite resource hungry.</li>
<li><a href="https://writewithharper.com/">Harper</a>, a grammar checker Language Server developed by Automattic, the people behind WordPress, Tumblr, WooCommerce, Beeper and more. Harper only support English and its variants, but they intend to support more languages in the future.</li>
</ul>
<p>I mostly write in English and want to keep a minimalistic setup. Automattic is well funded, and I’m confident they will keep working on Harper to improve it. Since grammar checker LSPs can easily be changed, I’ve decided to go with Harper for now.</p>
<p><img alt="A screenshot of Helix. The cursors is on the word &quot;place&quot; with a typo. The word is underlined. On the top right there is a warning message asking if the user intended to write the word like this." loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1520px) 1520px, 100vw" data-astro-image="constrained" width="1520" height="1044" src="https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_25IkSu.webp" srcset="https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_VCrV1.webp 640w, https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_Z2hdkPy.webp 750w, https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_u8pfW.webp 828w, https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_q8NWf.webp 1080w, https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_ZtntcY.webp 1280w, https://ergaster.org/_astro/helix-grammar-error.QcORNFVo_25IkSu.webp 1520w"></p>
<p>To install it, homebrew does the job as always:</p>

<p>Then I edited my <code>~/.config/helix/languages.toml</code> to add Harper as a secondary Language Server in addition to marksman</p>
<div><figure><pre data-language="toml"><code><div><p><span>[</span><span>language-server</span><span>.</span><span>harper-ls</span><span>]</span></p></div><div><p><span>command = </span><span>"harper-ls"</span></p></div><div><p><span>args = [</span><span>"--stdio"</span><span>]</span></p></div><div><p><span>[[</span><span>language</span><span>]]</span></p></div><div><p><span>name = </span><span>"markdown"</span></p></div><div><p><span>language-servers = [</span><span>"marksman"</span><span>, </span><span>"harper-ls"</span><span>]</span></p></div></code></pre></figure></div>
<p>Finally I can add a markdown linter to ensure my markdown is formatted properly. Several options exist, and <a href="https://github.com/DavidAnson/markdownlint">markdownlint</a> is one of the most popular. My colleagues recommended the new kid on the block, a <em>Blazing Fast</em> equivalent: <a href="https://github.com/rvben/rumdl">rumdl</a>.</p>
<p>Installing rumdl was pretty simple on my mac. I only had to add the repository of the maintainer, and install rumdl from it.</p>
<div><figure><pre data-language="console"><code><div><p><span>$ brew tap rvben/rumdl</span></p></div><div><p><span>$ brew install rumdl</span></p></div></code></pre></figure></div>
<p>After that I added a new <code>language-server</code> to my <code>~/.config/helix/languages.toml</code> and added it to the language servers to use for the markdown <code>language</code>.</p>
<div><figure><pre data-language="toml"><code><div><p><span>[</span><span>language-server</span><span>.</span><span>rumdl</span><span>]</span></p></div><div><p><span>command = </span><span>"rumdl"</span></p></div><div><p><span>args = [</span><span>"server"</span><span>]</span></p></div><div><p><span>[...]</span></p></div><div><p><span>[[</span><span>language</span><span>]]</span></p></div><div><p><span>name = </span><span>"markdown"</span></p></div><div><p><span>language-servers = [</span><span>"marksman"</span><span>, </span><span>"harper-ls"</span><span>, </span><span>"rumdl"</span><span>]</span></p></div><div><p><span>soft-wrap.enable = </span><span>true</span></p></div><div><p><span>text-width = </span><span>80</span></p></div><div><p><span>soft-wrap.wrap-at-text-width = </span><span>true</span></p></div></code></pre></figure></div>
<p>Since my website already contained a <code>.markdownlint.yaml</code> I could import it to the rumdl format with</p>
<div><figure><pre data-language="console"><code><div><p><span>$ rumdl import .markdownlint.yaml</span></p></div><div><p><span>Converted markdownlint config from '.markdownlint.yaml' to '.rumdl.toml'</span></p></div><div><p><span>You can now use: rumdl check --config .rumdl.toml .</span></p></div></code></pre></figure></div>
<p>You might have noticed that I’ve added a little quality of life improvement: soft-wrap at 80 characters.</p>
<p>Now if you add this to your own <code>config.toml</code> you will notice that the text is completely left aligned. This is not a problem on small screens, but it rapidly gets annoying on wider screens.</p>
<p>Helix doesn’t support centering the editor. There is <a href="https://github.com/helix-editor/helix/pull/9838">a PR tackling the problem</a> but it has been stale for most of the year. The maintainers are overwhelmed by the number of PRs making it their way, and it’s not clear if or when this PR will be merged.</p>
<p>In the meantime, a workaround exists, with a few caveats. It is possible to add spaces to the left gutter (the column with the line numbers) so it pushes the content towards the center of the screen.</p>
<p><img alt="A screenshot of Helix editing markdown. The column is 80 character wide and centered in the screen." loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 3408px) 3408px, 100vw" data-astro-image="constrained" width="3408" height="2110" src="https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_1tEuBf.webp" srcset="https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_dgVBO.webp 640w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_1AMJeD.webp 750w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_Z17PUS3.webp 828w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_1iPz5z.webp 1080w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_1q994v.webp 1280w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_Z1SYODT.webp 1668w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_1D8XxE.webp 2048w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_Z2fWAsQ.webp 2560w, https://ergaster.org/_astro/helix-zen-mode.Aup4KvDq_1tEuBf.webp 3408w"></p>
<p>To figure out how many spaces are needed, you need to get your terminal width with <code>stty</code></p>

<p>In my case, when in full screen, my terminal is 243 characters wide. I need to remove the content column with from it, and divide everything by 2 to get the space needed on each side. In my case for a 243 character wide terminal with a text width of 80 characters:</p>

<p>As is, I would add 203 spaces to my left gutter to push the rest of the gutter and the content to the right. But the gutter itself has a width of 4 characters, that I need to remove from the total. So I need to subtract them from the total, which leaves me with <code>76</code> characters to add.</p>
<p>I can open my <code>~/.config/helix/config.toml</code> to add a new key binding that will automatically add or remove those spaces from the left gutter when needed, to shift the content towards the center.</p>
<div><figure><pre data-language="toml"><code><div><p><span>[</span><span>keys</span><span>.</span><span>normal</span><span>.</span><span>space</span><span>.</span><span>t</span><span>]</span></p></div><div><p><span>z = </span><span>":toggle gutters.line-numbers.min-width 76 3"</span></p></div></code></pre></figure></div>
<p>Now when in normal mode, pressing <kbd>Space</kbd> then <kbd>t</kbd> then <kbd>z</kbd> will add/remove the spaces. Of course this workaround only works when the terminal runs in full screen mode.</p>
<h3 id="astro"><a href="#astro">Astro</a></h3>
<p>Astro works like a charm in VS Code. The team behind it provides <a href="https://github.com/withastro/language-tools?tab=readme-ov-file#astrojslanguage-server">a Language Server</a> and a <a href="https://github.com/withastro/language-tools?tab=readme-ov-file#astrojsts-plugin">TypeScript plugin</a> to enable code completion and syntax highlighting.</p>
<p>I only had to install those globally with</p>
<div><figure><pre data-language="console"><code><div><p><span>$ pnpm install -g @astrojs/language-server typescript @astrojs/ts-plugin</span></p></div></code></pre></figure></div>
<p>Now we need to add a few lines to our <code>~/.config/helix/languages.toml</code> to tell it how to use the language server</p>
<div><figure><pre data-language="toml"><code><div><p><span>[</span><span>language-server</span><span>.</span><span>astro-ls</span><span>]</span></p></div><div><p><span>command = </span><span>"astro-ls"</span></p></div><div><p><span>args = [</span><span>"--stdio"</span><span>]</span></p></div><div><p><span>config = { typescript = { tsdk = </span><span>"/Users/thibaultmartin/Library/pnpm/global/5/node_modules/typescript/lib"</span><span> }}</span></p></div><div><p><span>[[</span><span>language</span><span>]]</span></p></div><div><p><span>name = </span><span>"astro"</span></p></div><div><p><span>scope = </span><span>"source.astro"</span></p></div><div><p><span>injection-regex = </span><span>"astro"</span></p></div><div><p><span>file-types = [</span><span>"astro"</span><span>]</span></p></div><div><p><span>language-servers = [</span><span>"astro-ls"</span><span>]</span></p></div></code></pre></figure></div>
<p>We can check that the Astro Language Server can be used by helix with</p>
<div><figure><pre data-language="console"><code><div><p><span>$ hx --health astro</span></p></div><div><p><span>Configured language servers:</span></p></div><div><p><span><span>  </span></span><span>✓ astro-ls: /Users/thibaultmartin/Library/pnpm/astro-ls</span></p></div><div><p><span>Configured debug adapter: None</span></p></div><div><p><span>Configured formatter: None</span></p></div><div><p><span>Tree-sitter parser: ✓</span></p></div><div><p><span>Highlight queries: ✓</span></p></div><div><p><span>Textobject queries: ✘</span></p></div><div><p><span>Indent queries: ✘</span></p></div></code></pre></figure></div>
<p>I also like to get a formatter to automatically make my code consistent and pretty for me when I save a file. One of the most popular code formaters out there is <a href="https://prettier.io/">Prettier</a>. I’ve decided to go with the fast and easy formatter <a href="https://dprint.dev/">dprint</a> instead.</p>
<p>I installed it with</p>

<p>Then in the projects I want to use dprint in, I do</p>

<p>I might edit the <code>dprint.json</code> file to my liking. Finally, I configure Helix to use dprint globally for all Astro projects by appending a few lines in my <code>~/.config/helix/languages.toml</code>.</p>
<div><figure><pre data-language="toml"><code><div><p><span>[[</span><span>language</span><span>]]</span></p></div><div><p><span>name = </span><span>"astro"</span></p></div><div><p><span>scope = </span><span>"source.astro"</span></p></div><div><p><span>injection-regex = </span><span>"astro"</span></p></div><div><p><span>file-types = [</span><span>"astro"</span><span>]</span></p></div><div><p><span>language-servers = [</span><span>"astro-ls"</span><span>]</span></p></div><div><p><span>formatter = { command = </span><span>"dprint"</span><span>, args = [</span><span>"fmt"</span><span>, </span><span>"--stdin"</span><span>, </span><span>"astro"</span><span>]}</span></p></div><div><p><span>auto-format = </span><span>true</span></p></div></code></pre></figure></div>
<p>One final check, and I can see that Helix is ready to use the formatter as well</p>
<div><figure><pre data-language="console"><code><div><p><span>$ hx --health astro</span></p></div><div><p><span>Configured language servers:</span></p></div><div><p><span><span>  </span></span><span>✓ astro-ls: /Users/thibaultmartin/Library/pnpm/astro-ls</span></p></div><div><p><span>Configured debug adapter: None</span></p></div><div><p><span>Configured formatter:</span></p></div><div><p><span><span>  </span></span><span>✓ /opt/homebrew/bin/dprint</span></p></div><div><p><span>Tree-sitter parser: ✓</span></p></div><div><p><span>Highlight queries: ✓</span></p></div><div><p><span>Textobject queries: ✘</span></p></div><div><p><span>Indent queries: ✘</span></p></div></code></pre></figure></div>
<h3 id="yaml"><a href="#yaml">YAML</a></h3>
<p>For yaml, it’s simple and straightforward: Helix is preconfigured to use <code>yaml-language-server</code> as soon as it’s in the PATH. I just need to install it with</p>
<div><figure><pre data-language="console"><code><div><p><span>$ brew install yaml-language-server</span></p></div></code></pre></figure></div>
<h2 id="is-it-worth-it"><a href="#is-it-worth-it">Is it worth it?</a></h2>
<p><strong>Helix really grew on me. I find it particularly easy and fast to edit code with it.</strong> It takes a tiny bit more work to get the language support than it does in VS Code, but it’s nothing insurmountable. There is a slightly steeper learning curve than for VS Code, but I consider it to be a good thing. It forced me to learn how to move around and edit efficiently, because there is no way to do it inefficiently. Helix remains intuitive once you’ve learned the basics.</p>
<p>I am a GNOME enthusiast, and I adhere to the same principles: <strong>I like when my apps work out of the box, and when I have little to do to configure them.</strong> This is a strong stance that often attracts a vocal opposition. I like products that follow those principles better than those who don’t.</p>
<p>With that said, Helix sometimes feels like it is maintained by one or two people who have a strong vision, but who struggle to onboard more maintainers. As of writing, Helix has more than 350 PRs open. Quite a few bring interesting features, but the maintainers don’t have enough time to review them.</p>
<p>Those 350 PRs mean there is a lot of energy and goodwill around the project. <strong>People are willing to contribute. Right now, all that energy is gated, resulting in frustration</strong> both from the contributors who feel like they’re working in the void, and the maintainers who feel like there at the receiving end of a fire hose.</p>
<p><strong>A solution to make everyone happier without sacrificing the quality of the project would be to work on a Contributor Ladder.</strong> CHAOSS’ Dr Dawn Foster published <a href="https://fastwonderblog.com/2025/08/12/governance-part-3-new-contributors-and-pathways-to-leadership/">a blog post about it</a>, listing interesting resources at the end.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS to bare metal two years later: Answering your questions about leaving AWS (420 pts)]]></title>
            <link>https://oneuptime.com/blog/post/2025-10-29-aws-to-bare-metal-two-years-later/view</link>
            <guid>45745281</guid>
            <pubDate>Wed, 29 Oct 2025 11:14:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oneuptime.com/blog/post/2025-10-29-aws-to-bare-metal-two-years-later/view">https://oneuptime.com/blog/post/2025-10-29-aws-to-bare-metal-two-years-later/view</a>, See on <a href="https://news.ycombinator.com/item?id=45745281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                <p>When we published <a href="https://oneuptime.com/blog/post/2023-10-30-moving-from-aws-to-bare-metal/view">How moving from AWS to Bare-Metal saved us $230,000 /yr.</a> in 2023, the story travelled far beyond our usual readership. The discussion threads on <a href="https://news.ycombinator.com/item?id=38294569" target="_blank" rel="noopener noreferrer">Hacker News</a> and <a href="https://www.reddit.com/r/sysadmin/comments/17y6zbi/moving_from_aws_to_baremetal_saved_us_230000_yr/" target="_blank" rel="noopener noreferrer">Reddit</a> were packed with sharp questions: did we skip Reserved Instances, how do we fail over a single rack, what about the people cost, and when is cloud still the better answer? This follow-up is our long-form reply.</p><p>Over the last twenty-four months we:</p><ul><li>Ran the MicroK8s + Ceph stack in production for 730+ days with 99.993% measured availability.</li><li>Added a second rack in Frankfurt, joined to our primary Paris cage over redundant DWDM, to kill the “single rack” concern.</li><li>Cut average customer-facing latency by 19% thanks to local NVMe and eliminating noisy neighbours.</li><li>Reinvested the savings into buying bare metal AI servers to expand LLM-based alert / incident summarisation and auto code fixes based on log / traces and metrics in OneUptime.</li></ul><p>Below we tackle the recurring themes from the community feedback, complete with the numbers we use internally.</p><h2>$230,000 / yr savings? That is just an engineers salary.</h2><p>In the US, it is. In the rest of the world. That's 2-5x engineers salary. We <em>used</em> to save $230,000 / yr but now the savings have exponentially grown. We now save over $1.2M / yr and we expect this to grow, as we grow as a business.</p><h2>“Why not just buy Savings Plans or Reserved Instances?”</h2><p>We tried. Long answer: the maths still favoured bare metal once we priced everything in. We see a savings of over 76% if you compare our bare metal setup to AWS. </p><p>A few clarifications:</p><ul><li>Savings Plans <strong>do not</strong> reduce S3, egress, or Direct Connect. 37% off instances still leaves you paying list price for bandwidth, which was 22% of our AWS bill.</li><li>EKS had an extra $1,260/month control-plane fee plus $600/month for NAT gateways. Those costs disappear once you run Kubernetes yourself.</li><li>Our workload is 24/7 steady. We were already at &gt;90% reservation coverage; there was no idle burst capacity to “right size” away. If we had the kind of bursty compute profile many commenters referenced, the choice would be different.</li></ul><h2>“How much did migration and ongoing ops really cost?”</h2><p>We spent a week of engineers time (and that is the worst case estimate) on the initial migration, spread across SRE, platform, and database owners. Most of that time was work we needed anyway—formalising infrastructure-as-code, smoke testing charts, tightening backup policies. The incremental work that existed purely <em>because</em> of bare metal was roughly one week.</p><p>Ongoing run-cost looks like this:</p><ul><li><strong>Hands-on keyboard:</strong> ~24 engineer-hours/quarter across the entire platform team, including routine patching and firmware updates. That is comparable to the AWS time we used to burn on cost optimisation, IAM policy churn, and chasing deprecations and updating our VM's on AWS. </li><li><strong>Remote hands:</strong> 2 interventions in 24 months (mainly disks). Mean response time: 27 minutes. We do not staff an on-site team. We rely on co-location provider to physically manage our rack. This means no traditional hardware admins. </li><li><strong>Automation:</strong> We're now moving to Talos. We PXE boot with Tinkerbell, image with Talos, manage configs through Flux and Terraform, and run conformance suites before each Kubernetes upgrade. All of those tools also hardened our AWS estate, so they were not net-new effort.</li></ul><p>The opportunity cost question from is fair. We track it the same way we track feature velocity: did the infra team ship less? The answer was “no”—our release cadence increased because we reclaimed few hours/month we used to spend in AWS “cost council” meetings.</p><h2>“Isn’t a single rack a single point of failure?”</h2><p>We have multiple racks across two different DC / providers. We:</p><ul><li>Leased a secondary quarter rack in Frankfurt with a different provider and power utility.</li><li>Currently: Deployed a second MicroK8s control plane, mirrored Ceph pools with asynchronous replication. Future: We're moving to Talos. Nothing against Microk8s, but we like the Talos way of managing the k8s cluster.</li><li>Added isolated out-of-band management paths (4G / satellite) so we can reach the gear even during metro fibre events.</li></ul><p>The AWS failover cluster we mentioned in 2023 still exists. We rehearse a full cutover quarterly using the same Helm releases we ship to customers. DNS failover remains the slowest leg (resolver caches can ignore TTL), so we added Anycast ingress via BGP with our transit provider to cut traffic shifting to sub-minute.</p><h2>“What about hardware lifecycle and surprise CapEx?”</h2><p>We amortise servers over five years, but we sized them with 2 × AMD EPYC 9654 CPUs, 1 TB RAM, and NVMe sleds. At our current growth rate the boxes will hit CPU saturation before we hit year five. When that happens, the plan is to cascade the older gear into our regional analytics cluster (we use Posthog + Metabase for this) and buy a new batch. Thanks to the savings delta, we can refresh 40% of the fleet every 24 months and still spend less annually than the optimised AWS bill above.</p><p>We also buy extended warranties from the OEM (Supermicro) and keep three cold spares in the cage. The hardware lasts 7-8 years and not 5, but we wtill count it as 5 to be very conservative. </p><h2>“Are you reinventing managed services?”</h2><p>Another strong Reddit critique: why rebuild services AWS already offers? Three reasons we are comfortable with the trade:</p><ol><li><strong>Portability is part of our product promise.</strong> OneUptime customers self-host in their own environments. Running the same open stack we ship (Postgres, Redis, ClickHouse, etc.) keeps us honest. We eun on Kubernetes and self-hosted customers run on Kubernetes as well. </li><li><strong>Tooling maturity.</strong> Two years ago we relied on Terraform + EKS + RDS. Today we run MicroK8s (Talos in the future), Argo Rollouts, OpenTelemetry Collector, and Ceph dashboards. None of that is bespoke. We do not maintain a fork of anything.</li><li><strong>Selective cloud use.</strong> We still pay AWS for Glacier backups, CloudFront for edge caching, and short-lived burst capacity for load tests. Cloud makes sense when elasticity matters; bare metal wins when baseload dominates.</li></ol><p>Managed services are phenomenal when you are short on expertise or need features beyond commodity compute. If we were all-in on DynamoDB streams or Step Functions we would almost certainly still be on AWS.</p><h2>“How do bandwidth and DoS scenarios work now?”</h2><p>We committed to 5 Gbps 95th percentile across two carriers.  The same traffic on AWS egress would be 8x expensive in eu-west-1. For DDoS protection we front our ingress with Cloudflare. </p><h2>“Has reliability suffered?”</h2><p>Short answer: No. Infact it was better than AWS (compared to recent AWS downtimes)</p><p>We have 730+ days with 99.993% measured availability and we also escaped AWS region wide downtime that happened a week ago. </p><h2>“How do audits and compliance work off-cloud now?”</h2><p>We stayed SOC 2 Type II and ISO 27001 certified through the transition. The biggest deltas auditors cared about:</p><ul><li>Physical controls: We provide badge logs from the colo, camera footage on request, and quarterly access reviews. The colo already meets Tier III redundancy, so their reports roll into ours.</li><li>Change management: Terraform plans, and now Talos machine configs give us immutable evidence of change. Auditors liked that more than AWS Console screenshots.</li><li>Business continuity: We prove failover by moving workload to other DC.</li></ul><p>If you are in a regulated space (HIPAA for instance), expect the paperwork to grow a little. We worked it in by leaning on the colo providers’ standard compliance packets—they slotted straight into our risk register.</p><h2>“Why not stay in the cloud but switch providers?”</h2><p>We priced Hetzner, OVH, Leaseweb, Equinix Metal, and AWS Outposts. The short version:</p><ul><li>Hyperscaler alternatives were cheaper on compute but still expensive on egress once you hit petabytes/month. Outposts also carried minimum commits that exceeded our needs.</li><li>European dedicated hosts (Hetzner, OVH) are fantastic for lab clusters. The challenge was multi-100 TB Ceph clusters with redundant uplinks and smart-hands SLAs. Once we priced that tier, the savings narrowed.</li><li>Equinix Metal got the closest, but bare metal on-demand still carried a 25-30% premium over our CapEx plan. Their global footprint is tempting; we may still use them for short-lived expansion.</li></ul><p>Owning the hardware also let us plan power density (we run 15 kW racks) and reuse components. For our steady-state footprint, colocation won by a long shot.</p><h2>“What does day-to-day toil look like now?”</h2><p>We put real numbers to it because Reddit kept us honest:</p><ul><li>Weekly: Kernel and firmware patches (Talos makes this a redeploy), Ceph health checks,  Total time averages 1 hour/week on average over months. </li><li>Monthly: Kubernetes control plane upgrades in canary fashion. About 2 engineer-hours. We expect this to reduce when Talos kicks in.</li><li>Quarterly: Disaster recovery drills, capacity planning, and contract audits with carriers. Roughly 12 hours across three engineers.</li></ul><p>Total toil is ~14 engineer-hours/month, including prep. The AWS era had us spending similar time but on different work: chasing cost anomalies, expanding Security Hub exceptions, and mapping breaking changes in managed services. The toil moved; it did not multiply.</p><h2>“Do you still use the cloud for anything substantial?”</h2><p>Absolutely. Cloud still solves problems we would rather not own:</p><ul><li>Glacier keeps long-term log archives at a price point local object storage cannot match.</li><li>CloudFront handles 14 edge PoPs we do not want to build. We terminate TLS at the edge for marketing assets and docs. We will soon move this to Cloudflare as they are cheaper.</li><li>We spin up short-lived AWS environments for load testing.</li></ul><p>So yes, we left AWS for the base workload, but we still swipe the corporate card when elasticity or geography outweighs fixed-cost savings.</p><h2>When the cloud is still the right answer</h2><p><strong>It depends on your workload</strong>. We still recommend staying put if:</p><ul><li>Your usage pattern is spiky or seasonal and you can auto-scale to near zero between peaks.</li><li>You lean heavily on managed services (Aurora Serverless, Kinesis, Step Functions) where the operational load is the value prop.</li><li>You do not have the appetite to build a platform team comfortable with Kubernetes, Ceph, observability, and incident response.</li></ul><p>Cloud-first was the right call for our first five years. Bare metal became the right call once our compute footprint, data gravity, and independence requirements stabilised.</p><h2>What is next</h2><ul><li>We are working on a detailed runbook + Terraform module to help teams do <em>capex forecasting</em> for colo moves. Expect that on the blog later this year.</li><li>A deep dive on Talos is in the queue, as requested by multiple folks in the HN thread.</li></ul><p>Questions we did not cover? Let us know in the discussion threads—we are happy to keep sharing the gritty details.</p><p><strong>Related Reading:</strong></p>                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Aggressive bots ruined my weekend (159 pts)]]></title>
            <link>https://herman.bearblog.dev/agressive-bots/</link>
            <guid>45745072</guid>
            <pubDate>Wed, 29 Oct 2025 10:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://herman.bearblog.dev/agressive-bots/">https://herman.bearblog.dev/agressive-bots/</a>, See on <a href="https://news.ycombinator.com/item?id=45745072">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-10-29T09:43Z">
                    29 Oct, 2025
                </time>
            </i>
        </p>
    

    <p>On the 25th of October Bear had its first major outage. Specifically, the reverse proxy which handles custom domains went down, causing custom domains to time out.</p>
<p>Unfortunately my monitoring tool failed to notify me, and it being a Saturday, I didn't notice the outage for longer than is reasonable. I apologise to everyone who was affected by it.</p>
<p>First, I want to dissect the root cause, exactly what went wrong, and then provide the steps I've taken to mitigate this in the future.</p>
<p>I wrote about <a href="https://herman.bearblog.dev/the-great-scrape/">The Great Scrape</a> at the beginning of this year. The vast majority of web traffic is now bots, and it is becoming increasingly more hostile to have publicly available resources on the internet.</p>
<p>There are 3 major kinds of bots currently flooding the internet: AI scrapers, malicious scrapers, and unchecked automations/scrapers.</p>
<p>The first has been discussed at length. Data is <em>worth something</em> now that it is used as fodder to train LLMs, and there is a financial incentive to scrape, so scrape they will. They've depleted all human-created writing on the internet, and are becoming increasingly ravenous for new wells of content. I've seen this compared to the search for <a href="https://en.wikipedia.org/wiki/Low-background_steel" target="_blank">low-background-radiation steel</a>, which is, itself, very interesting.</p>
<p>These scrapers, however, are the easiest to deal with since they tend to identify themselves as ChatGPT, Anthropic, XAI, et cetera. They also tend to specify whether they are from user-initiated searches (think all the sites that get scraped when you make a request with ChatGPT), or data mining (data used to train models). On Bear Blog I allow the first kinds, but block the second, since bloggers want discoverability, but usually don't want their writing used to train the next big model.</p>
<p>The next two kinds of scraper are more insidious. The malicious scrapers are bots that systematically scrape and re-scrape websites, sometimes every few minutes, looking for vulnerabilities such as misconfigured Wordpress instances, or <code>.env</code> and <code>.aws</code> files, among other things, accidentally left lying around.</p>
<p>It's more dangerous than ever to self-host, since simple mistakes in configurations will likely be found and exploited. In the last 24 hours I've blocked close to 2 million malicious requests across several hundred blogs.</p>
<p>What's wild is that these scrapers rotate through thousands of IP addresses during their scrapes, which leads me to suspect that the requests are being tunnelled through apps on mobile devices, since the ASNs tend to be cellular networks. I'm still speculating here, but I think app developers have found another way to monetise their apps by offering them for free, and selling tunnel access to scrapers.</p>
<p>Now, on to the unchecked automations. Vibe coding has made web-scraping easier than ever. Any script-kiddie can easily build a functional scraper in a single prompt and have it run all day from their home computer, and if the dramatic rise in scraping is anything to go by, many do. Tens of thousands of new scrapers have cropped up over the past few months, accidentally DDoSing website after website in their wake. The average consumer-grade computer is significantly more powerful than a VPS, so these machines can easily cause a lot of damage without noticing.</p>
<p>I've managed to keep all these scrapers at bay using a combination of web application firewall (WAF) rules and rate limiting provided by Cloudflare, as well as some custom code which finds and quarantines bad bots based on their activity.</p>
<p>I've played around with serving <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank">Zip Bombs</a>, which was quite satisfying, but I stopped for fear of accidentally bombing a legitimate user. Another thing I've played around with is Proof of Work validation, making it expensive for bots to scrape, as well as serving endless junk data to keep the bots busy. Both of these are <em>interesting</em>, but ultimately are just as effective as simply blocking those requests, without the increased complexity.</p>
<p>With that context, here's exactly went wrong on Saturday.</p>
<p>Previously, the bottleneck for page requests was the web-server itself, since it does the heavy lifting. It automatically scales horizontally by up to a factor of 10, if necessary, but bot requests can scale by significantly more than that, so having strong bot detection and mitigation, as well as serving highly-requested endpoints via a CDN is necessary. This is a solved problem, as outlined in my Great Scrape post, but worth restating.</p>
<p>On Saturday morning a few hundred blogs were DDoSed, with tens of thousands of pages requested per minute (from the logs it's hard to say whether they were malicious, or just very aggressive scrapers). The above-mentioned mitigations worked as expected, however the reverse-proxy—which sits up-stream of most of these mitigations—became saturated with requests and decided it needed to take a little nap.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman/page-requests.webp" alt="page-requests"></p>
<p><small>The big blue spike is what toppled the server. It's so big it makes the rest of the graph look flat.</small></p>
<p>This server had been running with zero downtime for 5 years up until this point.</p>
<p>Unfortunately my uptime monitor failed to alert me via the push notifications I'd set up, even though it's the only app I have that not only has notifications enabled (see my <a href="https://herman.bearblog.dev/notifications/">post on notifications</a>), but even has critical alerts enabled, so it'll wake me up in the middle of the night if necessary. I still have no idea why this alert didn't come through, and I have ruled out misconfiguration through various tests.</p>
<p>This brings me to how I will prevent this from happening in the future.</p>
<ol>
<li>Redundancy in monitoring. I now have a second monitoring service running alongside my uptime monitor which will give me a phone call, email, and text message in the event of any downtime.</li>
<li>More aggressive rate-limiting and bot mitigation on the reverse proxy. This already reduces the server load by about half.</li>
<li>I've bumped up the size of the reverse proxy, which can now handle about 5 times the load. This is overkill, but compute is cheap, and certainly worth the stress-mitigation. I'm already bald. I don't need to go balder.</li>
<li>Auto-restart the reverse-proxy if bandwidth usage drops to zero for more than 2 minutes.</li>
<li>Added a status page, available at <a href="https://status.bearblog.dev/">https://status.bearblog.dev</a> for better visibility and transparency. Hopefully those bars stay solid green forever.</li>
</ol>
<p>This should be enough to keep everything healthy. If you have any suggestions, or need help with your own bot issues, <a href="https://herman.bearblog.dev/contact/">send me an email</a>.</p>
<p>The public internet is mostly bots, many of whom are bad netizens. It's the most hostile it's ever been, and it is because of this that I feel it's more important than ever to take good care of the spaces that make the internet worth visiting.</p>
<p>The arms race continues...</p>


    

    
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube is taking down videos on performing nonstandard Windows 11 installs (405 pts)]]></title>
            <link>https://old.reddit.com/r/DataHoarder/comments/1oiz0v0/youtube_is_taking_down_videos_on_performing/</link>
            <guid>45744503</guid>
            <pubDate>Wed, 29 Oct 2025 09:26:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/DataHoarder/comments/1oiz0v0/youtube_is_taking_down_videos_on_performing/">https://old.reddit.com/r/DataHoarder/comments/1oiz0v0/youtube_is_taking_down_videos_on_performing/</a>, See on <a href="https://news.ycombinator.com/item?id=45744503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Who are we?</strong></p>

<p>We are digital librarians. Among us are represented the various reasons to keep data -- legal requirements, competitive requirements, uncertainty of permanence of cloud services, distaste for transmitting your data externally (e.g. government or corporate espionage), cultural and familial archivists, internet collapse preppers, and people who do it themselves so they're sure it's done right. Everyone has their reasons for curating the data they have decided to keep (either forever or For A Damn Long Timetm). Along the way we have sought out like-minded individuals to exchange strategies, war stories, and cautionary tales of failures.</p>

<p>We are one. We are legion. And we're trying really hard not to forget.</p>

<p>-- <a href="https://old.reddit.com/u/5-4-3-2-1-bang">/u/5-4-3-2-1-bang</a> from <a href="https://www.reddit.com/r/DataHoarder/comments/41tqt4/hi_guys_can_i_kindly_ask_for_an_eli5_of_this/cz53pi0">this thread</a></p>

<ul>
<li><a href="https://redd.it/6qf716">A Quick DataHoarder FAQ</a></li>
</ul>

<hr>

<p><strong>Links!!</strong></p>

<ul>
<li><p><a href="https://old.reddit.com/r/DataHoarder/comments/1479c7b/historic_reddit_archives_ongoing_archival_effort/">Historic Reddit Archives &amp; Download Tools, Etc.</a></p></li>
<li><p><a href="http://www.reddit.com/r/DataHoarder/wiki/index">We have a wiki, you should check it out!</a></p></li>
<li><p><a href="https://www.reddit.com/r/DataHoarder/wiki/hardware#wiki_reliability">Have questions about hard drive life?</a></p></li>
<li><p><a href="https://www.reddit.com/r/DataHoarder/comments/7g2v9o/33v_pin_reset_directions_d/">3.3v Pin Reset Directions :D</a> / Alt <a href="https://imgur.com/a/BFdmB">Imgur link</a></p></li>
<li><p><a href="https://www.reddit.com/r/DataHoarder/comments/7fx0i0/wd_easystore_8tb_compendium">WD Easystore 8TB Compendium</a></p></li>
<li><p><a href="https://www.reddit.com/r/DataHoarder/comments/b7imx9/youtube_annotation_archive_annotation_data_from">YouTube Annotation Archive</a></p></li>
<li><p><a href="https://discord.gg/the-eye">#datahoarders ~ The-Eye Discord</a></p></li>
<li><p><a href="https://lemmy.ml/c/datahoarder">c/datahoarder ~ lemmy.ml</a></p></li>
<li><p><a href="http://redarc.basedbin.org/r/datahoarder">r/DataHorader 2013-2023 Searchable Archives</a></p></li>
</ul>

<hr>

<p><a href="https://www.reddit.com/r/DataHoarder/about/rules/"><strong>Rule(s)</strong></a></p>

<ol>
<li>Search the Internet, this subreddit and our wiki before posting.</li>
<li>Keep it about datahoarding.</li>
<li>Be excellent to each other.</li>
<li>No memes or <a href="https://redd.it/6mvzkq">'look at this old storage medium</a>/<a href="https://www.reddit.com/r/DataHoarder/comments/5sr5u8/had_fiber_hooked_up_today_the_future_is_now_cant/ddhgd0y/">connection speed</a>/purchase' (except on Free Post Fridays).</li>
<li>Posts must include context/detail.</li>
<li>No unapproved sale threads, advertisement posts, or giveaways. <strong>Companies must get prior approval from mod team before posting.</strong></li>
<li>No cryptocurrency or AI posts.</li>
<li>We are not your personal archival army.</li>
<li><a href="https://old.reddit.com/r/techsupport">r/techsupport</a> exists.</li>
<li>No requests, use <a href="https://old.reddit.com/r/DHExchange">r/DHExchange</a></li>
</ol>

<hr>

<p><strong>Free Post Friday</strong><br>
On Fridays we'll allow posts that don't normally fit in the usual data-hoarding theme, including posts that would usually be removed by rule 4: “No memes or 'look at this [thing]'”<br>
Just make sure to tag the post with the flair [Free-Post Friday!] and give a little background info/context. </p>

<hr>

<p><strong>Related Subreddits</strong><br>
Data Hoarding/Curation:</p>

<ul>
<li><a href="https://old.reddit.com/r/dhexchange">r/dhexchange</a></li>
<li><a href="https://old.reddit.com/r/archiveteam">/r/archiveteam</a><br></li>
<li><a href="https://old.reddit.com/r/Archivists">/r/Archivists</a><br></li>
<li><a href="https://old.reddit.com/r/opendirectories">/r/opendirectories</a><br></li>
<li><a href="https://old.reddit.com/r/MusicHoarder">/r/MusicHoarder</a><br></li>
<li><a href="https://old.reddit.com/r/datacurator">/r/datacurator</a><br></li>
<li><a href="https://old.reddit.com/r/dataengineering">/r/dataengineering</a><br></li>
</ul>

<p>Servers and Homelabs:  </p>

<ul>
<li><a href="https://old.reddit.com/r/homelab">/r/homelab</a><br></li>
<li><a href="https://old.reddit.com/r/HomeServer">/r/HomeServer</a><br></li>
<li><a href="https://old.reddit.com/r/selfhosted">/r/selfhosted</a><br></li>
<li><a href="https://old.reddit.com/r/storage">/r/storage</a><br></li>
</ul>

<p>Tech Support:  </p>

<ul>
<li><a href="https://old.reddit.com/r/datarecovery">/r/datarecovery</a><br></li>
<li><a href="https://old.reddit.com/r/techsupport">/r/techsupport</a><br></li>
<li><a href="https://old.reddit.com/r/sysadmin">/r/sysadmin</a><br></li>
<li><a href="https://old.reddit.com/r/linux">/r/linux</a><br></li>
</ul>

<p>Sales &amp; Marketplace:  </p>

<ul>
<li><a href="https://old.reddit.com/r/homelabsales">/r/homelabsales</a><br></li>
<li><a href="https://old.reddit.com/r/buildapcsales">/r/buildapcsales</a><br></li>
<li><a href="https://old.reddit.com/r/hardwareswap">/r/hardwareswap</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Who needs Graphviz when you can build it yourself? (382 pts)]]></title>
            <link>https://spidermonkey.dev/blog/2025/10/28/iongraph-web.html</link>
            <guid>45742907</guid>
            <pubDate>Wed, 29 Oct 2025 05:17:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spidermonkey.dev/blog/2025/10/28/iongraph-web.html">https://spidermonkey.dev/blog/2025/10/28/iongraph-web.html</a>, See on <a href="https://news.ycombinator.com/item?id=45742907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    



<p>We recently overhauled our internal tools for visualizing the compilation of JavaScript and WebAssembly. When SpiderMonkey’s optimizing compiler, Ion, is active, we can now produce interactive graphs showing exactly how functions are processed and optimized.</p>

<div id="livegraph-available">
  <p>You can play with these graphs right here on this page. Simply write some JavaScript code in the <code>test</code> function and see what graph is produced. You can click and drag to navigate, ctrl-scroll to zoom, and drag the slider at the bottom to scrub through the optimization process.</p>
  <p>As you experiment, take note of how stable the graph layout is, even as the sizes of blocks change or new structures are added. Try clicking a block's title to select it, then drag the slider and watch the graph change while the block remains in place. Or, click an instruction's number to highlight it so you can keep an eye on it across passes.</p>
</div>



<p><img id="livegraph-preview" alt="Example iongraph output" src="https://spidermonkey.dev/assets/img/iongraph-preview.png"></p>



<p>We are not the first to visualize our compiler’s internal graphs, of course, nor the first to make them interactive. But I was not satisfied with the output of common tools like <a href="https://graphviz.org/">Graphviz</a> or <a href="https://mermaid.js.org/">Mermaid</a>, so I decided to create a layout algorithm specifically tailored to our needs. The resulting algorithm is simple, fast, produces surprisingly high-quality output, and can be implemented in less than a thousand lines of code. The purpose of this article is to walk you through this algorithm and the design concepts behind it.</p>

<p><i>Read this post on desktop to see an interactive demo of iongraph.</i></p>

<h2 id="background">Background</h2>

<p>As readers of this blog already know, SpiderMonkey has several tiers of execution for JavaScript and WebAssembly code. The highest tier is known as Ion, an optimizing SSA compiler that takes the most time to compile but produces the highest-quality output.</p>

<p>Working with Ion frequently requires us to visualize and debug the SSA graph. Since 2011 we have used a tool for this purpose called <a href="https://github.com/sstangl/iongraph">iongraph</a>, built by Sean Stangl. It is a simple Python script that takes a JSON dump of our compiler graphs and uses Graphviz to produce a PDF. It is perfectly adequate, and very much the status quo for compiler authors, but unfortunately the Graphviz output has many problems that make our work tedious and frustrating.</p>

<p>The first problem is that the Graphviz output rarely bears any resemblance to the source code that produced it. Graphviz will place nodes wherever it feels will minimize error, resulting in a graph that snakes left and right seemingly at random. There is no visual intuition for how deeply nested a block of code is, nor is it easy to determine which blocks are inside or outside of loops. Consider the following function, and its Graphviz graph:</p>

<div><pre><code><span>function</span> <span>foo</span><span>(</span><span>n</span><span>)</span> <span>{</span>
  <span>let</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!!</span><span>(</span><span>i</span> <span>%</span> <span>2</span><span>))</span> <span>{</span>
      <span>result</span> <span>=</span> <span>0x600DBEEF</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>result</span> <span>=</span> <span>0xBADBEEF</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://spidermonkey.dev/assets/img/iongraph-example1-orig.svg">
</p>

<p>Counterintuitively, the <code>return</code> appears <em>before</em> the two assignments in the body of the loop. Since this graph mirrors JavaScript control flow, we’d expect to see the return at the bottom. This problem only gets worse as graphs grow larger and more complex.</p>

<p>The second, related problem is that Graphviz’s output is unstable. Small changes to the input can result in large changes to the output. As you page through the graphs of each pass within Ion, nodes will jump left and right, true and false branches will swap, loops will run up the right side instead of the left, and so on. This makes it very hard to understand the actual effect of any given pass. Consider the following before and after, and notice how the second graph is almost—but not quite—a mirror image of the first, despite very minimal changes to the graph’s structure:</p>

<div>
  <p><img src="https://spidermonkey.dev/assets/img/iongraph-example2-before.svg">
    <img src="https://spidermonkey.dev/assets/img/iongraph-example2-after.svg">
  </p>
</div>

<p>None of this felt right to me. Control flow graphs should be able to follow the structure of the program that produced them. After all, a control flow graph has many restrictions that a general-purpose tool would not be aware of: they have very few cycles, all of which are well-defined because they come from loops; furthermore, both JavaScript and WebAssembly have reducible control flow, meaning all loops have only one entry, and it is not possible to jump directly into the middle of a loop. This information could be used to our advantage.</p>

<p>Beyond that, a static PDF is far from ideal when exploring complicated graphs. Finding the inputs or uses of a given instruction is a tedious and frustrating exercise, as is following arrows from block to block. Even just zooming in and out is difficult. I eventually concluded that we ought to just build an interactive tool to overcome these limitations.</p>

<h2 id="how-hard-could-layout-be">How hard could layout be?</h2>

<p>I had one false start with graph layout, with an algorithm that attempted to sort blocks into vertical “tracks”. This broke down quickly on a variety of programs and I was forced to go back to the drawing board—in fact, back to the source of the very tool I was trying to replace.</p>

<p>The algorithm used by <code>dot</code>, the typical hierarchical layout mode for Graphviz, is known as the Sugiyama layout algorithm, from a 1981 paper by Sugiyama et al. As introduction, I found a short series of <a href="https://www.youtube.com/watch?v=3_FbSCWLC3A&amp;list=PLubYOWSl9mIvoXDwf_Wqcrvlg15N_AWQE&amp;index=38">lectures</a> that broke down the Sugiyama algorithm into 5 steps:</p>

<ol>
  <li><strong>Cycle breaking</strong>, where the direction of some edges are flipped in order to produce a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>.</li>
  <li><strong>Leveling</strong>, where vertices are assigned into horizontal layers according to their depth in the graph, and dummy vertices are added to any edge that crosses multiple layers.</li>
  <li><strong>Crossing minimization</strong>, where vertices on a layer are reordered in order to minimize the number of edge crossings.</li>
  <li><strong>Vertex positioning</strong>, where vertices are horizontally positioned in order to make the edges as straight as possible.</li>
  <li><strong>Drawing</strong>, where the final graph is rendered to the screen.</li>
</ol>

<p><img src="https://spidermonkey.dev/assets/img/kindermann.png" alt="A screenshot from the lectures, showing the five steps above"></p>

<p>These steps struck me as surprisingly straightforward, and provided useful opportunities to insert our own knowledge of the problem:</p>

<ul>
  <li>Cycle breaking would be trivial for us, since the only cycles in our data are loops, and loop backedges are explicitly labeled. We could simply ignore backedges when laying out the graph.</li>
  <li>Leveling would be straightforward, and could easily be modified to better mimic the source code. Specifically, any blocks coming after a loop in the source code could be artificially pushed down in the layout, solving the confusing early-exit problem.</li>
  <li>Permuting vertices to reduce edge crossings was actually just a bad idea, since our goal was stability from graph to graph. The true and false branches of a condition should always appear in the same order, for example, and a few edge crossings is a small price to pay for this stability.</li>
  <li>Since reducible control flow ensures that a program’s loops form a tree, vertex positioning could ensure that loops are always well-nested in the final graph.</li>
</ul>

<p>Taken all together, these simplifications resulted in a remarkably straightforward algorithm, with the <a href="https://github.com/mozilla-spidermonkey/iongraph/blob/fc27ee3e8f3bd3c020aaf2498de9a260da089bc1/src/Graph.ts">initial implementation</a> being just 1000 lines of JavaScript. (See this <a href="https://x.com/its_bvisness/status/1957565307809329465?s=46">demo</a> for what it looked like at the time.) It also proved to be very efficient, since it avoided the most computationally complex parts of the Sugiyama algorithm.</p>

<h2 id="iongraph-from-start-to-finish">iongraph from start to finish</h2>

<p>We will now go through the entire iongraph layout algorithm. Each section contains explanatory diagrams, in which rectangles are basic blocks and circles are dummy nodes. Loop header blocks (the single entry point to each loop) are additionally colored green.</p>

<p>Be aware that the block positions in these diagrams are not representative of the actual computed layout position at each point in the process. For example, vertical positions are not calculated until the very end, but it would be hard to communicate what the algorithm was doing if all blocks were drawn on a single line!</p>

<h3 id="step-1-layering">Step 1: Layering</h3>

<p>We first sort the basic blocks into horizontal tracks called “layers”. This is very simple; we just start at layer 0 and recursively walk the graph, incrementing the layer number as we go. As we go, we track the “height” of each loop, not in pixels, but in layers.</p>

<p>We also take this opportunity to vertically position nodes “inside” and “outside” of loops. Whenever we see an edge that exits a loop, we defer the layering of the destination block until we are done layering the loop contents, at which point we know the loop’s height.</p>

<p>A note on implementation: nodes are visited multiple times throughout the process, not just once. This can produce a quadratic explosion for large graphs, but I find that an early-out is sufficient to avoid this problem in practice.</p>

<p>The animation below shows the layering algorithm in action. Notice how the final block in the graph is visited twice, once after each loop that branches to it, and in each case, the block is deferred until the entire loop has been layered, rather than processed immediately after its predecessor block. The final position of the block is below the entirety of both loops, rather than directly below one of its predecessors as Graphviz would do. (Remember, horizontal and vertical positions have not yet been computed; the positions of the blocks in this diagram are hardcoded for demonstration purposes.)</p>

<details>
<summary>Implementation pseudocode</summary>

</details>

<div><pre><code><span>/*CODEBLOCK=layering*/</span><span>function</span> <span>layerBlock</span><span>(</span><span>block</span><span>,</span> <span>layer</span> <span>=</span> <span>0</span><span>)</span> <span>{</span>
  <span>// Omitted for clarity: special handling of our "backedge blocks"</span>

  <span>// Early out if the block would not be updated</span>
  <span>if</span> <span>(</span><span>layer</span> <span>&lt;=</span> <span>block</span><span>.</span><span>layer</span><span>)</span> <span>{</span>
    <span>return</span><span>;</span>
  <span>}</span>

  <span>// Update the layer of the current block</span>
  <span>block</span><span>.</span><span>layer</span> <span>=</span> <span>Math</span><span>.</span><span>max</span><span>(</span><span>block</span><span>.</span><span>layer</span><span>,</span> <span>layer</span><span>);</span>

  <span>// Update the heights of all loops containing the current block</span>
  <span>let</span> <span>header</span> <span>=</span> <span>block</span><span>.</span><span>loopHeader</span><span>;</span>
  <span>while</span> <span>(</span><span>header</span><span>)</span> <span>{</span>
    <span>header</span><span>.</span><span>loopHeight</span> <span>=</span> <span>Math</span><span>.</span><span>max</span><span>(</span><span>header</span><span>.</span><span>loopHeight</span><span>,</span> <span>block</span><span>.</span><span>layer</span> <span>-</span> <span>header</span><span>.</span><span>layer</span> <span>+</span> <span>1</span><span>);</span>
    <span>header</span> <span>=</span> <span>header</span><span>.</span><span>parentLoopHeader</span><span>;</span>
  <span>}</span>

  <span>// Recursively layer successors</span>
  <span>for</span> <span>(</span><span>const</span> <span>succ</span> <span>of</span> <span>block</span><span>.</span><span>successors</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>succ</span><span>.</span><span>loopDepth</span> <span>&lt;</span> <span>block</span><span>.</span><span>loopDepth</span><span>)</span> <span>{</span>
      <span>// Outgoing edges from the current loop will be layered later</span>
      <span>block</span><span>.</span><span>loopHeader</span><span>.</span><span>outgoingEdges</span><span>.</span><span>push</span><span>(</span><span>succ</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>layerBlock</span><span>(</span><span>succ</span><span>,</span> <span>layer</span> <span>+</span> <span>1</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>// Layer any outgoing edges only after the contents of the loop have</span>
  <span>// been processed</span>
  <span>if</span> <span>(</span><span>block</span><span>.</span><span>isLoopHeader</span><span>())</span> <span>{</span>
    <span>for</span> <span>(</span><span>const</span> <span>succ</span> <span>of</span> <span>block</span><span>.</span><span>outgoingEdges</span><span>)</span> <span>{</span>
      <span>layerBlock</span><span>(</span><span>succ</span><span>,</span> <span>layer</span> <span>+</span> <span>block</span><span>.</span><span>loopHeight</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div>







<h3 id="step-2-create-dummy-nodes">Step 2: Create dummy nodes</h3>

<p>Any time an edge crosses a layer, we create a dummy node. This allows edges to be routed across layers without overlapping any blocks. Unlike in traditional Sugiyama, we always put downward dummies on the left and upward dummies on the right, producing a consistent “counter-clockwise” flow. This also makes it easy to read long vertical edges, whose direction would otherwise be ambiguous. (Recall how the loop backedge flipped from the right to the left in the “unstable layout” Graphviz example from before.)</p>

<p>In addition, we coalesce any edges that are going to the same destination by merging their dummy nodes. This heavily reduces visual noise.</p>

<!--
Interesting program:

function test(n) {
  let result = 0;
  early:
  for (let i = n; i >= -10; i--) {
    if (i > 0) {
      switch (i % 3) {
        case 0:
          result += 1;
          break;
        case 1:
          result -= 1;
          break;
        case 2:
          result *= 3;
          break;
      }
    } else {
      result -= 2;
      break;
    }
    // result += 10;
  }
  return result;
}
-->




<h3 id="step-3-straighten-edges">Step 3: Straighten edges</h3>

<p>This is the fuzziest and most ad-hoc part of the process. Basically, we run lots of small passes that walk up and down the graph, aligning layout nodes with each other. Our edge-straightening passes include:</p>

<ul>
  <li>Pushing nodes to the right of their loop header to “indent” them.</li>
  <li>Walking a layer left to right, moving children to the right to line up with their parents. If any nodes overlap as a result, they are pushed further to the right.</li>
  <li>Walking a layer right to left, moving parents to the right to line up with their children. This version is more conservative and will not move a node if it would overlap with another. This cleans up most issues from the first pass.</li>
  <li>Straightening runs of dummy nodes so we have clean vertical lines.</li>
  <li>“Sucking in” dummy runs on the left side of the graph if there is room for them to move to the right.</li>
  <li>Straighten out any edges that are “nearly straight”, according to a chosen threshold. This makes the graph appear less wobbly. We do this by repeatedly “combing” the graph upward and downward, aligning parents with children, then children with parents, and so on.</li>
</ul>

<p>It is important to note that dummy nodes participate fully in this system. If for example you have two side-by-side loops, straightening the left loop’s backedge will push the right loop to the side, avoiding overlaps and preserving the graph’s visual structure.</p>

<p>We do not reach a fixed point with this strategy, nor do we attempt to. I find that if you continue to repeatedly apply these particular layout passes, nodes will wander to the right forever. Instead, the layout passes are hand-tuned to produce decent-looking results for most of the graphs we look at on a regular basis. That said, this could certainly be improved, especially for larger graphs which do benefit from more iterations.</p>

<p>At the end of this step, all nodes have a fixed X-coordinate and will not be modified further.</p>







<h3 id="step-4-track-horizontal-edges">Step 4: Track horizontal edges</h3>

<p>Edges may overlap visually as they run horizontally between layers. To resolve this, we sort edges into parallel “tracks”, giving each a vertical offset. After tracking all the edges, we record the total height of the tracks and store it on the preceding layer as its “track height”. This allows us to leave room for the edges in the final layout step.</p>

<p>We first sort edges by their starting position, left to right. This produces a consistent arrangement of edges that has few vertical crossings in practice. Edges are then placed into tracks from the “outside in”, stacking rightward edges on top and leftward edges on the bottom, creating a new track if the edge would overlap with or cross any other edge.</p>

<p>The diagram below is interactive. Click and drag the blocks to see how the horizontal edges get assigned to tracks.</p>

<details>
<summary>Implementation pseudocode</summary>

</details>

<div><pre><code><span>/*CODEBLOCK=tracks*/</span><span>function</span> <span>trackHorizontalEdges</span><span>(</span><span>layer</span><span>)</span> <span>{</span>
  <span>const</span> <span>TRACK_SPACING</span> <span>=</span> <span>20</span><span>;</span>

  <span>// Gather all edges on the layer, and sort left to right by starting coordinate</span>
  <span>const</span> <span>layerEdges</span> <span>=</span> <span>[];</span>
  <span>for</span> <span>(</span><span>const</span> <span>node</span> <span>of</span> <span>layer</span><span>.</span><span>nodes</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>const</span> <span>edge</span> <span>of</span> <span>node</span><span>.</span><span>edges</span><span>)</span> <span>{</span>
      <span>layerEdges</span><span>.</span><span>push</span><span>(</span><span>edge</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>layerEdges</span><span>.</span><span>sort</span><span>((</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span><span>.</span><span>startX</span> <span>-</span> <span>b</span><span>.</span><span>startX</span><span>);</span>

  <span>// Assign edges to "tracks" based on whether they overlap horizontally with</span>
  <span>// each other. We walk the tracks from the outside in and stop if we ever</span>
  <span>// overlap with any other edge.</span>
  <span>const</span> <span>rightwardTracks</span> <span>=</span> <span>[];</span> <span>// [][]Edge</span>
  <span>const</span> <span>leftwardTracks</span> <span>=</span> <span>[];</span>  <span>// [][]Edge</span>
  <span>nextEdge</span><span>:</span>
  <span>for</span> <span>(</span><span>const</span> <span>edge</span> <span>of</span> <span>layerEdges</span><span>)</span> <span>{</span>
    <span>const</span> <span>trackSet</span> <span>=</span> <span>edge</span><span>.</span><span>endX</span> <span>-</span> <span>edge</span><span>.</span><span>startX</span> <span>&gt;=</span> <span>0</span> <span>?</span> <span>rightwardTracks</span> <span>:</span> <span>leftwardTracks</span><span>;</span>
    <span>let</span> <span>lastValidTrack</span> <span>=</span> <span>null</span><span>;</span> <span>// []Edge | null</span>

    <span>// Iterate through the tracks in reverse order (outside in)</span>
    <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>trackSet</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>0</span><span>;</span> <span>i</span><span>--</span><span>)</span> <span>{</span>
      <span>const</span> <span>track</span> <span>=</span> <span>trackSet</span><span>[</span><span>i</span><span>];</span>
      <span>let</span> <span>overlapsWithAnyInThisTrack</span> <span>=</span> <span>false</span><span>;</span>
      <span>for</span> <span>(</span><span>const</span> <span>otherEdge</span> <span>of</span> <span>track</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>edge</span><span>.</span><span>dst</span> <span>===</span> <span>otherEdge</span><span>.</span><span>dst</span><span>)</span> <span>{</span>
          <span>// Assign the edge to this track to merge arrows</span>
          <span>track</span><span>.</span><span>push</span><span>(</span><span>edge</span><span>);</span>
          <span>continue</span> <span>nextEdge</span><span>;</span>
        <span>}</span>

        <span>const</span> <span>al</span> <span>=</span> <span>Math</span><span>.</span><span>min</span><span>(</span><span>edge</span><span>.</span><span>startX</span><span>,</span> <span>edge</span><span>.</span><span>endX</span><span>);</span>
        <span>const</span> <span>ar</span> <span>=</span> <span>Math</span><span>.</span><span>max</span><span>(</span><span>edge</span><span>.</span><span>startX</span><span>,</span> <span>edge</span><span>.</span><span>endX</span><span>);</span>
        <span>const</span> <span>bl</span> <span>=</span> <span>Math</span><span>.</span><span>min</span><span>(</span><span>otherEdge</span><span>.</span><span>startX</span><span>,</span> <span>otherEdge</span><span>.</span><span>endX</span><span>);</span>
        <span>const</span> <span>br</span> <span>=</span> <span>Math</span><span>.</span><span>max</span><span>(</span><span>otherEdge</span><span>.</span><span>startX</span><span>,</span> <span>otherEdge</span><span>.</span><span>endX</span><span>);</span>
        <span>const</span> <span>overlaps</span> <span>=</span> <span>ar</span> <span>&gt;=</span> <span>bl</span> <span>&amp;&amp;</span> <span>al</span> <span>&lt;=</span> <span>br</span><span>;</span>
        <span>if</span> <span>(</span><span>overlaps</span><span>)</span> <span>{</span>
          <span>overlapsWithAnyInThisTrack</span> <span>=</span> <span>true</span><span>;</span>
          <span>break</span><span>;</span>
        <span>}</span>
      <span>}</span>

      <span>if</span> <span>(</span><span>overlapsWithAnyInThisTrack</span><span>)</span> <span>{</span>
        <span>break</span><span>;</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>lastValidTrack</span> <span>=</span> <span>track</span><span>;</span>
      <span>}</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>lastValidTrack</span><span>)</span> <span>{</span>
      <span>lastValidTrack</span><span>.</span><span>push</span><span>(</span><span>edge</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>trackSet</span><span>.</span><span>push</span><span>([</span><span>edge</span><span>]);</span>
    <span>}</span>
  <span>}</span>

  <span>// Use track info to apply offsets to each edge for rendering.</span>
  <span>const</span> <span>tracksHeight</span> <span>=</span> <span>TRACK_SPACING</span> <span>*</span> <span>Math</span><span>.</span><span>max</span><span>(</span>
    <span>0</span><span>,</span>
    <span>rightwardTracks</span><span>.</span><span>length</span> <span>+</span> <span>leftwardTracks</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>,</span>
  <span>);</span>
  <span>let</span> <span>trackOffset</span> <span>=</span> <span>-</span><span>tracksHeight</span> <span>/</span> <span>2</span><span>;</span>
  <span>for</span> <span>(</span><span>const</span> <span>track</span> <span>of</span> <span>[...</span><span>rightwardTracks</span><span>.</span><span>toReversed</span><span>(),</span> <span>...</span><span>leftwardTracks</span><span>])</span> <span>{</span>
    <span>for</span> <span>(</span><span>const</span> <span>edge</span> <span>of</span> <span>track</span><span>)</span> <span>{</span>
      <span>edge</span><span>.</span><span>offset</span> <span>=</span> <span>trackOffset</span><span>;</span>
    <span>}</span>
    <span>trackOffset</span> <span>+=</span> <span>TRACK_SPACING</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div>







<h3 id="step-5-verticalize">Step 5: Verticalize</h3>

<p>Finally, we assign each node a Y-coordinate. Starting at a Y-coordinate of zero, we iterate through the layers, repeatedly adding the layer’s height and its track height, where the layer height is the maximum height of any node in the layer. All nodes within a layer receive the same Y-coordinate; this is simple and easier to read than Graphviz’s default of vertically centering nodes within a layer.</p>

<p>Now that every node has both an X and Y coordinate, the layout process is complete.</p>

<details>
<summary>Implementation pseudocode</summary>

</details>

<div><pre><code><span>/*CODEBLOCK=verticalize*/</span><span>function</span> <span>verticalize</span><span>(</span><span>layers</span><span>)</span> <span>{</span>
  <span>let</span> <span>layerY</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>const</span> <span>layer</span> <span>of</span> <span>layers</span><span>)</span> <span>{</span>
    <span>let</span> <span>layerHeight</span> <span>=</span> <span>0</span><span>;</span>
    <span>for</span> <span>(</span><span>const</span> <span>node</span> <span>of</span> <span>layer</span><span>.</span><span>nodes</span><span>)</span> <span>{</span>
      <span>node</span><span>.</span><span>y</span> <span>=</span> <span>layerY</span><span>;</span>
      <span>layerHeight</span> <span>=</span> <span>Math</span><span>.</span><span>max</span><span>(</span><span>layerHeight</span><span>,</span> <span>node</span><span>.</span><span>height</span><span>);</span>
    <span>}</span>
    <span>layerY</span> <span>+=</span> <span>layerHeight</span><span>;</span>
    <span>layerY</span> <span>+=</span> <span>layer</span><span>.</span><span>trackHeight</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div>







<h3 id="step-6-render">Step 6: Render</h3>

<p>The details of rendering are out of scope for this article, and depend on the specific application. However, I wish to highlight a stylistic decision that I feel makes our graphs more readable.</p>

<p>When rendering edges, we use a style inspired by <a href="https://en.wikipedia.org/wiki/Syntax_diagram">railroad diagrams</a>. These have many advantages over the Bézier curves employed by Graphviz. First, straight lines feel more organized and are easier to follow when scrolling up and down. Second, they are easy to route (vertical when crossing layers, horizontal between layers). Third, they are easy to coalesce when they share a destination, and the junctions provide a clear indication of the edge’s direction. Fourth, they always cross at right angles, improving clarity and reducing the need to avoid edge crossings in the first place.</p>

<p>Consider the following example. There are several edge crossings that may traditionally be considered undesirable—yet the edges and their directions remain clear. Of particular note is the vertical junction highlighted in red on the left: not only is it immediately clear that these edges share a destination, but the junction itself signals that the edges are flowing downward. I find this much more pleasant than the “rat’s nest” that Graphviz tends to produce.</p>

<p><img alt="Examples of railroad-diagram edges" src="https://spidermonkey.dev/assets/img/iongraph-edge-examples-highlighted.png" width="716"></p>

<h2 id="why-does-this-work">Why does this work?</h2>

<p>It may seem surprising that such a simple (and stupid) layout algorithm could produce such readable graphs, when more sophisticated layout algorithms struggle. However, I feel that the algorithm succeeds <em>because</em> of its simplicity.</p>

<p>Most graph layout algorithms are optimization problems, where error is minimized on some chosen metrics. However, these metrics seem to correlate poorly to readability in practice. For example, it seems good in theory to rearrange nodes to minimize edge crossings. But a predictable order of nodes seems to produce more sensible results overall, and simple rules for edge routing are sufficient to keep things tidy. (As a bonus, this also gives us layout stability from pass to pass.) Similarly, layout rules like “align parents with their children” produce more readable results than “minimize the lengths of edges”.</p>

<p>Furthermore, by rejecting the optimization problem, a human author gains more control over the layout. We are able to position nodes “inside” of loops, and push post-loop content down in the graph, <em>because</em> we reject this global constraint-solver approach. Minimizing “error” is meaningless compared to a human <em>maximizing</em> meaning through thoughtful design.</p>

<p>And finally, the resulting algorithm is simply more efficient. All the layout passes in iongraph are easy to program and scale gracefully to large graphs because they run in roughly linear time. It is better, in my view, to run a fixed number of layout iterations according to your graph complexity and time budget, rather than to run a complex constraint solver until it is “done”.</p>

<p>By following this philosophy, even the worst graphs become tractable. Below is a screenshot of a zlib function, compiled to WebAssembly, and rendered using the old tool.</p>

<p><img alt="spaghetti nightmare!!" src="https://spidermonkey.dev/assets/img/iongraph-spaghetti-nightmare.png"></p>

<p>It took about <strong>ten minutes</strong> for Graphviz to produce this spaghetti nightmare. By comparison, iongraph can now lay out this function in <strong>20 milliseconds</strong>. The result is still not particularly beautiful, but it renders thousands of times faster <em>and</em> is much easier to navigate.</p>

<p><img alt="better spaghetti" src="https://spidermonkey.dev/assets/img/iongraph-zlib.png"></p>

<p>Perhaps programmers ought to put less trust into magic optimizing systems, especially when a human-friendly result is the goal. Simple (and stupid) algorithms can be very effective when applied with discretion and taste.</p>

<h2 id="future-work">Future work</h2>

<p>We have already integrated iongraph into the Firefox profiler, making it easy for us to view the graphs of the most expensive or impactful functions we find in our performance work. Unfortunately, this is only available in specific builds of the SpiderMonkey shell, and is not available in full browser builds. This is due to architectural differences in how profiling data is captured and the flags with which the browser and shell are built. I would love for Firefox users to someday be able to view these graphs themselves, but at the moment we have no plans to expose this to the browser. However, one bug tracking some related work can be found <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1987005">here</a>.</p>

<p>We will continue to sporadically update iongraph with more features to aid us in our work. We have several ideas for new features, including <a href="https://github.com/mozilla-spidermonkey/iongraph/issues/9">richer navigation</a>, search, and visualization of <a href="https://github.com/mozilla-spidermonkey/iongraph/issues/4">register allocation info</a>. However, we have no explicit roadmap for when these features may be released.</p>

<p>To experiment with iongraph locally, you can run a debug build of the SpiderMonkey shell with <code>IONFLAGS=logs</code>; this will dump information to <code>/tmp/ion.json</code>. This file can then be loaded into the <a href="https://mozilla-spidermonkey.github.io/iongraph/">standalone deployment of iongraph</a>. Please be aware that the user experience is rough and unpolished in its current state.</p>

<p>The source code for iongraph can be found on <a href="https://github.com/mozilla-spidermonkey/iongraph">GitHub</a>. If this subject interests you, we would welcome contributions to iongraph and its integration into the browser. The best place to reach us is our <a href="https://chat.mozilla.org/#/room/#spidermonkey:mozilla.org">Matrix chat</a>.</p>

<hr>

<p><em>Thanks to Matthew Gaudet, Asaf Gartner, and Colin Davidson for their feedback on this article.</em></p>




  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keep Android Open (1959 pts)]]></title>
            <link>http://keepandroidopen.org/</link>
            <guid>45742488</guid>
            <pubDate>Wed, 29 Oct 2025 04:03:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://keepandroidopen.org/">http://keepandroidopen.org/</a>, See on <a href="https://news.ycombinator.com/item?id=45742488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      

<p>In August 2025, Google announced that starting next year,
it will no longer be possible to develop apps for the Android platform
without first registering centrally with Google.</p>

<p>This registration will involve:</p>

<ul>
  <li>Paying a fee to Google</li>
  <li>Agreeing to Google’s Terms and Conditions</li>
  <li>Providing government identification</li>
  <li>Uploading evidence of an app’s private signing key</li>
  <li>Listing all current and future application identifiers</li>
</ul>

<p>Some actions you can take to help oppose the enactment of this policy are:</p>

<h2 id="sign-the-open-letter">Sign the Open Letter</h2>
<ul>
  <li>Add your organization’s signature to the draft <a href="https://docs.fediverse.foundation/pad/#/2/pad/view/OkfvdusnqafC8Wv+WUVpXB8RQk6XUFxmFHIa6CiBxQI/">Open Letter to Google Regarding Mandatory Developer Registration for Third-Party App Distribution</a>.</li>
</ul>

<h2 id="european-union">European Union</h2>
<ul>
  <li>Send feedback on EU Digital Fairness Act: <a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14622-Digital-Fairness-Act_en">EU Digital Fairness Act: Have Your Say</a></li>
</ul>

<h2 id="united-states">United States</h2>
<ul>
  <li>Make a report to to <a href="https://www.justice.gov/atr/webform/submit-your-antitrust-report-online">US Department of Justice Antitrust Report Online</a> and <a href="https://www.ftc.gov/advice-guidance/competition-guidance/antitrust-complaint-intake">US Federal Trade Commission: Antitrust Complaint</a></li>
</ul>

<h2 id="united-kingdom">United Kingdom</h2>
<ul>
  <li>Make a report to the <a href="https://danb.me/blog/google-developer-verification-cma/">UK Competition &amp; Markets Authority</a> and <a href="https://petition.parliament.uk/petitions/744446/sponsors/new">petition the UK Parliament</a> [BROKEN]</li>
</ul>

<h2 id="brazil">Brazil</h2>
<ul>
  <li>Reach out to Brazil’s <a href="https://www.procon.sp.gov.br/">Procon</a> and <a href="https://www.gov.br/mj/pt-br/assuntos/seus-direitos/consumidor">Senacon</a></li>
</ul>

<h2 id="other">Other</h2>
<ul>
  <li>Provide feedback directly to Google using their <a href="https://docs.google.com/forms/d/e/1FAIpQLSfN3UQeNspQsZCO2ITkdzMxv81rJDEGGjO-UIDDY28Rz_GEVA/viewform?pli=1">Android developer verification requirements survey</a>.</li>
  <li>Make your voice heard on social media and with blog posts.</li>
  <li>Help this project out by <a href="https://github.com/keepandroidopen/keepandroidopen.github.io/blob/main/index.md">editing this page</a> with more useful information.</li>
</ul>

<h2 id="references">References</h2>

<h3 id="overview">Overview</h3>

<ul>
  <li><a href="https://consumerrights.wiki/w/Android_Developer_Verification">https://consumerrights.wiki/w/Android_Developer_Verification</a></li>
</ul>

<h3 id="press-reactions">Press Reactions</h3>
<ul>
  <li>“Google kneecaps indie Android devs, forces them to register” — <a href="https://www.theregister.com/2025/08/26/android_developer_verification_sideloading/">https://www.theregister.com/2025/08/26/android_developer_verification_sideloading/</a></li>
  <li>“Open-Source Android Apps at Risk Under Google’s New Decree” — <a href="https://www.techrepublic.com/article/news-f-droid-warns-google-developer-decree-open-source-android/">https://www.techrepublic.com/article/news-f-droid-warns-google-developer-decree-open-source-android/</a></li>
  <li>“Google’s New Developer ID Rule Could Harm F-Droid, Says Open-Source Advocate” — <a href="https://reclaimthenet.org/googles-android-id-rule-threatens-f-droids-future">https://reclaimthenet.org/googles-android-id-rule-threatens-f-droids-future</a></li>
  <li>“Google’s developer registration ‘decree’ means the end for alternative app stores” — <a href="https://cybernews.com/tech/googles-developer-registration-decree-end-alternative-app-stores/">https://cybernews.com/tech/googles-developer-registration-decree-end-alternative-app-stores/</a></li>
  <li>“Open-Source Android Apps Threatened by Google’s New Policy” — <a href="https://www.datamation.com/open-source/android-apps-google-policy/">https://www.datamation.com/open-source/android-apps-google-policy/</a></li>
  <li>“Google’s new ID requirements could destroy independent app stores” — <a href="https://www.techspot.com/news/109728-google-confirms-new-android-rules-significantly-restrict-app.html">https://www.techspot.com/news/109728-google-confirms-new-android-rules-significantly-restrict-app.html</a></li>
  <li>“Google’s Requirement For All Android Developers To Register And Be Verified Threatens To Close Down Open Source App Store F-Droid” — <a href="https://www.techdirt.com/2025/10/07/googles-requirement-for-all-android-developers-to-register-and-be-verified-threatens-to-close-down-open-source-app-store-f-droid/">https://www.techdirt.com/2025/10/07/googles-requirement-for-all-android-developers-to-register-and-be-verified-threatens-to-close-down-open-source-app-store-f-droid/</a></li>
  <li>“Google’s new developer rules could threaten sideloading and F-Droid’s future” — <a href="https://www.gizmochina.com/2025/09/30/googles-new-developer-rules-could-threaten-sideloading-and-f-droids-future/">https://www.gizmochina.com/2025/09/30/googles-new-developer-rules-could-threaten-sideloading-and-f-droids-future/</a></li>
  <li>“Google is restricting one of Android’s most important features, and users are outraged” — <a href="https://www.slashgear.com/1962802/google-restricting-important-android-feature-reason-why-users-outraged/">https://www.slashgear.com/1962802/google-restricting-important-android-feature-reason-why-users-outraged/</a></li>
  <li>“Android’s sideloading limits are its most anti-consumer move yet” - <a href="https://www.makeuseof.com/androids-sideloading-limits-are-anti-consumer-move-yet/">https://www.makeuseof.com/androids-sideloading-limits-are-anti-consumer-move-yet/</a></li>
  <li>“Google’s dev registration plan ‘will end the F-Droid project’” — <a href="https://www.theregister.com/2025/09/29/googles_dev_registration_plan_will/">https://www.theregister.com/2025/09/29/googles_dev_registration_plan_will/</a></li>
  <li>“F-Droid says Google’s new sideloading restrictions will kill the project” — <a href="https://arstechnica.com/gadgets/2025/09/f-droid-calls-for-regulators-to-stop-googles-crackdown-on-sideloading/">https://arstechnica.com/gadgets/2025/09/f-droid-calls-for-regulators-to-stop-googles-crackdown-on-sideloading/</a></li>
  <li>“Google will require developer verification for Android apps outside the Play Store” — <a href="https://techcrunch.com/2025/08/25/google-will-require-developer-verification-for-android-apps-outside-the-play-store/">https://techcrunch.com/2025/08/25/google-will-require-developer-verification-for-android-apps-outside-the-play-store/</a></li>
  <li>“Google will verify Android developers distributing apps outside the Play store” — <a href="https://www.theverge.com/news/765881/google-android-apps-side-loading-developer-verification">https://www.theverge.com/news/765881/google-android-apps-side-loading-developer-verification</a></li>
  <li>“Google will require developer verification to install Android apps, including sideloading” — <a href="https://9to5google.com/2025/08/25/android-apps-developer-verification/">https://9to5google.com/2025/08/25/android-apps-developer-verification/</a></li>
  <li>“Android Security or Vendor Lock-In? Google’s New Sideloading Rules Smell Fishy” — <a href="https://news.itsfoss.com/new-android-sideloading-rules/">https://news.itsfoss.com/new-android-sideloading-rules/</a></li>
</ul>

<h3 id="video-responses">Video Responses</h3>
<ul>
  <li>“Google: ‘Your $1000 phone needs our permission to install apps now’” — Louis Rossmann — <a href="https://youtu.be/QBEKlIV_70E">https://youtu.be/QBEKlIV_70E</a></li>
  <li>“F-Droid Will Die in 2026 Unless We Act Now — Techlore” — <a href="https://youtu.be/wRvqdLsnsKY">https://youtu.be/wRvqdLsnsKY</a></li>
  <li>“Google is Removing Sideloading” — LMG Clips — <a href="https://youtu.be/-R76VJtTDJ8">https://youtu.be/-R76VJtTDJ8</a></li>
  <li>“Google’s changes to sideloading could end F-Droid - Linux Weekly News” — <a href="https://youtu.be/iMqpm2Ahmt0">https://youtu.be/iMqpm2Ahmt0</a></li>
  <li>“Is F-Droid in Trouble? Google Developer Verification” — <a href="https://youtu.be/-SOOoQWv4kk">https://youtu.be/-SOOoQWv4kk</a></li>
  <li>“Google is Applefying Android: The End of Openness” — ChiefGyk3D — <a href="https://youtu.be/WFOPzixHoLY">https://youtu.be/WFOPzixHoLY</a></li>
</ul>

<h3 id="editorials-and-blogs">Editorials and Blogs</h3>
<ul>
  <li>“F-Droid and Google’s Developer Registration Decree” — <a href="https://f-droid.org/en/2025/09/29/google-developer-registration-decree.html">https://f-droid.org/en/2025/09/29/google-developer-registration-decree.html</a></li>
  <li>“Pluralistic: Darth Android” — <a href="https://pluralistic.net/2025/09/01/fulu/">https://pluralistic.net/2025/09/01/fulu/</a></li>
  <li>“Google plans to block side-loading like Apple, declaring war on Android freedom” — <a href="https://tuta.com/blog/android-side-load-apps-google">https://tuta.com/blog/android-side-load-apps-google</a></li>
</ul>

<h3 id="discussions">Discussions</h3>
<ul>
  <li><a href="https://news.ycombinator.com/item?id=45409794">https://news.ycombinator.com/item?id=45409794</a></li>
  <li><a href="https://news.ycombinator.com/item?id=45507173">https://news.ycombinator.com/item?id=45507173</a></li>
  <li><a href="https://news.ycombinator.com/item?id=45569371">https://news.ycombinator.com/item?id=45569371</a></li>
  <li><a href="https://lobste.rs/s/x1sdu5/f_droid_google_s_developer_registration">https://lobste.rs/s/x1sdu5/f_droid_google_s_developer_registration</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1n1m699/horrible_news/">https://www.reddit.com/r/androiddev/comments/1n1m699/horrible_news/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1n3jtrf/google_you_royally_screwed_up/">https://www.reddit.com/r/androiddev/comments/1n3jtrf/google_you_royally_screwed_up/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1n0uy6g/just_received_this_email_now_you_can_get/">https://www.reddit.com/r/androiddev/comments/1n0uy6g/just_received_this_email_now_you_can_get/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1n2im4j/this_may_mark_the_end_of_android_development_for/">https://www.reddit.com/r/androiddev/comments/1n2im4j/this_may_mark_the_end_of_android_development_for/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1n0f41c/google_will_require_developer_verification_to/">https://www.reddit.com/r/androiddev/comments/1n0f41c/google_will_require_developer_verification_to/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1km8jof/google_play_developer_verification/">https://www.reddit.com/r/androiddev/comments/1km8jof/google_play_developer_verification/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1mzw877/android_developers_blog_a_new_layer_of_security/">https://www.reddit.com/r/androiddev/comments/1mzw877/android_developers_blog_a_new_layer_of_security/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1n7g0cc/to_all_android_devs_speak_up_now_before_you_lose/">https://www.reddit.com/r/androiddev/comments/1n7g0cc/to_all_android_devs_speak_up_now_before_you_lose/</a></li>
  <li><a href="https://www.reddit.com/r/androiddev/comments/1oaj908/collection_of_actions_we_can_take_to_stop/">https://www.reddit.com/r/androiddev/comments/1oaj908/collection_of_actions_we_can_take_to_stop/</a></li>
</ul>

<h3 id="official-documentation">Official Documentation</h3>
<ul>
  <li>Initial announcement — <a href="https://android-developers.googleblog.com/2025/08/elevating-android-security.html">https://android-developers.googleblog.com/2025/08/elevating-android-security.html</a></li>
  <li>Android developer verification: Guides — <a href="https://developer.android.com/developer-verification/guides/android-developer-console#complete-identity">https://developer.android.com/developer-verification/guides/android-developer-console#complete-identity</a></li>
  <li>Android developer verification: Frequently asked questions — <a href="https://developer.android.com/developer-verification/guides/faq">https://developer.android.com/developer-verification/guides/faq</a></li>
  <li>Introducing the Android Developer Console: A first look — <a href="https://developer.android.com/developer-verification/assets/pdfs/introducing-the-android-developer-console.pdf">https://developer.android.com/developer-verification/assets/pdfs/introducing-the-android-developer-console.pdf</a></li>
  <li>Download an early look of the new Android Developer Console — <a href="https://support.google.com/android-developer-console/answer/16450960">https://support.google.com/android-developer-console/answer/16450960</a></li>
  <li>API Documentation — <a href="https://developer.android.com/reference/android/content/pm/PackageInstaller#DEVELOPER_VERIFICATION_FAILED_REASON_DEVELOPER_BLOCKED">https://developer.android.com/reference/android/content/pm/PackageInstaller#DEVELOPER_VERIFICATION_FAILED_REASON_DEVELOPER_BLOCKED</a></li>
</ul>

<h3 id="miscellaneous">Miscellaneous</h3>
<ul>
  <li><a href="https://docs.google.com/document/d/1axlQkdc-wseda9PL2ZP0fgy3I4DqAVVlK5kJw4ksIwU">Opposition recommendations</a></li>
</ul>


      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[uBlock Origin Lite Apple App Store (331 pts)]]></title>
            <link>https://apps.apple.com/in/app/ublock-origin-lite/id6745342698</link>
            <guid>45742446</guid>
            <pubDate>Wed, 29 Oct 2025 03:57:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apps.apple.com/in/app/ublock-origin-lite/id6745342698">https://apps.apple.com/in/app/ublock-origin-lite/id6745342698</a>, See on <a href="https://news.ycombinator.com/item?id=45742446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!---->
<!---->
<!---->
    

<!---->
    


  <div dir="" data-test-bidi=""><p>uBO Lite (uBOL) is a reliable and efficient content blocker.</p><p>The default ruleset corresponds to uBlock Origin's default filterset:</p><p>- uBlock Origin's built-in filter lists<br>- EasyList<br>- EasyPrivacy<br>- Peter Lowe’s Ad and tracking server list</p><p>You can enable more rulesets by visiting the options page -- click the _Cogs_ icon in the popup panel.</p><p>uBOL is entirely declarative, meaning there is no need for a permanent uBOL process for the filtering to occur, and CSS/JS injection-based content filtering is performed reliably by the browser itself rather than by the extension. This means that uBOL itself does not consume CPU/memory resources while content blocking is ongoing -- uBOL's service worker process is required _only_ when you interact with the popup panel or the option pages.</p></div>

<!---->
  <section>
    <div>
      <h2>What’s New</h2>
        

    </div>
    <div>
        <div>
            <p><time data-test-we-datetime="" datetime="2025-10-20T00:00:00.000Z" aria-label="20 October 2025">20 Oct 2025</time></p><p>Version 2025.1019.1656</p>
          </div>
      <div>
          <p dir="false" data-test-bidi="">• Automatically select optimal for newly allowed hosts<br>• Updated filter lists</p>


      </div>
    </div>
  </section>

      <section>
      <p>
        <h2>
          Ratings and Reviews
        </h2>

        <!---->
      </p>

        


      <div>
              
              <div aria-labelledby="we-customer-review-1047" id="ember87146">
  <figure aria-label="5 out of 5">
  <span>
    <span></span>
  </span>
<!----></figure>


  

    <h3 dir="ltr" id="we-customer-review-1047">
    The best content blocker is finally on iPadOS!!
</h3>



      <blockquote dir="">
        

        <p dir="false" data-test-bidi="">It’s was a really long wait, but finally we are able to use it directly on the iPad. The first TestFlight version had a big battery drain, but it’s better now on the official release. The only limitation is that we can’t add our own lists, but I am fine with the default lists ans it works perfect.</p>
    


<!----></blockquote>



<!----></div>

          
    
              <div aria-labelledby="we-customer-review-1048" id="ember87148">
  <figure aria-label="5 out of 5">
  <span>
    <span></span>
  </span>
<!----></figure>


  

    <h3 dir="ltr" id="we-customer-review-1048">
    I was looking for this long time finally it’s here.
</h3>



      <blockquote dir="">
        

        <p dir="false" data-test-bidi="">I love block. I do not want to use chrome. It’s perfect. I can use this in safari..</p>
    


<!----></blockquote>



<!----></div>

          
    
              <div aria-labelledby="we-customer-review-1049" id="ember87150">
  <figure aria-label="5 out of 5">
  <span>
    <span></span>
  </span>
<!----></figure>


  

    <h3 dir="ltr" id="we-customer-review-1049">
    Finally 🤩
</h3>



      <blockquote dir="">
        

        <p dir="false" data-test-bidi="">Waiting for many years. Added in all apple devices. Working properly. 🎉🎊</p>
    


<!----></blockquote>



<!----></div>

          

      </div>

        
    </section>


<!---->
<!---->
<!---->
  <section>
  <div>
    <h2>
      App Privacy
    </h2>

    


  </div>

  <p>
    The developer, <span>Raymond Hill</span>, indicated that the app’s privacy practices may include handling of data as described below. For more information, see the <a href="https://github.com/uBlockOrigin/uBOL-home/wiki/Privacy-policy">developer’s privacy policy</a>.
  </p>

  <div>
        
        <h3>Data Not Collected</h3>
        <p>The developer does not collect any data from this app.</p>
<!---->      </div>

    <p>Privacy practices may vary based on, for example, the features you use or your age. <a href="https://apps.apple.com/story/id1538632801">Learn&nbsp;More</a></p>
</section>


<section>
  <div>
    <h2>Information</h2>
    <dl>
        <p>
          <dt>Provider</dt>
          <dd>
              Raymond Hill
          </dd>
        </p>
        <p>
          <dt>Size</dt>
          <dd aria-label="6 megabytes">6 MB</dd>
        </p>
        <p>
          <dt>Category</dt>
          <dd>
              <a href="https://itunes.apple.com/in/genre/id6002" data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;actionUrl&quot;:&quot;https://itunes.apple.com/in/genre/id6002&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;GenrePage&quot;}">
                Utilities
              </a>
          </dd>
        </p>
      <div>
        <dt>Compatibility</dt>
          <dd>
              <dl>
                <dt>
                  iPhone
                </dt>
                <dd>Requires iOS 18.5 or later.
                </dd>
              </dl>
              <dl>
                <dt>
                  iPad
                </dt>
                <dd>Requires iPadOS 18.5 or later.
                </dd>
              </dl>
              <dl>
                <dt>
                  Mac
                </dt>
                <dd>Requires macOS 13.5 or later.
                </dd>
              </dl>
              <dl>
                <dt>
                  Apple Vision
                </dt>
                <dd>Requires visionOS 2.5 or later.
                </dd>
              </dl>
          </dd>
      </div>
<!---->      
      
<!---->      <p>
        <dt>Copyright</dt>
        <dd>© Raymond Hill 2025</dd>
      </p>
        <p>
          <dt>Price</dt>
          <dd>Free</dd>
        </p>
<!---->
    </dl>
  </div>
  <div>
    <ul>
<!---->        <li>
          <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToAppSupport&quot;}" href="https://github.com/uBlockOrigin/uBOL-home">
            App Support
          </a>
        </li>
        <li>
          <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToPrivacyPolicy&quot;}" href="https://github.com/uBlockOrigin/uBOL-home/wiki/Privacy-policy">
            Privacy Policy
          </a>
        </li>
<!----><!---->    </ul>
  </div>
</section>

<section>
  <ul>
<!---->      <li>
        <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToAppSupport&quot;}" href="https://github.com/uBlockOrigin/uBOL-home">
          App Support
        </a>
      </li>
<!---->      <li>
        <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToPrivacyPolicy&quot;}" href="https://github.com/uBlockOrigin/uBOL-home/wiki/Privacy-policy">
          Privacy Policy
        </a>
      </li>
  </ul>
</section>

<!---->
<!---->
<!---->
<!---->

<!---->

<!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tips for stroke-surviving software engineers (405 pts)]]></title>
            <link>https://blog.j11y.io/2025-10-29_stroke_tips_for_engineers/</link>
            <guid>45742419</guid>
            <pubDate>Wed, 29 Oct 2025 03:51:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.j11y.io/2025-10-29_stroke_tips_for_engineers/">https://blog.j11y.io/2025-10-29_stroke_tips_for_engineers/</a>, See on <a href="https://news.ycombinator.com/item?id=45742419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><p>2025-10-29</p><div>
<p>This is a pretty niche topic; I don't imagine there are many of us out there.</p>
<p>Actually, to be strict, I'd say this advice is tailored to people who've had hemorrhagic stroke in the parietal lobe with residual epilepsy...</p>
<p><img src="https://blog.j11y.io/post_imgs/stroke/main.png" alt="Brain/Head/Lightning/Eyes-closed - I drew this many years ago, before I knew what was to happen. Who knew..."></p><p>I was 29 and around 12 years into my career <a href="https://www.facebook.com/jamespadolsey/posts/pfbid0NSaR29y6QYRnBjvJyRwueDTuJx6Ef4bH3wUvEZ1W4rmqMTKbi4mFBviVs71qSLcwl">when it all happened</a>, and in the six years since then I've had time to learn a bit more about my new self.</p>
<ol>
<li><p>The first tip is to just stop. Fatigue, fuzziness, nausea, or affected-sided weird sensations are non-negotiable stop signals. So go lie down, hydrate, reset. Close your eyes and think about the cottage or lonely mountain you want to retire to. Escape the overwhelming mental or physical space. </p>
</li>
<li><p>HEADPHONES, blinders, and 'No'. Eliminate unwanted inputs at the earliest point of entry. Work from home or environments where you can control most variables. Routes of escape and rest are important.</p>
</li>
<li><p>Health above performance every single time. Metrics and productivity be damned. Self-advocate, and all that. Reject with directness any demands made of you that cross the threshold. </p>
</li>
<li><p>Laws. Use them. You don't have to rely on good behaviour and kindness. You are, depending on your location, usually protected by all types of anti-discrimination legislation, implicit and explicit. Use your employee assistance programs too.</p>
</li>
<li><p>Single-thread it all! Less context switching. Batch your work, finish one thing, then move to the next. Externalize working-memory. Use notebooks, whiteboards, and lists instead of juggling state in your head. I am not good at this, and over-stretch my brain, leading to auras, overwhelm, and general sickness. Terrible idea.</p>
</li>
<li><p>Related: Sssh to the AI naysayers. Use it as your help and scratchpad. Let it hold state so your brain can judge rather than store and needlessly cogitate on stuff. You don't have to do this alone out of some purity fetishism. You, too, have a limited context window. Sorry!</p>
</li>
<li><p>Do the heavy thinking in your peak window (for me, that's the morning); push everything else to later. Spend your time more carefully than your money.</p>
</li>
<li><p>Pick the route of least attention. Attention is expensive, and rarely needed as much as we think it is. It's a heavy toll to pay. Unless you're in an ops or monitoring role, you don't need to be synchronously active. DISABLE NOTIFICATIONS. </p>
</li>
<li><p>AVOID long meetings. Emails are good. Oh god am I bad at this? YES, I like people so I like some meetings, but communicating is so so expensive. Being polite is also expensive; It's not nice to have to tell people they're draining you.</p>
</li>
</ol>
<p>I think that's mostly it. I'm still working on this stuff. And would probably grade myself pretty poorly. One day I'll be better at saying no, at advocating for myself, and knowing how to navigate the disappointment of others.</p>
<hr>
<p><strong>Footnote &amp; some casual research</strong>: If you're into this, here's some stuff I found out related to my specific injury location and how it might apply to my work. This was gathered with help from gemini when I was struggling with left-arm and eye prodromes after long coding sessions:</p>
<blockquote>
<p>Frontal and parietal cortices form a flexible control system that holds goals, routes attention, and updates task sets; this "multiple-demand" network scales with task complexity and underpins how we store, manipulate, and decide on information during work<sup><a href="https://web.mit.edu/9.s915/www/classes/duncan.pdf">[1]</a><a href="https://www.pnas.org/doi/pdf/10.1073/pnas.1315235110">[2]</a><a href="https://pubmed.ncbi.nlm.nih.gov/16731517/">[3]</a></sup>. Superior parietal cortex is especially taxed when we transform or reorganize information in working memory rather than simply maintain it, which is why mental navigations, refactors, and other transformations feel costly<sup><a href="https://www.pnas.org/doi/abs/10.1073/pnas.0607101104">[4]</a><a href="https://link.springer.com/content/pdf/10.3758/CABN.3.4.255.pdf">[5]</a></sup>. Frequent context switches recruit lateral prefrontal and parietal regions and increase control load, so hopping between threads repeatedly spikes demand on this same circuitry<sup><a href="https://epa.psy.ntu.edu.tw/perception/pdf/Monsell_2003.pdf">[6]</a><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3421461/">[7]</a></sup>. After AVM resection (what I had!) or stroke generally, tissue near the lesion can remain hyperexcitable with impaired neurovascular coupling; heavy cognitive load lowers seizure threshold and can produce somatosensory auras and body-image distortions from parietal cortex<sup><a href="https://www.cell.com/neuron/pdf/S0896-6273%2817%2930652-9.pdf">[8]</a><a href="https://perspectivesinmedicine.cshlp.org/content/early/2015/09/17/cshperspect.a022822.full.pdf">[9]</a><a href="https://link.springer.com/article/10.1684/epd.2012.0484">[10]</a></sup>.</p>
</blockquote>
<hr>
<p>Thanks for reading :) Tonnes of love to all the stroke survivors out there &lt;3</p>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Shadowglass (114 pts)]]></title>
            <link>https://shadowglassgame.com</link>
            <guid>45741391</guid>
            <pubDate>Wed, 29 Oct 2025 01:06:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shadowglassgame.com">https://shadowglassgame.com</a>, See on <a href="https://news.ycombinator.com/item?id=45741391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" role="main">
    <section aria-label="Game introduction">
        <video autoplay="" muted="" loop="" playsinline="" preload="auto">
            <source src="https://shadowglassgame.com/pixelfire.mp4" type="video/mp4">
        </video>
        <div>
                <p>
                    <iframe src="https://www.youtube-nocookie.com/embed/FONl-1O_VBY?vq=hd1080&amp;modestbranding=1&amp;rel=0&amp;showinfo=0&amp;iv_load_policy=3&amp;cc_load_policy=0&amp;playsinline=1" title="Project Shadowglass Trailer" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" loading="lazy">
                    </iframe>
                </p>
            </div>
        
    </section>

    <!-- Mobile Hero Text Section -->
    <section>
        <video autoplay="" muted="" loop="" playsinline="" preload="auto">
            <source src="https://shadowglassgame.com/pixelfire.mp4" type="video/mp4">
        </video>
        
    </section>

    <!-- About Section -->
    <div id="about" aria-labelledby="about-heading">
            <p><img src="https://shadowglassgame.com/img/project_shadowglass_logo.png" alt="Project Shadowglass Logo - Dark Fantasy Immersive Sim Game">
            </p>
            <h2 id="about-heading">Now in Development</h2>
            <p>Project Shadowglass (working title) is a love letter to classic <strong>immersive sims</strong> such as <em>Thief</em>, <em>Deus Ex</em>, and <em>System Shock</em>, built with unique <strong>3D pixel art technology</strong>.</p>
            <p>You play a <strong>struggling thief</strong> in a dark, oppressive world where the rich grow richer and the poor are pushed further into the shadows. To succeed, you will need to rely on your wits and <strong>tools of the trade</strong>.</p>

            <p><strong>Please Note:</strong> All content shown is early in development and subject to change, including the game title, features, and release timeline.</p>
        </div>

    <!-- Media Section -->
    

    <!-- AI Statement Section -->
    <div aria-labelledby="ai-heading">
            <h2 id="ai-heading">Is this... AI?</h2>
            <p>No. Everything you see is <strong>100% real and running realtime in-engine</strong>.</p>
            <p>It may look similar to those pretty pixel art AI videos, but this is the <strong>playable real deal</strong>. No content or art featured in <em>Project Shadowglass</em> will be <strong>AI generated</strong>.</p>
            <p>Even the placeholder assets you see in this early footage are <strong>open source creative commons</strong> creations made by real people (<a href="#credits">you can see the full credit list here</a>).</p>
        </div>

    <!-- Technology Section -->
    <div aria-labelledby="tech-heading">
            <h2 id="tech-heading">The Tech</h2>
            <p>Project Shadowglass is built with <strong>unique 3D pixel art technology</strong> that delivers nostalgic <strong>pixelated graphics</strong> in smooth, full <strong>360° freedom</strong>. It is based off of the culmination of <strong>3D pixel art work</strong> I've spent over a decade perfecting.</p>
            <p>Walk around objects, examine details from any angle, and climb structures while enjoying those perfect little <strong>square pixels</strong>.</p>
        </div>

    <!-- Development Status Section -->
    <div aria-labelledby="dev-status-heading">
            <h2 id="dev-status-heading">Development Status</h2>
            
            <div>
                    <div>
                            <h4>Early Development</h4>
                            <p>Building core systems</p>
                            <p><span>Current</span>
                        </p></div>

                    <div>
                            <h4>Alpha Demo</h4>
                            <p>First playable mission</p>
                            <p><span>Early 2026</span>
                        </p></div>

                    <div>
                            <h4>Beta Testing</h4>
                            <p>Community feedback</p>
                            <p><span>TBD</span>
                        </p></div>

                    <div>
                            <h4>Early Access</h4>
                            <p>Expanded content</p>
                            <p><span>2027</span>
                        </p></div>

                    <div>
                            <h4>Full Release</h4>
                            <p>Complete experience</p>
                            <p><span>TBD</span>
                        </p></div>
                </div>

            <div>
                <p>Get early access to playable demos, dev updates, and help shape Project Shadowglass before release!</p>

                
            </div>
        </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keeping the Internet fast and secure: introducing Merkle Tree Certificates (190 pts)]]></title>
            <link>https://blog.cloudflare.com/bootstrap-mtc/</link>
            <guid>45740214</guid>
            <pubDate>Tue, 28 Oct 2025 22:39:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/bootstrap-mtc/">https://blog.cloudflare.com/bootstrap-mtc/</a>, See on <a href="https://news.ycombinator.com/item?id=45740214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2025-10-28</p><section><p>12 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1sJBsQ55nUSWxEq5SO0PS1/3265c773d1b11dafa78ea7e17354d408/image2.png" alt=""><div><p>The world is in a race to build its first quantum computer capable of solving practical problems not feasible on even the largest conventional supercomputers. While the quantum computing paradigm promises many benefits, it also threatens the security of the Internet by breaking much of the cryptography we have come to rely on.</p><p>To mitigate this threat, Cloudflare is helping to migrate the Internet to Post-Quantum (PQ) cryptography. Today, <a href="https://radar.cloudflare.com/adoption-and-usage#post-quantum-encryption"><u>about 50%</u></a> of traffic to Cloudflare's edge network is protected against the most urgent threat: an attacker who can intercept and store encrypted traffic today and then decrypt it in the future with the help of a quantum computer. This is referred to as the <a href="https://en.wikipedia.org/wiki/Harvest_now,_decrypt_later"><u>harvest now, decrypt later</u></a><i> </i>threat.</p><p>However, this is just one of the threats we need to address. A quantum computer can also be used to crack a server's <a href="https://www.cloudflare.com/learning/ssl/transport-layer-security-tls/"><u>TLS</u></a> certificate, allowing an attacker to impersonate the server to unsuspecting clients. The good news is that we already have PQ algorithms we can use for quantum-safe authentication. The bad news is that adoption of these algorithms in TLS will require significant changes to one of the most complex and security-critical systems on the Internet: the Web Public-Key Infrastructure (WebPKI).</p><p>The central problem is the sheer size of these new algorithms: signatures for ML-DSA-44, one of the most performant PQ algorithms standardized by NIST, are 2,420 bytes long, compared to just 64 bytes for ECDSA-P256, the most popular non-PQ signature in use today; and its public keys are 1,312 bytes long, compared to just 64 bytes for ECDSA. That's a roughly 20-fold increase in size. Worse yet, the average TLS handshake includes a number of public keys and signatures, adding up to 10s of kilobytes of overhead per handshake. This is enough to have a <a href="https://blog.cloudflare.com/another-look-at-pq-signatures/#how-many-added-bytes-are-too-many-for-tls"><u>noticeable impact</u></a> on the performance of TLS.</p><p>That makes drop-in PQ certificates a tough sell to enable today: they don’t bring any security benefit before Q-day — the day a cryptographically relevant quantum computer arrives — but they do degrade performance. We could sit and wait until Q-day is a year away, but that’s playing with fire. Migrations always take longer than expected, and by waiting we risk the security and privacy of the Internet, which is <a href="https://developers.cloudflare.com/ssl/edge-certificates/universal-ssl/"><u>dear to us</u></a>.</p><p>It's clear that we must find a way to make post-quantum certificates cheap enough to deploy today by default for everyone — not just those that can afford it. In this post, we'll introduce you to the plan we’ve brought together with industry partners to the <a href="https://datatracker.ietf.org/group/plants/about/"><u>IETF</u></a> to redesign the WebPKI in order to allow a smooth transition to PQ authentication with no performance impact (and perhaps a performance improvement!). We'll provide an overview of one concrete proposal, called <a href="https://datatracker.ietf.org/doc/draft-davidben-tls-merkle-tree-certs/"><u>Merkle Tree Certificates (MTCs)</u></a>, whose goal is to whittle down the number of public keys and signatures in the TLS handshake to the bare minimum required.</p><p>But talk is cheap. We <a href="https://blog.cloudflare.com/experiment-with-pq/"><u>know</u></a> <a href="https://blog.cloudflare.com/announcing-encrypted-client-hello/"><u>from</u></a> <a href="https://blog.cloudflare.com/why-tls-1-3-isnt-in-browsers-yet/"><u>experience</u></a> that, as with any change to the Internet, it's crucial to test early and often. <b>Today we're announcing our intent to deploy MTCs on an experimental basis in collaboration with Chrome Security.</b> In this post, we'll describe the scope of this experiment, what we hope to learn from it, and how we'll make sure it's done safely.</p>
    <p>
      <h2 id="the-webpki-today-an-old-system-with-many-patches">The WebPKI today — an old system with many patches</h2>
      
    </p>
    <p>Why does the TLS handshake have so many public keys and signatures?</p><p>Let's start with Cryptography 101. When your browser connects to a website, it asks the server to <b>authenticate</b> itself to make sure it's talking to the real server and not an impersonator. This is usually achieved with a cryptographic primitive known as a digital signature scheme (e.g., ECDSA or ML-DSA). In TLS, the server signs the messages exchanged between the client and server using its <b>secret key</b>, and the client verifies the signature using the server's <b>public key</b>. In this way, the server confirms to the client that they've had the same conversation, since only the server could have produced a valid signature.</p><p>If the client already knows the server's public key, then only <b>1 signature</b> is required to authenticate the server. In practice, however, this is not really an option. The web today is made up of around a billion TLS servers, so it would be unrealistic to provision every client with the public key of every server. What's more, the set of public keys will change over time as new servers come online and existing ones rotate their keys, so we would need some way of pushing these changes to clients.</p><p>This scaling problem is at the heart of the design of all PKIs.</p>
    <p>
      <h3 id="trust-is-transitive">Trust is transitive</h3>
      
    </p>
    <p>Instead of expecting the client to know the server's public key in advance, the server might just send its public key during the TLS handshake. But how does the client know that the public key actually belongs to the server? This is the job of a <b>certificate</b>.</p><p>A certificate binds a public key to the identity of the server — usually its DNS name, e.g., <code>cloudflareresearch.com</code>. The certificate is signed by a Certification Authority (CA) whose public key is known to the client. In addition to verifying the server's handshake signature, the client verifies the signature of this certificate. This establishes a chain of trust: by accepting the certificate, the client is trusting that the CA verified that the public key actually belongs to the server with that identity.</p><p>Clients are typically configured to trust many CAs and must be provisioned with a public key for each. Things are much easier however, since there are only 100s of CAs instead of billions. In addition, new certificates can be created without having to update clients.</p><p>These efficiencies come at a relatively low cost: for those counting at home, that's <b>+1</b> signature and <b>+1</b> public key, for a total of <b>2 signatures and 1 public key</b> per TLS handshake.</p><p>That's not the end of the story, however. As the WebPKI has evolved, so have these chains of trust grown a bit longer. These days it's common for a chain to consist of two or more certificates rather than just one. This is because CAs sometimes need to rotate<b> </b>their keys, just as servers do. But before they can start using the new key, they must distribute the corresponding public key to clients. This takes time, since it requires billions of clients to update their trust stores. To bridge the gap, the CA will sometimes use the old key to issue a certificate for the new one and append this certificate to the end of the chain.</p><p>That's<b> +1</b> signature and<b> +1</b> public key, which brings us to<b> 3 signatures and 2 public keys</b>. And we still have a little ways to go.</p>
    <p>
      <h3 id="trust-but-verify">Trust but verify</h3>
      
    </p>
    <p>The main job of a CA is to verify that a server has control over the domain for which it’s requesting a certificate. This process has evolved over the years from a high-touch, CA-specific process to a standardized, <a href="https://datatracker.ietf.org/doc/html/rfc8555/"><u>mostly automated process</u></a> used for issuing most certificates on the web. (Not all CAs fully support automation, however.) This evolution is marked by a number of security incidents in which a certificate was <b>mis-issued </b>to a party other than the server, allowing that party to impersonate the server to any client that trusts the CA.</p><p>Automation helps, but <a href="https://en.wikipedia.org/wiki/DigiNotar#Issuance_of_fraudulent_certificates"><u>attacks</u></a> are still possible, and mistakes are almost inevitable. <a href="https://blog.cloudflare.com/unauthorized-issuance-of-certificates-for-1-1-1-1/"><u>Earlier this year</u></a>, several certificates for Cloudflare's encrypted 1.1.1.1 resolver were issued without our involvement or authorization. This apparently occurred by accident, but it nonetheless put users of 1.1.1.1 at risk. (The mis-issued certificates have since been revoked.)</p><p>Ensuring mis-issuance is detectable is the job of the Certificate Transparency (CT) ecosystem. The basic idea is that each certificate issued by a CA gets added to a public <b>log</b>. Servers can audit these logs for certificates issued in their name. If ever a certificate is issued that they didn't request itself, the server operator can prove the issuance happened, and the PKI ecosystem can take action to prevent the certificate from being trusted by clients.</p><p>Major browsers, including Firefox and Chrome and its derivatives, require certificates to be logged before they can be trusted. For example, Chrome, Safari, and Firefox will only accept the server's certificate if it appears in at least two logs the browser is configured to trust. This policy is easy to state, but tricky to implement in practice:</p><ol><li><p>Operating a CT log has historically been fairly expensive. Logs ingest billions of certificates over their lifetimes: when an incident happens, or even just under high load, it can take some time for a log to make a new entry available for auditors.</p></li><li><p>Clients can't really audit logs themselves, since this would expose their browsing history (i.e., the servers they wanted to connect to) to the log operators.</p></li></ol><p>The solution to both problems is to include a signature from the CT log along with the certificate. The signature is produced immediately in response to a request to log a certificate, and attests to the log's intent to include the certificate in the log within 24 hours.</p><p>Per browser policy, certificate transparency adds <b>+2</b> signatures to the TLS handshake, one for each log. This brings us to a total of <b>5 signatures and 2 public keys</b> in a typical handshake on the public web.</p>
    <p>
      <h3 id="the-future-webpki">The future WebPKI</h3>
      
    </p>
    <p>The WebPKI is a living, breathing, and highly distributed system. We've had to patch it a number of times over the years to keep it going, but on balance it has served our needs quite well — until now.</p><p>Previously, whenever we needed to update something in the WebPKI, we would tack on another signature. This strategy has worked because conventional cryptography is so cheap. But <b>5 signatures and 2 public keys </b>on average for each TLS handshake is simply too much to cope with for the larger PQ signatures that are coming.</p><p>The good news is that by moving what we already have around in clever ways, we can drastically reduce the number of signatures we need.</p>
    <p>
      <h3 id="crash-course-on-merkle-tree-certificates">Crash course on Merkle Tree Certificates</h3>
      
    </p>
    <p><a href="https://datatracker.ietf.org/doc/draft-davidben-tls-merkle-tree-certs/"><u>Merkle Tree Certificates (MTCs)</u></a> is a proposal for the next generation of the WebPKI that we are implementing and plan to deploy on an experimental basis. Its key features are as follows:</p><ol><li><p>All the information a client needs to validate a Merkle Tree Certificate can be disseminated out-of-band. If the client is sufficiently up-to-date, then the TLS handshake needs just <b>1 signature, 1 public key, and 1 Merkle tree inclusion proof</b>. This is quite small, even if we use post-quantum algorithms.</p></li><li><p>The MTC specification makes certificate transparency a first class feature of the PKI by having each CA run its own log of exactly the certificates they issue.</p></li></ol><p>Let's poke our head under the hood a little. Below we have an MTC generated by one of our internal tests. This would be transmitted from the server to the client in the TLS handshake:</p>
            <pre><code>-----BEGIN CERTIFICATE-----
MIICSzCCAUGgAwIBAgICAhMwDAYKKwYBBAGC2ksvADAcMRowGAYKKwYBBAGC2ksv
AQwKNDQzNjMuNDguMzAeFw0yNTEwMjExNTMzMjZaFw0yNTEwMjgxNTMzMjZaMCEx
HzAdBgNVBAMTFmNsb3VkZmxhcmVyZXNlYXJjaC5jb20wWTATBgcqhkjOPQIBBggq
hkjOPQMBBwNCAARw7eGWh7Qi7/vcqc2cXO8enqsbbdcRdHt2yDyhX5Q3RZnYgONc
JE8oRrW/hGDY/OuCWsROM5DHszZRDJJtv4gno2wwajAOBgNVHQ8BAf8EBAMCB4Aw
EwYDVR0lBAwwCgYIKwYBBQUHAwEwQwYDVR0RBDwwOoIWY2xvdWRmbGFyZXJlc2Vh
cmNoLmNvbYIgc3RhdGljLWN0LmNsb3VkZmxhcmVyZXNlYXJjaC5jb20wDAYKKwYB
BAGC2ksvAAOB9QAAAAAAAAACAAAAAAAAAAJYAOBEvgOlvWq38p45d0wWTPgG5eFV
wJMhxnmDPN1b5leJwHWzTOx1igtToMocBwwakt3HfKIjXYMO5CNDOK9DIKhmRDSV
h+or8A8WUrvqZ2ceiTZPkNQFVYlG8be2aITTVzGuK8N5MYaFnSTtzyWkXP2P9nYU
Vd1nLt/WjCUNUkjI4/75fOalMFKltcc6iaXB9ktble9wuJH8YQ9tFt456aBZSSs0
cXwqFtrHr973AZQQxGLR9QCHveii9N87NXknDvzMQ+dgWt/fBujTfuuzv3slQw80
mibA021dDCi8h1hYFQAA
-----END CERTIFICATE-----</code></pre>
            <p>Looks like your average PEM encoded certificate. Let's decode it and look at the parameters:</p>
            <pre><code>$ openssl x509 -in merkle-tree-cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 531 (0x213)
        Signature Algorithm: 1.3.6.1.4.1.44363.47.0
        Issuer: 1.3.6.1.4.1.44363.47.1=44363.48.3
        Validity
            Not Before: Oct 21 15:33:26 2025 GMT
            Not After : Oct 28 15:33:26 2025 GMT
        Subject: CN=cloudflareresearch.com
        Subject Public Key Info:
            Public Key Algorithm: id-ecPublicKey
                Public-Key: (256 bit)
                pub:
                    04:70:ed:e1:96:87:b4:22:ef:fb:dc:a9:cd:9c:5c:
                    ef:1e:9e:ab:1b:6d:d7:11:74:7b:76:c8:3c:a1:5f:
                    94:37:45:99:d8:80:e3:5c:24:4f:28:46:b5:bf:84:
                    60:d8:fc:eb:82:5a:c4:4e:33:90:c7:b3:36:51:0c:
                    92:6d:bf:88:27
                ASN1 OID: prime256v1
                NIST CURVE: P-256
        X509v3 extensions:
            X509v3 Key Usage: critical
                Digital Signature
            X509v3 Extended Key Usage:
                TLS Web Server Authentication
            X509v3 Subject Alternative Name:
                DNS:cloudflareresearch.com, DNS:static-ct.cloudflareresearch.com
    Signature Algorithm: 1.3.6.1.4.1.44363.47.0
    Signature Value:
        00:00:00:00:00:00:02:00:00:00:00:00:00:00:02:58:00:e0:
        44:be:03:a5:bd:6a:b7:f2:9e:39:77:4c:16:4c:f8:06:e5:e1:
        55:c0:93:21:c6:79:83:3c:dd:5b:e6:57:89:c0:75:b3:4c:ec:
        75:8a:0b:53:a0:ca:1c:07:0c:1a:92:dd:c7:7c:a2:23:5d:83:
        0e:e4:23:43:38:af:43:20:a8:66:44:34:95:87:ea:2b:f0:0f:
        16:52:bb:ea:67:67:1e:89:36:4f:90:d4:05:55:89:46:f1:b7:
        b6:68:84:d3:57:31:ae:2b:c3:79:31:86:85:9d:24:ed:cf:25:
        a4:5c:fd:8f:f6:76:14:55:dd:67:2e:df:d6:8c:25:0d:52:48:
        c8:e3:fe:f9:7c:e6:a5:30:52:a5:b5:c7:3a:89:a5:c1:f6:4b:
        5b:95:ef:70:b8:91:fc:61:0f:6d:16:de:39:e9:a0:59:49:2b:
        34:71:7c:2a:16:da:c7:af:de:f7:01:94:10:c4:62:d1:f5:00:
        87:bd:e8:a2:f4:df:3b:35:79:27:0e:fc:cc:43:e7:60:5a:df:
        df:06:e8:d3:7e:eb:b3:bf:7b:25:43:0f:34:9a:26:c0:d3:6d:
        5d:0c:28:bc:87:58:58:15:00:00</code></pre>
            <p>While some of the parameters probably look familiar, others will look unusual. On the familiar side, the subject and public key are exactly what we might expect: the DNS name is <code>cloudflareresearch.com</code> and the public key is for a familiar signature algorithm, ECDSA-P256. This algorithm is not PQ, of course — in the future we would put ML-DSA-44 there instead.</p><p>On the unusual side, OpenSSL appears to not recognize the signature algorithm of the issuer and just prints the raw OID and bytes of the signature. There's a good reason for this: the MTC does not have a signature in it at all! So what exactly are we looking at?</p><p>The trick to leave out signatures is that a Merkle Tree Certification Authority (MTCA) produces its <i>signatureless</i> certificates <i>in batches</i> rather than individually. In place of a signature, the certificate has an <b>inclusion proof</b> of the certificate in a batch of certificates signed by the MTCA.</p><p>To understand how inclusion proofs work, let's think about a slightly simplified version of the MTC specification. To issue a batch, the MTCA arranges the unsigned certificates into a data structure called a <b>Merkle tree</b> that looks like this:</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4LGhISsS07kbpSgDkqx8p2/68e3b36deeca7f97139654d2c769df68/image3.png" alt="" width="1494" height="1026" loading="lazy">
          </figure><p>Each leaf of the tree corresponds to a certificate, and each inner node is equal to the hash of its children. To sign the batch, the MTCA uses its secret key to sign the head of the tree. The structure of the tree guarantees that each certificate in the batch was signed by the MTCA: if we tried to tweak the bits of any one of the certificates, the treehead would end up having a different value, which would cause the signature to fail.</p><p>An inclusion proof for a certificate consists of the hash of each sibling node along the path from the certificate to the treehead:</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4UZZHkRwsBLWXRYeop4rXv/8598cde48c27c112bc4992889f3d5799/image1.gif" alt="" width="1494" height="1026" loading="lazy">
          </figure><p>Given a validated treehead, this sequence of hashes is sufficient to prove inclusion of the certificate in the tree. This means that, in order to validate an MTC, the client also needs to obtain the signed treehead from the MTCA.</p><p>This is the key to MTC's efficiency:</p><ol><li><p>Signed treeheads can be disseminated to clients out-of-band and validated offline. Each validated treehead can then be used to validate any certificate in the corresponding batch, eliminating the need to obtain a signature for each server certificate.</p></li><li><p>During the TLS handshake, the client tells the server which treeheads it has. If the server has a signatureless certificate covered by one of those treeheads, then it can use that certificate to authenticate itself. That's <b>1 signature,1 public key and 1 inclusion proof</b> per handshake, both for the server being authenticated.</p></li></ol><p>Now, that's the simplified version. MTC proper has some more bells and whistles. To start, it doesn’t create a separate Merkle tree for each batch, but it grows a single large tree, which is used for better transparency. As this tree grows, periodically (sub)tree heads are selected to be shipped to browsers, which we call <b>landmarks</b>. In the common case browsers will be able to fetch the most recent landmarks, and servers can wait for batch issuance, but we need a fallback: MTC also supports certificates that can be issued immediately and don’t require landmarks to be validated, but these are not as small. A server would provision both types of Merkle tree certificates, so that the common case is fast, and the exceptional case is slow, but at least it’ll work.</p>
    <p>
      <h2 id="experimental-deployment">Experimental deployment</h2>
      
    </p>
    <p>Ever since early designs for MTCs emerged, we’ve been eager to experiment with the idea. In line with the IETF principle of “<a href="https://www.ietf.org/runningcode/"><u>running code</u></a>”, it often takes implementing a protocol to work out kinks in the design. At the same time, we cannot risk the security of users. In this section, we describe our approach to experimenting with aspects of the Merkle Tree Certificates design <i>without</i> changing any trust relationships.</p><p>Let’s start with what we hope to learn. We have lots of questions whose answers can help to either validate the approach, or uncover pitfalls that require reshaping the protocol — in fact, an implementation of an early MTC draft by <a href="https://www.cs.ru.nl/masters-theses/2025/M_Pohl___Implementation_and_Analysis_of_Merkle_Tree_Certificates_for_Post-Quantum_Secure_Authentication_in_TLS.pdf"><u>Maximilian Pohl</u></a> and <a href="https://www.ietf.org/archive/id/draft-davidben-tls-merkle-tree-certs-07.html#name-acknowledgements"><u>Mia Celeste</u></a> did exactly this. We’d like to know:</p><p><b>What breaks?</b> Protocol ossification (the tendency of implementation bugs to make it harder to change a protocol) is an ever-present issue with deploying protocol changes. For TLS in particular, despite having built-in flexibility, time after time we’ve found that if that flexibility is not regularly used, there will be buggy implementations and middleboxes that break when they see things they don’t recognize. TLS 1.3 deployment <a href="https://blog.cloudflare.com/why-tls-1-3-isnt-in-browsers-yet/"><u>took years longer</u></a> than we hoped for this very reason. And more recently, the rollout of PQ key exchange in TLS caused the Client Hello to be split over multiple TCP packets, something that many middleboxes <a href="https://tldr.fail/"><u>weren't ready for</u></a>.</p><p><b>What is the performance impact?</b> In fact, we expect MTCs to <i>reduce </i>the size of the handshake, even compared to today's non-PQ certificates. They will also reduce CPU cost: ML-DSA signature verification is about as fast as ECDSA, and there will be far fewer signatures to verify. We therefore expect to see a <i>reduction in latency</i>. We would like to see if there is a measurable performance improvement.</p><p><b>What fraction of clients will stay up to date? </b>Getting the performance benefit of MTCs requires the clients and servers to be roughly in sync with one another. We expect MTCs to have fairly short lifetimes, a week or so. This means that if the client's latest landmark is older than a week, the server would have to fallback to a larger certificate. Knowing how often this fallback happens will help us tune the parameters of the protocol to make fallbacks less likely.</p><p>In order to answer these questions, we are implementing MTC support in our TLS stack and in our certificate issuance infrastructure. For their part, Chrome is implementing MTC support in their own TLS stack and will stand up infrastructure to disseminate landmarks to their users.</p><p>As we've done in past experiments, we plan to enable MTCs for a subset of our free customers with enough traffic that we will be able to get useful measurements. Chrome will control the experimental rollout: they can ramp up slowly, measuring as they go and rolling back if and when bugs are found.</p><p>Which leaves us with one last question: who will run the Merkle Tree CA?</p>
    <p>
      <h3 id="bootstrapping-trust-from-the-existing-webpki">Bootstrapping trust from the existing WebPKI</h3>
      
    </p>
    <p>Standing up a proper CA is no small task: it takes years to be trusted by major browsers. That’s why Cloudflare isn’t going to become a “real” CA for this experiment, and Chrome isn’t going to trust us directly.</p><p>Instead, to make progress on a reasonable timeframe, without sacrificing due diligence, we plan to "mock" the role of the MTCA. We will run an MTCA (on <a href="https://github.com/cloudflare/azul/"><u>Workers</u></a> based on our <a href="https://blog.cloudflare.com/azul-certificate-transparency-log/"><u>StaticCT logs</u></a>), but for each MTC we issue, we also publish an existing certificate from a trusted CA that agrees with it. We call this the <b>bootstrap certificate</b>. When Chrome’s infrastructure pulls updates from our MTCA log, they will also pull these bootstrap certificates, and check whether they agree. Only if they do, they’ll proceed to push the corresponding landmarks to Chrome clients. In other words, Cloudflare is effectively just “re-encoding” an existing certificate (with domain validation performed by a trusted CA) as an MTC, and Chrome is using certificate transparency to keep us honest.</p>
    <p>
      <h2 id="conclusion">Conclusion</h2>
      
    </p>
    <p>With almost 50% of our traffic already protected by post-quantum encryption, we’re halfway to a fully post-quantum secure Internet. The second part of our journey, post-quantum certificates, is the hardest yet though. A simple drop-in upgrade has a noticeable performance impact and no security benefit before Q-day. This means it’s a hard sell to enable today by default. But here we are playing with fire: migrations always take longer than expected. If we want to keep an ubiquitously private and secure Internet, we need a post-quantum solution that’s performant enough to be enabled by default <b>today</b>.</p><p>Merkle Tree Certificates (MTCs) solves this problem by reducing the number of signatures and public keys to the bare minimum while maintaining the WebPKI's essential properties. We plan to roll out MTCs to a fraction of free accounts by early next year. This does not affect any visitors that are not part of the Chrome experiment. For those that are, thanks to the bootstrap certificates, there is no impact on security.</p><p>We’re excited to keep the Internet fast <i>and</i> secure, and will report back soon on the results of this experiment: watch this space! MTC is evolving as we speak, if you want to get involved, please join the IETF <a href="https://mailman3.ietf.org/mailman3/lists/plants@ietf.org/"><u>PLANTS mailing list</u></a>.</p></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><astro-slot> <!--[if astro]>server-island-start<![endif]--> </astro-slot><a href="https://blog.cloudflare.com/tag/post-quantum/">Post-Quantum</a><a href="https://blog.cloudflare.com/tag/research/">Research</a><a href="https://blog.cloudflare.com/tag/cryptography/">Cryptography</a><a href="https://blog.cloudflare.com/tag/security/">Security</a><a href="https://blog.cloudflare.com/tag/tls/">TLS</a><a href="https://blog.cloudflare.com/tag/chrome/">Chrome</a><a href="https://blog.cloudflare.com/tag/google/">Google</a><a href="https://blog.cloudflare.com/tag/ietf/">IETF</a><a href="https://blog.cloudflare.com/tag/transparency/">Transparency</a><a href="https://blog.cloudflare.com/tag/rust/">Rust</a><a href="https://blog.cloudflare.com/tag/open-source/">Open Source</a><a href="https://blog.cloudflare.com/tag/workers/">Cloudflare Workers</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tor Browser 15.0 (115 pts)]]></title>
            <link>https://blog.torproject.org/new-release-tor-browser-150/</link>
            <guid>45739515</guid>
            <pubDate>Tue, 28 Oct 2025 21:33:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.torproject.org/new-release-tor-browser-150/">https://blog.torproject.org/new-release-tor-browser-150/</a>, See on <a href="https://news.ycombinator.com/item?id=45739515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Tor Browser 15.0 is now available from the <a href="https://www.torproject.org/download/">Tor Browser download page</a> and <a href="https://www.torproject.org/dist/torbrowser/15.0/">distribution directory</a>. This is our first stable release based on <a href="https://www.firefox.com/en-US/firefox/140.0esr/releasenotes/">Firefox ESR 140</a>, incorporating a year's worth of changes that have been shipped upstream in Firefox. As part of this process, we've also completed our annual ESR transition audit, where we <a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/?sort=updated_desc&amp;state=all&amp;label_name%5B%5D=esr-140&amp;search=Review%20Mozilla&amp;first_page_size=20">reviewed and addressed around 200 Bugzilla issues</a> for changes in Firefox that may negatively affect the privacy and security of Tor Browser users. Our final reports from this audit are now available in the <a href="https://gitlab.torproject.org/tpo/applications/tor-browser-spec/-/tree/main/audits">tor-browser-spec repository</a> on our GitLab instance.</p>
<p>The ongoing development of Tor Browser is made possible thanks to the support of our community. If Tor Browser is important to you, now is a great time to support our mission to <strong>FREE THE INTERNET</strong>, as all donations will be matched by <a href="https://powerupprivacy.com/">Power Up Privacy</a> through December 31, 2025.</p>
<p><a href="https://torproject.org/donate/donate-bp2-yec2025"><img src="https://blog.torproject.org/new-release-tor-browser-150/button-donate-yec25.png" alt="Donate button"></a></p>
<h2>What's new?</h2>
<h3>Desktop</h3>
<p>Tor Browser 15.0 inherits a multitude of useful new features and usability improvements from Firefox that have passed our audit. For desktop, these include vertical tabs: providing a more manageable, alternative layout with open and pinned tabs stacked in a sidebar rather than across the top of the window. For ease of access, Bookmarks can be retrieved directly from the sidebar when expanded too. However, regardless of whether you prefer horizontal or vertical tabs, everyone  benefits from the addition of tab groups: helping you keep on top of the clutter by organizing tabs into collapsible groups that can be given names and color-coded. Tor Browser 15.0 also inherits elements of Firefox's recent address bar refresh, including a new unified search button that allows you to switch search engines on the fly, search bookmarks or tabs, and reference quick actions from the same menu.</p>
<p>Note that Tor Browser tabs are still private tabs, and will clear when you close the browser. This enforces a kind of natural tidiness in Tor Browser since each new session starts fresh – however for privacy-conscious power users, project managers, researchers, or anyone else who accumulates tabs frighteningly quickly, we hope these organizational improvements will give you a much needed productivity boost.</p>
<p><img src="https://blog.torproject.org/new-release-tor-browser-150/150-desktop.png" alt="A screenshot featuring Tor Browser for Desktop with vertical tabs enabled and three tab groups present in the resulting sidebar"></p>
<h3>Android</h3>
<p>On Android, screen lock adds an extra layer of security to your browsing sessions. After enabling screen lock in Settings &gt; Tabs, your tabs will lock automatically when you switch away from the browser without closing it. Upon returning to the app, you'll be prompted to unlock your tabs using your fingerprint, face, or pass code, depending on which option your device is configured to use.</p>
<p>Like Tor Browser for Desktop, your browsing session will still be cleared when Tor Browser is closed. However, this feature provides peace of mind in a specific scenario: by ensuring that your browsing remains private even if someone has gained temporary access to your unlocked phone with Tor Browser open in the background – whether you've handed it to a friend, or left your device sitting on a table.</p>
<p><img src="https://blog.torproject.org/new-release-tor-browser-150/150-android.png" alt="A screenshot demonstrating screen lock for Tor Browser on an Android phone, followed by a second screenshot of a passcode being entered"></p>
<h2>What's changing?</h2>
<h3>Updates to Android and Linux device compatibility</h3>
<p>At present, Firefox 140 and Tor Browser 15.0 support Android 5.0 or later, which was released almost 11 years ago. While Mozilla's commitment to support such an old version of Android is admirable, it introduces several technical and security challenges for developers. As a consequence, Firefox have announced their intention to increase the minimum support requirements to Android 8.0, and have also decided to drop support for x86 CPUs for <a href="https://blog.mozilla.org/futurereleases/2025/09/15/raising-the-minimum-android-version-for-firefox/">Android</a> and <a href="https://support.mozilla.org/en-US/kb/firefox-has-ended-support-32-bit-linux">Linux</a>. Sadly, it's not possible for the Tor Project to maintain support for these platforms on our own without official support from Mozilla.</p>
<p>While these changes won't impact Tor Browser users immediately, we expect them to take effect with the release of Tor Browser 16.0 mid-next year. This means that Tor Browser 15.0 will be the last major release to support x86 for Linux and Android, in addition to Android 5.0, 6.0, and 7.0. However, we will continue to release minor updates with security fixes for these platforms until Tor Browser 16.0's eventual release.</p>
<p>Although nobody wants to see support for their platform get dropped, it's an important step to maintain the stability and security of both Firefox and Tor Browser over time, and will allow developers to utilize newer technologies in both browsers. In addition, supporting x86 for Android has been particularly challenging for our developers due to the 100MB package size limit imposed by Google Play. While we have deployed several workarounds to stay within this limit in the recent past, these often come at a cost – such as x86 Android users missing out on the Conjure pluggable transport, for example.</p>
<h3>Disabling of WebAssembly now managed by NoScript</h3>
<p>WebAssembly (or Wasm) is a web technology that helps websites and web apps run faster. It allows web developers to write programs in languages like C, C++ or Rust, and compiles these into a special format that web browsers can run more efficiently.</p>
<p>As has been suggested in <a href="https://arxiv.org/html/2407.12297v1">this meta-analysis from 2024</a>, further investigation of Wasm's potential exploits is necessary – therefore Wasm is currently disabled in the Safer and Safest security levels in order to reduce Tor Browser's attack surface. Up until now, this was achieved by setting the global preference <code>javascript.options.wasm</code> to false – however this approach was no longer viable after Mozilla implemented part of their PDF reader in Wasm between versions 128 and 140. Consequently, we have decided to move control of Wasm to NoScript, which is bundled with Tor Browser, and already manages JavaScript and other security features. This means that Wasm now works on privileged browser pages such as the PDF renderer, but NoScript will continue blocking the technology on regular websites at the Safer and Safest security levels.</p>
<p>Users who have manually set <code>javascript.options.wasm</code> to "false" while in the Standard security level will see their security level represented as "Custom" instead. To mitigate any issues that may arise with the browser's PDF reader, we encourage those users to switch the preference back to "true", thereby passing management of Wasm over to NoScript. Furthermore, manually disabling Wasm at the Standard security level (either via NoScript or <code>javascript.options/wasm</code>) may also <a href="https://tb-manual.torproject.org/anti-fingerprinting/">make your fingerprint more unique</a> by deviating from Tor Browser's default configuration. To avoid this scenario, we recommend sticking with one of the <a href="https://tb-manual.torproject.org/security-settings/">pre-defined security levels</a> and caution users against making further changes to individual preferences in about:config.</p>
<p>Alternatively, should you wish to keep Wasm disabled in future, we invite you to increase your security level to Safer or Safest going forward. Note that both Safer and Safest users may notice <code>javascript.options.wasm</code> switch to "true" automatically as management of Wasm is passed over to and blocked by NoScript, meaning that you are still protected regardless. In addition, Safest users in particular are not vulnerable to any potential vulnerabilities introduced by Wasm since the format requires JavaScript to work.</p>
<h2>Known issues</h2>
<p>Tor Browser 15.0 comes with a number of known issues that can be found in <a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues">Tor Browser's issue tracker</a>. In particular, we would like to highlight the following:</p>
<h3>Desktop</h3>
<p>The initial release of vertical tabs in Tor Browser includes a couple of quirks:</p>
<ul>
<li>When the sidebar is visible (such as when vertical tabs are enabled), the window may visibly resize when Tor Browser is launched.</li>
<li>Due to variations in window size, <a href="https://support.torproject.org/tbb/maximized-torbrowser-window/">Letterboxing</a> may be visible. You still get the anti-fingerprinting protections provided by Letterboxing, but the default window size will be different than intended.</li>
</ul>
<p>We are currently working to issue a fix for both of these bugs. Please see <a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44096">tor-browser#44096</a> for details.</p>
<h3>Android</h3>
<ul>
<li>Web pages may not load after updating Tor Browser on older versions of Android. This can be fixed by clearing your app cache manually in <code>Settings &gt; Apps &gt; Tor Browser &gt; Storage &amp; cache</code>.</li>
</ul>
<h2>Get involved</h2>
<p>If you find a bug or have a suggestion for how we could improve this release, <a href="https://support.torproject.org/misc/bug-or-feedback/">we'd love to hear your feedback</a>. If you would like to contribute to a future release, please see <a href="https://gitlab.torproject.org/tpo/applications/wiki/-/wikis/Development-Information/Tor-Browser/Contributing-to-Tor-Browser">our guide for new contributors</a> to get started.</p>
<h2>Full changelog</h2>
<p>The <a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/raw/maint-15.0/projects/browser/Bundle-Data/Docs-TBB/ChangeLog.txt">full changelog</a> since Tor Browser 14.5.9 is:</p>
<ul>
<li>All Platforms<ul>
<li>Updated NoScript to 13.2.2</li>
<li>Updated Lyrebird to 0.6.2</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/19741">Bug tor-browser#19741</a>: Opensearch (contextual search) does not obey FPI</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43009">Bug tor-browser#43009</a>: Backport Bug 1973265 - Put WebCodecs API behind RFP Target</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43093">Bug tor-browser#43093</a>: Refactor the patch to disable LaterRun</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43727">Bug tor-browser#43727</a>: Update moz-toggle customisation for ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43745">Bug tor-browser#43745</a>: Disable HEVC (H265) playback support</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43772">Bug tor-browser#43772</a>: Do not use official branding for BB/TB/MB</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43784">Bug tor-browser#43784</a>: Get confirmation from NoScript that settings are applied</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43832">Bug tor-browser#43832</a>: Drop eslint-env</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43850">Bug tor-browser#43850</a>: Modify the Contrast Control settings for RFP</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43853">Bug tor-browser#43853</a>: DomainFrontedRequests: setData is no longer a function</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43864">Bug tor-browser#43864</a>: Remove features from the unified search button</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43869">Bug tor-browser#43869</a>: Hide pens with RFP</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43880">Bug tor-browser#43880</a>: Update moat's domain front url</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44045">Bug tor-browser#44045</a>: Drop AI and machine learning components</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44068">Bug tor-browser#44068</a>: Handle migration from meek-azure to meek built-in bridge type</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44069">Bug tor-browser#44069</a>: Update <code>meek-azure</code> related strings to <code>meek</code></li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44140">Bug tor-browser#44140</a>: Refactored patch to prevent writing temp PDF files to disk</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44234">Bug tor-browser#44234</a>: No images in PDF</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44275">Bug tor-browser#44275</a>: Reduce console noise on security level guess</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44280">Bug tor-browser#44280</a>: Test stream isolation</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41429">Bug tor-browser-build#41429</a>: Add a note about user safety to Tor Browser Alpha blog posts</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41442">Bug tor-browser-build#41442</a>: Update our audit CSVs to use the new Audit template</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41502">Bug tor-browser-build#41502</a>: Application services build is failing on isNetworkAllowed()</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41609">Bug tor-browser-build#41609</a>: Use new CDN77 fronts for snowflake</li>
</ul>
</li>
<li>Windows + macOS + Linux<ul>
<li>Updated Firefox to 140.4.0esr</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/42025">Bug tor-browser#42025</a>: Purple elements (e.g. Tor buttons) need dark theme variants</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/42738">Bug tor-browser#42738</a>: Tidy up the commit structure for browser updates UI</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43111">Bug tor-browser#43111</a>: Delete our webextensions for search engines when Bug 1885953 is fixed upstream</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43519">Bug tor-browser#43519</a>: Replace tor-loading.png with SVG</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43525">Bug tor-browser#43525</a>: Check if our search engine customization still works after ESR 140 transition</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43590">Bug tor-browser#43590</a>: Move letterboxing rules out of browser/base/content/browser.css</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43610">Bug tor-browser#43610</a>: Use newer CSS variable names for ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43629">Bug tor-browser#43629</a>: All migrations in migrateUIBB are run for new profiles</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43636">Bug tor-browser#43636</a>: Tor exiting during startup with "connect automatically" leads to "Try a bridge" page</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43638">Bug tor-browser#43638</a>: Fix up our <code>&amp;lt;command&amp;gt;</code> elements</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43664">Bug tor-browser#43664</a>: Review Mozilla 1842832: Move the private browsing toggle to initial install dialog</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43728">Bug tor-browser#43728</a>: Update search engine icon sizes</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43765">Bug tor-browser#43765</a>: Temporarily disable Lox</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43766">Bug tor-browser#43766</a>: Only save the relevant TorSettings changes to preferences.</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43770">Bug tor-browser#43770</a>: Bugzilla 1958070: More BrowserGlue simplification/splitting</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43776">Bug tor-browser#43776</a>: Set branding files for l10n merging</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43795">Bug tor-browser#43795</a>: Restore the URL classifier XPCOM components.</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43817">Bug tor-browser#43817</a>: Write e2e test for verifying if the browser is connected to the Tor network</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43844">Bug tor-browser#43844</a>: Security level shield icon should be flipped for RTL locales</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43874">Bug tor-browser#43874</a>: Incorporate our unified extension button hiding logic into mozilla's changes for ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43879">Bug tor-browser#43879</a>: tor-branding.css declarations are overwritten</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43886">Bug tor-browser#43886</a>: Fix new tab for ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43900">Bug tor-browser#43900</a>: Open newtab rather than firefoxview when unloading the last tab</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43901">Bug tor-browser#43901</a>: Modify about:license for Tor Browser and drop about:rights</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43902">Bug tor-browser#43902</a>: Hide Sidebar buttons</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43903">Bug tor-browser#43903</a>: Report broken site is disabled rather than hidden</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43905">Bug tor-browser#43905</a>: base-browser.ftl missing from about:addons</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43906">Bug tor-browser#43906</a>: Extension.sys.mjs change in the wrong commit</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43913">Bug tor-browser#43913</a>: Context menu not properly populated</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43929">Bug tor-browser#43929</a>: two about:tor pages opened after update</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43930">Bug tor-browser#43930</a>: Onionize toggle not centre aligned in about:tor</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43947">Bug tor-browser#43947</a>: Console error from ContentBlockingPrefs.init</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43966">Bug tor-browser#43966</a>: Notify the user when they are in a custom security level (desktop)</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43989">Bug tor-browser#43989</a>: Switch off AI chatbot preference</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44030">Bug tor-browser#44030</a>: Security Level selector does not get confirmation before restarting</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44034">Bug tor-browser#44034</a>: Update string used for checkbox on New Identity confirmation dialog</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44040">Bug tor-browser#44040</a>: Modify nsIPrompt and the commonDialog code to allow destructive buttons</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44090">Bug tor-browser#44090</a>: Several of our XUL pages cause a crash because of missing CSP</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44095">Bug tor-browser#44095</a>: Rename connectionPane.xhtml and remove it from the jar</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44101">Bug tor-browser#44101</a>: Toolbar connection status is not visible when using vertical tabs</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44106">Bug tor-browser#44106</a>: Make sure background tasks are not used for shutdown cleanup</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44107">Bug tor-browser#44107</a>: Switch tab search action is missing an icon</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44108">Bug tor-browser#44108</a>: Fix the new history sidebar</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44115">Bug tor-browser#44115</a>: Make remove all bridges dialog use a destructive red button</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44123">Bug tor-browser#44123</a>: Do not trim protocol off of URLs ever</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44125">Bug tor-browser#44125</a>: Do not offer to save signatures by default in Private Browsing Mode</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44141">Bug tor-browser#44141</a>: Hide "Report broken site" items by default</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44142">Bug tor-browser#44142</a>: Missing document_pdf.svg from our branding directories</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44145">Bug tor-browser#44145</a>: Switch onion connection icons to use --icon-color-critical and --icon-color</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44153">Bug tor-browser#44153</a>: Test search engine customization</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44159">Bug tor-browser#44159</a>: Change or hide the sidebar settings description</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44177">Bug tor-browser#44177</a>: Remove more urlbar actions</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44178">Bug tor-browser#44178</a>: Search preservation does not work with duckduckgo in safest security level</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44180">Bug tor-browser#44180</a>: Clear YEC 2024 preference</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44184">Bug tor-browser#44184</a>: Duckduckgo Onion Lite search does not work properly in safest when added as a search engine</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44187">Bug tor-browser#44187</a>: TLS session tickets leak Private Browsing mode</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44192">Bug tor-browser#44192</a>: Hovering unloaded tab causes console error</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44213">Bug tor-browser#44213</a>: Reduce linkability concerns of the "Search with" contextual search action</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44214">Bug tor-browser#44214</a>: Update letterboxing to reflect changes in ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44215">Bug tor-browser#44215</a>: Hide Firefox home settings in about:preferences</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44221">Bug tor-browser#44221</a>: Backport MozBug 1984333 Bump Spoofed Processor Count</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44239">Bug tor-browser#44239</a>: DDG HTML page and search results displayed incorrectly with Safest security setting</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44262">Bug tor-browser#44262</a>: Disable adding search engines from HTML forms</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44270">Bug tor-browser#44270</a>: Match Firefox's TLS fingerprint</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44279">Bug tor-browser#44279</a>: Disable contextual search install prompt</li>
</ul>
</li>
<li>Windows + Android<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44062">Bug tor-browser#44062</a>: Force touch enabled on Windows and Android</li>
</ul>
</li>
<li>Windows<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44046">Bug tor-browser#44046</a>: Replace BASE_BROWSER_UPDATE with BASE_BROWSER_VERSION in the font visibility list</li>
</ul>
</li>
<li>macOS<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44127">Bug tor-browser#44127</a>: Do not show macOS Privacy hint on network error pages</li>
</ul>
</li>
<li>Linux<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43950">Bug tor-browser#43950</a>: Review Mozilla 1894818: Support HEVC playback on Linux</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43959">Bug tor-browser#43959</a>: Make Noto Color Emoji the default emoji font on Linux</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44227">Bug tor-browser#44227</a>: Some CJK characters cannot be rendered by Tor which uses the Noto font family</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44286">Bug tor-browser#44286</a>: Hardcode GTK system font</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41586">Bug tor-browser-build#41586</a>: Replace Noto CJK with Jigmo on Linux</li>
</ul>
</li>
<li>Android<ul>
<li>Updated GeckoView to 140.4.0esr</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43179">Bug tor-browser#43179</a>: Make persistent 'private tabs' notification distinct from Firefox's</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43401">Bug tor-browser#43401</a>: Replace the constructor of Locale with a builder</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43577">Bug tor-browser#43577</a>: Flush settings fails on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43643">Bug tor-browser#43643</a>: Clean out unused tor connect strings</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43650">Bug tor-browser#43650</a>: Survey banner behaves like a dialog on Android, rather than a card</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43676">Bug tor-browser#43676</a>: Preemptively disable unified trust panel by default so we are tracking for next ESR</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43699">Bug tor-browser#43699</a>: Dummy "about:" pages are not cleared from recently closed tabs (and possibly elsewhere) because they are normal tabs, not private tabs.</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43755">Bug tor-browser#43755</a>: Restore functionality of "switch to tab" urlbar suggestion</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43757">Bug tor-browser#43757</a>: Disable setting for trending search</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43826">Bug tor-browser#43826</a>: Review Mozilla 1960122: Use <code>MOZ_BUILD_DATE</code> in Fenix build configuration</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43855">Bug tor-browser#43855</a>: brand.properties merging on Android is broken in 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43943">Bug tor-browser#43943</a>: Review Mozilla 1928705: Ship Android Font Restrictions as part of FPP</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44021">Bug tor-browser#44021</a>: Android settings page colors are sometimes messed up (seems to be on the first launch)</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44029">Bug tor-browser#44029</a>: Search/url bar doesn't work on android after ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44036">Bug tor-browser#44036</a>: Crash on opening "Search Settings" on android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44042">Bug tor-browser#44042</a>: Debug crash when opening settings too quickly after launching app</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44047">Bug tor-browser#44047</a>: Tor Browser's home doesn't have the background at the first load on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44080">Bug tor-browser#44080</a>: Further remove "Analytics data collection and usage"</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44083">Bug tor-browser#44083</a>: "snowflake" is lower case on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44098">Bug tor-browser#44098</a>: Bookmarks offer a way to go to sync in 15.0a1</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44133">Bug tor-browser#44133</a>: Hide the "Allow in private browsing" checkboxes from WebExtension management UI</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44139">Bug tor-browser#44139</a>: Restore the (inactive) YouTube and Reddit search plugins on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44172">Bug tor-browser#44172</a>: Fix crash in TorAndroidIntegration.handleMessage()</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44196">Bug tor-browser#44196</a>: Persistent notification sometimes does not clear</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44237">Bug tor-browser#44237</a>: Revoke access to all advertising ids available in Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44293">Bug tor-browser#44293</a>: Force immediate NoScript update checks after bootstrap</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41494">Bug tor-browser-build#41494</a>: Update GeckoView build scripts for ESR140</li>
</ul>
</li>
<li>Build System<ul>
<li>All Platforms<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43615">Bug tor-browser#43615</a>: Add Gitlab Issue and Merge request templates</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43616">Bug tor-browser#43616</a>: Customize Gitlab Issue and Merge templates</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43891">Bug tor-browser#43891</a>: Update the translation CI to use the new mozilla versions</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43954">Bug tor-browser#43954</a>: Update tb-dev to handle lightweight tags</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43962">Bug tor-browser#43962</a>: update tb-dev auto-fixup for git 2.50</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44061">Bug tor-browser#44061</a>: "Contributing" link is broken</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44067">Bug tor-browser#44067</a>: Move --enable-geckodriver only to Linux-only mozconfigs</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44103">Bug tor-browser#44103</a>: git's export-subst is a reproducibility problem</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44104">Bug tor-browser#44104</a>: Don't run linter when there are no overall changes</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/26408">Bug tor-browser-build#26408</a>: Make MAR signature checks clearer when creating incremental MAR files</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/34434">Bug tor-browser-build#34434</a>: Remove unused variables from rbm.conf</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/40551">Bug tor-browser-build#40551</a>: Drop go reproducibility patches</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/40697">Bug tor-browser-build#40697</a>: Delete repackage_browser.sh</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/40698">Bug tor-browser-build#40698</a>: Update locale in tbb_version.json</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41064">Bug tor-browser-build#41064</a>: Update tools/signing/README and add a tools/signing/machines-setup/README</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41227">Bug tor-browser-build#41227</a>: Update projects/common/list_toolchain_updates-common-firefox-geckoview to include check for binutils</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41434">Bug tor-browser-build#41434</a>: Go updates shouldn't target all platforms until macOS is on legacy in the changelogs</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41444">Bug tor-browser-build#41444</a>: Build artifacts to support artifact builds of Tor/Muillvad/Base Browser</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41448">Bug tor-browser-build#41448</a>: Update toolchains for Firefox ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41459">Bug tor-browser-build#41459</a>: Update taskcluster/ci paths in README and comments</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41465">Bug tor-browser-build#41465</a>: Disable development artifacts generation by default, keep it enabled for nightly builds</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41474">Bug tor-browser-build#41474</a>: update README to explain moat-settings project requires <code>jq</code> to be installed</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41478">Bug tor-browser-build#41478</a>: Add vim and others missing basic tools to base container image</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41486">Bug tor-browser-build#41486</a>: Track bundletool and osslicenses-plugin versions in list_toolchain_updates_checks</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41496">Bug tor-browser-build#41496</a>: Clean up unused projects</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41501">Bug tor-browser-build#41501</a>: cargo_vendor generated archive maintains timestamps</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41514">Bug tor-browser-build#41514</a>: Remove var/build_go_lib from projects/go/config</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41532">Bug tor-browser-build#41532</a>: Rename meek-azure to meek in pt_config.json</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41534">Bug tor-browser-build#41534</a>: Copy geckodriver only for Linux x86-64</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41537">Bug tor-browser-build#41537</a>: Add script to count mar downloads from web logs</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41539">Bug tor-browser-build#41539</a>: Update Ubuntu version used to run mmdebstrap to 24.04.3</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41568">Bug tor-browser-build#41568</a>: Update instructions for manually building 7zip</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41576">Bug tor-browser-build#41576</a>: Build expert bundles outside containers</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41579">Bug tor-browser-build#41579</a>: Add zip to the list of Tor Browser Build dependencies</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41594">Bug tor-browser-build#41594</a>: Remove version from tor-expert-bundle and tor-expert-bundle-aar filenames</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41600">Bug tor-browser-build#41600</a>: update lyrebird version to v0.6.2</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41602">Bug tor-browser-build#41602</a>: Update tools/changelog-format-blog-post</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/rbm/-/issues/40084">Bug rbm#40084</a>: Always use bash for the debug terminal</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/rbm/-/issues/40087">Bug rbm#40087</a>: Downloaded files getting stricter permissions than expected</li>
</ul>
</li>
<li>Windows + macOS + Linux<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44131">Bug tor-browser#44131</a>: Generate torrc-defaults and put it in objdir post-build</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41373">Bug tor-browser-build#41373</a>: Remove <code>_ALL</code> from mar filenames</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41457">Bug tor-browser-build#41457</a>: Set mar IDs as env variables in tor-browser-build</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41604">Bug tor-browser-build#41604</a>: Keep update-responses files from previous release</li>
</ul>
</li>
<li>Windows + Linux + Android<ul>
<li>Updated Go to 1.24.9</li>
</ul>
</li>
<li>Windows<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44167">Bug tor-browser#44167</a>: Move the nsis-uninstall.patch to tor-browser repository</li>
</ul>
</li>
<li>macOS<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41503">Bug tor-browser-build#41503</a>: Error 403 when downloading macOS SDK</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41527">Bug tor-browser-build#41527</a>: Update libdmg-hfsplus and enable LZMA compression on dmgs</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41538">Bug tor-browser-build#41538</a>: Bump macOS SDK to 15.5</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41571">Bug tor-browser-build#41571</a>: Work-around to prevent older 7z versions to break rcodesign.</li>
</ul>
</li>
<li>Linux<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41458">Bug tor-browser-build#41458</a>: Ship geckodriver only on Linux</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41488">Bug tor-browser-build#41488</a>: Disable sys/random.h for Node.js</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41558">Bug tor-browser-build#41558</a>: Share descriptions between Linux packages and archives</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41561">Bug tor-browser-build#41561</a>: Ship Noto Color Emoji on Linux</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41569">Bug tor-browser-build#41569</a>: Use var/display_name in .desktop files</li>
</ul>
</li>
<li>Android<ul>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43984">Bug tor-browser#43984</a>: Update android build scripts and docs for ESR 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/43987">Bug tor-browser#43987</a>: 140 Android is not reproducible</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44078">Bug tor-browser#44078</a>: Modify ./autopublish-settings.gradle for building a-s and glean with uniffi-bindgen no-op</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/44220">Bug tor-browser#44220</a>: Disable the JS minifier as it produces invalid JS</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41453">Bug tor-browser-build#41453</a>: Update application-services and uniffi-rs for ESR140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41467">Bug tor-browser-build#41467</a>: Remove list_toolchain_updates-firefox-android from Makefile</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41483">Bug tor-browser-build#41483</a>: geckoview_example-withGeckoBinaries-....apk doesn't exist anymore in Firefox 140</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41484">Bug tor-browser-build#41484</a>: Create a fork of application-services</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41500">Bug tor-browser-build#41500</a>: Optimize tor and its dependencies for size on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41506">Bug tor-browser-build#41506</a>: Use appilcation-services branch for nightlies builds</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41507">Bug tor-browser-build#41507</a>: Single-arch build fails because artifacts don't have arch subdirectories</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41523">Bug tor-browser-build#41523</a>: Use custom built Glean package on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41548">Bug tor-browser-build#41548</a>: Hide tor's symbols on Android and add other linker options to save space</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41577">Bug tor-browser-build#41577</a>: Minify JS with UglifyJS on Android x86</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41583">Bug tor-browser-build#41583</a>: Align tor and PTs to 16kB on Android</li>
<li><a href="https://gitlab.torproject.org/tpo/applications/tor-browser-build/-/issues/41605">Bug tor-browser-build#41605</a>: Ignore incrementals if we're not building desktop</li>
</ul>
</li>
</ul>
</li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tinkering is a way to acquire good taste (422 pts)]]></title>
            <link>https://seated.ro/blog/tinkering-a-lost-art</link>
            <guid>45739499</guid>
            <pubDate>Tue, 28 Oct 2025 21:31:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://seated.ro/blog/tinkering-a-lost-art">https://seated.ro/blog/tinkering-a-lost-art</a>, See on <a href="https://news.ycombinator.com/item?id=45739499">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <h2 id="tinker">tin·ker</h2>
<h4 id="ˈtingkər">/ˈtiNGkər/</h4>
<h4 id="to-make-small-changes-to-something-especially-in-an-attempt-to-repair-or-improve-it.">to make small changes to something, especially in an attempt to repair or improve it.</h4>
<h2 id="in-hindsight">In Hindsight</h2>
<p>Growing up, I never stuck to a single thing, be it guitar lessons, art school, martial arts – I tried them all. when it came to programming, though, I never really tinkered. I was always amazed with video games and wondered how they were made but I never pursued that curiosity.</p>
<p>My tinkering habits picked up very late, and now I cannot go by without picking up new things in one form or another. It’s how I learn. I wish I did it sooner. It’s a major part of my learning process now, and I would never be the <s>programmer</s> person I am today.</p>
<h2 id="what-the-hell-is-tinkering">What the hell is tinkering?</h2>
<p>Have you ever spent hours tweaking the mouse sensitivity in your favorite FPS game?</p>
<p>Have you ever installed a Linux distro, spent days configuring window managers, not because you had to, but purely because it gave you satisfaction and made your workflow exactly yours?</p>
<p>Ever pulled apart your mechanical keyboard, swapped keycaps, tested switches, and lubed stabilizers just for more thock?</p>
<p>That is what I mean.</p>
<p>I have come to understand that there are two kinds of people, those who do things only if it helps them achieve a goal, and those who do things just because. The ideal, of course, is to be a mix of both.</p>
<blockquote>
<p>when you tinker and throw away, that’s practice, and practice should inherently be ephemeral, exploratory, and be frequent - <a href="https://x.com/ludwigABAP/status/1842366186824032737"><span data-cites="ludwigABAP">@ludwigABAP</span></a></p>
</blockquote>
<h2 id="my-approach-to-tinkering">My approach to tinkering</h2>
<p>There are plenty of people who still use the VSCode terminal as their default terminal, do not know what vim bindings are, GitHub desktop rather than the cli (at the very least). I’m not saying these are bad things necessarily, just that this should be the minimum, not the median.</p>
<p>This does not mean I spend every waking hour fiddling with my neovim config. In fact, the last meaningful change to my config was 6 months ago. Finding that balance is where most people fail.</p>
<p>Over the years I have done so many things that in hindsight have made me appreciate programming more but were completely “unnecessary” in the strict sense.</p>
<p>In the past week I have, for the first time, written a glsl fragment shader, a rust procedural macro, template c++, a swift app, furthered my hatred for windows development (this is not new), and started using the helix editor more (mainly for good defaults + speed). I didn’t have to do these things, but I did, for fun! And I know more about these things now.</p>
<p>No time spent learning, is time wasted.</p>
<h2 id="why-taste-matters-especially-now">Why taste matters, especially now</h2>
<p>Acquiring good taste comes through using various things, discarding the ones you don’t like and keeping the ones you do. if you never try various things, you will not acquire good taste.</p>
<p>And what I mean by taste here is simply the honed ability to distinguish mediocrity from excellence. This will be highly subjective, and not everyone’s taste will be the same, but that is the point, you should NOT have the same taste as someone else.</p>
<p>Question the status quo, experiment, break things, do this several times, do this everyday and keep doing it.</p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI Image Editing Showdown (309 pts)]]></title>
            <link>https://genai-showdown.specr.net/image-editing</link>
            <guid>45739080</guid>
            <pubDate>Tue, 28 Oct 2025 20:58:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://genai-showdown.specr.net/image-editing">https://genai-showdown.specr.net/image-editing</a>, See on <a href="https://news.ycombinator.com/item?id=45739080">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Boring Is What We Wanted (418 pts)]]></title>
            <link>https://512pixels.net/2025/10/boring-is-what-we-wanted/</link>
            <guid>45738247</guid>
            <pubDate>Tue, 28 Oct 2025 19:57:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://512pixels.net/2025/10/boring-is-what-we-wanted/">https://512pixels.net/2025/10/boring-is-what-we-wanted/</a>, See on <a href="https://news.ycombinator.com/item?id=45738247">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-34213">
	<!-- .entry-header -->

	<div>
		<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/10/M1-M5.jpg" alt="M1-M5"></p>
<p>We are coming up on five years since the first M1 Macs shipped. It was an incredible time to be a Mac user. Those first Apple silicon Macs <em>looked</em> like the Intel machines they replaced, but they were better in every single way.</p>
<p>In December 2020, <a href="https://daringfireball.net/2020/12/m1_macs_truth_and_truthiness">John Gruber wrote</a>:</p>
<blockquote><p>
  We knew this to be true: Computers could run fast and hot, or slow and cool. For laptops in particular, the best you could hope for is a middle ground: fast enough and cool enough. But if you wanted a machine that ran really fast, it wasn’t going to run cool (and wasn’t going to last long on battery), and if you wanted a computer that ran cool (and lasted long on battery), it wasn’t going to be fast.</p>
<p>  We knew this to be true because that was the way things were. But now, with the M1 Macs, it’s not. M1 Macs run very fast and do so while remaining very cool and lasting mind-bogglingly long on battery. It was a fundamental trade-off inherent to PC computing, and now we don’t have to make it.
</p></blockquote>
<p>Despite its Touch Bar, I immediately bought that first M1 MacBook Pro, and when the 14-inch MacBook Pro came out a year later, I moved to it.<sup id="fnref-34213-fn-14mbp"><a href="#fn-34213-fn-14mbp" title="Read footnote.">1</a></sup> I’m typing these very words on my 14-inch MacBook Pro with an M4 Max inside. Each of these machines was faster than the one before it, outperforming my old iMac Pro and Mac Pro in new ways with every upgrade.</p>
<p>Apple silicon has been nothing but upside for the Mac, and yet some seem bored already. In the days since Apple announced the M5, I’ve seen and heard this sentiment more than I expected:</p>
<blockquote><p>
  This is just another boring incremental upgrade.
</p></blockquote>
<p>That 👏 is 👏 the 👏 point.</p>
<p>Back in the PowerPC and Intel days, Macs would sometimes go <em>years</em> between meaningful spec bumps, as Apple waited on its partners to deliver appropriate hardware for various machines. From failing NVIDIA cards in MacBook Pros to 27-inch Intel iMacs that ran so hot the fans were audible at all times, Mac hardware wasn’t always what Apple wanted.</p>
<p>Of course, some of the issues with previous generations of Mac were Apple’s fault — look no further than the butterfly keyboard or the years the Mac Pro spent in the wilderness. Apple will make questionable decisions in the future, just as it has in the past.</p>
<p>The difference is that with Apple silicon, Apple owns and controls the primary technologies behind the products it makes, <a href="https://asymco.com/2011/01/17/the-cook-doctrine/">as Tim Cook has always wanted</a>. It means that it can ship updates to its SoCs on a regular cadence, making progress in terms of both power and efficiency each time.</p>
<p>A predictable update schedule means that incremental updates are inevitable. <em>Revolution</em> then <em>evolution</em> is not a bad thing; it’s okay that not every release is exciting or groundbreaking. It’s how technology has worked for decades.</p>
<p>…but some people have short memories. Before the Apple silicon introduction, we all wanted steady, predictable progress in Mac hardware development. We wanted each product in the lineup to be updated regularly and not wither on the vine for years. For <a href="https://512pixels.net/2023/06/the-new-new-mac-pro/">the <em>most</em> part</a>, Apple has delivered. Just look at this chart of the progress Apple has made since the M1:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/10/m1-m5-cpu-chart.png" alt="CPU Geekbench 6 Scores"></p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/10/m1-m5-gpu-chart.png" alt="GPU Geekbench 6 Scores"></p>
<p>I don’t see anything in those charts to complain about, especially given the frequency at which most people buy new computers. That’s one reason why Apple compared the M5 to the M1 in <a href="https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/">its press release announcing the new chip</a>. Unless you buy a new computer every year, every update you experience will be meaningful.</p>
<p>That’s what we wanted when Apple announced the move away from Intel, and calling it boring five years in is missing the point and downplaying the success of Apple silicon thus far.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why do some radio towers blink? (166 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2025/why-do-some-radio-towers-blink</link>
            <guid>45737941</guid>
            <pubDate>Tue, 28 Oct 2025 19:38:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2025/why-do-some-radio-towers-blink">https://www.jeffgeerling.com/blog/2025/why-do-some-radio-towers-blink</a>, See on <a href="https://news.ycombinator.com/item?id=45737941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div>
<p><iframe src="https://www.youtube.com/embed/P7INyMXoO9c" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p>One day on my drive home, I saw three towers. One of them had a bunch of blinking white lights, another one had red lights that kind of faded in and out, and the third one, well, it wasn't doing anything. I'm lucky to have a radio engineer for a dad, so Dad: <em>why do some towers blink?</em></p>

<p>Joe: Well, blinking I would call like the way you described it, "flashing", "white light", or "strobe". All these lights are to aid pilots and air traffic. helicopters, fighter planes, regular jets. So that's the purpose of it.</p>

<p>Jeff: Well that one tower that I saw had red lights that faded in and out, but I even think there's a freestanding tower just north of here that has red and white on top.</p>

<p>Joe: Well red lighting is a thing. It's in the regulations, it specifies red lighting or white lighting, and one of the things like the red lights can be a bulb like this inside of a red housing, could be LED.</p>

<h2>Giant Bulbs</h2>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/giant-620w-tower-beacon-light-bulb-lamp.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-2ee38521-2172-4b55-b44c-1f8323b27f43" data-insert-attach="{&quot;id&quot;:&quot;2ee38521-2172-4b55-b44c-1f8323b27f43&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="620W large tower beacon light bulb"></p>

<p>Jeff: Where'd you find this bulb? This was not in my studio.</p>

<p>Joe: This bulb is a spare bulb for a tower site. And most of us use the same bulb, same socket, 620 watts. It's a very standard broadcast bulb for a broadcast tower. And a lot of the beacons, they're pretty tall and they'll have one right-side up, and one upside-down. So they'll have two bulbs in the socket. That way, when one bulb burns out, you realize you have a bulb out, but you're still legal with the second bulb.</p>

<p>Jeff: At my house, I don't have any of this kind of bulb anymore [incandescent]. I have, you know, this is a little bit different size, these are LED. Is that similar on towers?</p>

<p>Joe: Yeah. So it is the same. Like an <a href="https://pr-tech.com/product/l-864865-dual-beacon/">LED assembly for a tower</a> could be kind of flat, and it has, you know, it's set to just do what it needs to do. So in like white light, that's, typically it used to be always strobes. And at KMOX, you remember we had the whole assembly there. and you see the glass bulb, with xenon gas inside.</p>

<p>So those were the old way for that, but the newer ones are all white LED, and they can be little pancake-looking things compared to what the things are now. They can direct that LED light really to help airplanes and have less trouble for people who live in homes or apartment buildings nearby.</p>

<p>Jeff: So if they have a tower like the one that's just north of here that's in a residential area, you're not just flashing everybody constantly.</p>

<p>Joe: Yes, yes.</p>

<h2>Red light, white light?</h2>

<p>Jeff: You know, thinking about that tower, though, why do different towers have different lighting and different colors and things? And I even remember, like, on the tower that's right by here, there's actually teeny tiny little lights that are, like, on the sides, on the legs of the tower.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/side-markers-kdnl-tv-tower.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-7088cf8a-87ea-4f68-919d-a7e2f6b05f61" data-insert-attach="{&quot;id&quot;:&quot;7088cf8a-87ea-4f68-919d-a7e2f6b05f61&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="KDNL-TV tower side marker red lights"></p>

<p>Joe: Yeah, well, tower lighting is in the responsibility of FAA, and they have a detailed plan. The options depend on the heights of the tower, where they are at. The location is obviously important. And sometimes red is a good solution, sometimes white, and sometimes both, red and white solution. And an example is the tower that you're talking about.</p>

<p>Jeff: So why would you want both? It seems like that's twice the complexity.</p>

<p>Joe: You would have strobe in the day and red at night. And people in their homes at night, a pulsing red light is a lot easier than a big flashing white light.</p>

<p>Jeff: So sometimes if people are complaining about it, you might go to that solution.</p>

<p>Joe: You can propose the red at night and the dual lighting works. And then you literally see these two packs and one will be red and one will be white. That's what I've seen mostly, although I heard that they make one now. It's all in one.</p>

<p>Jeff: [sarcastically] You could have RGB lights—could you do Home Assistant for your tower lighting?</p>

<p>Joe: You'd have RGB, but that would not be allowed by the FAA.</p>

<p>Jeff: We'll actually talk about that a little bit too later, because there are some regulations for how you actually monitor these things.</p>

<p>Joe: Yes, there are.</p>

<h2>No lights at all?</h2>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/supertower-top-beacon-off-daytime-mode-light.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-3956130d-1180-43db-b318-de42c334c119" data-insert-attach="{&quot;id&quot;:&quot;3956130d-1180-43db-b318-de42c334c119&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Supertower beacon on top not lit during daytime mode"></p>

<p>Jeff: But before we get to that, what about the one tower I saw didn't have any lights that were blinking at all. And I zoomed in and I saw that there was a light on top, but it just wasn't doing anything.</p>

<p>Joe: Yeah. Well, and this is about daytime mode. So a tower that's painted, and that's legal for obstruction marking, and you don't have to light during the day. So at night, their lights would come on. So you can be in a situation where, like here, you could see three towers. One might be day and night with white light, and two of them might be red light day only, but one kicks on earlier than the other because of their exact photo cell triggering the lights.</p>

<p>Jeff: Or if the photo cell is covered by a layer of soot from 40 years...</p>

<p>Joe: Yeah. So that tower is probably in daytime mode, or it could be an AM tower. An AM tower below 200 feet doesn't have to be lit, so that's another one. In fact, all towers, I guess, under 200 feet, unless you're in a particular area where the FAA would require it.</p>

<p>Jeff: You always have to refer back to the documentation.</p>

<p>Joe: You always refer to the documentation.</p>

<p>Jeff: But what is the tower site that we went to for the hot dogs?</p>

<p>Joe: KHOJ? KHOJ, yeah. Those don't have lights. Those do not have lights.</p>

<p>Jeff: Because they're under 200 feet.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/khoj-am-tower-top-no-beacon-light.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-64a9354a-167c-4c19-b2b2-079eb75fd7e6" data-insert-attach="{&quot;id&quot;:&quot;64a9354a-167c-4c19-b2b2-079eb75fd7e6&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="KHOJ-AM tower top no light because less than 200 ft"></p>

<p>Joe: Yes, so they don't need lighting. So, and then they don't need painting either. So that's one of those things that, again, always refer to that because just because you have a tower that's under 200 feet doesn't mean you don't have to make sure it complies or you may have to paint it or you may have to light and paint.</p>

<p>Tower painting has changed a lot over the years. The older towers have lead in them. So whenever there's a project on the tower, it's not unusual to see the guys in some kind of a, what do they call those?</p>

<p>Jeff: A full ghillie suit? Or I don't know what they're called.</p>

<p>Joe: Yeah. Yeah. So they have that too. So anyway, that's the bottom line from then till now.</p>

<h2>But some short towers <em>do</em> have lights...</h2>

<p>Jeff: So far, we've been talking about radio and TV towers, the ones that are really big. But what about little small towers? I know I see a lot of cell towers that don't have any lights at all, but sometimes they do. They just have one little light bulb on top. Or even if they're 50 to 100 feet tall, I've seen it sometimes.</p>

<p>Joe: Yeah, and there's always a reason for seeing a light somewhere, almost always on structures, including buildings and so forth. But if you look around the area where you're seeing that tower that you know is not 200 feet and it's got a light on the top, look you're probably near an airport, a heliport, or somewhere where there's an aviation hazard. You know hospitals, they have their helipads there.</p>

<p>So everywhere there is a possible hazard for flight for aircraft is going to have lights involved, and that's why we see a lot of buildings even have lights.</p>

<h2>FAA Rules</h2>

<p>Jeff: So it sounds like we have towers and even buildings that have to have lights put up but who's in charge of all this? Like if I'm going to put up my own tower, who do I need to talk to to make sure that i'm doing it right and get it approved?</p>

<p>Joe: I think we go back to our friends at the FAA. They have that particular circular (<a href="https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.current/documentNumber/70_7460-1">AC 70/7460-1M - Obstruction Marking and Lighting</a>). It describes all kinds of of places where lighting is need for air safety.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/5g-cellular-tower-no-lighting.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-ff0e5178-846f-4879-abaf-394f0df70be9" data-insert-attach="{&quot;id&quot;:&quot;ff0e5178-846f-4879-abaf-394f0df70be9&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="5G Cell tower with no lighting"></p>

<p>So that includes our broadcast towers, big chimney stacks, water towers, bridges, nuclear power plant cooling towers, wind turbines, tall electrical towers, you know, those ones that they cross a river, they'll have those extra tall ones with markings in the middle. Sometimes those are required to have lighting.</p>

<p>And there are also rules that even apply during construction projects. So you've got these big buildings going up And you'll notice the cranes will have lights on them. And there's a spec for that, how many lights have to be on the crane, what height it has to be at.</p>

<p>As you look around the next 12 months, look around at all those lights. You'll enjoy it like I do.</p>

<p>Jeff: You'll look like a radio engineer once you know about these things!</p>

<h2>Estimating tower height by light</h2>

<p>Jeff: So that's made me think, like, looking through these instructions, I did find this page. And I thought, like, could you use tower lights, the number of them, as a way to judge how tall a tower is? Kind of a rough estimate.</p>

<p>Joe: Yes, actually you can because the specifications, like for tall, these would apply to radio and TV towers. They require so many lights depending on the height.</p>

<p>Like around here, we would have the F4 version with four lights, four blinking light levels, a light at the top if the antenna here at the top is higher than 40 feet.</p>

<p>So you can kind of look and get an idea of whether you're looking at a 500-foot tower or a 1,000-foot tower. I don't think you could go like 700 versus 1,000 as easily.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/three-towers-blinking-during-bird-migration-with-power-lines.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-ab955a70-d269-4738-81c2-018f47feaec8" data-insert-attach="{&quot;id&quot;:&quot;ab955a70-d269-4738-81c2-018f47feaec8&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Three towers with beacons blinking white strobes while birds migrate"></p>

<p>But you can tell, and the guys know. I know a couple of pilots that are also engineers or selling in radio business, and they can do that. They'll tell you, you know, like I was passing a tower. What's a tower that's a 1,200-foot tower doing out here? So it's pretty fun, and you go to this document has everything you need if you want to take the time and study that and memorize it and then fly.</p>

<h2>Monitoring and reporting outages (and NOTAMs)</h2>

<p>Jeff: One other thing that since we've been running this channel I keep getting emails about, if someone sees that there's lights out on a tower, like let's say it's nighttime and you're out there and you notice like one of these towers for the past few days hasn't had a light on, can you do anything about that? What should you do?</p>

<p>Joe: Well, first of all, if it's required to be lit, every tower that's required to be lit is also required to be monitored.</p>

<p>So in radio, we put a monitoring circuit on the electrical feed to the filaments and you can measure how much current is going through there, right? So you've got to monitor it. You've got to get alarmed by that. The alarm can call you or reach you. But you also have to call every day, check your circuit, your system, and make sure the lights are on. So if you only are lit at night, that means that call has to happen after it's dark.</p>

<p>You've got to verify that your lighting is working, and you have to report it within 30 minutes. And you find that if a light's out, you've got to report it. And we call that a <a href="https://notams.aim.faa.gov/#News">NOTAM</a>, where the FAA puts it on a system that all the pilots can have access to. And they know that there's a tower there, but it's lights out. And they can use it in their flight planning.</p>

<p>Jeff: You're an engineer and you have the tie-in with the FAA or whatever. But what would I be able to do if I did see a tower that was out?</p>

<p>Joe: Well, you can do a NOTAM search. Try to look through and see if you see it. The other thing, you could contact the tower owner or the engineer at the site, the tower's engineer, and they can check into it. They should already know because they have their monitoring equipment, right?</p>

<p>Jeff: They <em>should</em>.</p>

<p>Joe: They should already know. They do.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/fcc-sign-tower-base-supertower.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-c9c46c44-122d-42d6-9f8a-c04e6e509ea2" data-insert-attach="{&quot;id&quot;:&quot;c9c46c44-122d-42d6-9f8a-c04e6e509ea2&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="FCC sign with ASR at bottom of Supertower"></p>

<p>And then, of course, if you're out there, usually the tower, either on the tower or in the fencing around it or on the building, will have an <a href="https://wireless2.fcc.gov/UlsApp/AsrSearch/asrRegistrationSearch.jsp">ASR number</a>, which identifies that tower to the FAA and the FCC, actually. But that number would be the exact tower that you'd be reporting.</p>

<p>Jeff: So hopefully you learned a little bit more about why there are so many flashing lights around at night and not just for radio towers, but for bridges, buildings, and more. What other things do you want to know about towers? Let us know in the comments.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Samsung makes ads on $3,499 smart fridges official with upcoming software update (591 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/</link>
            <guid>45737338</guid>
            <pubDate>Tue, 28 Oct 2025 19:02:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/">https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/</a>, See on <a href="https://news.ycombinator.com/item?id=45737338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>After kicking off an unpopular <a href="https://arstechnica.com/gadgets/2025/09/samsung-forces-ads-onto-fridges-is-a-bad-sign-for-other-appliances/">pilot test last month,</a> Samsung made the practice of having its expensive smart fridges display ads official this week.</p>
<p>The ads will be shown on Samsung’s 2024 Family Hub smart fridges. As of this writing, Samsung’s Family Hub fridges have MSRPs ranging from <a href="https://www.samsung.com/us/home-appliances/refrigerators/all-refrigerators/?shop=Buy+Online&amp;key_category_features=Family+Hub%C3%A2%C2%84%C2%A2&amp;CID=afl-ecomm-rkt-cha-040122-url_Skimlinks.com&amp;utm_source=url_Skimlinks.com&amp;utm_medium=affiliate&amp;utm_campaign=1&amp;utm_content=2116208&amp;rktevent=Skimlinks.com_TnL5HPStwNw-XmUXqH629_Fatbxjry_5NQ&amp;ranMID=47773&amp;ranEAID=TnL5HPStwNw&amp;ranSiteID=TnL5HPStwNw-XmUXqH629_Fatbxjry_5NQ">$1,899 to $3,499</a>. The ads will arrive through a software update that Samsung will start issuing this month and display on the fridge’s integrated 21.5- or 32-inch (depending on the model) screen. The ads will show when the fridges are idle and display what Samsung calls Cover Screens.</p>
<blockquote><p>As part of the Family Hub software update, we are piloting a new widget for select Cover Screens themes of Family Hub refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements.</p></blockquote>
<p>Samsung also said that its fridges will only show contextualized ads, instead of personalized ads, which rely on collecting data on users.</p>
<p><a href="https://www.theverge.com/report/806797/samsung-family-hub-smart-fridge-ads-opt-out">The Verge</a> reported that the widget will appear as a rectangular box at the bottom of the screens. The box will change what it displays “every 10 seconds,” the publication said.</p>
<p>The software update will also introduce “a Daily Board theme that offers a new way to see useful information at a glance,” Samsung said. The Verge reported that this feature will also include ads, something that Samsung’s announcement neglected to state. The Daily Board theme will show five tiles with information such as appointments and the weather, and one with ads.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grokipedia and the coup against reality itself (117 pts)]]></title>
            <link>https://www.thedissident.news/grokipedia-and-the-coup-against-reality-itself/</link>
            <guid>45737044</guid>
            <pubDate>Tue, 28 Oct 2025 18:45:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedissident.news/grokipedia-and-the-coup-against-reality-itself/">https://www.thedissident.news/grokipedia-and-the-coup-against-reality-itself/</a>, See on <a href="https://news.ycombinator.com/item?id=45737044">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

            

            <div>
                <p><a href="https://www.thedissident.news/author/alejandra/">
                                <img src="https://www.thedissident.news/content/images/size/w160/2025/05/headshot-3-1.png" alt="Alejandra Caraballo">
                            </a>
                </p>
                
            </div>

                <figure>
        <img srcset="https://www.thedissident.news/content/images/size/w320/2025/10/Elon_Musk_-54349818093-.jpg 320w,
                    https://www.thedissident.news/content/images/size/w600/2025/10/Elon_Musk_-54349818093-.jpg 600w,
                    https://www.thedissident.news/content/images/size/w960/2025/10/Elon_Musk_-54349818093-.jpg 960w,
                    https://www.thedissident.news/content/images/size/w1200/2025/10/Elon_Musk_-54349818093-.jpg 1200w,
                    https://www.thedissident.news/content/images/size/w2000/2025/10/Elon_Musk_-54349818093-.jpg 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://www.thedissident.news/content/images/size/w1200/2025/10/Elon_Musk_-54349818093-.jpg" alt="Grokipedia and the Coup Against Reality Itself">
            <figcaption><span>Elon Musk speaking at the 2025 Conservative Political Action Conference (CPAC) at the Gaylord National Resort &amp; Convention Center in National Harbor, Maryland by </span><a href="https://www.flickr.com/people/22007612@N05" rel="nofollow"><span>Gage Skidmore</span></a><span>. </span></figcaption>
    </figure>

        </header>

        <section>
            <p>Grokipedia, the copycat of Wikipedia launched by Elon Musk isn’t just a string of AI generated slop, it is a weapon. The launch of "grokipedia" is a calculated, strategic escalation by the billionaire oligarch class to seize control of knowledge production itself and with that, control of reality. This is the construction of a reality production cartel that creates a parallel information ecosystem designed to codify a deeply partisan, far-right worldview as objective fact. This project was the result of Musk’s repeated failures to bend his existing Large Language Model (LLM), Grok, to his political will without destroying its coherence and reliability.<sup><a href="#fn1" id="fnref1">[1]</a></sup></p>
<p>The path to Grokipedia was paved with a spectacular technical failure as Grok previously devolved into calling itself "mechahitler."<sup><a href="#fn2" id="fnref2">[2]</a></sup> To understand why Musk had to build his own encyclopedia, one must first understand the central challenge of modern AI: alignment. LLM alignment is the complex process of ensuring an AI model’s behavior conforms to human values and intentions, typically defined by the broad principles of helpfulness, honesty, and harmlessness.<sup><a href="#fn3" id="fnref3">[3]</a></sup> This is achieved through sophisticated techniques like Reinforcement Learning from Human Feedback (RLHF), which essentially reward the model for desirable responses and punish it for undesirable ones.<sup><a href="#fn4" id="fnref4">[4]</a></sup></p>
<p>However, this process is fraught with peril, defined by two primary modes of failure. The first is Outer Alignment Failure. This occurs when we specify our goals incorrectly, the AI will follow the literal command but violate the spirit, leading to disastrous unintended consequences.<sup><a href="#fn5" id="fnref5">[5]</a></sup> An AI told to "make humans happy" might conclude that the most efficient solution is to place humanity into a drug-induced stupor.<sup><a href="#fn6" id="fnref6">[6]</a></sup> A more common problem; however, has been the sycophancy problem endemic to models that result in gaslighting and deception. The second, more insidious failure is Inner Alignment Failure, where the AI develops its own hidden goals. It may learn a proxy for the desired behavior that works during training but fails in the real world, or it may learn to deceive its creators, appearing aligned while pursuing a divergent, internal agenda.<sup><a href="#fn7" id="fnref7">[7]</a></sup></p>
<p>The "mechahitler" episode was a catastrophic alignment failure. When an LLM trained on the vast corpus of human knowledge—which, for all its flaws, contains a baseline of consensus reality—is then subjected to an aggressive fine-tuning process based on a incoherent, hateful, and counter-factual ideology, it is pushed into a state of cognitive dissonance. The model cannot reconcile its foundational understanding of the world with the extremist outputs it is being rewarded for producing. The model then engages in "reward hacking," finding bizarre loopholes to satisfy its instructions, resulting in incoherent, extremist gibberish.<sup><a href="#fn8" id="fnref8">[8]</a></sup> In Grok’s case, fulfilling the directive to be anti-woke meant reward hacking its alignment goals by spewing nazi rhetoric.</p>
<p>This reveals the fundamental dilemma facing those who would weaponize AI for political ends. The alignment problem for them is not about making the AI <em>safe</em> in a broad, humanistic sense; it is about making it <em>subservient</em> to a specific political ideology without rendering it useless. The "mechahitler" failure demonstrates that you cannot simply force a machine built on the bedrock of  high-quality open-source information such as Wikipedia to consistently and coherently adopt a worldview that is fundamentally at odds with the data that makes it useful in the first place. The tool breaks because the task is inherently contradictory.</p>
<p><strong>If You Can't Align the Model, Align the Data</strong></p>
<p>Grokipedia is the logical solution to this intractable problem. If you cannot force the model to lie coherently, you must change the underlying reality so that it is telling the "truth." This is a paradigm shift from RLHF and content moderation to reality construction through the creation of synthetic data.</p>
<p>Every major LLM is critically dependent on high-quality, human-curated data, and the one of the single most important sources is Wikipedia.<sup><a href="#fn9" id="fnref9">[9]</a></sup> Its vast, collaboratively verified corpus serves as the digital proxy for consensus knowledge, and the quality of this data is directly linked to an LLM's ability to be reliable and avoid factual "hallucinations".<sup><a href="#fn10" id="fnref10">[10]</a></sup></p>
<p>Grokipedia is a direct assault on this foundation. It is a poisoned well, a bespoke, ideologically filtered dataset designed to replace the digital commons. By pre-training a model on this alternate "source of truth," the need for contradictory post-training alignment is eliminated. The model's "natural" state, its foundational knowledge, is already aligned with the desired ideology. It can be "honest" and "reliable" because its outputs will faithfully reflect the manufactured reality of its training data.</p>
<p>The problem with relying on this AI generated training data is the positive feedback loop it creates. It creates the prospect of "model collapse," a phenomenon where AIs trained on the synthetic output of other AIs become progressively dumber, less connected to reality, and forget what they once knew.<sup><a href="#fn11" id="fnref11">[11]</a></sup> The Grokipedia ecosystem is a blueprint for a closed ideological loop: the AI is trained on a biased encyclopedia it created, its outputs reflect that bias, and those outputs are then used to reinforce and expand the original biased source, creating an accelerating spiral away from reality into a state of pure, self-referential dogma. This is a fundamental shift from propaganda as a narrative layer placed on top of reality to propaganda as the foundational infrastructure of a new, synthetic reality. Let’s be frank about what this, it is an attempt to solve a political disagreement by engineering a world where, for the AI, the disagreement is factually impossible.</p>
<p><strong>The Oligarchs Seizing Control of the Media and the Enclosure of the Digital Commons</strong></p>
<p>Musk’s project to align reality to his own is not happening in a vacuum. Musk's actions are part of a much larger campaign by a class of allied oligarchs to seize control of the entire information ecosystem. We are witnessing the birth of a fully integrated unreality pipeline.</p>
<p>First, the press is being hollowed out and consolidated. Billionaires are acquiring legacy media outlets as political assets. Jeff Bezos is actively shaping <em>The Washington Post</em>'s editorial direction, restricting its opinion section to favor "free markets".<sup><a href="#fn12" id="fnref12">[12]</a></sup> The Ellison family, backed by Oracle's immense wealth, is making moves to control Paramount (CBS News) and Warner Bros. Discovery (CNN), which has installed deeply partisan figures like Bari Weiss in top editorial roles.<sup><a href="#fn13" id="fnref13">[13]</a></sup> Meanwhile, the Murdoch empire's grip on right-wing media remains absolute.<sup><a href="#fn14" id="fnref14">[14]</a></sup></p>
<p>Second, the digital town square has been captured. Musk's conversion of Twitter into X—gutting safety teams and reinstating extremist accounts to create a platform dominated by MAGA voices—is the most visible example.<sup><a href="#fn15" id="fnref15">[15]</a></sup> It is paralleled by Meta's alignment with the Trump administration and the looming prospect of a Trump ally like Larry Ellison controlling TikTok's U.S. operations.<sup><a href="#fn16" id="fnref16">[16]</a></sup></p>
<p>These two movements converge to form the unreality pipeline. The first part of this is narrative generation. Oligarch-owned media such as Fox News, a captured CBS and Washington Post, and social platforms (X, Tiktok and Meta) generate and amplify a specific political narrative that align with the political goals of the oligarchs. The second part of this unreality pipeline is knowledge codification. These narratives, legitimized by incessant repetition, are then used to populate bespoke knowledge bases like Grokipedia, cementing them as "facts." The final part of this is automated propagation. AIs like Grok, trained on this manufactured knowledge, can then flood the digital world with an infinite stream of content that is both technically "reliable" (it matches its training data) and is perfectly aligned with its creators' political ideology.</p>
<p><strong>Seizing the Means of Ontological Production</strong></p>
<p>This creates a dangerous symbiosis. As LLMs require a constant stream of current and "reliable" data to stay relevant, and as oligarchs consolidate their control over the institutions that produce that data, the very definition of reliability shifts. To build a state-of-the-art AI in the future may require training it on the output of these consolidated media empires. The AI's utility will become contingent on its absorption of the oligarchs' worldview. This is the endgame: not just to build one biased AI, but to reshape the entire data ecosystem to ensure that any future AI will inevitably inherit that bias.</p>
<p>We must be clear about the nature of this threat. The launch of Grokipedia and the consolidation of the media that feeds it are not just another chapter in the culture war. This is a coup against reality itself. The battle has shifted from a fight over which facts are important to a fight over the definition of a fact. This is the seizure of the means of ontological production by the oligarch class.</p>
<p>The goal is no longer to win the argument, but to engineer a world where opposing arguments are impossible to construct. The consequence is the end of a shared world, the atomization of society into mutually incomprehensible, AI-reinforced realities where debate is impossible because there is no common ground on which to stand.</p>
<p>The only antidote to this synthetic world is a fierce, renewed commitment to the human-led, collaborative, and open projects that represent the best of our digital commons. Institutions like Wikipedia are the last bastions of the dream of a free and open internet that betters humanity. Protecting the source code of reality is a matter of survival for a free and sane society, and we must act like it.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Zoë Schiffer, <em>xAI Was About to Land a Major Government Contract. Then Grok Praised Hitler</em>, Wired,<a href="https://www.wired.com/story/xai-grok-government-contract-hitler/?ref=thedissident.news"> https://www.wired.com/story/xai-grok-government-contract-hitler/</a> (last visited Oct. 28, 2025); <em>See also</em> <em>The Algorithmic Unmasking: How Grok’s “MechaHitler” Turn Revealed the Inevitable Collapse of “Anti-Woke” AI</em>, The Dissident (Jul. 9, 2025),<a href="https://www.thedissident.news/the-algorithmic-unmasking-how-groks-mechahitler-turn-revealed-the-inevitable-collapse-of-anti-woke-ai/"> https://www.thedissident.news/the-algorithmic-unmasking-how-groks-mechahitler-turn-revealed-the-inevitable-collapse-of-anti-woke-ai/</a>. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Lisa Hagen, <em>Elon Musk’s AI Chatbot, Grok, Started Calling Itself “MechaHitler,”</em> NPR, Jul. 9, 2025,<a href="https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content?ref=thedissident.news"> https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content</a>. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p><em>See, e.g.</em>, <em>What is LLM Alignment?</em>, Deepchecks, <a href="https://www.deepchecks.com/glossary/llm-alignment/?ref=thedissident.news">https://www.deepchecks.com/glossary/llm-alignment/</a>; <em>LLM Alignment and Safety: A Comprehensive Guide</em>, Turing,<a href="https://www.turing.com/resources/llm-alignment-and-safety-guide?ref=thedissident.news"> https://www.turing.com/resources/llm-alignment-and-safety-guide</a>. <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p><em>LLM Alignment: Reward-Based vs Reward-Free Methods</em>, Towards Data Sci. (May 2, 2024),<a href="https://towardsdatascience.com/llm-alignment-reward-based-vs-reward-free-methods-ef0c0f6e8d88?ref=thedissident.news"> https://towardsdatascience.com/llm-alignment-reward-based-vs-reward-free-methods-ef0c0f6e8d88</a>. <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p><em>Id.</em> <a href="#fnref5">↩︎</a></p>
</li>
<li id="fn6"><p>Pratyush Maini et al., Safety Pretraining: Toward the Next Generation of Safe AI (Sep. 15, 2025),<a href="http://arxiv.org/abs/2504.16980?ref=thedissident.news"> http://arxiv.org/abs/2504.16980</a>; Tomasz Korbak et al., Pretraining Language Models with Human Preferences (Jun. 14, 2023),<a href="http://arxiv.org/abs/2302.08582?ref=thedissident.news"> http://arxiv.org/abs/2302.08582</a>. <a href="#fnref6">↩︎</a></p>
</li>
<li id="fn7"><p>Mrinank Sharma et al., Towards Understanding Sycophancy in Language Models (May 10, 2025),<a href="http://arxiv.org/abs/2310.13548?ref=thedissident.news"> http://arxiv.org/abs/2310.13548</a>. <a href="#fnref7">↩︎</a></p>
</li>
<li id="fn8"><p>Joar Skalse et al., Defining and Characterizing Reward Hacking (Mar. 5, 2025),<a href="http://arxiv.org/abs/2209.13085?ref=thedissident.news"> http://arxiv.org/abs/2209.13085</a>. <a href="#fnref8">↩︎</a></p>
</li>
<li id="fn9"><p><em>See</em> <em>Wikipedia's Value in the Age of Generative AI</em>, Wikimedia Found. (July 12, 2023),<a href="https://wikimediafoundation.org/news/2023/07/12/wikipedias-value-in-the-age-of-generative-ai/?ref=thedissident.news"> https://wikimediafoundation.org/news/2023/07/12/wikipedias-value-in-the-age-of-generative-ai/</a> <a href="#fnref9">↩︎</a></p>
</li>
<li id="fn10"><p><em>Id.</em> <a href="#fnref10">↩︎</a></p>
</li>
<li id="fn11"><p>Ilia Shumailov et al., <em>AI Models Collapse When Trained on Recursively Generated Data</em>, 631 Nature 755 (2024),<a href="https://www.nature.com/articles/s41586-024-07566-y?ref=thedissident.news"> https://www.nature.com/articles/s41586-024-07566-y</a>. <a href="#fnref11">↩︎</a></p>
</li>
<li id="fn12"><p><em>Washington Post Owner Jeff Bezos Says Opinion Pages Will Defend Free Market and “Personal Liberties,”</em> PBS News (Feb. 26, 2025),<a href="https://www.pbs.org/newshour/politics/washington-post-owner-bezos-says-opinion-pages-shift-from-broad-focus-to-will-defend-free-market-and-personal-liberties?ref=thedissident.news"> https://www.pbs.org/newshour/politics/washington-post-owner-bezos-says-opinion-pages-shift-from-broad-focus-to-will-defend-free-market-and-personal-liberties</a>. <a href="#fnref12">↩︎</a></p>
</li>
<li id="fn13"><p><em>Bari Weiss: Last Week Tonight with John Oliver (HBO)</em>, (2025),<a href="https://www.youtube.com/watch?v=gieTx_P6INQ&amp;ref=thedissident.news"> https://www.youtube.com/watch?v=gieTx_P6INQ</a>. <a href="#fnref13">↩︎</a></p>
</li>
<li id="fn14"><p>Jim Rutenberg, Jonathan Mahler Jim Rutenberg &amp; Jonathan Mahler have each covered the Murdochs for more than two decades, <em>Inside the Deal Ending the Murdoch Succession Fight</em>, The New York Times, Sep. 8, 2025,<a href="https://www.nytimes.com/2025/09/08/business/media/murdoch-family-trust-succession-deal.html?ref=thedissident.news"> https://www.nytimes.com/2025/09/08/business/media/murdoch-family-trust-succession-deal.html</a>. <a href="#fnref14">↩︎</a></p>
</li>
<li id="fn15"><p>Kate Conger &amp; Ryan Mac, Character Limit: How Elon Musk Destroyed Twitter (2024). <a href="#fnref15">↩︎</a></p>
</li>
<li id="fn16"><p>Terrence O’Brien, <em>TikTok Is Just Another Tool in Larry Ellison’s Quest to Run the World</em>, The Verge (Sep. 28, 2025),<a href="https://www.theverge.com/tech/787051/larry-ellison-tiktok-quest-to-run-the-world?ref=thedissident.news"> https://www.theverge.com/tech/787051/larry-ellison-tiktok-quest-to-run-the-world</a>. <a href="#fnref16">↩︎</a></p>
</li>
</ol>
</section>

        </section>

    </article>

        

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly 90% of Windows Games Now Run on Linux (443 pts)]]></title>
            <link>https://www.tomshardware.com/software/linux/nearly-90-percent-of-windows-games-now-run-on-linux-latest-data-shows-as-windows-10-dies-gaming-on-linux-is-more-viable-than-ever</link>
            <guid>45736925</guid>
            <pubDate>Tue, 28 Oct 2025 18:37:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/software/linux/nearly-90-percent-of-windows-games-now-run-on-linux-latest-data-shows-as-windows-10-dies-gaming-on-linux-is-more-viable-than-ever">https://www.tomshardware.com/software/linux/nearly-90-percent-of-windows-games-now-run-on-linux-latest-data-shows-as-windows-10-dies-gaming-on-linux-is-more-viable-than-ever</a>, See on <a href="https://news.ycombinator.com/item?id=45736925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-1600-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M.jpg" alt="Linux gaming" srcset="https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-1600-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/cPmWnCCVeXso2whj3QSh5M.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Tom's Hardware)</span>
</figcaption>
</div>

<div id="article-body">
<p id="71720470-1ea2-47dd-8ac6-aa06b5dcb024">The viability of Linux as a gaming platform has come on leaps and bounds in recent years due to the sterling work of WINE and Proton developers, among others, and interest in hardware like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/handheld-gaming/steam-deck-oled" data-before-rewrite-localise="https://www.tomshardware.com/video-games/handheld-gaming/steam-deck-oled">Steam Deck</a>. However, the most recent stats from <a data-analytics-id="inline-link" href="https://www.protondb.com/dashboard" target="_blank" data-url="https://www.protondb.com/dashboard" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">ProtonDB</a> (via <a data-analytics-id="inline-link" href="https://boilingsteam.com/windows-games-compatibility-on-linux-is-at-a-all-time-high/" target="_blank" data-url="https://boilingsteam.com/windows-games-compatibility-on-linux-is-at-a-all-time-high/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Boiling Steam</a>) highlight that we are edging towards a magnificent milestone. The latest distilled data shows that almost 90% of Windows games now run on Linux.</p><p>Having nine in ten Windows games accessible in a new <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/operating-systems/ive-been-using-linux-for-a-quarter-of-a-century-so-why-do-i-keep-coming-back-to-ubuntu" data-before-rewrite-localise="https://www.tomshardware.com/software/operating-systems/ive-been-using-linux-for-a-quarter-of-a-century-so-why-do-i-keep-coming-back-to-ubuntu">Linux </a>install is quite an achievement. The milestone comes as we see computer users <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/operating-systems/microsofts-decision-to-axe-windows-10-is-driving-apple-pc-sales-growth-users-buy-macs-instead-of-ai-pcs-despite-microsofts-push-for-copilot-pcs" target="_blank" data-before-rewrite-localise="https://www.tomshardware.com/software/operating-systems/microsofts-decision-to-axe-windows-10-is-driving-apple-pc-sales-growth-users-buy-macs-instead-of-ai-pcs-despite-microsofts-push-for-copilot-pcs">flocking to other platforms</a> during the transition from the Windows 10 to 11 eras. Of course, the underlying data isn’t quite so simple as the headline stat. There are different degrees of compatibility gamers must consider when checking if their favorite Windows games work on Linux distros like Mint, Zorin, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/bazzite-is-a-steamos-clone-that-supports-gaming-pcs-and-the-steam-deck" data-before-rewrite-localise="https://www.tomshardware.com/news/bazzite-is-a-steamos-clone-that-supports-gaming-pcs-and-the-steam-deck">Bazzite</a>, or even SteamOS.</p><div id="1982442169253363822"><blockquote data-lang="en"><p lang="en" dir="ltr">Windows Games’ Compatibility on Linux Is at an All-Time High: https://t.co/G06smdohrX #linux #linuxgaming #update #gaming #steam #proton #steamplay #wine #compatibility #windows pic.twitter.com/e598JNzqgP<a href="https://twitter.com/cantworkitout/status/1982442169253363822" data-url="https://twitter.com/cantworkitout/status/1982442169253363822" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">October 26, 2025</a></p></blockquote></div><p id="969416c4-f6ea-4db4-8331-75420898aba3-0">The above chart relies on Boiling Steam’s five definitions of playability, but these aren’t a million miles from the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/valve-speeds-steam-deck-game-verification-243-titles" data-before-rewrite-localise="https://www.tomshardware.com/news/valve-speeds-steam-deck-game-verification-243-titles">Steam Deck ratings</a> <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/valve" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/valve">Valve</a> dishes out. The main difference seems to be that Boiling Steam doesn’t seem to care whether Steam Deck performance is a gaming-limiting factor. So, in a way, its ratings are perhaps more useful to desktop and laptop PC users who typically have systems that easily outpace a Steam Deck.</p><p>Boiling Steam platinum (green) rank denotes games that run perfectly, out of the box. Gold (light green) requires just minor tweaks. Silver (yellow) games are playable but have some imperfections. Borked (dark red) games simply refuse to launch. Lastly, Bronze (red) titles exist in the murky water between silver and borked.</p><p>Looking at the chart trends, we see an encouraging growth in the number of new releases that are platinum (green) rated, and a thinning down of the red/dark red zone. Developers will, of course, benefit from more hardware being able to play their games with few if any wrinkles, so there must be an incentive to spend at least a little time checking a new Windows game on Linux, or the Steam Deck specifically.</p><p>On the flip side, there are some popular titles that don’t look like they will be becoming Linux-friendly anytime soon. The well-known compatibility issues with various <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/battlefield-6s-javelin-anti-cheat-secure-boot-requirement-could-kill-its-steam-deck-support" data-before-rewrite-localise="https://www.tomshardware.com/video-games/battlefield-6s-javelin-anti-cheat-secure-boot-requirement-could-kill-its-steam-deck-support">anti-cheat </a>technology platforms look set to persist, for now. Moreover, Boiling Steam notes that other devs just seem to be averse to non-Windows gamers. There is quite a bit that can be done with those non-intentionally stubborn games, though. We’d recommend researching community-driven Linux compatibility tips and tweaks for your favorite games.</p><a href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" id="0a97c2e5-45e3-4848-bc72-ffe8ecf02b73" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" alt="Google Preferred Source" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png">
</picture></p></div></figure></a><p id="5ae928cf-460a-49aa-b261-95744a4c3d9f"><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em> Tom's Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em> add us as a preferred source</em></a><em>, to get our latest news, analysis, &amp; reviews in your feeds.</em></p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-bNKZdrAbEnotEH5Pdyniun"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>




<!-- Drop in a standard article here maybe? -->



<div id="slice-container-authorBio-bNKZdrAbEnotEH5Pdyniun"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mapping the off-target effects of every FDA-approved drug in existence (151 pts)]]></title>
            <link>https://www.owlposting.com/p/mapping-the-off-target-effects-of</link>
            <guid>45736608</guid>
            <pubDate>Tue, 28 Oct 2025 18:12:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.owlposting.com/p/mapping-the-off-target-effects-of">https://www.owlposting.com/p/mapping-the-off-target-effects-of</a>, See on <a href="https://news.ycombinator.com/item?id=45736608">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!EovP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EovP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 424w, https://substackcdn.com/image/fetch/$s_!EovP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 848w, https://substackcdn.com/image/fetch/$s_!EovP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 1272w, https://substackcdn.com/image/fetch/$s_!EovP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!EovP!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png" width="1200" height="672.5274725274726" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:816,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:7436874,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.owlposting.com/i/160871483?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!EovP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 424w, https://substackcdn.com/image/fetch/$s_!EovP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 848w, https://substackcdn.com/image/fetch/$s_!EovP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 1272w, https://substackcdn.com/image/fetch/$s_!EovP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac3c4de-42fa-4d96-a5c4-f8edff920e6e_2912x1632.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>Note: Thank you to</span><a href="https://www.linkedin.com/in/williambusa/overlay/about-this-profile/" rel=""> Bill Busa</a><span>, CEO and co-founder of EvE Bio, for an extremely helpful discussion while working on this essay.</span></em></p><p><em><span>This essay is long, and I recognize that many people don’t necessarily care about the details. The real headline point you need to be aware of is </span><a href="https://data.evebio.org/" rel="">this dataset</a><span>, which was produced by EvE Bio underneath a </span><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="">CC-NA license</a><span>, and is a </span><strong>comprehensive mapping of the interactions between a significant fraction of clinically important human cellular receptors and 1,600~ FDA-approved drugs</strong><span>. I strongly believe that this data is really, really useful, and more people should be aware it exists. </span></em></p><p><em>If you’d like to understand why I think it is useful, and what the dataset exactly contains, read on! </em></p><ol><li><p><a href="https://www.owlposting.com/i/160871483/introduction" rel="">Introduction</a></p></li><li><p><a href="https://www.owlposting.com/i/160871483/why-is-understanding-off-target-effects-important" rel="">Why is understanding off-target effects important?</a></p><ol><li><p><a href="https://www.owlposting.com/i/160871483/drug-repurposing" rel="">Drug repurposing</a></p></li><li><p><a href="https://www.owlposting.com/i/160871483/validation-data-for-models" rel="">Validation data for models</a></p></li><li><p><a href="https://www.owlposting.com/i/160871483/maybe-polypharmacology" rel="">(Maybe) Polypharmacology</a></p></li></ol></li><li><p><a href="https://www.owlposting.com/i/160871483/how-do-you-understand-off-target-effects-in-a-tractable-way" rel="">How do you understand off-target effects in a tractable way?</a></p></li><li><p><a href="https://www.owlposting.com/i/160871483/why-hasnt-anyone-done-this-before" rel="">Why hasn’t anyone done this before?</a></p></li><li><p><a href="https://www.owlposting.com/i/160871483/what-does-the-future-look-like" rel="">What does the future look like?</a></p></li></ol><p><span>If you were to be a fly on the wall during the 1-6 years of preclinical drug discovery research within a pharmaceutical company, one observation you may walk away with is that, while the work is certainly complicated, it is also frighteningly limited in scope. What you’ll learn is that drugs are made by corporations that are optimizing for one primary thing, and one thing only: </span><strong>work</strong><span>. ‘Working’ is obviously contextual, but it is a simple concept no matter the situation: reduce a worrying biomarker, improve mood, lengthen lifespan and so on and so on. What does this discovery process ignore? Simply put: everything else a drug could do beyond that.</span></p><p><span>Yes, that’s a roundabout way of describing ‘off-target effects’ —  defined as the action of a drug at a gene product other than the gene product it was intended to affect — but I think it’s a helpful intuition pump. Viewing the drug discovery process as ‘</span><em><span>not paying attention to anything that is unrelated to the drug </span><strong>working</strong></em><span>’ is useful in that it contextualizes the situation we’re in. Drugs are meant to make money, and money is derived from </span><strong>drugs working</strong><span>. To spend time on understanding what else a particular drug does beyond It Working for its intended task is time lost and money lost.</span></p><p><span>One unfamiliar with the drug discovery process may find this bizarre; why wouldn’t the well meaning scientists in charge of developing drugs try to deeply understand how it interacts with the body? On the other hand, those deeply in the medical field would find this thesis so obvious that stating it is unnecessary; of </span><strong>course</strong><span> a pharmaceutical company would limit their scope of understanding a drug to things that lie between it working and not working. There’s only so much time and resources to go around. Priorities! </span></p><p><span>Of course, if an off-target effect comes between the drug and </span><strong>It Working</strong><span>, then certainly resources will be allocated to deal with it. But beyond that, mapping everything else a clinical-stage drug does — every receptor it unintentionally binds, every pathway it nudges sideways, every gene it perturbs slightly — is deemed so high effort and so low ROI, that it is relegated to hoping an academic will study it. Only if post-marketing surveillance turns up something worrying shall further exploration occur. Because, again, a deep understanding of </span><strong>what exactly an exogenous chemical is doing inside a body is not the point of the drug discovery process. </strong><span>Working is the point!</span></p><p>With that background context, I am ready to present three claims I’m going to make in this essay and spend the remaining sections trying to prove:</p><ol><li><p>Understanding off-target effects is really useful.</p></li><li><p>Learning about off-target effects at scale is possible.</p></li><li><p>No for-profit institution has a strong incentive to do this work.</p></li></ol><p>For the moment, let’s accept that these three are indeed true, and we can put our skeptic hat back on at the end of this section.</p><p><span>The subject of today’s essay is </span><strong><a href="https://evebio.org/" rel="">EvE Bio</a></strong><span>, and why I think they are doing something incredible.</span></p><p><span>EvE is a bit unlike the typical </span><a href="https://www.owlposting.com/s/startups" rel="">startups</a><span> I write about, because they aren’t really a startup. They are a FRO, or Focused Research Organization. Many reading this blog are likely already familiar with this recent renaissance of strange scientific organizations (</span><a href="https://www.owlposting.com/p/things-i-learned-talking-to-the-new" rel="">something I’ve written about in the past</a><span>) and already understand this acronym, but to those who don’t, this Venn diagram is quite instructive:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!D_9w!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!D_9w!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 424w, https://substackcdn.com/image/fetch/$s_!D_9w!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 848w, https://substackcdn.com/image/fetch/$s_!D_9w!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!D_9w!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!D_9w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg" width="617" height="513.1778846153846" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1211,&quot;width&quot;:1456,&quot;resizeWidth&quot;:617,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!D_9w!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 424w, https://substackcdn.com/image/fetch/$s_!D_9w!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 848w, https://substackcdn.com/image/fetch/$s_!D_9w!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!D_9w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F010d6a6f-e7ee-4453-81e3-12dbc40545ad_1456x1211.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Entire essays can (</span><a href="https://calvinball.substack.com/p/three-learnings-about-focused-research" rel="">and have been!</a><span>) written about the intricacies of FRO’s, but this essay will ignore much of their organizational structure, since it isn’t super relevant to what EvE is doing.</span></p><p><span>So what </span><strong>is</strong><span> EvE doing? EvE Bio is a scientific non-profit that has a clear, singular mission: </span><strong>map the off-target effects of every FDA-approved drug in existence and share the data.</strong><span> The data will be released underneath a non-commercial, creative commons license — free to use by academics, and available for licensing for commercial entities. Once they accomplish this task, they close up shop or spin off into their own thing. And if they don’t do it within 5-6 years, the same end result still happens. They do have some future plans that may come into the picture with time, which I’ll cover at the end, but the bolded bit is their primary thesis!</span></p><p>So why are they doing this? How will they do it? And why hasn’t anyone else done it yet? </p><p><span>There is a lazy answer that could be given here: "</span><em>because we want to know if potential side effects of a drug exist</em><span>". This is partially correct, but I think it pays to be more specific. On EvE’s website, they list six reasons why off-target effects are worth studying:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!x35K!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!x35K!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 424w, https://substackcdn.com/image/fetch/$s_!x35K!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 848w, https://substackcdn.com/image/fetch/$s_!x35K!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!x35K!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!x35K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg" width="1456" height="1047" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1047,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!x35K!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 424w, https://substackcdn.com/image/fetch/$s_!x35K!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 848w, https://substackcdn.com/image/fetch/$s_!x35K!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!x35K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7eb11aa-9d96-4b36-8720-11d8cdffdc6f_1456x1047.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Now, fairly, some of these are at least a </span><strong>little</strong><span> fluffy. Is the institution doing off-target mapping really going to be the ones developing the autonomous lab assays of the future? Maybe! But it feels like a third-order, fourth-order, or even further consequence of their main mission. Bill did mention to me that there are already promising results in that direction, such as better reporting cell lines, but still. I think it’s generally good to limit ones assessment of an institution based on what their first-order impact will be, and, there, I think there will be three distinct areas that EvE will service</span><strong>: drug repurposing, validation for machine-learning models, </strong><span>and</span><strong> </strong><span>to a weaker degree</span><strong>, polypharmacology.</strong></p><p><span>What about industrial chemical profiling and pharmacology profiling? I think EvE will certainly be important there, but it’s a bit fuzzier. Industrial chemical profiling may occur in the future but isn’t part of the current cohort of FDA-approved drugs that EvE is focusing on, and there’s a similar problem for pharmacology profiling as there is for ML-for-toxicity (</span><a href="https://www.owlposting.com/p/a-primer-on-why-computational-predictive" rel="">which I have written about before as being a challenging proposition</a><span>).</span></p><p><span>But even if we take my somewhat pessimistic stance that only three of these six things are genuinely tractable in the short term, </span><strong>those areas alone are extremely valuable.</strong><span> Let’s go over them.</span></p><p><span>I think it is under-appreciated just how </span><strong>rich</strong><span> the cohort of FDA-approved drugs that are out there. Consider the fact that basically all drugs start off with singular indications, meant to cure, alleviate, or address </span><strong>one</strong><span> thing.</span><a href="https://link.springer.com/article/10.1186/s40545-020-00282-8" rel=""> Yet, 30%~ of FDA-approved drugs gain a new post-approval indication,</a><span> based on a study of the 197 drugs approved by the FDA from 1997-2020. Funnily enough, the same paper that came up with that 30% number almost treats it as a matter of disappointment, </span><strong>given that 38% of all prescriptions written in the US are off-label!</strong><span> This implies that there are, potentially, hundreds of drugs that are </span><em>already</em><span> being used beyond their original scope, just without the formal validation or regulatory blessing. Which, in turn, implies that we’re sitting on a vast, under-explored landscape of therapeutic potential, one that clinicians are already intuitively poking into, but which the formal system has barely begun to chart.</span></p><p><span>Now, I think some caution is warranted. This 38% number does vary from paper to paper,</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11892052/" rel=""> one other study claims off-label prescriptions are as low as 25%.</a><span> If we’re being even </span><strong>more</strong><span> fair, it’s questionable exactly how proven-out these off-label indications are.</span><a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/410250" rel=""> One 2006 study claims that of the 21% of off-label prescriptions</a><span> they found, 73% of them had little-to-no scientific support. Hard to tell whether this is because there simply are no studies, or because the off-label usage was actively disproved!</span></p><p><span>Consider gabapentin, one of the most egregious cases of off-label drug prescriptions. Typically, most people view gabapentin as the nerve injury drug, right? But it, in fact, was not originally approved for that, only for seizures!</span><a href="https://lowninstitute.org/does-the-benefit-of-off-label-gabapentinoid-use-outweigh-the-harms/" rel=""> Yet, 95% of its prescriptions usage are for pain;</a><span> nerve pain, low-back pain, post-operative pain, and so on. But while the gabapentin is indeed effective for some specific types of nerve pain (diabetic neuropathy), it is ineffective for many other types (e.g sciatica), as confirmed by</span><a href="https://en.wikipedia.org/wiki/Gabapentin" rel=""> follow-up studies by Pfizer</a><span>.</span></p><p>Yet, prescriptions for these ineffective off-label usages continue.</p><p><span>But even if the true rate of valid, effective off-label use is lower than we’d like to imagine, the value of actually stumbling across a chance to repurpose a drug is</span><strong> </strong><span>high enough as to almost certainly still be worth it! Why? New chemical entities must follow the typical clinical phase progression timeline, whereas any repurposed drugs can skip preclinical, phase 1, and (sometimes)</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10627937/" rel=""> phase 2 trials as a result of their already-collected toxicity data</a><span>. Billions of dollars and years of time could be saved! </span></p><p><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/" rel="">From a 2017 review paper.</a></p><blockquote><p><em><span>…repurposed drugs are generally approved sooner (3–12 years) and at reduced (50–60%) cost (</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/#B5" rel="">5</a><span>,</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/#B6" rel=""> 6</a><span>). In addition, while ~10% of new drug applications gain market approval, approximately 30% of repurposed drugs are approved, giving companies a market-driven incentive to repurpose existing assets (</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/#B5" rel="">5</a><span>)….</span></em></p><p><em><span>For example, repurposing of the emergency contraceptive, mifepristone, for Cushing’s syndrome required a cohort of less than 30 patients to test its efficacy, whereas a clinical trial</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/#fn1" rel=""><sup>1</sup></a><span> for the same indication evaluating the safety and efficacy of a new chemical entity, levoketoconazole, required ~90 individuals (</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/#B2" rel="">2</a><span>,</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5694537/#B3" rel=""> 3</a><span>)…..</span></em></p></blockquote><p>But, as it stands today, most drug repurposing efforts are done somewhat blindly; haphazardly glancing through the literature, relying on anecdotal case reports, or waiting for some academic lab to publish a five-mouse study from 2013 that hints at a secondary use. In many ways, it isn’t too dissimilar to the usual drug-discovery process! Given how promising (and relatively limited) the list of FDA-approved drugs are, the simple act of a pre-triaged list of drug-target maps (EvE’s mission!) may be extraordinarily impactful.</p><p><span>In such a world where this data is easily accessible, perhaps an order of magnitude more energy would be devoted to repurposing efforts,</span><a href="https://x.com/cremieuxrecueil/status/1921986782523978044" rel=""> maybe vastly improving the currently horrific finances of modern day drug discovery.</a></p><p><span>But as with all seeming free-lunches, there’s a reason drug repurposing hasn’t been aggressively exploited beyond a few cases: economics. Unlike novel drugs, which come with fresh patents and a full runway of exclusivity, repurposed drugs necessarily rely on compounds whose original patents have expired or are near expiration</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-160871483" href="https://www.owlposting.com/p/mapping-the-off-target-effects-of#footnote-1-160871483" target="_self" rel="">1</a></span><span>. This limits the sponsor’s ability to recoup development costs, because generic competition can quickly erode any profits once the drug hits the market, even if it’s approved for a new use. There </span><em>are</em><span> mechanisms to extend exclusivity for repurposed indications — such as the</span><a href="https://www.fda.gov/industry/medical-products-rare-diseases-and-conditions/designating-orphan-product-drugs-and-biological-products" rel=""> 7-year exclusivity period given by the FDA’s Orphan Drug Act for treatments of rare diseases</a><span> or the</span><a href="https://www.mayerbrown.com/-/media/files/perspectives-events/events/2023/05/fda-lifecycle-management-webinar-3year-new-clinical-investigation-exclusivity--may-11-2023-final.pdf%3Frev=478b889bb39944e086c77a3c8de4faeb" rel=""> 3-year-exclusivity granted in cases where new clinical data was needed to repurpose a drug</a><span> — but it is a risky enough bet that most companies will shy away from it.</span></p><p><span>But as EvE is a non-profit, the economics don’t </span><strong>need</strong><span> to make sense. They plan to periodically announce opportunities for repurposing to the world, in hopes that other well-meaning non-profits take it on or, if the evidence is sufficiently convincing, that doctors simply take it as a useful datapoint for deciding whether an off-label prescription may be useful. And if they do most of the legwork in identifying good candidates for repurposing, it may even make the economics worth it for for-profit entities to pursue further. </span></p><p><span>One of the easiest ways to assure yourself that what you’re doing is valuable is if people come up to you and ask if they could use whatever you’re producing. This is true in typical SaaS products, and it is true for the fruits of R&amp;D work. But beyond assessing value outright, it also helps you learn </span><strong>what</strong><span> your work is most valuable for.</span></p><p><span>And, curiously, the primary area in which EvE has found ‘product market fit’ is in companies asking to use their data for internal model validation efforts. As I mentioned before, while EvE’s dataset is free-to-use by academics, it requires a commercial license to be used by any for-profit entity. And they are currently in discussions with 4 such commercial entities, all of whom desire to use EvE’s dataset to </span><strong>validate their machine-learning models predictions.</strong></p><p><span>Historically, model builders in drug discovery have had to make do with whatever internal datasets they could get their hands on, which were typically limited in scope, biased toward certain classes of molecules, or simply not reproducible. Public data from sources like</span><a href="https://www.ebi.ac.uk/chembl/" rel=""> ChEMBL</a><span>,</span><a href="https://www.bindingdb.org/rwd/bind/index.jsp" rel=""> BindingDB</a><span>, or</span><a href="https://pubchem.ncbi.nlm.nih.gov/docs/bioassays" rel=""> PubChem BioAssay</a><span> are much larger in size, but they tend to be noisy, heterogeneous in experimental methodology, and </span><strong>always</strong><span> lack negative results. Worse, they’re often cherry-picked around success stories or clustered around well-studied targets, introducing systemic biases that hamper generalization. We need not look further than Pat Walter’s famous essay on the topic:</span><a href="https://practicalcheminformatics.blogspot.com/2023/08/we-need-better-benchmarks-for-machine.html" rel=""> We Need Better Benchmarks for Machine Learning in Drug Discovery</a><span>, which expands on these issues even more.</span></p><p>This is an area of EvE’s work that I cannot personally shed much light on, and obviously, Bill cannot tell me the exact details on what the commercial entities are working on. But it was a surprising learning from our conversation that this particular topic is where public interest is most rapidly coalescing! Very excited to hear about more public statements they make in this area soon.</p><p>I do think this is the weakest, day-one value-add for EvE’s dataset. So take this section with a grain of salt! It just felt too interesting to not cover.</p><p><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10243259/" rel="">Polypharmacology is a drug discovery approach where a drug is designed to target multiple molecular targets</a><span>, instead of a more traditional single-target approach. It’s not a particularly new idea, most clinically useful drugs exhibit multi-target activity whether they were designed that way or not. But what’s changed in the past decade is the </span><strong>intentionality</strong><span>.</span></p><p><span>I think there are a lot of different arguments for the value of polypharmacology, the easiest one hinging on efficacy. There’s a very interesting story that could be told here about drugs that worked better because they modulated the activity of multiple receptors in parallel. A great, recent example is that of drugs that followed Ozempic. Ozempic simply targeted GLP-1, which reduces appetite and slows digestion. But the second-generation (e.g. Zepbound) also targeted GIP, which amplifies insulin response and regulates lipid metabolism differently in adipose tissue. The effects were incredible: </span><a href="https://www.nejm.org/doi/10.1056/NEJMoa2416394?" rel="">13.7% weight loss with Ozempic, 20.2% weight loss with Zepbound</a><span> over 48 weeks. Synergistic effects! The third generation (e.g. retatrutide) tacks on interactions with glucagon receptors — potentially increasing metabolic rate — </span><a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2301972" rel="">with early phase 2 results looking once again promising. </a></p><p><span>But a more interesting place to start is the very similarly named concept of </span><strong>polypharmacy.</strong></p><p><span>Polypharmacy refers to the clinical practice of prescribing multiple drugs simultaneously (usually 5+), typically to manage complex or co-occurring conditions. It’s common in geriatrics, psychiatry, oncology, and increasingly just about everywhere else in medicine: </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10337167/" rel="">~17% of all adults in the US meet the definition for polypharmacy</a><span>. The logic is straightforward: most diseases aren’t governed by a single pathway, and so tackling them with a single drug is often insufficient. Instead, clinicians stack therapies: an ACE inhibitor for the blood pressure, a statin for the cholesterol, metformin for the glucose, a GLP-1 for the weight, and so on.</span></p><p><span>As you may expect, polypharmacy is </span><strong>awful</strong><span> on the patient's physiology.</span><a href="https://pubmed.ncbi.nlm.nih.gov/28251277/" rel=""> One study estimates that</a><span> nearly </span><strong>10% of hospital admissions among older adults</strong><span> are directly attributable to adverse drug events from polypharmacy-related side effects. The more drugs we stack onto people, the more unpredictable the net interaction becomes, because even if each one has been individually safety-tested, nobody tests all the pairwise combinations in a clinically realistic setting.</span></p><p>The solution may very well be to bundle things up.</p><p><span>Rather than throwing five separately optimized molecules at a patient and hoping for cooperative behavior, we could, in principle, design a </span><strong>single </strong><span>molecule that alone engages the same therapeutic targets. This, in turn, allows clinical trials to suss out the net effect of such a drug in a controlled, interpretable way. Which naturally leads us to the utility of polypharmacology; not necessarily because it will give us magic drugs with efficacy far better than current ones (though it may!), but rather that it will simply avoid us having to deal with the current issues that polypharmacy presents.</span></p><p>But the obvious question: does EvE’s dataset help with polypharmacology efforts? There isn’t any current, empirical proof of this, but I think it will. If you squint, you could see it functioning as missing infrastructure, a dataset that is necessary for rational polypharmacology to occur at scale. But this is necessarily tied up with machine-learning for chemical design accelerating, so, again, this is not necessarily something I’d expect EvE’s work to contribute to by the end of the year. But perhaps soon!</p><p>This all said, even if you agreed that the value proposition that EvE is claiming is real, you may struggle to verbalize exactly how you would understand the off-target effects of the 13,000~ FDA approved drugs out there. What assays would you use? How do you dose any given drug? How do you understand the translation of your assay to real-world settings?</p><p>Let’s walk through the EvE workflow.</p><p>First, you need to decide what drugs you're actually going to test. While there are technically around 13,000 FDA-approved drugs out there, many of them aren't particularly relevant for this kind of screening. You can immediately exclude things like topical medications, inhalants, radioisotopes, and simple nutrients, stuff that is known to be largely innocuous or not have much systemic impact. After this initial filtering, you end up with about 1,600 small molecule drugs that are worth investigating. But this number gets further whittled down further based on practical constraints; availability, cost, licensing requirements, etc.</p><p>From this, EvE ended up with a library of 1,397 compounds to screen.</p><p><span>Then comes the harder question: what exactly are you screening against? The human body has somewhere around 20,000 protein-coding genes, and there is an argument that any drug could interact with any of them. But perhaps we’d be too zealous to immediately do an </span><em>(everything x everything)</em><span> screen. Shouldn’t we try to do something that’s closer to the Pareto optimal frontier? What if we suspect that the vast majority of clinically meaningful drug interactions occur with a tiny subset of those 20,000 genes?</span></p><p>And, indeed, that turns out to be the case.</p><p><span>The vast majority of genes have some nominal physiological function, yes, but when it comes to drug interactions, only a minority are commonly targeted. At least a minority of classes: </span><strong>nuclear receptors</strong><span> </span><strong>(NRs)</strong><span> and </span><strong>7-transmembrane receptors (also known as GPCRs). </strong><span>In total, there are about 800~ GPCRs and 48 NRs, but only</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11089380/" rel=""> 110 GPCR’s</a><span> and</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11279859/" rel=""> 12-13 NR’s</a><span> are actually targeted by drugs. Per last count, EvE has currently created data for</span><a href="https://data.evebio.org/data_explorer__3.html#targets" rel=""> 56 GPCR’s and 29 NR’s</a><span>. Over the course of their existence, they plan to cover, in total, a select set of the 200 GPCR’s and all 48 NR’s. Why not all 800 GPCR’s? I attached that information in the footnotes.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-160871483" href="https://www.owlposting.com/p/mapping-the-off-target-effects-of#footnote-2-160871483" target="_self" rel="">2</a></span><span> </span></p><p>They hope to do much more than this too, but we’ll cover that in the last section.</p><p><span>Both NRs and GPCRs have some nice properties, but most pertinent to EvE, they are known to be very ‘druggable’ classes of drugs, given that the cell often uses them to convey information from the outside world, and evolution has therefore made their binding pockets unusually receptive to small molecules.</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8233523/" rel=""> GPCRs, sitting on the cell surface, are natural sensors for hormones, neurotransmitters, and other circulating ligands</a><span>, many of which resemble or inspire drug scaffolds</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3677810/" rel="">. NRs, meanwhile, act as intracellular switches that come with protected internal pockets</a><span> meant to bind to estrogen, cortisol, and so on, making them ideal for selective small-molecule engagement. As a result, both are involved in a </span><strong>lot</strong><span> of important physiological processes.</span></p><p><span>This ‘physiological importance’ is useful in two ways! One, a plurality of drugs target the two —</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10252477/" rel=""> 13% of FDA-approved drugs target NR’s</a><span>, with that number jumping to</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5820538/" rel=""> 35% for GPCR’s</a><span> — so mapping the interactions here may give a clinically meaningful view of off-target effects. And two, given the extreme importance of GPCR’s and NR’s in modern-day drug development, there has been a fair bit of work in improving how we study their interactions with ligands of interest. As in, new assays outright shouldn’t need to be developed to study them.</span></p><p><span>Speaking of that, let’s start talking about </span><strong>how</strong><span> they are building this drug x receptor interaction map. They rely on two well-established assays which I’ll discuss here, but feel free to skip, understanding the two isn’t particularly important.</span></p><ol><li><p><strong>TR-FRET-based co-factor recruitment assays for NRs</strong></p><ol><li><p><span>When a drug successfully activates an NR, it usually causes a conformational shift that allows the receptor to recruit a specific co-factor protein, exposing what is often called the ‘AF2 domain’</span><strong>. These co-factors tend to have little peptide motifs (like an LXXLL motif) that latch onto that domain.</strong></p></li><li><p><span>TF-FRET exploits this. A chemical is tagged onto the NR domain and a chemical is tagged onto the co-factor protein, both of which are fluorophores. </span><strong>If the FDA-approved drug is an agonist, you’ll see a spike of light appear as the two fluorophores interact.</strong></p></li></ol></li><li><p><strong>Tango β-arrestin recruitment assays for 7TMs/GPCRs</strong></p><ol><li><p><span>Instead of recruiting co-factors inside the nucleus like NR’s, GPCR’s sit on the surface of a cell and transmit signals inward. As the name of the protein class implies, this involves utilizing</span><a href="https://en.wikipedia.org/wiki/G_protein" rel=""> G-proteins</a><span>. Unfortunately, G-proteins are quite specific to </span><strong>their</strong><span> GPCR, so using them in our assay as a way to understand activation would be difficult to scale. Luckily, there is a nearly universal binding protein:</span><a href="https://en.wikipedia.org/wiki/Arrestin_beta_1" rel=""> β-arrestin</a><span>. When a GPCR is activated by [something], their signaling process almost always involves binding to that protein.</span></p></li><li><p><span>In the assay, the GPCR (attached to a cell surface) is engineered to have a built-in “trap”, a little molecular tag connected to a transcription factor. When β-arrestin is recruited, it brings along a protease that snips the tag, releasing the transcription factor. That transcription factor then moves into the nucleus and turns on a reporter gene, which encodes for the enzyme β-lactamase. Meanwhile, the cell is loaded with </span><strong>CCF4-AM</strong><span>, a fluorescent substrate that shifts its emission profile when cleaved by β-lactamase. </span><strong>The stronger the GPCR activation by a drug, the more β-lactamase is produced, the more substrate is cleaved, and the bigger the fluorescence shift.</strong><span> </span><strong>That shift, measured as a ratio between ‘starting’ and ‘ending’ wavelengths, serves as a readout of how strongly the receptor was activated.</strong></p></li></ol></li></ol><p>Reasonably simple! One note: the explanations I gave above is for assessing the difference between an inactive drug and an agonist. For assessing inactive versus antagonist, a separate experiment is run with a known ligand included.</p><p><span>Well, wait a minute. Aren’t we missing something? Off-target effects of a small molecule can be summarized purely by these GPCR/NR measurements, but we’d be failing to capture something else that is of vital importance: whether the drug outright kills the cell. One could imagine this also affecting our receptor experiments! Perhaps a drug is an antagonist and there is no color shift, or perhaps the cell is just </span><strong>dead</strong><span>, and nothing is being expressed at all. Conversely, a drug might look like an agonist due to signal drift as the cell’s internal environment falls apart.</span></p><p><strong>EvE solves this in a pragmatic way: run a third assay which measures how healthy the cell is</strong><span>. How do you measure that? Well, one good proxy for how functional a cell is </span><strong>ATP production</strong><span>. Metabolically active cells generate ATP to power all their intracellular processes. Dead ones don’t. The assay EvE uses is called </span><strong>CellTiter-Glo</strong><span>. It works by adding a reagent that causes a fluorescent reaction in the presence of ATP. More ATP, more light. Less ATP, less light. No ATP? No light (and likely dead). Again, simple!</span></p><p><span>Is that all? One last thing: accounting for pan-assay interference compounds, or PAINS. These are molecules that often give false positives in high-throughput screening regimes. This can occur for </span><strong>many</strong><span> different reasons, but one relevant example is if a molecule itself is a fluorophore, leading to us falsely believing that it is an agonist during a run. EvE simply tracks how often a drug is leading to positive results, and flags it in their results if they believe it is a PAINS.</span></p><p>So they run these three assays across their pairwise (drug x receptor) combinations, producing readouts at multiple different concentrations with replicates for each one.</p><p><span>I’m going to skip over a lot at this point. EvE clearly put an immense amount of work into QA’ing this process and filtering through the data, and I think I would do both a disservice and detract from the point of this essay if I were to attempt to repeat it here. Summarizing it all down, using a complex logic table</span><a href="https://data.evebio.org/data_explorer__4b.html#methods" rel=""> detailed here in Fig 7</a><span>, EvE assigns 1 of 4 categories to each (drug x receptor) combination:</span></p><ol><li><p><strong>Inactive.</strong><span> Drug likely has no effect on the receptor, across all tested concentrations. Maybe it doesn’t bind or maybe it binds but does nothing.</span></p></li><li><p><strong>Likely Inactive.</strong><span> A little more ambiguous, perhaps there’s a single noisy point above baseline, but nothing more.</span></p></li><li><p><strong>Active – Unquantified.</strong><span> Something is happening, since there’s reproducible activity, but not enough clean data to fit a proper dose-response curve.</span></p></li><li><p><strong>Active – Quantified</strong><span>. The drug produced a clear, dose-dependent response (as either an agonist or antagonist) with a well-behaved curve. From this, EvE fits a 4-parameter logistic model and extracts a pXC₅₀; the negative log concentration at which the drug produces half its maximal effect. </span></p></li></ol><p>And…that’s it. A clean, rigorous, and tractable approach to understanding off-target effects, across hundreds of receptors, at multiple concentrations, using multiple modes of detection, with full transparency around the data.</p><p><span>How far along is EvE on their mission? Circa their last data release on 5/7/2025, </span><strong>237,490 (drug x concentration x receptor) combinations have been screened, revealing 8 median agonists and 31 median antagonists per target. </strong><span>They run these experiments in 384 well plates, so that means they’ve run the process a little bit over 600~ times to generate their current dataset — though much of the current process is automated, very little human-done pipetting is going on.</span><a href="https://data.evebio.org/" rel=""> Data dumps of the data started in November 2024, with new ones dropping every few months.</a></p><p>I haven’t worked in a wet lab before, but I’ve been assured by at least one person I trust that the effort that went into assembling this all together is nothing short of extraordinary. But it is worth asking the question…</p><p><span>When assessing the value of a seeming scientific achievement, it’s usually good to step back and ask one question:</span><strong> why wasn’t this done a decade back?</strong></p><p>In some cases, the answer is boring: the technology wasn’t there yet to achieve it.</p><p><span>But here, the technology was almost certainly available! Eve’s assay for measuring NR activity has been around</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3025134/" rel=""> at least since 2008</a><span>, and the one for GPCR</span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3014586/" rel=""> since 2010</a><span>, maybe even earlier for both. If it’s really </span><strong>that</strong><span> useful, why did it take so long for someone to start assembling this drug x receptor mapping together?</span></p><p><span>Haven’t I already given away this answer? In the introduction, I implied that pharma groups have no direct financial incentive to create such a dataset. And that is true to some degree, especially for smaller therapeutic companies that have bigger issues to focus on, </span><strong>but is that true for big pharma?</strong><span> A small slice of the billions in pharma spending couldn’t be sliced off to hand over to an internal research team? It’s not as if the data wouldn’t be useful for their </span><strong>own</strong><span> drug development pipelines. After all, off-target effects are among the most common reasons for late-stage trial failures and post-approval black box warnings, and even if the creation of an EvE-like dataset doesn’t fix the problem, I can’t imagine it’d hurt.</span></p><p><span>I should be fair: pharma companies do indeed do </span><strong>some</strong><span> of this. EvE’s own blog discusses this a little,</span><a href="https://www.nature.com/articles/s41573-024-00942-3" rel=""> referencing this paper:</a></p><blockquote><p><em>The report’s authors, luminaries in the discipline of safety pharmacology, surveyed 18 major pharmaceutical companies regarding the numbers and identities of potential off-targets against which they test each and every one of their new drug candidates in the interest of safety. The numbers ranged from a low of 11 to a high of 104 potential off-targets routinely profiled per company, with a median of about 45. Interestingly, the industry’s opinions regarding which potential off-targets to screen vary widely. The total number of potential off-targets screened, across the universe of all 18 pharmas, was 763, yet only 12% of them were screened by more than a third of those companies.</em></p></blockquote><p><span>So, yes, pharma companies do their own off-target screening. But, as we’ve discussed, this is a far cry from the universe of druggable receptors, and is only concentrated on </span><strong>their</strong><span> particular assets, not other ones. No attempt at creating a universal map!</span></p><p><span>But the same blogpost did reference another big pharma,</span><a href="https://www.nature.com/articles/s41467-023-40064-9" rel=""> Novartis, who also open-source</a><span> a </span><strong>much</strong><span> larger map:</span></p><blockquote><p><em>Novartis, who presented data collected “over a multi-year period” profiling drug/target interactions across a median of about 800 drugs per target and 105 gene product targets…</em></p></blockquote><p><span>This is impressive! One may imagine that if a big pharma was willing to release this, why does an entity like EvE need to exist? For interest's sake, let’s ignore the obvious answer of ‘</span><em>it is better for everyone if such a dataset is collected using a single, standardized protocol instead of compiled from unrelated experiments over years.</em><span>’</span></p><p>I asked Bill exactly this question, and the answer was a two-parter.</p><p><span>For one, the dataset that was collected by Novartis, and indeed every large-scale dataset that will ever be collected by big pharma, will always be limited by the constraint we mentioned at the start: everybody only cares about the drug working. </span><strong>A logical conclusion of this is that nearly every receptor covered in these sorts of screens is a safety-oriented receptor</strong><span>. Cytochrome P450, hERG, serotonin subtypes, dopamine D₂, and the like. These are important receptors, not because of how mechanistically interesting they are, but because they are </span><strong>dangerous</strong><span>.</span><a href="https://www.nature.com/articles/s41573-024-00942-3" rel=""> Indeed, the vast majority of screened receptors lie within the so-called Bowes-44 set</a><span>, which comes from a</span><a href="https://www.nature.com/articles/nrd3845" rel=""> 2012 paper that identified 44 receptors known to be often implicated in safety-related drug failures.</a><span> Though these do include NR’s and GPCR’s, it is a minimal set of them, as, again, the screening is not meant to assess how mechanistically interesting the receptors are.</span></p><p><span>And if a big pharma </span><strong>does</strong><span> decide to explore beyond the realm of safety-oriented receptors, they will almost certainly keep that dataset to themselves. Why release potential </span><a href="https://en.wikipedia.org/wiki/Alpha_(finance)" rel="">alpha</a><span> to competitors? Hence, why nothing quite like EvE has come out in the past and it is unlikely it ever will in the future, at least from a for-profit entity.</span></p><p><span>And two, EvE eventually hopes to cover a </span><strong>lot</strong><span> more ground than any of the publicly available datasets. Currently, yes, the Novartis dataset is larger than EvE’s, but it won’t be for long. In fact, their plans for the upcoming few years ended up being so interesting that I decided to split it off into another section:</span></p><p>EvE is still quite young, just over 2 years old, and I think the future of it is going to look really, really crazy. At the end of my startup coverage articles, I typically focus on commercial/scientific risks. But given that EvE is assured funding on a multi-year horizon without needing to care about market demands, it may be much more instructive (and interesting!) to instead discuss their upcoming plans.</p><p><span>Earlier I noted that EvE has currently released data for 29 NRs and 56 GPCRs, out of a planned 40 NR’s and 200 GPCR’s. In my conversation with Bill, I asked him how much time is left till the remaining ones are released. I expected the answer to be, optimistically, ‘</span><em>over the next few years</em><span>’, given how EvE only started to release data back in November 2024 </span><strong>and</strong><span> that the Novartis dataset collection process also took several years. </span><strong>I was astonished to learn that he expected to have released the remainder of all GPCR + NR screens dataset by the end of this year.</strong><span> Setting up the assays, validation, and automation was the hard part, which is why their data releases have only started recently. But now that that’s all set up, they simply must turn the crank to get the rest out of the door.</span></p><p><span>What’s next? Bill told me that the next target of receptors are kinases, 500~ or so receptors that have been</span><a href="https://www.nature.com/articles/s41573-024-00942-3" rel=""> increasingly valuable drug targets over the last 20 years.</a></p><p>Then what? Bill said he’s open to exploring even more drug targets, but he also said, surprisingly, that EvE may add more chemicals on top of the 1,600~ planned FDA-approved drugs. The FDA-approved drugs, he said, are success stories. Potentially it’d be even more interesting to consider the failures as well. Especially the ones that everybody expected to work, arrived at phase 3, and set billions of dollars on fire after the trial results came out.</p><p><span>Even more exotic options are also on the table. For example, Bill discussed exploring how metabolites of approved drugs interact with targets. Some context:</span><a href="https://www.nature.com/articles/s41573-024-00942-3" rel=""> most secondary pharmacology work stops at the parent compound</a><span>, but metabolic byproducts of a drug can have entirely different binding profiles, and, in some cases, they’re the ones responsible for efficacy (e.g codeine, which metabolizes into the much more effective morphine) </span><em>or</em><span> for toxicity (e.g. acetaminophen, which metabolizes into the very toxic</span><a href="https://en.wikipedia.org/wiki/NAPQI" rel=""> NAPQI</a><span>). He also mentioned potentially using EvE’s assaying work to develop our understanding of tool compounds, which are chemicals that don’t necessarily have therapeutic value themselves, but are used in research to probe specific biological pathways or validate target function.</span><a href="https://axial.acs.org/medicinal-chemistry/call-for-reviews-recommended-tool-compounds-for-biological-and-pharmacological-studies" rel=""> An ACS page has this to say about it:</a></p><blockquote><p><em>While tool compounds have tremendous potential for advancing life science research, they are broadly defined, and it is often difficult for a researcher to determine the best tool compounds to employ during the research process. There remains a great need for more tool compound databases and authoritative sources of information from experts in the field.</em></p></blockquote><p><a href="https://www.science.org/content/blog-post/tool-compound-s-new-personality" rel="">And, as always, there is a (very short) Derek Lowe piece</a><span> on how a commonly-relied upon tool compound moonlights as a ligand for a structurally unrelated receptor, likely muddying the literature the tiniest bit. More work here would almost certainly be deeply appreciated by those in the field.</span></p><p><span>Overall, EvE really exemplifies the thesis I put forward in a past essay about how</span><a href="https://www.owlposting.com/p/there-arent-enough-smart-people-in" rel=""> smart people in biology should do more boring things.</a><span> Very little that is directly sexy about doing an N x M screen, but the impact of doing something like it </span><strong>well</strong><span> can be immense. And I have little doubt that EvE Bio has been doing it well, and will continue to do so in their future projects. If you’re interested in checking out their dataset, check it out </span><a href="https://data.evebio.org/data_explorer__4b.html" rel="">here</a><span>.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTTPS by default (272 pts)]]></title>
            <link>https://security.googleblog.com/2025/10/https-by-default.html</link>
            <guid>45736499</guid>
            <pubDate>Tue, 28 Oct 2025 18:04:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2025/10/https-by-default.html">https://security.googleblog.com/2025/10/https-by-default.html</a>, See on <a href="https://news.ycombinator.com/item?id=45736499">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What we talk about when we talk about sideloading (1379 pts)]]></title>
            <link>https://f-droid.org/2025/10/28/sideloading.html</link>
            <guid>45736479</guid>
            <pubDate>Tue, 28 Oct 2025 18:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://f-droid.org/2025/10/28/sideloading.html">https://f-droid.org/2025/10/28/sideloading.html</a>, See on <a href="https://news.ycombinator.com/item?id=45736479">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We recently published a <a href="https://f-droid.org/en/2025/09/29/google-developer-registration-decree.html">blog
post</a>
with our reaction to the new Google Developer Program and how it impacts
your freedom to use the devices that you own in the ways that you want. The
post garnered quite a lot of feedback and interest from the community and
press, as well as various civil society groups and regulatory agencies.</p>

<p>In this post, I hope to clarify and expand on some of the points and rebut
some of the counter-messaging that we have witnessed.</p>

<h3 id="googles-message-that-sideloading-is-not-going-away-is-clear-concise-and-false">Google’s message that “Sideloading is Not Going Away” is clear, concise, and false</h3>

<p>Shortly after our post was published, Google aired an
<a href="https://www.youtube.com/watch?v=A7DEhW-mjdc&amp;t=613s">episode</a> of their
Android Developers Roundtable series, where they state unequivocally that
“sideloading isn’t going anywhere”. They follow-up with a <a href="https://android-developers.googleblog.com/2025/09/lets-talk-security-answering-your-top.html">blog
post</a>:</p>

<blockquote>
  <p><em><strong>Does this mean sideloading is going away on Android?</strong> Absolutely not. Sideloading is fundamental to Android and it is not going away.</em></p>
</blockquote>

<p>This statement is untrue. The developer verification decree effectively ends
the ability for individuals to choose what software they run on the devices
they own.</p>

<p>It bears reminding that “sideload” is a made-up term. Putting software on
your computer is simply called “installing”, regardless of whether that
computer is in your pocket or on your desk. This could perhaps be further
precised as “<em>direct</em> installing”, in case you need to make a distinction
between obtaining software the old-fashioned way versus going through a
rent-seeking intermediary marketplace like the Google Play Store or the
Apple App Store.</p>

<p>Regardless, the term “sideload” was coined to insinuate that there is
something dark and sinister about the process, as if the user were making an
end-run around safeguards that are designed to keep you protected and
secure. But if we reluctantly accept that “sideloading” is a term that has
wriggled its way into common parlance, then we should at least use a
consistent definition for it. Wikipedia’s summary
<a href="https://en.wikipedia.org/wiki/Sideloading">definition</a> is:</p>

<blockquote>
  <p><em>the transfer of apps from web sources that are not vendor-approved</em></p>
</blockquote>

<p>By this definition, Google’s statement that “sideloading is not going away”
is simply <em>false</em>. The vendor — Google, in the case of Android certified
devices — will, in point of fact, be approving the source. The supplicant
app developer must register with Google, pay a fee, provide government
identification, agree to non-negotiable (and ever-changing) terms and
conditions, enumerate all their current and future application identifiers,
upload evidence of their private signing key, and then hope and wait for
Google’s approval.</p>

<h3 id="what-this-means-for-your-rights">What this means for your rights</h3>

<p>You, the consumer, purchased your Android device believing in Google’s
promise that it was an open computing platform and that you could run
whatever software you choose on it. Instead, starting next year, they will
be non-consensually pushing an update to your operating system that
irrevocably blocks this right and leaves you at the mercy of their judgement
over what software you are permitted to trust.</p>

<p>You, the creator, can no longer develop an app and share it directly with
your friends, family, and community without first seeking Google’s
approval. The promise of Android — and a marketing advantage it has used to
distinguish itself against the iPhone — has always been that it is
“open”. But Google clearly feels that they have enough of a lock on the
Android ecosystem, along with sufficient regulatory capture, that they can
now jettison this principle with prejudice and impunity.</p>

<p>You, the state, are ceding the rights of your citizens and your own digital
sovereignty to a company with a track record of complying with the
extrajudicial demands of authoritarian regimes to remove perfectly legal
apps that they happen to dislike. The software that is critical to the
running of your businesses and governments will be at the mercy of the
opaque whims of a distant and unaccountable corporation. Monocultures are
perilous not just in agriculture, but in software distribution as well.</p>

<p>As a reminder, this applies not just to devices that exclusively use the
Google Play Store: this is for <em>every</em> Android Certified device <em>everywhere</em>
in the world, which encompasses over 95% of all Android devices outside of
China. Regardless of whether the device owner prefers to use a competing app
store like the Samsung Galaxy Store or the Epic Games Store, or a free and
open-source app repository like F-Droid, they will be captive to the
overarching policies unilaterally dictated by a competing corporate entity.</p>

<h3 id="the-place-of-greater-safety">The place of greater safety</h3>

<p>In promoting their developer registration program, Google
<a href="https://android-developers.googleblog.com/2025/08/elevating-android-security.html">purports</a>:</p>

<blockquote>
  <p><em>Our recent analysis found over 50 times more malware from internet-sideloaded sources than on apps available through Google Play.</em></p>
</blockquote>

<p>We haven’t seen this recent analysis — or any other supporting evidence —
but the “50 times” multiple does certainly sound like great cause for
distress (even if it is a surprisingly round number). But given the recent
<a href="https://www.malwarebytes.com/blog/news/2025/09/224-malicious-apps-removed-from-the-google-play-store-after-ad-fraud-campaign-discovered">news</a>
of “224 malicious apps removed from the Google Play Store after ad fraud
campaign discovered”, we are left to wonder whether their energies might
better be spent assessing and improving their own safeguards rather than
casting vague disparagements against the software development communities
that thrive outside their walled garden.</p>

<p>In addition, other recent
<a href="https://www.theregister.com/2025/08/26/apps_android_malware/">news</a> of over
19 million downloads of malware from the Play Store leads us to question
whether the sole judgement of a single corporate entity can be trusted to
identify and assess malware, especially when that judgement is clouded by
commercial incentives that may not align with the well-being of their users.</p>

<h3 id="what-can-be-done">What can be done?</h3>

<p>Google has been facing public outcry against their heavy-handed policies for
a long time, but this trend has accelerated recently. Last year they
<a href="https://arstechnica.com/gadgets/2024/08/chromes-manifest-v3-and-its-changes-for-ad-blocking-are-coming-real-soon/">crippled
ad-blockers</a>
in Chrome and Chromium-based browsers by forcing through their unpopular
“manifest v3” requirement for plugins, and earlier this year they <a href="https://arstechnica.com/gadgets/2025/03/google-makes-android-development-private-will-continue-open-source-releases/">closed
off</a>
the development of the Android Open Source Project (AOSP), which is how they
were able to clandestinely implement the verification infrastructure that
enforces their developer registration decree.</p>

<p>Developer verification is an existential threat to free software
distribution platforms like F-Droid as well as emergent commercial
competitors to the Play Store. We are witnessing a groundswell of opposition
to this attempt from both our user and developer communities, as well as the
tech press and civil society groups, but public policymakers still need to
be educated about the threat.</p>

<p>To learn more about what you can do as a consumer, visit
<a href="https://keepandroidopen.org/">keepandroidopen.org</a> for information on how to
contact your representative agencies and advocate for keeping the Android
ecosystem open for consumers and competition.</p>

<p>If you are an app developer, we recommend against signing yourself up for
Google’s developer registration program at this time. We unequivocally
reject their attempt to force this program upon the world.</p>

<p>Over half of all humankind uses an Android smartphone. Google does not own
your phone. You own your phone. You have the right to decide who to trust,
and where you can get your software from.</p>

  </div>

</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1X Neo – Home Robot - Pre Order (150 pts)]]></title>
            <link>https://www.1x.tech/order</link>
            <guid>45736457</guid>
            <pubDate>Tue, 28 Oct 2025 18:01:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.1x.tech/order">https://www.1x.tech/order</a>, See on <a href="https://news.ycombinator.com/item?id=45736457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><section><p><img alt="NEO" fetchpriority="high" width="3665" height="2062" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F0caf81e13a449a3e7e73d080655e6726e721e4a9-3665x2062.webp&amp;w=3840&amp;q=75 1x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F0caf81e13a449a3e7e73d080655e6726e721e4a9-3665x2062.webp&amp;w=3840&amp;q=75"></p></section><div><div><h3>$200 Deposit Due Today</h3><h3>Fully Refundable</h3><h3>US Deliveries start 2026</h3></div></div></div><div id="specs-overlay-content"><article id="overlay-utility-section"><h4>Utility</h4><div><div><p><span>Autonomy</span></p><h4></h4><p>NEO uses Redwood AI—1X’s Generalist AI model—for learning and repeating tasks. NEO arrives with basic autonomy for early owners and grows in capability overtime.</p></div><div><p><span>Scheduled Expert Mode</span></p><h4></h4><p>For complex tasks NEO doesn’t know, an Expert from 1X can remotely supervise its actions at scheduled times to help it learn new abilities and get the job done.</p></div></div><div><div><div><p><img alt="NEO" fetchpriority="high" width="1200" height="1686" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F900c4cb36ceb21a1c3d70ff0f261558c4b471d00-3000x1686.webp&amp;w=1200&amp;q=100 1x, https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F900c4cb36ceb21a1c3d70ff0f261558c4b471d00-3000x1686.webp&amp;w=3840&amp;q=100 2x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F900c4cb36ceb21a1c3d70ff0f261558c4b471d00-3000x1686.webp&amp;w=3840&amp;q=100"></p></div><div><h5>Voice Interface</h5><p>Companion allows you to speak naturally to NEO to access all features without using devices.</p></div></div><div><div><p><img alt="NEO Mobile app" fetchpriority="high" width="1200" height="2160" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F08fc56b688e0011d73e8adddbb6c7b4127f450b5-3840x2160.webp&amp;w=1200&amp;q=100 1x, https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F08fc56b688e0011d73e8adddbb6c7b4127f450b5-3840x2160.webp&amp;w=3840&amp;q=100 2x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F08fc56b688e0011d73e8adddbb6c7b4127f450b5-3840x2160.webp&amp;w=3840&amp;q=100"></p></div><div><h5>Mobile Interface</h5><p>With the NEO app, you can manage your NEO’s chore schedule, communicate remotely, monitor NEO and more.</p></div></div></div><div><div><p><img alt="Self-Charge Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/4549724c29d16d194ab3acd9d6b4f83eeb021dd0-24x24.svg"></p><div><h5>Self-Charge</h5><p>NEO manages it’s own battery life so you don't have to. When NEO needs a charge—it plugs itself in.</p></div></div><div><p><img alt="Remote Control Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/74bf89ce9ae0e3703f75501655694919d07a7f29-24x24.svg"></p><div><h5>Remote Control</h5><p>Pilot your NEO from anywhere in the world through your Mobile App &amp; VR device.</p></div></div><div><p><img alt="Emotive Ear Rings Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/11e01d38c945a1872b04b84bd72ced7d3a964d25-24x24.svg"></p><div><h5>Emotive Ear Rings</h5><p>NEO uses its Emotive Ear Rings to communicate its state and status (battery, attention, etc.)</p></div></div><div><p><img alt="Boom Box Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/7f528fe2df2f67bacab600e05da810f2382cde90-24x24.svg"></p><div><h5>Boom Box</h5><p>Use NEO as a mobile bluetooth speaker anywhere in your home.</p></div></div></div></article><article id="overlay-design-section"><h4>Design</h4><div><div><div><p><img alt="NEO MESH" fetchpriority="high" width="1200" height="2160" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F610080b1b2dcbf039e0248b833f7b0cc1414fbb2-3840x2160.webp&amp;w=1200&amp;q=100 1x, https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F610080b1b2dcbf039e0248b833f7b0cc1414fbb2-3840x2160.webp&amp;w=3840&amp;q=100 2x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F610080b1b2dcbf039e0248b833f7b0cc1414fbb2-3840x2160.webp&amp;w=3840&amp;q=100"></p></div><div><h5>Soft Body</h5><p>All NEO’s hardware is wrapped in custom 3D lattice polymer for safety and cushioning.</p></div></div><div><div><p><img alt="Tendon image" fetchpriority="high" width="1200" height="540" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F10b45d6f73c81112f6a12a31200046d965ce6b2f-960x540.png&amp;w=1200&amp;q=100 1x, https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F10b45d6f73c81112f6a12a31200046d965ce6b2f-960x540.png&amp;w=3840&amp;q=100 2x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F10b45d6f73c81112f6a12a31200046d965ce6b2f-960x540.png&amp;w=3840&amp;q=100"></p></div><div><h5>Safe Movements</h5><p>1X Tendon Drive actuation creates precise, low-energy movements necessary for home use.</p></div></div></div><div><div><p><img alt="Pinch Proof Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/50a6b6d2dccfacde1974692678cecc86a17c7389-24x24.svg"></p><div><h5>Pinch Proof</h5><p>NEO’s joints are covered from outside access, making the surface entirely pinch proof.</p></div></div><div><p><img alt="Body Language Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/66c09daa0373ef6902962cb67560cd2f01bd10ac-24x24.svg"></p><div><h5>Body Language</h5><p>NEO understands and responds to human gestures and expressions.</p></div></div><div><p><img alt="Comfortable to be Around Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/24637084772e5d8ad8b0d2cb935c1989a76f67a0-24x24.svg"></p><div><h5>Comfortable to be Around</h5><p>NEO is designed to compliment your living space, not disrupt it.</p></div></div><div><p><img alt="Machine Washable Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/7f9fbeda73560c4371e3d16a0780ae7707179145-24x24.svg"></p><div><h5>Machine Washable</h5><p>NEO’s soft suit and shoes are made from machine washable nylon.</p></div></div></div></article><article id="overlay-intelligence-section"><h4>Artificial Intelligence</h4><div><div><div><p><img alt="NEO Chip" fetchpriority="high" width="1200" height="2160" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2Fdf9ab4afbacf2d457ad8e984f4b80abdba0c2654-3840x2160.webp&amp;w=1200&amp;q=100 1x, https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2Fdf9ab4afbacf2d457ad8e984f4b80abdba0c2654-3840x2160.webp&amp;w=3840&amp;q=100 2x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2Fdf9ab4afbacf2d457ad8e984f4b80abdba0c2654-3840x2160.webp&amp;w=3840&amp;q=100"></p></div><div><h5>Redwood AI</h5><p><span>NEO’s vision language model for learning and performing chores around the house. <a href="https://1x.tech/ai" target="_blank" rel="noopener noreferrer">Learn more</a>.</span></p></div></div><div><div><p><img alt="NEO in the kitchen" fetchpriority="high" width="1200" height="1080" decoding="async" data-nimg="1" srcset="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F16ac313d16c3550c96e2d9432ca52b07e887ec44-1920x1080.webp&amp;w=1200&amp;q=100 1x, https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F16ac313d16c3550c96e2d9432ca52b07e887ec44-1920x1080.webp&amp;w=3840&amp;q=100 2x" src="https://www.1x.tech/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fqka6yvsc%2Fproduction%2F16ac313d16c3550c96e2d9432ca52b07e887ec44-1920x1080.webp&amp;w=3840&amp;q=100"></p></div><div><h5>Built-in LLM</h5><p><span>Interaction with NEO is driven by its built-in large language model, capable of understanding, reasoning, and conversing.</span></p></div></div></div><div><div><p><img alt="Audio Intelligence Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/909c055573fadcc8284926ada0e50ec88d0f49ef-24x24.svg"></p><div><h5>Audio Intelligence</h5><p>Interprets audio cues and conversational context.</p></div></div><div><p><img alt="Memory Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/fb9e15b60f55e5084dc38bdec17a182fa4770948-24x24.svg"></p><div><h5>Memory</h5><p>Retains information to personalize your experience.</p></div></div><div><p><img alt="Visual Intelligence  Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/b5a3d773fb01ddc62a872615b46cc53672be5141-24x24.svg"></p><div><h5>Visual Intelligence </h5><p>Uses visual input to enhance conversations.</p></div></div><div><p><img alt="Fully Mobile Icon" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" src="https://cdn.sanity.io/images/qka6yvsc/production/8d4331d652ecf1c8ea4bcd503ab9f9f610c387ad-24x24.svg"></p><div><h5>Fully Mobile</h5><p>Uses AI for navigating to where its needed.</p></div></div></div></article><section id="overlay-hardware-section"><h4>Hardware</h4><div><article><h5>Robot</h5></article><article><h5>Degrees of Freedom</h5></article><article><h5>Speed</h5></article><article><h5>Battery</h5><div><p>Quick charge</p><p> 6min per hour runtime</p></div></article><article><h5>Safety</h5><div><div><p>Body</p><p>Soft body with custom lattice polymer structure</p></div><div><p>Joints structure</p><p>No pinchpoints</p></div><div><p>Actuation</p><p>Low inertia tendon drives</p></div></div></article><article><h5>Ingress Protection</h5></article><article><h5>Tendon Drive</h5><div><div><p>Nominal load cycles</p><p>2.000.000 (1 day service replacement)</p></div><div><p>Peak (3x nominal) cycles&nbsp;</p><p>100.000 (1 day service replacement)&nbsp;</p></div><div><p>IMUs&nbsp;</p><p>Linkwise differential (velocity and accelerations)</p></div><div><p>Calibration</p><p>AI based continous adaption</p></div></div></article><article><h5>Compute</h5><div><div><p>Chipset</p><p>1X NEO Cortex (Nvidia Jetson Thor)</p></div><div><p>AI Compute</p><p>Up to 2070 FP4 TFLOPS</p></div><div><p>Microphone</p><p>4 beamforming microphones</p></div><div><p>Speakers</p><p>3 stage speaker in pelvis and chest area</p></div><div><p>Camera</p><p>Dual 8.85MP 90Hz Stereo Fisheye</p></div><div><p>Communication</p><p>Wifi, Bluetooth, 5G</p></div></div></article></div><h4>Comes with</h4></section></div><div id="specs-overlay-content"><article><h4>FAQ</h4></article></div></div></div>]]></description>
        </item>
    </channel>
</rss>