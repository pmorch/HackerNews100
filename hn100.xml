<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 26 Aug 2024 22:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Snowden: The arrest of Durov is an assault on the basic human rights (118 pts)]]></title>
            <link>https://twitter.com/Snowden/status/1827695836832334169</link>
            <guid>41360808</guid>
            <pubDate>Mon, 26 Aug 2024 19:24:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Snowden/status/1827695836832334169">https://twitter.com/Snowden/status/1827695836832334169</a>, See on <a href="https://news.ycombinator.com/item?id=41360808">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Arrest of Pavel Durov Is a Reminder That Telegram Is Not Encrypted (131 pts)]]></title>
            <link>https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960</link>
            <guid>41359502</guid>
            <pubDate>Mon, 26 Aug 2024 17:28:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960">https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960</a>, See on <a href="https://news.ycombinator.com/item?id=41359502">Hacker News</a></p>
Couldn't get https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Remove-bg ‚Äì open-source remove background using WebGPU (125 pts)]]></title>
            <link>https://bannerify.co/tools/remove-bg</link>
            <guid>41358490</guid>
            <pubDate>Mon, 26 Aug 2024 15:58:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bannerify.co/tools/remove-bg">https://bannerify.co/tools/remove-bg</a>, See on <a href="https://news.ycombinator.com/item?id=41358490">Hacker News</a></p>
Couldn't get https://bannerify.co/tools/remove-bg: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Using AI to fight insurance claim denials (169 pts)]]></title>
            <link>https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/</link>
            <guid>41358132</guid>
            <pubDate>Mon, 26 Aug 2024 15:31:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/">https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/</a>, See on <a href="https://news.ycombinator.com/item?id=41358132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>For San Francisco tech worker Holden Karau, paperwork had become a hobby.&nbsp;</p><p>Specifically, the forms and letters required to fight back when her health insurance provider denied a claim for a covered service, surgery, or pharmaceutical.&nbsp;</p><p>As a trans woman who loves motorcycles, she has required gender-affirming care and treatments for an accident in recent years, and received a spate of insurance denials along the way.&nbsp;</p><p>Instead of passively accepting the providers‚Äô decisions, she‚Äôd spend hours writing letters and filling out forms to appeal. It usually worked: Out of roughly 40 denials, she won more than 90% of her appeals, she estimates. (She also successfully fought an insurance denial for her dog, Professor Timbit.)&nbsp;</p><p>‚ÄúPart of that is an unreasonable willingness to take things too far,‚Äù Karau said. ‚ÄúThere‚Äôs an enjoyment in getting a counterparty to follow the rules that they don‚Äôt seem to want to have to follow.‚Äù</p></div><figure id=""><div><p><span><span></span><img alt="A person wearing a pink shirt and a smartwatch is working on a laptop. They are using their right hand to point at the screen and their left hand is resting on the laptop." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>Karau demonstrates the platform, which crafts appeals to health insurance denials. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>She began helping friends file appeals, too, then asked herself a question that‚Äôs typical for engineers: Could she figure out a way to automate the process?&nbsp;</p><p>After a year of tinkering, she just launched her answer: <a href="https://fighthealthinsurance.com/">Fight Health Insurance</a>, an open-source platform that takes advantage of large language models to help users generate health insurance appeals with AI.</p><p>With the slogan ‚ÄúMake your health insurance company cry too,‚Äù Karau‚Äôs site makes filing appeals faster and easier. <a href="https://www.kff.org/private-insurance/issue-brief/claims-denials-and-appeals-in-aca-marketplace-plans/">A recent study found that</a> Affordable Care Act patients appeal only about 0.1% of rejected claims, and she hopes her platform will encourage more people to fight back.&nbsp;</p></div><figure id=""><div><p><span><span></span><img alt="The image shows a tangle of multicolored cables connected to networking devices in a server rack, with wires coiled around various points and additional equipment nearby." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>One of the servers that operates the platform is in Karau's basement office. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>‚ÄúMost of the time, my relationship with my health insurance company is more adversarial than collaborative,‚Äù she said. ‚ÄúYou‚Äôre trying to force them to comply with the rules, and they‚Äôre trying to spend the <a href="https://www.propublica.org/article/unitedhealth-healthcare-insurance-denial-ulcerative-colitis">least amount of money</a>.‚Äù&nbsp;</p><p>A Fight Health Insurance user can scan their insurance denial, and the system will craft several appeal letters to choose from and modify.&nbsp;</p><p>The ‚Äúdirty secret‚Äù of the insurance industry is that most denials can be successfully appealed, according to Dr. Harley Schultz, a patient advocate in the Bay Area.</p><p>‚ÄúVery few people know about the process, and even fewer take advantage of it, because it‚Äôs rather cumbersome, arcane, and confusing, by design,‚Äù he said. ‚ÄúBut if you fight hard enough and long enough, most denials get overturned.‚Äù&nbsp;</p><p>It‚Äôs often assumed&nbsp; that only doctors can file appeals, but patients can do it too, he added. <a href="https://www.propublica.org/article/unitedhealth-healthcare-insurance-denial-ulcerative-colitis">Insurers reject about 1 in 7 claims</a> for treatment (Schultz estimates that it could be as high as 25% for some companies), and the reality is that physicians just don‚Äôt have time for all that filing.&nbsp;&nbsp;</p><p>‚ÄúI was in practice for many years, and if I fought every insurance denial, there wouldn‚Äôt be any time to do anything else,‚Äù Schultz said.&nbsp;</p><p>While some doctors have <a href="https://www.nytimes.com/2024/07/10/health/doctors-insurers-artificial-intelligence.html">turned to artificial intelligence themselves</a> to fight claims, Karau‚Äôs service puts the power in the hands of patients, who likely have more time and motivation to dedicate to their claims.&nbsp;</p><p>‚ÄúIn an ideal world, we would have a different system, but we don‚Äôt live in an ideal world, so what I‚Äôm shooting for here is incremental progress and making the world suck a little less,‚Äù she said.&nbsp;</p><p>So far, dozens have used the platform to generate an appeal, and Karau is assessing their feedback to fine-tune the platform and make it more effective and easier to use.&nbsp;</p></div><figure id=""><div><p><span><span></span><img alt="The image shows a computer screen displaying a draft appeal for an insurance company to cover PrEP medication. The document argues for coverage based on medical necessity." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>An example of an appeal letter generated by the AI platform. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>She&nbsp;estimates that she has spent about $10,000 building the platform. It‚Äôs free for users, though she might eventually charge for added services like faxing appeals.</p><p>At this point, she‚Äôs not planning on leaving her tech job to work on the platform full time (she has held gigs at IBM, Apple, Google, and Netflix, where she currently works) but hopes it can become a self-sustaining business, in addition to a cause about which she‚Äôs wildly passionate.&nbsp;</p><p>‚ÄúThe best-case scenario ‚Äî&nbsp;which is, admittedly, incredibly unlikely ‚Äî&nbsp;is that this increases the accessibility of appeals to the point that insurance companies stop denying so much tiny bullshit,‚Äù she said. ‚ÄúI suspect that they would still try to be dicks about big things, but hopefully we can get them to stop being dicks about small things.‚Äù</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dokku: My favorite personal serverless platform (491 pts)]]></title>
            <link>https://hamel.dev/blog/posts/dokku/</link>
            <guid>41358020</guid>
            <pubDate>Mon, 26 Aug 2024 15:21:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hamel.dev/blog/posts/dokku/">https://hamel.dev/blog/posts/dokku/</a>, See on <a href="https://news.ycombinator.com/item?id=41358020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<div>
<figure>
<p><img src="https://hamel.dev/blog/posts/dokku/images/serverless.png"></p>
<figcaption>With Dokku, you can turn a VPS into a powerful serverless platform</figcaption>
</figure>
</div>
<section id="what-is-dokku">
<h2 data-anchor-id="what-is-dokku">What is Dokku?</h2>
<p><a href="https://dokku.com/">Dokku</a> is an open-source Platform as a Service (PaaS) that runs on a single server of your choice. <strong>It‚Äôs like <a href="https://www.heroku.com/">Heroku</a>, but you own it.</strong> It is a great way to get the benefits of Heroku without the costs (Heroku can get quite expensive!). I need to deploy many applications for my <a href="https://hamel.dev/hire.html">LLM consulting work</a>. Having a cost-effective, easy-to-use serverless platform is essential for me.</p>
<p><strong>I run a Dokku server on a $7/month VPS on <a href="https://us.ovhcloud.com/">OVHcloud</a></strong> for non-gpu workloads. These applications include things like <a href="https://nbsanity.com/">nbsanity</a> and <a href="https://langfree.parlance-labs.com/tutorials/shiny.html#run-the-shiny-app-locally">data cleaning tools for LLMs</a>.</p>
<p>Some of the features I love about Dokku:</p>
<ul>
<li>Easy to use (like Heroku).</li>
<li>Automatic SSL certificate management via <a href="https://letsencrypt.org/">Let‚Äôs Encrypt</a>.</li>
<li>Basic Auth support so I can password-protect sites.</li>
<li>Scale up and down with a single command.</li>
<li>Flexibility to handle any application (Node, Python, etc), including defining a Docker container.</li>
<li>Lots of <a href="https://dokku.com/docs/community/plugins/?h=plugins#official-plugins">official plugins</a> that do almost anything I want.</li>
<li>Easily deploy with git commands.</li>
</ul>
</section>
<section id="minimal-dokku-examples">
<h2>Minimal Dokku Examples</h2>
<p>Make sure you <a href="https://dokku.com/docs/getting-started/installation/">install Dokku</a> on your VPS. As I mentioned, I use <a href="https://us.ovhcloud.com/">OVH</a>.</p>
<section id="deploying-apps-as-a-docker-container">
<h2 data-anchor-id="deploying-apps-as-a-docker-container">Deploying Apps as A Docker Container</h2>
<p>An easy way to deploy applications is with a Docker container.</p>
<p>To deploy a Docker container, I put a Dockerfile in the root of my git repo like this:</p>
<div id="cb1" data-filename="Dockerfile"><pre><code><span id="cb1-1"><span>FROM</span> python:3.10</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>COPY</span> . /app</span>
<span id="cb1-4"><span>WORKDIR</span> /app</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span># Install the local package</span></span>
<span id="cb1-7"><span>RUN</span> <span>pip</span> install .</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span># This directory contains app.py, a FastApi app</span></span>
<span id="cb1-10"><span>WORKDIR</span> /app/</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span>ENTRYPOINT</span> [<span>"./entrypoint.sh"</span>]</span></code></pre></div>
<div>
<p>The <code>entrypoint.sh</code> script allows me to easily run the app locally or in a Docker container. It looks like this:</p>
<div id="cb2" data-filename="entrypoint.sh"><pre><code><span id="cb2-1"><span>#!/bin/bash</span></span>
<span id="cb2-2"><span>exec</span> uvicorn main:app <span>--port</span> <span>"</span><span>$PORT</span><span>"</span> <span>--host</span> 0.0.0.0</span></code></pre></div>
</div>
<p>On the Dokku host, create the app:</p>

<p><strong>Locally</strong>, set up access to the Dokku host and name it <code>dokku</code> in your <code>~/.ssh/config</code> file. For example, here is mine:</p>
<pre><code>Host dokku
  HostName &lt;The external IP address of your Dokku host&gt;
  User ubuntu
  IdentityFile /Users/hamel/.ssh/dokku</code></pre>
<p>Locally, add the Dokku host as a remote and push to it:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>git</span> remote add dokku dokku@dokku:myapp</span>
<span id="cb5-2"><span>git</span> push dokku main</span></code></pre></div>
<p>That‚Äôs it - your app should be running on the Dokku host! Your local logs will print the URL that your application is served on, which by default will be <code>myapp.yourdomain.com</code>. You can also scale it up/down with the following command:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>#scale to two workers</span></span>
<span id="cb6-2"><span>dokku</span> ps:scale myapp web=2</span></code></pre></div>
<p>We are just scratching the surface. For more details, see the <a href="https://dokku.com/docs/">Dokku docs</a>.</p>
</section>
<section id="static-sites">
<h2 data-anchor-id="static-sites">Static Sites</h2>
<p>GitHub Pages is annoying in that you can‚Äôt easily deploy private static sites without paying for an expensive Enterprise account. With Dokku, you can easily deploy a static site from a private GitHub Repo and password-protect it.</p>
<p>We will assume that you have a static site in a git repo in a folder named <code>_site</code>.</p>
<p><strong>On the Dokku host</strong>, create an app named <code>mysite</code> and set the <code>NGINX_ROOT</code> environment variable to <code>_site</code>:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>dokku</span> apps:create mysite</span>
<span id="cb7-2"><span>dokku</span> config:set static-site NGINX_ROOT=_site</span></code></pre></div>
<p>Also on the Dokku host, install <a href="https://github.com/dokku/dokku-http-auth">basic auth</a> and <a href="https://github.com/dokku/dokku-http-auth/issues/15#issuecomment-1637058437">set permissions</a> so the plugin can work properly.</p>
<div id="cb8"><pre><code><span id="cb8-1"><span># do setup for the auth plugin that we will use later</span></span>
<span id="cb8-2"><span>sudo</span> dokku plugin:install https://github.com/dokku/dokku-http-auth.git</span>
<span id="cb8-3"><span>sudo</span> chmod +x /home/dokku</span></code></pre></div>
<p>Then execute the following commands from the root of your git repo that contains the static site. :</p>
<div id="annotated-cell-8"><pre><code><a data-target-cell="annotated-cell-8" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-8-1"><span>touch</span> .static</span>
<a data-target-cell="annotated-cell-8" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-8-2"><span>echo</span> BUILDPACK_URL=https://github.com/dokku/buildpack-nginx <span>&gt;</span> .env</span>
<a data-target-cell="annotated-cell-8" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-8-3"><span>git</span> remote add dokku dokku@dokku:mysite</span></code></pre></div>
<dl>
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="1" data-code-annotation="1">tells <code>dokku</code> that this is a static site</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="2" data-code-annotation="2">tells <code>dokku</code> to use the nginx buildpack for static sites (it will usually automatically detect this, but if you have a project with code and a static site, you need to tell it to use the nginx buildpack so it doesn‚Äôt get confused).</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="3" data-code-annotation="3">add the <code>dokku</code> host as a remote. For this to work, make sure <code>dokku</code> is a hostname in your <code>~/.ssh/config</code> file as described <a href="#deploying-apps-as-a-docker-container">in the previous section</a>.</span>
</dd>
</dl>
<p>Finally, deploy your application:</p>

<p>You can now add auth by running the following command on the Dokku host:</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>dokku</span> http-auth:enable mysite <span>&lt;</span>username<span>&gt;</span> <span>&lt;</span>password<span>&gt;</span></span></code></pre></div>
<div>

<p>You can add multiple usernames/passwords and even filter specific IPs. See <a href="https://github.com/dokku/dokku-http-auth">the docs</a>.</p>
</div>
<div>
<p>It‚Äôs often desirable to have HTTPS for your site. Dokku makes this easy with the <a href="https://github.com/dokku/dokku-letsencrypt">Let‚Äôs Encrypt Plugin</a>, which will even auto-renew for you. I don‚Äôt use this, because I‚Äôm letting <a href="https://developers.cloudflare.com/dns/manage-dns-records/reference/proxied-dns-records/">Cloudflare handle this with its proxy</a>.</p>
<p>If you are using Cloudflare this way, activating this plugin will mess things up (don‚Äôt worry its easy to disable). Honestly, I think it‚Äôs easier to let Cloudflare handle it if you are already doing so.</p>
</div>
</section>
</section>
<section id="deploying-with-github-actions">
<h2>Deploying With GitHub Actions</h2>
<p>You can automatically deploy Dokku apps with GitHub Actions, which is helpful if you don‚Äôt want to fiddle with pushing to the Dokku host. Here is an example GitHub Action workflow that does this:</p>
<div id="cb11" data-filename="deploy-dokku.yml"><pre><code><span id="cb11-1"><span>name</span><span>:</span><span> CI</span></span>
<span id="cb11-2"><span>on</span><span>:</span></span>
<span id="cb11-3"><span>  </span><span>workflow_dispatch</span><span>:</span></span>
<span id="cb11-4"><span>  </span><span>push</span><span>:</span></span>
<span id="cb11-5"><span>    </span><span>branches</span><span>:</span><span> </span><span>[</span><span>main</span><span>]</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span>concurrency</span><span>:</span><span> # Cancel previous jobs to avoid deploy locks on dokku</span></span>
<span id="cb11-8"><span>  </span><span>group</span><span>:</span><span> ${{ github.ref }}</span></span>
<span id="cb11-9"><span>  </span><span>cancel-in-progress</span><span>:</span><span> </span><span>true</span></span>
<span id="cb11-10"></span>
<span id="cb11-11"><span>jobs</span><span>:</span></span>
<span id="cb11-12"><span>  </span><span>deploy-dokku</span><span>:</span></span>
<span id="cb11-13"><span>    </span><span>runs-on</span><span>:</span><span> ubuntu-latest</span></span>
<span id="cb11-14"><span>    </span><span>steps</span><span>:</span></span>
<span id="cb11-15"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Checkout code</span></span>
<span id="cb11-16"><span>        </span><span>uses</span><span>:</span><span> actions/checkout@v2</span></span>
<span id="cb11-17"><span>        </span><span>with</span><span>:</span></span>
<span id="cb11-18"><span>          </span><span>fetch-depth</span><span>:</span><span> </span><span>0</span></span>
<span id="cb11-19"><span>      </span></span>
<span id="cb11-20"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Install SSH key</span></span>
<span id="cb11-21"><span>        run</span><span>: </span><span>|</span></span>
<span id="cb11-22">          echo "${{ secrets.DOKKU_SSH_PRIVATE_KEY }}" &gt; private_key.pem</span>
<span id="cb11-23">          chmod 600 private_key.pem</span>
<span id="cb11-24"></span>
<span id="cb11-25"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Add remote and push</span></span>
<span id="cb11-26"><span>        run</span><span>: </span><span>|</span></span>
<span id="cb11-27">          git remote add dokku dokku@rechat.co:llm-eval</span>
<span id="cb11-28">          GIT_SSH_COMMAND="ssh -i private_key.pem -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" git push dokku main -f</span></code></pre></div>
</section>
<section id="miscellaneous-tips">
<h2>Miscellaneous Tips</h2>
<p>These are things I often forget, so I‚Äôm writing them down here. For these examples, assume my app is named <code>llm-eval</code> and my host is <code>rechat.co</code>.</p>
<section id="run-commands-remotely">
<h2 data-anchor-id="run-commands-remotely">Run commands remotely</h2>
<p>You don‚Äôt have to ssh into the Dokku host just to execute commands. You can execute them remotely via the <code>dokku</code> user like this:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span># https://dokku.com/docs/deployment/application-management/</span></span>
<span id="cb12-2"><span>ssh</span> dokku@rechat.co apps:list</span></code></pre></div>
</section>
<section id="docker-cache">
<h2 data-anchor-id="docker-cache">Docker cache</h2>
<p>This is how you can <a href="https://dokku.com/docs/advanced-usage/repository-management/">invalidate the docker cache</a> for a fresh build:</p>
<div id="cb13"><pre><code><span id="cb13-1"><span>ssh</span> dokku@rechat.co repo:purge-cache llm-eval</span></code></pre></div>
</section>
<section id="rebuild-without-pushing">
<h2 data-anchor-id="rebuild-without-pushing">Rebuild without pushing</h2>
<p>Sometimes you want to rebuild without pushing. There are <a href="https://dokku.com/docs/processes/process-management/">many ways to do this</a>, but one way is like this:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>ssh</span> dokku@rehcat.co ps:rebuild llm-eval</span></code></pre></div>
</section>
</section>
<section id="why-did-i-write-this">
<h2>Why Did I Write This?</h2>
<p>I had to dig up these details whenever I wanted to deploy a new app, so I had to write it up anyway. I hope you find it useful, too!</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux: We need tiling desktop environments (134 pts)]]></title>
            <link>https://linuxblog.io/linux-tiling-desktop-environments/</link>
            <guid>41357853</guid>
            <pubDate>Mon, 26 Aug 2024 15:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxblog.io/linux-tiling-desktop-environments/">https://linuxblog.io/linux-tiling-desktop-environments/</a>, See on <a href="https://news.ycombinator.com/item?id=41357853">Hacker News</a></p>
Couldn't get https://linuxblog.io/linux-tiling-desktop-environments/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[DOJ Files Antitrust Suit Against RealPage, Maker of Rent-Setting Algorithm (158 pts)]]></title>
            <link>https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</link>
            <guid>41357557</guid>
            <pubDate>Mon, 26 Aug 2024 14:36:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm">https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</a>, See on <a href="https://news.ycombinator.com/item?id=41357557">Hacker News</a></p>
Couldn't get https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[NSA releases 1982 Grace Hopper lecture (478 pts)]]></title>
            <link>https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/</link>
            <guid>41356528</guid>
            <pubDate>Mon, 26 Aug 2024 12:37:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/">https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/</a>, See on <a href="https://news.ycombinator.com/item?id=41356528">Hacker News</a></p>
Couldn't get https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Coolify‚Äôs rise to fame, and why it could be a big deal (120 pts)]]></title>
            <link>https://blog.api-fiddle.com/posts/coolify-revolution</link>
            <guid>41356239</guid>
            <pubDate>Mon, 26 Aug 2024 11:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.api-fiddle.com/posts/coolify-revolution">https://blog.api-fiddle.com/posts/coolify-revolution</a>, See on <a href="https://news.ycombinator.com/item?id=41356239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>To this day, I remember deploying my first Next.js app on Vercel. It was a magical moment.</p>
<p>Before that, I had only known pain. From renting a server, dockerizing, setting up a proxy, SSL certificates, monitoring‚Äîyou name it!</p>
<p>Then came Next.js and Vercel. Sure, they weren‚Äôt the first to promise seamless deployments. Products like Heroku, AWS Elastic Beanstalk, etc. all tried to
remove the pain from deploying software on the internet.</p>
<p>However, it never felt as magical as connecting my repository to Vercel and pressing that sweet, sweet deploy button.</p>
<p>What happened next with Next.js and Vercel is far less magical... but back to the blog post.</p>
<h2><span>#</span>Coolify Clicked</h2>
<p>While the internet is in an AI craze, I quietly had another magical moment. This time, it wasn‚Äôt
fueled by a multimillion-dollar company like Google, AWS, or Vercel.</p>
<p>It was fueled by <a rel="nofollow" href="https://x.com/heyandras?lang=en" target="_blank">Andras Bacsai</a>, who turned down over 30 investors to build Coolify as a
community-funded project. It is a true revolution as I will try to explain later in this blog post.</p>
<p>During the last weeks, I was on the lookout for the best solution to deploy the <a rel="nofollow" href="https://api-fiddle.com/" target="_blank">Api-Fiddle</a> REST API. After considering <a rel="nofollow" href="https://fly.io/" target="_blank">fly.io</a>, a friend pointed me to <a rel="nofollow" href="https://github.com/coollabsio/coolify" target="_blank">Coolify</a>.
The name rang familiar‚ÄîI‚Äôd seen it on X before!</p>
<p>Coolify describes itself as:</p>
<blockquote>
<p>An open-source &amp; self-hostable Heroku / Netlify / Vercel alternative.</p>
</blockquote>
<p>I was hooked and ready to give it a try. I rented a Virtual Private Server (VPS) on <a rel="nofollow" href="https://hetzner.com/" target="_blank">Hetzner</a> and set it up with Coolify. I followed this fantastic
<a rel="nofollow" href="https://www.youtube.com/watch?v=taJlPG82Ucw&amp;t=3431s&amp;pp=ygUHY29vbGlmeQ%3D%3D" target="_blank">YouTube tutorial</a>.</p>
<p>While setting up a VPS isn‚Äôt exactly magical, it was simple enough, and it only took couple of hours to get Coolify running on my server.</p>
<h2><span>#</span>My Coolify Moment</h2>
<p>My Coolify moment happened right then and there.</p>
<p>Coolify is still in it's early days and the UI can be a bit rough. But with little effort I became the CEO of my own Vercel-like,
fully-featured deployment platform.</p>
<p>Deploying a PostgreSQL instance took three clicks and 30 seconds. Configuring a running instance of Grafana? Another 30 seconds.</p>
<p>When it was time to deploy my app. I pointed Coolify to my GitHub repository and specified the domain.</p>
<p>After a bit of fiddling my app was deployed with a database, hourly backups, and a <a rel="nofollow" href="https://caddyserver.com/" target="_blank">Caddy</a> proxy. Just like that.</p>
<p>Once you get the hang of it, deploying any app that is either dockerized or <a rel="nofollow" href="https://nixpacks.com/docs/getting-started" target="_blank">Nixpacks-compatible</a> is a breeze.</p>
<p>This alone makes me talk about Coolify with excitement. But I believe there is more to this story.</p>
<p>Coolify has the potential to change how small to mid-sized projects and companies -
deploy internal and external tooling.</p>
<h2><span>#</span>The Rise to Fame</h2>
<p>Looking back, I‚Äôve only had one moment in my software career that felt like a turning point: My first deployment to Vercel.
Now, I‚Äôve had another one with Coolify. Before you disagree, let me explain.</p>
<p>No, Coolify isn‚Äôt something entirely new. Like many new things, it‚Äôs a wrapper around existing technologies. Now and then, you could piece
together these technologies yourself and, depending on your skill and luck, end up with something very similar to what Coolify offers.</p>
<p>You can achieve this with foundational tools like Kubernetes or Docker Compose and additional layers to support rolling updates, webhooks, etc.</p>
<p>Additionally, Coolify isn‚Äôt the first attempt to build an open-source Platform as a Service (PaaS). Tools like Dokku have been
around since 2014 (Coolify began in 2021).</p>
<p>However, Coolify‚Äôs explosive growth in 2024 suggests we‚Äôre witnessing a different level of adoption and impact on the wider software community.</p>
<p><img src="https://blog.api-fiddle.com/post-media/0008-graph.png" alt="Comparison of github starts between Coolify and Dokky" width="864" height="549"></p><p><a rel="nofollow" href="https://star-history.com/#dokku/dokku&amp;coollabsio/coolify&amp;Date" target="_blank">Check out this graph</a>.</p>
<p>To paint the full picture of Coolify's rise to fame, we also need to talk about the recent rise of self-hosted software in general.</p>
<p>There‚Äôs a wide variety of open-source, self-hostable software out there‚Äîfrom Calendly alternative <a rel="nofollow" href="https://cal.com/" target="_blank">Cal.com</a>
to email and marketing tools like <a rel="nofollow" href="https://www.mailcoach.app/" target="_blank">Mailcoach</a>.</p>
<p>In recent years, many software companies have developed a business model around self-hosted versions of their products.</p>
<p>While altruism surely plays a role in open soucring software, it can be good for business too. Small comapnies often open source
products so they get adopted by large organizations quicker! This model is called
<a rel="nofollow" href="https://cal.com/blog/open-source" target="_blank">Commercial Open Source Software</a> (COSS).</p>
<p>Large enterprises self-host tools and retain ownership of their data. In return, they sign a service contract with the vendor.
This saves companies years of security certifications and enterprise sales cycles. All for the price of open sourcing their product that
no small company in their right mind would ever self-host...<strong>Right? Right!</strong></p>
<p>In the past, most self-hosting (aside from WordPress and a few other examples) was cumbersome for small companies. It was easier to wire $100 to Salesforce and
hope Slack will do right by them and their data.</p>
<p>I belive Coolify has the potential to change that. Coolify can enable organizations of any size to host an arbitrary number of free,
self-hosted software easier than ever.</p>
<p>Let‚Äôs look at this tweet from Jarek Ceborski, an indie creator, who self-hosted Mailcoach in just a couple of hours (I'm not sure if he uses Coolify):</p>

<p>Here's another Tweet from Theo, a larger creator:</p>

<p>More and more developers seem to take advantage of free, self-hostable software.</p>
<p>My argument is this: The increasing availability of well-designed, self-hostable software combined with tools that make self-hosting
trivial has the potential to shake things up.</p>
<h2><span>#</span>Dorothy, are we still in Kansas?</h2>
<p>One could be tempted to call this a full circle. We came from a world of on-premise (On-Prem) Software, moved to the Cloud, and ended up
in a Software as a Service (SaaS) world. Now, are we really considering leaving SaaS behind to return to cloud instances?</p>
<p>It may look like we're one step away from dusting off our old on-prem servers.</p>
<p>While this perspective has merit, there's another way to view it. We can choose to celebrate the wealth of tools and deployment options
available, allowing us to optimize for cost efficiency and data ownership.</p>
<h2><span>#</span>Final Thoughts</h2>
<p>This is an overwhelmingly positive review of Coolify, but it's important to remember that despite its wide usage, Coolify is still in its early stages.</p>
<p>This article was not sponsored by Coolify, and I have no affiliation with the product other than being a user.</p>
<p>If you‚Äôre looking to get started with Coolify, the best place to start is likely <a rel="nofollow" href="https://www.youtube.com/watch?v=taJlPG82Ucw&amp;t=3431s&amp;pp=ygUHY29vbGlmeQ%3D%3D" target="_blank">this video</a>
along with their <a rel="nofollow" href="https://coolify.io/" target="_blank">website</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fixing a Bug in Google Chrome as a First-Time Contributor (428 pts)]]></title>
            <link>https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</link>
            <guid>41355303</guid>
            <pubDate>Mon, 26 Aug 2024 09:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/">https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=41355303">Hacker News</a></p>
Couldn't get https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dutch DPA fines Uber 290M euro because of transfers of drivers' data to the US (289 pts)]]></title>
            <link>https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</link>
            <guid>41355021</guid>
            <pubDate>Mon, 26 Aug 2024 08:15:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us">https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</a>, See on <a href="https://news.ycombinator.com/item?id=41355021">Hacker News</a></p>
Couldn't get https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Avante.nvim: Use Your Neovim Like Using Cursor AI IDE (229 pts)]]></title>
            <link>https://github.com/yetone/avante.nvim</link>
            <guid>41353835</guid>
            <pubDate>Mon, 26 Aug 2024 03:44:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/yetone/avante.nvim">https://github.com/yetone/avante.nvim</a>, See on <a href="https://news.ycombinator.com/item?id=41353835">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">avante.nvim</h2><a id="user-content-avantenvim" aria-label="Permalink: avante.nvim" href="#avantenvim"></a></p>
<p dir="auto"><strong>avante.nvim</strong> is a Neovim plugin designed to emulate the behaviour of the <a href="https://www.cursor.com/" rel="nofollow">Cursor</a> AI IDE. It provides users with AI-driven code suggestions and the ability to apply these recommendations directly to their source files with minimal effort.</p>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">ü•∞ This project is undergoing rapid iterations, and many exciting features will be added successively. Stay tuned!</p>
</div>
<details open="">
  <summary>
    
    <span aria-label="Video description avante-2.mp4">avante-2.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description avante-3.mp4">avante-3.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>AI-Powered Code Assistance</strong>: Interact with AI to ask questions about your current code file and receive intelligent suggestions for improvement or modification.</li>
<li><strong>One-Click Application</strong>: Quickly apply the AI's suggested changes to your source code with a single command, streamlining the editing process and saving time.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install <code>avante.nvim</code> using <a href="https://github.com/folke/lazy.nvim">lazy.nvim</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;make&quot;,
  opts = {
    -- add any opts here
  },
  dependencies = {
    &quot;nvim-tree/nvim-web-devicons&quot;, -- or echasnovski/mini.icons
    &quot;stevearc/dressing.nvim&quot;,
    &quot;nvim-lua/plenary.nvim&quot;,
    &quot;MunifTanjim/nui.nvim&quot;,
    --- The below is optional, make sure to setup it properly if you have lazy=true
    {
      'MeanderingProgrammer/render-markdown.nvim',
      opts = {
        file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
      },
      ft = { &quot;markdown&quot;, &quot;Avante&quot; },
    },
  },
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>make<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span><span>--</span> add any opts here</span>
  },
  <span>dependencies</span> <span>=</span> {
    <span><span>"</span>nvim-tree/nvim-web-devicons<span>"</span></span>, <span><span>--</span> or echasnovski/mini.icons</span>
    <span><span>"</span>stevearc/dressing.nvim<span>"</span></span>,
    <span><span>"</span>nvim-lua/plenary.nvim<span>"</span></span>,
    <span><span>"</span>MunifTanjim/nui.nvim<span>"</span></span>,
    <span><span>---</span> The below is optional, make sure to setup it properly if you have lazy=true</span>
    {
      <span><span>'</span>MeanderingProgrammer/render-markdown.nvim<span>'</span></span>,
      <span>opts</span> <span>=</span> {
        <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
      },
      <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
    },
  },
}</pre></div>
<p dir="auto">For Windows users, change the build command to the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1&quot;,
  -- rest of the config
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1<span>"</span></span>,
  <span><span>--</span> rest of the config</span>
}</pre></div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><code>avante.nvim</code> is currently only compatible with Neovim 0.10.0 or later. Please ensure that your Neovim version meets these requirements before proceeding.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">If your neovim doesn't use LuaJIT, then change <code>build</code> to <code>make lua51</code>. By default running make will install luajit.
For ARM-based setup, make sure to also install cargo as we will have to build the tiktoken_core from source.</p>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">Recommended <strong>Neovim</strong> options:</p>
<div dir="auto" data-snippet-clipboard-copy-content="-- views can only be fully collapsed with the global statusline
vim.opt.laststatus = 3
-- Default splitting will cause your main splits to jump when opening an edgebar.
-- To prevent this, set `splitkeep` to either `screen` or `topline`.
vim.opt.splitkeep = &quot;screen&quot;"><pre><span><span>--</span> views can only be fully collapsed with the global statusline</span>
<span>vim</span>.<span>opt</span>.<span>laststatus</span> <span>=</span> <span>3</span>
<span><span>--</span> Default splitting will cause your main splits to jump when opening an edgebar.</span>
<span><span>--</span> To prevent this, set `splitkeep` to either `screen` or `topline`.</span>
<span>vim</span>.<span>opt</span>.<span>splitkeep</span> <span>=</span> <span><span>"</span>screen<span>"</span></span></pre></div>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto"><code>render-markdown.nvim</code> is an optional dependency that is used to render the markdown content of the chat history. Make sure to also include <code>Avante</code> as a filetype
to its setup:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;MeanderingProgrammer/render-markdown.nvim&quot;,
  opts = {
    file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
  },
  ft = { &quot;markdown&quot;, &quot;Avante&quot; },
}"><pre>{
  <span><span>"</span>MeanderingProgrammer/render-markdown.nvim<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
  },
  <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
}</pre></div>
</div>
<p dir="auto">Default setup configuration:</p>
<p dir="auto"><em>See <a href="https://github.com/yetone/avante.nvim/blob/main/lua/avante/config.lua">config.lua#L9</a> for the full config</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  ---@alias Provider &quot;openai&quot; | &quot;claude&quot; | &quot;azure&quot;  | &quot;copilot&quot; | [string]
  provider = &quot;claude&quot;,
  claude = {
    endpoint = &quot;https://api.anthropic.com&quot;,
    model = &quot;claude-3-5-sonnet-20240620&quot;,
    temperature = 0,
    max_tokens = 4096,
  },
  mappings = {
    ask = &quot;<leader>aa&quot;,
    edit = &quot;<leader>ae&quot;,
    refresh = &quot;<leader>ar&quot;,
    --- @class AvanteConflictMappings
    diff = {
      ours = &quot;co&quot;,
      theirs = &quot;ct&quot;,
      none = &quot;c0&quot;,
      both = &quot;cb&quot;,
      next = &quot;]x&quot;,
      prev = &quot;[x&quot;,
    },
    jump = {
      next = &quot;]]&quot;,
      prev = &quot;[[&quot;,
    },
    submit = {
      normal = &quot;<CR>&quot;,
      insert = &quot;<C-s>&quot;,
    },
    toggle = {
      debug = &quot;<leader>ad&quot;,
      hint = &quot;<leader>ah&quot;,
    },
  },
  hints = { enabled = true },
  windows = {
    wrap = true, -- similar to vim.o.wrap
    width = 30, -- default % based on available width
    sidebar_header = {
      align = &quot;center&quot;, -- left, center, right for title
      rounded = true,
    },
  },
  highlights = {
    ---@type AvanteConflictHighlights
    diff = {
      current = &quot;DiffText&quot;,
      incoming = &quot;DiffAdd&quot;,
    },
  },
  --- @class AvanteConflictUserConfig
  diff = {
    debug = false,
    autojump = true,
    ---@type string | fun(): any
    list_opener = &quot;copen&quot;,
  },
}"><pre>{
  <span><span>---</span><span>@alias</span> <span>Provider</span> <span><span>"</span>openai<span>" </span></span><span>| </span><span><span>"</span>claude<span>" </span></span><span>| </span><span><span>"</span>azure<span>"  </span></span><span>| </span><span><span>"</span>copilot<span>" </span></span><span>| </span><span>[string]</span></span>
  <span>provider</span> <span>=</span> <span><span>"</span>claude<span>"</span></span>,
  <span>claude</span> <span>=</span> {
    <span>endpoint</span> <span>=</span> <span><span>"</span>https://api.anthropic.com<span>"</span></span>,
    <span>model</span> <span>=</span> <span><span>"</span>claude-3-5-sonnet-20240620<span>"</span></span>,
    <span>temperature</span> <span>=</span> <span>0</span>,
    <span>max_tokens</span> <span>=</span> <span>4096</span>,
  },
  <span>mappings</span> <span>=</span> {
    <span>ask</span> <span>=</span> <span><span>"</span>&lt;leader&gt;aa<span>"</span></span>,
    <span>edit</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ae<span>"</span></span>,
    <span>refresh</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ar<span>"</span></span>,
    <span><span>---</span><span> @class</span> <span>AvanteConflictMappings</span></span>
    <span>diff</span> <span>=</span> {
      <span>ours</span> <span>=</span> <span><span>"</span>co<span>"</span></span>,
      <span>theirs</span> <span>=</span> <span><span>"</span>ct<span>"</span></span>,
      <span>none</span> <span>=</span> <span><span>"</span>c0<span>"</span></span>,
      <span>both</span> <span>=</span> <span><span>"</span>cb<span>"</span></span>,
      <span>next</span> <span>=</span> <span><span>"</span>]x<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[x<span>"</span></span>,
    },
    <span>jump</span> <span>=</span> {
      <span>next</span> <span>=</span> <span><span>"</span>]]<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[[<span>"</span></span>,
    },
    <span>submit</span> <span>=</span> {
      <span>normal</span> <span>=</span> <span><span>"</span>&lt;CR&gt;<span>"</span></span>,
      <span>insert</span> <span>=</span> <span><span>"</span>&lt;C-s&gt;<span>"</span></span>,
    },
    <span>toggle</span> <span>=</span> {
      <span>debug</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ad<span>"</span></span>,
      <span>hint</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ah<span>"</span></span>,
    },
  },
  <span>hints</span> <span>=</span> { <span>enabled</span> <span>=</span> <span>true</span> },
  <span>windows</span> <span>=</span> {
    <span>wrap</span> <span>=</span> <span>true</span>, <span><span>--</span> similar to vim.o.wrap</span>
    <span>width</span> <span>=</span> <span>30</span>, <span><span>--</span> default % based on available width</span>
    <span>sidebar_header</span> <span>=</span> {
      <span>align</span> <span>=</span> <span><span>"</span>center<span>"</span></span>, <span><span>--</span> left, center, right for title</span>
      <span>rounded</span> <span>=</span> <span>true</span>,
    },
  },
  <span>highlights</span> <span>=</span> {
    <span><span>---</span><span>@type</span> <span>AvanteConflictHighlights</span></span>
    <span>diff</span> <span>=</span> {
      <span>current</span> <span>=</span> <span><span>"</span>DiffText<span>"</span></span>,
      <span>incoming</span> <span>=</span> <span><span>"</span>DiffAdd<span>"</span></span>,
    },
  },
  <span><span>---</span><span> @class</span> <span>AvanteConflictUserConfig</span></span>
  <span>diff</span> <span>=</span> {
    <span>debug</span> <span>=</span> <span>false</span>,
    <span>autojump</span> <span>=</span> <span>true</span>,
    <span><span>---</span><span>@type</span> <span>string </span><span>| </span><span>fun</span><span>(): </span><span>any</span></span>
    <span>list_opener</span> <span>=</span> <span><span>"</span>copen<span>"</span></span>,
  },
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Given its early stage, <code>avante.nvim</code> currently supports the following basic functionalities:</p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">Avante will only support OpenAI (and its variants including copilot and azure), and Claude out-of-the-box due to its high code quality generation.
For all OpenAI-compatible providers, see <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more details.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">For most consistency between neovim session, it is recommended to set the environment variables in your shell file.
By default, <code>Avante</code> will prompt you at startup to input the API key for the provider you have selected.</p>
<p dir="auto">For Claude:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export ANTHROPIC_API_KEY=your-api-key"><pre><span>export</span> ANTHROPIC_API_KEY=your-api-key</pre></div>
<p dir="auto">For OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=your-api-key"><pre><span>export</span> OPENAI_API_KEY=your-api-key</pre></div>
<p dir="auto">For Azure OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export AZURE_OPENAI_API_KEY=your-api-key"><pre><span>export</span> AZURE_OPENAI_API_KEY=your-api-key</pre></div>
</div>
<ol dir="auto">
<li>Open a code file in Neovim.</li>
<li>Use the <code>:AvanteAsk</code> command to query the AI about the code.</li>
<li>Review the AI's suggestions.</li>
<li>Apply the recommended changes directly to your code with a simple command or key binding.</li>
</ol>
<p dir="auto"><strong>Note</strong>: The plugin is still under active development, and both its functionality and interface are subject to significant changes. Expect some rough edges and instability as the project evolves.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Bindings</h2><a id="user-content-key-bindings" aria-label="Permalink: Key Bindings" href="#key-bindings"></a></p>
<p dir="auto">The following key bindings are available for use with <code>avante.nvim</code>:</p>
<ul dir="auto">
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>a</kbd> ‚Äî show sidebar</li>
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>r</kbd> ‚Äî show sidebar</li>
<li><kbd>c</kbd><kbd>o</kbd> ‚Äî choose ours</li>
<li><kbd>c</kbd><kbd>t</kbd> ‚Äî choose theirs</li>
<li><kbd>c</kbd><kbd>b</kbd> ‚Äî choose both</li>
<li><kbd>c</kbd><kbd>0</kbd> ‚Äî choose none</li>
<li><kbd>]</kbd><kbd>x</kbd> ‚Äî move to previous conflict</li>
<li><kbd>[</kbd><kbd>x</kbd> ‚Äî move to next conflict</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlight Groups</h2><a id="user-content-highlight-groups" aria-label="Permalink: Highlight Groups" href="#highlight-groups"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Highlight Group</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>AvanteTitle</td>
<td>Title</td>
</tr>
<tr>
<td>AvanteReversedTitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteSubtitle</td>
<td>Selected code title</td>
</tr>
<tr>
<td>AvanteReversedSubtitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteThirdTitle</td>
<td>Prompt title</td>
</tr>
<tr>
<td>AvanteReversedThirdTitle</td>
<td>Used for rounded border</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODOs</h2><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul>
<li> Chat with current file</li>
<li> Apply diff patch</li>
<li> Chat with the selected block</li>
<li> Slash commands</li>
<li> Edit the selected block</li>
<li> Smart Tab (Cursor Flow)</li>
<li> Chat with project</li>
<li> Chat with selected files</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul dir="auto">
<li><strong>Enhanced AI Interactions</strong>: Improve the depth of AI analysis and recommendations for more complex coding scenarios.</li>
<li><strong>LSP + Tree-sitter + LLM Integration</strong>: Integrate with LSP and Tree-sitter and LLM to provide more accurate and powerful code suggestions and analysis.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions to avante.nvim are welcome! If you're interested in helping out, please feel free to submit pull requests or open issues. Before contributing, ensure that your code has been thoroughly tested.</p>
<p dir="auto">See <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more recipes and tricks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">avante.nvim is licensed under the Apache License. For more details, please refer to the <a href="https://github.com/yetone/avante.nvim/blob/main/LICENSE">LICENSE</a> file.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing stuff is never obvious yet often better (427 pts)]]></title>
            <link>https://www.gkogan.co/removing-stuff/</link>
            <guid>41353328</guid>
            <pubDate>Mon, 26 Aug 2024 01:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gkogan.co/removing-stuff/">https://www.gkogan.co/removing-stuff/</a>, See on <a href="https://news.ycombinator.com/item?id=41353328">Hacker News</a></p>
Couldn't get https://www.gkogan.co/removing-stuff/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Server Setup Basics for Self Hosting (161 pts)]]></title>
            <link>https://becomesovran.com/blog/server-setup-basics.html</link>
            <guid>41353284</guid>
            <pubDate>Mon, 26 Aug 2024 01:50:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://becomesovran.com/blog/server-setup-basics.html">https://becomesovran.com/blog/server-setup-basics.html</a>, See on <a href="https://news.ycombinator.com/item?id=41353284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>This is a post I've been meaning to do for a while. While it's simple to
                explain how to set up an app for self-hosting, it's pointless to host an app on a weak foundation.
                It's a massive pain in my ass to start every how to with a section on server setup, so I'm
                also making this post for myself as a reference on how I like to set up a server for apps I'm
                hosting. I'll start with basic stuff like proper login with SSH and non-root user set up and making
                users for each app. I'll also touch on NGINX setup, some quality of life tools that make server
                management easier, log management and basic network security.<br>‚Äç<br></p>
              <ul role="list">
                <li>
                  <a href="#ssh">SSH</a>
                </li>
                <li>
                  <a href="#users">Users</a>
                </li>
                <li>
                  <a href="#logs">Logs</a>
                </li>
                <li>
                  <a href="#backups">Backups</a>
                </li>
                <li>
                  <a href="#network">Basic Network Safety</a>
                </li>
                <li>
                  <a href="#nginx">NGINX</a>
                </li>
                <li>
                  <a href="#qol">Quality of Life Tools</a>
                </li>
                <li>
                  <a href="#dns">DNS</a>
                </li>
                <li>
                  <a href="#docker">Docker</a>
                </li>
              </ul>
              <h2 id="ssh"><p>SSH</p></h2>
              <p>First is login. You‚Äôll need a way to access your device securely. Don't even
                mess with username and password. You want to use SSH (Secure Shell) and make sure that SSH is the only
                way to log in. To do that, you‚Äôll need an SSH key and a new user account. On a newly provisioned VPS,
                you'll be logged in as root, and you want to protect the root account. First off on the VPS or
                remote machine make a new regular user with and add them to the ‚Äúsudo‚Äù group with:</p>
              <pre contenteditable="false"><code><span>sudo adduser newuser
</span>
sudo usermod -aG sudo newuser</code></pre>
              <p><br>Now on your local machine run:<br></p>
              <pre contenteditable="false"><code><span>ssh-keygen -t ed25519 -C </span><span>"your_email@example.com"</span></code></pre>
              <p><br>Follow the instructions, it should ask you where you want to save the file and
                if you want a password or not. Make sure you set a string one. To copy the public key over to your
                server run on your local machine:</p>
              <pre contenteditable="false"><code><span>ssh-copy-id -i ~/.ssh/id_ed25519.pub newuser@your_server_ip</span></code></pre>
              <p><br>Keep in mind newuser@your-server-ip is the username and the remote device you
                are trying to copy your public key into. When you get prompted for a password, it will be the password
                for the account on the remote device, NOT the password you just made for the SSH key. Once verified, it
                will copy over the public key, and you can now log in Via SSH. To turn off username and password login,
                type in:<br>‚Äç</p>
              <pre contenteditable="false"><code><span>sudo nano /etc/ssh/sshd_config</span></code></pre>
              <p><br>Find these values and set them as you see them here.<br>‚Äç</p>
              <pre contenteditable="false"><code><span>Port 2222     </span><span># Change default port (use a number between 1024 and 65535)</span><span>
</span><span>PermitRootLogin no                 </span><span># Disable root login</span><span>
</span><span>PasswordAuthentication no          </span><span># Disable password authentication</span><span>
</span><span>PubkeyAuthentication yes           </span><span># Enable public key authentication</span><span>
</span><span>AuthorizedKeysFile .ssh/authorized_keys </span><span># Specify authorized_keys file location</span><span>
</span><span>AllowUsers newuser                 </span><span># Only allow specific users to login</span></code></pre>
              <p><br>This disallows every login method besides SSH under the user you copied your
                public key to. Stops login as Root and only allows the user you specify to log in. Hit CTL+S to save and
                CTL+x to get out of the file editor. Restart SSH:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo service ssh restart</span></code></pre>
              <p><br>This might boot you out of the session. If it does, this is a good time to test
                the other login methods to see if they are declined before continuing. Also, it should go without
                saying, but you need to keep the private key safe and if you lose it you will not be able to get in
                remotely anymore.You can further lock down your login with: <br>‚Äç</p>
              <pre contenteditable="false"><code><span>Protocol 2                 </span><span># Use only SSH protocol version 2</span><span>
</span><span>MaxAuthTries 3             </span><span># Limit authentication attempts</span><span>
</span><span>ClientAliveInterval 300    </span><span># Client alive interval in seconds</span><span>
</span><span>ClientAliveCountMax 2      </span><span># Maximum client alive count</span></code></pre>
              <p><br>Now, let's dive into users a bit more and see how we can leverage them for
                a bit of organization and security.</p>
              <h2 id="users"><p>Users</p></h2>
              <div><p>Users are important when it comes to managing a Linux server. There
                is an idea in server management called the ‚ÄúPrinciple of The Least Privilege‚Äù this basically means that
                you want to give an app or process the minimum amount of privileges that it needs to do its job. Root
                has unlimited power, and no app really needs this. Making a user for apps that you're running
                accomplishes a few things. It can limit potential damage if an application you are running is
                compromised. It adds isolation when running more than one app, it helps with auditing so you know what
                app is using what system resources. </p><p>In short, users are a great way of helping organize your
                system and helps you troubleshoot if and when things go wrong. To add a new user, run:<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>sudo useradd -rms /usr/sbin/nologin -c </span><span>"a comment"</span><span> youruser</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like ‚ÄúRunning Nextcloud‚Äù or whatever. Clone app files into the /opt directory with:<br>‚Äç
              </p>
              <pre contenteditable="false"><code><span>sudo mkdir /opt/myapp</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like ‚ÄúRunning Nextcloud‚Äù or whatever. Clone app files into the /opt directory with:<br>‚Äç
              </p>
              <pre contenteditable="false"><code><span>sudo chown appuser:appuser /opt/myapp</span></code></pre>
              <p><br>Ok, with this your login is locked down, and you should have a decent
                idea about how to use users. Next is logs.<br>‚Äç</p>
              <h2 id="logs"><strong><p>Logs</p></strong></h2>
              <p><br>Logs are crucial to system administration. They keep track of system
                health, help troubleshoot issues and detect threats. So you want to set up proper log rotation so they
                do not take up too much space on your system, plus are easier to read and manage. To set up proper log
                rotation, you want to edit the logrotate.conf file located in /etc. Individual application
                configurations are typically stored in /etc/logrotate.d/, so an example configuration for NGINX would
                look like:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>/var/</span><span>log</span><span>/nginx/*.</span><span>log</span><span> {
</span>    weekly
    missingok
    rotate 52
    compress
    delaycompress
    notifempty
    create 0640 www-data adm
    sharedscripts
    postrotate
<span>        [ -f /var/run/nginx.pid ] &amp;&amp; </span><span>kill</span><span> -USR1 `cat /var/run/nginx.pid`
</span>    endscript
}
</code></pre>
              <p><br>This configuration rotates logs weekly, keeps 52 weeks of logs,
                compresses old logs, makes new logs with the right permissions and then signals NGINX to reopen log
                files after rotation. You can test it with:<br></p>
              <pre contenteditable="false"><code><span>sudo logrotate -d /etc/logrotate.conf</span></code></pre>
              <p><br>This will show what it will do without actually rotating logs. With
                this all set up, you can start to do more advanced stuff like triggering alerts based on log entries.
                Now this is good for a single server but if you manage more than one server it's a good idea to
                look into tools like Grafana Loki, Graylog and Fluentd. I won't go into detail here, but if
                you're looking to up your log game, these a decent place to start.<br>‚Äç<br></p>
              <h2 id="backups"><strong><p>Backups</p></strong></h2>
              <div><p>Backups, and more importantly, testing your backups, are extremely
                important in server management. Remember: a backup is not a backup unless you test it. Untested backups
                are essentially useless.</p><p>

                There are three main types of backups. Full, Differential, Incremental. Full backups are a complete copy
                of all data on a disk. Takes the most resources, but is the easiest to restore from. Differential
                backups back up all the changes since the last full backup, it's a middle ground strategy for backups on
                both space and restoration speed. An incremental backup backs up data that was changed since the last
                backup, this is the fastest backup option but can be the most complex to restore.</p><p>

                I think of it like this. I use incremental backups for things like photos and documents or project files
                and folders that get edited a lot. I'll use a full backup for backing up and entire server or disk.
                Differential backups Ill use for backing up full folders like /etc, /opt and log folders.</p><p>

                Now what about storage? If you follow the 3-2-1 rule, you will be golden. 3 copies of your data, 2
                storage types, and 1 offsite backup. I'd say if this seems like too much, the ‚Äúoffsite‚Äù storage is the
                most important and not one to skip. In case of a catastrophic meltdown, having a hard disk with your
                backups is invaluable. Offsite / offline backups can also save your ass from ransomware. So keep that in
                mind. There is a huge amount of backup software out there. <a href="https://github.com/awesome-foss/awesome-sysadmin#backups" target="_blank">This link</a> is for exploring some more
                professional backup tools. <a href="https://github.com/awesome-selfhosted/awesome-selfhosted?tab=readme-ov-file#file-transfer--synchronization" target="_blank">This link</a> has file sync, transfer and could storage solutions. I use a combo
                of sync-thing, Borg backup and good old-fashioned FTP.</p><p>

                Remember, that backup, logs and server monitoring is an evolving process based on your needs. The
                specific strategy you implement should be tailored to your needs and the criticality of your data.</p></div>


              <h2 id="network"><strong><p>Basic Network Safety</p></strong></h2>
              <p><br>The next step in securing a server is to lock down ports that need
                don‚Äôt need to be exposed to the internet and banning things that try to log in when they should not. UFW
                and Fail2Ban are two tools that are in widespread use for this. They are simple and easy to use, UFW
                lets you set traffic rules for ports and Fail2Ban will ban and IP address when it knocks on a port they
                should not be or if they fail to log in after some predefined rules. UFW or uncomplicated firewall often
                comes preinstalled on a lot of VPS services, same with Fail2Ban, but if you are on a new machine and
                you're unsure, run:<br>‚Äç</p>
              <pre contenteditable="false"><code><span>sudo apt install ufw
</span>
sudo apt install fail2ban</code></pre>
              <h3 id="ufw"><strong><br>UFW</strong></h3>
              <p><br>We will worry about Fail2Ban later, for now let's focus on UFW
                setup. First run some default policys with:<br></p>
              <pre contenteditable="false"><code><span>sudo ufw default deny incoming
</span> 
sudo ufw allow outgoing</code></pre>
              <p><br>This is considered best practice, as it follows the ‚Äúthe least
                privileges‚Äù idea I touched on earlier. It reduces attack surface on your machine and gives you precise
                control over what you do expose. In short, this configuration creates a balance between security and
                functionality. Your server can reach out to the internet as needed, but external entities can only
                connect to your server in ways you've explicitly allowed. Now let's allow some stuff
                in.<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo ufw allow ssh
</span>sudo ufw allow 80
sudo ufw allow 443</code></pre>
              <p><br>If you are going to be running a web server, you need port 80 and
                port 443 open. 80 is HTTP and 443 is HTTPS. By default, port 22 is SSH, if you changed this you need to
                specify the port instead of using the ‚Äúallow ssh‚Äù command. Here are some other useful commands:
                <br>‚Äç<br>
              </p>
              <pre contenteditable="false"><code><span>#List rules with numbers:</span><span>
</span>sudo ufw status numbered
<span></span><span>#Delete by number:</span><span>
</span>sudo ufw delete NUMBER
<span></span><span>#Delete by rule specification:</span><span>
</span>sudo ufw delete allow 80
<span></span><span>#You can allow connections from specific IP addresses:</span><span>
</span>sudo ufw allow from 192.168.1.100
<span></span><span>#You can also only allow an IP to connect to a specfic port with: </span><span>
</span>sudo ufw allow from 192.168.1.100 to any port 22
<span></span><span>#If you neeed to allow a range of ports: </span><span>
</span>sudo ufw allow 6000:6007/tcp
<span></span><span>#To further protect from brut force attacks you can rate limit specific ports with: </span><span>
</span><span>sudo ufw </span><span>limit</span><span> ssh
</span><span></span><span>#This would limit port 22 to 6 connections in 30 seconds from a single IP. To see the status of the firewall you can use: </span><span>
</span>
<span></span><span>#Adding this goves you more info</span><span>
</span>sudo ufw status verbose
<span></span><span>#and to reset incase you need to start over: </span><span>
</span>sudo ufw reset
<span></span><span>#and to enable and disable: </span><span>
</span><span>sudo ufw </span><span>enable</span><span> 
</span><span>sudo ufw </span><span>disable</span><span> 
</span>
<span></span><span>#finaly to enable logging and adjusting the log level: </span><span>
</span>sudo ufw logging on
<span>sudo ufw logging medium </span><span># levels are low, medium, high, full </span><span>
</span></code></pre>
              <p><br>On to Fail2Ban now. <br></p>
              <h3 id="ban"><strong><br>Fail2Ban</strong></h3>
              <p>‚Äç<br>The main configuration is located in /etc/fail2ban/jail.conf, but
                it's recommended to create a local configuration file:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
</span>
sudo nano /etc/fail2ban/jail.local</code></pre>
              <p>‚Äç<br>There are some basic settings in the [DEFAULT] section of the
                jail.local section those are:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>bantime = 10m
</span>findtime = 10m
maxretry = 5</code></pre>
              <p>‚Äç<br>Ban time is how long an IP is banned. Find time is the time frame in
                witch Fail2Ban looks for repeated failure, and max retry is the number of failures before an IP is
                banned. You can tune these as you see fit. There are also custom jails you can set, Fail2Ban also
                supports jails for commonly used services like SSH. There are even more steps you can take, but I think
                this covers the basics.<br></p>
              <h3 id="nginx"><strong><p>NGINX</p></strong></h3>
              <div><p>There are a small mess of web servers out there that you can use.
                Apache, Caddy, nginx, IIS to name a few. I use Nginx. It's what I know, and it works really damn
                well. Nginx (pronounced engine-x) is a web server, reverse proxy, and load balancer. As a web server, it
                excels at serving static content and can handle loads of concurrent connections with fairly low resource
                usage. As a reverse proxy, it can sit in front of your application servers and forward traffic to them
                while enchaining the apps' security. Its load balancing aspects can effectively balance traffic
                between servers, improving reliability and scalability. </p><p>When installed via apt, the default
                location for nginx is /etc/nginx/ the nginx.conf is mostly used for global server configuration and
                includes filed from the /etc/nginx/sites-enabled folder. This modular structure allows for easy
                management of multiple sites. Two folders to be aware of are the sites-enabled folder and the
                sites-available folders. You can think of the sites available as a staging place to test your site
                configurations, while the sites enabled is for live sites and apps. A common practice is to set up and
                test your configuration in the sites in the sites available, then when you're ready to go live and
                get an SSL cert, you link the file to the sites-enabled folder. You do that with:<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>ln -s /etc/nginx/sites-available/yoursitefile /etc/nginx/sites-enabled</span></code></pre>
              <p><br>Then reload nginx and double check nginx status with:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl reload nginx
</span>
sudo systemctl status nginx</code></pre>
              <div><p>Your site should be live now.</p><p>Below, I‚Äôll show you some
                boilerplate Nginx site configurations. Be sure to look into your app or sites needs as these are just
                starting points.&nbsp;For static sites, this is a decent starting point.&nbsp;</p></div>
              <p><br>Basic Static Website Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name example.com www.example.com;
    root /var/www/example.com/html;
    index index.html index.htm;
    location / {
<span>        try_files </span><span>$uri</span><span> </span><span>$uri</span><span>/ =404;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>Proxy Pass Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name app.example.com;
    location / {
        proxy_pass http://localhost:3000;
<span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/app.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/app.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/app.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/app.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>WebSocket Upgrade Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name ws.example.com;
    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
<span>        proxy_set_header Upgrade </span><span>$http_upgrade</span><span>;
</span><span>        proxy_set_header Connection </span><span>"upgrade"</span><span>;
</span><span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># WebSocket timeout settings</span><span>
</span>    proxy_read_timeout 300s;
    proxy_send_timeout 300s;
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/ws.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/ws.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/ws.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/ws.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <div><p>The basic configuration is for serving a simple static site. It
                specifies the domain name, listens on port 80 for both IPv4 and IPv6, sets the root directory for the
                site, configures error handling with try_files, adds some basic headers that protect from common web
                vulnerabilities, sets up logging for access and errors and includes a section for SSL that is commented
                out. Most of the SSL config will be handled by certbot, but there are a few lines in there that add some
                SSL security that can be uncommented after certbot is ran.<br>‚Äç<br>The proxy pass configuration is
                similar to the basic configuration, but instead of serving files directly, it proxies requests to a
                local application (in this case, running on port 3000).</p><p>The third configuration file is geared
                towards apps that need website connections, it's a lot like the proxy pass configuration with some
                changes to allow web sockets. &nbsp;</p><p>Ok, any bit about web servers is not really complete without
                talking about SSL. For casual use, certbot is a pleb's best friend. It's free, it is fast, and
                it fucking works. I use the python version of certbot. You can install that with: &nbsp;<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>sudo apt install certbot python3-certbot-nginx</span></code></pre>
              <p><br>Once it's installed you can simply run ‚Äúcertbot‚Äù in your
                terminal, this will detect the configs in your sites-enabled folder and ask what you want to do (renew,
                reissue, etc‚Ä¶). Follow the walk-through, certbot gives you It's pretty straight forward.<br>‚Äç<br>So
                nowadays certbot when getting a new cert will set up auto-renew for you, so it's a sit-and-forget
                kinda task. But to make sure it worked you can run:<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl status certbot.timer</span></code></pre>
              <p><br>if this is up and running, you should be good to go if you're
                using systemd.<br>‚Äç<br></p>
              <h2 id="qol"><strong><p>Quality Of Life Tools</p></strong></h2>
              <div><p>On the topic of tools that make managing your system easier, I'm
                going to present some tools I use on my servers that I think make management just a bit nicer. Not going
                to do a deep dive on any tool. All of these are optional and in no particular order. A lot of these I
                found on the site <a href="https://terminaltrove.com/" target="_blank">terminal trove</a>, a great site
                to browse if you're a terminal junkie like me.&nbsp;</p><p>First tool, <a href="https://terminaltrove.com/btop/" target="_blank">Btop</a> this is in my personal must haves
                list. Btop is a terminal monitor of resources. It shows you real time visuals of usage stats for your
                box‚Äôs CPU, RAM, disks, network and running possesses it's written in C++ and can be installed via
                most package managers.&nbsp;</p><p>For servers that have a lot of outside connections, i.e. a nostr relay, a
                tool like <a href="https://terminaltrove.com/neoss/" target="_blank">Neoss</a> is helpful. Neoss aims to
                replace usual ss command for basic usage. It provides a list of in use TCP and UDP sockets with their
                respective stats. Its main advantage over SS raw output is its clear and simple TUI (terminal user
                interface) that allows you to sort, refresh and navigate what is connected to your machine. It's
                installed Via NPM, meaning you need JavaScript installed.</p><p>
                <a href="https://github.com/allinurl/goaccess" target="_blank">GoAccess</a> is a terminal based log
                analyzer for web servers. It's great for a quick real time look at logs while in the terminal, but
                it can also generate real time HTML, JSON, and CSV reports. GoAccess can be installed via most package
                managers, works on all platforms.&nbsp;</p><p>Next on the list is <a href="https://terminaltrove.com/mc/" target="_blank">MC or ‚Äúmidnight commander‚Äù</a> Its a powerful text based file manager with a two panel
                display and lots of features for manipulating files and directories. It's also cross-platform and
                can be installed via most package managers.&nbsp;</p><p>In the same thread of server file management is <a href="https://dev.yorhel.nl/ncdu" target="_blank">NCDU</a>. This one is in my must-have list. It is a
                disk usage analyzer that is designed to find space hogs. It's fast and very simple to use. It can
                be installed on most systems and package managers. Windows will need Linux subsystems installed to use
                it.&nbsp;</p><p>Hopefully you find some use out of these. The last topic I'd like to touch on is DNS
                it's a bit topic, so I'm not going to do a massive deep dive, but if you're self-hosting
                it helps to have some of the basics of DNS down.&nbsp;ing doesn‚Äôt work.</p></div>
              <h2 id="dns"><strong><p>DNS</p></strong></h2>
              <div><p>DNS or The Domain Name System is a core part of how the internet as we
                know it works. Love it or hate it, it's what we have to work with If you want to be accessible to
                the wider internet. (I dislike what it currently is it, but I‚Äôm not opening that can of worms here.)
                Basically, Think of DNS like a phone book. It‚Äôs what allows you to type duckduckgo.com instead of
                ‚Äú52.250.42.157‚Äù every time you need to search the internet. It translates something easy for humans to
                remember into the information needed by computers to actually reach ‚Äúduckduckgo.com‚Äù</p><p>If
                you're hosting on a VPS, the only thing you really need to know is to know how to point an A record
                at your server's IP after you decide on a domain to use. Pretty much all VPS hosts can give you a
                static IP, so that's mostly a set and forget type deal. </p><p>Hosting from home presents some
                challenges. One prominent one is (and a valid question that I often hear) not having a static IP
                address. Nowadays with the number of devices online needing IP addresses we do a lot of juggling, and
                most IP addresses are assigned dynamically unless you pay for it from your ISP.&nbsp; But there is a
                solution. The answer to this is called Dynamic DNS or DDNS. This allows automatic updating of DNS
                servers every time an IP address changes. There are a mess of ways to set up dynamic DNS. You can host
                your own service or use a host. <a href="https://dynamic.domains/dynamic-dns/providers-list/default.aspx" target="_blank">Here is a
                  link</a> with some hosts and projects to check out.</p><p>In a nutshell, it works like so. You chose
                a provider or set up your own. You get a domain, install the client on your home router or server and
                the client periodically checks to see if the IP address has changed, if so it updates your DNS record
                for that domain.&nbsp;</p></div>
              <h2 id="docker"><strong><p>Docker</p></strong></h2>
              <p>I'm not gonna cover how to install docker here. It's best to
                follow <a href="https://docs.docker.com/engine/install/debian/" target="_blank">the official
                  installation</a> guide anyway. But I want to touch on a few things. First off, docker is useful as
                hell for testing new apps. But that's about as far as I take it. I personally do not like using
                docker all that much, and where possible run applications directly. Here are some pros and cons to keep
                in mind.<br></p>
              <h3><strong>Docker Pros</strong></h3>
              <p>Consistency is a big one it can make things more constant between
                development, testing, and deploying if your system can run docker you can run most docker apps. It can
                help with isolation, reducing conflicts between apps. In some cases it can help with efficiency as it
                takes less resources than traditional VM‚Äôs. It can help with scaling as it's pretty easy to spin up
                more containers and the microservice architecture can be useful because you can break down an
                application into smaller manageable services, allowing for independent scaling of said services. Lastly
                the community is large, so the documentation is good, and community support is always helpful, plus
                there is a wide range of ready to go docker images for deployment.<br></p>
              <h3><strong>Docker Cons</strong></h3>
              <div><p>I‚Äôll start with overhead. While it's better than a traditional VM,
                it uses more resources than running something directly on the host, and I/O operations can be slower.
                The fact that docker shares the system's kernel means that a compromised app could affect the
                system. Persistent data is doable but adds a layer of complexity that can cause data loss with new
                users, it also makes backups more complex. Networking can also be more complex with docker, making it
                not as straightforward. It's also good to note that if you use UFW or firewalld for a firewall,
                docker bypasses those rules. Docker is only compatible with iptables. Also, while a well managed docker
                container can help manage server resources, an improperly manged on can be detrimental to resources as
                well. Containers can get too large, effecting disk size, and misconfiguration can use too many of your
                servers resources. It also adds extra layers of complexity when monitoring and debugging applications,
                especially across multiple containers.</p><p>At the end of the day, it's your system. But I wanted
                to lay out some pros and cons when it comes to using Docker. Moving on.&nbsp; </p></div>
              <h2><strong><p>Wrap Up</p></strong></h2>
              <p>Well, that about does it for the basics of server setup and tools. There
                is a <a href="https://git.sovbit.dev/Enki/sovran-scripts" target="_blank"> a script that I wrote</a> that will do most of this for you. I wrote it to make my own server setup faster.
                You can get that here, it includes all of my must-haves and does some basic configuration. Tweak it to
                your own needs, and as always stay safe out there and ping me on nostr or simplex if you have questions
                or if I fucked something up in this post.<br></p>
              
              
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senior Intel CPU architects splinter to develop RISC-V processors (148 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</link>
            <guid>41353155</guid>
            <pubDate>Mon, 26 Aug 2024 01:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing">https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</a>, See on <a href="https://news.ycombinator.com/item?id=41353155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: AheadComputing)</span>
</figcaption>
</div>

<div id="article-body">
<p>While Intel is busy laying off thousands of employees some of its most experienced CPU architects, with a combined 80+ years at the firm, have left to form a RISC-V startup. <a data-analytics-id="inline-link" href="https://www.aheadcomputing.com/" data-url="https://www.aheadcomputing.com/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">AheadComputing</a> was co-founded by Debbie Marr, Mark Dechene, Jonathan Pearce, and Srikanth Srinivasan, with the goal of ‚Äúcreating compelling open specification core IP.‚Äù This proactive move by the quartet of architects and engineers must be congratulated, as they founded AheadComputing and went public on July 18 ‚Äì just a couple of weeks before Intel‚Äôs harsh <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend">workforce reduction plans</a> were announced.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg"></picture></p></div><figcaption itemprop="caption description"><span>Everyone deserves a better website </span><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>AheadComputing‚Äôs website is rather basic and threadbare at the time of writing, but it does contain a mission statement of sorts, some short bios detailing the ex-Intel co-founders, a single blog post (launch announcement), and a call for new recruits with experience in CPU design and verification roles.</p><p>As indicated above, the work of AheadComputing is going to begin with work on the RISC-V architecture. Specifically, the fledgling firm has set out with a plan ‚Äúdedicated to designing, verifying, and licensing compelling RISC-V core IP.‚Äù For any deeper dive into the goings-on behind the doors of the new Oregon-based firm, you will have to chat with them directly or wait for further blogging. However, they will also meet with people during Happy Hour on Tuesdays, between 4 - 5:30 pm, at Cornelius Pass Roadhouse, Hillsboro‚Ä¶</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>The most compelling feature of AheadComputing is, for now, its co-founders, so let‚Äôs take a closer look at their resumes.</p><p>Co-founder, CEO, &amp; President, Dr. Debbie Marr was an Intel Fellow and Chief Architect of the Advanced Architecture Development Group (AADG) at Intel and spent 33 years at the chipmaker on products spanning the i386 all up to the present day. A highlight of her career seems to have been bringing Intel Hyperthreading Technology from concept to finished product. Marr also authored over 40 patents in CPU, AI accelerators, and FPGA fields.</p><p>Co-Founder, Mark Dechene was an Intel Principal Engineer and CPU Architect in the Advanced Architecture Development Group. During his 16 years at Intel Dechene worked on architecture development for Intel CPU products including Haswell, Broadwell, Goldmont, Goldmont Plus, Tremont, and Skymont. Dechene has authored over 15 patents, focused on microprocessor performance.</p><p>Co-Founder, Jonathan Pearce was an Intel Principal Engineer, CPU Architect, and a key technologist &amp; strategist in the Advanced Architecture Development Group until recently. Pearce worked for 22 years at Intel. During his career, Pearce has worked in both pre-silicon and post-silicon roles on multiple generations of Intel Core SOCs. He also authored 19 patents in the CPU, AI, and GPU fields.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-k6SrjEwfa6jCtt4TU4Epnh"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>Co-Founder, Dr. Srikanth Srinivasan has over 20 years of technical leadership experience in product R&amp;D. At Intel he taped out some well-known chip designs like Nehalem, Haswell, and Broadwell. However, most recently, Srinivasan led the frontend and backend CPU teams at the Advanced Architecture Development Group at Intel. The highlight of his career / achievements so far is probably the authoring of more than a dozen highly cited papers and over 50 patents.</p><p>With its pedigree, surely we will hear about AheadComputing again, in the not-too-distant future. On the flip side, PC enthusiasts may rightly worry about the future of Intel when it has just instigated the most severe layoff plans in its 56-year history, some of its ambitious construction plans have come into question, and severe brain drain, as evidenced by this new RISC-V startup, could slow any chances of revival.</p>
</div>
<div id="slice-container-authorBio-k6SrjEwfa6jCtt4TU4Epnh"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>



<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We found North Korean engineers in our application pile (154 pts)]]></title>
            <link>https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</link>
            <guid>41353079</guid>
            <pubDate>Mon, 26 Aug 2024 01:18:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile">https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</a>, See on <a href="https://news.ycombinator.com/item?id=41353079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Cinder is part of a growing list of US-based tech companies that encounter engineering applicants who are actually suspected North Korean nationals. These North Koreans almost certainly work on behalf of the North Korean government to <a href="https://apnews.com/article/north-korea-weapons-program-it-workers-f3df7c120522b0581db5c0b9682ebc9b">funnel money back</a> to their government while working remotely via third countries like China. Since at least early 2023, many have applied to US-based remote-first tech companies like Cinder. If you‚Äôve been running into this issue, here are some tips for how you can handle this at your own company.</p><p>It‚Äôs important to note that funding the North Korean government could constitute a crime given <a href="https://ofac.treasury.gov/sanctions-programs-and-country-information/north-korea-sanctions">the sanctions</a> the regime is under. And nobody wants that kind of paperwork headache!</p><p>Cinder is unique in our ability to interface with this issue given our co-founders‚Äô backgrounds as ex-CIA operatives, as well as an expert on North Korea. Our prior experience spurred our interest in building internet safety software to begin with, and inspires a particular vigilance to maintain it to the best of our abilities.</p><p>I first learned of North Korea‚Äôs practice of sending workers abroad in 2014: I joined the board of a leadership development program for North Korean escapees and learned of North Korea‚Äôs government and its use of technology from those who experienced it firsthand. Later, I volunteered for a nonprofit developing information access technology for clandestine use inside closed countries like North Korea. I have spoken with North Korean escapees who have recent knowledge of the latest North Korean tech worker trends. But I never expected I would one day experience them as applicants attempting to join my company.&nbsp;</p><h2>North Koreans are applying to US tech companies?</h2><p>The North Korean government has a <a href="https://www.bloomberg.com/news/features/2018-02-07/inside-kim-jong-un-s-hacker-army">long history</a> of sending workers abroad to earn money for the regime. The workers are sent to countries like China where they must earn a salary quota, most of which will be taken by the government for its own needs. These workers are under close supervision by North Korean officials while abroad. They are often required to leave family members behind as collateral to prevent them from defecting while outside their home country.&nbsp;</p><p>North Koreans have been working undercover as software freelancers for part time contract jobs for years. And recently, they have <a href="https://blog.knowbe4.com/how-a-north-korean-fake-it-worker-tried-to-infiltrate-us">started</a> to apply to American tech companies that offer remote, full time work. This may be exacerbated by the rise of remote work after the COVID pandemic and the fact that working at US tech companies can be so lucrative. Hyun-Seung Lee, a former North Korean businessman and former chair of the Kim Il Sung Socialist Youth League branch in Dalian, China, told us that the earnings quota for a North Korean IT worker based in China is typically $6,000 per month. This quota is more than covered by many US tech salaries.</p><h2>The application process</h2><p>In our experience, North Koreans applying to US tech companies under false pretenses will often use a standard process: they will create profiles on multiple professional networking and job posting sites using a name that is not Korean and sometimes with an AI-edited profile image.&nbsp;</p><p>Once they go through the interview process and have received a job offer, they may ask their new company-provided laptop be <a href="https://www.bleepingcomputer.com/news/security/us-dismantles-laptop-farm-used-by-undercover-north-korean-it-workers/">sent to a US-based partner</a>. According to a Department of Justice <a href="https://www.justice.gov/usao-dc/media/1352191/dl">indictment</a>, the US-based partner may install remote desktop software so that the North Korean engineer can appear to be working from a US location, with a laptop physically located in the US, while remotely controlling the laptop from abroad.</p><p>By demonstrating sufficient technical capability and minimal English language skills, North Korean applicants can meet minimum thresholds for junior software engineer roles. Fast-growing start-ups eager to ship more products might overlook gaps in resume, unreliable or missing education records, or poor command of written or spoken English for an engineer with sufficient skill who is ready to start working soon.&nbsp;</p><p>We suspect if the worker is employed even for just a few months before being terminated, this can still be quite profitable for the regime.</p><h2>Cinder‚Äôs approach</h2><p>We have a unique perspective on this problem for a few reasons: our company is in the internet safety industry, two of our co-founders came from the CIA, and I have twelve years of experience working on cybersecurity and human rights issues related to North Korea. So when North Korean IT workers applied to Cinder, they had a different experience than they might have expected.</p><blockquote><em>Pyongyang has a long history of exploiting its people to further the regime‚Äôs ambitions and this activity is no exception. Two of Cinder‚Äôs founders bring years of CIA experience, so we‚Äôre no strangers to creating and running virtual operations, nor detecting and countering those of hostile nation states.<br>‚Äç<br>- Phil Brennan, Cinder co-founder and 10-year CIA veteran</em></blockquote><h3>What tipped us off</h3><p>Fifteen months prior to any <a href="https://www.bleepingcomputer.com/news/security/five-arizona-ukraine-charged-for-cyber-schemes-infiltrating-over-300-companies-to-benefit-north-koreas-weapons-program/">FBI indictments</a>, our COO first noticed a few unusual trends in our applicant pool. Upon further inspection he discovered these candidates either didn't seem to exist on the internet, or were mapped to people who weren't them, who did have an internet presence. Over time, we realized many applicants that had the following characteristics:</p><ol role="list"><li>No online presence outside of professional networking websites; and professional networking profiles were recently created, typically with profile pictures that obscured the individual‚Äôs image (in ski goggles, sunglasses), were too zoomed out to be helpful, were AI-generated, or were simply blank.&nbsp;</li><li>Completely fabricated job history including office locations that don‚Äôt actually exist.&nbsp;</li><li>Unable to find these applicants online outside of the standard professional networking sites (e.g. no presence on GitHub, social media etc).</li><li>Inability to answer basic questions about the cities in which they allegedly worked (‚ÄòWhat was your Metro stop in Paris?‚Äô) or technology on which they worked (‚ÄòWhat org were you in at Uber?‚Äô).</li><li>Background noise during their interview that indicated other people speaking in an interview-like setting, implying a crowded room of people on separate professional video calls.</li><li>Highly scripted answers with explicit preference for remote work, and little ability to deviate from the script.</li><li>A mismatch between the name displayed on the resume or networking site, and the candidate‚Äôs command of English (e.g. Chris Smith with a B.A. from a large US research university who can barely speak interview-level English is surprising).&nbsp;</li></ol><p>We also noticed vague cover letter language:</p><blockquote><em>Hi, team!<br>I hope you're fine and safe.&nbsp;<br>I am really excited about this potential opportunity with the ambitious project.<br>As a Senior Frontend Developer with 8+ years of experience, I have great experience in working with React.js/Redux, RTK, React Query, Vue, Next.js, Vercel, TypeScript, GraphQL, etc.</em> <em>Please have a look at my previous works.</em></blockquote><p>Another example: </p><blockquote><em>Hi,</em> <br>‚Äç<em>I love what you are doing in your company. With my eight-plus years of development, I'd love to be one of you.</em> <em>As an FE-heavy developer, I have a track record of building successful products. And I am familiar with startup environment.</em> <em>I'd love to use my strong debugging and problem-solving abilities to be a powerful force in the workplace. I can wear multiple hats and adapt to a fast-paced team.</em> <em>I look forward to meeting you to learn more about this role and share my relevant skills.</em> <em>Best,</em></blockquote><p>Taken together, to me these details suggested fake identities. And while I knew North Korea had a history of sending workers abroad to freelance, I didn‚Äôt expect that they would apply to full time roles at US-based companies.</p><h3>What we did</h3><p>First, because we come from the Trust and Safety industry, I was able to reach out to our partners at various security companies and confirm these patterns were consistent with North Koreans attempting to pass themselves off as Americans. I also learned a lot from published investigations like the one <a href="https://www.nisos.com/research/dprk-it-worker-scam/">Nisos published last year</a>.</p><p>With more knowledge, we were able to go digging. And we had a lot of material: For applicants from some job sites, roughly 80% of inbound applicants with experience matching our stack were suspected North Koreans.&nbsp;</p><p>We started filtering out suspected North Korean applicants by doing quick internet searches and closer examinations of job history, profile imagery, and a social media screening. However, our process wasn‚Äôt perfect, and we still ended up on occasional Zoom calls screening applicants who we would quickly discover, mid-call, had fabricated their career history and only recently created their online presence.</p><p>When we first started receiving North Korean applications, some of our interviewers noted applicants‚Äô strong resistance to travel in their post-interview write ups:</p><blockquote><em>One clarifying question that I neglected to ask about is that on his Linkedin profile he says he is&nbsp; looking for ‚Äú100% Remote job only without travel‚Äù. I did not notice the ‚Äúwithout travel‚Äù part until after the interview. We should make sure he would be willing to travel sometimes for team offsites as this is an important part of Cinder‚Äôs culture.</em></blockquote><p>I started informing candidates that Cinder‚Äôs customer base includes companies investigating nation-state espionage and insider threat issues. I added that this is a natural fit for us, because our co-founders came from the US intelligence community including the CIA.&nbsp;</p><p>Upon hearing this, one suspected North Korean applicant immediately dropped from the Zoom call and never contacted us again.</p><h2>What Cinder is doing now</h2><p>We continue to receive dozens of suspected North Korean applicants to Cinder. We take steps to share relevant information with security teams at networking and job listing sites that we work with. If your company is also affected by this growing threat, I encourage you to get in touch with me at <a href="mailto:declan@cndr.io">declan@cndr.io</a> and I‚Äôd be happy to share more tips and prevention strategies.&nbsp;</p><p>‚Äç</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber loses New Zealand appeal, court rules drivers are employees not contractors (111 pts)]]></title>
            <link>https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</link>
            <guid>41352997</guid>
            <pubDate>Mon, 26 Aug 2024 01:05:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/">https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</a>, See on <a href="https://news.ycombinator.com/item?id=41352997">Hacker News</a></p>
Couldn't get https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Australian employees now have the right to ignore work emails, calls after hours (454 pts)]]></title>
            <link>https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</link>
            <guid>41352681</guid>
            <pubDate>Mon, 26 Aug 2024 00:08:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/">https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</a>, See on <a href="https://news.ycombinator.com/item?id=41352681">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Matching dinosaur footprints found on opposite sides of the Atlantic Ocean (101 pts)]]></title>
            <link>https://phys.org/news/2024-08-dinosaur-footprints-sides-atlantic-ocean.html</link>
            <guid>41352656</guid>
            <pubDate>Mon, 26 Aug 2024 00:02:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-08-dinosaur-footprints-sides-atlantic-ocean.html">https://phys.org/news/2024-08-dinosaur-footprints-sides-atlantic-ocean.html</a>, See on <a href="https://news.ycombinator.com/item?id=41352656">Hacker News</a></p>
Couldn't get https://phys.org/news/2024-08-dinosaur-footprints-sides-atlantic-ocean.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>