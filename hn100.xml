<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 26 Oct 2024 16:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[New Windows Driver Signature bypass allows kernel rootkit installs (121 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/new-windows-driver-signature-bypass-allows-kernel-rootkit-installs/</link>
            <guid>41954825</guid>
            <pubDate>Sat, 26 Oct 2024 14:12:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/new-windows-driver-signature-bypass-allows-kernel-rootkit-installs/">https://www.bleepingcomputer.com/news/security/new-windows-driver-signature-bypass-allows-kernel-rootkit-installs/</a>, See on <a href="https://news.ycombinator.com/item?id=41954825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="New Windows Driver Signature bypass allows kernel rootkit installs" height="900" src="https://www.bleepstatic.com/content/hl-images/2024/10/02/Windows_11_headpic.jpg" width="1600"></p>

<p>Attackers can downgrade Windows kernel components to bypass security features such as Driver Signature Enforcement and deploy rootkits on fully patched systems.</p>

<p>This is possible by taking control of the Windows Update process to introduce outdated, vulnerable software components on an up-to-date machine without the operating system changing the fully patched status.</p>

<h3>Downgrading Windows</h3>

<p>SafeBreach security researcher Alon Leviev reported the update takeover issue but&nbsp;Microsoft dismissed it saying that it did not cross a defined security boundary, although was possible by gaining kernel code execution as an administrator.</p>

<p>Leviev&nbsp;at the <a href="https://www.blackhat.com/us-24/briefings/schedule/#windows-downdate-downgrade-attacks-using-windows-updates-38963" target="_blank" rel="nofollow noopener">BlackHat</a> and <a href="https://defcon.org/html/defcon-32/dc-32-speakers.html#54522" target="_blank" rel="nofollow noopener">DEFCON</a> security conferences this year demonstrated that the attack was feasible&nbsp;but the problem remains unfixed, leaving open the door for downgrade/version-rollback attacks.</p>

<p>The researcher published a tool called <a href="https://github.com/SafeBreach-Labs/WindowsDowndate" target="_blank" rel="nofollow noopener">Windows Downdate</a>, which allows creating custom downgrades and expose a seemingly fully update&nbsp;target system to already fixed vulnerabilities via outdated components, such as DLLs, drivers, and the NT kernel.</p>

<p>"I was able to make a fully patched Windows machine susceptible to past vulnerabilities, turning fixed vulnerabilities unfixed and making the term “fully patched” meaningless on any Windows machine in the world" -&nbsp;<a href="https://www.safebreach.com/blog/update-on-windows-downdate-downgrade-attacks/" target="_blank" rel="nofollow noopener">Alon Leviev</a></p>

<p>Despite kernel security improving significantly over the years, Leviev managed to bypass the&nbsp;Driver Signature Enforcement (DSE) feature, showing how&nbsp;an attacker could load unsigned kernel drivers to deploy&nbsp;rootkit malware that disables security controls and hides activity that could lead to detecting the compromise.</p>

<p>“In recent years, significant enhancements have been implemented to strengthen the security of the kernel, even under the assumption that it could be compromised with Administrator privileges,” Leviev says.&nbsp;</p>

<p>While the new protections make it more difficult to compromise the kernel, "the ability to downgrade components that reside in the kernel makes things much simpler for attackers," the researcher explains.</p>

<p>Leviev&nbsp;named his exploitation method&nbsp;<em>"ItsNotASecurityBoundary" DSE bypass</em>&nbsp;as it is part of the&nbsp;<strong>false file immutablity flaws</strong>, a new vulnerability class in Windows&nbsp;described in&nbsp;<a href="http://www.elastic.co/security-labs/false-file-immutability" target="_blank" rel="nofollow noopener">research from Gabriel Landau</a> of Elastic as a way to&nbsp;achieve arbitrary code execution with kernel privileges.</p>

<p>Following Landau's report, Microsoft patched the ItsNotASecurityBoundary admin-to-kernel privilege escalation. However, this does protect against a downgrade attack.</p>

<h3>Targeting the kernel</h3>

<p>In new research published today, Leviev shows how an attacker could exploit the Windows Update process to bypass DSE protections by downgrading a patched component, even on fully updated Windows 11 systems.</p>

<p>The attack is possible by replacing ‘ci.dll,’ a file responsible for enforcing DSE, with an unpatched version that ignores driver signatures, which essentially sidesteps Windows’ protective checks.</p>

<p>This replacement is triggered by the Windows Update, exploiting a double-read condition where the vulnerable ci.dll copy is loaded into memory right after Windows starts checking the latest copy of ci.dll.</p>

<div>
<figure><img alt="Loading the old DLL while Windows verifies the latest version" height="129" src="https://www.bleepstatic.com/images/news/u/1220909/2024/Campaigns/29/dll.png" width="796"><figcaption><strong>Loading the old DLL while Windows verifies the latest version</strong><br><em>Source: SafeBreach</em></figcaption></figure></div>

<p>This “race window” allows the vulnerable ci.dll to load while Windows thinks it has verified the file, hence allowing unsigned drivers to be loaded onto the kernel.</p>

<p>In the video below, the researcher demonstrates how he reverted the DSE patch via a downgrade attack and then exploited the component on a fully patched Windows 11 23H2 machine.</p>

<p><iframe allowfullscreen="" frameborder="0" height="360" mozallowfullscreen="" src="https://player.vimeo.com/video/1023363712" webkitallowfullscreen="" width="640"></iframe></p>

<p>Leviev also describes methods to disable or bypass Microsoft's Virtualization-based Security (VBS) that creates an isolated environment for Windows to protect essential resources and securtiy assets like the secure kernel code integrity mechanism (<em>skci.dll</em>)&nbsp;and authenticated user credentials.</p>

<p>VBS typically relies on protections like UEFI locks and registry configurations to prevent unauthorized changes, but it can be disabled if not configured with max security (“Mandatory” flag) by performing targeted registry key modification.</p>

<p>When partially enabled, key VBS files such as ‘SecureKernel.exe’ can be replaced with corrupt&nbsp;versions that disrupt VBS’s operation and open the way for “ItsNotASecurityBoundary” bypass and to replace 'ci.dll'.</p>

<div>
<figure><img alt="Ignoring the VBS configuration during boot" height="131" src="https://www.bleepstatic.com/images/news/u/1220909/2024/Campaigns/29/vbs.png" width="774"><figcaption><strong>Ignoring the VBS configuration during boot</strong><br><em>Source: SafeBreach</em></figcaption></figure></div>

<p>Leviev’s work shows that downgrade attacks are still possible via several pathways, even if they sometimes carry strong privilege prerequisites.</p>

<p>The researcher highlights the need for endpoint security tools to closely monitor downgrade procedures, even those that do not cross critical security boundaries.</p>

	   
           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky Is Not Decentralized (191 pts)]]></title>
            <link>https://beige.party/@possibledog/113367977656537478</link>
            <guid>41952994</guid>
            <pubDate>Sat, 26 Oct 2024 06:36:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://beige.party/@possibledog/113367977656537478">https://beige.party/@possibledog/113367977656537478</a>, See on <a href="https://news.ycombinator.com/item?id=41952994">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Adventures in algorithmic trading on the Runescape Grand Exchange (134 pts)]]></title>
            <link>https://tristanrhodes.com/blog/Adventures-in-Algorithmic-Trading-on-the-Runescape-Grand-Exchange</link>
            <guid>41952006</guid>
            <pubDate>Sat, 26 Oct 2024 02:23:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tristanrhodes.com/blog/Adventures-in-Algorithmic-Trading-on-the-Runescape-Grand-Exchange">https://tristanrhodes.com/blog/Adventures-in-Algorithmic-Trading-on-the-Runescape-Grand-Exchange</a>, See on <a href="https://news.ycombinator.com/item?id=41952006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
    <h2>Adventures in Algorithmic Trading on the Runescape Grand Exchange</h2>
    <h3>Overview</h3>
    <p>
      Runescape has been a game near and dear to my heart since I was a child. Though I do not actively 
      play anymore, it still functions as an interesting programming project substrate. 
      Most recently, I created a bot that automatically executes trades on the Grand Exchange in order to 
      conduct market making via common machine learning techniques. This blog post will explain the individual 
      components of the bot, the various trading algorithms used, and the results of an experiment comparing 
      the various trading algorithms' performance.
    </p>
    <p>
      The Old School Runescape Grand Exchange is a market where all players can place buy or sell offers 
      for almost any item in the game. It is a chaotic system like most markets, but it is also modelable 
      on small enough time scales or microstructures. The only constraint placed on offers is a four hour 
      buy limit that is different for each item. For example, coal ore has a buy limit of 13,000. This means that a player 
      can only buy up to 13,000 coal every four hours. Another interesting feature of the Grand Exchange is 
      the 1% tax applied to all executed sell offers. This tax is applied to all items with an individual 
      trading price greater than 100 gold. It is capped at 5 million gold per offer and is applied on a 
      per-item basis rounded down to the nearest integer. The proceeds of the tax are used by the game 
      developer to control inflation.  As an example, if I were to sell 10,000 coal ore at today's price 
      of 142 gold per item, then my executed trade would be subject to a tax of: <code>math.floor(0.01 * 142) * 10000 = 10,000 gold</code>
    </p>
    <h3>Components</h3>
    <p>
      The bot is composed of three separate applications: a JavaScript API to interact with the OSRS Wiki's 
      real-time item price stream, a Java client to control character actions, and a Python API to return the 
      ranking of a set of possible offers in terms of their forecasted profitability. The OSRS Wiki project 
      maintains <a target="_blank" href="https://oldschool.runescape.wiki/w/RuneScape:Real-time_Prices">a useful API</a> that, 
      every 5 minutes, writes data about every single item trading on the Grand Exchange. It records fields such 
      as the average item price spread over a configurable past period, the volume traded over a configurable past 
      period, and the buy limit of each item.
    </p>
    <p>
      The data pipeline I use to train the ML models is composed of two cronjobs that interact with the 
      OSRS Wiki API: one that polls it every 5 minutes, and another that polls it every hour. Each of them record 
      the price spreads and volumes of every item traded on the Grand Exchange over that time period and write the 
      resulting data to a database. Furthermore, the bot records data about each offer that it successfully executes. 
      The fields it records are: gold/second generated, absolute profit generated, timestamp of the buy offer 
      initialization, and the ID of the item traded. These two tables are joined on timestamp such that each row 
      contains aggregate trade data of the item across the entire Grand Exchange for the period leading up to 
      a successful trade as well as the profitability of the individual executed trade. The target of the model's 
      loss function is gold/second generated. Lastly, to prevent temporal leakage, the training set consists of 
      labeled trades from 63 days prior to 14 days prior, while the validation set includes the most recent 14 days.
    </p>
    <h3>Baseline Method</h3>
    <p>
      In any modeling scenario, it is always good practice to establish a naive baseline method that can be 
      used to determine if non-trivial methods are actually improving performance. The baseline method I came 
      up with is as follows:
    </p>
    <p>
      Given an item, its price spread over the last 5 mins, and its trade volume over the last hour, compute 
      the following variables:
    </p>
    <p>
      <b>ROI:</b>
      <code>(sell_total - {1% tax} - buy_total) / buy_total</code>
    </p>
    <p>
      <b>Volume ratio:</b>
      <code>(1h_volume_traded_high_price / 1h_volume_traded_low_price)</code>
    </p>
    <p>
      <b>Average gold/second of item trades over last two weeks</b>
    </p>
    <p>
      Then do the following:
      </p><ol>
        <li>Compute ROI Z score for each item.</li>
        <li>Compute volume ratio Z score for each item.</li>
        <li>Filter out any items with a historically negative average gold/second metric.</li>
        <li>Sort each item by <code>(roi_zscore + volume_ratio_zscore)</code> descending.</li>
      </ol>
    
    <h3>Machine Learning Methods</h3>
    <p>
      After generating results for the baseline method, I ran a one-week experiment comparing the baseline 
      to <a target="_blank" href="https://github.com/rhodesrt/ML_exercises/blob/main/random_forest/random_forest.ipynb">random forest</a> 
      and <a target="_blank" href="https://github.com/rhodesrt/ML_exercises/blob/main/random_forest/neural_net.ipynb">neural network</a> 
      regression models. In order to avoid a sample ratio mismatch, I 
      programmed the game client to choose randomly between each model type's output when ranking potential offers. 
      The results are displayed in the following table sorted by mean profit/hour in 
      descending order:
    </p>
    <table>
      <thead>
          <tr>
              <th>Model Type</th>
              <th>n</th>
              <th>L2 loss</th>
              <th>Mean profit/hr</th>
              <th>95% CI profit/hr</th>
          </tr>
      </thead>
      <tbody>
          <tr>
              <td>random forest</td>
              <td>257</td>
              <td>53</td>
              <td>150,892</td>
              <td>129,140 - 172,643</td>
          </tr>
          <tr>
              <td>neural network</td>
              <td>191</td>
              <td>57</td>
              <td>123,923</td>
              <td>103,279 - 144,566</td>
          </tr>
          <tr>
              <td>baseline</td>
              <td>216</td>
              <td>N/A</td>
              <td>87,353</td>
              <td>79,493 - 95,212</td>
          </tr>
      </tbody>
  </table>
  <h3>Conclusion</h3>
  <p>
    Machine learning methods outperformed baseline by a significant amount. Among ML model architectures, random 
    forest performed the best, edging out the neural network slightly. This aligns with the validation loss of each 
    model during training. I am somewhat surprised that the random forest generated the highest profit/hour, as 
    random forest predictions are typically constrained to the range of target values in the training data. With 
    that said, the training data does have relatively low variance as the market making trades these models are 
    predicting tend to be high frequency and low ROI.
  </p>
  <p>
    Please reach out to me if you are interested in obtaining the training data used for this project. 
    The code used to train the models can be found linked above as well as on my 
    <a target="_blank" href="https://github.com/rhodesrt/ML_exercises/tree/main/random_forest">Github</a>.
  </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Russia amplified hurricane disinformation to drive Americans apart (101 pts)]]></title>
            <link>https://abc7chicago.com/post/russia-amplified-hurricane-disinformation-drive-americans-apart-researchers-find/15463309/</link>
            <guid>41951773</guid>
            <pubDate>Sat, 26 Oct 2024 01:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abc7chicago.com/post/russia-amplified-hurricane-disinformation-drive-americans-apart-researchers-find/15463309/">https://abc7chicago.com/post/russia-amplified-hurricane-disinformation-drive-americans-apart-researchers-find/15463309/</a>, See on <a href="https://news.ycombinator.com/item?id=41951773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="prism-article-body"><p>Russia has helped amplify and spread false and misleading internet claims about recent <a data-testid="prism-linkbase" href="https://abc7chicago.com/tag/hurricane/">hurricanes</a> in the United States and the federal government's response, part of a wider effort by the Kremlin to manipulate America's political discourse before the presidential election, new research shows.</p><p>The content, spread by Russian state media and networks of social media accounts and websites, criticizes the federal response to Hurricanes Helene and Milton, exploiting legitimate concerns about the recovery effort in an attempt to paint American leaders as incompetent and corrupt, according to research from the Institute for Strategic Dialogue. The London-based organization tracks disinformation and online extremism.</p><p>In some cases, the claims about the storms include fake images created using artificial intelligence, such as a photo depicting scenes of devastating flooding at Disney World that never happened, researchers say.</p><p><strong>RELATED: </strong><a data-testid="prism-linkbase" href="https://abc7chicago.com/post/wnc-hurricane-helene-misinformation-fema-threats-hurting-recovery-gov-roy-cooper/15430603/" target="_blank"> Misinformation is 'really hurting' those in western North Carolina, Gov. Cooper says</a></p><p>The approach is consistent with the Kremlin's long-standing practice of identifying legitimate debates and contentious issues in the U.S. and then exploiting them. Previous disinformation campaigns have harnessed debates about immigration, racism, crime and the economy in an effort to portray the U.S. as corrupt, violent and unjust.</p><p>U.S. intelligence officials and private tech companies say Russian activity has increased sharply before the Nov. 5 election as Moscow tries to capitalize on an opportunity to undermine its chief global adversary.</p><p>By seizing on real concerns about disaster recovery, Russia's disinformation agencies can worm their way into U.S. discourse, using hot-button issues to undermine Americans' trust in their government and each other.</p><p>"These are not situations that foreign actors are creating," said Melanie Smith, director of research at ISD. "They're simply pouring gasoline on fires that already exist."</p><p>The content identified by ISD included English-language posts obviously meant for Americans, as well as Russian-language propaganda intended for domestic audiences. Much of the disinformation took aim at the Federal Emergency Management Agency and the Democratic administration of President Joe Biden and Vice President Kamala Harris. She is her party's nominee in the White House race against former President Donald Trump.</p><p>Russia's invasion of Ukraine remains the Kremlin's prime motivation for spreading lies about the hurricane response. If Russia can persuade enough Americans to oppose U.S. support for Ukraine, that could ease the way for a Moscow victory, officials and analysts have said.</p><p>U.S. intelligence officials have said Russia's disinformation seems designed to support Trump, who has praised Russian President Vladimir Putin and disparaged the NATO alliance and Ukraine's leaders. Posts linked to Russia routinely denigrate Harris, saying she is ignoring the pleas of storm victims. By contrast, a recent post from Russian state media company RT called Trump "a mystical figure of historic proportions."</p><p>Intelligence officials confirmed Tuesday that Russia created a manipulated video to smear Harris' running mate, Minnesota Gov. Tim Walz.</p><p>Russia has rejected claims that it trying to meddle in the U.S. election. The Russian Embassy hasn't responded to messages this week seeking comment about recent allegations by researchers and intelligence officials.</p><p><strong>ALSO SEE: </strong><a data-testid="prism-linkbase" href="https://abc7chicago.com/post/fema-has-faced-criticism-praise-during-hurricane-helene-heres-what-does-doesnt-do/15400270/" target="_blank"> FEMA has faced criticism and praise during Helene. Here's what it does - and doesn't do</a></p><p>Researchers at ISD found that Russian disinformation agents exploited weak content moderation on U.S.-owned social media platforms such as X to spread their content far and wide. Before it was purchased and renamed by Elon Musk, the platform once known as Twitter required labels on content from authoritarian state media. Musk rescinded that rule and gutted the platform's content moderation efforts, leading to a surge in foreign propaganda, hate speech and extremist recruitment.</p><p>Often the false or misleading claims come from fake accounts or websites that mimic Americans or legitimate news outlets, making it difficult to determine their true origin. Unsuspecting Americans then repost and spread the content.</p><p>In July, American intelligence officials warned that "unwitting Americans" were helping do Russia's work for it.</p><p>Vast armies of fake or automated accounts help spread the material further.</p><p>Researchers at the Israeli tech firm Cyabra analyzed popular posts on X that criticized <a data-testid="prism-linkbase" href="https://abc7chicago.com/tag/fema/">FEMA</a> for its storm response. A significant number could not be verified as belonging to a real person; one-quarter of all the responses to popular posts were deemed fake. The posts were seen by users over half a billion times.</p><p>In response, a spokesperson for X pointed to the platform's system that allows users to add context to posts with false claims. The company did not respond to questions about its labeling policy.</p><p>"The false claims, ranging from FEMA diverting funds to aid migrants to conspiracy theories about weather manipulation, undermine public trust in government as we near election day, which could seriously impact voter confidence," Cyabra researchers said in a report.</p><p>Politicians also have helped spread Russia's talking points.</p><p>Rep. Paul Gosar, R-Ariz., gave an interview to the Russian state media outlet Sputnik News for a piece that played up criticism of the hurricane response. He told Sputnik that the federal response was "nonexistent," a claim easily debunked by photos and videos of FEMA recovery workers as well as the firsthand accounts of local leaders and residents in hard-hit regions.</p><p>Gosar repeated another misleading claim that "billions of FEMA disaster funds" had been given instead to immigrants without legal status. In truth, money that funds U.S. border control and immigration programs comes from a different source than disaster funds.</p><p>Gosar's office did not respond to messages seeking comment Wednesday.</p></div><p>Copyright © 2024 by The Associated Press. All Rights Reserved.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OSI readies controversial open-source AI definition (103 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/995159/a37fb9817a00ebcb/</link>
            <guid>41951421</guid>
            <pubDate>Sat, 26 Oct 2024 00:23:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/995159/a37fb9817a00ebcb/">https://lwn.net/SubscriberLink/995159/a37fb9817a00ebcb/</a>, See on <a href="https://news.ycombinator.com/item?id=41951421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>The <a href="https://opensource.org/">Open Source Initiative</a>
(OSI) has been working on defining <a href="https://opensource.org/ai">Open Source AI</a>—that is what
constitutes an AI system that can be used, studied, modified, and
shared for any purpose—for almost two
years. Its <a href="https://opensource.org/about/board-of-directors">board</a> will
be voting on the <a href="https://opensource.org/ai/drafts/the-open-source-ai-definition-1-0-rc2">Open Source AI Definition</a> (OSAID) on Sunday,
October&nbsp;27, with the 1.0 version slated to be published on
October&nbsp;28. It is never possible to please <em>everyone</em> in
such an endeavor, and it would be folly to make that a goal. However,
a number of prominent figures in the open-source community have voiced
concerns that OSI is setting the bar too low with the OSAID—which
will undo decades of community work to cajole vendors into adhering to
or respecting the original <a href="https://opensource.org/osd">Open Source
Definition</a> (OSD).</p>

<h4>Defining Open&nbsp;Source&nbsp;AI</h4>

<p>OSI executive director Stefano Maffulli <a href="https://opensource.org/blog/now-is-the-time-to-define-open-source-ai">announced</a>
the organization's intent to provide a definition for open-source AI
in June&nbsp;2023. He took exception to announcements of 
"<q>large language models, foundational models, tooling, services all
claiming to be 'open' or 'Open Source'</q>", while adding restrictions
which run afoul of the OSD. A <a href="https://spectrum.ieee.org/open-source-llm-not-open">survey</a>
of large-language model (LLM) systems in 2023 found that ostensibly
open-source LLMs did not live up to the name.</p>

<p>The problem is not quite as simple as saying "use an OSD-compliant
license" for LLMs, because there are many more components to
consider. The original OSD is understood to apply to the
source code of a program in "<q>the preferred form in which a
programmer would modify the program</q>". A program is not considered
open source if a developer cannot study, use, modify, and share a
program, and a license is not OSD‑compliant if it does not
preserve those freedoms. A program can include non-free data and still
be open source. For example, the game <a href="https://github.com/id-Software/Quake-III-Arena">Quake&nbsp;III&nbsp;Arena</a>
(Q3A) is available under the GPLv2. That distribution, however, does
not include the <a href="https://quakewiki.org/wiki/.pak">pak</a>
files that contain the maps, textures, and other content required to
actually play the commercial game. Despite that, others can still use
the Q3A code to create their own games, such as <a href="https://tremulous.net/">Tremulous</a>.</p>

<!-- middle-ad -->

<p>When discussing an "AI system", however, things are much more
complicated. There is more than just the code that is used to run the
models to do work of some kind, and the data is not something that
can be wholly separate from the system in the way that it can be with a
game. When looking at, say, LLMs, there is the model architecture, the
code used to train models, model parameters, the techniques and methodologies used for
training, the procedures for labeling training data, the supporting
libraries, and (of course) the data used to train the models.</p>

<p>OSI has been working on its definition since last year. It held a kickoff meeting on June&nbsp;21, 2023 at the
Mozilla headquarters in San&nbsp;Francisco. It <a href="https://opensource.org/deepdive/#:~:text=How%20to%20participate">invited
participation</a> afterward via a regular series of in-person
and <a href="https://opensource.org/ai/townhalls">online sessions</a>,
and with a <a href="https://discuss.opensource.org/">forum for online
discussions</a>. LWN <a href="https://lwn.net/Articles/961868/#:~:text=Stefano%20Maffulli,AI%20system">covered</a>
one of the sessions, held at <a href="https://archive.fosdem.org/2024/">FOSDEM 2024</a>, in
February.</p>

<p>The current draft of the OSAID takes its definition of an AI system from the <a href="https://www.oecd.org/">Organisation for Economic Co-operation
and Development</a> (OECD) <a href="https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449">Recommendation
of the Council on Artificial Intelligence</a>:</p>

<blockquote>
A machine-based system that, for explicit or implicit objectives,
infers, from the input it receives, how to generate outputs such as
predictions, content, recommendations, or decisions that can influence
physical or virtual environments.
</blockquote>

<p>This includes source code for training and running the system,
model parameters "<q>such as weights or other configuration
settings</q>", as well as "<q>sufficiently detailed information about
the data used to train the system so that a skilled person can build a
substantially equivalent system</q>".</p>

<h4>Preferred form to make modifications</h4>

<p>Those elements must all be available under OSI-approved licenses,
according to the proposed definition, which seems perfectly in line
with what we've come to expect when something is called "open
source". There is an exception, though, for things like the data
information and model parameters which must be available under
"<q>OSI-approved terms</q>". The definition of OSI-approved terms is
not supplied yet.</p>

<p>There is no requirement to make the <em>training data</em> available. To be
compliant with the current draft of the OSAID, an AI system need only
provide "<q>detailed information</q>" about the data but not the data
itself.</p>

<p>The OSI <a href="https://opensource.org/blog/community-input-drives-the-new-draft-of-the-open-source-ai-definition">published</a>
version 0.0.9 on August 22. It acknowledged then that "<q>training data is
one of the most hotly debated parts of the definition</q>". However,
the OSI was choosing not to require training data:</p>

<blockquote>
<p>After long deliberation and co-design sessions we have concluded
that defining training data as a benefit, not a requirement, is the
best way to go.</p>

<p>Training data is valuable to study AI systems: to understand the
biases that have been learned, which can impact system behavior. But
training data is not part of the preferred form for making
modifications to an existing AI system. The insights and
correlations in that data have already been learned.</p>
</blockquote>

<p>As it stands, some feel that the OSAID falls short of allowing the
four freedoms that it is supposed to ensure. For example, julia
ferraioli <a href="https://www.juliaferraioli.com/blog/2024/on-open-source-ai/">wrote</a>
that without including data, the only things that the OSAID guarantees
are the ability to use and distribute an AI system. "<q>They would be
able to build on top of it, through methods such as transfer learning
and fine-tuning, but that's it.</q>"

</p><p>Tom Callaway has <a href="https://www.linkedin.com/pulse/why-open-data-necessary-source-ai-tom-callaway-stzcc/">written</a>
at length on LinkedIn about why open data should be a requirement. He 
acknowledges that there are good reasons that distributors of an AI
system may not want, or be able, to distribute training data. For
example, the data itself may have a high monetary value on its own,
and a vendor may be unwilling or unable to share it.
Acme Corp might license a data set and
have permission to create an AI system using it, but not the
ability to distribute the data itself. The data might have legal
issues, ranging from confidentiality (e.g., medical data sets) to a
desire to avoid lawsuits from using copyrighted data.</p>

<p>All of those are understandable reasons for not distributing
data with an AI system, he said, but they don't argue for crafting a definition
that allows companies to call their system open:</p>

<blockquote>
<p>If we let the Open Source AI definition contain a loophole that
makes data optional, we devalue the meaning of "open source" in all
other contexts. While there are lots of companies who would like to
see open source mean less, I think it's critical that we not
compromise here, even if it means there are less Open Source AI
systems at first.</p>
</blockquote>

<p>Objections to lack of training data are more than an attachment to
the original meaning of open source. Giacomo Tesio <a href="https://discuss.opensource.org/t/list-of-unaddressed-issues-of-osaid-rc2/650">posted</a>
a list of issues he considered unaddressed in the RC2 version of
the OSAID, including a claim that there is inherent insecurity due to the
ability to <a href="https://arxiv.org/abs/2204.06974">plant
undetectable backdoors</a> in machine-learning models.</p>

<h4>Others weigh in</h4>

<p>The Free Software Foundation (FSF) <a href="https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications">announced</a>
that it was working on "<q>a statement of criteria for free machine
learning applications</q>" to call something a free (or libre)
machine-learning application. The FSF says that it is close to a
definition, and is working on the exact text. However, it adds that
"<q>we believe that we cannot say a ML application 'is free' unless
all its training data and the related scripts for processing it
respect all users, following the four freedoms</q>".</p>

<p>However, the FSF makes a distinction between non-free and
unethical in this case:</p>

<blockquote>
It may be that some nonfree ML have valid moral reasons for not
releasing training data, such as personal medical data. In that case,
we would describe the application as a whole as nonfree. But using it
could be ethically excusable if it helps you do a specialized job that
is vital for society, such as diagnosing disease or injury.
</blockquote>

<p>The <a href="https://sfconservancy.org/">Software&nbsp;Freedom&nbsp;Conservancy</a>
has <a href="https://sfconservancy.org/news/2024/oct/25/aspirational-on-llm-generative-ai-programming/">announced</a>
an "<q>aspirational statement</q>" about LLM-backed generative AI for
programming called "Machine-Learning-Assisted Programming that
Respects User Freedom". Unlike the OSAID, this target focuses solely
on computer-assisted programming, and was developed <a href="https://sfconservancy.org/blog/2022/feb/03/github-copilot-copyleft-gpl/">in
response</a> to <a href="https://en.wikipedia.org/wiki/GitHub_Copilot">GitHub
Copilot</a>. The announcement did not directly name the OSI or the OSAID effort, but
said "<q>we have avoided any process that effectively auto-endorses
the problematic practices of companies whose proprietary products are
already widely deployed</q>". It describes an ideal LLM system built
only with FOSS, with all components available, and only for the creation of FOSS.</p>

<h4>Response to criticisms</h4>

<p>I emailed Maffulli about some of the criticisms of the current
OSAID draft, and asked why OSI appears to be "lowering the bar" when
the OSI has never budged on source availability and use
restrictions. He replied:</p>

<blockquote>
<p>I'll be blunt: you mention "source redistribution" in your question
and that's what leads people like [Callaway] into a mental trap
[...]</p>

<p>There are some groups believing that more components are required to
guarantee more transparency. Other groups instead believe that model
parameters and architecture are enough to modify AI. The Open Source
AI Definition, developed publicly with a wide variety of stakeholders
worldwide, with deep expertise on building AI (see the <a href="https://opensource.org/ai/endorsements">list of endorsers</a>),
found that while those approaches are legitimate, neither is
optimal. The OSAID grants users the rights (with licenses) and the
tools (with the list of required components) to meaningfully
collaborate and innovate on (and fork, if required) AI systems.  We
have not compromised on our principles: we learned many new things
from actual AI experts along the way.</p>
</blockquote>

<p>Maffulli objected to the idea that the OSAID was weaker or making
concessions, and said that the preferred form for modifying ML systems
was what is in the OSAID: "<q>it's not me nor OSI board saying that,
it's in the list of endorsers and in [Carnegie Mellon University's] <a href="https://www.cmu.edu/engin/programs/about-ofai/cmu-osaid-statement.html">comment</a></q>". He
added that OSI had synthesized input from "<q>AI builders, users, and
deployers, content creators, unions, ethicists, lawyers, software
developers from all over the world</q>" to arrive at the definition. A
"<q>simple translation</q>" of the OSD, he said, would not work.</p>

<p>Stephen O'Grady, founder of the RedMonk analyst firm, also makes
the case that the OSD does not easily translate to AI projects. But he
does not believe that the term open source "<q>can or should be
extended into the AI world</q>" as he <a href="https://redmonk.com/sogrady/2024/10/22/from-open-source-to-ai/">wrote</a>
in a blog post on October&nbsp;22:</p>

<blockquote>
<p>At its heart, the current deliberation around an open source
definition for AI is an attempt to drag a term defined over two
decades ago to describe a narrowly defined asset into the present to
instead cover a brand new, far more complicated future set of
artifacts.</p>
</blockquote>

<p>O'Grady makes the case that the OSI has set out on a pragmatic path
to define open-source AI, which requires nuance. Open source has
succeeded, in part, because the OSD removes nuance. Does a license
comply with the OSD or doesn't it? It's pretty easy to determine. Less
so with the OSAID. The pragmatic path, he said:

</p><blockquote>
Involves substantial compromise and, more problematically,
requires explanation to be understood. And as the old political adage
advises: "If you're explaining, you're losing."
</blockquote>

<p>It would have been better, he said, if the OSI had not tried to
"<q>bend and reshape a decades old definition</q>" and instead had
tried to craft something from a clean slate. That seems unlikely now,
he said, after two years of trying to "<q>thread the needle between
idealism and capitalism to arrive at an ideologically sound and yet
commercially acceptable</q>" definition.</p>

<p>Indeed, it seems likely that the OSI board will move forward with
the current draft of the OSAID or something close to it. The
impact that will have is much less certain.</p>

<br clear="all">
               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How can this 6 axis robot have a static accuracy of 0.05 mm? (2021) [video] (203 pts)]]></title>
            <link>https://www.youtube.com/watch?v=SioCwvR_PYY</link>
            <guid>41951408</guid>
            <pubDate>Sat, 26 Oct 2024 00:20:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=SioCwvR_PYY">https://www.youtube.com/watch?v=SioCwvR_PYY</a>, See on <a href="https://news.ycombinator.com/item?id=41951408">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Before you buy a domain name, first check to see if it's haunted (592 pts)]]></title>
            <link>https://www.bryanbraun.com/2024/10/25/before-you-buy-a-domain-name-first-check-to-see-if-its-haunted/</link>
            <guid>41951131</guid>
            <pubDate>Fri, 25 Oct 2024 23:43:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bryanbraun.com/2024/10/25/before-you-buy-a-domain-name-first-check-to-see-if-its-haunted/">https://www.bryanbraun.com/2024/10/25/before-you-buy-a-domain-name-first-check-to-see-if-its-haunted/</a>, See on <a href="https://news.ycombinator.com/item?id=41951131">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <p>In mid-2022 I bought a new domain name.</p>

<p>The name was <code>musicbox.fun</code>. I got it for a side-project, an <a href="https://musicbox.fun/">interactive online music box</a> that I had built and hosted at <code>musicboxfun.com</code>. The new name was shorter and more quirky. I felt lucky to have grabbed it.</p>

<p>Unfortunately, <code>musicbox.fun</code> had a history. Before I bought it, the domain was used to host pirated music.</p>

<figure>
  <img src="https://www.bryanbraun.com/assets/images/old-music-box-fun.png" alt="A screenshot of musicbox.fun as it existed in 2018, before I owned it">
  <figcaption><code>musicbox.fun</code>, as it existed in 2018 (before I owned it)</figcaption>
</figure>

<p>From June 2018 to February 2021, the site racked up thousands of copyright violation complaints. Over 20,000 of its urls were delisted by Google (and other search engines) before the site went offline in 2022.</p>

<p>I had no idea, of course. It wasn’t until I had redirected all of my <code>musicboxfun.com</code> traffic to <code>musicbox.fun</code> that I noticed that something wasn’t right: my web traffic from organic search dropped to zero.</p>

<p>I assumed it was temporary so I double-checked my process and waited for awhile, but it never really recovered. It wasn’t until a year later that I discovered the copyright violations and learned that the domain name was compromised.</p>

<p>Apparently, this is a thing that happens to domain names, but as far as I know, there’s not really a name for it. When I described it to my wife, she said <em>“Oh, so it’s haunted.”</em></p>

<p>“Haunted” is the perfect word for this:</p>
<ul>
  <li>Something terrible happened at the domain name in the past.</li>
  <li>On the surface, nothing seems wrong with the domain name.</li>
  <li>Then there are signs that something isn’t right.</li>
  <li>Obligatory jump-scare when you discover what happened.</li>
  <li>Internal debate: do you abandon it or try to fix it?</li>
  <li>There’s a ton of superstition around how to fix it.</li>
  <li>Superficial fixes don’t seem to work.</li>
</ul>

<figure>
  <img src="https://www.bryanbraun.com/assets/images/ghostbusters.jpg" alt="A scene from the movie Ghostbusters.">
  <figcaption>When there's something strange with your domain name, who you gonna call?</figcaption>
</figure>

<p>So to summarize, I’m saying a domain name is “haunted” when something in its past gives it a poor reputation among search engines, affecting its ability to rank in search results, even after it changes ownership.</p>

<p>The inner-workings of search engines are notoriously opaque*, making it difficult to 1) know if you’re being affected and 2) know how to fix it. The following are my suggestions, based on my experience with <code>musicbox.fun</code>.</p>

<h2 id="how-to-check-if-a-domain-name-is-haunted">How to check if a domain name is haunted</h2>

<p>Before you buy a domain name, there’s a few ways to check if it’s haunted:</p>

<h3 id="1-check-the-wayback-machine-at-archiveorg">1. Check the Wayback Machine at archive.org</h3>

<p>If you go to <a href="https://web.archive.org/">web.archive.org</a> and put in your domain name, it will pull up archived web pages of whatever lived at the domain in the past. Here’s a couple things to look out for:</p>

<ol>
  <li>Does anything in the past look illegal or sketchy (piracy, gambling, porn, etc)?</li>
  <li>Is the history suspiciously empty?
    <ul>
      <li>If so, then possibly the past content was <a href="https://help.archive.org/help/how-do-i-request-to-remove-something-from-archive-org-2/">removed by request</a> (I suspect this was the case for <code>musicbox.fun</code>)</li>
    </ul>
  </li>
</ol>

<h3 id="2-search-dmca-complaints">2. Search DMCA complaints</h3>

<p>DMCA stands for “Digital Millenium Copyright Act,” which is a US law that enables people to report copyright infractions to search engine companies (among other things). These reports are public, and you can look them up in a few ways:</p>

<ol>
  <li>Search <a href="https://transparencyreport.google.com/">Google Transparency Report</a> for your domain, to find delist requests (you can <a href="https://transparencyreport.google.com/copyright/domains/musicbox.fun">see the report for musicbox.fun here</a>).</li>
  <li>Search <a href="https://lumendatabase.org/">lumendatabase.org</a> for your domain, to find copyright complaints (for an example, see <a href="https://lumendatabase.org/notices/search?term=%22https%3A%2F%2Fmusicbox.fun%22&amp;term-exact-search=true&amp;sort_by=">these results for musicbox.fun</a>).</li>
</ol>

<p>Finding ANY copyright complaints for your domain is cause for concern, especially if there are a lot of them and they were filed recently.</p>

<h3 id="3-search-historical-seo-data">3. Search historical SEO data</h3>

<p>If you’re considering buying an important domain name, you may also want to search historical SEO data. Advanced SEO tools like <a href="https://ahrefs.com/">ahrefs.com</a> can give you detailed information about backlinks, ranking history, and estimates for traffic and domain authority. Often, you’ll need to pay to get full access to this kind of data.</p>

<p>Interpreting this data is beyond the scope of this post, but a bit of research can help uncover problems here.</p>

<h2 id="ok-its-haunted-now-what-do-i-do">Ok, it’s haunted. Now what do I do?</h2>

<h3 id="1-talk-to-the-search-engines">1. Talk to the search engines</h3>

<p>Many search engines have tools for domain owners, like <a href="https://search.google.com/search-console">Google Search Console</a> and <a href="https://www.bing.com/webmasters">Bing Webmaster Tools</a>. Definitely set up a profile and get your domain name added. It can help surface past issues and it gives you a way to report when issues have been resolved. For more details about specific actions you can take here, see <a href="https://webmasters.stackexchange.com/a/145283/36576">my stackexchange post</a> on the topic.</p>

<p>If your domain has DMCA complaints, you may be tempted to file a <a href="https://support.google.com/legal/troubleshooter/1114905?rd=2&amp;sjid=13861243148551035047-NC#ts=9814647%2C1115655%2C13630207%2C12999302%2C9814950%2C1115791">DMCA counter-notice</a>. Don’t do it. Counter-notices are for <em>errorneous</em> copyright complaints, not complaints that were once valid but no longer relevant. Per Google’s counter-notice submission form:</p>

<blockquote>
  <p>Please note: If the content on the page was infringing at the time the original removal request arrived, your counter notice is not legally valid. Do not submit a counter notice if there was illegal content, even if it’s now been removed.</p>
</blockquote>

<p>As far as I can tell, there’s not really anything you can do to make past, valid DCMA complaints go away.</p>

<h3 id="2-double-down-on-best-practices">2. Double-down on best practices</h3>

<p>My SEO strategy has always been to do great work and make it easy for Google to see it. It usually works pretty well (at least for my non-haunted domains). For haunted domains, you have a bad reputation to overturn, which seems to require extra vigilence. SEO basics, like high-quality, structured, accessible, content on a fast-loading site, are table stakes.</p>

<p>If you’ve done any SEO work, you know that search engines treat links to your site as a massive signal of relevance and trust. I suspect that fresh incoming links are especially important for overturning a bad reputation, though I haven’t confirmed this personally. If you think <code>musicbox.fun</code> is a useful project and you wield <a href="https://www.bryanbraun.com/2020/10/03/the-power-of-a-link/">the power of a link</a>, consider posting a link to it, and maybe we’ll find out together.</p>

<h3 id="3-wait-for-a-while">3. Wait for a while?</h3>

<p>In my research I found <a href="https://webmasters.stackexchange.com/a/99701/36576">a detailed stackexchange post about trust scores and how they are affected by DMCA complaints</a>. This post suggested that recovery could take some time:</p>

<blockquote>
  <p>It takes years to rebuild trust scores and for some sites, this may never happen.
…the reality is that a domain can ruin its value beyond redemption.</p>
</blockquote>

<p>This post isn’t a primary source, but I also came across an Q&amp;A with a Google Search employee who fielded a similar question about DMCA violations. Their response said something similar, basically, that it can take time for the reputation effects to wear off (I’m struggling to find the video now, but I’ll link it when I do).</p>

<p>All of this is fairly disappointing. In a perfect world, when your legitimately good content isn’t being surfaced by Google, it’s a failure on <strong>their</strong> part, and <strong>their</strong> problem to solve, not yours. In practice, it is <strong>your</strong> problem and you have to do a bunch of work to help them see that their current assessment of your domain name is no longer accurate.</p>

<p><img src="https://www.bryanbraun.com/assets/images/this-house-is-clean.jpg" alt="Image of the medium from the movie 'Poltergeist' saying &quot;this house is clean&quot;"></p>

<hr>

<p>Ideally, search engine algorithms would give new domain owners a fresh start. Yes, it would prevent “haunted domain issues” but it would also reduce <a href="https://macwright.com/2024/10/16/domain-second-thoughts">squatting on trusted domains</a> (another issue I’ve been burned by). Unfortunately, we don’t live in that world*, so we only have a few options:</p>

<ol>
  <li>Avoid buying haunted domain names</li>
  <li>Abandon domain names, once you discover that they are haunted</li>
  <li>Put in a bunch of time and effort to restore a haunted domain name’s low trust score</li>
</ol>

<p>For <code>musicbox.fun</code>, I want to at least <em>try</em> #3. I’ve taken some of the steps above and it feels like I’m starting to see progress. It’s slow, but I’m not in a big hurry to restore traffic. The site is just a hobby and it was always a niche project for a niche audience.</p>

<p>Either way, I hope to post an update in a while to let you know if it improves over time.</p>

<hr>

<p><small>* It’s easy to attribute issues like these to anti-competitive behavior or some other malicious cause, but I don’t blame Google here. If their reputation algorithm was more transparent (or forgiving), it could be more easily exploited by bad actors. Obscurity prevents exploitation but also adds to the mystery and superstition that plagues the SEO industry. It’s tempting to get sucked into the mystery, trying to figure out the algorithm despite its constant changes and intentional obscurity, but that’s not how I want to live my life.</small></p>

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wikipedia article blocked worldwide by Delhi high court (603 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Asian_News_International_vs._Wikimedia_Foundation</link>
            <guid>41950392</guid>
            <pubDate>Fri, 25 Oct 2024 22:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Asian_News_International_vs._Wikimedia_Foundation">https://en.wikipedia.org/wiki/Asian_News_International_vs._Wikimedia_Foundation</a>, See on <a href="https://news.ycombinator.com/item?id=41950392">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation"><tbody><tr><td><p><span typeof="mw:File"><span><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Wikimedia-logo_black.svg/40px-Wikimedia-logo_black.svg.png" decoding="async" width="40" height="40" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Wikimedia-logo_black.svg/60px-Wikimedia-logo_black.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Wikimedia-logo_black.svg/80px-Wikimedia-logo_black.svg.png 2x" data-file-width="512" data-file-height="512"></span></span></p></td><td><div><p><a href="https://wikimediafoundation.org/" title="foundationsite:">The Wikimedia Foundation</a> has suspended access to this page due to <a href="https://foundation.wikimedia.org/wiki/File:October_16_2024_ANI_v_Wikimedia_order.pdf" title="foundation:File:October 16 2024 ANI v Wikimedia order.pdf">an order by the Delhi High Court</a>, without prejudice to the Foundation's rights. We are pursuing all available legal options.  
</p><p>We remain committed to access to knowledge as a human right. We are working to ensure that everyone can access and share free knowledge on Wikipedia.  
</p><p>
This regards active litigation, and this page will be updated when we are able to share more information.</p></div></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jeff Bezos killed Washington Post endorsement of Kamala Harris (706 pts)]]></title>
            <link>https://www.cnbc.com/2024/10/25/jeff-bezos-killed-washington-post-endorsement-of-kamala-harris-.html</link>
            <guid>41949297</guid>
            <pubDate>Fri, 25 Oct 2024 20:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/10/25/jeff-bezos-killed-washington-post-endorsement-of-kamala-harris-.html">https://www.cnbc.com/2024/10/25/jeff-bezos-killed-washington-post-endorsement-of-kamala-harris-.html</a>, See on <a href="https://news.ycombinator.com/item?id=41949297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107424611" data-test="InlineImage"><p>The Washington Post Building at One Franklin Square Building in Washington, D.C., June 5, 2024.</p><p>Andrew Harnik | Getty Images</p></div><div><p><a href="https://www.washingtonpost.com/opinions/2024/10/25/washington-post-endorsement/" target="_blank">The Washington Post</a> said Friday that it will not endorse a candidate in the presidential election this year, breaking decades of tradition, and sparking immediate criticism of the decision.</p><p>The newspaper also published an <a href="https://www.washingtonpost.com/style/media/2024/10/25/washington-post-endorsement-president/" target="_blank">article</a> by two staff reporters saying that editorial page staffers had drafted an endorsement of Democratic nominee <a href="https://www.cnbc.com/kamala-harris/">Kamala Harris</a> over GOP nominee<a href="https://www.cnbc.com/donald-trump/"> Donald Trump</a> in the election.</p><p>"The decision not to publish was made by The Post's owner — <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-5"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> founder Jeff Bezos," the article said, citing two sources briefed on the events.</p><p>Trump, while president, had been critical of the billionaire Bezos and the Post, which he purchased in 2013.</p><p>The <a href="https://www.washingtonpost.com/opinions/hillary-clinton-for-president/2016/10/12/665f9698-8caf-11e6-bf8a-3d26847eeed4_story.html" target="_blank">newspaper</a> in 2016 and again in 2020 endorsed Trump's <a href="https://www.washingtonpost.com/opinions/2020/09/28/editorial-board-endorsement-joe-biden/" target="_blank">election</a> opponents, <a href="https://www.cnbc.com/hillary-clinton/">Hillary Clinton</a> and President <a href="https://www.cnbc.com/joe-biden/">Joe Biden</a>, in editorials that condemned the Republican in blunt terms.</p><p>In a 2019 lawsuit, Amazon claimed it had lost a $10 billion <a href="https://fingfx.thomsonreuters.com/gfx/reuterscom/1/161/161/Amazon.pdf" target="_blank">cloud computing contract</a> with the Pentagon to Microsoft because Trump had used "improper pressure ... to harm his perceived political enemy" Bezos.</p><p>The Post since 1976 had regularly endorsed candidates for president, except for the 1988 race. All those endorsements had been for Democrats.</p><p>In a statement to CNBC, when asked about Bezos' purported role in killing the endorsement, Post chief communications officer Kathy Baird said, "This was a Washington Post decision to not endorse, and I would refer you to the publisher's statement in full."</p><p>The Post on Friday evening published a third article, signed by <a href="https://www.washingtonpost.com/opinions/2024/10/25/post-columnist-no-endorsement-2024-trump-harris/" target="_blank">opinion columnists</a> for the newspaper, who said, "The Washington Post's decision not to make an endorsement in the presidential campaign is a terrible mistake."</p><p>"It represents an abandonment of the fundamental editorial convictions of the newspaper that we love, and for which we have worked a combined 218 years," the column said. "This is a moment for the institution to be making clear its commitment to democratic values, the rule of law and international alliances, and the threat that <a href="https://www.washingtonpost.com/donald-trump/?itid=lk_inline_manual_1" target="_blank">Donald Trump</a> poses to them — the precise points The Post made in endorsing Trump's opponents in 2016 and 2020."</p><p>CNBC has requested comment from Amazon, where Bezos remains the largest shareholder.</p></div><div id="ArticleBody-InlineImage-106944637" data-test="InlineImage"><p>Amazon founder Jeff Bezos arrives for his meeting with British Prime Minister Boris Johnson at the UK diplomatic residence in New York City, Sept. 20, 2021.</p><p>Michael M. Santiago | Getty Images News | Getty Images</p></div><div><p>Post publisher and chief executive Will Lewis, in an online explanation of the decision, wrote, "The Washington Post will not be making an endorsement of a presidential candidate in this election. Nor in any future presidential election."</p><p>"We are returning to our roots of not endorsing presidential candidates," Lewis wrote.</p><p>"We recognize that this will be read in a range of ways, including as a tacit endorsement of one candidate, or as a condemnation of another, or as an abdication of responsibility," he wrote.</p><p>"That is inevitable. We don't see it that way. We see it as consistent with the values The Post has always stood for and what we hope for in a leader: character and courage in service to the American ethic, veneration for the rule of law, and respect for human freedom in all its aspects."</p><p>Seven of the 13 paragraphs of Lewis' article either quoted at length or referred to Post Editorial Board statements in 1960 and 1972 explaining the paper's rationale for not endorsing presidential candidates in those years, which included its identity as "an independent newspaper."</p><p>Lewis noted that the paper had endorsed Jimmy Carter in 1976 "for understandable reasons at the times" — which he did not identify.</p><p>"But we had it right before that, and this is what we are going back to," Lewis wrote.</p><p>"Our job as the newspaper of the capital city of the most important country in the world is to be independent," he wrote. "And that is what we are and will be."</p><p>Post editor-at-large Robert Kagan, a member of the paper's opinions section, resigned following the decision, multiple news outlets reported.</p><p>More than 10,000 comments were posted on Lewis' article, many of them blasting the Post for its decision and saying they were canceling their subscriptions.</p><p>"The most consequential election in our country, a choice between Fascism and Democracy, and you sit out? Cowards. Unethical, fearful cowards," wrote one reader. "Oh, and by the way, I'm canceling my subscription, because you are putting business ahead of ethics and morals."</p><p>The announcement came days after Mariel Garza, the head of <a href="https://www.nytimes.com/2024/10/23/business/media/la-times-editor-quits-patrick-soon-shiong-endorsement.html" target="_blank">The Los Angeles Times</a>' editorial board, resigned in protest after that paper's owner, Patrick Soon-Shiong, decided against running a presidential endorsement.</p><p>"I am resigning because I want to make it clear that I am not okay with us being silent," Garza told the <a href="https://www.cjr.org/business_of_news/los-angeles-times-editorials-editor-resigns-after-owner-blocks-presidential-endorsement.php" target="_blank">Columbia Journalism Review</a>. "In dangerous times, honest people need to stand up. This is how I'm standing up."</p><p>Soon-Shiong, like Bezos, is a billionaire.</p><p>Marty Baron, the former editor of The Washington Post, called that paper's decision "cowardice, with democracy as its casualty."</p><p>″@realdonaldtrump will see this as an invitation to further intimidate owner @jeffbezos (and others)," Baron wrote. "Disturbing spinelessness at an institution famed for courage."</p><p>The Washington Post Guild, the union that represents the newspaper's staff, in a statement posted on the social media site X said it was "deeply concerned that The Washington Post — an American news institution in the nation's capital — would make a decision to no longer endorse presidential candidates, especially a mere 11 days ahead of an immensely consequential election."</p><p>"The message from our chief executive, Will Lewis — not from the Editorial Board itself — makes us concerned that management interfered with the work of our members in Editorial," the Guild said in the statement, which noted the paper's reporting about Bezos' role in the decision.</p><p>"We are already seeing cancellations from once loyal readers," the Guild said. "This decision undercuts the work of our members at a time when we should be building our readers' trust, not losing it."</p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC politics coverage</h2><div><ul><li><a href="https://www.cnbc.com/2024/10/25/biden-student-debt-financial-disaster-loan-cancellation.html">Biden's latest student debt plan would create forgiveness path for borrowers facing financial ruin</a></li><li><a href="https://www.cnbc.com/2024/10/24/polymarket-trump-french-election-bet.html">French trader bet over $28 million on Trump election win using 4 Polymarket accounts</a></li><li><a href="https://www.cnbc.com/2024/10/23/elon-musk-trump-pac-doj-letter-illegal-election.html">DOJ warns Elon Musk pro-Trump PAC that $1 million voter contest may be illegal</a></li><li><a href="https://www.cnbc.com/2024/10/23/harris-trump-hitler-election-john-kelly.html">Harris blasts Trump on reported Hitler comments, says 'he wants unchecked power'</a></li><li><a href="https://www.cnbc.com/2024/10/23/nobel-prize-winning-economists-donald-trump-agenda-endorse-harris.html">'Higher prices, larger deficits': 23 Nobel Prize-winning economists slam Trump agenda, endorse Harris</a></li></ul></div></div><div><p>Post columnist Karen Attiah, in a post on the social media site Threads, wrote, "Today has been an absolute stab in the back."</p><p>"What an insult to those of us who have literally put our careers and lives on the line to call out threats to human rights and democracy," Attiah wrote.</p><p>Rep. Ted Lieu, a Democrat from California, in his own tweet on the news wrote, "The first step towards fascism is when the free press cowers in fear."</p><p>Trump in August told Fox Business News that Bezos called him after the Republican narrowly escaped an assassination attempt in July at a campaign rally in western Pennsylvania.</p><p>"He was very nice even though he owns The Washington Post," Trump said of Bezos.</p><p>Bezos last posted on X on July 13, hours after the assassination attempt.</p><p>"Our former President showed tremendous grace and courage under literal fire tonight," Bezos wrote in that tweet. "So thankful for his safety and so sad for the victims and their families."</p><p>Trump on Friday met in Austin, Texas, with executives from the Bezos-owned space exploration company Blue Origin, among them CEO David Limp, the Associated Press reported</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In the US, regenerative farming practices require unlearning past advice (225 pts)]]></title>
            <link>https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/</link>
            <guid>41949108</guid>
            <pubDate>Fri, 25 Oct 2024 20:03:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/">https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/</a>, See on <a href="https://news.ycombinator.com/item?id=41949108">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-748674">
	<div>

		
		<figure><audio controls="" src="https://investigatemidwest.org/wp-content/uploads/2024/10/6705963765cad.audio_.mp3" autoplay="" loop=""></audio></figure><p>Early on a cool September morning, farmer Josh Payne tends to his flock in Concordia, just east of Kansas City, Missouri. As Payne opens the gate, about a thousand sheep round the corner and bound into fresh grass.</p><p>The pasture the flock grazes was once corn and soybeans, along with the rest of the Payne family farm. Josh’s grandfather Charles Payne cultivated nearly a thousand acres of row crops for decades.</p><p>But as Josh Payne took over managing the property about 15 years ago, that wasn’t going to work anymore.</p><p>“I found out I’m allergic to herbicide,” he said. “My throat would swell shut three or four times a week during harvest.”</p><p>Payne wanted to transition the farm to regenerative agriculture — a movement that aims to revive farmland soil and by extension the ecosystem and the small farm economy.</p><p>He hoped that by changing what and how they farmed, it would reduce the need for chemical inputs and farm with nature. Josh told his grandfather they should use cover crops, graze sheep and plant an orchard. But Charles Payne wasn’t having it.</p><figure><img data-recalc-dims="1" decoding="async" width="780" height="520" data-attachment-id="748688" data-permalink="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/67054967c8695/" data-orig-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?fit=1035%2C690&amp;ssl=1" data-orig-size="1035,690" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="67054967c8695" data-image-description="" data-image-caption="<p>Josh Payne drives from the farm house to the sheep pasture Sept. 3 at the Payne family farm in Concordia. Payne described his journey from teaching high school to returning to the Payne family farm and his discovery of cover crops as an alternative to the herbicides he’s allergic to. photo by Cory. W. Macneil, Missourian</p>
" data-medium-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?fit=780%2C520&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?resize=780%2C520&amp;ssl=1" alt="" srcset="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?w=1035&amp;ssl=1 1035w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054967c8695.webp?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px"><figcaption>Josh Payne drives from the farm house to the sheep pasture Sept. 3 at the Payne family farm in Concordia. Payne described his journey from teaching high school to returning to the Payne family farm and his discovery of cover crops as an alternative to the herbicides he’s allergic to. photo by Cory. W. MacNeil, Missourian</figcaption></figure><p>“I’m like, ‘Grandpa, we should do this.’ He’s like, ‘No, we’re not planting trees!’” Josh Payne said. “Literally. His phrase was, ‘I spent my whole life tearing out trees. We’re not gonna go plant them now.’”</p><p>Josh said he and his grandfather had similar disagreements, and even arguments, about many changes Josh hoped to make on the farm.</p><p>“We went through a really interesting process because I’m stubborn and he’s stubborn,” he said.</p><h3>Mid-century farm revolution</h3><p>Charles Payne, 96, came of age during an industrial and chemical revolution in agriculture. Like countless other Midwestern farmers, he heeded the advice from industry and government leaders to “plant fence row to fence row” to increase the production of commodities.</p><p>“And that’s what we did … tore out all the fences and hedgerows,” Charles Payne said. “Now I wish I had some of them back.”</p><p>U.S. agriculture&nbsp;<a href="https://www.ers.usda.gov/data-products/agricultural-productivity-in-the-u-s/summary-of-recent-findings" target="_blank" rel="noreferrer noopener">production tripled</a>&nbsp;in the latter half of the 20th century, due in part to chemical inputs. But that came with an environmental cost — soil degradation, water quality issues and a loss of biodiversity.</p><p>The resurgence of regenerative or environmentally sustainable agriculture is partially a response to the&nbsp;<a href="https://www.epa.gov/climateimpacts/climate-change-impacts-agriculture-and-food-supply" target="_blank" rel="noreferrer noopener">industry’s contribution to climate change</a>&nbsp;and its susceptibility to it. There’s now a surge of funding, research and education to figure out how to scale regenerative agriculture and turn away from equipment and chemically intensive ways of cultivating crops.</p><figure><img data-recalc-dims="1" decoding="async" width="780" height="520" data-attachment-id="748686" data-permalink="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/6705496e9683e-image/" data-orig-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?fit=1763%2C1176&amp;ssl=1" data-orig-size="1763,1176" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="6705496e9683e.image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?fit=780%2C520&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=780%2C520&amp;ssl=1" alt="" srcset="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?w=1763&amp;ssl=1 1763w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=1536%2C1025&amp;ssl=1 1536w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=1568%2C1046&amp;ssl=1 1568w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705496e9683e.image_.jpg?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px"><figcaption>Josh Payne returns to his truck after unhooking a portable shade he towed to a fresh pasture where the sheep will graze for three days, then move again on Sept. 3 at the Payne family farm in Concordia. Payne, who had once thought of raising cattle, switched to sheep after a suggestion at a farming conference, then confirmed by a banker he met at a fencing supplier who elaborated on the economics of cattle versus sheep. photo by Cory W. MacNeil, Missourian</figcaption></figure><p>But University of Missouri rural sociologist Mary Hendrickson said the way Charles Payne farmed was also a result of policy, research and methods encouraged by the industry at the time. Before the ecological consequences were understood, chemical inputs were “miracles” for a farm.</p><p>“Everybody who was going to be an advanced, innovative farmer, they were using chemicals for weed control, for pest control, for all of these things,” she said.</p><p>Hendrickson said for a certain generation of farmers, their skepticism or resistance to regenerative agriculture is a result of their lived experience.</p><p>“There’s a reason why somebody who has lived through that transition says, ‘Wait, you want me to go back to what?” Hendrickson said.</p><p>The advice Charles Payne’s grandchildren, Josh and his sister Jordan Welch, are getting is sometimes the exact opposite of what he was told in his day.</p><p>Hendrickson said this isn’t unique to agriculture. There are many things in life that people do differently than their grandparents’ generation — such as cooking, cleaning or child rearing.</p><p>“The things that my mother did to raise me were not in vogue when I was born, and they were (again) 20 years later,” she said.</p><h3>Generational legacy</h3><p>Farming isn’t Josh Payne’s first vocation. After teaching English for years, he said he ended up back on the farm “completely accidentally” when his grandfather requested help managing the land about 15 years ago.</p><p>“When we got here it was a very, very conventional farm. Everything was commodity, corn and soy. Everything was Roundup ready. Everything was genetically modified,” Josh Payne said. “I call it growing nickels and dimes.”</p><p>Payne wasn’t exactly happy row cropping, and he was curious about trying other methods. But when he discovered his allergy to herbicides, it was a catalyst for change.</p><p>“Grandpa, I’m either going to have to go back to teaching or we’re going to have to completely change what we do,” he told Charles Payne.</p><p>The Paynes now rotationally graze their sheep among 800 chestnut trees — a method called “silvopasture,” which revives the soil by keeping living roots in the ground year round. They planted the trees eight years ago and are completing their third harvest.</p><p>Before the flock of sheep was added to the operation, the Paynes cultivated conventional crops in between the orchard rows that are spaced 30-feet apart — a regenerative method called alley cropping. The Paynes are still finding ways to grow and adapt, most recently by adding a produce garden.</p><p>Charles Payne has been farming the stretch of land in Concordia since 1956. He said corn, soy and wheat were the “going” crops at the time.</p><figure><img data-recalc-dims="1" decoding="async" width="780" height="520" data-attachment-id="748684" data-permalink="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/6705b1f54b7f5-image/" data-orig-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?fit=1035%2C690&amp;ssl=1" data-orig-size="1035,690" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="6705b1f54b7f5.image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?fit=780%2C520&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?resize=780%2C520&amp;ssl=1" alt="" srcset="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?w=1035&amp;ssl=1 1035w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705b1f54b7f5.image_.jpg?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px"><figcaption>Josh Payne closes the electric fence after 1,000 sheep pass through to a fresh paddock Sept. 3 at the Payne family farm in Concordia. Payne said that moving 1,000 sheep from paddock to paddock is easier than moving a small number. photo by Cory W. MacNeil, Missourian</figcaption></figure><p>“We had some good years and we had some very poor years too,” he said.</p><p>Josh Payne said his grandfather has a deep knowledge of the land and the industry and now acts as a mentor and adviser to his grandkids.</p><p>Although he said he’s had to learn to bite his tongue at times during this transition, Charles Payne said he’s happy they are farming.</p><p>“That’s a good thing to have your grandkids farming where you left off,” Charles Payne said. “Of course, it’s a different way of farming, but they’re on the farm, and they seem to really enjoy it.”</p><p>For Charles and Josh Payne, the elder’s resistance to change and the younger’s desire for change were both motivated by the goal to keep the farm alive. Josh Payne said the markets for sheep and chestnuts are good and support jobs for him and his sister. He said they’re comparable to the markets his grandfather had for corn, soy and wheat decades ago.</p><p>“Grandpa, you made the right decisions for your time,” he said. “You were faithful to this land, to this place, to your family … but that just looks different now.”</p><p>Rural sociologist Hendrickson said in agriculture communities especially, there exists a generational pressure to farm and to succeed doing so.</p><p>“This identity as a farmer and the land and holding that for the next generation was significant for farmers,” she said.</p><p>For years farmers heard that to be successful in modern agriculture, they’d have to get big or get out. Payne thinks there’s another option.</p><p>“I think people either got to get big or get weird,” Josh Payne said. “We chose to get weird.”</p><h3>‘The new old way’</h3><p>Regenerative agriculture starts with the soil. The health of farm ground is connected to the financial viability and resiliency of the farm, said Chuck Rice, a professor at Kansas State University.</p><p>“We’ve lost 50% of our soil organic matter with 100 plus years of cultivation in the United States,” Rice said. “So we aren’t taking care of our soils.”</p><p>Methods like those Josh Payne has implemented on the Concordia farm revive — or regenerate — the soil and by extension the ecosystem. Regenerative agriculture methods aim to not only restore farmland to its prechemical and industrial state, but to help the land withstand the severe weather threats from climate change.</p><p>“Not only is the economy changing, but the climate’s changing,” Rice said. “I think if you’re staying with the same practices … ultimately you’re going to be losing out.”</p><p>Reducing or eliminating tillage of the soil, a practice called “no till,” is often the first step for farmers looking to operate more sustainably. Rice said market forces can sometimes jump start changes in the agriculture industry. In order to till fields, farmers need diesel fuel to power their equipment. That gas was highly priced during the 1970s fuel crisis, which made no till more popular, Rice said.</p><figure><img data-recalc-dims="1" decoding="async" width="780" height="520" data-attachment-id="748689" data-permalink="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/67054975b7485-image/" data-orig-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?fit=1763%2C1176&amp;ssl=1" data-orig-size="1763,1176" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="67054975b7485.image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?fit=780%2C520&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=780%2C520&amp;ssl=1" alt="" srcset="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?w=1763&amp;ssl=1 1763w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=1536%2C1025&amp;ssl=1 1536w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=1568%2C1046&amp;ssl=1 1568w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/67054975b7485.image_.jpg?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px"><figcaption>Josh Payne exits the shed where he grows micro-grains with a tray of sprouts to feed his the pigs Sept. 20 at the Payne family farm in Concordia. Growing the sprouts in trays allows Payne to monitor their growth and quality and makes it easy to transport from shed to pig pen. photo by Cory W. MacNeil, Missourian</figcaption></figure><p>“There was a quick, rapid adoption of no till during that time period,” he said.</p><p>Two generations later, no till continues to steadily spread. Rice said Kansas farmers are leaders in no till operation, encompassing about 40% of the state’s farmed acres.</p><p>“We still haven’t reached its peak, but it’s one of the more common practices,” Rice said.</p><p>Cody Jolliff is a farm historian and the CEO of the Midwest Center for Regenerative Agriculture at Powell Gardens, a botanical garden in Kansas City.</p><p>The Powell Gardens’ Midwest Center for Regenerative Agriculture is creating a living laboratory for farmers to come to Kansas City and get hands-on experience in regenerative agriculture methods. Or as Jolliff said, to learn “the new old way” to farm.</p><p>He said in many ways, regenerative agriculture is a return to the farming of another era.</p><p>“It’s really interesting though, because as we are going to these super modern methods, they also have a lot of resemblance to old methods,” he said.</p><p>Before the Civil War, over half of the country’s residents were farmers, Jolliff said, and they worked with small parcels of land in diversified operations. The modern regenerative agriculture movement encourages that same type of&nbsp;<a href="https://www.kbia.org/kbia-news/2024-09-25/farming-among-the-trees-how-perennial-crops-can-help-breathe-life-into-depleted-soil" target="_blank" rel="noreferrer noopener">farm diversification</a>.</p><p>Jolliff said agriculture has changed before and can change again. He points to the success of the 1914 Smith-Lever Act that created the cooperative extension programs that work from land-grant universities to teach farmers across the nation.</p><p>“It takes a long, long time for agriculture methods to change,” he said. “This is not going to be an overnight thing. It’s a huge investment right now across the country into these practices.”</p><figure><img data-recalc-dims="1" decoding="async" width="780" height="520" data-attachment-id="748687" data-permalink="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/6705497a23aa9-image/" data-orig-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?fit=1035%2C690&amp;ssl=1" data-orig-size="1035,690" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="6705497a23aa9.image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?fit=780%2C520&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?resize=780%2C520&amp;ssl=1" alt="" srcset="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?w=1035&amp;ssl=1 1035w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/6705497a23aa9.image_.jpg?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px"><figcaption>Josh Payne pours a bucket of grains for the pigs Sept. 20 at the Payne family farm in Concordia. photo by Cory W. MacNeil, Missourian</figcaption></figure><p><em>Cory W. MacNeil contributed reporting for this story.</em></p><div><figure><img data-recalc-dims="1" decoding="async" width="780" height="780" data-attachment-id="748695" data-permalink="https://investigatemidwest.org/2024/10/11/regenerative-farming-practices-require-unlearning-past-advice/the-next-harvest-2/" data-orig-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?fit=1760%2C1760&amp;ssl=1" data-orig-size="1760,1760" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the next harvest" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?fit=780%2C780&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=780%2C780&amp;ssl=1" alt="" srcset="https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=600%2C600&amp;ssl=1 600w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=1568%2C1568&amp;ssl=1 1568w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=706%2C706&amp;ssl=1 706w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?resize=100%2C100&amp;ssl=1 100w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1.webp?w=1760&amp;ssl=1 1760w, https://i0.wp.com/investigatemidwest.org/wp-content/uploads/2024/10/the-next-harvest-1-1024x1024.webp?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px"></figure><p><em>A KBIA News Series exploring what needs to change to sustain agriculture. Reported and produced by&nbsp;<a href="https://www.kbia.org/people/jana-rose-schleis">Jana Rose Schleis.</a> Logo designed by Harrison Petty.<br></em></p></div><section id="block-18"><p>Type of work: </p><p>News Service <span>Produced externally by an organization we trust to adhere to journalistic standards.</span></p></section>	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We can now fix McDonald's ice cream machines (916 pts)]]></title>
            <link>https://www.ifixit.com/News/102368/victory-is-sweet-we-can-now-fix-mcdonalds-ice-cream-machines</link>
            <guid>41949098</guid>
            <pubDate>Fri, 25 Oct 2024 20:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ifixit.com/News/102368/victory-is-sweet-we-can-now-fix-mcdonalds-ice-cream-machines">https://www.ifixit.com/News/102368/victory-is-sweet-we-can-now-fix-mcdonalds-ice-cream-machines</a>, See on <a href="https://news.ycombinator.com/item?id=41949098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p>Ever tried to get an ice cream at McDonald’s, only to hear, “Sorry, our machine’s broken?” You’re not the only one: <a href="https://mcbroken.com/">almost 15%</a> of ice cream machines at McDonald’s are broken right now around the US—and in New York, it’s 32%. But today, we won more ice cream, and things should start to change.</p>



<p>The U.S. Copyright Office <a href="https://public-inspection.federalregister.gov/2024-24563.pdf">just handed down a ruling</a> that marks an important victory for Right to Repair: we can now legally repair commercial food preparation equipment, including McDonald’s machines, without running afoul of copyright law.&nbsp;</p>



<p>We’ve been fighting for years to challenge the digital locks that manufacturers like Taylor (which makes McDonald’s ice cream machines) use to keep repair information out of reach, forcing expensive service calls for simple fixes. Digital locks blocking repair come from an archaic 1998 copyright law, and every three years, we get a chance to ask the Copyright Office to give us exemptions to that law. Last time, <a href="https://www.ifixit.com/News/54317/section-1201-exemptions-for-2021-repair-consoles-medical-devices">we won exemptions for basically all consumer equipment</a>, vehicles, and medical devices. The time before that, <a href="https://www.ifixit.com/News/11951/1201-copyright-final-rule">we won smartphones</a> and home appliances. This time, <a href="https://www.ifixit.com/News/92942/the-ftc-and-doj-call-for-ice-cream-machine-repair">the FTC and DOJ even weighed in</a> to support our petition.&nbsp;</p>



<p>But while this is a significant step forward, the battle is far from over. Any McDonald’s franchisee can hack your own machine, but if you want to share what you found with your friends or <a href="https://www.wired.com/story/kytch-taylor-mcdonalds-ice-cream-machine-smoking-gun/">sell a tool to help diagnose</a> and fix your machine, you’re out of luck. Plus, the ruling didn’t go nearly far enough in granting broader exemptions for repairing other commercial or industrial equipment.&nbsp;</p>



<p>Trust us, we’re not stopping there. This is a big win—and we’ll be celebrating with ice cream!—but copyright law still needs fixing before we’re free to fix everything we own.</p>



<h2>The Win: You’re Now Free to Hack Your Ice Cream Machine</h2>



<p>For years, McDonald’s franchise owners have struggled with error codes and malfunctioning ice cream machines that could only be fixed by manufacturer-authorized technicians. The machines would often sit broken for extended periods because owners couldn’t troubleshoot or repair them on their own, due to digital locks embedded in the machine’s software. These locks are <a href="https://www.scientificamerican.com/article/some-electronics-repairs-are-illegal-federal-law-could-change-that/">protected under Section 1201 of the Digital Millennium Copyright Act (DMCA)</a>, which generally makes it illegal to bypass software locks known as “technological protection measures,” even for legitimate repairs.</p>



<p>That changes today. Thanks to the new exemption granted by the Copyright Office, owners, repair technicians, and tinkerers can now legally bypass the software locks on retail-level commercial food preparation equipment, such as the Taylor ice cream machines. This allows for the diagnosis, maintenance, and repair of the machines without needing to rely on costly service calls or manufacturer intervention. The exemption also applies to other commercial kitchen equipment—we’ve heard about undocumented <a href="https://assets.breville.com/BES920/BES920_ANZ_IB_O21_FA_WEB.pdf">error codes in commercial espresso machines</a>, restaurant owners getting <a href="https://www.reddit.com/r/sheetz/comments/y35axd/sheetz_merrychef_manager_password/">locked out of their own commercial ovens</a>, and <a href="https://hvac-talk.com/vbb/threads/176851-ALTO-SHAAM-service-manuals">missing service manuals</a> for insulated cabinets. But we’re <a href="https://www.fastcompany.com/90923565/congress-mcdonalds-ice-cream-machines">especially excited</a> about the ice cream win.</p>



<p>For ice cream lovers everywhere, this could mean fewer “machine broken” signs at McDonald’s and more sundaes and McFlurries available when you want them. It’s tangible progress in the fight to regain control over the products we own.</p>



<figure><img fetchpriority="high" loading="lazy" decoding="async" width="1600" height="1200" src="https://valkyrie.cdn.ifixit.com/media/2020/10/19094648/oneplus_nord_tools.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2020/10/19094648/oneplus_nord_tools.jpg 1600w, https://valkyrie.cdn.ifixit.com/media/2020/10/19094648/oneplus_nord_tools-1536x1152.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2020/10/19094648/oneplus_nord_tools-1200x900.jpg 1200w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption>Repair’s pretty difficult without tools.</figcaption></figure>



<h2>The Problem: We Still Don’t Have Repair Tools</h2>



<p>Here’s the catch: while it’s now legal to circumvent the digital locks on these machines, the ruling does not allow us to share or distribute the tools necessary to do so. This is a major limitation. Most franchise owners and independent repair shops won’t have the technical expertise to create their own unlocking tools from scratch, meaning that while the door to repair has been opened, few will be able to walk through it without significant difficulty.</p>



<p>It is still a crime for iFixit to sell a tool to fix ice cream machines, and that’s a real shame. The ruling doesn’t change the underlying statute making it illegal to share or sell tools that bypass software locks. This leaves most of the repair work inaccessible to the average person, since the technical barriers remain high. Without these tools, this exemption is largely theoretical for many small businesses that don’t have in-house repair experts.</p>



<h2>The Miss: Broader Exemptions for Commercial and Industrial Equipment</h2>



<p>Even more disappointing is the denial of broader exemptions for commercial and industrial equipment. While we succeeded in securing an exemption for retail-level food equipment, the Copyright Office declined to extend similar protections to a wider class of commercial devices—meaning the ruling does not apply to things like heavy machinery, factory equipment, or even broader categories of restaurant hardware.</p>



<p>This was a key part of our petition, as the same issues plague repair in other industries. Many businesses, from farmers to factory owners, face the same frustrations: they are locked out of their own equipment by digital restrictions that prevent them from making repairs without calling in a certified technician. We pointed to examples like the <a href="https://social.hackerspace.pl/@q3k/111528162462505087">Polish trains</a> that were locked “for arbitrary reasons after being serviced at third-party workshops” with “bogus error codes,” <a href="https://www.reddit.com/r/PLC/comments/9dzlv1/safety_plccontroller_passwords/">multi-million dollar factory machines</a> getting bricked for a lack of software access, and a school that <a href="https://hvac-talk.com/vbb/threads/159467-NAE25-Metasyssyagent-Password-Reset">lost access to its HVAC system</a> when the maintenance technician passed away.</p>



<figure><p>
<iframe title="Forget about Sony and Netflix, there's DRM in public trains now...." width="456" height="257" src="https://www.youtube-nocookie.com/embed/w8NqBXT6Kos?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>We asked for an exemption that would cover all software-enabled commercial and industrial devices, but the Copyright Office denied this broader request, citing a lack of sufficient evidence that digital locks were creating adverse effects across a wider range of equipment.</p>



<p>Without this broader exemption, a significant portion of the repair market is still controlled by manufacturers, who can charge exorbitant prices for repair services and restrict access to parts and tools. This leaves many small businesses with no choice but to endure downtime and extra costs, even when a simple repair could get them back up and running quickly.</p>



<h2>Renewals: What We Won, What We Didn’t</h2>



<p>Every three years, the Copyright Office reviews the current exemptions and decides which ones to renew, expand, or let expire. This year, we secured several important renewals, though some gaps remain.</p>


<div>
    <p><span>
      Device Page    </span></p><div>
      <p><a href="https://www.ifixit.com/Device/Defibrillator">
          <img decoding="async" src="https://guide-images.cdn.ifixit.com/igi/GxJMngNjEyXdkcXb.medium" alt="Defibrillator">
        </a>
      </p>
      <div>
        <h3>Defibrillator</h3>
        <p>Repair information for defibrillators.</p>
        <p><a href="https://www.ifixit.com/Device/Defibrillator">
          View Device        </a>
      </p></div>
    </div>
  </div>


<h3>What We Won:</h3>



<p><strong>Medical Devices:</strong></p>



<p>Renewals were granted for medical devices, allowing technicians to access software controlling devices like defibrillators and insulin pumps. This helps ensure that life-saving equipment can be repaired quickly and efficiently, which is crucial for patient care. This renewal is essential for hospitals repairing their own equipment, and came despite heated opposition from AdvaMed. The medical device manufacturers are so upset about all of this that they are <a href="https://1technation.com/mita-advamed-appeal-dismissal-of-copyright-lawsuit/">suing the Copyright Office</a> over the last rulemaking that originally granted this exemption three years ago.</p>



<p><strong>Repair of Motorized Vehicles, Marine Vessels, and Agricultural Equipment:</strong></p>



<p>Exemptions allowing the repair of computer programs in motorized land vehicles, marine vessels, and mechanized agricultural equipment were renewed. This means farmers can continue to repair their tractors, and boat owners can fix their vessels without worrying about digital locks​.</p>



<p><strong>Consumer Devices:</strong></p>



<p>We also successfully renewed the exemption that allows repairs on consumer electronic devices, such as smartphones, tablets, and home appliances. This is a critical exemption for everyday consumers who want the right to repair their own gadgets without voiding warranties or violating copyright law​.</p>



<p><strong>Assistive Technologies:</strong></p>



<p>The exemptions for assistive technologies were renewed as well, ensuring that people with disabilities can access and use literary and musical works through assistive software without running afoul of copyright restrictions​.</p>



<figure><p>
<iframe title="Tobii 5: A NON-sponsored review of the premium tracking solution!" width="456" height="257" src="https://www.youtube-nocookie.com/embed/k2T0d8hWxwU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p><figcaption>Video game alternative input methods like eye tracking sometimes require getting around technological protection measures—and the Copyright Office declined to renew that exemption.</figcaption></figure>



<h3>What We Didn’t Win:</h3>



<p><strong>Video Game Accessibility:</strong></p>



<p>Unfortunately, the exemption allowing circumvention of digital locks on video games for accessibility purposes (introduced in 2021) was not renewed. No petition for renewal was submitted, and as a result, individuals with disabilities who need alternative input methods to play video games are left out.</p>



<p><strong>Broader Exemptions for Industrial Devices:</strong></p>



<p>As mentioned earlier, we failed to secure a broader exemption for industrial and commercial equipment. This leaves a huge number of businesses still locked out of the right to repair their own machinery​.</p>



<h2>Why Does This Matter?</h2>



<p>The Copyright Office’s ruling is a step in the right direction, but it’s far from the finish line. We’re thrilled to be able to fix ice cream machines, but without tools, most franchise owners won’t be able to take full advantage of this new freedom. And while retail food equipment is now covered, the vast world of commercial and industrial devices remains stuck in a repair monopoly, where manufacturers control who can fix what and at what cost.</p>



<p>This ruling highlights the ongoing battle between consumers and manufacturers over the right to repair. We’ve made significant strides, but we’re still facing systemic barriers that prevent small businesses and consumers from taking control of their own products.</p>



<h2>What’s Next?</h2>



<p>We’ll take today’s victory and keep fighting for more. Next on our list? Fixing federal copyright law, which is the only way we can secure access to the tools we need and share what we find as we troubleshoot our machines. iFixit CEO Kyle Wiens <a href="https://www.ifixit.com/News/78204/congress-asks-ifixit-if-the-right-to-repair-exists">testified before congress</a> last year about why this is so important, and we’re hoping to see US federal legislation like last session’s <a href="https://www.ifixit.com/News/56976/freedom-to-repair-act">Freedom to Repair Act</a>.</p>



<p>Meanwhile, Canada is in the final stages of <a href="https://www.parl.ca/legisinfo/en/bill/44-1/c-244">considering legislation</a> that would fix the Canadian version of the DMCA, a bill called C-244 that is in its third reading in the Senate and expected to move before the end of the month. If Canada legalized circumventing technological protection measures for the purposes of repair, we might just have to head north to find the tools we need to do repairs.</p>



<p>So go enjoy that McFlurry—just know that the fight to fix isn’t over yet.</p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Company named "><SCRIPT SRC=HTTPS://MJT.XSS.HT> LTD" forced to change it (2020) (494 pts)]]></title>
            <link>https://www.theguardian.com/uk-news/2020/nov/06/companies-house-forces-business-name-change-to-prevent-security-risk</link>
            <guid>41948666</guid>
            <pubDate>Fri, 25 Oct 2024 19:20:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/uk-news/2020/nov/06/companies-house-forces-business-name-change-to-prevent-security-risk">https://www.theguardian.com/uk-news/2020/nov/06/companies-house-forces-business-name-change-to-prevent-security-risk</a>, See on <a href="https://news.ycombinator.com/item?id=41948666">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Companies House has forced a company to change its name after it belatedly realised it could pose a security risk.</p><p>The company now legally known as “THAT COMPANY WHOSE NAME USED TO CONTAIN HTML SCRIPT TAGS LTD” was set up by a British software engineer, who says he did it purely because he thought it would be “a fun playful name” for his consulting business.</p><p>He now says he didn’t realise that Companies House was actually vulnerable to the extremely simple technique he used, known as “cross-site scripting”, which allows an attacker to run code from one website on another.</p><p>The original name of the company was ““&gt;&lt;SCRIPT SRC=HTTPS://MJT.XSS.HT&gt; LTD”. By beginning the name with a quotation mark and chevron, any site which failed to properly handle the HTML code would have mistakenly thought the company name was blank, and then loaded and executed a script from the site XSS Hunter, which helps developers find cross-site scripting errors.</p><p>That script would have simply put up a harmless alert – but it serves as proof that a malicious attacker could instead have used the same weakness as a gateway to more damaging ends.</p><p>Similar names have been registered in the past, such as “; DROP TABLE “COMPANIES”;-- LTD”, a <a href="https://pizzey.me/blog/no-i-didnt-try-to-break-companies-house/" data-link-name="in body link">wry attempt</a> to carry out an attack known as SQL injection, <a href="https://xkcd.com/327/" data-link-name="in body link">inspired by a famous XKCD webcomic</a>, but this was the first such name to have prompted a response. Companies House has retroactively removed the original name from its data feeds, and all documentation referring to its original moniker now reads simply “Company name available on request”.</p><p>The director of the company, who asked not to be named, told the Guardian: “Government Digital Service - GDS - have a good reputation for security, and other companies with similarly playful names have been registered in the past, so I thought there probably wouldn’t be a problem.</p><p>“When I discovered there were some minor problems, I contacted Companies House and the <a href="https://www.theguardian.com/technology/2020/nov/03/covid-related-cybercrime-drives-attacks-on-uk-to-record-number" data-link-name="in body link">National Cyber Security Centre</a> immediately, and didn’t disclose the issue to anyone else.”</p><p>He did not realise it would be an issue, he said, because characters including &gt; and “ are explicitly allowed as company names, which suggested that the agency had put security measures in place to prevent such attacks.</p><p>A Companies House spokesperson said: “A company was registered using characters that could have presented a security risk to a small number of our customers, if published on unprotected external websites. We have taken immediate steps to mitigate this risk and have put measures in place to prevent a similar occurrence. We are confident that Companies House services remain secure.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OmniParser for Pure Vision Based GUI Agent (132 pts)]]></title>
            <link>https://microsoft.github.io/OmniParser/</link>
            <guid>41948433</guid>
            <pubDate>Fri, 25 Oct 2024 18:54:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microsoft.github.io/OmniParser/">https://microsoft.github.io/OmniParser/</a>, See on <a href="https://news.ycombinator.com/item?id=41948433">Hacker News</a></p>
<div id="readability-page-1" class="page">


    <div>
                        <h2>OmniParser for Pure Vision Based GUI Agent</h2>
                        


                        <p><span>
                    <sup>1</sup>Microsoft Research,
                    <sup>2</sup>Microsoft Gen AI,<br> 

                        </span></p>

                        
                    </div>



    <!-- Paper abstract -->
    <div>
                        <h2>Abstract</h2>
                        <p>
                                The recent success of large vision language models shows great potential in driving the agent system operating on user interfaces. However, we argue that the
                                power multimodal models like GPT-4V as a general agent on multiple operating
                                systems across different applications is largely underestimated due to the lack of
                                a robust screen parsing technique capable of: 1. reliably identifying interactable
                                icons within the user interface, and 2. understanding the semantics of various
                                elements in a screenshot and accurately associate the intended action with the
                                corresponding region on the screen. To fill these gaps, we introduce OMNIPARSER,
                                a comprehensive method for parsing user interface screenshots into structured
                                elements, which significantly enhances the ability of GPT-4V to generate actions
                                that can be accurately grounded in the corresponding regions of the interface. We
                                first curated an interactable icon detection dataset using popular webpages and
                                an icon description dataset. These datasets were utilized to fine-tune specialized
                                models: a detection model to parse interactable regions on the screen and a caption
                                model to extract the functional semantics of the detected elements. OMNIPARSER
                                significantly improves GPT-4V's performance on ScreenSpot benchmark. And
                                on Mind2Web and AITW benchmark, OMNIPARSER with screenshot only input
                                outperforms the GPT-4V baselines requiring additional information outside of
                                screenshot
                            </p>
                    </div>
    <!-- End paper abstract -->



    <!-- Image carousel -->
    
    <!-- End image carousel -->


    <div>
                        <h2>Curated Dataset for Interactable Region Detection and Icon Functionality Description</h2>
                        <p>
                        We curate a dataset of interactable icon detection dataset, containing 67k unique screenshot images, each labeled with bounding boxes of interactable icons derived from DOM tree. We first took a 100k uniform sample of popular publicly availabe urls on the clueweb dataset, and collect bounding boxes of interactable regions of the webpage from the DOM tree of each urls. We also collected 7k icon-description
                        pairs for finetuning the caption model.
                        </p><div>
                            <p><img src="https://microsoft.github.io/OmniParser/static/images/curated_data.png" alt="Species Classification results on iWildCam2020-WILDS (OOD) dataset"></p><p>
                                <b>Examples from the Interactable Region Detection dataset. </b>. TThe bounding boxes are based on the interactable region extracted from the DOM tree of the webpage. 
                            </p>
                        </div>
                    </div>

<!-- 
    <section class="hero is-light is-small">
        <div class="hero-body">
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
              <div class="item item-steve">
                <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/web_5_demo_nocap.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-chair-tp">
                <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/web_22_demo_nocap.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
    </section> -->
    
    <div>
                        <h2>Results</h2>
                        <p>
                        We evaluate our model on SeeClick, Mind2Web, and AITW benchmarks. We show that our model outperforms the GPT-4V baseline on all benchmarks. We also show that our model with screenshot only input outperforms the GPT-4V baselines requiring additional information outside of screenshot.
                        </p><p><img src="https://microsoft.github.io/OmniParser/static/images/seeclick.png" alt="seeclick">
                            <img src="https://microsoft.github.io/OmniParser/static/images/m2w.png" alt="mind2web">
                            <img src="https://microsoft.github.io/OmniParser/static/images/aitw.png" alt="aitw">
                        </p>
                    </div>

    
        <div>
                        <h2>Plugin-ready for Other Vision Language Models</h2>
                        <p>
                        To further demonstrate OmniParser is a plugin choice for off-the-shelf vision langauge models, we show the performance of OmniParser combined with recently announced vision language models: Phi-3.5-V and Llama-3.2-V. As seen in table, our finetuned interactable region detection (ID) model significantly improves the task performance compared to grounding dino model (w.o. ID) with local semantics across all subcategories for GPT-4V, Phi-3.5-V and Llama-3.2-V. In addition, the local semantics of icon functionality helps significantly with the performance for every vision language model. 

                        In the table, LS is short for local semantics of icon functionality, ID is short for the interactable region detection model we finetune. The setting w.o. ID means we replace the ID model with original Grounding DINO model not finetuned on our data, and with local semantics. The setting w.o. ID and w.o LS means we use Grounding DINO model, and further without using the icon description in the text prompt. 
                        </p><p><img src="https://microsoft.github.io/OmniParser/static/images/ablation.png" alt="seeclick">
                        </p>
                    </div>
    

    <div>
            <h2>Demo of Mind2Web Tasks </h2>
            
          
    </div>
    <br>

    <!-- BibTex citation -->
    <div id="BibTeX">
            <h2>Citation</h2>
            <!-- Please cite our paper if you use our code, data, model or results: -->
            <!-- <br> -->
            <pre><code>@misc{lu2024omniparserpurevisionbased,
                title={OmniParser for Pure Vision Based GUI Agent}, 
                author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},
                year={2024},
                eprint={2408.00203},
                archivePrefix={arXiv},
                primaryClass={cs.CV},
                url={https://arxiv.org/abs/2408.00203}, 
          }
</code></pre>
        </div>


    





</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal investigators probe Tether (109 pts)]]></title>
            <link>https://www.wsj.com/finance/currencies/federal-investigators-probe-cryptocurrency-firm-tether-a13804e5</link>
            <guid>41947892</guid>
            <pubDate>Fri, 25 Oct 2024 18:08:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/finance/currencies/federal-investigators-probe-cryptocurrency-firm-tether-a13804e5">https://www.wsj.com/finance/currencies/federal-investigators-probe-cryptocurrency-firm-tether-a13804e5</a>, See on <a href="https://news.ycombinator.com/item?id=41947892">Hacker News</a></p>
Couldn't get https://www.wsj.com/finance/currencies/federal-investigators-probe-cryptocurrency-firm-tether-a13804e5: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Detecting when LLMs are uncertain (260 pts)]]></title>
            <link>https://www.thariq.io/blog/entropix/</link>
            <guid>41947566</guid>
            <pubDate>Fri, 25 Oct 2024 17:40:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thariq.io/blog/entropix/">https://www.thariq.io/blog/entropix/</a>, See on <a href="https://news.ycombinator.com/item?id=41947566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <div><p>This post tries to explain the new reasoning techniques developed by <a href="https://x.com/_xjdr">XJDR</a> in a new project called
<a href="https://github.com/xjdr-alt/entropix">Entropix</a>.</p><p>Entropix attempts to improve reasoning in models through being smarter at sampling during moments of uncertainty.</p><p>A big caveat, there have been no large scale evals yet for Entropix, so it’s not clear how much this helps in practice. But it does seem to introduce some promising techniques and mental models for reasoning.</p></div>
<h2 id="uncertainity-at-a-glance">Uncertainity at a glance</h2>
<p>Sampling is the process of choosing which token from the distribution of possible tokens (the logits) that a LLM chooses. You can tell how confident a model is in its predictions by looking at that distribution.</p>
<p>This is a <strong>confident</strong> model prediction for the next token:</p>
<p><img src="https://www.thariq.io/images/entropix/lowe-lowv.png" alt="Screenshot 2024-10-11 at 10.08.08 AM.png"></p><p>But in reality, models are not always so sure of their predictions. You will often run into cases where the next token prediction looks like this:</p>
<p><img src="https://www.thariq.io/images/entropix/lowe-highv.png" alt="Screenshot 2024-10-11 at 10.08.08 AM.png"><img src="https://www.thariq.io/images/entropix/highe-lowv.png" alt="Screenshot 2024-10-11 at 10.09.29 AM.png"></p>
<p>In these cases, the model is uncertain.</p>
<p>Entropix is a method for using <strong>adaptive sampling</strong> to make better decisions when the model is uncertain.</p>
<h3 id="what-does-uncertainity-mean-and-does-it-matter">What does uncertainity mean, and does it matter?</h3>
<p>This uncertainty in the logits might have many different underlying causes, and not all are bad.</p>
<p>Causes include:</p>
<ul>
<li>The tokens are synonyms or equivalent (e.g. good vs great)</li>
<li>There are branching paths (e.g. the AI could either write your program in Java or C)</li>
<li>The AI may genuinely not be sure what to do (it is ‘out of distribution’, it hasn’t seen this in its training data before).</li>
</ul>
<p>Entropix suggests that you should have <em>different methods</em> for choosing the next token, depending on how uncertain you are.</p>
<p>How do we do that? To start, we need to measure uncertainty.</p>
<h2 id="entropy-and-varentropy">Entropy and Varentropy</h2>
<p>The key tools that Entropix uses are two metrics that measure uncertainty: <strong>the entropy</strong> &amp; <strong>varentropy</strong> of the logits.</p>
<p>Entropy measures how different the predicted logits are from each other, i.e. how uncertain we are in the most probably outcome. In low entropy, we are pretty certain in a few of the logits. In high entropy, the distribution of the logits is more uniform and we are much less certain.</p>
<p>Varentropy is a different type of entropy metric. It gives us an idea of the “shape” of the uncertainty. High varentropy indicates that some of the values are highly different from others.</p>
<astro-island uid="ZPT0W8" prefix="r3" component-url="/_astro/SimpleExpandableBlock.-iQQRPjY.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;heading&quot;:[0,&quot;The Math&quot;]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;SimpleExpandableBlock&quot;,&quot;value&quot;:true}" await-children=""><template data-astro-template=""><p>Entropy &amp; Varentropy are based on the idea of <strong>surprisal</strong>.</p><p>Surprisal, also known as self-information, measures how unexpected or surprising an event is based on its probability. For an event x with probability P(x), the surprisal is:</p><div data-testid="react-katex"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(x) = -\log_2(P(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span></span></span></span></span></div><p>The more unlikely an event is, the higher its surprisal. For example, if P(x) = 1/8, the surprisal is 3 bits, while if P(x) = 1/2, the surprisal is only 1 bit.</p><p>Entropy is the expected value (weighted average) of surprisal across all possible outcomes.</p><div data-testid="react-katex"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">H = -\sum_{x \in X} P(x)\log_2(P(x)) = E[I(x)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3717em;vertical-align:-1.3217em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span></span></span></span></span></div><p>Varentropy is calculated as the variance of the surprisal:</p><div data-testid="react-katex"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>H</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>−</mo><mi>H</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V = \sum_{x \in X} P(x)(\log_2(P(x)) + H)^2 = E[(I(x) - H)^2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3717em;vertical-align:-1.3217em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mopen">(</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></div><p>High varentropy indicates that some of the values are highly different from others - in other words, some outcomes are much more surprising than others relative to the average surprisal (entropy).</p></template><!--astro:end--></astro-island>
<p>Combined, the two of us give 4 possible states:</p>
<ul>
<li>Low entropy, low varentropy: A very peaked distribution (one highly probable outcome).</li>
<li>Low entropy, high varentropy: A distribution with a few disparate peaks.</li>
<li>High entropy, low varentropy: A uniform or near-uniform distribution.</li>
<li>High entropy, high varentropy: A spread-out but uneven distribution.</li>
</ul>
<h2 id="adaptive-sampling-based-on-entropy--varentropy">Adaptive Sampling based on Entropy &amp; Varentropy</h2>
<p>Now that we have those metrics for uncertainty, we can use them to perform different types of sampling based on the situation.</p>
<h3 id="low-entropy-low-varentropy">Low Entropy, Low Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/lowe-lowv.png" alt="Low entropy, low varentropy"></p><p>This is usually the ideal case. The model is certain not only in what its first option would be, but also what it would choose if the first option was incorrect. Often times this means that the list is ordered in a neat way.</p>
<p>In this case, adaptive sampling would suggest the standard argmax sampling, e.g. choose the token with the highest probabilitly.</p>
<h3 id="low-entropy-high-varentropy">Low Entropy, High Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/lowe-highv.png" alt="Low entropy, high varentropy"></p><p>In this case, the model predicts a few options very highly.</p>
<p>This is a tricky case- it may be representing a whole new branch of output, or it may be representing a few options such as a synonym.</p>
<p>In this case, we may want to “<strong>branch</strong>” by predicting both logits, seeing what paths they take and comparing the results after some point. There are many ways to implement this branching, which deserves its own post.</p>
<p>Depending on the results of the branching, we could take different actions. If we get two branches with fairly equal confidence (as measured by their entropy and varentropy) but with different contents, we could formulate this as a question to the user.</p>
<h3 id="high-entropy-low-varentropy">High Entropy, Low Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/highe-lowv.png" alt="High entropy, low varentropy"></p><p>This state represents a possible low confidence state in the model. It may be seeing something that it doesn’t recognize at all, or all the options may be interchangeable with each other.</p>
<p>The best thing to do here is to help the model get to a higher confidence state. Entropix suggests using a <strong>“thinking” token</strong> here as the next token, e.g. <em>“Wait..”</em></p>
<p>A thinking token is a token that we insert into the output, to make the model realizes it needs to spend more compute time thinking about the answer before giving one.</p>
<p>For example, if the model is predicting <em>“The capital of Germany is Paris”</em> but it is not sure about the answer, it might insert a thinking token and predict <em>“The capital of Germany is Paris… Wait, no, it’s actually Berlin”</em></p>
<h3 id="high-entropy-high-varentropy">High Entropy, High Varentropy</h3>
<p><img src="https://www.thariq.io/images/entropix/highe-highv.png" alt="High entropy, high varentropy"></p><p>The model has no clear favorite, but it is more certain in some outputs than others. This is a difficult place to be in. One way to think about is that any of the top options may be solid choices (e.g. they are synonyms to each other), and so we should just choose one at random (aka a higher temperature).</p>
<p>We could also branch, or insert thinking tokens like we have done in previous options.</p>
<h2 id="branching-vs-thinking-tokens">Branching vs Thinking Tokens</h2>
<p>Branching &amp; thinking tokens are two different ways of achieving more compute in an uncertain state.</p>
<p>Branching predictions involves following a few logits to see what other tokens they lead to. This is often called MCTS (Monte Carlo Tree Search) and is a method that has been often tried in LLMs to middling success. One of the tradeoffs of branching is that it requires using inference compute in a way where the branches cannot benefit from each others compute.</p>
<p>Thinking tokens are a way of achieving more compute in an uncertain state without sacrificing some of that compute to explore a branch that you might kill. Inserting “Wait…” causes the AI to realize that it might have made a mistake.</p>
<p>Branching vs thinking tokens is overall an open research question, and deserving of another post.</p>
<h2 id="attention-entropy">Attention Entropy</h2>
<p>It’s worth noting that there are other measures of entropy that we might take into account. Entropix uses them slightly to figure out how to modify temperature, but they might be other tools.</p>
<p><strong>Attention Entropy</strong> - How much are your attention heads tend to follow specific tokens, vs pay attention to a large number of tokens in the context.</p>
<p><strong>Attention Agreement</strong> - How much your attention heads are paying attention to the same tokens as each other, vs different ones.</p>
<p>If your heads have low entropy and high agreement, that can be another signal for you to be confident sampling the highest probability. Low agreement might indicate that different heads are contributing to different predictions, and it might be worth branching.</p>
<h2 id="does-this-matter">Does this matter?</h2>
<p>The insights in Entropix feel in many ways fairly easy to understand, and not entirely novel, which has been surprising to many.</p>
<p>Even if the evals don’t show a large benefit yet. But, inference-time techniques like this are easy to experiment with and could be a promising direction for open source hackers to improve reasoning without huge budgets.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Git repos on Cloudflare workers (139 pts)]]></title>
            <link>https://gitlip.com/blog/infinite-git-repos-on-cloudflare-workers</link>
            <guid>41947513</guid>
            <pubDate>Fri, 25 Oct 2024 17:34:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlip.com/blog/infinite-git-repos-on-cloudflare-workers">https://gitlip.com/blog/infinite-git-repos-on-cloudflare-workers</a>, See on <a href="https://news.ycombinator.com/item?id=41947513">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>How we built a scalable Git server on Cloudflare Workers using WebAssembly and Durable Objects.</p><div><div><p>We’re building<!-- --> <a href="https://gitlip.com/">Gitlip</a> <!-- -->- the collaborative devtool for the AI era. An all-in-one combination of Git-powered version control, collaborative coding and 1-click deployments. Our goal is to simplify the practical application of state-of-the-art AI models.</p><p>We’re preparing to raise a seed round soon. Reach out to<!-- --> <a href="https://x.com/nataliemarleny">@nataliemarleny</a> <!-- -->for more information.</p></div><p>In this post we will describe how we implemented infinite Git repos on Cloudflare using a new type of serverless database: a highly optimized Webassembly Git server that runs on Cloudflare Workers and scales horizontally. It allows us to easily host an infinite number of repositories. Additionally, since it runs on Cloudflare our Git server supports IPv6 by default. For comparison,<!-- --> <a href="https://github.com/orgs/community/discussions/10539">GitHub doesn’t yet support IPv6</a>.</p><p>Currently we are leveraging this technology to build a coding platform. We’re also considering creating a serverless Database as a Service (DBaaS) offering, which would allow anyone to create an arbitrary number of Git repositories in the cloud and use them in their own product. If you’d be interested in a DBaaS product like this, please reach out to<!-- --> <a href="https://x.com/nataliemarleny">@nataliemarleny</a>!</p><h3>Motivation</h3><p>Originally, while working on a note-taking application for developers based on Git, we encountered the need to host Git repositories efficiently. Wanting to avoid managing the servers ourselves, we experimented with a serverless approach. After researching, we couldn’t find anyone attempting something similar, so besides its potential usefulness, it also seemed like an interesting problem to solve.</p><p>We’re big fans of Cloudflare and their Workers platform and we were aware of<!-- --> <a href="https://developers.cloudflare.com/durable-objects/">Durable Objects</a>. In terms of the usage model, likely access patterns, and general philosophy, Durable Objects seemed like the perfect underlying storage for a project like this.</p><p>We consider Durable Objects a novel and revolutionary type of storage. It offers a key-value store that is transactional, strongly consistent, and persistent. It’s tightly integrated with the Workers runtime and is suitable for all sorts of coordination and application-data use cases. Given its usefulness, we fully expect that other cloud providers will offer a comparable type of storage alongside their serverless offerings in the future.</p><p>When we started our research, we knew that Cloudflare had built D1 (their SQLite database offering) on Durable Objects. In addition to our early experiments with Durable Objects, this made us confident that what we intended to implement was feasible, so we made it our goal to host a Git repository within a Durable Object.</p><h3>Git in Cloudflare Workers</h3><p>Cloudflare Workers is a serverless platform based on the V8 JavaScript engine, which can also execute Wasm binaries, so when attempting to run Git in this environment, we had somewhat limited options. We tried a few different approaches, but in the end, there were only two legitimate candidates:</p><ol><li><a href="https://github.com/libgit2/libgit2">libgit2</a> <!-- -->- a cross-platform, linkable Git library written in C,</li><li><a href="https://github.com/isomorphic-git/isomorphic-git">isomorphic-git</a> <!-- -->- a pure JavaScript implementation of Git.</li></ol><p>We judged that it would be easier to start with isomorphic-git, but that the initial up-front investment in making libgit2 work might pay off more significantly, since libgit2 is used much more widely and is more battle-hardened. Prior to our attempts, other developers had already made libgit2 work in Node.js and browsers (see<!-- --> <a href="https://github.com/petersalomonsen/wasm-git">wasm-git</a>), which further encouraged us that we were on the right path.</p><p>We ended up compiling libgit2 with Emscripten and packaging it for Cloudflare Workers.</p><p>Git uses the filesystem as its underlying storage, so the next step was to implement a filesystem on top of Durable Objects. A big hurdle we encountered at this point was how I/O is handled in modern JavaScript (using promises or async/await) versus how filesystem I/O is expected to work in Emscripten (synchronous system calls). Emscripten offers two mechanisms for using asynchronous JavaScript function calls in synchronous C functions:<!-- --> <a href="https://emscripten.org/docs/porting/asyncify.html">JSPI and Asyncify</a>. After extensive research, we rewrote significant parts of Emscripten to support asynchronous file system calls. We ended up creating our own Emscripten filesystem on top of Durable Objects, which we call DOFS. Having a filesystem on Durable Objects is very useful for running a Git server, but it also unlocks many other interesting possibilities (we will write about this in the future).</p><p><img src="https://gitlip.com/images/blog/infinite-git-repos-on-cloudflare-workers/image-00.svg" alt=""></p><h3>Implementing a Git server</h3><p>Compiling libgit2 to Wasm and implementing a filesystem on top of Durable Objects was a good start, but we needed to do more work to make the entire project useful. At this point, our Git implementation in Cloudflare Workers could store a repo in a Durable Object and communicate with the outside world via custom HTTP operations (read file, list branches etc.), but it couldn’t communicate using the Git protocol, so we couldn’t use the Git command-line tool to fetch or push.</p><p>libgit2 is an excellent Git library, but it only provides client functionality; server functionality is missing. We couldn’t find any other implementations of Git server functionality on the web to use as a reference. While Git itself implements the server commands receive-pack and upload-pack, porting them to libgit2 proved impossible. The main reason was that the required server commands depended on numerous other source files, and the interfaces between these files appeared poorly defined. Edward Thomson, the maintainer of libgit2, has written<!-- --> <a href="https://www.edwardthomson.com/blog/libgit2-in-2024-the-past.html#and-then-theres-the-server">an excellent article on the history of libgit2</a>, detailing Git’s issues in more depth.</p><p>We abandoned the porting efforts and ended up implementing the missing Git server functionality ourselves by leveraging libgit2’s core functionality, studying all available documentation, and painstakingly investigating Git’s behavior. We also created an extensive integration test suite to ensure the robustness and performance of our Git server.</p><h3>Reproducible builds</h3><p>Compiling native libraries like libgit2 for a specific target platform requires a significant amount of preparation, especially when the library itself needs to be compiled with a modified version of the compiler. We found it cumbersome to maintain the repeatability of the entire build process by manually invoking build commands for each component. Luckily, amazing software built for this exact purpose already exists - enter<!-- --> <a href="https://nixos.org/">Nix</a>, a declarative, purely functional build system which enables reproducible builds.</p><p>We’ve built our build system by utilizing Nix. This allowed us to reproducibly build patched Emscripten, patched libgit2, and the C implementation of our Git server from scratch by invoking just a single command. Not only that, but Nix has also enabled us to fine-tune this build process and make it configurable with flags passed to the build command. We can now build our Git server from scratch targeting the native platform (Linux or Mac), Node.js, or Cloudflare Workers. We can also easily configure whether we want the release or development build of the entire package tree. Additionally, Nix allows us to build only a subtree of packages, enabling us to intervene mid-build to make necessary modifications. The learning curve for Nix is steep, but well worth it. If you’re interested in a similarly powerful tool that’s easier to get started with,<!-- --> <a href="https://flox.dev/">flox is an excellent option</a>.</p><p>We discovered a beautiful, initially unintended consequence of building our package tree with Nix: with a little bit of effort, we could compile a broad array of interesting native libraries to WebAssembly using our modified Emscripten compiler. So far, we’ve compiled zlib, libarchive, and libmagic to Wasm and statically linked them with our Git server. As a result, our Git server can create archives in many different formats (we currently only use zip and tar.gz) and easily detect MIME types for a vast array of stored files.<!-- --> <a href="https://github.com/NixOS/nixpkgs">Nixpkgs</a> <!-- -->is full of Nix scripts for building various software packages, and it was reasonably straightforward to adjust some of them to build to Wasm.</p><p>Finally, we also compiled<!-- --> <a href="https://bellard.org/quickjs/">QuickJS</a> <!-- -->to Wasm using our Nix build system. We use our QuickJS-based service to run JavaScript files with full support for ES modules’ import/export statements in Cloudflare Workers on-demand (more in the next section).</p><h3>Composable capabilities</h3><p>One of the core design principles in our codebase is to invest effort in building powerful, composable capabilities and curate them carefully in our repository. Having a strong set of these capabilities opens up interesting combinations especially when using a platform like Cloudflare Workers, which makes composition easy.</p><p><span>Example #1:</span> We developed our Git server with the intention of serving a single repository from a Durable Object, but after accomplishing this, it was very easy to package the same HTTP endpoints and Wasm and expose it from a plain Worker instead of a Durable Object. This way, we gained the ability to run the same exact Git code in either a persistent context (clients connect to the same Durable Object) or an ephemeral context (clients connect to any Worker closest to them). There are use cases where executing Git functionality in an ephemeral context is useful, and where sending the request to a Durable Object would be the wrong choice. For example, when validating a branch or tag name in the Web UI, there’s no need to reimplement these Git-specific rules in JavaScript if we can expose the exact upstream libgit2 behavior in the ephemeral Worker closest to the Web UI user.</p><p><span>Example #2:</span> If you visit<!-- --> <a href="https://gitlip.com/@nataliemarleny/test-repo/ref/HEAD/main.js">https://gitlip.com/@nataliemarleny/test-repo/ref/HEAD/main.js</a>, you’ll see an option to execute this file by pressing ’play’ on the right. Alternatively, here’s a quick video:</p><p><video height="200" width="100%" controls=""><source src="https://gitlip.com/images/blog/infinite-git-repos-on-cloudflare-workers/video-00.mp4" type="video/mp4">Your browser does not support the video tag.</video></p><p>Several of our composable capabilities work together to achieve the final result:</p><ol><li>api receives the request to execute main.js from the HEAD of the repo.</li><li>api coordinates the services (using<!-- --> <a href="https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/">service bindings</a>).</li><li>git-server service receives a request for an archive of the HEAD of the repo and streams the tar.gz snapshot of the HEAD back to the api.</li><li>api forwards the tar.gz stream to the js-run service (QuickJS-based).</li><li>js-run service unpacks the archive stream into memory.</li><li>js-run service runs the requested file from memory (note that main.js imports fizzbuzz.js!) and streams the response back to the api.</li><li>api streams the response back to the user.</li></ol><p><img src="https://gitlip.com/images/blog/infinite-git-repos-on-cloudflare-workers/image-01.svg" alt=""></p><p>For now, executing JavaScript in an on-demand manner like this is just a showcase of what we can easily achieve with our stack of capabilities, but in the future, we plan to make this more powerful by adding support for importing NPM modules and more.</p><h3>Optimizations</h3><p>Achieving predictable performance from our Git server required applying several optimization techniques. We’ll outline the most important ones.</p><p>Like any other serverless platform, Cloudflare Workers come with their own<!-- --> <a href="https://developers.cloudflare.com/workers/platform/limits/">set of constraints</a>. For the purposes of running a Git server, the most important ones are the Worker size (total size of the deployed code), memory, and CPU limit.</p><p><a href="https://blog.cloudflare.com/workers-pricing-scale-to-zero/">In September 2023</a>, the Worker size limit on the Paid plan was increased from 1MB to 10MB, but Cloudflare still recommends keeping your entire deployment under 1MB for best performance. Our Wasm Git server, along with libgit2, all other libraries, and JavaScript glue code, fits in just 800kB, which we consider to be quite an achievement. We achieved this primarily by optimizing for code size during compilation and trimming the number of file formats our libmagic utility can detect.</p><p>The runtime limit of 128MB of memory initially posed a challenge. libgit2 makes heavy use of memory mapping when reading or writing objects to Git packfiles. Unfortunately, in a Wasm application compiled with Emscripten, memory mapping requires a completely new copy of the file in memory (even if the file is already in memory). This meant our Git server would copy the entire Git packfile into memory when reading even the smallest objects, causing the server’s performance to depend on the packfile size rather than the object size. We attempted to address this by modifying Emscripten, but it proved too difficult, so we opted to modify libgit2 instead. We removed all mmap equivalents and replaced them with read/write equivalents, and the results were incredible. We achieved performance independent of the packfile (repo) size. Note that memory mapping makes total sense in the typical settings for which libgit2 was designed.</p><p>Durable Objects are single-threaded, so one might think it would be difficult to efficiently serve concurrent requests to the same repository. Fortunately, the access patterns to a Git repository are well-suited for optimization with a cache. For this purpose we created a component called ConsistentCache, which wraps around Cloudflare’s HTTP Cache API (available in every Worker and Durable Object) and adds the necessary consistency guarantees. This component also deduplicates calls to the Git Wasm program, issuing a single call and relaying the response to all requestors in parallel. Using this technique, a significant number of requests to the Git server are fulfilled directly from the cache, and any modification to the repository purges this cache consistently.</p><p>Persistent storage in Durable Objects<!-- --> <a href="https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/#part-3-automatic-in-memory-caching">has its own built-in caching layer</a>, which improves overall performance and provides additional consistency guarantees. Unfortunately, all reads that hit this built-in cache are billed the same as accessing the underlying storage. libgit2 specifically, and Git more generally, often need to read small chunks of a file incrementally, resulting in a large number of small reads, which became somewhat expensive during testing. We decided to implement our own storage cache, called StorageEngine, and completely disable the built-in cache. This way, we pay nothing for most of the operations our Git server performs on DOFS, only incurring costs for the occasional flush that writes all inodes and file blocks to storage and for occasional reads that populate the StorageEngine.</p><p>Finally, we optimized the implementation of our bare Git repositories to always contain a very limited (mostly constant) number of directories. This allowed us to preload all directories and pack-index files from the persistent storage (depending on the repo between 20 and 60, each up to a few kB in size) every time the Durable Object is instantiated, effectively pre-warming the repository for any Git command it might receive.</p><pre><code>(log) StorageEngine.get (1/1): [HTTP_CACHE_LRU_MAP]
(log) StorageEngine.get (4/4): [NNID, ..., PRECACHE]
(log) StorageEngine.get (48/48): [N_1, ..., B_463_0]
(log) StorageEngine.get (0/1): [N_1]
(log) StorageEngine.get (0/1): [N_2]
(log) StorageEngine.get (0/1): [N_350]
(log) StorageEngine.get (0/1): [N_3]
(log) StorageEngine.get (0/1): [N_6]
(log) StorageEngine.get (0/1): [N_349]
(log) StorageEngine.get (0/1): [B_349_0]
(log) StorageEngine.get (0/1): [N_10]
(log) StorageEngine.get (0/1): [B_350_0]
(log) StorageEngine.get (0/1): [N_7]
(log) StorageEngine.get (0/1): [N_463]
(log) StorageEngine.get (0/1): [B_463_0]
(log) StorageEngine.get (0/1): [N_5]
(log) StorageEngine.get (0/1): [N_25]
(log) StorageEngine.get (0/1): [N_24]
(log) StorageEngine.get (0/1): [N_4]
(log) StorageEngine.get (0/1): [B_25_0]
... previous line repeated 263 more times
(log) StorageEngine.get (1/1): [B_24_0]
(log) StorageEngine.get (1/1): [B_24_15]
(log) StorageEngine.get (0/1): [B_25_0]
(log) StorageEngine.get (1/1): [B_24_9]
(log) StorageEngine.get (0/1): [B_24_9]
(log) StorageEngine.get (0/1): [B_25_0]
... previous line repeated 8 more times
(log) StorageEngine.get (1/1): [B_24_10]
(log) StorageEngine.get (0/1): [B_24_10]
(log) StorageEngine.get (0/1): [B_24_9]
... previous line repeated 10 more times
(log) StorageEngine.get (0/1): [B_24_10]
(log) StorageEngine.get (0/1): [B_25_0]
... previous line repeated 8 more times
(log) StorageEngine.get (1/1): [B_24_12]
(log) StorageEngine.get (0/1): [B_24_12]
... previous line repeated 30 more times
(log) StorageEngine._syncBufferFinal START
(log) StorageEngine.put (1): [HTTP_CACHE_LRU_MAP]
(log) StorageEngine._syncBufferFinal END
(log) StorageEngine._syncBufferFinal START
(log) StorageEngine._syncBatchPut (1): [HTTP_CACHE_LRU_MAP]
(log) StorageEngine._syncBufferFinal END</code></pre><p>The optimizations above, along with a few others, ensure that the performance of our Git servers is both reasonable and reliable. Small read and write operations (think a typical README.md) over HTTP complete in under 150 ms, even without caching and regardless of the repository size.</p><h3>Limitations</h3><p>For now, our Git server is well-suited for repositories up to about 100 MB in size, which is more than enough for our specific use case. Beyond 100 MB, we encounter a few issues:</p><ol><li>Single-threaded packing and unpacking of Git packfiles during clone, fetch, and push operations exceeds the time limit on requests to Workers if the packfiles are too large.</li><li><a href="https://github.com/whatwg/fetch/issues/1254">Fetch body streams are not full duplex</a>, which unfortunately means that while we can theoretically clone and push any repository in our Git server, we may not be able to fetch from it. This is because the fetch operation in Git’s smart protocol requires a full duplex channel for negotiating the optimal packfile to send. Fortunately, in repositories with up to 32 refs, this negotiation process never occurs.</li><li>Cloudflare Workers support only HTTPs for now - so we can’t support cloning, fetching and pushing over SSH without meaningfully complicating our infrastructure.</li></ol><p>We believe the above limitations are solvable in the long term, and that in the future, we could adjust our Git server to handle repositories of arbitrary size and support SSH.</p><h3>Demo</h3><p>To preview this in production, feel free to explore our Gitlip public profiles:</p><ol><li><a href="https://gitlip.com/@nataliemarleny">https://gitlip.com/@nataliemarleny</a></li><li><a href="https://gitlip.com/@plesiv">https://gitlip.com/@plesiv</a></li></ol><p>Please note that the current performance is constrained by the fact that our primary database is not hosted on Cloudflare, and calls to it dominate the latency of most requests. We expect to reduce the overall latency of most requests by 50% to 75% through further optimizations, which we’ll write about in the future.</p><h3>Future</h3><p>Having a serverless and infinitely horizontally scalable Git server infrastructure opens many possibilities for products built on top of it. We believe Git is underutilized for storage purposes, given its versioning capabilities and the fact that it stores plain files, which can be in any format suitable for the application.</p><p>An additional benefit of achieving a performant Git server in JavaScript and Wasm is the fact that our server already mostly works directly in the browser itself. This opens up exciting possibilities: imagine having a lightweight Git client as part of a<!-- --> <a href="https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps">PWA</a> <!-- -->which can shallowly clone a remote repository to allow local editing even when offline. We plan to explore this further down the line.</p><h3>Conclusion</h3><p>We’re just getting started! Stay up to date with our journey of building<!-- --> <a href="https://gitlip.com/">Gitlip</a> <!-- -->by following<!-- --> <a href="https://x.com/nataliemarleny">@nataliemarleny</a>.</p><p>None of this would be possible without the amazing open-source software and the even more amazing communities and companies that produce it, most notably: libgit2, Emscripten, Nix, and the Cloudflare Workers platform. We’re very grateful to work with such incredible tools.</p><p>Thanks to Edward Thomson (<a href="https://x.com/ethomson">@ethomson</a>), Sunil Pai (<a href="https://x.com/threepointone">@threepointone</a>), Chris Nicholas (<a href="https://x.com/ctnicholasdev">@ctnicholasdev</a>) and Tim Neutkens (<a href="https://x.com/timneutkens">@timneutkens</a>) for reading drafts of this post.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Universal optimality of Dijkstra via beyond-worst-case heaps (182 pts)]]></title>
            <link>https://arxiv.org/abs/2311.11793</link>
            <guid>41947355</guid>
            <pubDate>Fri, 25 Oct 2024 17:19:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.11793">https://arxiv.org/abs/2311.11793</a>, See on <a href="https://news.ycombinator.com/item?id=41947355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.11793">View PDF</a>
    <a href="https://arxiv.org/html/2311.11793v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>This paper proves that Dijkstra's shortest-path algorithm is universally optimal in both its running time and number of comparisons when combined with a sufficiently efficient heap data structure.
<br>Universal optimality is a powerful beyond-worst-case performance guarantee for graph algorithms that informally states that a single algorithm performs as well as possible for every single graph topology. We give the first application of this notion to any sequential algorithm.
<br>We design a new heap data structure with a working-set property guaranteeing that the heap takes advantage of locality in heap operations. Our heap matches the optimal (worst-case) bounds of Fibonacci heaps but also provides the beyond-worst-case guarantee that the cost of extracting the minimum element is merely logarithmic in the number of elements inserted after it instead of logarithmic in the number of all elements in the heap. This makes the extraction of recently added elements cheaper.
<br>We prove that our working-set property is sufficient to guarantee universal optimality, specifically, for the problem of ordering vertices by their distance from the source vertex: The locality in the sequence of heap operations generated by any run of Dijkstra's algorithm on a fixed topology is strong enough that one can couple the number of comparisons performed by any heap with our working-set property to the minimum number of comparisons required to solve the distance ordering problem on this topology.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Richard Hladík [<a href="https://arxiv.org/show-email/03852112/2311.11793">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2311.11793v1">[v1]</a></strong>
        Mon, 20 Nov 2023 14:21:47 UTC (338 KB)<br>
    <strong>[v2]</strong>
        Tue, 9 Apr 2024 23:33:15 UTC (340 KB)<br>
</p></div></div>]]></description>
        </item>
    </channel>
</rss>