<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 16 Feb 2026 17:30:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Running My Own XMPP Server (130 pts)]]></title>
            <link>https://blog.dmcc.io/journal/xmpp-turn-stun-coturn-prosody/</link>
            <guid>47034801</guid>
            <pubDate>Mon, 16 Feb 2026 13:39:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.dmcc.io/journal/xmpp-turn-stun-coturn-prosody/">https://blog.dmcc.io/journal/xmpp-turn-stun-coturn-prosody/</a>, See on <a href="https://news.ycombinator.com/item?id=47034801">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Notes from setting up Prosody in Docker for federated messaging, with file sharing, voice calls, and end-to-end encryption.</p><section><p>About a year ago I <a href="https://blog.dmcc.io/journal/2025_my_privacy_reboot/">moved my personal messaging to Signal</a> as part of a broader push to take ownership of my digital life. That went well. Most of my contacts made the switch, and I’m now at roughly 95% Signal for day-to-day conversations. But Signal is still one company running one service. If they shut down tomorrow or change direction, I’m back to square one.</p><p>XMPP fixes that. It’s federated, meaning your server talks to other XMPP servers automatically and you’re never locked into a single provider. Your messages live on your hardware. The protocol has been around since 1999 and it’s not going anywhere. I’d tried XMPP years ago and bounced off it, but the clients have come a long way since then. <a href="https://monal-im.org/">Monal</a> and <a href="https://conversations.im/">Conversations</a> are genuinely nice to use now.</p><p>This post covers everything I did to get a fully working XMPP server running with <a href="https://prosody.im/">Prosody</a> in Docker, from DNS records through to voice calls.</p><h2 id="prerequisites">Prerequisites</h2><ul><li>A server with Docker and Docker Compose</li><li>A domain you control</li><li>TLS certificates (Let’s Encrypt works well)</li></ul><h2 id="dns-records">DNS records</h2><p>XMPP uses SRV records to let clients and other servers find yours. You’ll need these in your DNS:</p><div><pre><code data-lang="fallback">_xmpp-client._tcp.xmpp.example.com  SRV  0 5 5222 xmpp.example.com.
_xmpp-server._tcp.xmpp.example.com  SRV  0 5 5269 xmpp.example.com.
</code></pre></div><p>Port 5222 is for client connections, 5269 is for server-to-server federation. You’ll also want an A record pointing <code>xmpp.example.com</code> to your server’s IP.</p><p>If you want HTTP file uploads (I’d recommend it), add a CNAME or A record for <code>upload.xmpp.example.com</code> pointing to the same server. Same for <code>conference.xmpp.example.com</code> if you want group chats with a clean subdomain, though Prosody handles this internally either way.</p><h2 id="tls-certificates">TLS certificates</h2><p>Prosody won’t start without certificates. I use Let’s Encrypt with the Cloudflare DNS challenge so I don’t need to expose port 80:</p><div><pre><code data-lang="bash">docker run --rm <span>\
</span><span></span>  -v ~/docker/xmpp/certs:/etc/letsencrypt <span>\
</span><span></span>  -v ~/docker/xmpp/cloudflare.ini:/etc/cloudflare.ini:ro <span>\
</span><span></span>  certbot/dns-cloudflare certonly <span>\
</span><span></span>  --dns-cloudflare <span>\
</span><span></span>  --dns-cloudflare-credentials /etc/cloudflare.ini <span>\
</span><span></span>  -d xmpp.example.com
</code></pre></div><p>The <code>cloudflare.ini</code> file contains your API token:</p><div><pre><code data-lang="ini"><span>dns_cloudflare_api_token</span> <span>=</span> <span>your-cloudflare-api-token</span>
</code></pre></div><p>After certbot runs, fix the permissions so Prosody can read the certs:</p><div><pre><code data-lang="bash">chmod -R <span>755</span> ~/docker/xmpp/certs/live/ ~/docker/xmpp/certs/archive/
chmod <span>644</span> ~/docker/xmpp/certs/archive/xmpp.example.com/*.pem
</code></pre></div><p>Set up a cron to renew monthly:</p><div><pre><code data-lang="bash"><span>0</span> <span>3</span> <span>1</span> * * docker run --rm -v ~/docker/xmpp/certs:/etc/letsencrypt <span>\
</span><span></span>  -v ~/docker/xmpp/cloudflare.ini:/etc/cloudflare.ini:ro <span>\
</span><span></span>  certbot/dns-cloudflare renew <span>\
</span><span></span>  --dns-cloudflare-credentials /etc/cloudflare.ini <span>\
</span><span></span>  <span>&amp;&amp;</span> docker restart xmpp
</code></pre></div><h2 id="the-docker-setup">The Docker setup</h2><p>The <code>docker-compose.yml</code>:</p><div><pre><code data-lang="yaml"><span>services</span>:<span>
</span><span>  </span><span>prosody</span>:<span>
</span><span>    </span><span>image</span>:<span> </span>prosodyim/prosody:<span>13.0</span><span>
</span><span>    </span><span>container_name</span>:<span> </span>xmpp<span>
</span><span>    </span><span>restart</span>:<span> </span>unless-stopped<span>
</span><span>    </span><span>ports</span>:<span>
</span><span>      </span>- <span>"5222:5222"</span><span>
</span><span>      </span>- <span>"5269:5269"</span><span>
</span><span>    </span><span>volumes</span>:<span>
</span><span>      </span>- prosody-data:/var/lib/prosody<span>
</span><span>      </span>- ./prosody.cfg.lua:/etc/prosody/prosody.cfg.lua:ro<span>
</span><span>      </span>- ./certs/live/xmpp.example.com/fullchain.pem:/etc/prosody/certs/xmpp.example.com.crt:ro<span>
</span><span>      </span>- ./certs/live/xmpp.example.com/privkey.pem:/etc/prosody/certs/xmpp.example.com.key:ro<span>
</span><span>
</span><span></span><span>volumes</span>:<span>
</span><span>  </span><span>prosody-data</span>:<span>
</span></code></pre></div><p>Two ports exposed: 5222 for clients, 5269 for federation. The data volume holds user accounts and message archives. Config and certs are mounted read-only.</p><h2 id="prosody-configuration">Prosody configuration</h2><p>This is the core of it. I’ll walk through the key sections rather than dumping the whole file.</p><h3 id="modules">Modules</h3><p>Prosody is modular. My module list:</p><div><pre><code data-lang="lua">modules_enabled <span>=</span> {
    <span>-- Core</span>
    <span>"roster"</span>; <span>"saslauth"</span>; <span>"tls"</span>; <span>"dialback"</span>; <span>"disco"</span>;
    <span>"posix"</span>; <span>"ping"</span>; <span>"register"</span>; <span>"time"</span>; <span>"uptime"</span>; <span>"version"</span>;

    <span>-- Security</span>
    <span>"blocklist"</span>;

    <span>-- Multi-device &amp; mobile</span>
    <span>"carbons"</span>; <span>"csi_simple"</span>;
    <span>"smacks"</span>;         <span>-- Stream Management (reliable delivery)</span>
    <span>"cloud_notify"</span>;   <span>-- Push notifications for mobile</span>

    <span>-- Message archive</span>
    <span>"mam"</span>;

    <span>-- User profiles &amp; presence</span>
    <span>"vcard_legacy"</span>; <span>"pep"</span>; <span>"bookmarks"</span>;

    <span>-- Admin</span>
    <span>"admin_shell"</span>;
}
</code></pre></div><p>The ones I found matter most for a good mobile experience: <code>carbons</code> syncs messages across all your devices instead of delivering to whichever one happened to be online. <code>smacks</code> (Stream Management) handles flaky connections gracefully, so messages aren’t lost when your phone briefly drops signal. <code>cloud_notify</code> enables push notifications so mobile clients don’t need a persistent connection, which is essential for battery life. And <code>mam</code> (Message Archive Management) stores history server-side for search and cross-device sync.</p><h3 id="security-settings">Security settings</h3><div><pre><code data-lang="lua">c2s_require_encryption <span>=</span> <span>true</span>
s2s_require_encryption <span>=</span> <span>true</span>
s2s_secure_auth <span>=</span> <span>true</span>
authentication <span>=</span> <span>"internal_hashed"</span>
allow_registration <span>=</span> <span>false</span>
</code></pre></div><p>All connections are encrypted and registration is disabled since I create accounts manually with <code>prosodyctl</code>. I’ve enabled <code>s2s_secure_auth</code>, which means Prosody will reject connections from servers with self-signed or misconfigured certificates. You’ll lose federation with some poorly configured servers, but if you’re self-hosting for privacy reasons it doesn’t make much sense to relax authentication for other people’s mistakes.</p><h3 id="omemo-encryption">OMEMO encryption</h3><p>TLS encrypts connections in transit, but the server itself can still read your messages. If you’re self-hosting, that means you’re trusting yourself, which is fine. But if other people use your server, or if you just want the belt-and-braces approach, OMEMO adds end-to-end encryption so that not even the server operator can read message content.</p><p>OMEMO is built on the same encryption that Signal uses, so I’m comfortable trusting it. There’s nothing to configure on the server side either. OMEMO is handled entirely by the clients. Monal, Conversations, and Gajim all support it, and in most cases it’s enabled by default for new conversations. I’d recommend turning it on for everything and leaving it on.</p><h3 id="message-archive">Message archive</h3><div><pre><code data-lang="lua">archive_expires_after <span>=</span> <span>"1y"</span>
default_archive_policy <span>=</span> <span>true</span>
</code></pre></div><p>Messages are kept for a year and archiving is on by default. Clients can opt out per-conversation if they want.</p><h3 id="http-for-file-uploads">HTTP for file uploads</h3><div><pre><code data-lang="lua">http_interfaces <span>=</span> { <span>"*"</span> }
http_ports <span>=</span> { <span>5280</span> }
https_ports <span>=</span> { }
http_external_url <span>=</span> <span>"https://xmpp.example.com"</span>
</code></pre></div><p>Prosody serves HTTP on port 5280 internally. I leave HTTPS to my reverse proxy (Caddy), which handles TLS termination. The <code>http_external_url</code> tells Prosody what URL to hand clients when they upload files.</p><h3 id="virtual-host-and-components">Virtual host and components</h3><div><pre><code data-lang="lua">VirtualHost <span>"xmpp.example.com"</span>
    ssl <span>=</span> {
        key <span>=</span> <span>"/etc/prosody/certs/xmpp.example.com.key"</span>;
        certificate <span>=</span> <span>"/etc/prosody/certs/xmpp.example.com.crt"</span>;
    }

Component <span>"conference.xmpp.example.com"</span> <span>"muc"</span>
    modules_enabled <span>=</span> { <span>"muc_mam"</span> }
    restrict_room_creation <span>=</span> <span>"local"</span>

Component <span>"upload.xmpp.example.com"</span> <span>"http_file_share"</span>
    http_file_share_size_limit <span>=</span> <span>10485760</span>    <span>-- 10 MB</span>
    http_file_share_expires_after <span>=</span> <span>2592000</span>  <span>-- 30 days</span>
    http_external_url <span>=</span> <span>"https://xmpp.example.com"</span>
</code></pre></div><p>The MUC (Multi-User Chat) component gives you group chats with message history via <code>muc_mam</code>. I restrict room creation to local users so random federated accounts can’t spin up rooms on my server.</p><p>The file share component handles image and file uploads. A 10 MB limit and 30-day expiry keeps disk usage under control.</p><h2 id="reverse-proxy-for-file-uploads">Reverse proxy for file uploads</h2><p>Prosody’s HTTP port needs to be reachable from the internet for file uploads to work. I use Caddy:</p><div><pre><code data-lang="fallback">xmpp.example.com {
    reverse_proxy xmpp:5280
}
</code></pre></div><p>When a client sends an image, Prosody hands it a URL like <code>https://xmpp.example.com/upload/...</code> and the receiving client fetches it over HTTPS.</p><h2 id="creating-accounts">Creating accounts</h2><p>With registration disabled, accounts are created from the command line:</p><div><pre><code data-lang="bash">docker <span>exec</span> -it xmpp prosodyctl adduser danny@xmpp.example.com
</code></pre></div><p>It prompts for a password. Done. Log in from any XMPP client.</p><h2 id="firewall">Firewall</h2><p>Open the XMPP ports:</p><div><pre><code data-lang="bash">sudo ufw allow <span>5222</span> comment <span>'XMPP client'</span>
sudo ufw allow <span>5269</span> comment <span>'XMPP federation'</span>
</code></pre></div><p>Port 80/443 for the reverse proxy if you haven’t already. If your server is behind a router, forward 5222 and 5269.</p><h2 id="voice-and-video-calls">Voice and video calls</h2><p>Text and file sharing work at this point. Voice and video calls need one more piece: a TURN/STUN server. Without it, clients behind NAT can’t establish direct media connections.</p><p>I run <a href="https://github.com/coturn/coturn">coturn</a> alongside Prosody. The two share a secret, and Prosody generates temporary credentials for clients automatically.</p><p>Generate a shared secret:</p><p>The coturn <code>docker-compose.yml</code>:</p><div><pre><code data-lang="yaml"><span>services</span>:<span>
</span><span>  </span><span>coturn</span>:<span>
</span><span>    </span><span>image</span>:<span> </span>coturn/coturn:latest<span>
</span><span>    </span><span>container_name</span>:<span> </span>coturn<span>
</span><span>    </span><span>restart</span>:<span> </span>unless-stopped<span>
</span><span>    </span><span>network_mode</span>:<span> </span>host<span>
</span><span>    </span><span>volumes</span>:<span>
</span><span>      </span>- ./turnserver.conf:/etc/coturn/turnserver.conf:ro<span>
</span><span>    </span><span>tmpfs</span>:<span>
</span><span>      </span>- /var/lib/coturn<span>
</span></code></pre></div><p>It runs with <code>network_mode: host</code> because TURN needs real network interfaces to handle NAT traversal. Docker’s port mapping breaks this.</p><p>The <code>turnserver.conf</code>:</p><div><pre><code data-lang="fallback">listening-port=3478
tls-listening-port=5349
min-port=49152
max-port=49200
relay-threads=2
realm=xmpp.example.com
use-auth-secret
static-auth-secret=YOUR_SECRET_HERE
no-multicast-peers
no-cli
no-tlsv1
no-tlsv1_1
denied-peer-ip=10.0.0.0-10.255.255.255
denied-peer-ip=172.16.0.0-172.31.255.255
denied-peer-ip=192.168.0.0-192.168.255.255
log-file=stdout
</code></pre></div><p>If your server is behind NAT, add:</p><div><pre><code data-lang="fallback">external-ip=YOUR_PUBLIC_IP/YOUR_PRIVATE_IP
</code></pre></div><p>Then tell Prosody about it. Add <code>"turn_external"</code> to your modules, and inside the <code>VirtualHost</code> block:</p><div><pre><code data-lang="lua">    turn_external_host <span>=</span> <span>"xmpp.example.com"</span>
    turn_external_port <span>=</span> <span>3478</span>
    turn_external_secret <span>=</span> <span>"YOUR_SECRET_HERE"</span>
</code></pre></div><p>Open the firewall ports:</p><div><pre><code data-lang="bash">sudo ufw allow <span>3478</span> comment <span>'STUN/TURN'</span>
sudo ufw allow <span>5349</span> comment <span>'TURNS'</span>
sudo ufw allow 49152:49200/udp comment <span>'TURN relay'</span>
</code></pre></div><p>Verify with <code>docker exec xmpp prosodyctl check turn</code>.</p><h2 id="clients">Clients</h2><p>On iOS I went with <a href="https://monal-im.org/">Monal</a>, which is open source and supports all the modern XEPs. Push notifications work well. On Android, <a href="https://conversations.im/">Conversations</a> seems to be the go-to. On desktop, <a href="https://gajim.org/">Gajim</a> covers Linux and Windows, and Monal has a macOS build.</p><p>All of them support OMEMO encryption, file sharing, group chats, and voice/video calls.</p><h2 id="verifying-your-setup">Verifying your setup</h2><p>Prosody has solid built-in diagnostics:</p><div><pre><code data-lang="bash">docker <span>exec</span> xmpp prosodyctl check
</code></pre></div><p>This checks DNS records, TLS certificates, connectivity, and module configuration. Fix anything it flags. The error messages are genuinely helpful.</p><p>The <a href="https://compliance.conversations.im/">XMPP Compliance Tester</a> is worth running too. Mine scored above 90% after getting the config right.</p><h2 id="final-thoughts">Final thoughts</h2><p>The whole setup runs in two small Docker containers and a reverse proxy entry. Prosody, file uploads, message archive, push notifications, group chats, voice calls.</p><p>I still use Signal for most day-to-day conversations and I’m not planning to stop. But having my own XMPP server means I’m not entirely dependent on any single service. I can message anyone on any XMPP server, not just people who signed up to the same one. It’s a nice fallback to have.</p><p>If you’re already running Docker on a server somewhere, it’s a good weekend project.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ministry of Justice orders deletion of the UK's largest court reporting database (297 pts)]]></title>
            <link>https://www.legalcheek.com/2026/02/ministry-of-justice-orders-deletion-of-the-uks-largest-court-reporting-database/</link>
            <guid>47034713</guid>
            <pubDate>Mon, 16 Feb 2026 13:30:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.legalcheek.com/2026/02/ministry-of-justice-orders-deletion-of-the-uks-largest-court-reporting-database/">https://www.legalcheek.com/2026/02/ministry-of-justice-orders-deletion-of-the-uks-largest-court-reporting-database/</a>, See on <a href="https://news.ycombinator.com/item?id=47034713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                    <p><img alt="Avatar photo" src="https://www.legalcheek.com/wp-content/uploads/2023/08/cropped-legal-cheek-logo-up-and-down-96x96.jpeg" srcset="https://www.legalcheek.com/wp-content/uploads/2023/08/cropped-legal-cheek-logo-up-and-down-192x192.jpeg 2x" height="96" width="96" decoding="async">                    </p>

                    <p>By  on <time datetime="2026-02-11">Feb 11 2026 11:30am</time></p>
                </div><div>
            <p>Blow for open justice</p>
<p><img fetchpriority="high" decoding="async" src="https://www.legalcheek.com/wp-content/uploads/2024/10/AdobeStock_110501092-2.jpeg" alt="" width="800" height="423" srcset="https://www.legalcheek.com/wp-content/uploads/2024/10/AdobeStock_110501092-2.jpeg 800w, https://www.legalcheek.com/wp-content/uploads/2024/10/AdobeStock_110501092-2-300x159.jpeg 300w, https://www.legalcheek.com/wp-content/uploads/2024/10/AdobeStock_110501092-2-768x406.jpeg 768w, https://www.legalcheek.com/wp-content/uploads/2024/10/AdobeStock_110501092-2-360x190.jpeg 360w" sizes="(max-width: 800px) 100vw, 800px"><br>
<strong>A digital archive that helped journalists track criminal court cases is being shut down by the Ministry of Justice.</strong></p>
<p>Courtsdesk will reportedly be deleted within days after HM Courts &amp; Tribunals Service ordered every record wiped. The platform had been used by more than 1,500 reporters from 39 media outlets to search magistrates’ court lists and registers, but the move has triggered warnings that important cases could now go unreported.</p>
<p>Courtsdesk says it repeatedly found the media wasn’t being told about hearings, with two-thirds of courts regularly hearing cases without notifying journalists. </p>
<p>The platform was launched in 2020 following an agreement with HMCTS and approval by the Lord Chancellor and former Justice Minister Chris Philp, but HMCTS issued a cessation notice in November citing “unauthorised sharing” of court information.</p>

<p>Courtsdesk founder Enda Leahy said the company wrote to government agencies 16 times trying to save the service. It asked for the matter to be referred to the Information Commissioner’s Office but says that request went nowhere, and former Philp himself approached current courts minister Sarah Sackman asking for the archive not to be deleted. The government refused last week.</p>
<p>Leahy told <em>The Times</em> that HMCTS couldn’t do what Courtsdesk did. She pointed to figures showing the court service’s own records were accurate just 4.2% of the time and that 1.6 million criminal hearings went ahead without any advance notice to the press.</p>
<p>“We built the only system that could tell journalists what was actually happening in the criminal courts,” she said.</p>
<p>An HMCTS spokesperson said the press would continue to have full access to court information to support accurate reporting.</p>
<blockquote>
<p lang="en" dir="ltr">HMCTS acted to protect sensitive data after CourtsDesk sent information to a third-party AI company. </p>
<p>Journalists’ access to court information has not been affected: listings and records remain available. <a href="https://t.co/4KWlpCcaAq">pic.twitter.com/4KWlpCcaAq</a></p>
<p>— Ministry of Justice (@MoJGovUK) <a href="https://twitter.com/MoJGovUK/status/2021324797016219758?ref_src=twsrc%5Etfw">February 10, 2026</a></p></blockquote>

        </div><div>

            <p>
                <h2>Related Stories</h2>
            </p>

            <div>
                <div>
    <p><a href="https://www.legalcheek.com/2026/01/government-targets-law-firms-client-account-interest-to-help-fund-justice-system/">
        <img width="360" height="190" src="https://www.legalcheek.com/wp-content/uploads/2025/11/pro-bono-360x190.jpeg" alt="" decoding="async" loading="lazy">    </a></p>
</div><div>
    <p><a href="https://www.legalcheek.com/2025/02/inaccurate-media-lead-to-judicial-death-threats-says-lady-chief-justice/">
        <img width="360" height="190" src="https://www.legalcheek.com/wp-content/uploads/2025/02/Dame_Sue_Carr_2022-360x190.jpeg" alt="" decoding="async" loading="lazy">    </a></p>
</div>            </div>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thanks a lot, AI: Hard drives are sold out for the year, says WD (260 pts)]]></title>
            <link>https://mashable.com/article/ai-hard-drive-hdd-shortages-western-digital-sold-out</link>
            <guid>47034192</guid>
            <pubDate>Mon, 16 Feb 2026 12:28:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mashable.com/article/ai-hard-drive-hdd-shortages-western-digital-sold-out">https://mashable.com/article/ai-hard-drive-hdd-shortages-western-digital-sold-out</a>, See on <a href="https://news.ycombinator.com/item?id=47034192">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="article" data-autopogo="">
                                                            <p>Looking to buy a new hard drive? Get ready to pay even more this year.</p><p>According to Western Digital, one of the world's biggest hard drive manufacturers, the company has already sold out of its storage capacity for 2026 with more than 10 months still left in the year.</p><p>"We're pretty much sold out for calendar 2026," <a href="https://www.tweaktown.com/news/110168/western-digital-runs-out-of-hdd-capacity-ceo-says-massive-ai-deals-secured-price-surges-ahead/index.html" target="_blank" data-ga-click="1" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body" title="(opens in a new window)"><u>said</u></a> Western Digital CEO Irving Tan on the company's recent quarterly <a href="https://investor.wdc.com/events/event-details/western-digital-second-quarter-fiscal-2026-earnings-call" target="_blank" data-ga-click="1" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body" title="(opens in a new window)"><u>earnings call</u></a>.&nbsp;</p>
<p>Tan shared that most of the storage space has been allocated to its "top seven customers." Three of these companies already have agreements with Western Digital for 2027 and even 2028.&nbsp;</p><section x-data="window.newsletter({ isDeal: false })" x-init="init()" aria-label="Newsletter Sign-Up">
        <p><span>Mashable Light Speed</span>
        </p>
        
    </section>

<p>Furthermore, the incentive for these hardware companies to prioritize the average consumer is also dwindling. According to Western Digital, thanks to a surge in demand from its enterprise customers, the consumer market now accounts for just 5 percent of the company's revenue.</p><p>AI companies have been eating up computer hardware as industry growth accelerates. Prices for products ranging from computer processors to video game consoles have skyrocketed due to these AI companies cannibalizing supply chains.</p><p>The tech industry has already been experiencing <a href="https://mashable.com/article/micron-memory-ram-shortage-not-ending-soon-ai" target="_blank" data-ga-click="1" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body"><u>a shortage of memory</u></a>&nbsp;due to&nbsp;demand from AI companies. PC makers have been forced to <a href="https://mashable.com/article/framework-price-hike-ddr5-ram-memory-shortage" target="_blank" data-ga-click="1" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body"><u>raise RAM prices</u></a>&nbsp;on a near-regular basis as shortages persist. Video game console makers, like Sony, have even <a href="https://mashable.com/article/playstation-6-delayed-report-memory-shortages" target="_blank" data-ga-click="1" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body"><u>reportedly</u></a> considered pushing the next PlayStation launch beyond the planned 2027 release in hopes that AI-related hardware shortages would be resolved by then.</p><p>With this latest news from Western Digital, it appears the ever-increasing demands from AI companies for memory and storage will continue to grow, with no end in sight. Unless, of course, investors decide to <a href="https://mashable.com/article/ai-bubble-watch-tech-stocks-down" target="_blank" data-ga-click="1" data-ga-label="$text" data-ga-item="text-link" data-ga-module="content_body"><u>pull back</u></a> from AI over fears that AI's promises may not come to fruition. But, for now at least, the shortages – and price hikes for consumers – will continue.</p>

                                                                
                                    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Israeli spyware firm that accidentally just exposed itself (210 pts)]]></title>
            <link>https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally</link>
            <guid>47033976</guid>
            <pubDate>Mon, 16 Feb 2026 12:00:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally">https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally</a>, See on <a href="https://news.ycombinator.com/item?id=47033976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!IWq3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!IWq3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 424w, https://substackcdn.com/image/fetch/$s_!IWq3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 848w, https://substackcdn.com/image/fetch/$s_!IWq3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!IWq3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!IWq3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg" width="1200" height="781" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:781,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:118333,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://ahmedeldin.substack.com/i/187749296?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!IWq3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 424w, https://substackcdn.com/image/fetch/$s_!IWq3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 848w, https://substackcdn.com/image/fetch/$s_!IWq3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!IWq3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42bb89bb-8aa4-420b-8831-a4ae10887d15_1200x781.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Israeli surveillance company Paragon Solutions briefly exposed its own spyware dashboard on LinkedIn, revealing the hidden architecture of a billion-dollar surveillance empire built on the backs of journalists, activists, and ordinary people.</p><p>The technical slip-up is a moment of rare transparency in an industry built on secrecy, exposing the operational interface used to compromise devices, intercept communications, and harvest data from targets worldwide.</p><p><a href="https://techcrunch.com/2024/02/paragon-solutions-acquisition-900-million/" rel="">The $900 million acquisition of Paragon by U.S.</a><span> private equity firm AE Industrial Partners tells you everything you need to know about who profits from your digital insecurity. </span><a href="https://www.calcalistech.com/tech/article/byh2r8r0t" rel="">Former Israeli Prime Minister Ehud Barak reportedly pocketed $10-15 million from the deal</a><span>, a tidy sum for a politician-turned-surveillance capitalist. </span></p><p>What the LinkedIn photos show is chilling: a Czech phone number labeled “Valentina,” interception logs marked “Completed,” and application-level data categories targeting encrypted services. This isn’t some theoretical cybersecurity threat, it is the real-time dashboard of the modern surveillance capitalism system we endure.</p><p data-attrs="{&quot;url&quot;:&quot;https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><a href="https://x.com/jsrailton?lang=en" rel="">John Scott-Railton</a><span>, a senior researcher at the University of Toronto’s Citizen Lab, described the disclosure as an “epic OPSEC fail,” highlighting how the operational-security discipline on which the commercial spyware industry depends had been violated.</span></p><a href="https://x.com/jsrailton/status/2021647308790911384" target="_blank" rel="noopener noreferrer" data-component-name="Twitter2ToDOM"><div data-attrs="{&quot;url&quot;:&quot;https://x.com/jsrailton/status/2021647308790911384&quot;,&quot;full_text&quot;:&quot;Epic OPSEC fail by Paragon  exposing Graphite spyware capabilities.\n\nAnnotated pic from what we know.\n\nPlease help me figure out the other apps in in this pic that the spyware can access:\n\n<span class=\&quot;tweet-fake-link\&quot;>#WhatsApp</span>\n<span class=\&quot;tweet-fake-link\&quot;>#Telegram</span>\n<span class=\&quot;tweet-fake-link\&quot;>#Signal</span>\n?\n<span class=\&quot;tweet-fake-link\&quot;>#Line</span>?\n ?\n<span class=\&quot;tweet-fake-link\&quot;>#Snapchat</span>?\n<span class=\&quot;tweet-fake-link\&quot;>#TikTok</span>?&quot;,&quot;username&quot;:&quot;jsrailton&quot;,&quot;name&quot;:&quot;John Scott-Railton&quot;,&quot;profile_image_url&quot;:&quot;https://pbs.substack.com/profile_images/1648379486688231453/Wfi5gqVC_normal.jpg&quot;,&quot;date&quot;:&quot;2026-02-11T18:07:33.000Z&quot;,&quot;photos&quot;:[{&quot;img_url&quot;:&quot;https://pbs.substack.com/media/HA5T-uhboAAD2xT.jpg&quot;,&quot;link_url&quot;:&quot;https://t.co/01KQQSGm3X&quot;}],&quot;quoted_tweet&quot;:{&quot;full_text&quot;:&quot;The general counsel of Paragon, uploaded a picture on Linkedin today showing the Paragon spyware control panel.\n\nThe panel shows a phone number in Czechia, Apps, Accounts, media on the phone, the interception status and numbers extracted from various apps.&quot;,&quot;username&quot;:&quot;DrWhax&quot;,&quot;name&quot;:&quot;Jurre van Bergen&quot;,&quot;profile_image_url&quot;:&quot;https://pbs.substack.com/profile_images/1772672414582751234/cntuFXJt_normal.jpg&quot;},&quot;reply_count&quot;:67,&quot;retweet_count&quot;:531,&quot;like_count&quot;:2423,&quot;impression_count&quot;:381982,&quot;expanded_url&quot;:null,&quot;video_url&quot;:null,&quot;belowTheFold&quot;:false}"><div><div title="User"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!3RU0!,w_40,h_40,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg 40w, https://substackcdn.com/image/fetch/$s_!3RU0!,w_80,h_80,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg 80w, https://substackcdn.com/image/fetch/$s_!3RU0!,w_120,h_120,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg 120w" sizes="40px"><img src="https://substackcdn.com/image/fetch/$s_!3RU0!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg" sizes="40px" alt="X avatar for @jsrailton" srcset="https://substackcdn.com/image/fetch/$s_!3RU0!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg 40w, https://substackcdn.com/image/fetch/$s_!3RU0!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg 80w, https://substackcdn.com/image/fetch/$s_!3RU0!,w_120,h_120,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1648379486688231453%2FWfi5gqVC.jpg 120w" width="40" height="40" draggable="false"></picture></div><p><span>John Scott-Railton</span><span>@jsrailton</span></p><svg role="img" style="height:20px;width:20px;" width="20" height="20" viewBox="0 0 20 20" fill="var(--color-fg-primary)" stroke-width="1.8" stroke="#000" xmlns="http://www.w3.org/2000/svg"><g><title></title><path stroke="none" fill-rule="evenodd" clip-rule="evenodd" d="M13.2879 19.1666L8.66337 12.575L2.87405 19.1666H0.424805L7.57674 11.0258L0.424805 0.833252H6.71309L11.0717 7.04577L16.5327 0.833252H18.982L12.1619 8.59699L19.5762 19.1666H13.2879ZM16.0154 17.3083H14.3665L3.93176 2.69159H5.58092L9.7601 8.54422L10.4828 9.55981L16.0154 17.3083Z"></path></g></svg></div><p>Epic OPSEC fail by Paragon  exposing Graphite spyware capabilities.

Annotated pic from what we know.

Please help me figure out the other apps in in this pic that the spyware can access:

<span>#WhatsApp</span>
<span>#Telegram</span>
<span>#Signal</span>
?
<span>#Line</span>?
 ?
<span>#Snapchat</span>?
<span>#TikTok</span>?</p><p><img src="https://pbs.substack.com/media/HA5T-uhboAAD2xT.jpg"></p><div><div><div title="User"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!R4Tm!,w_20,h_20,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg 20w, https://substackcdn.com/image/fetch/$s_!R4Tm!,w_40,h_40,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg 40w, https://substackcdn.com/image/fetch/$s_!R4Tm!,w_60,h_60,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg 60w" sizes="20px"><img src="https://substackcdn.com/image/fetch/$s_!R4Tm!,w_20,h_20,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg" sizes="20px" alt="X avatar for @DrWhax" srcset="https://substackcdn.com/image/fetch/$s_!R4Tm!,w_20,h_20,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg 20w, https://substackcdn.com/image/fetch/$s_!R4Tm!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg 40w, https://substackcdn.com/image/fetch/$s_!R4Tm!,w_60,h_60,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1772672414582751234%2FcntuFXJt.jpg 60w" width="20" height="20" draggable="false"></picture></div><p><span>Jurre van Bergen</span> <span>@DrWhax</span></p></div><p>The general counsel of Paragon, uploaded a picture on Linkedin today showing the Paragon spyware control panel.

The panel shows a phone number in Czechia, Apps, Accounts, media on the phone, the interception status and numbers extracted from various apps.</p></div><div><p><span>6:07 PM · Feb 11, 2026</span><span> · </span><span>382K Views</span></p><p><span>67 Replies</span><span> · </span><span>531 Reposts</span><span> · </span><span>2.42K Likes</span></p></div></div></a><p><span>Paragon’s flagship product, </span><a href="https://citizenlab.ca/research/a-first-look-at-paragons-proliferating-spyware-operations/" rel="">Graphite</a><span>, represents the cutting edge of what researchers call “mercenary spyware”— highly targeted intrusion systems sold exclusively to state agencies. Unlike conventional malware, these platforms are engineered for precision, using </span><a href="https://www.lrqa.com/en/insights/articles/an-introduction-to-zero-click-attacks/" rel="">zero-click exploit chains</a><span> that compromise devices without any action from the target.</span></p><p>Once installed, spyware operates at the operating-system level, granting operators visibility into:</p><ul><li><p>Stored data and communications</p></li><li><p>Microphone and camera activation</p></li><li><p>Enclosed applications and services</p></li><li><p>Messages accessed before encryption or after decryption</p></li></ul><p><span>The secure boundaries that millions rely on including encrypted chats, locked apps, protected accounts dissolve once the device itself is compromised.</span><a href="https://www.bitdefender.com/en-us/blog/hotforsecurity/nso-groups-spyware-installed-iphones-al-jazeera-employees-using-zero-day-exploit" rel=""> Even if Paragon executives call this “lawful access”,</a><span> we all know there is nothing lawful about accessing someone’s entire digital life without their knowledge or consent?</span></p><p data-attrs="{&quot;url&quot;:&quot;https://ahmedeldin.substack.com/subscribe&quot;,&quot;text&quot;:&quot;Become A Paid Subscriber&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://ahmedeldin.substack.com/subscribe" rel=""><span>Become A Paid Subscriber</span></a></p><p><span>After NSO Group’s </span><a href="https://www.aljazeera.com/news/2021/12/3/us-officials-phones-hacked-nso-group-spyware-reuters" rel="">Pegasus spyware generated global outrage</a><span> by targeting journalists and dissidents, Paragon tried to position itself as the “ethical” alternative—a “light-touch” approach operating “within apps” rather than compromising the entire device.</span></p><div id="youtube2-b6VxWBXuEGM" data-attrs="{&quot;videoId&quot;:&quot;b6VxWBXuEGM&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/b6VxWBXuEGM?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p><a href="https://citizenlab.ca/research/first-forensic-confirmation-of-paragons-ios-mercenary-spyware-finds-journalists-targeted/" rel="">Independent researchers at Citizen Lab have repeatedly debunked this distinction. </a><span>Once spyware achieves device-level persistence, access pathways inevitably extend beyond the narrow confines vendors claim and describe. </span></p><p>The technical reality is clear: if you can compromise a device, you can access everything. </p><p>Laws and court precedents consider full device compromise as extraordinarily invasive, creating strict legal requirements. By describing their capabilities as 'selective' rather than 'systemic,' spyware vendors strategically frame their intrusion as less severe to navigate around these legal barriers and avoid meaningful oversight."</p><p><a href="https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages" rel="">Applications like WhatsApp are widely understood as privacy-preserving technologies.</a><span> End-to-end encryption, Meta has long argued, ensures that only communicating users can read messages or access calls. For hundreds of millions of people, that assurance functions as a baseline assumption of digital safety.</span></p><p>Disclosures over the past year have repeatedly unsettled that belief.</p><p><span>In early 2025, </span><a href="https://about.fb.com/news/2025/01/whatsapp-security-update/" rel="">Meta notified roughly 90 WhatsApp users that their devices had been targeted with spyware linked to Paragon.</a><span> The victims reportedly included journalists and members of civil society—individuals whose communications are often politically sensitive and professionally vulnerable.</span></p><p>Researchers have emphasized that infections associated with mercenary spyware frequently occur without user interaction. There are no malicious links to click, no suspicious files to download. Devices are compromised through exploit chains operating below the threshold of ordinary detection.</p><p>The episode reinforced a reality digital security researchers have warned about for years: encryption protects communications in transit, but offers limited protection once the device itself has been compromised.</p><p><span>The $900 million valuation of Paragon Solutions reveals the brutal economics of surveillance capitalism. Remote device intrusion is immensely profitable. When government clients create the demand, and private equity investors drive the scale, the revolving door between state security and commercial surveillance becomes the engine that powers this industry. </span><a href="https://constantinecannon.com/whistleblower/whistleblower-insider-blog/paragon-systems-52-million-fraudulently-securing-govt-security-set-aside-contracts/" rel="">Former senior officials and intelligence veterans populate executive ranks, repackaging capabilities developed for national security into commercial products.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!VaZ2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!VaZ2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 424w, https://substackcdn.com/image/fetch/$s_!VaZ2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 848w, https://substackcdn.com/image/fetch/$s_!VaZ2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!VaZ2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!VaZ2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg" width="1200" height="694" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:694,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138550,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://ahmedeldin.substack.com/i/187749296?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!VaZ2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 424w, https://substackcdn.com/image/fetch/$s_!VaZ2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 848w, https://substackcdn.com/image/fetch/$s_!VaZ2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!VaZ2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a9e5a8-afc2-41d2-810e-588ca613de96_1200x694.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Paragon founders with investor Ehud Barak (second from right)</figcaption></figure></div><div id="youtube2-5pPQydBGwQY" data-attrs="{&quot;videoId&quot;:&quot;5pPQydBGwQY&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/5pPQydBGwQY?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>Israel has become the Silicon Valley of surveillance technology over the past two decades. A dense network of private firms operates alongside military and intelligence institutions, with personnel pipelines flowing between state security structures and commercial ventures.</p><p>Palestinians have long lived under one of the most extensively documented surveillance regimes in the world. The deployment of facial recognition systems, predictive analytics, and device monitoring technologies in the occupied Palestinian territories are widely documented by  human-rights organizations and digital researchers.</p><p data-attrs="{&quot;url&quot;:&quot;https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://ahmedeldin.substack.com/p/the-israeli-spyware-firm-that-accidentally?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>At the same time, </span><a href="https://www.americanimmigrationcouncil.org/blog/ice-ai-surveillance-tracking-americans/" rel="">U.S. immigration enforcement agencies are expanding their own technological arsenal</a><span>—biometric databases, algorithmic risk scoring, location tracking, and now, potentially, advanced spyware capabilities using the same institutional logics are identical: </span><em><a href="https://www.americanimmigrationcouncil.org/blog/ice-ai-surveillance-tracking-americans/" rel="">Identify. Track. Classify. Control.</a></em></p><p>What was developed to control Palestinians in occupied territories is now sold to control immigrants in America. The same surveillance infrastructure built under occupation becomes a commercial product sold to authoritarian regimes worldwide.</p><p>While the political contexts differ, the technologies increasingly circulate within overlapping global markets. The actors shaping this ecosystem include former heads of state, elite intelligence veterans, multinational investors, and government clients.</p><p><span>Public procurement records reveal tha</span><a href="https://www.wired.com/story/ice-paragon-solutions-contract/" rel="">t U.S. immigration enforcement agencies have engaged with Paragon’s Graphite technology</a><span>, including contracts with DHS and ICE. While the exact procurement process remains obscured in bureaucratic paperwork, the fact that ICE—an agency notorious for due process violations, detention conditions, and aggressive enforcement practices—secured advanced Israeli spyware capabilities speaks volumes about where the Trump administration’s priorities truly lay.</span></p><p>The Trump administration is expanding the surveillance state’s reach into the lives of immigrants and marginalized communities, using the most invasive tools available from the Israeli surveillance industry.</p><p><span>Spyware companies consistently invoke crime prevention and national security in their public messaging. </span><strong><a href="https://breached.company/the-cyber-arms-trade-how-commercial-spyware-is-reshaping-global-security/" rel="">But follow the money, and the real story emerges:</a></strong><span> extraordinary valuations are commanded by companies capable of defeating device security because governments continue purchasing those capabilities.</span></p><p>We live in an age of unprecedented surveillance, where the architecture of control is built not just with walls and checkpoints, but with algorithms and exploits. The same logic that governs the occupied territories now governs our digital lives, sold to us as progress and security.</p><p>Paragon’s moment of transparency showed us the face of modern surveillance capitalism. The irony is bitter: the same people who built the surveillance state now profit from selling its tools to the highest bidder. Their fortunes are built on the erosion of privacy, the compromise of security, the violation of digital sanctuary. We are told this is about national security, about fighting terrorism. But follow the money, and the truth emerges: this is about power. This is about control. This is about the commodification of human vulnerability.</p><p>The devices in our pockets are no longer just tools. They are also windows, and mirrors. They are the architecture of our own surveillance, sold to us as convenience, packaged as security, and monetized as data.</p><p>Paragon exposed itself not through negligence, but through arrogance and the belief that their work was so normalized, so institutionalized, that it could be displayed openly on a professional networking site.</p><p>And in that moment of exposure, we saw the truth: the surveillance industry operates not in shadows, but in plain sight. The only thing hiding its true nature is our own willingness to look away, our own complicity in the fiction that this is somehow about security rather than control.</p><p>The surveillance industry does not just compromise our devices. It compromises our humanity. And that is the ultimate cost of this billion-dollar empire.</p><p>The threat is global and immediate. The tools developed in Israel to surveil and control Palestinians are now in the hands of ICE to surveil and control immigrants in America. They are in the hands of authoritarian regimes worldwide to surveil and control their citizens. They are in the hands of corporations to surveil and control consumers.</p><p>This is the new colonialism, executed not through armies and occupation, but through algorithms and exploits. The same institutional logic that justified the occupation of Palestinian territories justifies the occupation of our digital lives. The same people who profited from one occupation now profit from the next.</p><p>When former intelligence chiefs and politicians sit on corporate boards and rake in millions from the surveillance industry, when governments purchase these tools without democratic debate, when the media fails to connect the dots between occupation and digital control—this is the conspiracy.</p><p>The dissent that was once silenced in Gaza is now being erased in our inboxes. The journalists who were targeted in the occupied territories are now being targeted in our own cities. The activists who were monitored in refugee camps are now being monitored in our communities.</p><p>This is a crisis of global proportion, a threat to human dignity that crosses borders and transcends politics. The question is no longer whether we should be concerned about surveillance. The question is whether we will allow this system to continue unchecked, whether we will demand accountability from those who profit from our vulnerability, whether we will reclaim our digital lives from those who would turn our devices into tools of control.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic tries to hide Claude's AI actions. Devs hate it (236 pts)]]></title>
            <link>https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/</link>
            <guid>47033622</guid>
            <pubDate>Mon, 16 Feb 2026 11:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/">https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/</a>, See on <a href="https://news.ycombinator.com/item?id=47033622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Anthropic has updated Claude Code, its AI coding tool, changing the progress output to hide the names of files the tool was reading, writing, or editing. However, developers have pushed back, stating that they need to see which files are accessed.</p>
<p>Version 2.1.20 collapsed the output so that instead of showing, for example, the file names and how many lines were read, it would just print "Read 3 files (ctrl+o to expand)," according to a&nbsp;<a href="https://symmetrybreak.ing/blog/claude-code-is-being-dumbed-down/" target="_blank" rel="nofollow">post</a>&nbsp;complaining that "Claude Code is being dumbed down." The full details can still be accessed with the keyboard shortcut, but constantly invoking this is annoying and impractical.</p>
<p>Developers have many reasons for wanting to see the file names, such as for security, for knowing immediately if Claude is pulling context from the wrong files, and for easy audit of past activity by scrolling through conversation. "When I'm working on a complex codebase, knowing what context Claude is pulling helps me catch mistakes early and steer the conversation," one person wrote.</p>

    

<p>There's also a financial impact. If developers spot that Claude is going down a wrong track, they can interrupt and avoid wasting tokens.</p>

        


        

<p>&nbsp;A&nbsp;<a href="https://github.com/anthropics/claude-code/issues/21151" target="_blank" rel="nofollow">GitHub issue</a>&nbsp;on the subject drew a&nbsp;<a href="https://github.com/anthropics/claude-code/issues/21151#issuecomment-3812828803" target="_blank" rel="nofollow">response</a>&nbsp;from Boris Cherny, creator and head of Claude Code at Anthropic, that "this isn't a vibe coding feature, it's a way to simplify the UI so you can focus on what matters, diffs and bash/mcp outputs." He suggested that developers "try it out for a few days" and said that Anthropic's own developers "appreciated the reduced noise."</p>
<p>Cherny said that developers who wanted more detail could enable verbose mode. Responses were lackluster, with one person writing: "Verbose mode is not a viable alternative, there's way too much noise."</p>

        

<p>Another observation was that the new default output, such as "searched for 2 patterns, read 3 files," conveys no useful information. "It's not a nice simplification, it's an idiotic removal of valuable information,"&nbsp;<a href="https://github.com/anthropics/claude-code/issues/21151#issuecomment-3844716512" target="_blank" rel="nofollow">said</a>&nbsp;a user.</p>
<p>Cherny responded to the feedback by making changes. "We have repurposed the existing verbose mode setting for this," he&nbsp;<a href="https://github.com/anthropics/claude-code/issues/21151#issuecomment-3887552218" target="_blank" rel="nofollow">said</a>, so that it "shows file paths for read/searches. Does not show full thinking, hook output, or subagent output (coming in tomorrow's release)."</p>
<p>The problem with this is that making verbose mode less verbose is a bad change for those who wanted the full details.</p>

        

<p>Cherny also participated in a lengthy&nbsp;<a href="https://news.ycombinator.com/item?id=46978710" target="_blank" rel="nofollow">discussion</a>&nbsp;on Hacker News. "Claude has gotten more intelligent, it runs for longer periods of time, and it is able to more agentically use more tools... The amount of output this generates can quickly become overwhelming in a terminal, and is something we hear often from users," he said.</p>
<ul>

<li><a href="https://www.theregister.com/2026/02/13/anthropic_series_g/">Investors shove another $30B into the Anthropic money furnace</a></li>

<li><a href="https://www.theregister.com/2026/02/13/anthropic_c_compiler/">OK, so Anthropic's AI built a C compiler. That don't impress me much</a></li>

<li><a href="https://www.theregister.com/2026/02/13/cloudflare_markdown_for_ai_crawlers/">Cloudflare turns websites into faster food for AI agents</a></li>

<li><a href="https://www.theregister.com/2026/02/12/30_chrome_extensions_ai/">30+ Chrome extensions disguised as AI chatbots steal users' API keys, emails, other sensitive data</a></li>
</ul>
<p>Those users who want the collapsed output seem to be mostly absent from the discussion. "I can't tell you how many times I benefited from seeing the files Claude was reading, to understand how I could interrupt and give it a little more context... saving thousands of tokens,"&nbsp;<a href="https://news.ycombinator.com/item?id=46982115" target="_blank" rel="nofollow">said</a>&nbsp;one response.</p>
<p>Cherny said that the repurposed verbose mode was the solution, and that Claude Code will still default to the condensed view.</p>
<p>The debate is important because if AI tools like Claude Code hide what they are doing from developers (or other users), mistakes are more likely to slip through. "I'm a Claude user who has been burned lately by how opaque the system has become,"&nbsp;<a href="https://news.ycombinator.com/item?id=46988932" target="_blank" rel="nofollow">said</a>&nbsp;another developer. "Right now Claude cannot be trusted to get things right without constant oversight and frequent correction, often for just a single step. For people like me, this is make or break. If I cannot follow the reasoning, read the intent, or catch logic disconnects early, the session just burns through my token quota."</p>
<p>Claude Code changes frequently, so it is likely that this aspect will be further tweaked, but there is not yet any indication that it will revert to the old behavior. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MessageFormat: Unicode standard for localizable message strings (128 pts)]]></title>
            <link>https://github.com/unicode-org/message-format-wg</link>
            <guid>47033328</guid>
            <pubDate>Mon, 16 Feb 2026 10:26:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/unicode-org/message-format-wg">https://github.com/unicode-org/message-format-wg</a>, See on <a href="https://news.ycombinator.com/item?id=47033328">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">MessageFormat Working Group</h2><a id="user-content-messageformat-working-group" aria-label="Permalink: MessageFormat Working Group" href="#messageformat-working-group"></a></p>
<p dir="auto">Welcome to the home page for the MessageFormat Working Group, a subgroup of the <a href="https://cldr.unicode.org/" rel="nofollow">Unicode CLDR-TC</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Charter</h2><a id="user-content-charter" aria-label="Permalink: Charter" href="#charter"></a></p>
<p dir="auto">The MessageFormat Working Group (MFWG) is tasked with developing and supporting an industry standard
for the representation of localizable message strings.
MessageFormat is designed to support software developers, translators, and end users with fluent messages
and locally-adapted presentation for data values
while providing a framework for increasingly complex features, such as gender, inflections, and speech.
Our goal is to provide an interoperable syntax, message data model, and associated processing that is
capable of being adopted by any presentation framework or programming environement.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Unicode MessageFormat Standard</h2><a id="user-content-the-unicode-messageformat-standard" aria-label="Permalink: The Unicode MessageFormat Standard" href="#the-unicode-messageformat-standard"></a></p>
<p dir="auto">The <a href="https://github.com/unicode-org/message-format-wg/blob/main/spec">Unicode MessageFormat Standard</a> is a stable part of CLDR.
It was approved by the CLDR Technical Committee
and is recommended for implementation and adoption.
The normative version of the specification is published as a part of <a href="https://www.unicode.org/reports/tr35/" rel="nofollow">TR35</a>.
This repository contains the editor's copy.</p>
<p dir="auto"><strong>Unicode MessageFormat</strong> is sometimes referred to as <em>MessageFormat 2.0</em>,
since it replaces earlier message formatting capabilities built into ICU.</p>
<p dir="auto">Some <em>default functions</em> and items in the <code>u:</code> namespace are still in Draft status.
Feedback from users and implementers might result in changes to these capabilities.</p>
<p dir="auto">The MessageFormat Working Group and CLDR Technical Committee welcome any and all feedback,
including bugs reports,
implementation reports,
success stories,
feature requests,
requests for clarification,
or anything that would be helpful in supporting or enhancing the specification and
promoting widespread adoption.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sharing Feedback</h2><a id="user-content-sharing-feedback" aria-label="Permalink: Sharing Feedback" href="#sharing-feedback"></a></p>
<p dir="auto">Do you have feedback on the specification or any of its elements? <a href="https://github.com/unicode-org/message-format-wg/issues/new?labels=Preview-Feedback&amp;projects=&amp;template=tech-preview-feedback.md&amp;title=%5BFEEDBACK%5D+">file an issue here</a></p>
<p dir="auto">We invite feedback about implementation difficulties,
proposed functions or options
real-life use-cases,
requirements for future work,
tooling,
runtime APIs,
localization workflows,
and other topics.</p>
<ul dir="auto">
<li>General questions and thoughts → <a href="https://github.com/unicode-org/message-format-wg/discussions">post a discussion thread</a>.</li>
<li>Actionable feedback (bugs, feature requests) → <a href="https://github.com/unicode-org/message-format-wg/issues">file a new issue</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Participation / Joining the Working Group</h2><a id="user-content-participation--joining-the-working-group" aria-label="Permalink: Participation / Joining the Working Group" href="#participation--joining-the-working-group"></a></p>
<p dir="auto">We are looking for participation from software developers, localization engineers and others with experience
in Internationalization (I18N) and Localization (L10N).
If you wish to contribute to this work, please review the information about the Contributor License Agreement below.</p>
<p dir="auto">To follow this work:</p>
<ol dir="auto">
<li>Apply to join our <a href="https://groups.google.com/a/chromium.org/forum/#!forum/message-format-wg" rel="nofollow">mailing list</a></li>
<li>Watch this repository (use the "Watch" button in the upper right corner)</li>
</ol>
<p dir="auto">To contribute to this work, in addition to the above:</p>
<ol dir="auto">
<li>Each individual MUST have a copy of the CLA on file. See below.</li>
<li>Individuals who are employees of Unicode Member organizations SHOULD contact their member representative.
Individuals who are not employees of Unicode Member organizations MUST contact the chair to request Invited Expert status.
Employees of Unicode Member organizations MAY also apply for Invited Expert status,
subject to approval from their member representative.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Copyright &amp; Licenses</h3><a id="user-content-copyright--licenses" aria-label="Permalink: Copyright &amp; Licenses" href="#copyright--licenses"></a></p>
<p dir="auto">Copyright © 2019-2025 Unicode, Inc. Unicode and the Unicode Logo are registered trademarks of Unicode, Inc. in the United States and other countries.</p>
<p dir="auto">A CLA is required to contribute to this project - please refer to the <a href="https://github.com/unicode-org/message-format-wg/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> file (or start a Pull Request) for more information.</p>
<p dir="auto">The contents of this repository are governed by the Unicode <a href="https://www.unicode.org/copyright.html" rel="nofollow">Terms of Use</a> and are released under <a href="https://github.com/unicode-org/message-format-wg/blob/main/LICENSE">LICENSE</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3.5: Towards Native Multimodal Agents (247 pts)]]></title>
            <link>https://qwen.ai/blog?id=qwen3.5</link>
            <guid>47032876</guid>
            <pubDate>Mon, 16 Feb 2026 09:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwen.ai/blog?id=qwen3.5">https://qwen.ai/blog?id=qwen3.5</a>, See on <a href="https://news.ycombinator.com/item?id=47032876">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[picol: A Tcl interpreter in 500 lines of code (104 pts)]]></title>
            <link>https://github.com/antirez/picol</link>
            <guid>47032235</guid>
            <pubDate>Mon, 16 Feb 2026 08:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/antirez/picol">https://github.com/antirez/picol</a>, See on <a href="https://news.ycombinator.com/item?id=47032235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">Picol is a Tcl-alike interpreter in 500 lines of code that I released 15th of March 2007. Recentely I looked at the source code and realized this was a better C programming example compared to what I recalled, so I'm putting this on GitHub to archive it, together with the main points of the original article.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Rules</h2><a id="user-content-rules" aria-label="Permalink: Rules" href="#rules"></a></p>
<p dir="auto">When I built this code, I had some rule in mind:</p>
<ul dir="auto">
<li>I wanted to use more or less my normal C style. In Picol you'll find normal C spacing and even comments.</li>
<li>I wanted to write an interpreter with a design similar to a real one. One of the few useful things you can do with Picol is to learn how to write a Tcl interpreter if you are a newbie programmer, I guess, so the point was to write a simple to understand program, not just a <em>short</em> program.</li>
<li>The resulting interpreter should be able to run some kind of non trivial program: to just set few vars and print hello world was not an option.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">The resulting interpreter: Picol</h2><a id="user-content-the-resulting-interpreter-picol" aria-label="Permalink: The resulting interpreter: Picol" href="#the-resulting-interpreter-picol"></a></p>
<p dir="auto">The parser is very similar to the Tcl one, Picol supports interpolation as well, for example you can write:</p>
<div dir="auto" data-snippet-clipboard-copy-content="set a &quot;pu&quot;
set b {ts}
$a$b &quot;Hello World!&quot;"><pre><span>set</span> a <span><span>"</span>pu<span>"</span></span>
<span>set</span> b {ts}
<span>$a$b</span> <span><span>"</span>Hello World!<span>"</span></span></pre></div>
<p dir="auto">Note that Picol has an interactive shell! so just launch it without arguments to start to play (to compile the code use <code>gcc -O2 -Wall -o picol picol.c</code>).</p>
<p dir="auto">To run a program stored in a file, use: <code>picol filename.tcl</code>.</p>
<p dir="auto">Probably the parser could be rewritten in order to take less space, currently it takes almost 250 lines of code: this is too much and leaves little room for all the rest. On the other side, it's a decent example about writing parsers by hand.</p>
<p dir="auto">A Raw list of the supported features:</p>
<ul dir="auto">
<li>Interpolation, as seen above. You can also write <code>"2+2 = [+ 2 2]"</code> or <code>"My name is: $foobar"</code>.</li>
<li>Procedures, with return. Like Tcl if return is missing the result of the last command executed is returned.</li>
<li><code>If</code>, <code>if .. else ..</code>, <code>while</code> with <code>break</code> and <code>continue</code>.</li>
<li>Recursion.</li>
<li>Variables inside procedures are limited in scope like Tcl, i.e. there are real call frames in Picol.</li>
<li>The following other commands: <code>set</code> <code>+</code> <code>-</code> <code>*</code> <code>/</code> <code>==</code> <code>!=</code> <code>&gt;</code> <code>&lt;</code> <code>&gt;=</code> <code>&lt;=</code> <code>puts</code>.</li>
</ul>
<p dir="auto">This is an example of programs Picol can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="proc fib {x} {
    if {== $x 0} {
        return 0
    }
    if {== $x 1} {
        return 1
    }
    return [+ [fib [- $x 1]] [fib [- $x 2]]]
}

puts [fib 20]
that of course will output fib(20). Another example:
proc square {x} {
    * $x $x
}"><pre><span>proc</span> <span>fib</span> {x} {
    <span>if</span> {== <span>$x</span> 0} {
        <span>return</span> 0
    }
    <span>if</span> {== <span>$x</span> 1} {
        <span>return</span> 1
    }
    <span>return</span> [+ [fib [- <span>$x</span> 1]] [fib [- <span>$x</span> 2]]]
}

<span>puts</span> [fib 20]
that of course will output fib(20). Another example:
<span>proc</span> <span>square</span> {x} {
    * <span>$x</span> <span>$x</span>
}</pre></div>
<p dir="auto">Or:</p>
<div data-snippet-clipboard-copy-content="set a 1
while {<= $a 10} {
    if {== $a 5} {
        puts {Missing five!}
        set a [+ $a 1]
        continue
    }
    puts &quot;I can compute that $a*$a = [square $a]&quot;
    set a [+ $a 1]
}"><pre><code>set a 1
while {&lt;= $a 10} {
    if {== $a 5} {
        puts {Missing five!}
        set a [+ $a 1]
        continue
    }
    puts "I can compute that $a*$a = [square $a]"
    set a [+ $a 1]
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design</h2><a id="user-content-design" aria-label="Permalink: Design" href="#design"></a></p>
<ul dir="auto">
<li>It's pretty straightforward, the first important part you see in the source code is an hand written parser. The main function of the parser is <code>picolGetToken</code> that just calls functions able to parse the different parts of a Tcl program and return in the parsing structure the type of the token and start/end pointers in order to extract it.</li>
</ul>
<p dir="auto">This parsing function is in turn used by <code>picolEval</code> in order to execute the program. Every token is used either to form a new argument if a separator token was found before, or concatenated to the last argument (this is how interpolation is performed in Picol). Once an EOL (end of line) token is returned picolEval will call the command looking it up in a linked list of commands stored inside the interpreter structure.</p>
<p dir="auto">Variables and commands substitution is performed by <code>picolEval</code> itself. The parser is able to return variables and commands tokens already stripped by <code>$</code> and <code>[]</code>, so all it's required to do is to lookup the variable in the call frame and substitute the value with the token, or to recursively call <code>picolEval</code> if it's a command substitution, using the result instead of the original token.</p>
<p dir="auto">Commands are described by a name and a pointer to a C function implementing the command. In the command structure there is also a private data void pointer used in order to store data private to the command. This makes you able to implement multiple Picol commands using a single C function. User defined procedures are just like commands, but they are implemented by passing as private data the argument list and the body of the procedure, so a single C function is able to implement all the existing user defined procedures.</p>
<p dir="auto">Procedures call is trivial. The interpreter structure contains a call frame structure having more or less just a pointer to a liked list of variables (that are in turn structures with two fileds: name and value). When a procedure is called a new call frame is created and put at the top of the old one. When the procedure returns the top call frame is destroyed.</p>
<p dir="auto"><strong>Inside every large program there is a small program trying to get out -- Sir Tony Hoare.</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I want to wash my car. The car wash is 50 meters away. Should I walk or drive? (1119 pts)]]></title>
            <link>https://mastodon.world/@knowmadd/116072773118828295</link>
            <guid>47031580</guid>
            <pubDate>Mon, 16 Feb 2026 06:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.world/@knowmadd/116072773118828295">https://mastodon.world/@knowmadd/116072773118828295</a>, See on <a href="https://news.ycombinator.com/item?id=47031580">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Arm wants a bigger slice of the chip business (136 pts)]]></title>
            <link>https://www.economist.com/business/2026/02/12/arm-wants-a-bigger-slice-of-the-chip-business</link>
            <guid>47030271</guid>
            <pubDate>Mon, 16 Feb 2026 02:36:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2026/02/12/arm-wants-a-bigger-slice-of-the-chip-business">https://www.economist.com/business/2026/02/12/arm-wants-a-bigger-slice-of-the-chip-business</a>, See on <a href="https://news.ycombinator.com/item?id=47030271">Hacker News</a></p>
Couldn't get https://www.economist.com/business/2026/02/12/arm-wants-a-bigger-slice-of-the-chip-business: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Pink noise reduces REM sleep and may harm sleep quality (102 pts)]]></title>
            <link>https://www.pennmedicine.org/news/pink-noise-reduces-rem-sleep-and-may-harm-sleep-quality</link>
            <guid>47029397</guid>
            <pubDate>Mon, 16 Feb 2026 00:35:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pennmedicine.org/news/pink-noise-reduces-rem-sleep-and-may-harm-sleep-quality">https://www.pennmedicine.org/news/pink-noise-reduces-rem-sleep-and-may-harm-sleep-quality</a>, See on <a href="https://news.ycombinator.com/item?id=47029397">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[JavaScript-heavy approaches are not compatible with long-term performance goals (145 pts)]]></title>
            <link>https://sgom.es/posts/2026-02-13-js-heavy-approaches-are-not-compatible-with-long-term-performance-goals/</link>
            <guid>47029339</guid>
            <pubDate>Mon, 16 Feb 2026 00:26:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sgom.es/posts/2026-02-13-js-heavy-approaches-are-not-compatible-with-long-term-performance-goals/">https://sgom.es/posts/2026-02-13-js-heavy-approaches-are-not-compatible-with-long-term-performance-goals/</a>, See on <a href="https://news.ycombinator.com/item?id=47029339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    
<p>This post is a (very long) opinion piece, albeit one that I hope is somewhat substantiated by the accompanying anecdotes. The TL;DR is that in my experience the title is a correct statement the vast majority of the time, and we should favour more server-centric approaches instead, when possible.</p>
<details>
<summary>What I mean by “JS-heavy approaches“</summary>

<p>I use this term to refer to any approach that relies on shipping large quantities of JS to the browser, for the browser to execute as an intrinsic part of using the web app, often in the critical path. These sorts of approaches are usually associated with Single-page Applications (SPAs), but do unfortunately pop up in Multi-page Applications (MPAs) as well.</p>
</details>

<h2 id="background">Background</h2>
<h3 id="my-experience">My experience</h3>
<p>In case you don’t know me, hi! 👋 I work full-time on web performance at <a href="https://automattic.com/">Automattic</a>, as part of a small PerfOps team whose mission is to improve performance across the various things we build or work on as a company. Our team also builds and maintains our company’s performance monitoring infrastructure, but the majority of our time is spent finding and fixing performance issues across our various stacks, all the way from optimising DB queries to fixing janky CSS animations.</p>
<p>Personally, I specialize on the browser side of things. As part of this work, I have had more than my share of debugging sessions for loading performance issues, runtime performance problems, bundle size increases, framework-specific issues like expensive re-renders in <code>React</code>, etc., and there are some underlying root causes I’ve seen over and over again. These problems are not necessarily insurmountable, but they do add up to reveal some important gaps and outright falsehoolds in the narrative about the “modern web development approach” that we’ve been sold over the years.</p>
<h3 id="caveats">Caveats</h3>
<p>I don’t think I’ll necessarily bring any groundbreaking revelations to the table, nor do I come with a large corpus of data to back anything up as the unquestionable truth. This is all based on my own experience, and may not apply to what any given project is doing, particularly if it’s a small web app maintained by a focused, dedicated team.</p>
<p>Also note that I’ll be jumping between different aspects of web performance throughout the post, without much thought. That’s because while they’re all distinct, they’re all important! You don’t want to have an application that takes forever to load, any more than one that is sluggish at rendering the characters the user is typing, or one that has a disruptive delay on in-app navigations.</p>
<h3 id="the-pitch-and-the-reality-of-frameworks">The pitch and the reality of frameworks</h3>
<p>With the caveats out of the way, let’s look at the main topic: the long-term performance characteristics of “modern” development, which most of the time involves frameworks of some sort, like <code>React</code>.</p>
<details>
<summary>Yes, <code>React</code> is a framework</summary>

<p>I know there’s some discussion on whether <code>React</code> is a framework or not, with some folks — notably, the authors and maintainers — insisting on calling it a library. I don’t know why they do it, but it’s frankly wrong, as far as agreed-upon terms and shared vocabulary go.</p>
<p>In Computer Science, the <a href="https://en.wikipedia.org/wiki/Software_framework">commonly accepted distinction between the two</a> is that a library is something that your code calls into, while a framework is something that you relinquish control unto, so that <strong>it</strong> calls <strong>your code</strong> instead, at the appropriate time. That is, a framework works through Inversion of Control, and a library does not.</p>
<p>By this definition, <code>React</code> is a framework, because an idiomatic <code>React</code> application overwhelmingly consists of code that gets called by <code>React</code>, and lives under its control.</p>
</details>

<p>Frameworks like <code>React</code> are often perceived as accelerators, or even as the only sensible way to do web development. There’s this notion that a more “modern” stack (read: JS-heavy, where the JS ends up running on the user’s browser) allows you to be more agile, release more often with fewer bugs, make code more maintainable, and ultimately launch better sites. In short, the claim is that this approach will offer huge improvements to developer experience, and that these DevEx benefits will trickle down to the user.</p>
<p>But over the years, this narrative has proven to be unrealistic, at best. In reality, for any decently sized JS-heavy project, you should expect that what you build will be slower than advertised, it will keep getting slower over time while it sees ongoing work, and it will take more effort to develop and especially to maintain than what you were led to believe, with as many bugs as any other approach.</p>
<p>Where it comes to performance, the important thing to note is that a JS-heavy approach (and particularly one based on <code>React</code> &amp; friends) will most likely not be a good starting point; in fact, it will probably prove to be a performance minefield that you will need to keep revisiting, risking a detonation with every new commit.</p>
<h3 id="roadmap">Roadmap</h3>
<p>In this post, I’ll start by looking at some of the underlying causes for the most common categories of problems I’ve seen, and follow that up with mitigation strategies you can adopt to prevent some of them.</p>
<p>After that, I’ll reflect on whether JS-heavy approaches are worth it, whether performance is optional, and then explore server-centric development as an alternative, and why it tends to do better.</p>
<p>I’ll then finish up with my plea to our industry to change the way we do things.</p>
<h2 id="the-problems">The problems</h2>
<h3 id="dependencies-are-expensive">Dependencies are expensive</h3>
<p>One of the more immediate problems is that JS-heavy development approaches often deeply rely on the <code>npm</code> global package repository for runtime JS (i.e., the JS that the user’s browser will run). While this can be a great shortcut for getting something out the door quickly, it can come with some less-than-obvious costs, often measured in bytes on your bundle.</p>
<blockquote>
<p><strong>Note:</strong> while bundle size isn’t a metric that your users experience directly, most of the time it correlates strongly with ones that do (such as the various paint metrics), particularly in scenarios where large portions of your application get loaded as part of the critical path.</p>
</blockquote>
<p>It’s unfortunately common to pull large packages into your bundle, such as huge libraries for time and timezone management, extensive collections of JS utility functions, and entire component systems to kickstart your UI building. Some of these packages are well-designed, and built to be small and modular, so that you only pay for what you use. Many of them are not, however, and end up being monolithic, or close to it, due to their design (e.g. fluent APIs like <code>moment</code>), due to heavily reusing themselves internally (e.g. <code>lodash-es</code>), or due to failing to account for what bundlers need in order to perform effective tree-shaking.</p>
<p>Large dependencies are often bad enough on their own, but sadly, it gets worse: many of these packages grow larger over time. Which means that not only do we carry a ball and chain around, it keeps getting heavier!</p>
<ul>
<li>For example, <code>moment</code> has had a 10% increase in size over the last 5 years. Not outrageous, but lots of small increases like this across a number of dependencies do add up.</li>
<li><code>react-dom</code> has steadily grown over the years, and going from v18 to v19 alone results in a 33% increase in bundle size for a basic Hello World app.</li>
</ul>
<p>These increases are often hidden under the hood, and not something you’d easily come across, as most tools don’t give you this information by default:</p>
<ul>
<li><code>npm</code> won’t tell you how large a package is when you install or update it.</li>
<li>Many bundlers don’t show your bundle size at the end of a build (although some of the more recent ones like <code>Vite</code> or <code>Rsbuild</code>, do).</li>
<li>Your IDE or editor won’t tell you how much an import will add to your bundle unless you’ve specifically added a plugin for this.</li>
<li>If you have a tool like <code>dependabot</code> set up on your repo, it will helpfully point out that new versions are available and even prepare the upgrade PRs for you — but it won’t warn you that the new version is 20% larger.</li>
</ul>
<p>And to make matters worse, sticking to the previous version of a package is often not an option, because the new version includes security or bug fixes, or because another package is forcing you to upgrade a shared dependency.</p>
<p>But let’s say you were mindful when picking your dependencies, and you carefully vet each version upgrade not to balloon your bundle size. You’re also cautious about not adding too much code yourself. Does that mean your web app will be fast?</p>
<h3 id="its-easy-to-make-it-slow">It’s easy to make it slow</h3>
<p>A robust, developer-friendly system should make it easier to do the right thing than the wrong thing. It’s usually not feasible to make mistakes outright impossible, but it’s generally enough to ensure that following the wrong approach involves extra friction.</p>
<p>Unfortunately, where it comes to performance, JS-heavy development approaches often behave the opposite way: they make it easier to do the wrong thing than the right thing.</p>
<p>I’ll focus on <code>React</code> and <code>Redux</code> in some of my examples since that is what I have the most experience with, but much of this applies to other frameworks and to JS-heavy approaches in general. All of the following are issues I came across multiple times, in separate codebases:</p>
<ul>
<li>It’s often much easier to add things on a top-level component’s context and reuse them throughout the app, than it is to add them only where needed. But doing this means you’re paying the cost before (and whether) you need it.</li>
<li>It’s much simpler to add something as a synchronous top-level import and force it to be present on every code path, than it is to load it conditionally and deal with the resulting asynchronicity.</li>
<li>Setting up a bundler to produce one monolithic bundle is trivial, whereas splitting things up per route with shared bundles for the common bits often involves understanding and writing some complex configuration.</li>
<li>It’s less work to build a <code>Redux</code> reducer that blindly rewrites an entire subtree and leads to unnecessary rerenders, than it is to have it check to see if changes are needed.</li>
<li>It’s much more straightforward to write a <code>Redux</code> selector that blindly runs a <code>.map()</code> to generate a new array everytime, than it is to memoise the results correctly.</li>
<li>If you forget to use memoisation on a single prop, your component might now rerender every time something innocuous happens. And if it’s a root-adjacent component, that means potentially a large portion of your render tree needs to be recalculated.</li>
<li>It’s a lot less work to load your entire application state (i.e., all reducers) in the critical path, than it is to split things up so that only the relevant portions of state get loaded on each route.</li>
<li>It’s often much easier to wrap each of your SVG icons in JSX than it is to set things up to load them from an external <code>.svg</code> file with SVG <code>&lt;use&gt;</code>.</li>
</ul>
<p>This is compounded by the fact that developers are often taught the wrong approach by tutorials or other documentation resources. In an effort to make things easier to understand and learn, the code is kept simple — and as we’ve seen, the straightforward strategy is often the wrong one, at least where performance is concerned. Sometimes the docs go on to mention that they’re showing a simplified snippet of code and production code might need to be different. Sometimes they don’t.</p>
<p>These approaches are <strong>fragile</strong>, and make it easy for anyone to break performance at any time.</p>
<p>Which leads me to the next point. How likely is it that an initially fast JS-heavy app remains fast throughout development?</p>
<h3 id="its-hard-to-keep-it-fast">It’s hard to keep it fast</h3>
<p>If a system is fragile, it means that it even if it starts out solid, it will be hard to keep it intact as time goes by.</p>
<p>The unfortunate reality is that some of these performance issues are watershed moments, in that a single wrong move can effectively render all your previous efforts to avoid a given class of performance problems moot:</p>
<ul>
<li>If you’ve carefully made every usage of a library conditional and asynchronous, it only takes a single static import somewhere in the critical path for the library to now need to be parsed, compiled, and executed before your site gets a chance to render.</li>
<li>If you’ve painstakingly removed every instance of a large monolithic library like <code>moment</code>, it only takes a single import for it to come back in its entirety.</li>
<li>If you’ve isolated an endpoint from as much of the rest of the application as possible, it might only take a single import in that endpoint or in the shared core for a huge amount of code to pour back in.</li>
<li>It only takes a single, poorly-coded <code>Redux</code> selector or reducer to potentially affect performance on every action.</li>
</ul>
<p>These problems may be obvious to you as an experienced developer, but they might not be to someone who joined the team recently, or a coder whose experience mostly involves other frameworks or libraries. <strong>Any system that relies on developer discipline</strong> to maintain performance (or any other characteristic, really) <strong>is a fragile thing that requires constant vigilance</strong>, particularly for large teams or projects.</p>
<p>So while it may be easy to resolve the situation by rolling back the change or fixing the new code, the reality is that if you’re not carefully monitoring your web app, you might miss the problem entirely and unwittingly leave things in a worse state than before, despite all the work you had done to prevent the problem in the first place.</p>
<p>I’ve seen it happen time and time again over the years; some kinds of performance improvement efforts don’t tend to last for very long, because it’s just so easy to break things again.</p>
<p><em>“Okay”</em>, you might think, <em>“but these frameworks and friends claim to be focused on developer experience, which means they surely must come with some great tools for debugging performance issues too, right?”</em></p>
<p>Unfortunately, that’s often not the case.</p>
<h3 id="its-hard-to-debug-performance-issues">It’s hard to debug performance issues</h3>
<p>Performance is never easy to debug, even at the best of times.</p>
<p>That said, over the years, browser engines have put an incredible amount of effort into building robust web development tooling. Browser Dev Tools pretty much let you peer into every aspect of your site’s performance, and even into what the browser itself is doing while it loads and renders your site. They show you easy to understand waterfalls for resource loading, and helpful flamecharts for JS execution and rendering. They can throttle CPU and network, and run detailed profiles that combine all sorts of information. They can even now analyse those profiles for you, to point out problems and offer suggestions! These tools easily match and often exceed their server-side counterparts, and they’re a wonderful perk that we rely on daily.</p>
<p>Which is why it’s incredibly frustrating when frameworks like <code>React</code>, which again ostensibly pride themselves on being developer-friendly, throw all of that away to build their own Dev Tools. Poorly.</p>
<p>This is not the case with every framework, mind you; for instance, <code>Preact</code> takes the right approach, in <strong>enhancing</strong> the existing browser DevTools with framework-specific information. So if you run a browser profile on your <code>Preact</code> web app with their Dev Tools enabled, you’ll get some helpful markers added to the native browser profile, indicating when a component renders, for example. This lets you make sense of what’s happening in the browser layer as a result of the framework layer, so you can more quickly zero in on the code that’s seemingly causing a lot of garbage collection passes, or the component that’s triggering layout refreshes at an inconvenient time.</p>
<figure>
  <p><img loading="lazy" src="https://sgom.es/posts/2026-02-13-js-heavy-approaches-are-not-compatible-with-long-term-performance-goals/preact-dev-tools.jpg" alt="Preact-level timing information gets added to browser profiles, and is available to built-in functionality like the aggregate table of where time was spent. Great stuff! 👍">
  </p>
  <figcaption><code>Preact</code>-level timing information gets added to browser profiles, and is available to built-in functionality like the aggregate table of where time was spent. Great stuff! 👍</figcaption>
</figure>





<p>But that’s not the case with <code>React</code>: it has its own tools, which are entirely separate. You can run a <code>React</code> profile, but it doesn’t create a browser profile to go with it, and you have no way of combining <code>React</code> information with the JS sampling information from the browser to get a complete picture of where time is being spent. This means that often, even if you manage to figure out that the problem is in, say, a particular component’s commit to the DOM, you’re unable to understand why. You might need to resort to reproducing the problem twice (once for each profiler), carefully comparing the two separate profiles, and performing some leaps of logic.</p>
<figure>
  <p><img loading="lazy" src="https://sgom.es/posts/2026-02-13-js-heavy-approaches-are-not-compatible-with-long-term-performance-goals/react-dev-tools.jpg" alt="With React DevTools, browser profiles don’t include any React-level timing information 😞">
  </p>
  <figcaption>With <code>React</code> DevTools, browser profiles don’t include any <code>React</code>-level timing information 😞</figcaption>
</figure>





<p>In addition, the <code>React</code> DevTools profiler can be hard to use (from a UI point of view), and is missing essential information, like an aggregate view of where time was spent.</p>
<p>And this is not just a problem with <code>React</code> Dev Tools. The debugging information you need is often not available, and even when it is, you’re frequently forced to jump through extra hoops:</p>
<ul>
<li>In a server-side rendered <code>React</code> app, if your hydration fails and your application needs to render from scratch (a performance problem, in that you’re losing the SSR optimisation), the error messages are often a useless <code>Did not expect server HTML to contain a &lt;div&gt; in &lt;main&gt;.</code> or similar, even when running a debug build. Good luck finding that <code>&lt;div&gt;</code>!</li>
<li><code>Redux</code> Dev Tools don’t include any mechanism to help you find and debug slow reducers or selectors.</li>
<li>Debugging performance issues often requires you to find out about and switch to the “profiling“ build of your frameworks, if they exist at all. If you use a debug build instead, your timings won’t be meaningful, leading you to spend time trying to fix phantom issues; and if you use a production build, you’ll be missing the symbols that help you make sense of what’s happening.</li>
<li>To my knowledge, none of the bundlers default to building a map of what’s inside your bundle, for help with bundle size debugging if needed. Most of the time you need to find out about, install, and configure a separate plugin manually.</li>
</ul>
<p>Now, don’t get me wrong: the web platform can be a challenging performance environment on its own, with plenty of quirks to be aware of. But frameworks rarely address those definitively (if at all), and in fact make debugging performance <strong>harder</strong> than the baseline, because they add additional layers of abstraction.</p>
<p>The bigger the mismatch between a framework’s programming model and the underlying platform’s, the bigger the opportunity for complicated performance problems to arise in the interface between the two. So it sure would be nice if they would at least help with that part!</p>
<h2 id="mitigating-the-problems">Mitigating the problems</h2>
<p>So now that we know the problems and how easy it is for them to show up, what can we do about it? If you’re stuck building a JS-heavy client-side app, don’t despair! There are still actions you can take to improve your chances of making it faster, and keeping it from getting too slow over time.</p>
<p>Be warned, though: in my experience, you shouldn’t expect a consistently performant app, even if you follow all of these suggestions. But following them will help with stopping the bleeding and keeping things from getting too bad without you noticing.</p>
<h3 id="before-you-start">Before you start</h3>
<ul>
<li><strong>Make sure everyone is on the same page about performance.</strong> You might need to convince some non-technical folks by showing them industry studies that link page performance to business metrics like conversions. As for developers, you may need to remind them that their development devices and connections aren’t a good benchmark for “good enough”, since most users <a href="https://infrequently.org/2025/11/performance-inequality-gap-2026/">will unfortunately be relying on something significantly worse</a>.</li>
<li><strong>Define your performance budget.</strong> While there are some standard numbers across the industry, such as the thresholds Google recommends for <a href="https://web.dev/articles/vitals#core-web-vitals">its Core Web Vitals metrics</a>, not every project is the same. Depending on your audience and use-case, you may need to be more (or less) ambitious in your goals, or pick different metrics entirely. The key thing is to define them ahead of time, and stick to them during development, avoiding the temptation to move the goalposts to fit the outcome.</li>
<li><strong>Carefully choose your architecture and tech stack.</strong> Now’s a good time to figure out whether your client-side application should have a server-side aspect to it, to speed up initial renders. This is especially important if you have API calls in your critical path, and doubly so if they’re sequential in any way. Also, take the opportunity to research what’s out there, and pick the frameworks, libraries, and general approach that best fit your needs.</li>
</ul>
<h3 id="early-in-development">Early in development</h3>
<ul>
<li><strong>Set up code splitting.</strong> A lot of development environments give you this essentially for free, but many others unfortunately do not.<ul>
<li>Make sure that your bundler outputs multiple chunks, that are split in a reasonable way (e.g. per route).</li>
<li>Ensure that bundles for other routes don’t get loaded, or if they do, that it happens lazily, very late into the page loading process (e.g. after the <code>load</code> event). This is to ensure that they don’t compete with critical path resources for network and CPU availability.</li>
<li>Make sure you have things set up so that shared chunks are automatically created, with code that’s common to most bundles. There’s a balance to be found between fewer, larger chunks with more unused code for any given route, and having a multitude of tiny little chunks that all need to be fetched. Thankfully, that balance has been made easier to reach since we got widespread HTTP/2 usage, but do be mindful that there are still performance benefits to be had in keeping things down to fewer critical path resources.</li>
<li>Alternatively, you can create the shared bundles by hand, but keep in mind that this is an additional maintenance cost.</li>
</ul>
</li>
<li><strong>Set up bundle size tracking.</strong> While bundle size isn’t a particularly meaningful metric, it’s an easy one to track, and one that can serve as an early warning to look for actual performance issues.<ul>
<li>Have your bundler output bundle size when you build locally (e.g. <code>npm run build</code>), as a first step.</li>
<li>Once you have a CI (Continuous Integration) environment, add a build size action to it. For something like GitHub Actions, you can find pre-made ones that are fairly easy to set up (e.g. <a href="https://github.com/preactjs/compressed-size-action"><code>compressed-size-action</code></a>).</li>
<li>Once that’s in place, make sure that your CI adds a comment to pull requests where a large increase is detected. The earlier a developer learns about the problem, the better the chances they’ll fix it.</li>
</ul>
</li>
<li><strong>Set up linting.</strong> There aren’t many kinds of performance issues (or potential ones) that can be detected like this, but it’s hugely beneficial for those that can, since developers find out about them early in their work.<ul>
<li>Set up a list of “forbidden” imports, like <code>lodash</code> if you’re using <code>lodash-es</code>, as well as any packages you may have had trouble with in the past and want to avoid entirely.</li>
<li>Set up rules for packages that include both modular and monolithic imports, so that the monolithic ones are banned.</li>
<li>If you have a package or a portion of your application that you want to be loaded dynamically (i.e., with a dynamic <code>import()</code>), set up a rule to prevent static imports.</li>
<li>Keep updating the list as time goes by. Whenever you fix a problem or complete a performance-related migration away from something, consider adding new rules to help prevent the problem from resurfacing.</li>
</ul>
</li>
<li><strong>Set up performance tracking.</strong> You can use a tool like <code>puppeteer</code> or <code>playwright</code> to perform full page loads and in-app navigations, and measure how long things take. This is easily an order of magnitude more difficult than the previous suggestions, but it’s the best way I’m aware of to get somewhat meaningful performance numbers during development.<ul>
<li>Start by setting things up for running tests locally, on demand (e.g. <code>npm run test:perf</code>). Make sure you test both initial loading performance and in-app navigations, and that you use both network and CPU throttling when doing so.</li>
<li>Once that’s working, move it to CI, and run it on every pull request.</li>
<li>The tricky part here is making the numbers reliable, which can be incredibly difficult, depending on your CI environment. For some of them, it may actually be a bit of a lost cause, because they don’t give you any way to achieve reasonable stability.<ul>
<li>On the test suite side of things, you can try calibrating performance by running a pre-test CPU benchmark to determine an appropriate CPU throttling multiplier, as well as ensuring that only a single test runs at a time.</li>
<li>On the CI side of things, you can try to reduce the amount of virtualisation (ideally, to zero), and other concurrent work.</li>
<li>On the hardware side of things, if that’s an option, you can go as far as trying to force a fixed amount of RAM (when virtualising), as well as a fixed CPU speed.</li>
</ul>
</li>
<li>Once you manage to make it stable, with reasonably reliable numbers, have your CI add comments to pull requests whenever a large shift is detected.</li>
<li>If you can, make sure to keep historical data, so that you can visualise long-term trends. Small increases often go by unnoticed (particularly if your data is noisy), but they do add up over time.</li>
</ul>
</li>
</ul>
<h3 id="once-you-launch">Once you launch</h3>
<ul>
<li><strong>Add RUM (Real User Monitoring) performance tracking.</strong> This is the gold standard in performance monitoring, since it reflects what your real users are experiencing, regardless of what your expectations were.<ul>
<li>If your web app is large enough to be featured in the <a href="https://developer.chrome.com/docs/crux">CrUX</a> dataset, start by looking at those numbers. They’re fairly limited for client-side apps, and they won’t give you much in the way of debugging information, but they’ll help you calibrate your expectations with reality.</li>
<li>Choose a RUM vendor and integrate their client code into your app, or roll out your own system. The latter obviously involves more work, but it might help you tailor things better to your application, so that you have the metrics that make the most sense to you (e.g. when the first image rendered, if you’re building an image-focused site).</li>
<li>Consider including debug information in your app. While you don’t want your RUM code to grow huge, and you probably don’t want to collect lots of data for every user action, there may be some useful info around the metrics themselves that will help with debugging. For example, you could complement the Largest Contentful Paint value with ancillary information like what type of element the LCP target was, the external resource it related to (if any), or the portion of the UI it came from.</li>
</ul>
</li>
<li><strong>Collect performance feedback.</strong> If you have a support team, make sure they know who to reach for complaints about performance. Depending on your product, you may find that most users are non-technical and unable to communicate the problem clearly, but you’ll get a general idea of what the pain points are, and where to target your improvement work.</li>
</ul>
<h2 id="are-js-heavy-approaches-worth-it">Are JS-heavy approaches worth it?</h2>
<p>If that seems like a lot of overhead to you, we’re definitely in agreement. It’s a lot of running to stay in the same place, and it’s probably not even going to be such a great spot to stick around in anyway.</p>
<p>Implementing all of these mitigations will take a significant amount of time, and keeping the ongoing vigilance will force you to either have a dedicated team that actively tries to counter these effects, or to somehow educate all your developers on all of the pitfalls, and convince them to keep this level of vigilance themselves, constantly.</p>
<p>This level of overhead may be feasible if your organisation is really large or well-funded, but it’s less doable for everyone else.</p>
<p>Given all of this cost and the prospect of bad performance, at some point we should probably look at the benefits we’re getting in return for these JS-heavy approaches. We’ve talked about the promises, but what is reality like?</p>
<h3 id="is-react-worth-it">Is React worth it?</h3>
<p>I’m going to make things a bit more concrete for this section, and talk about <code>React</code> and its ecosystem specifically. They’re dominant, they’ve been around for a while, and they’re what I’ve had the most SPA experience with, so they’re the best examples I’ve got.</p>
<p>I do get the appeal of building in <code>React</code>, really, I do. It’s a fun programming model, and there are inherent organisational benefits to the component paradigm it pushes so hard. There’s also a lot you can reuse out there, and maybe that gives you the confidence that you’ll spend less time in the initial implementation, leaving you longer for improvements and polish.</p>
<p>And that’s fair, you probably won’t find a larger ecosystem of components, libraries, and complementary frameworks, ready to use! But beyond generally poor performance, they come with another pretty big caveat: they don’t seem to last very long. In my experience, there isn’t much in the way of stability in the <code>React</code> ecosystem, or even the JS ecosystem as a whole. Perhaps that’s changing lately, but historically, I’ve seen multiple large applications end up rewriting massive portions of their code after a while, not because of product reasons, but because of dependencies:</p>
<ul>
<li><code>React</code> hooks were meant to be an alternative to class-based components, but their adoption by the broader ecosystem forced substantial rewrites, as keeping class-based components (which can’t use hooks directly) in your code became less feasible.</li>
<li>The concurrency changes in <code>React</code> 18 forced many components to be rewritten to avoid practices that were formerly fine.</li>
<li>The deprecation of Enzyme forced projects to rewrite their entire test suites.</li>
<li>Some long-lived projects went through multiple state management architectures, as the favoured approach changed over the years, from prop drilling, to <code>Flux</code> or <code>MobX</code>, to <code>Redux</code>, to contexts, etc.</li>
</ul>
<p>Of course, I’m a developer as well, and I understand that tradeoffs are needed. When we’re building a project, there are a lot of different concerns that need to be carefully weighed so that it actually launches at some point, and in a half-decent state. So it may well be justifiable to accept all of the JS ecosystem instability, as well as some later code churn, and to view them as a reasonable price to pay for getting off the ground quickly. That’s fair.</p>
<p>That still leaves us with the issue of performance, though.</p>
<h2 id="is-performance-optional">Is performance optional?</h2>
<p>So what about performance, then? If we’re dealing with code churn, new features, and bugfixes, then we probably won’t have a lot of time for it, since as we saw, it comes with a lot of overhead in JS-heavy apps.</p>
<p>So maybe we decide that performance isn’t <strong>that</strong> important to us, and we’re better off forgoing some of the vigilance and monitoring above. If we get to it, great! If we don’t, the app will still work, and that’s what matters. And that can be a perfectly reasonable decision; less work is a good thing, as is not having to worry about performance!</p>
<p>But in the end, someone else will be making a decision: our audience. They’ll be choosing whether to use our site or not, and maybe whether to pay for it. That choice will involve how quickly they can get things done, and how “good” our site feels to use, which is non-trivially impacted by how fast it is for them.</p>
<p>In all likelihood, an unmonitored JS-heavy web app will not work well for all of our users. It’ll work great for some, sure, those with fast devices and connections that are similar to the typical developer’s, but chances are our audience is much broader than that, with all kinds of devices and connections. And so:</p>
<ul>
<li>Do we want to exclude entire classes of folks who can’t afford a high-end phone / laptop and a fast connection, and make them look at long loading screens?</li>
<li>Are we okay with having large portions of our audience see our sites through the lens of a sluggish experience, where every action makes them question whether they tapped the wrong thing or <em>“the site is just being slow again“</em>?</li>
<li>Do we want to keep sending megabytes of JavaScript down the wire (that probably doesn’t even get cached for very long because of a rapid release cycle), and inflating a pay-as-you-go customer’s bills with <strong>our code</strong> instead of <strong>their content</strong>?</li>
</ul>
<p>Is it worth it to give up on providing a great experience to a broad range of users? Opinions will vary, I’m sure, but my answer would be an emphatic “no”. We can do better than that.</p>
<h2 id="the-real-alternative-server-side-work">The real alternative: server-side work</h2>
<p>So as we’ve seen, there’s a whole host of problems when we build our web apps primarily out of JS. Most of them stem from just how expensive JS can be to run on users’ devices, and how easy it is to accidentally arrive at a place where the level of required work exceeds a device’s ability to do it in an acceptable timeframe.</p>
<details>
<summary>Just why is JS so expensive?</summary>

<p>Not all bytes are created equal, and JS is byte-for-byte the heaviest resource for a browser to handle. Parsing and compiling it are both expensive, with its complex syntax and type flexibility. When it finally does run, it mostly does so on a single thread, and can therefore only take advantage of a single core in your device’s CPU or SoC — and if it happens to be a little core in a heterogenous core architecture, it might be very slow indeed.</p>
</details>

<p>The obvious alternative is to shift all or much of this work to the server, so that even if it’s still JS (e.g. <code>nodejs</code>), it can take advantage of more powerful CPUs, dramatically higher power budgets (no battery life to worry about!), longer-lived bytecode caches, and better multi-core utilisation.</p>
<p>A server-centric architecture serves browsers with ready-to-use page content, instead of a recipe and some ingredients that allow them to build that content themselves, at their own expense.</p>
<h3 id="server-side-rendering-with-frameworks">Server-side rendering with frameworks</h3>
<p>However, not all server-side work is equally effective. While some of these JS-heavy architectures do involve a server-side rendering aspect to them, it’s often really only a band-aid, and a poorly-fitting one at that, which negates a lot of the benefits I was talking about.</p>
<p>The best example of this is probably monolithic hydration, where you render the whole page on the server, and ship both the initial markup and the application code to the user. The idea there is that the browser can use the markup to show the page quickly, without waiting for the JS, which only “hydrates“ the page with interactivity afterwards.</p>
<p>While this approach can definitely help with initial paint times, you’re still potentially shipping megabytes of JS down the wire to an unwitting user’s browser. That browser is still going to have to fetch, parse, compile, and run all that code on boot, which may end up resulting in a significant delay between the application being visible and actually being usable. So even if you solve the paint issue, there’s still the interactivity one — and you may have unwittingly made that one worse, if you’re now shipping even more JS down the wire to hydrate that initial state!</p>
<p>Partial hydration strategies can help lessen these costs, but you still need to be mindful of just how much JS is going to run at any one time and keep a watchful eye on that, which means one more thing to worry about and track.</p>
<h3 id="server-centric-models">Server-centric models</h3>
<p>The real alternative, as I see it, is to switch to a server-centric programming model, with the majority of the code intended never to leave the server. It can still be JS, too, if that’s what you prefer! Just not JS you will ever need to ship down the wire to someone’s device.</p>
<p>The server is a much more predictable and scalable environment, and more importantly, you have some level of control over it. Performance logging and debugging can be a lot easier since the bulk of the code is running on machines you manage in some way, not a vast array of wildly heterogenous computing devices entirely outside of your control. And most of the time you don’t need to worry about code size at all!</p>
<p>In a HTML-based approach, if your processing power and your content distribution strategy are sufficient for your needs, it becomes somewhat irrelevant if the user is running a high-end desktop computer with a blazingly fast CPU, or a bargain bin phone with an SoC that costs less than that desktop’s CPU cooler. Your web app will demand a lot less of your users’ devices and connections, providing a great experience to everyone.</p>
<h3 id="some-examples-of-server-centric-approaches">Some examples of server-centric approaches</h3>
<p>The obvious one is simple full-page navigation, which is the foundational architecture of the web. It has a proven track record of consistently hitting performance goals when paired with solid, globally-distributed hosting infrastructure that reduces network latency. Following this approach doesn’t mean that you can’t use JS; but you should lean towards keeping it as a sprinkle on top for some interactive bits here and there, not the engine the entire thing runs on. You can use isolated JS scripts, or other approaches like progressively-enhanced web components, and you can use as much or as little of a build process as you like to transform between source code and production code.</p>
<p>Beyond that, we’ve had various kinds of JS-lite architectures over the years that still do a great job, and have only been getting better. For example, the approach of substituting parts of the page with a new server-rendered HTML payload (made popular by e.g. <code>turbolinks</code>) still works really well, and now even has some level of native support with the <a href="https://developer.mozilla.org/en-US/docs/Web/API/View_Transition_API">View Transitions API</a>. HTML-enhancing approaches like <code>htmx</code> or WordPress’s Interactivity API are another kind of JS-lite approach, and can also serve as the foundation for many different kinds of projects.</p>
<h3 id="server-centric-isnt-a-good-fit-for-everything">Server-centric isn’t a good fit for everything</h3>
<p>Of course, we need to be realistic: not all web apps can be built like this, and some of them only really make sense as primarily client-side affairs. A highly interactive application like an editor is one such example, with server roundtrips ideally kept to a minimum, so that the user can focus on what they’re writing and not have to worry about a delay every time they click on something. They might even be willing to tolerate a longer page loading time than usual, if they see it as enough of a “destination”, and if their upcoming task (e.g. writing a post) is going to take long enough to justify the wait.</p>
<p>But even in the context of an entirely client-side application, there are many different approaches you could take, and in 2026, <code>React</code> is honestly one of the least compelling ones. It’s big, it’s slow, it’s riddled with performance pitfalls, and it’s not even fresh and exciting. It does have a huge ecosystem you can rely on, which is a really important point — albeit one that suggests that if that’s the deciding factor for you, you might be prioritising development speed above your users’ needs.</p>
<p>If you really need to go client-side, give one of the other frameworks a try! The framework runtimes are often smaller, they use finer-grained reactivity (which helps with modularity and UI responsiveness), and some of them use fundamentally different approaches that get away from the performance minefield of having to diff large trees all the time. A few have been around for a while, too, so you’re not necessarily relying on unproven dependencies.</p>
<h2 id="lets-change-the-way-we-do-things">Let’s change the way we do things</h2>
<p>To sum things up: in my experience, JS-heavy web apps usually start in a poor place, performance-wise, and they tend to get worse over time. Mitigating this requires significant overhead that is expensive to set up and maintain, and will usually still lead to performance degradation anyway — albeit at a slower rate.</p>
<p>The touted benefits are also not as obvious to me as they’re made out to be. Do frameworks actually make us more agile, and lead to a better overall user experience, or do they just trade one set of problems for another? Do they actually save us development time and effort in the long run, or does dependency-driven code churn in lasting projects undo much of that? I can’t answer any of this definitively, but I do feel that there’s a bit of a blind spot around the costs we’re paying, especially long-term.</p>
<p>Despite this, the industry perception seems to be that JS-heavy approaches are “fine”, performance-wise, and that the benefits are worth it. I find this overly optimistic, as none of the JS-heavy applications I’ve looked at in my work has ever managed to consistently hit good performance over time. Selection bias? Maybe, but <a href="https://infrequently.org/2025/11/performance-inequality-gap-2026/#content-trends">the wider landscape doesn’t provide much of a counterpoint to my anecdotes</a>.</p>
<p>I really do believe that the amount of effort needed to maintain a good level of performance in a healthy, long-running JS-heavy project is so high that it won’t be sustainable long term, in most cases. At some point, you’ll likely learn that your optimisation work was undone by unrelated changes, despite the monitoring you set up. Even if the developer that introduced the problem realised it, when deadlines clash with performance goals, the deadlines typically win.</p>
<p>This is why I’m a strong advocate for more robust systems, that make it harder to break performance in the first place.</p>
<p>Now, don’t get me wrong: building things server-side isn’t a panacea, nor is it the best fit for all projects. It’s certainly possible to build something slow on the server, and performance degradation can occur there as well. All systems have their performance challenges, and the server is no exception.</p>
<p>But maintaining a good level of performance does tend to be easier on the server, from what I’ve seen, because you’re keeping the expensive work where it makes sense: the powerful dedicated servers you own, manage, or rent; and not the slow, underpowered devices that your audience have access to. It’s also often much easier to track and log what’s happening on the server, which will greatly help with finding and fixing performance bugs, and even application logic ones. And there’s a lot less to send over the wire too, if your application code never leaves the server.</p>
<p>It’s time to stop lying to ourselves that JS-heavy client-side approaches are <strong>the way</strong> to develop a web app nowadays. We really should stop reflexively reaching for JS frameworks for everything we build, and to stop basing our architecture decisions on the stack we’re most familiar with.</p>
<p>Many use-cases are simply better suited to a server-side, HTML-centric approach, because the performance tradeoffs more closely align with the expected usage — and that really should be a part of the decision process. Instead of habitually <code>npm install</code>ing some framework boilerplate, we should take a moment to consider if we shouldn’t instead be building a multi-page application on the server.</p>
<p>Will client-side rendering really be helping, or will the user be stuck waiting for API calls anyway?</p>
<p>Will the user offset the upfront loading wait by later saving time on a number of in-app navigations or actions, or will they <a href="https://infrequently.org/2025/11/performance-inequality-gap-2026/#are-spas-working%3F">leave once they’ve done the couple of things they meant to</a>?</p>
<p>Will they get any benefit at all, as we borrow their device to do the work we could be handling on our servers?</p>
<p>We really owe it to our users to do better as an industry, because right now we’re often building the way we want to, not the way they need us to.</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why I don't think AGI is imminent (119 pts)]]></title>
            <link>https://dlants.me/agi-not-imminent.html</link>
            <guid>47028923</guid>
            <pubDate>Sun, 15 Feb 2026 23:34:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dlants.me/agi-not-imminent.html">https://dlants.me/agi-not-imminent.html</a>, See on <a href="https://news.ycombinator.com/item?id=47028923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="root"><p>February 14, 2026</p><div><ul><li><a href="#issue-1-cognitive-primitives-embodied-cognition">Issue 1: cognitive primitives, embodied cognition</a></li><li><a href="#what-about-world-models">What about world models?</a></li><li><a href="#benchmarking-the-gap">Benchmarking the gap</a></li><li><a href="#addendum-gemini-3-deep-think-and-inference-time-co">Addendum: Gemini 3 Deep Think and inference-time compute added after initial publication</a></li><li><a href="#issue-2-architecture">Issue 2: Architecture</a></li><li><a href="#revision-chain-of-thought-changes-this-picture-add">Revision: Chain of Thought changes this picture added after initial publication</a></li><li><a href="#the-discourse-problem">The Discourse Problem</a></li><li><a href="#research-labs-and-secrecy">Research Labs and Secrecy</a></li><li><a href="#what-does-this-mean">What does this mean?</a></li></ul></div><p>The CEOs of OpenAI and Anthropic have both claimed that human-level AI is just around the corner — and at times, that it's already here. These claims have generated enormous public attention. There has been some technical scrutiny of these claims, but critiques rarely reach the public discourse. This piece is a sketch of my own thinking about the boundary of transformer-based large language models and human-level cognition. I have an MS degree in Machine Learning from over a decade ago, and I don't work in the field of AI currently, but I am well-read on the underlying research. If you know more than I do about these topics, please <a href="https://dlants.me/about.html">reach out</a> and let me know, I would love to develop my thinking on this further.</p><h2 id="issue-1-cognitive-primitives-embodied-cognition"><a href="#issue-1-cognitive-primitives-embodied-cognition">Issue 1: cognitive primitives, embodied cognition</a></h2><p>Research in evolutionary neuroscience has identified a set of cognitive primitives that are <a href="https://pubmed.ncbi.nlm.nih.gov/39932126/">hardwired into vertebrate brains</a>: some of these are a sense of number, object permanence, causality, spatial navigation, and the ability to distinguish animate from inanimate motion. These capacities are <a href="https://www.nature.com/articles/s41598-024-64396-8">shared across vertebrates</a>, from fish to ungulates to primates, pointing to a common evolutionary origin hundreds of millions of years old.</p><p>Language evolved on top of these primitives — a tool for communication where both speaker and listener share the same cognitive foundation. Because both sides have always had these primitives, language takes them for granted and does not state them explicitly.</p><p>Consider the sentence "Mary held a ball." To understand it, you need to know that Mary is an animate entity capable of intentional action, that the ball is a separate, bounded, inanimate object with continuous existence through time, that Mary is roughly human-sized and upright while the ball is small enough to fit in her hand, that her hand exerts an upward force counteracting gravity, that the ball cannot pass through her palm, that releasing her grip would cause the ball to fall, and that there is one Mary and one ball, each persisting as the same entity from moment to moment, each occupying a distinct region of three-dimensional space. All of that is what a human understands from four words, and none of it is in the text. Modern LLMs are now trying to reverse-engineer this cognitive foundation from language, which is an extremely difficult task.</p><p>I find this to be useful framing for understanding many of the observed limitations of current LLM architectures. For example, transformer-based language models <a href="https://arxiv.org/abs/2410.05229">can't reliably do multi-digit arithmetic</a> because they have no number sense, only statistical patterns over digit tokens. They <a href="https://arxiv.org/abs/2309.12288">can't generalize simple logical relationships</a> — a model trained on "A is B" can't infer "B is A" — because they lack the compositional, symbolic machinery.</p><p>One might object: modern AIs are now being trained on video, not just text. And it's true that video prediction can teach something like object permanence. If you want to predict the next frame, you need to model what happens when an object passes behind an occluder, which is something like a representation of persistence. But I think the reality is more nuanced. Consider a shell game: a marble is placed under one of three cups, and the cups are shuffled. A video prediction model might learn the statistical regularity that "when a cup is lifted, a marble is usually there." But actually tracking the marble through the shuffling requires something deeper — a commitment to the marble as a <em>persistent entity</em> with a continuous trajectory through space. That's not merely a visual pattern.</p><p>The shortcomings of visual models align with this framing. Early GPT-based vision models failed at even basic spatial reasoning. Much of the recent progress has come from generating large swaths of synthetic training data. But even in this, we are trying to learn the physical and logical constraints of the real world from visual data. The results, predictably, are fragile. A model trained on synthetic shell game data could probably learn to track the marble. But I suspect that learning would not generalize to other situations and relations — it would be shell game tracking, not object permanence.</p><p>Developmental psychologist <a href="https://harvardlds.org/wp-content/uploads/2017/01/SpelkeKinzler07-1.pdf">Elizabeth Spelke's research on "core knowledge"</a> has shown that infants — including blind infants — represent objects as bounded, cohesive, spatiotemporally continuous entities. This isn't a learned visual skill. It appears to be something deeper: a fundamental category of representation that the brain uses to organize all sensory input. Objects have identity. They persist. They can't teleport or merge. This "object-ness" likely predates vision itself — it's rooted in hundreds of millions of years of organisms needing to <em>interact with things in the physical world</em>, and I think this aspect of our evolutionary "training environment" is key to our robust cognitive primitives. Organisms don't merely observe reality to predict what happens next. They perceive in order to act, and they act in order to perceive. Object permanence allows you to track prey behind an obstacle. Number sense lets you estimate whether you're outnumbered. Logical composition enables tool construction and use. Spatial navigation helps you find your way home. Every cognitive primitive is directly linked to action in a rich, multisensory, physical world.</p><p>As Rodney Brooks <a href="https://rodneybrooks.com/why-todays-humanoids-wont-learn-dexterity/">has pointed out</a>, even human dexterity is a tight coupling of fine motor control and rich sensory feedback. Modern robots do not have nearly as rich of sensory information available to them. While LLMs have benefited from vast quantities of text, video, and audio available on the internet, we simply don't have large-scale datasets of rich, multisensory perception coupled to intentional action. Collecting or generating such data is extremely challenging.</p><h2 id="what-about-world-models"><a href="#what-about-world-models">What about world models?</a></h2><p>What if we built simulated environments where AIs could gather embodied experience? Would we be able to create learning scenarios where agents could learn some of these cognitive primitives, and could that generalize to improve LLMs? There are a few papers that I found that poke in this direction.</p><p>Google DeepMind's <a href="https://arxiv.org/abs/2512.04797">SIMA 2</a> is one. Despite the "embodied agent" branding, SIMA 2 is primarily trained through behavioral cloning: it watches human gameplay videos and learns to predict what actions they took. The reasoning and planning come from its base model (Gemini Flash-Lite), which was pretrained on internet text and images — not from embodied experience. There is an RL self-improvement stage where the agent does interact with environments, but this is secondary; the core intelligence is borrowed from language pretraining. SIMA 2 reaches near-human performance on many game tasks, but what it's really demonstrating is that a powerful language model can be taught to output keyboard actions.</p><p>Can insights from world-model training actually transfer to and improve language understanding? DeepMind's researchers explicitly frame this as a trade off between two competing objectives: "embodied competence" (acting effectively in 3D worlds) and "general reasoning" (the language and math abilities from pretraining). They found that baseline Gemini models, despite being powerful language models, achieved only 3-7% success rates on embodied tasks — demonstrating that embodied competence is not something that emerges from language pretraining. After fine-tuning on gameplay data, SIMA 2 achieved near-human performance on embodied tasks while showing "only minor regression" on language and math benchmarks. But notice the framing: the <em>best case</em> is that embodied training doesn't <em>hurt</em> language ability too much. There's no evidence that it <em>improves</em> it. The two capabilities sit in separate regions of the model's parameter space, coexisting but not meaningfully interacting. LLMs have billions of parameters, and there is plenty of room in those weights to predict language and to model a physical world <em>separately</em>. Bridging that gap — using physical understanding to actually improve language reasoning — remains undemonstrated.</p><p>DeepMind's <a href="https://arxiv.org/abs/2509.24527">Dreamer 4</a> also hints at this direction. Rather than borrowing intelligence from a language model, Dreamer 4 learns a world model from gameplay footage, then trains an RL agent within that world model through simulated rollouts where the agent takes actions, observes consequences provided by the world model, and updates its policy. This is genuinely closer to perception-action coupling: the agent learns <em>through</em> acting. However, the goal of this research is not general intelligence — it's sample-efficient control for robotics. The agent is trained and evaluated on predefined task milestones (get wood, craft pickaxe, find diamond), scored by a learned reward model. Nobody has tested whether the representations learned through this sort of training generalize to reasoning, language, or anything beyond the specific control tasks they were trained on. The gap between "an agent that learns to get diamonds in Minecraft through simulated practice" and "embodied experience that produces transferable cognitive primitives" is enormous and entirely unexplored.</p><p>As far as I understand, we don't know how to:</p><ul><li><p>embed an agent in a perception-action coupled training environment</p></li><li><p>create an objective and training process that leads it to learn cognitive primitives like spatial reasoning or object permanence</p></li><li><p>leverage this to improve language models or move closer to general artificial intelligence</p></li></ul><p>Recent benchmarking work underscores how far we are. Stanford's <a href="https://arxiv.org/abs/2511.20937">ENACT benchmark</a> (2025) tested whether frontier vision-language models exhibit signs of embodied cognition — things like affordance recognition, action-effect reasoning, and long-horizon memory. The results were stark: current models lag significantly behind humans, and the gap <em>widens</em> as tasks require longer interaction horizons.</p><p>In short: world models are a genuinely exciting direction, and they could be the path to learning foundational primitives like object permanence, causality, and affordance. But this work is still in the absolute earliest stages. Transformers were an incredible leap forward, which is why we can now have things like the ENACT benchmark which better illustrate the boundaries of cognition. I think this area is really promising, but research in this space could easily take decades.</p><p>I will also mention that the most prominent "world model" comes from Yann LeCun, who recently left Meta to start <a href="https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/">AMI Labs</a>. His <a href="https://openreview.net/pdf?id=BZ5a1r-kVsf">Joint Embedding Predictive Architecture (JEPA)</a> is a representation learning method: it trains a Vision Transformer on video data, masking parts of the input and predicting their abstract representations rather than their raw pixels. The innovation is predicting in representation space rather than input space, which lets the model focus on high-level structure and ignore unpredictable low-level details. This is a genuine improvement over generative approaches for learning useful embeddings. But despite the "world model" branding, JEPA's actual implementations (I-JEPA, V-JEPA, V-JEPA 2) are still training on passively observed video — not on agents embedded in physics simulations. There is no perception-action coupling, no closed-loop interaction with an environment. JEPA is a more sophisticated way to learn from observation, but by the logic of the argument above, observation alone is unlikely to yield the cognitive primitives that emerge from acting in the world.</p><h2 id="benchmarking-the-gap"><a href="#benchmarking-the-gap">Benchmarking the gap</a></h2><p>The <a href="https://arcprize.org/">ARC-AGI benchmark</a> offers an important illustration of where these primitives show up. ARC tasks are grid-based visual puzzles that test abstract reasoning: spatial composition, symmetry, relational abstraction, and few-shot generalization. They require no world knowledge or language — just the ability to infer abstract rules from a handful of examples and apply them to novel cases. Humans solve these tasks trivially, usually in under two attempts. When <a href="https://arcprize.org/blog/announcing-arc-agi-2-and-arc-prize-2025">ARC-AGI-2</a> launched in March 2025, pure LLMs scored 0% and frontier reasoning systems achieved only single-digit percentages. By the end of the year, <a href="https://arcprize.org/blog/arc-prize-2025-results-analysis">refinement-loop systems</a> — scaffolding that wraps a model in iterative generate-verify-refine cycles — pushed scores to <a href="https://poetiq.ai/posts/arcagi_verified/">54% on the semi-private eval</a> and as high as 75% on the public eval using GPT-5.2, surpassing the 60% human average. But the nature of this progress matters as much as the numbers.</p><p>The nature of this progress is telling: the top standalone model without <a href="https://arxiv.org/abs/2601.10904">refinement</a> scaffolding — Claude Opus 4.5 — scores 37.6%. It takes a <a href="https://poetiq.ai/posts/arcagi_verified/">refinement harness</a> running dozens of iterative generate-verify-refine cycles at $30/task to push that to 54%, and a combination of GPT-5.2's strongest reasoning mode plus such a harness to reach 75%. This is not behavior that comes out of the core transformer architecture — it is scaffolded brute-force search, with each percentage point requiring substantially more compute. The <a href="https://arcprize.org/competitions/2025/">ARC Prize Grand Prize</a> at 85% remains unclaimed.</p><p>ARC is important because it illustrates the kind of abstract reasoning that seems central to intelligence. For humans, these capabilities arose from embodied experience. It's conceivable that training methods operating in purely abstract or logical spaces could teach an agent similar primitives without embodiment. We simply don't know yet. Research in this direction is just beginning, catalyzed by benchmarks like ARC that are sharpening our understanding of the boundary between what LLMs do and what intelligence actually requires. Notably, the benchmark itself is evolving in this direction <a href="https://arxiv.org/abs/2601.10904">ARC-AGI-3</a> introduces interactive reasoning challenges requiring exploration, planning, memory, and goal acquisition — moving closer to the perception-action coupling that I argue is central to intelligence.</p><p>It's worth addressing a common counterargument here: AI models have saturated many benchmarks in recent years, and we have to keep introducing new ones. Isn't this just moving the goalposts? I don't think this framing is true - benchmark saturation is exactly how we learn what a benchmark was actually measuring. Creating different benchmarks in response is not goalpost-moving — it's the normal process of refining our instruments and understanding. The "G" in AGI stands for "general" — truly general intelligence should transfer from one reasoning task to another. If a model had genuinely learned abstract reasoning from saturating one benchmark, the next benchmark testing similar capabilities should be easy, not devastating. The fact that each new generation of benchmarks consistently exposes fundamental failures is itself evidence about the nature of the gap. The ARC benchmark series illustrates this well: the progression from ARC-AGI-1 to ARC-AGI-3 didn't require heroic effort to find tasks that stump AI while remaining easy for humans - it just required refining the understanding of where the boundary lies. Tasks that are trivially easy for humans but impossible for current models are <em>abundant</em> (see multi-digit arithmetic, above). The benchmark designers aren't hunting for exotic edge cases; they're mapping a vast territory of basic cognitive capability that AI simply doesn't have.</p><h2 id="addendum-gemini-3-deep-think-and-inference-time-co"><a href="#addendum-gemini-3-deep-think-and-inference-time-co">Addendum: Gemini 3 Deep Think and inference-time compute <em>added after initial publication</em></a></h2><p>I didn't realize while writing this piece that Google DeepMind released <a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/">Gemini 3 Deep Think</a> (February 12, 2026), which scored <a href="https://arcprize.org/blog/arc-prize-2025-results-analysis">84.6% on ARC-AGI-2</a> — just shy of the 85% Grand Prize threshold. For context, the base Gemini 3 Pro model scores 31.1%. The entire 53-point gap is inference-time compute: extended reasoning chains, parallel hypothesis exploration, and search.</p><p>This result is significant. While I wasn't able to find details about the architecture behind this particular model, the <a href="https://arcprize.org/blog/arc-prize-2025-results-analysis">ARC Prize team's earlier analysis of 2025 submissions</a> identifies "refinement loops" — iterative generate-verify-refine cycles — as the central theme driving progress. The intelligence is coming from scaffolding rather than from the base model having learned general abstract reasoning. As the ARC Prize team put it:</p><blockquote><p>For the ARC-AGI-1/2 format, we believe the Grand Prize accuracy gap is now primarily bottlenecked by engineering while the efficiency gap remains bottlenecked by science and ideas. ARC Prize stands for open AGI progress, and, as we've previously committed, we will continue to run the ARC-AGI-2 Grand Prize competition in 2026 to track progress towards a fully open and reproducible solution.</p></blockquote><blockquote><p>As good as AI reasoning systems are, they still exhibit many flaws and inefficiencies necessary for AGI. We still need new ideas, like how to separate knowledge and reasoning, among others. And we'll need new benchmarks to highlight when those new ideas arrive.</p></blockquote><p>I am now really curious about how the agents will fare with AGI-3, which comes out in March 2026. Are refinement loops / search / extended CoT chains effective at general reasoning? My guess is that these techniques are specifically fitting to the geometric pattern format of AGI 1 and 2, and we'll see a big drop-off in performance on AGI-3, which will be recovered over time as teams adjust their scaffolding to the new challenges.</p><h2 id="issue-2-architecture"><a href="#issue-2-architecture">Issue 2: Architecture</a></h2><p>The transformer architectures powering current LLMs are strictly feed-forward. Information flows from tokens through successive layers to the output, and from earlier tokens to later ones, but never backward. This is partly because backpropagation — the method used to train neural networks — <a href="https://www.offconvex.org/2016/12/20/backprop/">requires acyclic computation graphs</a>. But there's also a hard practical constraint: these models have hundreds of billions of parameters and are trained on trillions of tokens, and rely heavily on reusing computation. When processing token N+1, an LLM reuses all the computation from tokens 1 through N (a technique called KV caching). This is what makes training and inference tractable at scale. But it also means the architecture is locked into a one-directional flow — processing a new token can never revisit or revise the representations of earlier ones. Any architecture that allowed backward flow would compromise this caching, requiring novel computational techniques to make it tractable at scale.</p><p>Human brains function in a fundamentally different way. The brain is not a feed-forward pipeline. Activations reverberate through recurrent, bidirectional connections, eventually settling into stable patterns. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3864796/">For every feedforward connection in the visual cortex, there is a reciprocal feedback connection</a> carrying contextual information back to earlier processing stages. When you recognize a face, it's not the output of a single forward pass — it's the result of distributed activity that echoes back and forth between regions until the system converges on an interpretation.</p><p>This is not to say that the human brain architecture is <em>necessary</em> to reach general intelligence. But the contrast helps contextualize just how constrained current LLM architectures are. There's a growing body of <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00663/120983">peer-reviewed theoretical work</a> formalizing these constraints. Merrill and Sabharwal have <a href="https://arxiv.org/abs/2207.00729">shown</a> that fixed-depth transformers with realistic (log-precision) arithmetic fall within the complexity class TC⁰ — which means they provably cannot recognize even regular languages or determine whether two nodes in a graph are connected. These are formally simple problems, well within the reach of basic algorithms, that transformers provably cannot solve in a single forward pass. This isn't an engineering limitation to be overcome with more data or compute — it's a mathematical property of the architecture itself. And Merrill and Sabharwal go further, arguing that this is a consequence of the transformer's high parallelizability: any architecture that is as parallelizable — and therefore as scalable — will hit similar walls.</p><p>What might alternative architectures look like? Gary Marcus has long advocated for other approaches, like <a href="https://arxiv.org/abs/2002.06177">neurosymbolic AI</a> — hybrid systems that combine neural networks with explicit symbolic reasoning modules for logic, compositionality, and variable binding. I think that neural architectures with feedback connections — networks that are not strictly feed-forward but allow information to flow backward and settle into stable states — could learn to represent cognitive primitives. The challenge, as discussed above, is that such architectures break the computational shortcuts that make current transformers trainable and deployable at scale. In either case, getting neurosymbolic, recurrent or bidirectional neural networks to work at the scale of modern LLMs is an open engineering and research problem.</p><h2 id="revision-chain-of-thought-changes-this-picture-add"><a href="#revision-chain-of-thought-changes-this-picture-add">Revision: Chain of Thought changes this picture <em>added after initial publication</em></a></h2><p>A <a href="https://news.ycombinator.com/item?id=47030078">reader pointed out</a> that chain of thought effectively invalidates the feed-forward argument, since we are never doing a single feed-forward pass, but instead repeated passes where preceding tokens are fed back into the network. As such, the transformer can use its own context window as a working space to solve a more complex class of problems. After this, I found a <a href="https://arxiv.org/abs/2310.07923">follow-up paper by the same authors</a> (Merrill &amp; Sabharwal, ICLR 2024) that confirms this. While a single forward pass through a transformer is limited to TC⁰, allowing the model to generate intermediate "chain of thought" tokens — where each token is the output of a new forward pass conditioned on all previous tokens — fundamentally extends its computational power. Specifically, with a polynomial number of CoT steps, a transformer can solve any problem in P.</p><p>This matters because modern "reasoning" models (OpenAI's o-series, Anthropic's Claude with extended thinking, DeepSeek R1) do exactly this: they generate long chains of intermediate reasoning tokens before producing an answer. The theoretical result says that this approach, in principle, overcomes the TC⁰ barrier I described above.</p><p>I'll admit I was a victim of anti-AI media hype on this point. I was sold on the architecture argument after reading a <a href="https://www.wired.com/story/ai-agents-math-doesnt-add-up/">Wired article</a> and <a href="https://arxiv.org/pdf/2507.07505">an accompanying paper</a> that brushed off CoT's impact on complexity, arguing that the base operation still carries the limited complexity and that token budgets are too small. In hindsight, that doesn't really address the formal result.</p><p>That said, there are important caveats. First, the theoretical result is about expressive power — what a transformer with CoT <em>could</em> compute with the right weights — not about what models actually <em>learn</em> to do. As the authors themselves note: "our lower bounds do not directly imply transformers can learn to use intermediate steps effectively." Whether current training methods (including reinforcement learning) can actually teach models to exploit this theoretical capacity is an open question.</p><p>Second, the P result works by showing that a transformer can encode the transitions of any <em>specific</em> Turing machine, with the CoT tokens serving as the tape. But AGI would require something more demanding: the feed-forward network would need to encode a <em>universal</em> Turing machine — one capable of reading a novel problem, constructing a solution strategy, and executing it. (Some smart) humans can do this. Whether a fixed-depth transformer can learn to do this through CoT, even in principle, is a much stronger claim than "CoT reaches P."</p><p>Furthermore, the systems achieving the highest scores on ARC-AGI-2 — like Gemini 3 Deep Think at 84.6% — go beyond simple sequential chain of thought. They use parallel hypothesis exploration, search over candidate solutions, and iterative refinement loops. This is a genuine extension to the feed-forward architecture: the transformer is no longer operating alone but is embedded in a broader program that orchestrates multiple inference passes, evaluates their outputs, and steers the search. In the original version of this piece, I suggested that alternative architectures with feedback connections might be needed. What's actually emerging is something different — the feedback is happening <em>outside</em> the model, in scaffolding that wraps the transformer in a loop. Whether this external scaffolding can ultimately substitute for the kind of internal recurrence I was imagining remains to be seen, but the progress is harder to dismiss than I initially thought.</p><p>So the architecture argument is weaker than I originally stated, but it isn't entirely gone. The theoretical ceiling has been raised from TC⁰ to P, which is a significant expansion. Whether models can actually reach that ceiling through current training methods, and whether P is sufficient for the kind of flexible, general reasoning that characterizes intelligence, remain open questions.</p><h2 id="the-discourse-problem"><a href="#the-discourse-problem">The Discourse Problem</a></h2><p>Most people encounter AGI through CEO proclamations. Sam Altman <a href="https://openai.com/index/reflections/">claims</a> that OpenAI knows how to build superintelligent AI. Dario Amodei <a href="https://darioamodei.com/machines-of-loving-grace">writes</a> that AI could be "smarter than a Nobel Prize winner across most relevant fields" by 2026. These are marketing statements from people whose companies depend on continued investment in the premise that AGI is imminent. They are not technical arguments.</p><p>Meanwhile, the actual research community tells a different story. A <a href="https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-FINAL.pdf">2025 survey by the Association for the Advancement of Artificial Intelligence (AAAI)</a>, surveying 475 AI researchers, found that 76% believe scaling up current AI approaches to achieve AGI is "unlikely" or "very unlikely" to succeed. The researchers cited specific limitations: difficulties in long-term planning and reasoning, generalization beyond training data, causal and counterfactual reasoning, and embodiment and real-world interaction. This is an extraordinary disconnect.</p><p>Consider the <a href="https://ai-2027.com/">AI 2027</a> scenario, perhaps the most widely-discussed AGI forecast of 2025. The <a href="https://www.aifuturesmodel.com/">underlying model's</a> first step is automating coding, which is entirely based on an extrapolation of the <a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/">METR study</a> on coding time horizons. The METR study collects coding tasks that an AI can complete with a 50% success rate, and tracks how the duration of those tasks grows over time. But task duration is not a measure of task complexity. As the ARC-AGI benchmarks illustrate, there are classes of problems that take humans only seconds to solve but that require AI systems thousands of dollars of compute and dozens of iterative refinement cycles to approach — and even then, the 85% Grand Prize threshold remains unmet. The focus on common coding tasks strongly emphasizes <em>within distribution</em> tasks, which are well-represented within the AI training set. The 50% success threshold also allows one to ignore precisely the tricky, out of distribution, short tasks that agents may not be making any progress on at all. The second step within the 2027 modeling is agents developing "research taste". My take is that research taste is going to rely heavily on the short-duration cognitive primitives that the ARC highlights but the METR metric does not capture.</p><p>I'd encourage anyone interested in this topic to seek out technical depth. Understand what these systems actually can and can't do. The real story is fascinating - it's about the fundamental nature of intelligence, and how far we still have to go to understand it.</p><h2 id="research-labs-and-secrecy"><a href="#research-labs-and-secrecy">Research Labs and Secrecy</a></h2><p>Betting against AI is difficult currently, due to the sheer amount of capital being thrown at it. One thing I've spent a lot of time thinking about is — what if there's a lab somewhere out there that's about to crack this? Maybe there are labs — even within OpenAI and Anthropic themselves — that are already working on all of these problems and keeping them secret?</p><p>But the open questions described above are not the kind of problem a secret lab can solve. They are long-standing problems that span multiple different fields — embodied cognition, evolutionary neuroscience, architecture design and complexity theory, training methodology and generalizability. Solving problems like this requires a global research community working across disciplines over many years, with plenty of dead ends along the way. This is high-risk, low-probability-of-reward, researchers-tinkering-in-a-lab kind of work. It's not a sprint towards a finish line.</p><p>This also helps us frame what AI companies are actually doing. They're buying up GPUs, building data centers, expanding product surface area, securing more funding. They are scaling up the current paradigm, which doesn't really have bearing on the fundamental research that can make progress in the problems highlighted above.</p><h2 id="what-does-this-mean"><a href="#what-does-this-mean">What does this mean?</a></h2><p>I'm not saying that AGI is impossible, or even that it won't come within our lifetime. I fully believe neural networks, using appropriate architectures and training methods, can represent cognitive primitives and reach superhuman intelligence. They can probably do this without repeating our long evolutionary history, by training in simulated logical / symbolic simulations that have little to do with the physical world. I am also not saying that LLMs aren't useful. Even the current technology is fundamentally transforming our society (see <a href="https://dlants.me/ai-mid.html">AI is not mid - a response to Dr. Cottom’s NYT Op-Ed</a>)</p><p>We have to remember though that neural networks have their origins in the 1950's. Modern backpropagation was popularized in 1986. Many of the advances that made modern GPTs possible were discovered gradually over the following decades:</p><ul><li><p>Long Short-Term Memory (LSTM) networks, which solved the vanishing gradient problem for sequence modeling — Hochreiter and Schmidhuber, 1997</p></li><li><p>Attention mechanisms, which allowed models to dynamically focus on relevant parts of their input — Bahdanau et al., 2014</p></li><li><p>Residual connections (skip layers), which made it possible to train networks hundreds of layers deep — He et al., 2015</p></li><li><p>The transformer architecture itself, which combined attention with parallelizable training to replace recurrent networks entirely — Vaswani et al., 2017</p></li></ul><p>Transformers have fundamental limitations. They are very powerful, and they have taught us a lot about what general intelligence is. We are gaining a more and more crisp understanding of where the boundaries lie. But solving these problems will require research, which is a non-linear processs full of dead ends and plateaus. It could take decades, and even then we might discover new and more nuanced issues.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Thiel: 2,436 emails with Epstein from 2014 to 2019 (222 pts)]]></title>
            <link>https://jmail.world/wiki/peter-thiel</link>
            <guid>47028369</guid>
            <pubDate>Sun, 15 Feb 2026 22:29:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jmail.world/wiki/peter-thiel">https://jmail.world/wiki/peter-thiel</a>, See on <a href="https://news.ycombinator.com/item?id=47028369">Hacker News</a></p>
<div id="readability-page-1" class="page"><!--$?--><template id="B:1"></template><!--/$--><title>Peter Thiel — The Jmail Encyclopedia</title><meta name="description" content="Peter Thiel — The Jmail Encyclopedia. Sourced from 2,429 emails across 1,345 threads in the Jmail archive."><meta name="author" content="Luke Igel"><meta name="author" content="Riley Walz"><meta name="creator" content="Luke Igel &amp; Riley Walz"><meta name="publisher" content="Kino AI"><meta name="robots" content="index, follow"><meta name="googlebot" content="index, follow"><meta property="og:title" content="Peter Thiel — The Jmail Encyclopedia"><meta property="og:description" content="Peter Thiel — The Jmail Encyclopedia. Sourced from 2,429 emails across 1,345 threads in the Jmail archive."><meta property="og:url" content="https://jmail.world/wiki/peter-thiel"><meta property="og:site_name" content="Jmail"><meta property="og:image" content="https://jmail.world/api/og/jwiki/peter-thiel"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Peter Thiel — The Jmail Encyclopedia"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@jmailarchive"><meta name="twitter:title" content="Peter Thiel — The Jmail Encyclopedia"><meta name="twitter:description" content="Peter Thiel — The Jmail Encyclopedia. Sourced from 2,429 emails across 1,345 threads in the Jmail archive."><meta name="twitter:image" content="https://jmail.world/api/og/jwiki/peter-thiel"></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magnus Carlsen Wins the Freestyle (Chess960) World Championship (343 pts)]]></title>
            <link>https://www.fide.com/magnus-carlsen-wins-2026-fide-freestyle-world-championship/</link>
            <guid>47028227</guid>
            <pubDate>Sun, 15 Feb 2026 22:17:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fide.com/magnus-carlsen-wins-2026-fide-freestyle-world-championship/">https://www.fide.com/magnus-carlsen-wins-2026-fide-freestyle-world-championship/</a>, See on <a href="https://news.ycombinator.com/item?id=47028227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="377e8e4" data-element_type="widget" data-elementor-type="wp-post" data-elementor-id="43662" data-elementor-post-type="post" data-widget_type="theme-post-content.default">
				<div data-id="815ffae" data-element_type="widget" data-widget_type="image.default">
				<p><img fetchpriority="high" decoding="async" width="1000" height="605" src="https://www.fide.com/wp-content/uploads/FS-D03.jpg" alt="" srcset="https://www.fide.com/wp-content/uploads/FS-D03.jpg 1000w, https://www.fide.com/wp-content/uploads/FS-D03-300x182.jpg 300w, https://www.fide.com/wp-content/uploads/FS-D03-768x465.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">															</p>
				</div>
				<div data-id="13c5e19" data-element_type="widget" data-widget_type="text-editor.default">
									<p><strong>Magnus Carlsen</strong> (Norway) is the 2026 FIDE Freestyle Chess World Champion. A draw in the fourth and final game against <strong>Fabiano Caruana</strong> (USA) was enough to seal a 2.5–1.5 match victory in Weissenhaus, Germany.</p><p><span>&nbsp;</span><span>The decisive moment came in game three. Carlsen won from a dead lost position, turning the match in his favor. Entering the final game, he needed only a draw and achieved it in an equal endgame after Caruana missed late chances to mount a comeback. Both finalists qualified for the 2027 FIDE Freestyle Chess World Championship.</span></p>								</div>
				<div data-id="3d4b435" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" width="1000" height="661" src="https://www.fide.com/wp-content/uploads/FS-D03-Carlsen-Caruana.jpg" alt="" srcset="https://www.fide.com/wp-content/uploads/FS-D03-Carlsen-Caruana.jpg 1000w, https://www.fide.com/wp-content/uploads/FS-D03-Carlsen-Caruana-300x198.jpg 300w, https://www.fide.com/wp-content/uploads/FS-D03-Carlsen-Caruana-768x508.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">															</p>
				</div>
				<div data-id="cb9359c" data-element_type="widget" data-widget_type="text-editor.default">
									<p>The 2026 tournament marks the first official FIDE-recognized Freestyle Chess World Championship. World number one Carlsen had previously attempted to win the FIDE Fischer Random World Championship without success. In Weissenhaus, he secured the official FIDE Freestyle Chess title – his 21st world title across formats.</p><p><span>&nbsp;</span><span>In the match for third place, <strong>Nodirbek Abdusattorov</strong> (Uzbekistan) defeated <strong>Vincent Keymer</strong> (Germany). Abdusattorov secured the match by drawing a winning position in the final game, also ensuring qualification for the 2027 championship.</span></p>								</div>
				<div data-id="27aa71b" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" width="1000" height="670" src="https://www.fide.com/wp-content/uploads/FS-D03-Abdusattorov-Keymer.jpg" alt="" srcset="https://www.fide.com/wp-content/uploads/FS-D03-Abdusattorov-Keymer.jpg 1000w, https://www.fide.com/wp-content/uploads/FS-D03-Abdusattorov-Keymer-300x201.jpg 300w, https://www.fide.com/wp-content/uploads/FS-D03-Abdusattorov-Keymer-768x515.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">															</p>
				</div>
				<div data-id="55d317e" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span><strong>Hans Niemann</strong> (USA) took fifth place with a 2–0 victory over <strong>Arjun Erigaisi</strong> (India), while <strong>Levon Aronian</strong> (USA) won his Armageddon against <strong>Javokhir Sindarov</strong> (Uzbekistan) to take seventh place.</span></p><p>In the women’s exhibition match, <strong>Bibisara Assaubayeva</strong> (Kazakhstan) prevailed over <strong>Alexandra Kosteniuk</strong> (Switzerland) after winning the third game and drawing the fourth.</p>								</div>
				<div data-id="b1752d4" data-element_type="widget" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="1000" height="670" src="https://www.fide.com/wp-content/uploads/FS-D03-Kosteniuk-Assaubayeva.jpg" alt="" srcset="https://www.fide.com/wp-content/uploads/FS-D03-Kosteniuk-Assaubayeva.jpg 1000w, https://www.fide.com/wp-content/uploads/FS-D03-Kosteniuk-Assaubayeva-300x201.jpg 300w, https://www.fide.com/wp-content/uploads/FS-D03-Kosteniuk-Assaubayeva-768x515.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">															</p>
				</div>
				<div data-id="20a76b5" data-element_type="widget" data-widget_type="text-editor.default">
									<p><strong>Key facts</strong>:</p><ul><li><span>⁠</span><span>⁠<span>Location: Weissenhaus, Germany</span></span></li><li><span><span>⁠</span><span>Dates: February 13–15, 2026</span></span></li><li><span><span>⁠</span><span>Prize fund: $300,000</span></span></li><li><span><span>⁠</span><span>Winner’s prize: $100,000</span></span></li><li><span><span>⁠</span><span>Top three qualify for 2027</span></span></li></ul><p><span>&nbsp;</span><span>A full report is available <a href="https://www.freestyle-chess.com/news/magnus-carlsen-wins-fide-freestyle-chess-world-championship/"><strong>[HERE]</strong></a>.</span></p><p><strong>Written by Till Behrend</strong></p><p><strong>Photos: Lennart Ootes and Steve Bonhage / Freestyle Chess</strong></p><p>Official website:&nbsp;<strong><a href="https://www.freestyle-chess.com/">https://www.freestyle-chess.com/</a></strong></p>								</div>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I’m joining OpenAI (1296 pts)]]></title>
            <link>https://steipete.me/posts/2026/openclaw</link>
            <guid>47028013</guid>
            <pubDate>Sun, 15 Feb 2026 21:54:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steipete.me/posts/2026/openclaw">https://steipete.me/posts/2026/openclaw</a>, See on <a href="https://news.ycombinator.com/item?id=47028013">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" data-astro-cid-vj4tpspi="">  <p><strong>tl;dr: I’m joining OpenAI to work on bringing agents to everyone. <a href="https://openclaw.ai/">OpenClaw</a> will move to a foundation and stay open and independent.</strong></p>
<p>The last month was a whirlwind, never would I have expected that my playground project would create such waves. The internet got weird again, and it’s been incredibly fun to see how my work inspired so many people around the world.</p>
<p>There’s an endless array of possibilities that opened up for me, countless people trying to push me into various directions, giving me advice, asking how they can invest or what I will do. Saying it’s overwhelming is an understatement.</p>
<p>When I started exploring AI, my goal was to have fun and inspire people. And here we are, the lobster is taking over the world. My next mission is to build an agent that even my mum can use. That’ll need a much broader change, a lot more thought on how to do it safely, and access to the very latest models and research.</p>
<p>Yes, I could totally see how OpenClaw could become a huge company. And no, it’s not really exciting for me. I’m a builder at heart. I did the whole creating-a-company game already, poured 13 years of my life into it and learned a lot. What I want is to change the world, not build a large company and teaming up with OpenAI is the fastest way to bring this to everyone.</p>
<p>I spent last week in San Francisco talking with the major labs, getting access to people and unreleased research, and it’s been inspiring on all fronts. I want to thank all the folks I talked to this week and am thankful for the opportunities.</p>
<p>It’s always been important to me that OpenClaw stays open source and given the freedom to flourish. Ultimately, I felt OpenAI was the best place to continue pushing on my vision and expand its reach. The more I talked with the people there, the clearer it became that we both share the same vision.</p>
<p>The community around OpenClaw is something magical and OpenAI has made strong commitments to enable me to dedicate my time to it and already sponsors the project. To get this into a proper structure I’m working on making it a foundation. It will stay a place for thinkers, hackers and people that want a way to own their data, with the goal of supporting even more models and companies.</p>
<p>Personally I’m super excited to join OpenAI, be part of the frontier of AI research and development, and continue building with all of you.</p>
<p>The claw is the law.</p>
<p><img src="https://steipete.me/assets/img/2026/openclaw/clawcon.jpg" alt="ClawCon" loading="lazy"></p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[State Attorneys General Want to Tie Online Access to ID (145 pts)]]></title>
            <link>https://reclaimthenet.org/40-attorneys-general-back-ids-online-safety-act</link>
            <guid>47026848</guid>
            <pubDate>Sun, 15 Feb 2026 19:49:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reclaimthenet.org/40-attorneys-general-back-ids-online-safety-act">https://reclaimthenet.org/40-attorneys-general-back-ids-online-safety-act</a>, See on <a href="https://news.ycombinator.com/item?id=47026848">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="7eda0c13" data-element_type="widget" data-e-type="widget" data-widget_type="theme-post-content.default">
					<p>A bloc of 40 state and territorial attorneys general is urging Congress to adopt the Senate’s version of the controversial <a href="https://reclaimthenet.org/kids-online-safety-act-kosa-privacy-surveillance-concerns-2025">Kids Online Safety Act</a>, positioning it as the stronger regulatory instrument and rejecting the House companion as insufficient.</p>
<p>The Act would kill online anonymity and tie online activity and speech to a real-world identity.</p>
<p>Acting through the National Association of Attorneys General, the coalition sent a letter to congressional leadership endorsing S. 1748 and opposing H.R. 6484.</p>
<p><strong>We obtained a copy of the letter for you <a href="https://docs.reclaimthenet.org/ag-letter-supporting-senate-kosa-february-10-2026.pdf">here</a>.</strong></p><div data-id="eb333a5" data-element_type="container" data-e-type="container" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}" data-elementor-type="section" data-elementor-id="235992" data-elementor-post-type="elementor_library">
				<div data-id="4678215" data-element_type="widget" data-e-type="widget" data-widget_type="text-editor.default">
				<p>Reclaim Your Digital Freedom.</p>
				</div>
				<div data-id="fe169cc" data-element_type="widget" data-e-type="widget" data-widget_type="text-editor.default">
				<p>Get unfiltered coverage of surveillance, censorship, and the technology threatening your civil liberties.</p>
				</div>
				
					</div>

<p>Their request centers on structural differences between the bills. The Senate proposal would create a federally enforceable “Duty of Care” requiring covered platforms to mitigate defined harms to minors.</p>
<p>Enforcement authority would rest with the Federal Trade Commission, which could investigate and sue companies that fail to prevent minors from encountering content deemed to cause “harm to minors.”</p>
<p>That framework would require regulators to evaluate internal content moderation systems, recommendation algorithms, and safety controls.</p>
<p>S. 1748 also directs the Secretary of Commerce, the FTC, and the Federal Communications Commission to study “the most technologically feasible methods and options for developing systems to verify age at the device or operating system level.”</p>
<p>This language moves beyond platform-level age gates and toward infrastructure embedded directly into hardware or operating systems.</p>
<p>Age verification at that layer would not function without some form of credentialing. Device-level verification would likely depend on digital identity checks tied to government-issued identification, third-party age verification vendors, or persistent account authentication systems.</p>
<p>That means users could be required to submit identifying information before accessing broad categories of lawful online speech.&nbsp;Anonymous browsing depends on the ability to access content without linking identity credentials to activity.</p>
<p>A device-level age verification architecture would establish identity checkpoints upstream of content access, creating records that age was verified and potentially associating that verification with a persistent device or account.</p>
<p>Even if content is not stored, the existence of a verified identity token tied to access creates a paper trail.</p>
<p>Constitutional questions follow. The Supreme Court has repeatedly recognized anonymous speech as protected under the First Amendment. Mandating identity verification before accessing lawful speech raises prior restraint and overbreadth concerns, particularly where the definition of “harm to minors” extends into categories that are legal for adults.</p>
<p>Courts have struck down earlier <a href="https://reclaimthenet.org/texas-app-store-accountability-act-blocked-federal-judge-first-amendment">efforts to impose age verification requirements</a> for online content on First Amendment grounds, citing the chilling effect on lawful expression and adult access.</p>
<p>Despite this history, state officials continue to advocate for broader age verification regimes. Several states have enacted or proposed laws requiring age checks for social media or adult content sites, often triggering litigation over compelled identification and privacy burdens.</p>
<p>The coalition’s letter suggests that state attorneys general are not retreating from that position and are instead seeking federal backing.</p>
<p>The attorneys general argue that social media companies deliberately design products that draw in underage users and monetize their personal data through targeted advertising. They contend that companies have not adequately disclosed addictive features or mental health risks and point to evidence suggesting firms are aware of adverse consequences for minors.</p>
<p>Multiple state offices have already filed lawsuits or opened investigations against Meta and TikTok, alleging “harm” to young users.</p>
<p>At the same time, the coalition objects to provisions in H.R. 6484 that would limit state authority. The House bill contains broader federal preemption language, which could restrict states from enforcing parallel or more stringent requirements. The attorneys general warn that this would curb their ability to pursue emerging online harms under state law. They also fault the House proposal for relying on company-maintained “reasonable policies, practices, and procedures” rather than imposing a statutory Duty of Care.</p>
<p>The Senate approach couples enforceable federal standards with preserved state enforcement power.</p>
<p>The coalition calls on the United States House of Representatives to align with the Senate framework, expand the list of enumerated harms to include even suicide, eating disorders, compulsive use, mental health harms, and financial harms, and ensure that states retain authority to act alongside federal regulators. The measure has bipartisan sponsorship in the United States Senate.</p>
<p>The policy direction is clear. Federal agencies would study device-level age verification systems, the FTC would police compliance with harm mitigation duties, and states would continue to pursue parallel litigation. Those mechanisms would reshape how platforms design their systems and how users access speech.</p>
<p>Whether framed as child protection or platform accountability, the architecture contemplated by S. 1748 would move identity verification closer to the heart of internet access.</p>
<p>Once age checks are embedded at the operating system level, the boundary between verifying age and verifying identity becomes difficult to maintain.</p>
<p>The internet would be changed forever.</p>
<!-- CONTENT END 1 -->
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Microgpt is a GPT you can visualize in the browser (263 pts)]]></title>
            <link>https://microgpt.boratto.ca</link>
            <guid>47026186</guid>
            <pubDate>Sun, 15 Feb 2026 18:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microgpt.boratto.ca">https://microgpt.boratto.ca</a>, See on <a href="https://news.ycombinator.com/item?id=47026186">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Towards Autonomous Mathematics Research (103 pts)]]></title>
            <link>https://arxiv.org/abs/2602.10177</link>
            <guid>47026134</guid>
            <pubDate>Sun, 15 Feb 2026 18:35:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2602.10177">https://arxiv.org/abs/2602.10177</a>, See on <a href="https://news.ycombinator.com/item?id=47026134">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+T" rel="nofollow">Tony Feng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trinh,+T+H" rel="nofollow">Trieu H. Trinh</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bingham,+G" rel="nofollow">Garrett Bingham</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hwang,+D" rel="nofollow">Dawsen Hwang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chervonyi,+Y" rel="nofollow">Yuri Chervonyi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung,+J" rel="nofollow">Junehyuk Jung</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+J" rel="nofollow">Joonkyung Lee</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pagano,+C" rel="nofollow">Carlo Pagano</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+S" rel="nofollow">Sang-hyun Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasqualotto,+F" rel="nofollow">Federico Pasqualotto</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gukov,+S" rel="nofollow">Sergei Gukov</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+J+N" rel="nofollow">Jonathan N. Lee</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+J" rel="nofollow">Junsu Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou,+K" rel="nofollow">Kaiying Hou</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghiasi,+G" rel="nofollow">Golnaz Ghiasi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tay,+Y" rel="nofollow">Yi Tay</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y" rel="nofollow">YaGuang Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuang,+C" rel="nofollow">Chenkai Kuang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y" rel="nofollow">Yuan Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin,+H" rel="nofollow">Hanzhao Lin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+E+Z" rel="nofollow">Evan Zheran Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nayakanti,+N" rel="nofollow">Nigamaa Nayakanti</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+X" rel="nofollow">Xiaomeng Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+H" rel="nofollow">Heng-Tze Cheng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassabis,+D" rel="nofollow">Demis Hassabis</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kavukcuoglu,+K" rel="nofollow">Koray Kavukcuoglu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le,+Q+V" rel="nofollow">Quoc V. Le</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luong,+T" rel="nofollow">Thang Luong</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2602.10177">View PDF</a>
    <a href="https://arxiv.org/html/2602.10177v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research. We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom's Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest quantifying standard levels of autonomy and novelty of AI-assisted results, as well as propose a novel concept of human-AI interaction cards for transparency. We conclude with reflections on human-AI collaboration in mathematics and share all prompts as well as model outputs at <a href="https://github.com/google-deepmind/superhuman/tree/main/aletheia" rel="external noopener nofollow">this https URL</a>.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Thang Luong [<a href="https://arxiv.org/show-email/33fda5ca/2602.10177" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2602.10177v1" rel="nofollow">[v1]</a></strong>
        Tue, 10 Feb 2026 18:50:15 UTC (2,611 KB)<br>
    <strong>[v2]</strong>
        Thu, 12 Feb 2026 18:27:29 UTC (2,612 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Editor's Note: Retraction of article containing fabricated quotations (285 pts)]]></title>
            <link>https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/</link>
            <guid>47026071</guid>
            <pubDate>Sun, 15 Feb 2026 18:29:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/">https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/</a>, See on <a href="https://news.ycombinator.com/item?id=47026071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>On Friday afternoon, Ars Technica published <a href="https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name/">an article</a> containing fabricated quotations generated by an AI tool and attributed to a source who did not say them. That is a serious failure of our standards. Direct quotations must always reflect what a source actually said.</p>
<p>That this happened at Ars is especially distressing. We have covered the risks of overreliance on AI tools for years, and our written policy reflects those concerns. In this case, fabricated quotations were published in a manner inconsistent with that policy. We have reviewed recent work and have not identified additional issues. At this time, this appears to be an isolated incident.</p>
<p>Ars Technica does not permit the publication of AI-generated material unless it is clearly labeled and presented for demonstration purposes. That rule is not optional, and it was not followed here.</p>
<p>We regret this failure and apologize to our readers. We have also apologized to Mr. Scott Shambaugh, who was falsely quoted.</p>


          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Radio host David Greene says Google's NotebookLM tool stole his voice (159 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2026/02/15/david-greene-google-ai-podcast/</link>
            <guid>47025864</guid>
            <pubDate>Sun, 15 Feb 2026 18:05:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2026/02/15/david-greene-google-ai-podcast/">https://www.washingtonpost.com/technology/2026/02/15/david-greene-google-ai-podcast/</a>, See on <a href="https://news.ycombinator.com/item?id=47025864">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/2026/02/15/david-greene-google-ai-podcast/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Modern CSS Code Snippets: Stop writing CSS like it's 2015 (601 pts)]]></title>
            <link>https://modern-css.com</link>
            <guid>47025851</guid>
            <pubDate>Sun, 15 Feb 2026 18:04:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modern-css.com">https://modern-css.com</a>, See on <a href="https://news.ycombinator.com/item?id=47025851">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="all-comparisons">
    
    <p><span>Browser compatibility:</span>
      
      
      
      
    </p>
    <div id="tipsGrid">
            <a href="https://modern-css.com/range-style-queries-without-multiple-blocks/" data-baseline="limited">
        <div>
          
          <h3>Range style queries without multiple blocks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>/* Multiple style() blocks */</span><br><span>@container</span> <span>style</span>(<span>--p: 51%</span>) {}<br><span>@container</span> <span>style</span>(<span>--p: 52%</span>) {}<br><span>/* ...for each value */</span></span>
          </p>
          <p><span>Modern</span>
            <span>@container</span> <span>style</span>(<br>&nbsp;&nbsp;<span>--progress &gt; 50%</span><br>) {<br>&nbsp;&nbsp;<span>.bar</span> { ... }<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/sticky-snapped-styling-without-javascript/" data-baseline="limited">
        <div>
          
          <h3>Sticky &amp; snapped element styling without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>window</span>.<span>addEventListener</span>(<br>&nbsp;&nbsp;<span>'scroll'</span>, () =&gt; {<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>/* check position */</span><br>});</span>
          </p>
          <p><span>Modern</span>
            <span>@container</span> <span>scroll-state</span>(<br>&nbsp;&nbsp;<span>stuck: top</span><br>) {<br>&nbsp;&nbsp;<span>.header</span> { ... }<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/typed-attribute-values-without-javascript/" data-baseline="limited">
        <div>
          
          <h3>Typed attribute values without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JS reading dataset</span><br><span>el</span>.<span>style</span>.<span>width</span> =<br>&nbsp;&nbsp;<span>el</span>.<span>dataset</span>.<span>pct</span> + <span>'%'</span>;</span>
          </p>
          <p><span>Modern</span>
            <span>.bar</span> {<br>&nbsp;&nbsp;<span>width</span>: <span>attr</span>(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>data-pct</span> <span>type</span>(<span>&lt;percentage&gt;</span>)<br>&nbsp;&nbsp;);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/inline-conditional-styles-without-javascript/" data-baseline="limited">
        <div>
          
          <h3>Inline conditional styles without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JavaScript toggling</span><br><span>el</span>.<span>classList</span>.<span>toggle</span>(<br>&nbsp;&nbsp;<span>'primary'</span>, <span>isPrimary</span><br>);</span>
          </p>
          <p><span>Modern</span>
            <span>.btn</span> {<br>&nbsp;&nbsp;<span>background</span>: <span>if</span>(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>style(--variant: primary)</span>:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>blue</span>; <span>else</span>: <span>gray</span><br>&nbsp;&nbsp;);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/reusable-css-logic-without-sass-mixins/" data-baseline="limited">
        <div>
          
          <h3>Reusable CSS logic without Sass mixins</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Sass function</span><br><span>@function</span> <span>fluid</span>(<span>$min</span>, <span>$max</span>) {<br>&nbsp;&nbsp;<span>@return</span> <span>clamp</span>(...);<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>@function</span> <span>--fluid</span>(<br>&nbsp;&nbsp;<span>--min</span>, <span>--max</span><br>) {<br>&nbsp;&nbsp;<span>@return</span> <span>clamp</span>(...);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/corner-shapes-beyond-rounded-borders/" data-baseline="limited">
        <div>
          
          <h3>Corner shapes beyond rounded borders</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.card</span> {<br>&nbsp;&nbsp;<span>clip-path</span>: <span>polygon</span>(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>...</span> <span>/* 20+ points */</span><br>&nbsp;&nbsp;);<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.card</span> {<br>&nbsp;&nbsp;<span>border-radius</span>: <span>2em</span>;<br>&nbsp;&nbsp;<span>corner-shape</span>: <span>squircle</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/responsive-clip-paths-without-svg/" data-baseline="limited">
        <div>
          
          <h3>Responsive clip paths without SVG</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.shape</span> {<br>&nbsp;&nbsp;<span>clip-path</span>: <span>path</span>(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>'M0 200 L100 0...'</span><br>&nbsp;&nbsp;);<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.shape</span> {<br>&nbsp;&nbsp;<span>clip-path</span>: <span>shape</span>(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>from 0% 100%</span>, ...<br>&nbsp;&nbsp;);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/scroll-spy-without-intersection-observer/" data-baseline="limited">
        <div>
          
          <h3>Scroll spy without IntersectionObserver</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>const</span> <span>observer</span> = <span>new</span><br>&nbsp;&nbsp;<span>IntersectionObserver</span>(cb);<br><span>/* 15+ lines of JS */</span></span>
          </p>
          <p><span>Modern</span>
            <span>nav a</span>:<span>target-current</span> {<br>&nbsp;&nbsp;<span>color</span>: <span>var(--accent)</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/filling-available-space-without-calc-workarounds/" data-baseline="limited">
        <div>
          
          <h3>Filling available space without calc workarounds</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.full</span> {<br>&nbsp;&nbsp;<span>width</span>: <span>calc</span>(<span>100%</span> - <span>40px</span>);<br>&nbsp;&nbsp;<span>/* or width: 100% and overflow */</span><br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.full</span> {<br>&nbsp;&nbsp;<span>width</span>: <span>stretch</span>;<br>}<br><span>/* fills container, keeps margins */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/staggered-animations-without-nth-child-hacks/" data-baseline="widely">
        <div>
          
          <h3>Staggered animations without nth-child hacks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>li:nth-child(1)</span> { <span>--i</span>: <span>0</span>; }<br><span>li:nth-child(2)</span> { <span>--i</span>: <span>1</span>; }<br><span>li:nth-child(3)</span> { <span>--i</span>: <span>2</span>; }<br><span>/* repeat for every item… */</span></span>
          </p>
          <p><span>Modern</span>
            <span>li</span> {<br>&nbsp;&nbsp;<span>transition-delay</span>:<br>&nbsp;&nbsp;&nbsp;&nbsp;<span>calc</span>(<span>0.1s</span> * (<span>sibling-index()</span> - <span>1</span>));<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/carousel-navigation-without-a-javascript-library/" data-baseline="limited">
        <div>
          
          <h3>Carousel navigation without a JavaScript library</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Swiper.js or Slick carousel</span><br><span>new</span> <span>Swiper</span>(<span>'.carousel'</span>, {<br>&nbsp;&nbsp;<span>navigation</span>: { <span>/* … */</span> },<br>&nbsp;&nbsp;<span>pagination</span>: { <span>/* … */</span> },<br>});</span>
          </p>
          <p><span>Modern</span>
            <span>.carousel</span><span>::scroll-button(right)</span> {<br>&nbsp;&nbsp;<span>content</span>: <span>"➡"</span>;<br>}<br><span>.carousel li</span><span>::scroll-marker</span> {<br>&nbsp;&nbsp;<span>content</span>: <span>''</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/vertical-text-centering-without-padding-hacks/" data-baseline="limited">
        <div>
          
          <h3>Vertical text centering without padding hacks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.btn</span> {<br>&nbsp;&nbsp;<span>padding</span>: <span>10px 20px</span>;<br>&nbsp;&nbsp;<span>/* looks off-center, tweak top/bottom */</span><br>&nbsp;&nbsp;<span>padding-top</span>: <span>8px</span>; <span>/* hack */</span><br>}</span>
          </p>
          <p><span>Modern</span>
            <span>h1</span>, <span>button</span> {<br>&nbsp;&nbsp;<span>text-box</span>: <span>trim-both cap alphabetic</span>;<br>}<br><span>/* true optical centering */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/hover-tooltips-without-javascript-events/" data-baseline="limited">
        <div>
          
          <h3>Hover tooltips without JavaScript events</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JS: mouseenter + mouseleave</span><br><span>btn</span>.<span>addEventListener</span>(<span>'mouseenter'</span>,<br>&nbsp;&nbsp;() =&gt; <span>showTooltip</span>())<br><span>/* + focus, blur, positioning */</span></span>
          </p>
          <p><span>Modern</span>
            <span>&lt;button</span> <span>interestfor</span>=<span>"tip"</span><span>&gt;</span>Hover me<span>&lt;/button&gt;</span><br><span>&lt;div</span> <span>id</span>=<span>"tip"</span> <span>popover</span>=<span>hint</span><span>&gt;</span><br>&nbsp;&nbsp;Tooltip content<br><span>&lt;/div&gt;</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/modal-controls-without-onclick-handlers/" data-baseline="">
        <div>
          
          <h3>Modal controls without onclick handlers</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>&lt;button</span> <span>onclick</span>=<span>"</span><br>&nbsp;&nbsp;<span>document</span>.<span>querySelector</span>(<span>'#dlg'</span>)<br>&nbsp;&nbsp;.<span>showModal</span>()<span>"</span><span>&gt;</span>Open<span>&lt;/button&gt;</span></span>
          </p>
          <p><span>Modern</span>
            <span>&lt;button</span> <span>commandfor</span>=<span>"dlg"</span><br>&nbsp;&nbsp;<span>command</span>=<span>"show-modal"</span><span>&gt;</span>Open<span>&lt;/button&gt;</span><br><span>&lt;dialog</span> <span>id</span>=<span>"dlg"</span><span>&gt;</span>...<span>&lt;/dialog&gt;</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/dialog-light-dismiss-without-click-outside-listeners/" data-baseline="">
        <div>
          
          <h3>Dialog light dismiss without click-outside listeners</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JS: listen for click on ::backdrop</span><br><span>dialog</span>.<span>addEventListener</span>(<span>'click'</span>,<br>&nbsp;&nbsp;(e) =&gt; { <span>/* check bounds */</span> })</span>
          </p>
          <p><span>Modern</span>
            <span>&lt;dialog</span> <span>closedby</span>=<span>"any"</span><span>&gt;</span><br>&nbsp;&nbsp;Click outside to close<br><span>&lt;/dialog&gt;</span><br><span>/* no JS listeners */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/customizable-selects-without-a-javascript-library/" data-baseline="limited">
        <div>
          
          <h3>Customizable selects without a JavaScript library</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Select2 or Choices.js</span><br><span>new</span> <span>Choices</span>(<span>'#my-select'</span>);<br><span>/* rebuilds entire DOM */</span></span>
          </p>
          <p><span>Modern</span>
            <span>select</span>,<br><span>select</span> <span>::picker(select)</span> {<br>&nbsp;&nbsp;<span>appearance</span>: <span>base-select</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/vivid-colors-beyond-srgb/" data-baseline="newly">
        <div>
          
          <h3>Vivid colors beyond sRGB</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.hero</span> {<br>&nbsp;&nbsp;<span>color</span>: <span>rgb</span>(200, 80, 50);<br>}<br><span>/* sRGB only, washed on P3 */</span></span>
          </p>
          <p><span>Modern</span>
            <span>.hero</span> {<br>&nbsp;&nbsp;<span>color</span>: <span>oklch</span>(0.7 0.25 29);<br>}<br><span>/* or color(display-p3 1 0.2 0.1) */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/color-variants-without-sass-functions/" data-baseline="newly">
        <div>
          
          <h3>Color variants without Sass functions</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>/* Sass: lighten($brand, 20%), darken($brand, 10%) */</span><br><span>.btn</span> { <span>background</span>: <span>#e0e0e0</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>.btn</span> {<br>&nbsp;&nbsp;<span>background</span>: <span>oklch</span>(<span>from</span> <span>var</span>(--brand) <span>calc</span>(l + 0.2) c h);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/multiline-text-truncation-without-javascript/" data-baseline="widely">
        <div>
          
          <h3>Multiline text truncation without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>/* JS: slice text by chars/words, add "..." */</span><br><span>.card-title</span> { <span>overflow</span>: <span>hidden</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>.card-title</span> {<br>&nbsp;&nbsp;<span>display</span>: <span>-webkit-box</span>;<br>&nbsp;&nbsp;<span>-webkit-line-clamp</span>: <span>3</span>;<br>&nbsp;&nbsp;<span>line-clamp</span>: <span>3</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/drop-caps-without-float-hacks/" data-baseline="newly">
        <div>
          
          <h3>Drop caps without float hacks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.drop-cap::first-letter</span> {<br>&nbsp;&nbsp;<span>float</span>: <span>left</span>;<br>&nbsp;&nbsp;<span>font-size</span>: <span>3em</span>; <span>line-height</span>: <span>1</span>;<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.drop-cap::first-letter</span> {<br>&nbsp;&nbsp;<span>initial-letter</span>: <span>3</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/positioning-shorthand-without-four-properties/" data-baseline="widely">
        <div>
          
          <h3>Positioning shorthand without four properties</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.overlay</span> {<br>&nbsp;&nbsp;<span>top</span>: <span>0</span>; <span>right</span>: <span>0</span>;<br>&nbsp;&nbsp;<span>bottom</span>: <span>0</span>; <span>left</span>: <span>0</span>;<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.overlay</span> {<br>&nbsp;&nbsp;<span>position</span>: <span>absolute</span>;<br>&nbsp;&nbsp;<span>inset</span>: <span>0</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/lazy-rendering-without-intersection-observer/" data-baseline="newly">
        <div>
          
          <h3>Lazy rendering without IntersectionObserver</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JS IntersectionObserver</span><br><span>new</span> <span>IntersectionObserver</span>(<br>&nbsp;&nbsp;(entries) =&gt; { <span>/* render */</span> }<br>).<span>observe</span>(el);</span>
          </p>
          <p><span>Modern</span>
            <span>.section</span> {<br>&nbsp;&nbsp;<span>content-visibility</span>: <span>auto</span>;<br>&nbsp;&nbsp;<span>contain-intrinsic-size</span>: <span>auto 500px</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/dropdown-menus-without-javascript-toggles/" data-baseline="newly">
        <div>
          
          <h3>Dropdown menus without JavaScript toggles</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.menu</span> { <span>display</span>: <span>none</span>; }<br><span>.menu.open</span> { <span>display</span>: <span>block</span>; }<br><span>/* + JS: click, clickOutside, ESC, aria */</span></span>
          </p>
          <p><span>Modern</span>
            <span>button</span>[<span>popovertarget</span>=<span>menu</span>] { }<br><span>#menu</span>[<span>popover</span>] {<br>&nbsp;&nbsp;<span>position</span>: <span>absolute</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/tooltip-positioning-without-javascript/" data-baseline="limited">
        <div>
          
          <h3>Tooltip positioning without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>/* Popper.js / Floating UI: compute rect,</span><br><span>   position: fixed, update on scroll */</span><br><span>.tooltip</span> { <span>position</span>: <span>fixed</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>.trigger</span> { <span>anchor-name</span>: <span>--tip</span>; }<br><span>.tooltip</span> {<br>&nbsp;&nbsp;<span>position-anchor</span>: <span>--tip</span>;<br>&nbsp;&nbsp;<span>top</span>: <span>anchor(bottom)</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/scoped-styles-without-bem-naming/" data-baseline="newly">
        <div>
          
          <h3>Scoped styles without BEM naming</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// BEM: .card__title, .card__body</span><br><span>.card__title</span> { â€¦ }<br><span>.card__body</span> { â€¦ }<br><span>// or CSS Modules / styled-components */</span></span>
          </p>
          <p><span>Modern</span>
            <span>@scope</span> (<span>.card</span>) {<br>&nbsp;&nbsp;<span>.title</span> { <span>font-size</span>: <span>1.25rem</span>; }<br>&nbsp;&nbsp;<span>.body</span> { <span>color</span>: <span>#444</span>; }<br>}<br><span>/* .title only inside .card */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/typed-custom-properties-without-javascript/" data-baseline="newly">
        <div>
          
          <h3>Typed custom properties without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// --hue was a string, no animation</span><br><span>:root</span> { <span>--hue</span>: <span>0</span>; }<br><span>hsl</span>(<span>var</span>(<span>--hue</span>), â€¦) <span>/* no interpolation */</span></span>
          </p>
          <p><span>Modern</span>
            <span>@property</span> <span>--hue</span> {<br>&nbsp;&nbsp;<span>syntax</span>: <span>"&lt;angle&gt;"</span>;<br>&nbsp;&nbsp;<span>inherits</span>: <span>false</span>;<br>&nbsp;&nbsp;<span>initial-value</span>: <span>0deg</span>;<br>}<br><span>/* animatable, validated */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/independent-transforms-without-the-shorthand/" data-baseline="widely">
        <div>
          
          <h3>Independent transforms without the shorthand</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.icon</span> { <span>transform</span>: <span>translateX</span>(<span>10px</span>) <span>rotate</span>(<span>45deg</span>) <span>scale</span>(<span>1.2</span>); }<br><span>/* change one = rewrite all */</span></span>
          </p>
          <p><span>Modern</span>
            <span>.icon</span> {<br>&nbsp;&nbsp;<span>translate</span>: <span>10px 0</span>;<br>&nbsp;&nbsp;<span>rotate</span>: <span>45deg</span>;<br>&nbsp;&nbsp;<span>scale</span>: <span>1.2</span>;<br>}<br><span>/* animate any one without touching the rest */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/animating-display-none-without-workarounds/" data-baseline="newly">
        <div>
          
          <h3>Animating display none without workarounds</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// wait for transitionend then display:none</span><br><span>el</span>.<span>addEventListener</span>(<span>'transitionend'</span>, â€¦)<br><span>visibility</span> + <span>opacity</span> + <span>pointer-events</span></span>
          </p>
          <p><span>Modern</span>
            <span>.panel</span> { <span>transition</span>: <span>opacity .2s, overlay .2s</span>;<br>&nbsp;&nbsp;<span>transition-behavior</span>: <span>allow-discrete</span>; }<br><span>.panel.hidden</span> { <span>opacity</span>: <span>0</span>; <span>display</span>: <span>none</span>; }<br><span>/* no JS wait or visibility hack */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/entry-animations-without-javascript-timing/" data-baseline="newly">
        <div>
          
          <h3>Entry animations without JavaScript timing</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// add class after paint</span><br><span>requestAnimationFrame</span>(() =&gt; {<br>&nbsp;&nbsp;<span>el</span>.<span>classList</span>.<span>add</span>(<span>'visible'</span>);<br>});</span>
          </p>
          <p><span>Modern</span>
            <span>.card</span> { <span>transition</span>: <span>opacity .3s, transform .3s</span>; }<br><span>.card</span> { <span>@starting-style</span> { <span>opacity</span>: <span>0</span>; <span>transform</span>: <span>translateY</span>(<span>10px</span>); } }<br><span>/* no rAF/setTimeout */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/page-transitions-without-a-framework/" data-baseline="newly">
        <div>
          
          <h3>Page transitions without a framework</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Barba.js or React Transition Group</span><br><span>Barba</span>.<span>init</span>({ â€¦ })<br><span>transition</span> hooks + <span>duration</span> state</span>
          </p>
          <p><span>Modern</span>
            <span>document</span>.<span>startViewTransition</span>(() =&gt; <span>updateDOM</span>());<br><span>.hero</span> { <span>view-transition-name</span>: <span>hero</span>; }<br><span>/* no Barba, no React TG */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/scroll-snapping-without-a-carousel-library/" data-baseline="widely">
        <div>
          
          <h3>Scroll snapping without a carousel library</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Slick, Swiper, or scroll/touch JS</span><br><span>$</span>(<span>'.carousel'</span>).<span>slick</span>({ â€¦ })<br><span>touchstart</span> / <span>scroll</span> handlers</span>
          </p>
          <p><span>Modern</span>
            <span>.carousel</span> { <span>scroll-snap-type</span>: <span>x mandatory</span>; }<br><span>.carousel &gt; *</span> { <span>scroll-snap-align</span>: <span>start</span>; }<br><span>/* no lib, no touch handlers */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/balanced-headlines-without-manual-line-breaks/" data-baseline="newly">
        <div>
          
          <h3>Balanced headlines without manual line breaks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// manual &lt;br&gt; or Balance-Text.js</span><br><span>h1</span> { <span>text-align</span>: <span>center</span>; }<br><span>.balance-text</span> <span>/* JS lib */</span></span>
          </p>
          <p><span>Modern</span>
            <span>h1</span>, <span>h2</span> {<br>&nbsp;&nbsp;<span>text-wrap</span>: <span>balance</span>;<br>}<br><span>/* no br or JS */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/font-loading-without-invisible-text/" data-baseline="widely">
        <div>
          
          <h3>Font loading without invisible text</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>@font-face</span> { ... }<br><span>/* Default: invisible text until load */</span></span>
          </p>
          <p><span>Modern</span>
            <span>@font-face</span> {<br>&nbsp;&nbsp;<span>font-family</span>: <span>"MyFont"</span>;<br>&nbsp;&nbsp;<span>font-display</span>: <span>swap</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/multiple-font-weights-without-multiple-files/" data-baseline="widely">
        <div>
          
          <h3>Multiple font weights without multiple files</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>@font-face</span> { <span>font-weight</span>: <span>400</span>; }<br><span>@font-face</span> { <span>font-weight</span>: <span>700</span>; }<br><span>/* 4+ files */</span></span>
          </p>
          <p><span>Modern</span>
            <span>@font-face</span> {<br>&nbsp;&nbsp;<span>font-family</span>: <span>"MyVar"</span>;<br>&nbsp;&nbsp;<span>src</span>: <span>url("MyVar.woff2")</span>;<br>&nbsp;&nbsp;<span>font-weight</span>: <span>100 900</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/dark-mode-defaults-without-extra-css/" data-baseline="widely">
        <div>
          
          <h3>Dark mode defaults without extra CSS</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>@media</span> (<span>prefers-color-scheme</span>: <span>dark</span>) {<br>&nbsp;&nbsp;<span>input, select, textarea</span> { ... }<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>:root</span> {<br>&nbsp;&nbsp;<span>color-scheme</span>: <span>light dark</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/dark-mode-colors-without-duplicating-values/" data-baseline="newly">
        <div>
          
          <h3>Dark mode colors without duplicating values</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>@media</span> (<span>prefers-color-scheme</span>: <span>dark</span>) {<br>&nbsp;&nbsp;<span>color</span>: <span>#eee</span>;<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>color</span>: <span>light-dark</span>(<span>#111</span>, <span>#eee</span>);<br><span>color-scheme</span>: <span>light dark</span>;          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/low-specificity-resets-without-complicated-selectors/" data-baseline="widely">
        <div>
          
          <h3>Low-specificity resets without complicated selectors</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.reset ul, .reset ol</span> { ... }<br><span>/* or (0,0,1) specificity, still wins */</span></span>
          </p>
          <p><span>Modern</span>
            <span>:where</span>(<span>ul, ol</span>) {<br>&nbsp;&nbsp;<span>margin</span>: <span>0</span>;<br>&nbsp;&nbsp;<span>padding-inline-start</span>: <span>1.5rem</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/direction-aware-layouts-without-left-and-right/" data-baseline="widely">
        <div>
          
          <h3>Direction-aware layouts without left and right</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>margin-left</span>: <span>1rem</span>;<br><span>padding-right</span>: <span>1rem</span>;<br><span>[dir="rtl"</span>] <span>.box</span> { <span>margin-right</span>: ... }</span>
          </p>
          <p><span>Modern</span>
            <span>margin-inline-start</span>: <span>1rem</span>;<br><span>padding-inline-end</span>: <span>1rem</span>;<br><span>border-block-start</span>: <span>1px solid</span>;          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/naming-grid-areas-without-line-numbers/" data-baseline="widely">
        <div>
          
          <h3>Naming grid areas without line numbers</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>float</span>: <span>left</span>; <span>/* clearfix, margins */</span><br><span>grid-column</span>: <span>1 / 3</span>;<br><span>grid-row</span>: <span>2</span>;</span>
          </p>
          <p><span>Modern</span>
            <span>.layout</span> {<br>&nbsp;&nbsp;<span>display</span>: <span>grid</span>;<br>&nbsp;&nbsp;<span>grid-template-areas</span>: <span>"header header" "sidebar main" "footer footer"</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/aligning-nested-grids-without-duplicating-tracks/" data-baseline="newly">
        <div>
          
          <h3>Aligning nested grids without duplicating tracks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.child-grid</span> {<br>&nbsp;&nbsp;<span>grid-template-columns</span>: <span>1fr 1fr 1fr</span>;<br><span>/* duplicate parent tracks */</span><br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.child-grid</span> {<br>&nbsp;&nbsp;<span>display</span>: <span>grid</span>;<br>&nbsp;&nbsp;<span>grid-template-columns</span>: <span>subgrid</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/modal-dialogs-without-a-javascript-library/" data-baseline="">
        <div>
          
          <h3>Modal dialogs without a JavaScript library</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.overlay</span> { <span>position</span>: <span>fixed</span>; <span>z-index</span>: <span>999</span>; }<br><span>/* + JS: open/close, ESC, focus trap */</span></span>
          </p>
          <p><span>Modern</span>
            <span>dialog</span> {<br>&nbsp;&nbsp;<span>padding</span>: <span>1rem</span>;<br>}<br><span>dialog::backdrop</span> { <span>background</span>: <span>rgb</span>(0 0 0 / .5); }          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/styling-form-controls-without-rebuilding-them/" data-baseline="widely">
        <div>
          
          <h3>Styling form controls without rebuilding them</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>appearance</span>: <span>none</span>;<br><span>// + 20+ lines of custom box/border/background</span></span>
          </p>
          <p><span>Modern</span>
            <span>input</span>[<span>type</span>=<span>"checkbox"</span>],<br><span>input</span>[<span>type</span>=<span>"radio"</span>] {<br>&nbsp;&nbsp;<span>accent-color</span>: <span>#7c3aed</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/grouping-selectors-without-repetition/" data-baseline="widely">
        <div>
          
          <h3>Grouping selectors without repetition</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.card h1</span>, <span>.card h2</span>, <span>.card h3</span>, <span>.card h4</span> {<br>&nbsp;&nbsp;<span>margin-bottom</span>: <span>0.5em</span>;<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.card</span> <span>:is</span>(<span>h1</span>, <span>h2</span>, <span>h3</span>, <span>h4</span>) {<br>&nbsp;&nbsp;<span>margin-bottom</span>: <span>0.5em</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/focus-styles-without-annoying-mouse-users/" data-baseline="widely">
        <div>
          
          <h3>Focus styles without annoying mouse users</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>:focus</span> { <span>outline</span>: <span>2px solid blue</span>; }<br><span>// Shows on mouse click too, or people remove it (a11y fail)</span></span>
          </p>
          <p><span>Modern</span>
            <span>:focus-visible</span> {<br>&nbsp;&nbsp;<span>outline</span>: <span>2px solid</span> <span>var</span>(<span>--focus-color</span>);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/controlling-specificity-without-important/" data-baseline="widely">
        <div>
          
          <h3>Controlling specificity without !important</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.card .title</span> { ... }<br><span>.page .card .title</span> { ... }<br><span>.page .card .title.special</span> { <span>color</span>: <span>red</span> <span>!important</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>@layer</span> <span>base</span>, <span>components</span>, <span>utilities</span>;<br><span>@layer</span> <span>utilities</span> { <span>.mt-4</span> { <span>margin-top</span>: <span>1rem</span>; } }          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/theme-variables-without-a-preprocessor/" data-baseline="widely">
        <div>
          
          <h3>Theme variables without a preprocessor</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Sass: $primary: #7c3aed;</span><br><span>// Compiles to static #7c3aed</span><br><span>.btn</span> { <span>background</span>: <span>$primary</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>:root</span> {<br>&nbsp;&nbsp;<span>--primary</span>: <span>#7c3aed</span>;<br>}<br><span>.btn</span> { <span>background</span>: <span>var</span>(<span>--primary</span>); }          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/fluid-typography-without-media-queries/" data-baseline="widely">
        <div>
          
          <h3>Fluid typography without media queries</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>h1</span> { <span>font-size</span>: <span>1rem</span>; }<br><span>@media</span> (<span>min-width</span>: <span>600px</span>) { <span>h1</span> { <span>font-size</span>: <span>1.5rem</span>; } }<br><span>@media</span> (<span>min-width</span>: <span>900px</span>) { <span>h1</span> { <span>font-size</span>: <span>2rem</span>; } }</span>
          </p>
          <p><span>Modern</span>
            <span>h1</span> {<br>&nbsp;&nbsp;<span>font-size</span>: <span>clamp</span>(<span>1rem</span>, <span>2.5vw</span>, <span>2rem</span>);<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/spacing-elements-without-margin-hacks/" data-baseline="widely">
        <div>
          
          <h3>Spacing elements without margin hacks</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.grid</span> <span>&gt; *</span> { <span>margin-right</span>: <span>16px</span>; }<br><span>.grid</span> <span>&gt; *:last-child</span> { <span>margin-right</span>: <span>0</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>.grid</span> {<br>&nbsp;&nbsp;<span>display</span>: <span>flex</span>;<br>&nbsp;&nbsp;<span>gap</span>: <span>16px</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/aspect-ratios-without-the-padding-hack/" data-baseline="widely">
        <div>
          
          <h3>Aspect ratios without the padding hack</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>.wrapper</span> { <span>padding-top</span>: <span>56.25%</span>; <span>position</span>: <span>relative</span>; }<br><span>.inner</span> { <span>position</span>: <span>absolute</span>; <span>inset</span>: <span>0</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>.video-wrapper</span> {<br>&nbsp;&nbsp;<span>aspect-ratio</span>: <span>16 / 9</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/sticky-headers-without-javascript-scroll-listeners/" data-baseline="widely">
        <div>
          
          <h3>Sticky headers without JavaScript scroll listeners</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JS: scroll listener + getBoundingClientRect</span><br><span>// then add/remove .fixed class</span><br><span>.header.fixed</span> { <span>position</span>: <span>fixed</span>; }</span>
          </p>
          <p><span>Modern</span>
            <span>.header</span> {<br>&nbsp;&nbsp;<span>position</span>: <span>sticky</span>;<br>&nbsp;&nbsp;<span>top</span>: <span>0</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/scroll-linked-animations-without-a-library/" data-baseline="newly">
        <div>
          
          <h3>Scroll-linked animations without a library</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JS + IntersectionObserver</span><br><span>observer</span>.<span>observe</span>(el)<br><span>el</span>.<span>style</span>.<span>opacity</span> = …</span>
          </p>
          <p><span>Modern</span>
            <span>animation-timeline</span>: <span>view()</span>;<br><span>animation-range</span>: <span>entry</span>;<br><span>/* pure CSS, GPU-accelerated */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/nesting-selectors-without-sass-or-less/" data-baseline="newly">
        <div>
          
          <h3>Nesting selectors without Sass or Less</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// requires Sass compiler</span><br><span>.nav</span> {<br>&nbsp;&nbsp;<span>&amp; a</span> { <span>color</span>: <span>#888</span>; }<br>}</span>
          </p>
          <p><span>Modern</span>
            <span>.nav</span> {<br>&nbsp;&nbsp;<span>&amp; a</span> { <span>color</span>: <span>#888</span>; }<br>}<br><span>/* plain .css, no build */</span>          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/responsive-components-without-media-queries/" data-baseline="widely">
        <div>
          
          <h3>Responsive components without media queries</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>@media</span> (<span>max-width</span>: <span>768px</span>) {<br>&nbsp;&nbsp;<span>.card</span> { … }<br>}<br><span>/* viewport, not container */</span></span>
          </p>
          <p><span>Modern</span>
            <span>@container</span> (<span>width</span> &lt; <span>400px</span>) {<br>&nbsp;&nbsp;<span>.card</span> { <span>flex-direction</span>: <span>column</span>; }<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/mixing-colors-without-a-preprocessor/" data-baseline="newly">
        <div>
          
          <h3>Mixing colors without a preprocessor</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// Sass required</span><br><span>$blend</span>: <span>mix</span>(<br>&nbsp;&nbsp;<span>$blue</span>, <span>$pink</span>, <span>60%</span>);</span>
          </p>
          <p><span>Modern</span>
            <span>background</span>: <span>color-mix</span>(<br>&nbsp;&nbsp;<span>in oklch</span>, <span>#3b82f6</span>,<br>&nbsp;&nbsp;<span>#ec4899</span>);          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/selecting-parent-elements-without-javascript/" data-baseline="newly">
        <div>
          
          <h3>Selecting parent elements without JavaScript</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>// JavaScript required</span><br><span>el</span>.<span>closest</span>(<span>'.parent'</span>)<br>&nbsp;&nbsp;.<span>classList</span>.<span>add</span>(…)</span>
          </p>
          <p><span>Modern</span>
            <span>.card:has(img)</span> {<br>&nbsp;&nbsp;<span>grid-template</span>: <span>auto 1fr</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
            <a href="https://modern-css.com/centering-elements-without-the-transform-hack/" data-baseline="widely">
        <div>
          
          <h3>Centering elements without the transform hack</h3>
        </div>
        <div>
          <p><span>Old</span>
            <span><span>position</span>: <span>absolute</span>;<br><span>top</span>: <span>50%</span>; <span>left</span>: <span>50%</span>;<br><span>transform</span>: <span>translate(-50%,-50%)</span>;</span>
          </p>
          <p><span>Modern</span>
            <span>.parent</span> {<br>&nbsp;&nbsp;<span>display</span>: <span>grid</span>;<br>&nbsp;&nbsp;<span>place-items</span>: <span>center</span>;<br>}          </p>
          <p><span>see modern →</span>
        </p></div>
        
      </a>
          </div>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Palantir Gets Millions of Dollars from New York City's Public Hospitals (295 pts)]]></title>
            <link>https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/</link>
            <guid>47025624</guid>
            <pubDate>Sun, 15 Feb 2026 17:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/">https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/</a>, See on <a href="https://news.ycombinator.com/item?id=47025624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p><span>New York City’s</span> public hospital system is paying millions to Palantir, the controversial ICE and military contractor, according to documents obtained by The Intercept.</p>
<p>Since 2023, the New York City Health and Hospitals Corporation has paid Palantir nearly $4 million to improve its ability to track down payment for the services provided at its hospitals and medical clinics. Palantir, a data analysis firm that’s now a Wall Street giant thanks to its lucrative work with the Pentagon and U.S. intelligence community, deploys its software to make more efficient the billing of Medicaid and other public benefits. That includes automated scanning of patient health notes to “Increase charges captured from missed opportunities,” contract materials reviewed by The Intercept show.</p>
<p>Palantir’s administrative involvement in the business of healing people stands in contrast to its longtime role helping facilitate warfare, <a href="https://theintercept.com/2017/03/02/palantir-provides-the-engine-for-donald-trumps-deportation-machine/">mass deportations</a>, and dragnet surveillance.</p>
<p>In 2016, <a href="https://theintercept.com/2017/02/22/how-peter-thiels-palantir-helped-the-nsa-spy-on-the-whole-world/">The Intercept revealed</a> Palantir’s role behind XKEYSCORE, a secret NSA bulk surveillance program revealed by the whistleblower Edward Snowden that allowed the U.S. and its allies to search the unfathomably large volumes of data they collect. The company has also attracted global scrutiny and criticism for its “<a href="https://www.palantir.com/assets/xrfr7uokpv1b/3MuEeA8MLbLDAyxixTsiIe/9e4a11a7fb058554a8a1e3cd83e31c09/C134184_finaleprint.pdf">strategic partnership</a>” with the Israeli military while it was leveling Gaza.</p>

<p>But it’s Palantir’s work with U.S. Immigration and Customs Enforcement that is drawing the most protest today. The company provides a variety of services to help the federal government find and deport immigrants. ICE’s Palantir-furnished case management software, for example, “plays a critical role in supporting the daily operations of ICE, ensuring critical mission success,” according to federal contracting documents.</p>
<p>“It’s unacceptable that the same company that is targeting our neighbors for deportation and providing tools to the Israeli military is also providing software for our hospitals,” said Kenny Morris, an organizer with the American Friend Service Committee, which shared the contract documents with The Intercept.</p>
<!-- BLOCK(cta)[0](%7B%22componentName%22%3A%22CTA%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) --><!-- END-BLOCK(cta)[0] -->
<p>Established by the state legislature, New York City Health and Hospitals is the nation’s biggest municipal health care system, administering over 70 facilities throughout New York City, including Bellevue Hospital, and providing care for over 1 million New Yorkers annually.</p>
<p>New York City Health and Hospitals spokesperson Adam Shrier did not respond to multiple requests to discuss the contract’s details. Palantir spokesperson Drew Messing said the company does not use or share hospital data outside the bounds of its contract.</p>
<p>Palantir’s contract with New York’s public health care system allows the company to work with patients’ protected health information, or PHI. With permission from New York City Health and Hospitals, Palantir can “de-identify PHI and utilize de-identified PHI for purposes other than research,” the contract states. De-identification generally involves the stripping of certain revealing information, such as names, Social Security numbers, and birthdays. Such provisions are common in contracts involving health data.</p>
<p>Activists who oppose Palantir’s involvement in New York point to a large body of research that indicates re-identifying personal data, including in medial contexts, is <a href="https://georgetownlawtechreview.org/re-identification-of-anonymized-data/GLTR-04-2017/">often</a> <a href="https://techscience.org/a/2017082801/">trivial</a>.</p>
<p>“Any contract that shares any of New Yorkers’ highly personal data from NYC Health &amp; Hospital’s with Palantir, a key player in the Trump administration’s mass deportation effort, is reckless and puts countless lives at risk,” said Beth Haroules of the New York Civil Liberties Union. “Every New Yorker, without exception, has a right to quality healthcare and city services. New Yorkers must be able to seek healthcare without fear that their intimate medical information, or immigration status, will be delivered to the federal government on a silver platter.”</p>
<!-- BLOCK(newsletter)[0](%7B%22componentName%22%3A%22NEWSLETTER%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) --><!-- END-BLOCK(newsletter)[0] -->
<p>Palantir has long provided similar services to the U.K. National Health Service, a business relationship that today has an increasing number of detractors. Palantir “has absolutely no place in the NHS, looking after patients’ personal data,” Green Party leader Zack Polanski recently stated in a <a href="https://www.theguardian.com/politics/2026/feb/05/calls-to-halt-uk-palantir-contracts-grow-amid-lack-of-transparency-over-deals">letter to the U.K. health secretary</a>.</p>
<figure>
<blockquote>
<p>“Palantir is targeting the exact patients that NYCHH is looking to serve.” </p>
</blockquote>
</figure>
<p>Some New York-based groups feel similarly out of distrust for what the firm could do with troves of sensitive personal data.</p>
<p>“Palantir is targeting the exact patients that NYCHH is looking to serve,” said Jonathan Westin of the Brooklyn-based organization Climate Organizing Hub. “They should immediately sever their contract with Palantir and stand with the millions of immigrant New Yorkers that are being targeted by ICE in this moment.”</p>
<p>“The chaos Palantir is inflicting through its technology is not just limited to the kidnapping of our immigrant neighbors and the murder of heroes like our fellow nurse, Alex Pretti,” said Hannah Drummond, an Asheville, North Carolina-based nurse and organizer with National Nurses United, a nursing union. “As a nurse and patient advocate, I don’t want anything having to do with Palantir in my hospital — and neither should any elected leader who claims to represent nurses.”</p>
<p>Palantir’s vocally right-wing CEO Alex Karp&nbsp;has been a <a href="https://www.axios.com/2025/11/08/alex-karp-palantir-democrats-mamdani">frequent</a> critic <a href="https://www.foxbusiness.com/video/6384521232112">of New York City’s</a> newly inaugurated democratic socialist Mayor Zohran Mamdani. Health and Hospitals operates as a public benefit corporation, but the mayor can exert considerable influence over the network, for instance through the appointment of its board of directors. Its president, Dr. Mitchell Katz, was <a href="https://www.nyc.gov/site/ocme/news/cm1025/mayor-elect-mamdani-renominates-nyc-health-hospitals-president-ceo-dr-mitchell-katz-and">renominated</a> by Mamdani, then the mayor-elect, late last year.</p>
<p>The mayor’s office did not respond in time for publication when asked about its stance on the contract.<a id="_msocom_1"></a></p>
  </div></div>]]></description>
        </item>
    </channel>
</rss>