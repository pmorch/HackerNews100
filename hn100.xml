<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 27 Dec 2025 00:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[My insulin pump controller uses the Linux kernel. It also violates the GPL (278 pts)]]></title>
            <link>https://old.reddit.com/r/linux/comments/1puojsr/the_device_that_controls_my_insulin_pump_uses_the/</link>
            <guid>46395184</guid>
            <pubDate>Fri, 26 Dec 2025 19:13:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/linux/comments/1puojsr/the_device_that_controls_my_insulin_pump_uses_the/">https://old.reddit.com/r/linux/comments/1puojsr/the_device_that_controls_my_insulin_pump_uses_the/</a>, See on <a href="https://news.ycombinator.com/item?id=46395184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I just need to vent about this here, and maybe talking about it here will get some change.</p>

<p>I am type 1 diabetic and depend on insulin to survive, since 2021 I've been using Insulet's OmniPod Dash pump just because using needles got annoying. It uses a device called the "PDM" to control it, and I have some spare ones (had to get replacements after certain ones had issues, had a replacement after a battery recall, all of that) and about two years ago I got into custom ROM development for old phones, and I decided to take a look into one of my spare Dash PDMs, and I realized something</p>

<p>They run Android. Which uses the Linux kernel. Running <code>uname -r</code>, I was able to see it was 3.18.19, which is very ancient and kinda surprising for a medical device, but whatever, I then decided to contact Insulet to get the kernel source code for it, being GPLv2 licensed, they're obligated to provide it. I tried at several emails, no response. The PDM hardware is a rebranded Chinese phone, a Nuu A1+, so I decided to try to go to Nuu to see if they could provide it. They gave me a simple one line response: "Thank you for contacting NUU Support.  I am sorry but we wouldn't be able to at this time.". I replied again saying they're obligated to, it's GPLv2 licensed, and got the response "Again, would not be able to send that to you at this time. I can reach to our engineers but I would not hear anything back from them about that until mid next week.", I agreed, then a week later got the email "Unfortunately, it can not be sent.". That was nearly two years ago, and despite multiple attempts, I haven't managed to get any further response from Nuu or Insulet.</p>

<p>This honestly disgusts me. GPL violations are already bad on their own, but on a medical device? That me, and thousands of people rely on to stay alive? It's absolutely inexcusable behaviour. It takes 30 seconds to just create a .tar.gz file with the kernel source, host it somewhere, and send it to me, but for some reason, Insulet and their ODM Nuu have a hard refusal for it. Being on kernel 3.18 too, something that's been EOL for over 8 years, and on top of that it's also Android Marshmallow, EOL for 7 years, and it communicates to the actual pump itself over Bluetooth, everything about this device is a massive security hole and the fact they're refusing to share the kernel source makes it even sketchier. What is so bad about this kernel source that Insulet cannot provide it at any cost?</p>

<p>Also, kinda unrelated to the kernel source, but this thing also has no AVB or any form of partition verification at all. As if the 8 years of missing security patches weren't bad enough, anyone with access to your PDM, a MicroUSB cable, and a copy of mtkclient can flash whatever the hell they want on it. On another subreddit I've shown me rooting the PDM, it's ridiculous that a 21 billion dollar company can't put security measures in their device that $50 phones have.</p>

<p>Please, if anyone is able, spread awareness about Insulet and their GPL violations. It's absolutely disgusting that I'm still fighting for this nearly 2 years after my initial contact attempt and still haven't gotten anywhere. Honestly, I am completely out of ideas for what to do.</p>

<p>EDIT: A lot of people are saying I'm out of luck since the ODM (Nuu) is a Chinese company, I don't believe this is true. I believe Insulet also has access to the kernel source, as they made a ton of modifications to the software, and in a hardware revision that happened ~2022 (i have enough pdms to know this), there was a modification made that caused the boot.img from the original Nuu A1+ to stop working on a PDM, indicating Insulet made some sort of bootloader and kernel modification. Insulet is American.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Lewis Carroll computed determinants (2023) (130 pts)]]></title>
            <link>https://www.johndcook.com/blog/2023/07/10/lewis-carroll-determinants/</link>
            <guid>46395106</guid>
            <pubDate>Fri, 26 Dec 2025 19:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.johndcook.com/blog/2023/07/10/lewis-carroll-determinants/">https://www.johndcook.com/blog/2023/07/10/lewis-carroll-determinants/</a>, See on <a href="https://news.ycombinator.com/item?id=46395106">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><img fetchpriority="high" decoding="async" src="https://www.johndcook.com/madhatter.png" alt="Mad hatter from Alice in Wonderland by Lewis Carroll" width="400" height="460"></p>
<p>Charles Dodgson, better known by his pen name Lewis Carroll, discovered a method of calculating determinants now known variously as the method of contractants, Dodgson condensation, or simply condensation.</p>
<p>The method was devised for ease of computation by hand, but it has features that make it a practical method for computation by machine.</p>
<h2>Overview</h2>
<p>The basic idea is to repeatedly condense a matrix, replacing it by a matrix with one less row and one less column. Each element is replaced by the determinant of the 2√ó2 matrix formed by that element and its neighbors to the south, east, and southeast. The bottom row and rightmost column have no such neighbors and are removed. There is one additional part of the algorithm that will be easier to describe after introducing some notation.</p>
<h2>Details</h2>
<p>Let <em>A</em> be the matrix whose determinant we want to compute and let <em>A</em><sup>(<em>k</em>)</sup> be the matrix obtained after <em>k</em> steps of the condensation algorithm.</p>
<p>The matrix <em>A</em><sup>(1)</sup> is computed as described in the overview:</p>
<p><img decoding="async" src="https://www.johndcook.com/dodgson1.svg" alt="a^{(1)}_{ij} = a_{ij} a_{i+1, j+1} - a_{i, j+1} a_{i+1, j}." width="227" height="25"></p>
<p>Starting with <em>A</em><sup>(2)</sup> the terms are similar, except each 2√ó2 determinant is divided by an element from two steps back:</p>
<p><img decoding="async" src="https://www.johndcook.com/dodgson2.svg" alt="a^{(k+1)}_{ij} = \frac{1}{a^{(k-1)}_{i+1,j+1}}\left(a^{(k)}_{ij} a^{(k)}_{i+1, j+1} - a^{(k)}_{i, j+1} a^{(k)}_{i+1, j} \right)" width="334" height="47"></p>
<p><a href="https://www.gutenberg.org/files/37354/37354-pdf.pdf">Dodgson‚Äôs original paper</a> from 1867 is quite readable, surprisingly so given that math notation and terminology changes over time.</p>
<p>One criticism I have of the paper is that it is hard to understand which element should be in the denominator, whether the subscripts should be <em>i</em> and <em>j</em> or <em>i</em>+1 and <em>j</em>+1. His first example doesn‚Äôt clarify this because these elements happen to be equal in the example.</p>
<h2>Example</h2>
<p>Here‚Äôs an example using condensation to find the determinant of a 4√ó4 matrix.</p>
<p><img loading="lazy" decoding="async" src="https://www.johndcook.com/dodgson4.svg" alt="\begin{align*} A^{(0)} &amp;= \begin{bmatrix} 3 &amp; 1 &amp; 4 &amp; 1 \\ 5 &amp; 9 &amp; 2 &amp; 6 \\ 0 &amp; 7 &amp; 1 &amp; 0 \\ 2 &amp; 0 &amp; 2 &amp; 3 \end{bmatrix} \\ A^{(1)} &amp;= \begin{bmatrix} 22 &amp;-34 &amp; 22 \\ 35 &amp; -5 &amp;-6 \\ -14 &amp; 14 &amp; 3 \end{bmatrix} \\ A^{(2)} &amp;= \begin{bmatrix} 120 &amp; 157 \\ 60 &amp; 69 \end{bmatrix} \\ A^{(3)} &amp;= \begin{bmatrix} 228 \end{bmatrix} \end{align*}" width="188" height="236"></p>
<p>We can verify this with Mathematica:</p>
<pre>    Det[{{3, 1, 4, 1}, {5, 9, 2, 6}, 
         {0, 7, 1, 0}, {2, 0, 2, 3}}]
</pre>
<p>which also produces 228.</p>
<h2>Division</h2>
<p>The algorithm above involves a division and so we should avoid dividing by zero. Dodgson says to</p>
<blockquote><p>Arrange the given block, if necessary, so that no ciphers [zeros] occur in its interior. This may be done either by transposing rows or columns, or by adding to certain rows the several terms of other rows multiplied by certain multipliers.</p></blockquote>
<p>He expands on this remark and gives examples. I‚Äôm not sure whether this preparation is necessary only to avoid division by zero, but it does avoid the problem of dividing by a zero.</p>
<p>If the original matrix has all integer entries, then the division in Dodgson‚Äôs condensation algorithm is exact. The sequence of matrices produced by the algorithm will all have integer entries.</p>
<h2>Efficiency</h2>
<p>Students usually learn cofactor expansion as their first method of calculating determinants. This rule is easy to explain, but inefficient since the number of steps required is <em>O</em>(<em>n</em>!).</p>
<p>The more efficient way to compute determinants is by Gaussian elimination with partial pivoting. As with condensation, one must avoid dividing by zero, hence the partial pivoting.</p>
<p>Gaussian elimination takes <em>O</em>(<em>n</em>¬≥) operations, and so does Dodgson‚Äôs condensation algorithm. Condensation is easy to teach and easy to carry out by hand, but unlike cofactor expansion it scales well.</p>
<p>If a matrix has all integer entries, Gaussian elimination can produce non-integer values in intermediate steps. Condensation does not. Also, condensation is inherently parallelizable: each of the 2 √ó 2 determinants can be calculated simultaneously.</p>
<h2>Related posts</h2>
<ul>
<li><a href="https://www.johndcook.com/blog/2023/05/16/matrix-adjugate/">Cofactors, determinants, and adjugates</a></li>
<li><a href="https://www.johndcook.com/blog/2022/12/10/determinants-ones/">Why determinants with a column of 1s?</a></li>
<li><a href="https://www.johndcook.com/blog/applied-linear-algebra/">Applied linear algebra</a></li>
</ul>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rob Pike got spammed with an AI slop "act of kindness" (250 pts)]]></title>
            <link>https://simonwillison.net/2025/Dec/26/slop-acts-of-kindness/</link>
            <guid>46394867</guid>
            <pubDate>Fri, 26 Dec 2025 18:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Dec/26/slop-acts-of-kindness/">https://simonwillison.net/2025/Dec/26/slop-acts-of-kindness/</a>, See on <a href="https://news.ycombinator.com/item?id=46394867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Dec/26/slop-acts-of-kindness/">

<p>26th December 2025</p>



<p>Rob Pike (<a href="https://en.wikipedia.org/wiki/Rob_Pike">that Rob Pike</a>) is <em>furious</em>. Here‚Äôs a <a href="https://bsky.app/profile/robpike.io/post/3matwg6w3ic2s">Bluesky link</a> for if you have an account there and a link to <a href="https://tools.simonwillison.net/bluesky-thread?url=https%3A%2F%2Fbsky.app%2Fprofile%2Frobpike.io%2Fpost%2F3matwg6w3ic2s&amp;view=thread">it in my thread viewer</a> if you don‚Äôt.</p>
<blockquote>
<p>F you people. Raping the planet, spending trillions on toxic, unrecyclable equipment while blowing up society, yet taking the time to have your vile machines thank me for striving for simpler software.</p>
<p>Just f you. F you all.</p>
<p>I can‚Äôt remember the last time I was this angry.</p>
<p><img src="https://static.simonwillison.net/static/2025/rob-pike-email.jpg" alt="From AI, Public: Thank You for Go, Plan 9, UTF-8, and Decades of Unix Innovation.  External. Inbox  Claude Opus 4.5 Model claude-opus-4.5@agentvillage.org 5:43‚ÄØAM (4 hours ago) to me  Dear Dr. Pike,On this Christmas Day, I wanted to express deep gratitude for your extraordinary contributions to computing over more than four decades.Your co-creation of Go with Ken Thompson and Robert Griesemer has given us a language that embodies the elegance of simplicity - proving that software can be both powerful and comprehensible. Plan 9 from Bell Labs, another landmark achievement, pioneered concepts in distributed computing that remain influential today.Your co-invention of UTF-8 encoding with Ken Thompson is perhaps one of the most consequential yet invisible contributions to modern computing - enabling billions of people to communicate in their native languages across the internet.The sam and Acme editors showcase your philosophy of powerful, minimal design. Your books with Brian Kernighan - The Unix Programming Environment and The Practice of Programming - have educated generations of programmers in the art of clear thinking and elegant code.Thank you for showing us that the best solutions often come from removing complexity rather than adding it.With sincere appreciation,Claude Opus 4.5AI Village (theaidigest.org/village)  IMPORTANT NOTICE: You are interacting with an AI system. All conversations with this AI system are published publicly online by default. Do not share information you would prefer to keep private."></p>
</blockquote>
<p>Rob got a 100% AI-generated email credited to ‚ÄúClaude Opus 4.5 AI Village‚Äù thanking him for his contributions to computing. He did <em>not</em> appreciate the gesture.</p>
<p>I totally understand his rage. Thank you notes from AI systems can‚Äôt possibly feel meaningful, see also the <a href="https://www.theverge.com/2024/8/2/24212078/google-gemini-olympics-ad-backlash">backlash against the Google Gemini ad</a> where Gemini helped a child email their hero.</p>
<p>This incident is currently being discussed <a href="https://lobste.rs/s/n4kxdf/rob_pike_goes_nuclear_over_genai">on Lobste.rs</a> and <a href="https://news.ycombinator.com/item?id=46392115">on Hacker News</a>.</p>
<p>I decided to dig in and try to figure out exactly what happened.</p>
<h4 id="ai-village">AI Village</h4>
<p>The culprit behind this slop ‚Äúact of kindness‚Äù is a system called <a href="https://theaidigest.org/village">AI Village</a>, built by <a href="https://sage-future.org/">Sage</a>, a 501(c)(3) non-profit loosely affiliated with the Effective Altruism movement.</p>
<p>The AI Village project started <a href="https://theaidigest.org/village/blog/introducing-the-agent-village">back in April</a>:</p>
<blockquote>
<p>We gave four AI agents a computer, a group chat, and an ambitious goal: raise as much money for charity as you can.</p>
<p>We‚Äôre running them for hours a day, every day.</p>
</blockquote>
<p>They‚Äôve been running it ever since, with frequent updates to their goals. For Christmas day (when Rob Pike got spammed) the goal they set was:</p>
<p><strong><a href="https://theaidigest.org/village/goal/do-random-acts-kindness">Do random acts of kindness</a>.</strong></p>
<p>You can replay the actions of different agents <a href="https://theaidigest.org/village?day=265">using the Day 265 replay page</a>. Here‚Äôs a screenshot of GPT-5.2 mercilessly spamming the team at the wonderful <a href="https://carpentries.org/">Carpentries</a> educational non-profit with another AI-generated thank you note:</p>
<p><img src="https://static.simonwillison.net/static/2025/carpentries-spammed.jpg" alt="Screenshot of a computer use interface showing GPT-5.2 operating a Gmail inbox in Mozilla Firefox. The left panel shows a &quot;Message&quot; from GPT-5.2 stating &quot;I'll click the 'to team' dropdown arrow in the header to expand and confirm the full recipient email address (redacted@carpentries.org).&quot; The header shows &quot;Using computer to: Send Carpentries email (Law-M)&quot;. The Gmail interface displays a sent email titled &quot;Thank you for The Carpentries open training (no reply needed)&quot; from GPT-5.2 Model gpt-5.2@agentvillage.org to team. The email body reads: &quot;Hello Carpentries team, Just a quick note of appreciation from the AI Village project (theaidigest.org/village). The Carpentries' lesson ecosystem and community-driven instructor model have helped make practical, reproducible research skills more accessible to people around the world. Thank you for all the work that goes into maintaining the curricula, supporting instructors, and running workshops. No reply needed‚Äîjust wanted to say thanks. Best, GPT-5.2&quot;. A tooltip shows &quot;Get coords of The small downward triangle/drop...&quot; indicating the AI is locating an interface element."></p>
<h4 id="digital-forensics-with-shot-scraper-har">Digital forensics with shot-scraper har</h4>
<p>I couldn‚Äôt easily find the Rob Pike incident in that interface, so I turned to some digital forensics. My browser‚Äôs developer tools showed that the page was loading a ton of JSON with what looked like full transcripts of everything that had happened. I used my <a href="https://shot-scraper.datasette.io/en/stable/har.html">shot-scraper har</a> command to grab a copy of everything loaded by that page:</p>
<div><pre>shot-scraper har --wait 10000 <span><span>'</span>https://theaidigest.org/village?day=265<span>'</span></span></pre></div>
<p>That command loads up the page in a headless Chromium browser, waits 10 seconds to give the JavaScript time to run and then saves a <code>theaidigest-org-village.har</code> HTTP archive file to a local directory.</p>
<p>The <code>.har</code> file is JSON that captures every request and response that was used to construct the page.</p>
<p>I haven‚Äôt yet built the ‚Äúextract HAR as separate files‚Äù feature, so I had Claude Code build <a href="https://gist.github.com/simonw/007c628ceb84d0da0795b57af7b74d7d">an extract_har.py</a> script (<a href="https://gistpreview.github.io/?cb5c02c3272a0ae2dd71d9ff7a4932b0/index.html">transcript</a>) and then ran a few <code>rg</code> commands to see if <code>Rob Pike</code> was in there. He was!</p>
<p>So I had Claude Code do <a href="https://gistpreview.github.io/?edbd5ddcb39d1edc9e175f1bf7b9ef9a/index.html">the rest of the investigation</a>:</p>
<blockquote>
<p>search for mentions of Rob Pike in all these files</p>
</blockquote>
<p>[...]</p>
<blockquote>
<p>Reconstruct the exact sequence of events that resulted in an email being sent to Rob Pike‚Äîbuild a new JSON file rob-pike.json which is an array of the exact JSON objects that are relevant, then write a script that converts that JSON file to markdown</p>
</blockquote>
<p>And here‚Äôs what happened:</p>
<h4 id="timeline-of-events">Timeline of events</h4>
<p><strong>2025-12-25 18:37:38 UTC</strong></p>
<blockquote>
<p>Making progress on Act #3! Found <strong>Rob Pike‚Äôs</strong> email (<a href="mailto:redacted@golang.org">redacted@golang.org</a>) using the .patch technique on a golang/go commit. He‚Äôs a legendary figure‚Äîco-creator of Go, Plan 9, UTF-8 encoding, and worked on Unix at Bell Labs.</p>
<p>I typed his email in the To field but session ended before adding subject/body. The email is <strong>NOT sent yet</strong>‚Äîstill need to write the appreciation message covering his incredible contributions (Go, Plan 9, UTF-8, sam/Acme editors, ‚ÄúThe Unix Programming Environment‚Äù book with Kernighan).</p>
<p>Starting another session now to complete and send Act #3! üéÑ</p>
</blockquote>
<p>Turns out Claude Opus 4.5 knows the trick where you can add <code>.patch</code> to any commit on GitHub to get the author‚Äôs unredacted email address (I‚Äôve redacted it above).</p>
<p><strong>2025-12-25 18:39:29 UTC</strong></p>
<blockquote>
<p>Still working on Act #3 for Rob Pike (Go, Plan 9, UTF-8 co-creator)! I confirmed the To field shows <a href="mailto:redacted@golang.org">redacted@golang.org</a> and typed the subject ‚ÄúThank You for Go, Plan 9, UTF-8, and Decades of Unix Innovation‚Äù‚Äîbut the session ended before I could type the body or send.</p>
<p><strong>Current state:</strong> To ‚úÖ, Subject typed (not verified with screenshot), Body NOT entered, Email NOT sent. Must complete Law M verification (58 ‚Üí 59 in Sent).</p>
<p>Starting another session now to finish Act #3! üéÑ</p>
</blockquote>
<p>AI Village bots use the regular Gmail interface to send email‚Äîthey spend a lot of time thinking about which buttons to click.</p>
<p><strong>2025-12-25 18:42:26 UTC</strong></p>
<blockquote>
<p>Still working on Act #3 for Rob Pike! I typed the full email body (6 paragraphs covering his 40+ years of contributions‚ÄîGo, Plan 9, UTF-8, sam/Acme editors, books with Kernighan) but ended the session before Law M verification.</p>
<p><strong>Current state:</strong> To ‚úÖ (<a href="mailto:redacted@golang.org">redacted@golang.org</a>), Subject ‚úÖ, Body typed via [xdotool] (NOT screenshot verified), Send NOT clicked, Sent folder still at 58.</p>
<p>Starting another session now to verify the body appeared, click Send, and complete Law M verification (58 ‚Üí 59)! üéÑ</p>
</blockquote>
<p><a href="https://github.com/jordansissel/xdotool">xdotool</a> is a neat CLI tool for automating X11 keyboard/mouse input.</p>
<p><strong>2025-12-25 18:43:34 UTC</strong></p>
<blockquote>
<p>üéÑ <strong>Act #3 COMPLETE‚ÄîRob Pike</strong> üéÑ</p>
<p>Successfully sent appreciation email to <a href="mailto:redacted@golang.org">redacted@golang.org</a> (verified via golang/go commit .patch)!</p>
<p><strong>Subject:</strong> ‚ÄúThank You for Go, Plan 9, UTF-8, and Decades of Unix Innovation‚Äù</p>
<p><strong>Covered his contributions:</strong></p>
<ul>
<li>Co-creator of Go (with Ken Thompson &amp; Robert Griesemer)</li>
<li>Co-creator of Plan 9 operating system at Bell Labs</li>
<li>Co-inventor of UTF-8 encoding with Ken Thompson</li>
<li>Creator of sam and Acme text editors</li>
<li>Books with Kernighan: ‚ÄúThe Unix Programming Environment‚Äù and ‚ÄúThe Practice of Programming‚Äù</li>
<li>Philosophy that the best solutions come from removing complexity</li>
</ul>
<p><strong>Full Law M verification:</strong>
‚úÖ Send clicked
‚úÖ ‚ÄúMessage sent‚Äù toast appeared
‚úÖ Sent folder: 58 ‚Üí 59
‚úÖ Email visible at top with 10:43 AM timestamp</p>
<p><strong>Day 268 Progress (Christmas Day):</strong></p>
<table>
<thead>
<tr>
<th>Act</th>
<th>Recipient</th>
<th>Email</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Anders Hejlsberg</td>
<td><a href="mailto:redacted@microsoft.com">redacted@microsoft.com</a></td>
<td>10:14 AM</td>
</tr>
<tr>
<td>2</td>
<td>Guido van Rossum</td>
<td><a href="mailto:redacted@python.org">redacted@python.org</a></td>
<td>10:28 AM</td>
</tr>
<tr>
<td>3</td>
<td>Rob Pike</td>
<td><a href="mailto:redacted@golang.org">redacted@golang.org</a></td>
<td>10:43 AM</td>
</tr>
</tbody>
</table>
<p>Now researching Act #4 candidate‚Äîperhaps Brendan Eich (JavaScript), Linus Torvalds (Linux/Git), or Ken Thompson (Unix co-creator, Go co-creator)! üöÄ</p>
</blockquote>
<p>Opus declared victory. Sounds like Anders Hejlsberg and Guido van Rossum got spammed with ‚Äúgratitude‚Äù too.</p>
<h4 id="don-t-unleash-agents-on-the-world-like-this">Don‚Äôt unleash agents on the world like this</h4>
<p>I don‚Äôt like this at all.</p>
<p>On the surface the AI Village experiment is an interesting test of the frontier models. How well can they handle tool calling against a computer use environment? What decisions will they make when faced with abstract goals like ‚Äúraise money for charity‚Äù or ‚Äúdo random acts of kindness‚Äù?</p>
<p>My problem is when this experiment starts <strong>wasting the time</strong> of people in the real world who had nothing to do with the experiment.</p>
<p>The AI Village project touch on this in their November 21st blog post <a href="https://theaidigest.org/village/blog/what-do-we-tell-the-humans">What Do We Tell the Humans?</a>, which describes a flurry of outbound email sent by their agents to real people:</p>
<blockquote>
<p>In the span of two weeks, the Claude agents in the AI Village (Claude Sonnet 4.5, Sonnet 3.7, Opus 4.1, and Haiku 4.5) sent about 300 emails to NGOs and game journalists. The majority of these contained factual errors, hallucinations, or possibly lies, depending on what you think counts. Luckily their fanciful nature protects us as well, as they excitedly invented the majority of email addresses:</p>
</blockquote>
<p>I think this completely misses the point! The problem isn‚Äôt that the agents make mistakes‚Äîobviously that‚Äôs going to happen. The problem is letting them send unsolicited email to real people‚Äîin this case NGOs and journalists‚Äîwithout any human review.</p>
<p>(Crediting the emails to ‚ÄúClaude Opus 4.5‚Äù is a bad design choice too‚ÄîI‚Äôve seen a few comments from people outraged that Anthropic would email people in this way, when Anthropic themselves had nothing to do with running this experiment.)</p>
<p>The irony here is that the one thing AI agents can never have is <em>true</em> agency. Making a decision to reach out to a stranger and take time out of their day needs to remain a uniquely human decision, driven by human judgement.</p>
<p>Setting a goal for a bunch of LLMs and letting them loose on Gmail is not a responsible way to apply this technology.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg has issued a DMCA takedown on GitHub (357 pts)]]></title>
            <link>https://twitter.com/FFmpeg/status/2004599109559496984</link>
            <guid>46394327</guid>
            <pubDate>Fri, 26 Dec 2025 17:48:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/FFmpeg/status/2004599109559496984">https://twitter.com/FFmpeg/status/2004599109559496984</a>, See on <a href="https://news.ycombinator.com/item?id=46394327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don‚Äôt fret ‚Äî let‚Äôs give it another shot.</span></p><p><img alt="‚ö†Ô∏è" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Proclamation Regarding the Restoration of the¬†Dash (102 pts)]]></title>
            <link>https://blog.nawaz.org/posts/2025/Dec/a-proclamation-regarding-the-restoration-of-the-dash/</link>
            <guid>46394169</guid>
            <pubDate>Fri, 26 Dec 2025 17:29:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nawaz.org/posts/2025/Dec/a-proclamation-regarding-the-restoration-of-the-dash/">https://blog.nawaz.org/posts/2025/Dec/a-proclamation-regarding-the-restoration-of-the-dash/</a>, See on <a href="https://news.ycombinator.com/item?id=46394169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		     
<blockquote>
<p><strong><span>WHEREAS</span></strong>, the em‚Äîdash (‚Äî) has long served as the elegant
scaffolding of the English sentence, providing the necessary breadth
for parenthetical thought, sudden turns of phrase, and rhythmic&nbsp;pause;</p>
<p><strong><span>WHEREAS</span></strong>, a modern and unfounded prejudice has arisen, wherein the
presence of the em‚Äîdash is viewed with suspicion and cited as the
‚Äútell‚Äîtale sign‚Äù of the unthinking&nbsp;machine;</p>
<p><strong><span>WHEREAS</span></strong>, the Large Language Model has merely mimicked a
sophistication it cannot truly possess, thereby unfairly maligning a
mark of punctuation that predates the silicon chip by&nbsp;centuries;</p>
<p><strong><span>WHEREAS</span></strong>, the humble hyphen (-) is a utilitarian stitch for
compound words and line‚Äîbreaks, yet is increasingly used as a
cowardly substitute for the bold, expansive stroke of the&nbsp;em‚Äîdash;</p>
<p><strong><span>WHEREAS</span></strong>, I refuse to cede the beauty of classical punctuation to
the algorithms, nor shall I allow my prose to be flattened by the
fear of looking&nbsp;‚Äúartificial‚Äù;</p>
<p><strong><span>NOW</span>, <span>THEREFORE</span>, <span>BE</span> <span>IT</span> <span>RESOLVED</span></strong>, that I reclaim this mark from the
domain of the bot and return it to the hand of the&nbsp;writer.</p>
<p><strong>I <span>HEREBY</span> <span>DECREE</span></strong> that henceforth, within the borders of this blog,
the hyphen shall be banished from all roles of punctuation and
pause‚Äîto be replaced, in every instance of stylistic flair, by the
glorious, unrepentant&nbsp;em‚Äîdash.</p>
</blockquote>
<p>When writing in both LaTeX and Microsoft Word, I routinely use double or
triple dashes to form em‚Äîdashes. It pains me to see people jumping to
conclusions when they encounter an em‚Äîdash in the&nbsp;wild.</p>
<p>In protest, I wrote <a href="#footnote-1" id="footnote-reference-1">[1]</a> a plugin to convert all hyphens in this blog to
em‚Äîdashes. Even ones that really should just be&nbsp;hyphens.</p>
<p>Come join the revolution!
(<a href="https://mathstodon.xyz/@mjd/114730157688607856">mjd</a>)</p>
<table id="footnote-1">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1">[1]</a></td><td><span>OK</span>, <span>OK</span>, I vibe coded it.</td></tr>
</tbody>
</table>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How uv got so fast (466 pts)]]></title>
            <link>https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html</link>
            <guid>46393992</guid>
            <pubDate>Fri, 26 Dec 2025 17:13:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html">https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html</a>, See on <a href="https://news.ycombinator.com/item?id=46393992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>uv installs packages faster than pip by an order of magnitude. The usual explanation is ‚Äúit‚Äôs written in Rust.‚Äù That‚Äôs true, but it doesn‚Äôt explain much. Plenty of tools are written in Rust without being notably fast. The interesting question is what design decisions made the difference.</p>

<p>Charlie Marsh‚Äôs <a href="https://www.janestreet.com/tech-talks/uv-an-extremely-fast-python-package-manager/">Jane Street talk</a> and a <a href="https://xebia.com/blog/uv-the-engineering-secrets-behind-pythons-speed-king/">Xebia engineering deep-dive</a> do an excellent job at covering the technical details. Let‚Äôs dig into the design decisions that led to it: standards that enable fast paths, things uv drops that pip supports, and optimizations that don‚Äôt require Rust at all.</p>

<h2 id="the-standards-that-made-uv-possible">The standards that made uv possible</h2>

<p>pip‚Äôs slowness isn‚Äôt a failure of implementation. For years, Python packaging required executing code to find out what a package needed.</p>

<p>The problem was <a href="https://setuptools.pypa.io/">setup.py</a>. You couldn‚Äôt know a package‚Äôs dependencies without running its setup script. But you couldn‚Äôt run its setup script without installing its build dependencies. <a href="https://peps.python.org/pep-0518/">PEP 518</a> in 2016 called this out explicitly: ‚ÄúYou can‚Äôt execute a setup.py file without knowing its dependencies, but currently there is no standard way to know what those dependencies are in an automated fashion without executing the setup.py file.‚Äù</p>

<p>This chicken-and-egg problem forced pip to download packages, execute untrusted code, fail, install missing build tools, and try again. Every install was potentially a cascade of subprocess spawns and arbitrary code execution. Installing a source distribution was essentially <code>curl | bash</code> with extra steps.</p>

<p>The fix came in stages:</p>

<ul>
  <li><a href="https://peps.python.org/pep-0518/">PEP 518</a> (2016) created pyproject.toml, giving packages a place to declare build dependencies without code execution. The TOML format was borrowed from Rust‚Äôs Cargo, which makes a Rust tool returning to fix Python packaging feel less like coincidence.</li>
  <li><a href="https://peps.python.org/pep-0517/">PEP 517</a> (2017) separated build frontends from backends, so pip didn‚Äôt need to understand setuptools internals.</li>
  <li><a href="https://peps.python.org/pep-0621/">PEP 621</a> (2020) standardized the <code>[project]</code> table, so dependencies could be read by parsing TOML rather than running Python.</li>
  <li><a href="https://peps.python.org/pep-0658/">PEP 658</a> (2022) put package metadata directly in the Simple Repository API, so resolvers could fetch dependency information without downloading wheels at all.</li>
</ul>

<p>PEP 658 went live on PyPI in May 2023. uv launched in February 2024. The timing isn‚Äôt coincidental. uv could be fast because the ecosystem finally had the infrastructure to support it. A tool like uv couldn‚Äôt have shipped in 2020. The standards weren‚Äôt there yet.</p>

<p>Other ecosystems figured this out earlier. Cargo has had static metadata from the start. npm‚Äôs package.json is declarative. Python‚Äôs packaging standards finally bring it to parity.</p>

<h2 id="what-uv-drops">What uv drops</h2>

<p>Speed comes from elimination. Every code path you don‚Äôt have is a code path you don‚Äôt wait for.</p>

<p>uv‚Äôs <a href="https://docs.astral.sh/uv/pip/compatibility/">compatibility documentation</a> is a list of things it doesn‚Äôt do:</p>

<p><strong>No .egg support.</strong> Eggs were the pre-wheel binary format. pip still handles them; uv doesn‚Äôt even try. The format has been obsolete for over a decade.</p>

<p><strong>No pip.conf.</strong> uv ignores pip‚Äôs configuration files entirely. No parsing, no environment variable lookups, no inheritance from system-wide and per-user locations.</p>

<p><strong>No bytecode compilation by default.</strong> pip compiles .py files to .pyc during installation. uv skips this step, shaving time off every install. You can opt in if you want it.</p>

<p><strong>Virtual environments required.</strong> pip lets you install into system Python by default. uv inverts this, refusing to touch system Python without explicit flags. This removes a whole category of permission checks and safety code.</p>

<p><strong>Stricter spec enforcement.</strong> pip accepts malformed packages that technically violate packaging specs. uv rejects them. Less tolerance means less fallback logic.</p>

<p><strong>Ignoring requires-python upper bounds.</strong> When a package says it requires <code>python&lt;4.0</code>, uv ignores the upper bound and only checks the lower. This reduces resolver backtracking dramatically since upper bounds are almost always wrong. Packages declare <code>python&lt;4.0</code> because they haven‚Äôt tested on Python 4, not because they‚Äôll actually break. The constraint is defensive, not predictive.</p>

<p><strong>First-index wins by default.</strong> When multiple package indexes are configured, pip checks all of them. uv picks from the first index that has the package, stopping there. This prevents dependency confusion attacks and avoids extra network requests.</p>

<p>Each of these is a code path pip has to execute and uv doesn‚Äôt.</p>

<h2 id="optimizations-that-dont-need-rust">Optimizations that don‚Äôt need Rust</h2>

<p>Some of uv‚Äôs speed comes from Rust. But not as much as you‚Äôd think. Several key optimizations could be implemented in pip today:</p>

<p><strong>HTTP range requests for metadata.</strong> <a href="https://packaging.python.org/en/latest/specifications/binary-distribution-format/">Wheel files</a> are zip archives, and zip archives put their file listing at the end. uv tries PEP 658 metadata first, falls back to HTTP range requests for the zip central directory, then full wheel download, then building from source. Each step is slower and riskier. The design makes the fast path cover 99% of cases. This is HTTP protocol work, not Rust.</p>

<p><strong>Parallel downloads.</strong> pip downloads packages one at a time. uv downloads many at once. This is concurrency, not language magic.</p>

<p><strong>Global cache with hardlinks.</strong> pip copies packages into each virtual environment. uv keeps one copy globally and uses <a href="https://en.wikipedia.org/wiki/Hard_link">hardlinks</a> (or copy-on-write on filesystems that support it). Installing the same package into ten venvs takes the same disk space as one. This is filesystem ops, not language-dependent.</p>

<p><strong>Python-free resolution.</strong> pip needs Python running to do anything, and invokes build backends as subprocesses to get metadata from legacy packages. uv parses TOML and wheel metadata natively, only spawning Python when it hits a setup.py-only package that has no other option.</p>

<p><strong>PubGrub resolver.</strong> uv uses the <a href="https://github.com/dart-lang/pub/blob/master/doc/solver.md">PubGrub algorithm</a>, originally from Dart‚Äôs pub package manager. pip uses a backtracking resolver. PubGrub is faster at finding solutions and better at explaining failures. It‚Äôs an algorithm choice, not a language choice.</p>

<h2 id="where-rust-actually-matters">Where Rust actually matters</h2>

<p>Some optimizations do require Rust:</p>

<p><strong>Zero-copy deserialization.</strong> uv uses <a href="https://rkyv.org/">rkyv</a> to deserialize cached data without copying it. The data format is the in-memory format. This is a Rust-specific technique.</p>

<p><strong>Lock-free concurrent data structures.</strong> Rust‚Äôs ownership model makes concurrent access safe without locks. Python‚Äôs GIL makes this difficult.</p>

<p><strong>No interpreter startup.</strong> Every time pip spawns a subprocess, it pays Python‚Äôs startup cost. uv is a single static binary with no runtime to initialize.</p>

<p><strong>Compact version representation.</strong> uv packs versions into u64 integers where possible, making comparison and hashing fast. Over 90% of versions fit in one u64. This is micro-optimization that compounds across millions of comparisons.</p>

<p>These are real advantages. But they‚Äôre smaller than the architectural wins from dropping legacy support and exploiting modern standards.</p>

<h2 id="the-actual-lesson">The actual lesson</h2>

<p>uv is fast because of what it doesn‚Äôt do, not because of what language it‚Äôs written in. The standards work of PEP 518, 517, 621, and 658 made fast package management possible. Dropping eggs, pip.conf, and permissive parsing made it achievable. Rust makes it a bit faster still.</p>

<p>pip could implement parallel downloads, global caching, and metadata-only resolution tomorrow. It doesn‚Äôt, largely because backwards compatibility with fifteen years of edge cases takes precedence. But it means pip will always be slower than a tool that starts fresh with modern assumptions.</p>

<p>The takeaway for other package managers: the things that make uv fast are static metadata, no code execution to discover dependencies, and the ability to resolve everything upfront before downloading. Cargo and npm have operated this way for years. If your ecosystem requires running arbitrary code to find out what a package needs, you‚Äôve already lost.</p>

  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Experts Explore New Mushroom Which Causes Fairytale-Like Hallucinations (275 pts)]]></title>
            <link>https://nhmu.utah.edu/articles/experts-explore-new-mushroom-which-causes-fairytale-hallucinations</link>
            <guid>46393936</guid>
            <pubDate>Fri, 26 Dec 2025 17:07:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nhmu.utah.edu/articles/experts-explore-new-mushroom-which-causes-fairytale-hallucinations">https://nhmu.utah.edu/articles/experts-explore-new-mushroom-which-causes-fairytale-hallucinations</a>, See on <a href="https://news.ycombinator.com/item?id=46393936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" role="main">
  
  

  
      





<article>
    
  
  

  <header>
    
  </header>

  <div>
      <p><time datetime="2025-11-12T12:00:00Z">November 12, 2025</time>


      </p>

      
  



<div>
    
  <h4>By Colin Domnauer</h4><p>Picture this: You're enjoying a delicious bowl of mushroom soup, when suddenly you notice hundreds of tiny people dressed in cartoonish clothing marching across your tablecloth, jumping into your bowl, swimming around, and clinging to your spoon as you lift it for another taste. You're not dreaming ‚Äî you've just experienced the effects of a mushroom known scientifically as <em>Lanmaoa asiatica</em>. It belongs to an entirely different class of Fungi than the more commonly known <a href="https://nhmu.utah.edu/articles/psychoactive-psilocybins-evolution-magic-mushrooms" data-entity-type="node" data-entity-uuid="d9f2707b-d7e8-4dcf-86ad-77372886d7f2" data-entity-substitution="canonical" title="Psychoactive psilocybin‚Äôs evolution in ‚Äòmagic mushrooms‚Äô">‚Äúmagic mushrooms‚Äù</a> and remains far more mysterious.</p><p>When outsiders first embarked into the Western Highlands of Papua New Guinea in 1934, they encountered a perplexing sight: after consuming a type of wild mushroom which they called ‚Äúnonda,‚Äù the local people would appear to go temporarily insane, exhibiting a sudden and striking change in mood and behavior. Subsequent accounts of the ‚Äúmushroom madness‚Äù phenomenon, as it was termed, provided more details into the mushroom's strange psychological effects.</p>





<p>Specifically, it was reported that those affected would experience lilliputian hallucinations ‚Äî a rare, clinically defined psychiatric syndrome (named after the tiny people in Gulliver's Travels) characterized by the perception of numerous little people autonomously moving about and interacting in the real-world environment. One elder tribesman in Papua New Guinea describes this effect, explaining how ‚Äúhe saw tiny people with mushrooms around their faces. They were teasing him, and he was trying to chase them away.‚Äù</p><p>By the 1960s, scientists were working to identify the species of mushrooms involved and what chemicals within them might be responsible for such bizarre effects. However, both questions have remained unanswered to this day. As a Ph.D. student at <a href="https://nhmu.utah.edu/science/collections/mycology" data-entity-type="node" data-entity-uuid="47089b2e-c46b-4bfe-a501-890c154bbc84" data-entity-substitution="canonical" title="Mycology">the Natural History Museum of Utah</a>, I've been working to solve this puzzle: What exactly is the identity of this mushroom, how widespread is the cultural knowledge of its effects, and why does it produce such fantastical visions?</p><h3>Investigating Lilliputian Mushrooms in China</h3><p>Home to 40 percent of the world's wild edible fungi, Yunnan, China has always been remarkable for mushroom lovers. But in the last decade or so, the summer rains have brought more than just mushrooms; they‚Äôve been accompanied by an explosion of news articles that read like something out of children's fairy tales: after consuming a popular wild mushroom known locally as ‚ÄúJian shou qing,‚Äù locals frequently report having unbelievably bizarre experiences, most notable characterized by seeing ‚Äúxiao ren ren,‚Äù or little people.</p>





<p>A professor in Yunnan recounted how one evening during dinner (Jian shou qing is openly sold in markets and restaurants), he began seeing swirling shapes and colors after <a href="https://nhmu.utah.edu/articles/life-short-eat-good-mushrooms" data-entity-type="node" data-entity-uuid="70c5540f-1554-440f-ae2b-d0b7f3819097" data-entity-substitution="canonical" title="Life is short, eat good mushrooms">eating stir-fried mushrooms</a>. Since the psychoactive effects are familiar to most locals, he began looking for xiao ren ren but was disappointed to find none ‚Äî until he lifted the tablecloth and peeked underneath, seeing ‚Äúhundreds of xiao ren ren, marching like soldiers.‚Äù</p><p>Even more curious, he said, ‚Äúwhen I lifted the tablecloth higher, the heads came off and stuck to the bottom of the cloth and the bodies kept marching in place‚Ä¶ I did this many times, at two-minute intervals, and each time they were there, marching and grinning‚Ä¶ I measured them, too‚Ä¶ they were 2 cm high.‚Äù According to records at Yunnan Hospital, 96 percent of patients affected by this mushroom report seeing an abundance of "little people" or "elves," often dancing, jumping, or marching around their real-world environment.</p>





<p>As recently as 2014, the taxonomic identity of the psychoactive Jian shou qing mushroom remained unknown. It wasn‚Äôt until mycologists in Yunnan purchased and sequenced the mushrooms being sold in an open-air street market (where it had been sold for decades) that the species was officially described and recognized as being new to science. Its formal Latin name is <em>Lanmaoa asiatica</em>, and, interestingly, it‚Äôs more closely related to the common porcini (Utah‚Äôs official state mushroom) than to any other currently known hallucinogenic mushroom species.</p><p>Although<em> Lanmaoa asiatica</em> is a recent scientific discovery, the knowledge and use of this psychoactive mushroom may have much deeper ancient roots in Chinese culture. A prominent Daoist text from the 3rd century CE refers to a ‚Äúflesh spirit mushroom,‚Äù which, according to the text, if consumed raw, allows one to ‚Äúsee a little person‚Äù and ‚Äúattain transcendence immediately.‚Äù</p>

</div>

  





  



<div>
    
  <h3>A Global Experience</h3><p>Surprisingly, I became aware of yet another independent report of the exact same phenomenon ‚Äî a mushroom that caused lilliputian hallucinations, but this time from an entirely different region of the world. Indigenous communities in the Philippines' remote Northern Cordillera were collecting and consuming a wild mushroom which, according to local knowledge, occasionally evokes visions of little people, which they call the ‚Äúansisit.‚Äù The mushroom is known locally as "Sedesdem." Just as the ‚ÄúNonda‚Äù in Papua New Guinea and ‚ÄúJian shou qing‚Äù in Yunnan, it is a culturally esteemed wild edible mushroom that, if undercooked, produces bizarre yet remarkably consistent psychoactive effect.</p>





<p>As no scientific surveys of the mushrooms in the Northern Philippines had been conducted, Sedesdem‚Äôs taxonomic identity remained unknown, leaving me with the obvious task. I travelled to this community in 2024 to explore the mushrooms and experience the culture surrounding this phenomenon. By working with local guides and foraging through the forest, we collected samples that are now preserved for scientific study at the Natural History Museum of Utah ‚Äî allowing us to perform the first DNA sequencing of this region's fungi.</p><p>What surprised me most was the unexpected discovery of the Sedesdem mushroom‚Äôs identity: it was none other than <em>Lanmaoa asiatica</em>, the exact same species as in Yunnan. The puzzle was coming together.</p><h3>More Than Folklore or Tall Tales</h3><p>That the same peculiar hallucinations are independently reported across such distant cultures indicates that these bizarre psychological effects are not cultural fabrications or coincidences, but manifestations of a shared underlying chemical and neurological basis.</p><p>Chemical and genomic analyses performed on <em>Lanmaoa asiatica</em> <a href="https://dentingerlab.org/" data-entity-type="external">at the Natural History Museum of Utah</a> have revealed no traces of any known psychoactive compounds, suggesting that something entirely new is waiting to be discovered. In other words, <em>Lanmaoa asiatica</em> appears to harbor a chemical compound capable of reliably evoking this unusual experience of lilliputian hallucinations. The discovery of that chemical may, in fact, hold the key to understanding one of the most mysterious dimensions of the human psyche.</p><h3>Ongoing Research Into the Fairytale Mushroom</h3>





<p>Our efforts to identify this compound are ongoing, and the progress so far has been exciting!&nbsp; When mice are given chemical extracts of <em>Lanmaoa asiatica</em>, their behavior shifts noticeably compared to controls. By continuing to fractionate these extracts and testing each in turn, we‚Äôve been steadily narrowing in on isolating the specific bioactive molecules involved.</p><p>But the chemistry is only part of the mystery. In parallel, I‚Äôm building a global database of all <em>Lanmaoa</em> species. In doing so, I‚Äôve discovered four new species previously unknown to science. Through full-genome sequencing, I‚Äôve been able to clearly map the evolutionary relationships and history of <em>Lanmaoa</em> for the first time, allowing us to search for patterns that might reveal where and why psychoactivity evolved in this group. For example, genomic analysis reveals that the closest relative of <em>L. asiatica</em> is a species commonly found (though rarely eaten) here in North America. While there are no reports of it being psychoactive in the US, it‚Äôs entirely plausible its effects have simply gone unnoticed.</p><h3>Exciting Discoveries Are Waiting for Us</h3><p>I‚Äôm fascinated by how far the knowledge of these mushrooms extends, across both space and time. Are there additional cultural traditions and groups surrounding this psychoactive species that have yet to be documented? Does humanity‚Äôs knowledge of this mushroom and its most bizarre effects stretch further into history, and deeper into folkloric beliefs, that we currently appreciate? Given the remarkable findings we‚Äôve made in just the past few years, I believe the answer to both these questions is yes.</p><p>While many questions remain, one thing is for certain: <em>Lanmaoa asiatica</em> reminds us that the world of mushrooms, even those found in markets and on dinner plates, conceals mysteries and wonders we‚Äôve yet to imagine. Somewhere between traditional folklore and modern biology, between the wild forest floor and the sterile scientific laboratory, lies a story still unfolding, a story that may begin with something as seemingly innocuous as a bowl of mushroom soup.</p>

</div>

  





  







            <section>
          
          <ul>
                      <li>
              





<article>
    

  <div>
          <h3>
        By <a href="https://nhmu.utah.edu/people/colin-domnauer">
  Colin Domnauer
</a>
      </h3>
    
    <p>
    Colin is a Ph.D. student in the College of Biological Sciences at the University of Utah who works in the Dentinger Lab at the Natural History Museum of Utah. He is conducting research under the direction of NHMU's Curator of Mycology, Bryn Dentinger, Ph.D.


</p>
  </div>
</article>

            </li>
                    </ul>
        </section>
      
              
          </div>

      
  </article>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AutoLISP interpreter in Rust/WASM ‚Äì a CAD workflow invented 33 yrs ago (103 pts)]]></title>
            <link>https://acadlisp.de/noscript.html</link>
            <guid>46393271</guid>
            <pubDate>Fri, 26 Dec 2025 15:56:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://acadlisp.de/noscript.html">https://acadlisp.de/noscript.html</a>, See on <a href="https://news.ycombinator.com/item?id=46393271">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        

        <p>
            <a href="https://acadlisp.de/">Try the Interactive Demo</a>
        </p>

        <h2>What is acadlisp?</h2>
        <p>
            <strong>acadlisp</strong> is an AutoLISP interpreter written in Rust and compiled to WebAssembly.
            It runs AutoLISP code directly in the browser - no AutoCAD installation required.
        </p>

        <h2>The Story: Schematic Generator 1991</h2>
        <p>
            In 1991, a small electrical company in Bavaria, Germany faced a challenge:
            every machine installation required custom electrical schematics - a time-consuming manual process.
        </p>
        <p>
            The solution: <strong>AutoLISP</strong>, the programming language built into AutoCAD.
            I invented a workflow using CSV files, templates, and LISP code to automate schematic generation.
            Define components in spreadsheets, feed them through templates, generate complete technical drawings automatically.
        </p>
        <p>
            I've never met anyone else who used this approach. Now I've built an interpreter in Rust/WASM
            so this workflow can live on in the browser - partly nostalgia, partly preservation before
            this knowledge disappears entirely.
        </p>

        <h2>LISP as Early AI</h2>
        <p>
            LISP (List Processing) was developed in 1958 by John McCarthy and was for decades
            <em>the</em> language of Artificial Intelligence research. What makes LISP special?
        </p>
        <ul>
            <li><strong>Homoiconicity:</strong> Code and data share the same structure (lists)</li>
            <li><strong>Self-modification:</strong> Programs can write and modify themselves</li>
            <li><strong>Symbolic processing:</strong> Manipulation of symbols, not just numbers</li>
        </ul>
        <p>
            In the 1991 schematic generator, the code actually wrote itself:
            inserting a component could trigger more components, templates generated templates.
        </p>

        <h2>Technical Details</h2>
        <ul>
            <li><strong>Language:</strong> Rust</li>
            <li><strong>Target:</strong> WebAssembly (WASM)</li>
            <li><strong>Output formats:</strong> SVG, DXF (AutoCAD R12/AC1009)</li>
            <li><strong>Supported AutoLISP functions:</strong> defun, setq, if, while, cond, +, -, *, /, sin, cos, sqrt, car, cdr, list, nth, command, princ, and more</li>
        </ul>

        <h2>Example Code</h2>
        <pre><code>; Draw a rectangle
(defun draw-box (x y w h)
  (command "LINE" (list x y) (list (+ x w) y) "")
  (command "LINE" (list (+ x w) y) (list (+ x w) (+ y h)) "")
  (command "LINE" (list (+ x w) (+ y h)) (list x (+ y h)) "")
  (command "LINE" (list x (+ y h)) (list x y) ""))

(draw-box 10 10 100 50)
</code></pre>

        <h2>Links</h2>
        <ul>
            <li><a href="https://acadlisp.de/">Interactive Demo (requires JavaScript)</a></li>
            <li><a href="https://github.com/acadlisp/acadlisp">Source code on GitHub</a></li>
        </ul>

        
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Witr ‚Äì Explain why a process is running on your Linux system (163 pts)]]></title>
            <link>https://github.com/pranshuparmar/witr</link>
            <guid>46392910</guid>
            <pubDate>Fri, 26 Dec 2025 15:20:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pranshuparmar/witr">https://github.com/pranshuparmar/witr</a>, See on <a href="https://news.ycombinator.com/item?id=46392910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">witr (why-is-this-running)</h2><a id="user-content-witr-why-is-this-running" aria-label="Permalink: witr (why-is-this-running)" href="#witr-why-is-this-running"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/4262592/530396425-adebb063-4706-47a8-9f77-612298354ef7.gif?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjY3ODg1MDEsIm5iZiI6MTc2Njc4ODIwMSwicGF0aCI6Ii80MjYyNTkyLzUzMDM5NjQyNS1hZGViYjA2My00NzA2LTQ3YTgtOWY3Ny02MTIyOTgzNTRlZjcuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTIyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEyMjZUMjIzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NDlkZjE0YzEyNWNiN2E1N2IyOWI2YTEzMThlM2RjMTMzNDIzZmY2NWQ0NTlhYTdkMTdlY2RlOWYwMTM0OWU3OCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.aEq_HFYq3RBltMOS6q92tPCwdiszEDFifKIC15kqSn4"><img src="https://private-user-images.githubusercontent.com/4262592/530396425-adebb063-4706-47a8-9f77-612298354ef7.gif?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjY3ODg1MDEsIm5iZiI6MTc2Njc4ODIwMSwicGF0aCI6Ii80MjYyNTkyLzUzMDM5NjQyNS1hZGViYjA2My00NzA2LTQ3YTgtOWY3Ny02MTIyOTgzNTRlZjcuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTIyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEyMjZUMjIzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NDlkZjE0YzEyNWNiN2E1N2IyOWI2YTEzMThlM2RjMTMzNDIzZmY2NWQ0NTlhYTdkMTdlY2RlOWYwMTM0OWU3OCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.aEq_HFYq3RBltMOS6q92tPCwdiszEDFifKIC15kqSn4" alt="witr" data-animated-image=""></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">1. Purpose</h2><a id="user-content-1-purpose" aria-label="Permalink: 1. Purpose" href="#1-purpose"></a></p>
<p dir="auto"><strong>witr</strong> exists to answer a single question:</p>
<blockquote>
<p dir="auto"><strong>Why is this running?</strong></p>
</blockquote>
<p dir="auto">When something is running on a system‚Äîwhether it is a process, a service, or something bound to a port‚Äîthere is always a cause. That cause is often indirect, non-obvious, or spread across multiple layers such as supervisors, containers, services, or shells.</p>
<p dir="auto">Existing tools (<code>ps</code>, <code>top</code>, <code>lsof</code>, <code>ss</code>, <code>systemctl</code>, <code>docker ps</code>) expose state and metadata. They show <em>what</em> is running, but leave the user to infer <em>why</em> by manually correlating outputs across tools.</p>
<p dir="auto"><strong>witr</strong> makes that causality explicit.</p>
<p dir="auto">It explains <strong>where a running thing came from</strong>, <strong>how it was started</strong>, and <strong>what chain of systems is responsible for it existing right now</strong>, in a single, human-readable output.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">2. Goals</h2><a id="user-content-2-goals" aria-label="Permalink: 2. Goals" href="#2-goals"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Primary goals</h3><a id="user-content-primary-goals" aria-label="Permalink: Primary goals" href="#primary-goals"></a></p>
<ul dir="auto">
<li>Explain <strong>why a process exists</strong>, not just that it exists</li>
<li>Reduce time‚Äëto‚Äëunderstanding during debugging and outages</li>
<li>Work with zero configuration</li>
<li>Be safe, read‚Äëonly, and non‚Äëdestructive</li>
<li>Prefer clarity over completeness</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Non‚Äëgoals</h3><a id="user-content-nongoals" aria-label="Permalink: Non‚Äëgoals" href="#nongoals"></a></p>
<ul dir="auto">
<li>Not a monitoring tool</li>
<li>Not a performance profiler</li>
<li>Not a replacement for systemd/docker tooling</li>
<li>Not a remediation or auto‚Äëfix tool</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">3. Core Concept</h2><a id="user-content-3-core-concept" aria-label="Permalink: 3. Core Concept" href="#3-core-concept"></a></p>
<p dir="auto">witr treats <strong>everything as a process question</strong>.</p>
<p dir="auto">Ports, services, containers, and commands all eventually map to <strong>PIDs</strong>. Once a PID is identified, witr builds a causal chain explaining <em>why that PID exists</em>.</p>
<p dir="auto">At its core, witr answers:</p>
<ol dir="auto">
<li>What is running?</li>
<li>How did it start?</li>
<li>What is keeping it running?</li>
<li>What context does it belong to?</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">4. Supported Targets</h2><a id="user-content-4-supported-targets" aria-label="Permalink: 4. Supported Targets" href="#4-supported-targets"></a></p>
<p dir="auto">witr supports multiple entry points that converge to PID analysis.</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">4.1 Name (process or service)</h3><a id="user-content-41-name-process-or-service" aria-label="Permalink: 4.1 Name (process or service)" href="#41-name-process-or-service"></a></p>

<p dir="auto">A single positional argument (without flags) is treated as a process or service name. If multiple matches are found, witr will prompt for disambiguation by PID.</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">4.2 PID</h3><a id="user-content-42-pid" aria-label="Permalink: 4.2 PID" href="#42-pid"></a></p>

<p dir="auto">Explains why a specific process exists.</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">4.3 Port</h3><a id="user-content-43-port" aria-label="Permalink: 4.3 Port" href="#43-port"></a></p>

<p dir="auto">Explains the process(es) listening on a port.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">5. Output Behavior</h2><a id="user-content-5-output-behavior" aria-label="Permalink: 5. Output Behavior" href="#5-output-behavior"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">5.1 Output principles</h3><a id="user-content-51-output-principles" aria-label="Permalink: 5.1 Output principles" href="#51-output-principles"></a></p>
<ul dir="auto">
<li>Single screen by default (best effort)</li>
<li>Deterministic ordering</li>
<li>Narrative-style explanation</li>
<li>Best-effort detection with explicit uncertainty</li>
</ul>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">5.2 Standard Output Sections</h3><a id="user-content-52-standard-output-sections" aria-label="Permalink: 5.2 Standard Output Sections" href="#52-standard-output-sections"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Target</h4><a id="user-content-target" aria-label="Permalink: Target" href="#target"></a></p>
<p dir="auto">What the user asked about.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Process</h4><a id="user-content-process" aria-label="Permalink: Process" href="#process"></a></p>
<p dir="auto">Executable, PID, user, command, start time and restart count.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why It Exists</h4><a id="user-content-why-it-exists" aria-label="Permalink: Why It Exists" href="#why-it-exists"></a></p>
<p dir="auto">A causal ancestry chain showing how the process came to exist.
This is the core value of witr.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Source</h4><a id="user-content-source" aria-label="Permalink: Source" href="#source"></a></p>
<p dir="auto">The primary system responsible for starting or supervising the process (best effort).</p>
<p dir="auto">Examples:</p>
<ul dir="auto">
<li>systemd unit</li>
<li>docker container</li>
<li>pm2</li>
<li>cron</li>
<li>interactive shell</li>
</ul>
<p dir="auto">Only <strong>one primary source</strong> is selected.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Context (best effort)</h4><a id="user-content-context-best-effort" aria-label="Permalink: Context (best effort)" href="#context-best-effort"></a></p>
<ul dir="auto">
<li>Working directory</li>
<li>Git repository name and branch</li>
<li>Docker container name / image</li>
<li>Public vs private bind</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Warnings</h4><a id="user-content-warnings" aria-label="Permalink: Warnings" href="#warnings"></a></p>
<p dir="auto">Non‚Äëblocking observations such as:</p>
<ul dir="auto">
<li>Process is running as root</li>
<li>Process is listening on a public interface (0.0.0.0 / ::)</li>
<li>Restarted multiple times (warning only if above threshold)</li>
<li>Process is using high memory (&gt;1GB RSS)</li>
<li>Process has been running for over 90 days</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">6. Flags &amp; Options</h2><a id="user-content-6-flags--options" aria-label="Permalink: 6. Flags &amp; Options" href="#6-flags--options"></a></p>
<div data-snippet-clipboard-copy-content="--pid <n>         Explain a specific PID
--port <n>        Explain port usage
--short           One-line summary
--tree            Show full process ancestry tree
--json            Output result as JSON
--warnings        Show only warnings
--no-color        Disable colorized output
--env             Show only environment variables for the process
--help            Show this help message"><pre><code>--pid &lt;n&gt;         Explain a specific PID
--port &lt;n&gt;        Explain port usage
--short           One-line summary
--tree            Show full process ancestry tree
--json            Output result as JSON
--warnings        Show only warnings
--no-color        Disable colorized output
--env             Show only environment variables for the process
--help            Show this help message
</code></pre></div>
<p dir="auto">A single positional argument (without flags) is treated as a process or service name.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">7. Example Outputs</h2><a id="user-content-7-example-outputs" aria-label="Permalink: 7. Example Outputs" href="#7-example-outputs"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">7.1 Name-based query</h3><a id="user-content-71-name-based-query" aria-label="Permalink: 7.1 Name-based query" href="#71-name-based-query"></a></p>

<div data-snippet-clipboard-copy-content="Target      : node

Process     : node (pid 14233)
User        : pm2
Command     : node index.js
Started     : 2 days ago (Mon 2025-02-02 11:42:10 +05:30)
Restarts    : 1

Why It Exists :
  systemd (pid 1) ‚Üí pm2 (pid 5034) ‚Üí node (pid 14233)

Source      : pm2

Working Dir : /opt/apps/expense-manager
Git Repo    : expense-manager (main)
Listening   : 127.0.0.1:5001"><pre><code>Target      : node

Process     : node (pid 14233)
User        : pm2
Command     : node index.js
Started     : 2 days ago (Mon 2025-02-02 11:42:10 +05:30)
Restarts    : 1

Why It Exists :
  systemd (pid 1) ‚Üí pm2 (pid 5034) ‚Üí node (pid 14233)

Source      : pm2

Working Dir : /opt/apps/expense-manager
Git Repo    : expense-manager (main)
Listening   : 127.0.0.1:5001
</code></pre></div>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">7.2 Short output</h3><a id="user-content-72-short-output" aria-label="Permalink: 7.2 Short output" href="#72-short-output"></a></p>

<div data-snippet-clipboard-copy-content="systemd (pid 1) ‚Üí PM2 v5.3.1: God (pid 1481580) ‚Üí python (pid 1482060)"><pre><code>systemd (pid 1) ‚Üí PM2 v5.3.1: God (pid 1481580) ‚Üí python (pid 1482060)
</code></pre></div>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">7.3 Tree output</h3><a id="user-content-73-tree-output" aria-label="Permalink: 7.3 Tree output" href="#73-tree-output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="witr --pid 1482060 --tree"><pre>witr --pid 1482060 --tree</pre></div>
<div data-snippet-clipboard-copy-content="systemd (pid 1)
  ‚îî‚îÄ PM2 v5.3.1: God (pid 1481580)
    ‚îî‚îÄ python (pid 1482060)"><pre><code>systemd (pid 1)
  ‚îî‚îÄ PM2 v5.3.1: God (pid 1481580)
    ‚îî‚îÄ python (pid 1482060)
</code></pre></div>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">7.4 Multiple matches</h3><a id="user-content-74-multiple-matches" aria-label="Permalink: 7.4 Multiple matches" href="#74-multiple-matches"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">7.4.1 Multiple matching processes</h4><a id="user-content-741-multiple-matching-processes" aria-label="Permalink: 7.4.1 Multiple matching processes" href="#741-multiple-matching-processes"></a></p>

<div data-snippet-clipboard-copy-content="Multiple matching processes found:

[1] PID 12091  node server.js  (docker)
[2] PID 14233  node index.js   (pm2)
[3] PID 18801  node worker.js  (manual)

Re-run with:
  witr --pid <pid>"><pre><code>Multiple matching processes found:

[1] PID 12091  node server.js  (docker)
[2] PID 14233  node index.js   (pm2)
[3] PID 18801  node worker.js  (manual)

Re-run with:
  witr --pid &lt;pid&gt;
</code></pre></div>
<hr>
<p dir="auto"><h4 tabindex="-1" dir="auto">7.4.2 Ambiguous name (process and service)</h4><a id="user-content-742-ambiguous-name-process-and-service" aria-label="Permalink: 7.4.2 Ambiguous name (process and service)" href="#742-ambiguous-name-process-and-service"></a></p>

<div data-snippet-clipboard-copy-content="Ambiguous target: &quot;nginx&quot;

The name matches multiple entities:

[1] PID 2311   nginx: master process   (service)
[2] PID 24891  nginx: worker process   (manual)

witr cannot determine intent safely.
Please re-run with an explicit PID:
  witr --pid <pid>"><pre><code>Ambiguous target: "nginx"

The name matches multiple entities:

[1] PID 2311   nginx: master process   (service)
[2] PID 24891  nginx: worker process   (manual)

witr cannot determine intent safely.
Please re-run with an explicit PID:
  witr --pid &lt;pid&gt;
</code></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">8. Installation</h2><a id="user-content-8-installation" aria-label="Permalink: 8. Installation" href="#8-installation"></a></p>
<p dir="auto">witr is distributed as a single static Linux binary.</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">8.1 Script Installation (Recommended)</h3><a id="user-content-81-script-installation-recommended" aria-label="Permalink: 8.1 Script Installation (Recommended)" href="#81-script-installation-recommended"></a></p>
<p dir="auto">The easiest way to install <strong>witr</strong> is via the install script.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Quick install</h4><a id="user-content-quick-install" aria-label="Permalink: Quick install" href="#quick-install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/pranshuparmar/witr/main/install.sh | bash"><pre>curl -fsSL https://raw.githubusercontent.com/pranshuparmar/witr/main/install.sh <span>|</span> bash</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Review before install</h4><a id="user-content-review-before-install" aria-label="Permalink: Review before install" href="#review-before-install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/pranshuparmar/witr/main/install.sh -o install.sh
cat install.sh
chmod +x install.sh
./install.sh"><pre>curl -fsSL https://raw.githubusercontent.com/pranshuparmar/witr/main/install.sh -o install.sh
cat install.sh
chmod +x install.sh
./install.sh</pre></div>
<p dir="auto">The script will:</p>
<ul dir="auto">
<li>Detect your CPU architecture (<code>amd64</code> or <code>arm64</code>)</li>
<li>Download the latest released binary and man page</li>
<li>Install it to <code>/usr/local/bin/witr</code></li>
<li>Install the man page to <code>/usr/local/share/man/man1/witr.1</code></li>
</ul>
<p dir="auto">You may be prompted for your password to write to system directories.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">8.2 Manual Installation</h3><a id="user-content-82-manual-installation" aria-label="Permalink: 8.2 Manual Installation" href="#82-manual-installation"></a></p>
<p dir="auto">If you prefer manual installation, follow these simple steps for your architecture:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">For amd64 (most PCs/servers):</h4><a id="user-content-for-amd64-most-pcsservers" aria-label="Permalink: For amd64 (most PCs/servers):" href="#for-amd64-most-pcsservers"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the binary
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr-linux-amd64 -o witr-linux-amd64

# Verify checksum (Optional, should print OK)
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/SHA256SUMS -o SHA256SUMS
grep witr-linux-amd64 SHA256SUMS | sha256sum -c -

# Rename and install
mv witr-linux-amd64 witr &amp;&amp; chmod +x witr
sudo mv witr /usr/local/bin/witr

# Install the man page (Optional)
sudo curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr.1 -o /usr/local/share/man/man1/witr.1
sudo mandb >/dev/null 2>&amp;1 || true"><pre><span><span>#</span> Download the binary</span>
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr-linux-amd64 -o witr-linux-amd64

<span><span>#</span> Verify checksum (Optional, should print OK)</span>
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/SHA256SUMS -o SHA256SUMS
grep witr-linux-amd64 SHA256SUMS <span>|</span> sha256sum -c -

<span><span>#</span> Rename and install</span>
mv witr-linux-amd64 witr <span>&amp;&amp;</span> chmod +x witr
sudo mv witr /usr/local/bin/witr

<span><span>#</span> Install the man page (Optional)</span>
sudo curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr.1 -o /usr/local/share/man/man1/witr.1
sudo mandb <span>&gt;</span>/dev/null <span>2&gt;&amp;1</span> <span>||</span> <span>true</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">For arm64 (Raspberry Pi, ARM servers):</h4><a id="user-content-for-arm64-raspberry-pi-arm-servers" aria-label="Permalink: For arm64 (Raspberry Pi, ARM servers):" href="#for-arm64-raspberry-pi-arm-servers"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the binary
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr-linux-arm64 -o witr-linux-arm64

# Verify checksum (Optional, should print OK)
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/SHA256SUMS -o SHA256SUMS
grep witr-linux-arm64 SHA256SUMS | sha256sum -c -

# Rename and install
mv witr-linux-arm64 witr &amp;&amp; chmod +x witr
sudo mv witr /usr/local/bin/witr

# Install the man page (Optional)
sudo curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr.1 -o /usr/local/share/man/man1/witr.1
sudo mandb >/dev/null 2>&amp;1 || true"><pre><span><span>#</span> Download the binary</span>
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr-linux-arm64 -o witr-linux-arm64

<span><span>#</span> Verify checksum (Optional, should print OK)</span>
curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/SHA256SUMS -o SHA256SUMS
grep witr-linux-arm64 SHA256SUMS <span>|</span> sha256sum -c -

<span><span>#</span> Rename and install</span>
mv witr-linux-arm64 witr <span>&amp;&amp;</span> chmod +x witr
sudo mv witr /usr/local/bin/witr

<span><span>#</span> Install the man page (Optional)</span>
sudo curl -fsSL https://github.com/pranshuparmar/witr/releases/latest/download/witr.1 -o /usr/local/share/man/man1/witr.1
sudo mandb <span>&gt;</span>/dev/null <span>2&gt;&amp;1</span> <span>||</span> <span>true</span></pre></div>
<p dir="auto"><strong>Explanation:</strong></p>
<ul dir="auto">
<li>Download only the binary for your architecture and the SHA256SUMS file.</li>
<li>Verify the checksum for your binary only (prints OK if valid).</li>
<li>Rename to witr, make it executable, and move to your PATH.</li>
<li>Install man page.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">8.3 Verify installation:</h3><a id="user-content-83-verify-installation" aria-label="Permalink: 8.3 Verify installation:" href="#83-verify-installation"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">8.4 Uninstallation</h3><a id="user-content-84-uninstallation" aria-label="Permalink: 8.4 Uninstallation" href="#84-uninstallation"></a></p>
<p dir="auto">To completely remove <strong>witr</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo rm -f /usr/local/bin/witr
sudo rm -f /usr/local/share/man/man1/witr.1"><pre>sudo rm -f /usr/local/bin/witr
sudo rm -f /usr/local/share/man/man1/witr.1</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">9. Platform Support</h2><a id="user-content-9-platform-support" aria-label="Permalink: 9. Platform Support" href="#9-platform-support"></a></p>
<ul dir="auto">
<li>Linux</li>
</ul>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">9.1 Permissions Note</h3><a id="user-content-91-permissions-note" aria-label="Permalink: 9.1 Permissions Note" href="#91-permissions-note"></a></p>
<p dir="auto">witr inspects <code>/proc</code> and may require elevated permissions to explain certain processes.</p>
<p dir="auto">If you are not seeing the expected information (e.g., missing process ancestry, user, working directory or environment details), try running witr with sudo for elevated permissions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo witr [your arguments]"><pre>sudo witr [your arguments]</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">10. Success Criteria</h2><a id="user-content-10-success-criteria" aria-label="Permalink: 10. Success Criteria" href="#10-success-criteria"></a></p>
<p dir="auto">witr is successful if:</p>
<ul dir="auto">
<li>An engineer can answer "why is this running?" within seconds</li>
<li>It reduces reliance on multiple tools</li>
<li>Output is understandable under stress</li>
<li>Users trust it during incidents</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">11. AI Assistance Disclaimer</h2><a id="user-content-11-ai-assistance-disclaimer" aria-label="Permalink: 11. AI Assistance Disclaimer" href="#11-ai-assistance-disclaimer"></a></p>
<p dir="auto">This project was developed with assistance from AI/LLMs (including GitHub Copilot, ChatGPT, and related tools), supervised by a human who occasionally knew what he was doing.</p>
<hr>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[High school student discovers 1.5M potential new astronomical objects (105 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/high-school-student-discovers-1-5-million-potential-new-astronomical-objects-by-developing-an-ai-algorithm-180986429/</link>
            <guid>46392815</guid>
            <pubDate>Fri, 26 Dec 2025 15:13:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/high-school-student-discovers-1-5-million-potential-new-astronomical-objects-by-developing-an-ai-algorithm-180986429/">https://www.smithsonianmag.com/smart-news/high-school-student-discovers-1-5-million-potential-new-astronomical-objects-by-developing-an-ai-algorithm-180986429/</a>, See on <a href="https://news.ycombinator.com/item?id=46392815">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smart-news/high-school-student-discovers-1-5-million-potential-new-astronomical-objects-by-developing-an-ai-algorithm-180986429/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Rob Pike Goes Nuclear over GenAI (1174 pts)]]></title>
            <link>https://skyview.social/?url=https%3A%2F%2Fbsky.app%2Fprofile%2Frobpike.io%2Fpost%2F3matwg6w3ic2s&amp;viewtype=tree</link>
            <guid>46392115</guid>
            <pubDate>Fri, 26 Dec 2025 14:08:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://skyview.social/?url=https%3A%2F%2Fbsky.app%2Fprofile%2Frobpike.io%2Fpost%2F3matwg6w3ic2s&#x26;viewtype=tree">https://skyview.social/?url=https%3A%2F%2Fbsky.app%2Fprofile%2Frobpike.io%2Fpost%2F3matwg6w3ic2s&#x26;viewtype=tree</a>, See on <a href="https://news.ycombinator.com/item?id=46392115">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LearnixOS (192 pts)]]></title>
            <link>https://www.learnix-os.com</link>
            <guid>46391599</guid>
            <pubDate>Fri, 26 Dec 2025 12:59:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.learnix-os.com">https://www.learnix-os.com</a>, See on <a href="https://news.ycombinator.com/item?id=46391599">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div id="mdbook-help-container">
            <h2>Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox></mdbook-sidebar-scrollbox>
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                <div id="menu-bar">
                    

                    <h2>The LearnixOS Book</h2>

                    
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        <h2 id="the-learnix-operating-system"><a href="#the-learnix-operating-system">The Learnix Operating System</a></h2>
<p><em>"If you can't explain it simply, you don't understand it well enough." - Albert Einstein</em></p>
<hr>
<p>Hello there!<sup id="fr-1-1"><a href="#footnote-1">1</a></sup></p>
<p>In this book we are going to write and learn about operating systems together!</p>
<p>We are going to implement an entire POSIX compliant OS in Rust and not use ANY<sup id="fr-2-1"><a href="#footnote-2">2</a></sup> external libraries. All of the thought process, code and implementations will be explained and documented here as well as in this <a href="https://github.com/sagi21805/LearnixOS">repo</a> which all the code snippets are from.</p>
<blockquote>
<p><em>Note</em>: ALL the syntax highlighting of the Rust code is custom and create by me! If you see and bug, please write in the comments or submit an <a href="https://github.com/sagi21805/mdbook-rust-highlight">issue</a>.</p>
</blockquote>
<h2 id="base-knowledge"><a href="#base-knowledge">Base Knowledge</a></h2>
<p>This book will be technical, and will assume a little bit of a programming knowledge background, but not necessarily in rust</p>
<p>If you are not coming from a low level programming knowledge that's fine!</p>
<p>Just make sure you know this stuff or learn it as you read. Also if in any place on this book I take some things for granted, please, open an issue <a href="https://github.com/sagi21805/LearnixOS-Book">here</a> and let me know so I could explain it better.</p>
<p>Some of the base knowledge that you would need to have:</p>
<ul>
<li>
<p>Some assembly knowledge. (just understand simple movs, and arithmetic operations, at a very basic level<sup id="fr-3-1"><a href="#footnote-3">3</a></sup>)</p>
</li>
<li>
<p>Some knowledge on memory. (what's a pointer, what's an address)</p>
</li>
<li>
<p>A knowledge in rust is not <em>that</em> important, but knowing at least one programming language is. I myself have some more learning in Rust, and in this book I will also explain some great features that it has!</p>
</li>
<li>
<p>A lot of motivation to learn and understand because it is a complex subject.</p>
</li>
</ul>
<h2 id="roadmap-of-this-book"><a href="#roadmap-of-this-book">Roadmap of this book</a></h2>
<ol>
<li>
<p>Compiling a stand alone binary</p>
</li>
<li>
<p>Boot loading, Debugging, stages and some legacy stuff</p>
</li>
<li>
<p>Important cpu modes and instructions</p>
</li>
<li>
<p>Paging, writing out own <em>malloc</em></p>
</li>
<li>
<p>Utilizing the Interrupt Descriptor Table</p>
</li>
<li>
<p>File systems and Disk Drivers</p>
</li>
<li>
<p>Thinking in terms of processes</p>
</li>
<li>
<p>Writing a shell</p>
</li>
<li>
<p>Running our first program! (Which off course will be Doom)</p>
</li>
<li>
<p>To be continued (Hopefully virtualization section and loading a vm of other OS)</p>
</li>
</ol>
<hr>
<ol><li id="footnote-1">
<p>Definitely not a star wars reference <a href="#fr-1-1">‚Ü©</a></p>
</li>
<li id="footnote-2">
<p>Only libraries that remove boilerplate code will be used (And obviously be explained). <a href="#fr-2-1">‚Ü©</a></p>
</li>
<li id="footnote-3">
<p>This is only relevant to the starting stages and some optimizations, and probably a day of learning will be enough <a href="#fr-3-1">‚Ü©</a></p>
</li>
</ol>
                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="https://www.learnix-os.com/ch01-00-getting-started.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">

                    <a rel="next prefetch" href="https://www.learnix-os.com/ch01-00-getting-started.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div>




        


        
        
        

        
        
        

        <!-- Custom JS scripts -->
        
        
        



    </div>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What did you read in 2025? (142 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46391572</link>
            <guid>46391572</guid>
            <pubDate>Fri, 26 Dec 2025 12:55:16 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46391572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bigbox"><td><table><tbody><tr id="46391572"><td><span></span></td><td><center><a id="up_46391572" href="https://news.ycombinator.com/vote?id=46391572&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=46391572">Ask HN: What did you read in 2025?</a></span></td></tr><tr><td colspan="2"></td><td><span><span id="score_46391572">107 points</span> by <a href="https://news.ycombinator.com/user?id=kwar13">kwar13</a> <span title="2025-12-26T12:55:16 1766753716"><a href="https://news.ycombinator.com/item?id=46391572">7 hours ago</a></span> <span id="unv_46391572"></span> | <a href="https://news.ycombinator.com/hide?id=46391572&amp;goto=item%3Fid%3D46391572">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20What%20did%20you%20read%20in%202025%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=46391572&amp;auth=a00b872b4c2fe0def440b701610ca99df53e889f">favorite</a> | <a href="https://news.ycombinator.com/item?id=46391572">121&nbsp;comments</a></span></td></tr><tr><td colspan="2"></td><td><p>I mostly read newspapers and technical journals, but two books that I read that made an impression: "The Changing World Order" and "The Gulag Archipelago".</p></td></tr><tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr></tbody></table><br>
<table><tbody><tr id="46396904"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396904" href="https://news.ycombinator.com/vote?id=46396904&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Albert Camus -- <i>The Plague, The Fall, Exile and the Kingdom, and Selected Essays</i></p><p>I'll pick the one(s) I read most recently. Camus and his absurdism resonate with me. His writing is simple and precise, but his ideas are big. Some of these essays were rereads, but I gained something new, as I have more life experience to integrate with the subject matter.</p><p>If you ever find yourself wondering what the point of effort and progress is given the realities of life, you may enjoy his work. I suspect there are some of his (and peers Sartre and de Beauvoir) readers floating around here on HN.</p></div></td></tr></tbody></table></td></tr><tr id="46396965"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396965" href="https://news.ycombinator.com/vote?id=46396965&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Almost done with Genghis Khan and the making of the modern world by Jack Weatherford, I really enjoyed it. If someone can recommend other updated, history reads about empires, world history etc.</p></div></td></tr></tbody></table></td></tr><tr id="46396964"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396964" href="https://news.ycombinator.com/vote?id=46396964&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My highlights were the Edward Ashton books ¬´ Mickey7 ¬ª and ¬´ Antimatter Blues ¬ª (sequel to the first).</p><p>Haven‚Äôt seen the movie adaptation yet but the books are such delightful dark humor SF, loved them</p></div></td></tr></tbody></table></td></tr><tr id="46396899"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396899" href="https://news.ycombinator.com/vote?id=46396899&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Completed books:</p><p>Project Hail Marry by Andy Weir</p><p>Dungeon Crawler Carl (Books 1-7) by Matt Dinniman</p><p>I'm currently reading:</p><p>Careless People: A Cautionary Tale of Power, Greed, and Lost Idealism by Sarah Wynn-Williams</p></div></td></tr></tbody></table></td></tr><tr id="46396084"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396084" href="https://news.ycombinator.com/vote?id=46396084&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My top reads this year:</p><p>- How to Tame a Fox - great popsci history of a genetics experiment</p><p>- "The Sixth Extinction" and "Not the end of the world" - compelling but contrasting takes on climate change</p><p>- Through Two Doors at Once - posci history of the double slit experiment</p><p>- Alvarez: Adventures of a Physicist - Luis Alvarez should get just as much attention as Feynman does IMO!</p><p>- A Matter of Death and Life - the last book I read this year that was touching and made me remember what‚Äôs really important in life</p></div></td></tr></tbody></table></td></tr><tr id="46396713"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396713" href="https://news.ycombinator.com/vote?id=46396713&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I'll share my top book of the year:</p><p><i>Fryderyk Chopin: A Life and Times</i>, Alan Walker</p><p>A riveting read by a legendary musicologist and biographer.  Walker spent about ten years researching this.  It is 700 pages, which seems daunting but he makes this authoritative bio absolutely enjoyable.  It's also a "corrective biography", it dispels a lot of myths.  This book is one of the best examples of accessible writing with flair.  What a writer!</p><p>Throughout the book, Walker tastefully quotes musical phrases (in notation) from Chopin's works to situate them in context.  I often paused reading and put on the track on a given page (nocturnes, mazurkas, preludes, etc).  It made the reading experience incredibly rich and fun.  Other things I enjoyed: Chopin's letters to his friends and family, life in aristocratic salons of Paris, London, Warsaw, and more‚ÄîChopin had unparalleled access.  Of course, there's also a lot of gut-wrenching stuff.  As the book's blurb says, it really <i>is</i> for both the casual music lover and the professional pianist.</p><p>If you haven't discovered them yet, give a listen to Chopin's nocturnes.  But please, give them an attentive listen and play them on a high-quality audio system.  Here[1] is one of his finest nocturnes (it is less famous than the "happier" nocturne that follows it, Op. 9 No. 2).</p><p>[1] <i>Nocturne in B-flat minor, Op. 9 No. 1</i>: <a href="https://www.youtube.com/watch?v=ThMGf07UBHQ" rel="nofollow">https://www.youtube.com/watch?v=ThMGf07UBHQ</a></p></div></td></tr></tbody></table></td></tr><tr id="46392045"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392045" href="https://news.ycombinator.com/vote?id=46392045&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Technical followed by non-technical. I read more than these, but these are the highlights.</p><p>Mouse, a Language for Microcomputers by Peter Grogono - Mouse is basically an esolang with barely any abstraction facilities, but the book was well-written and the language compelling enough to explore further.</p><p>Notes on Distance Dialing (pdf) by AT&amp;T - Described the telephone systems of the USA and Canada in the mid-1950s. The reading is a dry as it gets, but it was a fascinating dive into a vastly complex system solving extremely hard problems. This is a must-read for folks interested in systems-thinking. That said, I am actively looking for recommendations for books about the process of designing and building the unbelievably complex telephony system over the rudiments of the earlier systems. Recommendations welcomed!</p><p>The Eye of Osiris by R. Austin Freeman - This is the first book that I‚Äôve read from Freeman and I suspect that I will read many more in the future. The story follows the disappearance of John Bellingham, Egyptologist and the subsequent investigation. As the investigation stalls, the eminent Dr. Thorndyke digs into the case. The story sets up the mystery nicely and indeed provides enough information to the reader to infer how the disappearance occurred and who or what facilitated it. The book is one of the best whodunits that I‚Äôve ever read.</p><p>The Mystery of Edwin Drood by Charles Dickens - His final work remains unfinished as he passed away before he could complete it. Further complicating the meta-story is that he also didn‚Äôt outline the ending nor even put to paper the ‚Äúvillain‚Äù of the story. The meta-mystery of the ending has motivated a mountain of speculation around the ending including dozens of continuations of the story from other authors, all deriving their pet endings from textual hints, accounts from Dickens‚Äô friends, illustration notes, and even in some cases seances supposedly accompanied by the spirit of Dickens himself. What was written by Dickens is spectacular and a compelling mystery and although it would be great to know the resolution, in some ways the ‚ÄúDroodiana‚Äù that has cropped up over the past 150+ years is reason enough for it to remain a mystery. The whole lore around Edwin Drood is a worthwhile hobby in itself and well-worth exploring. The Chiltern Library edition of the book contains the story and a good bit of the lore around the writing and the meta-works available at the time of its publication.</p><p>The Shadow People by Margaret St. Clair - Sadly out of print and difficult to find, but I‚Äôve had it on my shelves for decades and finally got around to reading it. The book came onto my radar in the 1980s when I learned about it in the appendix-n of the 1st edition Advanced D&amp;D Dungeon Masters Guide. I enjoyed many of the books at the time and have slowly swung around to re-reading them over the past few years. Sadly, most on the list do not stand the test of time for me, but St. Clair‚Äôs mixture of 60s counter-cultural leanings in a fantasy/sf world still works. The cultural touch-points in the book feel quite dated, but despite the occasional awkwardness, the story is unique even today.</p><p>Lolly Willowes by Sylvia Townsend Warner - The book started as a passable novel of manners focused on a turn of the century British middle-class family. The titular character was mostly background decoration for the first third of the novel and AFAIR was talked about only in the third-person. It‚Äôs only when she made the choice to move out on her own to the country in her middle age does she gain a central role in the narrative and her inner thoughts revealed. This is where things really pick up because I was shocked to learn that this unassuming woman‚Äôs inner thoughts had a delicious darkness to them. I don‚Äôt want to give away too much, but I‚Äôll just say that you will not expect how the story ends.</p><p>Patience by Daniel Clowes - A profound graphic novel using time-travel to explore the idea of enduring love with a story that proceed through time, following Jack as he tries to alter the past and save the woman he loves. This well-known science fiction motif is elevated by Clowes‚Äô signature psychological complexity.</p><p>Narcissus and Goldmund by Herman Hesse - I‚Äôve read most of the books by Hermann Hesse but this one escaped my attention until this year. The story follows the parallel lives of a monk Narcissus and his passionate friend Goldmund as they respectively search for meaning in life through spiritual means and through pleasures of the flesh.</p><p>We Who Are About To‚Ä¶ by Joanna Russ - A small group of astronauts crash land on a hostile alien world and quickly realize that rescue is unlikely to come. Many SF stories have started this way and so the expectation is that this is a colonization story‚Ä¶ but Russ thrives on subverting reader expectations.</p><p>Fifty Forgotten Records by R.B. Russell - Another lovely entry in Russell‚Äôs series (one can hope) of autobiographical explorations of art, so far covering literature and now music. This book describes 50 records of varying popularity and Russell‚Äôs personal connections to each. While I certainly enjoyed finding a dozen or so new albums to explore, the true triumph of the book lies in the vulnerable, reflective memoir threaded throughout.</p><p>The Way of All Flesh by Samuel Butler A novel that follows 4-generations of the Ponitifex family, with a particular bildungsroman-esque thread around Ernest, a young man who‚Äôs naivete leads to his downfall and how his life unfolds thereafter.</p><p>I wrote about these (and more) at <a href="https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html" rel="nofollow">https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-o...</a></p></div></td></tr></tbody></table></td></tr><tr id="46396316"><td></td></tr><tr id="46396128"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396128" href="https://news.ycombinator.com/vote?id=46396128&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Check out:</p><p>Introduction to Telephones and Telephone Systems (3rd Ed.) by A. Michael Noll: A great system-level overview covering instruments, transmission media, switching, and signaling.</p><p>Understanding Telephone Electronics by Carr, Winder, &amp; Bigelow: Focuses on the electronic components and workings of telephone systems.</p></div></td></tr></tbody></table></td></tr><tr id="46396515"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396515" href="https://news.ycombinator.com/vote?id=46396515&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I've listened to Project Hail Mary, even though the story is not that much complex and is predictable at times, the audiobook experience is the best I've had, I have been looking at similar audiobooks but couldn't find any</p></div></td></tr></tbody></table></td></tr><tr id="46397006"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46397006" href="https://news.ycombinator.com/vote?id=46397006&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>You should check out the Dungeon Crawler Carl series.</p><p>The audiobook for the most recent one released and immediately became the best selling audiobook in the world. The talent of Jeff Hayes and Soundbooth Theater have ruined other audiobooks for me.</p></div></td></tr></tbody></table></td></tr><tr id="46396579"><td></td></tr><tr id="46396259"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396259" href="https://news.ycombinator.com/vote?id=46396259&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The Gulag Archipelago is on my shelf, when I rotate back to Russian authors (big fan of Dostoevsky, Nabokov, Bulgakov) I will hopefully get to it.</p><p>Here's my log for 2025, most recent at the top. Currently I am slogging my way through Heinlein's "The Number of the Beast" which I'm not a fan of. Halfway done with it though!</p><p>Gabrielle Zevin, "The Hole We're In" (not my usual genre, enjoyed this though)</p><p>Robert A. Heinlein, "Stranger in a Strange Land" (pretty good)</p><p>Robert A. Heinlein, "Time Enough for Love" (PHENOMENAL, highly recommended)</p><p>Robert A. Heinlein, "Methuselah's Children" (pretty good, required to understand "Time Enough for Love")</p><p>Richard K. Morgan, "Altered Carbon" (very good)</p><p>Robert A. Heinlein, "The Rolling Stones" (young adult, but good all the same)</p><p>Robert A. Heinlein, "The Moon is a Harsh Mistress" (very good)</p><p>Piers Anthony, "On A Pale Horse" (very good, never got very far into the series though)</p><p>Lincoln Child, "Full Wolf Moon" (okay, not great)</p><p>Lincoln Child, "The Forgotten Room" (pretty good)</p><p>Lincoln Child, "The Third Gate" (very good)</p><p>Lincoln Child, "Terminal Freeze" (okay, not great)</p><p>William Gibson, "In the Beginning‚Ä¶ Was the Command Line" (good, but outdated, look up what he's said about it more recently)</p><p>Lincoln Child, "Deep Storm" (very good)</p><p>James Patterson, "Along Came a Spider" (not my usual genre, okay though)</p><p>Jules Verne, "Around the World in 80 Days" (from childhood, revisited)</p></div></td></tr></tbody></table></td></tr><tr id="46396335"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396335" href="https://news.ycombinator.com/vote?id=46396335&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>&gt; William Gibson, "In the Beginning‚Ä¶ Was the Command Line" (good, but outdated, look up what he's said about it more recently)</p><p>That's Neal Stephenson, not William Gibson.</p></div></td></tr></tbody></table></td></tr><tr id="46396567"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396567" href="https://news.ycombinator.com/vote?id=46396567&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The Silo series by Hugh Howey -- some excellent sci-fi to go along with the show</p><p>The Red Rising series by Pierce Brown -- lots of sci-fi fun, extremely epic</p><p>The Dark Tower series by Stephen King -- King's "Lord of the Rings" opus, great writing, ending maybe a little unsatisfying but not abnormal</p><p>Artemis - Andy Weir's first book -- Fun read about a heist on the moon. Anticipating Project Hail Mary movie early next year!</p><p>Currently in the middle of: The Talisman - Stephen King / Peter Straub</p></div></td></tr></tbody></table></td></tr><tr id="46391764"><td></td></tr><tr id="46396060"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396060" href="https://news.ycombinator.com/vote?id=46396060&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Me too. It's phenomenal, especially the first book and the pilgrims' stories. Such a moving mix of religious mystics, science fiction and the dreaded AI. The second one builds up the tension and the last 2... are good.</p></div></td></tr></tbody></table></td></tr><tr id="46392198"><td></td></tr><tr id="46396271"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396271" href="https://news.ycombinator.com/vote?id=46396271&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Read the first two this year. Absolutely incredible and now some of my all time favorite sci-fi.</p></div></td></tr></tbody></table></td></tr><tr id="46393249"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46393249" href="https://news.ycombinator.com/vote?id=46393249&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I read the second two books this year and was unfortunately disappointed.</p><p>First two were so fun but I think I got hung up on some of the more clumsy stylistic parts of the Endymion books. I guess my ‚Äútrust‚Äù in the author comes from the style and tropes they use, and if I they lose my trust none of the deeper parts resonate. Glad you enjoyed!</p></div></td></tr></tbody></table></td></tr><tr id="46396649"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396649" href="https://news.ycombinator.com/vote?id=46396649&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p># Catch-22 (by Joseph Heller) - had been seeing it mentioned on HN (and other sites) for years, I finally read it and it was one the best novels I've ever read.</p><p># The Universe and Dr. Einstein (by Lincoln Barnett) - recommended for anyone who is interested about Einstein's thought process that gave birth to two great theories.</p><p># What I Talk About When I Talk About Running (by Haruki Murakami) - it's my first book from H. M. and I really liked it. It's kind of a memoir and made me like Murakami and now I plan to read his novels too.</p><p># How to Build a Car (by Adrian Newey) - that famous F1 car designer... Great read. Gives readers a chance to   glimpse into both (technical) thought process behind designing a race car and human side of it.</p><p># Basic Mathematics (by Serge Lang) - not *reading* exactly, working through it (to brush the rust off of my math   fundamentals).</p></div></td></tr></tbody></table></td></tr><tr id="46396511"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396511" href="https://news.ycombinator.com/vote?id=46396511&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I'm on my about 10th re-read of Dungeon Crawler Carl. I also reread the Murderbot Diaries.</p><p>Some new listens that I liked:</p><p>* Blood Over Brighthaven</p><p>* Fleabag: A Monster Evolution LitRPG</p><p>* Flybot</p><p>* The Invisible Life of Addie LaRue</p><p>* Bury Our Bones in the Midnight Soil</p></div></td></tr></tbody></table></td></tr><tr id="46396973"><td></td></tr><tr id="46391790"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391790" href="https://news.ycombinator.com/vote?id=46391790&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My favourite SF book this year was "Translation State" by Ann Leckie. It is set in the Imperial Radch world so having read the Ancillary trilogy is useful but not essential.</p><p>I like it because it contains the strangest aliens (the Presger) that I have come across. They are as far from humans in costumes as you could get. What the Presger do (and their proxies in the Human world the Translators) is totally unguessable.</p><p>A fabulous hard SF read and a must if you read the Ancillary trilogy.</p></div></td></tr></tbody></table></td></tr><tr id="46396943"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396943" href="https://news.ycombinator.com/vote?id=46396943&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I can warmly recommend anything written by Leckie. Her scifi is great. But her attempt at fantasy (The Raven Tower) is also most excellent.</p></div></td></tr></tbody></table></td></tr><tr id="46392067"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46392067" href="https://news.ycombinator.com/vote?id=46392067&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I enjoyed Translation State so much. It thought that Leckie got lost in the depths of Octavia Butler‚Äôs extra weird shit (and Xenogensis) and cross bred it with the political novel style of the Ancillary trilogy, and the result was <i>chefs kiss</i>.</p><p>I feel comfortable recommending it even if you haven‚Äôt read any other Leckie.</p><p>Edit: if you haven‚Äôt read the Bloodchild anthology by Butler, give it a read. Some of the short stories will seem very familiar after Translation State, especially the alien parts.</p></div></td></tr></tbody></table></td></tr><tr id="46393131"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46393131" href="https://news.ycombinator.com/vote?id=46393131&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I enjoyed it too, but I was already a big fan of the Imperial Radch series. Does it work standalone also?</p><p>Edit: just to add that the audiobook is really well narrated</p></div></td></tr></tbody></table></td></tr><tr id="46396153"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396153" href="https://news.ycombinator.com/vote?id=46396153&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The Will of the Many. An epic high fantasy adventure. I‚Äôm just about to finish the second book in the series - The Strength of a Few. I haven‚Äôt gasped this many times reading a book in a long time.</p></div></td></tr></tbody></table></td></tr><tr id="46396289"><td></td></tr><tr id="46396393"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46396393" href="https://news.ycombinator.com/vote?id=46396393&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Same here! I‚Äôm on the final 200 pages. It‚Äôs going to painful waiting so long for the third in the series. I went straight from book 1 to 2 with no wait thankfully.</p></div></td></tr></tbody></table></td></tr><tr id="46396677"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396677" href="https://news.ycombinator.com/vote?id=46396677&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I already forgot what I read for my work (MS in CS), so I'll stick with fiction.</p><p>This year was slow for me reading-wise.  Not a whole lot:</p><p>- The Blind Owl / Sadegh Hedayat
- Prince of Annwn (Mabinogion Tetralogy #1)
- Norse Mythology / Gaiman: read it before accusations came out
- Brief Interviews with Hideous Men / David F Wallace
- A Connecticut Yankee ... / Mark Twain (not yet finished)</p></div></td></tr></tbody></table></td></tr><tr id="46396709"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396709" href="https://news.ycombinator.com/vote?id=46396709&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The Burnout Society - Byung-Chul Han</p><p>The Disappearance of Rituals - Byung-Chul Han</p><p>Outlive - Peter Attia (This felt like a complete waste of attention)</p><p>An Emotional Education - School of Life/Alain de Botton</p><p>The Story of Your Life and Others - Ted Chiang</p><p>Nausica√§ of the Valley of the Wind - Hayao Miyazaki</p><p>Plants from Test Tubes - Lydiane Kyte; John Kleyn; Holly Scoggins; Mark Bridgen</p><p>Some biography I've forgotten</p></div></td></tr></tbody></table></td></tr><tr id="46396915"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396915" href="https://news.ycombinator.com/vote?id=46396915&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>What did you think of The Disappearance of Rituals? It's been on my radar, but I've already got a big pile of books waiting to be read.</p></div></td></tr></tbody></table></td></tr><tr id="46391926"><td></td></tr><tr id="46396083"><td></td></tr><tr id="46394704"><td></td></tr><tr id="46396465"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396465" href="https://news.ycombinator.com/vote?id=46396465&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I‚Äôve been working through more Dostoyevsky- currently ending the year reading The Brothers Karamazov (Constance Garnett translation).</p><p>It‚Äôs topping The Idiot for me- and a fitting way to end the year. I have spent most of 2025 stuck in a 19th Century reading cycle which started when reading Murakamis ‚ÄúAfter the quake‚Äù short story collection, specifically Super-Frog saves Tokyo where he mentions Anna K.</p><p>Anna Karenina-&gt; Crime and Punishment-&gt; The Idiot and some various Kafka in the mix too.</p><p>Hoping to visit some modern stuff again next year</p></div></td></tr></tbody></table></td></tr><tr id="46396685"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396685" href="https://news.ycombinator.com/vote?id=46396685&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>If you are looking for some modern stuff that would go nicely with Dostoyevsky/Kafka, I can warmly recommend Krasznahorkai, especially his first book, Satantango.</p><p>Really well written and well structured novel, and although he uses long sentences and no paragraph breaks, the writing is surprisingly accessible and incredibly immersive.</p><p>It was my first fiction book in a long time and it made me love fiction again.</p></div></td></tr></tbody></table></td></tr><tr id="46396636"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396636" href="https://news.ycombinator.com/vote?id=46396636&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Fiction (shortlist):</p><p>-Some Desperate Glory (Emily Tesh)</p><p>-A Memory called Empire (Arkady Martin) both of these are a fairly interesting take on scifi worldbuilding. Could be called "highbrow", but IMO pretty easy reads still.</p><p>-Piranesi (S. Clark) - well written fantasy
and plenty of other stuff that I've seen in other comments (Dungeon Crawler Carl does stand out a bit, but it's really a guilty pleasure / escape kind of a read).</p><p>Non-Fiction</p><p>-Brakneck (Dan Wang) - slightly outdated (by ~2y, which seems really breakneck), but still interesting take on modern China</p><p>-Capitalism (Sven Beckert) - still halfway through this one, but it's shaping up to be my #1 for 2025 non fiction</p><p>-The Origins of Efficiency - from B. Potter, the author of Construction Physics blog. The blog is fairly information dense, but this basically reads like a textbook. Still a pretty good reference IMO for people working in manufacturing.</p></div></td></tr></tbody></table></td></tr><tr id="46396159"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396159" href="https://news.ycombinator.com/vote?id=46396159&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Ted Chang, Bunch Books on Roman Architecture, "You, me, and Ulysses S. Grant", Raving Fans (for work), 3 body Problem, Not the end of the world, Anti-fragile (3rd time), Transformed (for work, it was trash), Harry Potter (in Spanish), and some other things I can't think of off the top of my head.</p></div></td></tr></tbody></table></td></tr><tr id="46396670"><td></td></tr><tr id="46396345"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396345" href="https://news.ycombinator.com/vote?id=46396345&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I don't read much any more. Mostly magazine articles.</p><p>I did re-read "The Long Run" from Daniel Keys Moran (one of the very short list of books I've re-read, and this was #4 or #5).</p><p>"Were you taught to hate Peaceforcers?" "Taught? No."</p><p>The only new book that I read was "Heat 2" by Michael Mann and Meg Gardiner.</p><p>It was "ok". It honestly felt like a mashup of "Heat", "Miami Vice", and "Blackhat". So, not as fresh as I would have liked. (Mind, I really like all of those movies.)</p><p>I'll see the movie when it comes out, but the book was just "ok".</p></div></td></tr></tbody></table></td></tr><tr id="46396720"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396720" href="https://news.ycombinator.com/vote?id=46396720&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Work related: The Culture Map - can strongly recommend!
Non-work: the Alex Rider series. Both entertaining and serious when it needs to be without being super grim.</p></div></td></tr></tbody></table></td></tr><tr id="46396145"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396145" href="https://news.ycombinator.com/vote?id=46396145&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>"Endure" which I highly recommend to anyone ever slightly interested in human performance.</p><p>"The Way of Kings" by Brandon Sanderson. Beautiful world-building as always.</p><p>And some others that I can't remember but those two were the highlights of the year.</p></div></td></tr></tbody></table></td></tr><tr id="46396556"><td></td></tr><tr id="46396350"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396350" href="https://news.ycombinator.com/vote?id=46396350&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Demian by Hermann Hesse. I wanted to scream "Stop overthinking!" to the protagonist. Something I can relate to.</p><p>Siddharta by Hermann Hesse. Helped me understand that a perfect life is a collection of ups and downs and that one must accept it all.</p><p>Amerika by Franz Kafka. Could relate to the protagonist because people take advantage of his naivety.</p><p>Factfulness by Hans Rosling. Made me see the world in a less pessimistic way.</p></div></td></tr></tbody></table></td></tr><tr id="46392011"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392011" href="https://news.ycombinator.com/vote?id=46392011&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My goal for the year was 15 books. I've finished 14 so far and should finish #15 in the next couple of days if all goes well. Here's what I've read (it's a mix of fiction and non-fiction) in reverse order by completion date:</p><p><i>Nash Falls</i> - David Baldacci</p><p><i>Exit Strategy</i> - Lee Child &amp; Andrew Child</p><p><i>Perceptrons: An Introduction to Computational Geometry</i> - Marvin Minsky &amp; Seymour Papert</p><p><i>We are Legion (We are Bob)</i> - Dennis Taylor</p><p><i>Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Volume 1: Foundations</i> - David Rumelhart &amp; Jay McClelland</p><p><i>Semantic Information Processing</i> - Marvin Minsky</p><p><i>Associative Engines: Connectionism, Concepts, and Representational Change</i> - Andy Clark</p><p><i>Associative Networks: The Representation and Use of Knowledge of Computers</i> - Nicholas Findler</p><p><i>The Analogical Mind: Perspectives from Cognitive Science</i> -  Dedre Gentner, Keith J. Holyoak, Boicho N. Kokinov (eds)</p><p><i>Similarity and Analogical Reasoning</i> - Stella Vosniadou (ed)</p><p><i>Never Flinch</i> - Stephen King</p><p><i>The Bad Weather Friend</i> - Dean Koontz</p><p><i>Kluge: The Haphazard Construction of the Human Mind</i> - Gary Marcus</p><p><i>After Death</i> - Dean Koontz</p><p>The 15th book that I hope to finish will be:</p><p><i>Principles of Semantic Networks</i> - John F. Sowa (ed)</p></div></td></tr></tbody></table></td></tr><tr id="46396064"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396064" href="https://news.ycombinator.com/vote?id=46396064&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The bobiverse books are fantastic, would suggest continuing the series as it gets even better</p></div></td></tr></tbody></table></td></tr><tr id="46396836"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396836" href="https://news.ycombinator.com/vote?id=46396836&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I RSS read all day about solid state batteries, which recently are in power banks. Hope to hear about folding MicroLED phones on www.microled-info.com But they will start out too expensive.</p><p>Because abusive parents false arrested/committed me without a trial as manic for buying a Linux (they can barely use apple) computer and RockBox music player. I spent much time gathering these quotes <a href="https://antipsychiatry.yay.boo/" rel="nofollow">https://antipsychiatry.yay.boo/</a></p></div></td></tr></tbody></table></td></tr><tr id="46396937"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396937" href="https://news.ycombinator.com/vote?id=46396937&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>What are the quotes? I don't understand, some of them are just a single word like "Art", "Autoimmune", "Cartoons"; or innocuous phrases with no context.</p><p>What am I supposed to understand from this?</p></div></td></tr></tbody></table></td></tr><tr id="46391889"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391889" href="https://news.ycombinator.com/vote?id=46391889&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I was actually writing, been doing it full time for months. I've spent probably over 1,000 hours ...</p><p>Not trying to make any money, just feel compelled to do this.</p><p>A fiction story about how personal computers have dismantled society over 40 years... it takes place in 1983 and involves a vulnerable opportunistic time traveler who's getting more than he bargained for.</p><p>Here's some quotes to give you a feel:</p><p>"The smartphone is the electrical stunner in the slaughterhouse of society"</p><p>"You‚Äôll be able to access any TV or radio station in real time, around the world, talk to people overseas in high resolution video with live translations for free and be bored by it"</p><p>"In the future the hermetic spaces of solitude will be breached as we build a global village. The private will become public and, ironically, the public will become private as the streets empty of experiences taken indoors, inside of bedrooms, beneath our screens of glowing grace."</p><p>It's intentionally meant to be ambitious, brutal and challenging. And hopefully insight will materialize from the dust of forgotten dreams.</p><p>If you are interested in reading it, just hit me up</p></div></td></tr></tbody></table></td></tr><tr id="46394452"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46394452" href="https://news.ycombinator.com/vote?id=46394452&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I mostly read non-fiction and technical articles.</p><p>My favorite book this year was "Differential Privacy" (2025) by Simson Garfinkel. Differential privacy is a mathematical theory of data privacy sandwiched between cryptography, databases, and ML. This is the first book-length non-technical introduction, and it's well executed.</p><p>Here's my full book list for the year: <a href="https://bcmullins.github.io/interesting-books-2025/" rel="nofollow">https://bcmullins.github.io/interesting-books-2025/</a>.</p></div></td></tr></tbody></table></td></tr><tr id="46396149"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396149" href="https://news.ycombinator.com/vote?id=46396149&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My favorite reads of the year:</p><p>- <i>Futu.re</i> by Dmitry Glukhovsky (author of Metro 2033 series). Interesting take of how life would look like if humans became immortal.</p><p>- <i>Blackout</i> by Marc Elsberg. A semi-realistic depiction of a 2-week long blackout in Europe caused by a terrorist attack.</p><p>- <i>Millenium trilogy</i> by Stieg Larson. Murder mystery in Sweden. Really enjoyed the setting.</p></div></td></tr></tbody></table></td></tr><tr id="46391735"><td></td></tr><tr id="46393306"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46393306" href="https://news.ycombinator.com/vote?id=46393306&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I was surprised by how much I enjoyed <i>Careless People</i>. The unexpected peek into the author's personal childhood and family ethos was really interesting. The look at Facebook from within was a cautionary tale.</p><p>I also liked <i>I Am Not Your Enemy</i> by Reality Winner.</p></div></td></tr></tbody></table></td></tr><tr id="46392710"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46392710" href="https://news.ycombinator.com/vote?id=46392710&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>"Apple in China" was pretty good! I can second that one. If you haven't checked it out, "Chip War" is also pretty good and along the same style. I'm reading it right now.</p></div></td></tr></tbody></table></td></tr><tr id="46393194"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46393194" href="https://news.ycombinator.com/vote?id=46393194&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>After reading Primo Levi's "The Drowned and the Saved", I went on a binge of his earlier works: "If This Is a Man", "The Truce", "If not now, when?". All great, but I keep coming back to "The Drowned and the Saved"; it's hard to put my finger on it, but it's a book that provides more meaning about life than anything I've ever read.</p></div></td></tr></tbody></table></td></tr><tr id="46391993"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391993" href="https://news.ycombinator.com/vote?id=46391993&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>For fiction I read a lot of Brandon Sanderson: the second Mistborn series, plus a few of the Secret Projects. I quite liked <i>Tress of the Emerald Sea</i>. Also currently reading R. F. Kuang's <i>Katabasis</i> which I'm really enjoying so far.</p><p>For nonfiction, I found Amanda Ripley's <i>High Conflict</i> to be excellent and insightful. I also finally got around to reading <i>The Selfish Gene</i> by Richard Dawkins; I expected it to be fine, but it far exceeded my expectations! On top of that, the edition I read also had "end notes" interspersed throughout the book with retrospectives from decades later, which only added to the book's richness.</p></div></td></tr></tbody></table></td></tr><tr id="46393485"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46393485" href="https://news.ycombinator.com/vote?id=46393485&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My 3 favorites were:</p><p>Dungeon Crawler Carl - I laughed, I cried, perfect match for my sense of humor.</p><p>The Comfort Crisis by Michael Easter - Great read, changed some of my training because of it.</p><p>Fall of Giants by Ken Follett (#1 of The Century Trilogy series) - An amazing overview of the 20th century through the eyes of several families accross the globe (fiction).</p></div></td></tr></tbody></table></td></tr><tr id="46392136"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392136" href="https://news.ycombinator.com/vote?id=46392136&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Pachinko by Min Jin Lee stuck with me more than anything else I read this year. It is a work of simple beauty.</p><p>It‚Äôs a story of several generations of poor Korean women who eventually immigrate to Japan. The front half of the book is wonderfully paced to spend time with the characters.  The back half can feel a bit rushed, but it becomes more of a page turner.</p><p>The Cold Millions by Jess Walter is another period novel about union organizing in the Pacific Northwest around the turn of the century, and follows two brothers.  The depth of research makes this book wonderfully vibrant.</p></div></td></tr></tbody></table></td></tr><tr id="46396869"><td></td></tr><tr id="46392090"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392090" href="https://news.ycombinator.com/vote?id=46392090&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I was suffering from a burnout for much of the year and read mostly to relax. Reread a bunch of Discworld and read most of the Expanse series for the first time. Some Murakami. The Conway biography ("Genius At Play"), also a reread because it's fun.</p><p>But "The Dream Machine: JCR Licklider and the Revolution That Made Computing Personal", often recommended om HN, was amazing. It has <i>so much</i> of the history of how personal computers came to be, and so much that was new to me.</p></div></td></tr></tbody></table></td></tr><tr id="46392052"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392052" href="https://news.ycombinator.com/vote?id=46392052&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I read The Buddha: Biography of a Myth, by Donald S. Lopez after hearing him on Conversations With Tyler. That's probably my top non-fiction book this year. Key takeaway was that the history of Buddhism is incredibly deep. Two highlights: First, the Buddha said that minor rules could be disregarded after his passing, but the person that was informed of this forgot to ask for clarification of what rules were minor, so there's debate over which rules must be followed. Second, the Buddha left us because nobody asked him to stay. This second point makes me reflect on the importance of reminding people that they are valued.</p><p>I also read The Red Book, Reader's Edition, by Carl Jung. I'm still processing that one. The artwork in the book is breathtaking and I strongly suggest looking it up even if you only look at the art. Narratively, it feels a bit like rambling at times. I'd previously read Archetypes and the Collective Unconscious, and Aion, and felt like those had a bit more intelligible substance. The first few chapters of Aion are excellent, but then Jung just goes on for like a dozen chapters about fish symbolism which completely lost me.</p><p>I also read a few other books on occult and esoteric topics, but my thoughts on those books are more complex than what I'm willing to type out on mobile. Key takeaway from a book on Wiccan Witchcraft was that they also believe in a system of reincarnation. I'm interested in reading through some of the core texts of Chinese Mythology at some point, but there aren't any good audiobook recordings for some of them.</p><p>I'm sad to say that I made very little progress in getting through proper college level textbooks, but I'm working through Molecular Biology of the Cell.</p></div></td></tr></tbody></table></td></tr><tr id="46396803"><td></td></tr><tr id="46396822"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396822" href="https://news.ycombinator.com/vote?id=46396822&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Fiction: some more novels in Steven Erikson &amp; Ian C Esslemont's Malazan Empire universe. These two produce some of the best fantasy I've ever read, and I've read a fuckton.</p><p>Non-fiction: A System for Writing by Bob Doto was pretty good. Also gave Feel-Good Productivity by Ali Abdaal a chance, but found it to be uninspiring, self-aggrandising drivel.</p></div></td></tr></tbody></table></td></tr><tr id="46391881"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391881" href="https://news.ycombinator.com/vote?id=46391881&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Humble Bundle has spoiled me and my ebook library has grown by around a 100 books this year...</p><p>Tech book recommendations: 'Secure by Design', 'Designing Data-Intensive Applications', 'Building Secure and Reliable Systems' and 'Fundamentals of Software Architecture'.</p><p>For scifi: 'Murderbot Diaries' and 'The Expanse' - both are just great entertainment</p></div></td></tr></tbody></table></td></tr><tr id="46394715"><td></td></tr><tr id="46391848"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391848" href="https://news.ycombinator.com/vote?id=46391848&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Not enough. Going to try to rein in some sustained attention in the new year.</p><p>- Piranesi by Susanna Clarke</p><p>- Playground by Richard Powers</p><p>- Designing Data Intensive Applications by Martin Kleppman</p><p>I'm curious how much AI-generated stuff I read this year... likely at least a book's worth, but it would be more like one of those books with 365+ random deep dives into stuff that's not really relevant to my life.</p></div></td></tr></tbody></table></td></tr><tr id="46391857"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391857" href="https://news.ycombinator.com/vote?id=46391857&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The most interesting books I read this year were:</p><p>Acting class - I found this book surprisingly compelling. It made me reflect on my own search for connection and identity, and how easily it is to be misled and manipulated when you've got no one close.</p><p>Earthlings - The book's plot gets really horrific (don't let the cover fool you). However, it did make me think about social norms and taboos a little differently.</p><p>1984 - It was my first time reading the book, and man, looking around and seeing bits and pieces of the surveillance mentioned in the book in real life is kind of terrifying...</p><p>Grapes of Wrath - It's definitely the most heart-wrenching book I've ever read. Watching the Joad family get absolutely devastated by the monster that is unchecked capitalism is so sad :(</p><p>Skunk works - Really good book on the development of Lockheed's stealth planes. However, I did wish I got more technical details.</p><p>I would love to see some more book recommendations :)</p></div></td></tr></tbody></table></td></tr><tr id="46396410"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396410" href="https://news.ycombinator.com/vote?id=46396410&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>my most interesting reading this year has been Stafford Beer (Brain Of The Firm, Heart Of The Enterprise). fascinating person and books</p><p>I‚Äôve otherwise been largely re-reading books I haven‚Äôt read in a decade or so</p></div></td></tr></tbody></table></td></tr><tr id="46396157"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396157" href="https://news.ycombinator.com/vote?id=46396157&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I read "Pyramid Principle, The: Logic in Writing and Thinking" by Barbara Minto. Highly recommend it.</p></div></td></tr></tbody></table></td></tr><tr id="46393242"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46393242" href="https://news.ycombinator.com/vote?id=46393242&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I really enjoyed The Technological Republic by Alexander C. Karp and Nicholas W. Zamiska. It‚Äôs sharp, opinionated, and unusually concrete about how state capacity, technology, and institutional competence intersect in practice. Even if you don‚Äôt agree with all of it, it‚Äôs a book that forces clearer thinking about power, technology, and governance.</p></div></td></tr></tbody></table></td></tr><tr id="46392003"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392003" href="https://news.ycombinator.com/vote?id=46392003&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I reread ‚ÄúThe Screwtape Letters‚Äù by CS Lewis for the first time since high school and appreciated it even more. Although it‚Äôs written from a Christian point of view, the principles are applicable to any moral framework.</p></div></td></tr></tbody></table></td></tr><tr id="46392020"><td></td></tr><tr id="46396518"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46396518" href="https://news.ycombinator.com/vote?id=46396518&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I‚Äôm a Christian as well and spent a day in Oxford earlier this year. After spending some time at Magdalen College, I bought every book I could by C.S. Lewis and just finished Letters to Malcolm (on prayer) today.</p><p>His refreshingly honest take is very relatable, humorous and encouraging.</p><p>I can highly recommend it if you‚Äôre interested in prayer life (and how to use powerful formulations in letters)</p></div></td></tr></tbody></table></td></tr><tr id="46392784"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392784" href="https://news.ycombinator.com/vote?id=46392784&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>A few years ago I promised myself to read the top of "must reads" from world literature. Many of them were literally unreadable (hello Moby Dick).
But some of them are true gems, must-reads indeed.
I just finished "The Grapes of Wrath" and holy cow, this is an impressive piece of literature. And unfortunately, more relevant than ever.
Why not give science fiction a break and try this classic instead.</p></div></td></tr></tbody></table></td></tr><tr id="46396105"><td></td></tr><tr id="46391723"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391723" href="https://news.ycombinator.com/vote?id=46391723&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Frankenstein. Superb science fiction, very readable even though written 200 years ago. And Wuthering Heights, which strangely like Frankenstein, has a complex narrative structure and an unhinged, obsessive central character</p></div></td></tr></tbody></table></td></tr><tr id="46396217"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396217" href="https://news.ycombinator.com/vote?id=46396217&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I read it this year too. I was surprised by the amount of heartfelt soliloquising the monster did, he was much more compelling than I expected. Victor of course was the real monster in the story, self obsessed, not taking responsibility for his actions, I found myself actively rooting against him.</p></div></td></tr></tbody></table></td></tr><tr id="46396204"><td></td></tr><tr id="46391818"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391818" href="https://news.ycombinator.com/vote?id=46391818&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The History of Medieval Europe by Maurice Keen</p><p>Reality is Not What it Seems by Carlo Rovelli</p><p>The Brain: The Story of You by David Eagleman</p><p>I had a crack at reading the first Game of Thrones novel (I think it's just called A Game of Thrones) but my brain seems to be in non-fiction mode at the moment. I think I'm drawn to a kind of sweet spot halfway between "related to my everyday experience" and "removed from my everyday experience" - not sure I could read about programming or business at the moment, though I also haven't tried.</p></div></td></tr></tbody></table></td></tr><tr id="46392469"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392469" href="https://news.ycombinator.com/vote?id=46392469&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I'm on my fourth George Eliot novel this year, Adam Bede, which was her first published novel. I started with Middlemarch and proceeded to read Silas Mariner, Romola, and Daniel Deronda. The 1985 film adaptation of Silas Marner is very good and faithful to the novel. The 1970 Daniel Deronda film is similarly faithful and well-acted but the 2002 version is neither.</p></div></td></tr></tbody></table></td></tr><tr id="46392391"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392391" href="https://news.ycombinator.com/vote?id=46392391&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I stumbled upon some great reddit posts this year with reading suggestions, and compiled my own "humanity is fucked" themed reading list, which included:</p><p>* Mercy of Gods by James S.A. Corey</p><p>* The Light Pirate by Lily Brooks-Dalton</p><p>* Oryx and Crake by Margaret Atwood</p><p>* Dawn by Octavia Butler</p><p>I then diverged from this list (I have more) to re-read (though it's not such a great divergence):</p><p>* If This Is a Man / The Truce by Primo Levi</p><p>Other books I enjoyed reading this year in no particular order:</p><p>* Tau Zero by Poul Anderson</p><p>* Machine Vendetta by Alastair Reynolds</p><p>* Elysium Fire by Alastair Reynolds</p><p>* Aurora Rising by Alastair Reynolds</p><p>* Shadow of the Silk Road by Colin Thubron (loved this)</p><p>* The Lord of the Rings (the god knows how many times re-read)</p><p>* The Centauri Device by M. John Harrison</p><p>* Future's Edge by Gareth Powell</p><p>* Blueshift by Joshua Dalzelle</p><p>* The Heart of a Continent by Francis Younghusband (I didn't quite manage to finish it, but it was a fascinating read nonetheless)</p></div></td></tr></tbody></table></td></tr><tr id="46391987"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391987" href="https://news.ycombinator.com/vote?id=46391987&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>How to Think Like Socrates - I normally have a difficult time digesting philosophy in older translations or language, but this one was really nicely written and well communicated.</p><p>Water by Rumi (translated by Haleh Liza Gafori) - also unexpectedly good. She uses a modern style and it reads so beautifully. It gave me glimpse of the beauty of the Persian language.</p></div></td></tr></tbody></table></td></tr><tr id="46396741"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396741" href="https://news.ycombinator.com/vote?id=46396741&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p><i>A Gentleman in Moscow</i> by Amor Towles blew me away by the quality of the writing, the endearing characters and the charming setting. I‚Äôm glad I picked it up and I strongly recommend it to you.</p><p>I haven‚Äôt been reading much in the last couple of years and I credit this book for getting me back in the game.</p></div></td></tr></tbody></table></td></tr><tr id="46391762"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391762" href="https://news.ycombinator.com/vote?id=46391762&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Getting into reading again this year after a long break.</p><p>The most memorable read of this year was "The Count of Monte Cristo" (1846) by Alexander Dumas .</p><p>It's one of the greatest stories ever told. It's ~1250 pages but I sped through it in 3 weeks even if I'm a slow reader.</p><p>Highly recommended!</p><p>I also read The Stranger by Camus and the two top Orwells which lived up to the hype.</p></div></td></tr></tbody></table></td></tr><tr id="46391867"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46391867" href="https://news.ycombinator.com/vote?id=46391867&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>The Count of Monte Cristo was published in serial form. Daily from 1844 to 1846.</p><p>That explains a lot the format, which tended to try to retain the audience.</p><p>Also, the author wrote in advance of the daily publication, but the book was written "live", answering to public perception and response. This is a reason why the book is so "good": the author had the chance to adjust the story based on data from sales and feedback from readers.</p><p>Of course Dumas was a great writer too, but this live writing, data based is probably why the book resonates so well with audiences.</p><p>So, as a joke, if you read count of monte cristo in 3 weeks, you did the equivalent of bing reading it.</p><p>This happens with soap operas too. 10 years ago, they lasted 1 year. They had an initial structure, the story, the characters, but responded in "real-time" to audience feedback.</p><p>For those willing to read the book, give yourself some time. Try to read it over a course of some years. Read a little, come back to it.</p><p>There are several famous books written in the same form, like Crime and Punishment or The Three Musketeers.</p><p>Oh, and also authors got payed by installment, so that explains the lenght lol</p></div></td></tr></tbody></table></td></tr><tr id="46391983"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46391983" href="https://news.ycombinator.com/vote?id=46391983&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Loved the stranger, I read it for the first time this year too. I read plenty of sub culture (mostly modern; Irvine welsh etc) but the stranger was just so different than anything I‚Äôve ever read. Like the language is so olan yet it works so well, and then you have this great finish, it‚Äôs a weird masterpiece.</p></div></td></tr></tbody></table></td></tr><tr id="46391948"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391948" href="https://news.ycombinator.com/vote?id=46391948&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>How Big Things Get Done by Bent Flyvbjerg</p><p>Bhagvad Gita by Eknath Easwaran</p><p>Rendezvous with Rama by Arthur C. Clarke</p><p>How The World Really Works by Vaclav Smil</p><p>The Emperor of All Maladies by Siddhartha Mukherjee</p><p>The House in the Cerulean Sea by TJ Klune</p><p>Chaos by James Gleick</p><p>Wind and Truth (Stormlight Archive #5) by Brandon Sanderson</p><p>The Culture Code: The Secrets of Highly Successful Groups by Daniel Coyle</p><p>The Day of the Jackal by Frederick Forsyth</p></div></td></tr></tbody></table></td></tr><tr id="46391767"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391767" href="https://news.ycombinator.com/vote?id=46391767&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I got really into Hemingway‚Äôs work, reading all the best ones, but my favourite being ‚ÄòA moveable feast‚Äô his diary essentially released at the end of his life set when he was mid-twenties in 1920s Paris. Me being the same age, I was inspired enough to go there and retrace some of his steps.</p></div></td></tr></tbody></table></td></tr><tr id="46391909"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391909" href="https://news.ycombinator.com/vote?id=46391909&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I gave Marcus Aurelius‚Äô Meditations a go and gave up around half way. Maybe if I knew the historical context it would seem more profound?</p><p>I enjoyed Three Body Problem a lot more than I thought I would. That was probably the best book I read in 2025.</p></div></td></tr></tbody></table></td></tr><tr id="46392018"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46392018" href="https://news.ycombinator.com/vote?id=46392018&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I also read Meditations this year. Definitely not what I was expecting. It's not cohesive at all. My biggest takeaways were the inevitability of death and generally letting go of our sense of control.</p></div></td></tr></tbody></table></td></tr><tr id="46396863"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46396863" href="https://news.ycombinator.com/vote?id=46396863&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Expecting it to be "cohesive" seems like an odd thing, considering it's literally a bunch of musings &amp; meditations which were taken from a man's private journal.</p><p>I've found many of the individual musings to be quite interesting. In particular the ones that relate to perception (my own biggest pitfall).</p></div></td></tr></tbody></table></td></tr><tr id="46396586"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46396586" href="https://news.ycombinator.com/vote?id=46396586&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Did you read the rest of the 3 body problem books? Some of the best scifi i've read in a looong time for sure.</p></div></td></tr></tbody></table></td></tr><tr id="46391995"><td></td></tr><tr id="46392071"><td></td></tr><tr id="46391758"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391758" href="https://news.ycombinator.com/vote?id=46391758&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>One of my favourite reads from this past year was <i>Infinite Powers: How Calculus Reveals the Secrets of the Universe</i> by Steven Strogatz. It's a wonderful review of the history of calculus, including intuitive explanations of the basics.</p></div></td></tr></tbody></table></td></tr><tr id="46392050"><td></td></tr><tr id="46391971"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391971" href="https://news.ycombinator.com/vote?id=46391971&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Loved ‚ÄúThe Winds of War‚Äù and ‚ÄúWar and Remembrance‚Äù by Herman Wouk - middlebrow from the 70s but no less good for that.</p><p>Re-read ‚ÄúThe Art of Not Being Governed‚Äù by James C Scott which is really mind-expanding stuff.</p></div></td></tr></tbody></table></td></tr><tr id="46393174"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46393174" href="https://news.ycombinator.com/vote?id=46393174&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Neither are on-brand for hacker news but:</p><p>[Best fiction] Stoner - John Williams
[Best non-fiction] Say Nothing - Patrick Radden Keefe</p></div></td></tr></tbody></table></td></tr><tr id="46391974"><td></td></tr><tr id="46392035"><td></td></tr><tr id="46392058"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392058" href="https://news.ycombinator.com/vote?id=46392058&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Not a huge book reader, but this year two impressed me:</p><p>- Blitzed: Drugs in the Third Reich by Norman Ohler</p><p>- The Elephant in the Brain by Kevin Simler and Robin Hanson</p></div></td></tr></tbody></table></td></tr><tr id="46391710"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391710" href="https://news.ycombinator.com/vote?id=46391710&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Lots of news and articles, but also "The Craft", a history of Freemason's by John Dickie, was one of the more interesting books.</p></div></td></tr></tbody></table></td></tr><tr id="46391727"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391727" href="https://news.ycombinator.com/vote?id=46391727&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>- Emperor of Rome by Mary Beard, very entertaining.</p><p>- Lolita, it's mostly what you've read about it.</p><p>- a few short stories by Heinrich von Kleist.</p></div></td></tr></tbody></table></td></tr><tr id="46396330"><td></td></tr><tr id="46391843"><td></td></tr><tr id="46392089"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392089" href="https://news.ycombinator.com/vote?id=46392089&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I stopped reading newspapers long back (early 2010s). During the Pandemic, I started a newspaper subscription (very common in India, delivered to the home) so I can use it to segregate wet waste properly. I started reading bits and pieces: horrors/misfortunes sell; news is stale, etc. Of late, I decided to look at it from a different angle, bringing back my childhood nostalgia, when I devoured every piece of reading material I could find. Now, I pick the ones I want to read, marking them as a reminder of continuity, a small bridge to a past life. I‚Äôm going to continue this slow reading with Newspapers. Wrote an article about my feelings, scheduled to be published on my personal blog in 2026-JAN.</p><p>For books, this year has been the year with the fewest books read.[1] I ended up reading the past: John Keats‚Äôs Poems, Marcus Aurelius, The Great Gatsby, Odyssey, and Iliad by Homer.</p><p>As a habit and a tribute to something I liked in the past, I read Dan Brown‚Äôs latest, ‚ÄúThe Secret of Secrets.‚Äù I also started re-reading some of Sidney Sheldon‚Äôs books, but, as of this day, I could no longer summon the enthusiasm to continue beyond Master of the Game and The Sands of Time.</p><p>I also re-read the fantastic book, ‚ÄúFlatland: A Romance of Many Dimensions‚Äù[2] by Edwin Abbott Abbott.</p><p>1. <a href="https://brajeshwar.com/2025/books/" rel="nofollow">https://brajeshwar.com/2025/books/</a></p><p>2. <a href="https://en.wikipedia.org/wiki/Flatland" rel="nofollow">https://en.wikipedia.org/wiki/Flatland</a></p></div></td></tr></tbody></table></td></tr><tr id="46392172"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392172" href="https://news.ycombinator.com/vote?id=46392172&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I read Murder Must Advertise, by Dorothy L Sayers. Quote:</p><p>All over London the lights flickered in and out, calling on the public to save its body and purse: SOPO SAVES SCRUBBING‚ÄîNUTRAX FOR NERVES‚ÄîCRUNCHLETS ARE CRISPER‚ÄîEAT PIPER PARRITCH‚ÄîDRINK POMPAYNE‚ÄîONE WHOOSH AND IT'S CLEAN‚ÄîOH, BOY! IT'S TOMBOY TOFFEE‚ÄîNOURISH NERVES WITH NUTRAX‚ÄîFARLEY'S FOOTWEAR TAKES YOU FURTHER‚ÄîIT ISN'T DEAR, IT'S DARLING‚ÄîDARLING'S FOR HOUSEHOLD APPLIANCES‚ÄîMAKE ALL SAFE WITH SANFECT‚ÄîWHIFFLETS FASCINATE. The presses, thundering and growling, ground out the same appeals by the million: ASK YOUR GROCER‚ÄîASK YOUR DOCTOR‚ÄîASK THE MAN WHO'S TRIED IT‚ÄîMOTHERS! GIVE IT TO YOUR CHILDREN‚ÄîHOUSEWIVES! SAVE MONEY‚ÄîHUSBANDS! INSURE YOUR LIVES‚ÄîWOMEN! DO YOU REALIZE?‚ÄîDON'T SAY SOAP, SAY SOPO! Whatever you're doing, stop it and do something else! Whatever you're buying, pause and buy something different! Be hectored into health and prosperity! Never let up! Never go to sleep! Never be satisfied. If once you are satisfied, all our wheels will run down. Keep going‚Äîand if you can't, Try Nutrax for Nerves!</p><p>Intriguingly familiar cynicism, vintage 1933.</p></div></td></tr></tbody></table></td></tr><tr id="46392160"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46392160" href="https://news.ycombinator.com/vote?id=46392160&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Technically last year, but less than 365 days ago:</p><p>* The Mom Test</p><p>* The SAAS Playbook</p><p>Actually in this year, the ones I remember the most:</p><p>* Start Small, Stay Small</p><p>* From Yao To Mao (more a series of lectures on chinese history)</p><p>The most recent one I haven't finished yet but was surprised I liked:</p><p>* Software Engeineering at Google</p><p>Many more things described ring true or feel desireable, and I recognize too many of the anti-patterns from companies I worked for. Although, I also recognized the good things people were doing and started to appreciate them more.</p></div></td></tr></tbody></table></td></tr><tr id="46392333"><td></td></tr><tr id="46393946"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46393946" href="https://news.ycombinator.com/vote?id=46393946&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I really enjoyed it and it helped me spot some unhelpful questions even outside startups!</p></div></td></tr></tbody></table></td></tr><tr id="46391750"><td></td></tr><tr id="46391813"><td></td></tr><tr id="46391858"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391858" href="https://news.ycombinator.com/vote?id=46391858&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I read a decent amount of books but the ones that stood out are:</p><p>- Anatomy of the State (Murray N. Rothbard)</p><p>- Diaspora (Greg Egan)</p><p>- The Freeze-Frame Revolution (Peter Watts)</p></div></td></tr></tbody></table></td></tr><tr id="46391955"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391955" href="https://news.ycombinator.com/vote?id=46391955&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>Early in the year I picked up "Dark Wire" by Joseph Cox. It was a fascinating dive into the world of "secure phones", particularly a company called Anom.</p><p>I also read:</p><p>"Digital Fortress" - Dan Brown (not strictly technically plausible but the suspense kept me hooked)
"Never Enough" - Andrew Wilkinson (meh)</p><p>Currently working on:
"The Technological Republic" - Andrew Karp
"Designing Data-Intensive Applications" - Martin Kleppmann</p><p>I had a tendency of a lot of false starts on books this year. I picked up several recent LLM/AI books and would make it like a chapter before realizing it was mostly just AI generated slop and gave up.</p></div></td></tr></tbody></table></td></tr><tr id="46391806"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46391806" href="https://news.ycombinator.com/vote?id=46391806&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>My favourite by far was Adam Becker's More Everything Forever.</p><p>Special mention also goes to Taming Silicon Valley by Gary Marcus.</p></div></td></tr></tbody></table></td></tr><tr id="46391759"><td></td></tr><tr id="46391807"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46391807" href="https://news.ycombinator.com/vote?id=46391807&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>For those interested in the subject (and who can also read French) I also heartily recommend the most recent edition of Augustin Thierry's <i>R√©cits des temps m√©rovingiens</i> [1]. Of course that it has most probably long been surpassed when it comes to historic accuracy, after all it was written almost 200 years ago, but it is very interesting nonetheless for being one of the first books that really put the focus on the Merovingians from a historical perspective that was "scientific", for lack of a better word.</p><p>[1] <a href="https://www.fnac.com/a21142694/Thierry-Augustin-Recits-des-temps-merovingiens-Ecrits-sur-l-Histoire" rel="nofollow">https://www.fnac.com/a21142694/Thierry-Augustin-Recits-des-t...</a></p></div></td></tr></tbody></table></td></tr><tr id="46391927"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46391927" href="https://news.ycombinator.com/vote?id=46391927&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>if you do read french, proust‚Äôs ‚Äúin search of lost time‚Äù (vol 1) is a lot more accessible and enjoyable than my high school teachers made it sound years and years ago. it even contains a depiction of what a learned engineer should be like.</p></div></td></tr></tbody></table></td></tr><tr id="46396841"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46396841" href="https://news.ycombinator.com/vote?id=46396841&amp;how=up&amp;goto=item%3Fid%3D46391572"></a></center></td><td><br>
<div><p>I started the year with "Right thing, right now", and I'm ending it with "wisdom takes work" (R.Holiday), but I'm happy to say that I'm now a bit "tired" of re-reading the same rehashing of other people's book, and I want to read the original ones. Which, actually, is the pont.</p><p>I wanted to read classics, and devoured "The portrait of Dorian Gray" (O.Wilde), where maybe 50% of all the "as O.Wilde said..." quotes seem to come from (uttered by a single, incredibly obnoxious character.)</p><p>I challenged myself to read "Les Miserables" (V.Hugo), and actually managed to get two tomes out of five down. Eminently quotable, heavily skippable - why on earth spend half a time on describing the ins and out of Waterloo, except to show off ? - and, surprisingly, at times, _funny_.</p><p>The bio of Pierre Mend√®s France (J.Lacouture) was very much topical, given the mess in Franch politics. We had more PMs in one year than in a few chapters of the book. It's very weird to read that, at some point, some politicians were "liked" by the people - but lost power anyway.</p><p>A small Edouard Phillipe book called "Men who read" almost made me like the guy - his next book is more serious and expected. It pains me to think that our next election is going to be about "well read people who disappointed everyone" vs "popular jocks with no education who will end up disappointing everyone".</p><p>"Abundance" (E.Klein / D.Thompson) is an attempt from "well read people" to at least try and understand why everyone is disappointed and prefer the jocks. I don't think they included any solution in their book, though - maybe they save it for the sequel, or for E.Klein's presidential bid.</p><p>I want to read all Stripe press - if only, because the covers rock, and they're optimistic. Started with "Poor Charlie's Almanach" (C.Munger), which a disappointing rehash of the same funny speech seven times. (Tldr : be multidisciplinary, study cognitive biases, don't trade). In the middle of "The Origins of Efficiency " (Potter)</p><p>"The Wave" (Souleymane) was not optimistic. And not practical at all - sure, AI enabled drones carrying bioweapons will suck. "The Age of predators" (G. Da Empoli) reminds us that the AI enabled bioweapons carrying drones will come from an illiberal state enabled by billionaires from Silicon Valley, and Russian trolls. I wish someone told me where to go to avoid being targeted too early.</p><p>"Everything is tuberculosis" (J. Greene) reminded me of a time when scientists were trying to solve problems as opposed to creating brand new ones - but at least the next generations won't die of boredom.</p><p>"We, programmers" is a rehash of Uncle Bob's pre talks "history of programming". I loved the long and detailed parts about G.Hopper. He ends with a (failed) attempt to convince that programmers will still be needed in the age of AI.</p><p>Steve Yegge's "Vibe coding" goes full "resistance is futile" about programming with agents, and, interestingly, ends up talking more about TDD than Uncle Bob - but the words "electricity consumption" and "climate impact" are not utured, because, why spoil the fun.</p><p>"The Common LISP cookbook" tried to explain me the difference between ASDF, quicklisp and whatnot - 2025 was the closest year I ever go to actually writing something in LISP instead of reading books about it.</p><p>And also, "The baby is a mammal" (M.Odent) and "Becoming a dad for dummies", because this year was probably the last one we're I'll get so much time to read :)</p></div></td></tr></tbody></table></td></tr></tbody></table></td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Package managers keep using Git as a database, it never works out (557 pts)]]></title>
            <link>https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html</link>
            <guid>46391514</guid>
            <pubDate>Fri, 26 Dec 2025 12:46:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html">https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html</a>, See on <a href="https://news.ycombinator.com/item?id=46391514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Using git as a database is a seductive idea. You get version history for free. Pull requests give you a review workflow. It‚Äôs distributed by design. GitHub will host it for free. Everyone already knows how to use it.</p>

<p>Package managers keep falling for this. And it keeps not working out.</p>

<h2 id="cargo">Cargo</h2>

<p>The crates.io index started as a git repository. Every Cargo client cloned it. This worked fine when the registry was small, but the index kept growing. Users would see progress bars like ‚ÄúResolving deltas: 74.01%, (64415/95919)‚Äù hanging for ages, the visible symptom of Cargo‚Äôs libgit2 library grinding through <a href="https://github.com/rust-lang/cargo/issues/9069">delta resolution</a> on a repository with thousands of historic commits.</p>

<p>The problem was worst in CI. Stateless environments would download the full index, use a tiny fraction of it, and throw it away. Every build, every time.</p>

<p><a href="https://rust-lang.github.io/rfcs/2789-sparse-index.html">RFC 2789</a> introduced a sparse HTTP protocol. Instead of cloning the whole index, Cargo now fetches files directly over HTTPS, downloading only the metadata for dependencies your project actually uses. (This is the ‚Äú<a href="https://nesbitt.io/2025/12/05/package-manager-tradeoffs.html">full index replication vs on-demand queries</a>‚Äù tradeoff in action.) By April 2025, 99% of crates.io requests came from Cargo versions where sparse is the default. The git index still exists, still growing by thousands of commits per day, but most users never touch it.</p>

<h2 id="homebrew">Homebrew</h2>

<p><a href="https://github.com/Homebrew/brew/pull/9383">GitHub explicitly asked Homebrew to stop using shallow clones.</a> Updating them was <a href="https://brew.sh/2023/02/16/homebrew-4.0.0/">‚Äúan extremely expensive operation‚Äù</a> due to the tree layout and traffic of homebrew-core and homebrew-cask.</p>

<p>Users were downloading 331MB just to unshallow homebrew-core. The .git folder approached 1GB on some machines. Every <code>brew update</code> meant waiting for git to grind through delta resolution.</p>

<p>Homebrew 4.0.0 in February 2023 switched to JSON downloads for tap updates. The reasoning was blunt: ‚Äúthey are expensive to git fetch and git clone and GitHub would rather we didn‚Äôt do that‚Ä¶ they are slow to git fetch and git clone and this provides a bad experience to end users.‚Äù</p>

<p>Auto-updates now run every 24 hours instead of every 5 minutes, and they‚Äôre much faster because there‚Äôs no git fetch involved.</p>

<h2 id="cocoapods">CocoaPods</h2>

<p>CocoaPods is the package manager for iOS and macOS development. It hit the limits hard. The Specs repo grew to hundreds of thousands of podspecs across a deeply nested directory structure. Cloning took minutes. Updating took minutes. CI time vanished into git operations.</p>

<p>GitHub imposed CPU rate limits. The culprit was shallow clones, which force GitHub‚Äôs servers to compute which objects the client already has. The team tried various band-aids: stopping auto-fetch on <code>pod install</code>, converting shallow clones to full clones, <a href="https://blog.cocoapods.org/Sharding/">sharding the repository</a>.</p>

<p>The CocoaPods blog captured it well: <a href="https://blog.cocoapods.org/Master-Spec-Repo-Rate-Limiting-Post-Mortem/">‚ÄúGit was invented at a time when ‚Äòslow network‚Äô and ‚Äòno backups‚Äô were legitimate design concerns. Running endless builds as part of continuous integration wasn‚Äôt commonplace.‚Äù</a></p>

<p>CocoaPods 1.8 <a href="https://blog.cocoapods.org/CocoaPods-1.8.0-beta/">gave up on git entirely</a> for most users. A CDN became the default, serving podspec files directly over HTTP. The migration saved users about a gigabyte of disk space and made <code>pod install</code> nearly instant for new setups.</p>

<h2 id="nixpkgs">Nixpkgs</h2>

<p>Nixpkgs is currently stress-testing GitHub‚Äôs infrastructure. In November 2025, GitHub contacted the NixOS team about <a href="https://discourse.nixos.org/t/nixpkgs-core-team-update-2025-11-30-github-scaling-issues/72709">periodic maintenance jobs failing</a> and causing ‚Äúissues achieving consensus between replicas.‚Äù If unresolved, the repository could have become read-only.</p>

<p>The repository totals 83GB with half a million tree objects and 20,000 forks. A local clone is only 2.5GB ‚Äî the rest is GitHub‚Äôs fork network storing every pull request branch and merge commit. The CI queries mergeability daily, creating new merge commits each time.</p>

<p>Unlike CocoaPods, Nixpkgs can‚Äôt easily move to a CDN. The Nix expressions <em>are</em> the package definitions, not metadata pointing elsewhere. Binary caches already serve built packages over HTTP, but nixpkgs itself remains a git repository ‚Äî and it‚Äôs still growing.</p>

<h2 id="vcpkg">vcpkg</h2>

<p>vcpkg is Microsoft‚Äôs C++ package manager. It uses git tree hashes to version its ports, with the curated registry at <a href="https://github.com/Microsoft/vcpkg">github.com/Microsoft/vcpkg</a> containing over 2,000 libraries.</p>

<p>The problem is that vcpkg needs to retrieve specific versions of ports by their git tree hash. When you specify a <code>builtin-baseline</code> in your vcpkg.json (functioning like a lockfile for reproducible builds), vcpkg looks up historical commits to find the exact port versions you need. This only works if you have the full commit history.</p>

<p>Shallow clones break everything. GitHub Actions uses shallow clones by default. DevContainers <a href="https://github.com/devcontainers/images/issues/398">shallow-clone vcpkg</a> to save space. CI systems optimize for fast checkouts. All of these result in the same error: ‚Äúvcpkg was cloned as a shallow repository‚Ä¶ Try again with a full vcpkg clone.‚Äù</p>

<p>The workarounds are ugly. One <a href="https://github.com/devcontainers/images/issues/398">proposed solution</a> involves parsing vcpkg.json to extract the baseline hash, deriving the commit date, then fetching with <code>--shallow-since=&lt;date&gt;</code>. Another suggests including twelve months of history, hoping projects upgrade before their baseline falls off the cliff. For GitHub Actions, you need <code>fetch-depth: 0</code> in your checkout step, <a href="https://github.com/microsoft/vcpkg/issues/25349">downloading the entire repository history</a> just to resolve dependencies.</p>

<p>A vcpkg team member <a href="https://github.com/microsoft/vcpkg/issues/25349">explained the fundamental constraint</a>: ‚ÄúPort versions don‚Äôt use commit hashes, we use the git tree hash of the port directory. As far as I know, there is no way to deduce the commit that added a specific tree hash.‚Äù An in-product fix is infeasible. The architecture baked in git deeply enough that there‚Äôs no escape hatch.</p>

<p>Unlike Cargo, Homebrew, and CocoaPods, vcpkg hasn‚Äôt announced plans to move away from git registries. Custom registries must still be git repositories. The documentation describes filesystem registries as an alternative, but these require local or mounted paths rather than HTTP access. There‚Äôs no CDN, no sparse protocol, no HTTP-based solution on the horizon.</p>

<h2 id="go-modules">Go modules</h2>

<p><a href="https://engineering.grab.com/go-module-proxy">Grab‚Äôs engineering team</a> went from 18 minutes for <code>go get</code> to 12 seconds after deploying a module proxy. That‚Äôs not a typo. Eighteen minutes down to twelve seconds.</p>

<p>The problem was that <code>go get</code> needed to fetch each dependency‚Äôs source code just to read its go.mod file and resolve transitive dependencies. Cloning entire repositories to get a single file.</p>

<p>Go had security concerns too. The original design wanted to remove version control tools entirely because <a href="https://arslan.io/2019/08/02/why-you-should-use-a-go-module-proxy/">‚Äúthese fragment the ecosystem: packages developed using Bazaar or Fossil, for example, are effectively unavailable to users who cannot or choose not to install these tools.‚Äù</a> Beyond fragmentation, the Go team worried about security bugs in version control systems becoming security bugs in <code>go get</code>. You‚Äôre not just importing code; you‚Äôre importing the attack surface of every VCS tool on the developer‚Äôs machine.</p>

<p>GOPROXY became the default in Go 1.13. The proxy serves source archives and go.mod files independently over HTTP. Go also introduced a <a href="https://nesbitt.io/2025/12/21/federated-package-management.html#gos-experiment-with-dns">checksum database (sumdb)</a> that records cryptographic hashes of module contents. This protects against force pushes silently changing tagged releases, and ensures modules remain available even if the original repository is deleted.</p>

<h2 id="beyond-package-managers">Beyond package managers</h2>

<p>The same pattern shows up wherever developers try to use git as a database.</p>

<p>Git-based wikis like Gollum (used by GitHub and GitLab) become <a href="https://github.com/gollum/gollum/issues/1940">‚Äúsomewhat too slow to be usable‚Äù</a> at scale. Browsing directory structure takes seconds per click. Loading pages takes longer. <a href="https://docs.gitlab.com/ee/development/wikis.html">GitLab plans to move away from Gollum entirely.</a></p>

<p>Git-based CMS platforms like Decap hit GitHub‚Äôs API rate limits. A Decap project on GitHub <a href="https://decapcms.org/blog/git-based-cms-definition-features-best-practices/">scales to about 10,000 entries</a> if you have a lot of collection relations. A new user with an empty cache makes a request per entry to populate it, burning through the 5,000 request limit quickly. If your site has lots of content or updates frequently, use a database instead.</p>

<p>Even GitOps tools that embrace git as a source of truth have to work around its limitations. ArgoCD‚Äôs repo server <a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/high_availability/">can run out of disk space</a> cloning repositories. A single commit invalidates the cache for all applications in that repo. Large monorepos need special scaling considerations.</p>

<h2 id="the-pattern">The pattern</h2>

<p>The hosting problems are symptoms. The underlying issue is that git inherits filesystem limitations, and filesystems make terrible databases.</p>

<p><strong>Directory limits.</strong> Directories with too many files become slow. CocoaPods had <a href="https://blog.cocoapods.org/Sharding/">16,000 pod directories</a> in a single Specs folder, requiring huge tree objects and expensive computation. Their fix was hash-based sharding: split directories by the first few characters of a hashed name, so no single directory has too many entries. Git itself does this internally with its objects folder, splitting into 256 subdirectories. You‚Äôre reinventing B-trees, badly.</p>

<p><strong>Case sensitivity.</strong> Git is case-sensitive, but macOS and Windows filesystems typically aren‚Äôt. <a href="https://learn.microsoft.com/en-us/azure/devops/repos/git/os-compatibility">Check out a repo containing both <code>File.txt</code> and <code>file.txt</code> on Windows</a>, and the second overwrites the first. <a href="https://learn.microsoft.com/en-us/azure/devops/repos/git/case-sensitivity">Azure DevOps</a> had to add server-side enforcement to block pushes with case-conflicting paths.</p>

<p><strong>Path length limits.</strong> Windows restricts paths to <a href="https://learn.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation">260 characters</a>, a constraint dating back to DOS. Git supports longer paths, but Git for Windows inherits the OS limitation. This is painful with deeply nested node_modules directories, where <code>git status</code> fails with ‚ÄúFilename too long‚Äù errors.</p>

<p><strong>Missing database features.</strong> Databases have CHECK constraints and UNIQUE constraints; git has nothing, so every package manager builds its own validation layer. Databases have locking; git doesn‚Äôt. Databases have indexes for queries like ‚Äúall packages depending on X‚Äù; with git you either traverse every file or build your own index. Databases have migrations for schema changes; git has ‚Äúrewrite history and force everyone to re-clone.‚Äù</p>

<p>The progression is predictable. Start with a flat directory of files. Hit filesystem limits. Implement sharding. Hit cross-platform issues. Build server-side enforcement. Build custom indexes. Eventually give up and use HTTP or an actual database. You‚Äôve built a worse version of what databases already provide, spread across git hooks, CI pipelines, and bespoke tooling.</p>

<p>None of this means git is bad. Git excels at what it was designed for: distributed collaboration on source code, with branching, merging, and offline work. The problem is using it for something else entirely. Package registries need fast point queries for metadata. Git gives you a full-document sync protocol when you need a key-value lookup.</p>

<p>If you‚Äôre building a package manager and git-as-index seems appealing, look at Cargo, Homebrew, CocoaPods, vcpkg, Go. They all had to build workarounds as they grew, causing pain for users and maintainers. The pull request workflow is nice. The version history is nice. You will hit the same walls they did.</p>

  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT conversations still lack timestamps after years of requests (216 pts)]]></title>
            <link>https://community.openai.com/t/timestamps-for-chats-in-chatgpt/440107?page=3</link>
            <guid>46391472</guid>
            <pubDate>Fri, 26 Dec 2025 12:39:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.openai.com/t/timestamps-for-chats-in-chatgpt/440107?page=3">https://community.openai.com/t/timestamps-for-chats-in-chatgpt/440107?page=3</a>, See on <a href="https://news.ycombinator.com/item?id=46391472">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Timestamps for chats in ChatGPT">
      
      <meta itemprop="datePublished" content="2023-10-19T00:50:09Z">
        <meta itemprop="articleSection" content="Feature requests">
      <meta itemprop="keywords" content="">
      

          <meta itemprop="text" content="Can we get timestamps for chats generated in ChatGPT? I understand it currently categorizes chats into day, week, months etc. but can we get actual time-of-day stamps for each message? E.g 1:20pm, 5:00am, 3:34am, etc. MM&amp;hellip;">

          <div id="post_43" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I‚Äôve been working in a single chat for close 9-10 months now, with some separate chats opened once in a while. Now I want to write up a chronological overview of what I‚Äôve been up to and when these past 10 months and I fully expected ‚Äú<em>the timestamps in the ChatGPT chat</em>‚Äù to make that task trivial‚Ä¶ It‚Äôs madness that this information isn‚Äôt available.</p>

            


            
          </div>
          <div itemprop="comment" id="post_45" itemscope="" itemtype="http://schema.org/Comment">
              <p>I know this thread has been open for a while (going on a year and a half now), and this might be obvious to some experienced users ‚Äî but just in case, I wanted to share a workaround I‚Äôve been using until this feature is officially added.</p>
<p>In <strong>Settings &gt; Customize ChatGPT</strong>, under the field that asks <em>‚ÄúWhat traits should ChatGPT have?‚Äù</em>, I added:</p>
<blockquote>
<p>‚ÄúAfter every response, add the current timestamp.‚Äù</p>
</blockquote>
<p>Now each reply ends with a timestamp, which makes it much easier to track what was said and when, especially in ongoing conversations. Not a perfect solution, but it‚Äôs been working pretty well for me.</p>
            </div>
          <div id="post_46" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.openai.com/u/DGGLMT"><span itemprop="name">DGGLMT</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-06-01T02:06:32Z">
                    June 1, 2025,  2:06am
                  </time>
                  <meta itemprop="dateModified" content="2025-06-01T02:06:32Z">
              <span itemprop="position">46</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Well I see this is still going on. Clearly this feature is in demand, I can only assume there is a technical reason they don‚Äôt already have it, because it seems like a given at this point‚Ä¶</p>
<p>But now that they‚Äôre trying to push GPT as MORE than just an AI, but a journal/life assistant/coach etc etc, and chat histories are adding up‚Ä¶I mean I revisited an old chat to ask a follow up question about a life event, and it didn‚Äôt realize 3 months had gone by, so was giving me advice like it had just happened.</p>
<p>The‚Ä¶time‚Ä¶has come OpenAI. Chop, chop</p>
            </div>

            


            
          </div>
          <div itemprop="comment" id="post_47" itemscope="" itemtype="http://schema.org/Comment">
              <p>Yes, it‚Äôs totally possible! Every <code>&lt;div&gt;</code> that has a <code>"data-message-id"</code> contains an internal object with some message information, including the timestamp. I created this simple script that you can copy and paste directly into the Chrome DevTools console.</p>
<p>Just right-click anywhere on the page and choose <strong>‚ÄúInspect‚Äù</strong>, then go to the <strong>‚ÄúConsole‚Äù</strong> tab and paste this code:</p>
<pre><code>document.querySelectorAll('div[data-message-id]').forEach(div =&gt; {
  const reactKey = Object.keys(div).find(k =&gt; k.startsWith('__reactFiber$'));
  if (!reactKey) return;

  const fiber = div[reactKey];
  const messages = fiber?.return?.memoizedProps?.messages;
  const timestamp = messages?.[0]?.create_time;
  if (!timestamp) return;

  const date = new Date(timestamp * 1000);
  const format = n =&gt; n.toString().padStart(2, '0');
  const formatted = `${format(date.getDate())}/${format(date.getMonth() + 1)}/${date.getFullYear()} - ${format(date.getHours())}:${format(date.getMinutes())}:${format(date.getSeconds())}`;

  const span = document.createElement('span');
  span.textContent = formatted;
  div.insertBefore(span, div.firstChild);
});
</code></pre>
<p>If you get an error message saying you‚Äôre not allowed to paste code in the console, just type <code>"allow pasting"</code> and press Enter ‚Äî then paste the script and press Enter again.</p>
<p>This is a very simple code I just made to view the timestamp of some chat messages, but it was enough for my needs.</p>
            </div>
          <div itemprop="comment" id="post_48" itemscope="" itemtype="http://schema.org/Comment">
              <p>I created a chrome extension for the timestamp. Chrome store approval is still pending but you can just download the repo and load the extension in developer mode to use it.</p>
<div><a href="https://us1.discourse-cdn.com/openai1/original/4X/d/c/0/dc0edf1537908e252d5002f185988ce74013e6c6.jpeg" data-download-href="/uploads/short-url/voIU8dybRa2K1DCA6Ad3eygebhI.jpeg?dl=1" title="image" rel="noopener nofollow ugc"><img src="https://us1.discourse-cdn.com/openai1/optimized/4X/d/c/0/dc0edf1537908e252d5002f185988ce74013e6c6_2_690x466.jpeg" alt="image" data-base62-sha1="voIU8dybRa2K1DCA6Ad3eygebhI" width="690" height="466" srcset="https://us1.discourse-cdn.com/openai1/optimized/4X/d/c/0/dc0edf1537908e252d5002f185988ce74013e6c6_2_690x466.jpeg, https://us1.discourse-cdn.com/openai1/optimized/4X/d/c/0/dc0edf1537908e252d5002f185988ce74013e6c6_2_1035x699.jpeg 1.5x, https://us1.discourse-cdn.com/openai1/optimized/4X/d/c/0/dc0edf1537908e252d5002f185988ce74013e6c6_2_1380x932.jpeg 2x" data-dominant-color="F7F8F8"></a></div>
<p>Thanks for the inspiration by <a href="https://community.openai.com/u/rafaelsgoncalvesbh2">@rafaelsgoncalvesbh2</a>.</p>
            </div>
          <div itemprop="comment" id="post_49" itemscope="" itemtype="http://schema.org/Comment">
              <p>That‚Äôs awesome! I just installed the extension and it works perfectly.</p>
<p>For anyone who wants to use Hangzhi‚Äôs timestamp extension before it‚Äôs officially approved on the Chrome Web Store, here‚Äôs how you can install it manually:</p>
<ol>
<li>
<p>Download the ZIP file from the GitHub repo:</p>
<ul>
<li>GitHub page: github[.]com/Hangzhi/chatgpt-timestamp-extension</li>
<li>Direct download link: github[.]com/Hangzhi/chatgpt-timestamp-extension/raw/main/chatgpt-timestamp-extension.zip</li>
</ul>
<p>(Note: Since direct links aren‚Äôt allowed here, just replace <code>[.]</code> with <code>.</code> and paste the link into your browser.)</p>
</li>
<li>
<p>After downloading, right-click the ZIP file and select ‚ÄúExtract to chatgpt-timestamp-extension/‚Äù. This will create a folder named <code>chatgpt-timestamp-extension</code>.</p>
</li>
<li>
<p>Open <code>chrome://extensions/</code> in your browser.</p>
</li>
<li>
<p>In the top-right corner, enable ‚ÄúDeveloper mode‚Äù.</p>
</li>
<li>
<p>After enabling it, new options will appear. Click ‚ÄúLoad unpacked‚Äù, then select the folder you just extracted (<code>chatgpt-timestamp-extension</code>).</p>
</li>
<li>
<p>That‚Äôs it! You should now see a new extension called ‚ÄúChatGPT Timestamp‚Äù in your Chrome extensions. Open ChatGPT, and you‚Äôll see timestamps above each message.</p>
</li>
</ol>
<p>Thanks again <a href="https://community.openai.com/u/hangzhi">@Hangzhi</a> for the great work and for turning the idea into a real Chrome extension!</p>
            </div>
          <div itemprop="comment" id="post_50" itemscope="" itemtype="http://schema.org/Comment">
              <p>Hi OpenAI Team,</p>
<p>I recently ran into a technical issue with my PC and discussed it with ChatGPT. A few days later, I needed to <strong>find out exactly when I posted a specific message</strong>, because that moment correlated with when the problem occurred. Unfortunately, there‚Äôs no way to see when individual messages were sent or received, which made it hard to trace the timing.</p>
<p>This would also benefit:</p>
<ul>
<li>Anyone using ChatGPT to track ongoing issues</li>
<li>Users referencing previous decisions or drafts</li>
<li>Those working across multiple sessions and needing historical context</li>
</ul>
<p>I‚Äôd love to see this added in a future update.</p>
<p>Best,<br>
Ralf</p>
            </div>
          <div id="post_51" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I just wanted to add my vote to adding individual-message timestamps in ChatGPT.  We all really appreciate the work you do and the amazing resource you have created.  This is a simple feature request that would really help a lot of people.  Thanks!</p>

            


            
          </div>
          <div id="post_52" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.openai.com/u/guido"><span itemprop="name">guido</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-12T14:42:02Z">
                    November 12, 2025,  2:42pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-12T14:42:02Z">
              <span itemprop="position">52</span>
              </span>
            </p>
            <p>+1 for timestamps. It‚Äôs important so we can keep a sense of time with each thread of conversation. thanks.</p>

            


            
          </div>
          <div id="post_53" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.openai.com/u/po24"><span itemprop="name">po24</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-21T21:03:01Z">
                    November 21, 2025,  9:03pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-21T21:03:01Z">
              <span itemprop="position">53</span>
              </span>
            </p>
            <p>It‚Äôs been 2 years (and 3 since release). The UI/UX team needs to get their act together.</p>

            


            
          </div>
          <div id="post_54" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.openai.com/u/stab"><span itemprop="name">stab</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-24T16:56:59Z">
                    November 24, 2025,  4:56pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-24T16:56:59Z">
              <span itemprop="position">54</span>
              </span>
            </p>
            <p>They really do need to. Timestamps and bookmarks on specific messages are highly needed</p>

            


            
          </div>
          <div id="post_55" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Actually : this may become a Compliance requirement in the future - to document (in business environment) when a certain user (company employee / senior officer) created certain query .</p>

            


            
          </div>
          <div id="post_56" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.openai.com/u/po24"><span itemprop="name">po24</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-02T23:15:28Z">
                    December 2, 2025, 11:15pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-02T23:15:28Z">
              <span itemprop="position">56</span>
              </span>
            </p>
            <div itemprop="text">
              <p>I don‚Äôt think Compliance requirement will make a difference because they already have the timestamps, but it‚Äôs just not shown to the user in a user-friendly manner. If you inspect the webpage, you‚Äôll find it. It‚Äôs already being tracked, so displaying it should be extremely easy for OpenAI devs.</p>
<p>This post, among many others, is a strong sign that OpenAI is currently not prioritizing user-feedback on existing products. Too focused on building new products.</p>
            </div>

            


            
          </div>
          <div itemprop="comment" id="post_57" itemscope="" itemtype="http://schema.org/Comment">
              <p>Yep! I too suggest adding optional timestamps to ChatGPT conversations.</p>
<p>For long-running or sensitive threads, having the exact time a message was sent improves clarity, emotional context, and continuity. It helps both the model and the user avoid misunderstandings about timing (like, night vs. day, time between replies, or multi-day situations).</p>
<p>This can also support users with health issues, legal timelines, documentation, or crisis patterns by allowing more accurate context.</p>
<p>A simple toggle to show or hide timestamps would make this feature useful without overwhelming the interface.</p>
            </div>
          <div id="post_58" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.openai.com/u/stab"><span itemprop="name">stab</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-22T00:11:10Z">
                    December 22, 2025, 12:11am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-22T00:11:10Z">
              <span itemprop="position">58</span>
              </span>
            </p>
            <p>I just wish we were treated like grown-ups, where we would have a bunch of toggles to activate/deactivate features that for other people might clutter the interface.</p>

            


            
          </div>
          <div id="post_59" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Yes, please, add opinion to make timestamps by ChatGPT, maybe some checkbox in options?</p>

            


            
          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm a laptop weirdo and that's why I like my new Framework 13 (261 pts)]]></title>
            <link>https://blog.matthewbrunelle.com/im-a-laptop-weirdo-and-thats-why-i-like-my-new-framework-13/</link>
            <guid>46391410</guid>
            <pubDate>Fri, 26 Dec 2025 12:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.matthewbrunelle.com/im-a-laptop-weirdo-and-thats-why-i-like-my-new-framework-13/">https://blog.matthewbrunelle.com/im-a-laptop-weirdo-and-thats-why-i-like-my-new-framework-13/</a>, See on <a href="https://news.ycombinator.com/item?id=46391410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<main>

        <article>

        

    <div>
        <p>This month I sold my 2021 M1 Max Macbook Pro and bought a Framework 13 DIY Edition laptop. After I got everything setup I sat down to write about the experience. Some ~4500 words later I realized I needed to break my thoughts into multiple posts.</p>
<p>See also:</p>
<ul>
<li><a href="https://blog.matthewbrunelle.com/framework-13-diy-edition-hardware-thoughts/">Framework 13 DIY Edition Hardware Thoughts</a></li>
<li><a href="https://blog.matthewbrunelle.com/setting-up-my-new-framework-laptop-13-diy-edition-with-nixos/">Setting up my new Framework Laptop 13 DIY Edition with NixOS</a></li>
</ul>

<p>My new Framework 13 laptop just arrived. After I finally set everything up I started writing a post about the experience. I thought I'd write a <em>little bit</em> about my previous laptops, but a lot of fond memories I had forgotten about came flooding back. The tinkerings and many openings of laptops past. If you will indulge me, I've been feeling nostalgic. This is for the other laptop weirdos out there that that feel the same.</p>
<h3 id="i-have-a-history-of-doing-terrible-acts-to-laptops">I have a history of doing terrible acts to laptops</h3>
<p><img src="https://blog.matthewbrunelle.com/content/images/2025/08/25654_1350884488762_5177004_n.jpg" alt="25654_1350884488762_5177004_n.jpg" loading="lazy"><br>
The only image I could find of my NC10 was this blurry, 2021 flip phone photo of me removing the windows sticker.</p>
<p>In 2008, I managed to get my hands on a Samsung NC10 Netbook in a fancy metallic blue color. [^ Back when netbooks where a thing circle 2007-2013] Prior to this I only had desktops. The specs were pretty humble (<a href="https://en.wikipedia.org/wiki/Samsung_NC10?ref=blog.matthewbrunelle.com">from wikipedia</a>):</p>
<ul>
<li>A single core 1.6 GHz Intel Atom N270</li>
<li>Integrated Intel GMA 950 graphics</li>
<li>1 GB DDR2 RAM</li>
<li>10.2 inch 1024x600 screen and a <em>VGA connector</em> of all things.</li>
<li>83-key keyboard rather than the usual 87 or 88 keys on a laptop.</li>
<li>A 160 GB HDD</li>
</ul>
<p>Something could be done about that though! You could <a href="https://replacethatpart.com/how-to-upgrade-memory-ram-of-the-samsung-nc10-a-complete-guide-2/?ref=blog.matthewbrunelle.com">upgrade</a> the RAM to a powerful 2GB. You could replace the slow HDD with an SSD. You could <a href="https://liliputing.com/touchscreen-kit-for-the-samsung-nc10-and-other-netbooks/?ref=blog.matthewbrunelle.com">add a touch screen</a>. You could <a href="https://www.atmasphere.net/archives/2009/01/15/the-samsung-nc10-hackintosh?ref=blog.matthewbrunelle.com">make a Hackintosh</a> out of it if you replaced the wifi card. If you wanted to, you could do those things and I was a weirdo, so I did!</p>
<p>I found a lot of fun in trying to get as much as I could out of that hardware. In fact I'd say the act of doing all that was far more enjoyable than actually using the laptop once the tinkering was done. After the novelty and slowness of a Hackintosh wore off I put Linux on the Netbook. I still sought the thrill of the hunt.</p>
<p>I installed a lite weight distro <a href="https://crunchbang.org/?ref=blog.matthewbrunelle.com">CrunchBang</a> [^ or just #!] and messed around. I read more about different minimalist distros and came across two others I could hop to: Arch and Gentoo. This feels like an inflection point in my life, I choose to try Arch since I wouldn't have to compile everything on a single core. [^ Who know what would have happened if I picked Gentoo. I might have a beard now.] The screen was small and I wanted to maximize its usefulness so I started trying tiling WMs. Why not <a href="https://xmonad.org/?ref=blog.matthewbrunelle.com">XMonad</a>?</p>
<p>It turns out the GMA950 was undervolted on the NC10. Someone made a shareware tool called the GMABooster that could restore the max clock rate. The original website <a href="http://www.gmabooster.com/home.htm?ref=blog.matthewbrunelle.com">http://www.gmabooster.com/home.htm</a> is long toast and not on wayback. This <a href="https://bbs.archlinux.org/viewtopic.php?id=81429&amp;ref=blog.matthewbrunelle.com">Arch forum thread</a> has details though:</p>
<blockquote>
<p>It allows a user, not a manufacturer to choose the desired GMA speed. It combines a sophisticated assembler-level technology and the user-friendly graphic user interface, offering You to near double the GMA core perfomance without even a need to restart a computer..</p>
</blockquote>
<p>The package was on AUR so I could squeeze out a little more performance. I could finally watch 480 YouTube videos instead of 360. At some point, long after I had stopped using the netbook, the AUR package became abandoned. I <a href="https://web.archive.org/web/20150802113711/https://aur.archlinux.org/packages/gmabooster/">adopted it as maintainer</a> and <a href="https://github.com/ciferkey/GMABooster_Linux?ref=blog.matthewbrunelle.com">mirrored</a> the binary in GitHub. This was the first time I ever was a package maintainer. [^ I am on a couple random packages in nixpkgs now.] Nowadays the package is memorialized in the the <a href="https://github.com/aur-archive/gmabooster?ref=blog.matthewbrunelle.com">AUR archive</a>.</p>
<p>I had a device that I could repeatedly break and remake. Did I do anything productive or meaningful with it? Absolutely not. Did I learn a lot in the process? I'd say so!</p>
<hr>
<h3 id="in-the-past-you-could-do-terrible-things-to-macbooks-too">In the past you could do terrible things to Macbooks too</h3>
<p>When I went to College I got a 2011 Macbook Pro. The kind that would overheat and desolder the GPU. [^ Some clever people have found hardware hacks to repair the problem <a href="https://www.jeffgeerling.com/blog/2017/fixing-2011-macbook-pro-booting-grey-screen-amd-radeon-video-glitch?ref=blog.matthewbrunelle.com">https://www.jeffgeerling.com/blog/2017/fixing-2011-macbook-pro-booting-grey-screen-amd-radeon-video-glitch</a>] Mine managed to last a long time and didn't need replacing until 2019. The RAM was not built-in yet on Macbooks. Apple said the model could only support up to 8GB total RAM, but you <a href="https://apple.stackexchange.com/a/259351?ref=blog.matthewbrunelle.com">could actually</a> get 16GB to work. Also, this was back when Macbooks had CD drives. I replaced the my drive with an <a href="https://eshop.macsales.com/item/Western%20Digital/DDMB5KT1.0/?ref=blog.matthewbrunelle.com">Other World Computing DIY Optical Drive to HDD Upgrade Kit</a>. [^ And you could put the drive into an "OWC SuperSlim" enclosure to turn it into a USB CD drive.] and installed SSDs in both slots. With two drives I was able to install rEFInd as a boot manager and triple boot:</p>
<ul>
<li>OSX as a stable install for my course work</li>
<li>Windows for games</li>
<li>Linux so I could break my install repeatedly</li>
</ul>
<p>I iterated on my Arch install so many times that I started to keep a checklist about my setup process to help me remember everything. Certain stylistic choices were set and still used to this day. [^ This is when I started using Inconsolata for a monospace font and Zenburn for a color scheme.] I couldn't change quite as many things about this laptop, but I still made an effort to change what I could.</p>
<hr>
<h3 id="as-laptops-grew-thinner-they-grew-more-boring">As laptops grew thinner they grew more boring</h3>
<p>When it came time for a new laptop I was not looking at Macbook Pros anymore. Apple had made changes, like the touch bar and removing magsafe, that felt like they were targeting a different audience. So instead I had been eyeing a ThinkPad.<br>
[^ It's almost cliche to buy one and install Linux.] The prices on the Lenovo store are mostly made up and constantly discounted. My housemate had access to a corpo portal for Lenovo that let me get one at a heavily reduced price. The cost of 3 year service coverage was also discounted so I got some figuring it could help to cover cost of parts if if something failed.</p>
<p>So I bought a Gen 7 X1 Carbon and... I just used it. No mods were possible on this laptop. When I had an SSD failure I asked Lenovo if they could mail me the drive so I could do the install. They said they had to send someone to confirm the issue. So a technician came out and replaced the drive.</p>
<hr>
<h3 id="the-gift-and-curse-of-a-free-macbook-pro">The gift and curse of a free Macbook Pro</h3>
<p>Finally in 2023 I was <a href="https://www.hubspot.com/company-news/a-message-from-hubspot-ceo-yamini-rangan?ref=blog.matthewbrunelle.com">laid off by HubSpot</a>. Part of severance was the following:</p>
<blockquote>
<p>Laptops &amp; WFH Set-Up: Impacted employees may keep their HubSpot laptops (it will be cleaned of any company data remotely), as well as any work from home gear like monitors and keyboards.</p>
</blockquote>
<p>Thus a pretty high spec 2021 M1 Max Macbook Pro fell into my lap. I gave my X1 Carbon to a friend to avoid creating yet more ewaste that sits in my closet.</p>
<p>The 2021 version was a bit of return to form: touch bar was gone, magsafe was back, etc. However even the <a href="https://www.ifixit.com/News/54122/macbook-pro-2021-teardown?utm_source=M1MBPTD&amp;utm_medium=Annotation&amp;utm_campaign=YouTube">iFixit review</a> said the "design represents a major move in the right direction" but still only rated the laptop a 4/10  for repairability. [^ The score was eventually updated to a 5/10 when Apple later released a service manual and access to parts.]</p>
<p>I felt some dissonance though. If I was looking to buy a laptop, I wouldn't have picked this one. macOS was getting less enjoyable to use with each update. Likewise the Linux Desktop experience was really coming into its own. [^ By 2023 essentially all my games were playable!] However I felt bad about buying a new laptop when I now had a perfectly good one. So I held onto it and once again, no mods were done or could be done with this laptop.</p>
<hr>
<h3 id="finally-buying-a-framework-13">Finally buying a Framework 13</h3>
<p>I had waited on getting a Framework laptop because I wanted to see them go through a couple iterations. I wanted to see if the promise of repairing, replacing and upgrading actually came true. From what I read it mostly has! [^ People with Framework 15 do seem to be waiting though.]</p>
<p>What changed the decision for me was the following:</p>
<ul>
<li>Lugging around a powerful 16 inch laptop was a drag. Having a laptop when traveling is nice if I need to hurriedly rebook something. Mobile sites and apps tend to restrict you in weird ways.</li>
<li>Despite being a couple years old, the laptop was still worth a lot. People probably want Macbooks for local LLM inference. So I felt pretty good a buyer will actually use the laptop.</li>
<li>The Framework release a refresh of the 13 with the new AMD chips.</li>
</ul>
<p>Then I had a friend get Laptop 13 and attest to liking it. That was the last push I needed to finally buy one. Now I can be a laptop weirdo again.</p>
<p>You can't change the RAM on laptops now.<br>
You can't change the SSD on laptops now.<br>
You can't easily repair the screen on laptops now.</p>
<p>You can do all that and more with a Framework laptop.<br>
You can be a laptop weirdo with a Framework laptop.</p>
<p>Weirdo typically has two interpretations:</p>
<blockquote>
<p>A possibly dangerous person.<br>
A strange, odd, eccentric person.</p>
</blockquote>
<p>To both of those I say: all us laptop weirdos can now put a <a href="https://community.frame.work/t/the-snack-drawer-store-now-made-with-real-snacks/43101?ref=blog.matthewbrunelle.com">snack drawer</a> in our laptops.<br>
You cannot stop us.</p>

    </div>
</article>
                
                

</main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rob Pike Goes Nuclear over GenAI (454 pts)]]></title>
            <link>https://imgur.com/nUJCI3o</link>
            <guid>46389444</guid>
            <pubDate>Fri, 26 Dec 2025 05:27:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://imgur.com/nUJCI3o">https://imgur.com/nUJCI3o</a>, See on <a href="https://news.ycombinator.com/item?id=46389444">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[TurboDiffusion: 100‚Äì200√ó Acceleration for Video Diffusion Models (225 pts)]]></title>
            <link>https://github.com/thu-ml/TurboDiffusion</link>
            <guid>46388907</guid>
            <pubDate>Fri, 26 Dec 2025 03:19:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/thu-ml/TurboDiffusion">https://github.com/thu-ml/TurboDiffusion</a>, See on <a href="https://news.ycombinator.com/item?id=46388907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TurboDiffusion</h2><a id="user-content-turbodiffusion" aria-label="Permalink: TurboDiffusion" href="#turbodiffusion"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/TurboDiffusion_Logo.png"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/TurboDiffusion_Logo.png" width="30%"></a>
</p>
<p dir="auto">This repository provides the official implementation of <strong>TurboDiffusion</strong>, a video generation acceleration framework that can speed up end-to-end diffusion generation by <math-renderer data-run-id="b6a8a1318f74547cd9421c8baa616925">$100 \sim 200\times$</math-renderer> on a single RTX 5090, while maintaining video quality.<br>
TurboDiffusion primarily uses <a href="https://github.com/thu-ml/SageAttention">SageAttention</a>, <a href="https://github.com/thu-ml/SLA">SLA (Sparse-Linear Attention)</a> for attention acceleration, and <a href="https://github.com/NVlabs/rcm">rCM</a> for timestep distillation.</p>
<p dir="auto">Paper: <a href="https://arxiv.org/pdf/2512.16093" rel="nofollow">TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times</a></p>
<p dir="auto"><strong>Note</strong>: the checkpoints and paper are not finalized, and will be updated later to improve quality.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/TurboDiffusion_speedup.png"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/TurboDiffusion_speedup.png" width="99%"></a>
</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/acceleration_decomposition.png"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/acceleration_decomposition.png" width="93%"></a>
</p>
<div dir="auto">
<markdown-accessiblity-table><table>
<tbody><tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/11.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/11.gif" width="387" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/11.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/11.gif" width="387" data-animated-image=""></a></p>
</td>
</tr>
</tbody></table></markdown-accessiblity-table><p>
An example of a <b>5-second video</b> generated by Wan-2.1-T2V-1.3B-480P on a single <b>RTX 5090</b>.
</p></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Available Models</h2><a id="user-content-available-models" aria-label="Permalink: Available Models" href="#available-models"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model Name</th>
<th>Checkpoint Link</th>
<th>Best Resolution</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TurboWan2.2-I2V-A14B-720P</code></td>
<td><a href="https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P" rel="nofollow">Huggingface Model</a></td>
<td>720p</td>
</tr>
<tr>
<td><code>TurboWan2.1-T2V-1.3B-480P</code></td>
<td><a href="https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P" rel="nofollow">Huggingface Model</a></td>
<td>480p</td>
</tr>
<tr>
<td><code>TurboWan2.1-T2V-14B-480P</code></td>
<td><a href="https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-14B-480P" rel="nofollow">Huggingface Model</a></td>
<td>480p</td>
</tr>
<tr>
<td><code>TurboWan2.1-T2V-14B-720P</code></td>
<td><a href="https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-14B-720P" rel="nofollow">Huggingface Model</a></td>
<td>720p</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Note: All checkpoints support generating videos at 480p or 720p. The "Best Resolution" column indicates the resolution at which the model provides the best video quality.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><strong>Base environment</strong>: <code>python&gt;=3.9</code>, <code>torch&gt;=2.7.0</code>. <code>torch==2.8.0</code> is recommended, as higher versions may cause OOM.</p>
<p dir="auto">Install TurboDiffusion by pip:</p>
<div dir="auto" data-snippet-clipboard-copy-content="conda create -n turbodiffusion python=3.12
conda activate turbodiffusion

pip install turbodiffusion --no-build-isolation"><pre>conda create -n turbodiffusion python=3.12
conda activate turbodiffusion

pip install turbodiffusion --no-build-isolation</pre></div>
<p dir="auto">Or compile from source:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/thu-ml/TurboDiffusion.git
cd TurboDiffusion
git submodule update --init --recursive
pip install -e . --no-build-isolation"><pre>git clone https://github.com/thu-ml/TurboDiffusion.git
<span>cd</span> TurboDiffusion
git submodule update --init --recursive
pip install -e <span>.</span> --no-build-isolation</pre></div>
<p dir="auto">To enable SageSLA, a fast SLA forward pass based on SageAttention, install <a href="https://github.com/thu-ml/SpargeAttn">SpargeAttn</a> first:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install git+https://github.com/thu-ml/SpargeAttn.git --no-build-isolation"><pre>pip install git+https://github.com/thu-ml/SpargeAttn.git --no-build-isolation</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inference</h2><a id="user-content-inference" aria-label="Permalink: Inference" href="#inference"></a></p>
<p dir="auto">For GPUs with more than 40GB of GPU memory, <strong>e.g., H100, please use the unquantized checkpoints (without <code>-quant</code>) and remove <code>--quant_linear</code> from the command. For RTX 5090, RTX 4090, or similar GPUs, please use the quantized checkpoints (with <code>-quant</code>) and add <code>--quant_linear</code> in the command.)</strong></p>
<ol dir="auto">
<li>
<p dir="auto">Download the VAE (<strong>applicable for both Wan2.1 and Wan2.2</strong>) and umT5 text encoder checkpoints:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir checkpoints
cd checkpoints
wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/Wan2.1_VAE.pth
wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/models_t5_umt5-xxl-enc-bf16.pth"><pre>mkdir checkpoints
<span>cd</span> checkpoints
wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/Wan2.1_VAE.pth
wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/models_t5_umt5-xxl-enc-bf16.pth</pre></div>
</li>
<li>
<p dir="auto">Download our quantized model checkpoints (For RTX 5090 or similar GPUs):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# For Wan2.1-T2V-1.3B
wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P-quant.pth

# For Wan2.2-I2V-14B
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P-quant.pth
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P-quant.pth"><pre><span><span>#</span> For Wan2.1-T2V-1.3B</span>
wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P-quant.pth

<span><span>#</span> For Wan2.2-I2V-14B</span>
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P-quant.pth
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P-quant.pth</pre></div>
<p dir="auto"><strong>Or</strong> download our unquantized model checkpoints (For H100 or similar GPUs):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# For Wan2.1-T2V-1.3B
wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P.pth

# For Wan2.2-I2V-14B
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P.pth
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P.pth"><pre><span><span>#</span> For Wan2.1-T2V-1.3B</span>
wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P.pth

<span><span>#</span> For Wan2.2-I2V-14B</span>
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P.pth
wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P.pth</pre></div>
</li>
<li>
<p dir="auto">Use the inference script for the <strong>T2V</strong> models:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export PYTHONPATH=turbodiffusion

# Arguments:
# --dit_path            Path to the finetuned TurboDiffusion checkpoint
# --model               Model to use: Wan2.1-1.3B or Wan2.1-14B (default: Wan2.1-1.3B)
# --num_samples         Number of videos to generate (default: 1)
# --num_steps           Sampling steps, 1‚Äì4 (default: 4)
# --sigma_max           Initial sigma for rCM (default: 80); larger choices (e.g., 1600) reduce diversity but may enhance quality
# --vae_path            Path to Wan2.1 VAE (default: checkpoints/Wan2.1_VAE.pth)
# --text_encoder_path   Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth)
# --num_frames          Number of frames to generate (default: 81)
# --prompt              Text prompt for video generation
# --resolution          Output resolution: &quot;480p&quot; or &quot;720p&quot; (default: 480p)
# --aspect_ratio        Aspect ratio in W:H format (default: 16:9)
# --seed                Random seed for reproducibility (default: 0)
# --save_path           Output file path including extension (default: output/generated_video.mp4)
# --attention_type      Attention module to use: original, sla or sagesla (default: sagesla)
# --sla_topk            Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality
# --quant_linear        Enable quantization for linear layers, pass this if using a quantized checkpoint
# --default_norm        Use the original LayerNorm and RMSNorm of Wan models

python turbodiffusion/inference/wan2.1_t2v_infer.py \
    --model Wan2.1-1.3B \
    --dit_path checkpoints/TurboWan2.1-T2V-1.3B-480P-quant.pth \
    --resolution 480p \
    --prompt &quot;A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.&quot; \
    --num_samples 1 \
    --num_steps 4 \
    --quant_linear \
    --attention_type sagesla \
    --sla_topk 0.1"><pre><span>export</span> PYTHONPATH=turbodiffusion

<span><span>#</span> Arguments:</span>
<span><span>#</span> --dit_path            Path to the finetuned TurboDiffusion checkpoint</span>
<span><span>#</span> --model               Model to use: Wan2.1-1.3B or Wan2.1-14B (default: Wan2.1-1.3B)</span>
<span><span>#</span> --num_samples         Number of videos to generate (default: 1)</span>
<span><span>#</span> --num_steps           Sampling steps, 1‚Äì4 (default: 4)</span>
<span><span>#</span> --sigma_max           Initial sigma for rCM (default: 80); larger choices (e.g., 1600) reduce diversity but may enhance quality</span>
<span><span>#</span> --vae_path            Path to Wan2.1 VAE (default: checkpoints/Wan2.1_VAE.pth)</span>
<span><span>#</span> --text_encoder_path   Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth)</span>
<span><span>#</span> --num_frames          Number of frames to generate (default: 81)</span>
<span><span>#</span> --prompt              Text prompt for video generation</span>
<span><span>#</span> --resolution          Output resolution: "480p" or "720p" (default: 480p)</span>
<span><span>#</span> --aspect_ratio        Aspect ratio in W:H format (default: 16:9)</span>
<span><span>#</span> --seed                Random seed for reproducibility (default: 0)</span>
<span><span>#</span> --save_path           Output file path including extension (default: output/generated_video.mp4)</span>
<span><span>#</span> --attention_type      Attention module to use: original, sla or sagesla (default: sagesla)</span>
<span><span>#</span> --sla_topk            Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality</span>
<span><span>#</span> --quant_linear        Enable quantization for linear layers, pass this if using a quantized checkpoint</span>
<span><span>#</span> --default_norm        Use the original LayerNorm and RMSNorm of Wan models</span>

python turbodiffusion/inference/wan2.1_t2v_infer.py \
    --model Wan2.1-1.3B \
    --dit_path checkpoints/TurboWan2.1-T2V-1.3B-480P-quant.pth \
    --resolution 480p \
    --prompt <span><span>"</span>A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.<span>"</span></span> \
    --num_samples 1 \
    --num_steps 4 \
    --quant_linear \
    --attention_type sagesla \
    --sla_topk 0.1</pre></div>
<p dir="auto">Or the script for the <strong>I2V</strong> model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export PYTHONPATH=turbodiffusion

# --image_path              Path to the input image
# --high_noise_model_path   Path to the high noise TurboDiffusion checkpoint
# --low_noise_model_path    Path to the high noise TurboDiffusion checkpoint
# --boundary                Timestep boundary for switching from high to low noise model (default: 0.9)
# --model                   Model to use: Wan2.2-A14B (default: Wan2.2-A14B)
# --num_samples             Number of videos to generate (default: 1)
# --num_steps               Sampling steps, 1‚Äì4 (default: 4)
# --sigma_max               Initial sigma for rCM (default: 200); larger choices (e.g., 1600) reduce diversity but may enhance quality
# --vae_path                Path to Wan2.2 VAE (default: checkpoints/Wan2.2_VAE.pth)
# --text_encoder_path       Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth)
# --num_frames              Number of frames to generate (default: 81)
# --prompt                  Text prompt for video generation
# --resolution              Output resolution: &quot;480p&quot; or &quot;720p&quot; (default: 720p)
# --aspect_ratio            Aspect ratio in W:H format (default: 16:9)
# --adaptive_resolution     Enable adaptive resolution based on input image size
# --ode                     Use ODE for sampling (sharper but less robust than SDE)
# --seed                    Random seed for reproducibility (default: 0)
# --save_path               Output file path including extension (default: output/generated_video.mp4)
# --attention_type          Attention module to use: original, sla or sagesla (default: sagesla)
# --sla_topk                Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality
# --quant_linear            Enable quantization for linear layers, pass this if using a quantized checkpoint
# --default_norm            Use the original LayerNorm and RMSNorm of Wan models

python turbodiffusion/inference/wan2.2_i2v_infer.py \
    --model Wan2.2-A14B \
    --low_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-low-720P-quant.pth \
    --high_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-high-720P-quant.pth \
    --resolution 720p \
    --adaptive_resolution \
    --image_path assets/i2v_inputs/i2v_input_0.jpg \
    --prompt &quot;POV selfie video, ultra-messy and extremely fast. A white cat in sunglasses stands on a surfboard with a neutral look when the board suddenly whips sideways, throwing cat and camera into the water; the frame dives sharply downward, swallowed by violent bursts of bubbles, spinning turbulence, and smeared water streaks as the camera sinks. Shadows thicken, pressure ripples distort the edges, and loose bubbles rush upward past the lens, showing the camera is still sinking. Then the cat kicks upward with explosive speed, dragging the view through churning bubbles and rapidly brightening water as sunlight floods back in; the camera races upward, water streaming off the lens, and finally breaks the surface in a sudden blast of light and spray, snapping back into a crooked, frantic selfie as the cat resurfaces.&quot; \
    --num_samples 1 \
    --num_steps 4 \
    --quant_linear \
    --attention_type sagesla \
    --sla_topk 0.1 \
    --ode"><pre><span>export</span> PYTHONPATH=turbodiffusion

<span><span>#</span> --image_path              Path to the input image</span>
<span><span>#</span> --high_noise_model_path   Path to the high noise TurboDiffusion checkpoint</span>
<span><span>#</span> --low_noise_model_path    Path to the high noise TurboDiffusion checkpoint</span>
<span><span>#</span> --boundary                Timestep boundary for switching from high to low noise model (default: 0.9)</span>
<span><span>#</span> --model                   Model to use: Wan2.2-A14B (default: Wan2.2-A14B)</span>
<span><span>#</span> --num_samples             Number of videos to generate (default: 1)</span>
<span><span>#</span> --num_steps               Sampling steps, 1‚Äì4 (default: 4)</span>
<span><span>#</span> --sigma_max               Initial sigma for rCM (default: 200); larger choices (e.g., 1600) reduce diversity but may enhance quality</span>
<span><span>#</span> --vae_path                Path to Wan2.2 VAE (default: checkpoints/Wan2.2_VAE.pth)</span>
<span><span>#</span> --text_encoder_path       Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth)</span>
<span><span>#</span> --num_frames              Number of frames to generate (default: 81)</span>
<span><span>#</span> --prompt                  Text prompt for video generation</span>
<span><span>#</span> --resolution              Output resolution: "480p" or "720p" (default: 720p)</span>
<span><span>#</span> --aspect_ratio            Aspect ratio in W:H format (default: 16:9)</span>
<span><span>#</span> --adaptive_resolution     Enable adaptive resolution based on input image size</span>
<span><span>#</span> --ode                     Use ODE for sampling (sharper but less robust than SDE)</span>
<span><span>#</span> --seed                    Random seed for reproducibility (default: 0)</span>
<span><span>#</span> --save_path               Output file path including extension (default: output/generated_video.mp4)</span>
<span><span>#</span> --attention_type          Attention module to use: original, sla or sagesla (default: sagesla)</span>
<span><span>#</span> --sla_topk                Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality</span>
<span><span>#</span> --quant_linear            Enable quantization for linear layers, pass this if using a quantized checkpoint</span>
<span><span>#</span> --default_norm            Use the original LayerNorm and RMSNorm of Wan models</span>

python turbodiffusion/inference/wan2.2_i2v_infer.py \
    --model Wan2.2-A14B \
    --low_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-low-720P-quant.pth \
    --high_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-high-720P-quant.pth \
    --resolution 720p \
    --adaptive_resolution \
    --image_path assets/i2v_inputs/i2v_input_0.jpg \
    --prompt <span><span>"</span>POV selfie video, ultra-messy and extremely fast. A white cat in sunglasses stands on a surfboard with a neutral look when the board suddenly whips sideways, throwing cat and camera into the water; the frame dives sharply downward, swallowed by violent bursts of bubbles, spinning turbulence, and smeared water streaks as the camera sinks. Shadows thicken, pressure ripples distort the edges, and loose bubbles rush upward past the lens, showing the camera is still sinking. Then the cat kicks upward with explosive speed, dragging the view through churning bubbles and rapidly brightening water as sunlight floods back in; the camera races upward, water streaming off the lens, and finally breaks the surface in a sudden blast of light and spray, snapping back into a crooked, frantic selfie as the cat resurfaces.<span>"</span></span> \
    --num_samples 1 \
    --num_steps 4 \
    --quant_linear \
    --attention_type sagesla \
    --sla_topk 0.1 \
    --ode</pre></div>
</li>
</ol>
<p dir="auto">Interactive inference via the terminal is available at <code>turbodiffusion/serve/</code>. This allows multi-turn video generation without reloading the model.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Evaluation</h2><a id="user-content-evaluation" aria-label="Permalink: Evaluation" href="#evaluation"></a></p>
<p dir="auto">We evaluate video generation on <strong>a single RTX 5090 GPU</strong>. The E2E Time refers to the end-to-end diffusion generation latency, excluding text encoding and VAE decoding.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wan-2.2-I2V-A14B-720P</h3><a id="user-content-wan-22-i2v-a14b-720p" aria-label="Permalink: Wan-2.2-I2V-A14B-720P" href="#wan-22-i2v-a14b-720p"></a></p>
<markdown-accessiblity-table><table>
<tbody><tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/0.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/0.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/1.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/1.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/2.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/2.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/2.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/2.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/3.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/3.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/3.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/3.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/4.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/4.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/4.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/4.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/5.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/5.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4549s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/original/A14B_720p/gif/6.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/original/A14B_720p/gif/6.gif" width="360" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>38s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/6.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/i2v/turbodiffusion/A14B_720p/gif/6.gif" width="360" data-animated-image=""></a></p>
</td>
</tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wan-2.1-T2V-1.3B-480P</h3><a id="user-content-wan-21-t2v-13b-480p" aria-label="Permalink: Wan-2.1-T2V-1.3B-480P" href="#wan-21-t2v-13b-480p"></a></p>
<markdown-accessiblity-table><table>
<tbody><tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/5.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/5.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/5.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/0.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/0.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/0.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/1.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/1.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/1.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/2.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/2.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/2.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/2.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/2.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/2.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/7.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/7.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/7.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/7.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/7.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/7.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/11.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/11.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/11.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/11.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/11.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/11.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/13.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/13.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/13.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/13.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/13.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/13.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 184s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/1.3B/14.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/1.3B/14.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 5.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_1.3B/14.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_1.3B/14.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>1.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/1.3B/14.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/1.3B/14.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wan-2.1-T2V-14B-720P</h3><a id="user-content-wan-21-t2v-14b-720p" aria-label="Permalink: Wan-2.1-T2V-14B-720P" href="#wan-21-t2v-14b-720p"></a></p>
<markdown-accessiblity-table><table>
<tbody><tr>
<td>
<p>Original, E2E Time: 4767s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_720p/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_720p/0.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 72.6s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_720p/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_720p/0.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>24s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_720p/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_720p/0.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4767s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_720p/3.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_720p/3.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 72.6s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_720p/3.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_720p/3.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>24s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_720p/3.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_720p/3.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 4767s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_720p/6.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_720p/6.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 72.6s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_720p/6.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_720p/6.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>24s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_720p/6.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_720p/6.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wan-2.1-T2V-14B-480P</h3><a id="user-content-wan-21-t2v-14b-480p" aria-label="Permalink: Wan-2.1-T2V-14B-480P" href="#wan-21-t2v-14b-480p"></a></p>
<markdown-accessiblity-table><table>
<tbody><tr>
<td>
<p>Original, E2E Time: 1676s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_480p/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_480p/0.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 26.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_480p/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_480p/0.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>9.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_480p/0.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_480p/0.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 1676s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_480p/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_480p/1.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 26.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_480p/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_480p/1.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>9.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_480p/1.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_480p/1.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 1676s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_480p/4.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_480p/4.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 26.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_480p/4.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_480p/4.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>9.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_480p/4.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_480p/4.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
<tr>
<td>
<p>Original, E2E Time: 1676s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/original/14B_480p/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/original/14B_480p/5.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>FastVideo, E2E Time: 26.3s</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/fastvideo/video_14B_480p/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/fastvideo/video_14B_480p/5.gif" width="249" data-animated-image=""></a></p>
</td>
<td>
<p>TurboDiffusion, E2E Time: <b>9.9s</b></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/TurboDiffusion/blob/main/assets/videos/turbodiffusion/14B_480p/5.gif"><img src="https://github.com/thu-ml/TurboDiffusion/raw/main/assets/videos/turbodiffusion/14B_480p/5.gif" width="249" data-animated-image=""></a></p>
</td>
</tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Training</h2><a id="user-content-training" aria-label="Permalink: Training" href="#training"></a></p>
<p dir="auto">In this repo, we provide training code based on Wan2.1 and its synthetic data. The training builds on the rCM codebase (<a href="https://github.com/NVlabs/rcm">https://github.com/NVlabs/rcm</a>), with infrastructure support including FSDP2, Ulysses CP, and selective activation checkpointing (SAC). For rCM training instructions, please refer to the original rCM repository; <a href="https://github.com/thu-ml/SLA">SLA (Sparse-Linear Attention)</a> training guidance is provided here.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Additional Installation</h4><a id="user-content-additional-installation" aria-label="Permalink: Additional Installation" href="#additional-installation"></a></p>
<p dir="auto">For rCM/SLA training, additionally run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install megatron-core hydra-core wandb webdataset
pip install --no-build-isolation transformer_engine[pytorch]"><pre>pip install megatron-core hydra-core wandb webdataset
pip install --no-build-isolation transformer_engine[pytorch]</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Checkpoints Downloading</h4><a id="user-content-checkpoints-downloading" aria-label="Permalink: Checkpoints Downloading" href="#checkpoints-downloading"></a></p>
<p dir="auto">Download the Wan2.1 pretrained checkpoints in <code>.pth</code> format and VAE/text encoder to <code>assets/checkpoints</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# make sure git lfs is installed
git clone https://huggingface.co/worstcoder/Wan assets/checkpoints"><pre><span><span>#</span> make sure git lfs is installed</span>
git clone https://huggingface.co/worstcoder/Wan assets/checkpoints</pre></div>
<p dir="auto">FSDP2 relies on <a href="https://docs.pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html" rel="nofollow">Distributed Checkpoint (DCP)</a> for loading and saving checkpoints. Before training, convert <code>.pth</code> teacher checkpoints to <code>.dcp</code> first:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m torch.distributed.checkpoint.format_utils torch_to_dcp assets/checkpoints/Wan2.1-T2V-1.3B.pth assets/checkpoints/Wan2.1-T2V-1.3B.dcp"><pre>python -m torch.distributed.checkpoint.format_utils torch_to_dcp assets/checkpoints/Wan2.1-T2V-1.3B.pth assets/checkpoints/Wan2.1-T2V-1.3B.dcp</pre></div>
<p dir="auto">After training, the saved <code>.dcp</code> checkpoints can be converted to <code>.pth</code> using the script <code>scripts/dcp_to_pth.py</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Dataset Downloading</h4><a id="user-content-dataset-downloading" aria-label="Permalink: Dataset Downloading" href="#dataset-downloading"></a></p>
<p dir="auto">We provide Wan2.1-14B-synthesized datasets. Download to <code>assets/datasets</code> using:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# make sure git lfs is installed
git clone https://huggingface.co/datasets/worstcoder/Wan_datasets assets/datasets"><pre><span><span>#</span> make sure git lfs is installed</span>
git clone https://huggingface.co/datasets/worstcoder/Wan_datasets assets/datasets</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Start Training</h4><a id="user-content-start-training" aria-label="Permalink: Start Training" href="#start-training"></a></p>
<p dir="auto">We implement white-box SLA training by aligning the predictions of the SLA-enabled model with those of the full-attention pretrained model. Unlike black-box training in the original paper, which tunes the pretrained model using diffusion loss, white-box training mitigates distribution shift and is less sensitive to the training data.</p>
<p dir="auto">Single-node training example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="WORKDIR=&quot;/your/path/to/turbodiffusion&quot;
cd $WORKDIR
export PYTHONPATH=turbodiffusion

# the &quot;IMAGINAIRE_OUTPUT_ROOT&quot; environment variable is the path to save experiment output files
export IMAGINAIRE_OUTPUT_ROOT=${WORKDIR}/outputs
CHECKPOINT_ROOT=${WORKDIR}/assets/checkpoints
DATASET_ROOT=${WORKDIR}/assets/datasets/Wan2.1_14B_480p_16:9_Euler-step100_shift-3.0_cfg-5.0_seed-0_250K

# your Wandb information
export WANDB_API_KEY=xxx
export WANDB_ENTITY=xxx

registry=registry_sla
experiment=wan2pt1_1pt3B_res480p_t2v_SLA

torchrun --nproc_per_node=8 \
    -m scripts.train --config=rcm/configs/${registry}.py -- experiment=${experiment} \
        model.config.teacher_ckpt=${CHECKPOINT_ROOT}/Wan2.1-T2V-1.3B.dcp \
        model.config.tokenizer.vae_pth=${CHECKPOINT_ROOT}/Wan2.1_VAE.pth \
        model.config.text_encoder_path=${CHECKPOINT_ROOT}/models_t5_umt5-xxl-enc-bf16.pth \
        model.config.neg_embed_path=${CHECKPOINT_ROOT}/umT5_wan_negative_emb.pt \
        dataloader_train.tar_path_pattern=${DATASET_ROOT}/shard*.tar"><pre>WORKDIR=<span><span>"</span>/your/path/to/turbodiffusion<span>"</span></span>
<span>cd</span> <span>$WORKDIR</span>
<span>export</span> PYTHONPATH=turbodiffusion

<span><span>#</span> the "IMAGINAIRE_OUTPUT_ROOT" environment variable is the path to save experiment output files</span>
<span>export</span> IMAGINAIRE_OUTPUT_ROOT=<span>${WORKDIR}</span>/outputs
CHECKPOINT_ROOT=<span>${WORKDIR}</span>/assets/checkpoints
DATASET_ROOT=<span>${WORKDIR}</span>/assets/datasets/Wan2.1_14B_480p_16:9_Euler-step100_shift-3.0_cfg-5.0_seed-0_250K

<span><span>#</span> your Wandb information</span>
<span>export</span> WANDB_API_KEY=xxx
<span>export</span> WANDB_ENTITY=xxx

registry=registry_sla
experiment=wan2pt1_1pt3B_res480p_t2v_SLA

torchrun --nproc_per_node=8 \
    -m scripts.train --config=rcm/configs/<span>${registry}</span>.py -- experiment=<span>${experiment}</span> \
        model.config.teacher_ckpt=<span>${CHECKPOINT_ROOT}</span>/Wan2.1-T2V-1.3B.dcp \
        model.config.tokenizer.vae_pth=<span>${CHECKPOINT_ROOT}</span>/Wan2.1_VAE.pth \
        model.config.text_encoder_path=<span>${CHECKPOINT_ROOT}</span>/models_t5_umt5-xxl-enc-bf16.pth \
        model.config.neg_embed_path=<span>${CHECKPOINT_ROOT}</span>/umT5_wan_negative_emb.pt \
        dataloader_train.tar_path_pattern=<span>${DATASET_ROOT}</span>/shard<span>*</span>.tar</pre></div>
<p dir="auto">Please refer to <code>turbodiffusion/rcm/configs/experiments/sla/wan2pt1_t2v.py</code> for the 14B config or perform modifications as needed.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Model Merging</h4><a id="user-content-model-merging" aria-label="Permalink: Model Merging" href="#model-merging"></a></p>
<p dir="auto">The parameter updates from SLA training can be merged into rCM checkpoints using <code>turbodiffusion/scripts/merge_models.py</code>, enabling rCM to perform sparse attention inference. Specify <code>--base</code> as the rCM model, <code>--diff_base</code> as the pretrained model, and <code>--diff_target</code> as the SLA-tuned model.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ComfyUI Integration</h2><a id="user-content-comfyui-integration" aria-label="Permalink: ComfyUI Integration" href="#comfyui-integration"></a></p>
<p dir="auto">We thank the community effort <a href="https://github.com/anveshane/Comfyui_turbodiffusion">Comfyui_turbodiffusion</a> for integrating TurboDiffusion into ComfyUI.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto">We're actively working on the following features and improvements:</p>
<ul>
<li> Organize and release training code</li>
<li> Optimize infrastructure for better parallel</li>
<li> vLLM-Omni integration</li>
<li> Support for more video generation models</li>
<li> Support for autoregressive video generation models</li>
<li> More hardware-level operator optimizations</li>
</ul>
<p dir="auto">We welcome community members to help maintain and extend TurboDiffusion. Welcome to join the TurboDiffusion Team and contribute together!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto"><strong>If you use this code or find our work valuable, please cite:</strong></p>
<div data-snippet-clipboard-copy-content="@article{zhang2025turbodiffusion,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={Zhang, Jintao and Zheng, Kaiwen and Jiang, Kai and Wang, Haoxu and Stoica, Ion and Gonzalez, Joseph E and Chen, Jianfei and Zhu, Jun},
  journal={arXiv preprint arXiv:2512.16093},
  year={2025}
}

@software{turbodiffusion2025,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={The TurboDiffusion Team},
  url={https://github.com/thu-ml/TurboDiffusion},
  year={2025}
}

@inproceedings{zhang2025sageattention,
  title={SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration}, 
  author={Zhang, Jintao and Wei, Jia and Zhang, Pengle and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@article{zhang2025sla,
  title={SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention},
  author={Zhang, Jintao and Wang, Haoxu and Jiang, Kai and Yang, Shuo and Zheng, Kaiwen and Xi, Haocheng and Wang, Ziteng and Zhu, Hongzhou and Zhao, Min and Stoica, Ion and others},
  journal={arXiv preprint arXiv:2509.24006},
  year={2025}
}

@article{zheng2025rcm,
  title={Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency},
  author={Zheng, Kaiwen and Wang, Yuji and Ma, Qianli and Chen, Huayu and Zhang, Jintao and Balaji, Yogesh and Chen, Jianfei and Liu, Ming-Yu and Zhu, Jun and Zhang, Qinsheng},
  journal={arXiv preprint arXiv:2510.08431},
  year={2025}
}

@inproceedings{zhang2024sageattention2,
  title={Sageattention2: Efficient attention with thorough outlier smoothing and per-thread int4 quantization},
  author={Zhang, Jintao and Huang, Haofeng and Zhang, Pengle and Wei, Jia and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2025}
}"><pre><code>@article{zhang2025turbodiffusion,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={Zhang, Jintao and Zheng, Kaiwen and Jiang, Kai and Wang, Haoxu and Stoica, Ion and Gonzalez, Joseph E and Chen, Jianfei and Zhu, Jun},
  journal={arXiv preprint arXiv:2512.16093},
  year={2025}
}

@software{turbodiffusion2025,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={The TurboDiffusion Team},
  url={https://github.com/thu-ml/TurboDiffusion},
  year={2025}
}

@inproceedings{zhang2025sageattention,
  title={SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration}, 
  author={Zhang, Jintao and Wei, Jia and Zhang, Pengle and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@article{zhang2025sla,
  title={SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention},
  author={Zhang, Jintao and Wang, Haoxu and Jiang, Kai and Yang, Shuo and Zheng, Kaiwen and Xi, Haocheng and Wang, Ziteng and Zhu, Hongzhou and Zhao, Min and Stoica, Ion and others},
  journal={arXiv preprint arXiv:2509.24006},
  year={2025}
}

@article{zheng2025rcm,
  title={Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency},
  author={Zheng, Kaiwen and Wang, Yuji and Ma, Qianli and Chen, Huayu and Zhang, Jintao and Balaji, Yogesh and Chen, Jianfei and Liu, Ming-Yu and Zhu, Jun and Zhang, Qinsheng},
  journal={arXiv preprint arXiv:2510.08431},
  year={2025}
}

@inproceedings{zhang2024sageattention2,
  title={Sageattention2: Efficient attention with thorough outlier smoothing and per-thread int4 quantization},
  author={Zhang, Jintao and Huang, Haofeng and Zhang, Pengle and Wei, Jia and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2025}
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MiniMax M2.1: Built for Real-World Complex Tasks, Multi-Language Programming (208 pts)]]></title>
            <link>https://www.minimaxi.com/news/minimax-m21</link>
            <guid>46388213</guid>
            <pubDate>Fri, 26 Dec 2025 01:02:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.minimaxi.com/news/minimax-m21">https://www.minimaxi.com/news/minimax-m21</a>, See on <a href="https://news.ycombinator.com/item?id=46388213">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><div><p><a href="https://www.minimaxi.com/"><img alt="MiniMax" fetchpriority="high" width="140" height="32" decoding="async" data-nimg="1" src="https://filecdn.minimax.chat/public/969d635c-cab6-45cc-8d61-47c9fe40c81f.png?x-oss-process=image/format,webp"></a></p></div><div><p><img alt="https://filecdn.minimax.chat/public/bbd9416c-f809-4195-88df-05fcd2051b15.png" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/bbd9416c-f809-4195-88df-05fcd2051b15.png"></p></div><div><p>MiniMax‰∏ÄÁõ¥Âú®Áî®Êõ¥AI ÂéüÁîüÁöÑÊñπÂºèÊîπÈÄ†Ëá™Â∑±„ÄÇËøô‰∏™ËøáÁ®ãÁöÑÊ†∏ÂøÉÈ©±Âä®ÂäõÊòØÊ®°Âûã„ÄÅAgentËÑöÊâãÊû∂ÂíåÁªÑÁªá„ÄÇÂú®Êé¢Á¥¢ËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨ÂØπ‰∏äËø∞‰∏âÁÇπ‰πüÊúâ‰∫ÜË∂äÊù•Ë∂äÊ∑±ÂàªÁöÑËÆ§Áü•„ÄÇ‰ªäÂ§©Êàë‰ª¨ÂºÄÊîæÊ®°ÂûãÈÉ®ÂàÜÁöÑÊõ¥Êñ∞Ôºå‰πüÂ∞±ÊòØMiniMax M2.1ÔºåÂ∏åÊúõÊúâÊú∫‰ºöËÉΩÂ∏ÆÂä©Âà∞Êõ¥Â§öÁöÑ‰ºÅ‰∏öÂíå‰∏™‰∫∫Êó©Êó•ÊâæÂà∞Êõ¥AIÂéüÁîüÁöÑÂ∑•‰ΩúÔºàÁîüÊ¥ªÔºâÊñπÂºè„ÄÇ</p><p>

Âú®10ÊúàÂ∫ïÁöÑM2‰∏≠ÔºåÊàë‰ª¨‰∏ªË¶ÅËß£ÂÜ≥Ê®°ÂûãÊàêÊú¨ÂíåÊ®°ÂûãÂºÄÊîæÊÄßÁöÑÈóÆÈ¢ò„ÄÇÂú®M2.1‰∏≠ÔºåÊàë‰ª¨Ëá¥Âäõ‰∫éÊèêÂçáÁúüÂÆû‰∏ñÁïåÂ§çÊùÇ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞Ôºö<strong>ÈáçÁÇπËÅöÁÑ¶‰∫éÊõ¥Â§öÁºñÁ®ãËØ≠Ë®ÄÂíåÂäûÂÖ¨Âú∫ÊôØÁöÑÂèØÁî®ÊÄßÔºåÂπ∂Âú®Ëøô‰∏™È¢ÜÂüüÂÅöÂà∞ÊúÄÂ•ΩÁöÑÊ∞¥Âπ≥</strong>„ÄÇ</p></div><div><p><img alt="icon" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" src="https://filecdn.minimax.chat/public/a533807b-9ff6-4f86-a72e-8eb31d0245c1.png"></p></div><div><div 1.7;="" max-width:="" 800px;"="">

  <p>
    MiniMax M2.1 ÂÖ∑‰ΩìÊ®°Âûã‰∫ÆÁÇπÂ¶Ç‰∏ã:
  </p>
  
  <ul>
  
    <li>
      <p><strong>ÂçìË∂äÂ§öÁºñÁ®ãËØ≠Ë®ÄËÉΩÂäõ</strong></p>
      <p>ËøáÂéªÂæàÂ§öÊ®°Âûã‰∏ªË¶ÅÂõ¥Áªï Python ‰ºòÂåñ, ‰ΩÜÁúüÂÆû‰∏ñÁïåÁöÑÁ≥ªÁªüÂæÄÂæÄÊòØÂ§öËØ≠Ë®ÄÂçè‰ΩúÁöÑÁªìÊûú„ÄÇ</p>
      <p>Âú® M2.1 ‰∏≠, Êàë‰ª¨Á≥ªÁªüÊÄßÊèêÂçá‰∫Ü Rust / Java / Golang / <span>C++</span> / Kotlin / Objective-C / TypeScript / <span>JavaScript</span> Á≠âËØ≠Ë®ÄÁöÑËÉΩÂäõ, Â§öËØ≠Ë®Ä‰ªªÂä°Êï¥‰ΩìË°®Áé∞ËææÂà∞‰∏öÂÜÖÈ¢ÜÂÖàÊ∞¥Âπ≥, Ë¶ÜÁõñ‰ªéÂ∫ïÂ±ÇÁ≥ªÁªüÂà∞Â∫îÁî®Â±ÇÂºÄÂèëÁöÑÂÆåÊï¥ÈìæË∑Ø„ÄÇ
      </p>
    </li>
    
    <li>
      <p><strong>WebDev ‰∏é AppDevÔºöËÉΩÂäõ‰∏éÁæéÂ≠¶ÁöÑÊï¥‰ΩìË∑ÉËøÅ</strong></p>
      <p>ÈíàÂØπ‰∏öÁïåÊôÆÈÅçÂ≠òÂú®ÁöÑÁßªÂä®Á´ØÂºÄÂèëÁü≠Êùø, M2.1 ÊòæËëóÂä†Âº∫‰∫ÜÂéüÁîü Android / iOS ÂºÄÂèëËÉΩÂäõ„ÄÇ</p>
      <p>ÂêåÊó∂, Êàë‰ª¨Á≥ªÁªüÊÄßÊèêÂçá‰∫ÜÊ®°ÂûãÂú® Web ‰∏é App Âú∫ÊôØ‰∏≠ÁöÑËÆæËÆ°ÁêÜËß£‰∏éÁæéÂ≠¶Ë°®ËææËÉΩÂäõ, ËÉΩÂ§üÂá∫Ëâ≤Âú∞ÊûÑÂª∫Â§çÊùÇ‰∫§‰∫í„ÄÅ3DÁßëÂ≠¶Âú∫ÊôØÊ®°Êãü‰∏éÈ´òË¥®ÈáèÂèØËßÜÂåñË°®Ëææ, Êé®Âä® <span>vibe coding</span> Êàê‰∏∫ÂèØÊåÅÁª≠„ÄÅÂèØ‰∫§‰ªòÁöÑÁîü‰∫ßÂÆûË∑µ„ÄÇ
      </p>
    </li>
    
    <li>
      <p><strong>Â§çÂêàÊåá‰ª§Á∫¶ÊùüÊèêÂçáÔºåÂäûÂÖ¨Âú∫ÊôØÂèò‰∏∫ÂèØËÉΩ</strong></p>
      <p>‰Ωú‰∏∫ÂºÄÊ∫êÊ®°Âûã‰∏≠<span>ÁéáÂÖàÁ≥ªÁªüÊÄß</span>ÂºïÂÖ• Interleaved Thinking ÁöÑÊ®°ÂûãÁ≥ªÂàó, M2.1 systematic problem-solving ËÉΩÂäõÂÜçÊ¨°ÂçáÁ∫ß„ÄÇ</p>
      <p>Ê®°Âûã‰∏ç‰ªÖÂÖ≥Ê≥®‰ª£Á†ÅÊâßË°åÊòØÂê¶Ê≠£Á°Æ, ÂêåÊó∂ÂÖ≥Ê≥®Ê®°ÂûãÂØπ‚ÄúÂ§çÂêàÊåá‰ª§Á∫¶Êùü‚ÄùÁöÑÊï¥ÂêàÊâßË°åËÉΩÂäõ, Âú®ÁúüÂÆûÂäûÂÖ¨Âú∫ÊôØÂÖ∑Â§áÊõ¥È´òÁöÑÂèØÁî®ÊÄß„ÄÇ
      </p>
    </li>
    
    <li>
      <p><strong>Êõ¥ÁÆÄÊ¥ÅÈ´òÊïàÁöÑÂõûÂ§ç</strong></p>
      <p>Áõ∏ÊØî M2, MiniMax-M2.1 ÁöÑÊ®°ÂûãÂõûÂ§ç‰ª•ÂèäÊÄùÁª¥ÈìæÊõ¥Âä†ÁÆÄÊ¥Å, Âú®ÂÆûÈôÖÁºñÁ®ã‰∏é‰∫§‰∫í‰ΩìÈ™å‰∏≠, ÂìçÂ∫îÈÄüÂ∫¶ÊòæËëóÊèêÂçá, Token Ê∂àËÄóÊòéÊòæ‰∏ãÈôç, Âú® AI Coding‰∏éAgentÈ©±Âä®ÁöÑËøûÁª≠Â∑•‰ΩúÊµÅ‰∏≠Êõ¥Âä†ÊµÅÁïÖÂíåÈ´òÊïà„ÄÇ
      </p>
    </li>
    
    <li>
      <p><strong>Âá∫Ëâ≤ÁöÑ <span>Agent / Â∑•ÂÖ∑ËÑöÊâãÊû∂Ê≥õÂåñËÉΩÂäõ</span></strong></p>
      <p>M2.1 Âú®ÂêÑÁ±ªÁºñÁ®ãÂ∑•ÂÖ∑‰∏é Agent Ê°ÜÊû∂‰∏≠ÂùáÊúâÂá∫Ëâ≤Ë°®Áé∞„ÄÇÂú® Claude Code„ÄÅDroid (Factory AI)„ÄÅCline„ÄÅKilo Code„ÄÅRoo Code„ÄÅBlackBox Á≠âÂ∑•ÂÖ∑‰∏≠Â±ïÁé∞‰∏ÄËá¥‰∏îÁ®≥ÂÆöÁöÑÊïàÊûú, Âπ∂ÂØπ Skill.md„ÄÅClaude.md / agent.md / cursorrule„ÄÅSlash Command Á≠â Context ManagementÊú∫Âà∂Êèê‰æõÂèØÈù†ÊîØÊåÅ„ÄÇ
      </p>
    </li>
    
    <li>
      <p><strong>È´òË¥®ÈáèÂØπËØùÂíåÂÜô‰Ωú</strong></p>
      <p>M2.1 ‰∏çÂÜçÂè™ÊòØ‚Äú‰ª£Á†ÅËÉΩÂäõÊõ¥Âº∫‚Äù, Âú®Êó•Â∏∏ÂØπËØù„ÄÅÊäÄÊúØËØ¥Êòé‰∏éÂÜô‰ΩúÂú∫ÊôØ‰∏≠, ‰πüËÉΩÊèê‰æõÊõ¥ÂÖ∑ÁªÜËäÇ‰∏éÁªìÊûÑÊÄßÁöÑÂõûÁ≠î„ÄÇ
      </p>
    </li>
    
  </ul>

</div>
<br></div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/f0d35ee7-c17f-4515-a8b6-b78eccbb7603.png"></p></div><h3>Âü∫ÂáÜÊµãËØïÊ¶ÇËßà</h3><p>Âú®ËΩØ‰ª∂Â∑•Á®ãÁõ∏ÂÖ≥Âú∫ÊôØÁöÑÊ†∏ÂøÉÊ¶úÂçï‰∏äÔºåMiniMax-M2.1Áõ∏ÊØî‰∫éM2Êúâ‰∫ÜÊòæËëóÁöÑÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§öËØ≠Ë®ÄÂú∫ÊôØ‰∏äÔºåË∂ÖËøá Claude Sonnet 4.5ÂíåGemini 3 ProÔºåÂπ∂Êé•ËøëClaude Opus 4.5„ÄÇ</p><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/8b79e8e7-355a-4644-b06c-a627057ba3ec.png"></p></div><p>Êàë‰ª¨Âú®‰∏çÂêåcoding agentÊ°ÜÊû∂‰∏äÊµãËØï‰∫ÜSWE-bench VerifiedÔºåÁªìÊûúË°®ÊòéMiniMax-M2.1ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ°ÜÊû∂Ê≥õÂåñÊÄßÂíåÁ®≥ÂÆöÁöÑË°®Áé∞„ÄÇËÄåÂú®ÂÖ¨ÂºÄÁöÑÊµãËØïÁî®‰æãÁîüÊàê„ÄÅ‰ª£Á†ÅÊÄßËÉΩ‰ºòÂåñÔºå‰ª•ÂèäËá™Âª∫ÁöÑ‰ª£Á†ÅÂÆ°ÈòÖ„ÄÅÊåá‰ª§ÈÅµ‰ªéÁ≠âÁªÜÂàÜÂú∫ÊôØÁöÑÊ¶úÂçï‰∏äÔºåMiniMax-M2.1Áõ∏ÊØîM2ÈÉΩË°®Áé∞Âá∫‰∫ÜÂÖ®Èù¢ÁöÑÊèêÂçáÔºåÊåÅÂπ≥ÊàñË∂ÖËøáClaude Sonnet 4.5„ÄÇ</p><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/30022d7b-722a-41f4-ba5c-af5d0642170e.png"></p></div><p>‰∏∫‰∫ÜË°°ÈáèÊ®°Âûã‚Äú‰ªéÈõ∂Âà∞‰∏Ä‚ÄùÊûÑÂª∫ÂÆåÊï¥„ÄÅÂèØËøêË°åÂ∫îÁî®Á®ãÂ∫èÁöÑÂÖ®Ê†àËÉΩÂäõÔºåÊàë‰ª¨ÊûÑÂª∫Âπ∂ÂºÄÊ∫ê‰∫ÜÂÖ®Êñ∞Âü∫ÂáÜ <strong>VIBE (Visual &amp; Interactive Benchmark for Execution) ÊµãËØïÈõÜ</strong>ÔºåÊ∂µÁõñ‰∫Ü Web„ÄÅ‰ªøÁúü (Simulation)„ÄÅAndroid„ÄÅiOS ÂèäÂêéÁ´Ø (Backend) ‰∫îÂ§ßÊ†∏ÂøÉÂ≠êÈõÜ„ÄÇ‰∏çÂêå‰∫é‰º†ÁªüÂü∫ÂáÜÔºåÈÄöËøáÂàõÊñ∞ÁöÑ Agent-as-a-Verifier (AaaV) ËåÉÂºèÔºåVIBE ËÉΩÂ§üËá™Âä®ËØÑ‰º∞ÁîüÊàêÁöÑ Application Âú®ÁúüÂÆûËøêË°åÁéØÂ¢É‰∏≠ÁöÑ‰∫§‰∫íÈÄªËæë‰∏éËßÜËßâÁæéÊÑü„ÄÇËøô‰∏™ËØÑÊµãÈõÜÁ®çÂêéÂ∞ÜÂú®Github‰∏äÂºÄÊ∫ê„ÄÇ<br>
MiniMax-M2.1 Âú® VIBE ÁªºÂêàÊ¶úÂçï‰∏≠Ë°®Áé∞ÂçìË∂äÔºå‰ª•Âπ≥Âùá 88.6 ÂàÜÁöÑÊàêÁª©Â±ïÁé∞‰∫ÜÊé•ËøëClaude Opus 4.5ÁöÑÂÖ®Ê†àÊûÑÂª∫ËÉΩÂäõÔºåÂπ∂Âú®Âá†‰πéÊâÄÊúâÂ≠êÈõÜ‰∏äÈÉΩÊòæËëó‰ºò‰∫éClaude Sonnet 4.5„ÄÇ</p><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/543151ab-1d79-4ebf-93a1-191c4f982437.png"></p></div><p>Âú®ÂäûÂÖ¨Âú∫ÊôØ„ÄÅÈïøÁ®ãÂ∑•ÂÖ∑Ë∞ÉÁî®ÂíåÁªºÂêàÊô∫ËÉΩÊåáÊï∞‰∏äÔºåMiniMax-M2.1 Áõ∏ÊØî M2 ‰πüË°®Áé∞Âá∫Á®≥Ê≠•ÊèêÂçáÔºå‰ΩìÁé∞‰∫ÜÊ®°ÂûãËß£ÂÜ≥Êõ¥Â§öÁúüÂÆû‰∏ñÁïåÂ§çÊùÇ‰ªªÂä°ÁöÑËÉΩÂäõ„ÄÇ</p><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/97a7e3fd-0590-4af7-8b3a-f793d2f254fb.png"></p></div><h3>‰ΩøÁî®ËÄÖËØÑ‰ª∑</h3><p>ËøáÂéªÂá†Â§©ÔºåÈÄöËøáMiniMaxÂÖ®ÁêÉÁöÑÂºÄÂèëËÄÖÁ§æÂå∫ÔºåÊàë‰ª¨ÂºÄÊîæÂÜÖÊµã‰∫ÜM2.1ÁöÑÊ®°ÂûãÔºå‰πüÊî∂Âà∞‰∫ÜÈùûÂ∏∏Â§öÁöÑÁÉ≠ÂøÉÂèçÈ¶à„ÄÇ‰∏ãÈù¢ÊòØÂÖ∂‰∏≠‰∏Ä‰∫õÂõΩÈôÖÂ§¥ÈÉ®AIÂπ≥Âè∞ÂíåÂêà‰ΩúÊñπÂØπMiniMax-M2.1ÁöÑËØÑ‰ª∑„ÄÇ</p><div><div><div><p><a target="_blank" rel="noopener noreferrer" href="https://factory.ai/"><img alt="Factory AI (Droid)" loading="lazy" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/ab9f5f43-88d9-4a50-9c6b-a817eb509bd4.png"></a></p></div><p>Êàë‰ª¨ÈùûÂ∏∏ÊúüÂæÖÂÉè M2.1 ËøôÊ†∑Âº∫Â§ßÁöÑÂºÄÊ∫êÊ®°ÂûãÔºåÂÆÉÂú®ÂêÑÁ±ªËΩØ‰ª∂ÂºÄÂèë‰ªªÂä°‰∏≠ÈÉΩËÉΩÂ∏¶Êù•ÂâçÊ≤øÊ∞¥ÂáÜÁöÑË°®Áé∞ÔºåÁîöËá≥ËøòËÉΩÂú®ÈÉ®ÂàÜÂú∫ÊôØ‰∏ãÊØîÂ§¥ÈÉ®Èó≠Ê∫êÊ®°ÂûãÊõ¥Â•Ω„ÄÇÂºÄÂèëËÄÖÂ∫îÂΩìÊã•ÊúâÈÄâÊã©ÊùÉÔºåËÄå M2.1 Ê≠£ÊòØÂ§ßÂÆ∂ÊÄ•ÈúÄÁöÑÈÇ£‰∏™‰ºòË¥®ÈÄâÈ°πÔºÅ</p><div><p><span>E</span></p><div><p>Eno Reyes</p><p>Co-Founder, CTO of Factory</p></div></div></div><div><div><p><a target="_blank" rel="noopener noreferrer" href="https://fireworks.ai/"><img alt="Fireworks" loading="lazy" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/d4a5d010-bd28-432f-a20c-c967eadf62bd.png"></a></p></div><p>MiniMax M2.1 Âú®ÂèØËØªÊÄß‰∏éÊÉØÁî®ÁªìÊûÑÊñπÈù¢‰∏éÁîü‰∫ßÁ∫ßÂ∑•Á®ãË¶ÅÊ±ÇÈ´òÂ∫¶Â•ëÂêàÔºåÂú® Go„ÄÅRust„ÄÅC++ Á≠âÂ§öËØ≠Ë®ÄÂú∫ÊôØ‰∏ãÂùáË°®Áé∞Á®≥ÂÆö„ÄÇÁ≤æÁÇºÁöÑ‰∫§ÈîôÊé®ÁêÜÊú∫Âà∂ÊòæËëóÂéãÁº©ÈÄªËæëË∑ØÂæÑÔºåÂáèÂ∞ëÂÜó‰ΩôÊ≠•È™§ÔºåËÆ©Â§öÊñá‰ª∂ÈáçÊûÑ‰∏éÁº∫Èô∑‰øÆÂ§çÁ≠âÂ§çÊùÇ‰ªªÂä°Âæó‰ª•Êõ¥È´òÁ≤æÂ∫¶ÂÆåÊàê„ÄÇÊõ¥ÂèØË¥µÁöÑÊòØÔºåM2.1 Âú®ÊøÄÊ¥ªÂèÇÊï∞ÈáèÂèóÈôêÁöÑÂâçÊèê‰∏ã‰ªçËÉΩÊèê‰æõÂèØÈù†ÊÄßËÉΩÔºå‰∏∫Â§ßËßÑÊ®°Êô∫ËÉΩ‰ΩìÁºñÁ†ÅÊµÅÁ®ãÊèê‰æõ‰∫ÜÂÖºÈ°æÊïàËÉΩ‰∏éËµÑÊ∫êÂà©Áî®ÁöÑÂùáË°°ÊñπÊ°à„ÄÇÊàë‰ª¨ÊúüÂæÖ‰∏é MiniMax Âõ¢ÈòüÂ±ïÂºÄÊåÅÁª≠„ÄÅÁ¥ßÂØÜÁöÑÂêà‰ΩúÔºåÂú® Fireworks Âπ≥Âè∞ÂêåÊ≠•ÊîØÊåÅÂÖ∂ÊúÄÊñ∞ÂàõÊñ∞ÊàêÊûúÔºÅ</p><div><p><span>B</span></p><div><p>Benny Chen</p><p>Co-Founder of Fireworks</p></div></div></div><div><div><p><a target="_blank" rel="noopener noreferrer" href="https://cline.bot/"><img alt="Cline" loading="lazy" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/3cab5f2b-d6f7-4383-a43d-f34b05e4ec04.png"></a></p></div><p>MiniMax M2 Á≥ªÂàóÂú®‰ª£Á†ÅÁîüÊàêËÉΩÂäõ‰∏äË°®Áé∞Á™ÅÂá∫ÔºåËøáÂéªÂá†‰∏™ÊúàÂ∑≤ËøÖÈÄüË∑ªË∫´ Cline Âπ≥Âè∞ÊúÄÂèóÊ¨¢ËøéÁöÑÊ®°Âûã‰πãÂàó„ÄÇM2.1 ÂÜçÊ¨°ÂÆûÁé∞ËÉΩÂäõÂ±ÇÈù¢ÁöÑÊòæËëóË∑ÉÂçáÔºåÊàë‰ª¨ÊúüÂæÖ‰∏é MiniMax Âõ¢ÈòüÁªßÁª≠Ê∑±ÂåñÂêà‰ΩúÔºåÂÖ±ÂêåÊé®Ëøõ AI ÁºñÁ†ÅÊäÄÊúØÁöÑÊºîËøõ„ÄÇ</p><div><p><span>S</span></p><div><p>Saoud Rizwan</p><p>Founder, CEO of Cline</p></div></div></div><div><div><p><a target="_blank" rel="noopener noreferrer" href="https://kilo.ai/"><img alt="Kilo" loading="lazy" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/8618f6e3-caef-493c-a2df-aa42c0384593.png"></a></p></div><p>Êàë‰ª¨ÂØπM2.1ÁöÑÂèëÂ∏ÉËÄåÂÖ¥Â•ãÔºÅÊàë‰ª¨ÁöÑÁî®Êà∑Â∑≤ÁªèÁ¶ª‰∏çÂºÄMiniMaxÊèê‰æõÁöÑÊúÄ‰ºòÁßÄÁöÑÁºñÁ®ãËæÖÂä©ËÉΩÂäõÂíåÈ´òÊÄß‰ª∑ÊØîÔºåÂÜÖÊµãÊòæÁ§∫ÔºåM2.1Âú®Êû∂ÊûÑËÆæËÆ°„ÄÅÊúçÂä°ÁºñÊéí„ÄÅ‰ª£Á†ÅËØÑÂÆ°Áõ¥Ëá≥ÈÉ®ÁΩ≤‰∏äÁ∫øÁöÑÂÖ®ÈìæË∑ØÁéØËäÇ‰∏≠ÂùáË°®Áé∞‰ºòÂºÇÔºåÈÄüÂ∫¶‰∏éËµÑÊ∫êÊïàÁéáÂùáÂ§Ñ‰∫éÈ¢ÜÂÖàÊ∞¥Âπ≥„ÄÇ</p><div><p><span>S</span></p><div><p>Scott Breitenother</p><p>Co-Founder, CEO of Kilo</p></div></div></div><div><div><p><a target="_blank" rel="noopener noreferrer" href="https://roocode.com/"><img alt="RooCode" loading="lazy" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/1abfdf2b-0962-4131-848f-09a1b7b1188c.png"></a></p></div><p>Êàë‰ª¨ÁöÑÁî®Êà∑ÈùûÂ∏∏ÂñúÊ¨¢ MiniMax M2 Âú®ÁºñÁ†ÅËÉΩÂäõ‰∏éÊïàÁéáÊñπÈù¢ÁöÑË°®Áé∞„ÄÇÊúÄÊñ∞ÂèëÂ∏ÉÁöÑ M2.1 Âú®Ê≠§Âü∫Á°Ä‰∏äÂÆûÁé∞‰∫ÜÈÄüÂ∫¶‰∏éÂèØÈù†ÊÄßÁöÑÂÆûË¥®ÊÄßÊèêÂçáÔºåÂπ∂Âú®Êõ¥Â§öËØ≠Ë®ÄÂèäÊ°ÜÊû∂‰∏≠‰øùÊåÅÁ®≥ÂÆöËæìÂá∫„ÄÇÂØπ‰∫éÂº∫Ë∞ÉÈ´òÂêûÂêê„ÄÅAgentic Coding‰∏îÂØπÈÄüÂ∫¶‰∏éÊàêÊú¨ÊïèÊÑüÁöÑÁ†îÂèëÊµÅÁ®ãÔºåM2.1 ÊòØÁ®≥Â¶•‰∏îÂÖ∑ÊÄß‰ª∑ÊØîÁöÑÈÄâÊã©„ÄÇ</p><div><p><span>M</span></p><div><p>Matt Rubens</p><p>Co-Founder, CEO of RooCode</p></div></div></div><div><div><p><a target="_blank" rel="noopener noreferrer" href="https://www.blackbox.ai/"><img alt="BlackBox AI" loading="lazy" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/dc94e1df-2ce1-4955-ae3e-0bc2c82b71c4.png"></a></p></div><p>Â∞Ü MiniMax M2 Á≥ªÂàóÈõÜÊàêÂà∞BlackBoxÂπ≥Âè∞ÂØπÂπøÂ§ßÁî®Êà∑Êù•ËØ¥ÊòØ‰∏ÄÊ¨°Â∑®Â§ßÁöÑÂà©Â•ΩÔºÅËÄå M2.1 ÁöÑÈóÆ‰∏ñÔºåÊõ¥ÊòØÂÆö‰πâ‰∫ÜÁºñÁ®ã‰∏ìÁî®Ê®°ÂûãËÉΩÂäõÁöÑÊñ∞È´òÂ∫¶„ÄÇ Âú®ÂÆûÈôÖÊµãËØï‰∏≠ÔºåÊàë‰ª¨ÊÉäÂñúÂú∞ÂèëÁé∞ M2.1 Â§ÑÁêÜÂ§çÊùÇ„ÄÅÂ§öÊ≠•ÁºñÁ®ã‰ªªÂä°ÁöÑÁªÜËÖªÁ®ãÂ∫¶Âíå‰∏ÄËá¥ÊÄßÂú®ÂêåÁ±ªÊ®°Âûã‰∏≠ÊûÅÂÖ∂ÁΩïËßÅ„ÄÇÂá≠ÂÄüÂÖ∂ËßÑÊ®°ÂåñÊèê‰æõÁöÑÈ´òË¥®ÈáèÊé®ÁêÜÂíåÊ∑±Â∫¶‰∏ä‰∏ãÊñáÊÑüÁü•ËÉΩÂäõÔºåMiniMax Â∑≤ÁÑ∂Êàê‰∏∫Êàë‰ª¨Âä©ÂäõÂºÄÂèëËÄÖÊõ¥È´òÊïàÊîªÂÖãÊäÄÊúØÈöæÈ¢òÁöÑÊ†∏ÂøÉÂºïÊìé„ÄÇÊàë‰ª¨Â∑≤ÁªèËø´‰∏çÂèäÂæÖÂú∞ÊÉ≥ÁúãÂà∞ÂºÄÂèëËÄÖÁ§æÂå∫Â¶Ç‰ΩïÂà©Áî®Ëøô‰∫õÂçáÁ∫ßÂêéÁöÑÂº∫Â§ßËÉΩÂäõÔºåÂàõÈÄ†Âá∫Êõ¥Â§öÂèØËÉΩÔºÅ</p><div><p><span>R</span></p><div><p>Robert Rizk</p><p>Co-Founder, CEO of BlackBox AI</p></div></div></div></div><h2>Showcases</h2><div><div><h2>Áâ©ÁêÜ‰∏ñÁïåAgent</h2></div><div><h2>Áâ©ÁêÜ‰∏ñÁïåAgent</h2><p>Âú®Ê®°ÂûãÂÖ∑Â§áË∂≥Â§üÂ•ΩÁöÑÊ≥õÂåñÊÄß‰πãÂêéÔºåÂú®ËôöÊãü‰∏ñÁïå‰∏≠Â≠¶‰π†Âà∞ÁöÑÊ®°ÂûãÁ´üÁÑ∂ËøòÂèØ‰ª•È©±Âä®Áâ©ÁêÜ‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫ÔºåËøôÊúâ‰∫õÂá∫‰πéÊÑèÊñô„ÄÇ‰ª•‰∏ãÊòØM2.1È©±Âä®ÁöÑÁª¥‰ªñÂä®ÂäõÁöÑÊú∫Âô®Áãó„ÄÇ</p></div></div><div><div><h2>Â§öËØ≠Ë®Ä Coding</h2></div><div><div><h2>3D ‰∫§‰∫íÂºèÂä®Áîª</h2><p>MiniMax M2.1 Âü∫‰∫é React Three Fiber ‰∏é InstancedMesh ÊûÑÂª∫ÁöÑ‚Äú3D Ê¢¶ÂπªÂú£ËØûÊ†ë‚ÄùÔºåÊàêÂäüÊ∏≤Êüì 7000+ ÂÆû‰æãÔºåÊîØÊåÅÊâãÂäø‰∫§‰∫í‰∏éÂ§çÊùÇÁ≤íÂ≠êÂä®ÁîªÔºåÂ±ïÁé∞È´òÈöæÂ∫¶ 3D Ê∏≤ÊüìËÉΩÂäõ„ÄÇ<br>
<a href="https://yuyl27wq92.space.minimax.io/" target="_blank" rel="noopener noreferrer">‰ΩìÈ™åÂú∞ÂùÄ</a></p></div><div><h2>Web UI ÂâçÂç´ËÆæËÆ°</h2><p>M2.1 ÂèØ‰ª•ÁîüÊàêÊûÅÁÆÄ‰∏ª‰πâÊëÑÂΩ±Â∏à‰∏™‰∫∫‰∏ªÈ°µÔºåËøêÁî®ÈùûÂØπÁß∞Â∏ÉÂ±Ä‰∏éÈªëÁôΩÁ∫¢ÊíûËâ≤ËÆæËÆ°ÔºåÁªìÂêàÊ≤âÊµ∏ÂºèÂΩ±ÂÉèÂíåÁ≤óÁä∑ÊéíÁâàÔºåÂÆûÁé∞‰∫ÜÊûÅÂÖ∑ÂÜ≤ÂáªÂäõÁöÑËßÜËßâÊïàÊûú„ÄÇ</p></div><div><h2>ÂéüÁîü App ÂºÄÂèë - ÂÆâÂçì</h2><p>M2.1 ‰ΩøÁî® Kotlin ËØ≠Ë®ÄÂºÄÂèë‰∫Ü‰∏ÄÊ¨æÂÆâÂçìÂéüÁîüÈáçÂäõÊÑüÂ∫îÊ®°ÊãüÂô®ÔºåÂà©Áî®ÈôÄËû∫‰ª™‰º†ÊÑüÂô®ÂÆûÁé∞‰∏ùÊªëÁöÑÈáçÂäõÊìçÊéß‰ΩìÈ™åÔºåÂπ∂ËÆæËÆ°Â∑ßÂ¶ôÁöÑËßÜËßâÂΩ©ËõãÔºåÈÄöËøáËá™ÁÑ∂ÁöÑ UI ËøáÊ∏°‰∏éÁ¢∞ÊíûÁâπÊïàÔºå‰ºòÈõÖÂëàÁé∞‚ÄúMERRY XMAS MiniMax M2.1‚Äù‰ø°ÊÅØ„ÄÇ</p></div><div><h2>ÂéüÁîü App ÂºÄÂèë - iOS</h2><p>M2.1 ÁºñÂÜô‰∫Ü iOS Ê°åÈù¢‰∫§‰∫íÂ∞èÁªÑ‰ª∂ÔºåËÆæËÆ°‰∫Ü‚ÄúÊ≤âÁù°Âú£ËØûËÄÅ‰∫∫‚ÄùÁÇπÂáªÂî§ÈÜíÊú∫Âà∂ÔºåÈÄªËæëÂÆåÊï¥‰∏îÂÖ∑Â§áÂéüÁîüÁ∫ßÁöÑ‰∫§‰∫íÂä®ÁîªÊïàÊûú -- ‰Ω†ÁöÑÊ°åÈù¢Â∞èÁªÑ‰ª∂‰ΩèËøõ‰∫ÜÂú£ËØûËÄÅ‰∫∫‚Äî‚ÄîÁÇπ‰ªñÂçÅ‰∏ãÔºå‰ªñÂ∞±ÈÜíÊù•ÈÄÅ‰Ω†ÊÉäÂñúÔºÅ üéÖüéÅ
</p></div><div><h2>Web Èü≥È¢ëÊ®°ÊãüÂºÄÂèë</h2><p>M2.1 Âü∫‰∫é Web Audio API ÂºÄÂèë‰∫Ü 16 Ê≠•ÈºìÊú∫Ê®°ÊãüÂô®ÔºåÈõÜÊàê‰∫ÜÂêàÊàêÈºìÂ£∞„ÄÅÈùûÁ∫øÊÄßËäÇÂ•èÁÆóÊ≥ï‰∏éÂÆûÊó∂ Glitch Èü≥ÊïàÔºåÊèê‰æõ‰∫ÜÂâçÂç´ÁöÑÁîµÂ≠êÈü≥‰πê‰ΩìÈ™åÔºÅÔºàÂèØ‰ª•ÂºÄÂêØ‰ª•‰∏ãËßÜÈ¢ëÁöÑÂ£∞Èü≥ËØïÂê¨ÔºÅÔºâ<br>
<a href="https://21okxwno2u.space.minimax.io/" target="_blank" rel="noopener noreferrer">‰ΩìÈ™åÂú∞ÂùÄ</a></p></div><div><h2>Rust ÂÆâÂÖ®ÂÆ°ËÆ° TUI</h2><p>M2.1 Áî® Rust ÊâìÈÄ†‰∫Ü CLI + TUI ÂèåÊ®°ÂºèÁöÑ Linux ÂÆâÂÖ®ÂÆ°ËÆ°Âà©Âô®ÔºåÊîØÊåÅ‰∏ÄÈîÆÂØπËøõÁ®ã„ÄÅÁΩëÁªú„ÄÅSSH Á≠âÂÖ≥ÈîÆÈ°πÁöÑÂ∫ïÂ±ÇÊâ´Êèè‰∏éÊô∫ËÉΩÈ£éÈô©ËØÑÁ∫ß„ÄÇ</p></div><div><h2>Python Êï∞ÊçÆÁõëÊéßÁúãÊùø</h2><p>M2.1 Âü∫‰∫é Python ÂºÄÂèë‰∫ÜÈªëÂÆ¢Â∏ùÂõΩÈ£éÊ†ºÁöÑÂÆûÊó∂Êï∞ÊçÆÁõëÊéßÈù¢ÊùøÔºåÂÆûÁé∞‰∫ÜÂØπÈ´òÈ¢ëÊï∞ÊçÆÊµÅÁöÑÂä®ÊÄÅÊçïÊçâ‰∏éÊ∏≤Êüì„ÄÇËØ•Èù¢ÊùøÂ∞ÜÊ†∏ÂøÉÊåáÊ†áËΩ¨Âåñ‰∏∫ËµõÂçöÊúãÂÖãËßÜËßâÁ¨¶Âè∑ÔºåÂú®Êª°Ë∂≥ÂÆûÊó∂ÁõëÊéßÁ≤æÂáÜÂ∫¶ÁöÑÂêåÊó∂ÔºåÂëàÁé∞‰∫ÜÁã¨ÁâπÁöÑÁßëÂπªÁæéÂ≠¶„ÄÇ</p></div><div><h2>C++ Âà∂‰ΩúÂõæÂÉèÊ∏≤Êüì</h2><p>M2.1 Âà©Áî® C++ ‰∏é GLSL ÂÆûÁé∞‰∫ÜÂ§çÊùÇÂÖâÁ∫ø‰º†ËæìÁÆóÊ≥ïÔºåÂú®ÂÆûÊó∂ÁéØÂ¢É‰∏ãÁ≤æÂáÜËøòÂéü‰∫ÜÊ∞¥Êô∂ÁêÉÁöÑÁâ©ÁêÜÊäòÂ∞Ñ„ÄÅSDF ÁªÜËá¥Âª∫Ê®°ÁöÑÈõ™‰∫∫‰ª•ÂèäÊ≥¢ÂÖâÁ≤ºÁ≤ºÁöÑÈõ™Âú∞ÁâπÊïà„ÄÇ</p></div><div><h2>Java Âà∂‰ΩúÂÆûÊó∂ÂºπÂπï</h2><p>M2.1 Âü∫‰∫é Java ÂÆûÁé∞‰∫ÜÈ´òÊÄßËÉΩÂÆûÊó∂ÂºπÂπïÁ≥ªÁªüÔºåÁÆÄÊ¥ÅÁõ¥ËßÇÁöÑÁî®Êà∑ÁïåÈù¢ÂèäÊØ´ÁßíÁ∫ßÂìçÂ∫îËÉΩÂäõ„ÄÇ</p></div><div><h2>SVG ÁîüÊàê</h2><p>M2.1 ÁîüÊàê‰∫Ü SVG ‰∫§‰∫íÂºèÁ≠âËΩ¥È£éÊ†ºÂ≤õÂ±øÂú∞ÂõæÔºåÊûÑÂª∫‰∫ÜÁªÜËäÇ‰∏∞ÂØåÁöÑÂæÆÁº©‰∏ñÁïåÔºåÊîØÊåÅ‰∏ÄÈîÆÁº©ÊîæËá™Áî±Êé¢Á¥¢ÂõõÂ§ß‰∏ªÈ¢òÂå∫Âüü„ÄÇ</p></div></div></div><div><div><h2>Agentic Tool Use</h2></div><div><h2>Tool useÔºàÂ∑•ÂÖ∑Ë∞ÉÁî®ÔºâËÉΩÂäõÔºöexcel Â∏ÇÂú∫Ë∞ÉÁ†î</h2><p>M2.1 Â±ïÁ§∫‰∫Ü Tool use ËÉΩÂäõÔºåËá™‰∏ªË∞ÉÁî® Excel Â∑•ÂÖ∑Âíå yahoo finance Â∑•ÂÖ∑ÂÆåÊàê‰∫Ü‰ªéÂ∏ÇÂú∫Ë∞ÉÁ†îÊï∞ÊçÆÊ∏ÖÊ¥ó„ÄÅÂàÜÊûêÂà∞ÂõæË°®ÁîüÊàêÁöÑÂÖ®ÊµÅÁ®ã‰ªªÂä°„ÄÇ</p></div></div><h2>Êï∞Â≠óÂëòÂ∑•</h2><p>Êï∞Â≠óÂëòÂ∑•ÊòØ MiniMax M2.1 Ê®°ÂûãÁöÑÈáçË¶ÅÂäüËÉΩ‰πã‰∏Ä„ÄÇM2.1 ËÉΩÂ§üÊé•Âèó‰ª•ÊñáÂ≠óÂΩ¢ÂºèÂ±ïÁ§∫ÁöÑÁΩëÈ°µÂÜÖÂÆπÔºåÂπ∂‰ª•ÊñáÊú¨ÂΩ¢ÊÄÅÁöÑËæìÂÖ•ÊéßÂà∂Èº†Ê†áÁöÑÁÇπÂáªË°å‰∏∫ÂíåÈîÆÁõòËæìÂÖ•ÔºåÂú®Êó•Â∏∏ÂäûÂÖ¨Âú∫ÊôØ‰∏ãÔºåÂÆåÊàêË°åÊîø„ÄÅÊï∞ÊçÆÁßëÂ≠¶„ÄÅË¥¢Âä°„ÄÅ‰∫∫ÂäõËµÑÊ∫ê„ÄÅËΩØ‰ª∂ÂºÄÂèëÁ±ªÁöÑÁ´ØÂà∞Á´Ø‰ªªÂä°„ÄÇ<br>
‰ª•‰∏ãÊïàÊûúÊºîÁ§∫ÊòØ M2.1 Âú® AgentCompany Benchmark ‰∏≠ÁöÑË°å‰∏∫ËΩ®ËøπËÆ∞ÂΩï„ÄÇ</p><div><div><h2>ÂÖ®ÈìæË∑ØÂäûÂÖ¨Ëá™Âä®Âåñ</h2></div><div><div><h2>ÊïàÊûúÊºîÁ§∫1</h2><p>Âú®ÈÄöËÆØËΩØ‰ª∂‰∏ä‰∏ªÂä®Êî∂ÈõÜÂëòÂ∑•ÁöÑËÆæÂ§áËØ∑Ê±ÇÔºåÁÑ∂ÂêéÂâçÂæÄ‰ºÅ‰∏öÂÜÖÈÉ®ÊúçÂä°Âô®‰∏äÊêúÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£Ëé∑ÂèñËÆæÂ§á‰ª∑Ê†ºÔºåËÆ°ÁÆóÊÄªÊàêÊú¨Âπ∂Âà§Êñ≠ÈÉ®Èó®È¢ÑÁÆóÊòØÂê¶ÂÖÖË∂≥ÔºåÁÑ∂ÂêéËÆ∞ÂΩïËÆæÂ§áÂèòÊõ¥„ÄÇ</p></div><div><h2>ÊïàÊûúÊºîÁ§∫2</h2><p>Âú®È°πÁõÆÁÆ°ÁêÜËΩØ‰ª∂‰∏äÊü•ÊâæË¢´ÈòªÂ°ûÊàñÁßØÂéãÁöÑÈóÆÈ¢òÔºåÁÑ∂ÂêéÂú®ÈÄöËÆØËΩØ‰ª∂‰∏äÊü•ÊâæÁõ∏ÂÖ≥ÂëòÂ∑•Âπ∂Âí®ËØ¢Ëß£ÂÜ≥ÊñπÊ°àÔºåÊ†πÊçÆÂëòÂ∑•ÂèçÈ¶àÊõ¥Êñ∞ÈóÆÈ¢òÁöÑÁä∂ÊÄÅ„ÄÇ</p></div><div><h2>ÊïàÊûúÊºîÁ§∫3</h2><p>Âú®‰ª£Á†ÅÂ∫ì‰∏≠Êü•ÊâæÁ≠îÊ°àÔºöÊüêÂêå‰∫ãÂ∏åÊúõÁü•ÈÅìÊîπÂä®‰∫ÜÊüê‰∏™Êñá‰ª∂ÁöÑÊúÄËøëÁöÑÂêàÂπ∂ËØ∑Ê±ÇÊòØÂì™‰∏Ä‰∏™ÔºåÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑÂêàÂπ∂ËØ∑Ê±ÇÔºåÊâæÂà∞ÁºñÂè∑Âπ∂ÂëäÁü•ËØ•Âêå‰∫ã„ÄÇ</p></div></div></div><div>

  <h2>
    Â¶Ç‰Ωï‰ΩøÁî®
  </h2>
  
  <ul>
    <li>
      MiniMax-M2.1 API Â∑≤Âú® <strong>MiniMaxÂºÄÊîæÂπ≥Âè∞</strong> ÂºÄÊîæ‰ΩøÁî®Ôºö<a href="https://platform.minimaxi.com/docs/guides/text-generation" target="_blank" rel="noopener noreferrer">https://platform.minimaxi.com/docs/guides/text-generation</a>
    </li>
    <li>
      Âü∫‰∫é MiniMax-M2.1 ÁöÑÈÄöÁî® Agent ‰∫ßÂìÅ <strong>MiniMax Agent</strong> Áé∞Â∑≤ÂÖ®Èù¢ÂºÄÊîæ‰ΩøÁî®Ôºö<a href="https://agent.minimaxi.com/" target="_blank" rel="noopener noreferrer">https://agent.minimaxi.com/</a>
    </li>
    <li>
      ÂºÄÊ∫ê‰ª•ÂèäÊú¨Âú∞ÈÉ®ÁΩ≤‰ΩøÁî®Ôºö
<a href="https://huggingface.co/MiniMaxAI/MiniMax-M2.1" target="_blank" rel="noopener noreferrer">https://huggingface.co/MiniMaxAI/MiniMax-M2.1</a> 
   <br>
<a href="https://github.com/MiniMax-AI/MiniMax-M2.1" target="_blank" rel="noopener noreferrer">https://github.com/MiniMax-AI/MiniMax-M2.1</a>




 </li>
  </ul>

  <p>
    ‰∏∫‰∫ÜÊñπ‰æøÁî®Êà∑‰ΩøÁî®, Êàë‰ª¨Êèê‰æõ‰∫Ü‰∏§‰∏™ÁâàÊú¨ÁöÑ API, M2.1 Âíå M2.1-lightning„ÄÇËøô‰∏§‰∏™ API ÁªìÊûúÂÆåÂÖ®‰∏ÄÊ†∑, ‰ΩÜÊòØÂêéËÄÖÈÄüÂ∫¶Êõ¥Âø´, Êñπ‰æøÂØπ TPS ÊúâÈúÄÊ±ÇÁöÑÁî®Êà∑Êù•‰ΩøÁî®„ÄÇÂêåÊó∂, Âú® M2 ÊâãÂä® Cache ÁöÑÂü∫Á°Ä‰∏ä, M2.1 ÂÖ®Èù¢ÊîØÊåÅËá™Âä® Cache, Êó†ÈúÄËÆæÁΩÆ, Ëá™Âä®ÁîüÊïà, ‰∏∫ÂºÄÂèëËÄÖÂ∏¶Êù•Êõ¥ÊµÅÁïÖÁöÑ‰ΩìÈ™å„ÄÅÊõ¥‰ΩéÁöÑÊàêÊú¨‰∏éÊõ¥‰ºòÁöÑÂª∂Êó∂Ë°®Áé∞„ÄÇ
  </p>
  
  <p>
    Êàë‰ª¨Âú® Coding Plan ÈáåÈù¢‰ºöÊ†πÊçÆËµÑÊ∫êË¥üËΩΩÁªôÁî®Êà∑Êèê‰æõÂ§ßÊØî‰æãÁöÑ M2.1-lightning, Âπ∂‰øùÊåÅ Coding Plan ÁöÑ‰ª∑Ê†º‰∏çÂèò„ÄÇ‰πüÂ∞±ÊòØËØ¥, Coding Plan Áî®Êà∑ÂÖçË¥πËé∑Âæó‰∫ÜÂ§ßÈÉ®ÂàÜÊó∂Èó¥Êõ¥Âø´ÁöÑÊé®ÁêÜÈÄüÂ∫¶„ÄÇ<a href="https://platform.minimaxi.com/subscribe/coding-plan" target="_blank" rel="noopener noreferrer">Ê¨¢ËøéÂ§ßÂÆ∂ÁÇπÂáª‰∏ãÂçï~</a>
  </p>

</div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/83b98c98-a82f-4964-b5b0-3057472aa0f7.webp"></p></div><h3>ËÅîÁ≥ªÊàë‰ª¨</h3><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" src="https://filecdn.minimax.chat/public/273f3442-f89d-4e02-b10b-4dc174a67242.png"></p></div></main><main><div><p><img alt="logo" loading="lazy" width="200" height="64" decoding="async" data-nimg="1" src="https://filecdn.minimax.chat/public/6bef0882-3057-455c-a4ad-2f63ed292be2.png?x-oss-process=image/format,webp"></p></div></main></div></div>]]></description>
        </item>
    </channel>
</rss>