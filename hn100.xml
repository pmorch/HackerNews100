<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 08 Nov 2023 13:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hard-to-swallow truths they won't tell you about software engineer job (211 pts)]]></title>
            <link>https://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/</link>
            <guid>38188689</guid>
            <pubDate>Wed, 08 Nov 2023 10:41:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/">https://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/</a>, See on <a href="https://news.ycombinator.com/item?id=38188689">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>Last weekend I had a chance to talk with some students who just got their degree. They are pursuing their first software engineer job. In conversation with them, I learned that they have a pretty wrong perception of this job.</p><p>This is because the reality for these new kids is so skewed. They only see good pay, remote work, team building, and pizza parties. </p><p>These are all good perks, but no one is talking to them about the real things that we do in this job. </p><p>As someone who spent a lot of years in this industry, I gave them a slap of reality in the face. I told them good things but also some hard-to-swallow truths. </p><p>After reading this article, some people will say I am talking overly negatively about it. but my opinion is that these things go together with the job and you have to accept it.</p><h2 id="1-college-will-not-prepare-you-for-the-job">1) College will not prepare you for the job</h2><p>This is the first thing I explained to these guys. </p><p>To precisely describe how college will prepare you for the job imagine that you are learning how to swim. </p><p>Your instructor spends a huge amount of time to describe you all the moves you need to make. He makes you recite all those moves, asks you questions about it and you have exams about it. But you never touch the water.</p><p>After 5 years, you get a piece of paper that proves your swimming skills. Then the day comes, and you have to swim now. The guys in the swimming place just kick you into the water.</p><p>You have a hard time breathing, you fight for your life. Maybe you will drown, maybe you will manage to swim.</p><p>That's what the first 6 months look like for a freshly graduated student in a software engineer job.</p><p>The college will prepare you for some basics, but what most of the colleges teach is so far away from day-to-day jobs. Most of the professors who teach at universities are not good software engineers. </p><p>Only a small percentage of them even worked as software engineers. Also, the university curriculums are heavily outdated. They trot years behind the software development market needs.</p><p>You have to put in extra work while you are in college. Code more projects besides homework and seminars. Do some volunteering. Learn about business domains to prepare for the job that awaits you. </p><p>Most of the students don't do that. They wait until they get their diploma to start working on their portfolio.</p><h2 id="2-you-will-rarely-get-greenfield-projects">2) You will rarely get greenfield projects</h2><p>In college or boot camps, you get a lot of smaller assignments that you write from scratch. Total freedom to express yourself. You can implement all the fancy stuff you learn, like algorithms or design patterns. </p><p>The time you spend on those assignments is at most a few weeks, but mostly a couple of days of work. Typically those assignments contain at most 500 lines of code.</p><p>In day to day job you are working with projects that contain multiple layers and thousands of lines of code. Multiple people work at the same time on those projects. You have limited freedom, you have to adapt to the project. The time you spend on projects is usually half a year to a couple of years.</p><p>Sometimes you spend a whole week fixing the nasty bug. The fix is just a couple of lines of code. You talk with your colleagues. You exchange information about the project. You collaborate with them to get approval for your solution.</p><p>New projects are rare, and most of the time you work on existing projects. You can consider yourself lucky if you get the normal project and not some old legacy project.</p><figure><img src="https://www.mensurdurakovic.com/content/images/2023/10/image-2-1.png" alt="" loading="lazy" width="768" height="6088" srcset="https://www.mensurdurakovic.com/content/images/size/w600/2023/10/image-2-1.png 600w, https://www.mensurdurakovic.com/content/images/2023/10/image-2-1.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="3-nobody-gives-a-f-about-your-clean-code">3) Nobody gives a f*** about your clean code</h2><p>You can forget that your boss will tell you: "Congratulations on writing this elegant and clean code, I am gonna give you a raise!". Quite the opposite, nobody cares about your clean code. </p><p>Don't get me wrong, people will expect you to write good and clean code. Still, you will rarely get any praise for it. Except sometimes from your colleagues who will review your code.</p><p>This may be a shock for some new folks, but it makes perfect sense. As a software engineer, your primary task is to generate value for users. Writing code is just a step that accomplishes that goal. </p><p>You can think of it as the following cycle:</p><ul><li>software engineer writes code</li><li>users get new features</li><li>more users use your products</li><li>company profits from products</li></ul><p>So code is just a tool to get profit. </p><p>I have seen so many graveyards of projects, with horrible legacy codebases. Still, these projects are successful as they have fancy landing pages and solve user's problems. So users are happy to pay for using them.</p><p>The user doesn't know how the codebase looks. The user just sees what features that product is offering. So don't get overly attached to your clean and elegant code. Focus on shipping the feature on time and bug-free.</p><h2 id="4-you-will-sometimes-work-with-incompetent-people">4) You will sometimes work with incompetent people</h2><p>People have prejudices that only smart and competent people work in the IT industry. Especially the software development branch. But this is far from the truth. </p><p>As in every job, you will sometimes have incompetent people in your environment. Working with them is very frustrating. They waste so much time and create a toxic environment. On top of that, they are extremely unproductive. All this reflects on deadlines and produces delays. This costs companies money and resources.</p><p>Unfortunately, I also had experience working with those kinds of people. I have to say, they tested my nerves so well that I spent a good amount of time thinking of ways to get around their incompetence.  </p><p>Here are some advice:</p><ul><li>try to be efficient and productive as much as you can, focus on yourself and not on them</li><li>try other options/solutions that don't involve that person in the process</li><li>document everything you do. If things go wrong, you will have proof of their incompetence</li><li>if you have a blocker because that person didn't do their job, try to ask someone else to unblock you  (if it's possible)</li><li>talk directly to them, be professional but not mean, and tell them what and how they can improve</li></ul><p>Remember that there is no need to be a jerk to them. </p><p>Sometimes you don't know the whole story. I have seen some cases where a person just can't do their job properly. They are burdened with tons of tasks and doing work for 2 people.</p><h2 id="5-get-used-to-being-in-meetings-for-hours">5) Get used to being in meetings for hours </h2><p>Meetings are an important part of the software development job. Some of them are good, but some of them are just time wasters. </p><p>There are recurring meetings scheduled on a daily or weekly basis. Most of these are not productive. The majority of them are forced by a person who is organizing them because that's the only "work" that that person is doing. </p><p>It's just an empty protocol to prove their purpose of existence in the company.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/UDpKWVuBNQE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Meeting | MonkeyUser 5SP Animation"></iframe></figure><p>On the other hand, there are productive meetings. Those meetings ensure information exchange between team members or different teams. </p><p>The majority of software engineers hate meetings. But remember that your job is also to communicate about things openly and proactively. </p><p>Sharing information is crucial for projects to move forward. When you share information it can help other teams to better understand what you are doing and the opposite. </p><h2 id="6-they-will-ask-you-for-estimates-a-lot-of-times">6) They will ask you for estimates a lot of times</h2><p>Business revolves around numbers. Every project has its cost, and to calculate the cost, management needs to estimate how long it will take to build a certain feature.</p><p>Then, it goes down to software engineers to estimate their work. Usually, estimates are time-based, but sometimes they also ask for complexity estimates. </p><p>In a lot of situations, you will have no clue how long it will take to build something. You read requirements, do some research and you give a number. </p><figure><img src="https://www.mensurdurakovic.com/content/images/2023/10/image-6.png" alt="" loading="lazy" width="1600" height="987" srcset="https://www.mensurdurakovic.com/content/images/size/w600/2023/10/image-6.png 600w, https://www.mensurdurakovic.com/content/images/size/w1000/2023/10/image-6.png 1000w, https://www.mensurdurakovic.com/content/images/2023/10/image-6.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>Later, when you start to work on that feature, you encounter many problems that you weren't aware of when you gave time estimates. Then you need to compensate for the wasted and hope not to break the deadline.</p><p>That's why it's always good to underpromise but overdeliver. </p><p>For example, when your project manager asks you to implement feature X by Friday, you won't say "Oh, I can finish it by Tuesday". Instead, you will say: "Sure, no problem". </p><p>Why?</p><p>Because if you promise to deliver it by Tuesday and you run into some problems, you won't be able to fulfill the promise. Instead, if you accept Friday as a deadline, and you finish it by Wednesday, you can deliver it 2 days earlier. </p><p>There are a lot of formulas on how to do estimates, and everyone has their own rules. I also have my own rules. </p><p>If I need to deliver some feature, and I think it will take 2 days, I add roughly 40% more time to it, just to be safe. So, in this case, the estimate will be 3 days. Later, if I am done in 2 days, I can just deliver it earlier.</p><h2 id="7-bugs-will-be-your-arch-enemy-for-life">7) Bugs will be your arch-enemy for life</h2><p>The more you code, the more you are aware that bugs in the code are everywhere. When you are just starting with programming, you think you will code something, it will work fine and it's the end of the story.</p><p>But in reality, it's a different story. There are countless things that can produce bugs:</p><ul><li>your own code - humans make mistakes, and you should not trust that code is working perfectly. You can write tests, but bugs can occur after that due to various reasons that you aren't even aware of.</li><li>3rd party libraries - those libraries are also written by software engineers like you and me. Always watch for activity and how frequently those libraries are updated.</li><li>hardware failure - software relies on hardware. Mark Hanna explained what your software is without hardware in his quote: "It's fugayzi, fugazi. It's a whazy. It's a woozie. It's fairy dust. It doesn't exist. It's never landed. It is no matter. It's not on the elemental chart. It's not f***ing real."</li></ul><figure><img src="https://media.tenor.com/Zbfjs-GE8p0AAAAC/rookie-numbers.gif" alt="" loading="lazy" width="498" height="289"></figure><ul><li>electricity - yep, hardware needs electric power to run, without it, it's useless. I worked on one project with Raspberry Pi. The client had constant problems with the device turning off at random times. After days of investigation, we finally found out the issue. He used a different power supply than the original one provided. Because of that device was turning off at random times.</li></ul><p>So the truth is you should assume that everything has bugs. That's why experienced devs never trust their code if it runs successfully on the first try. Even if the QA engineer reports a bug, assume that the bug ticket has a "bug" and check for everything.</p><h2 id="8-uncertainty-will-be-your-toxic-friend">8) Uncertainty will be your toxic friend</h2><p>In this job, you will feel uncertainty almost all the time. </p><p>I already explained the estimates example above. That's just one example where you feel uncertainty. You give your best shot but you are not 100% sure you can finish the work in that estimate.</p><p>Besides that, there are countless other things that are uncertain. Here are some examples:</p><ul><li>implementing something in your project you never worked with, eg. 3rd party API - how are you going to implement something you aren't familiar with</li><li>transfer to a new project, with new technologies - you will think about how you are going to be efficient and productive with something you need to learn</li><li>move to a new company - you are unsure how you are going to settle in and vibe with new people</li><li>bug report on the day you need to finish the work - you fear that you are gonna break the deadline</li><li>job security - economic situations, pandemics, wars, and other factors heavily affect this industry which results in layoffs</li><li>the evolution of technology - you are never sure if tomorrow you are gonna be replaced by some new technologies like AI</li></ul><p>The good thing about uncertainty is that drives you to be a better software engineer. It demands improvements and learning if you want to stay in the game.</p><h2 id="9-it-will-be-almost-impossible-to-disconnect-from-your-job">9) It will be almost impossible to disconnect from your job</h2><p>From time to time, I catch myself thinking about my job, problems, and bugs. Or things I have to do tomorrow when I should relax and chill. </p><p>Sometimes, cold water in the shower wakes me up from my thinking about how I am gonna fix the nasty bug I worked on yesterday. I had countless squabbles with my girlfriend about why I am on Slack when we are on the beach. </p><p>So I publicly admit, that I have a hard time disconnecting from work. </p><p>It's especially hard to disconnect when you are working from home. If your laptop is on, you can always check emails or Slack messages.</p><p>So to avoid all this:</p><ul><li>I turn off my laptop after I am done with the work,</li><li>I put quiet hours on my mobile phone for my business emails</li><li>I pause Slack notifications after working hours. I disable them on weekends.</li><li>When my mind gets into this "think about work" loop, I try to immediately cut it out. I remind myself that rest and relaxation are important to be productive. </li><li>I take long walks after work. On some days I do sports like padel or football. </li><li>I try to engage socially as much as I can, avoiding screen time after work.</li></ul><p>Still, with all these steps I do every day, I fail a lot of times.</p><h2 id="10-you-will-profit-more-from-good-soft-skills-than-from-good-technical-skills">10) You will profit more from good soft skills than from good technical skills</h2><p>Technical skills are the ones you can learn easily. With different projects, you can understand a particular programming language. You can learn its syntax, pros and cons. It's just a matter of practice.</p><p>On the other hand, soft skills are much harder to improve. Improvement takes a lot of mental strength. You must do things you are not comfortable with. </p><p>You have to put yourself in situations where you can improve or practice particular soft skills.</p><p>For example, communication is one soft skill that people always talk about. Let's say you suck at public speaking. You have to force yourself into situations where you can practice some public speaking.</p><p>It's very hard to intentionally put yourself into situations where you know you will suck at. Your mind will do everything to avoid those situations. It will bring hundreds of excuses and it's easy to give up.</p><p>Besides communication, there are other <a href="https://www.mensurdurakovic.com/boost-your-career-with-top-ten-soft-skills/" rel="noreferrer">soft skills</a>:</p><ul><li>teamwork</li><li>learning mindset</li><li>organization/time management</li><li>emotional intelligence/empathy</li><li>approachability</li><li>persistence/patience</li><li>confidence</li></ul><p>I have met a lot of folks who are good with technical skills but awful to work with.</p><p>For example, one colleague would ask me for help a lot of times. I helped him a couple of times. Then, I noticed after we fixed his problems, he would come back to me and blame me for messing up other things on the project. Then I had to spend more time with him fixing stuff I wasn't even aware of. And because he was blaming me with such a bad tone, I stopped helping him. I would say that I have a lot on my plate to do, so I can help him tomorrow. </p><p>Another example, I was the new guy on the project. A colleague (let's call him George) was assigned to help me with anything I needed. I set up the project pretty much by myself, but there was one error I was getting when I tried to run the project. I asked George for help. He spent maybe 2 minutes with me in total to solve a problem and said that he didn't know the solution. I thanked him anyway, tried to solve the error on my own but finally succeded with the help of colleague Michael. On daily standup, George said that he spent his whole day supporting me. I never asked George for help, after that. </p><p>One more example, there was one colleague who was the main man on the project. Still, the whole team hated him (other devs, project managers, QA, designers, etc). He was a good software engineer, but a real jerk. Extremely rude in communication with everyone. He never wanted to admit he was wrong or accept constructive criticism of his code. Management tolerated him as he was always the loudest one in the room. When he finally resigned, the whole team was celebrating. </p><p>With good soft skills, people will like you more and you have a better chance of getting a raise or promotion. If you are technically gifted but hard to work with, your chances are slightly reduced.</p><p>Also, with good soft skills, people who know you will spread a good word behind your back. They can recommend you for the job, without even you knowing about it.</p><h2 id="conclusion">Conclusion</h2><p>Software development is not a dream job. </p><p>Working in software engineering often means long working hours. Most of the time, you are glued to a computer screen, with little work-life balance. </p><p>The job demands an online presence, sometimes even after work hours. This often leads to stress and limited personal time. </p><p>Additionally, job satisfaction is frequently hindered by tedious tasks. Depending on the situation you have limited career growth prospects. There is also potential isolation in remote work.  And there is always a threat of job insecurity due to rapidly evolving technology.</p><p>But, there is also positive stuff.</p><p>Software development nurtures continuous innovation. Software engineers can create attractive applications and solve interesting problems.</p><p>The global demand for software solutions across diverse industries is big. This means there is always a demand for good software engineers. Software development careers provide flexibility with remote work options. </p><p>It's one big blessing to work from any location. Flexibility allows you to sleep in the morning without an alarm. You can work from your home in comfy pajamas. Also, you don't waste your precious time and money on commuting.</p>
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Home Assistant blocked from integrating with Garage Door opener API (170 pts)]]></title>
            <link>https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/</link>
            <guid>38188162</guid>
            <pubDate>Wed, 08 Nov 2023 09:04:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/">https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/</a>, See on <a href="https://news.ycombinator.com/item?id=38188162">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article>
<header>


</header>
<p><strong>TL;DR:</strong> The MyQ integration will be removed from Home Assistant in release 2023.12 on December 6, 2023. Chamberlain Group, the owners of MyQ, have released a public statement saying they will continue blocking access to third-party apps, like the MyQ integration. For current MyQ users we recommend <a href="https://paulwieland.github.io/ratgdo/" rel="external nofollow">ratgdo</a>, a device that physically connects to your MyQ garage door opener and allows you to control it locally.</p>
<p>If you own a garage door opener from Chamberlain or Liftmaster, you are probably familiar with MyQ. Itâ€™s a cloud-based smart home brand owned by Chamberlain Group, best known for its smart garage devices. MyQ is also currently one of the most problematic integrations for Home Assistant users. The MyQ garage door opener integration has, for the past months, been in a state of <a href="https://community.home-assistant.io/t/the-current-state-of-myq-from-the-codeowner/630623">constant repair</a> as the integration breaks, is fixed, and then breaks again. This is a direct result of actions taken by MyQ to block access from third parties.</p>
<a name="read-more"></a>
<p>Last month, Chamberlain Group put out a <a href="https://chamberlaingroup.com/press/a-message-about-our-decision-to-prevent-unauthorized-usage-of-myq" rel="external nofollow">statement</a> by their CTO, Dan Phillips, on this matter:</p>
<blockquote>
<p>Chamberlain Group recently made the decision to prevent unauthorized usage of our myQ ecosystem through third-party apps. This decision was made so that we can continue to provide the best possible experience for our 10 million+ users, as well as our authorized partners who put their trust in us. We understand that this impacts a small percentage of users, but ultimately this will improve the performance and reliability of myQ, benefiting all of our users.</p>
</blockquote>
<p>This <em>â€˜unauthorized usageâ€™</em> appears to refer to the MyQ integration for Home Assistant which was added to Home Assistant in February, 2017. We have reached out to Chamberlain Group in several ways to see if we can come to an understanding, but we have not received an official response. We can only assume that this means Chamberlain Group has made its decision and will force customers to use only the MyQ app or those of their authorized partners.</p>
<p>You may wonder if Home Assistant could become an authorized partner. In their partner program, the partner companies pay Chamberlain Group for the privilege of letting MyQ owners control their own garage doors. We are open to working together with Chamberlain Group, but as Home Assistant is an open-source project, we cannot pay a partnership fee. Not only is this financially not viable, it also goes against our values. MyQ users should be able to access the devices they paid for and the data they own in any way they want, without a third party having to pay an additional fee.</p>
<p>So, to quote the maintainer of the MyQ integration, <a href="https://github.com/Lash-L" rel="external nofollow">Lash-L</a>:</p>
<blockquote>
<p>We are playing a game of cat and mouse with MyQ and right now it looks like the cat is winning.</p>
</blockquote>
<p>Once a company decides to be hostile to its customers, the only way we can win is by not playing their game at all. Do not buy products or services from companies that treat their customers this way. Tell your friends not to deal with companies that treat their customers this way. Buy products that work locally and wonâ€™t stop functioning when management wants an additional revenue stream.</p>
<p>Because we cannot continue to work around Chamberlain Group if they keep blocking access to third parties, the MyQ integration will be removed from Home Assistant in the upcoming 2023.12 release on December 6, 2023. We are very disappointed that it has come to this and sincerely hope that Chamberlain Group is willing to reconsider its position. We would happily welcome this integration back if Chamberlain Group would work with us for the good of their customers.</p>
<p>For now, if you are a MyQ owner, weâ€™re afraid you are in the â€˜small percentage of usersâ€™ Chamberlain Group refuses to serve. We recommend buying <a href="https://paulwieland.github.io/ratgdo/" rel="external nofollow">ratgdo</a>.</p>
<p>Ratgdo is a fully local, ESPHome-based, solution that is compatible with MyQâ€™s security+ protocol and can be installed on an existing MyQ system by connecting three wires. It offers the same garage door controls that MyQ does and even adds features that MyQ does not have, like motion events, controlling the light, and locking out wired remotes.</p>
</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop making every conversation about yourself (160 pts)]]></title>
            <link>https://thoguhts.substack.com/p/stop-making-every-conversation-about</link>
            <guid>38187430</guid>
            <pubDate>Wed, 08 Nov 2023 06:39:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoguhts.substack.com/p/stop-making-every-conversation-about">https://thoguhts.substack.com/p/stop-making-every-conversation-about</a>, See on <a href="https://news.ycombinator.com/item?id=38187430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw"><img src="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:4000,&quot;width&quot;:6000,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;man in black jacket standing beside body of water during sunset&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="man in black jacket standing beside body of water during sunset" title="man in black jacket standing beside body of water during sunset" srcset="https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1586806974856-c55e8b9364e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNXx8dGFsa2luZ3xlbnwwfHx8fDE2OTgzODk2Mzd8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption></figcaption></figure></div><p>I realized about a year ago, that Iâ€™d picked up a trait from my mother, wherein I would not be present in conversations. Instead, Iâ€™d be trying to find a way to agree/disagree with the person about a point, and then direct the conversation towards being about MY experience of said thing.</p><p>Itâ€™s been hard, like rewiring my brain, but I hope Iâ€™ve become more stoic and thoughtful. I was an obnoxious extrovert who had no privacy, shared everything online, and never thought before I spoke.</p><p>This post is actually just me talking about me, but I guess itâ€™s good to share these things. </p><p>If you think youâ€™re too â€˜muchâ€™ sometimes, it could be because you are seeking approval from external things.&nbsp;</p><p>Whereas true happiness comes from finding the quiet calm, the â€˜homeâ€™ within you. Once you find this place, youâ€™ll see that your friend list is narrowed down. </p><p>Youâ€™ll seek only true friends who align with your values, and experiences that bring you purpose and fulfillment and youâ€™ll find a calm quiet center within&nbsp;:)</p><p><strong>Something extra</strong><span>:</span></p><p>Well, it is important to share information with others, especially those who care about you. However, you should equally give importance to being mindful of how, when, and what you share. If someone shares something with you, Showing empathy or responding with a related story can be a great way to connect. </p><p>Anyhow, it can be offensive and create a negative impression if you overshare or try to one-up the other personâ€™s story. </p><p>Thus, itâ€™s important to strike a balance and be mindful of the impact your words may have on others.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Antidepressants or Tolkien (394 pts)]]></title>
            <link>https://antidepressantsortolkien.vercel.app/</link>
            <guid>38186190</guid>
            <pubDate>Wed, 08 Nov 2023 02:53:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antidepressantsortolkien.vercel.app/">https://antidepressantsortolkien.vercel.app/</a>, See on <a href="https://news.ycombinator.com/item?id=38186190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

            <div>
                <p><span>
                        <p>Antidepressants or Tolkien</p>
                    </span><br>
                    <span>
                        <p>Can you guess if the word is an antidepressants drug or a Tolkien character? </p>
                    </span><br>

                    <span>
                        Play
                    </span>
                </p>
            </div>

            <div>
                
                <p><span>

                    </span><br>
                    <span>

                    </span><br>

                    <span>
                    </span><br>

                    <span>
                        <img src="">
                    </span>
                </p>
            </div>


            

            <div>
                <p>
                    Tolkien
                </p>

                <p>
                    Antidepressants
                </p>


                <p>
                    Next
                </p>

                <p>
                    Game ended! See results...
                </p>

                

                <p>
                    New Game
                </p>

                <div>
                    <p>Idea based on <a href="https://twitter.com/checarina/status/977387234226855936" target="_blank">@checarina</a>'s tweet</p>
                    <p>Copyrights and trademarks for the books, films, and other promotional materials are held by their respective owners and their use is allowed under the <a href="http://en.wikipedia.org/wiki/fair_use" title="Fair use" target="_blank">fair use</a> clause of the <a href="http://en.wikipedia.org/wiki/Copyright" target="_blank" title="Copyright">Copyright Law</a>.
            </p></div>
        </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interactive examples for learning jq (136 pts)]]></title>
            <link>https://ishan.page/blog/2023-11-06-jq-by-example/</link>
            <guid>38186153</guid>
            <pubDate>Wed, 08 Nov 2023 02:49:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ishan.page/blog/2023-11-06-jq-by-example/">https://ishan.page/blog/2023-11-06-jq-by-example/</a>, See on <a href="https://news.ycombinator.com/item?id=38186153">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    
    
    <blockquote>
<p>Cover Photo by <a href="https://www.pexels.com/photo/airport-bank-board-business-534216/" target="_blank" rel="noopener">Pixabay</a></p>
</blockquote>

<p>Has this ever happened to you?</p>
<p>Youâ€™ve just received a massive JSON file that looks like it was designed to confuse you. Or maybe you entered a command, and you got so much JSON that it looks incomprehensible.</p>
<p>The data you need is buried inside, and youâ€™re dreading the hours itâ€™ll take to extract and clean it up.</p>
<p>Iâ€™ve been there. Iâ€™ve <code>grep</code>ped my way through JSON and written ad-hoc Python scripts to process it for me.</p>
<p>But things donâ€™t have to be like this.</p>
<h2 id="introduction">Introduction</h2>
<p><code>jq</code> is one of the best-kept secrets in the data processing world.</p>
<p>Here are some scenarios where <code>jq</code> could swoop in to save your day (and saves mine regularly):</p>
<ol>
<li>
<p>Integrating with APIs in shell scripts often means handling JSON responses, requiring data extraction and manipulation.</p>
</li>
<li>
<p>Data from different sources may need to be converted to or from JSON format for compatibility.</p>
</li>
<li>
<p>Managing software configuration files in JSON format can be a regular task.</p>
</li>
<li>
<p>Extracting data from websites often results in dealing with JSON data that requires parsing and filtering.</p>
</li>
<li>
<p>Server logs and monitoring data often use JSON, necessitating parsing and analysis.</p>
</li>
<li>
<p>Infra as Code tools like Ansible and Terraform use JSON-like configurations, requiring management. JSON is a subset of YAML, so every valid JSON file is also a valid YAML file.</p>
</li>
</ol>
<p>All examples are <em>âœ¨fully interactiveâœ¨</em>, so I encourage you to play around!<br>
In fact, Iâ€™ll be downright heartbroken if you donâ€™t, because I put a lot of effort into it. You can edit both the input JSON data, and the jq program as well.</p>
<p>Letâ€™s dive in! Weâ€™ll start off easy, and get slowly deeper into the weeds.</p>
<h2 id="basic-operations">Basic Operations</h2>
<h3 id="selecting-values">Selecting values</h3>
<p>Everything in <code>jq</code> is a filter. The dot <code>.</code> is used to select the current object or element, and we can put the property name after it to access a key from an object:</p>


<h3 id="filtering-arrays">Filtering Arrays</h3>
<p>The <code>.[]</code> notation is used to iterate over the elements of an array in a JSON document. It allows you to access each element of an array and perform operations on them.</p>
<p>The <code>select()</code> function is used to filter JSON data based on a specified condition or criteria. It is a powerful tool for extracting specific elements from a JSON document that meet certain conditions.</p>
<p>Similiar to shell scripting, <code>jq</code> works on a pipes-and-filters manner. We use the <code>|</code> to send the data from one filter to the next.
<jq-view name="example2"></jq-view></p>

<h3 id="mapping-arrays">Mapping Arrays</h3>
<p>We can use the <code>map</code> function to run any operation on every element of the array and return a new array containing the outputs of that operation:
<jq-view name="example3"></jq-view></p>

<h3 id="combining-filters">Combining Filters</h3>
<p>The pipe operator <code>|</code> can be used to chain as many filters or functions as we want:
<jq-view name="example4"></jq-view></p>

<h3 id="splitting-strings">Splitting Strings</h3>
<p>We can use the <code>split()</code> function to a split a string on a particular separator character. <br>
Note also the usage of <code>.[0]</code> to select the first index from the split array.</p>


<h3 id="conditional-logic">Conditional Logic</h3>
<p>We can use <code>if</code> to create expressions
<jq-view name="example6"></jq-view></p>

<h3 id="handling-null-values">Handling Null Values</h3>
<p>Null values can often mess up logic in our scripts, so we can filter them all out using <code>map</code> and <code>select</code>
<jq-view name="example17"></jq-view></p>

<h3 id="formatting-output">Formatting Output</h3>
<p>Sometimes we donâ€™t want JSON output. We want it in a particular string format.<br>
Note the use of the <code>-r</code> flag, it makes the output raw. Without it, it would be displayed with quote marks around it.
<jq-view name="example10"></jq-view></p>

<h3 id="multiple-outputs">Multiple Outputs</h3>
<p>Curly braces create a new object, which we can use for multiple outputs:
<jq-view name="example5"></jq-view></p>

<h2 id="dealing-with-nested-items">Dealing with Nested Items</h2>
<p><img src="https://ishan.page/blog/2023-11-06-jq-by-example/russian_dolls.jpg" width="3500" height="2333" srcset="https://ishan.page/blog/2023-11-06-jq-by-example/russian_dolls_hu3d03a01dcc18bc5be0e67db3d8d209a6_252781_480x0_resize_q75_box.jpg 480w, https://ishan.page/blog/2023-11-06-jq-by-example/russian_dolls_hu3d03a01dcc18bc5be0e67db3d8d209a6_252781_1024x0_resize_q75_box.jpg 1024w" loading="lazy" data-flex-grow="150" data-flex-basis="360px"></p>
<blockquote>
<p><a href="https://www.pexels.com/photo/two-yellow-and-red-ceramic-owl-figurines-4966180/" target="_blank" rel="noopener">Photo by cottonbro studio</a></p>
</blockquote>
<p>JSON is very commonly used to store nested objects, and we often need to traverse or manipulate such structures. <code>jq</code> gives us all the tools we need to make it easy:</p>
<h3 id="recursive-descent">Recursive Descent</h3>
<p>We can use <code>..</code> to recursively descend through a tree of an object.</p>


<h3 id="filtering-nested-arrays">Filtering Nested Arrays</h3>


<h3 id="flattening-nested-json-objects">Flattening Nested JSON Objects</h3>
<p>Often, we just want all the key-values, and flattening the object may be the most convenient way to go:</p>


<h3 id="recursive-object-manipulation">Recursive Object Manipulation</h3>
<p>We can use the <code>recurse</code> as well, to traverse a tree.
<jq-view name="example18"></jq-view></p>

<h3 id="complex-object-transformation">Complex Object Transformation</h3>


<h3 id="walk-through-object-and-apply-a-transformation-conditionally">Walk through object and apply a transformation conditionally</h3>
<p>The <code>walk()</code> function provides a convenient way to traverse a nested object and apply some transformation to it.
<jq-view name="example24"></jq-view></p>

<h2 id="statistical-operations">Statistical Operations</h2>
<p><img src="https://ishan.page/blog/2023-11-06-jq-by-example/stats.jpg" width="6016" height="4016" srcset="https://ishan.page/blog/2023-11-06-jq-by-example/stats_hu3d03a01dcc18bc5be0e67db3d8d209a6_2144012_480x0_resize_q75_box.jpg 480w, https://ishan.page/blog/2023-11-06-jq-by-example/stats_hu3d03a01dcc18bc5be0e67db3d8d209a6_2144012_1024x0_resize_q75_box.jpg 1024w" loading="lazy" data-flex-grow="149" data-flex-basis="359px"></p>
<blockquote>
<p>Photo by <a href="https://www.pexels.com/photo/magnifying-glass-on-white-paper-with-statistical-data-5561913/" target="_blank" rel="noopener">Leeloo Thefirst</a></p>
</blockquote>
<p><code>jq</code> is incredibly handy for doing quick and dirty statistical analysis in the field. Hereâ€™s most of the common operations related to that</p>
<h3 id="sorting-arrays">Sorting Arrays</h3>
<p>Sorting an array is a basic operation that is useful for many things in statistics.
<jq-view name="example7"></jq-view></p>


<p>Extracting unique values from an array is another fairly basic operation that we need for many things.
<jq-view name="example12"></jq-view></p>

<h3 id="calculating-averages">Calculating Averages</h3>
<p>Calculating the mean or average of a dataset is a common statistical operation we may often need to do
<jq-view name="example20"></jq-view></p>

<h3 id="grouping-and-aggregating">Grouping and Aggregating</h3>
<p>We can group an array of objects by a particular key and get an aggregated value of the other keys fairly easily:
<jq-view name="example11"></jq-view></p>

<h3 id="filtering-after-aggregation">Filtering after Aggregation</h3>


<h3 id="custom-aggregation-with-reduce">Custom Aggregation with reduce</h3>
<p>We can also use <code>reduce</code> to perform a single-output aggregation from an array
<jq-view name="example23"></jq-view></p>

<h3 id="calculating-histogram-bins">Calculating Histogram Bins</h3>
<p>We may want to calculate a histogram from an array of data.
<jq-view name="example22"></jq-view></p>

<h2 id="other-common-operations">Other Common Operations</h2>
<p>These are some other common operations I frequently find myself doing every day, but I couldnâ€™t think of a better way to categorize them.</p>

<p>We can combine multiple conditions in a <code>select</code> call. The <code>test()</code> function is used to check if the passed string contains one of the substrings or not.
<jq-view name="example15"></jq-view></p>

<h3 id="formatting-unix-timestamps">Formatting Unix Timestamps</h3>
<p>Various tools emit Unix Timestamps, and we can use the handy <code>strftime</code> function to format it so itâ€™s easier to understand at a glace.
<jq-view name="example16"></jq-view></p>

<h3 id="enumerating-by-top-level-key-and-value">Enumerating by Top Level Key and Value</h3>


<h2 id="closing-thoughts">Closing Thoughts</h2>
<p>Whew! Thatâ€™s been a long article ðŸ˜… If youâ€™re still here, then I appreciate you staying till the very end.</p>
<p>I hope youâ€™ve learned something new, and that youâ€™ll be able to quickly identify use cases for <code>jq</code> in your current workflow and apply your learnings there.</p>
<h3 id="how-does-this-article-work">How Does This Article Work?</h3>
<ul>
<li>I have used web components to create a custom component <code>&lt;jq-view&gt;</code>.</li>
<li>There is some Javascript in this page which renders all the <code>&lt;jq-view&gt;</code>s when the page is loaded.</li>
<li>The WebAssembly build of <code>jq</code>, as well as all the code for calling out to it is provided by BioWasm.</li>
<li>I have used AlpineJs to make the examples interactive. When the button is clicked, it sends an event to a listener, which makes it run <code>jq</code> and then update the output.</li>
<li>Since I am not good at front-end, this was a substantial learning experience for me.</li>
</ul>
<h3 id="get-in-touch">Get In Touch</h3>
<p>If you have any suggestions on how this may be improved, errors that I might have made, or you just want to discuss any other topic, please feel free to <a href="mailto:ishan.dassharma1@gmail.com">email me</a>. I always love to hear from you.</p>

<p><a href="https://jqlang.github.io/jq/manual/" target="_blank" rel="noopener">JQ Manual</a></p>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bing Chat is so hungry for GPUs, Microsoft will rent them from Oracle (126 pts)]]></title>
            <link>https://www.theregister.com/2023/11/07/bing_gpu_oracle/</link>
            <guid>38184925</guid>
            <pubDate>Wed, 08 Nov 2023 00:01:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/07/bing_gpu_oracle/">https://www.theregister.com/2023/11/07/bing_gpu_oracle/</a>, See on <a href="https://news.ycombinator.com/item?id=38184925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Demand for Microsoft's AI services is apparently so great â€“ or Redmond's resources so tight â€“ that the software giant plans to offload some of the machine-learning models used by Bing Search to Oracle's GPU supercluster as part of a multi-year agreement announced Tuesday.</p>
<p>"Our collaboration with Oracle and use of Oracle Cloud infrastructure along with our Microsoft Azure AI infrastructure, will expand access to customers and improve the speed of many of our search results," Divya Kumar, who heads up Microsoft's Search and AI marketing team, explained in a <a href="https://www.oracle.com/apac/news/announcement/oracle-cloud-infrastructure-utilized-by-microsoft-for-bing-conversational-search-2023-11-07/" rel="nofollow">statement</a>.</p>
<p>The partnership essentially boils down to: Microsoft needs more compute resources to keep up with the alleged "explosive growth" of its AI services, and Oracle just happens to have tens of thousands of Nvidia A100s and H100 GPUs available for rent. Far be it from us to suggest the Larry-Ellison-founded database giant doesn't have enough cloud customers to consume its stocks of silicon.</p>

    

<p>Microsoft was among the first to integrate a generative AI chatbot into its search engine with the <a href="https://www.theregister.com/2023/02/07/microsoft_bing_ai/">launch</a> of Bing Chat back in February. You all know the drill by now: you can feed prompts, requests, or queries into Bing Chat, and it will try to look up information, write bad poetry, generate pictures and other content, and so on.</p>

        


        

<p>The large language models that underpin the service not only require massive clusters of GPUs to train, but for inferencing â€“ the process of putting a model to work â€“ to run at scale. It's Oracle's stack of GPUs that will help with this inference work.</p>
<p>The two cloud providers' latest collaboration takes advantage of the Oracle Interconnect for Microsoft Azure, which allows services running in Azure to interact with resources in Oracle Cloud Infrastructure (OCI). The two super-corps have <a href="https://www.theregister.com/2022/07/20/oracle_microsoft_multi_cloud_database/">previously</a> used the service to allow customers to connect workloads running in Azure back to OCI databases.</p>
<ul>

<li><a href="https://www.theregister.com/2023/11/05/biden_ai_reporting_thresholds/">Developing AI models or giant GPU clusters? Uncle Sam would like a word</a></li>

<li><a href="https://www.theregister.com/2023/11/03/microsoft_365_copilot/">Microsoft 365 Copilot 'generally available' â€“ if you can afford 300 seats</a></li>

<li><a href="https://www.theregister.com/2023/10/19/redis_disk_support/">In-memory database Redis wants to dabble in disk</a></li>

<li><a href="https://www.theregister.com/2023/11/06/openai_gpt4_turbo_copyright_shield/">OpenAI hits the GPT-4 Turbo button plus promises copyright shield for fans</a></li>
</ul>
<p>In this case, Microsoft is using the system alongside its Azure Kubernetes Service to orchestrate Oracle's GPU nodes to keep up with what's said to be demand for Bing's AI features.</p>
<p>According to StatCounter, for October 2023, Bing had a <a target="_blank" rel="nofollow" href="https://gs.statcounter.com/search-engine-market-share">3.1 percent</a> global web search market share for all platforms â€“ that's compared to Google's 91.6 percent, but up from 3 percent the month before. On desktop, Bing climbed to 9.1 percent, and 4.6 percent for tablets.</p>

        

<p>Maybe StatCounter is wrong; maybe Microsoft's chatty search engine isn't as staggeringly popular as we're led to believe. Maybe Microsoft just wants to make Bing look like it's in high demand; maybe Redmond really does need the extra compute.</p>
<p>Oracle claims its cloud super-clusters, which presumably Bing will use, can each scale to 32,768 Nvidia A100s or 16,384 H100 GPUs using a ultra-low latency Remote Direct Memory Access (RDMA) network. This is supported by petabytes of high-performance cluster file storage designed to support highly parallel applications.</p>
<p>Microsoft hasn't said just how many of Oracle's GPU nodes it needs for its AI services and apps, and won't say. A spokesperson told us: â€œThose arenâ€™t details we are sharing as part of this announcement.â€ We've asked Oracle too for more information and we'll let you know if we hear anything back.</p>

        

<p>This isn't the first time the frenemies have leaned on each other for help. Back in September Oracle <a href="https://www.theregister.com/2023/09/15/oracle_database_at_azure/">announced</a> it would colocate its database systems in Microsoft Azure datacenters. In that case, the collaboration was intended to reduce the latency associated with connecting Oracle databases running in OCI to workloads in Azure. Â®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nature retracts controversial superconductivity paper by embattled physicist (175 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-03398-4</link>
            <guid>38184750</guid>
            <pubDate>Tue, 07 Nov 2023 23:44:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-03398-4">https://www.nature.com/articles/d41586-023-03398-4</a>, See on <a href="https://news.ycombinator.com/item?id=38184750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_26239314.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_26239314.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Ranga Dias working at a desktop computer." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_26239314.jpg">
  <figcaption>
   <p><span>Physicist Ranga Dias is under investigation by his institution, the University of Rochester in New York.</span><span>Credit: Lauren Petracca/New York Times/Redux/eyevine</span></p>
  </figcaption>
 </picture>
</figure><p><i>Nature</i> has retracted a controversial paper<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> claiming the discovery of a superconductor â€” a material that carries electrical currents with zero resistance â€” capable of operating at room temperature and relatively low pressure.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02733-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_26230840.jpg"><p>Why a blockbuster superconductivity claim met a wall of scepticism</p></a>
 </article><p>The <a href="https://www.nature.com/articles/s41586-023-06774-2" data-track="click" data-label="https://www.nature.com/articles/s41586-023-06774-2" data-track-category="body text link">text of the retraction notice</a> states that it was requested by eight co-authors. â€œThey have expressed the view as researchers who contributed to the work that the published paper does not accurately reflect the provenance of the investigated materials, the experimental measurements undertaken and the data-processing protocols applied,â€ it says, adding that these co-authors â€œhave concluded that these issues undermine the integrity of the published paperâ€. (The <i>Nature</i> news team is independent from its journals team.)</p><p>It is the third high-profile retraction of a paper by the two lead authors, physicists Ranga Dias at the University of Rochester in New York and Ashkan Salamat at the University of Nevada, Las Vegas (UNLV). <i>Nature</i> withdrew a separate paper last year<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> and <i>Physical Review Letters</i> retracted one this August<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup>. It spells more trouble in particular for Dias, <a href="https://www.science.org/content/article/plagiarism-allegations-pursue-physicist-behind-stunning-superconductivity-claims" data-track="click" data-label="https://www.science.org/content/article/plagiarism-allegations-pursue-physicist-behind-stunning-superconductivity-claims" data-track-category="body text link">whom some researchers allege plagiarized portions of his PhD thesis</a>. Dias has objected to the first two retractions and not responded regarding the latest. Salamat approved the two this year.</p><p>â€œIt is at this point hardly surprising that the team of Dias and Salamat has a third high-profile paper being retracted,â€ says Paul Canfield, a physicist at Iowa State University in Ames and at Ames National Laboratory. Many physicists had seen the <i>Nature</i> retraction as inevitable after the other two â€” and especially since <a href="https://www.wsj.com/science/room-temperature-superconductor-retract-journal-nature-e554536a" data-track="click" data-label="https://www.wsj.com/science/room-temperature-superconductor-retract-journal-nature-e554536a" data-track-category="body text link"><i>The Wall Street Journal</i></a> and <a href="https://www.science.org/content/article/another-retraction-looms-embattled-physicist-behind-blockbuster-superconductivity" data-track="click" data-label="https://www.science.org/content/article/another-retraction-looms-embattled-physicist-behind-blockbuster-superconductivity" data-track-category="body text link"><i>Science</i></a> reported in September that 8 of the 11 authors of the paper â€” including Salamat â€” had requested it in a letter to the journal.</p><p>Dias and Salamat did not respond to a request for comment by <i>Nature</i>â€™s news team. The retraction states that he and two other co-authors â€” Nugzari Khalvashi-Sutter and Sasanka Munasinghe, both at Rochester â€” "have not stated whether they agree or disagree with this retraction".</p><h2>Early scepticism</h2><p>This yearâ€™s report by Dias and Salamat is the second significant claim of superconductivity to crash and burn in 2023. In July, a separate team at a start-up company in Seoul described<sup><a href="#ref-CR4" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">4</a></sup><sup>,</sup><sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup> a crystalline purple material dubbed LK-99 â€” made of copper, lead, phosphorus and oxygen â€” that they said showed superconductivity at normal pressures and at temperatures up to at least 127 Â°C (400 kelvin). There was much online excitement and many attempts to reproduce the results, but researchers quickly reached a consensus that the material <a href="https://www.nature.com/articles/d41586-023-02585-7" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02585-7" data-track-category="body text link">was not a superconductor at all</a>.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02585-7" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_25924888.jpg"><p>LK-99 isnâ€™t a superconductor â€” how science sleuths solved the mystery</p></a>
 </article><p>Superconductors are important in many applications, from magnetic resonance imaging machines to particle colliders, but their use has been limited by the need to keep them at extremely low temperatures. For decades, researchers have been developing new materials with the dream of finding one that exhibits superconductivity without any refrigeration.</p><p>Specialists in the field have been sceptical since this yearâ€™s Dias and Salamat paper was published, says Lilia Boeri, a physicist at the Sapienza University of Rome. This, she says, is in part because of controversies swirling around the team and in part because the latest paper was not written to what she considers a high standard.</p><p>â€œVirtually every serious condensed-matter physicist I know saw right away that there were serious problems with the work,â€ says Peter Armitage, an experimental physicist at Johns Hopkins University in Baltimore, Maryland. In particular, members of the community took issue with measurements of the materialâ€™s electrical resistance, saying it was not clear whether the property truly dropped to zero, or whether Dias and Salamat had subtracted a background signal from a key plot of resistance to create the appearance that it did. Critics say that it should not be necessary to remove background from this type of measurement. In today's text, the journal stated, "An investigation by the journal and post-publication review have concluded that these concerns are credible, substantial and remain unresolved."</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-022-03066-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_23949000.jpg"><p>Stunning room-temperature-superconductor claim is retracted</p></a>
 </article><p>Armitage adds that the publication of the paper also raises questions about the editorial review process at <i>Nature</i>, and why reviewers didnâ€™t catch the issues.</p><p>â€œThe highly qualified expert reviewers we selected raised a number of questions about the original submission, which were largely resolved in later revisions,â€œ says Karl Ziemelis, chief physical sciences editor at <i>Nature</i>. â€œWhat the peer-review process cannot detect is whether the paper as written accurately reflects the research as it was undertaken.â€</p><p>â€œDecisions about what to accept for publication are not always easy to make,â€ Ziemelis continues. â€œAnd there may be conflicts, but we strive to take an unbiased position and to ensure the interests of the community always drive our deliberations.â€</p><h2>Audible clamour</h2><p><i>Nature</i> published the now-retracted paper on 8 March. That week, Dias himself presented the results to a standing-room-only audience at a meeting of the American Physical Society in Las Vegas. Over the audible clamour of the crowd assembled outside the roomâ€™s doors â€” where conference staff limited entry to avoid violating fire regulations â€” Dias briefly described a compound made of hydrogen, lutetium and small amounts of nitrogen that was a superconductor at temperatures up to 21 Â°C (294 kelvin) when kept at a pressure of around 1 gigapascal (10,000 times atmospheric pressure).</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02401-2" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_25984902.jpg"><p>â€˜A very disturbing pictureâ€™: another retraction imminent for controversial physicist</p></a>
 </article><p>Many teams had already created and experimented with similar hydrogen-rich materials, called hydrides, after a milestone discovery in 2015. A group led by physicist Mikhail Eremets at the Max Planck Institute for Chemistry in Mainz, Germany, reported<sup><a href="#ref-CR6" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">6</a></sup> superconductivity in a hydrogenâ€“sulfur compound at âˆ’70 Â°C (203 kelvin); at the time, this was a record-high operating temperature for a superconductor. But Eremetsâ€™s material required a much higher pressure of 145 gigapascals (1.4 million times atmospheric pressure) â€” comparable to the crushing conditions at the centre of Earth.</p><p>Since then, researchers have made hydride superconductors that push closer and closer to operating at room temperature, but all of them work only under extreme pressures. When Dias and Salamat published their paper in <i>Nature</i> in March, they <a href="https://www.nature.com/articles/d41586-023-02733-z#ref-CR10" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02733-z#ref-CR10" data-track-category="body text link">seemed to have made a significant step</a> towards a material that could find practical applications.</p><p>But some specialists were already wary because of <a href="https://www.nature.com/articles/d41586-022-03066-z" data-track="click" data-label="https://www.nature.com/articles/d41586-022-03066-z" data-track-category="body text link">the first <i>Nature</i> retraction</a>. And some say they immediately found the fresh claims to be improbable. For instance, the material described in the paper was supposed to have around three hydrogen atoms for every lutetium atom. But if so, the lutetium would tend to donate an electron to each hydrogen, resulting in a kind of salt, says Artem Oganov, a materials scientist at the Skolkovo Institute of Science and Technology in Moscow. â€œYou get either an insulator or an extremely poor metal,â€ he says â€” not a superconductor.</p><p>One lab says it has partially reproduced Dias and Salamatâ€™s results using a sample provided by the Rochester team<sup><a href="#ref-CR7" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">7</a></sup>. But many others, which tried creating their own samples and running tests, could not. And in the meantime, other causes for concern have arisen. An investigation launched by <i>Physical Review Letters</i> before it retracted its paper by Dias and Salamat found â€œapparent data fabricationâ€, <a href="https://www.nature.com/articles/d41586-023-02401-2" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02401-2" data-track-category="body text link">as <i>Nature</i>â€™s news team reported in July</a>. And an investigation launched by <i>Nature</i>â€™s journals team after it received an anonymous critique of data in this yearâ€™s paper found that â€œthe credibility of the published results are in questionâ€, according to <a href="https://www.science.org/content/article/another-retraction-looms-embattled-physicist-behind-blockbuster-superconductivity" data-track="click" data-label="https://www.science.org/content/article/another-retraction-looms-embattled-physicist-behind-blockbuster-superconductivity" data-track-category="body text link">Septemberâ€™s news story in <i>Science</i></a>.</p><h2>Credibility concerns</h2><p>Armitage does not think that Dias and Salamat will be able to keep doing research, pointing to the investigation findings and allegations of plagiarism in Diasâ€™s PhD thesis. The University of Rochester has confirmed to <i>Nature</i> that it has launched an investigation into the integrity of Diasâ€™s work, which is being conducted now by external experts. The universityâ€™s spokesperson did not answer questions about whether the institution has yet disciplined Dias. UNLV did not answer <i>Nature</i>â€™s queries about whether Salamat is being investigated, saying that â€œUNLV does not publicly discuss personnel mattersâ€, but that it â€œis committed to maintaining the highest standards for research integrity campus wideâ€.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02681-8" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03398-4/d41586-023-03398-4_26007520.jpg"><p>How would room-temperature superconductors change science?</p></a>
 </article><p>Canfield says that the Diasâ€“Salamat collaboration has spread a â€œfoul vapourâ€ over the field, which â€œis scaring young researchers and funding agencies awayâ€.</p><p>â€œI have some colleagues who simply are afraid that this case of Dias puts a shadow of doubt on the credibility of our field in general,â€ Eremets says.</p><p>Ho-Kwang Mao, director of the Center for High Pressure Science and Technology Advanced Research in Beijing, is more sanguine. â€œI do not think it will affect the funding for superconductivity research other than more careful reviews, which is not necessarily bad,â€ he says.</p><p>Hai-Hu Wen, director of the Center for Superconducting Physics and Materials at Nanjing University in China, agrees. â€œActually, it seems more easy to get funding for the research of superconductivity since some government officials seem to be influenced by the expectation of a room-temperature superconductor,â€ he says.</p><p>But Boeri says she has heard researchers complain that the controversies â€” the allegations of PhD thesis plagiarism and the findings of apparent data fabrication â€” have made it harder to recruit students to work on superconductors. â€œWe face a serious communication problem, to make people understand that the field is healthy â€” that although there may be some bad apples, the communityâ€™s standards are much higher,â€ she says.</p><p>â€œSerious people continue to do amazing and interesting work,â€ Armitage says. â€œSure, they can be disheartened by this nonsense, but it wonâ€™t stop the science.â€</p>
                </div><p>Additional reporting by Lauren Wolf.</p><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Dasenbrock-Gammon, N. <i>et al.</i> <i>Nature</i> <b>615</b>, 244â€“250 (2023); retraction https://doi.org/10.1038/s41586-023-06774-2 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-023-05742-0" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-023-05742-0" aria-label="Article reference 1" data-doi="10.1038/s41586-023-05742-0">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Nature&amp;doi=10.1038%2Fs41586-023-05742-0&amp;volume=615&amp;pages=244-250&amp;publication_year=2023&amp;author=Dasenbrock-Gammon%2CN.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Snider, E. <i>et al.</i> <i>Nature</i> <b>586</b>, 373â€“377 (2022); retraction <b>610</b>, 804 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-020-2801-z" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-020-2801-z" aria-label="Article reference 2" data-doi="10.1038/s41586-020-2801-z">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Nature&amp;doi=10.1038%2Fs41586-020-2801-z&amp;volume=586&amp;pages=373-377&amp;publication_year=2022&amp;author=Snider%2CE.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Durkee, D. <i>et al. Phys. Rev. Lett.</i> <b>127</b>, 016401 (2021); retraction <b>131</b>, 079902 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1103/PhysRevLett.127.016401" data-track-action="article reference" href="https://doi.org/10.1103%2FPhysRevLett.127.016401" aria-label="Article reference 3" data-doi="10.1103/PhysRevLett.127.016401">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Phys.%20Rev.%20Lett&amp;doi=10.1103%2FPhysRevLett.127.016401&amp;volume=127&amp;publication_year=2021&amp;author=Durkee%2CD.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="4."><p id="ref-CR4">Lee, S. <i>et al.</i> Preprint at <a href="https://arxiv.org/abs/2307.12037" data-track="click" data-track-action="external reference" data-track-label="https://arxiv.org/abs/2307.12037">https://arxiv.org/abs/2307.12037</a> (2023).</p></li><li data-counter="5."><p id="ref-CR5">Lee, S., Kim, J.-H. &amp; Kwon, Y.-W. Preprint at <a href="https://arxiv.org/abs/2307.12008" data-track="click" data-track-action="external reference" data-track-label="https://arxiv.org/abs/2307.12008">https://arxiv.org/abs/2307.12008</a> (2023).</p></li><li data-counter="6."><p id="ref-CR6">Drozdov, A. P., Eremets, M. I., Troyan, I. A., Ksenofontov, V. &amp; Shylin, S. <i>I. Nature</i> <b>525</b>, 73â€“76 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature14964" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature14964" aria-label="Article reference 6" data-doi="10.1038/nature14964">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=I.%20Nature&amp;doi=10.1038%2Fnature14964&amp;volume=525&amp;pages=73-76&amp;publication_year=2015&amp;author=Drozdov%2CA.%20P.&amp;author=Eremets%2CM.%20I.&amp;author=Troyan%2CI.%20A.&amp;author=Ksenofontov%2CV.&amp;author=Shylin%2CS.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="7."><p id="ref-CR7">Salke, N. P., Mark, A. C., Ahart, M. &amp; Hemley, R. J. Preprint at <a href="https://arxiv.org/abs/2306.06301" data-track="click" data-track-action="external reference" data-track-label="https://arxiv.org/abs/2306.06301">https://arxiv.org/abs/2306.06301</a> (2023).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/d41586-023-03398-4?format=refman&amp;flavour=references">Download references</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tumble Forth (124 pts)]]></title>
            <link>http://tumbleforth.hardcoded.net/</link>
            <guid>38184539</guid>
            <pubDate>Tue, 07 Nov 2023 23:23:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://tumbleforth.hardcoded.net/">http://tumbleforth.hardcoded.net/</a>, See on <a href="https://news.ycombinator.com/item?id=38184539">Hacker News</a></p>
<div id="readability-page-1" class="page">


<p>
Hello, my name is Virgil Dupras, author of <a href="http://collapseos.org/">Collapse OS</a> and <a href="http://duskos.org/">Dusk OS</a> and I'm starting a series of articles that
aims to hand-hold my former self, a regular web developer, into the rabbit hole
leading to the wonderful world of low level programming. Hopefully, I can
hand-hold you too.
</p>

<p>
The general goal is to broaden your perspectives on the subject of computing. I
intend do to that through story arcs leading, step by step, to some nice and
shiny objective. I also intend to work into a gimmick where in each episode, I
get to tell one corny joke.
</p>

<p>
The target reader is a person who knows their way around programming, but is
inexperienced in the area of low level programming. If you're the target reader
but find some parts of this content difficult to understand, this is not
intentional. In this case, or if you have any question or comment, reach out to
me at hsoft@hardcoded.net.
</p>

<h2>Story arcs</h2>

<h3>Buckle up, Dorothy</h3>

<p>
In my <a href="http://tumbleforth.hardcoded.net/01-duskcc/01-buckleup.html">â€œpilotâ€ story arc</a>, we peek in
disgust in the abyss of modern software complexity and escape this dystopia by
tumbling down the rabbit hole of low level development.
</p>
<p>
Starting from bare metal on the PC platform, we build a Forth from scratch, then
switch to <a href="http://duskos.org/">Dusk OS</a> and then build a partial C
compiler (just enough to compile our example code), again from scratch.
</p>

<p>Table of Contents</p>
<ol>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/01-buckleup.html">Buckle up, Dorothy</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/02-baremetal.html">Liberation through bare metal</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/03-onesector.html">One sector to rule them all</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/04-wordsshell.html">Words in the shell</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/05-dolookup.html">Do Look Up</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/06-taletwostacks.html">A tale of two stacks</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/07-babywalk.html">Baby's first steps</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/08-immediate.html">The Unbearable Immediateness of Compiling</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/09-dusktillc.html">From Dusk Till C</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/10-beast.html">Feeding the beast</a></li>
    <li><a href="http://tumbleforth.hardcoded.net/01-duskcc/11-eye.html">In the Eye of the Compiler</a></li>
</ol>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[WasmFX: Effect Handlers for WebAssembly (124 pts)]]></title>
            <link>https://wasmfx.dev/</link>
            <guid>38184339</guid>
            <pubDate>Tue, 07 Nov 2023 23:04:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wasmfx.dev/">https://wasmfx.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=38184339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <div>
          <div>
            <h3>Efficient and fast</h3>
            <p>WasmFX provides a general and flexible instruction set
            for fast stack switching, paving the way for efficient
            implementations of various non-local control flow
            abstractions, which would otherwise have to be implemented
            using whole-program transformations such as continuation
            passing style. WasmFX is carefully designed to enable Wasm
            to maintain backwards-compatible performance for legacy
            programs.</p>
          </div>
          <div>
            <h3>Modular and composable</h3>
            <p>WasmFX provides a modular and composable basis for
            implementing non-local control flow abstractions via
            delimited control, as the design draws heavily
            on <a href="https://homepages.inf.ed.ac.uk/gdp/publications/Effect_Handlers.pdf">Plotkin
            and Pretnar's handlers for algebraic effects</a>. As such
            the design is based on strong and well-understood
            theoretical foundations; at the same time it also
            incorporates the practical lessons learnt during the
            previous 30 years of research on delimited control.</p>
          </div>
        </div>
        <div>
          <div>
            <h3>Debuggable and profilable </h3>
            <p>WasmFX is designed to preserve the debugging and
            profiling experience of WebAssembly. The structure of
            WasmFX stacks offers excellent compatibility with popular
            formats such as <a href="https://dwarfstd.org/">DWARF
            stack unwind tables</a>, enabling WebAssembly
            implementations to maintain compatibility with standard
            debugging and profiling tools.</p>
          </div>
          <div>
            <h3>Minimal and compatible</h3>
            <p>WasmFX is designed as a minimal and compatible
            extension to WebAssembly for structured non-local control
            flow. The extension is minimal in the sense that it
            leverages WebAssembly's existing instruction set and type
            system. It extends the instruction set with six new
            instructions and the type system with a new reference
            type.</p>
          </div>
        </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gleam: a type safe language on the Erlang VM (295 pts)]]></title>
            <link>https://gleam.run/</link>
            <guid>38183454</guid>
            <pubDate>Tue, 07 Nov 2023 21:53:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gleam.run/">https://gleam.run/</a>, See on <a href="https://news.ycombinator.com/item?id=38183454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
  <section>
    <p>
        The power of a type system, the expressiveness of functional
        programming, and the reliability of the highly concurrent, fault
        tolerant Erlang runtime, with a familiar and modern syntax.
      </p>
    <pre><code><span>import</span> <span>gleam/io</span>

<span>pub fn</span> <span>main</span>() {
  <span>io.</span><span>println</span>(<span>"hello, friend!"</span>)
}</code></pre>
  </section>

  

  <section>
    <div>
      <h2>Reliable and scalable</h2>
      <p>
        Running on the battle-tested Erlang virtual machine that powers
        planet-scale systems such as WhatsApp and Ericsson, Gleam is ready for
        workloads of any size.
      </p>
      <p>
        Thanks to a multi-core actor based concurrency system that can run
        millions of concurrent tasks, fast immutable data structures, and a
        concurrent garbage collector that never stops the world, your service can
        scale and stay lightning fast with ease.
      </p>
    </div>
    <pre><code><span>fn</span> <span>spawn_task</span>(i) {
  <span>task.</span><span>async</span>(<span>fn</span>() {
    <span>let</span> n = <span>int.</span><span>to_string</span>(i)
    <span>io.</span><span>println</span>(<span>"Hello from "</span> <span>&lt;&gt;</span> n)
  })
}

<span>pub fn</span> <span>main</span>() {
  <span>// Run loads of threads, no problem</span>
  <span>list.</span><span>range</span>(<span>0</span>, <span>200_000</span>)
  <span>|&gt;</span> <span>list.</span><span>map</span>(<span>spawn_task</span>)
  <span>|&gt;</span> <span>list.</span><span>each</span>(<span>task.</span><span>await_forever</span>)
}
</code></pre>
  </section>

  <section>
    <div>
      <h2>Ready when you are</h2>
      <p>
        Gleam comes with compiler, build tool, formatter, editor integrations,
        and package manager all built in, so creating a Gleam project is just
        running <code>gleam new</code>.
      </p>
      <p>
        As part of the wider BEAM ecosystem, Gleam programs can use thousands
        of published packages, whether they are written in Gleam, Erlang, or
        Elixir.
      </p>
    </div>
    <pre><code><span>âžœ (main)</span> gleam add gleam_json
<span>  Resolving</span> versions
<span>Downloading</span> packages
<span> Downloaded</span> 2 packages in 0.01s
<span>      Added</span> gleam_json v0.5.0
<span>âžœ (main)</span> gleam test
<span> Compiling</span> thoas
<span> Compiling</span> gleam_json
<span> Compiling</span> app
<span>  Compiled</span> in 1.67s
<span>   Running</span> app_test.main
<span>.
1 tests, 0 failures</span>
</code></pre>
  </section>

  <section>
    <div>
      <h2>Here to help</h2>
      <p>
        No null values, no exceptions, clear error messages, and a practical
        type system. Whether you're writing new code or maintaining old code,
        Gleam is designed to make your job as fun and stress-free as possible.
      </p>
    </div>
    <pre><code><span>error:</span> Unknown record field

  â”Œâ”€ ./src/app.gleam:8:16
  â”‚
8 â”‚ user.alias
  â”‚ <span>    ^^^^^^ Did you mean `name`?</span>

The value being accessed has this type:
    User

It has these fields:
    .name
</code></pre>
  </section>

  <section>
    <div>
      <h2>Multilingual</h2>
      <p>
        Gleam makes it easy to use code written in other BEAM languages such
        as Erlang and Elixir, so there's a rich ecosystem of thousands of open
        source libraries for Gleam users to make use of.
      </p>
      <p>
        Gleam can additionally compile to JavaScript, enabling you to use your
        code in the browser, or anywhere else JavaScript can run. It also
        generates TypeScript definitions, so you can interact with your Gleam
        code confidently, even from the outside.
      </p>
    </div>
    <pre><code>
      

<span>@external</span>(erlang, <span>"Elixir.HPAX", "new"</span>)
<span>pub fn</span> <span>new</span>(size: <span>Int</span>) -&gt; <span>Table</span>
  


<span>pub fn</span> <span>register_event_handler</span>() {
  <span>let</span> el = <span>document.</span><span>query_selector</span>(<span>"a"</span>)
  <span>element.</span><span>add_event_listener</span>(el, <span>fn</span>() {
    <span>io.</span><span>println</span>(<span>"Clicked!"</span>)
  })
}</code></pre>
  </section>

  <section>
    <!-- TODO: add triangles here -->
    <div>
      <h2>Friendly ðŸ’œ</h2>
      <p>
        As a community, we want to be friendly too. People from around the
        world, of all backgrounds, genders, and experience levels are welcome
        and respected equally. See our community code of conduct for more.
      </p>
      <p>
        Black lives matter. Trans rights are human rights. No nazi bullsh*t.
      </p>
    </div>
    <!-- TODO: add Lucy here -->
    <img src="https://gleam.run/images/waves.svg" alt="a soft wavey boundary between two sections of the website">
  </section>


  

  <div>
      <h2>You're still here?</h2>
      <p>
        Well, that's all this page has to say. Maybe you should go read the
        language introduction!
      </p>
      <p><a href="https://gleam.run/getting-started">Let's go!</a></p><hr>

      <h3>Wanna keep in touch?</h3>
      <p>
        Subscribe to the Gleam newsletter
      </p>
      
      <p>
        We send emails at most a few times a year, and we'll never share your
        email with anyone else.
      </p>
      <p>
        This site is protected by reCAPTCHA and the Google
        <a href="https://policies.google.com/privacy">Privacy Policy</a> and
        <a href="https://policies.google.com/terms">Terms of Service</a> apply.
      </p>
    </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asahi Linux folks are doing us a solid with WPA3 fixes (155 pts)]]></title>
            <link>https://rachelbythebay.com/w/2023/11/07/wpa3/</link>
            <guid>38183394</guid>
            <pubDate>Tue, 07 Nov 2023 21:49:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2023/11/07/wpa3/">https://rachelbythebay.com/w/2023/11/07/wpa3/</a>, See on <a href="https://news.ycombinator.com/item?id=38183394">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2023/11/07/wpa3/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What the QWAC? an EV Certificate all over again (146 pts)]]></title>
            <link>https://scotthelme.co.uk/what-the-qwac/</link>
            <guid>38183259</guid>
            <pubDate>Tue, 07 Nov 2023 21:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scotthelme.co.uk/what-the-qwac/">https://scotthelme.co.uk/what-the-qwac/</a>, See on <a href="https://news.ycombinator.com/item?id=38183259">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<article>

<section>
<div>
<p>Almost 2 years on from the last time I wrote about QWACs, I'm sadly not here to tell you that things have gone well since then. In fact, I'm actually here to tell you that things are not going well at all...</p><h4 id="qwac">QWAC</h4><p>Back in Jan 2022, I wrote a blog post that went into details on what a QWAC, or Qualified Website Authentication Certificate, actually is: <a href="https://scotthelme.co.uk/looks-like-a-duck-swims-like-a-duck-qwacs-like-a-duck-probably-an-ev-certifiacate/?ref=scotthelme.co.uk" rel="noreferrer">If it looks like a duck, swims like a duck, and QWACs like a duck, then it's probably an EV Certificate</a></p><p>TLDR; It's an EV Certificate all over again ðŸ¤·â€â™‚ï¸</p><figure><img src="https://scotthelme.co.uk/content/images/2023/11/facepalm-crowd.gif" alt="" loading="lazy" width="498" height="274"></figure><p>In all seriousness though, that's actually quite a long and detailed post about the shortcomings of a QWAC and why they're just a terrible, terrible idea. They're only being pushed by organisations that would make $$$ selling them (funny that) and it's like the entire mess of EV has been conveniently forgotten. I'm not here to re-tread the same ground, though, I'm here to talk about something even more concerning. You might think "ok, so we have a new type of pointless certificate available", and if that were the case, I wouldn't be writing about it again and we could all just not buy them. The problem is that there's something bigger lurking that really concerns me.</p><h4 id="my-concerns">My Concerns</h4><p>This isn't all just talk for me, having dedicated a huge portion of my life to working in this industry and being so passionate about it, this worries me. It worries me enough that I've signed multiple open letters speaking out against this, with the most recent <a href="https://last-chance-for-eidas.org/?ref=scotthelme.co.uk" rel="noreferrer">just a few days ago</a>, and I've even travelled to Brussels to sit alongside Member of European Parliament Karen Melchior, and other industry representatives, to <a href="https://securityriskahead.eu/wp-content/uploads/2022/11/Press-release-event-on-cybersecurity-risks-within-the-eIDAS-revision.pdf?ref=scotthelme.co.uk" rel="noreferrer">speak against this</a>. I have absolutely no skin in this game, one way or another, but I've seen something that I believe is just fundamentally wrong, and I feel compelled to speak out against it.</p><figure><img src="https://scotthelme.co.uk/content/images/2023/11/image-17.png" alt="" loading="lazy" width="643" height="382" srcset="https://scotthelme.co.uk/content/images/size/w600/2023/11/image-17.png 600w, https://scotthelme.co.uk/content/images/2023/11/image-17.png 643w"></figure><h4 id="eidas-article-45latest-recitals">eIDAS Article 45 - latest recitals</h4><p>As we come towards the end of the legal process, we're closing in on the final revisions and final draft of some new regulation coming to the EU called <a href="https://digital-strategy.ec.europa.eu/en/policies/eidas-regulation?ref=scotthelme.co.uk" rel="noreferrer">eIDAS</a>. This new regulation contains many things, and it's only one small part of it that I fundamentally oppose, but it will have Global impact, far beyond the borders of any member state of the EU.</p><p>Alongside introducing the concept of a QWAC, discussed in my previous blog post, eIDAS is also going to introduce some very concerning requirements that affect the Internet PKI. At the top of my list of concerns is that browser and client vendors (Root Store Operators) will have a legal obligation to add Government mandated Root Certificate Authorities to their Root Stores, bypassing existing approval mechanisms. </p><p>Yep, you read that right. Government mandated Root Certificate Authorities...</p><p>I could end this blog post right here because anyone reading this will understand the significance of such a statement, and just how much of a catastrophically bad idea that is, but it gets worse. There will also be restrictions placed on Root Store Operators around handling incidents at those Root CAs and possibly removing trust in them for wrongdoing. I cannot stress this enough so I'm going to say it again, this is a terrible idea.</p><h4 id="how-it-works-now">How it works now</h4><p>The system that we have now is not perfect, by any stretch of the imagination, but it has been improved so much over the years with tireless work from the industry, that where we are now, finally, is a good place.</p><p>A browser or device vendor like Apple has a collection of Trusted Root Certificate Authorities that their devices will trust, and in turn, those devices will trust any certificates issued by those Trusted Root CAs. If you want to join this collection of Trusted Root CAs, you have to apply to join the <a href="https://www.apple.com/certificateauthority/ca_program.html?ref=scotthelme.co.uk" rel="noreferrer">Apple Root Certificate Program</a> and pass some very strict requirements. Of course, this makes sense, because being a Trusted Root CA is a massive responsibility that gives you an enormous amount of power, and Apple want to make sure that their customers aren't going to come to any harm because of your actions. The same goes for all such Root Store Operators like <a href="https://www.mozilla.org/en-US/about/governance/policies/security-group/certs/policy/?ref=scotthelme.co.uk" rel="noreferrer">Mozilla</a>, <a href="https://www.chromium.org/Home/chromium-security/root-ca-policy/?ref=scotthelme.co.uk" rel="noreferrer">Chrome</a>, <a href="https://learn.microsoft.com/en-us/security/trusted-root/program-requirements?ref=scotthelme.co.uk" rel="noreferrer">Microsoft</a> and many others that operate Trusted Root Programs for their own devices or software. It is in the interest of the software/device vendor to make sure that a Root CA is capable of operating properly because if not, all of that vendor's customers are at serious risk of having their traffic intercepted and decrypted. So, for Apple, their concern is that if a Root CA makes a mistake, the potential outcome is that everyone using an iPhone could have the security of all of their traffic compromised! That's a serious risk, and it's why organisations like Apple take the process of approving Trusted Root CAs so damn seriously.</p><p>This is the existing approval mechanism that will be bypassed by this new legislation and the Root Store Operators will be required to accept these European Root CAs without the ability to scrutinise them, or, reject their inclusion.</p><figure><img src="https://scotthelme.co.uk/content/images/2023/11/CABForum_logo.png" alt="" loading="lazy" width="426" height="93"></figure><h4 id="how-its-going-to-work">How it's going to work</h4><p>I have access to the near-final text of the regulation, which is not yet public, but was leaked to me by a confidential source. I've been looking through the proposed changes and I still see all of the things that have concerned me throughout this entire process. Here are a few snippets from the hundreds of pages that I've read through that still demonstrate my concerns. These snippets outline the definition of a QWAC and that they must be held against the standards set out in the legislation:</p><blockquote>â€˜qualified certificate for website authenticationâ€™ means a certificate for website authentication, which is issued by a qualified trust service provider and meets the requirements laid down in Annex IV;</blockquote><blockquote>Qualified certificates for website authentication shall meet the requirements laid down in Annex IV.</blockquote><blockquote>Evaluation of compliance with those requirements shall be carried out in accordance with the standards and the specifications referred to in paragraph 3.</blockquote><p>But if that isn't clear enough for you, the legislation goes on to say:</p><blockquote>Qualified certificates for website authentication issued in accordance with paragraph 1 shall be recognised by web-browsers. Web-browsers shall ensure that the identity data attested in the certificate and additional attested attributes are displayed in a user-friendly manner. Web-browsers shall ensure support and interoperability with qualified certificates for website authentication referred to in paragraph 1</blockquote><p>That's pretty clear, and we can still see the same concerns I raised previously about the legislation controlling not only support for, and use of, the Government Mandated Root CAs, but even control over the UI of the browser itself. It goes on:</p><blockquote>National trusted lists should confirm the qualified status of website authentication services and of their trust service providers, including their full compliance with the requirements of this Regulation with regards to the issuance of qualified certificates for website authentication. Recognition of QWACs means that the providers of web-browsers should not deny the authenticity of qualified certificates for website authentication attesting the link between the website domain name and the natural or legal person to whom the certificate is issued and confirming the identity of that person. Providers of web-browsers should display in a user-friendly manner the certified identity data and the other attested attributes to the end-user, in the browser environment, by relying on technical implementations of their choice. To that end, providers of web-browsers should ensure support and interoperability with qualified certificates for website authentication issued in full compliance with the requirement of this Regulation.</blockquote><p>Again, pressing this idea of a list of Trusted Root CAs that the client vendors must accept and "should not deny the authenticity of". Then, with regards to limiting the ability of a Root Store Operator to audit the behaviour of a Trusted Root CA on an ongoing basis:</p><blockquote>In order to contribute to the online security of end-users, providers of web-browsers should be able to take measures, in exceptional circumstances, that are both necessary and proportionate in reaction to substantiated concerns on breaches of security or loss of integrity of an identified certificate or set of certificates. In this case, while taking any such precautionary measures, web browsers should notify without undue delay the national supervisory body and the Commission, the entity to whom the certificate was issued and the qualified trust service provider that issued that certificate or set of certificates of any such concern of a security breach as well as the measures taken relating to a single certificate or a set of certificates. These measures, should be without prejudice to the obligation of the browsers to recognize qualified website authentication certificates in accordance with the national trusted lists.</blockquote><p>Then, just to make sure we don't have any tremendously beneficial technologies like <a href="https://scotthelme.co.uk/tag/certificate-transparency/?ref=scotthelme.co.uk" rel="noreferrer">Certificate Transparency</a> protecting us, it is clarified that:</p><blockquote>Qualified certificates for website authentication shall not be subject to any mandatory requirements other than the requirements laid down in paragraph 1.</blockquote><p>Paragraph 1, of course, does not make any mention of Certificate Transparency. All of these points are then summarised in a newly added section with the title "Cybersecurity precautionary measures": </p><blockquote>1. Web-browsers shall not take any measures contrary to their obligations set out in Art 45, notably the requirement to recognise Qualified Certificates for Web Authentication, and to display the identity data provided in a user friendly manner.</blockquote><blockquote>2. By way of derogation to paragraph 1 and only in case of substantiated concerns related to breaches of security or loss of integrity of an identified certificate or set of certificates, web-browsers may take precautionary measures in relation to that certificate or set of certificates</blockquote><blockquote>3. Where measures are taken, web-browsers shall notify their concerns in writing without undue delay, jointly with a description of the measures taken to mitigate those concerns, to the Commission, the competent supervisory authority, the entity to whom the certificate was issued and to the qualified trust service provider that issued that certificate or set of certificates. Upon receipt of such a notification, the competent supervisory authority shall issue an acknowledgement of receipt to the web-browser in question.</blockquote><blockquote>4. The competent supervisory authority shall consider the issues raised in the notification in accordance with Article 17(3)(c). When the outcome of that investigation does not result in the withdrawal of the qualified status of the certificate(s), the supervisory authority shall inform the web-browser accordingly and request it to put an end to the precautionary measures referred to in paragraph 2.</blockquote><h4 id="the-industry-speaks-out">The industry speaks out</h4><p>It's not just me that thinks this is a bad idea though, of course, I'm just adding my voice to the chorus of other voices from across industry.</p><ol><li>Mozilla set up the <a href="https://securityriskahead.eu/?ref=scotthelme.co.uk" rel="noreferrer">Security Risk Ahead</a> website with lots of details.</li><li>The Chrome Security Team has called for change in <a href="https://security.googleblog.com/2023/11/qualified-certificates-with-qualified.html?ref=scotthelme.co.uk" rel="noreferrer">Qualified certificates with qualified risks</a>.</li><li>You can head over to <a href="https://last-chance-for-eidas.org/?ref=scotthelme.co.uk">https://last-chance-for-eidas.org/</a> to read more about the risks.</li><li>You can read our latest open letter with 400+ signatures so far. <a href="https://eidas-open-letter.org/?ref=scotthelme.co.uk">https://eidas-open-letter.org/</a></li></ol><figure><img src="https://scotthelme.co.uk/content/images/2023/11/zU7C5hOn_400x400.jpg" alt="" loading="lazy" width="400" height="400"></figure><p>The thing that it will always come down to for me, and the thing that you can use to guide your decisions, is to look at the interests of the parties involved. I've long been critical of many CAs for shitty marketing and shady practises, and it seems that's continuing. The organisations and voices speaking out in support of QWACs and Article 45 are those that are going to be able to sell them for $$$ once this comes to pass. The organisations and voices speaking out against QWACs and Article 45 are those with an interest in preserving and improving the security of the ecosystem we've worked so hard to build. I have nothing to gain here by swaying your opinion, but you sure as hell have a lot to lose.</p><h4 id="what-do-we-do-about-it">What do we do about it?</h4><p>I'll quote the following snippet from the 'Last Chance' <a href="https://last-chance-for-eidas.org/?ref=scotthelme.co.uk#what-next" rel="noreferrer">website</a>:</p><blockquote>If youâ€™re a European citizen, you can write to the member of the European Parliament responsible for the <a href="https://oeil.secure.europarl.europa.eu/oeil/popups/ficheprocedure.do?reference=2021%2F0136%28COD%29&amp;l=en&amp;ref=scotthelme.co.uk" rel="noreferrer">eIDAS file</a> - <a href="https://www.europarl.europa.eu/meps/en/112747/ROMANA_JERKOVIC/home?ref=scotthelme.co.uk" rel="noreferrer">Romana JERKOVIÄ†</a> - and register your concern.</blockquote><blockquote>If youâ€™re a cybersecurity expert, researcher or represent an NGO, consider signing the open letter at <a href="https://eidas-open-letter.org/?ref=scotthelme.co.uk" rel="noreferrer">https://eidas-open-letter.org</a>.</blockquote><p>In truth, I don't know what else to do next, but I believe we have to do something. If these Qualified Trust Service Providers (QTSP is the name given to a CA that issues QWACs) are all they're cracked up to be, then why can't they just submit to the existing audit/approval process and pass with flying colours?.. That's not too much to ask, is it?</p><h4 id="additional-information-and-reading">Additional information and reading</h4><p><a href="https://sslmate.com/resources/certificate_authority_failures?ref=scotthelme.co.uk" rel="noreferrer">Timeline of Certificate Authority Failures</a> - why Trust Store Operators need the ability to audit and remove Root CAs.</p><p><a href="https://www.european-signature-dialog.eu/ESD_answer_to_Mozilla_misinformation_campaign.pdf?ref=scotthelme.co.uk" rel="noreferrer">Mozilla website pushes serious eIDAS misinformation to political decision makers and public</a> - The ESD (<a href="https://ec.europa.eu/transparencyregister/public/consultation/displaylobbyist.do?id=994150833943-81&amp;ref=scotthelme.co.uk#scrollNav-13" rel="noreferrer">a group of CAs</a>) produced this laughable document. It closes by pointing out that Google and Mozilla are "investors" in Let's Encrypt who are "in competition with all QTSPs" ðŸ˜‚ (a QTSP is a CA that issues QWACs)</p><p>Digital rights organisation epicenter.works had <a href="https://epicenter.works/en/content/eu-digital-identity-reform-the-good-bad-ugly-in-the-eidas-regulation?ref=scotthelme.co.uk#:~:text=to%20this%20information.-,The%20Ugly,-QWACs" rel="noreferrer">this</a> to say about QWACs.</p><p>You should read what <a href="https://alecmuffett.com/article/108139?ref=scotthelme.co.uk" rel="noreferrer">Alec Muffett</a> has to say on eIDAS/QWACs.</p><p>This informative Tweet from <a href="https://x.com/rmhrisk/status/1721329896746848353?s=46&amp;t=Ms_J84N8ypSKLl6M43cBnQ&amp;ref=scotthelme.co.uk" rel="noreferrer">Ryan Hurst</a> is also a great start for info on the Internet PKI.</p><p><em>Update 19:10 UTC 7th Nov</em>: The EFF have just published something on this, <a href="https://www.eff.org/deeplinks/2023/11/article-45-will-roll-back-web-security-12-years?ref=scotthelme.co.uk" rel="noreferrer">Article 45 Will Roll Back Web Security by 12 Years</a>, and as you would expect, it's well written and makes a lot of sense!</p>
</div>
<br>If you want to get notified when I publish a new blog, please consider <a href="https://scotthelme.ghost.io/#/portal/signup">subscribing</a>!<p>
<i></i>
Tags: <a href="https://scotthelme.co.uk/tag/qwac/">QWAC</a>, <a href="https://scotthelme.co.uk/tag/eidas/">eIDAS</a>, <a href="https://scotthelme.co.uk/tag/tls/">TLS</a>, <a href="https://scotthelme.co.uk/tag/pki/">PKI</a>, <a href="https://scotthelme.co.uk/tag/ev/">EV</a></p>
</section>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What does and doesn't matter about Apple shooting their October event on iPhone (280 pts)]]></title>
            <link>https://prolost.com/blog/scarybts</link>
            <guid>38182869</guid>
            <pubDate>Tue, 07 Nov 2023 21:08:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prolost.com/blog/scarybts">https://prolost.com/blog/scarybts</a>, See on <a href="https://news.ycombinator.com/item?id=38182869">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-content-field="main-content" id="pageWrapper" role="main">
        <article id="article-6549717174a74b3d8221d4bd" data-item-id="6549717174a74b3d8221d4bd">

  <!--SPECIAL CONTENT-->

  
     
  

  
  <!--POST HEADER-->
    
  <header>
    
    
  </header>
  
  
  <!--POST BODY-->

  <div data-layout-label="Post Body" data-type="item" data-updated-on="1699312007408" id="item-6549717174a74b3d8221d4bd"><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699383543319_113472">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Actual footage of me watching the event.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699383543319_260414"><p>Then Apple posts a <a href="https://youtu.be/V3dbG9pAi8I">behind-the-scenes video</a> showing how this was done, revealing a rare and imposing glimpse into the scale and scope of their industry-leading launch videos. At the center of it all, instead of their customary <a href="https://en.wikipedia.org/wiki/Arri_Alexa">Arri Alexa</a> (a digital cinema camera costing $35â€“150K before you even add a lens, used to shoot everything from <em>Avengers: Endgame</em> to <em>Barbie),</em> was an off-the-shelf iPhone 15 Pro Max, gripped into truckloads of professional support gear.</p></div><div data-block-json="{&quot;thumbnailUrl&quot;:&quot;https://i.ytimg.com/vi/V3dbG9pAi8I/hqdefault.jpg&quot;,&quot;width&quot;:854,&quot;height&quot;:480,&quot;hSize&quot;:null,&quot;html&quot;:&quot;<iframe class=\&quot;embedly-embed\&quot; src=\&quot;//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FV3dbG9pAi8I%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DV3dbG9pAi8I&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FV3dbG9pAi8I%2Fhqdefault.jpg&amp;key=61d05c9d54e8455ea7a9677c366be814&amp;type=text%2Fhtml&amp;schema=youtube\&quot; width=\&quot;854\&quot; height=\&quot;480\&quot; scrolling=\&quot;no\&quot; title=\&quot;YouTube embed\&quot; frameborder=\&quot;0\&quot; allow=\&quot;autoplay; fullscreen; encrypted-media; picture-in-picture;\&quot; allowfullscreen=\&quot;true\&quot;></iframe>&quot;,&quot;url&quot;:&quot;https://youtu.be/V3dbG9pAi8I&quot;,&quot;resolvedBy&quot;:&quot;youtube&quot;,&quot;floatDir&quot;:null,&quot;providerName&quot;:&quot;YouTube&quot;,&quot;customThumbEnabled&quot;:false}" data-block-type="22" id="block-yui_3_17_2_1_1699312008488_9068"><p>




  <iframe src="//www.youtube.com/embed/V3dbG9pAi8I?wmode=opaque" height="480" width="854" scrolling="no" frameborder="0" allowfullscreen=""></iframe>

</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1699312008488_9121"><p>At this point, some folks felt differently about what was implied by â€œShot on iPhone.â€ There have been <a href="https://www.theverge.com/2023/10/31/23940060/apple-event-shot-on-iphone-behind-the-scenes">bad takes</a> on this, and <a href="https://daringfireball.net/linked/2023/10/31/downplaying-shot-on-iphone">good</a><a href="https://joe-steel.com/2023-11-01-Videography-For-Dummies.html">takes</a> on those bad takes.</p>
<p>Anyone who knows the tiniest bit about video production knows that the camera is a small, but important, but <em>small,</em> part of the overall production picture. â€œShot on iPhoneâ€ doesnâ€™t promise â€œand you can do it tooâ€ any more than Stanley Kubrick lighting <em>Barry Lyndon</em> with <a href="https://www.criterion.com/current/posts/5059-kubrick-s-candle-tricks-in-barry-lyndon">candlelight</a> means anyone with candles can make <em>Barry Lyndon.</em></p>
<p>But when the camera is the least expensive piece of gear on the set after clothespins and coffee, it does feel strange. Iâ€™ve been on a lot of productions like this, having played an active role in the DV filmmaking revolution of the late â€™90s-to-early-2000s. It was an odd feeling to scrounge for the adapter plates required to mount a $3,000 DV camcorder purchased at Circuit City to a Fisher dolly that literally has no purchase price.</p>
<p>Apple, of course, has no burden of best-practices logic for their decision to shoot their â€œScary Fastâ€ event on iPhone â€” itâ€™s a marketing ploy, a cool stunt, and a massive flex. A thing to do for its own sake. In the filmmaking community, it was the mic drop of the year. We greedily soaked up all the details in the behind-the-scenes video, and made a hundred tiny calculations about which aspects of this lavish production actually mattered to the question of the iPhone 15â€™s validity as a professional camera, and which did not.</p>
<p>With all that gear and production support, which aspects of the event really matter to you, the iPhone-curious filmmaker? What can you learn, and which aspects can you safely ignore?</p>
<p>Letâ€™s take it one at a time:</p>
<h2 id="that-they-did-it-does-matter">That They Did It: Does Matter</h2>
<p>As camera features have played a larger and larger role in Appleâ€™s marketing for new iPhones over the years, you might have begun to feel a bit of cognitive dissonance. Apple tells you about how great, and even â€œpro,â€ these new iPhone cameras are â€” but would never have dreamt of using them to shoot their own videos or product stills. Apple was effectively saying â€œpro enough for you, but not for us.â€ Valid, but a bit dissatisfying.</p>

</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699312008488_19622">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>A still frame from Appleâ€™s October 30 â€œScary Fastâ€ event video, shot on iPhone 15 Pro Max.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699312008488_19960"><p>Apple has set the aesthetic bar impossibly high with these pre-recorded events. Theyâ€™re not just executives teleprompting in front of Keynote slides â€” they feature â€œslice of lifeâ€ moments shot on huge sets and real locations. Elaborate visual effects transition between locations and settings that might be partially virtual. These videos have looked great ever since Covid pushed Apple to find an alternative to executives-on-stage-in-front-of-slides, and even as Apple is now once again able to welcome guests to in-person product launches, these lavishly-produced videos are the new gold standard in pitching the world on a new iThing.</p>
<p>With â€œScary Fast,â€ Apple repeated their now well-established high-production-value playbook, but yoinked out the professional cameras and lenses, and dropped in a commodity consumer telephone in their place.</p>
<p>And crucially, <em>none of us noticed.</em></p>
<p>Itâ€™s a big deal.</p>
<h2 id="they-shot-prores-log-matters-so-much-it-would-be-impossible-without-it">They Shot ProRes Log: Matters So Much It Would Be Impossible Without It</h2>
<p>There is one single feature of the iPhone 15 Pro that made this stunt possible: Log. As I detailed <a href="https://prolost.com/blog/applelog">here in words and video</a>, the â€œiPhone video lookâ€ is designed to win consumer popularity contests, not mimic Apple's own marketing videos, nor plug into professional workflows.</p>
<p>It may be hard to imagine that a slightly different bit of signal processing when recording a video file from a tiny sensor can make the difference between consumer birthday-cam and professional viability, bit that is exactly the power of log. Apple Log has catapulted the iPhone into filmmaking legitimacy.</p>

</div><div data-block-type="44" id="block-yui_3_17_2_1_1699312008488_28200">
<h2 id="they-used-big-lights-does-matter-with-an-asterisk">They Used Big Lights: Does Matter, With An Asterisk</h2>
<p>Appleâ€™s event was set at night, with a dark, Halloween-inspired look. It takes a lot of professional lighting gear to illuminate a wide shot of Appleâ€™s campus, and professional skill to balance this lighting with the practical sources on the building itself.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699312008488_37554">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg" width="3840" height="2160" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/a92c31a0-5743-4b57-873d-07115538eb25/BTS_01_iPhone+%2801319%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>You can do this for cheaper than it looks.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_9784"><p>Lighting matters more than any camera, more than any lens. As <a href="https://prolost.com/blog/2009/4/13/fact-moment-light.html">I wrote</a> in 2009:</p><blockquote>
<p>Photos are nothing but light â€” itâ€™s literally all they are made of. Timmyâ€™s birthday and Sallyâ€™s wedding are reduced to nothing but photons before they become photographs. So getting the light right is more meaningful to a photo than anything else.</p>
</blockquote><p>Should you look at the giant lights in Appleâ€™s video and feel dejected that your own productions will never afford this level of illumination? I say no, because a) youâ€™re probably not lighting up the whole side of an architectural marvel, and b) youâ€™re probably not designing your production around one of the worldâ€™s highest-paid CEOs.</p><p>For Tim Cookâ€™s appearance, Appleâ€™s production had their giant LED light panels on camera dollies, which is not typical. The two reasons I can image they did this are to be low-impact on the campus itself (rubber wheels instead of metal stands), and to be able to adjust the lighting quickly out of respect for Cookâ€™s valuable time. It makes the lighting rigs seem more complex than they really are.</p><p>What they really are is big, bright, and soft. And rather spareâ€‰â€”â€‰mostly key, a bit of fill.</p><p>Big, soft LED lighting is actually quite affordable these days. I have two <a href="https://www.bhphotovideo.com/c/product/1560654-REG/aputure_light_storm_ls_60x.html/BI/4778/KBID/5292">medium-power bi-color lights from Aputure</a>, and together they cost less than my iPhone 15 Pro Max. I couldnâ€™t cover Cookâ€™s opening wide shot with them, but I could get close.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699331059768_29490">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>That big softbox overhead? Now <em>thatâ€™s</em> expensive.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699331059768_34898">
<p>I might also be willing to compromise on my ISO settings to work with a smaller lighting package, where Apple seemingly was not. More on this below.</p><p>So the lighting is important, but the quantity of it and the support gear itâ€™s on is specific to this rarified type of time-is-money, night-exterior production. Donâ€™t be distracted by the extra equipment, focus on the fact that the lighting is actually rather spare .</p>
<h2 id="they-attached-the-iphone-to-cranes-and-gimbals-and-drones-and-dollies-does-not-matter-except-for-one-little-thing">They Attached the iPhone to Cranes and Gimbals and Drones and Dollies: Does Not Matter, Except for One Little Thing</h2>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699312008488_39805">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg" width="3840" height="2160" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/d57d0485-4961-446b-93ac-9dfea59024c7/BTS_01_iPhone+%2800742%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699312008488_40143"><p>The behind-the-scenes video is almost comical in its portrayal of the iPhone gripped into all manner of high-end support gear.</p>
<p>You do not need any of this stuff.</p>
<p>I mean, every filmmaker <em>needs</em> a crane shot â€” but this is why small cameras are so empowering: everything is a crane when your camera weighs less than a Panavision lens cap!</p>
<p>Check out <a href="https://youtu.be/OnS5sLclqqY">this video</a> from filmmaker Brandon Li. He uses a gimbal on a hand-held pole to create a perfect crane shot for the opening of his action short. Toward the end, he achieves a nifty top-down shot by... standing on a railing. All with a camera substantially more cumbersome than a phone.</p>

</div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_46552">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Director Brandon Li is his own crane.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_64587">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Get your kicks without sticks.</p>
          </figcaption>
        
      
        </figure>
      

    </div></div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_46890"><p>Apple used cranes and remote heads designed for big cameras because thatâ€™s how they know how to shoot these videos. Appleâ€™s marketing department is large, and knows exactly what they need on these productions. One thing they need is for a dozen people to watch the camera feed, making sure everything is committee-approved perfect.</p></div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_28757">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>This is just the DIT cart, not even the client monitor.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_29095"><p>This kind of client-driven support gear compounds on its own requirements. As Tyler Stalman points out in his <a href="https://youtu.be/lDqQ_C5BkY4">excellent breakdown video</a>, some of whatâ€™s bolted to the iPhones is simply a metal counterweight so that a gimbal head, designed for a much larger camera, can be properly balanced.</p>
<p>You can plug an external drive into the USB-C slot on the iPhone 15 Pro Max, or you can plug in an HDMI adapter for a clean client feed. If you want to do both, you need a USB-C hub, which at that point requires power. So now youâ€™ve got an Anton-Bauer battery pack mounted to this tangle of gear.</p>
<p>When you donâ€™t have clients, you can skip all that and just shoot. This means you can replace most of the gear you see here with a <a href="https://amzn.to/3stXw46">cheap consumer gimbal</a> â€” or a tripod.</p>
<p>And hereâ€™s the key takeaway for this point: Apple achieved optimal image quality from the iPhone in a number of ways, and one, Iâ€™m betting, was by turning off image stabilization â€” which is only advisable when this tiny camera is physically stabilized.</p>
<p>So you donâ€™t need all the stuff Apple used, but if you want comparable results, you need a way to mount your iPhone to something solid. Maybe not a whole powered cage, but certainly a simple tripod mount. Then you can eek out that last bit of extra image quality by turning off image stabilization â€” which brings us to our next point:</p>
<h2 id="they-used-the-blackmagic-camera-app-matters-as-much-as-log">They Used the Blackmagic Camera App: Matters as Much as Log</h2>

</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_70912">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg" width="3840" height="2160" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e02bed03-28ad-4650-b582-c84de4aeaa10/BTS_01_iPhone+%2802096%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>I donâ€™t think this exact rig was used to capture what we saw in the video, but I believe the settings are representative.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_71249"><p>The <a href="https://www.blackmagicdesign.com/products/blackmagiccamera">Blackmagic Camera App</a> has the option to turn off image stabilization, yes, and also like a million other features. Manual, locking exposure control is the top of the list, but thereâ€™s a ton more. The app includes a false-color mode to help match exposure from shot to shot. It can load a preview LUT, so you can shoot log but view something closer to what the audience will see.</p><p>Itâ€™s silly to be grumpy with Apple for not offering this power in their own camera app when they clearly worked with Blackmagic Design to have this app available day-and-date with the iPhone 15.</p><p>Oh, and itâ€™s free.</p><h2 id="they-used-a-180-shutter-matters-more-thank-you-think">They Used a 180Âº Shutter: Matters More Thank You Think</h2>
</div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_101663"><p>One slick feature of the Blackmagic Camera App is that you can choose to express the shutter speed in degrees, like a cinema camera, rather than fractions of a second, which is more typical in stills. A 180Âº shutter â€” where the shutter is open for half the duration of a single frame, e.g. 1/60th of a second at 30 fps â€” is important for a pro look. Anything slower and you get smeary blur and a camcorder look. Anything faster and your footage looks like you shot it on a phone, because 99% of the time our iPhones are using insanely fast shutter speeds to handle typical daylight. Look at any of your own daytime iPhone video â€” Iâ€™d be surprised if you see any motion blur at all.</p></div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-below&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;<p class=\&quot;\&quot; style=\&quot;white-space:pre-wrap;\&quot;>Compare Apple\u2019s motion blur to mine. 180\u00BA shutter vs. probably something more like 1\u00BA.</p>&quot;},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;isOldBlock&quot;:false,&quot;settings&quot;:{&quot;muted&quot;:true,&quot;autoPlay&quot;:true,&quot;loop&quot;:true,&quot;controls&quot;:&quot;none&quot;},&quot;url&quot;:&quot;&quot;,&quot;resolvedBy&quot;:&quot;native&quot;,&quot;nativeVideo&quot;:&quot;6549811d14cf17486eb7fe30&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1699314604996_106232"><p>Compare Appleâ€™s motion blur to mine. 180Âº shutter vs. probably something more like 1Âº.</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_106282"><p>Relatedly:</p>
<h2 id="they-shot-at-iso-55-matters-to-apple-s-goal-of-maximum-image-quality">They Shot at ISO 55: Matters to Appleâ€™s Goal of Maximum Image Quality</h2>
<p>Hereâ€™s where the level of professional control over the lighting starts to really matter: If Apple decided that they must shoot at ISO 55 (the lowest, although possibly not the <em>native</em> ISO of the 1x camera) for the highest image quality, and with a 180Âº shutter for the most pro-camera look, that means they have no other control over exposure. The iPhone 15 Pro 1x lens does not have a variable aperture, so shutter speed and ISO are your only exposure controls.</p>
<p>When shooting in uncontrolled environments, the typical method of limiting the amount of light entering the lens is via ND filters, sometimes <em>variable</em> ND filters. I donâ€™t see any evidence that Apple used filters on this shoot, which would fit with their overall prioritization of image quality over all else. So this goes back to lighting â€” Appleâ€™s team controlled that lighting perfectly, because they opted out of any exposure control they might have had in-camera.</p>
<p>I'm curious to learn more about this setting though. YouTubers Gerald Undone and Patrick Tomasso <a href="https://youtu.be/RNd74wyVtKw">did some tests</a> and found that the best dynamic range from the iPhone 15 Pro came from ISO 1100â€“1450, with 1250 being their recommended sweet spot. Did Apple prioritize low noise over dynamic range?</p>
<h2 id="they-shot-30p-doesn-t-matter">They shot 30p: Doesnâ€™t Matter</h2>
<p>Apple has used 30 frames-per-second for these pre-recorded keynotes since they started in September of 2020. Theyâ€™re not trying to be â€œcinematic,â€ theyâ€™re trying to make a nice, clean video that can take the place of a live event. 30p is a choice, and a fine one for an on-stage presentation. You might choose 24 or 25 fps for a more narrative look, and thatâ€™s great too.</p>
<p>Note that Appleâ€™s native Camera app offers 30.0 and 24.0 fps, but the Blackmagic Camera app adds support for 29.97 and 23.976 fps, which are the actual broadcast frame rates Apple uses for their productions.</p>
<h2 id="they-focused-manually-doesn-t-matter">They Focused Manually: Doesnâ€™t Matter</h2>
<p>The Blackmagic Camera app truly has a dizzying set of features, some seemingly part of an attempt to win some kind of bizarre bet. Like support for wireless external follow-focus controls? I mean, wow, but also, really?</p>
<p>Sure makes for a cool behind-the-scenes shot, but I bet you can live without this.</p>

</div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_128955"><h2 id="they-used-a-matte-box-does-matter">They Used a Matte Box: Does Matter</h2>
<p>While Apple did not attach any additional lenses to their production iPhones, they did put stuff in front of the built-in lenses â€” notably teleprompters, of course, and comically-large matte boxes.</p>

</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_132284">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg" width="3840" height="2160" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/18eab21f-fa71-4820-8df0-9c51635cf6e9/BTS_01_iPhone+%2801778%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_132621"><p>Matte boxes might feel like affectations in this context, but shielding that tiny lens from glare is actually a significant way to improve overall image quality. Luckily, you donâ€™t really need a full-on matte box to do this. A French flag will do it, as will your hand.</p></div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-below&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;<p class=\&quot;\&quot; style=\&quot;white-space:pre-wrap;\&quot;>If a bright light is dinging your little lens, you\u2019re leaving a ton of image quality on the floor.</p>&quot;},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;isOldBlock&quot;:false,&quot;settings&quot;:{&quot;muted&quot;:true,&quot;autoPlay&quot;:true,&quot;loop&quot;:true,&quot;controls&quot;:&quot;none&quot;},&quot;url&quot;:&quot;&quot;,&quot;resolvedBy&quot;:&quot;native&quot;,&quot;nativeVideo&quot;:&quot;6549982702e58c5eb5b22795&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1699314604996_437565"><p>If a bright light is dinging your little lens, youâ€™re leaving a ton of image quality on the floor.</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_437616"><h2 id="they-exclusively-used-the-1x-camera-does-matter-to-apple">They Exclusively Used the 1x Camera: Does Matter â€” to Apple</h2>
<p>The 1x camera, with image stabilization turned off, gives the highest-quality image available from the iPhone 15 Pro Max. Are you detecting a theme here? Apple imposed a number of limitations on how they used the iPhone camera, seemingly always in the name of maximizing image quality.</p>
<p>As weâ€™ll discuss below, you may or may not share this priority.</p>
<h2 id="they-edited-in-premiere-pro-doesn-t-matter">They Edited in Premiere Pro? Doesnâ€™t Matter</h2>

</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_182614">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg" width="3840" height="2160" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/85083792-4dd8-4492-8577-bd5dfb1bb3f5/BTS_01_iPhone+%2803165%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Real editor, fake set.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_182951"><p>Eagle-eyed viewers noticed that an Adobe Premiere Pro timeline appears behind the editor of â€œScary Fast.â€ But weâ€™re not in a real edit suite here â€” weâ€™re actually on one of the sets from the production. Did Apple <em>really</em> edit in Premiere?</p>
<p>I have a feeling that Stefan Sonnenfeldâ€™s interview was also staged at Appleâ€™s campus rather than filmed on-location at Company 3, to keep the production close to home for cost, control, and secrecy reasons. So letâ€™s assume Apple really did cut in Premiere. This means next to nothing. All editing software does the same job, and itâ€™s unlikely Apple would impose a workflow on the production company they hired to both shoot and post-produce the video.</p>
<p>Other than of course to ensure that it be cut on a Mac. Itâ€™s interesting to note that Appleâ€™s Pro Workflows Group, representatives from which are interviewed in the behind-the-scenes video, are a part of the hardware division at Apple. Their charter is to promote and support professional use of Apple <em>devices,</em> regardless of which software theyâ€™re running.</p>
<p>Should FCPX users be <a href="https://daringfireball.net/linked/2023/11/02/tobin-bts-scary-fast">nervous</a> that Apple might send it to live on a farm with Shake and Aperture? Itâ€™s hard to regain our trust here, but Apple did just release a very nice version for iPad a few months ago, and <a href="https://www.polarpro.com/products/iphone-15-case?variant=iPhone15ProForest">substantial updates</a> to that and the Mac version just yesterday.</p>
<p>So thereâ€™s really nothing to see here. Move along.</p>
<h2 id="they-colored-in-resolve-doesn-t-matter">They Colored in Resolve: Doesnâ€™t Matter</h2>
<p>Apple hired <a href="https://www.company3.com/">Company 3</a> to produce this video. Company 3 is best-known as a color house. In my VFX and commercial directing career. Iâ€™ve worked with several amazing colorists there, from Dave Hussey to Siggy Ferstl to their CEO, Stefan Sonnenfeld, who is prominently featured in the behind-the-scenes. Stephan is one of the most prolific, talented, and well-known colorists working today. I modeled half the presets in Magic Bullet Looks after his famous grades on films like <em>Transformers, 300, John Wick, Man on Fire,</em> and hundreds more.</p>

</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_196734">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg" width="3840" height="2160" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/9f3f2f02-c0d2-44c9-a63a-e637fae85939/BTS_01_iPhone+%2802346%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Real colorist, not his real office.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="44" id="block-yui_3_17_2_1_1699314604996_197072"><p>If you can get Stefan to color your video, <em>thatâ€™s</em> what matters â€” not the tool he uses. Resolve is â€œfreeâ€ (with many asterisks), but a session at Company 3 is four-figures per hour.</p>
<p>Whether you use Resolve, Magic Bullet, or whatever else, what matters here is that shooting log means color grading is not just possible, but essential, and great care was taken with this part of the process.</p>
<h2 id="this-all-makes-sense-why-do-i-still-feel-weird-about-it-">This All Makes Sense. Why Do I Still Feel Weird About it?</h2>
<p>As much as I might disagree with an accusation that Apple was disingenuous to say â€œShot on iPhoneâ€ about a massive production with seemingly unlimited resources, I understand where this feeling comes from. â€œShot on iPhoneâ€ carries with it the implication of accessibility. We are meant to be inspired by this phrase to use a tool that we already carry with us every day to capture videos that might transcend mere records of our lifeâ€™s moments, and become part of our artistic pursuits.</p>
<p>And we should absolutely feel that way about the iPhone 15 Pro and Pro Max.</p>
<p>The reason we feel slightly disconnected from Appleâ€™s impressive exercise is not that they were dishonest â€” it's that their priorities were different from ours. Apple wants to sell iPhones, and to accomplish this, they spared no expense to put the very highest image quality on the screen.</p>
<h4 id="as-a-filmmaker-you-care-about-image-quality-but-you-care-about-other-things-too-probably-more-">As a filmmaker, you care about image quality, but you care about other things too â€” probably more.</h4>
<p>Sticking to the 1x lens gives the best image quality, sure, but choosing the right lens for the story youâ€™re telling might matter more to a filmmaker. Youâ€™ll probably use all the focal lengths Apple supplied.</p>
<p>As much as you might value the clean image that comes from shooting at ISO 55, you might get more production value for your budget by using smaller lights (or available light!) and accepting some noise at higher ISOs.</p>
<p>You might truly appreciate the value of a 180Âº shutter, and simply not always have a camera case/cage that allows you to mount a variable ND filter to your telephone. I ordered one from <a href="https://proloststore.com/products/applelog">PolarPro</a> the day the iPhone 15 was released and it still hasnâ€™t shipped, so Iâ€™ve shot next to no 180Âº shutter footage so far.</p>
<p>You might well understand that turning off image stabilization will improve your image â€” unless your shot is now wobbly, because youâ€™re shooting handheld out the window of a moving car. So maybe youâ€™ll leave stabilization on, and be a <a href="https://www.instagram.com/p/BZaekQujG3T/">human crane</a>, or gimbal, or dolly, or all of the above.</p>

</div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-below&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;<p class=\&quot;\&quot; style=\&quot;white-space:pre-wrap;\&quot;>Never use the 5x lens. Never use image stabilization. Never shoot through a dirty windshield. And never get this dope-ass shot.</p>&quot;},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;isOldBlock&quot;:false,&quot;settings&quot;:{&quot;muted&quot;:true,&quot;autoPlay&quot;:true,&quot;loop&quot;:true,&quot;controls&quot;:&quot;none&quot;},&quot;resolvedBy&quot;:&quot;native&quot;,&quot;nativeVideo&quot;:&quot;6549c53542010b3a8b88fd32&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1699332889824_51888"><p>Never use the 5x lens. Never use image stabilization. Never shoot through a dirty windshield. And never get this dope-ass shot.</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1699332889824_51940"><p>Letâ€™s be honest: If image quality is your top priority, there are much better options for your next production than a consumer telephone. Youâ€™d probably choose the iPhone for accessibility, nimbleness, ubiquity, and cost. Those are great reasons, and when you pair them with image quality that can be mistaken for high-end cinema camera footage by a veteran colorist, youâ€™ve got something magic.</p><h2 id="give-it-to-me-in-bullets-you-long-winded-monster">Give It To Me In Bullets You Long-winded Monster</h2><p>So we may well ignore much of Appleâ€™s implied advice, but we would do well to follow some of it if we can:</p><ul>
<li>Use camera support. Not crazy camera support, but some.</li>
<li>Use lights. Not crazy lights, but some.</li>
<li>Use a camera app that allows manual control, like Blackmagic Camera</li>
<li>Use 180Â° shutter, if you can (ND filters will help)</li>
<li>Keep light off of the lens using a $8,000 matte box or a bit of black tape</li>
<li>Hire literally the worldâ€™s most famous colorist. Or just do some <a href="https://prolost.com/blog/applelog">color correction</a>.</li>
<li>And most importantly, shoot in log, with a good preview <a href="https://prolost.com/blog/applelog">LUT</a></li>
</ul>
</div><div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-below&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;<p class=\&quot;\&quot; style=\&quot;white-space:pre-wrap;\&quot;>The incredible production apparatus of my helicopter tunnel shot from my last post.</p>&quot;},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;isOldBlock&quot;:false,&quot;settings&quot;:{&quot;muted&quot;:true,&quot;autoPlay&quot;:true,&quot;loop&quot;:true,&quot;controls&quot;:&quot;minimal&quot;},&quot;url&quot;:&quot;&quot;,&quot;resolvedBy&quot;:&quot;native&quot;,&quot;nativeVideo&quot;:&quot;6549c8ee5cdb130a5993e91d&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1699333890972_22172"><p>The incredible production apparatus of my helicopter tunnel shot from my last post.</p></div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699333890972_96598">

      

      
        <figure>
          
        
        

        
          <a href="https://prolost.com/blog/applelog">
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg" data-image-dimensions="1920x800" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg" width="1920" height="800" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/e7641ddb-90bd-4831-b834-9ca32a90d580/thumbnail_05_heloTun_17_A1-SC+%2801007%29.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          </a>
        

        
      
        </figure>
      

    </div></div><div data-block-type="44" id="block-yui_3_17_2_1_1699333890972_22223"><h2 id="shot-on-iphone-means-what-it-means-to-you">Shot on iPhone Means What it Means to You</h2><p>All of this is academic if you donâ€™t go put it into practice. If you got this far and feel empowered to wring the most out of your iPhone 15 Pro with just the right amount of gear, thatâ€™s great. If you actively forget all of this and occasionally flip on the Log switch so you can play with the color of your iPhone videos in post, thatâ€™s great too.</p><p>Because hereâ€™s the thing: movies have already been shot on phones. No productionâ€™s decisions validate any camera for all other production needs. You decide what â€œShot on iPhoneâ€ means to you, if anything. And the way you decide is by getting out there and shooting something.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1699314604996_238460">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>I went to Peru with nothing but my iPhone 15 Pro Max. I shot some stuff with zero gear, and Iâ€™m having a blast color grading it various ways.</p>
          </figcaption>
        
      
        </figure>
      

    </div></div>
      
  <!--POST FOOTER-->
    
  
  

</article>




<!--PAGINATION-->
  

  




<!-- COMMENTS -->


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing a Compiler is Surprisingly Easy (part 1) (228 pts)]]></title>
            <link>http://sebmestre.blogspot.com/2023/11/en-writing-compiler-is-surprisingly.html</link>
            <guid>38182461</guid>
            <pubDate>Tue, 07 Nov 2023 20:36:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://sebmestre.blogspot.com/2023/11/en-writing-compiler-is-surprisingly.html">http://sebmestre.blogspot.com/2023/11/en-writing-compiler-is-surprisingly.html</a>, See on <a href="https://news.ycombinator.com/item?id=38182461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-974883917963364008">


<p>
Ever since I was a teenager I wanted to create my own systems programming
language. Such a programming language would certainly
have to be compiled to native code, which meant I'd have to write a compiler.
</p><p>
Even though I managed to write several half-working parsers, I'd always
fail at the stage of generating assembly code, as the task turned too complex.
</p><p>
In this blog I intend to show my teenage self how writing a code generator is, in fact, not
complex at all, and it can be fully done in a couple of weekends. (As long as we
make some simplifying assumptions)
</p>
 <blockquote>I will that assume you already know that <a href="https://sebmestre.blogspot.com/2023/11/en-representing-programs-within.html">representing programs within a
   program is surprisingly easy</a>
</blockquote>
<h2>Where do we even start?</h2>
<p>
The goal today is to translate a high level language to x86-64 machine code. Our
high-level language will have integer literals, variables, negation, and
addition.
</p><p>
To make our job simpler, we will translate the high level code to x86-64
assembly code, and use a pre-existing assembler (like the one inside GCC) to
translate that to machine code.
</p><p>
Let's get started. Here is how we will represent integer literals:
</p>
<pre>struct int_literal {
	int value;
};
</pre>
<p>
Compiling them is straightforward:
</p>
<pre>void compile_int_literal(struct int_literal* e) {
	printf("mov $%d, %%rax\n", e-&gt;value);
}
</pre>

<blockquote><code>printf</code> uses the <code>%</code> character to denote formatting commands, so a double <code>%%</code> is used to print the character verbatim.</blockquote>
<p>
Here I used the x86-64 <code>mov</code> instruction. This instruction moves data from one
place to another. In the notation used in this blog, the flow of data is
  left-to-right (i.e. the instruction is works as <code>mov source, destination</code>)
</p><p>
In this case we are moving an immediate value (a numeric constant written
directly in the code, notated with a <code>$</code> preceding it) into the "a" register (a
little space of data that lives directly inside the CPU, written as <code>%rax</code>)
</p>
<p>
The x86-64 <code>mov</code> instruction can be used in several ways ("addressing modes"):
immediate-to-register (the one we just used), register-to-memory, memory-to-register,
register-to-register, etc. We will see some of these later on.
</p><p>
I want to note that, at this point, many design decisions have already been made.
Most notably:
</p>
<ul>
  <li>Our compiler will output AT&amp;T-style assembly code to <code>stdout</code>, using <code>printf</code></li>
<li>The result of compiling an expression will be assembly code that computes and
  stores the value of that expression in <code>%rax</code></li>
</ul>
<p>
The last point is in no small part responsible for making the compiler so
simple, but it also means that the code we'll generate is not very efficient.
</p><p>
For the initiated, some obvious things that we could add to mitigate this are a
peephole optimizer and a register allocator. But these would force us to
implement some intermediate representation and make our compiler a lot more
complicated, so we are not going to.
</p><p>
Let's move on.
</p>
<h2>How can we implement variables?</h2>
<p>
The way we will represent variables in our compiler is with an integer. Yes, not
with a string that corresponds to the name of the variable, but an index that
represents where that variable will live in memory. Indeed, all variables will
be stored in our computer's main memory. In particular, they will live in a
  place called <i>the stack</i>.
</p>

<p>
The stack is a wonderful mechanism that allows us to quickly store some values
in memory and safely discard them once we don't need them. In memory, it is
simply laid out like an array of 64 bit integers.
</p><p>
The way it works is extremely simple: the CPU has a register -- known as the
stack pointer <code>%rsp</code> -- that always tells us the first slot in the stack that is
available to be used. Every slot after will be free, and every slot before will
be occupied. As with everything low-level, this doesn't happen magically, and we
will be responsible for keeping that register up to date.
</p><p>
We are going to be a bit naughty and not update the stack pointer for now. This
is mostly okay as long as our code does not perform any function calls.
</p><p>
With this in mind, we can represent variables using an index that tells us how
many slots *after* the first available slot the variable is stored.
</p>

<pre>struct variable {
	int slot;
};
</pre>

<blockquote>In a more complete compiler there would be a previous step that takes care of
  assigning a stack slot to each declared variable, and translating variable names to stack
  slots. We wouldn't expect the language user to type in the slots by hand.</blockquote>
<p>
Compiling them is simple enough, but we do need to learn some more x86-64
assembly to fully grasp it.
</p>
<pre>void compile_variable(struct variable* e) {
	int slot = e-&gt;slot;
	printf("mov %d(%%rsp), %%rax\n", -8 * (slot + 1));
}
</pre>
<p>
Here we use a different version of the <code>mov</code> instruction. This one looks like
<code>mov number(register1), register2</code>, and it means "take the value at address
<code>number+register1</code>, and store it in <code>register2</code>". (mem-to-reg mode)
</p><p>
This is how we implement access into the stack. The stack pointer holds the
address of the first free slot, and we add an offset to to access the slot that
holds the desired variable.
</p><p>
Besides that, there is a funny looking bit of math up there. There are two
things to know about the stack:
</p>
<ul>
<li>each slot holds a 64-bit value. This equals 8 bytes, which is why we multiply
  by 8</li>
<li>the stack grows downwards. This means that the occupied slots are at higher
  addresses than the free slots. This explains why the 8 is negative instead of
  positive</li>
<li>there is a +1 in there because I lied. The stack pointer actually points at the last
  occupied slot, instead of the first free slot.</li>
</ul>
<h2> Negation</h2>
<p>
The representation of negation is similarly straightforward, and should be
apparent to those who read the previous blog.
</p>
<pre>struct negation {
	struct expression* target;
};
</pre>

<blockquote>I will omit the definition of <code>struct expression</code> for now, as it would
distract from the main points of this section.</blockquote>
<p>
To compile negations we will take advantage of the fact that compiling an
expression will produce code that stores its result in <code>%rax</code>. This means that
if we emit some code that negates <code>%rax</code> right after the code that computes the
value to be negated, we will have succesfully computed the desired negation.
</p><p>
Luckily, x86-64 has an instruction that does just this.
</p>
<pre>void compile_negation(struct negation* e) {
	compile_expression(e-&gt;target);
	printf("neg %%rax\n");
}
</pre>
<p>
But just to get used to the kind of puzzles we have to solve to compile some
more complicated operations, let's avoid using <code>neg</code>. x86-64 has a <code>sub</code>
instruction that subtracts one operand from another. Let's try using that.
</p><p>
In particular, let's:
</p>
<ul>
  <li>compute the target expression (leaving the result in <code>%rax</code>)</li>
  <li>put a zero into <code>%rcx</code></li>
  <li>substract <code>%rax</code> from <code>%rcx</code> (leaving the negated result in <code>%rcx</code>)</li>
  <li>put the negated result in <code>%rax</code></li>
</ul>
<pre>void compile_negation(struct negation* e) {
	compile_expression(e-&gt;target);
	printf("mov $0, %%rcx\n");
	printf("sub %%rax, %%rcx\n");
	printf("mov %%rcx, %%rax\n");
}
</pre>
<blockquote><p>
We use <code>%rcx</code> instead of <code>%rbx</code> because <code>%rbx</code> is a callee-saved register in
x86-64, meaning we are not allowed to use it without first storing its old
content in the stack, and later restoring its value. This is mandated by the x86-64 calling conventions.
</p><p>
This is too cumbersome, so we just use the nearest non-callee-saved register.
</p></blockquote>
<p>
While not too complicated, this ilustrates the kind of hoops we will sometimes
have to jump through in order to compile more advanced operations. I don't think
this makes compiling hard, but it can get pretty tedious.
</p>
<blockquote>Also, note the use of the reg-to-reg addressing mode</blockquote>

<h2>Addition</h2>
<p>
Like in the previous blog, we will represent additions as follows:
</p>
<pre>struct addition {
	struct expression* left_term;
	struct expression* right_term;
};
</pre>
<p>
The general idea here will be to first compile the left term, then the right
term, then emit an <code>add</code> instruction that adds their results. The main problem
that arises is that the result of the the left term will be lost while we
compute the right term.
</p><p>
A simple fix might be to move the result to a different register, like this:
</p>
<pre>void compile_addition(struct addition* e) {
	compile_expression(e-&gt;left_term);
	printf("mov %%rax, %%rcx\n");
	compile_expression(e-&gt;right_term);
	printf("add %%%rcx, %%rax\n");
}
</pre>


  
<p>
Unfortunately, this will not work when the right term also stores something in
<code>%rcx</code> in an intermediate step. Instead, we will get some help from to our good
friend, the stack.
</p><p>
We will store that intermediate value in the stack, and read it back after the
right term is done computing. If we take care that the code we generate for the
right term doesn't write into the same stack slot, then we can be sure that the
value will be preserved.
</p><p>
The mechanism to prevent re-using the same stack slot is a simple counter. Since
we also store variables in the stack, its value must be greater than any slot
that's been assigned to a variable. For now let's just initialize it with some
large number, like 10.
</p>
<pre>int temp_counter = 10;
void compile_addition(struct addition* e) {
	compile_expression(e-&gt;left_term);
	int slot = temp_counter++; // allocate a new slot
	printf("mov %%rax, %d(%%rsp)\n", -8 * (slot + 1));
	compile_expression(e-&gt;right_term);
	printf("add %d(%%rsp), %%rax\n", -8 * (slot + 1));
	temp_counter--; // restore the counter
}
</pre>

<blockquote>Here we finally see a <code>mov</code> that uses reg-to-mem addressing mode. Also, note that <code>add</code>
can also use mem-to-reg mode.
</blockquote>
<h2>Putting it All Together</h2>
<p>
The final piece of the puzzle, for now, is the <code>struct expression</code> data type,
and its corresponding <code>compile_expression</code> function. These are pretty much
trivial given what we've seen so far, but I'll type them out for completeness'
sake.
</p>
<pre>enum expression_tag {
	EXPRESSION_INT_LITERAL,
	EXPRESSION_VARIABLE,
	EXPRESSION_NEGATION,
	EXPRESSION_ADDITION,
};
struct expression {
	enum expression_tag tag;
	union {
		struct int_literal as_int_literal;
		struct variable as_variable;
		struct negation as_negation;
		struct addition as_addition;
	};
};

void compile_expression(struct expression* e) {
	switch (e-&gt;tag) {
	case EXPRESSION_INT_LITERAL:
		compile_int_literal(&amp;e-&gt;as_int_literal);
		break;
	case EXPRESSION_VARIABLE:
		compile_variable(&amp;e-&gt;as_variable);
		break;
	case EXPRESSION_NEGATION:
		compile_negation(&amp;e-&gt;as_negation);
		break;
	case EXPRESSION_ADDITION:
		compile_addition(&amp;e-&gt;as_addition);
		break;
	}
}
</pre>

<h2>Testing it out</h2>
<p>
At this point, we are capable of compiling simple arithmetic expressions. To
test this out, we can write a small program like this one:
</p>
<pre>int main() {
	// var0 + (-var1 + 42)
	struct expression* e =
		addition(
			variable(0),
			addition(
				negation(variable(1)),
				int_literal(42)));
	compile_expression(e);
}
</pre>

<blockquote><code>int_literal</code>, <code>variable</code>, <code>negation</code> and <code>addition</code> are some helpers that
build up the corresponding expressions.</blockquote>
<p>
Which produces the following output:
</p>
<pre>mov -8(%rsp), %rax
mov %rax, -88(%rsp)
mov -16(%rsp), %rax
neg %rax
mov %rax, -96(%rsp)
mov $42, %rax
add -96(%rsp), %rax
add -88(%rsp), %rax
</pre>

<p>
Then, to be able to run it, we can just add some assembly that will take two
arguments and store them in stack slots 0 and 1, and return after executing the
code.
</p>
<pre>.global foo
foo:
	mov %rdi, -8(%rsp)
	mov %rsi, -16(%rsp)

	mov -8(%rsp), %rax
	mov %rax, -88(%rsp)
	mov -16(%rsp), %rax
	neg %rax
	mov %rax, -96(%rsp)
	mov $42, %rax
	add -96(%rsp), %rax
	add -88(%rsp), %rax

	ret
</pre>

<p>
Finally, we hook into this code from C, and check that it returns the right thing:
</p>
<pre>#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;
int64_t foo(int64_t a, int64_t b);
int main() {
	for (int i = 0; i &lt; 10; ++i) {
		for (int j = 0; j &lt; 10; ++j) {
			printf("expected: %d, got: %ld\n", i-j+42, foo(i, j));
		}
	}
}
</pre>

<p>
To do this we compile using GCC and run it in a terminal:
</p>
<pre>$ gcc main.c foo.s -o main
$ ./main
expected: 42, got: 42
expected: 41, got: 41
expected: 40, got: 40
... and so on ...
</pre>

<h2> Conclusion</h2>
<p>
Writing a compiler is not as hard as it seems if we are willing to keep it
simple. If we avoid introducing complexity ourselves, its main source is
understanding the target architecture, and not the compilation process itself.
</p><p>
In the next parts we will look at how to compile classic control flow constructs
such as <code>if</code> and <code>while</code>, as well as function calls and pointers.
  </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Ray, this is a religion': How Bridgewater lost two top hires (173 pts)]]></title>
            <link>https://nymag.com/intelligencer/article/ray-dalio-rob-copeland-the-fund-book-excerpt.html</link>
            <guid>38181408</guid>
            <pubDate>Tue, 07 Nov 2023 19:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nymag.com/intelligencer/article/ray-dalio-rob-copeland-the-fund-book-excerpt.html">https://nymag.com/intelligencer/article/ray-dalio-rob-copeland-the-fund-book-excerpt.html</a>, See on <a href="https://news.ycombinator.com/item?id=38181408">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="nymag.com/intelligencer/_components/article/instances/clon9g6bj001v0pge3mlcivcl@published" data-content-channel="Business" data-crosspost="" data-type="Book Excerpt" data-syndication="original" data-headline="â€˜Ray, This Is a Religionâ€™" data-authors="Rob Copeland" data-publish-date="2023-11-07" data-tags="chapters, ray dalio, the money game, wall street, money, book excerpt, remove interruptions" data-issue-date="" data-components-count="75" data-canonical-url="http://nymag.com/intelligencer/article/ray-dalio-rob-copeland-the-fund-book-excerpt.html">
    


  
  
  
  <header>
    <div>
      <div>
          
            <h2 data-editable="displayTeaser">How the worldâ€™s largest hedge fund lost two top hires â€” and was paralyzed by puddles of pee.</h2>
            

            
        </div>
          <div>
            <p>
              Ray Dalio is the founder of the Bridgewater Associates, the worldâ€™s largest hedge fund.
              <span>Photo-Illustration: Intelligencer; Photos: Getty</span>
            </p>
          </div>
    </div>
      <div data-editable="lede">
          <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.2x.rhorizontal.w1100.jpg" width="1100" height="733"> <img src="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.rhorizontal.w1100.jpg" data-content-img="" width="1100" height="733" fetchpriority="high"> </picture>
          </div>
        <p>
            Ray Dalio is the founder of the Bridgewater Associates, the worldâ€™s largest hedge fund.
          <span>Photo-Illustration: Intelligencer; Photos: Getty</span>
        </p>
  </header>
  <section>
    <div data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.2x.rhorizontal.w1100.jpg" width="1100" height="733"> <img src="https://pyxis.nymag.com/v1/imgs/31f/e60/adfb533a3933c603006dbe63dd54dc70bd-ray-dalio.rhorizontal.w1100.jpg" data-content-img="" width="1100" height="733" fetchpriority="high"> </picture>
          </div>
            <div>
              <p>
                  Ray Dalio is the founder of the Bridgewater Associates, the worldâ€™s largest hedge fund.
                <span>Photo-Illustration: Intelligencer; Photos: Getty</span>
              </p>
            </div>
              </div>
            <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9g6bj001u0pgetusj4kt7@published" data-word-count="5"><em>Thereâ€™s piss on the floor</em>.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka2x001s3b82gi87hayl@published" data-word-count="36">So read the email from Ray Dalio, founder of the worldâ€™s largest hedge fund, Bridgewater Associates, and a billionaire many times over. It would be read by more than 1,000 of his underlings at the company.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka2x001t3b8268r85lja@published" data-word-count="44">Everyone at Bridgewater would soon learn the backstory. Dalio had excused himself from a meeting and walked to the nearest restroom at Bridgewaterâ€™s sprawling, medieval-stone-style headquarters near Westport, Connecticut. After relieving himself at the urinal, Dalio glanced down. There was piss on the floor.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka2y001u3b82qgcq4wfw@published" data-word-count="19">This couldnâ€™t be allowed to go on, Dalio said. Whose was it? And who had permitted it to happen?</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka2y001v3b82l2ejqxw6@published" data-word-count="13">â€œIf people canâ€™t aim their fucking pee, they canâ€™t work here,â€ Dalio proclaimed.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka2y001w3b82m5a4jrzf@published" data-word-count="135">It seemed inconceivable that it could be an accident. After all, Dalio ruled Bridgewater under what he called his â€œPrinciples,â€ which held that no matter was too small for investigation. There were hundreds of Principles, including one that stated, â€œPeople have to value getting at truth so badly that they are willing to humiliate themselves to get it.â€ Employees were instructed to â€œprobeâ€ one anotherâ€™s work, as Dalio put it, on a daily basis. That wasnâ€™t all. As part of what Dalio called â€œradical transparency,â€ a team of videographers and editors made tapes and videos of Dalioâ€™s many lessons to his staff. These were uploaded into what Bridgewater called its â€œTransparency Library,â€ viewable internally. All employees at Bridgewater â€” from top investment strategists to receptionists â€” were required to view cases pulled from this library.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka30001x3b82d4s2yjck@published" data-word-count="94">That puddle of urine on the bathroom would be the subject of one of these cases. Dalio summoned the hedge fundâ€™s head of facilities for questioning. Staff were assigned to a rotating guard, standing outside the restroom to take notes on all who entered â€” and whether they left clean floors. After each visitor, a member of the cleaning crew would rush in to mop. New urinals were brought in for testing. Stickers were applied to the porcelain to give men a more effective target. Then the exact placement of the stickers was probed.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka30001y3b82bw4l6574@published" data-word-count="17">For all that, Dalio was never able to figure out exactly what had happened at that urinal.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka31001z3b82oynyqq0l@published" data-word-count="45">Thereâ€™s plenty of weird behavior in the business world, from Mark Zuckerbergâ€™s glamour-shot hydrofoiling with an American flag on Independence Day to Goldman Sachs CEO David Solomonâ€™s boasting to his underlings that he â€” and only he â€” had received a blowjob the night before.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3100203b825aaxzgm5@published" data-word-count="7">And then there is Dalio and Bridgewater.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3100213b82y3xalxn9@published" data-word-count="86">Since founding Bridgewater nearly 50 years ago, Dalio has become one of the worldâ€™s richest investors (Forbes pegs his net worth at roughly $20 billion). He is widely credited with having predicted and profited from the 2008 financial crisis, which made him famous. Yet the Greenwich, Connecticut, resident professes to be seeking something more important than the mere accumulation of wealth. His main interest, as he wrote in his best-selling autobiography-<em>cumâ€“</em>self-help book, <em>Principles: Life and Work,</em> is to lead others toward â€œmeaningful livesâ€ and â€œmeaningful relationships.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3100223b820vdv01oe@published" data-word-count="134">Core to that effort is Dalioâ€™s narrative that all Bridgewater employees are on an equal playing field and that any difference in rank or authority is due only to a rigorous system that susses out merit. That system involves employees constantly rating one another, taking real-time polls in meetings on whether a speaker is right or wrong, voting on whom to hire and fire, and being quizzed on internal case studies and investigations. This corporate culture, featuring a strict and overarching dogma created and enforced by a charismatic leader, has been repeatedly compared to a cult. Itâ€™s a comparison Dalio rejects. As he told one interviewer, â€œItâ€™s the opposite of a cult. Itâ€™s independent thinking. Itâ€™s you knowing that you have the right and obligation to make sense of everything. It is a culture.â€</p>

  <div data-uri="nymag.com/intelligencer/_components/image/instances/clonhmnna000o3b807jsx12yb@published" data-editable="settings">
    
    <p>
      Ray Dalio in 2019.
      <span>Photo: David Paul Morris/Bloomberg via Getty Images</span>
    </p>
</div>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3200233b82qk2311t0@published" data-word-count="44">Dalio declined to be interviewed for <a href="https://www.amazon.com/Fund-Bridgewater-Associates-Unraveling-Street-ebook/dp/B0BST4LN26?tag=thestrategistsite-20&amp;ascsubtag=__in1107aam__clon9g6a4001c0pge17h79oez________________" rel="sponsored,nofollow" data-track-type="product-link">the book from which this article is adapted</a>. This excerpt is based on dozens of interviews with current and former Bridgewater employees, as well as on copies of emails, recordings, internal company documents, and published interviews and articles.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3f00243b82y0hxmkn2@published" data-word-count="24">Dalioâ€™s lawyer said the Bridgewater founder â€œtreated all employees equally, giving people at all levels the same respect and extending them the same perks.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3f00253b82hbtpad1r@published" data-word-count="103">While Dalio is hardly the first financier to develop a taste for the spotlight, thereâ€™s no doubt that heâ€™s been fabulously successful at selling the gospel of Ray. Over the past ten years, he has become world-famous, appearing on major broadcast and cable networks, popular podcasts, and magazine covers and starring in TED Talks. Inside Bridgewater, Dalio has bragged that Bill Gates, Elon Musk, and Jack Dorsey are all interested in his Principles (none of those three would comment). He has said that Sean â€œDiddyâ€ Combs asked to be personally mentored. He was interviewed by Gwyneth Paltrow, who suggested he run for president.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3g00263b829bci5lt4@published" data-word-count="22">The truth is that at Bridgewater, some are more equal than others. And Ray Dalio is the most equal one of all.</p>

  

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3g00283b82o0vt6o0a@published" data-word-count="99">The piss case, as it was known internally, was merely a small example of the expansive Bridgewater employee-rating system in action. Staffers were given iPads and directed to rank one another on a one-to-ten scale on their performance dozens of times per day in categories derived from Dalioâ€™s Principles, such as â€œability to self-assessâ€ and â€œpushing through to results.â€ Dalio would often review the results in his office, where the Bridgewater founder would lean back in his chair, chewing on Scotch tape, as was his habit when he was concentrating, and review the ever-changing ratings of those under him.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3h00293b82yeexhqry@published" data-word-count="112">The goal of all the data, Dalio would say, was to sort everyone at Bridgewater on a single scale. At Bridgewater, the most important assessment was â€œbelievability,â€ a score that was applied to each category. If one was judged highly believable in â€œpushing through to results,â€ for instance, then his or her ratings of other people in the same category would be counted more heavily. Dalio called this â€œbelievability weighting,â€ and in virtually all important categories, Dalio expected that his rating would be the highest, or close to it, at the firm. That status essentially gave him the final word, no matter how many others at Bridgewater might have disagreed with him.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3h002a3b82xlxllq17@published" data-word-count="112">For more than a decade, at a cost that would balloon to over $100 million, Bridgewater attempted to develop secret software to expand the Principles into what employees widely described as a computerized version of Dalio himself. One iteration carried the nickname â€œPrince,â€ short for Principles. Prince was to be the equivalent of Siri, the voice-activated assistant on Apple products. Just as billions of consumers around the world spoke to Siri to get the answers to their queries, so, too, would Prince be the singular source for answers according to the Principles and highly believable employees. The product was first intended for use inside Bridgewater, and then, Dalio hoped, by the world.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3i002b3b822gm0hs62@published" data-word-count="70">For his star creation, Dalio hunted for a star technologist to bring it to life. Near the end of 2012, he found one in computer scientist David Ferrucci, as close to a celebrity as there was at that time in the field of artificial intelligence. Ferrucci had worked at IBM and led the team that created Watson, a question-answering AI system that made headlines by beating human competitors on <em>Jeopardy!.</em></p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3i002c3b82t5prfv5z@published" data-word-count="111">Ferrucci said publicly that he was enthusiastic to join Bridgewater to help predict the direction of financial markets. This made perfect sense â€” any other hedge fund would have put Ferrucci to work on investments. Instead, Bridgewater put Ferrucci, who reported to Dalioâ€™s deputy Greg Jensen, in charge of a new team that operated in secret and went by a strange name, the Systematized Intelligence Lab. Its main task was to add artificial intelligence to Prince and the other Principles rating tools. Few who werenâ€™t a part of his group were let into the lab and almost no one else at the hedge fund had a clue what was happening there.</p>

  <div data-uri="nymag.com/intelligencer/_components/image/instances/clonhonw1000v3b80iwmhkogb@published" data-editable="settings">
    
    <p>
      David Ferrucci, creator of IBMâ€™s Watson and high-profile Dalio hire, in 2017.
      <span>Photo: Alex Flynn/Bloomberg via Getty Images</span>
    </p>
</div>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3j002d3b82odh5fg4w@published" data-word-count="136">Roughly one year into Ferrucciâ€™s tenure at Bridgewater, Dalio burst into the hedge fundâ€™s headquarters full of excitement. It was just after Christmas 2013, and the night before he had seen a new movie, the Oscar-nominated <em>Her</em>, about a forlorn single man, played by Joaquin Phoenix, who falls in love with his Siri-like virtual assistant, voiced by Scarlett Johansson. Dalio, too, had apparently been taken by Johanssonâ€™s sultry work. â€œLetâ€™s get her,â€ Dalio said. â€œWeâ€™ll pay her to be the voice of Prince!â€ But Bridgewaterâ€™s staff couldnâ€™t get Johanssonâ€™s representatives to return their calls. There was a tantalizing mystery to what was going on inside Ferrucciâ€™s lab. Some of the few with access were consultants from the venture-capital billionaire Peter Thielâ€™s data-crunching firm, Palantir, famed as the tech spooks who helped hunt down Osama bin Laden.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3k002e3b82kn2jjvnb@published" data-word-count="84">What was becoming obvious to Ferrucci and his staff, however, was that Prince â€” and the Principles â€” were a mess. Ferrucci told colleagues he couldnâ€™t figure out where to begin applying hard science to the rating tools. Before Ferrucciâ€™s arrival, it seemed there had been no double-blind tests, no anonymous surveys â€” not even a simple regression analysis to show that the adoption of the Principlesâ€™ methods led to better results. (â€œI donâ€™t believe in regressions,â€ Dalio told one employee who suggested it.)</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3k002f3b82mk9js5g7@published" data-word-count="267">Bridgewaterâ€™s most important results, the returns of its key hedge funds, seemed to even suggest the opposite: The more time that people spent on the Principles â€” and its associated arguments, votes, case studies, and rating experiments â€” the worse the companyâ€™s investments seemed to perform. In the six years following the financial crisis, Bridgewaterâ€™s main fund, Pure Alpha, turned in two good years and four poor ones.Still, Ferrucci tried to bring Dalioâ€™s vision for the Principles rating tools to life. He modeled his approach on how IBM created Watson. The first step had been to gather a raw trove of real-world knowledge needed to produce answers. IBM engineers seeded Watson with millions of documents, newspaper articles, and books. Ferrucci and his team grappled with what an equivalent process might look like for a program grounded in the Principles. The goal was for Ferrucciâ€™s software to be able to listen in real time to discussions at Bridgewater and identify which Principles needed to be applied at any given moment. He laid out a list of attributes in Dalioâ€™s Principles and looked them up in the dictionary. â€œWhat does creativity actually mean?â€ he asked. The answer, from Merriam-Webster was â€œthe ability to create.â€ He looked up another attribute: lateral thinking. The definition, â€œA method for solving problems by making unusual or unexpected connections between ideas.â€ Ferrucci and his team found that many of the various attributes seemed to bleed into one another. Long periods of time were spent on futile attempts to define them in a manner that was workable in a software program. It was a slog.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3o002g3b82b5awzrh1@published" data-word-count="49">(Ferrucci declined to be interviewed. He denied that he used a dictionary to look up definitions of personality attributes. His spokeswoman wrote in an email about his work for Bridgewater, â€œQuantitative survey data was used to find statistically significant differentiation using industry-standard statistical methods.â€ Asked to elaborate, she declined.)</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3p002h3b82mxf91cg1@published" data-word-count="101">Ferrucci tried a different way. Dalio was the inventor of the Principles â€” surely he could tell the different attributes apart. Ferrucci decided to seed the software system with Dalioâ€™s own definitions of the terms. Ferrucciâ€™s team pulled hundreds of hours of videos from the Transparency Library, Bridgewaterâ€™s repository of meeting recordings, and tried to track patterns in when Dalio cited specific Principles. Ferrucciâ€™s lab employees also went through years of Bridgewaterâ€™s old management-training videos â€” the same ones that all staffers were tested on, including the piss case â€” and painstakingly noted which Principles were used, and in what context.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3p002i3b822zo8sh92@published" data-word-count="86">From all this effort, the researchers created a series of word clouds, intending to show whether employees who used certain language tended to rate highly in one attribute or another. More broadly, Ferrucci hoped to train a computer to read or listen to a passage of text and realize that, if certain words were used in a certain order, the topic at hand dealt with one Principle or another. If the scientists could nail the method, they could essentially create a computerized version of Dalio himself.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3q002j3b82dksxh80b@published" data-word-count="54">The goal proved elusive. Ferrucciâ€™s team could find no pattern to predict when the Bridgewater founder â€” or anyone else at Bridgewater â€” would bring up one Principle or another. The employee ratings also showed little underlying logic. Ferrucci shared with colleagues a gradual awakening: Dalioâ€™s system might not be a system at all.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3q002k3b82rxtujb5b@published" data-word-count="32">A few days before Christmas 2014, roughly two years into Ferrucciâ€™s tenure, Dalio called a meeting with him and a host of others from the lab to review progress on their work.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3q002l3b82dv2nvvf6@published" data-word-count="69">The rating system was still a work in progress, but Dalio had access to a prototype that graded more than 1,000 employees in dozens of categories. Dalio began pointing out problems with the ratings of specific Bridgewater employees. Some were rated too highly, Dalio said, which must have been an error in the calculations â€” the Bridgewater founder knew these individuals to be less competent than the numbers indicated.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3q002m3b82e6zzbdo8@published" data-word-count="20">Ferrucci sat quietly. Midway through his remarks, Dalio stopped and said, â€œIâ€™m giving you direction. Youâ€™re not writing it down.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002n3b82m2njwp7x@published" data-word-count="7">â€œIâ€™m taking in your input,â€ replied Ferrucci.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002o3b82q1b8k4y2@published" data-word-count="8">Dalio cocked his head. â€œYou work for me.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002p3b82ea0qn5lr@published" data-word-count="4">â€œI work for Greg.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002q3b82jh05705m@published" data-word-count="38">â€œNo, you work for me.â€ Dalio waved his hands in a flutter of frustration. He turned to the dozen or so people in the room. â€œHow many people think that Dave is looking at this the right way?â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002r3b828htodoph@published" data-word-count="29">One of Dalioâ€™s assistants typed the prompt into her iPad, creating an instant poll for those in the room. The verdict was that Ferrucci was looking at it wrong.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002s3b820m1cmt46@published" data-word-count="35">Dalio continued, pointing out how unlikely it was that certain people could be rated in one way or another in certain attributes. He gave his list of tweaks: â€œThis is what I want to see.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002t3b82f6ftztik@published" data-word-count="13">Ferrucciâ€™s voice came back, barely above a whisper. â€œThatâ€™s not a valid algorithm.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002u3b82pl5ve051@published" data-word-count="4">Dalio cocked his head.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002v3b82r56tvus2@published" data-word-count="30">Ferrucci, voice quavering, said, â€œThatâ€™s not scientific, Ray.â€ The team couldnâ€™t just make changes based on Dalioâ€™s whims. â€œItâ€™s not how I work. I canâ€™t just take direction like this.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3r002w3b820fo3u9c4@published" data-word-count="57">The room seemed to shift. The group had seen Dalio tear into countless underlings before, but here he was on unfamiliar ground. He wasnâ€™t in a position to argue computer science with his hand-picked expert. After the meeting, Ferrucci went from the meeting to Bridgewaterâ€™s parking lot visibly brimming with anger. Many present assumed he would quit.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3s002x3b82fl6rahz1@published" data-word-count="24">Ferrucciâ€™s spokeswoman said the scientist and Dalio â€œwould regularly have disagreements and would openly debate â€¦ always respecting each other and their respective opinions.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3s002y3b824dlcxc79@published" data-word-count="42">Bridgewater and Dalio declined to comment on the friction. In a joint statement, they said Dalio â€œhas always believed that there are many dimensions to every personâ€ and wanted â€œto develop an objective, measurable way to assess individualsâ€™ relative strengths and weaknesses.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3s002z3b82tvfo9dmd@published" data-word-count="81">The prospect of Ferrucci leaving the firm was treated as a five-alarm fire. Besides Dalio, he was the best-known Bridgewater employee. Also, quantitative investing was the wave of the future, and any rival hedge fund would have been thrilled to swoop in and hire Ferrucci. Bridgewater didnâ€™t want to have to explain to its clients and the world that it had lost the IBM Watson inventor â€” particularly if the reason was that Ferrucci judged Dalioâ€™s management system to be hogwash.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3s00303b82hykujvs6@published" data-word-count="54">The day after Christmas, Ferrucci received a note that Dalio wanted to chat again, this time by phone, according to two people briefed on the call afterward. There would be no crowd around a table, and no recording for everyone to listen to. The two men could speak frankly about how to move forward.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3t00313b8260cwjao8@published" data-word-count="10">Ferrucci told Dalio that he couldnâ€™t do the ratings anymore.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3t00323b82bd4br221@published" data-word-count="11">Dalio asked what could get the scientist to change his mind.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3t00333b823n1cvzln@published" data-word-count="102">Ferrucci was prepared for that question. He had an idea for a start-up company, Elemental Cognition, completely unconnected to Bridgewater or investing. Elemental Cognition would use the technology behind Watson to teach computers to understand common sense, human intuition. This could not be achieved merely by trawling the internet for knowledge or reading every book in existence. Elemental Cognitionâ€™s goal required the mastery of fundamental concepts such as time, causality, and social interaction. It would require expensive, advanced supercomputing and the services of a slew of Ph.D. researchers. All of this would be expensive, with no guarantee that anything would work out.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3t00343b82h3knbxq9@published" data-word-count="47">Dalio said that he would fund it. He offered tens of millions of dollars from Bridgewater, on one condition. Ferrucci could spend only half his time on his dream company. The other half of the time, Ferrucci would pursue the work that Dalio wanted him to pursue.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3u00353b82aut6anp6@published" data-word-count="4">Ferrucci took the deal.</p>

  

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3u00373b82xvey3jnf@published" data-word-count="61">With Ferrucci now on the equivalent of part-time status, Dalio hunted for more big-name technology help. In May 2016, he hired Steve Jobsâ€™s former lieutenant, Jon Rubinstein, who at Apple had been nicknamed the Podfather for helping create the first iPod. In exchange for compensation of as much as $50 million over the first two years, Rubinstein became Bridgewaterâ€™s co-chief executive.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3u00383b828u2dxlp7@published" data-word-count="73">â€œTechnology is pervasively important at Bridgewater, especially since one of our major strategic initiatives in the coming years is to continue building out the systemized decision-making that has been so successful in our investment area and to extend it to our management as well,â€ Dalio wrote to clients in announcing the new hire. Rubinsteinâ€™s phone quickly blew up with well-wishers congratulating him on landing a prestigious gig at the worldâ€™s largest hedge fund.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3u00393b82hudv36my@published" data-word-count="74">It didnâ€™t take long for Rubinstein to start having doubts. In his first days, Rubinstein sat, befuddled, as a procession of Bridgewater staffers drilled him on the Principles. They showed him slides and videos of employees being investigated and probed by their superiors, including Dalio. Rubinstein was immediately turned off. His former boss Jobs had a well-earned reputation for being controlling, but the Apple founder never claimed it was due to any high-brow philosophy.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3v003a3b82eskhqbgm@published" data-word-count="61">Rubinstein, who declined to comment, was cognizant of everything heâ€™d heard about the Bridgewater founderâ€™s love of raw honesty and decided to tell Dalio what was on his mind: â€œYouâ€™ve got 375 Principles. Those arenâ€™t principles. Toyota has 14 principles. Amazon has 14 principles. The Bible has ten. Three hundred and seventy-five canâ€™t possibly be principles. They are an instruction manual.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3v003b3b82hqpgw0fa@published" data-word-count="12">Dalio told him he simply needed more time to understand it all.</p>

  <div data-uri="nymag.com/intelligencer/_components/image/instances/clonhq8y400123b808nfypnj7@published" data-editable="settings">
    
    <p>
      Jon Rubinstein â€” aka the Podfather â€” in 2011.
      <span>Photo: Noah Berger/Bloomberg via Getty Images</span>
    </p>
</div>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3v003c3b82p8i08xh4@published" data-word-count="79">A few months into his gig, Rubinstein was beginning to wonder aloud if there was a Principles system at all. The hedge fund was spending tens of millions of dollars on developing the Principles rating software, but when Rubinstein tried to investigate what it actually did, he was simply told that it measured â€œbelievability.â€ Many told him the systems involved secret calculations from the former IBM scientist Ferrucci and that the researcher told almost no one how it worked.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003d3b82uz7tnsx9@published" data-word-count="47">This immediately struck the former Apple executive as off. He had spent his life working with experts like Ferrucci, and in Rubinsteinâ€™s experience, corporate scientists tended to overexplain their work to company executives in excruciating, unnecessary detail. The struggle was usually to get them to shut up.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003e3b82xasqmu7d@published" data-word-count="29">Rubinstein was no junior hire, so he sought out Ferrucci in person. The two men exchanged pleasantries, then the co-CEO dropped his biggest question: â€œHow do you calculate believability?â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003f3b82fnvixl52@published" data-word-count="11">Ferrucci briefly broke eye contact. â€œIâ€™m not going to tell you.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003g3b82loolfv91@published" data-word-count="1">â€œWhy?â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003h3b829x984n1v@published" data-word-count="2">â€œIâ€™m embarrassed.â€</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003i3b82d7wt30un@published" data-word-count="8">(Ferrucciâ€™s spokeswoman said he doesnâ€™t recall this conversation.)</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3w003j3b82ah5vytim@published" data-word-count="72">Rubinstein had been vexed from the start by the mysterious, omnipotent metric of â€œbelievability.â€ Ferrucciâ€™s lab, Rubinstein would conclude, was wasting their time. Those at Bridgewater who had been rated highly believable in certain areas didnâ€™t earn those scores through any complicated algorithm of artificial intelligence. They earned it by being an artificial Ray Dalio. The secret to becoming believable at Bridgewater was to model oneself after the only man who mattered.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3x003k3b824z3vvji7@published" data-word-count="9">Bridgewater didnâ€™t run on believability. It ran on believers.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3x003l3b82x1pd4zo7@published" data-word-count="8">â€œRay, this is a religion,â€ Rubinstein told Dalio.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3x003m3b82uctaqzr2@published" data-word-count="70">That would be Rubinsteinâ€™s final day at Bridgewater. He agreed to stay for several months longer, in part to save face after his splashy arrival. Rubinstein agreed to keep quiet publicly about his feelings on the firm, and Dalio agreed that the firm would honor paying out the remainder of the co-CEOâ€™s two-year compensation. It added up to tens of millions of dollars for less than a year of work.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3x003n3b829339oaoa@published" data-word-count="110">Much to the surprise of some who worked for him, Ferrucci stayed on for years longer. He split the time between his own company that Dalio funded and project after project at Bridgewater work that Dalio came up with for him. One Bridgewater effort, code-named Allstream, was essentially One Rating to Rule Them All â€” a metric that would replace all other categories and boil employees down to a single statistic that encompassed their overall worth at the firm. Others on his team worked on a project called â€œVideo Book,â€ which would package Bridgewater case studies and sell them to the public for $75 apiece. Neither initiative was ever completed.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3y003o3b82h3ws7kkb@published" data-word-count="87">By late 2019, after many years of fruitless toil, Ferrucci had hit his limit. He seemed reluctant to make a big deal about leaving â€” that might call attention to how little heâ€™d accomplished. Instead, in an agreement with Dalio, he arranged to quit his work at the hedge fund but keep offices on the Bridgewater campus, where he gave interviews about his latest computer-science research. None of them had anything to do with Dalio, Bridgewater, or the Principles. Neither Bridgewater nor Ferrucci publicly acknowledged his departure.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9ka3y003p3b82z2iu6sg0@published" data-word-count="20">Two years later, in late 2021, Bridgewater laid off most of the remaining staff dedicated to building the Principles software.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clon9nefq005d3b821ntm3ccl@published" data-word-count="22"><strong><em>Excerpted from&nbsp;</em></strong><a href="https://www.amazon.com/Fund-Bridgewater-Associates-Unraveling-Street/dp/1250276934?tag=thestrategistsite-20&amp;ascsubtag=__in1107aam__clon9g6a4001c0pge17h79oez________________" rel="sponsored,nofollow" data-track-type="product-link"><strong>The Fund: Ray Dalio, Bridgewater Associates, and the Unraveling of a Wall Street Legend</strong></a><strong>,<em> by Rob Copeland&nbsp;(St. Martinâ€™s Press, November 7).</em></strong></p>

    </div>

    


          



      <span>â€˜Ray, This Is a Religionâ€™</span>



  </section>

  
  
    
  

</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go, Containers, and the Linux Scheduler (320 pts)]]></title>
            <link>https://www.riverphillips.dev/blog/go-cfs/</link>
            <guid>38181346</guid>
            <pubDate>Tue, 07 Nov 2023 19:10:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.riverphillips.dev/blog/go-cfs/">https://www.riverphillips.dev/blog/go-cfs/</a>, See on <a href="https://news.ycombinator.com/item?id=38181346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-bvzihdzo=""><div data-astro-cid-bvzihdzo=""><div data-astro-cid-bvzihdzo=""><p><time datetime="2023-11-04T00:00:00.000Z">Nov 4, 2023</time></p><p>
Last updated on <time datetime="2023-11-07T00:00:00.000Z">Nov 7, 2023</time></p></div><hr data-astro-cid-bvzihdzo=""></div><p>Like many Go developers my applications are usually deployed in containers.
When running in container orchestrators itâ€™s important to set CPU limits to ensure that the container doesnâ€™t consume all the CPU on the host.
However, the Go runtime is not aware of the CPU limits set on the container and will happily use all the CPU available.
This has bitten me in the past, leading to high latency, in this blog Iâ€™ll explain what is going on and how to fix it.</p>
<h2 id="how-the-go-garbage-collector-works">How the Go Garbage Collector works</h2>
<p>This is going to be a pretty high level overview of the Go Garbage Collector (GC).
For a more in depth overview I recommend reading <a href="https://tip.golang.org/doc/gc-guide">the go docs</a>
and this <a href="https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html">excellent series of blogs</a>
by Will Kennedy.</p>
<p>The vast majority of the time the Go runtime performs garbage collection concurrently with the execution of your program.
This means that the GC is running at the same time as your program. However, there are two points in the GC process where the Go runtime needs to stop every Goroutine.
This is required to ensure data integrity. Before the Mark Phase of the GC the runtime stops every Goroutine to apply the write barrier, this ensures no objects created after this point are garbage collected. This phase is known as Sweep Termination.
After the mark phase has finished there is another stop the world phase, this is known as Mark Termination and the same process happens to remove the write barrier. These usually takes in the order of tens of microseconds.</p>
<p>I created a simple web application that allocates a lot of memory and ran it in a container with a limit of 4 CPU cores with the following command.The Source code for this is available <a href="https://github.com/RiverPhillips/go-cfs-blog">here.</a></p>
<pre tabindex="0" lang="bash"><code><span><span>docker</span><span> run</span><span> --cpus=4</span><span> -p</span><span> 8080</span><span>:8080</span><span> $(</span><span>ko</span><span> build </span><span>-L</span><span> main.go)</span></span>
<span></span></code></pre>
<p>Itâ€™s worth noting the docker CPU limit is a soft limit, meaning itâ€™s only enforced when the host is CPU constrained. This means that the container can use more than 4 CPU cores if the host has spare capacity.</p>
<p>You can collect a trace using the <a href="https://golang.org/pkg/runtime/trace/">runtime/trace</a> package then analyze it with <code>go tool trace</code>. The following trace shows a GC cycle captured on my machine. You can see the Sweep Termination and the Mark Termination stop the world phase on <code>Proc 5</code> (Theyâ€™re labelled STW for stop the world).</p>
<p><a href="https://www.riverphillips.dev/gc_trace.jpg"><img src="https://www.riverphillips.dev/gc_trace.jpg" alt="GC Trace"></a></p>
<p>This GC cycle took just under 2.5ms, but we spent almost 10% of that in a stop the world phase. This is a pretty significant amount of time, especially if you are running a latency sensitive application.</p>
<h2 id="the-linux-scheduler">The Linux Scheduler</h2>
<p>The <a href="https://docs.kernel.org/scheduler/sched-design-CFS.html">Completely Fair Scheduler (CFS)</a> was introduced in Linux 2.6.23 and was the default Scheduler until Linux 6.6 which was released last week. Itâ€™s likely youâ€™re using the CFS.</p>
<p>The CFS is a <a href="https://en.wikipedia.org/wiki/Proportional_share_scheduling">proportional share scheduler</a>, this means that the weight of a process is proportional to the number of CPU cores it is allowed to use. For example, if a process is allowed to use 4 CPU cores it will have a weight of 4. If a process is allowed to use 2 CPU cores it will have a weight of 2.</p>
<p>The CFS does this by allocating a fraction of CPU time. A 4 core system has 4 seconds of CPU time to allocate every second. When you allocate a container a number of CPU cores youâ€™re essentially asking the Linux Scheduler to give it <code>n</code> CPUs worth of time.</p>
<p>In the above <code>docker run</code> command Iâ€™m asking for 4 CPUs worth of time. This means that the container will get 4 seconds of CPU time every second.</p>
<h2 id="the-problem">The Problem</h2>
<p>When the Go runtime starts it creates an OS thread for each CPU core. This means if you have a 16 core machine the Go runtime will create 16 OS threads - regardless of any CGroup CPU Limits. The Go runtime then uses these OS threads to schedule goroutines.</p>
<p>The problem is that the Go runtime is not aware of the CGroup CPU limits and will happily schedule goroutines on all 16 OS threads. This means that the Go runtime will expect to be able to use 16 seconds of CPU time every second.</p>
<p>Long stop the world durations arise from the Go runtime needing to stop Goroutine on threads that itâ€™s waiting for the Linux Scheduler to schedule. These threads will not be scheduled once the container has used itâ€™s CPU quota.</p>
<h2 id="the-solution">The Solution</h2>
<p>Go allows you to limit the number of CPU threads that the runtime will create using the <code>GOMAXPROCS</code> environment variable.
This time I used the following command to start the container</p>
<pre tabindex="0" lang="bash"><code><span><span>docker</span><span> run</span><span> --cpus=4</span><span> -e</span><span> GOMAXPROCS=</span><span>4</span><span> -p</span><span> 8080</span><span>:8080</span><span> $(</span><span>ko</span><span> build </span><span>-L</span><span> main.go)</span></span></code></pre>
<p>Below is a trace captured from the same application as above, now with the <code>GOMAXPROCS</code> environment variable matching the CPU quota.</p>
<p><a href="https://www.riverphillips.dev/gc_trace_4.jpg"><img src="https://www.riverphillips.dev/gc_trace_4.jpg" alt="GC Trace"></a></p>
<p>In this trace, the garbage collection is much shorter, despite having the exact same load. The GC Cycle took under 1ms and the stop the world phase was 26Î¼s, approximately 1/10 of the time when there was no limit.</p>
<p><code>GOMAXPROCS</code> should be set to the number of CPU cores that the container is allowed to use, if youâ€™re allocating fractional CPU round down, unless youâ€™re allocating less than 1 CPU core in which case round up. <code>GOMAXPROCS=max(1, floor(CPUs))</code> can be used to calculate the value.
If you find it easier Uber has open sourced a library <a href="https://github.com/uber-go/automaxprocs">automaxprocs</a> to calculate this value for you from your containerâ€™s cgroups automatically.</p>
<p>Thereâ€™s an outstanding <a href="https://github.com/golang/go/issues/33803">Github Issue</a> with the Go runtime to support this out the box so hopefully it will be added eventually!</p>
<h2 id="conclusion">Conclusion</h2>
<p>When running Go in a containerised application itâ€™s important to set CPU limits. Itâ€™s also important to ensure that the Go runtime is aware of these limits by setting a sensible <code>GOMAXPROCS</code> value or using a library like <a href="https://github.com/uber-go/automaxprocs">automaxprocs</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Got the Fed to Release Its 2011 "Treasury Default" Playbook (143 pts)]]></title>
            <link>https://www.crisesnotes.com/i-got-the-fed-to-release-its-2011-treasury-default-playbook-heres-what-it-says-and-why-it-matters/</link>
            <guid>38181280</guid>
            <pubDate>Tue, 07 Nov 2023 19:04:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.crisesnotes.com/i-got-the-fed-to-release-its-2011-treasury-default-playbook-heres-what-it-says-and-why-it-matters/">https://www.crisesnotes.com/i-got-the-fed-to-release-its-2011-treasury-default-playbook-heres-what-it-says-and-why-it-matters/</a>, See on <a href="https://news.ycombinator.com/item?id=38181280">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="main">

        <header>
            <span>November 7, 2023</span>
            
        </header>

        <p><img src="https://www.crisesnotes.com/content/images/2023/11/FOIA-2011-memo-success-letter.jpg" alt="I Got the Fed to Release its 2011 â€œTreasury Defaultâ€ Playbook. Hereâ€™s What it Says and Why it Matters."></p>

        <div>
            <p>Readers may recall that I wrote a Politico Op Ed at a critical moment in the debt ceiling showdown. That piece, was entitled <a href="https://www.politico.com/news/magazine/2023/04/19/powell-debt-ceiling-fed-00092522?ref=crisesnotes.com">â€œBiden Can Steamroll Republicans on the Debt Ceilingâ€</a>, and I aimed squarely at debunking the idea that the Federal Reserve would step on any â€œunilateral actionsâ€ to avoid treasury default. My key piece of evidence was a memo that I had not read, and was not publicly available. But I knew the contents of the memo indirectly through the Federal Open Market Committee Meeting transcripts. Those comments were in some ways especially revealing, since they came from the Fedâ€™s three leaders: Ben Bernanke, Janet Yellen and Jerome Powell. Itâ€™s worth quoting the key part of <a href="https://www.politico.com/news/magazine/2023/04/19/powell-debt-ceiling-fed-00092522?ref=crisesnotes.com">my Op Ed</a> at length:</p><blockquote>On that call, Powell and most of his colleagues reluctantly endorsed buying defaulted Treasury securities â€” an unprecedented move to maintain financial stability â€”<strong> </strong>if a legislative debt ceiling solution did not come in time. Hereâ€™s the key exchange between Powell and then-Fed Chair Ben Bernanke (options â€œ8 and 9â€ in the memo are purchases of defaulted Treasury securities and the Fed â€œswappingâ€ non-defaulted Treasury securities for defaulted Treasury securities):</blockquote><blockquote><strong>MR. POWELL: </strong>As long as Iâ€™m talking, I find 8 and 9 to be loathsome. I hope that gets into the minutes. [Laughter] But I donâ€™t want to say today what I would and wouldnâ€™t do, if we have to actually deal with a catastrophe on this.</blockquote><blockquote></blockquote><blockquote><strong>CHAIRMAN BERNANKE: </strong>So you are willing to accept â€œloathsomeâ€ under some certain circumstances. [Laughter]</blockquote><blockquote></blockquote><blockquote><strong>MR. POWELL: </strong>Yes, under certain circumstances.</blockquote><blockquote>Powellâ€™s willingness to purchase defaulted Treasury securities â€” however â€œloathsomeâ€ he finds it â€” casts the entire debate over bypassing Congress on the debt ceiling in a new light. No option under discussion is more extreme, from the Federal Reserveâ€™s point of view, than stepping in and buying compromised securities of uncertain underlying value.</blockquote><p>When I wrote and published this Op Ed, I was actually working on getting hold of that memo. Using the Federal Open Market Committee Freedom of Information Act <a href="https://fomcfoia.federalreserve.gov/?ref=crisesnotes.com">official website portal</a>, I had crafted a request for this memo, as well as some older unreleased materials. As an aside, make sure the website you are on is about the Federal Open Market Committee, if you decide to get into the FOMC Freedom of Information Act Request game yourself. There is a website for the <a href="https://foia.federalreserve.gov/?ref=crisesnotes.com">Board of Governors of the Federal Reserve</a>. If you submit a request to that website when youâ€™re seeking Federal Open Market Committee related material, your request will bounce and will be redirected to the FOMC FOIA website. I personally make sure to resubmit when I make this mistake in case something gets lost in the shuffle between FOIA portals. If you want to request materials related to the discount window and 13(3) â€œunusual and exigent circumstancesâ€ authority, the Board of Governors website is the one you want.</p><p>Anyway, I had not gotten a response at the time of publishing the OpEd â€” nor frankly did I expect to get one. I thought this material would be considered too sensitive and too recent to release. Happily, I can inform you that I was wrong. On June 30th of this year I received a copy of the memo. It was also quietly linked to in the â€œ2011 memosâ€ section of their website, meaning it has technically been publicly available since I received it. However, it does not show up on google searches (like many other memos do). As far as I can tell, no one has noticed that this memo is now public. Thus, I can confidently say that I am the first to bring the full text of this memo to the public, and analyze its specific contents. The memo is dryly entitled <a href="https://www.federalreserve.gov/monetarypolicy/files/FOMC20110719memo01.pdf">â€œPotential Policy Responses to the Debt Ceilingâ€</a>. </p><p>Before getting to the policy options it lays out, it's worth commenting on how it elegantly summarizes â€œthe problemâ€. The first sentence of the memo claims: â€œWith the federal debt ceiling binding and the Treasury running out of the additional borrowing capacity it can achieve under various accounting procedures, a technical default on Treasury securities cannot be ruled out.â€. That summary is notable for a few reasons. First, it recognizes that the problem is not â€œdebtâ€ or â€œdeficitsâ€, but rather the lack of legal authority to issue additional treasury securities. Second, as Iâ€™ve hammered many times in this newsletter (as well as the Financial Times and Politico among other outlets) the treasury always already uses accounting gimmicks to continue to fill up its checking account, and make payments. What does that mean?&nbsp; That there is <strong>no debate</strong> about whether the treasury should use accounting gimmicks to circumvent the debt ceiling. It already does that. The real debate is over whether it should use an â€œaccounting gimmickâ€ to permanently and unilaterally avoid default.</p><p>With that out of the way, we move on to their policy options. Letâ€™s start with the five basic options listed first. These are interesting because they were uncontroversial to members of the FOMC when they were discussed in 2011, and again in 2013. Therefore the extent to which these options themselves preserve liquidity for defaulted treasury securities, they emphasize the extent to which the Federal Reserve will strive to contain the economic and financial stability fallout from a treasury default.:</p><blockquote>We begin by describing how defaults could affect five routine policy actions that are permissible under the Federal Reserve Act and fall within the current authorization of the Desk and the authority of the Reserve Banks. The relevant issue for these actions is the treatment of defaulted Treasury securities â€“ that is, securities that are experiencing a delay in principal or interest payments due to the debt ceiling. The staffâ€™s recommendation is to make no changes to our current procedures, thereby treating defaulted Treasury securities in these transactions on the same terms that apply to other (non-defaulted) Treasury securities. This approach would send a signal to the market that we continue to view principal and interest for these securities as backed by the full faith and credit of the U.S. government. Moreover, in many cases, this approach would help the market cope with the pressures that could emerge in such circumstances.&nbsp;</blockquote><p>In other words, there are all sorts of day to day things that the Federal Reserve does that provide liquidity to treasury markets which the Federal Reserve would continue. But what are those options?</p><blockquote>1. Outright purchases of Treasury securities</blockquote><blockquote>2. Rollovers of maturing Treasury securities.</blockquote><blockquote>3. Securities lending activity.</blockquote><blockquote>4. Repurchase agreements.</blockquote><blockquote>5. Discount window lending.</blockquote><p>These tools are very familiar to people who read about monetary policy. The main surprise here is regarding the first â€œoptionâ€. In inferring the contents of this memo from the FOMC transcript, I didnâ€™t realize that the first option included the purchase of defaulted treasury securities. Yet, <strong>it does.</strong> As the document says: â€œAccordingly, unless otherwise directed by the Committee, the [New York Federal Reserve Trading] Desk intends to accept defaulted securities in these operations in the same manner as other Treasury securities, with the prices determined through competitive bidding.â€ This means that Federal Reserve officials have across the board found the purchase of defaulted treasury securities by The Fed to be uncontroversial. This is an important and remarkable fact.</p><p>But what of the other options? Option 2 is not really focused on the defaulted securities part of a potential debt ceiling crisis. Instead, it is concerned with how to deal with the Fedâ€™s â€œreinvestment policyâ€ when the treasury is no longer conductings new auctions. I will skip over that issue to focus on options 3 to 5. These options sound very different, but really they are all about borrowing from the Federal Reserve. They are really concerned with the question of â€œcollateralâ€ for those loans. In option 3, the Federal Reserve is lending securities rather than â€œcashâ€. Nevertheless, it wants collateral. The repurchase agreements of option 4 are simply a form of borrowing that has preferential treatment in bankruptcy. Since the collateralized loan is structured like a repurchase agreement, if the borrower fails to â€œrepurchaseâ€ the collateral, then the lender gets to keep it. Option 5 is simply the discount window, the most traditional version of Federal Reserve lending.</p><p>So what is the Federal Reserveâ€™s concern? In all these cases, they are thinking through how to treat defaulted treasury securities. An obvious approach would be to not accept defaulted treasury securities as collateral. The justification would beâ€¦ <strong>theyâ€™ve defaulted. </strong>A subtler option is accepting them as collateral, but at their current (depressed) market price, or at some other lower price. The issue with these approaches is that they<strong> worsen liquidity for these securities</strong> â€” while causing panic about what might happen to currently undefaulted treasury securities. The Memoâ€™s alternative is to accept them <strong>at the same terms they accept undefaulted treasury securities.&nbsp;</strong></p><p>While this is a more technical issue than outright purchases of defaulted treasury securities, <strong>it is not less important. </strong>As we saw earlier this year with the Bank Term Funding Program, changing the collateral policy to treasury securities can have a profound impact. There is no doubt that if the Federal Reserve, for lending purposes, treated defaulted treasury securities like undefaulted securities it would go quite a long way to preserving liquidity for these instruments, and thus the larger treasury market. It is thus notable that Federal Reserve officials treated these options (which are simply three manifestations of the same policy) as uncontroversial&nbsp;</p><p>The next three options are about technical issues related to the repo market, as well as Money Market Mutual Funds. I may write about this section of the memo in a premium piece in the future. But for today Iâ€™m keeping my focus on the issue of defaulted treasury securities. It is worth saying though, that this part of the memo illustrates the Federal Reserveâ€™s commitment to preventing a treasury default from having a wider knock-on impact on financial markets. In any case, the remaining part of the memo deals with engaging in purchase and sale operations specifically aimed at absorbing defaulted treasury securities. Now that we have the memo in hand, it's clearer that purchasing defaulted treasury securities was not controversial. Instead, it was specifically aiming at, and designing a comprehensive program to solve, the issue of defaulted treasury securities which made Federal Reserve officials uncomfortable. However, the transcript conversations show far more willingness to use these options if circumstances truly required them than staffers expected. For completeness sake, I will quote this part of the memo below:</p><blockquote><strong>9. Purchase operations to remove defaulted Treasury securities from the market.</strong> To limit the negative impact of defaulted securities on market functioning, the FOMC could decide to purchase a specified amount of these issues from market participants. These purchases would be in addition to those associated with reinvestments (the first policy issue described above). This approach would help market functioning if cash market liquidity were to deteriorate and participants were otherwise unable to sell their Treasury holdings. Moreover, in contrast to the financing operations discussed above, outright purchases remove the securities from firmsâ€™ balance sheets, so that the firms no longer have to deal with the operational issues associated with defaulted securities. Unless offset by other actions, such operations would increase the size of the SOMA portfolio and the amount of reserves in the banking system.&nbsp;</blockquote><blockquote></blockquote><blockquote><strong>10. Outright CUSIP swaps to remove defaulted Treasury securities from the market.</strong> One way to avoid the effects of additional purchase operations on the size of the Federal Reserveâ€™s balance sheet and the amount of reserves is to do them as CUSIP swaps. A CUSIP swap would be an operation in which the Desk simultaneously (or at least on the same day) bought a defaulted Treasury security and sold a non-defaulted Treasury security. This operation would be roughly neutral in terms of the size of the SOMA portfolio and the amount of reserves in the banking system. It could also be designed to limit any change in the duration risk of the SOMA. This approach has similarities to securities lending operations against defaulted Treasury collateral (the third policy issue described above), only in this case the operation would remove the defaulted securities from the market permanently. The terms of these operations would be determined through competitive bidding</blockquote><p>Now that we know the Federal Reserveâ€™s playbook in case of a treasury default, we can be much more confident in the future when arguing during the next debt ceiling crisis. Powell, or any future Federal Reserve chair, may deny that this playbook has any implications for how they would respond to unilateral workarounds of the debt ceiling. However, now any reader can plainly see <strong>that that isnâ€™t true.</strong> They are willing to do an incredible amount â€” if it's necessary to contain the financial instability resulting from a treasury default. They would gladly facilitate an option the Treasury pursues in its role as fiscal agent, since they can always claim that it was the Treasuryâ€™s decision and they had no other option as fiscal agent (which<strong> happens to be true</strong>). To deny the Treasury and then step into the breach themselves with a policy that is clearly their own to follow, or not follow, puts them in a far more untenable political position. Iâ€™m glad to have this out there, and I look forward to unearthing many more gems through Freedom of Information Act requests in the coming months and years.</p>
        </div>


        

    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Article 45 of eIDAS 2.0 will roll back web security by 12 years (236 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/11/article-45-will-roll-back-web-security-12-years</link>
            <guid>38181114</guid>
            <pubDate>Tue, 07 Nov 2023 18:52:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/11/article-45-will-roll-back-web-security-12-years">https://www.eff.org/deeplinks/2023/11/article-45-will-roll-back-web-security-12-years</a>, See on <a href="https://news.ycombinator.com/item?id=38181114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>The EU is poised to </span><a href="https://last-chance-for-eidas.org/"><span>pass a sweeping new regulation</span></a><span>, eIDAS 2.0. Buried deep in the text is Article 45, which returns us to the dark ages of 2011, when certificate authorities (CAs) could collaborate with governments to spy on encrypted trafficâ€”and get away with it. Article 45 forbids browsers from enforcing modern security requirements on certain CAs without the approval of an EU member government. Which CAs? Specifically the CAs that were appointed by the government, which in some cases will be owned or operated by that selfsame government. That means cryptographic keys under one governmentâ€™s control could be used to intercept HTTPS communication throughout the EU and beyond.</span></p>
<p><span>This is a catastrophe for the privacy of everyone who uses the internet, but particularly for those who use the internet in the EU. Browser makers have not announced their plans yet, but it seems inevitable that they will have to create two versions of their software: one for the EU, with security checks removed, and another for the rest of the world, with security checks intact. Weâ€™ve been </span><a href="https://www.nytimes.com/2000/01/31/business/worldbusiness/IHT-us-removes-an-encryption-barrier.html"><span>down this road before</span></a><span>, when export controls on cryptography meant browsers were released in two versions: strong cryptography for US users, and weak cryptography for everyone else. It was a fundamentally inequitable situation and the knock-on effects set back web security by decades.</span></p>
<p><span>The current text of Article 45 requires that browsers trust CAs appointed by governments, and </span><a href="https://blog.mozilla.org/netpolicy/files/2023/11/eIDAS-Industry-Letter-updated.pdf"><span>prohibits browsers from enforcing any security requirements</span></a><span> on those CAs beyond what is approved by </span><a href="https://en.wikipedia.org/wiki/ETSI"><span>ETSI</span></a><span>. In other words, it sets an upper bar on how much security browsers can require of CAs, rather than setting a lower bar. That in turn limits how vigorously browsers can compete with each other on improving security for their users.</span></p>
<p><span>This upper bar on security may even ban browsers from enforcing </span><a href="https://en.wikipedia.org/wiki/Certificate_Transparency"><span>Certificate Transparency</span></a><span>, an IETF technical standard that ensures a CAâ€™s issuing history can be examined by the public in order to detect malfeasance. Banning CT enforcement makes it much more likely for government spying to go undetected.</span></p>
<p><span>Why is this such a big deal? The role of a CA is to bootstrap encrypted </span><a href="https://www.eff.org/encrypt-the-web"><span>HTTPS</span></a><span> communication with websites by issuing certificates. The CAâ€™s core responsibility is to match web site names with customers, so that the operator of a website can get a valid certificate for that website, but no one else can. If someone else gets a certificate for that website, they can use it to intercept encrypted communications, meaning they can read private information like emails.</span><span><br></span><span><br></span><span>We know HTTPS encryption is a barrier to government spying because of the NSAâ€™s famous â€œ</span><a href="https://www.washingtonpost.com/world/national-security/nsa-infiltrates-links-to-yahoo-google-data-centers-worldwide-snowden-documents-say/2013/10/30/e51d661e-4166-11e3-8b74-d89d714ca4dd_story.html"><span>SSL added and removed here</span></a><span>â€ note. We also know that misissued certificates have been used to spy on traffic in the past. For instance, in 2011 </span><a href="https://en.wikipedia.org/wiki/DigiNotar"><span>DigiNotar was hacked</span></a><span> and the resulting certificates used to intercept emails for people in Iran. In 2015, </span><a href="https://slate.com/technology/2016/12/how-the-2011-hack-of-diginotar-changed-the-internets-infrastructure.html"><span>CNNIC issued an intermediate certificate</span></a><span> used in intercepting traffic to a variety of websites. Each CA was subsequently </span><a href="https://blog.mozilla.org/security/2015/04/02/distrusting-new-cnnic-certificates/"><span>distrusted</span></a><span>.</span></p>
<p><span>Distrusting a CA is just one end of a spectrum of technical interventions browsers can take to improve the security of their users. Browsers operate â€œroot programsâ€ to monitor the security and trustworthiness of CAs they trust. Those root programs impose a number of requirements varying from â€œhow must key material be securedâ€ to â€œhow must validation of domain name control be performedâ€ to â€œwhat algorithms must be used for certificate signing.â€ As one example, certificate security rests critically on the security of the hash algorithm used. The </span><a href="https://en.wikipedia.org/wiki/SHA-1"><span>SHA-1 hash algorithm</span></a><span>, published in 1993, was considered not secure by 2005. NIST disallowed its use in 2013. However, CAs didn't stop using it until 2017, and that only happened because one browser made SHA-1 removal a requirement of its root program. After that, the other browsers followed suit, along with the </span><a href="https://cabforum.org/"><span>CA/Browser Forum</span></a><span>.</span></p>
<p><span>The removal of SHA-1 illustrates the backwards security incentives for CAs. A CA serves two audiences: their customers, who get certificates from them, and the rest of the internet, who trusts them to provide security. When it comes time to raise the bar on security, a CA will often hear from their customers that upgrading is difficult and expensive, as it sometimes is. That motivates the CA to drag their feet and keep offering the insecure technology. But the CAâ€™s other audience, the population of global internet users, needs them to continually improve security. Thatâ€™s why browser root programs need to (and do) require a steadily increasing level of security of CAs. The root programs advocate for the needs of their users so that they can provide a more secure product. The security of a browserâ€™s root program is, in a very real way, a determining factor in the security of the browser itself.</span></p>
<p><span>Thatâ€™s why itâ€™s so disturbing that eIDAS 2.0 is poised to prevent browsers from holding CAs accountable. By all means, </span><i><span>raise</span></i><span> the bar for CA security, but permanently lowering the bar means less accountability for CAs and less security for internet users everywhere.</span></p>
<p><span>The text isn't final yet, but is subject to approval behind closed doors in Brussels on November 8.</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Northlight technology in Alan Wake 2 (412 pts)]]></title>
            <link>https://www.remedygames.com/article/how-northlight-makes-alan-wake-2-shine</link>
            <guid>38180846</guid>
            <pubDate>Tue, 07 Nov 2023 18:32:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.remedygames.com/article/how-northlight-makes-alan-wake-2-shine">https://www.remedygames.com/article/how-northlight-makes-alan-wake-2-shine</a>, See on <a href="https://news.ycombinator.com/item?id=38180846">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Northlight team is super-excited to have Alan Wake 2 out there. We've created and polished off a lot of new tech so that Alan Wake 2 looks great and plays great. Here are the key highlights of the new features and tools that we'd like to give a moment in the spotlight. We're keeping the description to a fairly high level here; our engineers will be back with more in-depth topics in due course.</p><h3>Core engine: New data-oriented game object model</h3><p>Northlight switched to a completely new data-oriented game object framework during the development of Alan Wake 2. The new entity component system (ECS) based model enables memory-efficient storage and makes parallel execution efficient and safe. This means that the engine can support a varying number of target hardware cores efficiently, enabling bigger, more dynamic and fuller worlds. ECS also played a supporting role for our tools development, simplifying the building of the new Scattering tool for mass-authoring vegetation - ECS allowed us to simply have a lot more entities without the need to invent any custom solution for scattering objects in the world.</p><p>The ECS framework also made it to our gameplay programmers' "favorite tech" list as it helped implement the Case Board - Saga's visual storyboard for gathering evidence. ECS meant that iteration was quick because adding new or modifying existing systems or game objects was easy, and performance gains were clear when saving and loading the Case Board.</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544bf00d880ecdd52ccc46e_image-2023-11-3_11-17-22.png" loading="lazy" alt="Picture of Case Board"></p></figure><h3>Voxel-Based Character Controller</h3><p>Alan Wake 2 called forth reimagining character control in Northlight. We built a new Voxel-Based Character Control that enables smooth navigation in cramped, complex and dynamic environments; it makes character movement more natural and fluid. Our marketing folks would say the characters are more responsive and lifelike than ever before; our internal dev notes described it as "the characters won't bump or get stuck into objects in tight spaces".</p><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://player.vimeo.com/video/880838821" title="VCC_path_demo"></iframe></p></figure><p><figcaption>Character path visualization showing predicted path (white) as the character tries to reach the movement target (yellow).</figcaption></p><h3>Reworked<em> </em>NPC locomotion</h3><p>Our animation tech made some major changes into how Non-Player Characters (NPC) move. The revamped NPC locomotion means that in Alan Wake 2 all NPCs utilize animation-driven movement combined with new distance-based Motion Matching. This new tech improves movement quality and gives us more control over how and when animations are used.</p><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://player.vimeo.com/video/882017461" title="Alan Wake 2 NPC Locomotion"></iframe></p></figure><h3>Realistic wind</h3><p>More realistic wind was on the must-have tech list for Alan Wake 2 - and that's we have, wind that realistically affects physics, particles, and cloth.</p><p>For example, game designers can now easily define indoor and outdoor areas that have different wind speeds, with smooth, stateless transitions between the two types of areas. The indoor vs. outdoor area definitions are used, for example, to ensure that there's no wind inside the car that Saga and Casey are driving. This is done through defining a moving "wind box" that specifies that the inside of the car is a wind-free indoor area.</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544bea014d3dfaf2f5c6858_moving_windbox.png" loading="lazy" alt="Northlight Wind Debugger showing wind box that defines indoor vs. outdoor area. Block edge shows the transition."></p><figcaption>Northlight Wind Debugger showing wind box that defines indoor vs. outdoor area. Block edge shows the transition.</figcaption></figure><p>The wind system tech is built on Signed Distance Fields (SDF) methods where wind boxes are used as primitives that define a smooth, global wind strength field. The wind boxes act like basic building blocks that define how strong the wind is in different areas, creating realistic and smoothly varying wind patterns between indoor and outdoor areas.</p><h3>Scattering tool</h3><p>We developed a new Scattering tool to allow for mass-authoring vegetation and propping environments on a grand scale. In Alan Wake 2 it was used to create denser, richer and more life-like environments with the longer-than-before draw distances (i.e. what defines how far the player can see objects and details in the game world).</p><h3>Luau</h3><p>We switched our scripting language from a proprietary language into Luau, embeddable scripting language derived from Lua by our friends at Roblox. It exposes a comprehensive set of engine functionality and supports live-editing. Luau is used for level scripting and also for various gameplay systems such as the weapon upgrade system. Luau allowed the game team to prototype and implement various game features and VFX effects without needing help from engine programmers.</p><p>We've also cooked up our own VS Code language server extension, so that it all integrates seamlessly into Remedyâ€™s development pipelines. And adopting Luau helped us boot out some 80 000 lines of code we no longer need to maintain.</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544c372589da1e2a2285809_luau_weather_system.png" loading="lazy" alt="VFX team used Luau to implement a weather system - The different weather conditions can be quickly tested through a debug panel,"></p><figcaption>VFX team used Luau to implement a weather system - The different weather conditions can be quickly tested through a debug panel.</figcaption></figure><h2><br>Graphics and rendering</h2><h3>New GPU-driven rendering pipeline</h3><p>Alan Wake 2 showcases Northlight's brand-new GPU-driven rendering pipeline. It allows us to push more geometry into the world without sacrificing performance. With GPU-driven rendering using mesh shaders, we can now do occlusion culling down to a single-pixel precision and use everything in a scene as an occluder. This ability to only draw what is visible means that the world of AW2 has more geometric detail than weâ€™ve ever shipped before.</p><p>Diving a bit deeper into how it works: we also cull meshlets, in addition to the mesh. Meshlets are smaller, more optimized, groups of triangles extracted from the mesh. In the images below you can see what meshlets look like around Cauldron Lake's convenience store location.</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544d4dc52652337e5f1e521_meshlet_visualization1.jpg" loading="lazy" alt=""></p><figcaption>What the player sees...</figcaption></figure><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544d5a842800d0cc9817d14_meshlet_visualization2.jpg" loading="lazy" alt=""></p><figcaption>...vs. what's fed into the renderer (silly amount of geometric detail!). Colors represent clusters.</figcaption></figure><h3>Character-style rigs on foliage - Large scale procedural GPU animation</h3><p>The expansive primordial forest environments of Alan Wake 2 are brought to life through our new shader-based vegetation system. It's based on a new skinning system that runs entirely on GPU and supports "art-driven" bone shader animations. In Alan Wake 2 it enabled us to use full character-style rigs on all the foliage visible in the environments.</p><p>We're calling the new system art-driven here because the bone shaders expose an API with which artists can write their own shader code that hooks into the underlying system. So technically artists could use it to animate anything they'd like: foliage, objects bobbing up and down on water, power cables wobbling in the wind, etc. </p><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://player.vimeo.com/video/880842428" title="GPU_animation"></iframe></p></figure><p><figcaption>GPU bone visualization - The skeleton rigs animating all vegetation. Each line is one bone, with almost 300,000 bones in Cauldron Lake being processed every frame.</figcaption></p><p>â€</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544da11f604c7d5e835ae8e_GPU_animation_pic2NoDraw.JPG" loading="lazy" alt=""></p><figcaption>GPU bone visualization OFF</figcaption></figure><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544da29c20118c775ce9996_GPU_animation_pic2WDraw.JPG" loading="lazy" alt=""></p><figcaption>GPU bone visualization ON</figcaption></figure><h3>HDR support</h3><p>Alan Wake 2 fully supports HDR. We've made sure that the game looks great out-of-the-box with default settings, regardless of whether your display supports SDR or HDR. </p><p>On the tech side, adding HDR support could almost be said to have been a simple 'let's change the output format' operation; the more significant effort was done on the creative side. Alan Wake 2 is authored in HDR, meaning that the color grading was done by actual human colorists to ensure that the unique art styles and aesthetics, the storytelling and mood of Alan Wake 2 is amplified in both HDR and SDR.</p><h3>Transparency and atmospheric effects</h3><p>The pervasive fog scenes in Alan Wake 2 are built upon improvements into how we render transparency. We're using MBOIT (Moment-Based Order-Independent Transparency) to make see-through surfaces blend together smoothly, even when they have different levels of detail.</p><p>During Alan Wake 2's development, Northlight did a complete overhaul of transparent rendering. We now draw transparency in three resolutions with MBOIT, which makes it possible to blend fog, transparent geometry and effects seamlessly. In addition to better blending of fog and other transparent elements, weâ€™ve improved pipelines to allow more fine-grained control over fog placement in the world. Combining all this to per-pixel transparent lighting and fog-affected reflections makes opaque and transparent elements fit together better than in our previous projects.</p><p>Our fog also approximates multiple light scattering, giving it a thick and realistic look that improves atmosphere.</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544db9b6fe3aaa039dcc7b8_transparency_boat.jpg" loading="lazy" alt=""></p><figcaption>Note how the water refracts correctly and supports non-uniform blur for realistic looking water.</figcaption></figure><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544dba3c20118c775cfbc07_atmospheric_sunset.jpg" loading="lazy" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544dba991ac1ce7f3e43dda_multiple_light_scattering.jpg" loading="lazy" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544dbb6c31507ffce973345_coffee_world_MBOIT.jpg" loading="lazy" alt=""></p><figcaption>Transparent Rendering - A perfect blend of different transparent effects: fog, particles and water all use MBOIT. </figcaption></figure><h3>VFX</h3><p>Effects are an essential part of Alan Wake 2â€™s visuals and expand on what we achieved in Control. The node-based VFX tools in Northlight have evolved significantly in terms of supported features and runtime performance. Visual effects artists are now able to author complex and dynamic effects like rain, wetness, water simulation, and character wounds. VFX tools also benefit from GPU-driven rendering and can push a lot of geometry through the GPU. This is required, for example, when rendering rain blocker objects to a dynamic mask that prevents rain from appearing indoors or under cover.</p><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544dc4a7b3667e57e5d06b7_vfx_off.jpg" loading="lazy" alt=""></p><figcaption>Screenshot of Dark Place with visual effects OFF.</figcaption></figure><figure><p><img src="https://assets-global.website-files.com/64630b03551142e3347ae3da/6544dc4f3df84ea77d6fa679_vfx_on.jpg" loading="lazy" alt=""></p><figcaption>Screenshot of Dark Place with visual effects ON. 'Fade Out' enemies and weather effects are key parts of the visual identity.</figcaption></figure><p>â€</p><h3>Ray tracing</h3><p>We have added support for fully ray-traced direct lighting and combined this with improved denoising and indirect lighting algorithms with Nvidia. Ray tracing in Alan Wake 2 is more accurate and robust than what has been seen in Control. Ray tracing also makes the animated foliage look amazing, now that all the geometry animation (foliage) is authored and simulated using skinning.</p><p>With Alan Wake 2, PC players can experience (GPU and CPU setup permitting) the latest Nvidia DLSS innovations - DLSS Frame Generation, DLSS Ray Reconstruction, Path Traced Indirect Lighting - all the things that enable us to say 'never before' once more.</p><p>â€</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Seeing like a bank (531 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/</link>
            <guid>38180477</guid>
            <pubDate>Tue, 07 Nov 2023 18:07:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/">https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/</a>, See on <a href="https://news.ycombinator.com/item?id=38180477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>The New York Times recently ran a <a href="https://www.nytimes.com/2023/11/05/business/banks-accounts-close-suddenly.html">piece</a> on a purported sudden spate of banks closing customer accounts. Little of it is surprising if you have read <a href="https://www.bitsaboutmoney.com/archive/money-laundering-and-aml-compliance/">previous</a> <a href="https://www.bitsaboutmoney.com/archive/money-laundering-and-aml-compliance/">issues</a> of Bits about Money. The reported anecdotal user experiences have a common theme to them. Banks frequently present to their users as notably disorganized, discombobulated institutions. This an alarming and surprising fact for the parts of society that are supposed to accurately keep track of all of the money.</p><p>Why does this happen? Why does it happen across issues as diverse as bank-initiated account closures, credit card or Zelle fraud, debit card reissuance, and mortgage foreclosures? Why does it happen in such a similar fashion across many institutions, of all sizes, who exist in vicious competition with each other and who know their customers hate this?</p><p>Banks are extremely good at tracking one kind of truth, ledgers. They are extremely bad at tracking certain other forms of truth, for structural reasons. In pathological cases, which are extremely uncommon relative to all banking activity but which nonetheless happen every day and which will impact some people extremely disproportionately, the bank will appear to lack object permanence. Every interaction of the user with it feels like being Bill Murray in Groundhog Day: the people youâ€™re talking to remember literally nothing of what theyâ€™ve promised before, what youâ€™ve told them, and the months or years of history that lead to this moment.</p><p>How did we end up here?</p><h2 id="recordkeeping-systems">Recordkeeping systems</h2><p>Like every bureaucratic system, banks run on a formal system of recordkeeping which requires an unrecognized, illegible shadow system to actually function. The interactions between those systems, and what they are optimized for tracking and not optimized for, cause a lot of the pathologies that people see. The seminal text on this, focused on government bureaucracies, is <a href="https://www.amazon.com/Seeing-like-State-Certain-Condition/dp/0300078153">Seeing like a State</a>.</p><p>Because banks are filled with extremely creative people, we call the primary system banking is conducted on a â€œ<a href="https://www.gartner.com/en/information-technology/glossary/core-banking-systems">core</a>.â€ The largest banks in the world have complicated bespoke subsystems for this, but most banks are not in the software development business, and instead license a system from a so-called core processor like Jack Henry or Fiserv.</p><p>One could fill a book with architecture diagrams for a mid-sized financial institution. The key thing that non-specialists need to understand is a) the â€œcoreâ€ does a lot of what you think of banking as, b) the core interfaces with many other systems which make up a bank, c) in particular, the core interfaces with the ledgers of the bank, and d) all of these systems together cannot represent reality nearly as well as youâ€™d hope.</p><p>They typically grow over the years by accretion, caused by the normal processes of software development, regulatory changes, and competitive pressures. No system will ever be able to answer all interesting questions about a user; that is formally undecidable in computer science. Banks are extremely, painfully aware that the ordinary operation of the business of the bank will occasionally drop things on the floor. They have long-since automated the fat head of customer issues, and the long tail is kicked over to operational and customer support teams.</p><p>Every time responsibility moves between subsystems, be they different organizations, different computer systems, or different groups within the bank, some percentage of cases will simply break. The boundaries of systems are responsible for a huge percentage of all operational issues at banks. (Theyâ€™re also where most security vulnerabilities live: systems A and B usually agree on reality, but a bad actor can sometimes intentionally get them to disagree, in ways which cause the bad actor to gain value before A and B reconcile their view of reality.)</p><p>A major technological advance over the course of the last few decades has been ticketing systems, which strikes many technologists as being crazy, because theyâ€™re almost the simplest software that you can describe as software. All a ticketing system does is enforce an invariant: if there is a problem with a case number assigned to it, and it goes between Group A and Group B, Group A needs to know it no longer is responsible and Group B needs to know it is now responsible. Then you can do canâ€™t-believe-they-pay-us-for-this computing and observe things like â€œGroup B is now working on 10,342 casesâ€, â€œThere are 76 cases which Group B has not acted on within the last monthâ€, and â€œGinger seems to be anomalously unproductive at closing out cases relative to her nearest coworkers.â€</p><p>So why didnâ€™t ticketing systems solve this problem? Part of it is that the problem is self-referential: the ticketing system is not the core. The ticketing system is not the subsystem that is directly responsible for anything of interest to you. The ticketing system is an entirely new system, which requires integration with other subsystems and which will frequently need to do handovers to them. This interface is frightening, unexplored territory where new classes of issues that youâ€™ve never seen before can spring up.</p><p>Bank systems are an interesting combination of designed and accidental. The accrete like sedimentary layers. A particular force which affects banks more than most institutions is that the banking industry has undergone <a href="https://www.visualcapitalist.com/the-banking-oligopoly-in-one-chart/">decades of consolidation</a>. When banks merge, one bank doesnâ€™t simply eat the other and digest its balance sheet and people. They end up running their systems in parallel for years while working out an integration plan. That plan will, almost inevitably, cause one of the systems to mostly â€œwinâ€ and the other system to mostly â€œloseâ€, but for business reasons, something of the loser will be retained indefinitely. It now has to be grafted onto the winner, despite frequently being itself decades out of date, having its own collection of grafted acquirees partially attached to it, and needing expert input from people who are no longer with the firm.</p><p>Users can watch this play out in real time. For example, I <a href="https://www.bitsaboutmoney.com/archive/requiem-for-a-bank-loan/">banked</a> at First Republic and also bank at Chase, which now owns First Republic. In something which sounds unimpressive and would blow the mind of bank CTOs from as recently as ten years ago, both sides of the bank understand that the same person has an account on the other side. (You wouldn't think testing Social Security Numbers for equality requires any high-tech wizardry, and you'd be right. The thing which was actually hard was building a process to allow complex ad hoc bidirectional synching of systems that were not built in tandem with each other.)</p><figure><img src="https://lh7-us.googleusercontent.com/pw89gj716u9qQuFKG0Et6S09kSO2MfvOjMlxqyZlBanciXztwHW0ctGAWD4AjVMY71ydYW2JhlMDoKlQxfL0tN2EO_MOEobbCg-PmJxqBpoUW6lc7JSPw5y81xAysm51HIkdswJDdBqeQIXHt6qeZcc" alt="A screenshot of a banner in Chase's web application, welcoming First Republic clients." loading="lazy" width="624" height="87"><figcaption><span>Chase paid tens of billions of dollars over the years to get to the point where one engineer could bang this in-app banner out in 30 minutes.</span></figcaption></figure><p>But because that integration is ongoing and will take years to resolve, neither part of the bank knows consequential things the other part knows about me, even where it strikes most people as obvious that they should. Chase eagerly communicates timelines for transitioning the home loan that First Republic very definitely never wrote. It is utterly clueless about the Line of Credit that they factually did extend. And it will require a lot of midnight oil from hundreds or thousands of people for most of another year before I can walk into a Chase branch and ask what the balance is on an account serviced by First Republic's core.</p><h2 id="human-accountability-and-its-malcontents">Human accountability and its malcontents</h2><p>So letâ€™s talk about how banks spackle over the infelicities in their systems.</p><p>First, the bank builds many subsystems which interface with its core processing systems and ledgers. These systems are built so internal bank staff can see what a customer has done in their accounts and, perhaps, act upon those accounts on their behalf.</p><p>For those keeping score: yep, this interface boundary is another place which can cause the bank to fail to agree with reality. Relatively simple programming issues can cause the staff-exposed view of an account to fail to agree with reality known to the bank.</p><p>For example, they not infrequently fail to show some staff transactions which are â€œpending.â€ In many cases, â€œpendingâ€ has consequences which are extremely similar to being finalized from the perspective of the user, but a particular system might simply not show them. Youâ€™d think that is a confusing choice to make and often underrate the possibility that no one ever made this choice, not really. Sure, it exists (inarguably in this case) in code, and that code might be described in a requirements analysis document that someone handwaved together 18 years ago, but nobody ever said â€œNah, exclude pending transactionsâ€. This was a simple oversight, projected into the future indefinitely, to the enduring annoyance of old hands among staff and the continued surprise of non-specialist users. You might assume that senior members of operational staff have the ability to write a memo to engineering or procurement to tell them that the software that makes up the bank is broken. That is a thing which exists at surprisingly few firms.</p><p>(A repeated experience of my time at Stripe was watching engineers embed with Ops teams for a day, then run back to their laptops while saying â€œIâ€™m so sorry! I canâ€™t believe we did that to you! I will drop everything I am doing and fix it immediately!â€ In many cases, those bugs had existed for months or years. I watched senior engineering leadership ask senior Ops leadership why they had never been asked to fix them. Ops replied that their long experience in the financial industry had taught them that Ops never gets to use software which isnâ€™t broken and that complaining about this is like complaining about gravity.)</p><p>Banks aggressively partition staff based on job duties and levels within those duties. The most relevant silo for retail consumers is actually a series of parallel silos which staff front-line phone support for the bank. Often, each line of business gets its own silo, which accounts for much of the Your Princess Is In Another Castle that happens when you call a bank with a seemingly straightforward question and then get passed between various departments.</p><p>Most products offered to retail consumers and small businesses are relatively low margin, in absolute dollar terms. To be able to offer these, banks use various methods to cram down their support costs. Offshoring is often the face of these initiatives, but stratification by skill levels and powers granted is probably more important to understand.</p><p>A fairly typical setup for a financial institution will have the retail bank support teams stratified into Tier One, Tier Two, and Tier Three. Each has management located with them, who may or may not be shared across tiers.</p><p>You truly havenâ€™t lived until youâ€™ve tried paying for your college education by being a Tier One customer service representative, like your humble correspondent did. (Not at a bank, thank goodness; I might have stayed in a field with that many interesting problems presented.) The reason Tier One exists is that the median problem, so-to-speak, from a retail user is not actually a problem. That retail user is extremely unsophisticated about the bank account, finance in general, and frequently many other things in life. Tier One exists to handhold this individual in getting something very straightforward done, or to pass the call off to Tier Two.</p><p>Many people in our social class want to be extremely compassionate in explaining challenges that some people endure. Sometimes this compassion extends to believing that people with substantial challenges donâ€™t exist or donâ€™t exist in any large numbers. It is extremely important to understand that those challenges exist and that they will <em>dominate your frequent fliers</em> for support. Some people have only emerging competence in English but will want services from a bank which does business in English. Some people, frequently with large account balances and long successful histories with you, are experiencing age-related decline in their faculties and need to be protected, frequently without that being a capital-F Fact within the system yet. Some people are crooks. Some people have a very interesting relationship with the truth, and say many things to banks which probably felt true to them in the moment. (Is that fraud? Eh, itâ€™s complicated.)</p><p>But to zoom into one particular way people can differ from each other: Some people are not as intelligent as you are. That is uncouth to say. In the United States, almost every large organization will institutionally tamp down on any explicit discussion of it. They all must structure their affairs to deal with the reality of it, though.</p><p>Think of the person from your grade school classes who had the most difficulty at everything. The U.S. expects banks to service people much, much less intelligent than them. Some customers do not understand why a $45 charge and a $32 charge would overdraw an account with $70 in it. The bank will not be more effective at educating them on this than the public school system was given a budget of $100,000 and 12 years to try. This customer calls the bank <em>much more frequently than you do</em>. You can understand why, right? From their perspective, they were just going about their life, doing nothing wrong, and then for some bullshit reason the bank charged them $35.</p><p>The reason you have to â€œjump through hoopsâ€ to â€œsimply talk to someoneâ€ (a professional, with meaningful decisionmaking authority) is because the system is set up to a) try to dissuade <em>that guy</em> from speaking to someone whose time is expensive and b) believes, on the basis of voluminous evidence, that you are likely <em>that guy</em> until proven otherwise.</p><p>And so every Tier One rep will talk to dozens of folks a day. Many of those calls areâ€¦ fairly aggravating, from the perspective of the agent. Tier One has limited ability to do anything useful; this depends on the firm and the silo within the firm, but they are largely read-only interfaces to money. They have a few pre-programmed buttons to push which get 90%+ of people they talk to to not call again. They execute scripts and flowcharts, written by people better paid than them, which gate your access to Tier Two.</p><p>In the best operated systems in the world, Tier One gets about one tweet worth of context to pass over to Tier Two when doing a handoff to them. (â€œCust didnâ€™t rec new debit card to Japan plz next day air + waive fee.â€) Most financial institutions are not the best operated systems in the world. The bank â€œforgetsâ€ about your issue as soon as youâ€™re off the line with Tier One, and needs to be told it entirely de novo when you speak to Tier Two.</p><p>Tier Two typically spent a few years in Tier One and has begun to specialize in a subfiefdom of banking. They have emerging competence into the nitty gritty of operations at their institution, at least with regards to that subfiefdom. Theyâ€™re paid more, though not by much. Theyâ€™re typically given more ability to do what my shop called â€œaccommodationsâ€, which means self-authorizing a resolution for a customer which costs money. Tier Two might be able to, for example, credit an account a small amount of money for an arbitrary reason and have the bank charge it off as an operations loss. </p><p>Your humble correspondent had a soft limit of approximately $200, below which no number was worth trifling my management chain or a specialist about. An interesting observation about the physics of money is that Tier Two could conceivably cost the bank more by authorizing accommodations than they earn in salary. A line manager apprised of this probably will not investigate it for more than five minutes before deciding that the bank is satisfied.</p><p>Then you have Tier Three, which at some firms sits in Customer Service and at some firms sits in Operations. There exist some ambiguity and spectral ranges here, but at some point the job changes in character from â€œlow-wage peon reciting a scriptâ€ to â€œprofessional who has a career doing this and is no longer managed on a tickets-closed-per-hour basis.â€</p><p>Tier Three, letâ€™s call them for simplicity, engages in constant firefighting, because at the volume of transactions (and other sources of cases) in all-but-the-tiniest financial firms, something is always on fire. Sometimes youâ€™re covering for hiccups in the technical systems of your institution or counterparties. Sometimes someone has found themselves in an odd edge case or been passed around for ages between departments. Sometimes youâ€™ve received an escalation, about which more later.</p><p>A user of the banking system will often have to redundantly explain themselves when they hit Tier Three, for the same reason as they did when they hit Tier Two. However, because theyâ€™re no longer operating in time-starved tickets-per-hour crunch mode, Tier Three has richer access to systems at the bank and more ability to forensically reconstruct procedural history, including history that is not ledgered. They will frequently do this both to do their jobs and to do the legwork for other professionals at the bank who might have decisionmaking authority in some cases but do not have the access or acumen to pull together a view of a case from disparate systems.</p><p>The gaps in experience between getting passed around tiers are replicated for being passed around departments. Say, for example, that the bank owes you a check and you do not receive it in the mail. The vast majority of checks sent through the mail arrive without issue, but the bank knows that it will have to reissue some of them. There is a process for doing this. Unfortunately, because this is a relatively infrequent issue, Tier 2 does not have a Reissue Check button available to them. Instead, their interface to this process is likely â€œRaise a ticket with Ops and tell the customer someone will call them.â€ There is no system available to Tier 2 which can verify that that call was actually made. The agent has no basis in their training or experience to know whether the bank routinely makes that call. It is quite possible that success rates on that call being placed are quite low, even if you ask for it three times consecutively, and that the bank is entirely institutionally unaware of this.</p><p>And so the customer will feel frustrated and they have been lied to, Tier 2 certainly doesnâ€™t feel like theyâ€™ve lied to anyone (they read the script, itâ€™s a Tuesday), Ops feels like the world is on fire because the world is always on fire, and senior bank management cannot detect this problem because no metric available to them is capable of disaggregating it from the complex monster that is the financial system.</p><h2 id="two-embedded-surprises-about-bank-staffing">Two embedded surprises about bank staffing</h2><p>Many traditionally-minded users of banks assume that someone at their branch can likely help them with issues. Due to the <a href="https://www.bitsaboutmoney.com/archive/branch-banking/">deskilling of the bank branch</a>, the people at a bank branch, including the branch manager in many firms, can only offer solutions to relatively straightforward problems. For the other ones, they also have to call into a support phone tree. Sometimes the bank will have ability to e.g. share context between their screen and the Tier 2 rep; sometimes theyâ€™re literally incapable of proving to the bank that they work there. (You might think Iâ€™m joking. To beat a drum: the level of technical sophistication across the spectrum of U.S. financial institutions varies wildly.)</p><p>The other surprise is that substantially every financial institution has a parallel way to reach decisionmakers in every area it operates in, which skips most or all of the tiering system and the technical and organizational scar tissue that it carries. This goes by different names in different places but â€œescalationsâ€ is a fairly common one.</p><p>Much like the United States has decided, in its infinite wisdom, that caseworkers for immigration and passport services should be staffed <a href="https://sgp.fas.org/crs/misc/R44726.pdf">in every Congressmanâ€™s office</a> and not at the agency that actually handles immigration or passport issuance, there very likely exist people at the bank whose job is working the bank more than it is working for the bank. A number of functions which are not ordinarily customer-facing are given the contact information for that group, with the instruction â€œIn case of emergency, skip Tier Everything and talk immediately to the highly-placed troubleshooting team.â€</p><p>If you are a reporter and call a bank for comment about a widow on the cusp of being improperly foreclosed upon, you will (fairly reliably) find your words forwarded to the troubleshooting team within a few minutes. If youâ€™re a regulator and intervene on behalf of an individual, same result. You can absolutely achieve this as a civilian, too; a paper letter to the VP of Retail Banking, Office of the President, or Investor Relations will often cause the bank to swing into motion in the same way. (I wrote a few hundred letters like that <a href="https://www.kalzumeus.com/2017/09/09/identity-theft-credit-reports/#ghostwriting">as a hobby</a> back in the day.)</p><p>These folks are professionals who are capable of keeping paper notes and having day-to-day recollection of things they have done in complex cases. They are managed and incentivized in a way which allows them to have agency. The formal customer support organization is <em>very, very bad at this</em>, at every tier. It is very difficult to do in a model where youâ€™re constantly bouncing cases around individual reps and between departments.</p><p>Is this because banks are malicious? Are they willing to grind retail users to bonemeal in the pursuit of another cent of earnings per share? The truth is a bit more mundane: supporting people with can-do-anything-you-throw-at-them professionals is ridiculously expensive and getting moreso over time. The per-case cost for the troubleshooting team can be more than 100X that of the tiering system.</p><p>Retail customers have relationships where they pay highly-educated high-agency jacks-of-all-trades to provide professional services in arbitrarily complex situations. <em>They hate the experience of those relationships.</em> They hate their medical bills. They are incredulous that lawyers bill hundreds of dollars per hour (in six minute increments).</p><p>You can get something approaching this level of service out of a bank, too, and the private bank generating $150,000+ in annual revenue per client would be happy to make your acquaintance. But if you want phone calls to the bank to be both answered at 2 AM and absolutely free, you want the tiering system. <em>Society</em> wants the tiering system. It is why a high school student with a paper route can open a checking account, get a debit card, and start buying things on Amazon. It is why bank branches can be operated in working class neighborhoods.</p><p>As a sophisticated user of the banking system, a useful skill to have is understanding whether the ultimate solution to an issue facing you is probably available to Tier Two or probably only available to a professional earning six figures a year. You can then route your queries to the bank to get in front of the appropriate person with the minimal amount of effort expended on making this happen.</p><p>You might think bank would hate this, and aggressively direct people who discover side channels to Use The 1-800 Number That Is What It Is For. For better or worse, the side channels are not an accident. They are <em>extremely intentionally designed</em>. Accessing them often requires performance of being a professional-managerial class member or otherwise knowing some financial industry shibboleths. This is <em>not accidental</em>; that greatly cuts down on â€œmisuseâ€ of the side channels by <em>that guy</em>.</p><p>It is also much more institutionally palatable to the bank and other stakeholders like e.g. regulators. No financial institution can say â€œWe offer differential service levels to our community based on their education level, perceived social class, and perceived capability to bring power to bear on their behalf.â€ <em>Every financial institution factually does that.</em> The successful way to phrase it is â€œWe offer contextually appropriate services to the entire range of customers, who come from all walks of life, <em>and also</em> we respond with alacrity to any issues impacting our important stakeholders via a variety of programs.â€&nbsp;</p><h2 id="society-has-goals-which-conflict-with-banks-being-good-at-banking">Society has goals which conflict with banks being good at banking</h2><p>I hate sounding like a conspiracy theorist about banks, which for whatever reason seem to attract a disproportionate amount of attention from people who believe the Illuminati and lizardmen are conspiring to corrupt the free peoples of the world. And so ordinarily I do not want to say crazy things like â€œSometimes banks suck because we want them to suck.â€</p><p>Sometimes banks suck because we want them to suck.</p><p>In the specific case of â€œWhy did the bank close my account, seemingly for no reason? Why will no one tell me anything about this? Why will no one take responsibility?â€, the answer is frequently that the bank is following the law. As weâ€™ve <a href="https://www.bitsaboutmoney.com/archive/money-laundering-and-aml-compliance/">discussed previously</a>, banks will frequently make the â€œindependentâ€ â€œcommercial decisionâ€ to â€œexit the relationshipâ€ with a particular customer after that customer has had multiple Suspicious Activity Reports filed. SARs can (and sometimes must!) be filed for innocuous reasons and do not necessarily imply any sort of wrongdoing.</p><p>SARs are secret, by regulation. See <a href="https://www.law.cornell.edu/cfr/text/12/21.11#:~:text=A%20SAR%2C%20and%20any%20information,in%20this%20paragraph%20(k).">12 CFR Â§ 21.11(k)(1)</a> from the Office of Comptroller of the Currency:</p><blockquote>No national <a href="https://www.law.cornell.edu/definitions/index.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=1b4e13db0fedfcf4130540b3d34ef442&amp;term_occur=999&amp;term_src=Title:12:Chapter:I:Part:21:Subpart:B:21.11">bank</a>, and no director, officer, employee, or agent of a national <a href="https://www.law.cornell.edu/definitions/index.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=1b4e13db0fedfcf4130540b3d34ef442&amp;term_occur=999&amp;term_src=Title:12:Chapter:I:Part:21:Subpart:B:21.11">bank</a>, shall disclose a SAR or any information that would reveal the existence of a SAR. Any national <a href="https://www.law.cornell.edu/definitions/index.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=1b4e13db0fedfcf4130540b3d34ef442&amp;term_occur=999&amp;term_src=Title:12:Chapter:I:Part:21:Subpart:B:21.11">bank</a>, and any director, officer, employee, or agent of any national <a href="https://www.law.cornell.edu/definitions/index.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=1b4e13db0fedfcf4130540b3d34ef442&amp;term_occur=999&amp;term_src=Title:12:Chapter:I:Part:21:Subpart:B:21.11">bank</a> that is subpoenaed or otherwise requested to disclose a SAR, or any information that would reveal the existence of a SAR, shall decline to produce the SAR or such information, citing this section and <a href="https://www.law.cornell.edu//uscode/text/31/5318">31 U.S.C. 5318(g)(2)(A)(i)</a>...</blockquote><p>If the United States brings its subpoena power to bear against a bank teller and asks them about a SAR, theyâ€™re supposed to say nothing. That is the law! (Regulation, well, if one wants to be technical.) It is designed to be enforced <em>against the interests of the United States of America</em>! Customers have far less access than the U.S. awards to the U.S.! So does the teller, incidentally: to avoid constantly violating this, Compliance at most functioning institutions has long-since decided that SARs will live in their own walled garden of a subsystem, seen only by the people responsible for drafting them and sending them to FinCEN.</p><p>That subsystemsâ€™ interactions with every other system are, of course, a site for <em>extremely painful</em> hilarity to happen. If, for example, a SAR is misfiled because that subsystem doesnâ€™t share the same view of account ownership as another part of the overall system, investigating that problem might require telling the customer that they were investigated, which you cannot do. And because this is insufficiently Kafkaesque, at some financial institutions, you can get a SAR filed for knowing what a SAR is, because â€œadvanced knowledge of anti-moneylaundering procedureâ€ is a characteristic only of financial professionals and terrorists. Compliance training can tell e.g. personal bankers to please look at the Know Your Customer questionnaire and see if â€œProfessional background: I work in financeâ€ is bubbled in and then draw the appropriate inference.</p><p>You might think I am joking. I am utterly not joking. Most of the times infelicities in the world have a logical explanation to them, a structural cause where each individual link in the chain sounded good at the time and the result just happens to be suboptimal. And sometimes the world is <em>absolutely batshit insane</em>.</p><h2 id="so-what-can-be-done-about-this">So what can be done about this?</h2><p>Like many structural problems, banks lacking object permanence didnâ€™t happen overnight and canâ€™t be fixed overnight.</p><p>A lot of the fix is technical. In the not-too-distant past, there were zeroâ€”<em>zero</em>â€”financial institutions which were competent at software. There are now a handful of them, after the expenditure of many tens of billions of dollars. That was the price of getting without-loss-of-generality Chase to the point where in-house engineers can cause the retail web app to react to me having an account at First Republic less than a year after their purchase of that bank.</p><p>Although it certainly doesnâ€™t feel like it to people who hit edge cases, the tiered support model is a technology which took us decades to popularize and which <em>made the world much better</em>. It brought down the cost of financial services and supported product innovation which would have been impossible under the mid-century bank staffing model. We could not have credit cards or discount brokerages without the tiered support model. The <a href="https://www.amazon.com/Invested-Changing-Forever-Americans-Invest-ebook/dp/B07MYKVLCL/">biography of Charles Schwab</a> makes this point persuasively at considerable length: competent telephone operations were instrumental to bringing equity ownership to the middle class. You should prefer a world with credit cards and discount brokerages to one which doesnâ€™t have them, even as you listen to hold music occasionally.</p><p>It will similarly take decades to roll out the best-functioning refinements on customer service at scale to the entirety of the financial system. Partly this will happen through continued consolidation; the more banks Chase ends up owning, the higher the average operational competence in the U.S. financial system is. (And thatâ€™sâ€¦ saying something.)</p><p>Partly this will happen as banks increasingly tap external providers for technology where the right things are recorded automatically and actioned appropriately. Partly, I continue to expect Operations to come further into its own as a high-status discipline, and to rewrite the internal structure of banks just as engineering has done over the last two decades.</p><p>Partly this will happen as banks increasingly partner with firms that impose a tech-inflected view of the customer experience. Google is, for example, a legendarily hostile organization to attempt to get customer support from. Google is also beloved by users because of overwhelming competence in shipping products that work almost all of the time. If you think that talking to a compassionate human is a core part of the banking experience, there are many banks in Iowa who will sell that service to you. If you simply want to access your money on your phone and have that almost always work, Cash App will happily operate as a front end over Lincoln Savings Bank to make that happen. (There are <a href="https://www.theinformation.com/articles/tiny-banks-that-powered-cash-app-grew-like-crazy-then-the-feds-came-calling">many layers</a> to that onion. No particular equilibrium is necessarily the â€œrightâ€ one!)</p><p>And partly, we as a society have to make some tradeoffs. We <em>want something</em> from 12 CFR Â§ 21.11(k)(1) . It was not written by accident or because the drafters were stupid. Every future with 12 CFR Â§ 21.11(k)(1) in it will include many Americans whose bank accounts are closed for no reason that can be disclosed to them. Many of them will have done nothing wrong.</p><p>Plausibly, we should decide to stop doing the thing that no one wants us to do. And, as a particular thing which could help unlock that: if one cares a lot about the experience of people at the socioeconomic margins, one should perhaps spend less time fulminating about greedy capitalists and spend more time reading Requests For Public Comment by relatively obscure parts of the administrative state.</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why only 1% of the Snowden Archive will ever be published (116 pts)]]></title>
            <link>https://www.computerweekly.com/news/366554957/Why-only-1-of-the-Snowden-Archive-will-ever-be-published</link>
            <guid>38180197</guid>
            <pubDate>Tue, 07 Nov 2023 17:49:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.computerweekly.com/news/366554957/Why-only-1-of-the-Snowden-Archive-will-ever-be-published">https://www.computerweekly.com/news/366554957/Why-only-1-of-the-Snowden-Archive-will-ever-be-published</a>, See on <a href="https://news.ycombinator.com/item?id=38180197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-header">
	
	






	

	<h2>Speaking to Computer Weekly after we published new revelations from the Snowden archive, the Guardianâ€™s Pulitzer Prize winner, Ewen MacAskill, explains why more of the Snowden trove is unlikely to see the light of day</h2>
</div><div id="content-center">
					<!-- EzinePromoController, generated at 13:50:14 Tue Nov 7, 2023, by cds1 -->
<!-- ContentItemController, generated at 12:29:19 Tue Nov 7, 2023, by cds1 -->













<ul>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	


	
		<li><i data-icon="1"></i></li>
	
	
		<li><i data-icon="2"></i></li>
	
	
		
	
</ul>		<section id="content-body">
<p>Some 10 years after he flew to Hong Kong to meet Edward Snowden with Glenn Greenwald and Laura Poitras, <em>The Guardianâ€™s</em> Pulitzer Prize winner, Ewen MacAskill, talks to Computer Weekly about the Snowden files.</p>
 
<p>MacAskill was speaking after Computer Weekly revealed the <a href="https://www.computerweekly.com/news/366552520/New-revelations-from-the-Snowden-archive-surface">first new facts to emerge from the Snowden files</a> since the archive first made headlines in 2013.</p> 
<p>The three new revelations have surfaced for the first time only thanks to a highly technical publication: a doctoral thesis authored by US investigative journalist and postdoctoral researcher Jacob Appelbaum, as part of his degree in applied cryptography from the Eindhoven University of Technology in the Netherlands.</p> 
<p>Their publication by Computer Weekly has revived the debate as to why the entire Snowden archive has never been published, considering that even after a decade the three revelations remain indisputably in the public interest, and it is reasonable to assume there are many others like them.</p> 
<p>MacAskill, who shared the Pulitzer Prize for Public Service with Glenn Greenwald and Laura Poitras for their journalistic work on the Snowden files, retired from <em>The Guardian</em> in 2018. He told Computer Weekly that:&nbsp;</p> 
<ul> 
 <li>As far as he knows, a copy of the documents is still locked in the <em>New York Times</em> office. Although the files are in the <em>New York Times</em> office, <em>The Guardian</em> retains responsibility for them.</li> 
 <li>As to why the New York Times has not published them in a decade, MacAskill maintains â€œthis is a complicated issueâ€. â€œThere is, at the very least, a case to be made for keeping them for future generations of historians,â€ he said.</li> 
 <li>Why was only 1% of the Snowden archive published by the journalists who had full access to it? Ewen MacAskill replied: â€œThe main reason for only a small percentage â€“ though, given the mass of documents, 1% is still a lot â€“ was diminishing interest.â€</li> 
</ul> 
<p>The Snowden archive allows exposing and documenting the rise of the mass-surveillance state, a serious threat to democracy. Have the journalists and media with access to the full archive done everything they can to expose this threat? That is the crux of the matter, because even in a democracy bad people can be elected who could use such unprecedented Orwellian control to crush any opposition. Legendary Pentagon Papers whistleblower Daniel Ellsberg said: â€œAs Snowden has put it, weâ€™re a â€˜turnkey tyrannyâ€™: in other words, turn a switch, and we could be a total police state.â€</p> 
<section data-menu-title="Mass surveillance and loss of privacy">
 <h2><i data-icon="1"></i>Mass surveillance and loss of privacy</h2>
 <p>MacAskill tells Computer Weekly: â€œThat is what we did. With hindsight, we could have done some things better. But those stories reverberated around the world and still do today. Snowden wanted to alert the world to the scale of mass surveillance and loss of privacy, and he succeeded in that. He believes that those living in democracies have a right to know.</p>
 <p>â€œAlthough the NSA and GCHQ have since developed better tools and surveillance is more intrusive than ever, Snowden has increased public awareness of the threat posed by loss of privacy,â€ he said. â€œMuch of the public may be apathetic, but at least they know.â€</p>
 <p>MacAskill said he only worked on a small selection of documents from the archive, when he met the former CIA whistleblower in Hong Kong. There, Snowden gave him a memory stick with tens of thousands of documents from the National Security Agency (NSA) and its British partner, GCHQ, which formed the basis of the subsequent reporting by <em>The Guardian</em>. <em>The Guardian</em> shared the documents with <em>The New York Times</em> and ProPublica, and were to work alongside journalists from those organisations.</p>
</section>    
<section data-menu-title="Three revelations">
 <h2><i data-icon="1"></i>Three revelations</h2>
 <p><em>The Guardianâ€™s</em> journalist did not recall seeing the three revelations published by Computer Weekly, summarised below:</p>
 <ul> 
  <li>The NSA listed Cavium, an American semiconductor company marketing Central Processing Units (CPUs) â€“ the main processor in a computer which runs the operating system and applications â€“ as a successful example of a â€œSIGINT-enabledâ€ CPU supplier. Cavium, now owned by Marvell, said it does not implement back doors for any government.</li> 
  <li>The NSA compromised lawful Russian interception infrastructure, SORM. The NSA archive contains slides showing two Russian officers wearing jackets with a slogan written in Cyrillic: â€œYou talk, we listen.â€ The NSA and/or GCHQ has also compromised key lawful interception systems.</li> 
  <li>Among example targets of its mass-surveillance programme, PRISM, the NSA listed the Tibetan government in exile.</li> 
 </ul>
 <p>â€œGiven the sheer volume of documents, it is possible I and reporters from <em>The Guardian</em>, <em>The New York Times</em> and ProPublica missed them or were more interested in other documents. Or it could be that the documents you refer to are in the main archive, which, as far as I know, only Laura Poitras and Glenn Greenwald had access to.â€</p>
 <p>He said he worked on â€œonly a small selection of documents from the archive while in Hong Kong, though these contained the stories that were to have the most impact, such as the mass collection of US phone records and the revelations of the PRISM programmeâ€.</p>
 <p>Why was only 1% of the documents published, in the end? â€œThe documents are not like the WikiLeaks ones from the US state department, which were written by diplomats and, for the most part, easily understandable,â€ said Ewen MacAskill.</p>
 <p>â€œThe Snowden files are largely technical, with lots of codewords and jargon that is hard to decipher. There are pages and pages of that which the public would not be interested in. There are also documents that relate to operational matters. Snowden said from the start he wanted us to report on issues related to mass surveillance, not operational matters. So we stuck to that.â€</p>
</section>       
<section data-menu-title="Snowden did not want documents published en masse">
 <h2><i data-icon="1"></i>Snowden did not want documents published en masse</h2>
 <p><em>The Guardianâ€™s</em> Pulitzer Prize winner said the main reason why only a small percentage was published was due to diminishing interest. â€œ<em>The Guardian</em> published lots of stories from the Snowden files for months and months after Hong Kong,â€ he said. â€œBut it reached a point where each story attracted smaller and smaller readerships, as interest dwindled.</p>
 <p>â€œThe feeling at <em>The Guardian</em> â€“ and, I assume, at <em>The New York Times</em> and ProPublica â€“ was they had reported on the biggest stories in the documents and there was diminishing interest in publishing more.</p>
 <p>â€œThe feeling, too, at <em>The Guardian</em> was that by continuing to report on stories that attracted less interest, we were in danger of undermining the impact of the initial ones. <em>The Intercept</em>, which had access to more documents than us, continued publishing for a while after us.â€</p>
 <p>The three unpublished revelations revealed by Computer Weekly, thanks to Jacob Appelbaumâ€™s doctoral thesis, confirm it is reasonable to assume the archive still contains important information in the public interest. According to Appelbaum: â€œEven if the privacy-violating intercepts are excluded from publication, there is an entire parallel history in that archive.â€</p>
 <p>We asked McAskill why <em>The New York Times</em> hasnâ€™t published them in a decade. â€œThis is a complicated issue,â€ he said. â€œAlthough the files are in the <em>New York Times</em> office, <em>The Guardian</em> retains responsibility for them. Should more journalists be given access to the Snowden documents? In that case, who should decide which journalists get to see them? Should the whole lot just be published for everyone to see? Snowden did not want the documents to be published en masse.</p>
</section>      
<section data-menu-title="Espionage Act">
 <h2><i data-icon="1"></i>Espionage Act</h2>
 <p>â€œThe bottom line is that Snowden is facing charges under the Espionage Act. If he was ever to return to the US and face trial, the documents could be used against him. All journalists have a duty to protect source material. How best to do that? How long would <em>The</em> <em>New York Times</em> be willing to store them? Where else could they be stored? Should the documents be destroyed?â€</p>
 <p>MacAskill acknowledges that â€œthere is, at the very least, a case to be made for keeping them for future generations of historiansâ€.</p>
 <p>â€œIs there a university that would be prepared to take them?â€ he suggested. â€œBut that would be expensive, and could they ensure they would be secure?â€</p>
 <p>MacAskill left the staff of <em>The Guardian</em> in 2018. â€œI donâ€™t know what discussions, if any, have taken place between <em>The Guardian</em> and <em>The New York Times</em> since then,â€ he said.&nbsp;</p>
</section></section>










<!-- DownloadOfferController, generated at 13:50:15 Tue Nov 7, 2023, by cds1 -->
<!-- AskAnExpertController, generated at 13:50:15 Tue Nov 7, 2023, by cds1 -->
<!-- DigDeeperController, generated at 12:58:34 Tue Nov 7, 2023, by cds1 -->
<section id="DigDeeperSplash">
		<h4>
			<i data-icon="m"></i>Read more on Privacy and data protection</h4>
		<ul>
			<li><a id="DigDeeperItem-1" href="https://www.computerweekly.com/news/366552520/New-revelations-from-the-Snowden-archive-surface">
					<img data-src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero Images/US-NSA-aerial-day-hero_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/US-NSA-aerial-day-hero_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/US-NSA-aerial-day-hero.jpg 1280w" alt="" srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/US-NSA-aerial-day-hero_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/US-NSA-aerial-day-hero.jpg 1280w">
					<h5>New revelations from the Snowden archive surface</h5>
						
				</a></li>
			<li><a id="DigDeeperItem-2" href="https://www.techtarget.com/searchsecurity/definition/National-Security-Agency">
					<img data-src="https://cdn.ttgtmedia.com/visuals/digdeeper/2.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/digdeeper/2_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/digdeeper/2.jpg 1280w" alt="" src="https://cdn.ttgtmedia.com/visuals/digdeeper/2.jpg" srcset="https://cdn.ttgtmedia.com/visuals/digdeeper/2_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/digdeeper/2.jpg 1280w">
					<h5>National Security Agency (NSA)</h5>
						<div>
							<p><img src="https://cdn.ttgtmedia.com/rms/onlineimages/patrizio_andy.jpg" alt="AndyPatrizio">
									</p>
								<p><span>By: <span>Andy&nbsp;Patrizio</span></span>
							</p></div>
				</a></li>
			<li><a id="DigDeeperItem-3" href="https://www.computerweekly.com/news/252489133/Julian-Assange-held-back-15000-documents-to-prevent-harm-to-US-government">
					<img data-src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero Images/Julian-Assange-trial-Sept-2020-CREDIT-Jekaterina-Saveljeva-hero_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/Julian-Assange-trial-Sept-2020-CREDIT-Jekaterina-Saveljeva-hero_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/Julian-Assange-trial-Sept-2020-CREDIT-Jekaterina-Saveljeva-hero.jpg 1280w" alt="" srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/Julian-Assange-trial-Sept-2020-CREDIT-Jekaterina-Saveljeva-hero_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/Julian-Assange-trial-Sept-2020-CREDIT-Jekaterina-Saveljeva-hero.jpg 1280w">
					<h5>Julian Assange held back 15,000 documents to prevent harm to US government</h5>
						<div>
							<p><img src="https://cdn.ttgtmedia.com/rms/computerweekly/Bill-Goodwin-CW-contributor-2022-140x180px.jpg" alt="BillGoodwin">
									</p>
								<p><span>By: <span>Bill&nbsp;Goodwin</span></span>
							</p></div>
				</a></li>
			<li><a id="DigDeeperItem-4" href="https://www.computerweekly.com/opinion/11-obscure-questions-Facebook-Max-Schrems-and-the-European-Court-of-Justice">
					<img data-src="https://cdn.ttgtmedia.com/rms/computerweekly/Max-Schrems-hero_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/rms/computerweekly/Max-Schrems-hero_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/rms/computerweekly/Max-Schrems-hero.jpg 1280w" alt="" src="https://cdn.ttgtmedia.com/rms/computerweekly/Max-Schrems-hero_searchsitetablet_520X173.jpg" srcset="https://cdn.ttgtmedia.com/rms/computerweekly/Max-Schrems-hero_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/rms/computerweekly/Max-Schrems-hero.jpg 1280w">
					<h5>11 obscure questions, Facebook, Max Schrems and the European Court of Justice</h5>
						<div>
							<p><img src="https://cdn.ttgtmedia.com/rms/computerweekly/Kevin-Cahill-CW-contributor.jpg" alt="KevinCahill">
									</p>
								<p><span>By: <span>Kevin&nbsp;Cahill</span></span>
							</p></div>
				</a></li>
			</ul>
	</section>
<!-- EHandbookController, generated at 12:58:16 Tue Nov 7, 2023, by cds1 -->
<!-- CollectionController, generated at 12:58:16 Tue Nov 7, 2023, by cds1 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. military members' personal data being sold by online brokers (154 pts)]]></title>
            <link>https://www.axios.com/2023/11/06/military-data-sold-for-cents-cheap-privacy</link>
            <guid>38180014</guid>
            <pubDate>Tue, 07 Nov 2023 17:39:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2023/11/06/military-data-sold-for-cents-cheap-privacy">https://www.axios.com/2023/11/06/military-data-sold-for-cents-cheap-privacy</a>, See on <a href="https://news.ycombinator.com/item?id=38180014">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-theme="core" data-overlay-container="true" id="__next"><header><nav aria-label="Primary" data-cy="top-nav-header"></nav></header><main id="main-content"><div data-theme="core"><div data-vars-content-id="db774c90-c9b7-4fb2-8014-1ce74aa26dd2" data-vars-headline="Study: U.S. military members' personal data being sold by online brokers" data-vars-category="story" data-vars-sub-category="story"><div><div><p><img alt="headshot" loading="lazy" width="52" height="52" decoding="async" data-nimg="1" srcset="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2F8DRdJWpR5xDCrc2WmI-xkbYz0ug%3D%2F0x0%3A328x328%2F52x0%2F2020%2F05%2F01%2F1588371366979.jpg&amp;w=320&amp;q=75 1x" src="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2F8DRdJWpR5xDCrc2WmI-xkbYz0ug%3D%2F0x0%3A328x328%2F52x0%2F2020%2F05%2F01%2F1588371366979.jpg&amp;w=320&amp;q=75"></p></div><div><ul><li data-cy="byline-author"><a href="https://www.axios.com/authors/jknutson"><span>Jacob Knutson</span></a></li></ul></div></div><figure data-cy="au-image"><img data-cy="StoryImage" alt="Members of a military honor guard marching in Washington, D.C., in October 2023." fetchpriority="high" width="1920" height="1080" decoding="async" data-nimg="1" sizes="100vw" srcset="https://images.axios.com/VRvj8WXOIkpPfYSLyXWpppvJRIw=/0x217:8000x4717/320x180/2023/11/06/1699287620638.jpg?w=320 320w, https://images.axios.com/VRvj8WXOIkpPfYSLyXWpppvJRIw=/0x217:8000x4717/320x180/2023/11/06/1699287620638.jpg?w=320 320w, https://images.axios.com/ZY4XOcCtS0XtRmymz2x-6TgPVCA=/0x217:8000x4717/640x360/2023/11/06/1699287620638.jpg?w=640 640w, https://images.axios.com/ZY4XOcCtS0XtRmymz2x-6TgPVCA=/0x217:8000x4717/640x360/2023/11/06/1699287620638.jpg?w=640 640w, https://images.axios.com/Qpz4AXkEJ0FKoglrdTHInSDzzTw=/0x217:8000x4717/768x432/2023/11/06/1699287620638.jpg?w=768 768w, https://images.axios.com/Qpz4AXkEJ0FKoglrdTHInSDzzTw=/0x217:8000x4717/768x432/2023/11/06/1699287620638.jpg?w=768 768w, https://images.axios.com/Dd5PDa9AnD0TjedLbukTVZoFzF8=/0x217:8000x4717/1024x576/2023/11/06/1699287620638.jpg?w=1024 1024w, https://images.axios.com/Dd5PDa9AnD0TjedLbukTVZoFzF8=/0x217:8000x4717/1024x576/2023/11/06/1699287620638.jpg?w=1024 1024w, https://images.axios.com/6Bh9BlqhwhNRYsMOYXHX-jJ1has=/0x217:8000x4717/1366x768/2023/11/06/1699287620638.jpg?w=1366 1366w, https://images.axios.com/6Bh9BlqhwhNRYsMOYXHX-jJ1has=/0x217:8000x4717/1366x768/2023/11/06/1699287620638.jpg?w=1366 1366w, https://images.axios.com/VbfTYCZ6tX51Dn8bDiPttQ2EoB8=/0x217:8000x4717/1600x900/2023/11/06/1699287620638.jpg?w=1600 1600w, https://images.axios.com/VbfTYCZ6tX51Dn8bDiPttQ2EoB8=/0x217:8000x4717/1600x900/2023/11/06/1699287620638.jpg?w=1600 1600w, https://images.axios.com/DXwCc83muwr-D7Y6ZljLbu3v8ss=/0x217:8000x4717/1920x1080/2023/11/06/1699287620638.jpg?w=1920 1920w, https://images.axios.com/DXwCc83muwr-D7Y6ZljLbu3v8ss=/0x217:8000x4717/1920x1080/2023/11/06/1699287620638.jpg?w=1920 1920w" src="https://images.axios.com/DXwCc83muwr-D7Y6ZljLbu3v8ss=/0x217:8000x4717/1920x1080/2023/11/06/1699287620638.jpg?w=1920"><figcaption><p>Members of a military honor guard marching in Washington, D.C., in October 2023. Photo: Drew Angerer/Getty Images</p></figcaption></figure><div><p>Sensitive, highly detailed personal data for thousands of active-duty and veteran U.S. military members can be purchased for as little as one cent per name through data broker websites, according to a <a data-vars-link-text="new study published" data-vars-click-url="https://techpolicy.sanford.duke.edu/wp-content/uploads/sites/4/2023/11/Sherman-et-al-2023-Data-Brokers-and-the-Sale-of-Data-on-US-Military-Personnel.pdf" data-vars-content-id="db774c90-c9b7-4fb2-8014-1ce74aa26dd2" data-vars-headline="Study: U.S. military members' personal data being sold by online brokers" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://techpolicy.sanford.duke.edu/wp-content/uploads/sites/4/2023/11/Sherman-et-al-2023-Data-Brokers-and-the-Sale-of-Data-on-US-Military-Personnel.pdf" target="_blank">new study published</a> on Monday by Duke University researchers.</p><p><strong>Why it matters: </strong>Researchers warned that the data can be easily obtained and used by malicious actors to target current and former military personnel, their families and acquaintances with a myriad of schemes, including blackmail and misinformation campaigns.</p><ul><li>The data about military personnel purchased as part of the study included full names, physical and email addresses, health and financial information and details about their ethnicity, religious practices and political affiliation.</li><li>In some cases, the information also included whether the person owned or rented a home, was married or had children. The children's ages and sexes were accessible, too.</li></ul><p><strong>How it works: </strong>As part of the study, the researchers contacted 12 data brokers about purchasing information on military personnel.</p><ul><li>The researcher found that many of the brokers lacked controls on who could purchase the data or regulations to ascertain the intended uses for the information.</li><li>In making their purchases, the researchers were able to narrow down their data selections to personnel in Maryland, Virginia, or the District of Columbia. </li><li>In one data set, the results showed service members living near military installations including Virginia's Quantico and Fort Walker, formerly known as Fort AP Hill, and North Carolina's Fort Liberty, formerly known as Fort Bragg. </li><li>Thousands of data brokers, many of which are based in the U.S., collect and sell data on millions of people every year.</li><li>The multi-billion-dollar industry collects data on virtually every American, primarily through public records or other businesses â€” such as mobile app companies and credit reporting agencies â€” collecting data on their customers and selling it.</li></ul><p><strong>By the numbers: </strong>The researchers bought data on up to around 45,000 military personnel for between $0.12 to $0.32 per record. </p><ul><li>They also bought data belonging to 5,000 friends and family members of military personnel.</li><li>Larger data purchases of over 1.5 million service members were available for as little as $0.01 per record from at least one broker the researchers contacted.</li></ul><p><strong>The big picture:</strong> The researchers called on Congress to pass a comprehensive privacy law and for regulatory agencies like the Federal Trade Commission to develop rules to govern military personnel data purchases.</p><p><strong>Thought bubble</strong>: The report is especially concerning given nation-state adversaries and governments are also interested in buying information from data brokers. </p><ul><li>Although brokers typically collect and sell information about a wide range of Americans, international spies are likely to find unique value in data sets focused on military personnel for their operations targeting classified U.S. sources.</li></ul><p><strong>Go deeper: </strong><a data-vars-link-text="2023 toll of data breaches and leaks already tops 2022" data-vars-click-url="https://www.axios.com/2023/10/13/2023-data-compromises-surpass-2022" data-vars-content-id="db774c90-c9b7-4fb2-8014-1ce74aa26dd2" data-vars-headline="Study: U.S. military members' personal data being sold by online brokers" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/10/13/2023-data-compromises-surpass-2022" target="_self">2023 toll of data breaches and leaks already tops 2022</a></p></div></div><h5>Go deeper</h5></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toyota's new $10k pickup (121 pts)]]></title>
            <link>https://www.motortrend.com/reviews/2025-toyota-imv-0-pickup-truck-first-drive-review-japan-mobility-show/</link>
            <guid>38178727</guid>
            <pubDate>Tue, 07 Nov 2023 16:21:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.motortrend.com/reviews/2025-toyota-imv-0-pickup-truck-first-drive-review-japan-mobility-show/">https://www.motortrend.com/reviews/2025-toyota-imv-0-pickup-truck-first-drive-review-japan-mobility-show/</a>, See on <a href="https://news.ycombinator.com/item?id=38178727">Hacker News</a></p>
Couldn't get https://www.motortrend.com/reviews/2025-toyota-imv-0-pickup-truck-first-drive-review-japan-mobility-show/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Fedora 39 Released (154 pts)]]></title>
            <link>https://fedoramagazine.org/announcing-fedora-linux-39/</link>
            <guid>38178666</guid>
            <pubDate>Tue, 07 Nov 2023 16:17:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fedoramagazine.org/announcing-fedora-linux-39/">https://fedoramagazine.org/announcing-fedora-linux-39/</a>, See on <a href="https://news.ycombinator.com/item?id=38178666">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
						
<p>On November 6, 2003, the Fedora Project released the Fedora Core 1. One day and twenty years later, weâ€™re pleased to bring you Fedora Linux 39, our complete, community-built operating system for desktops, laptops, servers, the cloud, edge devices â€” and just about anything else you can think of.</p>



<p>As always, you should make sure your system is fully up-to-date before upgrading from a previous release. Canâ€™t wait to get started? <a href="https://fedoraproject.org/#editions">Download</a> while you read!</p>



<h2><strong>Desktop news</strong></h2>



<p>Fedora Workstation now features GNOME 45, which brings better performance and many usability enhancements, including a new workspace switcher and a much-improved image viewer.</p>



<p>If youâ€™re looking for a different desktop experience, our Budgie Special Interest Group has created Fedora Onyx, a Budgie-based â€œAtomicâ€ desktop in the spirit of Fedora Silverblue.&nbsp;</p>



<p>Of course, thatâ€™s not all â€” we also have updated desktop flavors featuring KDE Plasma Desktop, Xfce, Cinnamon, and more.</p>



<h2><strong>In the cloud</strong></h2>



<p>Fedora Cloud images will be officially available in Microsoft Azure (in addition to Google Cloud and AWS). Also, our cloud images now are configured so that cloud-init can (at your option) install updates and reboot when first provisioned, so you know youâ€™re running with our latest security updates.</p>



<h2><strong>Other updates</strong></h2>



<p>As always, weâ€™ve updated many, many other packages as we work to bring you the best of everything the free and open source software world has to offer. Fedora Linux 39 includes gcc 13.2, binutils 2.40, glibc 2.38, gdb 13.2, and rpm 4.19. It also has updates to popular programming language stacks, including Python 3.12 and Rust 1.73.</p>



<p>Of particular note, we include the latest version of Inkscape, the popular vector graphics illustration and drawing tool. Inkscape <em>also</em> turned 20 yesterday â€” weâ€™re digital twins! Congratulations to everyone in that awesome project as well.</p>



<h2><strong>In the unlikely event of a problemâ€¦</strong></h2>



<p>If you run into a problem, visit our<a href="https://ask.fedoraproject.org/"> Ask Fedora</a> user support forum. This includes a category for <a href="https://discussion.fedoraproject.org/tags/c/ask/common-issues/82/none/f39">common issues</a>. (There are a few issues with Raspberry Pi in particular which we are still working to resolve. So if youâ€™re planning on updating one of those, make sure to check first.)&nbsp;</p>



<h2>Or if you just want to say â€œhelloâ€â€¦</h2>



<p>Drop by our <a href="https://discussion.fedoraproject.org/c/fun/8">â€œvirtual watercoolerâ€ on Fedora Discussion</a> and join a conversation, share something interesting, and introduce yourself.</p>



<p>Youâ€™re also invited to our virtual release party this Friday and Saturday. Itâ€™s free! And weâ€™ll have interesting presentations and fun social events. <a href="https://hopin.com/events/fedora-linux-39-release-party/registration">Register here!</a></p>



<h2><strong>Thank you everyone</strong></h2>



<p>Thank you again to the thousands of people who contributed to the Fedora Project in this release cycle. You are amazing!</p>
						
											
					</div><div>
									<p><a href="https://fedoramagazine.org/author/mattdm/"></a>
										<img alt="" src="https://secure.gravatar.com/avatar/2fccc1daa2adc4c5004cbd389e9eecf7?s=96&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/2fccc1daa2adc4c5004cbd389e9eecf7?s=192&amp;d=retro&amp;r=g 2x" height="96" width="96" loading="lazy" decoding="async"></p><!-- .avatar -->
									<h4><a href="https://fedoramagazine.org/author/mattdm/">Matthew Miller</a></h4>

									<p>Matthew is the <a href="https://docs.fedoraproject.org/en-US/council/fpl/">Fedora Project Leader</a>. You can find him on the Fedora mailing lists or Fedora Chat as "mattdm", or <a href="https://fosstodon.org/@mattdm">@mattdm@fosstodon.org </a> on Mastodon.

 Matthew's content on this site is made available under the <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International</a> license (or an earlier CC-BY-SA license if you need that for compatibility) â€” share all you like, give credit, and let others share as well.</p>
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A four year plan for async Rust (201 pts)]]></title>
            <link>https://without.boats/blog/a-four-year-plan/</link>
            <guid>38178592</guid>
            <pubDate>Tue, 07 Nov 2023 16:12:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://without.boats/blog/a-four-year-plan/">https://without.boats/blog/a-four-year-plan/</a>, See on <a href="https://news.ycombinator.com/item?id=38178592">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Four years ago today, the Rust async/await feature was released in version 1.39.0. The announcement
<a href="https://blog.rust-lang.org/2019/11/07/Async-await-stable.html">post</a> says that â€œthis work has been a long time in development â€“ the key
ideas for zero-cost futures, for example, were first proposed by Aaron Turon and Alex Crichton in
2016â€. Itâ€™s now been longer since the release of async/await than the time between the first design
work that underlies async/await. Despite this, and despite the fact that async/await syntax was
explicitly shipped as a â€œminimum viable product,â€ the Rust project has shipped almost no extensions
to async/await in the four years since the MVP was released.</p><p>This fact has been noticed, and I contend it is the primary controllable reason that async Rust has
developed a negative reputation (other reasons, like its <a href="https://without.boats/blog/why-async-rust">essential complexity</a>, are
not in the projectâ€™s control). Itâ€™s encouraging to see project leaders like Niko Matsakis
<a href="https://smallcultfollowing.com/babysteps/blog/2023/10/14/eurorust-reflections/">recognize</a> the problem as well. I want to outline the features that I think async Rust needs
to consider improve its user experience. Iâ€™ve organized these features into features that I think
the project could ship in the short term (say, in the next 18 months), to those that will take
longer (up to three years), and finally a section on a potential change to the language that I think
would take years to plan and prepare for.</p><h2 id="near-term-features">Near-term features</h2><p>These features are all features that I believe the Rust project would be able to ship within the
next year or two. They all require relatively small changes to the compiler, because they depend on
abstractive capabilities that are already implemented, and they involve relatively small changes to
the surface syntax, largely new syntax implied already by the existing syntax. I think these are the
things the project should focus its attention on, because they should be easier to ship and easier
to build a consensus around.</p><h2 id="asynciterator-and-async-generators">AsyncIterator and async generators</h2><p>Iâ€™ve <a href="https://without.boats/blog/patterns-and-abstractions">harped on</a> the importance of generators to Rust repeatedly in the past, so I wonâ€™t
devote a lot of attention here. Iâ€™ve also highlighted before that the original plan for iterators
<a href="https://web.archive.org/web/20140716172928/https://mail.mozilla.org/pipermail/rust-dev/2013-June/004599.html">included</a> shipping generator syntax. Briefly, my opinion is that the absence of generators
has left Rust in a confused state, in which the relationship between asynchrony and iteration is
unclear (I elaborate more in my linked blog post). I want to focus specifically on <em>async</em> iterators
and <em>async</em> generators, and the features that are needed to complete these.</p><p>An async generator is a natural transformation from a generator: just like functions, generators
can be marked async, and now you can use the await operator inside of them. Using my preferred
syntax, this would look something like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>async</span><span> </span><span>gen</span><span> </span><span>fn</span> <span>sum_pairs</span><span>(</span><span>rx</span>: <span>Receiver</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>)</span><span> </span><span>yields</span><span> </span><span>i32</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>left</span><span> </span><span>=</span><span> </span><span>rx</span><span>.</span><span>next</span><span>().</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>right</span><span> </span><span>=</span><span> </span><span>rx</span><span>.</span><span>next</span><span>().</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>yield</span><span> </span><span>left</span><span> </span><span>+</span><span> </span><span>right</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>The composition of these features falls out naturally from these syntaxes. Unlike a generator, an
async generator compiles to an <code>AsyncIterator</code>.</p><p>There is one other piece of syntax that is needed: <code>for await</code> loops. These can be called from
within any async context, and consume items from the <code>AsyncIterator</code>, yielding control when the
<code>AsyncIterator</code> yields pending:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>for</span><span> </span><span>await</span><span> </span><span>item</span><span> </span><span>in</span><span> </span><span>async_iter</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>println!</span><span>(</span><span>"</span><span>{}</span><span>"</span><span>,</span><span> </span><span>item</span><span>);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>When I was working on async Rust, this syntax was held up on two different design tangents. On the
one hand, Taylor Cramer thought that the feature was a poor choice because users should instead be
using <code>for_each_concurrent</code>, to get some concurrency. I do not agree with that: itâ€™s not always the
case that users want to use <code>for_each_concurrent</code>, adding more internal concurrency to your async
function is a decision that needs to be considered with care, and there should be an obvious syntax
for when you donâ€™t want that, which <code>for await</code> is. On the other hand, there was some speculation
about making â€œawait patternsâ€ that destructure futures and then somehow making that work here; I
think this would imprudent and leaving await as an expression, and <code>for await</code> as a special
expression for handling <code>AsyncIterator</code>, is the most sensible choice.</p><p>Revisiting the table from my previous blog post, you could add this column for async iteration:</p><table><thead><tr><th></th><th>Asynchronous Iteration</th></tr></thead><tbody><tr><td><strong>Context</strong></td><td><code>async gen</code></td></tr><tr><td><strong>Effect</strong> (iteration)</td><td><code>yield</code></td></tr><tr><td><strong>Forward</strong> (asynchrony)</td><td><code>await</code></td></tr><tr><td><strong>Complete</strong> (iteration)</td><td><code>for await</code></td></tr></tbody></table><p>The biggest thing blocking this is an issue on the library side: how should the <code>AsyncIterator</code>
interface be expressed. Iâ€™ve already <a href="https://doc.rust-lang.org/std/async_iter/trait.AsyncIterator.html">written</a> about my preference for stabilizing
<code>AsyncIterator</code> as-is, with the <code>poll_next</code> method. This remains a subject of some controversy,
so I will return to it, but not in this post.</p><p>For now Iâ€™ll just say that I think the failure to stabilize <code>AsyncIterator</code> over the past 4 years
(which was absolutely not our intention when we planned the async MVP) has been harmful to async
Rust, because APIs based on async iteration have been relegated to unstable features and
side-libraries, leaving users confused and poorly supported when they need to deal with repetitious
asynchronous events, a very common pattern. The single best thing the Rust project could do for
users is stabilize <code>AsyncIterator</code> so the ecosystem can build on it, and it could do that tomorrow.</p><p>The good news is that work is already <a href="https://github.com/rust-lang/rfcs/pull/3513">underway</a> on reserving the <code>gen</code> keyword in the next
edition, so that generators could be implemented. This feature is using the same state machine
transform that async functions already use, and by analogy should be feasible to implement without
big changes to the compiler. The only big unresolved questions with generators (and which doesnâ€™t
apply to async generators, if <code>AsyncIterator</code> is stabilized as is) is how to make them
self-referential. Iâ€™ll return to that question later in this post.</p><h2 id="coroutine-methods">Coroutine methods</h2><p>Orthogonal to the introduction of these additional kinds of coroutines is their integration into the
trait system. Right now, you cannot define an async trait method in stable Rust. The good news is
that this is changing, and in a soon-to-be-released version of Rust, it will be possible to write an
async trait method. As other coroutines, generators and async generators should not require any
special support to use them in traits that wasnâ€™t already implemented for async functions. So when
generators and async generators are implemented and stabilized, they should be supported as methods
out of the box.</p><p>The only thing that remains to be implemented for coroutine methods is the concept of â€œReturn Type
Notationâ€ (or RTN). The problem is that adding a coroutine method to a trait adds an anonymous
associated type to that trait, which is the return type of that method. Sometimes (most importantly:
when spawning that method in a task on a work-stealing executor or otherwise moving it to another
thread) users need to add additional bounds to that anonymous associated type. So Rust needs some
syntax for declaring that. This is RTN. For example:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>trait</span><span> </span><span>Foo</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>async</span><span> </span><span>fn</span> <span>foo</span><span>(</span><span>&amp;</span><span>self</span><span>);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// later:
</span></span></span><span><span><span></span><span>where</span><span> </span><span>F</span>: <span>Foo</span><span> </span><span>+</span><span> </span><span>Send</span><span>,</span><span>
</span></span></span><span><span><span>      </span><span>F</span>::<span>foo</span><span>()</span>: <span>Send</span>
</span></span></code></pre></div><p>In my opinion, it is important to ship RTN because of a design principle I call the â€œCan you fix
it?â€ principle. If an upstream dependency of yours has an async method, and you need to add a <code>Send</code>
bound to the return type, can you fix it, or do you need to fork the library? Without the ability to
add RTN bounds to where clauses, you cannot express the bounds that you require without changing the
upstream code, even if your code is all perfectly valid (i.e. even if the async method you want to
call <em>is</em> <code>Send</code>). Itâ€™s very frustrating for users to encounter a problem in which their code should
compile fine, but the only way to satisfy the compiler is to fork a dependency.</p><p>Fortunately, the project is already focusing on this feature, and I expect it to be shipped in the
next year. There seems to be some discussion around the exact syntax for this feature: I would
encourage contributors not to be too obstinate over syntax differences that donâ€™t substantially
change the feature.</p><h2 id="coroutine-closures">Coroutine closures</h2><p>Another aspect of Rustâ€™s language design in which coroutines are currently not well-supported is
closures. Niko Matsakis has explored this issue in two recent blog posts, focusing only on async
closures and not on generative or asynchronously generative closures. In the <a href="https://smallcultfollowing.com/babysteps/blog/2023/03/29/thoughts-on-async-closures/">first</a>, he
proposed treating async closures as a new hierarchy of function traits (i.e. adding <code>AsyncFn</code>,
<code>AsyncFnMut</code>, and <code>AsyncFnOnce</code>). In the <a href="https://smallcultfollowing.com/babysteps/blog/2023/05/09/giving-lending-and-async-closures/">second</a>, he instead explores the idea of modeling
async closures as closures returning <code>impl Future</code> (e.g. <code>F: Fn() -&gt; impl Future</code>).</p><p>I prefer the second approach, because it does not result in a proliferation of more traits. This
becomes especially apparent when you consider generative closures and asynchronously generative
closures: if the function trait for each of these things were distinct, instead of 3 function
traits, Rust would have 12. In contrast, by modeling coroutine closures as closures returning an
<code>impl Trait</code>, no new traits are needed. It has the additional benefit that it involves modeling
them in the exact way that Rust already desugars normal async functions.</p><p>As Niko highlights in his blog post, this would require adapting the <code>Fn</code> traits to allow their
return type to capture input lifetimes. There are a few things that Niko calls out in his post that
require changing Rustâ€™s syntax, possibly across an edition boundary:</p><ul><li>Adding a lifetime to the <code>Output</code> parameter of the <code>Fn</code> traits</li><li>Desugaring <code>-&gt; impl Trait</code> to a bound on the associated type projection instead of a new
variable</li></ul><p>Because these may require an edition change, the project should work through the specifics of these
changes immediately. But they do not seem like extremely thorny problems to work out.</p><p>There is one other thing I would add to this feature, though. Once you have <code>Fn() -&gt; impl Future</code>
and so on, it would be natural to extend the syntax to have a kind of â€œasync sugarâ€ (and â€œgen
sugarâ€) just like functions do. That is to say, special syntax sugar should be added to the <code>Fn</code>
traits that makes it possible to write closure bounds like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>where</span><span> </span><span>F</span>: <span>async</span><span> </span><span>FnOnce</span><span>()</span><span> </span>-&gt; <span>T</span><span>
</span></span></span><span><span><span></span><span>// equivalent to:
</span></span></span><span><span><span></span><span>where</span><span> </span><span>F</span>: <span>FnOnce</span><span>()</span><span> </span>-&gt; <span>impl</span><span> </span><span>Future</span><span>&lt;</span><span>Output</span><span> </span><span>=</span><span> </span><span>T</span><span>&gt;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>where</span><span> </span><span>F</span>: <span>gen</span><span> </span><span>FnOnce</span><span>()</span><span> </span><span>yields</span><span> </span><span>T</span><span>
</span></span></span><span><span><span></span><span>// equivalent to:
</span></span></span><span><span><span></span><span>where</span><span> </span><span>F</span>: <span>FnOnce</span><span>()</span><span> </span>-&gt; <span>impl</span><span> </span><span>Iterator</span><span>&lt;</span><span>Item</span><span> </span><span>=</span><span> </span><span>T</span><span>&gt;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>where</span><span> </span><span>F</span>: <span>async</span><span> </span><span>gen</span><span> </span><span>FnOnce</span><span>()</span><span> </span><span>yields</span><span> </span><span>T</span><span>
</span></span></span><span><span><span></span><span>// equivalent to
</span></span></span><span><span><span></span><span>where</span><span> </span><span>F</span>: <span>FnOnce</span><span>()</span><span> </span>-&gt; <span>impl</span><span> </span><span>AsyncIterator</span><span>&lt;</span><span>Item</span><span> </span><span>=</span><span> </span><span>T</span><span>&gt;</span><span>
</span></span></span></code></pre></div><p>Whatâ€™s nice about this is that it isnâ€™t some new general-purpose abstractive concept like â€œtrait
transformersâ€ or â€œeffect generics:â€ itâ€™s just a little bit of sugar that is a natural extension of
sugar that already exists from one place (function declarations) to another (function trait bounds).
And these function traits already have special syntax, because they use parens and arrows for their
parameters and return type. This wouldnâ€™t require a lot of implementation work or consensus on a
controversial new feature.</p><h2 id="medium-term-features">Medium-term features</h2><p>The features in the previous section were all features that I believe could be shipped without a
huge amount of implementation effort, and which donâ€™t have many thorny open questions in their
design. The features in this section, on the other hand, are more difficult. Itâ€™s good that people
are already investigating them now, but they donâ€™t seem very close to shipping and I wouldnâ€™t expect
them in the next year or two.</p><h2 id="object-safe-coroutine-methods">Object-safe coroutine methods</h2><p>Though async trait methods will soon be a stable feature, they will not initially be object-safe. I
think this was the right decision, but it would be ideal if someday they could be. The problem with
object-safety is this: each coroutine method implies an anonymous associated type, which would have
a different size and layout in each implementation. In order to erase the static type of the trait
object, you also need to erase the type of that methodâ€™s anonymous return type: in other words, it
also needs to somehow be a trait object.</p><p>For our examples, weâ€™ll consider this trait:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>trait</span><span> </span><span>Foo</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>async</span><span> </span><span>fn</span> <span>foo</span><span>(</span><span>&amp;</span><span>self</span><span>);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>If I want to make a trait object of <code>Foo</code>, I need to specify the return type of <code>Foo::foo</code>.
Thankfully, RTN starts to unravel this problem by allowing us this syntax: <code>Box&lt;dyn Foo&lt;foo() = Something&gt;&gt;</code> But what is <code>Something</code>? It canâ€™t be a specific type, or else that limits the trait
object to implementations that return that type: in practice, this means limiting it to a single
specific type, and now it isnâ€™t even a meaningful trait object at all. Thatâ€™s why it needs to be a
trait object itself.</p><p>For example, that might be <code>Box&lt;dyn Foo&lt;foo() = Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt;&gt;&gt;&gt;&gt;</code>. Of course,
that is incredibly verbose. There are basically two problems at play which shape the design space:</p><ul><li>There needs to be some kind of transformer that takes your implementation of <code>Foo</code>, and includes
the glue to allocate the future in the heap.</li><li>Some members of the project leadership have the very strongly held view that heap allocations
should be â€œexplicit,â€ where explicit means there should be more syntax required to do it.</li></ul><p>As a result, the project has considered a new wrapper type that would be required, which would
â€œexplicitlyâ€ indicate (by virtue of being a different type) that the future type will be heap
allocated. My understanding is that something like what Iâ€™ve written above would be <code>Box&lt;Boxed&lt;dyn Foo&gt;&gt;</code>, or maybe just <code>Boxed&lt;dyn Foo&gt;</code> (itâ€™s not clear to me from the material I have available).</p><p>My own opinion is different. I think its reasonable to make the default behavior of a heap allocated
trait object (i.e. <code>Box&lt;dyn Foo&gt;</code>, <code>Rc&lt;dyn Foo&gt;</code> and <code>Arc&lt;dyn Foo&gt;</code>) to allocate the state machine
with the same allocator as that type. For non-owned trait objects, like <code>&amp;mut dyn Foo</code>, I would also
be fine making the default behavior allocating them with the global allocator, though here I see the
point more (especially because this wouldnâ€™ be possible in <code>no_std</code> contexts).</p><p>Regardless, I agree it would be important to allow users to override this behavior with some
alternative glue mechanism. This requires an interface for writing your own glue code, which might
do something else (like use <code>alloca</code> to allocate a dynamically sized type on the stack). I just
think that there should be a reasonable default behavior, which for heap allocated trait objects is
probably heap allocating that state. In my opinion, this is not â€œimplicitâ€ any more than requiring
all users to use an adapter is â€œimplicit,â€ it just involves setting a reasonable default. Still,
resolving this controversy to everyoneâ€™s satisfaction would be a blocker on this feature, as well as
developing the interface for the glue code.</p><p>I want to make one other note in this section: previous discussions of this issue treat the unstable
<a href="https://smallcultfollowing.com/babysteps/blog/2022/03/29/dyn-can-we-make-dyn-sized"><code>dyn*</code></a> feature as a prerequisite for object-safe coroutine methods. I do not believe
this is the case. What <code>dyn*</code> does is create an existential type that all of the different trait
object pointer types would implement, by virtualizing also their destructor code; if you can accept
that trait objects using different allocation strategies for their virtual coroutine methods are
different types, thereâ€™s no dependence on <code>dyn*</code> at all. I personally think the <code>dyn*</code> feature is a
questionable direction for the Rust project to pursue.</p><h2 id="async-destructors">Async destructors</h2><p>Another very thorny issue is the problem of async destructors. Sometimes, a destructor might need to
perform some kind of IO operation or otherwise block the current thread; it is desirable to support
non-blocking destructors which instead yield control, so that other tasks can run concurrently.
Unfortunately, there are several problems with this.</p><p>The first problem is that running the async destructor is best effort, even more-so than running any
destructor. This is because if you drop a type with an async destructor in a non-async context,
thereâ€™s no possibility of running the destructor because this is not in an async context. There have
been a couple of different ideas about how to solve this, such as using <code>let async</code> bindings to
indicate variables that canâ€™t be moved into a non-async context, or just accepting it and treating
the async destructor as only an optimization over the non-async destructor.</p><p>The second problem is actually very similar to the problem with trait objects: if the async
destructor needs to use some sort of state, where do you store it? One option is to disallow async
destructors from having state, using a poll method. This is simple, but it is problematic for things
like data structures: a <code>Vec</code> for example has no way of storing which items it has polled already,
and has to keep polling their destructors in a loop. This would be pretty unacceptable, probably. But
then dealing with the state raises the same issues as trait objects.</p><p>The third problem with async destructors is how to handle their interaction with unwinding. In
particular, if you are unwinding through an async destructor, which returns <code>Pending</code>, what happens?
There would need to be some kind of asynchronous version of <code>catch_unwind</code> that the pending calls
can jump to, so that other tasks can run. This problem I think is easier to solve than the other
two, but it needs to be specced out.</p><p>I go back and forth between thinking that the difficulty with async destructors is one of the worst
things about async Rust and thinking that maybe async destructors arenâ€™t that useful anyway.
Regardless of where you land, there is a lot of design work needed for this feature to be shippable,
and I donâ€™t think it will come soon.</p><h2 id="long-term-features">Long-term features</h2><p>In contrast to the near-term and medium-term features, there are certain larger problems with the
design of Rust that I think should be considered carefully, such that they could not be addressed in
the next few years. Still, the work of considering them must begin at some point, so that they can
eventually be closed. Iâ€™m talking about <a href="https://without.boats/blog/changing-the-rules-of-rust">â€œchangingâ€</a> the rules of Rust.</p><p>As of right now, there are a few valuable kinds of types that Rust cannot really support:</p><ul><li><strong>Immoveable types:</strong> types which canâ€™t be moved once their address has been witnessed.</li><li><strong>Unforgetable types:</strong> types which canâ€™t go out of scope without running their destructor or
destructuring them.</li><li><strong>Undroppable types:</strong> types which canâ€™t be dropped or forgotten but must be destructured.</li></ul><p>(The latter two are usually grouped together as â€œlinear typesâ€ when people talk about them, but
there are very important differences.)</p><p>I think evidence has shown that there is a strong motivation for at least the first two categories.</p><p>To support self-referential coroutines and intrusive data structures, Rust needs some support for
types that are known never to move again. Because Rust doesnâ€™t support immovable types, we added
this functionality using the <code>Pin</code> API. But the <code>Pin</code> API has a few big flaws: one is that the API
is clunky and difficult to work with. More important, though, is that it requires an interface to
explicitly <em>opt in</em> to supporting immovable types; traits that existed before <code>Pin</code> canâ€™t gain the
ability to work with immovable types.</p><p>There are two specific traits for which this is a big problem:</p><ul><li><code>Iterator</code>: because iterator doesnâ€™t support immovable types, the project is at an impasse about
how to support immovable generators.</li><li><code>Drop</code>: because drop doesnâ€™t support immovable types, an arcane implication is that you need
crates like <code>pin-project</code> to access fields of pinned types. This is all very baroque and
confusing, and wouldnâ€™t be necessary if <code>Drop</code> supported immovable types.</li></ul><p>On the other hand, if Rust had the <code>Move</code> trait, these problems would go away. Self-referential
generators would just not implement <code>Move</code>, and work naturally. The <code>Pin</code> type could be completely
deprecated, and a reference to a type that doesnâ€™t implement <code>Move</code> would have the same semantics as
a pinned reference to a type that doesnâ€™t implement <code>Unpin</code>. Of course, this would require pretty
major edition-crossing changes.</p><p>The <a href="https://without.boats/blog/the-scoped-task-trilemma">scoped task trilemma</a> presents a strong argument for types which cannot be forgotten.
Stackless coroutines cannot use the destructor-based concurrent borrow trick: the only way to make
it work is to use a closure-passing â€œinternalâ€ style, which is what Rust opted against when it went
for stackless coroutines. This incompatibility between these two desirable aspects of Rustâ€™s design
makes a strong case that the decision not to support unforgettable types was the wrong decision.</p><p>I titled this post â€œa four year planâ€ for a reason: if Rust were to adopt these fundamental changes,
it would have to be done across an edition boundary, and I strongly doubt that it could be done as
part of the 2024 edition. This leaves the 2027 edition, four years from now, as the target for such
a change. But the project should commit to a decision about this change sometime soon, in the next
two years, and that should include a temporary solution for generators, such as requiring them to be
pinned before they can be used as iterators.</p><p>Iâ€™ve been exploring what would be required to do this change on my blog this year because I think it
is something the Rust project should seriously consider changing. I intend to continue to focus on
this issue next year, because I think the implications of all of the different options needs to be
fully understood. Iâ€™m trying to find ways to make this a collaborative process, but my options are
limited. My goal isnâ€™t really even to make a particular recommendation (though I will surely have
opinions), but just to understand the full space of options for resolving these issues.</p><p>What are the exact trade offs between different options to handle the problem of self-referential
generators? What different requirements would there be to support â€œunforgettableâ€ types as opposed
to â€œundroppableâ€ types? If <code>Move</code> were to be added, how could <code>Pin</code> be removed across an edition
boundary? These are the kinds of questions I want to answer.</p><p>However, I recognize that adding support for these kinds of types would be the biggest change to
Rust since it was stabilized in 2015, and that making this change would bring with it enormous costs
for both the project and the community. I also recognize that there are valid arguments why
supporting these kinds of types isnâ€™t really worth it (like the painful interaction with trait
objects). For these reasons, the Rust project should build into its consideration of this idea the
possibility that <em>not doing anything</em> may ultimately be the right outcome.</p><p>In general, my instinct is to doubt big changes to Rust at this point in its design process. What I
think Rust needs is to finish integrating the features it has already committed to - features like
external iterators, stackless coroutines, monomorphized generics, and unsized trait object types. I
specifically feel changing the rules around moveability and linear types is justified because of the
implications for the integration of these existing features.</p><p>This post has once again gotten very long. I decided to focus this post on changes to the language;
in another post to come I will focus my attention on the standard library and the async library
ecosystem, as well as devote a specific post to the <code>AsyncIterator</code> interface. I want to make one
other remark, which I tried to find a place for in this post and the previous one, but couldnâ€™t. It
concerns the controversy around the final syntax for the await operator which played out in 2019.</p><p>For those who donâ€™t know, there was a big debate whether the await operator in Rust should be a
prefix operator (as it is in other languages) or a postfix operator (as it ultimately was). This
attracted an inordinate amount of attention - over 1000 comments. The way it played out was that
almost everyone on the language team had reached a consensus that the operator should be postfix,
but I was the lone hold out. At this point, it was clear that no new argument was going to appear,
and no one was going to change their mind. I allowed this state of affairs to linger for several
months. I regret this decision of mine. It was clear that there was no way to ship except for me to
yield to the majority, and yet I didnâ€™t for some time. In doing so, I allowed the situation to
spiral with more and more â€œcommunity feedbackâ€ reiterating the same points that had already been
made, burning everyone out but especially me.</p><p>The lesson I learned from this experience is to distinguish between factors that are truly critical
and factors that donâ€™t matter. If youâ€™re going to be obstinate about some issue, youâ€™d better be
able to articulate a deep reason why it is important, and it had better be something more pressing
than the slight differences in affordances and aesthetics between syntax options. Iâ€™ve tried to
take this to heart in how I engage in technical questions since then.</p><p>I worry that the Rust project took the wrong lesson from this experience. The project continues in
its norm (as Graydon mentioned <a href="https://graydon2.dreamwidth.org/307105.html">here</a>) that with enough ideation and brainstorming,
eventually a win-win solution to every controversy can be discovered. Rather than accepting that
sometimes a hard decision has to be made, the projectâ€™s solution to the burnout of that comes from
allowing these controversies to hang open indefinitely has been to turn inward. Design decisions are
now documented primarily in unindexed formats like Zulip threads and HackMD documents. To the extent
that there is a public expression of the design, it is one of a half dozen different blogs belonging
to different contributors. As an outsider, it is nearly impossible to understand what the project
considers a priority, and what the current state of any of these things are.</p><p>Iâ€™ve never seen the projectâ€™s relationship with its community be in a worse state. But that
community contains invaluable expertise; closing yourselves off is not the solution. I want to see
the relationships of mutual trust and respect rebuilt between project members and community members,
instead of the present situation of hostility and dissatisfaction. To this, I want to thank those
from the project who have reached out and engaged with me on design issues over the last few months.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICE faces heat after agents install apps, VPNs on official phones (107 pts)]]></title>
            <link>https://www.theregister.com/2023/11/06/ice_device_security/</link>
            <guid>38178582</guid>
            <pubDate>Tue, 07 Nov 2023 16:12:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/06/ice_device_security/">https://www.theregister.com/2023/11/06/ice_device_security/</a>, See on <a href="https://news.ycombinator.com/item?id=38178582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>America's immigration cops have pushed back against an official probe that concluded their lax mobile device security potentially put sensitive government information at risk of being stolen by foreign snoops.</p>
<p>Between April 27 and August 17, the US Department of Homeland Security Office of the Inspector General conducted an audit of equipment managed by Immigration and Customs Enforcement (ICE) and the agency's IT policies.</p>
<p>In an October 30 write-up, the inspector general came down hard on the Feds' device management practices, highlighting "urgent issues" on ICE-managed handhelds â€“ including concerns about devices running apps that could be hijacked by foreign adversaries. Think: software linked to or developed within reach of China or Russia, which could be altered or compromised to spy on Uncle Sam.</p>

    

<p>"Specifically, we found mobile device management issues that put ICE mobile devices â€” and potentially other [Homeland Security] mobile devices demonstrating similar issues â€” and sensitive data at greater risk of potential espionage, leaks, and attacks from viruses," wrote Inspector General Joseph Cuffari in a redacted report [<a target="_blank" rel="nofollow" href="https://www.oig.dhs.gov/sites/default/files/assets/2023-11/OIG-24-02-Oct23-mgmtalert-Redacted.pdf">PDF</a>].</p>

        


        

<p>The investigation found "thousands" of applications installed on ICE-managed devices that had been installed by employees, contractors, and other DHS staff. This included third-party file sharing services and virtual private networks (VPN), outdated messaging platforms, and apps developed by companies banned from US government IT systems.</p>
<p>While we don't know which of these naughty-list apps auditors found on ICE employees phones, it's probably safe to assume one of the offenders was TikTok â€” banned from US <a target="_blank" href="https://www.theregister.com/2023/03/01/government_tiktok_ban/">federal government staff</a> and <a target="_blank" href="https://www.theregister.com/2023/06/06/us_contractors_tiktok_ban/">contractors' devices</a> because of <a target="_blank" href="https://www.theregister.com/2023/03/29/china_tiktok_trojan_horse/">espionage concerns</a>, due to the <a target="_blank" href="https://www.theregister.com/2023/03/30/tiktok_ban_register_kettle/">influence</a> the Chinese government can exert over Beijing-based parent ByteDance.</p>

        

<p>The DHS OIG report added the software it found on the handhelds included "applications associated with [redacted] and [redacted]." We're guessing the redacted names are China and Russia. According to the inspector general, these user-installed apps potentially put ICE's operations, employees, and all of DHS at risk.</p>
<p>"These applications introduce the potential for collecting and monitoring user and device information through device sensors such as a camera, microphone, and Global Positioning System," the report stated. "The applications may also collect and distribute information stored on the device (eg, photos, videos, and documents), including potentially sensitive information outside the secure containers."&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2023/06/06/us_contractors_tiktok_ban/">US govt now bans TikTok from contractors' work gear</a></li>

<li><a href="https://www.theregister.com/2023/10/25/ice_social_media_surveillance/">Your ex isn't the only one stalking your social media posts. The Feds are, too</a></li>

<li><a href="https://www.theregister.com/2022/12/01/ice_data_dump/">ICE data dump reveals names, locations of 6,000+ asylum seekers</a></li>

<li><a href="https://www.theregister.com/2022/05/14/ice_28bn_domestic_surveillance/">How ICE became a $2.8b domestic surveillance agency</a></li>
</ul>
<p>Because ICE considered these downloads to be "personal applications," it didn't monitor them, we're told, despite their presence on the federal agency's devices. To be fair, some of the ICE-approved apps sound equally concerning, such as "one ICE-owned application allows ICE personnel to capture and search biometric information of people they encounter in real-time."</p>
<p>An ICE spokesperson declined to comment on this scanning app, and also did not answer <em>The Register</em>'s questions about its last personal-use policy update, which happened in 2014, and if it planned to review the policy more frequently from here on out.&nbsp;</p>
<p>In a lengthy statement emailed to <em>The Register</em>, an ICE spokesperson said:</p>

<p>The report acknowledged that ICE has implemented some of the auditors' recommendations already to boost device security, such as blocking and disabling prohibited apps, vulnerable messaging applications, and VPN applications.&nbsp;</p>
<p>"ICE also stated it has taken steps to implement application vetting and is in the process of updating its mobile device use policy," the report says.</p>

        

<p>Additionally, DHS, in its response to the audit, disagreed that ICE security controls did not reduce the risk to federal mobile devices and their sensitive information. Homeland Security also claimed the percentage of ICE-managed devices that did not have mobile threat defense capability installed is significantly lower than the inspector general's audit number.</p>
<p>While ICE's actions "demonstrate progress," the report concludes that ICE still hasn't fully addressed "risks associated with user-installed applications communicated in this alert." Â®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Real vs. fake AirPods with industrial CT (132 pts)]]></title>
            <link>https://www.lumafield.com/article/real-vs-fake-apple-products-through-industrial-ct-airpods-pro-macbook-magsafe-charger</link>
            <guid>38178492</guid>
            <pubDate>Tue, 07 Nov 2023 16:06:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lumafield.com/article/real-vs-fake-apple-products-through-industrial-ct-airpods-pro-macbook-magsafe-charger">https://www.lumafield.com/article/real-vs-fake-apple-products-through-industrial-ct-airpods-pro-macbook-magsafe-charger</a>, See on <a href="https://news.ycombinator.com/item?id=38178492">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today's counterfeit products are so sophisticated that they often appear visually and functionally identical to the genuine articlesâ€”at least initially. For both manufacturers and consumers, counterfeits present a serious challenge: how can you ensure the quality and safety of your products?</p><p>CT scanning, a technique once reserved for medical diagnostics, has found a new purpose in the fight against counterfeit electronics. Industrial CT scanners like the <a href="https://www.lumafield.com/products/neptune-industrial-x-ray-ct-scanner">Neptune</a> allow engineers to inspect and optimize their designs throughout the product development cycle, <a href="https://www.lumafield.com/article/what-is-industrial-ct">from R&amp;D to field support</a>. Theyâ€™re also the perfect tool for identifying fakes with precision. Along the way, they also reveal the complexity and sophistication of the engineering that goes into genuine products.</p><p>We examined the internal structure of Appleâ€™s AirPods Pro and MagSafe 2 power adapters for MacBook, exposing the shortcuts and compromises made in counterfeit versions that could compromise functionality and user safety.</p><h3>Apple AirPods Pro</h3><h4>Batteries</h4><p>Batteries are the key to the wireless convenience and flexibility of the AirPods design, so we started there. The authentic AirPods house meticulously-engineered button cell batteries in each earbud, designed to fit snugly within the compact form factor and provide optimal power efficiently. In contrast, both specimens of counterfeit AirPods contain lithium-ion pouch cell batteries that are not only less sophisticated in their construction but also potentially less safe. The rectangular pouches are crammed into circular spaces rather than tailored to fit.</p><h4>Circuitry</h4><p>Moving to the internal circuitry, the genuine AirPods are a marvel of miniaturization and precision engineering. They use a combination of rigid and flexible printed circuit boards to pack components densely and ensure that every millimeter of space is used effectively. On the other hand, the counterfeit AirPods reveal much simpler electronics cobbled together from off-the-shelf components. That leaves less room for functionality; the counterfeits have fewer microphones and less control circuitry, compromising their sound quality.</p><h4>Build quality</h4><p>Lastly, the contrast in overall build quality is dramatic between the genuine AirPods and their counterfeit counterparts. One of the fakes doesn't offer wireless charging at all (no coils are visible in the scans), and the other one has wireless charging coils but lacks the magnets that snap the real AirPods case onto Apple's Watch charger. The counterfeit AirPods even resort to using internal weights with no other function than to mimic the heft of the genuine product, a deceptive tactic for making them feel heavier to compensate for poorer materials and less functionality. These fakes may replicate the visual cues of the original, but the use of substandard materials not only affects the tactile experience but also compromises the structural integrity and overall lifespan of the product.</p><h3>Apple MagSafe 2 Power Adapters for MacBook</h3><h4>Power cycling</h4><p>We also CT scanned a genuine and counterfeit 85W MagSafe 2 Power Adapter for MacBook, finding differences in their internal circuitry and power cycling systems. The genuine Apple charger has a sophisticated power management system that includes components for power conditioning and conversion. The counterfeit charger's internal circuitry is far less complex, lacking the filtering features that ensure safety and longevity in Apple's charger. This simplified internal structure not only raises concerns about the counterfeitâ€™s performance but also its ability to safely manage the power supplied to your devices.</p><figure><p><img src="https://assets-global.website-files.com/63e15418201b6e2a5cabb911/6549d5eae6ee48357ab18632_Counterfeit%20charger%201.png" loading="lazy" alt=""></p></figure><h5><a href="https://app.lumafield.com/project/94be4eac-ca9a-426e-8686-92928b2d9efd" target="_blank">Explore the real charger scan</a></h5><h4>Heat sinks</h4><p>Our CT scans reveal an intriguing difference between the heat sinks in the real and counterfeit chargers. The genuine charger uses a relatively thin heat sink that wraps around most of the transformer. The counterfeit uses a heavier, but simpler heat sink design. Appleâ€™s heat sink requires more manufacturing steps to stamp and assemble and likely provides more even distribution of heat. The counterfeitâ€™s design is more likely to lead to dangerous hot spotsâ€”especially combined with its less sophisticated transformer, which would tend to generate more heat.</p><figure><p><img src="https://assets-global.website-files.com/63e15418201b6e2a5cabb911/6549d5f8cad14f949bd29e5d_Counterfeit%20charger%202.png" loading="lazy" alt=""></p></figure><h5><a href="https://app.lumafield.com/project/98077f2f-9863-41e5-a6e9-a2c31eba5974" target="_blank">Explore the fake charger scan</a></h5><h4>Build quality</h4><p>The CT scans reveal a dense, well-organized internal structure in the genuine charger and a more haphazard internal layout in the counterfeit. They also reveal that the counterfeit charger has a fake grounding capability: the real charger has a grounded pin that can be connected with an optional 3-prong plug. The fake looks like it has a grounded pin, but the pin isnâ€™t connected to any grounding circuitry inside the charger.</p><h3>Adam Savage compares the scans</h3><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/Db99cXMD780" title="Fake Apple AirPod Pro Exposed!"></iframe></p></figure><h3>Conclusion</h3><p>The differences between these products and their counterfeits are subtle at first glance, but our industrial CT scans reveal significant differences that have implications for performance and safety. In the end, the choice between real and counterfeit may be more than a matter of cost; itâ€™s a decision to invest in reliability and peace of mind.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google ends deal to build 15,000 Bay Area homes due to "market conditions" (165 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/11/google-cost-cutting-ends-deal-to-build-thousands-of-affordable-housing-units/</link>
            <guid>38178123</guid>
            <pubDate>Tue, 07 Nov 2023 15:43:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/11/google-cost-cutting-ends-deal-to-build-thousands-of-affordable-housing-units/">https://arstechnica.com/tech-policy/2023/11/google-cost-cutting-ends-deal-to-build-thousands-of-affordable-housing-units/</a>, See on <a href="https://news.ycombinator.com/item?id=38178123">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Google real estate cuts    â€”
</h4>
            
            <h2 itemprop="description">15,000-home plan in limbo as Google ends contract with builder after four years.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/google-housing-800x339.jpg" alt="Illustration of a housing development with apartments and a park area with benches, sidewalks, and a bike lane.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/google-housing.jpg" data-height="906" data-width="2136">Enlarge</a> <span>/</span> Google's conceptual rendering of its housing plan.</p><p>Google</p></figcaption>  </figure>

  




<!-- cache hit 645:single/related:14a669b63c03e8668d4a5d20bab82a1c --><!-- empty -->
<p>Google has ended an agreement with a developer to build 15,000 homes in the San Francisco Bay Area, including affordable housing, as it continues a string of cost-cutting moves to reduce real estate costs. Google said it is "looking at a variety of options" to provide housing despite ending the development deal but didn't offer specific details on its plans.</p>
<p>Google <a href="https://www.lendlease.com/us/media-center/media-releases/lendlease-to-jointly-deliver-new-mixed-use-neighbourhoods-with-google-in-the-san-francisco-bay-area/">partnered</a> with the Australian company Lendlease in 2019 on a $15 billion <a href="https://www.lendlease.com/us/projects/san-francisco-bay-area-project/">plan</a> for "residential, retail, hospitality, and community development space," with an expected completion date of 2038. Lendlease was to be the developer, builder, and owner of the residential, retail, hospitality, and community components, while Google also planned a related office expansion. Including office space, the developments could have covered 15 million square feet.</p>
<p>But on Friday, <a href="https://www.lendlease.com/siteassets/lendlease/shared/investor-centre/announcements/asx/2023/11/2635882.pdf">Lendlease and Google announced</a> that they "mutually reached an agreement to end the Development Services Agreements of the four master-planned districts in San Jose (Downtown West), Sunnyvale (Moffett Park), and Mountain View (Middlefield Park and North Bayshore) in the San Francisco Bay area in California, collectively referred to as the San Francisco Bay Project." Google is making a payment to Lendlease as part of the agreement to part ways.</p>
<p>The Google <a href="https://realestate.withgoogle.com/northbayshore/plan/#housing">plan</a> that Lendlease was involved in calls for up to 7,000 homes in North Bayshore, including 1,050 affordable units; 4,000 homes in <a href="https://realestate.withgoogle.com/sanjose/#section-4">Downtown West</a>, including 1,000 affordable units; and 1,900 homes in <a href="https://realestate.withgoogle.com/middlefieldpark/plan/#housing">Middlefield Park</a>, including 380 affordable units. That would presumably leave 2,100 homes for Sunnyvale, but <a href="https://realestate.withgoogle.com/bay-housing/">Google's description</a> of the project doesn't specify the number of homes in that city.</p>
<p>A Google spokesperson told us today that the company will work with developers and capital partners to move its Bay Area developments forward, despite ending the Lendlease deal. But Google declined to answer our specific questions about the number of homes that will be built now that the original partnership has been scrapped.</p>
<p>"The decision to end these agreements followed a comprehensive review by Google of its real estate investments, and a determination by both organizations that the existing agreements are no longer mutually beneficial given current market conditions... Lendlease will remove the San Francisco Bay Project, which was expected to commence construction in FY26, from its development pipeline," the Lendlease announcement said.</p>                                            
                                                        
<h2>Project was still on track in June</h2>
<p>Lendlease was not the developer or builder in Google's related plan for <a href="https://arstechnica.com/gadgets/2021/05/googles-san-jose-megacampus-will-be-a-mixed-use-neighborhood/">new office buildings</a> on a "megacampus" in San Jose. Google put the office-building plan <a href="https://arstechnica.com/gadgets/2023/04/google-puts-10-to-30-year-campus-construction-project-on-hold-after-2-years/">on hold</a> earlier this year, reports in April said.</p>
<p>In June 2019, <a href="https://blog.google/inside-google/company-announcements/1-billion-investment-bay-area-housing/">Google CEO Sundar Pichai</a> announced a plan to rezone a large part of Google's commercial and office land for residential housing and build "at least 15,000 new homes at all income levels in the Bay Area, including housing options for middle and low-income families." Pichai also announced a $250 million investment fund to "provide incentives to enable developers to build at least 5,000 affordable housing units across the market."</p>
<p>A <a href="https://blog.google/inside-google/company-announcements/google-bay-area-housing-update/">June 2023 update</a> from Google said the company still planned "to support the creation or preservation of 20,000 homes." Google said its "work with local elected officials and residents to rezone $750 million worth of our land has paved the way for up to 12,900 units to be built in Mountain View and San Jose as part of our mixed-use development plans." Google also said it had allocated over $133 million of the $250 million fund to "more than 3,800 units across 29 affordable housing projects."</p>
<p>Exactly how many of the 20,000 planned homes could still be built is unclear. "As we've shared before, we've been optimizing our real estate investments in the Bay Area, and part of that work is looking at a variety of options to move our development projects forward and deliver on our housing commitment. We appreciate Lendlease and the work the team has done to get us to this point," Alexa Arena, senior director of development at Google, said in a statement provided to Ars today.</p>
<p>Google's pullback comes amid a rise in surplus office space.</p>
<p>"Silicon Valley companies are dumping office space at an accelerating pace, as tech leaders such as Google and Facebook parent Meta Platforms close locations and reassess their commitments to the workplace," The Wall Street Journal <a href="https://www.wsj.com/articles/vacant-offices-are-piling-up-in-silicon-valley-68e19f7">wrote in June</a>. "Office-vacancy rates in Silicon Valley, which includes the Northern California communities of San Jose, Palo Alto and Sunnyvale, were up to 17 percent in June from 11 percent in 2019, according to data firm CoStar Group." The vacancy rate had surpassed 20 percent in Menlo Park and Mountain View.</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Verizon, AT&T Customers Sue to Undo T-Mobile Merger, Saying It Raised All Prices (257 pts)]]></title>
            <link>https://www.techdirt.com/2023/11/07/verizon-att-customers-sue-to-reverse-t-mobile-merger-saying-it-raised-everybodys-prices/</link>
            <guid>38177930</guid>
            <pubDate>Tue, 07 Nov 2023 15:31:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/11/07/verizon-att-customers-sue-to-reverse-t-mobile-merger-saying-it-raised-everybodys-prices/">https://www.techdirt.com/2023/11/07/verizon-att-customers-sue-to-reverse-t-mobile-merger-saying-it-raised-everybodys-prices/</a>, See on <a href="https://news.ycombinator.com/item?id=38177930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-424820">


<h3>from the <i>merge-ALL-the-things!</i> dept</h3>

<p>We just got done noting how pretty much all of the criticism of the Sprint T-Mobile merger by economists and consumer advocates <a href="https://www.techdirt.com/2023/10/17/everything-t-mobile-sprint-merger-critics-predicted-has-come-true/" data-type="link" data-id="https://www.techdirt.com/2023/10/17/everything-t-mobile-sprint-merger-critics-predicted-has-come-true/">wound up being true</a>. The deal has resulted in more than 10,000+ eliminated jobs, steady price hikes, annoying new fees, a weaker T-Mobile brand, and a lower quality product overall. It also clearly distracted T-Mobile from <a href="https://www.techdirt.com/2023/01/23/t-mobile-hacked-eighth-time-in-five-years/" data-type="link" data-id="https://www.techdirt.com/2023/01/23/t-mobile-hacked-eighth-time-in-five-years/">competent network security</a>.</p>
<p>T-Mobileâ€™s reddit forums are filled with employees saying the disruptive spirit of the company has been <a href="https://www.reddit.com/r/tmobile/comments/10zsncc/what_changed_about_tmobiles_employee_experience/" data-type="link" data-id="https://www.reddit.com/r/tmobile/comments/10zsncc/what_changed_about_tmobiles_employee_experience/">dead since the merger</a>. T-Mobile customers are annoyed by <a href="https://www.techdirt.com/2023/10/30/t-mobile-backs-off-price-hike-they-pretended-wasnt-a-price-hike/" data-type="link" data-id="https://www.techdirt.com/2023/10/30/t-mobile-backs-off-price-hike-they-pretended-wasnt-a-price-hike/">endless new restrictions and price hikes</a>. </p>
<p>But Verizon and AT&amp;T customers are also pissed, and are part of a new <a href="https://www.reuters.com/legal/litigation/t-mobile-must-face-private-antitrust-lawsuit-over-26-bln-sprint-deal-us-judge-2023-11-03/" data-type="link" data-id="https://www.reuters.com/legal/litigation/t-mobile-must-face-private-antitrust-lawsuit-over-26-bln-sprint-deal-us-judge-2023-11-03/">lawsuit against T-Mobile</a> arguing that the merger raised prices for <strong>everybody</strong> due to the reduction in overall wireless market competition. A federal judge in Chicago last week ruled that plaintiffs made some decent points and the lawsuit should be allowed to proceed:</p>
<blockquote>
<p><em>â€œU.S. District Judge Thomas Durkin in a&nbsp;<a rel="noreferrer noopener" href="https://fingfx.thomsonreuters.com/gfx/legaldocs/mopajzamwva/Dale%20v%20T%20Mobile%20order%2020231102.pdf" target="_blank">41-page ruling</a>&nbsp;on Thursday said the plaintiffs â€œplausiblyâ€ argued that higher prices â€œflowed directlyâ€ from the $26 billion merger.â€</em></p>
</blockquote>
<p>The important time to protect consumers is before these kinds of competition-eroding deals are approved, but that very clearly didnâ€™t happen here. Trump regulators at the FCC <a href="https://www.techdirt.com/2019/10/22/fcc-approved-t-mobile-sprint-merger-without-even-seeing-full-details/" data-type="link" data-id="https://www.techdirt.com/2019/10/22/fcc-approved-t-mobile-sprint-merger-without-even-seeing-full-details/">didnâ€™t even bother to read about the dealâ€™s impact</a> before approving it. Trump â€œantitrust enforcersâ€ at the FTC actively helped T-Mobile <a href="https://www.techdirt.com/2019/12/30/doj-antitrust-boss-delrahim-ignored-hard-data-as-he-rubber-stamped-t-mobile-merger/" data-type="link" data-id="https://www.techdirt.com/2019/12/30/doj-antitrust-boss-delrahim-ignored-hard-data-as-he-rubber-stamped-t-mobile-merger/">avoid regulatory scrutiny on their personal time</a>, you know, like antitrust enforcers do. </p>
<p>T-Mobileâ€™s response to the lawsuit was expected: to deny everything and insist the U.S. wireless sector is secretly super competitive:</p>
<blockquote>
<p><em>Attorneys for T-Mobile&nbsp;<a rel="noreferrer noopener" href="https://fingfx.thomsonreuters.com/gfx/legaldocs/jnpwwzdgrpw/Softbank%20Tmobile%20-%2079.pdf" target="_blank">called</a>&nbsp;the lawsuit â€œunprecedented,â€ and said the plaintiffsâ€™ damages were â€œspeculative.â€</em></p>
<p><em>â€œIf plaintiffs are unhappy with Verizon and AT&amp;T, there is a remedy available in the highly competitive market that wireless consumers enjoy today â€” they should switch to T-Mobile, not sue it,â€ attorneys for T-Mobile told the court.</em></p>
</blockquote>
<p>The harms of mindless consolidation are not theoretical. Theyâ€™re clearly documented. Yet weâ€™re dedicated to ignoring those harms because such consolidation is hugely profitable for a handful of over-compensated executives and a few key investors (sometimes). Rinse, wash, repeat, with nobody responsible for the end result getting within a thousand miles of introspection or accountability. </p>
<p>Iâ€™d not expect much from the suit in terms of reform. Any payout will be a tiny fraction of the financial harm caused. The real fix lies in more stringent merger review and well funded and staffed regulators; concepts defenders of a broken but profitable status quo have no real interest in. </p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/antitrust/" rel="tag">antitrust</a>, <a href="https://www.techdirt.com/tag/antitrust-reform/" rel="tag">antitrust reform</a>, <a href="https://www.techdirt.com/tag/competition/" rel="tag">competition</a>, <a href="https://www.techdirt.com/tag/consolidation/" rel="tag">consolidation</a>, <a href="https://www.techdirt.com/tag/high-speed-internet/" rel="tag">high speed internet</a>, <a href="https://www.techdirt.com/tag/mergers/" rel="tag">mergers</a>, <a href="https://www.techdirt.com/tag/prices/" rel="tag">prices</a>, <a href="https://www.techdirt.com/tag/wireless/" rel="tag">wireless</a>
<br>
Companies: <a href="https://www.techdirt.com/company/t-mobile/" rel="category tag">t-mobile</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An update on salary transparency in job posts (122 pts)]]></title>
            <link>https://directlyapply.com/blog/an-update-on-salary-transparency-in-job-posts-november-2023</link>
            <guid>38177702</guid>
            <pubDate>Tue, 07 Nov 2023 15:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://directlyapply.com/blog/an-update-on-salary-transparency-in-job-posts-november-2023">https://directlyapply.com/blog/an-update-on-salary-transparency-in-job-posts-november-2023</a>, See on <a href="https://news.ycombinator.com/item?id=38177702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Salary transparency is a hot topic in today's job market, and for good reason. When job seekers have access to accurate salary information, they can make informed decisions about their careers, negotiate fair compensation, and ensure that their financial needs are met. Employers benefit from salary transparency as well, it can help attract top talent, reduce turnover, build trust with their workforce and crucially, increase efficiency for all parties during the hiring process. </p><p>At DirectlyApply we have always believed that giving job seekers access to as much information up front about potential job opportunities leads to the best outcomes for both them and also employers, not just salary information, but job requirements, benefits offered, working conditions, shifts etc. In order to present this information to job seekers DirectlyApply has developed the most comprehensive rich data extractions for job postings on the market.</p><p><b>44% of job postings across the US contain salary information in November 2023.</b></p><p>From almost 5m active job vacancies on DirectlyApply, we have analysed salary transparency across US states and also job categories. </p><p><b>States:</b></p><p>Louisiana comes in with the lowest level of salary transparency at only 30% of job postings containing salary information, South Dakota tops the charts with 75% of job postings containing salary information.</p><p>While a number of states have enacted salary transparency rules, currently only four states require salary ranges in job postings. Amongst these states, New York is the worse performer with only 44% of job posting containing salary information (though New York only required this from September 2023). Colorado leads with 70% of job postings containing salary information. Washington and California also have job posting requirements with 60%, and 53% respectively. </p><p>The average across the 4 states with enacted laws is 56%, higher than the 44% national average.</p><p>A break down of all states is below: </p><table><tbody><tr><th><p><b>State</b></p></th><th><p><b>Percentage with salary information</b></p></th></tr><tr><td><p>Alabama</p></td><td><p>39%</p></td></tr><tr><td><p>Alaska</p></td><td><p>39%</p></td></tr><tr><td><p>Arizona</p></td><td><p>38%</p></td></tr><tr><td><p>Arkansas</p></td><td><p>37%</p></td></tr><tr><td><p>California</p></td><td><p>53%</p></td></tr><tr><td><p>Colorado</p></td><td><p>70%</p></td></tr><tr><td><p>Connecticut</p></td><td><p>30%</p></td></tr><tr><td><p>Delaware</p></td><td><p>50%</p></td></tr><tr><td><p>District of Columbia</p></td><td><p>34%</p></td></tr><tr><td><p>Florida</p></td><td><p>30%</p></td></tr><tr><td><p>Georgia</p></td><td><p>38%</p></td></tr><tr><td><p>Hawaii</p></td><td><p>33%</p></td></tr><tr><td><p>Idaho</p></td><td><p>47%</p></td></tr><tr><td><p>Illinois</p></td><td><p>33%</p></td></tr><tr><td><p>Indiana</p></td><td><p>48%</p></td></tr><tr><td><p>Iowa</p></td><td><p>59%</p></td></tr><tr><td><p>Kansas</p></td><td><p>44%</p></td></tr><tr><td><p>Kentucky</p></td><td><p>43%</p></td></tr><tr><td><p>Louisiana</p></td><td><p>30%</p></td></tr><tr><td><p>Maine</p></td><td><p>43%</p></td></tr><tr><td><p>Maryland</p></td><td><p>43%</p></td></tr><tr><td><p>Massachusetts</p></td><td><p>36%</p></td></tr><tr><td><p>Michigan</p></td><td><p>35%</p></td></tr><tr><td><p>Minnesota</p></td><td><p>46%</p></td></tr><tr><td><p>Mississippi</p></td><td><p>42%</p></td></tr><tr><td><p>Missouri</p></td><td><p>46%</p></td></tr><tr><td><p>Montana</p></td><td><p>53%</p></td></tr><tr><td><p>Nebraska</p></td><td><p>50%</p></td></tr><tr><td><p>Nevada</p></td><td><p>46%</p></td></tr><tr><td><p>New Hampshire</p></td><td><p>52%</p></td></tr><tr><td><p>New Jersey</p></td><td><p>48%</p></td></tr><tr><td><p>New Mexico</p></td><td><p>50%</p></td></tr><tr><td><p>New York</p></td><td><p>44%</p></td></tr><tr><td><p>North Carolina</p></td><td><p>42%</p></td></tr><tr><td><p>North Dakota</p></td><td><p>50%</p></td></tr><tr><td><p>Ohio</p></td><td><p>36%</p></td></tr><tr><td><p>Oklahoma</p></td><td><p>52%</p></td></tr><tr><td><p>Oregon</p></td><td><p>52%</p></td></tr><tr><td><p>Pennsylvania</p></td><td><p>40%</p></td></tr><tr><td><p>Rhode Island</p></td><td><p>36%</p></td></tr><tr><td><p>South Carolina</p></td><td><p>33%</p></td></tr><tr><td><p>South Dakota</p></td><td><p>75%</p></td></tr><tr><td><p>Tennessee</p></td><td><p>40%</p></td></tr><tr><td><p>Texas</p></td><td><p>35%</p></td></tr><tr><td><p>Utah</p></td><td><p>36%</p></td></tr><tr><td><p>Vermont</p></td><td><p>55%</p></td></tr><tr><td><p>Virginia</p></td><td><p>49%</p></td></tr><tr><td><p>Washington</p></td><td><p>60%</p></td></tr><tr><td><p>West Virginia</p></td><td><p>38%</p></td></tr><tr><td><p>Wisconsin</p></td><td><p>37%</p></td></tr><tr><td><p>Wyoming</p></td><td><p>62%</p></td></tr></tbody></table><p><b>Categories:</b></p><p>When comparing salary transparency by job category Military and IT positions lead with 58% and 57% respectively advertising salary information. At the other end Sanitation, Engineering, Transportation &amp; Logistics and Agriculture all perform well below average with less than 33% of job posting advertising salary ranges. </p><table><tbody><tr><th><p><b>Job Category</b></p></th><th><p><b>Percentage with salary information</b></p></th></tr><tr><td><p>Administration</p></td><td><p>39%</p></td></tr><tr><td><p>Agriculture</p></td><td><p>32%</p></td></tr><tr><td><p>Construction</p></td><td><p>52%</p></td></tr><tr><td><p>Education</p></td><td><p>47%</p></td></tr><tr><td><p>Engineering</p></td><td><p>31%</p></td></tr><tr><td><p>Healthcare</p></td><td><p>46%</p></td></tr><tr><td><p>Hospitality</p></td><td><p>39%</p></td></tr><tr><td><p>Information Technology</p></td><td><p>57%</p></td></tr><tr><td><p>Legal</p></td><td><p>51%</p></td></tr><tr><td><p>Management</p></td><td><p>45%</p></td></tr><tr><td><p>Manufacturing</p></td><td><p>54%</p></td></tr><tr><td><p>Military</p></td><td><p>58%</p></td></tr><tr><td><p>Sales</p></td><td><p>43%</p></td></tr><tr><td><p>Sanitation</p></td><td><p>30%</p></td></tr><tr><td><p>Science</p></td><td><p>39%</p></td></tr><tr><td><p>Security</p></td><td><p>54%</p></td></tr><tr><td><p>Transportation &amp; Logistics</p></td><td><p>32%</p></td></tr></tbody></table><p><b>Notes on the data:</b></p><p>The above data is extracted from 5m active job postings, live on DirectlyApply as of 3rd November 2023. DirectlyApply removes all duplicate postings, postings where our AI systems detect there may be fraud, or job postings that don't meet our standards for advertising.</p><p>If you want more information about DirectlyApply or our features feel free to reach out to&nbsp;&nbsp; <a href="https://www.linkedin.com/in/dylankbuckley/" target="_blank" rel="noopener noreferrer">
          Dylan&nbsp;
        </a>or&nbsp;&nbsp; <a href="https://www.linkedin.com/in/will-capper-a1703045/" target="_blank" rel="noopener noreferrer">
          Will&nbsp;
        </a>on Linkedin or email:&nbsp;&nbsp; <a href="https://directlyapply.com/cdn-cgi/l/email-protection#334756525e73575a415650475f4a5243435f4a1d505c5e" target="_blank" rel="noopener noreferrer">
          <span data-cfemail="057160646845616c77606671697c647575697c2b666a68">[email&nbsp;protected]</span>
        </a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The OpenAI Keynote (106 pts)]]></title>
            <link>https://stratechery.com/2023/the-openai-keynote/</link>
            <guid>38177409</guid>
            <pubDate>Tue, 07 Nov 2023 14:52:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stratechery.com/2023/the-openai-keynote/">https://stratechery.com/2023/the-openai-keynote/</a>, See on <a href="https://news.ycombinator.com/item?id=38177409">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-11869">
	<!-- .entry-header -->

	<div>
		<p>In 2013, when I started Stratechery, there was no bigger event than the launch of the new iPhone; its only rival was Google I/O, which is when the newest version of Android was unveiled (hardware always breaks the tie, including with Appleâ€™s iOS introductions at WWDC). It wasnâ€™t just that smartphones were relatively new and still adding critical features, but that the strategic decisions and ultimate fates of the platforms were still an open question. More than that, the entire future of the tech industry was clearly tied up in said platforms and their corresponding operating systems and devices; how could keynotes <em>not</em> be a big deal?</p>
<p>Fast forward a decade and the tech keynote has diminished in importance and, in the case of Apple, disappeared completely, replaced by a pre-recorded marketing video. I want to be mad about it, but it makes sense: an iPhone introduction has been diminished not by Appleâ€™s presentation, but rather Appleâ€™s presentations reflect the reality that the most important questions around an iPhone are about marketing tactics. How do you segment the iPhone line? How do you price? What sort of brand affinity are you seeking to build? There, I just summarized <a href="https://stratechery.com/2023/apples-iphone-event-innovation-and-iteration-pricing-inflation-and-services/">the iPhone 15 introduction</a>, and the reality that the smartphone era â€” <a href="https://stratechery.com/2020/the-end-of-the-beginning/">The End of the Beginning</a> â€” is over as far as strategic considerations are concerned. iOS and Android are a given, but what is next and yet unknown?</p>
<p>The answer is, clearly, AI, but even there, the energy seems muted: Apple hasnâ€™t talked about generative AI other than to assure investors on earnings calls that they are working on it; Google I/O was of course about AI, but mostly in the context of Googleâ€™s own products â€” few of which have actually shipped â€” and <a href="https://stratechery.com/2023/google-i-o-and-the-coming-ai-battles/">my Article at the time</a> was quickly side-tracked into philosophical discussions about both the nature of AI innovation (sustaining versus disruptive), the question of tech revolution versus alignment, and a preview of the coming battles of regulation that arrived with <a href="https://stratechery.com/2023/attenuating-innovation-ai/">last weekâ€™s Executive Order on AI</a>.</p>
<p><a href="https://stratechery.com/2023/ai-hardware-and-virtual-reality/">Metaâ€™s Connect keynote was much more interesting</a>: not only were AI characters being added to Metaâ€™s social networks, but next year you will be able to take AI with you via Smart Glasses (I told you hardware was interesting!). Nothing, though, seemed to match the energy around yesterdayâ€™s OpenAI developer conference, their first ever: there is nothing more interesting in tech than a consumer product with product-market fit. And that, for me, is enough to bring back an old Stratechery standby: the keynote day-after.</p>
<h3>Keynote Metaphysics and GPT-4 Turbo</h3>
<p>This was, first and foremost, a really <em>good</em> keynote, in the keynote-as-artifact sense. CEO Sam Altman, in a humorous exchange with Microsoft CEO Satya Nadella, promised, â€œI wonâ€™t take too much of your timeâ€; never mind that Nadella was presumably in San Francisco just for this event: in this case he stood in for the audience who witnessed a presentation that was tight, with content that was interesting, leaving them with a desire to learn more.</p>
<p>Altman himself had a good stage presence, with the sort of nervous energy that is only present in a live keynote; the fact he never seemed to know which side of the stage a fellow presenter was coming from was humanizing. Meanwhile, the live demos not only went off without a hitch, but leveraged the fact that they were live: in one instance a presenter instructed a GPT she created to text Altman; he held up his phone to show he got the message. In another a GPT randomly selected five members of the audience to receive $500 in OpenAI API credits, only to then extend it to everyone.</p>
<p>New products and features, meanwhile, were available â€œtodayâ€, not weeks or months in the future, as is increasingly the case for events like I/O or WWDC; everything combined to give a palpable sense of progress and excitement, which, when it comes to AI, is mostly true.</p>
<p>GPT-4 Turbo is an excellent example of what I mean by â€œmostlyâ€. The API consists of six new features:</p>
<ul>
<li>Increased context length</li>
<li>More control, specifically in terms of model inputs and outputs</li>
<li>Better knowledge, which both means updating the cut-off date for knowledge about the world to April 2023 and providing the ability for developers to easily add their own knowledge base</li>
<li>New modalities, as DALL-E 3, Vision, and TTS (text-to-speech) will all be included in the API, with a new version of Whisper speech recognition coming.</li>
<li>Customization, including fine-tuning, and custom models (which, Altman warned, wonâ€™t be cheap)</li>
<li>Higher rate limits</li>
</ul>
<p>This is, to be clear, still the same foundational model (GPT-4); these features just make the API more usable, both in terms of features and also performance. It also speaks to how OpenAI is becoming more of a product company, with iterative enhancements of its core functionality. Yes, the mission still remains AGI (artificial general intelligence), and the core scientific team is almost certainly working on GPT-5, but Altman and team arenâ€™t just tossing models over the wall for the rest of the industry to figure out.</p>
<h3>Price and Microsoft</h3>
<p>The next â€œfeatureâ€ was tied into the GPT-4 Turbo introduction: the API is getting cheaper (3x cheaper for input tokens, and 2x cheaper for output tokens). Unsurprisingly this announcement elicited cheers from the developers in attendance; what I cheered as an analyst was Altmanâ€™s clear articulation of the companyâ€™s priorities: lower price first, speed later. You can certainly debate whether that is the right set of priorities (I think it is, because the biggest need now is for increased experimentation, not optimization), but what I appreciated was the clarity.</p>
<p>Itâ€™s also appropriate that the segment after that was the brief â€œinterviewâ€ with Nadella: OpenAIâ€™s pricing is ultimately a function of Microsoftâ€™s ability to build the infrastructure to support that pricing. Nadella actually explained how Microsoft is accomplishing that on the <a href="https://seekingalpha.com/article/4643129-microsoft-corporation-msft-q1-2024-earnings-call-transcript">companyâ€™s most recent earnings call</a>:</p>
<blockquote><p>
  It is true that the approach we have taken is a full stack approach all the way from whether itâ€™s ChatGPT or Bing Chat or all our Copilots, all share the same model. So in some sense, one of the things that we do have is very, very high leverage of the one model that we used, which we trained, and then the one model that we are doing inferencing at scale. And that advantage sort of trickles down all the way to both utilization internally, utilization of third parties, and also over time, you can see the sort of stack optimization all the way to the silicon, because the abstraction layer to which the developers are riding is much higher up than low-level kernels, if you will.</p>
<p>  So, therefore, I think there is a fundamental approach we took, which was a technical approach of saying weâ€™ll have Copilots and Copilot stack all available. That doesnâ€™t mean we donâ€™t have people doing training for open source models or proprietary models. We also have a bunch of open source models. We have a bunch of fine-tuning happening, a bunch of RLHF happening. So thereâ€™s all kinds of ways people use it. But the thing is, we have scale leverage of one large model that was trained and one large model thatâ€™s being used for inference across all our first-party SaaS apps, as well as our API in our Azure AI serviceâ€¦</p>
<p>  The lesson learned from the cloud side is â€” weâ€™re not running a conglomerate of different businesses, itâ€™s all one tech stack up and down Microsoftâ€™s portfolio, and that, I think, is going to be very important because that discipline, given what the spend like â€” it will look like for this AI transition any business thatâ€™s not disciplined about their capital spend accruing across all their businesses could run into trouble.
</p></blockquote>
<p>The fact that Microsoft is benefiting from OpenAI is obvious; what this makes clear is that OpenAI uniquely benefits from Microsoft as well, in a way they would not from another cloud provider: <a href="https://stratechery.com/2023/google-earnings-microsoft-earnings-ai-leverage/">because Microsoft is also a product company investing in the infrastructure to run OpenAIâ€™s models for said products</a>, it can afford to optimize and invest ahead of usage in a way that OpenAI alone, even with the support of another cloud provider, could not. In this case that is paying off in developers needing to pay less, or, ideally, have more latitude to discover use cases that result in them paying far more because usage is exploding.</p>
<h3>GPTs and Computers</h3>
<p>I mentioned GPTs before; you were probably confused, because this is a name that is either brilliant or a total disaster. Of course you could have said the same about ChatGPT: massive consumer uptake has a way of making arguably poor choices great ones in retrospect, and I can see why OpenAI is seeking to basically brand â€œGPTâ€ as an OpenAI chatbot, a meaning far afield from â€œgeneral pre-trained transformerâ€ â€” the whole point is that they are not â€œgeneralâ€!</p>
<p>Regardless, this was how Altman explains GPTs:</p>

<blockquote><p>
  GPTs are tailored version of ChatGPT for a specific purpose. You can build a GPT â€” a customized version of ChatGPT â€” for almost anything, with instructions, expanded knowledge, and actions, and then you can publish it for others to use. And because they combine instructions, expanded knowledge, and actions, they can be more helpful to you. They can work better in many contexts, and they can give you better control. Theyâ€™ll make it easier for you accomplish all sorts of tasks or just have more fun, and youâ€™ll be able to use them right within ChatGPT. You can, in effect, program a GPT, with language, just by talking to it. Itâ€™s easy to customize the behavior so that it fits what you want. This makes building them very accessible, and it gives agency to everyone.</p>
<p>  Weâ€™re going to show you what GPTs are, how to use them, how to build them, and then weâ€™re going to talk about how theyâ€™ll be distributed and discovered. And then after that, for developers, weâ€™re going to show you how to build these agent-like experiences into your own apps.
</p></blockquote>
<p>Altmanâ€™s examples included a lesson-planning GPT from Code.org and a natural language vision design GPT from Canva. As Altman noted, the second example might have seemed familiar: Canva had a plugin for ChatGPT, and Altman explained that â€œweâ€™ve evolved our plugins to be custom actions for GPTs.â€</p>
<p>I found the plugin concept fascinating and a useful way to understand both the capabilities and limits of large language models; I wrote in <a href="https://stratechery.com/2023/chatgpt-learns-computing/">ChatGPT Gets a Computer</a>:</p>
<blockquote><p>
  The implication of this approach is that computers are deterministic: if circuit X is open, then the proposition represented by X is true; 1 plus 1 is always 2; clicking â€œbackâ€ on your browser will exit this page. There are, of course, a huge number of abstractions and massive amounts of logic between an individual transistor and any action we might take with a computer â€” and an effectively infinite number of places for bugs â€” but the appropriate mental model for a computer is that they do exactly what they are told (indeed, a bug is not the computer making a mistake, but rather a manifestation of the programmer telling the computer to do the wrong thing)â€¦
</p></blockquote>
<p>Large language models, though, with their probabilistic approach, are in many domains shockingly intuitive, and yet can hallucinate and are downright terrible at math; that is why the most compelling plug-in OpenAI launched was from Wolfram|Alpha. Stephen Wolfram <a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/">explained</a>:</p>
<blockquote><p>
  For decades thereâ€™s been a dichotomy in thinking about AI between â€œstatistical approachesâ€ of the kind ChatGPT uses, and â€œsymbolic approachesâ€ that are in effect the starting point for Wolfram|Alpha. But nowâ€”thanks to the success of ChatGPTâ€”as well as all the work weâ€™ve done in making Wolfram|Alpha understand natural languageâ€”thereâ€™s finally the opportunity to combine these to make something much stronger than either could ever achieve on their own.
</p></blockquote>
<p>That is the exact combination that happened, which led to the title of that Article:</p>
<blockquote><p>
  The fact this works so well is itself a testament to what Assistant AIâ€™s are, and are not: they are not computing as we have previously understood it; they are shockingly human in their way of â€œthinkingâ€ and communicating. And frankly, I would have had a hard time solving those three questions as well â€” thatâ€™s what computers are for! And now ChatGPT has a computer of its own.
</p></blockquote>
<p>I still think the concept was incredibly elegant, but there was just one problem: the user interface was terrible. You had to get a plugin from the â€œmarketplaceâ€, then pre-select it before you began a conversation, and only then would you get workable results after a too-long process where ChatGPT negotiated with the plugin provider in question on the answer.</p>
<p>This new model somewhat alleviates the problem: now, instead of having to select the correct plug-in (and thus restart your chat), you simply go directly to the GPT in question. In other words, if I want to create a poster, I donâ€™t enable the Canva plugin in ChatGPT, I go to Canva GPT in the sidebar. Notice that this doesnâ€™t actually <em>solve</em> the problem of needing to have selected the right tool; what it does do is make the choice more apparent to the user at a more appropriate stage in the process, and thatâ€™s no small thing. I also suspect that GPTs will be much faster than plug-ins, given they are integrated from the get-go. Finally, standalone GPTs are a much better fit with the store model that OpenAI is trying to develop.</p>
<p>Still, there is a better way: Altman demoed it.</p>
<h3>ChatGPT and the Universal Interface</h3>
<p>Before Altman introduced the aforementioned GPTs he talked about improvements to ChatGPT:</p>

<blockquote><p>
  Even though this is a developer conference, we canâ€™t help resist making some improvements to ChatGPT. A small one, ChatGPT now uses GPT-4 Turbo, with all of the latest improvements, including the latest cut-off, which weâ€™ll continue to update â€” thatâ€™s all live today. It can now browse the web when it needs to, write and run code, analyze data, generate images, and much more, and we heard your feedback that that model picker was extremely annoying: that is gone, starting today. You will not have to click around a drop-down menu. All of this will just work together. ChatGPT will just know what to use and when you need it. But thatâ€™s not the main thing.
</p></blockquote>
<p>You may wonder why I put this section after GPTs, given they were, according to Altman, the main thing: itâ€™s because I think this feature enhancement is actually much more important. As I just noted, GPTs are a somewhat better UI on an elegant plugin concept, in which a probabilisitic large language model gets access to a deterministic computer. The best UI, though, is no UI at all, or rather, just one UI, by which I mean â€œUniversal Interfaceâ€.</p>
<p>In this case â€œbrowsingâ€ or â€œimage generationâ€ are basically plug-ins: they are specialized capabilities that, before today, you had to explicitly invoke; going forward they will just work. ChatGPT will seamlessly switch between text generation, image generation, and web browsing, without the user needing to change context. What is necessary for the plug-in/GPT idea to ultimately take root is for the same capabilities to be extended broadly: if my conversation involved math, ChatGPT should know to use Wolfram|Alpha on its own, without me adding the plug-in or going to a specialized GPT.</p>
<p>I can understand why this capability doesnâ€™t yet exist: the obvious technical challenges of properly exposing capabilities and training the model to know when to invoke those capabilities are a textbook example of Professor Clayton Christensenâ€™s theory of integration and modularity, wherein integration works better when a product isnâ€™t good enough; it is only when a product exceeds expectation that there is room for standardization and modularity. To that end, ChatGPT is only now getting the capability to generate an image without the mode being selected for it: I expect the ability to seek out less obvious tools will be fairly difficult.</p>
<p>In fact, itâ€™s possible that the entire plug-in/GPT approach ends up being a dead-end; towards the end of the keynote Ramon Huet, the head of developer experience at OpenAI, explicitly demonstrated ChatGPT programming a computer. The scenario was splitting the tab for an Airbnb in Paris:</p>

<blockquote><p>
  Code Interpreter is now available today in the API as well. That gives the AI the ability to write and generate code on the file, or even to generate files. So letâ€™s see that in action. If I say here, â€œHey, weâ€™ll be 4 friends staying at this Airbnb, whatâ€™s my share of it plus my flights?â€</p>
<p>  Now here whatâ€™s happening is that Code Interpreter noticed that it should write some code to answer this query so now itâ€™s computing the number of days in Paris, the number of friends, itâ€™s also doing some exchange rate calculation behind the scene to get this answer for us. Not the most complex math, but you get the picture: imagine youâ€™re building a very complex finance app thatâ€™s counting countless numbers, plotting charts, really any tasks you might tackle with code, then Code Interpreter will work great.
</p></blockquote>
<p>Uhm, what tasks do you <em>not</em> tackle with code? To be fair, Huet is referring to fairly simple math-oriented tasks, not the wholesale recreation of every app on the Internet, but it is interesting to consider for which problems ChatGPT will gain the wisdom to choose the right tool, and for which it will simply brute force a new solution; the history of computing would actually give the latter a higher probability: there are a lot of problems that were solved less with clever algorithms and more with the <a href="https://stratechery.com/2023/china-chips-and-moores-law/">application of Mooreâ€™s Law</a>.</p>
<h3>Consumers and Hardware</h3>
<p>Speaking of the first year of Stratechery, that is when I first wrote about integration and modularization, in <a href="https://stratechery.com/2013/clayton-christensen-got-wrong/">What Clayton Christensen Got Wrong</a>; as the title suggests I didnâ€™t think the theory was universal:</p>
<blockquote><p>
  Christensen himself laid out his theoryâ€™s primary flaw in the first quote excerpted above (from 2006):</p>
<blockquote><p>
    You also see it in aircrafts and software, and medical devices, and over and over.
  </p></blockquote>
<p>  That is the problem: Consumers donâ€™t buy aircraft, software, or medical devices. Businesses do.</p>
<p>  Christensenâ€™s theory is based on examples drawn from buying decisions made by businesses, not consumers. The reason this matters is that the theory of low-end disruption presumes:</p>
<ul>
<li>Buyers are rational</li>
<li>Every attribute that matters can be documented and measured</li>
<li>Modular providers can become â€œgood enoughâ€ on all the attributes that matter to the buyers</li>
</ul>
<p>  All three of the assumptions fail in the consumer market, and this, ultimately, is why Christensenâ€™s theory fails as well. Let me take each one in turn:
</p></blockquote>
<p>To summarize the argument, consumers care about things in ways that are inconsistent with whatever price you might attach to their utility, they prioritize ease-of-use, and they care about the quality of the user experience and are thus especially bothered by the seams inherent in a modular solution. This means that integrated solutions win because nothing is ever â€œgood enoughâ€; as I noted in the context of Amazon, <a href="https://stratechery.com/2018/divine-discontent-disruptions-antidote/">Divine Discontent is Disruptionâ€™s Antidote</a>:</p>
<blockquote><p>
  Bezosâ€™s letter, though, reveals another advantage of focusing on customers: it makes it impossible to overshoot. When I wrote that piece five years ago, I was thinking of the opportunity provided by a focus on the user experience as if it were an asymptote: one could get ever closer to the ultimate user experience, but never achieve it:</p>
<p>  <a href="https://stratechery.com/2018/divine-discontent-disruptions-antidote/"><img loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.347.png?resize=640%2C389&amp;ssl=1" alt="A drawing of The Asymptote Version of the User Experience" width="640" height="389" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.347.png?w=1300&amp;ssl=1 1300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.347.png?resize=300%2C183&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.347.png?resize=768%2C467&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.347.png?resize=1024%2C623&amp;ssl=1 1024w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.347.png?resize=1035%2C630&amp;ssl=1 1035w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a></p>
<p>  In fact, though, consumer expectations are not static: they are, as Bezosâ€™ memorably states, â€œdivinely discontentâ€. What is amazing today is table stakes tomorrow, and, perhaps surprisingly, that makes for a tremendous business opportunity: if your company is predicated on delivering the best possible experience for consumers, then your company will never achieve its goal.</p>
<p>  <a href="https://stratechery.com/2018/divine-discontent-disruptions-antidote/"><img loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.348.png?resize=640%2C389&amp;ssl=1" alt="A drawing of The Ever-Changing Version of the User Experience" width="640" height="389" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.348.png?w=1300&amp;ssl=1 1300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.348.png?resize=300%2C183&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.348.png?resize=768%2C467&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.348.png?resize=1024%2C623&amp;ssl=1 1024w, https://i0.wp.com/stratechery.com/wp-content/uploads/2018/05/Paper.stratechery-Year-One.348.png?resize=1035%2C630&amp;ssl=1 1035w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a></p>
<p>  In the case of Amazon, that this unattainable and ever-changing objective is embedded in the companyâ€™s culture is, in conjunction with the companyâ€™s demonstrated ability to spin up new businesses on the profits of established ones, a sort of perpetual motion machine.
</p></blockquote>
<p>I see no reason why both Articles wouldnâ€™t apply to ChatGPT: while I might make the argument that hallucination is, in a certain light, a feature not a bug, the fact of the matter is that a lot of people use ChatGPT for information despite the fact it has a well-documented flaw when it comes to the truth; that flaw is acceptable, because to the customer ease-of-use is worth the loss of accuracy. Or look at plug-ins: the concept as originally implemented has already been abandoned, because the complexity in the user interface was more detrimental than whatever utility might have been possible. It seems likely this pattern will continue: of course customers will <em>say</em> that they want accuracy and 3rd-party tools; their actions will continue to demonstrate that convenience and ease-of-use matter most.</p>
<p>This has two implications. First, while this may have been OpenAIâ€™s first developer conference, I remain unconvinced that OpenAI is going to ever be a true developer-focused company. I think that was Altmanâ€™s plan, but reality in the form of ChatGPT intervened: ChatGPT is the most important consumer-facing product since the iPhone, making OpenAI <a href="https://stratechery.com/2023/the-accidental-consumer-tech-company-chatgpt-meta-and-product-market-fit-aggregation-and-apis/">The Accidental Consumer Tech Company</a>. That, by extension, means that integration will continue to matter more than modularization, which is great for Microsoftâ€™s compute stack and maybe less exciting for developers.</p>
<p>Second, there remains one massive patch of friction in using ChatGPT; from <a href="https://stratechery.com/2023/ai-hardware-and-virtual-reality/">AI, Hardware, and Virtual Reality</a>:</p>
<blockquote><p>
  AI is truly something new and revolutionary and capable of being something more than just a homework aid, but I donâ€™t think the existing interfaces are the right ones. Talking to ChatGPT is better than typing, but I still have to launch the app and set the mode; vision is an amazing capability, but it requires even more intent and friction to invoke. I could see a scenario where Metaâ€™s AI is inferior technically to OpenAI, but more useful simply because it comes in a better form factor.
</p></blockquote>
<p>After highlighting some news stories about OpenAI potentially partnering with Jony Ive to build hardware, I concluded:</p>
<blockquote><p>
  There are obviously many steps before a potential hardware product, including actually agreeing to build one. And there is, of course, the fact that Apple and Google already make devices everyone carries, with the latter in particular investing heavily in its own AI capabilities; betting on the hardware in market winning the hardware opportunity in AI is the safest bet. That may not be a reason for either OpenAI or Meta to abandon their efforts, though: waging a hardware battle against Google and Apple would be difficult, but it might be even worse to be â€œjust an appâ€ if the full realization of AIâ€™s capabilities depend on fully removing human friction from the process.
</p></blockquote>
<p>This is the implication of a Universal Interface, which ChatGPT is striving to be: it also requires universal access, and that will always be a challenge for any company that is â€œjust an app.â€ Yes, as I noted, the odds seem long, thanks to Apple and Googleâ€™s dominance, but I think there is an outside chance that the paradigm-shifting keynote is only just beginning its comeback.</p>

	</div><!-- .entry-content -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Escapist staff resign following termination of editor-in-chief Nick Calandra (182 pts)]]></title>
            <link>https://www.gamesindustry.biz/the-escapist-staff-resign-following-termination-of-editor-in-chief-nick-calandra</link>
            <guid>38177250</guid>
            <pubDate>Tue, 07 Nov 2023 14:40:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamesindustry.biz/the-escapist-staff-resign-following-termination-of-editor-in-chief-nick-calandra">https://www.gamesindustry.biz/the-escapist-staff-resign-following-termination-of-editor-in-chief-nick-calandra</a>, See on <a href="https://news.ycombinator.com/item?id=38177250">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content_above">



<p>
If you click on a link and make a purchase we may receive a small commission.  <a href="https://www.gamesindustry.biz/editorial-policy">Read our editorial policy</a>.
</p>
  <article data-ads="true" data-article-type="news" data-paywalled="false" data-premium="false" data-type="article">


<header>
  

    <div>
        

        <p>Zero Punctuation's Ben "Yahtzee" Croshaw is one of many to leave the site</p>

    </div>


  <div>
  <figure>
  <a href="https://assetsio.reedpopcdn.com/the-escapist.jpg?width=1920&amp;height=1920&amp;fit=bounds&amp;quality=80&amp;format=jpg&amp;auto=webp" target="_blank" data-lightbox="true">
  <img src="https://assetsio.reedpopcdn.com/the-escapist.jpg?width=720&amp;quality=70&amp;format=jpg&amp;auto=webp" srcset="https://assetsio.reedpopcdn.com/the-escapist.jpg?width=720&amp;quality=70&amp;format=jpg&amp;auto=webp 1x, https://assetsio.reedpopcdn.com/the-escapist.jpg?width=720&amp;quality=70&amp;format=jpg&amp;dpr=2&amp;auto=webp 2x" loading="eager" alt="" width="720" height="405" fetchpriority="high">
  </a>

  </figure>
  </div>

    

      



  

  

</header>  <div>



            <p>
Journalists from The Escapist have resigned in response to the termination of its editor-in-chief Nick Calandra.
</p>
<p>
On Monday, Calandra announced on <a href="https://twitter.com/nickjcal/status/1721640314203464045">X</a> that he was fired for "not achieving goals" reportedly set by the Gamurs Group, <a href="https://www.gamesindustry.biz/gamurs-group-buying-enthusiast-gaming-sites-report">which acquired The Escapist last year</a>.
</p>
<p>
"I was let go for 'not achieving goals' that were never properly set for us, and a lack of understanding of our audience and the team that built that audience," Calandra wrote. "I've watched many colleagues let go for the same reasons, and today was my day."
</p>
<p>
<em>GamesIndustry.biz</em> has reached out to Calandra and the Gamurs Group for more clarification.
</p>
<p>
Calandra shared more information on <a href="https://discord.com/channels/1171109642294808616/1171234055220641793">Discord</a>, revealing that the "entire video team" has resigned in response.
</p>
<p>
This includes Ben "Yahtzee" Croshaw, who created the video review series Zero Punctuation. 
</p>
<p>
"Today, I formally resigned from The Escapist and Gamurs," Croshaw wrote today on <a href="https://twitter.com/YahtzeeCroshaw/status/1721687212541280425">X</a>. "I don't have the rights to Zero Punctuation, but whatever happens you'll be hearing from my voice again soon, in a new place."
</p>
<p>
Contributors such as <a href="https://twitter.com/sassqueenamy/status/1721693823729066025">Amy Campbell</a>, <a href="https://twitter.com/ParkesHarman/status/1721692595166794023">Parkes Harman</a>, <a href="https://twitter.com/Darren_Mooney/status/1721683973506568532">Darren Mooney</a>, <a href="https://twitter.com/_mattjlaughlin/status/1721714880859042098">Matt Laughlin</a>, and <a href="https://twitter.com/DesignDelve/status/1721677391368425571">Design Delve's JM8</a> have also left the site in response to Calandra's termination.
</p>
<blockquote><p><a href="https://www.gamesindustry.biz/newsletters">Sign up for the GI Daily here</a> to get the biggest news straight to your inbox</p></blockquote>

        </div>
  </article>


      </div><div id="content_below">

  

  <nav>



    




    
<div id="newsletters">
    <p><img src="https://www.gamesindustry.biz/static/e4997cbeb6c57196f815a1e3f8393b7e/img/icon.svg" loading="lazy" alt="GamesIndustry.biz logo"></p><h2>
Newsletters    </h2>

    <p>
Subscribe to GamesIndustry.biz newsletters for the latest industry news.    </p>

  </div>



    


  



  </nav>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waze will now warn drivers about crash dangers using historical data (160 pts)]]></title>
            <link>https://arstechnica.com/cars/2023/11/waze-will-now-warn-drivers-about-crash-dangers-using-historical-data/</link>
            <guid>38176984</guid>
            <pubDate>Tue, 07 Nov 2023 14:19:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/cars/2023/11/waze-will-now-warn-drivers-about-crash-dangers-using-historical-data/">https://arstechnica.com/cars/2023/11/waze-will-now-warn-drivers-about-crash-dangers-using-historical-data/</a>, See on <a href="https://news.ycombinator.com/item?id=38176984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      be careful out there    â€”
</h4>
            
            <h2 itemprop="description">The feature combines geographic and traffic data with historical crash data.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/Crash-History-Alerts_Still_2096x1182-800x451.png" alt="A screenshot from Waze">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/Crash-History-Alerts_Still_2096x1182.png" data-height="1182" data-width="2096">Enlarge</a> <span>/</span> The Waze crash history alerts look like this.</p><p>Waze</p></figcaption>  </figure>

  




<!-- cache hit 652:single/related:a9c6272094afb14c257c96b97f82edb6 --><!-- empty -->
<p>Traffic navigation app Waze is adding a new feature to its toolbox today. It's called crash history alerts, and it's meant to warn drivers about dangerous hotspots, based on a combination of historical data plus road and traffic data.</p>
<p>Originally an independent startup, <a href="https://arstechnica.com/information-technology/2013/06/google-acquires-waze-for-real-this-time-likely-for-1b-plus/">in 2013</a> Google purchased the Israeli company for $1.15 billion, perhaps <a href="https://arstechnica.com/gadgets/2013/01/apple-may-buy-social-navigation-app-waze-to-bolster-maps/">beating Apple to the punch</a>. Even before the purchase, Waze was becoming an Ars reader favorite thanks to more advanced traffic rerouting than either Google Maps or Apple Maps.</p>
<p>It has not been entirely smooth <span>sailing</span>driving; for a while the app was infamous for asking drivers to make difficult left turns across busy multi-lane roads and <a href="https://arstechnica.com/tech-policy/2018/04/waze-blamed-for-rise-in-accidents-along-one-of-steepest-streets-in-us/">routing cars through once-quiet neighborhoods as shortcuts</a>, aggravating the people who live in those neighborhoods.</p>
<p>After a long period operating as its own company, <a href="https://arstechnica.com/gadgets/2022/12/googles-cost-cutters-come-for-waze-will-lose-status-as-independent-company/">more recently</a> Google has been integrating Waze into its "Geo" division, home to Google Maps. That merger <a href="https://arstechnica.com/google/2023/06/waze-googles-other-mapping-app-gets-hit-with-layoffs/">was followed</a> this year by layoffs.</p>
<p>One feature of Waze that was unique for a long time was its ability to crowdsource traffic information. Users add live traffic information to the app as they drive, like a car stopped by the side of the road or a crash. Waze now leverages that data, together with geographic information, including road layout and elevation, plus typical traffic levels, to determine whether a particular stretch of road has a high crash rate. Should that be the case, the app will warn the driver.</p>
<figure>
    
    </figure>
<p>However, Waze says that to minimize distractions, it won't show these alerts on regularly traveled roads and will limit alerts on unfamiliar roads to prevent driver overload.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euclid's First Images (304 pts)]]></title>
            <link>https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_first_images_the_dazzling_edge_of_darkness</link>
            <guid>38176750</guid>
            <pubDate>Tue, 07 Nov 2023 13:58:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_first_images_the_dazzling_edge_of_darkness">https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_first_images_the_dazzling_edge_of_darkness</a>, See on <a href="https://news.ycombinator.com/item?id=38176750">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<header>
	<span>Science &amp; Exploration</span>
	
	<p><span>07/11/2023</span>
				<span><span id="viewcount">57522</span><small> views</small></span>
										<span><span id="ezsr_total_25170425">89</span><small> likes</small></span>
				
	</p>
</header>




<div>
	<div>
		<h2>In brief</h2>
		<p>Today, ESAâ€™s <a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid" target="_blank">Euclid</a> space mission reveals its first full-colour images of the cosmos. Never before has a telescope been able to create such razor-sharp astronomical images across such a large patch of the sky, and looking so far into the distant Universe. These five images illustrate Euclid's full potential; they show that the telescope is ready to create the most extensive 3D map of the Universe yet, to uncover some of its hidden secrets.</p>
	</div>
	<h2>In-depth</h2>
</div>

<div>
				
		<p>Euclid, our dark Universe detective, has a difficult task: to investigate how dark matter and dark energy have made our Universe look like it does today. <a href="https://www.esa.int/ESA_Multimedia/Images/2023/05/The_light_and_dark_Universe">95% of our cosmos appears to be made of these mysterious â€˜darkâ€™ entities.</a> But we donâ€™t understand what they are because their presence causes only very subtle changes in the appearance and motions of the things we can see.</p><p>To reveal the â€˜darkâ€™ influence on the visible Universe, over the next six years Euclid will observe the shapes, distances and motions of billions of galaxies out to 10 billion light-years. By doing this, it will create the largest cosmic 3D map ever made.</p><p>What makes Euclidâ€™s view of the cosmos special is its ability to <a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_wide-eyed_look_at_the_cosmos" target="_blank">create a remarkably sharp visible and infrared image across a huge part of the sky in just one sitting.</a></p><p>The images released today showcase this special capacity: from bright stars to faint galaxies, the observations show the entirety of these celestial objects, while remaining extremely sharp, even when zooming in on distant galaxies.</p>
	</div>
				
	
    
						
			<div>
				<p>â€œDark matter pulls galaxies together and causes them to spin more rapidly than visible matter alone can account for; dark energy is driving the accelerated expansion of the Universe. Euclid will for the first-time allow cosmologists to study these competing dark mysteries together,â€ explains ESA Director of Science, Professor Carole Mundell. â€œEuclid will make a leap in our understanding of the cosmos as a whole, and these exquisite Euclid images show that the mission is ready to help answer one of the greatest mysteries of modern physics.â€</p><p>â€œWe have never seen astronomical images like this before, containing so much detail. They are even more beautiful and sharp than we could have hoped for, showing us many previously unseen features in well-known areas of the nearby Universe. Now we are ready to observe billions of galaxies, and study their evolution over cosmic time,â€ says RenÃ© Laureijs, ESAâ€™s Euclid Project Scientist.</p><p>â€œOur high standards for this telescope paid off: that there is so much detail in these images, is all thanks to a special optical design, perfect manufacturing and assembly of telescope and instruments, and extremely accurate pointing and temperature control,â€ adds Giuseppe Racca, ESAâ€™s Euclid Project Manager.</p><p>â€œI wish to congratulate and thank everyone involved with making this ambitious mission a reality, which is a reflection of European excellence and international collaboration. The first images captured by Euclid are awe-inspiring and remind us of why it is essential that we go to space to learn more about the mysteries of the Universe,â€ says ESA Director General Josef Aschbacher.</p>	</div>	
    
							
														
																								



				
				
								
						
								
						<div>
		<a href="https://www.esa.int/ESA_Multimedia/Videos/2023/11/Euclid_s_first_images_the_dazzling_edge_of_darkness">
		<div>
				

   <p><img src="https://www.esa.int/extension/pillars/design/pillars/images/play-button.svg" alt="Play"></p>
   <p><img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/videos/2023/11/euclid_s_first_images_the_dazzling_edge_of_darkness/25174596-2-eng-GB/Euclid_s_first_images_the_dazzling_edge_of_darkness_pillars.png" alt="$video.data_map.short_description.content">

 
		</p></div>
		</a>
				<p>
			Euclid's first images: the dazzling edge of darkness
			<br><a href="https://www.esa.int/ESA_Multimedia/Videos/2023/11/Euclid_s_first_images_the_dazzling_edge_of_darkness">Access the video</a>
		</p>
			</div>	
	<p>
	<h2>Zoom into the Universe through Euclidâ€™s eyes</h2>
	    
						</p>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_the_Perseus_cluster_of_galaxies">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2023/11/euclid_s_view_of_the_perseus_cluster_of_galaxies/25170524-1-eng-GB/Euclid_s_view_of_the_Perseus_cluster_of_galaxies_article.jpg" alt="Euclidâ€™s view of the Perseus cluster of galaxies">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_the_Perseus_cluster_of_galaxies">Euclidâ€™s view of the Perseus cluster of galaxies</a>
								</figcaption>
	</figure>	
		<p><b>The Perseus Cluster of galaxies</b></p><p>This incredible snapshot from Euclid is a revolution for astronomy. The image shows 1000 galaxies belonging to the Perseus Cluster, and more than 100 000 additional galaxies further away in the background.</p><p>Many of these faint galaxies were previously unseen. Some of them are so distant that their light has taken 10 billion years to reach us. By mapping the distribution and shapes of these galaxies, cosmologists will be able to find out more about how dark matter shaped the Universe that we see today.</p><p>This is the first time that such a large image has allowed us to capture so many Perseus galaxies in such a high level of detail. Perseus is one of the most massive structures known in the Universe, located â€˜justâ€™ 240 million light-years away from Earth.</p><p>Astronomers demonstrated that galaxy clusters like Perseus can only have formed if dark matter is present in the Universe. Euclid will observe numerous galaxy clusters like Perseus across cosmic time, revealing the â€˜darkâ€™ element that holds them together.</p><p><a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_view_of_the_Perseus_cluster_of_galaxies" target="_blank">Read the full story about this image</a></p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_spiral_galaxy_IC_342">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2023/11/euclid_s_view_of_spiral_galaxy_ic_342/25170712-1-eng-GB/Euclid_s_view_of_spiral_galaxy_IC_342_article.jpg" alt="Euclidâ€™s view of spiral galaxy IC 342">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_spiral_galaxy_IC_342">Euclidâ€™s view of spiral galaxy IC 342</a>
								</figcaption>
	</figure>	
		<p><b>Spiral galaxy IC 342</b></p><p>Over its lifetime, our dark Universe detective will image billions of galaxies, revealing the unseen influence that dark matter and dark energy have on them. Thatâ€™s why itâ€™s fitting that one of the first galaxies that Euclid observed is nicknamed the â€˜Hidden Galaxyâ€™, also known as IC 342 or Caldwell 5. Thanks to its infrared view, Euclid has already uncovered crucial information about the stars in this galaxy, which is a look-alike of our Milky Way.</p><p><a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_view_of_spiral_galaxy_IC_342" target="_blank">Read the full story about this image</a></p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_irregular_galaxy_NGC_6822">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2023/11/euclid_s_view_of_irregular_galaxy_ngc_6822/25170757-1-eng-GB/Euclid_s_view_of_irregular_galaxy_NGC_6822_article.jpg" alt="Euclidâ€™s view of irregular galaxy NGC 6822">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_irregular_galaxy_NGC_6822">Euclidâ€™s view of irregular galaxy NGC 6822</a>
								</figcaption>
	</figure>	
		<p><b>Irregular galaxy NGC 6822</b></p><p>To create a 3D map of the Universe, Euclid will observe the light from galaxies out to 10 billion light-years. Most galaxies in the early Universe donâ€™t look like the quintessential neat spiral, but are irregular and small. They are the building blocks for bigger galaxies like our own, and we can still find some of these galaxies relatively close to us. This first irregular dwarf galaxy that Euclid observed is called NGC 6822 and is located close by, just 1.6 million light-years from Earth.</p><p><a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_view_of_irregular_galaxy_NGC_6822" target="_blank">Read the full story about this image</a></p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_globular_cluster_NGC_6397">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2023/11/euclid_s_view_of_globular_cluster_ngc_6397/25170802-1-eng-GB/Euclid_s_view_of_globular_cluster_NGC_6397_article.jpg" alt="Euclidâ€™s view of globular cluster NGC 6397">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_globular_cluster_NGC_6397">Euclidâ€™s view of globular cluster NGC 6397</a>
								</figcaption>
	</figure>	
		<p><b>Globular cluster NGC 6397</b></p><p>This sparkly image shows Euclidâ€™s view on a globular cluster called NGC 6397. This is the second-closest globular cluster to Earth, located about 7800 light-years away. Globular clusters are collections of hundreds of thousands of stars held together by gravity. Currently no other telescope than Euclid can observe an entire globular cluster in one single observation, and at the same time distinguish so many stars in the cluster. These faint stars tell us about the history of the Milky Way and where dark matter is located.</p><p><a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_view_of_globular_cluster_NGC_6397" target="_blank">Read the full story about this image</a></p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_the_Horsehead_Nebula">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2023/11/euclid_s_view_of_the_horsehead_nebula/25170855-1-eng-GB/Euclid_s_view_of_the_Horsehead_Nebula_article.jpg" alt="Euclidâ€™s view of the Horsehead Nebula">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2023/11/Euclid_s_view_of_the_Horsehead_Nebula">Euclidâ€™s view of the Horsehead Nebula</a>
								</figcaption>
	</figure>	
		<p><b>The Horsehead Nebula</b></p><p>Euclid shows us a spectacularly panoramic and detailed view of the Horsehead Nebula, also known as Barnard 33 and part of the constellation Orion. In Euclidâ€™s new observation of this stellar nursery, scientists hope to find many dim and previously unseen Jupiter-mass planets in their celestial infancy, as well as young brown dwarfs and baby stars.</p><p><a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_view_of_the_Horsehead_Nebula" target="_blank">Read the full story about this image</a></p>	</div>	
	<div>
	<h2>New discoveries, soon</h2>
	    
						
		<p>Euclidâ€™s first view of the cosmos is not only beautiful, but also immensely valuable for the scientific community.</p><p>Firstly, it showcases that Euclidâ€™s telescope and instruments are performing extremely well and that astronomers can use Euclid to study the distribution of matter in the Universe and its evolution at the largest scales. Combining many observations of this quality covering large areas of the sky will show us the dark and hidden parts of the cosmos.</p><p>Secondly, each image individually contains a wealth of new information about the nearby Universe (click on the individual images to learn more about this). â€œIn the coming months, scientists in the Euclid Consortium will analyse these images and publish a series of scientific papers in the journal Astronomy &amp; Astrophysics, together with papers about the scientific objectives of the Euclid mission and the instrument performance,â€ adds Yannick Mellier, <a href="https://www.euclid-ec.org/" target="_blank">Euclid Consortium</a> lead.</p><p>And finally, these images take us beyond the realm of dark matter and dark energy, also showing how Euclid will create a <a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_treasure_trove" target="_blank">treasure trove of informatio</a>n about the physics of individual stars and galaxies.</p><h3>Getting ready for routine observations</h3><p>Euclid launched to the Sun-Earth Lagrange point 2 on a SpaceX Falcon 9 rocket from Cape Canaveral Space Force Station in Florida, USA, at 17:12 CEST on 1 July 2023. In the months after launch, scientists and engineers have been engaged in an<a href="https://www.esa.int/Science_Exploration/Space_Science/Euclid/Follow_Euclid_s_first_months_in_space" target="_blank">&nbsp;intense phase of testing and calibrating Euclidâ€™s scientific instruments.</a> The team is doing the last fine-tuning of the spacecraft before routine science observations begin in early 2024.</p><p>Over six years, Euclid will survey one third of the sky with unprecedented accuracy and sensitivity. As the mission progresses, Euclidâ€™s bank of data will be released once per year, and will be available to the global scientific community via the <a href="https://www.cosmos.esa.int/web/esdc" target="_blank">Astronomy Science Archives</a> hosted at ESAâ€™s European Space Astronomy Centre in Spain.</p><h3>About Euclid</h3><p>Euclid is a European mission, built and operated by ESA, with contributions from NASA. The Euclid Consortium â€“ consisting of more than 2000 scientists from 300 institutes in 13 European countries, the US, Canada and Japan â€“ is responsible for providing the scientific instruments and scientific data analysis. ESA selected Thales Alenia Space as prime contractor for the construction of the satellite and its service module, with Airbus Defence and Space chosen to develop the payload module, including the telescope. NASA provided the detectors of the Near-Infrared Spectrometer and Photometer, NISP. Euclid is a medium-class mission in ESAâ€™s Cosmic Vision Programme.</p><p><b>For more information, please contact:</b></p><p>
ESA Media Relations<br>Email: media@esa.int</p>	</div>	
    
					



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Maine's Constitution Has Unprintable Sections (222 pts)]]></title>
            <link>https://www.mitsc.org/news/maine-2023-election-ballot-question-6-fact-sheet</link>
            <guid>38176592</guid>
            <pubDate>Tue, 07 Nov 2023 13:43:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mitsc.org/news/maine-2023-election-ballot-question-6-fact-sheet">https://www.mitsc.org/news/maine-2023-election-ballot-question-6-fact-sheet</a>, See on <a href="https://news.ycombinator.com/item?id=38176592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Do you favor amending the Constitution of Maine to require that all of the provisions of the Constitution be included in the official printed copies of the Constitution prepared by the Secretary of State?</h2><p>A â€œyesâ€ vote on Question 6 would restore certain original sections of the Maine Constitution to printed copies. Although these sections have always been part of the Maine Constitution as originally adopted in 1820, an amendment in 1876 prevented those sections from being printed in copies of the Constitution. Part of the redacted material pertained to Maineâ€™s treaty obligations to Wabanaki people.</p><p>â€</p><h3>Why are we voting on this?</h3><p>In 1820 when Maine separated from the Commonwealth of Massachusetts and became a state, its new Constitution included Article X, Section 5 that said, in part:</p><blockquote>The new State shall, as soon as the necessary arrangements can be made for that purpose, assume and perform all the duties and obligations of this Commonwealth, towards the Indians within said District of Maine, whether the same arise from treaties, or otherwise . . .</blockquote><p>This is the only section of Maineâ€™s Constitution that mentions the â€œduties and obligationsâ€ Maine inherited as regards the Wabanaki people within its borders. In 1876, the Constitution was amended to remove that language from printed copies. Maineâ€™s current Constitution reads, in part:â€¨</p><blockquote>Sections 1, 2 and 5, of Article X of the Constitution, shall hereafter be omitted in any printed copies thereof prefixed to the laws of the State; but this shall not impair the validity of acts under those sections; and said section 5 shall remain in full force, as part of the Constitution, according to the stipulations of said section, with the same effect as if contained in said printed copies.</blockquote><p>A â€œyesâ€ vote on Question 6 would cancel the 1876 amendment and restore the language of original Sections 1, 2, and 5 of Article X to printed copies of the Constitution.</p><p>â€</p><h3>What is the history behind Question 6?</h3><p>For Maine to become a state, Massachusetts first had to pass legislation called the Articles of Separation. That legislation divided and allocated public property and certain obligations as between Maine and Massachusetts once they became separate states. As part of that division, Maine assumed all the â€œduties and obligationsâ€ Massachusetts had as regards the â€œIndians within said District of Maine.â€</p><p>The Articles also required that its terms and conditions â€œbe incorporated into, and become and be a part of any Constitution, provisional or other, under which the Government of the said proposed State, shall, at any time hereafter, be administered; subject however, to be modified, or annulled by the agreement of the Legislature of both the said States; but by no other power or body whatsoever." The Articles of Separation were included in the Maine Constitution as Section 5 of Article X. This was one of the Sections redacted from printed copies in 1876.</p><p>Sections 1 and 2 of Article X were also redacted in 1876. They covered when the first Maine legislature would meet, when initial elections would be held, how Senate and House seats would be allocated as between the counties and towns, and what the initial terms of Maineâ€™s elected and appointed officers would be. These Sections would also be restored to printed copies of the Constitution if Question 6 passes.</p><p>â€</p><h3>What would be the legal effect of a â€œyesâ€ vote on Question 6?</h3><p>The only legal effect would be that printed copies of the Maine Constitution would henceforth contain the language redacted in 1876, including the full Articles of Separation. Passage of Question 6 would not change the â€œduties and obligationsâ€ Maine has always had as regards the Wabanaki Nations. Those â€œduties and obligationsâ€, despite the redaction, remained â€œin full force, as part of the Constitution . . . as if contained in said printed copies.â€ Although there would be no substantive legal changes, passage of Question 6 would give citizens of Maine easy access to the original language in our Constitution.</p><p>â€</p><h3>How will Question 6 appear on your ballot?</h3><p>QUESTION 6: RESOLUTION, Proposing an Amendment to the Constitution of Maine to Require All Provisions in the Constitution to Be Included in the Official Printing. Do you favor amending the Constitution of Maine to require that all of the provisions of the Constitution be included in the official printed copies of the Constitution prepared by the Secretary of State?</p><p>â€</p></div></div>]]></description>
        </item>
    </channel>
</rss>