<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 19 Sep 2025 09:30:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Nostr (124 pts)]]></title>
            <link>https://nostr.com/</link>
            <guid>45298336</guid>
            <pubDate>Fri, 19 Sep 2025 05:49:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nostr.com/">https://nostr.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45298336">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <!-- Header -->
    <header>
      
    </header>

    <!-- Hero -->
    <section>
      <h2>
        An open protocol with a chance of working
      </h2>
      <p>
        Nostr is an apolitical communication commons. A simple standard that defines a scalable
        architecture of clients and servers that can be used to spread information freely. Not
        controlled by any corporation or government, anyone can build on Nostr and anyone can use
        it.
        <img src="https://nostr.com/robots/nostr-robot.png" alt="Friendly robot">
      </p>
      
    </section>

    <!-- Screenshots -->
    <section>
      <!-- Terminal Mock -->
      

      <!-- Screenshot -->
      <img @click="window.open('https://coracle.social')" src="https://nostr.com/screenshots/coracle.png" title="the Coracle client">

      <!-- iframe -->
      

      <!-- iframe -->
      

      <!-- Screenshot -->
      <img @click="window.open('https://www.amethyst.social/')" src="https://nostr.com/screenshots/amethyst.png" title="the Amethyst client">

      <!-- Screenshot -->
      <img @click="window.open('https://yakihonne.com/yakihonne-mobile-app')" src="https://nostr.com/screenshots/yakihonne2.png" title="the Yakihonne client">

      <!-- Screenshot -->
      <img @click="window.open('https://nostur.com/')" src="https://nostr.com/screenshots/nostur.png" title="the Nostur client">
    </section>

    <!-- Integration Subtitle -->
    <section>
      <span>
        All Kinds of Stuff
      </span>
      <h2>
        Like the internet itself: open and chaotic
      </h2>
      <p>
        Nostr embraces the chaos of the early internet—multiple kinds of data, diverse forms of user
        interaction and different clients providing their own perspectives over the same underlying
        information.
      </p>
    </section>

    <!-- Innovation Card -->
    <div data-swap="cards">
        <div>
          <p><span>rebase</span>
          </p>
          <div>
            <h3>Many clients, many servers</h3>
            <p>
              The client is the app that is running on your computer or phone, the server is
              whatever is running on a cloud somewhere with a domain name. In centralized platforms
              and other protocols, one client talks to a single server. In Nostr clients connect to
              many.
            </p>
          </div>
        </div>
        <p><a href="https://newsletter.squishy.computer/p/natures-many-attempts-to-evolve-a" target="_blank">
          Learn how Nostr is different
          <span>›</span>
        </a>
      </p></div>

    <!-- Features Grid -->
    

    <!-- Cryptography Card -->
    <div data-swap="cards">
        <div>
          <p><span>signature</span>
          </p>
          <div>
            <h3>A new paradigm for communication</h3>
            <p>
              In Nostr, every user is represented by a secret number called a "key" and every
              message carries a digital "signature" that proves its authorship authorship and
              authenticity without the need for any authority to say so. This foundation of trust
              enables the decentralized broadcasting of information.
            </p>
          </div>
        </div>
        <p><a href="https://www.youtube.com/watch?v=GLluXpTRbqs&amp;t=169s" target="_blank">
          Watch a human-friendly explanation
          <span>›</span>
        </a>
      </p></div>

    <!-- Pro-censorship Section -->
    <div>
        <p><img :src="isDark ? '/robots/relayselection-dark.png' : '/robots/relayselection.png'"></p><div>
          <p><span>
            <span>shield</span> Pro-censorship
          </span></p><h2>
            The protocol is ownerless, relays are not
          </h2>
          <p>
            Nostr doesn't subscribe to political ideals of "free speech" — it simply recognizes that
            different people have different morals and preferences and each server, being privately
            owned, can follow their own criteria for rejecting content as they please and users are
            free to choose what to read and from where.
          </p>
          
          <div>
            <div>
              <div>
                <p>
                  handshake
                </p><p>
                Freedom of association
              </p></div>
              <p>
                When the network effect is not tied to a single organization a group of users cannot
                harm others.
              </p>
              <p><a href="https://www.youtube.com/watch?v=K5oXaW1EqbE" target="_blank">
                Watch <span>›</span>
              </a>
            </p></div>
            <div>
              <div>
                <p>
                  landscape_2
                </p><p>
                Your own piece of Nostr
              </p></div>
              <p>
                If you are a programmer or know how to run servers it is trivial to run your own
                relay with your own rules.
              </p>
              <p><a href="https://khatru.nostr.technology/" target="_blank">
                Write code <span>›</span>
              </a>
            </p></div>
          </div>
        </div>
      </div>

    <!-- Subprotocols Section -->
    <div>
        <p><img :src="isDark ? '/robots/feed-dark.png' : '/robots/feed.png'"></p><div>
          <p><span>
            <span>lightbulb_2</span> New Ideas
          </span></p><h2>Exploring the commons</h2>
          <p>
            Besides being a natural medium for a Twitter-like microblogging social network, Nostr
            can also be used for other purposes. And not only similar things like sharing
            <i>videos</i>, longform <i>articles</i>, <i>pictures</i> or <i>voice notes</i>. There
            are initiatives on Nostr for the development of sub-protocols that power
            <b>closed groups</b>, <b>decentralized wikipedia</b>, <b>couchsurfing</b>,
            <b>marketplaces</b> or <b>web annotations</b>; as well as protocols that don't use Nostr
            for the core data but as a coordination and discovery mechanism, such as
            <b>decentralized code collaboration using git</b>, <b>file hosting</b>,
            <b>torrent sharing</b> and <b>video livestreaming</b>.
          </p>
          <p><a href="https://github.com/nostr-protocol/nips" target="_blank">
            Browse the NIPs
          </a>
        </p></div>
      </div>

    <!-- Under Construction section -->
    <div>
        <p><img :src="isDark ? '/robots/underconstruction-dark.png' : '/robots/underconstruction.png'"></p><div>
          <p><span>
            <span>grass</span> Ecosystem
          </span></p><h2>Still under construction</h2>
          <p>
            Nostr is an idea with a lot of open-source software around it and a large userbase, but
            not a finished, polished product that you can buy without stress. We're still pretty
            much in the phase where new programmers and early adopters are needed to help us refine
            the protocol flows and the user experience.
          </p>
          

          <div>
            <div>
              
              <p>
                The so-called "outbox model" is the canonical way of implementing a
                censorship-resistant client, but its parameters are fluid.
              </p>
              <p><a href="https://github.com/coracle-social/how-to-nostr/blob/master/04-relays-are-repositories.md#the-outbox-model-and-friends" target="_blank">
                Learn about it <span>›</span>
              </a>
            </p></div>

            <div>
              
              <p>
                NIP-29 describes a way to do closed groups for forums or chat that can be very
                efficient by relying on a relay but are still censorship-resistant.
              </p>
              <p><a href="https://njump.me/naddr1qvzqqqr4gupzp978pfzrv6n9xhq5tvenl9e74pklmskh4xw6vxxyp3j8qkke3cezqqxnzde5xyersd33xscrwwfh5ekns6" target="_blank">
                Read the guide <span>›</span>
              </a>
            </p></div>
          </div>
        </div>
      </div>

    <!-- How Nostr Works -->
    <section>
      <span>
        <span>account_circle</span>
        Following
      </span>
      <h2>How Nostr works</h2>
      <p>
        Nostr enables true freedom by allowing users to stay connected to their audience even in
        adverse scenarios.
      </p>

      

      
    </section>

    <!-- FAQ Heading -->
    <section>
      <span>
        <span>contact_support</span>
        FAQ
      </span>
      <h2>I've got some questions!</h2>
      <p>
        It may sound like Nostr is very good, but what about these hard issues?
      </p>
    </section>

    <!-- FAQ Items -->
    <div>
        <!-- FAQ Item -->
        <details>
          <summary>
            What is a "protocol"?
          </summary>
          <div>
            <p>
              A protocol is like a common language that multiple different software can use to talk
              to each other, it's like <b>e-mail</b>, <b>HTML</b> or <b>HTTP</b>.
            </p>
            <p>
              When we say "protocol" we mean that there is no need to use a specific app in order to
              be in Nostr: there are many apps that talk the same language and can be used (mostly)
              interchangeably — and each has its own take on how to do and display things.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            How does Nostr handle spam and unwanted content?
          </summary>
          <div>
            <p>
              In the default feed you never see any spam, because clients will only fetch
              information from people that <i>you</i> follow. In that sense no one can "push" spam
              into you.
            </p>
            <p>
              It's trickier when you want to see, for example, replies to your posts, in that case a
              client might be programmed to fetch anything that <i>claims</i> to be a reply
              <i>from anyone</i>, which might include spam.
            </p>
            <p>
              The way we can deal with it on Nostr is by restricting our area of contact with the
              spam: for example, some clients may easily decide to only display replies that come
              from people followed by people you follow. More refined strategies involve announcing
              and then only reading notes from relays known to be "safe" according to your criteria
              (could be relays that require payment, relays that do screening for humans, relays
              that only accept members of certain communities or political affiliations etc).
            </p>
            <p>
              There are no perfect solutions. But these do not exist anywhere, centralized platforms
              are also full of spam. Nostr at least isn't naïve and tries to build resiliency from
              the start.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            Will Nostr scale effectively with massive user adoption?
          </summary>
          <div>
            <p>
              Yes, Nostr is just a basic client-server architecture. And the fact that users can
              naturally spread among hundreds of different relays while clients can query dozens of
              relays that they're interested in at the same time means the network has a natural
              load balancer (which doesn't prevent a single relay from having its own internal load
              balancer either).
            </p>
            <p>
              Another (almost the opposite) concern that may be raised is with problems arising from
              clients having to connect to too many relays if the profiles being followed for
              whatever reason decide to spread way too much, but this shouldn't be a problem either
              because people tend to follow many accounts with similar content and these will tend
              to share relays. Still, if it happens, it's cheap for native apps to open many
              hundreds of WebSocket connections simultaneously (as they will be getting very few
              data in each of those). For web apps that isn't so hard, but we can still go up to a
              few hundreds without big problems. Regardless of any of that, in any complete enough
              app that wants to display a "following feed" it's already necessary to store events in
              a local database, and that will make all these issues easy to deal with as you can do
              the event requests in batches instead of all at once.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            What protections does Nostr offer against online harassment?
          </summary>
          <div>
            <p>
              Harassment is similar to spam in the sense that anyone can still create the undesired
              content and publish to the relays that accept them. All the techniques mentioned in
              avoiding spam can also be applied in this case, but if we're talking about specific
              individuals with a permanent identity and not only an army of bots in this case the
              problem becomes easier, as those individuals can just be blocked by their target and
              their content will vanish. Presumably friends of such target will also block, and
              creative solutions involving shared blocklists can be created such that some people
              don't even have to click the block button directly.
            </p>
            <p>
              Other approaches involving, for example, relays with restricted read (that can emulate
              "protected account"/"only friends" features seen in centralized platforms) can further
              improve this.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            Why not just use Mastodon/Fediverse?
          </summary>
          <div>
            <p>
              There are many problems with Mastodon, mostly due to the fact that it doesn't rely on
              any cryptography. Because it cannot do the multi-master approach of Nostr due to lack
              of cryptography, identities are assumed to be "owned" by the server, which is fully
              trusted by its tenants. Mastodon server owners can do all the harm centralized
              platforms can do to their underlings, which are completely helpless in case of
              misbehavior or even in the normal case where a server owner loses their server or
              decides to shut down for whatever reason.
            </p>
            <p>
              Worse than that, for many of its purported features, such as blocking or direct
              messages, users have to also trust owners of the other servers.
            </p>
            <p>
              There are also problems with reliance on the DNS system, but we don't have to talk
              about those.
            </p>
            <p>
              The most interesting feature of Mastodon is that by its nature it creates communities
              with shared values that grow in each of its servers. Or, should I say, that should be
              a feature if it actually worked like that. In fact these are not really communities,
              but a mashup of users that may share some interests among each other, but also have
              other interests and those other interests end up polluting the supposed "community"
              with things that do not interest the other users.
            </p>
            <p>
              Nostr, on the other hand, can create real communities around relays, specifically
              because users don't have to fully belong to those relays, but can go to them only for
              some of their needs and go to other relays for other needs.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            Why not just use Bluesky/ATProto?
          </summary>
          <div>
            <p>Bluesky has many problems, the two most pronounced are:</p>
            <ol role="list">
              <li>
                Identity centralization: all accounts belong to <b>PLC</b>, a database ran by a
                central entity that can censor at will — or, alternatively, they can belong to a DNS
                domain, which is cumbersome, also censorable, risky and is not expected to be used
                by many anyway;
              </li>
              <li>
                Data centralization: because the <code>Relay-AppView-Client</code> flow assumes only
                one canonical source of data at each step (unlike Nostr multi-master architecture)
                that source is always a server that has power to censor, shadowban, reorder data and
                so on.
              </li>
            </ol>
            <p>
              <code>Clients</code> are assumed to be dumb and trust the <code>AppView</code>, and
              here you have room for all sorts of undesired shenanigans. Then AppViews also assume
              to source their data from a single <code>Relay</code>, and here you have room for the
              same effect.
            </p>
            <p>
              You could argue that Bluesky <code>Clients</code> could become smart and start
              sourcing data from multiple <code>AppViews</code>, or from multiple Relays, or that
              the <code>AppViews</code> could rely on multiple <code>Relays</code>, or that the
              <code>Clients</code> could talk directly to the <code>PDSes</code> — and all of that
              is possible and would indeed bring solutions, but notice that if those things started
              happening Bluesky would end up becoming Nostr, except with more steps.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            Are economic incentives aligned to keep relays operational?
          </summary>
          <div>
            <p>
              Yes,
              <a target="_blank" href="https://njump.me/nevent1qqsxstdgkge3k9mtezv4z4lpp88p3lnqta9k0k6n8hex0a4zv62pdmqzyqalp33lewf5vdq847t6te0wvnags0gs0mu72kz8938tn24wlfze6pfalk0">this clip</a>
              answers it well.
            </p>
            <p>
              But basically the answer is the same as the question about scale: if users can go to
              whatever relay they want we'll see relays ran by all sorts of people and entities.
              Running servers is very cheap, and a relay can run on a $5/mo server and house at
              least a few thousand users. It's not hard to imagine relays ran by communities,
              individuals who just want to be useful to others, big organizations wanting to gain
              good will with some parts of the public, but also companies, client makers, and, of
              course, dedicated entities who sell relay hosting for very cheap.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            If content is spread across multiple relays how can I be sure I'm seeing everything?
          </summary>
          <p>
              It's not a feature of the world at large to be able to see or hear everything that is
              happening everywhere at all times. Nostr inherits that property from the world, making
              it so that you can only see what you focus your attention on (and you're allowed to
              see by the relay that hosts that information).
            </p>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            How does search work?
          </summary>
          <div>
            <p>
              It's only possible to search on what you have seen, so search engines will always have
              to crawl some parts of the network they chose to and index those to enable public
              search. The word "chose" is employed because, as we know, there can't be a "global"
              view of the network (and no one would want such a thing anyway as it would be full of
              spam), so indexers have to choose. This is not different from Google deciding what
              websites to index.
            </p>
            <p>
              On the other hand, it's surprisingly doable for clients to store all the posts from
              people you follow, or all the posts you have seen or interacted with over time (since
              it's just text, a huge amount of notes can fit in the same space that would otherwise
              be required to store a single photo, for example) then provide local search over that.
              That kind of search will be sufficient for most of the cases you would reach out for a
              search bar in a centralized platform (which is to search for things that you have seen
              before), and perhaps even more useful since it would naturally filter out all the
              unrelated garbage.
            </p>
            <p>
              Last, niche or community-oriented relays can also provide very useful search
              capabilities by just indexing the notes they have stored locally, already filtered and
              scoped to that relay's topic or cohort (imagine searching over a Discord, Slack or
              Telegram group, for example).
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            How can I discover new content from people I don't already follow if there are no
            algorithms?
          </summary>
          <div>
            <p>
              The most basic way to do that is by following the natural habits used by most
              centralized social platforms users since a long time ago: by looking at the people you
              follow and whom they're interacting with.
            </p>
            <p>
              But also it's not true that Nostr doesn't have algorithms. Nostr can have algorithms
              of all kinds: manual, automatic, AI-powered or rule-based. Some of these algorithms
              can be run entirely locally on clients (for example, surfacing posts from the times
              when you were not online, or from people that make fewer posts), while other
              algorithms can be provided by all sorts of relays, either by naturally surfacing posts
              from a community of people you don't follow or by dedicated relays that have the
              stated purpose of curating content desirable for a target audience or even by
              targeting specific users.
            </p>
          </div>
        </details>

        <!-- FAQ Item -->
        <details>
          <summary>
            Is Nostr related to Bitcoin?
          </summary>
          <div>
            <p>
              Nostr uses the same cryptographic principles of Bitcoin and was kickstarted mostly by
              a community of Bitcoiners, so it has disproportionately attracted the attention of
              Bitcoiners at the start, but aside from that it doesn't have any relationship with
              Bitcoin. It doesn't depend on Bitcoin for anything and you don't have to know or have
              or care about any Bitcoin in order to use Nostr.
            </p>
            <p>
              What about "zaps"? Zaps are a standard for tipping Nostr content using Bitcoin that is
              implemented by some Nostr clients, but it's fully and completely optional and if you
              don't care about Bitcoin you don't have to bother about it.
            </p>
          </div>
        </details>
      </div>

    

    <!-- .com Services -->
    

    <!-- Quotations -->
    <div>
        <p><span>
          <span>speaker_notes</span>
          Opinion
        </span></p><h2>What people are saying</h2>
        <p>
          Quotes from those who know better and decided to like Nostr.
        </p>
      </div>

    <!-- Footer -->
    

    

    

    

    

    <!-- Key Generation Modal -->
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini in Chrome (173 pts)]]></title>
            <link>https://gemini.google/overview/gemini-in-chrome/</link>
            <guid>45297331</guid>
            <pubDate>Fri, 19 Sep 2025 02:25:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gemini.google/overview/gemini-in-chrome/">https://gemini.google/overview/gemini-in-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=45297331">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="root"><main id="main"><div id="hero" aria-label="Meet Gemini in Chrome"><h2>Her er <strong>Gemini</strong> i Chrome</h2><ul><li><a href="https://support.google.com/gemini?p=mws_gic_ga" rel="nofollow" data-tracking-event="{&quot;event&quot;:&quot;gemini_in_chrome_cta&quot;,&quot;eventParams&quot;:{&quot;buttonPosition&quot;:&quot;top&quot;}}"><p>Få flere oplysninger</p></a></li></ul></div><section id="help-thats-right-with-you" aria-label="Intelligens, der arbejder sammen med dig, lige der, hvor du er."><div><h2>Intelligens, der arbejder sammen med dig, lige der, hvor du er.</h2><p>Get key takeaways, clarify concepts, and find answers based on the context of your open tabs.</p></div><gemini-5050-accordion id="see-how-it-works"><div><mws-accordion data-mode="single"><mws-accordion-item id="see-how-it-works-drawer-0" open=""><div data-slot="accordion-item-content" id="see-how-it-works-drawer-0-content" role="region" aria-labelledby="see-how-it-works-drawer-0-trigger"><p>Har du brug for et overblik i en fart? Gemini leverer præcise opsummeringer af artikler, sider og tråde direkte i din browser, så du hurtigt får et overblik over hovedpunkterne.</p></div></mws-accordion-item><mws-accordion-item id="see-how-it-works-drawer-1"><div data-slot="accordion-item-content" id="see-how-it-works-drawer-1-content" role="region" aria-labelledby="see-how-it-works-drawer-1-trigger"><p>Have a question about what you're reading? Ask Gemini. It uses the context of your open tabs to provide relevant answers and explanations, keeping you focused.</p></div></mws-accordion-item><mws-accordion-item id="see-how-it-works-drawer-2"><div data-slot="accordion-item-content" id="see-how-it-works-drawer-2-content" role="region" aria-labelledby="see-how-it-works-drawer-2-trigger"><p>Gå ud over de simple forklaringer. Når du beskæftiger dig med komplekse emner eller nye koncepter, kan du bede Gemini om ikke bare at klarlægge forvirrende dele, men også om at hjælpe dig med at engagere dig aktivt i materialet.</p></div></mws-accordion-item><mws-accordion-item id="see-how-it-works-drawer-3"><div data-slot="accordion-item-content" id="see-how-it-works-drawer-3-content" role="region" aria-labelledby="see-how-it-works-drawer-3-trigger"><p>Undersøger du produkter, eller overvejer du forskellige valgmuligheder? Bed Gemini om at finde nøgleoplysninger, specifikationer og fordele og ulemper på siden, så du kan træffe velovervejede beslutninger på en nem og overskuelig måde.</p></div></mws-accordion-item><mws-accordion-item id="see-how-it-works-drawer-4"><div data-slot="accordion-item-content" id="see-how-it-works-drawer-4-content" role="region" aria-labelledby="see-how-it-works-drawer-4-trigger"><p>Vil du brainstorme, organisere dine tanker eller dykke dybere ned i et emne? Chat naturligt med Gemini Live, og få mundtlige svar – alt sammen i Chrome.</p></div></mws-accordion-item><mws-accordion-item id="see-how-it-works-drawer-5"><div data-slot="accordion-item-content" id="see-how-it-works-drawer-5-content" role="region" aria-labelledby="see-how-it-works-drawer-5-trigger"><p>Just like on your computer, Gemini on mobile is there to answer questions about what you’re reading. On Android it works with anything on your screen—including Chrome. And coming soon to iOS, Gemini will be built right into the Chrome app.</p></div></mws-accordion-item></mws-accordion></div></gemini-5050-accordion></section><section id="your-web-your-control" aria-label="Dit net, du bestemmer"><div><h2>Dit net, du bestemmer</h2><p>Gemini i Chrome arbejder sammen med dig på dine præmisser. Den hjælper kun, når du beder den om det, så du har kontrollen.</p></div><div data-num-cards="3"><div><h3>Altid klar</h3><p>Gemini i Chrome aktiveres kun, når du vælger det ved at klikke på Gemini-ikonet eller den tastaturgenvej, du har konfigureret. Den hjælper på dine præmisser og træder kun til, når du beder om det.</p></div><div><h3>Få hjælp på din måde</h3><p>Få hjælp på din måde med Gemini i Chrome. Sig eller skriv dit spørgsmål på en naturlig måde, og Gemini bruger sidens indhold til at give dig en forståelse af emnet eller udføre kedelige opgaver.</p></div></div></section><div id="" aria-label="Nettet på en ny måde"><h2>Nettet på en ny måde</h2><p>With Gemini in Chrome, no tab switching is needed with AI assistance right in your browser, helping you quickly understand content or get tasks done using the context of your open tabs.</p><ul><li><a href="https://support.google.com/gemini?p=mws_gic_ga" rel="nofollow" data-tracking-event="{&quot;event&quot;:&quot;gemini_in_chrome_cta&quot;,&quot;eventParams&quot;:{&quot;buttonPosition&quot;:&quot;bottom&quot;}}"><p>Få flere oplysninger</p></a></li></ul></div><div id="faqs" aria-labelledby="faqs-title" aria-label="Ofte stillede spørgsmål"><p><h2 id="faqs-title">Ofte stillede spørgsmål</h2></p><mws-accordion data-mode="multiple"><mws-accordion-item id="faqs-accordion-item-0"><div data-slot="accordion-item-content" id="faqs-accordion-item-0-content" role="region" aria-labelledby="faqs-accordion-item-0-trigger"><p>With the <a href="https://support.google.com/gemini?p=mws_gic_ga">Gemini in Chrome</a> feature, you can get AI assistance from your browser to do things easily like get key takeaways, clarify concepts, find answers and more. To provide the most relevant responses, Gemini in Chrome uses the context of your open tabs.&nbsp;</p><p>Gemini i Chrome er en del af Chrome-browseren på computer og er ikke det samme som at gå til Gemini i en browser på <a href="http://gemini.google.com/">gemini.google.com</a> eller starte en chat med Gemini-webappen ved at skrive @gemini i adresselinjen i Chrome. Du kan bruge Gemini-webappen i andre browsere (eller i indholdsområdet af Chrome), men du kan hverken dele sideindhold eller bruge Live-tilstand, som du kan med Gemini i Chrome.</p></div></mws-accordion-item><mws-accordion-item id="faqs-accordion-item-1"><div data-slot="accordion-item-content" id="faqs-accordion-item-1-content" role="region" aria-labelledby="faqs-accordion-item-1-trigger"><p>You can access <a href="https://support.google.com/gemini?p=mws_gic_ga">Gemini in Chrome</a> through the Gemini icon in the Chrome toolbar or via a keyboard shortcut that you set up on a Windows or Mac desktop.</p><p>You can also activate Gemini when using Chrome on Android, and other apps, by holding the power button. And starting soon, on iOS Gemini in Chrome will be built into the app, with access through the Chrome omnibox.</p></div></mws-accordion-item><mws-accordion-item id="faqs-accordion-item-2"><div data-slot="accordion-item-content" id="faqs-accordion-item-2-content" role="region" aria-labelledby="faqs-accordion-item-2-trigger"><p><a href="https://support.google.com/gemini?p=mws_gic_ga">Gemini in Chrome</a> is&nbsp;rolling out to all eligible Mac and Windows users&nbsp;in the US who have their Chrome language set to English. We look forward to bringing this feature to more people and additional languages soon.</p><p>Gemini in Chrome on iOS is coming soon to eligible iPhone users in the US who have their Chrome language set to English.</p></div></mws-accordion-item></mws-accordion></div><div id="disclaimers"><p>Check responses. Setup required. Compatibility and availability varies. 18+</p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playing “Minecraft” without Minecraft (2024) (103 pts)]]></title>
            <link>https://lenowo.org/viewtopic.php?t=5</link>
            <guid>45297258</guid>
            <pubDate>Fri, 19 Sep 2025 02:13:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lenowo.org/viewtopic.php?t=5">https://lenowo.org/viewtopic.php?t=5</a>, See on <a href="https://news.ycombinator.com/item?id=45297258">Hacker News</a></p>
Couldn't get https://lenowo.org/viewtopic.php?t=5: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[David Lynch LA House (172 pts)]]></title>
            <link>https://www.wallpaper.com/design-interiors/david-lynch-house-los-angeles-for-sale</link>
            <guid>45296638</guid>
            <pubDate>Fri, 19 Sep 2025 00:30:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wallpaper.com/design-interiors/david-lynch-house-los-angeles-for-sale">https://www.wallpaper.com/design-interiors/david-lynch-house-los-angeles-for-sale</a>, See on <a href="https://news.ycombinator.com/item?id=45296638">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p id="860c08d3-d800-4389-abae-f88720bbb782"><a data-analytics-id="inline-link" href="https://www.wallpaper.com/tag/david-lynch" data-before-rewrite-localise="https://www.wallpaper.com/tag/david-lynch">David Lynch</a>, the visionary American filmmaker behind Twin Peaks, Blue Velvet and Mulholland Dr, <a data-analytics-id="inline-link" href="https://www.wallpaper.com/art/remembering-david-lynch-obituary" data-before-rewrite-localise="https://www.wallpaper.com/art/remembering-david-lynch-obituary">passed away this January</a>, yet his creative universe endures in objects, spaces and ideas.</p><p>Among the most striking of these relics is his larger-than-life, meticulously designed Hollywood Hills home; a cinematic setting in its own right. Perched on a sweeping 2.3-acre hillside, David Lynch’s private compound, which is now listed for $15 million by Marc Silver of The Agency, unfolds like one of his own intricately plotted storylines. A showcase of <a data-analytics-id="inline-link" href="https://www.wallpaper.com/tag/midcentury-modern" data-before-rewrite-localise="https://www.wallpaper.com/tag/midcentury-modern">Mid-Century modern architecture</a>, the estate was conceived with the same care and cinematic precision that defined his work.</p><h2 id="inside-david-lynch-s-los-angeles-estate-3">Inside David Lynch's Los Angeles estate</h2><figure data-bordeaux-image-check="" id="30df4fdb-a214-4048-9ce4-bde64a5773d4"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1080-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1080-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1080-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-768-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1080-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1080-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1080-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-768-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/qZV29f7uwbajiGKRmUgbPZ.jpg">
</picture></p></div><p>(Image credit: @hellomarcsilver)</p></figure><p id="8ef1cd5a-194e-4f1f-bea4-126f834e0241">The property, set across five contiguous parcels, reads like a storyboard in relief: three main residences and several ancillary structures stepping down the hillside, each capturing a different note in Lynch’s creative oeuvre.</p><p>The story behind this compound started in 1987, when he acquired the pink-hued Beverly Johnson House designed in the early 1960s by Lloyd Wright, son of <a data-analytics-id="inline-link" href="https://www.wallpaper.com/tag/frank-lloyd-wright" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.wallpaper.com/tag/frank-lloyd-wright">Frank Lloyd Wright</a>. The home, in fact, was recognised by Historic Places LA as an exemplary work of Mid-Century Modern residential design. Then in 1991, he commissioned Eric Lloyd Wright (Lloyd Wright’s son) to add a pool and pool house, extending the Wright imprint on his property with a new generation.</p><figure data-bordeaux-image-check="" id="5f89dbe0-f906-4a1e-be64-38ae8424c085"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1080-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1080-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1080-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-768-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1080-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1080-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1080-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-768-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/PgcGNM2xyyeRmta3RN9UQZ.jpg">
</picture></p></div><p>(Image credit: @hellomarcsilver)</p></figure><figure data-bordeaux-image-check="" id="b1ae9c49-c048-4e87-ac49-e92aff8eaff9"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1080-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1080-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1080-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-768-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1080-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1080-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1080-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-768-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/XozxLsJH4VQ6t24iLAZEQZ.jpg">
</picture></p></div><p>(Image credit: @hellomarcsilver)</p></figure><p id="b316f11d-f378-468f-a833-6998bd623a63">Across the years, Lynch kept expanding the plotline: in 1989, he purchased an adjoining two-bedroom Brutalist house; in 1995, a studio building; and later, more pieces of land, ultimately shaping a seven-structure sanctuary with 10 bedrooms and 11 bathrooms spread over roughly 11,000 square feet. The result was a creative campus perched above the city.</p><figure data-bordeaux-image-check="" id="cffa9a99-7c14-4250-ab1f-a342aeecc04b"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1080-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1080-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1080-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-768-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1080-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1080-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1080-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-768-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/w2AFf2sL6TxLv6s5FJv3QZ.jpg">
</picture></p></div><p>(Image credit: @hellomarcsilver)</p></figure><p id="f022e7a7-f8e0-4648-975a-b2c9506a2a70">At the heart of the compound lies the architectural crescendo – the approximately 2,000 square feet home where light pours through generous windows and skylights to rake across organic textures and bold geometries. The facade’s cement chevrons catch the sun; inside, simple metalwork and natural woods are drenched in material honesty that often surfaced in Lynch’s films.</p><figure data-bordeaux-image-check="" id="ae17eeca-0a53-42f0-a89b-3a26b1ad4aee"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1080-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1080-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1080-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-768-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1080-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1080-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1080-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-768-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5kSfqfCHxxBSdi3KvCttPZ.jpg">
</picture></p></div><p>(Image credit: @hellomarcsilver)</p></figure><p id="8683a440-de58-4525-8d44-ffdcdd0ec56d">Two neighbouring addresses deepen the lore: 7029 Senalda served as the home of Asymmetrical Productions, while 7035 Senalda attained near-mythic status as both the Madison residence in the movie Lost Highway and Lynch’s own studio, complete with a library, screening room and editing suite – spaces where he refined major works, including Mulholland Drive.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-Jbf5ZvkntpGPfedcdaTi4Q"><section><p>Receive our daily digest of inspiration, escapism and design stories from around the world direct to your inbox.</p></section></div><figure data-bordeaux-image-check="" id="9f4bf3dd-9e96-457c-9728-e1fafe81c849"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-640-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/kVwxPkg4ysUpwi5wFipHUh.jpg">
</picture></p></div><p>(Image credit: @barrysloanestyle)</p></figure><figure data-bordeaux-image-check="" id="4ad4f7e6-6a68-4b60-b1c5-631efabd972f"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-640-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/gJmmjEKsTxBxrRsUSMcKUh.jpg">
</picture></p></div><p>(Image credit: @barrysloanestyle)</p></figure><p id="2a496d32-f12d-4fdc-8284-bb505506a735">Beyond the exemplary structures, Lynch left a personal handprint, collaborating on additional buildings: a sculptural two-storey guest house and a one-bedroom retreat finished in his favoured smooth grey plaster. Outdoors the terraces, courtyards and planted walkways offer a counterpoint to the intensity of production and everyday life.</p><figure data-bordeaux-image-check="" id="c8904453-ef00-402c-9cf2-4bfeb2affd00"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-640-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/c9upqcD7Een7evvLSwAEUh.jpg">
</picture></p></div><p>(Image credit: @barrysloanestyle)</p></figure><figure data-bordeaux-image-check="" id="55d32573-66d9-4857-913c-60f9185dcbd6"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-640-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/oxBq92T3bxFXv79eBWhMUh.jpg">
</picture></p></div><p>(Image credit: @barrysloanestyle)</p></figure><p id="32ad14fb-71e8-49a4-a2e6-b26b1209c6e5">As a listing note from The Agency suggests, this is a 'creative sanctuary and architectural landmark,' with provenance unlike any other in <a data-analytics-id="inline-link" href="https://www.wallpaper.com/tag/los-angeles" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.wallpaper.com/tag/los-angeles">Los Angeles</a>. For admirers of Lynch, it reads as both home and archive: a lived-in factory of ideas, meticulously composed and, at last, ready for its next act.</p><figure data-bordeaux-image-check="" id="a0e83742-6e9c-4b8a-ad5a-27ce3a13c1c6"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1080-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1080-80.jpg.webp 1600w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1080-80.jpg.webp 1280w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-768-80.jpg.webp 768w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-415-80.jpg.webp 415w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-360-80.jpg.webp 360w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-320-80.jpg.webp 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)">
<img src="https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh.jpg" alt="David Lynch house in LA" srcset="https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1080-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1080-80.jpg 1600w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1080-80.jpg 1280w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-768-80.jpg 768w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-415-80.jpg 415w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-360-80.jpg 360w, https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh-320-80.jpg 320w" sizes="(min-width: 710px) 670px, calc(100vw - 30px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/zEXqpshRP4DUtkUuvyoLUh.jpg">
</picture></p></div><p>(Image credit: @barrysloanestyle)</p></figure>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jimmy kimmel should have strong odds at the Supreme Court (109 pts)]]></title>
            <link>https://www.politico.com/news/magazine/2025/09/18/jimmy-kimmel-supreme-court-first-amendment-lawsuit-00570697</link>
            <guid>45296182</guid>
            <pubDate>Thu, 18 Sep 2025 23:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.com/news/magazine/2025/09/18/jimmy-kimmel-supreme-court-first-amendment-lawsuit-00570697">https://www.politico.com/news/magazine/2025/09/18/jimmy-kimmel-supreme-court-first-amendment-lawsuit-00570697</a>, See on <a href="https://news.ycombinator.com/item?id=45296182">Hacker News</a></p>
Couldn't get https://www.politico.com/news/magazine/2025/09/18/jimmy-kimmel-supreme-court-first-amendment-lawsuit-00570697: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Want to piss off your IT department? Are the links not malicious looking enough? (575 pts)]]></title>
            <link>https://phishyurl.com/</link>
            <guid>45295898</guid>
            <pubDate>Thu, 18 Sep 2025 22:40:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phishyurl.com/">https://phishyurl.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45295898">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <h4>What is this and what does it do?</h4>
                    <p>This is a tool that takes any link and makes it look malicious. It works on the idea of a <a href="https://en.wikipedia.org/wiki/URL_redirection" target="_blank">redirect</a>.
                        Much like <a href="https://tinyurl.com/" target="_blank">https://tinyurl.com/</a> for example.
                        Where tinyurl makes an url shorter, this site makes it look malicious.
                    </p>
                    <p>
                        Place any link in the below input, press the button and get back a fishy(phishy, heh...get, it?)
                        looking link.
                        The fishy link doesn't actually do anything, it will just redirect you to the original link you
                        provided.
                    </p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI tools are making the world look weird (116 pts)]]></title>
            <link>https://strat7.com/blogs/weird-in-weird-out/</link>
            <guid>45295794</guid>
            <pubDate>Thu, 18 Sep 2025 22:27:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://strat7.com/blogs/weird-in-weird-out/">https://strat7.com/blogs/weird-in-weird-out/</a>, See on <a href="https://news.ycombinator.com/item?id=45295794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="04147a8" data-element_type="widget" data-widget_type="text-editor.default"> <p>In academia and the media, AI is often described as mirroring human psychology with <a href="https://spectrum.ieee.org/chain-of-thought-prompting" target="_blank" rel="noopener"><span>humanlike reasoning</span></a>, <a href="https://www.psypost.org/ai-reaches-human-level-performance-on-general-intelligence-test-what-does-it-mean/" target="_blank" rel="noopener"><span>human-level performance</span></a>, <a href="https://www.theguardian.com/technology/2025/may/14/ai-can-spontaneously-develop-human-like-communication-study-finds" target="_blank" rel="noopener"><span>human-like communication</span></a>. In these comparisons, “humans” are treated as the benchmark.</p><p>In a provocative <a href="https://osf.io/preprints/psyarxiv/5b26t_v1" target="_blank" rel="noopener"><span>2023 paper</span></a>, researchers at Harvard University asked – which humans?</p><p>The diversity of human psychologies has been a hot topic since 2010, when researchers found that many accepted psychological “truths” were often confined to so-called “WEIRD people”: Western, Educated, Industrialised, Rich, Democratic. What feel like universal beliefs for people like me and no doubt many of the readers of this blog, e.g. that I am an automonous individual, are instead only true for a thin slice of humanity.</p><p>So when we say AI tools are “human-like”, what we mean is that AI is WEIRD.</p><p>In fact, this paper found that more than that, it thinks American. The greater the cultural distance between a country and the USA, the less accurate ChatGPT got at simulating peoples’ values. For countries like Libya and Pakistan, AI results are little better than a coin toss.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta's live staged demo fails; the "AI" recording plays before the actor acts (406 pts)]]></title>
            <link>https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/</link>
            <guid>45294859</guid>
            <pubDate>Thu, 18 Sep 2025 20:50:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/">https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/</a>, See on <a href="https://news.ycombinator.com/item?id=45294859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="siteTable_t3_1nkbig7"><div id="thing_t1_newl6dz" onclick="click_thing(this)" data-fullname="t1_newl6dz" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Rorviver" data-author-fullname="t2_69ucetcs" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newl6dz/"><div id="thing_t1_nex0x4h" onclick="click_thing(this)" data-fullname="t1_nex0x4h" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Tormint_mp3" data-author-fullname="t2_kwtzdtb0" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nex0x4h/"><p>[–]<a href="https://old.reddit.com/user/systemhost">systemhost</a><span></span> <span title="3">3 points</span><span title="4">4 points</span><span title="5">5 points</span> <time title="Thu Sep 18 18:57:12 2025 UTC" datetime="2025-09-18T18:57:12+00:00">3 hours ago</time>&nbsp;(1 child)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexqyinty2"><div><p>Meta Ray-Ban Glasses?</p>

<p>I don't use Instagram or Facebook but I've seen videos recorded on them trickling down to Reddit. It is a nifty way to do POV recording without a silly looking camera strapped to your head. </p>

<p>Seems the video and especially audio quality could use some improvements but it's still amazing tech for the packaging.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexqyin/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nex0x4h" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nexkcu2" onclick="click_thing(this)" data-fullname="t1_nexkcu2" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Silent-Hyena9442" data-author-fullname="t2_82e9vusx" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexkcu2/"><p>[–]<a href="https://old.reddit.com/user/Any_Potato_7716">Any_Potato_7716</a><span></span> <span title="1">1 point</span><span title="2">2 points</span><span title="3">3 points</span> <time title="Thu Sep 18 18:33:37 2025 UTC" datetime="2025-09-18T18:33:37+00:00">3 hours ago</time><time title="last edited 1 hour ago" datetime="2025-09-18T20:48:34+00:00">*</time>&nbsp;(2 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexm1cybw4"><div><p>I don’t really have any distrust of Apple nor Samsung themselves stealing my data. </p>

<p>I do with certain apps for sure, but not with my phone by itself.</p>

<p>If my phone was made by Facebook or Google, i’d certainly believe it’d be siphoning every bit of my data it could by itself. They have a long history of selling off every bit of your privacy. </p>

<p>That’s why I’m not gonna trust these Facebook glasses. </p>

<p>It’s not the phones that are the problem. It’s the apps, and the companies running them.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexm1cy/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nexkcu2" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div></div><div id="thing_t1_newlebx" onclick="click_thing(this)" data-fullname="t1_newlebx" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Eienkei" data-author-fullname="t2_128k9d" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newlebx/"><p>[–]<a href="https://old.reddit.com/user/ChawulsBawkley">ChawulsBawkley</a><span></span> <span title="165">165 points</span><span title="166">166 points</span><span title="167">167 points</span> <time title="Thu Sep 18 16:16:52 2025 UTC" datetime="2025-09-18T16:16:52+00:00">6 hours ago</time>&nbsp;(23 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_newt4u1a9g"><div><p>Reminds me of some of those “real gameplay” demonstrations for game announcements. The dialogue between the co-op players was always unbearable. </p>

<p>It’s time to get serious guys, let’s bring in the heavy artillery! </p>

<p>It’s too quiet. Stay frosty Steve!</p>

<p>Woah there Tyler! Calm down! Save some of the action for me!</p>

<p>Not actual quotes, but just examples. What was that one that was absolutely terrible… Anthem or something?</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newt4u1/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#newlebx" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_newnn31" onclick="click_thing(this)" data-fullname="t1_newnn31" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="reffob" data-author-fullname="t2_ym61l" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newnn31/"><div id="thing_t1_nexn1j6" onclick="click_thing(this)" data-fullname="t1_nexn1j6" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="bs000" data-author-fullname="t2_562jk" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexn1j6/"><p>[–]<a href="https://old.reddit.com/user/bs000">bs000</a><span></span> <span title="10">10 points</span><span title="11">11 points</span><span title="12">12 points</span> <time title="Thu Sep 18 18:38:30 2025 UTC" datetime="2025-09-18T18:38:30+00:00">3 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexn1j6jm5"><div><p>Watch the video again.</p>

<p>"You've already combined the base ingredients, so now grate a pear to add to the sauce."</p>

<p>"You've already combined the base ingredients, so now grate the pear and gently combine it with the base sauce."</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexn1j6/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nex3vmc" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nexod2q" onclick="click_thing(this)" data-fullname="t1_nexod2q" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="thefpspower" data-author-fullname="t2_glpw94" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexod2q/"><p>[–]<a href="https://old.reddit.com/user/thefpspower">thefpspower</a><span></span> <span title="1">1 point</span><span title="2">2 points</span><span title="3">3 points</span> <time title="Thu Sep 18 18:44:50 2025 UTC" datetime="2025-09-18T18:44:50+00:00">3 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexod2qru9"><div><blockquote>
<p>AIs don't normally use the exact same responses if they get asked the same question more than once.&nbsp;</p>
</blockquote>

<p>In my experience that's false, I've had multiple situations where I ask a question, it answers, then I ask a similar question but with aditional details and the response sometimes is exactly the same because it keeps using the same context.</p>

<p>When that happens I have to start a new chat because nothing I say next gets a proper answer.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexod2q/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nex3vmc" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div></div><div id="thing_t1_newmlrl" onclick="click_thing(this)" data-fullname="t1_newmlrl" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="SmoogzZ" data-author-fullname="t2_5bwb2n6l" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newmlrl/"><div id="thing_t1_newqtp6" onclick="click_thing(this)" data-fullname="t1_newqtp6" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Pervasivepeach" data-author-fullname="t2_g27hl" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newqtp6/"><div><p>[–]<a href="https://old.reddit.com/user/Pervasivepeach">Pervasivepeach</a><span></span> <span title="39">39 points</span><span title="40">40 points</span><span title="41">41 points</span> <time title="Thu Sep 18 16:05:46 2025 UTC" datetime="2025-09-18T16:05:46+00:00">6 hours ago</time>&nbsp;(8 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_newqtp6nfq"><div><p>These kinds of issues are funny, but the ai bubble isn’t going anywhere, not when it’s become the modern day arms race between China and the US. Who both see ai as a necessity to stay economically competitive </p>

<p>Meta just dropped 20 billion on a brand new data center purely for ai, openAI are investing 500 billion over the next 4 years. And AI is at the cusp of being able to self improve, to the point where nobody is saying it won’t happen, the arguments just when it will happen.</p>

<p>I despise ai like everyone else. But it’s naive to think it’s going to go away on its own, not without constant pushback.</p>

<p>And it’s only going to get so much worse</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newqtp6/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#newmlrl" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="siteTable_t1_newqtp6"><div id="thing_t1_nexeaqa" onclick="click_thing(this)" data-fullname="t1_nexeaqa" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="seagulls51" data-author-fullname="t2_e5eba" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexeaqa/"><p>[–]<a href="https://old.reddit.com/user/Pervasivepeach">Pervasivepeach</a><span></span> <span title="3">3 points</span><span title="4">4 points</span><span title="5">5 points</span> <time title="Thu Sep 18 19:30:21 2025 UTC" datetime="2025-09-18T19:30:21+00:00">2 hours ago</time><time title="last edited 2 hours ago" datetime="2025-09-18T19:39:01+00:00">*</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexxu3c9q9"><div><p>But ai isn’t just some startup craze like the .com bubble was. It has a lot more in common with the nuclear arms race of the Cold War. Right now ai is being pushed by the two major world superpowers not as a product, but as a means of defense and economic warfare. The US doesn’t care how many students use ChatGPT to cheat on homework. They care about its ability to decrypt nuclear launch codes. </p>

<p>For context the US government has invested over 300 billion in AI. In addition to 20+ billion from Facebook, 500 billion from open AI, 30 billion from Microsoft. I can go on forever. And none of this is including China who’s invested very similar numbers. We are talking trillions now. At its most the .com bubble was in the 300 billion range. </p>

<p>It isn’t about the bubble, or consumer use anymore, or even profits. It’s about having a smarter Ai Than China for defense. The department of defense is currently the biggest support of AI In the world, since they are responsible for 72% of the 300+ billion from the US. And they will continue spending.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexxu3c/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nexeaqa" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nex3m0f" onclick="click_thing(this)" data-fullname="t1_nex3m0f" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Informal_Tennis8599" data-author-fullname="t2_1gcdwu7num" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nex3m0f/"><p>[–]<a href="https://old.reddit.com/user/Pervasivepeach">Pervasivepeach</a><span></span> <span title="2">2 points</span><span title="3">3 points</span><span title="4">4 points</span> <time title="Thu Sep 18 19:31:23 2025 UTC" datetime="2025-09-18T19:31:23+00:00">2 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexy1qeuez"><div><p>The point is the discussion has gone from “is this possible” to “how long”</p>

<p>Yes the debate for how long is up in air all the time, but even the biggest ai skeptics are no longer saying “it won’t happen”</p>

<p>That’s what’s scary</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexy1qe/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nex3m0f" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div></div></div><div id="thing_t1_nexhz2e" onclick="click_thing(this)" data-fullname="t1_nexhz2e" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Colley619" data-author-fullname="t2_cp4nx" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexhz2e/"><p>[–]<a href="https://old.reddit.com/user/Colley619">Colley619</a><span></span> <span title="1">1 point</span><span title="2">2 points</span><span title="3">3 points</span> <time title="Thu Sep 18 18:14:02 2025 UTC" datetime="2025-09-18T18:14:02+00:00">4 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexhz2e2l5"><div><p>All that's popping is peoples perceptions of current "AI" and maybe realizing that current "AI" is not real artificial intelligence, it's just advanced search algorithms and advanced emulation tools. Key word <strong>emulation</strong>.</p>

<p>AI is a fancy buzzword that does not best describe these tools, and despite them not working how people think, they ARE still revolutionizing various industries by how they <strong>actually</strong> work.</p>

<p>I am bullish on current "AI" as a whole when used correctly, I am bearish on platforms trying to use them incorrectly.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexhz2e/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#newmlrl" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div></div><div id="thing_t1_newqki3" onclick="click_thing(this)" data-fullname="t1_newqki3" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="Remic75" data-author-fullname="t2_1736xx" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newqki3/"><p>[–]<a href="https://old.reddit.com/user/Remic75">Remic75</a><span></span> <span title="20">20 points</span><span title="21">21 points</span><span title="22">22 points</span> <time title="Thu Sep 18 16:04:32 2025 UTC" datetime="2025-09-18T16:04:32+00:00">6 hours ago</time><time title="last edited 6 hours ago" datetime="2025-09-18T16:14:27+00:00">*</time>&nbsp;(9 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_newqki3aoi"><div><p>Looking at it, the guy likely went off script.</p>

<p>AI said "I love the setup you have, I SEE that you have soy sauce and others"</p>

<p>I think he was supposed to say something like "What can I make with this? Maybe something Korean inspired" or similar. Reason why I think this is because he asked Meta the question and Meta basically responded back with redundancy (look at what he had on the table and what the AI was saying) or it was doing a general search and not waiting for its “cue”. He knew he messed up which is why he immediately interrupted the AI to go to the next step. He likely said something off script which didn't make sense in the sequence.</p>

<p>But the problem was, the AI likely included what to do to prepare FIRST with the dialogue it was giving, but he interrupted. The script got confused because the scripted dialogue was just following what it was told. This guy bumped it off of alignment.</p>

<p>Could've likely been first time jitters, or stage fright. Regardless, bad demo.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/newqki3/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nexrlf3" onclick="click_thing(this)" data-fullname="t1_nexrlf3" data-type="comment" data-gildings="0" data-subreddit="LivestreamFail" data-subreddit-prefixed="r/LivestreamFail" data-subreddit-fullname="t5_38jf0" data-subreddit-type="public" data-author="OdinsOneG00dEye" data-author-fullname="t2_8tcci8eb" data-replies="0" data-permalink="/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexrlf3/"><p>[–]<a href="https://old.reddit.com/user/OdinsOneG00dEye">OdinsOneG00dEye</a><span></span> <span title="0">0 points</span><span title="1">1 point</span><span title="2">2 points</span> <time title="Thu Sep 18 19:00:12 2025 UTC" datetime="2025-09-18T19:00:12+00:00">3 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nexrlf3fz8"><div><p>He’s a non technical person I believe so like my parents - the WiFi being messed up is a go to thing to say for what can be a range of issues with actual hardware. </p>

<p>He’s done his best to end the demo and hand over preventing further cringe - good job on that front. </p>

<p>The self awareness meme from this should be putting one those glasses and asking “what do I do first?” - be nice to see some self deprecating humour from a tech giant company, this is some Apple would never do allowing Meta a more human touch to exist in their marketing of this device / service once released</p>
</div></form><ul><li><a href="https://old.reddit.com/r/LivestreamFail/comments/1nkbig7/metas_live_staged_demo_fails_the_ai_recording/nexrlf3/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple: SSH and FileVault (387 pts)]]></title>
            <link>https://keith.github.io/xcode-man-pages/apple_ssh_and_filevault.7.html</link>
            <guid>45294440</guid>
            <pubDate>Thu, 18 Sep 2025 20:15:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keith.github.io/xcode-man-pages/apple_ssh_and_filevault.7.html">https://keith.github.io/xcode-man-pages/apple_ssh_and_filevault.7.html</a>, See on <a href="https://news.ycombinator.com/item?id=45294440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<section>
<h2 id="NAME"><a href="#NAME">NAME</a></h2>
<p><code>apple_ssh_and_filevault</code> —
    <span>SSH and FileVault</span></p>
</section>
<section>
<h2 id="DESCRIPTION"><a href="#DESCRIPTION">DESCRIPTION</a></h2>
<p>When FileVault is enabled, the data volume is locked and
    unavailable during and after booting, until an account has been
    authenticated using a password. The macOS version of OpenSSH stores all of
    its configuration files, both system-wide and per-account, in the data
    volume. Therefore, the usually configured authentication methods and shell
    access are not available during this time. However, when Remote Login is
    enabled, it is possible to perform password authentication using SSH even in
    this situation. This can be used to unlock the data volume remotely over the
    network. However, it does not immediately permit an SSH session. Instead,
    once the data volume has been unlocked using this method, macOS will
    disconnect SSH briefly while it completes mounting the data volume and
    starting the remaining services dependent on it. Thereafter, SSH (and other
    enabled services) are fully available.</p>
</section>
<section>
<h2 id="HISTORY"><a href="#HISTORY">HISTORY</a></h2>
<p>The capability to unlock the data volume over SSH appeared in
    macOS 26 Tahoe.</p>
</section>
<section>
<h2 id="SEE_ALSO"><a href="#SEE_ALSO">SEE
  ALSO</a></h2>
<p><a>sshd(8)</a></p>
</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[President Says Broadcasters Should Lose Licenses for Criticizing Him (131 pts)]]></title>
            <link>https://www.nytimes.com/live/2025/09/18/us/trump-news</link>
            <guid>45294199</guid>
            <pubDate>Thu, 18 Sep 2025 19:54:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/live/2025/09/18/us/trump-news">https://www.nytimes.com/live/2025/09/18/us/trump-news</a>, See on <a href="https://news.ycombinator.com/item?id=45294199">Hacker News</a></p>
Couldn't get https://www.nytimes.com/live/2025/09/18/us/trump-news: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. already has the critical minerals it needs, according to new analysis (161 pts)]]></title>
            <link>https://www.minesnewsroom.com/news/us-already-has-critical-minerals-it-needs-theyre-being-thrown-away-new-analysis-shows</link>
            <guid>45294058</guid>
            <pubDate>Thu, 18 Sep 2025 19:41:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.minesnewsroom.com/news/us-already-has-critical-minerals-it-needs-theyre-being-thrown-away-new-analysis-shows">https://www.minesnewsroom.com/news/us-already-has-critical-minerals-it-needs-theyre-being-thrown-away-new-analysis-shows</a>, See on <a href="https://news.ycombinator.com/item?id=45294058">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      


            
      
            <p>In new Science article, Colorado School of Mines researchers call for more research, development and policy to increase critical mineral recovery</p>
      </div><div>
      
            <p>Colorado's Climax Mine, which produces produces approximately 30 million pounds of molybdenum every year, was among the U.S. mining operations evaluated in the critical minerals analysis published today in the journal Science.</p>
      
  </div><div><p>All the critical minerals the U.S. needs annually for energy, defense and technology applications are already being mined at existing U.S. facilities, according to a <a href="http://www.science.org/doi/10.1126/science.adw8977">new analysis published today</a> in the journal <em>Science</em>.</p><p>The catch? These minerals, such as cobalt, lithium, gallium and rare earth elements like neodymium and yttrium, are currently being discarded as tailings of other mineral streams like gold and zinc, said Elizabeth Holley, associate professor of <a href="https://mining.mines.edu/">mining engineering at Colorado School of Mines</a> and lead author of the new paper.</p><p>"The challenge lies in recovery," Holley said. "It's like getting salt out of bread dough – we need to do a lot more research, development and policy to make the recovery of these critical minerals economically feasible."</p><p>To conduct the analysis, Holley and her team built a database of annual production from federally permitted metal mines in the U.S. They used a statistical resampling technique to pair these data with the geochemical concentrations of critical minerals in ores, recently compiled by the <a href="https://usgs.gov/">U.S. Geological Survey</a>, Geoscience Australia and the Geologic Survey of Canada.</p><p>Using this approach, Holley’s team was able to estimate the quantities of critical minerals being mined and processed every year at U.S. metal mines but not being recovered. Instead, these valuable minerals are ending up as discarded tailings that must be stored and monitored to prevent environmental contamination.</p><p>“This is a brand-new view of ‘low hanging fruit’ – we show where each critical mineral exists and the sites at which even 1 percent recovery of a particular critical mineral could make a huge difference, in many cases dramatically reducing or even eliminating the need to import that mineral,” Holley said.</p><p>The analysis in <em>Science</em> looks at a total of 70 elements used in applications ranging from consumer electronics like cell phones to medical devices to satellites to renewable energy to fighter jets and shows that unrecovered byproducts from other U.S. mines could meet the demand for all but two – platinum and palladium.</p><p>Among the elements included in the analysis are:</p><ul><li><strong>Cobalt (Co): </strong>The lustrous bluish-gray metal, a key component in electric car batteries, is a byproduct of nickel and copper mining. Recovering less than 10 percent of the cobalt currently being mined and processed but not recovered would be more than enough to fuel the entire U.S. battery market.</li><li><strong>Germanium (Ge):</strong> The brittle silvery-white semi-metal used for electronics and infrared optics, including sensors on missiles and defense satellites, is present in zinc and molybdenum mines. If the U.S. recovered less than 1 percent of the germanium currently mined and processed but not recovered from U.S. mines, it would not have to import any germanium to meet industry needs.</li></ul><p>The benefits of enhanced recovery are not only economic and geopolitical but also environmental, Holley said – recovering these critical minerals instead of sending them to tailings piles would reduce the environmental impact of mine waste and open more opportunities for reuse in construction and other industries.</p><p>“Now that we know which sites are low-hanging fruit, we need to conduct detailed analyses of the minerals in which these chemical elements reside and then test the technologies suitable for recovery of those elements from those specific minerals,” Holley said. “We also need policies that incentivize mine operators to incorporate additional processing infrastructure. Although these elements are needed, their market value may not be sufficient to motivate operators to invest in new equipment and processes without the right policies in place.”</p><p>Co-authors on the paper are Karlie Hadden, PhD candidate in <a href="https://geology.mines.edu/">geology</a>; Dorit Hammerling, associate professor of <a href="https://ams.mines.edu/">applied mathematics and statistics</a>; Rod Eggert, research professor of <a href="https://econbus.mines.edu/">economics and business</a>; Erik Spiller, research professor of mining engineering; and Priscilla Nelson, professor of mining engineering.</p><p>Read the full paper, <a href="http://www.science.org/doi/10.1126/science.adw8997">"Byproduct recovery from US metal mines could reduce import reliance for critical minerals,"</a> on the <em>Science</em> website. To access the data and figures before the paper appears in print, contact Mines Media Relations Specialist Erich Kirshner at <a href="mailto:erich.kirshner@mines.edu">erich.kirshner@mines.edu</a>.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When Knowing Someone at Meta Is the Only Way to Break Out of "Content Jail" (277 pts)]]></title>
            <link>https://www.eff.org/pages/when-knowing-someone-meta-only-way-break-out-content-jail</link>
            <guid>45293273</guid>
            <pubDate>Thu, 18 Sep 2025 18:30:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/pages/when-knowing-someone-meta-only-way-break-out-content-jail">https://www.eff.org/pages/when-knowing-someone-meta-only-way-break-out-content-jail</a>, See on <a href="https://news.ycombinator.com/item?id=45293273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><strong>BY&nbsp;<a href="https://www.eff.org/about/staff/rindala-alajaji" target="_blank" rel="noopener noreferrer">RINDALA ALAJAJI</a></strong> | September 17, 2025</p>
<p><i><span>This is the second instalment in a ten-part blog series documenting EFF's findings from the </span></i><a href="https://www.eff.org/deeplinks/2025/02/stop-censoring-abortion-fight-reproductive-rights-digital-age"><i><span>Stop Censoring Abortion</span></i></a><i><span> campaign. You can read additional posts </span></i><a href="https://www.eff.org/pages/stop-censoring-abortion"><i><span>here</span></i></a><i><span>.</span></i><span>&nbsp;</span></p>
<p><span>During our </span><a href="https://www.eff.org/pages/stop-censoring-abortion"><span>Stop Censoring Abortion</span></a><span> campaign, we set out to collect and spotlight the growing number of stories from people and organizations that have had abortion-related content removed, suppressed, or flagged by dominant social media platforms. Our survey submissions have revealed some alarming trends, including: </span><b>if you don’t have a personal or second-degree connection at Meta, your chances of restoring your content or account are likely to drop significantly.&nbsp;</b></p>
<p><span>Through the survey, we heard from activists, clinics, and researchers whose accounts were suspended or permanently removed for allegedly violating Meta’s </span><a href="https://transparency.meta.com/policies/community-standards/restricted-goods-services/"><span>policies on promoting or selling “restricted goods,”</span></a><span> even when their posts were purely educational or informational. What the submissions also showed is a pattern of overenforcement, lack of transparency, and arbitrary moderation decisions that have specifically affected reproductive health and reproductive justice advocates.&nbsp;</span></p>
<p><span>When accounts are taken down, appeals can take days, weeks, or even months (if they're even resolved at all, or if users are even given the option to appeal). For organizations and providers, this means losing access to vital communication tools and being cut off from the communities they serve. This is highly damaging since so much of that interaction happens on Meta’s platforms. Yet we saw a disturbing pattern emerge in our survey: on several occasions, accounts are swiftly restored once someone with a connection to Meta intervenes.</span></p>
<h2><b>The</b> <b>Case Studies: An Abortion Clinic</b></h2>
<p><a href="https://www.redriverwomensclinic.com/"><span>The Red River Women's Clinic</span></a><span> is an abortion clinic in Moorhead, MN. It was originally located in Fargo, North Dakota, and for many years was the only abortion clinic in North Dakota. In early January, the clinic’s director heard from a patient that she thought they only offered procedural/surgical abortions and not medication abortion. To clarify for other patients, they posted on the clinic’s page that they offered both procedural and medication abortions—attaching an image of a box of mifepristone. When they tried to boost the post, the ad was flagged and their account was suspended.</span></p>
<p><span>They appealed the decision and initially got the ad approved, yet the page was suspended again shortly after. But this time, multiple appeals and direct emails went unanswered,&nbsp;</span><span>until they reached out to a digital rights organization that</span><span>&nbsp;was able to connect with staff at Meta that stepped in. Only then was their page restored, with Meta noting that their post did not violate the policies but warning that future violations could lead to permanent removal.</span></p>
<p><span>While this may have been a glitch in Meta’s systems or a misapplication of policy, the suspension of the clinic’s Facebook account was detrimental for them. “We were unable to update our followers about dates/times we were closed, we were unable to share important information and news about abortion that would have kept our followers up to date, there was a legislative session happening and we were unable to share events and timely asks for reaching out to legislators about issues,” shared Tammi Kromenaker, Director of Red River Women's Clinic. The clinic was also prevented from starting an Instagram page due to the suspension. “Facebook has a certain audience and Instagram has another audience,” said Kromenaker, “we are trying to cater to all of our supporters so the loss of FB and the inability to access and start an Instagram account were really troubling to us.”&nbsp;</span></p>
<h2><b>The Case Studies: RISE at Emory University</b></h2>
<p><a href="https://rise.emory.edu/"><span>RISE, a reproductive health research center at Emory University</span></a><span>, launched an Instagram account to share community-centered research and combat misinformation related to reproductive health. In January of this year, they posted educational content about mifepristone on their instagram. “Let's talk about Mifepristone + its uses + the importance of access”, read the post. Two months later, their account was suddenly suspended, flagging the account under its policy against selling illegal drugs. Their appeal was denied, which led to the account being permanently deleted.&nbsp;</span></p>
<div><p><img src="https://www.eff.org/files/2025/09/12/screenshot_2025-09-12_at_12.26.09_pm_0.png" width="1272" height="820" alt="A screenshot of an instagram post from @emory.rise that reads &quot;let's talk about mifepristone&quot; in bold black font &quot;+ its uses + the importance of access&quot; in blue" title="A screenshot of an instagram post from @emory.rise that reads &quot;let's talk about mifepristone&quot; in bold black font &quot;+ its uses + the importance of access&quot; in blue"></p><p>Screenshot submitted by RISE to EFF</p></div>
<p><span>“As a team, this was a hit to our morale” shared Sara Redd, Director of Research Translation at </span><i><span>RISE</span></i><span>. “We pour countless hours of person-power, creativity, and passion into creating the content we have on our page, and having it vanish virtually overnight took a toll on our team.” For many organizational users like RISE, their social media accounts are a repository for resources and metrics that may not be stored elsewhere. “We spent a significant amount of already-constrained team capacity attempting to recover all of the content we’d created for Instagram that was potentially going to be permanently lost. [...] We also spent a significant amount of time and energy trying to understand what options we might have available from Meta to appeal our case and/or recover our account; their support options are not easily accessible, and the time it took to navigate this issue distracted from our existing work.”&nbsp;&nbsp;</span></p>
<p><span>Meta restored the account only after RISE was able to connect with someone there. Once RISE logged back in, they confirmed that the flagged post was the one about mifepristone. The post never sold or directed people where to buy pills, it simply provided accurate information about the use and efficacy of the drug.&nbsp;</span></p>
<h2><b>This Shouldn’t Be How Content Moderation Works</b></h2>
<p><span>Meta spokespersons have admitted to instances of “overenforcement” </span><a href="https://www.theverge.com/2025/1/24/24350967/metas-instagram-facebook-abortion-access-information-blocking-banning"><span>in various</span></a> <a href="https://www.tortoisemedia.com/2025/01/27/abortion-pill-information-censored-online-1"><span>press statements</span></a><span>, noting that content is sometimes incorrectly removed or blurred even when it doesn’t actually violate policy. Meta has insisted to the public that they care about free speech, as a spokesperson mentioned </span><a href="https://www.nytimes.com/2024/06/11/business/abortion-groups-tech-platforms.html"><span>to The New York Times</span></a><span>: “We want our platforms to be a place where people can access reliable information about health services, advertisers can promote health services and everyone can discuss and debate public policies in this space [...] That’s why we allow posts and ads about, discussing and debating abortion.” In fact, </span><a href="https://www.facebook.com/business/help/263390265553560?id=434838534925385"><span>their platform policies directly mention this</span></a><span>:&nbsp;</span></p>
<blockquote><p><i><span>Note that advertisers don’t need authorization to run ads that only:</span></i></p>
<ul>
<li><i><span>Educate, advocate or give public service announcements related to prescription drugs</span></i></li>
</ul>
</blockquote>
<p><a href="https://transparency.meta.com/policies/community-standards/restricted-goods-services/"><span>Additionally</span></a><span>:&nbsp;</span></p>
<blockquote><p><i><span>Note: Debating or advocating for the legality or discussing scientific or medical merits of prescription drugs is allowed. This includes news and public service announcements.&nbsp;</span></i></p>
</blockquote>
<p><span>Meta also has policies specific to “</span><a href="https://transparency.meta.com/policies/ad-standards/restricted-goods-services/health-wellness"><span>Health and Wellness,</span></a><span>” where they state:&nbsp;</span></p>
<blockquote><p><i><span>When targeting people 18 years or older, advertisers can run ads that:</span></i></p>
<ul>
<li><i><span>Promote sexual and reproductive health and wellness products or services, as long as the focus is on health and the medical efficacy of the product or the service and not on the sexual pleasure or enhancement. And these ads must target people 18 years or older. This includes ads for: [...]</span></i></li>
<li><span>Family planning methods, such as:</span>
<ul>
<li><span>Family planning clinics</span></li>
<li><span>In Vitro Fertilization (IVF) or any other artificial insemination procedures</span></li>
<li><span>Fertility awareness</span></li>
<li><strong>Abortion medical consultation and related services</strong></li>
</ul>
</li>
</ul>
</blockquote>
<p><span>But these public commitments don’t always match users’ experiences.&nbsp;</span></p>
<p><span>Take the </span><a href="https://www.nytimes.com/2025/01/23/technology/instagram-facebook-abortion-pill-providers.html"><span>widely</span></a> <a href="https://jessica.substack.com/p/instagram-is-censoring-abortion-pill"><span>covered</span></a><span> case of </span><a href="https://aidaccess.org/en/"><span>Aid Access</span></a><span>, a group that provides medication abortion by mail. This year, several of their Instagram posts were blurred and removed on Instagram, including one with tips for feeling safe and supported at home after taking abortion medication. But only after multiple national media outlets contacted Meta for comment on the story were the posts and account restored.</span></p>
<p><span>So the question becomes: If Meta admits its enforcement isn’t perfect, why does it still take knowing someone, or having the media involved, to get a fair review? When companies like Meta claim to uphold </span><a href="https://about.fb.com/news/2025/01/meta-more-speech-fewer-mistakes/"><span>commitments to free speech</span></a><span>, those commitments </span><a href="https://www.eff.org/deeplinks/2025/01/metas-new-content-policy-will-harm-vulnerable-users-if-it-really-valued-free"><span>should materialize</span></a><span> in clear policies that are enforced equally, not only when it is escalated through leveraging relationships with Meta personnel.</span></p>
<h2><b>“Facebook Jail” Reform</b></h2>
<p><span>There is no question that the enforcement of these content moderation policies on Meta platforms and the length of time people are spending in “content jail” or “Facebook/Instagram jail” has created a </span><a href="https://www.thefire.org/research-learn/chilling-effect-overview"><span>chilling effect</span></a><span>.&nbsp;</span></p>
<p><span>“I think that I am more cautious and aware that the 6.1K followers we have built up over time could be taken away at any time based on the whims of Meta,” Tammi from Red River Women’s Clinic told us.&nbsp;</span></p>
<p><span>RISE sees it in a slightly different light, sharing that “[w]hile this experience has not affected our fundamental values and commitment to sharing our work and rigorous science, it has highlighted for us that no information posted on a third-party platform is entirely one’s own, and thus can be dismantled at any moment.”</span></p>
<p><span>At the end of the day, clinics are left afraid to post basic information, patients are left confused or misinformed, and researchers lose access to their audiences. But unless your issue catches the attention of a journalist or you know someone at Meta, you might never regain access to your account.</span></p>
<p><span>These case studies highlight the urgent need for transparent, equitable, and timely enforcement that is not dependent on insider connections, as well as accountability from platforms that claim to support open dialogue and free speech. Meta’s admitted overenforcement should, at minimum, be coupled with efficient and well-staffed review processes and policies that are transparent and easily understandable.&nbsp;</span></p>
<p><span>It’s time for Meta and other social media platforms to implement the reforms they claim to support, and for them to prove that protecting access to vital health information doesn’t hinge on who you know.</span></p>
<p><i><span>This is the second post in our blog series documenting the findings from our Stop Censoring Abortion campaign. Read more in the series: </span></i><i><span>https://www.eff.org/pages/stop-censoring-abortion</span></i><i><span>&nbsp; </span></i><span>&nbsp;</span></p>

</div>

          </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This map is not upside down (271 pts)]]></title>
            <link>https://www.maps.com/this-map-is-not-upside-down/</link>
            <guid>45292694</guid>
            <pubDate>Thu, 18 Sep 2025 17:47:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.maps.com/this-map-is-not-upside-down/">https://www.maps.com/this-map-is-not-upside-down/</a>, See on <a href="https://news.ycombinator.com/item?id=45292694">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="66318cae" data-element_type="container" data-widget_type="text-editor.default">
									<p>Simmon’s map includes countries, major lakes, oceans, gulfs, seas, roads, and cities. It also features inset maps depicting Earth’s biosphere, global land cover, and bathymetry. All of these are familiar to most map readers. Yet the map may seem disorienting to many. Simmon’s map is geographically correct, yet purposely—and literally—turns convention on its head. What was once familiar becomes alien, challenging readers to look at Earth anew. It also encourages us to think more deeply about such conventions: Why is north almost always at the top of maps? And must it always be that way? Simmon’s map reminds us that it doesn’t have to be.</p><p>Simmon is not the first to create a south-up map. Others have made these maps to challenge conventions and norms. And it was only rather recently that north-up maps became so commonplace. Centuries ago, <a href="https://www.bbc.com/future/article/20160614-maps-have-north-at-the-top-but-it-couldve-been-different">cartographers drew maps</a> with the top being south, east, or other orientations. These alternatives reflected the limited tools, knowledge, and practices of the time. The basic idea behind a compass (which most today recognize as a device that points north) was known to the Han and Tang dynasties of China more than 2,000 years ago. Early Chinese navigators used magnetized devices as a compass, but for them <a href="https://books.google.com/books?id=CjRAiqGSJ50C&amp;pg=PA27#v=onepage&amp;q&amp;f=false">south was the dominant position</a> from which bearings were derived.&nbsp;</p><p>Deciding to put south, or north, at the top of maps is a decision of consequence. Psychologically, we <a href="https://journals.sagepub.com/doi/abs/10.1177/1948550611401042">tend to view</a> things nearer the top as ‘good’ and those lower as ‘bad.’ This can influence our interpretation of maps at both global and local scales. Still, the prominence of north-up maps did not arrive deliberately to elevate the status of some areas or their rulers. It is in part a consequence of the work of Ptolemey, who first labeled his maps with calculated lines of latitude and longitude. This made it easy for others to copy, extend, and derive new maps. Each map drawn in this way would adopt Ptolemy’s orientation.</p><p>Regardless of the reasons for a given orientation and the implications that follow, Simmon’s map reminds us to challenge tradition and consider its influence. As both a map and a philosophical prompt, this example hits the mark beautifully.</p>								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn Your Way: Reimagining Textbooks with Generative AI (307 pts)]]></title>
            <link>https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/</link>
            <guid>45292648</guid>
            <pubDate>Thu, 18 Sep 2025 17:42:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/">https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=45292648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20250916">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="ucxot">Textbooks are a cornerstone of education, but they have a fundamental limitation: they are a one-size-fits-all medium. The manual creation of textbooks demands significant human effort, and as a result they lack alternative perspectives, multiple formats and tailored variations that can make learning more effective and engaging. At Google, we’re exploring how we can use generative AI (GenAI) to automatically generate alternative representations or personalized examples, while preserving the integrity of the source material. What if students had the power to shape their own learning journey, exploring materials using various formats that fit their evolving needs? What if we could reimagine the textbook to be as unique as every learner?</p><p data-block-key="e8fqs">Recent advances in GenAI are bringing this vision closer to reality. Today we are excited to introduce <a href="https://learnyourway.withgoogle.com/" target="_blank" rel="noopener noreferrer">Learn Your Way</a>, now on <a href="https://labs.google/" target="_blank" rel="noopener noreferrer">Google Labs</a>, a research experiment that explores how GenAI can transform educational materials to create a more effective, engaging, learner-driven experience for every student. Here we outline the research and pedagogy underpinning Learn Your Way, with more details in the accompanying <a href="https://arxiv.org/abs/2509.13348" target="_blank" rel="noopener noreferrer">tech report</a>. We also report early indicators of its impact: in our efficacy study, students using Learn Your Way scored 11 percentage points higher on retention tests than students using a standard digital reader.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Grounded in learning, built for the student</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">Our approach is built on two key pillars that work together to augment the learning experience: (1) generating various multimodal representations of the content, and (2) taking foundational steps toward personalization.</p><p data-block-key="7jca2">The seminal <a href="https://www.researchgate.net/publication/225249172_Dual_Coding_Theory_and_Education" target="_blank" rel="noopener noreferrer">dual coding theory</a> states that forging mental connections between different representations strengthens the underlying conceptual schema in our brain. Subsequent <a href="https://www.sciencedirect.com/science/article/abs/pii/S0360131599000299" target="_blank" rel="noopener noreferrer">research</a> indeed showed that when students actively engage with information in various formats, they build a more robust and complete mental model of the material. Inspired by this, our approach empowers students with the agency to choose and intermix multiple formats and modalities to best help them understand the material. In addition, personalization is increasingly becoming an <a href="https://par.nsf.gov/servlets/purl/10274018" target="_blank" rel="noopener noreferrer">aspirational standard</a> in K-12 educational settings, and so our research reflects this. We aim to enhance the relatability and effectiveness of educational content by adapting it to student attributes. Moreover, we incorporate quizzing capabilities that enable us to further tailor the experience according to the learners’ real-time responses. Such personalization can be a powerful method for <a href="https://www.researchgate.net/publication/320564894_The_Role_of_Situational_Interest_in_Personalized_Learning" target="_blank" rel="noopener noreferrer">enhancing motivation</a> and <a href="https://journals.sagepub.com/doi/full/10.3102/00346543221148478" target="_blank" rel="noopener noreferrer">deepening learning</a>.</p><p data-block-key="35lic">Bringing this to life involves a layered technical approach using <a href="https://blog.google/outreach-initiatives/education/google-learnlm-gemini-generative-ai/" target="_blank" rel="noopener noreferrer">LearnLM</a>, our best-in-class pedagogy-infused family of models, now integrated directly into <a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/" target="_blank" rel="noopener noreferrer">Gemini 2.5 Pro</a>. The first layer is a unique personalization pipeline that serves as the basis for the second layer of multiple content representations. Our starting point is a textbook PDF, although our approach could be used with other forms of source material.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>The personalization pipeline</h3>
            
        
        
    </p>



    <p data-block-key="ucxot">The Learn Your Way interface asks the learner to select their grade and interests (e.g., sports, music, food). The original source material is first re-leveled to the learner’s reported grade level, while maintaining the scope of its content. This is followed by the strategic replacement of generic examples with ones that are personalized to the learner’s reported interests. The resulting text serves as the basis for the generation of all the other representations, effectively propagating the personalization effect and setting up a pipeline for further personalization.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Multiple representations of content</h3>
            
        
        
    </p>



    <p data-block-key="ucxot">Following the source personalization, we generate multiple representations of the content. For some content representations, such as mind maps and timelines, Gemini’s broad capabilities are used directly. Other features such as narrated slides, require more elaborate pipelines that weave together multiple specialized AI agents and tools to achieve an effective pedagogical result. Finally, specialized tasks, such as generating effective educational visuals, proved too challenging even for state-of-the-art general-purpose image models. To overcome this, we fine-tuned a dedicated model specifically for generating educational illustrations. The combination of a powerful base model, multi-step agentic workflows, and fine-tuned components allows us to generate a wide range of high-quality multimodal representations for learning.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>The Learn Your Way experience</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">Our research comes to life in Learn Your Way. The interface brings together multiple, personalized representations of content including: (1) immersive text, (2) section-level quizzes, (3) slides &amp; narration, (4) audio lessons, and (5) mind maps.</p><ul><li data-block-key="digp2"><b>Immersive text:</b> Breaks the content up into digestible sections that are augmented with generated images and embedded questions. Put together, these transform passive reading into an active multimodal experience that follows learning science principles.</li><li data-block-key="8kkuc"><b>Section-level quizzes</b>: Promote active learning by allowing a user to interactively assess their learning, and uncover existing knowledge gaps.</li><li data-block-key="aq4r1"><b>Slides &amp; narration:</b> Offers presentations that span the entire source material and include engaging activities like fill-in-the-blanks, as well as a narrated version, mimicking a recorded lesson.</li><li data-block-key="act6h"><b>Audio lesson:</b> Provides simulated conversations, coupled with visual aids, between an AI-powered teacher and a student that models how a real learner might engage with the material, including the expression of misconceptions, which are clarified by the teacher.</li><li data-block-key="eqbtv"><b>Mind map:</b> Organizes the knowledge hierarchically and allows learners to zoom in and out from the big picture to the details.</li></ul><p data-block-key="eef4f">The above representations give learners choice and are all adapted to their selected grade level and personal interests. Throughout the experience, the interactive quizzes provide dynamic feedback, guiding students to revisit specific content areas where they struggled. This marks our first steps towards true personalization.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Pedagogical evaluation</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">To evaluate Learn You Way's pedagogical performance, we transformed ten varied source materials from <a href="https://openstax.org/" target="_blank" rel="noopener noreferrer">OpenStax</a> (a provider of free educational textbooks) to three different personalization settings. The source materials covered various subjects from history to physics. Three pedagogical subject matter experts then evaluated the transformed materials using pedagogical criteria, such as accuracy, coverage, and the <a href="https://blog.google/outreach-initiatives/education/google-learnlm-gemini-generative-ai/" target="_blank" rel="noopener noreferrer">LearnLM</a> learning science principles.</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="ucxot">The results were highly positive, with an average expert rating of 0.85 or higher across all pedagogical criteria. See the <a href="https://arxiv.org/abs/2509.13348" target="_blank" rel="noopener noreferrer">tech report</a> for more evaluation details.</p>

    </div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Efficacy study</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">An AI-powered learning tool is only valuable if it both effectively improves learning outcomes and students want to use it. Learn Your Way now serves as a research platform for us to conduct studies with partners around the world to explore how AI-powered transformations and personalization affects outcomes, and to ensure that what we build is effective and <a href="https://blog.google/intl/en-africa/company-news/outreach-and-initiatives/5-ways-were-bringing-ai-innovations-to-people-across-africa/" target="_blank" rel="noopener noreferrer">locally relevant</a>.</p><p data-block-key="rstv">Recently, we conducted a randomized controlled study with 60 students from the Chicago area, ages 15–18 and with similar reading levels. Participants were given up to 40 minutes to learn about adolescent brain development from a textbook, and randomly assigned to learn using Learn Your Way or a traditional digital PDF reader.</p><p data-block-key="e1qod">We assessed students with a quiz immediately after the study session, and with a retention test 3–5 days later, using assessments designed by pedagogical experts to be a good measure of content comprehension. We also surveyed them about the learning experience, and to gain deeper insights beyond these quantitative metrics, each student participated in a 30-minute qualitative interview where they could share more nuanced feedback about their experience.</p><p data-block-key="2tkk3">The results were compelling and statistically significant. Here are the highlights. See the <a href="https://arxiv.org/abs/2509.13348" target="_blank" rel="noopener noreferrer">tech report</a> for more details.</p><ul><li data-block-key="1603p"><b>Positive learning outcomes:</b> The Learn Your Way group scored, on average, 9% higher on the immediate assessment following the study session.</li><li data-block-key="2plg8"><b>Better long-term retention:</b> Similarly, the Learn Your Way group scored 11% higher on the retention assessment 3-5 days later (78% vs. 67%).</li><li data-block-key="c6kod"><b>Positive user sentiment:</b> 100% of students who used Learn Your Way reported that they felt the tool made them more comfortable taking the assessment, compared to 70% in the digital reader control group. 93% said they would want to use Learn Your Way for future learning, compared to just 67% for the digital reader.</li><li data-block-key="4mg4i"><b>Valuable experience</b>: Insights from the qualitative interviews revealed that students found great value in Learn Your Way.</li></ul>
</div>

                    
                    
    




                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>The path forward</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">Our findings suggest that generative AI can be used to build learning experiences that are not only more effective but also more empowering. By evolving the static textbook into an interactive artifact and giving students greater agency over <i>how</i> they learn, we saw learning retention improve.</p><p data-block-key="88po1">This work is just the beginning of our exploration. We envision many more ways to tailor content, moving towards systems that continuously adapt to each learner's unique needs and progress. As we take our next steps towards personalized education, we will continue to ground our research in pedagogical principles, measuring the impact of AI on learning efficacy, so that in the future every student might have access to a high-quality, engaging learning experience that is custom built for them.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Acknowledgements</h2>
            
        
        
    </p>



    <p data-block-key="ucxot"><i>Shout out to our Google Research LearnLM team who have contributed to this work: Alicia Martín, Amir Globerson, Amy Wang, Anirudh Shekhawat, Anisha Choudhury, Anna Iurchenko, Avinatan Hassidim, Ayça Çakmakli, Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Dana Oria, Diana Akrong, Hairong Mu, Ian Li, Ido Cohen, Komal Singh, Lev Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Preeti Singh, Rena Levitt, Shashank Agarwal, Shay Sharon, Sophie Allweis, Tracey Lee-Joe, Xiaohong Hao, Yael Gold-Zamir, Yishay Mor, and Yoav Bar Sinai. Special thanks to our executive champions: Niv Efron, Avinatan Hassidim, Yossi Matias and Ben Gomes.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chrome's New AI Features (186 pts)]]></title>
            <link>https://blog.google/products/chrome/new-ai-features-for-chrome/</link>
            <guid>45292260</guid>
            <pubDate>Thu, 18 Sep 2025 17:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/chrome/new-ai-features-for-chrome/">https://blog.google/products/chrome/new-ai-features-for-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=45292260">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            

    
    

    <article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
  }">
  
  <div>
      
      
        <p>
          We’re taking you behind the browser to show you how AI is being built into Chrome to help you get things done while staying safe online. Here are the top 10 new AI updates we’re bringing to Chrome.
        </p>
      
    </div>
  
  <div data-component="uni-ai-generated-summary" data-analytics-module="{
    &quot;event&quot;: &quot;module_impression&quot;,
    &quot;module_name&quot;: &quot;ai_summary&quot;,
    &quot;section_header&quot;: &quot;CTA&quot;
  }">
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>Chrome is getting its biggest upgrade ever with new Google AI features to improve your browsing. Gemini in Chrome can clarify complex information, handle tedious tasks, and work across multiple tabs. Also, expect better integration with Google apps, AI-powered search from the address bar, and enhanced security features.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      
        <div data-summary-id="ai_summary_2">
          <h2>Bullet points</h2>
          <ul>
<li>Mike Torres, VP of Product, introduces "Go behind the browser with Chrome’s new AI features."</li>
<li>Gemini in Chrome helps you understand complex info, works across tabs, and finds past webpages.</li>
<li>Agentic browsing is coming! Gemini in Chrome will handle tasks like booking haircuts for you.</li>
<li>Chrome's AI Mode in the omnibox lets you ask complex questions and get AI-powered answers.</li>
<li>AI helps Chrome block scams, manage notifications, and change compromised passwords easily.</li>
</ul>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      
      <div>
        <h4>
          Explore other styles:
        </h4>
        
      </div>
      

      </div>
</div>

    

    
      




  <uni-youtube-player-hero index="0" thumbnail-alt="Video episode of Behind the Browser summarizing the latest AI update for Chrome" component-title="Go behind the browser with Chrome’s new AI features" video-id="WjOvZ8n9MK0" video-type="video" image="Main video thumbnail" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Main_video_thumbnail.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Main_video_thumbnail.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Main_video_thumbnail.width-1000.format-webp.webp">
  </uni-youtube-player-hero>











    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="Go behind the browser with Chrome’s new AI features" listen-to-article="Listen to article" data-date-modified="2025-09-18T17:15:15.999483+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><p data-block-key="w9jcq">Today represents the biggest upgrade to Chrome in its history, as we share how we’re using the latest in Google AI to enhance your browsing experience. <a href="https://blog.google/products/chrome/chrome-reimagined-with-ai/">We’re building Google AI into Chrome across multiple levels</a> so it can better anticipate your needs, help you understand more complex information and make you more productive when you browse the web, all while keeping you safe.</p><p data-block-key="31r25">Here are 10 new ways AI is helping us make Chrome smarter, safer and more useful than ever:</p><h2 data-block-key="2k0na">1. Enhance your browsing with Gemini in Chrome</h2><p data-block-key="4u5oa">Starting today, we’re rolling out <a href="https://blog.google/products/gemini/gemini-app-updates-io-2025/#chrome">Gemini in Chrome</a>


<a data-ga4-analytics-superscript-click="" data-target="inline text" href="#footnote-1" id="footnote-source-1" aria-label="Jump to link reference 1">
  <sup>1</sup>
</a>
 to Mac and Windows desktop users in the U.S. with their language set to English, so you can ask Gemini to clarify complex information on any webpage (or webpages) you're reading. It’ll be <a href="https://cloud.google.com/blog/products/chrome-enterprise/supercharging-employee-productivity-with-ai-securely-with-gemini-in-chrome-enterprise">available to businesses</a> in the coming weeks via Google Workspace with enterprise-grade data protections and controls. And we’re also bringing Gemini in Chrome to mobile in the U.S., ensuring you’ll always have access to our AI features, whether you’re at home or on the go. You can also activate Gemini when using Chrome on Android, and other apps, by holding the power button. And starting soon, on iOS Gemini in Chrome will be built into the app.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing things you can do with Gemini in Chrome" external-image="" or-mp4-video-title="Gemini in Chrome Intro" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini_in_Chrome_intro.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Gemini in Chrome is rolling out to all Mac and Windows users in the U.S.</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">2. Get ready for your agentic browsing assistant</h2><p data-block-key="ddnsk">In the coming months, we’ll be introducing agentic capabilities to Gemini in Chrome. These will let Gemini in Chrome handle those tedious tasks that take up so much of your time, like booking a haircut or ordering your weekly groceries. You tell Gemini in Chrome what you want to get done, and it acts on web pages on your behalf, while you focus on other things. It can be stopped at any time so you’re in control.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Gemini ordering weekly groceries" external-image="" or-mp4-video-title="Gemini Instacart" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/MainVid_InstaCart_1.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Gemini in Chrome will be able to handle repetitive tasks for you</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">3. Make better sense of all your tabs</h2><p data-block-key="b95ah">Gemini in Chrome can now work across multiple tabs, so you can quickly compare and summarize information across multiple websites to find what you need. Planning your flight, hotel and vacation activities across multiple tabs? Gemini in Chrome can help you consolidate that information into a single itinerary to take the stress out of your travel plans.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Gemini in Chrome summarizing information across multiple tabs" external-image="" or-mp4-video-title="Multitab" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Multitab.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Gemini in Chrome can work with context of multiple tabs</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">4. Find webpages you previously visited</h2><p data-block-key="4318b">For those frustrating instances when you want to jump back into a past project but don’t want to scroll through your history to find an important website you previously visited, soon you’ll be able to use Gemini in Chrome to recall it for you. Once launched, you can try prompts like “what was the website that I saw the walnut desk on last week?” or “what was that blog I read on back to school shopping?”</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Gemini in Chrome recalling past webpages visited" external-image="" or-mp4-video-title="GiC tabs" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/GiC_make_sense_of_your_tabs.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Gemini in Chrome will be able to recall your past tabs for you</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">5. Work with your favorite Google apps without changing tabs</h2><p data-block-key="b8d15">We’ve also built a deeper integration between Gemini in Chrome and your favorite Google apps, like Calendar, YouTube and Maps, so you can schedule meetings, see location details and more without leaving the page you’re on. For example, if you’re looking for a specific spot in a YouTube video, you can just ask Gemini in Chrome and it will take you there immediately.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Gemini in Chrome integrated with YouTube" external-image="" or-mp4-video-title="GiC YouTube" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/GiC_YouTube_integration.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Gemini in Chrome is now integrated with your favorite Google apps</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">6. Search with AI Mode right from the omnibox</h2><p data-block-key="2q2a3">You’ll have the option to quickly access Google Search’s <a href="https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search">AI Mode</a>, our most powerful AI search, right from the Chrome address bar (what we call the omnibox) on your computer. AI Mode allows you to ask longer, more complex questions and get a helpful AI response, with the ability to easily ask follow up questions and dive deeper on the web. This update will be rolling out later this month in English in the U.S. and expanding to more countries and languages in the weeks ahead.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing AI mode in the Chrome address bar" external-image="" or-mp4-video-title="AI mode omnibox" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/AI_Mode_in_omnibox.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">AI Mode is now available right in your address bar</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">7. Ask questions and learn more about your current page</h2><p data-block-key="3o0u3">You can now ask questions about the entire page you’re on right from the omnibox. Chrome can suggest relevant questions based on the context of the page to help you kickstart your search. You'll get a helpful AI Overview from Search right alongside the page, with the ability to ask follow-up questions in AI Mode, so you can get helpful information without leaving the page. Contextual suggestions are available in the U.S. in English and will be rolling out to more countries and languages in the weeks ahead.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing AI Overview in the side panel in Chrome" external-image="" or-mp4-video-title="contextual search" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/AIMode_ContextualSearch.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">AI Overview in the side panel can help with follow up questions</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">8. Combat more sophisticated scams with Gemini Nano</h2><p data-block-key="1ubgs">We’re continuing to expand how we use AI to help you navigate the threats and annoyances on the web. Safe Browsing’s Enhanced Protection mode already uses Gemini Nano to help identify tech support scams that try to trick you into downloading harmful software. Soon, we’ll be expanding this protection to also stop sites that use fake viruses or fake giveaways to trick you.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Chrome’s Enhanced Protection mode with AI" external-image="" or-mp4-video-title="enhanced safety 2" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/EnhancedSafety_v3.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Chrome’s Enhanced Protection is expanding its scams detection with AI</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">9. Say goodbye to dodgy notifications and unwanted permissions</h2><p data-block-key="6dvcg">Chrome now detects potentially spammy or scammy notifications and gives you the option of seeing them or unsubscribing. Since rolling out this feature, we’ve reduced unwanted website notifications for Chrome on Android users by around 3 billion each day, cutting down on unnecessary distractions.</p><p data-block-key="acsut">You always want to be careful when granting sites permissions, like access to your camera or location. Chrome now uses AI to learn your preferences and to take into account signals like site quality. When it determines you’re unlikely to grant them, it will present permissions requests in a less intrusive way.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Chrome detecting potential spammy notifications" external-image="" or-mp4-video-title="safety permissions" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Safety_permissions.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Chrome helps you deal with spammy notifications and unwanted permissions</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Go behind the browser with Chrome’s new AI features&quot;
         }"><h2 data-block-key="w9jcq">10. Change compromised passwords in 1-step</h2><p data-block-key="ekni8">Chrome already automatically and securely fills in your login credentials and proactively alerts you if any of your passwords are compromised. Very soon it’ll use AI as a password agent to go a step further, letting you change your saved passwords with a single click on supported sites, like Coursera, Spotify, Duolingo, H&amp;M and more.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing Chrome using AI to help you fix your compromised password" external-image="" or-mp4-video-title="chrome password" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Safety_password_fix.mp4" section-header="Go behind the browser with Chrome’s new AI features" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="hllxw">Chrome will help you fix your compromised password with one click</p>
    </div>
  
  
</uni-image-full-width>


  

  
    







<uni-related-content-tout title="Chrome: The browser you love, reimagined with AI" cta="See more" summary="Google is taking the next step in its journey to make your browser smarter with new AI integrations" hideimage="False" eyebrow="" image-alt-text="Rocket ship with. Chrome logo taking off" role="none" externalurl="https://blog.google/products/chrome/chrome-reimagined-with-ai/" fullurl="" pagetype="" isarticlepage="">
  
    <div slot="rct-image-slot">
      
      
        
    <figure>
        <picture>
            


    

    
        <source media="(max-resolution: 1.5dppx)" sizes="300px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_image_1920x1080_1.width-1300.width-300.format-webp.webp 300w">
    
        <source media="(min-resolution: 1.5dppx)" sizes="600px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_image_1920x1080_1.width-1300.width-600.format-webp.webp 600w">
    

    <img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_image_1920x1080_1.width-1300.width-600.format-webp.webp" alt="Rocket ship with. Chrome logo taking off" sizes=" 300px,  600px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_image_1920x1080_1.width-1300.width-300.format-webp.webp 300w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_image_1920x1080_1.width-1300.width-600.format-webp.webp 600w" data-target="image" loading="lazy">
    


        </picture>
    </figure>


      
    </div>
  
</uni-related-content-tout>

  


            
            

            
              




            
          </div>
  </article>
  



  








  <uni-footnotes layout="align-center">
    
  </uni-footnotes>



  

  


<div data-component="uni-related-articles" aria-roledescription="carousel" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Footer Related Stories&quot;,
    &quot;section_header&quot;: &quot;Related stories&quot;
  }">
        <h3>
          <p>
            Related stories
          </p>
        </h3>
      </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yes, Jimmy Kimmel's suspension was government censorship (230 pts)]]></title>
            <link>https://www.theverge.com/policy/781148/jimmy-kimmel-charlie-kirk-monologue-brendan-carr-censorship-first-amendment</link>
            <guid>45292130</guid>
            <pubDate>Thu, 18 Sep 2025 17:03:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/policy/781148/jimmy-kimmel-charlie-kirk-monologue-brendan-carr-censorship-first-amendment">https://www.theverge.com/policy/781148/jimmy-kimmel-charlie-kirk-monologue-brendan-carr-censorship-first-amendment</a>, See on <a href="https://news.ycombinator.com/item?id=45292130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>Yesterday, Disney-owned ABC <a href="https://www.theverge.com/news/780471/disney-abc-jimmy-kimmel-live-charlie-kirk">suspended <em>Jimmy Kimmel Live</em></a> “indefinitely” for a comment Kimmel made about the response to Charlie Kirk’s death. The response from Republican commentators has been <a href="https://www.hollywoodreporter.com/news/politics-news/maga-reaction-jimmy-kimmel-suspension-1236374491/">predictably gleeful</a>. They’ve positioned the suspension as a reversal of “cancel culture,” a “deplatforming” that’s simply fair retaliation for antagonizing them. “Jimmy Kimmel does have Free Speech, he is free to speak just not on ABC,” posted comedian <a href="https://x.com/w_terrence/status/1968521190693019710">Terrence Kentrell Williams on X</a>.</p><p>This framing is transparently false. ABC’s suspension of Kimmel was the result of an explicit threat from President Donald Trump’s Federal Communications Commission Chair Brendan Carr, aimed at Disney and companies that worked with it. The move was effective because of the FCC’s authority to regulate broadcast TV and, perhaps more importantly, to approve communications mergers in a hyper-consolidated landscape. It was repeating a playbook Carr recently used on Disney’s fellow media giant Paramount. And it’s an unabashed attempt at the government dictating the speech of private TV networks and entertainers, as objectionable and un-American as a McCarthyist blacklist.</p><p>The starting point of all this is a pretty tame late-night show monologue. On Monday, Kimmel said the following:</p><p>“We hit some new lows over the weekend, with the MAGA gang desperately trying to characterize this kid who murdered Charlie Kirk as anything other than one of them and doing everything they can to score political points from it.”</p><p>The line led into a clip from last week in which Trump <a href="https://www.nytimes.com/2025/09/16/arts/television/late-night-trump-white-house-ballroom.html">responded to Kirk’s death</a> by bragging about the new White House ballroom — “he’s at the fourth stage of grief: construction,” Kimmel quipped.</p><p>Carr and other Republicans loudly interpreted the remark as claiming Tyler Robinson, who’s charged with killing Kirk, was part of MAGA. (An <a href="https://www.nytimes.com/interactive/2025/09/16/us/tyler-robinson-charges.html">indictment released</a> Tuesday says Robinson believed Kirk was spreading “hate”; at the time of Kimmel’s monologue, the evidence was <a href="https://www.theverge.com/politics/777313/charlie-kirks-alleged-killer-scratched-bullets-with-a-helldivers-combo-and-a-furry-sex-meme">mostly confusing</a> and speculation was rife.)</p><p>On Wednesday, Carr <a href="https://x.com/bennyjohnson/status/1968359685045838041">appeared in high dudgeon</a> for an interview with conservative commentator Benny Johnson. “It appears to be some of the sickest conduct possible,” Carr intoned over a clip of Kimmel’s statement. It was also, he said, legally actionable. Broadcasters “have a license granted by us at the FCC, and that comes with an obligation to operate in the public interest,” he said. “We can do this the easy way or the hard way. These companies can find ways to change conduct and take action, frankly, on Kimmel, or there’s going to be additional work for the FCC ahead.”</p><p>Carr and Johnson walked out the threat a little further. They noted that Disney and ABC aren’t issued a central license to broadcast; licenses are granted to individual TV stations, owned in small numbers by Disney but mainly by separate companies that broadcast ABC and other networks’ programming. “FCC regulatory action focuses on these individual stations,” Carr noted. “The public interest means you can’t be running a narrow partisan circus and still meeting your public interest obligations.”</p><p>Citing rules against “news distortion” and “broadcast hoaxes,” Carr repeated that “there’s actions we can take on licensed broadcasters. And frankly, I think it’s really past time that a lot of these licensed broadcasters themselves push back on Comcast and Disney and say, ‘Listen, we are going to preempt, we are not going to run Kimmel anymore until you straighten this out, because we, a licensed broadcaster, are running the possibility of fines or license revocation from the FCC if we continue to run content that ends up being a pattern of news distortion.’”</p><p>This is <a href="https://www.theverge.com/24283652/fcc-license-donald-trump-elon-musk-first-amendment-fairness-doctrine-please-vote-decoder">not how any pre-Carr FCC in recent memory</a> (or arguably before that) has defined the “public interest” requirement. If the issue is a “narrow partisan circus,” the highly partisan Fox — whose news division <a href="https://www.theverge.com/2023/4/18/23688582/fox-dominion-election-defamation-lawsuit-settled-trial-averted">settled a massive defamation suit</a> for lying about voting machine companies in 2023 — has been a stolid fixture on TV stations across the country for decades. Carr invoked rules against “news distortion” and “broadcast hoaxes,” neither of which makes logical sense as a charge against Kimmel. The bar for stripping a license is typically high — a rare example is <a href="https://www.nytimes.com/1979/12/07/archives/black-group-is-awarded-license-for-television-station-in.html">the 1989 revocation</a> of aggressively pro-segregationist station WLBT, which among other things, blacked out broadcasts involving civil rights.</p><p>Some commentators on the left <em>have </em>pushed for the FCC to do what Carr threatened, just with Fox instead of ABC, particularly <a href="https://prospect.org/blogs-and-newsletters/tap/2023-08-28-will-fox-lose-its-broadcast-license/">after the defamation settlement</a>. But the FCC has never pulled a station’s license as a result of this urging, and <a href="https://deadline.com/2025/09/brendan-carr-jimmy-kimmel-public-interest-1236547721/">in 2019 Carr decried</a> even Democratic commissioner Jessica Rosenworcel’s suggestion they crack down on TV and radio e-cigarette ads, saying the FCC “does not have a roving mandate to police speech in the name of the ‘public interest.’”</p><p>Carr’s statement on Wednesday was unambiguous: ABC-affiliated TV stations needed to stop airing Kimmel’s show ASAP, or they could be fined or lose their license. And the stations’ parent companies were listening. Nexstar, which owns around 200 stations and reaches roughly 39 percent of US households, <a href="https://www.nexstar.tv/nexstar-abc-affiliates-to-preempt-jimmy-kimmel-live-indefinitely-beginning-tonight/">said quickly</a> that it would no longer air <em>Jimmy Kimmel Live</em>. So did <a href="https://sbgi.net/sinclair-says-kimmel-suspension-is-not-enough-calls-on-fcc-and-abc-to-take-additional-action/">fellow giant Sinclair Broadcast Group</a>.</p><p>Those companies, particularly Nexstar, have reasons beyond station licensing to keep Carr happy. Nexstar is pushing for a $6.2 billion merger with broadcaster Tegna that would require the FCC to loosen the rules on TV station consolidation, something CEO Perry Sook <a href="https://www.newscaststudio.com/2025/08/22/nexstar-ceo-perry-sook-defends-6-2b-tegna-acquisition-as-regulatory-shift-creates-opening/">has expressed hope</a> that Trump’s “deregulatory moment” will enable.</p><p>Carr has shown himself willing to slow-walk deals with companies that earn his ire. A merger between Paramount and Skydance was not approved until Paramount subsidiary CBS <a href="https://www.theverge.com/news/696422/paramount-settlement-trump-cbs-lawsuit">agreed to pay $16 million</a> to resolve a blatantly frivolous lawsuit filed by Trump. It proceeded on the grounds that Skydance promote a “diversity of viewpoints from across the political and ideological spectrum” and employ an ombudsman who would “receive and evaluate any complaints of bias or other concerns involving CBS.” CBS also ended the show of Kimmel’s fellow late-night host Stephen Colbert, a decision <a href="https://www.theverge.com/news/709544/stephen-colberts-version-of-the-late-show-will-end-next-may">CBS called financial</a> that was nonetheless widely seen as a concession to Trump — and that was celebrated by Carr.</p><p>The pressure from Carr, Sinclair, and Nexstar quickly reached ABC, which made a terse announcement it had pulled Kimmel’s show off the air. Outlets with inside sources have indicated this wasn’t because of public outrage or because Kimmel’s bosses found the remarks inappropriate — <a href="https://www.rollingstone.com/tv-movies/tv-movie-news/jimmy-kimmel-out-abc-charlie-kirk-comments-1235430078/"><em>Rolling Stone</em> reports</a> that “multiple execs felt that Kimmel had not actually said anything over the line.” Instead, they were “pissing themselves” over the threat of Trump administration retaliation, one source said.</p><p>Disney, too, has pressure points beyond broadcast license fines. The FCC chair has previously threatened to investigate it for having (non-“ideological,” of course) diversity programs. And as <a href="https://www.status.news/p/jimmy-kimmel-pulled-fcc-decision">Oliver Darcy of <em>Status</em> notes</a>, the company is “working to complete a high-stakes deal with the NFL, one that is crucial to the future of ESPN” and <a href="https://www.reuters.com/legal/litigation/espn-nfl-deal-faces-regulatory-hurdles-2025-08-07/">requires regulatory approval</a> from the Department of Justice. Trump <a href="https://www.nbcnews.com/politics/justice-department/attorney-general-pam-bondi-doj-hate-speech-rcna231633">incidentally told</a> an ABC journalist this week that the DOJ might “come after ABC” for “hate” offenses, responding to questions about a “hate speech” crackdown declared by Attorney General Pam Bondi after Kirk’s death.</p><p>Under the First Amendment, a government official like Carr is allowed to call Kimmel talentless or unfunny. He’s allowed to say Kimmel shouldn’t be on the air. He’s <em>not </em>allowed to accompany this with a clear threat backed by government authority. “The easy way or the hard way” isn’t healthy debate, it’s <a href="https://www.theverge.com/2025/1/20/24346317/trump-gangster-tech-regulation-corruption-grift">gangster talk</a>. Or more precisely, government jawboning.</p><p>Even the substantially Trump-picked, overwhelmingly conservative Supreme Court has condemned something very similar to Carr’s conduct. <a href="https://www.techdirt.com/2025/09/17/cowardly-disney-caves-to-brendan-carrs-bogus-censorial-threats-pulling-jimmy-kimmel/">Mike Masnick at <em>Techdirt</em> points out</a> that a ruling last year, in the case <em>NRA v. Vullo</em>, declared flatly that “the First Amendment prohibits government officials from relying on the ‘threat of invoking legal sanctions and other means of coercion . . . to achieve the suppression’ of disfavored speech.” That’s true even if they do so through intermediaries like Nexstar rather than attacking the speaker directly.</p><p>Disney, of course, didn’t have to bow to a clearly unconstitutional threat. CEO Bob Iger and Disney Entertainment chief Dana Walden, according to <em>Status</em>, were among the latest powerful figures who made a cowardly decision to appease Carr and Trump rather than stand up for themselves and their employees in public and, if necessary, in court.</p><p>But even if there’s plenty of blame to go around, Carr’s threat is impossible to ignore — and the implicit comparisons to conservative provocateurs being banned on social media, or commentators being fired after outcry for a hateful statement, or any other example of alleged “cancel culture,” off-base. Whatever the underlying offense, this isn’t a private company independently making a business judgment about its public image and financial interests. It’s a government official inserting himself into the process of making entertainment, decreeing what a comedian is allowed to say.</p><p>Carr and Johnson aren’t denying the pressure campaign. Carr responded to a request for comment from <em>Status</em> with a grinning emoji and <a href="https://x.com/BrendanCarrFCC/status/1968449919221416427">thanked Nexstar on X</a> for “doing the right thing.” Johnson <a href="https://x.com/bennyjohnson/status/1968464339515417001">crowed on X</a> that he had “ended Jimmy Kimmel’s career” by bringing Carr on to “announce investigations into ABC and Disney.”<br>It’s unclear whether Kimmel will come back on the air at some point — but either way, the Trump administration’s <a href="https://www.theverge.com/policy/779799/republican-charlie-kirk-first-amendment-crackdown-continues">war on free speech</a> is still going strong.</p><p><em><strong>Correction:</strong> The proposed merger between Nexstar and Tegna is worth $6.2 billion, not million.</em></p><p><span><a href="https://www.theverge.com/policy/781148/jimmy-kimmel-charlie-kirk-monologue-brendan-carr-censorship-first-amendment#comments"><span>0<!-- --> <!-- -->Comments</span></a></span></p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6MTcy"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Adi Robertson</span></span></span></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Configuration files are user interfaces (152 pts)]]></title>
            <link>https://ochagavia.nl/blog/configuration-files-are-user-interfaces/</link>
            <guid>45291858</guid>
            <pubDate>Thu, 18 Sep 2025 16:43:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ochagavia.nl/blog/configuration-files-are-user-interfaces/">https://ochagavia.nl/blog/configuration-files-are-user-interfaces/</a>, See on <a href="https://news.ycombinator.com/item?id=45291858">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>We have all been there. Your software keeps growing and you feel the need to make it customizable. It is too soon for a full-blown UI with all the bells and whistles, so your pragmatic instinct suggests a text-based configuration file. Yes, that’s exactly it!</p>
<p>You rejoice knowing the software’s configuration will be trivial to version control. Your pragmatic instinct is satisfied as well; the door remains open to creating a proper UI later, since it would be merely a graphical view of your configuration’s structured data. The future is bright!</p>
<p>Now, which language should you pick for your glorious configuration file? It needs to be user-friendly, so people can inspect it and modify it with ease. JSON springs immediately to your mind, but the abundance of brackets and the lack of comments give you pause. TOML maybe? You are afraid it might be too minimal for your needs. Rolling your own language? Too impractical.</p>
<h3 id="yaml">YAML</h3>
<p>A forbidden spark lights inside your head. Any attempts to put it out are futile. It grows and grows until it finally stands ablaze before you, tempting you with its warmth: why not YAML? Yes, YAML, which is so pleasant to the eye and widely used across the industry. How could you say no to that?</p>
<p>Shivers run down your spine as you remember <a href="https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell">the yaml document from hell</a>. So often have you been warned about YAML’s deceptive simplicity! It’s a traitorous mask, your elders said, behind which a dark being lurks. Don’t ever come near, it will swallow your soul when you least expect it.</p>
<p>And yet… could YAML indeed be the pragmatic solution in this particular case? We are talking about a small configuration file here. What could possibly go wrong? Surely the gods of software wouldn’t punish you for this offense? How could they ask you to swim against the current, when even renowned projects such as Kubernetes use YAML pervasively?</p>
<p>Trembling, you stretch your hand towards the forbidden fruit, reap it and take a good bite. The flavor of instant productivity fills your mouth with delight and you feel confirmed in your choice. Why did you even doubt? After a few code changes your software is configurable through a YAML file. The dopamine surge overwhelms you, and you put the icing on the cake by adding an example configuration to the project’s readme.</p>
<p>But alas, superficial satisfaction cannot last. As the years go by, the sweet flavor in your mouth turns bitter. Your software has grown. The once simple configuration file now spans more than a hundred lines. Yes, the file is pleasant to <em>look</em> at, but <em>modifying</em> it is nothing short of miserable. Why did you disregard ancient wisdom? In silence, you mourn your lost innocence and the fallen state of humanity.</p>
<p>Ah, if you could begin again.</p>
<h3 id="the-crux-of-the-problem">The crux of the problem</h3>
<p>Do you recognize yourself in this story? I have seen it play out a few times and feel like we, as an industry, have somehow come to terms with the miserable situation we are in. Once in a while you may see some brave and noble soul proposing a new configuration language, but so far none has achieved mass adoption. What is going on?</p>
<p>The crux of the problem is, in my eyes, beyond the domain of configuration language choice (i.e., YAML vs. alternatives). We seem to be approaching the very problem of configuration from a flawed starting point, setting way too low expectations for our tools. We are failing to see that configuration files are actually user interfaces, and that they should be treated as such.</p>
<p>Once you start thinking of configuration files as user interfaces, it suddenly makes sense to demand an excellent user experience for working with them. The whole point of a user interface is to make the software accessible, with mechanisms that prevent human error and guide the user down the <a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/">pit of success</a>. We all recognize bad UX when it feels like you are fighting the computer to achieve a specific goal. In an ideal world, the computer would enhance you without getting in the way, like a <a href="https://www.pixelandtimber.com/bcl-journal/2019/7/11/bicycle-for-the-mind">bicycle for the mind</a>.</p>
<p>What would configuring software look like if our tools were rooted in the “configuration is UI” paradigm? Can we realistically dream of an ecosystem in which configuration is a joy to write and maintain?</p>
<h3 id="a-shout-out-to-kson">A shout out to KSON</h3>
<p>Having come to this point, I’m resisting the urge to present an all-encompassing theory of what configuring software could look like in the perfect world. Instead, I’d like to give a shout out to an existing open source project, which in my eyes is an excellent real-world example of the “configuration is UI” vision. I’m talking about <a href="https://kson.org/">KSON</a>, which just released its first public beta after years in the making. Feel free to check out the <a href="https://kson.org/">website</a>, or go directly to the <a href="https://kson.org/playground/">online playground</a>. That will give you a <em>much</em> better idea of the project than anything I could write here. You know what they say: show, don’t tell.</p>
<p>For those who’d rather skip the links above, let me briefly quote some paragraphs from the <a href="https://kson.org/docs/blog/2025/09/17/introducing-kson/">beta release announcement</a>:</p>
<blockquote>
<p>Anywhere a human is reading or editing YAML/JSON/TOML, KSON may be used as a more effective interface on that data.</p>
</blockquote>
<p>That’s a bold claim right there! But maybe it’s warranted, especially once you consider the sheer amount of work that has gone into the release:</p>
<blockquote>
<p>KSON is a <a href="https://github.com/kson-org/kson/pull/72">verified superset of JSON</a>, has <a href="https://github.com/kson-org/kson/pull/186">native JSON Schema support</a>, transpiles cleanly to <a href="https://github.com/kson-org/kson/pull/80">YAML (with comments preserved!)</a>, and is likely available wherever you want it—current supported platforms: <a href="https://www.npmjs.com/package/@kson_org/kson">JS/TS</a>, <a href="https://pypi.org/project/kson-lang/">Python</a>, <a href="https://crates.io/crates/kson-rs">Rust</a>, <a href="https://central.sonatype.com/artifact/org.kson/kson-jvm">JVM</a>, and <a href="https://central.sonatype.com/artifact/org.kson/kson">Kotlin Multiplatform</a>.</p>
<p>KSON is also widely available in developer tools, with support for <a href="https://marketplace.visualstudio.com/items?itemName=kson.kson">VS Code</a>, <a href="https://plugins.jetbrains.com/plugin/28510-kson-language">Jetbrains IDEs</a>, and anywhere you can plug in an <a href="https://github.com/kson-org/kson/blob/main/tooling/language-server-protocol/README.md">LSP</a>.</p>
</blockquote>
<p>See the appendix at the end of this article for an example KSON document. You will notice that the language feels familiar and that it has been designed from the ground up to provide an excellent editing experience. Also, advanced language support in code editors is to me a great example of the “configuration is UI” paradigm. It lets the document come to life under your fingertips, instead of being a dead text file.</p>
<h3 id="join-the-movement">Join the movement</h3>
<p>What a breath of fresh air! I’m hoping the vision of user-friendly configuration keeps unfolding over time, be it inside the KSON project or elsewhere. We, as an industry, should really set a new standard in which it’s normal and even expected to provide a top-tier configuration editing experience. There are so many possibilities<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>!</p>
<p>In case it’s not clear yet, I’m enthusiastic about KSON. If you visit the <a href="https://github.com/kson-org/kson/">open source repository</a>, you will probably see me among the contributors to the project<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. Besides the technical merits of KSON, I’m impressed by the driving force behind it: a small community of engineers has decided to bite the bullet and craft open software configuration tools that put humans first. It truly is “a love letter to the humans maintaining computer configurations”, as it says in the repository’s tagline.</p>
<p>To me, KSON is more than a new language or a collection of tools. It is an attempt to bootstrap a developer movement based in the “configuration is UI” principle. If that resonates with you, please join us in our effort! Merely trying out KSON is already a good start. And, if you end up liking it, go use it wherever it makes sense. Finally, feel free to chat with us on <a href="https://kson-org.zulipchat.com/">Zulip</a> any time. I’m looking forward to meeting you there!</p>
<h4 id="appendix-a-kson-example">Appendix: a KSON example</h4>
<p>While this blog post is about the principles behind the project, and not about the KSON language, here’s a tiny example of a <code>.kson</code> file derived from a dbt model:</p>
<div><pre tabindex="0"><code data-lang="yaml"><span><span><span>version</span>: <span>2</span>
</span></span><span><span><span>models</span>:
</span></span><span><span>  - <span>name</span>: <span>my_transformation</span>
</span></span><span><span>    <span>description</span>: <span>'This model transforms raw data'</span>
</span></span><span><span>    <span>columns</span>:
</span></span><span><span>      - <span>name</span>: <span>id</span>
</span></span><span><span>        <span>description</span>: <span>'A unique identifier'</span>
</span></span><span><span>      - <span>name</span>: <span>name</span>
</span></span><span><span>        <span>description</span>: <span>'The name of the item'</span>
</span></span><span><span>        <span>.</span>
</span></span><span><span>    <span>database</span>: <span>your_database</span>
</span></span><span><span>    <span>schema</span>: <span>your_schema</span>
</span></span><span><span>    <span>materialized</span>: <span>table</span>
</span></span><span><span>    <span>sql</span>: <span>%sql</span>
</span></span><span><span>      <span>SELECT</span>
</span></span><span><span>        <span>id,</span>
</span></span><span><span>        <span>name</span>
</span></span><span><span>      <span>FROM source_data%%</span>
</span></span></code></pre></div><p>As you can see, it has the readability of YAML, which is a great feature in my book! Importantly, however, KSON carefully avoids classic YAML footguns. One example of that is indentation handling: the code snippet above is indented in a way that makes the structure of the document evident. But, contrary to YAML, having “wrong” indentation does not break your configuration. If you were to remove or randomize the leading spaces for every line, the following would happen:</p>
<ol>
<li>The document would parse to the same object as before.</li>
<li>KSON would warn you that the document’s formatting is confusing, because the indentation doesn’t match the structure of the document (fortunately, the autoformatter can trivially fix the warning for you on save).</li>
</ol>
<p>An additional feature that is not immediately apparent here is that the embedded SQL is actually “alive”. A properly configured editor will see more than a multiline string there! It will know that it’s SQL, it will provide syntax highlighting for it, validation, and all other goodies you are used to when dealing with code.</p>
<p>See the <a href="https://kson.org/">official website</a> for more information and a space to play with KSON right from your browser.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[American Prairie unlocks another 70k acres in Montana (268 pts)]]></title>
            <link>https://earthhope.substack.com/p/victory-for-public-access-american</link>
            <guid>45291132</guid>
            <pubDate>Thu, 18 Sep 2025 15:47:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthhope.substack.com/p/victory-for-public-access-american">https://earthhope.substack.com/p/victory-for-public-access-american</a>, See on <a href="https://news.ycombinator.com/item?id=45291132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Public lands and public access are now constantly under threat in the U.S., but there’s still good news to share. </p><p><span>Ambitious conservation nonprofit </span><a href="https://americanprairie.org/" rel="">American Prairie</a><span> has secured its second-largest land purchase and leasing arrangement to date, buying up the 70,000-acre Anchor Ranch in Montana, which had been listed for sale for $35 million. The group bought the land from </span><a href="https://dailymontanan.com/2025/09/06/american-prairie-announces-new-acquisitions-access-in-breaks/" rel="">two billionaire Texas brothers </a><span>who’d kept the public locked out of one of the only western access roads into adjacent public land, the Upper Missouri River Breaks National Monument, which totals almost 400,000 acres. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!dM3L!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!dM3L!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 424w, https://substackcdn.com/image/fetch/$s_!dM3L!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 848w, https://substackcdn.com/image/fetch/$s_!dM3L!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!dM3L!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!dM3L!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg" width="1200" height="800.2747252747253" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:17891594,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://earthhope.substack.com/i/173040155?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!dM3L!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 424w, https://substackcdn.com/image/fetch/$s_!dM3L!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 848w, https://substackcdn.com/image/fetch/$s_!dM3L!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!dM3L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80005b74-8e2f-4967-858d-b63faecdd9a1_6214x4143.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Photo courtesy of American Prairie.</figcaption></figure></div><p>“This is a once-in-a-generation opportunity to secure an important piece of ecologically and culturally significant land,” said American Prairie CEO Alison Fox in a press release. “But this acquisition is equally important as a way to return public access to the people so they can explore, hunt, and recreate on land that’s been off-limits for many years.”</p><p><span>The group </span><a href="https://www.facebook.com/reel/1059049422744737" rel="">shared videos</a><span> of staff unlocking a gate and tearing down “no trespassing” signs along a 3.8-mile section of Bullwhacker Road, which was the subject of lawsuits for many years. The move was hailed by hunting and </span><a href="https://www.backpacker.com/news-and-events/new-land-acquisition-american-prairie/" rel="">recreation</a><span> groups that had fought to keep the road open but lost their bid in 2011 when a judge ruled the road was private. The move essentially blocked public access to 50,000 acres of the monument.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!J7xO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!J7xO!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 424w, https://substackcdn.com/image/fetch/$s_!J7xO!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 848w, https://substackcdn.com/image/fetch/$s_!J7xO!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!J7xO!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!J7xO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg" width="302" height="462.5523114355231" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1259,&quot;width&quot;:822,&quot;resizeWidth&quot;:302,&quot;bytes&quot;:149002,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://earthhope.substack.com/i/173040155?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91723c4c-eb88-4a04-8ccc-65523c3aa196_3939x1294.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!J7xO!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 424w, https://substackcdn.com/image/fetch/$s_!J7xO!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 848w, https://substackcdn.com/image/fetch/$s_!J7xO!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!J7xO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ea423fc-25e7-49de-a6d9-3d224d3c8a4d_822x1259.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>Building ties with new allies is critical for American Prairie, which has faced </span><a href="https://dailymontanan.com/2021/12/05/gianforte-knudsen-try-to-stop-american-prairies-bison-through-political-pressure/" rel="">decades of distrust </a><span>in a conservative state run on beef cattle ranching. The state refuses to classify bison as wildlife instead of livestock, meaning they must be fenced. </span></p><p>Undeterred, American Prairie keeps buying up land, tearing down or widening its fences, and growing its 900-head bison herd. Its holdings now total over 600,000 acres.</p><p>The group is trying to preserve the last untouched swath of shortgrass prairie on the planet, 3.2 million acres that are home to bison, badgers, black-tailed prairie dog, black-footed ferret, pronghorn, sage grouse, and swift fox, most of which are endangered species.</p><p>— American Prairie</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!13BE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!13BE!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 424w, https://substackcdn.com/image/fetch/$s_!13BE!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 848w, https://substackcdn.com/image/fetch/$s_!13BE!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!13BE!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!13BE!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg" width="1200" height="777.1978021978022" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:943,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:418572,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://earthhope.substack.com/i/173040155?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!13BE!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 424w, https://substackcdn.com/image/fetch/$s_!13BE!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 848w, https://substackcdn.com/image/fetch/$s_!13BE!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!13BE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09c7cb7b-ec23-4cc7-bfdf-27918c630159_1568x1015.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>American Prairie landholdings map as of September 2025. Anchor Ranch is marked in blue in the top left.</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!kahJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!kahJ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!kahJ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!kahJ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!kahJ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!kahJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2084152,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://earthhope.substack.com/i/173040155?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!kahJ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!kahJ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!kahJ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!kahJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20b60595-04cc-4716-843f-072d5f907ceb_3072x2048.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Anchor Ranch lies in a key migration corridor for pronghorn, elk, and deer. Photo of pronghorn doe and calves by Diane Hargreaves, courtesy of American Prairie.</figcaption></figure></div><p><span>Read more from </span><em>Earth Hope</em><span> about American Prairie:</span></p><div data-component-name="DigestPostEmbed"><a href="https://earthhope.substack.com/p/bison-country-just-grew-bigger" rel="noopener" target="_blank"><h2>Bison country just grew bigger</h2></a><div><div><a href="https://earthhope.substack.com/p/bison-country-just-grew-bigger" rel="noopener" target="_blank"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!bPcv!,w_280,h_280,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3a937f5-23ee-482c-ad7e-11bc48e0dedf_1383x2048.jpeg"><img src="https://substackcdn.com/image/fetch/$s_!bPcv!,w_280,h_280,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3a937f5-23ee-482c-ad7e-11bc48e0dedf_1383x2048.jpeg" sizes="100vw" alt="Bison country just grew bigger" width="280" height="280"></picture></a></div><div><p>Under Montana’s big sky, where buffalo by the tens of thousands once thundered across temperate grasslands teeming with wildlife like prairie dogs and ferrets, elk and grizzly bears, a nonprofit is pushing forward with its ambitious plan to save one of the l…</p></div></div></div><p><em>Grist </em><span>(April 2025)</span><em>:</em><strong><span> </span><a href="https://grist.org/indigenous/wildlife-not-livestock-why-the-eastern-shoshone-in-wyoming-are-reclassifying-buffaloes/" rel="">Wildlife, not livestock: Why the Eastern Shoshone in Wyoming are reclassifying buffalo</a></strong></p><p><span>Wind River Tribal Buffalo Initiative (August 2025): </span><strong><a href="https://windriverbuffalo.org/northern-arapaho-tribe-officially-classifies-buffalo-as-wildlife/" rel="">Northern Arapaho Tribe officially classifies buffalo as wildlife on Wind River Indian Reservation</a></strong></p><p><span>National Caucus of Environmental Legislators (May, 2025): </span><strong><a href="https://ncel.net/articles/colorado-grants-wild-bison-legal-protection/" rel="">Colorado grants wild bison legal protection</a></strong></p><p><span>Earthjustice: </span><strong><a href="https://earthjustice.org/article/for-tribes-that-have-bison-youve-got-something-back-that-was-taken-from-you" rel="">In Montana, wild bison</a></strong><a href="https://earthjustice.org/article/for-tribes-that-have-bison-youve-got-something-back-that-was-taken-from-you" rel=""> </a><strong><a href="https://earthjustice.org/article/for-tribes-that-have-bison-youve-got-something-back-that-was-taken-from-you" rel="">are back, and an entire ecosystem is healing</a></strong><span> (In 2013, bison returned to the Fort Belknap Reservation, which is adjacent to the lands American Prairie is protecting.)</span></p><p><span>High Country News: </span><strong><a href="https://www.hcn.org/issues/53-2/indigenous-affairs-tribes-reclaiming-the-national-bison-range/" rel="">Reclaiming the National Bison Range</a><span> (</span></strong><span>For 113 years, an 18,000-acre federal wildlife refuge for bison lay like a donut hole inside the </span><a href="https://www.bisonrange.org/history/" rel="">Flathead Indian Reservation</a><span> in Montana. In 2021, Congress passed legislation to return it to the Confederated Salish and Kootenai Tribes.) </span></p><p><a href="https://earthhope.substack.com/subscribe?coupon=8bb41ac1" rel="">HELP SUPPORT SOLUTIONS-BASED JOURNALISM FOR JUST $20</a><span>. </span><em>Earth Hope</em><span> is not affiliated with American Prairie, but all subscription revenues this week (Sept 9-16) will go to American Prairie.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://earthhope.substack.com/p/victory-for-public-access-american?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://earthhope.substack.com/p/victory-for-public-access-american?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://earthhope.substack.com/p/victory-for-public-access-american/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://earthhope.substack.com/p/victory-for-public-access-american/comments" rel=""><span>Leave a comment</span></a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!xkzA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!xkzA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 424w, https://substackcdn.com/image/fetch/$s_!xkzA!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 848w, https://substackcdn.com/image/fetch/$s_!xkzA!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!xkzA!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!xkzA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg" width="413" height="525.6105769230769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1853,&quot;width&quot;:1456,&quot;resizeWidth&quot;:413,&quot;bytes&quot;:4709662,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://earthhope.substack.com/i/173040155?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!xkzA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 424w, https://substackcdn.com/image/fetch/$s_!xkzA!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 848w, https://substackcdn.com/image/fetch/$s_!xkzA!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!xkzA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bccb03b-a709-4771-beec-c355bfc3c40c_1895x2412.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Prairie dog on American Prairie lands. Photo by Dennis Lingohr, courtesy of American Prairie.</figcaption></figure></div><p><em>Earth Hope</em><span> is a solutions-based journalism project that highlights environmental success stories to inspire action. I’m </span><a href="https://open.substack.com/users/183550901-amanda-royal?utm_source=mentions" rel="">Amanda Royal</a><span>, a former newspaper reporter and current eco-news junkie. </span><a href="https://earthhope.substack.com/about" rel="">Read more</a><span> about this project and what inspired it. Visit </span><a href="https://earthhope.substack.com/" rel="">earthhope.substack.com</a><span> for more stories.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Samsung confirms its smart fridges will start showing you ads (105 pts)]]></title>
            <link>https://www.androidauthority.com/samsung-confirms-smart-refrigerator-ads-are-coming-3598848/</link>
            <guid>45291107</guid>
            <pubDate>Thu, 18 Sep 2025 15:46:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.androidauthority.com/samsung-confirms-smart-refrigerator-ads-are-coming-3598848/">https://www.androidauthority.com/samsung-confirms-smart-refrigerator-ads-are-coming-3598848/</a>, See on <a href="https://news.ycombinator.com/item?id=45291107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-content-wrapper="true"><div><picture><source sizes="(min-width: 64rem) 51.25rem, 80vw" srcset="https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator.jpg.webp 1261w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-64w-36h.jpg.webp 64w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-1000w-562h.jpg.webp 1000w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-675w-380h.jpg.webp 675w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-300w-170h.jpg.webp 300w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-840w-472h.jpg.webp 840w" type="image/webp"><img decoding="async" loading="eager" sizes="(min-width: 64rem) 51.25rem, 80vw" title="Samsung Family Hub smart refrigerator" srcset="https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator.jpg 1261w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-64w-36h.jpg 64w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-1000w-562h.jpg 1000w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-675w-380h.jpg 675w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-300w-170h.jpg 300w, https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator-840w-472h.jpg 840w" alt="Samsung Family Hub smart refrigerator" src="https://www.androidauthority.com/wp-content/uploads/2025/09/Samsung-Family-Hub-smart-refrigerator.jpg"></picture></div><div data-container-type="content"><p>TL;DR</p>
<ul>
<li>Samsung is rolling out a new software update to its Family Hub refrigerators in the US.</li>
<li>The update adds promotions and advertisements to the refrigerator’s display when it is idle.</li>
<li>Samsung has confirmed the pilot program, though some Cover Screen themes will remain ad-free.</li>
</ul>
</div><p>Samsung started rolling out an <a href="https://www.androidauthority.com/samsung-smart-refrigerators-ads-3598564/">update to its refrigerators that brought ads to the display</a>, whether you like it or not. The whole situation is rather surreal but not entirely unsurprising. There were some doubts that the changelog wasn’t real or that it belonged to a different product. Now, Samsung has confirmed to us that ads are indeed coming to its refrigerators.</p><div>
<p>We had reached out to Samsung for a statement, and this is what a Samsung spokesperson said:</p>
<blockquote><p>Samsung is committed to innovation and enhancing every day value for our home appliance customers. As part of our ongoing efforts to strengthen that value, we are conducting a pilot program to offer promotions and curated advertisements on certain Samsung Family Hub refrigerator models in the U.S. market.</p>

<p>As a part of this pilot program, Family Hub refrigerators in the U.S. will receive an over-the-network (OTN) software update with Terms of Service (T&amp;C) and Privacy Notice (PN). Advertising will appear on certain Family Hub refrigerator Cover Screens. The Cover Screen appears when a Family Hub screen is idle. Ad design format may change depending on Family Hub personalization options for the Cover Screen, and advertising will not appear when Cover Screen displays Art Mode or picture albums.</p>

<p>Advertisements can be dismissed on the Cover Screens where ads are shown, meaning that specific ads will not appear again during the campaign period.</p></blockquote>
<p>As the statement notes, this is a pilot program for certain Samsung Family Hub refrigerator models sold in the US. As part of the program, these refrigerators will display “promotions and curated advertisements” on certain Cover Screens when the Family Hub screen (i.e., the door display) is idle.</p></div><p>The company notes that ads can be dismissed, and dismissed ads will not appear again. The ad design format will also change depending on the Cover Screen’s personalization options. Ads will not appear when the Cover Screen displays photos or art.</p><p>From the changelog, we know that ads will be displayed on the Cover Screen for the Weather, Color, and Daily Board themes, whereas the Cover Screen for the Art and Gallery themes will not display advertisements, in line with the company’s statement.</p><p>It’s still unclear which exact refrigerators are getting the ad infestation, but Samsung’s current Family Hub-equipped lineup in the US starts at $1,800 and goes all the way up to $3,500. It doesn’t seem like users can entirely turn off ads, which is a shame. Disconnecting the fridge from the internet might stop the ads, but you will also inevitably lose out on several smart features you paid for. If you have a Samsung refrigerator with a door display, let us know in the comments how your experience has been with them, and how you feel about ads coming to them.</p><div data-container-type="content"><p>Thank you for being part of our community. Read our&nbsp;<a href="https://www.androidauthority.com/android-authority-comment-policy/" target="_blank" rel="noopener noreferrer" data-stringify-link="https://www.androidauthority.com/android-authority-comment-policy/" data-sk="tooltip_parent">Comment Policy</a> before posting.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Cactus (YC S25) – AI inference on smartphones (102 pts)]]></title>
            <link>https://github.com/cactus-compute/cactus</link>
            <guid>45291024</guid>
            <pubDate>Thu, 18 Sep 2025 15:40:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cactus-compute/cactus">https://github.com/cactus-compute/cactus</a>, See on <a href="https://news.ycombinator.com/item?id=45291024">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/cactus-compute/cactus/blob/main/assets/banner.jpg"><img src="https://github.com/cactus-compute/cactus/raw/main/assets/banner.jpg" alt="Logo"></a></p>
<p dir="auto">Energy-efficient AI inference framework &amp; kernels for phones &amp; AI-native hardware.
Budget and mid-range phones control over 70% of the market, but frameworks today optimise for the highend phones.
Cactus is designed bottom-up with no dependencies for all mobile devices.</p>
<p dir="auto">Example (CPU-only):</p>
<ul dir="auto">
<li>Model: Qwen3-600m-INT8</li>
<li>File size: 370-420mb</li>
<li>16-20 t/s on Pixel 6a, Galaxy S21, iPhone 11 Pro</li>
<li>50-70 t/s on Pixel 9, Galaxy S25, iPhone 16</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">Cactus exposes 4 levels of abstraction.</p>
<div data-snippet-clipboard-copy-content="┌─────────────────┐
│   Cactus FFI    │ ←── OpenAI compatible C API for integration  
└─────────────────┘
         │
┌─────────────────┐
│  Cactus Engine  │ ←── High-level transformer engine
└─────────────────┘
         │
┌─────────────────┐  
│  Cactus Graph   │ ←── Unified zero-copy computation graph 
└─────────────────┘
         │
┌─────────────────┐
│ Cactus Kernels  │ ←── Low-level ARM-specific SIMD operations
└─────────────────┘"><pre><code>┌─────────────────┐
│   Cactus FFI    │ ←── OpenAI compatible C API for integration  
└─────────────────┘
         │
┌─────────────────┐
│  Cactus Engine  │ ←── High-level transformer engine
└─────────────────┘
         │
┌─────────────────┐  
│  Cactus Graph   │ ←── Unified zero-copy computation graph 
└─────────────────┘
         │
┌─────────────────┐
│ Cactus Kernels  │ ←── Low-level ARM-specific SIMD operations
└─────────────────┘
</code></pre></div>
<p dir="auto">Cactus Graph is a general numerical computing framework that runs on Cactus Kernels.
Great for implementing custom models and scientific computing, like JAX for phones.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include cactus.h

CactusGraph graph;

auto a = graph.input({2, 3}, Precision::FP16);
auto b = graph.input({3, 4}, Precision::INT8);

auto x1 = graph.matmul(a, b, false);
auto x2 = graph.transpose(x1);
auto result = graph.matmul(b, x2, true);

float a_data[6] = {1.1f, 2.3f, 3.4f, 4.2f, 5.7f, 6.8f};
float b_data[12] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};

graph.set_input(a, a_data, Precision::FP16);
graph.set_input(b, b_data, Precision::INT8);
graph.execute();

void* output_data = graph.get_output(result);
graph.hard_reset(); 
"><pre>#<span>include</span> cactus.h

CactusGraph graph;

<span>auto</span> a = graph.input({<span>2</span>, <span>3</span>}, Precision::FP16);
<span>auto</span> b = graph.input({<span>3</span>, <span>4</span>}, Precision::INT8);

<span>auto</span> x1 = graph.matmul(a, b, <span>false</span>);
<span>auto</span> x2 = graph.transpose(x1);
<span>auto</span> result = graph.matmul(b, x2, <span>true</span>);

<span>float</span> a_data[<span>6</span>] = {<span>1</span>.<span>1f</span>, <span>2</span>.<span>3f</span>, <span>3</span>.<span>4f</span>, <span>4</span>.<span>2f</span>, <span>5</span>.<span>7f</span>, <span>6</span>.<span>8f</span>};
<span>float</span> b_data[<span>12</span>] = {<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>};

graph.set_input(a, a_data, Precision::FP16);
graph.set_input(b, b_data, Precision::INT8);
graph.execute();

<span>void</span>* output_data = graph.get_output(result);
graph.hard_reset(); 
</pre></div>
<p dir="auto">Cactus Engine is a transformer inference engine built on top of Cactus Graphs.
It is abstracted via Cactus Foreign Function Interface.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include cactus.h

const char* model_path = &quot;path/to/weight/folder&quot;;
cactus_model_t model = cactus_init(model_path, 2048);

const char* messages = R&quot;([
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;/nothink My name is Henry Ndubuaku&quot;}
])&quot;;

const char* options = R&quot;({
    &quot;temperature&quot;: 0.1,
    &quot;top_p&quot;: 0.95,
    &quot;top_k&quot;: 20,
    &quot;max_tokens&quot;: 50,
    &quot;stop_sequences&quot;: [&quot;<|im_end|>&quot;]
})&quot;;

char response[1024];
int result = cactus_complete(model, messages, response, sizeof(response), options, nullptr, nullptr, nullptr);"><pre>#<span>include</span> cactus.h

<span>const</span> <span>char</span>* model_path = <span><span>"</span>path/to/weight/folder<span>"</span></span>;
<span>cactus_model_t</span> model = cactus_init(model_path, <span>2048</span>);

<span>const</span> <span>char</span>* messages = <span><span>R"(</span>[</span>
<span>    {"role": "system", "content": "You are a helpful assistant."},</span>
<span>    {"role": "user", "content": "/nothink My name is Henry Ndubuaku"}</span>
<span>]<span>)"</span></span>;

<span>const</span> <span>char</span>* options = <span><span>R"(</span>{</span>
<span>    "temperature": 0.1,</span>
<span>    "top_p": 0.95,</span>
<span>    "top_k": 20,</span>
<span>    "max_tokens": 50,</span>
<span>    "stop_sequences": ["&lt;|im_end|&gt;"]</span>
<span>}<span>)"</span></span>;

<span>char</span> response[<span>1024</span>];
<span>int</span> result = cactus_complete(model, messages, response, <span>sizeof</span>(response), options, <span>nullptr</span>, <span>nullptr</span>, <span>nullptr</span>);</pre></div>
<p dir="auto">With tool support:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const char* tools = R&quot;([
    {
        &quot;function&quot;: {
            &quot;name&quot;: &quot;get_weather&quot;,
            &quot;description&quot;: &quot;Get weather for a location&quot;,
            &quot;parameters&quot;: {
                &quot;properties&quot;: {
                    &quot;location&quot;: {
                        &quot;type&quot;: &quot;string&quot;,
                        &quot;description&quot;: &quot;City name&quot;,
                        &quot;required&quot;: true
                    }
                },
                &quot;required&quot;: [&quot;location&quot;]
            }
        }
    }
])&quot;;

int result = cactus_complete(model, messages, response, sizeof(response), options, tools, nullptr, nullptr);"><pre><span>const</span> <span>char</span>* tools = <span><span>R"(</span>[</span>
<span>    {</span>
<span>        "function": {</span>
<span>            "name": "get_weather",</span>
<span>            "description": "Get weather for a location",</span>
<span>            "parameters": {</span>
<span>                "properties": {</span>
<span>                    "location": {</span>
<span>                        "type": "string",</span>
<span>                        "description": "City name",</span>
<span>                        "required": true</span>
<span>                    }</span>
<span>                },</span>
<span>                "required": ["location"]</span>
<span>            }</span>
<span>        }</span>
<span>    }</span>
<span>]<span>)"</span></span>;

<span>int</span> result = cactus_complete(model, messages, response, <span>sizeof</span>(response), options, tools, <span>nullptr</span>, <span>nullptr</span>);</pre></div>
<p dir="auto">This makes it easy to write Cactus bindings for any language.
Header files are self-documenting but documentation contributions are welcome.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Cactus in your apps</h2><a id="user-content-using-cactus-in-your-apps" aria-label="Permalink: Using Cactus in your apps" href="#using-cactus-in-your-apps"></a></p>
<p dir="auto">Cactus SDKs run 500k+ weekly inference tasks in production today, try them!</p>
<a href="https://github.com/cactus-compute/cactus-flutter">
  <img alt="Flutter" src="https://camo.githubusercontent.com/d57d3164dc073311fc19c11367c7aa4011bab2182b3c5f1bc5f0c5aef3471b8e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466c75747465722d677265792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d466c7574746572266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Flutter-grey.svg?style=for-the-badge&amp;logo=Flutter&amp;logoColor=white">
</a> <a href="https://github.com/cactus-compute/cactus-react">
  <img alt="React Native" src="https://camo.githubusercontent.com/fe61c2055c44a2fab881671623eba1a62b544ffb5b87630950d1fb1d07ad932e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742532304e61746976652d677265792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d7265616374266c6f676f436f6c6f723d253233363144414642" data-canonical-src="https://img.shields.io/badge/React%20Native-grey.svg?style=for-the-badge&amp;logo=react&amp;logoColor=%2361DAFB">
</a> <a href="https://github.com/cactus-compute/cactus-kotlin">
  <img alt="Kotlin Multiplatform" src="https://camo.githubusercontent.com/6256a84b4568b4c8b1ced300592082852c763cd18cac9d1411db5047de672f76/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4b6f746c696e5f4d756c7469706c6174666f726d2d677265792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f746c696e266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Kotlin_Multiplatform-grey.svg?style=for-the-badge&amp;logo=kotlin&amp;logoColor=white">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<a href="https://cactuscompute.com/docs" rel="nofollow">
  <img alt="Documentation" src="https://camo.githubusercontent.com/66eae253333dba0dc826720ca250cd806b2b8a9bb8e07f64f4c12ab7b974c90b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63756d656e746174696f6e2d3441393045323f7374796c653d666f722d7468652d6261646765266c6f676f3d676974626f6f6b266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Documentation-4A90E2?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white">
</a> <a href="https://discord.gg/bNurx3AXTJ" rel="nofollow">
  <img alt="Discord" src="https://camo.githubusercontent.com/62d3d35241760cf174631c4e6b5f4503c0a6b34640fd306e36a829ab5ec47b14/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d3538363546323f7374796c653d666f722d7468652d6261646765266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<a href="https://apps.apple.com/gb/app/cactus-chat/id6744444212" rel="nofollow">
  <img alt="Download iOS App" src="https://camo.githubusercontent.com/35be197596b80ef392cccd1610b6204c38198b871e5c90d2c8c02d3b9e46e28c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5472795f694f535f44656d6f2d677265793f7374796c653d666f722d7468652d6261646765266c6f676f3d6170706c65266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Try_iOS_Demo-grey?style=for-the-badge&amp;logo=apple&amp;logoColor=white">
</a> <a href="https://play.google.com/store/apps/details?id=com.rshemetsubuser.myapp&amp;pcampaignid=web_share" rel="nofollow">
  <img alt="Download Android App" src="https://camo.githubusercontent.com/7b16e937255afaf712ca03a71a3c1d1b93f15173c637e0b2ca779d6c77f03050/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5472795f416e64726f69645f44656d6f2d677265793f7374796c653d666f722d7468652d6261646765266c6f676f3d616e64726f6964266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Try_Android_Demo-grey?style=for-the-badge&amp;logo=android&amp;logoColor=white">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing or Using the Repo</h2><a id="user-content-contributing-or-using-the-repo" aria-label="Permalink: Contributing or Using the Repo" href="#contributing-or-using-the-repo"></a></p>
<p dir="auto">You can run these codes directly on Macbooks with Apple chips due to their design.
Performance gain is observed in mobile devices but for testing during development,
Vanilla M3 CPU-only can run Qwen3-600m-INT8 at 60-70 toks/sec, use the following:</p>
<ol dir="auto">
<li><strong>Generate weights from HuggingFace model:</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python3 tools/convert_hf.py Qwen/Qwen3-0.6B weights/qwen3-600m-i8/ --precision INT8"><pre>python3 tools/convert_hf.py Qwen/Qwen3-0.6B weights/qwen3-600m-i8/ --precision INT8</pre></div>
<ol start="2" dir="auto">
<li><strong>Build and test:</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./tests/run.sh # remember to chmod +x any script first time
"><pre>./tests/run.sh <span><span>#</span> remember to chmod +x any script first time</span>
</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap:</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap:" href="#roadmap"></a></p>
<ul dir="auto">
<li>Gemma, SmolVLM, Liquid, Kitten, Vosk etc.</li>
<li>SMMLA, NPU &amp; DSP for high-end phones.</li>
<li>INT4 support for 1B+ models.</li>
<li>Python tools for porting Torch/JAX cactus.</li>
</ul>
<p dir="auto">Preliminary results:</p>
<ul dir="auto">
<li>Qwen3-4B-INT4 on iPhone 16 Pro NPU = 21 t/s</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Footer</h2><a id="user-content-footer" aria-label="Permalink: Footer" href="#footer"></a></p>
<p dir="auto">While Cactus can be used for all Apple devices including Macbooks, for computers/AMD/Intel/Nvidia generally,
please use HuggingFace, Llama.cpp, Ollama, vLLM, MLX. They're built for those, support x86, and are all great!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TernFS – An exabyte scale, multi-region distributed filesystem (224 pts)]]></title>
            <link>https://www.xtxmarkets.com/tech/2025-ternfs/</link>
            <guid>45290245</guid>
            <pubDate>Thu, 18 Sep 2025 14:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.xtxmarkets.com/tech/2025-ternfs/">https://www.xtxmarkets.com/tech/2025-ternfs/</a>, See on <a href="https://news.ycombinator.com/item?id=45290245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent">
    
<p><strong>September 2025</strong></p>
<p>XTX is an algorithmic trading firm: it builds statistical models that produce price forecasts for over 50,000 financial instruments worldwide. We use those forecasts to make trades. As XTX's research efforts to build better models ramped up, the demand for resources kept increasing.</p>
<p>The firm started out with a couple of desktops and an NFS server, and 10 years later ended up with tens of thousands of high-end GPUs, hundreds of thousands of CPUs, and hundreds of petabytes of storage.</p>
<p>As compute grew, storage struggled to keep up. We rapidly outgrew NFS first and existing open-source and commercial filesystems later. After evaluating a variety of third-party solutions, we made the decision to implement our own filesystem, which we called TernFS<sup><a href="#f1">[1]</a></sup>.</p>

<p>We have decided to open source our efforts: TernFS is <a href="https://github.com/XTXMarkets/ternfs">available as free software on our public GitHub.</a> This post <a href="#another-filesystem">motivates TernFS</a>, explains its <a href="#high-level">high-level architecture</a>, and then explores some <a href="#important-details">key implementation details</a>. If you just want to spin up a local TernFS cluster, head to the <a href="https://github.com/XTXMarkets/ternfs?tab=readme-ov-file#playing-with-a-local-ternfs-instance">README</a>.</p>

<h2>Another filesystem?</h2>
<p>There's a reason why every major tech company has developed its own distributed filesystem — they're crucial to running large-scale compute efforts, and liable to cause intense disruption if they malfunction. <sup><a href="#f2">[2]</a></sup></p>

<p>XTX was in the same position, so we designed TernFS to be a one-stop solution for most of our storage needs, going from relatively 'cold' storage of raw market data to short-lived random-access data used to communicate between GPU jobs running on our cluster.</p>
<p>TernFS:</p>
<ul>
<li>Is designed to scale up to tens of exabytes, trillions of files, millions of concurrent clients.</li>
<li>Stores file contents redundantly to protect against drive failures.</li>
<li>Has no single point of failure in its metadata services.</li>
<li>Supports file snapshot to protect against accidental file deletion.</li>
<li>Can span across multiple regions.</li>
<li>Is hardware agnostic and uses TCP/IP to communicate.</li>
<li>Utilizes different types of storage (such as flash vs. hard disks) cost effectively.</li>
<li>Exposes read/write access through its own API over TCP and UDP, and a Linux kernel filesystem module.</li>
<li>Requires no external service and has a minimal set of build dependencies. <sup><a href="#f3">[3]</a></sup></li>
</ul>

<p>Naturally, there are some limitations, the main ones being:</p>
<ul>
<li>Files are immutable — once they're written they can't be modified.</li>
<li>TernFS should not be used for tiny files — our median file size is 2MB.</li>
<li>The throughput of directory creation and removal is significantly constrained compared to other operations.</li>
<li>TernFS is permissionless, deferring that responsibility to other services.</li>
</ul>
<p>We started designing TernFS in early 2022 and began putting it into production in summer 2023. By mid-2024 all of our machine learning efforts were driven out of TernFS, and we're migrating the rest of the firm's storage needs onto it as well.</p>
<p>As of September 2025, our TernFS deployment stores more than 500PB across 30,000 disks, 10,000 flash drives, and three data centres. At peak we serve multiple terabytes per second. To this day, we haven't lost a single byte.</p>

<h2>High-level overview</h2>
<p>Now that the stage is set, we're ready to explain the various components that make up TernFS. TernFS' core API is implemented by four services:</p>
<ul>
<li><em>Metadata shards</em> store the directory structure and file metadata.</li>
<li>The <em>cross-directory coordinator</em> (or CDC) executes cross-shard transactions.</li>
<li><em>Block services</em> store file contents.</li>
<li>The <em>registry</em> stores information about all the other services and monitors them.</li>
</ul>
<pre><code>
 A ──► B means "A sends requests to B" 
                                       
                                       
 ┌────────────────┐                    
 │ Metadata Shard ◄─────────┐          
 └─┬────▲─────────┘         │          
   │    │                   │          
   │    │                   │          
   │ ┌──┴──┐                │          
   │ │ CDC ◄──────────┐     │          
   │ └──┬──┘          │     │          
   │    │             │ ┌───┴────┐     
   │    │             └─┤        │     
 ┌─▼────▼────┐          │ Client │     
 │ Registry  ◄──────────┤        │     
 └──────▲────┘          └─┬──────┘     
        │                 │            
        │                 │            
 ┌──────┴────────┐        │            
 │ Block Service ◄────────┘            
 └───────────────┘

</code></pre>

<p>In the next few sections, we'll describe the high-level design of each service and then give more background on <a href="#important-details">other relevant implementation details</a>.<sup><a href="#f4">[4]</a></sup></p>

<h3>Metadata</h3>
<p>To talk about metadata, we first need to explain what metadata <em>is</em> in TernFS. The short answer is: 'everything that is not file contents.' The slightly longer answer is:</p>
<ul>
<li>Directory entries, including all files and directory names.</li>
<li>File metadata including creation/modification/access time, logical file size, and so on.</li>
<li>The mapping between files and the <a href="#block-services">blocks containing their contents</a>.</li>
<li>Other ancillary data structures to facilitate maintenance operations.</li>
</ul>
<p>TernFS' metadata is split into 256 logical <em>shards</em>. Shards never communicate with each other. This is a general principle in TernFS: each service is disaggregated from the others, deferring to the clients to communicate with each service directly.<sup><a href="#f5">[5]</a></sup></p>

<p>A logical shard is further split into five physical instances, one leader and four followers, in a typical distributed consensus setup. The distributed consensus engine is provided by a purpose-built Raft-like implementation, which we call LogsDB, while RocksDB is used to implement read/write capabilities within a shard instance.</p>
<p>Currently all reads and writes go through the leader, but it would be trivial to allow clients to read from followers, and with a bit more effort to switch to a write-write setup.</p>
<pre><code>    ┌─────────┐ ┌─────────┐       ┌───────────┐ 
    │ Shard 0 │ │ Shard 1 │  ...  │ Shard 255 │ 
    └─────────┘ │         │       └───────────┘ 
            ┌───┘         └───────────────────┐ 
            │                                 │ 
            │                  ┌────────────┐ │ 
            │ ┌───────────┐    │ Replica 0  │ │ 
            │ │           ◄────► (follower) │ │ 
 ┌────────┐ │ │ Replica 3 ◄──┐ └────────────┘ │ 
 │ Client ├─┼─► (leader)  ◄─┐│ ┌────────────┐ │ 
 └────────┘ │ │           ◄┐│└─► Replica 1  │ │ 
            │ └───────────┘││  │ (follower) │ │ 
            │              ││  └────────────┘ │ 
            │              ││  ┌────────────┐ │ 
            │              │└──► Replica 2  │ │ 
            │              │   │ (follower) │ │ 
            │              │   └────────────┘ │ 
            │              │   ┌────────────┐ │ 
            │              └───► Replica 4  │ │ 
            │                  │ (follower) │ │ 
            │                  └────────────┘ │ 
            └─────────────────────────────────┘ 
</code></pre>

<p>Splitting the metadata into 256 shards from the get-go simplifies the design, given that horizontal scaling of metadata requires no rebalancing, just the addition of more metadata servers.</p>
<p>For instance, our current deployment can serve hundreds of petabytes and more than 100,000 compute nodes with just 10 metadata servers per data centre, with each server housing roughly 25 shard leaders and 100 shard followers.</p>
<p>Given that the metadata servers are totally decoupled from one another, this means that we can scale metadata performance by 25× trivially, and by 100× if we were to start offloading metadata requests to followers.</p>
<p>TernFS shards metadata by assigning each directory to a single shard. This is done in a simple round-robin fashion by the <a href="#cdc">cross-directory coordinator</a>. Once a directory is created, all its directory entries and the files in it are housed in the same shard.</p>
<p>This design decision has downsides: TernFS assumes that the load will be spread across the 256 logical shards naturally. This is not a problem in large deployments, given that they will contain many directories, but it is something to keep in mind.<sup><a href="#f6">[6]</a></sup></p>


<h3>Cross-directory transactions</h3>
<p>Most of the metadata activity is contained within a single shard:</p>
<ul>
<li>File creation, same-directory renames, and deletion.</li>
<li>Listing directory contents.</li>
<li>Getting attributes of files or directories.</li>
</ul>
<p>However, some operations do require coordination between shards, namely directory creation, directory removal, and moving directory entries across different directories.</p>
<p>The <em>cross-directory coordinator</em> (CDC) performs these distributed transactions using a privileged metadata shard API. The CDC transactions are stateful, and therefore the CDC uses RocksDB and LogsDB much like the metadata shards themselves to persist its state safely.</p>
<pre><code> ┌────────┐    ┌──────────┐ ┌───────────┐ 
 │ Client ├─┐  │ Shard 32 │ │ Shard 103 │ 
 └────────┘ │  └────────▲─┘ └─▲─────────┘ 
 ┌─────┬────┼───────────┼─────┼─┐         
 │ CDC │  ┌─▼──────┐    │     │ │         
 ├─────┘  │ Leader ├────┴─────┘ │         
 │        └─────▲──┘            │         
 │              │               │         
 │       ┌──────┴───────┐       │         
 │       │              │       │         
 │ ┌─────▼────┐    ┌────▼─────┐ │         
 │ │ Follower │ .. │ Follower │ │         
 │ └──────────┘    └──────────┘ │         
 └──────────────────────────────┘   
</code></pre>

<p>The CDC executes transactions in parallel, which increases throughput considerably, but it is still a bottleneck when it comes to creating, removing, or moving directories. This means that TernFS has a relatively low throughput when it comes to CDC operations.<sup><a href="#f7">[7]</a></sup> <a name="block-services"></a></p>

<h3>Block services, or file contents</h3>
<p>In TernFS, files are split into chunks of data called <em>blocks</em>. Blocks are read and written to by <em>block services</em>. A block service is typically a single drive (be it a hard disk or a flash drive) storing blocks. At XTX a typical storage server will contain around 100 hard disks or 25 flash drives — or in TernFS parlance 100 or 25 block services.<sup><a href="#f8">[8]</a></sup></p>

<p>Read/write access to the block service is provided using a simple TCP API currently implemented by a Go process. This process is hardware agnostic and uses the Go standard library to read and write blocks to a conventional local file system. We originally planned to rewrite the Go process in C++, and possibly write to block devices directly, but the idiomatic Go implementation has proven performant enough for our needs so far. <a name="registry"></a></p>
<h3>The registry</h3>
<p>The final piece of the TernFS puzzle is the <em>registry</em>. The registry stores the location of each instance of service (be it a metadata shard, the CDC, or a block storage node). A client only needs to know the address of the registry to mount TernFS — it'll then gather the locations of the other services from it.</p>
<p>In TernFS all locations are IPv4 addresses. Working with IPv4 directly simplifies the kernel module considerably, since DNS lookups are quite awkward in the Linux kernel. The exception to this rule is addressing the registry itself, for which DNS is used.</p>
<p>The registry also stores additional information, such as the capacity and available size of each drive, who is a follower or a leader in LogsDB clusters, and so on.</p>
<p>Predictably, the registry itself is a RocksDB and LogsDB C++ process, given its statefulness. <a name="going-global"></a></p>
<h3>Going global</h3>
<p>TernFS tries very hard not to lose data, by storing both metadata and file contents on many different drives and servers. However, we also want to be resilient to the temporary or even permanent loss of one entire data centre. Therefore, TernFS can transparently scale across multiple <em>locations</em>.</p>
<p>The intended use for TernFS locations is for each location to converge to the same dataset. This means that each location will have to be provisioned with roughly equal resources.<sup><a href="#f9">[9]</a></sup> Both metadata and file contents replication are asynchronous. In general, we judge the event of losing an entire data centre rare enough to tolerate a time window where data is not fully replicated across locations.</p>

<p>Metadata replication is set up so that one location is the metadata primary. Write operations in non-primary locations pay a latency price since they are acknowledged only after they are written to the primary location, replicated, and applied in the originating location. In practice this hasn't been an issue since metadata write latencies are generally overshadowed by writing file contents.</p>
<p>There is no automated procedure to migrate off a metadata primary location — again, we deem it a rare enough occurrence to tolerate manual intervention. In the future we plan to move from the current protocol to a multi-master protocol where each location can commit writes independently, which would reduce write latencies on secondary locations and remove the privileged status of the primary location.</p>
<p>File contents, unlike metadata, are written locally to the location the client is writing from. Replication to other locations happens in two ways: proactively and on-demand. Proactive replication is performed by tailing the metadata log and replicating new file contents. On-demand replication happens when a client requests file content which has not been replicated yet. <a name="important-details"></a> <a name="speaking-ternfs"></a></p>
<h2>Important Details</h2>
<p>Now that we've laid down the high-level design of TernFS, we can talk about several key implementation details that make TernFS safer, more performant, and more flexible.</p>
<h3>Talking to TernFS</h3>
<h4>Speaking TernFS' language</h4>
<p>The most direct way to talk to TernFS is by using its own API. All TernFS messages are defined using a custom serialization format we call <em>bincode</em>. We chose to develop a custom serialization format since we needed it to work within the confines of the <a href="#posix-shaped">Linux kernel</a> and to be easily chopped into UDP packets.</p>
<p>We intentionally kept the TernFS API stateless, in the sense that each request executes without regard to previous requests made by the same client. This is in contrast to protocols like NFS, whereby each connection is very stateful, holding resources such as open files, locks, and so on.</p>
<p>A stateless API dramatically simplifies the state machines that make up the TernFS core services, therefore simplifying their testing. It also forces each request to be idempotent, or in any case have clear retry semantics, since they might have to be replayed, which facilitates testing further.</p>
<p>It also allows the metadata shards and CDC API to be based on UDP rather than TCP, which makes the server and clients (especially the kernel module) simpler, due to doing away with the need for keeping TCP connections. The block service API is TCP based, since it is used to stream large amounts of contiguous data, and any UDP implementation would have to re-implement a reliable stream protocol. The registry API is also TCP-based, given that it is rarely used by clients, and occasionally needs to return large amounts of data.</p>
<p>While the TernFS API is simple out-of-the-box, we provide a permissively licensed Go library implementing common tasks that clients might want to perform, such as caching directory policies and retrying requests. This library is used to implement many TernFS processes that are not part of the core TernFS services, such as <a href="#scrubbing">scrubbing</a>, <a href="#snapshots">garbage collection</a>, <a href="#migrations">migrations</a>, and the <a href="#web-ui">web UI</a>.</p>

<h4>Making TernFS POSIX-shaped</h4>
<p>While the Go library is used for most ancillary tasks, some with high performance requirements, the main way to access TernFS at XTX is through its Linux kernel module.</p>
<p>This is because, when migrating our machine learning workflows to TernFS, we needed to support a vast codebase working with files directly. This not only meant that we needed to expose TernFS as a normal filesystem, but also that said normal filesystem API needed to be robust and performant enough for our machine learning needs.<sup><a href="#f10">[10]</a></sup></p>

<p>For this reason, we opted to work with Linux directly, rather than using FUSE. Working directly with the Linux kernel not only gave us the confidence that we could achieve our performance requirements but also allowed us to bend the POSIX API to our needs, something that would have been more difficult if we had used FUSE.<sup><a href="#f11">[11]</a></sup></p>

<p>The main obstacle when exposing TernFS as a 'normal' filesystem is that TernFS files are immutable. More specifically, TernFS files are fully written before being 'linked' into the filesystem as a directory entry. This is intentional: it lets us cleanly separate the API for 'under construction' files and 'completed files', and it means that half-written files are not visible.</p>
<p>However this design is essentially incompatible with POSIX, which endows the user with near-absolute freedom when it comes to manipulating a file. Therefore, the TernFS kernel module is <em>not</em> POSIX-compliant, but rather exposes enough POSIX to allow many programs to work without modifications, but not all.</p>
<p>In practice this means that programs which write files left-to-right and never modify the files' contents will work out-of-the-box. While this might seem very restrictive, we found that a surprising number of programs worked just fine.<sup><a href="#f12">[12]</a></sup> Programs that did not follow this pattern were modified to first write to a temporary file and then copy the finished file to TernFS.</p>

<p>While we feel that writing our own kernel module was the right approach, it proved to be the trickiest part of TernFS, and we would not have been able to implement it without <a href="#block-proofs">some important safety checks</a> in the TernFS core services.<sup><a href="#f13">[13]</a></sup></p>

<h4>S3 gateway</h4>
<p>Almost all the storage-related activity at XTX is due to our machine-learning efforts, and for those purposes the TernFS' kernel module has served us well. However, as TernFS proved itself there, we started to look into offering TernFS to the broader firm.</p>
<p>Doing so through the kernel module presented multiple challenges. For starters installing a custom kernel module on every machine that needed to reach TernFS is operationally cumbersome. Moreover, while all machine-learning happens in clusters housed in the same data centre as TernFS itself, we wanted to expose TernFS in a way that's more amenable to less local networks, for instance by removing the need for UDP. Finally, TernFS does not have any built-in support for permissions or authentication, which is a requirement in multi-tenant scenarios.</p>
<p>To solve all these problems, we implemented a gateway for TernFS, which exposes a TernFS subtree using the S3 API. The gateway is a simple Go process turning S3 calls into TernFS API calls. The S3 gateway is not currently open sourced since it is coupled to authentication services internal to XTX, but we have open sourced a minimal S3 gateway to serve as a starting point for third-party contributors to build their own.</p>
<p>We've also planned an NFS gateway to TernFS, but we haven't had a pressing enough need yet to complete it.</p>

<h4>The web UI and the JSON interface</h4>
<p>Finally, a view of TernFS is provided by its web UI. The web UI is a stateless Go program which exposes most of the state of TernFS in an easy-to-use interface. This state includes the full filesystem contents (both metadata and file contents), the status of each service including information about decommissioned block services, and so on.</p>
<p>Moreover, the web UI also exposes the <a href="#speaking-ternfs">direct TernFS API</a> in JSON form, which is very useful for small scripts and curl-style automation that does not warrant a full-blown Go program.</p>

<h3>Directory Policies</h3>
<p>To implement some of the functionality we'll describe below, TernFS adopts a system of per-directory policies.</p>
<p>Policies are used for all sorts of decisions, including:</p>
<ul>
<li><a href="#reed-solomon">How to redundantly store files.</a></li>
<li><a href="#drive-type-picking">On which type of drive to store files.</a></li>
<li><a href="#snapshots">How long to keep files around after deletion.</a></li>
</ul>
<p>Each of the topics above (and a few more we haven't mentioned) correspond to a certain policy <em>tag</em>. The body of the policies are stored in the metadata together with the other directory attributes.</p>
<p>Policies are inherited: if a directory does not contain a certain policy tag, it transitively inherits from the parent directory. TernFS clients store a cache of policies to allow for traversal-free policy lookup for most directories.</p>
<h3>Keeping blocks in check</h3>
<p>A filesystem is no good if it loses, leaks, corrupts, or otherwise messes up its data. TernFS deploys a host of measures to minimize the chance of anything going wrong. So far, these have worked: we've never lost data in our production deployment of TernFS. This section focuses on the measures in place to specifically safeguard files' blocks.</p>
<h4>Against bitrot, or CRC32-C</h4>
<p>The first and possibly most obvious measure consists of aggressively checksumming all TernFS' data. The metadata is automatically checksummed by RocksDB, and every block is stored in a format interleaving 4KiB pages with 4byte CRC32-C checksums.</p>
<p>CRC32-C was picked since it is a high-quality checksum and implemented on most modern silicon.<sup><a href="#f14">[14]</a></sup> It also exhibits some desirable properties when used together with <a href="#block-proofs">Reed-Solomon coding</a>.</p>

<p>4KiB was picked since it is the read boundary used by Linux filesystems and is fine-grained while still being large enough to render the storage overhead of the 4byte checksums negligible.</p>
<p>Interleaving the CRCs with the block contents does not add any safety, but it does improve operations in two important ways. First, it allows for safe partial reads: clients can demand only a few pages from a block which is many megabytes in size and still check the reads against its checksum. Second, it allows <a href="#scrubbing">scrubbing</a> files locally on the server which hosts the blocks, without communicating with other services at all.</p>

<h4>Storing files redundantly, or Reed-Solomon codes</h4>
<p>We've been talking about files being split into blocks, but we haven't really explained <em>how</em> files become blocks.</p>
<p>The first thing we do to a file is split it into <em>spans</em>. Spans are at most 100MiB and are present just to divide files into sections of a manageable size.</p>
<p>Then each span is divided into D <em>data blocks</em>, and P <em>parity blocks</em>. D and P are determined by the corresponding <a href="#directory-policies">directory policy</a> in which the file is created. When D is 1, the entire contents of the span become a single block, and that block is stored D+P times. This scheme is equivalent to a simple mirroring scheme and allows it to lose up to P blocks before losing file data.</p>
<p>While wasteful, mirroring the entire contents of the file can be useful for very hot files, since TernFS clients will pick a block at random to read from, thereby sharing the read load across many block services. And naturally files which we do not care much for can be stored with D = 1 and P = 0, without any redundancy.</p>
<p>That said, most files will not be stored using mirroring but rather using Reed-Solomon coding. Other resources can be consulted to understand the <a href="https://mazzo.li/posts/reed-solomon.html">high-level idea</a> and the <a href="https://www.corsix.org/content/reed-solomon-for-software-raid">low-level details</a> of Reed-Solomon coding, but the gist is it allows us to split a span into D equally sized blocks (some padding might be necessary), and then generate P blocks of equal size such that up to any P blocks can be lost while retaining the ability to reconstruct all the other blocks.</p>
<p>As mentioned, D and P are fully configurable, but at XTX we tend to use D = 10 and P = 4, which allows us to lose up to any four drives for any file.</p>

<h4>Drive type picking</h4>
<p>We now know how to split files into a bunch of blocks. The next question is: which drives to pick to store the blocks on. The first decision is which kind of drive to use. At XTX we separate drives into two broad categories for this purpose — flash and spinning disks.</p>
<p>When picking between these two, we want to balance two needs: minimizing the cost of hardware by utilizing hard disks if we can <sup><a href="#f15">[15]</a></sup>, and maximizing hard disk productivity by having them reading data most of the time, rather than seeking.</p>

<p>To achieve that, directory policies offer a way to tune how large each block will be, and to tune which drives will be picked based on block size. This allows us to configure TernFS so that larger files that can be read sequentially are stored on hard disks, while random-access or small files are stored on flash. <sup><a href="#f16">[16]</a></sup></p>

<p>Currently this system is not adaptive, but we found that in practice it's easy to carve out sections of the filesystem which are not read sequentially. We have a default configuration which assumes sequential reads and then uses hard disks down to roughly 2.5MB blocks, below which hard disks stop being productive enough and blocks start needing to be written to flash. <a name="block-service-picking"></a></p>
<h4>Block service picking</h4>
<p>OK, we now know what type of drive to select for our files, but we still have tens of thousands of individual drives to pick from. Picking the 'right' individual drive requires some sophistication.</p>
<p>The first thing to note is that drive failures or unavailability are often correlated. For instance, at XTX a single server handles 102 spinning disks. If the server is down, faulty, or needs to be decommissioned, it'll render its 102 disks temporarily or permanently unavailable.</p>
<p>It's therefore wise to spread a file's blocks across many servers. To achieve this, each TernFS block service (which generally corresponds to a single drive) has a <em>failure domain</em>. When picking block services in which to store the blocks for a given file, TernFS will make sure that each block is in a separate failure domain. In our TernFS deployment a failure domain corresponds to a server, but other users might wish to tie it to some other factor as appropriate.</p>
<p>TernFS also tries hard to avoid write bottlenecks by spreading the current write load across many disks. Moreover, since new drives can be added at any time, it tries to converge to a situation where each drive is roughly equally filled by assigning writing more to drives with more available space.</p>
<p>Mechanically this is achieved by having each shard periodically request a set of block services to use for writing from the registry. When handing out block services to shards, the registry selects block services according to several constraints:</p>
<ul>
<li>It never gives block services from the same failure domain to the same shard</li>
<li>It minimizes the variance in how many shards each block service is currently assigned to</li>
<li>It prioritizes block services which have more available space.</li>
</ul>
<p>Then when a client wants to write a new span, requiring D+P blocks, the shard simply selects D+P block services randomly amongst the ones it last received from the registry.</p>
<p>One concept currently absent from TernFS is what is often known as 'copyset replication'. When assigning disks to files at random (even with the caveat of failure domains) the probability of rendering at least one file unreadable quickly becomes a certainty as more and more drives fail:</p>
<p><img src="https://www.xtxmarkets.com/assets/tech/2025-ternfs-faileddisks.png" alt="Probability of data loss vs Failed disks" title="Probability of data loss vs Failed disks"></p>

<p>Copysets reduce the likelihood of data loss occurring by choosing blocks out of a limited number of sets of drives, as opposed to picking the drives randomly. This dramatically reduces the probability of data loss<sup><a href="#f17">[17]</a></sup>.  They are generally a good idea, but we haven't found them to be worthwhile, for a few reasons.</p>

<p>First, evacuating a 20TB drive takes just a few minutes, and in the presence of multiple failed drives the migrator process evacuates first the files which are present in multiple failed drives to get ahead of possible data loss. This means that for TernFS to lose data within a single data centre tens of drives would have to fail within a matter of seconds.</p>
<p>More importantly, our TernFS deployment is replicated across three data centres. This replication eliminates the chance of losing data due to 'independent' drive failures — thousands of drives would need to fail at once. Obviously, data centre wide events <em>can</em> cause a large proportion of the drives within it to fail, but having such an event in three data centres at once is exceedingly unlikely.</p>
<p>Finally, copysets are not without drawbacks or complications. Assigning drives at random is an optimal strategy when it comes to evacuating drives quickly, since the files with blocks in the drives to be evacuated will be evenly spread over the rest of the filesystem, and since we only ever need to replace the failed blocks given that we're not constrained by fitting the new set of blocks in predetermined copysets. This means that the evacuation procedure will not be bottlenecked by drive throughput, which is what enables evacuation to finish in a matter of minutes. Moreover, the algorithm to distribute drives to shards is significantly simpler and more flexible than if it needed to care about copysets.</p>
<p>However, users that wish to deploy TernFS within a single data centre might wish to implement some form of copyset replication. Such a change would be entirely contained to the registry and would not change any other component.</p>

<h4>Block Proofs</h4>
<p>We now have a solid scheme to store files redundantly (thanks to Reed-Solomon codes) and protect against bitrot (thanks to the checksums). However, said schemes are only as good as their implementation.</p>
<p>As previously mentioned, TernFS clients communicate their intention to write a file to metadata servers, the metadata servers select block services that the blocks should be written to, and the clients then write the blocks to block services independently of the metadata services. The same happens when a client wants to erase blocks: the client first communicates its intentions to delete the blocks to the right metadata shard and then performs the erasing itself.</p>
<p>This poses a challenge. While verifying the correctness of the core TernFS services is feasible, verifying all clients is not, but we'd still like to prevent buggy clients from breaking key invariants of the filesystem.</p>
<p>Buggy clients can wreak havoc in several ways:</p>
<ul>
<li>They can <em>leak data</em> by writing blocks to block services that are not referenced anywhere in the metadata.</li>
<li>They can <em>lose data</em> by erasing blocks which are still referenced in metadata.</li>
<li>They can <em>corrupt data</em> by telling the metadata services they'll write something and then writing something else.</li>
</ul>
<p>We address all these points by using what we call <em>block proofs</em>. To illustrate how block proofs work, it's helpful to go through the steps required to write new data to a file.</p>
<ol>
<li>When a client is creating a file, it'll do so by adding its <a href="#reed-solomon">file spans</a> one-by-one. For each span the client wants to add it sends an 'initiate span creation' request to the right metadata shard. This request contains both the overall checksum of the span, and the checksum of each block in it (including parity blocks).</li>
<li>The metadata shard checks the consistency of the checksum of the span and of its blocks, something it can do thanks to <a href="https://mazzo.li/posts/rs-crc.html">some desirable mathematical properties</a> of CRCs.</li>
<li>The shard picks block services for the blocks to be written in and returns this information to the client together with a signature for each 'block write' instruction.</li>
<li>The client forwards this signature to the block services, which will refuse to write the block without it. Crucially, the cryptographic signature ranges over a unique identity for the block (ensuring we only write the block we mean to write), together with its checksum, ensuring we don't write the wrong data.<sup><a href="#f18">[18]</a></sup></li>
<li>After committing the block to disk, the block service returns a 'block written' signature to the client.</li>
<li>Finally, the client forwards the block written signature back to the shard, which certifies that the span has been written only when it has received the signatures for all the blocks that make up the span. <sup><a href="#f19">[19]</a></sup></li>
</ol>

<p>Similarly, when a client wants to delete a span, it first asks the metadata shard to start doing so. The metadata shard marks the span as 'in deletion' and returns a bunch of 'block erase' signatures to the client. The client then forwards the signatures to the block services that hold the blocks, which delete the blocks, and return a 'block erased' signature. The clients forward these signatures back to the metadata shards, which can then forget about the span entirely.</p>

<p>We use AES to generate the signatures for simplicity but note that the goal here is not protecting ourselves from malicious clients — just buggy ones. The keys used for the signature are not kept secret, and CRC32-C is not a secure checksum. That said, we've found this scheme enormously valuable in the presence of <a href="#posix-shaped">complex clients</a>. We spent considerable efforts making the core services very simple so we could then take more implementation risks in the clients, with the knowledge that we would have a very low chance of corrupting the filesystem itself.</p>

<h4>Scrubbing</h4>
<p>Finally, if things go wrong, we need to notice. The most common failure mode for a drive is for it to fail entirely, in which case our internal hardware monitoring system will pick it up and migrate from it automatically. The more insidious (and still very common) case is a single sector failing in a drive, which will only be noticed when we try to read the block involving that sector.</p>
<p>This is acceptable for files which are read frequently, but some files might be very 'cold' but still very important.</p>
<p>Consider the case of raw market data taps which are immediately converted to some processed, lossy format. While we generally will use the file containing the processed data, it's paramount to store the raw market data forever so that if we ever want to include more information from the original market data, we can. So important cold files might go months or even years without anyone reading them, and in the meantime, we might find that enough blocks have been corrupted to render them unreadable.<sup><a href="#f20">[20]</a></sup></p>

<p>To make sure this does not happen, a process called the <em>scrubber</em> continuously reads every block that TernFS stores, and replaces blocks with bad sectors before they can cause too much damage.</p>

<h3>Snapshots and garbage collection</h3>
<p>We've talked at length about what TernFS does to try to prevent data loss due to hardware failure or bugs in clients. However, the most common type of data loss is due to human error — the <code>rm —rf / home/alice/notes.txt</code> scenario.</p>
<p>To protect against these scenarios, TernFS implements a lightweight snapshotting system. When files or directories are deleted, their contents aren't actually deleted. Instead, a weak reference to them is created. We call such weak references <em>snapshot</em> directory entries.</p>
<p>Snapshot entries are not be visible through the kernel module or the S3 gateway, but are visible through <a href="#speaking-ternfs">the direct API</a>, and at XTX we have developed internal tooling to easily recover deleted files through it.<sup><a href="#f21">[21]</a></sup> Deleted files are also visible through the TernFS web UI.</p>

<p>Given that 'normal' file operations do not delete files, but rather make them a snapshot, the task of freeing up space is delegated to an external Go process, the <em>garbage collector</em>. The garbage collector traverses the filesystem and removes expired snapshots, which involves deleting their blocks permanently. Snapshot expiry is predictably regulated by <a href="#directory-policies">directory policies</a>.</p>
<h3>Keeping TernFS healthy</h3>
<p>This last section covers how we (humans of XTX) notice problems in TernFS, and how TernFS self-heals when things go wrong — both key topics if we want to ensure no data loss and notice performance problems early.</p>
<h4>Performance metrics</h4>
<p>TernFS exposes a plethora of performance metrics through the HTTP <a href="https://docs.influxdata.com/influxdb/v2/reference/syntax/line-protocol/">InfluxDB line protocol</a>. While connecting TernFS to a service which ingests these metrics is optional, it is <em>highly</em> recommended for any production service.</p>
<p>Moreover, the kernel module exposes many performance metrics itself through DebugFS.</p>
<p>Both types of metrics, especially when used in tandem, have proved invaluable to resolve performance problems quickly.</p>
<h4>Logging and alerts</h4>
<p>TernFS services log their output to files in a simple line-based format. The internal logging API is extremely simple and includes support for syslog levels out-of-the-box. At XTX we run TernFS as normal systemd services and use journalctl to view logs.</p>
<p>As with metrics, the kernel module includes various logging facilities as well. The first type of logging is just through dmesg, but the kernel module also includes numerous tracepoints for low-overhead opt-in logging of many operations.</p>
<p>TernFS is also integrated with XTX's internal alerting system, called <em>XMon</em>, to page on call developers when things go wrong. XMon is not open source, but all the alerts are also rendered as error lines in logs. <sup><a href="#f22">[22]</a></sup> We plan to eventually move to having alerts feed off performance metrics, which would make them independent from XMon, although we don't have plans to do so in the short-term. <a name="migrations"></a></p>

<h4>Migrations</h4>
<p>Finally, there's the question of what to do when drives die — and they will die, frequently, when you have 50,000 of them. While drives dying is not surprising, we've been surprised at the variety of different drive failures. <sup><a href="#f23">[23]</a></sup> A malfunctioning drive might:</p>

<ul>
<li>Produce IO errors when reading specific files. This is probably due to a single bad sector.</li>
<li>Produce IO errors when reading or writing anything. This might happen because enough bad sectors have gone bad and the drive cannot remap them, or for a variety of other reasons.</li>
<li>Return wrong data. This is usually caught by the built-in error correction codes in the hard drives, but not always.</li>
<li>Lie about data being successfully persisted. This can manifest in a variety of ways: file size being wrong on open, file contents being partially zero'd out, and so on.</li>
<li>Disappear from the mount list, only to reappear when the machine is rebooted, but missing some data.</li>
</ul>
<p>When clients fail to read from a drive, they'll automatically fall back on other drives to reconstruct the missing data, which is extremely effective in hiding failures from the end-user. That said, something needs to be done about the bad drives, and <a href="#block-service-picking">done quickly to avoid permanent data loss</a>.</p>
<p>The TernFS registry allows marking drives as faulty. Faulty drives are then picked up by the <em>migrator</em>, a Go process which waits for bad drives and then stores all its blocks onto freshly picked block services.</p>
<p>TernFS also tries to mark drives as bad automatically using a simple heuristic based on the rate of IO errors the drive is experiencing. The number of drives automatically marked as faulty is throttled to avoid having this check go awry and mark the whole cluster as faulty, which would not be catastrophic but would still be messy to deal with.</p>
<p>Moreover, drives that are faulty in subtle ways might not be picked up by the heuristics, which means that occasionally a sysadmin will need to mark a drive as faulty manually, after which the migrator will evacuate them.</p>
<h2>Closing thoughts</h2>
<p>At XTX we feel strongly about utilizing our resources efficiently. When it comes to software, this means having software that gets close to some theoretical optimum when it comes to total cost of ownership. This culture was borne out by competing hard for technological excellence when doing on-exchange trading at first, and by our ever-growing hardware costs as our business has grown later.</p>
<p>Such idealized tools might not exist or be available yet, in which case we're happy to be the tool makers. TernFS is a perfect example of this and we're excited to open source this component of our business for the community.</p>
<p>Crucially, the cost of implementation of a new solution is often overblown compared to the cost of tying yourself to an ill-fitting, expensive third-party solution. Designing and implementing a solution serving exactly your needs allows for much greater simplicity. If the requirements do change, as often happens, changes can be implemented very quickly, again only catering to your needs.</p>
<p>That said, we believe that TernFS' set of trade-offs are widely shared across many organizations dealing with large-scale storage workloads, and we hope we'll contribute to <a href="https://xkcd.com/927/">at least slowing down the seemingly constant stream of new filesystems</a>.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fuck, you're still sad? (349 pts)]]></title>
            <link>https://bessstillman.substack.com/p/oh-fuck-youre-still-sad</link>
            <guid>45290021</guid>
            <pubDate>Thu, 18 Sep 2025 14:17:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bessstillman.substack.com/p/oh-fuck-youre-still-sad">https://bessstillman.substack.com/p/oh-fuck-youre-still-sad</a>, See on <a href="https://news.ycombinator.com/item?id=45290021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><audio src="https://bessstillman.substack.com/api/v1/audio/upload/fd01a944-08be-4ddd-ae11-37c2087b24e6/src" preload="auto">Audio playback is not supported on your browser. Please upgrade.</audio></p><p><strong>My husband Jake has been dead for a year and I still don’t believe it. </strong><span>Not really. Not when I look for his marginalia in new books, or read an article about self-driving cars and text him a link, or when I see an interesting new Malaysian restaurant and have the urge to make us a reservation. Certainly not when I look at our daughter, Athena, who wears Jake’s face as her own and who, especially when she’s examining an object closely, looks out at the world through the same perceptive brown eyes.</span></p><p>I can still see the future I’d imagined for us as clearly as I recall the past. In doing so, time collapses into a single point: Now. It feels like Jake is here right now.</p><p>Apparently, that’s a disease.</p><p><span>The American Psychiatric Association describes “disordered grief,” also known as “prolonged grief,” as a loss that occurred at least one measly year ago for adults (for children there’s an even faster grief clock). The diagnosis is made when people experience three of the following symptoms</span><s>,</s><span> every day</span><s>,</s><span> in the month before the diagnosis is made:</span></p><p>Avoidance of reminders the person has died; intense emotional pain; or, alternately, emotional numbness; difficulty with reintegration; feeling that life is meaningless; intense loneliness; feeling as though part of oneself has died; a marked sense of disbelief.</p><p>Just three?</p><p>I imagine a makeshift consensus group clad in tweed in some back room at a Psychiatric conference deciding on the shelf life of grief over coffee and Costco muffins, like it’s yogurt that’s starting to curdle. Is there a sniff test for pain? How long, exactly, is too long?</p><p>It took almost six months just to stop expecting Jake to text asking me to pick him up from Sky Harbor Airport – Terminal 3 – apologizing for his flight’s long delay. And although I no longer wonder if he’s about to walk through the door, my brain hasn’t given up the fleeting but frequent thought that he might still pick up the phone if I call.</p><p><span>There’s a persistent, searching feeling, as if he’s just around a corner. Last week, I met a friend at Cartel Coffee after work and was confused when she, not Jake, sat down on the couch beside me. Why had Jake sent her when he and I usually meet here after I work a night shift? Then yesterday, while loading groceries into the trunk of my car, I glanced back at the store entrance and thought- Jesus, is he </span><em>still </em><span>in the produce section picking out the perfect zucchini?</span></p><p><strong>In neuroscience, a prediction error refers to the discrepancy</strong><span> between what an organism expects to happen and what actually occurs. The ability to make accurate predictions comes from repetition. When Jake laughed at my stupid jokes every time I told them; when he got irritated because I pushed too hard with the nib of his fine-tipped pen, but still lent it to me anytime I asked; when he reached out to squeeze my hand whenever I felt anxious, that wasn’t just love—that was how I built the mental model of my life. When Jake died, even though he could no longer laugh at my jokes, or lend me a pen, or hold my hans, my brain still expected him to.</span></p><p><span>Dismantling that mental model</span><s>—</s><span>resolving the prediction error–also requires repetition. For a year, I’ve been freshly reminded that the clacking sound from the other room isn’t Jake at his keyboard, but the refrigerator making ice; the bed is always empty when I sneak in after a late shift; the text alert on my phone isn’t Jake sending me a photo of the fancy heirloom bean soup he made for dinner, but a spam message. Sometimes, I’ll go ahead and dial Jake’s phone number in case the laws of entropy have changed, and he picks up (hey, you never know), but his phone only ever rings and then drops to voicemail. He never even recorded a message.</span></p><p>Repetition is the only way to create accurate predictions. Repetition is the only way to dismantle them. And in doing so, dismantle myself. Grief, then, is a terrible kind of learning.</p><p><span>But it seems I’m a slow learner, and, as Jake would confirm, a resistant one: Last night I logged into Jake’s gmail and forwarded myself one of the weekly letters he used to send me, chasing the way my heart reflexively jumps when I see his name in my inbox–</span><s> </s><span>even if it was me who put it there.</span></p><p>So what if I cling to disbelief. In those moments of brief delusion, I feel like myself again.</p><p><span>Which only sharpens the truth: Part of me died with Jake. That’s not a symptom. It’s anatomy. </span><a href="https://bessstillman.substack.com/p/the-year-i-didnt-survive" rel="">My brain isn’t the same, and neither is my body</a><em>. </em><span>A person missing an arm isn’t told it’s a sickness to believe they’re structurally altered. A phantom limb is still gone, even if its ghost causes pain. Death, too, is an amputation.</span></p><p>In as little as six weeks, Axolotls can regrow not just their limbs, but parts of their brain. Starfish create an entire body from a single arm. Zebrafish can regenerate their heart.</p><p>What human has ever regrown their heart? And in just one year?</p><p><strong>For a diagnosis of disordered grief to be made, symptoms</strong><span> not only have to be present a year after the death, but “significantly impact daily life and functioning.” I can’t imagine anything that “significantly impacts”</span><s> </s><span>life </span><em>more</em><span> than death, and not only for the dead guy. And yet since the night Jake died, I’ve been able to shower, drive, and do laundry. I’ve birthed a baby, nursed her, and kept her alive. I’ve returned to work in the hospital and—as far as I know—I haven’t killed anyone. I pay my bills. I brush my teeth.</span></p><p><span>I function. I appear to function very well. Maybe that means I </span><em>am </em><span>well.</span></p><p><span>That’s not to say that I haven’t suspected otherwise. In the first months after Jake died, when I wasn’t paralyzed by grief, I thought that meant something was wrong with me. Then, seven months after Jake’s death, when I suddenly </span><em>was</em><span> paralyzed by grief, I thought that meant something was wrong with me. Countless self-help books reassure me that there’s “no right way to grieve,” but it definitely feels like there’s a wrong way, and we’re quick to diagnose it.</span></p><p><strong>We medicalize grief because we fear it</strong><span>. A diagnosis–</span><s> </s><span>naming what ails us</span><s> </s><span>–</span><s> </s><span>means we can fix it. Every shift I work, I have patients who are disappointed when I don’t have a clear diagnosis for them—even if it means I’ve ruled out a life-threatening one. Ambiguity means sitting with uncertainty and waiting to see how pain evolves. In a world where we swipe midway through 30 second video reels like rats hitting a cocaine lever, who has the patience for that? If what ails us has a name, that means we understand it. If we understand it, we can cure it, if we cure it, we won’t suffer.</span></p><p>Grief resists naming. It shifts and adapts. It’s not the same for any two people, or for any two losses.</p><p>Before the psychiatrists come for me, I understand that the spirit behind the diagnosis isn’t to pathologize a normal human experience, but to pathologize too much of that experience. As if there could be too much being human: Too much sadness. Too much struggle. Too much love.</p><p>I’m too much. And people, I think, are afraid of me. I walk into a room not as Bess, but as a reminder that awful things can happen randomly to any of us. When people first found out about Jake’s tongue cancer, they often asked what his risk factors were: did he smoke heavily? Was it HPV-positive? Did he chew tobacco? They needed to reassure themselves that their own lack of similar risks made them safe. And yet, Jake had no risk factors, which made askers visibly uncomfortable. I remember the way their faces strained to find a plausible explanation that, at the very least, excluded them from the horrible randomness of an impersonal universe.</p><p>I watch people perform the same futile calculations when they find out that I was widowed two months before the birth of my daughter. But what could the risk factors have possibly been for such a fate? What could I have done or not done that made me more susceptible to marrying a man who was dead by his 40th birthday?</p><p>Maybe the problem isn’t that my grief needs to resolve faster, but that other people need it to; then they can still believe that, when their grief comes, it will pass swiftly.</p><p><strong>There’s no modern cultural framework for dealing with death</strong><span>. We hide it, sanitize it, convince ourselves we have the technology to outsmart it, as if the singularity already occurred and we aren’t all still headed for the same six-</span><s> </s><span>foot hole. Memento mori have been replaced by positivity culture. And death, once part of public life, is tucked behind hospital walls for ER docs like me to witness. </span></p><p><span>The Victorians had mourning dress that made their grief visible. Ancient Greek funerals proceeded through the streets with professional wailers in their wake</span><strong>. </strong><span>Grief, once collective, is now treated as if it’s contagious. It’s like glitter: grief gets everywhere, attaches to everything; just walking past it means you’ll find it stuck to your own body in odd places for months.</span></p><p>Is it any wonder, then, that I’ve walked for miles with my baby daughter in her stroller, away from the gaze of family and friends, to keep my grief off display? So I can weep until my throat is raw. So I can sweat and scream until I’m filthy with rage. I duck into the bathroom at work whenever I feel tears coming, splash cold water on my face, and, ten seconds later, walk out with a smile and a wave to whoever is in the hallway.</p><p><span>And while time has taught me to manage the public messiness of grief, if anything, that’s given it space to grow in private. It feels a little shameful, the way it surges like desire behind closed doors, the way I wonder if it’s leaking out around my edges. Secretly–or maybe not so secretly now-I’ve thought: It’s been a </span><em>year</em><span>. Shouldn’t I be better by now?</span></p><p><span>But of course there’s still pain. Of course there’s still anger, bitterness and sorrow. Of course, there’s still loneliness-</span><s> </s><span>Jake’s remains are in a box on my bookshelf beside his copy of </span><em>Lord of the Rings</em><span> while his side of the bed remains empty. Our daughter Athena’s small, sticky hands rest on my cheek, her body dense and warm in my arms while I feed her from my own breast, and yet I’m still starving to be touched. Jake made me promise that I’d eat, and I do, but I’m never full. There’s a constant, baseline, gnawing ache.</span></p><p><strong><span>Maybe I’m repelled by the concept of “disordered grief</span><s>,</s><span>”</span></strong><span> because I can’t conceive of ordered grief. Grief resists linearity. I began grieving Jake while he was still alive, as the cancer relentlessly ate away at both his body and our future together. I still love him although he’s been dead for a year. My pain is recursive: I relentlessly cycle from moments of contentment or joy to shock and sadness and yearning, until the feelings become familiar, but no less breathtaking.</span></p><p><span>Every day grief comes in a different order. Some days I wake up at 4am, seized by the need to hold Jake’s hand</span><s>,</s><span> and feel anger that all I have is a plaster model of it. Other days, grief waits till I’m performing a physical exam on a patient and their wet cough reminds me of the way I would awaken in the middle of the night to hear Jake choking on his own saliva. Time seems to fold in on itself: Sometimes, I close my eyes while I breastfeed my daughter and the cocktail of oxytocin and prolactin saturates my brain in a way that resurrects Jake with hallucinatory vividness. Suddenly, we’re 27 and running out of the cold Seattle rain into Belle’s Buns for coffee, and then Athena unlatches from my nipple and I’ve lost him again.</span></p><p><strong>Time diverged when Jake died. </strong><span>For the rest of the world, a year has passed  since his death, and yet, somehow, it seems like it’s only just happened for me. At first, I was hurt when the flurry of concern and well-wishing that permeated the first weeks after his death naturally receded. Promised visits  failed to materialize. Calls were skipped. People move on with their own lives that continue at normal speed, while a large part of me is still kneeling beside Jake’s corpse, my fingers pressed against his absent pulse.</span></p><p>I don’t know how to resolve that discrepancy. How is it possible to reintegrate into a world that doesn’t understand that mine stopped? It’s hard enough trying to speak to people who haven’t experienced a similar loss, and even more difficult trying to be understood by people living a year in the future. I hadn’t realized before that grief isn’t an illness so much as a physics problem. Catching up may be impossible. I can only move so quickly.</p><p><strong>Every cure is about timing.</strong><span> When a patient comes to the emergency room, I’m only as useful as my ability to react quickly. It only helps if I give epinephrine to the anaphylactic before their throat closes and they develop a hypoxic brain injury. I have 90 minutes to get a patient with a massive heart attack diagnosed, stabilized and into the cardiac cath lab for stenting before their heart is irreversibly damaged. In a patient with a massive pulmonary embolism, I may only have minutes to administer tPA. My job, really, isn’t just to figure out that death is coming, but how fast. Sometimes, that’s impossible, and I lose the race. Other times–and these are the most exciting saves–a patient is clinically dead and I snatch them back. Sometimes it takes a few seconds; in extremely rare instances, hours.</span></p><p>But at no time in over a decade of training did I learn how long it takes to bring a person back to life when they’re not the one who’s died.</p><p><span>A year is nothing.</span><strong> </strong><span>Jake will be dead forever. Then I will be too. In the meantime, I’m not going to wait to be cured of grief so I can return to life. This</span><em> is</em><span> life.</span><em> </em><span>If you’re a mortal who loves other mortals the APA’s list isn’t a warning of what you might feel if you don’t grieve right; it’s a list of what you will feel, again and again, during a lifetime of discovering what’s still worth living for.</span></p><p>Is that sickness? I don’t feel sick. I just still feel love.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Gl2F!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Gl2F!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg" width="1086" height="724" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:724,&quot;width&quot;:1086,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:163207,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bessstillman.substack.com/i/173911439?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Gl2F!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geizhals Preisvergleich Donates USD 10k to the Perl and Raku Foundation (164 pts)]]></title>
            <link>https://www.perl.com/article/geizhals-donates-to-tprf/</link>
            <guid>45289834</guid>
            <pubDate>Thu, 18 Sep 2025 14:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perl.com/article/geizhals-donates-to-tprf/">https://www.perl.com/article/geizhals-donates-to-tprf/</a>, See on <a href="https://news.ycombinator.com/item?id=45289834">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
              
              <p>Sep 18, 2025 by
              
              
                
                
                <a href="#author-bio-olaf-alders">Olaf Alders</a>
              
              </p>
               <img alt="" src="https://www.perl.com/images/geizhals-donates-to-tprf/geizhals_logo_official.svg">
                <p>Today The Perl and Raku Foundation is thrilled to announce a donation of USD
10,000 from <a href="https://geizhals.at/">Geizhals Preisvergleich</a>. This gift helps to
secure the future of The Perl 5 Core Maintenance Fund.</p>
<blockquote>
<p>Perl has been an integral part of our product price comparison platform
from the start of the company 25 years ago. Supporting the Perl 5 Core
Maintenance Fund means supporting both present and future of a
substantial pillar of Modern Open Source Computing, for us and other
current or prospective users.</p></blockquote>
<p>– Michael Kröll of Geizhals Preisvergleich</p>
<blockquote>
<p>“Geizhals is not only providing core funding for the Perl ecosystem, but also
supporting developers, actively contributing to European conferences, and
employing Perl coders. Their interest in the strategic maintenance and
development of Perl and CPAN is of great value to us all, and their
investment is very much appreciated.”</p></blockquote>
<p>– Stuart J Mackintosh, President of The Perl and Raku Foundation</p>
<p>But who exactly is Geizhals, and why does their support matter so much to the
Perl community?</p>
<p>Geizhals Preisvergleich began in July of 1997 as a hobby project—and yes,
“Geizhals” literally translates to “skinflint” in English (they even operate
<a href="https://skinflint.co.uk/">skinflint.co.uk</a> for UK users!). From those humble
beginnings, they’ve leveraged the power of Perl to scale up to serving <a href="https://unternehmen.geizhals.at/">4.3
million monthly users</a>. With Perl being a key
part of their infrastructure, they have generously decided to support the Perl
5 Core Maintenance Fund.</p>
<p>While many of us know about the Core Maintenance Fund, the specific problems it
addresses often remain invisible to users. I reached out to the maintainers
whose work is supported by this fund. This is what core maintainer Tony Cook
had to say:</p>
<blockquote>
<p>My work tends to be little things, I review other people’s work which I think
improves quality and velocity, and fix more minor issues, some examples would
be:</p>
<ul>
<li>
<p>a fix to signal handling where perl could crash where an external library
created threads (<a href="https://github.com/perl/perl5/issues/22487">#22487</a>)</p>
</li>
<li>
<p>fix a segmentation fault in smartmatch against a sub if the sub exited via a
loop exit op (such as last)
(<a href="https://github.com/perl/perl5/issues/16608">#16608</a>)</p>
</li>
<li>
<p>fixed a bug where a regexp warning could leak memory.</p>
</li>
<li>
<p>prevent a confusing undefined warning message when accessing a sub
parameter that was placeholder for a hash element indexed by an
undef key (<a href="https://github.com/perl/perl5/issues/22423">#22423</a>)</p>
</li>
</ul></blockquote>
<p>What Tony has highlighted are the kinds of bug fixes which collectively help to
ensure that Perl remains stable, secure and reliable for the many organisations
and individuals who depend on it.</p>
<p>With organizations like Geizhals Preisvergleich funding the work which Tony and
others put into maintaining the Perl 5 core, we can work together to ensure that
the Perl core continues to receive the maintenance which it deserves, for many
years to come. Whether you’re a startup using Perl for rapid prototyping or an
enterprise running mission-critical systems, your support helps ensure Perl
remains reliable for everyone. Please join us on this journey.</p>
<p>For more information on how to become a sponsor, please contact:
<a href="mailto:olaf@perlfoundation.org">olaf@perlfoundation.org</a></p>

              </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Luau – Fast, small, safe, gradually typed scripting language derived from Lua (169 pts)]]></title>
            <link>https://luau.org/</link>
            <guid>45289558</guid>
            <pubDate>Thu, 18 Sep 2025 13:38:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://luau.org/">https://luau.org/</a>, See on <a href="https://news.ycombinator.com/item?id=45289558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
  







<div>
      
      
        <p>Lua<em>u</em> (lowercase <em>u</em>, /ˈlu.aʊ/) is a fast, small, safe, gradually typed embeddable scripting language derived from Lua.
</p>
      
      


      
      
    </div>



<div id="main" role="main">
  <article itemscope="" itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Luau">
    <meta itemprop="description" content="Luau (lowercase u, /ˈlu.aʊ/) is a fast, small, safe, gradually typed embeddable scripting language derived from Lua.">
    
    

    <section itemprop="text">
      
<div>

  
    <div>
          
            <h2>Motivation</h2>
          

          
            <p>Around 2006, <a href="https://www.roblox.com/">Roblox</a> started using Lua 5.1 as a scripting language for games. Over the years we ended up substantially evolving the implementation and the language; to support growing sophistication of games on the Roblox platform, growing team sizes and large internal teams writing a lot of code for application/editor (1+MLOC as of 2020), we had to invest in performance, ease of use and language tooling, and introduce a gradual type system to the language. <a href="https://luau.org/why">More…</a></p>
          

          
        </div>
  
    <div>
          
            <h2>Sandboxing</h2>
          

          
            <p>Luau limits the set of standard libraries exposed to the users and implements extra sandboxing features to be able to run unprivileged code (written by our game developers) side by side with privileged code (written by us). This results in an execution environment that is different from what is commonplace in Lua. <a href="https://luau.org/sandbox">More…</a></p>
          

          
        </div>
  
    <div>
          
            <h2>Compatibility</h2>
          

          
            <p>Whenever possible, Luau aims to be backwards-compatible with Lua 5.1 and at the same time to incorporate features from later revisions of Lua. However, Luau is not a full superset of later versions of Lua - we do not always agree with Lua design decisions, and have different use cases and constraints. All post-5.1 Lua features, along with their support status in Luau, <a href="https://luau.org/compatibility">are documented here</a>.</p>
          

          
        </div>
  

</div>

<div>
        
          <p><img src="https://luau.org/assets/images/example.png" alt="">
            
          </p>
        

        <div>
          
            <h2>Syntax</h2>
          

          
            <p>Luau is syntactically backwards-compatible with Lua 5.1 (code that is valid Lua 5.1 is also valid Luau); however, we have extended the language with a set of syntactical features that make the language more familiar and ergonomic. The syntax <a href="https://luau.org/syntax">is described here</a>.</p>
          

          
        </div>
      </div>

<div>

  
    <div>
          
            <h2>Analysis</h2>
          

          
            <p>To make it easier to write correct code, Luau comes with a set of analysis tools that can surface common mistakes. These consist of a linter and a type checker, colloquially known as script analysis, and are integrated into <code>luau-analyze</code> command line executable. The linting passes are <a href="https://luau.org/lint">described here</a>, and the type checking user guide can <a href="https://luau.org/typecheck">be found here</a>.</p>
          

          
        </div>
  
    <div>
          
            <h2>Performance</h2>
          

          
            <p>In addition to a completely custom front end that implements parsing, linting and type checking, Luau runtime features new bytecode, interpreter and compiler that are heavily tuned for performance. Luau interpreter can be competitive with LuaJIT interpreter depending on the program. An optional component for manual Just-In-Time compilation is also available for x64 and arm64 platforms, which can considerably speed up certain programs. We continue to optimize the runtime and rewrite portions of it to be even more efficient. While our overall goal is to minimize the amount of time programmers spend tuning performance, some details about the performance characteristics are <a href="https://luau.org/performance">provided for inquisitive minds</a>.</p>
          

          
        </div>
  
    <div>
          
            <h2>Libraries</h2>
          

          
            <p>As a language, Luau is a full superset of Lua 5.1. As far as standard library is concerned, some functions had to be removed from the builtin libraries, and some functions had to be added; refer to <a href="https://luau.org/library">full documentation</a> for details. When Luau is embedded into an application, the scripts normally get access to extra library features that are application-specific.</p>
          

          
        </div>
  

</div>


    </section>
  </article>
</div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flipper Zero Geiger Counter (237 pts)]]></title>
            <link>https://kasiin.top/blog/2025-08-04-flipper_zero_geiger_counter_module/</link>
            <guid>45289453</guid>
            <pubDate>Thu, 18 Sep 2025 13:28:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kasiin.top/blog/2025-08-04-flipper_zero_geiger_counter_module/">https://kasiin.top/blog/2025-08-04-flipper_zero_geiger_counter_module/</a>, See on <a href="https://news.ycombinator.com/item?id=45289453">Hacker News</a></p>
Couldn't get https://kasiin.top/blog/2025-08-04-flipper_zero_geiger_counter_module/: Error: read ECONNRESET]]></description>
        </item>
        <item>
            <title><![CDATA[The quality of AI-assisted software depends on unit of work management (152 pts)]]></title>
            <link>https://blog.nilenso.com/blog/2025/09/15/ai-unit-of-work/</link>
            <guid>45289168</guid>
            <pubDate>Thu, 18 Sep 2025 13:06:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nilenso.com/blog/2025/09/15/ai-unit-of-work/">https://blog.nilenso.com/blog/2025/09/15/ai-unit-of-work/</a>, See on <a href="https://news.ycombinator.com/item?id=45289168">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The craft of AI-assisted software creation is substantially about correctly managing units of work.</p>

<p>When I was new to this emerging craft of AI-assisted coding, I was getting lousy results, despite the models being rather intelligent. Turns out the major bottleneck is not intelligence, but rather providing the correct context.</p>

<p>Andrej Karpathy, <a href="https://youtube.com/clip/Ugkx7m0MVzHTnKXdoDjlqei60zlK4DWCXWr2?si=kIwnm0xQXdSKMQCC">while referencing</a> my <a href="https://blog.nilenso.com/blog/2025/05/29/ai-assisted-coding/">earlier article on this topic</a>, described the work of AI-assisted engineering as “putting AI on a tight leash”. What does a tight leash look like for a process where AI agents are operating on your code more independently than ever? He dropped a hint: work on small chunks of a single concrete thing.</p>

<h2 id="the-right-sized-unit-of-work-respects-the-context">The right sized unit of work respects the context</h2>

<p>I like the term <a href="https://simonwillison.net/2023/Jan/23/riley-goodside/">context engineering</a>, because it has opened up the vocabulary to better describe why managing units of work is perhaps the most important technique to get better results out of AI tools. It centers our discussion around the “canvas” against which our AI is generating code.</p>

<p>I like <a href="https://blog.nilenso.com/blog/2025/09/15/ai-unit-of-work/docs.anthropic.com/en/docs/build-with-claude/context-windows">Anthropic’s visualisation</a> from their docs:</p>

<p><img src="https://blog.nilenso.com/images/blog/context-window-thinking-tools.jpg" alt="Anthropic's visualisation of a context window filling up for each turn until it exceeds the window limit"></p>

<p>The generated output of the LLM is a sample of the next token probability. Every time we generate a token, what has already been generated in the previous iteration is appended to the context window. What this context window looks like has a huge influence on the quality of your generated output.</p>

<p><a href="https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html">Drew Breunig wrote an excellent article</a> about all kinds of things that can go wrong with your context and proposed various techniques to fix them.</p>

<p>The best AI-assisted craftsmen are often thinking about the design and arrangement of their context to get the AI to one-shot a solution. This is tricky and effortful, contrary to what the AI coding hype suggests.</p>

<p>If you don’t provide the necessary information in the context to do a good job, your AI will hallucinate or generate code that is not congruent with the practices of your codebase. It is especially brittle at integration points of your software system.</p>

<p>On the other hand, if you fill up the context with too much information, and <a href="https://research.trychroma.com/context-rot">the quality of your output degrades</a>, because of a lack of focused attention.</p>

<p>Breaking down your task into “right-sized” units of work, which describe just the right amount of detail is perhaps the most powerful lever to improve your context window, and thus the correctness and quality of the generated code.</p>

<h2 id="the-right-sized-unit-of-work-controls-the-propagation-of-errors">The right sized unit of work controls the propagation of errors</h2>

<p>Time for some napkin maths.</p>

<p>Let’s say your AI agent has a 5% chance of making a mistake. I’m not just referring to hallucinations—it could be a subtle mistake because it forgot to look up some documentation or you missed a detail in your specification.</p>

<p>In an agentic multi-turn workflow, which is what all coding workflows are converging to, this error compounds. If your task takes 10 turns to implement, you will have a (1 – 0.95)<sup>10</sup>&nbsp;=&nbsp;59.9% chance of success. Not very high.</p>

<p><a href="https://utkarshkanwat.com/writing/betting-against-agents">Utkarsh Kanwat in his blog post</a> has made the same argument. His conclusion was that any AI agent would need some kind of pause-and-verify gating mechanism at each step for a long-horizon task.</p>

<table>
  <thead>
    <tr>
      <th rowspan="2">Per-action<br>error rate</th>
      <th colspan="4">Overall Success Rate</th>
    </tr>
    <tr>
      <th>5 turns</th>
      <th>10 turns</th>
      <th>20 turns</th>
      <th>50 turns</th>
    </tr>
  </thead>
  <tbody>
    <tr><td>0.1%</td><td>99.5%</td><td>99.0%</td><td>98.0%</td><td>95.1%</td></tr>
    <tr><td>1%</td><td>95.1%</td><td>90.4%</td><td>81.8%</td><td>60.5%</td></tr>
    <tr><td>5%</td><td>77.4%</td><td>59.9%</td><td>35.8%</td><td>7.7%</td></tr>
    <tr><td>10%</td><td>59.0%</td><td>34.9%</td><td>12.2%</td><td>0.5%</td></tr>
    <tr><td>20%</td><td>32.8%</td><td>10.7%</td><td>1.2%</td><td>0.0%</td></tr>
  </tbody>
</table>

<p>What does the state of the art for multi-turn error rates look like? METR recently published a popular chart <a href="https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/">describing how AI models are getting better at long-horizon tasks</a>. Currently GPT-5 is at the top of the leaderboard, where it can perform ~2-hour long tasks at around a 70% success rate. Working backwards (let’s say a 2 hour task is 50+ turns) this would amount to a sub-1% error rate per action.</p>

<p><img src="https://blog.nilenso.com/images/blog/metr.png" alt="Chart showing results of METR's chart showing task horizons increasing over time"></p>

<p>Doesn’t a &lt;1% error rate per action seem suspicious to you? As a regular user of agentic coding tools (my current one is Codex CLI), I’ll eat my shoe if GPT-5 starts nailing my tasks 99.9% of the time.</p>

<p>My intuition derived from experience tells me that even the best AI right now isn’t even 95% likely to be correct. So where is the difference coming from? It needs a closer look at the actual paper:</p>

<blockquote>
  <p>Our tasks typically use environments that do not significantly change unless directly acted upon by the agent. In contrast, real tasks often occur in the context of a changing environment.</p>

  <p>[…]</p>

  <p>Similarly, very few of our tasks are punishing of single mistakes. This is in part to reduce the expected cost of collecting human baselines.</p>
</blockquote>

<p>This is not at all like the tasks I am doing.</p>

<p>METR acknowledges the messiness of the real world. They have come up with a “messiness rating” for their tasks, and the “mean messiness” of their tasks is 3.2/16.</p>

<p>By METR’s definitions, the kind of software engineering work that I’m mostly exposed to would score at least around 7-8, given that software engineering projects are path-dependent, dynamic and without clear counterfactuals. I have worked on problems that get to around 13/16 levels of messiness.</p>

<blockquote>
  <p>An increase in task messiness by 1 point reduces mean success rates by roughly 8.1%</p>
</blockquote>

<p>Extrapolating from METR’s measured effect of messiness, GPT-5 would go from 70% to around 40% success rate for 2-hour tasks. This maps to my experienced reality.</p>

<p>I am not certain that pure intelligence can solve for messiness. Robustness to environmental chaos and the fuzzy nature of reality is fundamentally about managing context well. Until we find the magic sauce that solves this, it is clear that we need a workflow that can break down our problem into units of work, with verifiable checkpoints to manage the compounding of errors.</p>

<p>These verifiable checkpoints need to be <em>legible to humans</em>.</p>

<p><img src="https://blog.nilenso.com/images/blog/unit-of-work-management.jpg" alt="A diagram of boxes that represent units of work, with circles that represent checkpoints where users can verify outcomes and make corrections"></p>

<h2 id="so-what-is-the-right-sized-unit-of-work">So, what is the “right sized” unit of work?</h2>

<p>The right sized unit of work needs to be small and describe the desired outcome concisely.</p>

<p>The desired outcome on completion of a unit of work needs to be human-legible. I argue that it needs to provide legible <em>business value</em>. Ultimately, the users of software are going to be humans (or systems that model human constructs). Therefore, an elegant way to break down a project is to model it as small units of work that provide legible business value at each checkpoint. This will serve the purpose of respecting the context window of the LLM and help manage the propagation of errors.</p>

<p>Software engineers have already defined a unit of work that provides business value and serve as the placeholder for all the context and negotiation of scope—User Stories. I think they are a good starting point to help us break down a large problem into smaller problems that an LLM can one-shot, while providing a concrete result. They center <em>user outcomes</em>, which unlike “tasks”, are robust to the messy dynamic environment of software development.</p>

<p>Deliverable business value is also what all stakeholders can understand and work with. Software is not built in a vacuum by developers—it needs the coordination of teams, product owners, business people and users. The fact that AI agents work in their own context environment separate from the other stakeholders hurts effectiveness and transfer of its benefits. I think this is an important gap that needs to be bridged.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>unit size</th>
      <th>outcome of completion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>TODO item</td>
      <td>small</td>
      <td>incremental technical value</td>
    </tr>
    <tr>
      <td>“Plan Mode”</td>
      <td>large</td>
      <td>technical value</td>
    </tr>
    <tr>
      <td>Amazon Kiro Spec</td>
      <td>small</td>
      <td>technical value</td>
    </tr>
    <tr>
      <td>User Story</td>
      <td>small</td>
      <td>business value</td>
    </tr>
  </tbody>
</table>

<p>Most AI agents today have well-functioning “planning” modes. These are good at keeping the agent on rails, but they mostly provide technical value, and not necessarily a legible business outcome. I believe planning is complementary to our idea of breaking down a project into small units of business value. My proposed unit of work can be planned with existing planning tools. And I believe this is superior to planning over a large unit of work due to the context rot issues described earlier.</p>

<p>Of course, plain old User Stories as described in the Agile canon is not sufficient. It needs to be accompanied by “something more” that can nudge the agents to gather the right context that serves the business value outcome of the stories. What that “something more” could look like is something we hope to answer in the coming months.</p>

<h2 id="the-storymachine-experiment">The StoryMachine experiment</h2>

<p>To test whether user stories with “something more” can indeed serve as optimal units of work that that have the properties I described above, we are running an experiment called <a href="https://github.com/nilenso/storymachine">StoryMachine</a>. Currently StoryMachine does not do much—it reads your PRD and Tech Specs and produces story cards. It is still early days. But we will set up an evaluation system that will help us iterate to a unit of work description that helps us build useful software effortlessly. I hope to share updates on what we find in the coming months.</p>

<p>I want the craft of AI-assisted development to be less effortful and less like a slot-machine. And our best lever to get there is managing the unit of work.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KDE is now my favorite desktop (729 pts)]]></title>
            <link>https://kokada.dev/blog/kde-is-now-my-favorite-desktop/</link>
            <guid>45288690</guid>
            <pubDate>Thu, 18 Sep 2025 12:17:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kokada.dev/blog/kde-is-now-my-favorite-desktop/">https://kokada.dev/blog/kde-is-now-my-favorite-desktop/</a>, See on <a href="https://news.ycombinator.com/item?id=45288690">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
            <p>From <a href="https://kokada.dev/blog/from-gaming-rig-to-personal-computer-my-journey-with-nixos-and-jovian">my last blog
post</a>,
I am now using KDE as the desktop environment for my gaming rig. The reason is
because I want a reasonably easy to use Linux desktop for when my wife needs to
use the PC for something other than gaming, and this was the reason why my
"traditional" <a href="https://swaywm.org/">Sway</a> setup was a no-go.</p>
<p>But, after using KDE for a while I am starting to really appreciate how good it
is. And no, this is not compared to other Linux desktops, but also with both
Windows and macOS (that I need to use often, especially the later since my job
gave me a MacBook Pro).</p>
<p>To start, KDE is surprisingly feature-complete. For example, the network applet
gives lots of information that in other operational systems are either not
available or difficult to access. It is easy to see in the screenshot below:</p>
<p><a href="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_191837.png"><img src="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_191837.png" alt="Wi-Fi information available in the network applet from
KDE"></a></p>
<p>You can see things like channel, signal strength, frequency, MAC address, BSSID
address (so the MAC address of the router). It even includes a handy button to
share the Wi-Fi information via QR code, so you can easily setup a new mobile
device like Android.</p>
<p>By the way, the crop and blur from that screenshot above? I made everything
using the integrated screenshot tool. I didn't need to open an external
application even once. It is also really smart, I need to redo this screenshot
a few times and it kept the cropping to the exact area I was taking the
screenshot before.</p>
<p>Another example, I wanted <a href="https://steamcommunity.com/">Steam</a> to start
automatically with the system, but it has the bad habit of putting its main
window at the top. Really annoying since it sometimes ended up stealing up the
focus. However KDE has this "Window Rules" feature inside "Window Management"
settings where you can pretty much control whatever you want about application
windows. Really useful tool.</p>
<p>KDE also has lots of really well integrated tools. For example, I am using some
Flatpak applications and I can easily configure the permissions via System
Settings. Or if I want hardware information like
<a href="https://en.wikipedia.org/wiki/Self-Monitoring,_Analysis_and_Reporting_Technology">SMART</a>
status, I can just open Info Center. I can prevent the screen and computer to
sleep at the click of a button (something that in both Windows and macOS I need
to install a separate program). The list goes on, I keep getting surprised how
many things that I used to need a third-party program that KDE just has
available by default.</p>
<p><a href="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_192302.png"><img src="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_192302.png" alt="Flatpak permission
management"></a></p>
<p>But not only KDE is fully featured, it is also fast. Now to be clear, this is
a completely subjective analysis but I find KDE faster than Windows 11 in the
same hardware, especially for things integrated in the system itself. For
example, while opening Windows settings it can take a few seconds after a cold
boot, the KDE's System Settings is pretty much instantaneous. Even compared
with macOS in my MacBook Pro M2 Pro (that is of course comparing Apples and
Bananas), KDE just feels snappier. I actually can't find much difference
between KDE and my Sway setup to be honest, except maybe for the heavy use of
animations (that can be disabled, but I ended up liking it after a while).</p>
<p>I will not say KDE is perfect though. At the first launch I got one issue where
it started without the task bar because I connected this PC to both my monitor
and TV, but the TV is used exclusively for gaming. However, KDE considered my
TV the primary desktop and put the task bar only in that monitor, and even
disabling the TV didn't add the task bar to my monitor. Easily fixed by
manually adding a task bar, but an annoying problem (especially when you're not
used to the desktop). There were also a few other minor issues that I don't
remember right now.</p>
<p>After using KDE for about a week I can say that this is the first time that I
really enjoy a desktop environment on Linux, after all those years. Props for
the KDE developers for making the experience so good.</p>
<p><a href="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_195215.png"><img src="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_195215.png" alt="About this System"></a></p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Had No Taste Before AI (203 pts)]]></title>
            <link>https://matthewsanabria.dev/posts/you-had-no-taste-before-ai/</link>
            <guid>45288551</guid>
            <pubDate>Thu, 18 Sep 2025 12:00:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matthewsanabria.dev/posts/you-had-no-taste-before-ai/">https://matthewsanabria.dev/posts/you-had-no-taste-before-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=45288551">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>There’s been an influx of people telling others to develop taste to use AI.
Designers. Marketers. Developers. All of them touting the same message. It’s
ironic, though. These are the same people who never questioned why their designs
all look identical, never iterated beyond the first draft, and never asked if
their work actually solved the problem at hand.</p>
<p>They’re not alone. The loudest voices preaching about taste and AI are often the
ones who never demonstrated taste before AI.</p>
<h2 id="what-is-taste">What is Taste? <span><a href="#what-is-taste" aria-label="Anchor">#</a></span></h2><p>The technology industry has a tendency to use words that mean multiple things
without describing which definition they are referring to. When I read about
taste and AI I usually see people referring to the following definition.</p>
<blockquote>
<p>Critical judgment, discernment, or appreciation of aesthetic quality.</p></blockquote>
<p>In the context of AI, this definition manifests itself in several ways.</p>
<p><strong>Contextual Appropriateness</strong>: Knowing when AI-generated content fits the
situation and when it doesn’t. Put another way, knowing when a human touch is
needed (e.g., a message to a loved one).</p>
<p><strong>Quality Recognition</strong>: Being able to distinguish between useful AI-generated
content and slop. This requires domain knowledge to truly discern aesthetic
quality rather than just functional quality.</p>
<p><strong>Iterative Refinement</strong>: Understanding that AI is a starting point that
requires further iteration. This point is most similar to how culinary taste is
applied to refine a dish by iterating on the recipe and presentation.</p>
<p><strong>Ethical Boundaries</strong>: Recognizing when AI crosses the lines of authenticity,
legality, and respect. Basically, don’t use AI to do bad things.</p>
<p>None of these skills are new. These are the same skills we should have been
applying to our work all along. Why are we asking about taste and AI now when
we should have been applying taste the whole time? Perhaps people advocating for
taste are telling on themselves.</p>
<h2 id="being-tasteless">Being Tasteless <span><a href="#being-tasteless" aria-label="Anchor">#</a></span></h2><p>Some people have no taste. In the best case that may be due to lack of
experience but in the worst case it may be due to ignorance. I’m noticing that
many people worried about tasteless AI-generated content are often guilty of
producing tasteless content themselves, usually manifesting as the following.</p>
<ul>
<li>
<p>Copying and pasting code without understanding it.</p>
</li>
<li>
<p>Sending resumes and emails that aren’t proofread and edited.</p>
</li>
<li>
<p>Asking others to review code without giving it a self review.</p>
</li>
<li>
<p>Noticing a quality issue and failing to document or fix it.</p>
</li>
<li>
<p>Designing websites that look exactly like every other company’s website.</p>
</li>
<li>
<p>Regurgitating content from the trending influencer of the week.</p>
</li>
</ul>
<p>Where’s the taste here? Where’s the critical judgment, discernment, or
appreciation of aesthetic quality that separates mediocrity from excellence?</p>
<p>It’s not there because most people haven’t developed their taste yet. AI didn’t
create this tasteless problem. People did. Now that everyone can generate
content at the speed of thought we’re noticing that not all content is actually
good. To play on a popular quote from Ratatouille, anyone can cook, but not
everyone is a chef. Don’t complain about mediocre work when you’re producing
mediocre work yourself.</p>
<h2 id="spectrum-of-taste">Spectrum of Taste <span><a href="#spectrum-of-taste" aria-label="Anchor">#</a></span></h2><p>What about the nature of taste itself? Should people focus on developing depth
of taste in specific domains or breadth of taste across many domains? My short
answer is a bit of both, if possible.</p>
<p>Depth of taste means becoming an expert within a particular domain. We’ve all
met such experts and even asked them for help on tricky, bespoke topics within
their domain. A person with depth of taste can recognize when AI-generated
content is refined and of high quality versus merely functional. This kind of
taste comes from years of experience in a specific role coupled with deep domain
knowledge.</p>
<p>Breadth of taste means becoming knowledgeable across multiple domains and
understanding how those domains interface with one another. A person with
breadth of taste can recognize when AI-generated content is contextually
appropriate, authentic, and of enough quality to use for their needs. This
kind of taste comes from years of experience across multiple roles coupled with
moderate domain knowledge.</p>
<p>Breadth of taste is more valuable with AI. When using AI, you’re constantly
switching between domains: a software engineer writing documentation, a marketer
creating designs. Breadth lets you maintain quality across these contexts while
recognizing when you need domain expertise. You iterate faster because you have
opinions about what “good enough” looks like across multiple domains.</p>
<p>The people I see being most effective with AI developed a breadth of taste that
they use to determine what good AI-generated content looks like, regardless
of domain. They can recognize when something feels off, even if they can’t
articulate exactly why. They understand their own limitations and know when to
seek expertise in a specific domain. That’s not to say those with depth of taste
can’t be successful with AI, but I see those people reluctant to use AI because
they are more knowledgeable than AI in a particular domain.</p>
<h2 id="it-tastes-bitter">It Tastes Bitter <span><a href="#it-tastes-bitter" aria-label="Anchor">#</a></span></h2><p>If you’re reading this thinking you have to spend time developing your taste,
good! Perhaps I’ve left a bitter taste in your mouth. The good news is you’re
not alone. There are many people that need to hear this to better their
taste, myself included. The challenge here is recognizing that it’s not about
developing taste for AI but rather about developing taste, period. If you’ve had
poor taste before AI you’ll have poor taste with AI. If you’ve had good taste
before AI, you’ll be able to apply that taste with AI.</p>
<p>Instead of treating AI taste as some mystical new skill, focus on the
fundamentals that were always important. Here are some actionable ways to
develop your taste.</p>
<p><strong>Tomorrow</strong>: Pick one piece of work you’re proud of and one you’re not.
Write down specifically what makes them different. That’s taste in action.</p>
<p><strong>This week</strong>: Find three examples of excellence in a domain you work in. Study
them. What patterns emerge? What choices did the creators make?</p>
<p><strong>This month</strong>: Take something you’ve created with or without AI and iterate
on it a few times. Each iteration should have a specific improvement based on a
specific critique.</p>
<p><strong>Always</strong>: When someone preaches about AI taste, ask them to show you their
work from before AI. If they can’t demonstrate taste in their pre-AI work,
they’re not qualified to lecture you about it now.</p>
<p>The people succeeding with AI aren’t the ones who suddenly discovered taste.
They’re the ones who already had it and simply adapted their standards to a
new tool. Develop your taste with or without AI. The medium doesn’t matter, the
fundamentals do.</p>
<p>Stop waiting for AI to force you to develop taste. Start now.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia buys $5B in Intel stock in seismic deal (821 pts)]]></title>
            <link>https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal</link>
            <guid>45288161</guid>
            <pubDate>Thu, 18 Sep 2025 11:04:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal">https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal</a>, See on <a href="https://news.ycombinator.com/item?id=45288161">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1856-80.png.webp 1920w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-320-80.png.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH.png" alt="asdf" srcset="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1856-80.png 1920w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-320-80.png 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH.png" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Nvidia)</span>
</figcaption>
</div>

<div id="article-body">
<p id="dd0fa8e5-b304-4f38-98c1-c6e171c2a53a">In a surprise announcement that finds two long-time rivals working together, Nvidia and Intel announced today that the companies will jointly develop multiple new generations of x86 products together — a seismic shift with profound implications for the entire world of technology. Before the news broke, Tom's Hardware spoke with Nvidia representatives to learn more details about the company’s plans.</p><p>The products include x86 Intel CPUs tightly fused with an Nvidia RTX graphics chiplet for the consumer gaming PC market, named the ‘Intel x86 RTX SOCs.’ Nvidia will also have Intel build custom x86 data center CPUs for its AI products for hyperscale and enterprise customers. Additionally, Nvidia will buy $5 billion in Intel common stock at $23.28 per share, representing a roughly 5% ownership stake in Intel. (Intel stock is now up 33% in premarket trading.)</p><p>Nvidia emphasized that the companies are committed to multi-generation roadmaps for the co-developed products, which represents a strong investment in the x86 ecosystem. But representatives tells us it also remains fully committed to other announced product roadmaps and architectures, including the company's Arm-based <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidias-project-digits-desktop-ai-supercomputer-fits-in-the-palm-of-your-hand-usd3-000-to-bring-1-pflops-of-performance-home" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/gpus/nvidias-project-digits-desktop-ai-supercomputer-fits-in-the-palm-of-your-hand-usd3-000-to-bring-1-pflops-of-performance-home">GB10 Grace Blackwell processors for workstations</a> and the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/nvidia-unveils-144-core-grace-cpu-superchip-claims-arm-chip-15x-faster-than-amds-epyc-rome" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-unveils-144-core-grace-cpu-superchip-claims-arm-chip-15x-faster-than-amds-epyc-rome">Nvidia Grace</a> <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/nvidia-details-grace-hopper-cpu-superchip-design-144-cores-on-4n-tsmc-process" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-details-grace-hopper-cpu-superchip-design-144-cores-on-4n-tsmc-process">CPUs for data centers</a>, as well as the next-gen <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-rubin-gpu-and-vera-cpu-data-center-ai-platforms-begin-tape-out-both-chips-in-fab-and-on-track-for-2026" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-rubin-gpu-and-vera-cpu-data-center-ai-platforms-begin-tape-out-both-chips-in-fab-and-on-track-for-2026">Vera CPUs</a>. Nvidia says it also remains committed to products on its internal roadmaps that haven’t been publicly disclosed yet, indicating that the new roadmap with Intel will merely be additive to existing initiatives.</p><p>The chip giant hasn’t disclosed whether it will use Intel Foundry to produce any of these products yet. However, while Intel has used TSMC to manufacture some recent products, its goal is to bring production of most high-performance products back into its own foundries.</p><p>Some products never left. For instance, Intel’s existing <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-launches-granite-rapids-xeon-6900p-series-with-120-cores-matches-amd-epycs-core-counts-for-the-first-time-since-2017" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-launches-granite-rapids-xeon-6900p-series-with-120-cores-matches-amd-epycs-core-counts-for-the-first-time-since-2017">Granite Rapids</a> data center processors use the ‘Intel 3’ node, and the upcoming <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/servers/intel-reveals-288-core-xeon" data-before-rewrite-localise="https://www.tomshardware.com/desktops/servers/intel-reveals-288-core-xeon">Clearwater Forest Xeons</a> will use Intel’s own 18A process node for compute. This suggests that at least some of the Nvidia-custom x86 silicon, particularly for the data center, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/nvidia-ceo-intel-test-chip-results-for-next-gen-process-look-good" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-ceo-intel-test-chip-results-for-next-gen-process-look-good">could be fabbed on Intel nodes</a>. Intel also uses TSMC to fabricate many of its client x86 processors, however, so we won’t know for sure until official announcements are made — particularly for the RTX GPU chiplet.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-6S7ZPUsULrjZhoioYnhg6Z"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>While the two companies have engaged in heated competition in some market segments, Intel and Nvidia have partnered for decades, ensuring interoperability between their hardware and software for products spanning both the client and data center markets. And the PCIe interface has long been used to connect Intel CPUs and Nvidia GPUs. The new partnership will find tighter integration using the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products">NVLink interface for CPU-to-GPU communication</a>, which affords up to 14 times more bandwidth along with lower latency than PCIe, thus granting the new x86 products access to the highest performance possible when paired with GPUs. Let’s dive into the details we’ve learned so far.</p><h2 id="intel-x86-rtx-socs-for-the-pc-gaming-market-3">Intel x86 RTX SOCs for the PC gaming market</h2><p id="ca731ff8-3e95-42f5-affb-2bcbd162c7fc">For the PC market, the Intel x86 RTX SoC chips will come with an x86 CPU chiplet tightly connected with an Nvidia RTX GPU chiplet via the NVLink interface. This type of processor will have both CPU and GPU units merged into one compact chip package that externally looks much like a standard CPU, rivaling AMD’s competing APU products.</p><p>This type of tight integration packs all the gaming prowess into one package without an external discrete GPU, providing power and footprint advantages. As such, these chips will be heavily focused on thin-and-light gaming laptops and small form-factor PCs, much like today’s APUs from AMD. However, it’s possible the new Nvidia/Intel chips could come in multiple flavors and permeate further into the Intel stack over time.</p><p>Intel has worked on a similar type of chip before with AMD; there is at least one significant technical difference between these initiatives, however. Intel launched its <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/intel-hades-canyon-nuc-vr,5536.html" data-before-rewrite-localise="https://www.tomshardware.com/reviews/intel-hades-canyon-nuc-vr,5536.html">Kaby Lake-G chip in 2017</a> with an Intel processor fused into the same package as an AMD Radeon GPU chiplet, much the same as the description of the new Nvidia/Intel chips. You can see an image of the Intel/AMD chip below.</p><div aria-hidden="false" data-swipeable="true" data-hydrate="true" id="slice-container-imageGallery-6S7ZPUsULrjZhoioYnhg6Z-r0GQqSmxKDyfaegDCSFcLIEvP0Ymx0AV"><figure data-bordeaux-image-check="false"><div><picture data-hydrate="true"><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-nopin="true" data-slice-image="true"><source type="image/jpeg" srcset="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-nopin="true" data-slice-image="true"><img src="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" alt="sdf" srcset="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-normal="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-nopin="true" data-slice-image="true"></picture></div><figcaption><span>An RTX GPU chiplet connected to an Intel CPU chiplet via the fast and efficient NVLink interface. </span></figcaption></figure></div><p id="06b33e49-7ca0-467a-933e-b68f8f0ddbe8">This SoC had a CPU at one end connected via a PCIe connection to the separate AMD GPU chiplet, which is flanked by a small, dedicated memory package. This separate memory package was only usable by the GPU. The Nvidia/Intel products will have an RTX GPU chiplet connected to the CPU chiplet via the faster and more efficient NVLink interface, and we’re told it will have uniform memory access (UMA), meaning both the CPU and GPU will be able to access the same pool of memory.</p><p>Intel notoriously <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-discontinue-kaby-lake-g-amd-graphics,40577.html" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-discontinue-kaby-lake-g-amd-graphics,40577.html">axed the Kaby Lake-G products in 2019</a>, and the existing systems were <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-graphics-driver-update-hades-canyon-amd-12-month-delay" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-graphics-driver-update-hades-canyon-amd-12-month-delay">left without proper driver support</a> for <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/windows-11-kaby-lake-g-drivers" data-before-rewrite-localise="https://www.tomshardware.com/news/windows-11-kaby-lake-g-drivers">quite some time</a>, in part because Intel was responsible for validating the drivers, and then finger-pointing ensued. We’re told that both Intel and Nvidia will be responsible for their respective drivers for the new models, with Nvidia naturally providing its own GPU drivers. However, Intel will build and sell the consumer processors.</p><p>We haven’t spoken with Intel yet, but the limited scope of this project means that Intel’s proprietary Xe graphics architecture will most assuredly live on as the primary integrated GPU (iGPU) for its mass-market products.</p><h2 id="nvidia-s-first-x86-data-center-cpus-3">Nvidia's first x86 data center CPUs</h2><p id="7fcd26a5-8509-41c5-a5da-0629cef0d258">Intel will fabricate custom x86 data center CPUs for Nvidia, which Nvidia will then sell as its own products to enterprise and data center customers. However, the entirety and extent of the modification are currently unknown. We do know that Nvidia will employ its NVLink interface, which tells us the chips could leverage Nvidia’s new <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products">NVLink Fusion</a> tech that enables custom CPUs and accelerators to enable faster, more efficient communication with Nvidia’s GPUs than found with the PCIe interface.</p><figure data-bordeaux-image-check="" id="7ade6161-9180-406c-b223-19e2635b8553"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi.png" alt="NVLink Fusion" srcset="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi.png">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nvidia)</span></figcaption></figure><p id="730616fb-ebb0-4d0b-a3de-38195e8eb02e">Intel has long offered custom Xeons to its customers, primarily hyperscalers, often with relatively minor tweaks to clock rates, cache capacities, and other specifications. In fact, these mostly slightly-modified custom Xeon models once comprised more than 50% of Intel’s Xeon shipments. Intel has endured several years of market share erosion due to AMD’s advances, most acutely in the hyperscale market. Therefore, it is unclear if the 50% number still holds true, as hyperscalers were the primary customers for custom models.</p><p>Intel has <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-announces-idm-20-foundry" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-announces-idm-20-foundry">long said that it will design completely custom x86 chips for customers</a> as part of its IDM 2.0 strategy. However, aside from a recent announcement of <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-outlines-a-plan-to-get-back-in-the-game-pause-fab-projects-in-europe-make-the-foundry-unit-an-independent-subsidiary-and-streamline-the-x86-portfolio" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-outlines-a-plan-to-get-back-in-the-game-pause-fab-projects-in-europe-make-the-foundry-unit-an-independent-subsidiary-and-streamline-the-x86-portfolio">custom AWS chips</a> that sound like the slightly modified Xeons mentioned above, we haven’t heard of any large-scale uptake for significantly modified custom x86 processors. Intel <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/intel-ousts-ceo-of-products-as-part-of-the-latest-executive-shake-up-ending-30-year-career-company-also-establishes-new-custom-chip-design-unit" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/intel-ousts-ceo-of-products-as-part-of-the-latest-executive-shake-up-ending-30-year-career-company-also-establishes-new-custom-chip-design-unit">announced a new custom chip design unit just two weeks ago</a>, so it will be interesting to learn the extent of the customization for Nvidia’s x86 data center CPUs.</p><p>Nvidia already uses Intel’s Xeons in several of its systems, like the Nvidia DGX B300, but these systems still use the PCIe interface to communicate with the CPU. Intel’s new collaboration with Nvidia will obviously open up new opportunities, given the tighter integration with NVLink and all the advantages it brings with it. The likelihood of AMD adopting NVLink Fusion is somewhere around zero, as the company is heavily invested in its own <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/amd-infinity-fabric-cpu-to-gpu" data-before-rewrite-localise="https://www.tomshardware.com/news/amd-infinity-fabric-cpu-to-gpu">Infinity Fabric (XGMI)</a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/ualink-has-nvidias-nvlink-in-the-crosshairs-final-specs-support-up-to-1-024-gpus-with-200-gt-s-bandwidth" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/ualink-has-nvidias-nvlink-in-the-crosshairs-final-specs-support-up-to-1-024-gpus-with-200-gt-s-bandwidth">Ultra Accelerator Link (UALink)</a> initiatives, which aim to provide an open-standard interconnect to rival NVLink and democratize rack-scale interconnect technologies. Intel is also a member of UALink, which uses AMD’s Infinity Fabric protocol as the foundation.</p><h2 id="dollar-and-cents-geopolitics-3">Dollar and Cents, Geopolitics</h2><p id="e09444e0-bebc-4edc-83cf-79a58ac357b5">Nvidia’s $5 billion purchase of Intel common stock will come at $23.28 a share, roughly 6% below the current market value, but several aspects of this investment remain unclear. Nvidia hasn’t stated whether it will have a seat on the board (which is unlikely) or how it will vote on matters requiring shareholder approval. It is also unclear if Intel will issue new stock (primary issuance) for Nvidia to purchase, as it did when the U.S. government recently became an Intel shareholder (that is likely). Naturally, the investment is subject to approval from regulators.</p><p>Nvidia’s buy-in comes on the heels of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/big-tech/trump-says-u-s-govt-will-take-a-10-percent-ownership-stake-in-intel-lip-bu-tan-reportedly-agreed-to-unprecedented-arrangement-for-a-domestic-chipmaker" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/big-tech/trump-says-u-s-govt-will-take-a-10-percent-ownership-stake-in-intel-lip-bu-tan-reportedly-agreed-to-unprecedented-arrangement-for-a-domestic-chipmaker">U.S government buying $10 billion of newly-created Intel stock</a>, granting the country a 9.9% ownership stake at $20.47 per share. The U.S. government won’t have a seat on the board and agreed to vote with Intel’s board on matters requiring shareholder approval “with limited exceptions.” <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/softbank-to-buy-usd2-billion-in-intel-shares-at-usd23-each-firm-still-owns-majority-share-of-arm" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/semiconductors/softbank-to-buy-usd2-billion-in-intel-shares-at-usd23-each-firm-still-owns-majority-share-of-arm">Softbank has also recently purchased $2 billion worth of primary issuance Intel stock</a> at $23 per share.</p><div id="slice-container-table-6S7ZPUsULrjZhoioYnhg6Z-JiGkjEwwBtiv7WLzNY6ijtNd9T35JBCY"><div><p>Swipe to scroll horizontally</p><svg viewBox="0 0 23 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M21.554 15.726a2.878 2.878 0 0 0-1.705-.374 2.881 2.881 0 0 0-1.388-3.068 2.877 2.877 0 0 0-1.992-.333 2.884 2.884 0 0 0-.1-.766 2.865 2.865 0 0 0-1.346-1.75c-.47-.27-.996-.4-1.527-.385l2.742-4.73a2.87 2.87 0 0 0 .323-.83h2.612V2.084h-2.661A2.861 2.861 0 0 0 15.18.385a2.903 2.903 0 0 0-3.952 1.055l-.373.644H2.983l1.003-1L2.99.09 1.28 1.793l-.999.995L2.99 5.484l.998-.994-1.003-.999h7.054L6.505 9.586c-.34.066-.905.186-1.523.366-1.405.41-2.321.895-2.8 1.483-.742.911-1.159 2.513-1.277 4.898l-.001.01c-.067 1.816.946 6.943.99 7.16a.688.688 0 0 0 1.35-.266c-.01-.051-1.023-5.177-.963-6.84.127-2.556.598-3.64.97-4.098.133-.163.602-.587 2.104-1.027l.206-.058-1.425 2.458a.685.685 0 0 0 .252.937c.33.19.75.077.94-.251L12.42 2.126a1.52 1.52 0 0 1 2.07-.552c.35.2.6.527.705.916.105.39.051.797-.15 1.145l-4.767 8.222a.685.685 0 0 0 .252.937c.33.19.75.077.94-.25l.794-1.368c.201-.348.529-.597.92-.702a1.508 1.508 0 0 1 1.854 1.066c.105.39.052.796-.15 1.144l-.377.652-.002.002-.898 1.55a.685.685 0 0 0 .252.938c.329.189.75.077.94-.251l.9-1.551c.201-.348.528-.597.92-.702a1.512 1.512 0 0 1 1.703 2.21l-1.223 2.11a.685.685 0 0 0 .252.938c.33.189.75.076.941-.252l.5-.862c.202-.348.529-.597.92-.702.392-.104.8-.051 1.15.15.723.416.972 1.34.554 2.06l-3.525 6.08c-.517.892-1.57 1.795-3.044 2.611-1.156.64-2.163.998-2.173 1.002a.685.685 0 0 0 .23 1.333.688.688 0 0 0 .229-.04c.18-.062 4.419-1.575 5.952-4.22l3.524-6.08a2.878 2.878 0 0 0-1.059-3.934Z" fill="#333"></path></svg></div><div><table tabindex="0"><caption>Purchases of Intel Stock</caption><tbody><tr><td colspan="1"><span>Row 0 - Cell 0 </span></td><td colspan="1"><p>Total</p></td><td colspan="1"><p>Share Price</p></td><td colspan="1"><p>Stake in Intel</p></td></tr><tr><td colspan="1"><p>Nvidia</p></td><td colspan="1"><p>$5 Billion</p></td><td colspan="1"><p>$23.28</p></td><td colspan="1"><p>~5%</p></td></tr><tr><td colspan="1"><p>U.S. Government</p></td><td colspan="1"><p>$9 Billion</p></td><td colspan="1"><p>$20.47</p></td><td colspan="1"><p>~9.9%</p></td></tr><tr><td colspan="1"><p>Softbank</p></td><td colspan="1"><p>$2 Billion</p></td><td colspan="1"><p>$23</p></td><td colspan="1"><span>Row 3 - Cell 3 </span></td></tr></tbody></table></div></div><p id="c44d2679-944b-4a74-827f-1a98316271f9">The U.S. government says it invested in Intel with the goal of bolstering US technology, manufacturing, and national security, and the investments from the private sector also help solidify the struggling Intel. Altogether, these investments represent a significant cash influx for Intel as it attempts to maintain the heavy cap-ex investments required to compete with TSMC, all while struggling with a negative amount of free cash flow.</p><p>“AI is powering a new industrial revolution and reinventing every layer of the computing stack — from silicon to systems to software. At the heart of this reinvention is Nvidia’s CUDA architecture,” said Nvidia CEO Jensen Huang. “This historic collaboration tightly couples NVIDIA’s AI and accelerated computing stack with Intel’s CPUs and the vast x86 ecosystem—a fusion of two world-class platforms. Together, we will expand our ecosystems and lay the foundation for the next era of computing.”</p><p>“Intel’s x86 architecture has been foundational to modern computing for decades – and we are innovating across our portfolio to enable the workloads of the future,” said Intel CEO Lip-Bu Tan. “Intel’s leading data center and client computing platforms, combined with our process technology, manufacturing and advanced packaging capabilities, will complement Nvidia's AI and accelerated computing leadership to enable new breakthroughs for the industry. We appreciate the confidence Jensen and the Nvidia team have placed in us with their investment and look forward to the work ahead as we innovate for customers and grow our business.”</p><p>We’ll learn more details of the new partnership later today when Nvidia CEO Jensen Huang and Intel CEO Lip-Bu Tan hold a <a data-analytics-id="inline-link" href="https://events.q4inc.com/attendee/108505485" data-url="https://events.q4inc.com/attendee/108505485" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">webcast press conference at 10 am PT</a>.</p><p><em><strong>This is breaking news…more to come.</strong></em></p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
</div>



<!-- Drop in a standard article here maybe? -->




<div id="slice-container-authorBio-6S7ZPUsULrjZhoioYnhg6Z"><p>Paul Alcorn is the Editor-in-Chief for Tom's Hardware US. He also writes news and reviews on CPUs, storage, and enterprise hardware.</p></div>
</section>




</div></div>]]></description>
        </item>
    </channel>
</rss>