<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 18 Oct 2023 11:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[When was the last time Marc Andreessen talked to a poor person? (153 pts)]]></title>
            <link>https://techcrunch.com/2023/10/17/when-was-the-last-time-marc-andreessen-talked-to-a-poor-person/</link>
            <guid>37925099</guid>
            <pubDate>Wed, 18 Oct 2023 05:25:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/10/17/when-was-the-last-time-marc-andreessen-talked-to-a-poor-person/">https://techcrunch.com/2023/10/17/when-was-the-last-time-marc-andreessen-talked-to-a-poor-person/</a>, See on <a href="https://news.ycombinator.com/item?id=37925099">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Venture capitalist Marc Andreessen posted a manifesto on the a16z website, calling for “<a href="https://a16z.com/the-techno-optimist-manifesto/" target="_blank" rel="noopener">techno-optimism</a>” in a frenzied, 5,000-word blog post that somehow manages to re-invent Reaganomics, propose the colonization of outer space and unironically answer a question with the phrase “QED.”</p>
<p>Andreessen’s vision of techno-optimism could seem inspiring: He imagines a Libertarian-esque world where technology solves all of our problems, poverty and climate change are eradicated, and an honest meritocracy reigns supreme. Though Andreessen may call us “Communists and Luddites” for saying so, his dreams are unrealistic, and founded upon a flawed premise that tech exclusively makes the world better.</p>
<p>First, we need to remember the biases that Andreessen brings to the table, mainly that he is absurdly wealthy (worth an estimated $1.35 billion as of September 2022) and that his absurd wealth is largely tied to the investments of his namesake tech venture fund. So, he inherently is going to push for his techno-optimist vision, because the success of tech companies means he gets even more rich. When you have a financial stake in something, you become biased: This is why, as reporters, we can’t buy Netflix stock, then turn around and write an article about why Netflix is going to have a great Q4.</p>
<p>But money can be blinding. Early on in his essay, Andreessen writes, “We believe that there is no material problem – whether created by nature or by technology – that cannot be solved with more technology.” A16z is increasingly investing in defense companies, including Palmer Luckey’s controversial startup Anduril, which manufactures autonomous weapons. Is war the problem these companies are solving? What does “solve” even mean in the context of conflicts like the ongoing war in Israel and Gaza — isn’t the true solution an end to conflict?</p>
<p>Another inconsistency lies in Andreessen’s assertion that “technological innovation in a market system is inherently philanthropic, by a 50:1 ratio.” He references economist William Nordhaus’ claim that those who create technology only retain 2% of its economic value, so the other 98% “flows through to society.”</p>
<p>“Who gets more value from a new technology, the single company that makes it, or the millions or billions of people who use it to improve their lives?” asks Andreessen.</p>
<p>We won’t lie and say that tech startups have not made our lives easier. If we’re out too late and the subway isn’t running, we can take an Uber or Lyft. If we want to buy a book and get it delivered to our doors by the end of the day, we can order it on Amazon. But to deny the negative impacts of these companies is to move through the world with blinders up.</p>
<p>Furthermore, it’s implicit — but not stated in Andreessen’s argument — that these platforms have effectively made large swatches of society renters, and the platforms, the landlords. Perhaps he needs a refresher on the ills of the “<a href="https://www.tutor2u.net/economics/reference/rentier-capitalism#:~:text=Rentier%20capitalism%20describes%20a%20system,to%20help%20provide%20public%20services." target="_blank" rel="noopener">rentier economy</a>” and how antithetical it is to innovators and entrepreneurship?</p>
<p>When was the last time Marc Andreessen walked through the streets of San Francisco, where wealthy tech workers pretend that they don’t see the homeless encampments outside of their companies’ HQ?</p>
<p>When was the last time Marc Andreessen talked to a poor person — or an <a href="https://techcrunch.com/2021/10/15/instacart-shopper-activists-are-going-on-strike/">Instacart shopper</a> struggling to make ends meet, for that matter?</p>
<p>Andreessen’s argument is a contemporary rehashing of trickle-down economics, the notorious Reagan-era idea that as rich people get richer, some of that wealth will “trickle down” to the poor. But this theory has been <a href="https://eprints.lse.ac.uk/107919/1/Hope_economic_consequences_of_major_tax_cuts_published.pdf" target="_blank" rel="noopener">repeatedly</a> <a href="https://wir2022.wid.world/" target="_blank" rel="noopener">debunked</a>. Again: Do Amazon warehouse workers really get their fair share?</p>
<p>At one point, Andreessen makes the case that free markets “prevent monopolies” because the “market naturally disciplines.” As any third-party Amazon seller will tell you — or anyone who’s tried to get Eras Tour tickets — this is a point easily disproved. Andreessen may argue that the U.S. market isn’t truly “free” in the sense that it’s regulated by agencies and the lawmakers who empower those agencies to enforce policy. But the U.S. has had its fair share of stretches of laissez-faire tech oversight, and each has spawned — not stifled — tech giants strongly inclined to crush competition.</p>
<p>Andreessen’s motivations are further crystalized when he makes a list of whom he considers to be his enemies.</p>
<p>In that section, he lists off what he feels has subjugated society to “mass demoralization.” On this list is a mention of the United Nations’ <a href="https://sdgs.un.org/goals" target="_blank" rel="noopener">Sustainable Development Goals</a> (SDGs), the 17 objectives that were created to inspire nations to strive toward peace. According to Andreessen, these are the so-called enemies “against technology and life:” environmental sustainability, reduced gender inequalities, the elimination of poverty or hunger, and more good jobs.</p>
<p>How are these 17 goals against technology and life, when technology is already being used to achieve more life — already being used to make clean water, alleviate mass production and generate clean energy? He has a vague, empty way of writing that leaves more questions than answers; it brings forth the idea that he has probably never read the 17 Sustainable Goals, and that instead he is using it as a code word for something else. Then, Andreessen decries ESG stakeholder capitalism, tech ethics, trust and safety, and risk management as enemies to his cause.</p>
<p>What are you really trying to say, Marc? That regulation and accountability are bad? That we should pursue the development of technology at the expense of all else, in hopes that the world will be better if Amazon stock breaks $200 per share?</p>
<p>Andreessen has a coded way of speaking in general, so it’s no wonder that he takes such umbrage with the UN’s goals of supporting those most at risk. He talks about the planet being “dramatically underpopulated” and specifically calls out the way “developed societies” are dwindling in population, a seeming endorsement of one of the core tenets of pronatalism. He wants 50 billion people to be on earth (and then for some of us to colonize outer space), and says the “markets” can generate the money needed to fund social welfare programs. (We must repeat the question: Has this man been to San Francisco lately?) He also mentions that Universal Basic Income “would turn people into zoo animals to be farmed by the state.” (Sam Altman would no doubt disagree.) He wants us to work, to be productive, “to be proud.”</p>
<p>The missing link here is how we can use tech to actually take care of people; how to feed them, clothe them, how to make sure the planet doesn’t reach such high temperatures that we all just melt away. What is missing here is that San Francisco is already the tech hub of the world and is one of the most unequal places in the universe, both socially and economically. What is missing here is that the technological revolution made it easier to hail an Uber or order food delivery, but did nothing about how those drivers and delivery people are being exploited, and how <a href="https://www.theguardian.com/technology/2019/may/07/the-uber-drivers-forced-to-sleep-in-parking-lots-to-make-a-decent-living" target="_blank" rel="noopener">some live</a> in their cars to sustain a decent wage.</p>
<p>There are lines and lines to analyze in his manifesto, but it all goes back to the point that what’s missing here is life: the element of living and all its nuances. He takes an either “you are for technology” or “against it” approach to actually utilizing productivity to help make lives better. He talks about the economic frameworks that life is spun around, without mentioning the intricate ways it actually impacts people.</p>
<p>Plenty of tech giants speak of creating a world they have no grasp on. We watch as Meta founder Mark Zuckerberg “moves fast and breaks things” and then ends up testifying before Congress about election interference. We watch as OpenAI founder Sam Altman draws <a href="https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html" target="_blank" rel="noopener">parallels</a> between himself and Robert Oppenheimer, not stopping to think so much about whether or not it’s a good thing to push the limits of technological innovation at any cost.</p>
<p>Andreessen is a product — and an engineer — of a tech bubble that doesn’t understand the people whom it purports to serve.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Localization Failure: Temperature Is Hard (133 pts)]]></title>
            <link>https://randomascii.wordpress.com/2023/10/17/localization-failure-temperature-is-hard/</link>
            <guid>37924589</guid>
            <pubDate>Wed, 18 Oct 2023 03:38:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://randomascii.wordpress.com/2023/10/17/localization-failure-temperature-is-hard/">https://randomascii.wordpress.com/2023/10/17/localization-failure-temperature-is-hard/</a>, See on <a href="https://news.ycombinator.com/item?id=37924589">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-4050">
																
					<!-- .entry-meta -->

					<div>
						<p>The Guardian is one of my favorite news sources. I’m a subscriber (support news organizations!) and I read it daily. But it is not immune to errors, as this headline shows:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-7.png"><img width="236" height="241" title="Record heat: Malawi swelters with temperatures nearly 68F above average" alt="Record heat: Malawi swelters with temperatures nearly 68F above average" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-7.png?w=236&amp;h=241"></a></p>
<p>68 <b>°</b>F above average is a lot. For a tropical country it is not credible for temperatures to be that much warmer than average because the average is too high to give enough headroom. So what gives?</p>

<p>Reading the article I found this:</p>
<blockquote>
<p>parts of Malawi saw a maximum temperature of 43C (109F), compared with an average of nearly 25C (77F)</p>
</blockquote>
<p>As I expected the actual temperature increase was 32 <b>°</b>F, not 68 <b>°</b>F. So what’s up with that headline? Here’s a hint: this is what the headline might say if you set your location to somewhere other than the United States:</p>
<p><a href="https://randomascii.files.wordpress.com/2023/10/image-8.png"><img width="235" height="203" title="Malawi swelters in record heat with temperatures nearly 20C above average" alt="Malawi swelters in record heat with temperatures nearly 20C above average" src="https://randomascii.files.wordpress.com/2023/10/image_thumb-8.png?w=235&amp;h=203"></a></p>
<p>Now “nearly 20C” is an odd way of saying “18 <b>°</b>C”, but I guess they really like round numbers, and that’s not the problem. The problem is that somebody – the localization team? an algorithm? – decided that 20 <b>°</b>C was equivalent to 68 <b>°</b>F. And they’re not wrong. And yet they are.</p>
<p>When converting from a temperature in Celsius to one in Fahrenheit you have to multiply by 1.8 (because each degree Celsius covers a range 1.8 times as large as a degree Fahrenheit) and you have to add 32 <b>°</b>F (because the freezing point in Fahrenheit is 32, compared to 0 in Celsius). However if you are converting a temperature <em>difference</em> you just multiply by 1.8.</p>
<p>That is, if the temperature goes up by 1 <b>°</b>C then it has gone up by 1.8 <b>°</b>F. If it goes up by 10 <b>°</b>C then it has gone up by 18 <b>°</b>F. If it goes up by 20 <b>°</b>C then it has gone up by 36 <b>°</b>F. Adding 32 <b>°</b>F in this context is just wrong.</p>
<p>This is just another version of the fallacy involved when somebody says that it is “twice as hot” when the temperature goes from 5 <b>°</b>C to 10 <b>°</b>C – note that this is equivalent to going from 278 <b>°</b>K to 283 <b>°</b>K, or 41 <b>°</b>F to 50 <b>°</b>F, so clearly not “twice as hot” in any meaningful way.</p>
<p>In short, translating 20 <b>°</b>C requires examining the context and there are at least three possible translations:</p>
<ul>
<li>“The temperature is 20 <b>°</b>C” translates to “The temperature is 78 <b>°</b>F”</li>
<li>“It’s 20 <b>°</b>C warmer than yesterday” translates to “It’s 36 <b>°</b>F warmer than yesterday”</li>
<li>“The temperature is minus 20 <b>°</b>C” translates to “The temperature is minus 4 <b>°</b>F”</li>
</ul>
<p>So 20 <b>°</b>C is either 78 <b>°</b>F, 36 <b>°</b>F, or (minus) 4 <b>°</b>F.</p>
<p>Reported here:</p>
<p><a title="https://twitter.com/BruceDawson0xB/status/1714406661904007624" href="https://twitter.com/BruceDawson0xB/status/1714406661904007624">https://twitter.com/BruceDawson0xB/status/1714406661904007624</a></p>
<p>Hacker news discussion <a href="https://news.ycombinator.com/item?id=37924589#37925146">here</a>.</p>
											</div><!-- .entry-content -->

							<div id="entry-author-info">
						<p><img alt="" src="https://2.gravatar.com/avatar/5046e4ce5e1de3d9e062e3ff22d7f3ba7a997c221a6b6d84a73194db7e0aa0d7?s=60&amp;d=identicon&amp;r=G" srcset="https://2.gravatar.com/avatar/5046e4ce5e1de3d9e062e3ff22d7f3ba7a997c221a6b6d84a73194db7e0aa0d7?s=60&amp;d=identicon&amp;r=G 1x, https://2.gravatar.com/avatar/5046e4ce5e1de3d9e062e3ff22d7f3ba7a997c221a6b6d84a73194db7e0aa0d7?s=90&amp;d=identicon&amp;r=G 1.5x, https://2.gravatar.com/avatar/5046e4ce5e1de3d9e062e3ff22d7f3ba7a997c221a6b6d84a73194db7e0aa0d7?s=120&amp;d=identicon&amp;r=G 2x, https://2.gravatar.com/avatar/5046e4ce5e1de3d9e062e3ff22d7f3ba7a997c221a6b6d84a73194db7e0aa0d7?s=180&amp;d=identicon&amp;r=G 3x, https://2.gravatar.com/avatar/5046e4ce5e1de3d9e062e3ff22d7f3ba7a997c221a6b6d84a73194db7e0aa0d7?s=240&amp;d=identicon&amp;r=G 4x" height="60" width="60" loading="lazy" decoding="async">						</p><!-- #author-avatar -->
						<div id="author-description">
							<h2>
							About brucedawson							</h2><p>
							I'm a programmer, working for Google, focusing on optimization and reliability. Nothing's more fun than making code run 10x as fast. Unless it's eliminating large numbers of bugs.

I also unicycle. And play (ice) hockey. And sled hockey. And juggle. And worry about whether this blog should have been called randomutf-8.

2010s in review tells more: https://twitter.com/BruceDawson0xB/status/1212101533015298048							</p><!-- #author-link	-->
						</div><!-- #author-description -->
					</div><!-- #entry-author-info -->

						<div><p>
							This entry was posted in <a href="https://randomascii.wordpress.com/category/math/" rel="category tag">Math</a>, <a href="https://randomascii.wordpress.com/category/metric/" rel="category tag">metric</a>, <a href="https://randomascii.wordpress.com/category/rants/" rel="category tag">Rants</a> and tagged <a href="https://randomascii.wordpress.com/tag/celsius/" rel="tag">Celsius</a>, <a href="https://randomascii.wordpress.com/tag/fahrenheit/" rel="tag">Fahrenheit</a>, <a href="https://randomascii.wordpress.com/tag/localization/" rel="tag">localization</a>. Bookmark the <a href="https://randomascii.wordpress.com/2023/10/17/localization-failure-temperature-is-hard/" title="Permalink to Localization Failure: Temperature is&nbsp;Hard" rel="bookmark">permalink</a>.													</p></div><!-- .entry-utility -->
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[4K4D: Real-Time 4D View Synthesis at 4K Resolution (267 pts)]]></title>
            <link>https://zju3dv.github.io/4k4d/</link>
            <guid>37923801</guid>
            <pubDate>Wed, 18 Oct 2023 01:20:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zju3dv.github.io/4k4d/">https://zju3dv.github.io/4k4d/</a>, See on <a href="https://news.ycombinator.com/item?id=37923801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h3>Abstract</h3>
          <hr>
          <p>
            This paper targets high-fidelity and real-time view
            synthesis of <span>dynamic 3D scenes at 4K resolution</span>. Recently, some
            methods on dynamic view synthesis have shown impressive rendering quality. However, their speed is still
            limited when rendering high-resolution images. To overcome this problem, we propose <span>4K4D</span>, a 4D point cloud representation that supports hardware
            rasterization and enables unprecedented rendering speed. Our representation is built on a 4D feature grid so
            that the points are naturally regularized and can be robustly optimized. In addition, we design a novel
            hybrid appearance model that significantly boosts the rendering quality while preserving efficiency.
            Moreover, we develop a differentiable depth peeling algorithm to effectively learn the proposed model from
            RGB videos. Experiments show that our representation can be rendered at over 400 FPS on the DNA-Rendering
            dataset at 1080p resolution and 80 FPS on the ENeRF-Outdoor dataset at 4K resolution using an RTX 4090 GPU,
            which is 30x faster than previous methods and achieves the state-of-the-art rendering quality.
            <!-- Experiments show that our representation can be rendered at <span style="font-weight: bold">over 400 FPS</span> on the DNA-Rendering dataset at <span style="font-weight: bold">1080p resolution</span> and <span style="font-weight: bold">80 FPS</span> on the ENeRF-Outdoor dataset at <span style="font-weight: bold">4K resolution</span> using an RTX 4090 GPU, which is 30x faster than previous methods and achieves the state-of-the-art rendering quality. -->
          </p>
          <!-- <div class="col-md-12">
            <img src="img/pipeline_fig.svg" width="100%" />
          </div> -->
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Psytrance Guide (319 pts)]]></title>
            <link>https://psytranceguide.com/</link>
            <guid>37923732</guid>
            <pubDate>Wed, 18 Oct 2023 01:10:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://psytranceguide.com/">https://psytranceguide.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37923732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <div>
            <div data-effect="slide" data-right="50em" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/5CgcYeAMe3yfpzGWzVXKCm?si=GEQjna8LSc6lJwXoWuNhbQ">Psychedelic</a></h2>
                    <p>Also known as: Uptempo Psy, UK Psy, Classic</p>

                    

                    <div>

                        <p>BPM range: 145—148</p>
                        <p>Psychedelic is&nbsp;probably the most iconic subgenre of&nbsp;Psytrance music, with driving basslines and futuristic sounds often created using&nbsp;FM synthesis. Pioneered by&nbsp;the London-based labels like Alchemy, Flying Rhino and TIP Records, among the others, this subgenre has also become known as&nbsp;the UK&nbsp;Psy.</p>
                    </div>
                    

                    
                    

                </div>

            <div data-effect="slide" data-left="50em" data-hold="100">
                    
                    <p>Also known as: Psy-Trance, Classy, 140-BPM-Psy</p>
                    

                    <div>

                        <p>BPM range: 138—142</p>
                        <p>This subgenre organically fits between Progressive Psy and the classic Psychedelic in&nbsp;the BPM range, combining the best elements of&nbsp;these two. It&nbsp;is&nbsp;arguably the most common Psytrance subgenre now that sounds on&nbsp;the festivals all over the world, and in&nbsp;fact, if&nbsp;you hear the word “Psytrance”, it’s most likely referred to&nbsp;this particular subgenre. </p>
                        <p>Note: read why author prefers to&nbsp;call these tracks Psytrance and not Progressive Psy <a href="http://daniellesden.com/blog/all/what-is-progressive/">in&nbsp;the blog</a>.</p>
                    </div>

                    

                    
                    

                </div>
        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/0ZVlYhZpCUkjZZ04pdKx8O?si=IhUTV2ihRJavhtbmQ3xsmw">Progressive Psy</a></h2>
                    <p>Also known as: Psy-Prog, Progressive</p>
                    

                    <div>
                        <p>BPM range: 134—138</p>
                        <p>Emerging in&nbsp;the mid 00’s in&nbsp;Europe, Progressive Psy has quickly expanded to&nbsp;become one of&nbsp;the most common Psytrance subgenres. And it’s very diverse too, featuring a&nbsp;quite wide range of&nbsp;vibes. Progressive Psy doesn’t utilise one particular type of&nbsp;sound, but rather focuses on&nbsp;the groove, the flow, and how it&nbsp;progresses over time.</p>
                    </div>

                    

                    
                    

                </div>


            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/14qV08HoVAe1QR1xTn1zIl?si=dpHuX3zgQ5Kbj_frGdzHQg">Minimal Psy</a></h2>
                    <p>Also known as: Minimal, Deep Psychedelic, Zenonesque</p>
                    

                    <div>

                        <p>BPM range: 130—135</p>
                        <p>Although this subgenre might be&nbsp;formally called Progressive, it’s typically slower, deeper and less melodic than the Progressive Psy we&nbsp;know today. Tracks of&nbsp;this subgenre build-up slowly, allowing artists to&nbsp;focus more on&nbsp;things like reverb tails, delay effects, little percussion tricks, and other subtle details.</p>
                        <p>Note: probably, Dark Progressive aka Zenonesque and Psygressive will be separated in&nbsp;the future version of&nbsp;this guide. Please <a href="http://daniellesden.com/blog/all/introducing-psytrance-guide/">read more in&nbsp;the blog</a>.</p>
                    </div>

                    

                    
                    

                </div>
        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/4aJ4xMUFLTUNZuNa8UH3XH?si=buNBTtFfTzWX6WxVkPzmeg">Tribal</a></h2>
                    <p>Also known as: Triplets, Ethnic Psy</p>
                    

                    <div>

                        <p>BPM range: 136—140</p>
                        <p>Pioneered by&nbsp;Juno Reactor and then recently popularised by&nbsp;Vini Vici, Tribal Psy utilises triplets bassline pattern along with some ethnic drums and vocal samples. Some producers overused triplets so&nbsp;much in&nbsp;the recent years, so&nbsp;at&nbsp;some point, having a&nbsp;triplet drop is&nbsp;almost considered as&nbsp;a&nbsp;cliché.</p>
                    </div>

                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/6CtQyNaVNWDkjPmoo7VeEp?si=H--XgzK1RbCpOBn9FUzUZQ">Offbeat</a></h2>
                    <p>Also known as: The Offbeat, Progressive Trance, Hamburg Psy</p>
                    

                    <div>

                        <p>BPM range: 134—140</p>
                        <p>The Offbeat Psy uses a&nbsp;specific bassline pattern at&nbsp;which a&nbsp;single bass note hits between four-on-the-floor kick drums, hence the name. It&nbsp;is&nbsp;originated from Hamburg, Germany, in&nbsp;the late 00’s. Tracks in&nbsp;this subgenre often include sampled speech samples processed with the gate or&nbsp;sidechain effects.</p>
                    </div>

                    

                    
                    

                </div>
        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/4ylkw2N6XUvlBVqaQU8adV?si=5fCA-SuYTRO3mdYNLnOt_g">Psy-Techno</a></h2>
                    <p>Also known as: Psychedelic Techno, Psy-Tech</p>
                    

                    <div>

                        <p>BPM range: 125—136</p>
                        <p>As&nbsp;the title suggests, this subgenre is&nbsp;a&nbsp;blend of&nbsp;Psytrance and Techno that combines various elements from these two. And since both Psytrance and Techno can vary in&nbsp;tempo and vibe, there are&nbsp;pretty much no&nbsp;boundaries to&nbsp;this subgenre too: it&nbsp;can go&nbsp;from deep and minimal to&nbsp;hard and rough.</p>
                    </div>

                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/5yjAn7dvW1f8jxqUOv5zIj?si=At5bTPS3RoGjv57HQI9GmA">Psy Tech-Trance</a></h2>
                    <p>Also known as: Uplifting Psy</p>
                    

                    <div>

                        <p>BPM range: 138—140</p>
                        <p>Psy Tech-Trance is&nbsp;a&nbsp;product of&nbsp;a&nbsp;clash between Psytrance and a&nbsp;regular Trance worlds. Tracks in&nbsp;this subgenre typically have the Psy bassline, longer uplifting breakdowns, and acidic riffs at&nbsp;the climax. Although some devoted psytrance fans don’t accept this subgenre as&nbsp;a&nbsp;part of&nbsp;the Psy scene and culture, it&nbsp;grows pretty rapidly, especially in&nbsp;the&nbsp;US.</p>
                    </div>

                    

                    
                    

                </div>
        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/4H8v3IOJVYwxWkbwyyules?si=tav1ERORRDyAuh72WVzO7w">Psybreaks</a></h2>
                    <p>Also known as: Psychedelic Breaks, Psy Tech-Funk, Broken Beats</p>
                    

                    <div>

                        <p>BPM range: 130—138</p>
                        <p>Psybreaks is&nbsp;a&nbsp;relatively new subgenre that emerged in&nbsp;the last 00’s. It&nbsp;combines heavy Psytrance bassline and squelch sounds with a&nbsp;Breaks rhythm, classic Electro snares, and sometimes even Industrial scrapes.</p>
                    </div>

                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/3AdmS1ZAakAnvAyPsBwwMe?si=gYOJfPPjRoiak1nFxtaQcQ">Mainstream</a></h2>
                    <p>Also known as: Commercial Psy, Pop Psy</p>
                    

                    <div>

                        <p>BPM range: 130—138</p>
                        <p>This isn’t quite a&nbsp;subgenre, but rather consequences of&nbsp;when Psytrance artists go&nbsp;mainstream: it often includes vocals and cheesy melodies to appeal to a broader audience. Although these tracks are typically labelled in&nbsp;stores as&nbsp;“Psytrance”, let’s be&nbsp;clear about&nbsp;it: it’s not Psytrance, really. </p>
                    </div>

                    

                    
                    

                </div>


        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/3A2Q7NG68qqMUMBO72pCBR?si=SPQwTSwFSeu5Ijq1YxpJpQ">Goa Trance</a></h2>
                    <p>Also known as: Goa, 604 Psy</p>
                    

                    <div>

                        <p>BPM range: 135—150</p>
                        <p>Goa Trance is&nbsp;the ancestor of&nbsp;all Psytrance music as&nbsp;a&nbsp;whole we&nbsp;know today. Formed in&nbsp;the 80’s in&nbsp;Goa, India, by&nbsp;the modern hippies of&nbsp;that time, Goa Trance got its global recognition in&nbsp;the mid 90’s. Goa Trance is&nbsp;considered as&nbsp;“organic”, that is&nbsp;to&nbsp;say, it&nbsp;does not have the typical “metallic” sounds of&nbsp;electronic music and often presents an&nbsp;oriental aesthetics in&nbsp;its melodies, mostly with Indian consonance, as&nbsp;well as&nbsp;various tribal elements from the Indian culture such as&nbsp;references to&nbsp;the Buddhist or&nbsp;Hinduist mythology and mysticism. Although Goa Trance is&nbsp;considered as&nbsp;an&nbsp;oldschool genre now, some artists and labels are still releasing&nbsp;it, referring to&nbsp;it&nbsp;as&nbsp;a&nbsp;New School or&nbsp;Neogoa.</p>
                    </div>

                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/2WuPfPRaCA4wiu4ZVOgepX?si=b3se8ywJQqmCOihkY4G03g">Nitzhonot</a></h2>
                    <p>Also known as: Uplifting Goa, Morning Goa Trance</p>
                    

                    <div>

                        <p>BPM range: 145—160</p>
                        <p>Nitzhonot is&nbsp;a&nbsp;subgenre that formed from the classic Goa Trance in&nbsp;the mid 90’s in&nbsp;Israel, and it&nbsp;literally means “victories” in&nbsp;Hebrew. It&nbsp;is&nbsp;typically faster than Goa Trance, with high-pitched kick drums and fast-paced oriental melodies. And just like Goa Trance, Nitzhonot considered an&nbsp;underground subgenre among Psytrance as&nbsp;a&nbsp;whole, which is&nbsp;an&nbsp;underground style itself.</p>
                    </div>

                    

                    
                    

                </div>
        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/6Xh0gKYWHvWoDwub793Jr9?si=j8wfRdIyQG-gN8XousR_Lg">Full-on</a></h2>
                    <p>Also known as: Morning Fullon, Israeli Full-on</p>
                    

                    <div>

                        <p>BPM range: 140—148</p>
                        <p>Full-on is&nbsp;a&nbsp;dynamic, playful, and musical subgenre of&nbsp;Psytrance that appeals to&nbsp;a&nbsp;broader audience because of&nbsp;its positive vibe. Unlike of&nbsp;a&nbsp;typical straight Psytrance bassline pattern, the Full-on basssline plays on&nbsp;various notes across few octaves, creating a&nbsp;special rhythm and melody that way. The period of&nbsp;2004–2009&nbsp;is considered as&nbsp;the “golden age” of&nbsp;Full-on, before Progressive Psy took over the global Psy scene.</p>
                    </div>
                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/3fVWcTZTn6foNlg33OTp6U?si=zDCih2uoSAeHHEzZcyvsZw">Night Full-on</a></h2>
                    <p>Also known as: Twilight, South African Full-on</p>
                    

                    <div>

                        <p>BPM range: 145—150</p>
                        <p>Night Full-on is&nbsp;the evil twin of&nbsp;Full-on: it&nbsp;has the same fast-paced bass and leads but with a&nbsp;darker vibe and twisted, synthetic sounds. On&nbsp;the festivals, Twilight Psy typically sound during the night-time, hence the name.</p>
                        <p>Note: probably, Night Full-on and Twilight will be separated in&nbsp;the future version of&nbsp;this guide. Please <a href="http://daniellesden.com/blog/all/introducing-psytrance-guide/">read more in&nbsp;the blog</a>.</p>
                    </div>

                    

                    
                    

                </div>
        </div>



        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/2BLorPESgjNe6OBAnB6FGM?si=FmFkQXE8S_qBWP1DH1EoEA">Dark Psy</a></h2>
                    <p>Also known as: Cyberdelic, Alien Psy</p>
                    

                    <div>

                        <p>BPM range: 140—155</p>
                        <p>Dark Psy name speaks for itself. This subgenre is&nbsp;dark, cold, and themed with a&nbsp;horror special effects. Sometimes it’s called Cyberdelic, which stands for “cybernetic + psychedelic”, due to&nbsp;a&nbsp;massive amount of&nbsp;artificial sounds, lasers, and other alien sounds. Many Dark Psy producers are hailing from Russia, so&nbsp;you might see this genre referred as&nbsp;a&nbsp;Russian style.</p>
                    </div>

                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/5qNqt8wJs5VNGSK1YS7u0H?si=LdB0lbKgQbGAGDiJBPF5BA">Forest Psy</a></h2>
                    <p>Also known as: Forest Psychedelic, Scandinavian Dark Psy</p>
                    

                    <div>

                        <p>BPM range: 150—160</p>
                        <p>Forest Psy is&nbsp;very similar to&nbsp;Dark Psy in&nbsp;many ways, but it’s less robotic-themed and focuses more on&nbsp;the ambient noises, nature atmosphere, and the spooky sounds you would hear in&nbsp;a&nbsp;dark psychedelic forest. Filled with swarming and teeming effects, it&nbsp;is&nbsp;also slightly faster than Dark Psy and arranged in&nbsp;a&nbsp;straightforward manner, almost with no&nbsp;breakdowns and beat interruptions.</p>
                    </div>

                    

                    
                    

                </div>
        </div>



        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/6ADFesBjevIYRUtfG2k5ex?si=eDE9h9fHRIaMRARejul1pw">Hi-Tech</a></h2>
                    <p>Also known as: Hitek Psy, Psycore </p>
                    

                    <div>

                        <p>BPM range: 170—230</p>
                        <p>Hi-Tech is&nbsp;a&nbsp;Psytrance style strongly influenced by&nbsp;Dark Psytrance, Psycore, and Full-On. It&nbsp;is&nbsp;characterized by&nbsp;a&nbsp;synthetic aesthetic pushed to&nbsp;the extreme. In&nbsp;terms of&nbsp;tempo, Hi-Tech vary from 150&nbsp;BPM to&nbsp;over 200&nbsp;BPM, making it&nbsp;and Psycore the fastest Psychedelic Trance styles. Unlike Psycore, Hi-Tech can present an&nbsp;absence of&nbsp;atmosphere in&nbsp;favor of&nbsp;a&nbsp;non-regular melodic structure. In&nbsp;addition, Hi-Tech is&nbsp;generally the least predictable and constant of&nbsp;all Psychedelic Trance styles.</p>
<p>Note: in&nbsp;the future version of&nbsp;this guide, Hi-Tech and Psycore will be&nbsp;separated. Please <a href="http://daniellesden.com/blog/all/introducing-psytrance-guide/">read more in&nbsp;the blog</a>.</p>
                    </div>
                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/4JJWQQQcOhg4roMqcGQyWe?si=zONgz4_bQ4O9hMpk54AAdg">Suomi</a></h2>
                    <p>Also known as: Suomisaundi, Finnish Psy </p>
                    

                    <div>

                        <p>BPM range: 135—145</p>
                        <p>Originated from Finland, Suomi is&nbsp;probably the most free-form subgenre of&nbsp;Psychedelic music allowing artists to&nbsp;go&nbsp;wild and experiment both musically and production-wise. Suomisaundi tracks are usually very melodic, including heavy influences from early Goa, tribal beats and Acid Trance tracks, as&nbsp;well as&nbsp;funky guitar and keyboard loops and sounds from or&nbsp;reminiscent of&nbsp;80’s.</p>
                    </div>

                    

                    
                    

                </div>
        </div>

        <div>
            <div data-expose="true" data-effect="slide" data-right="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/5bureHLe8RGJoak8ARvsDt?si=e-clwODLQ4OgEXT-jVIz0g">Psychill</a></h2>
                    <p>Also known as: Psybient, Psychedelic Chillout, Downtempo Psy</p>
                    

                    <div>

                        <p>BPM range: 90—120</p>
                        <p>Psychill is&nbsp;a&nbsp;downtempo genre that often seeks to reach a state of deep relaxation, close to meditation and lucid dreaming. It utilises various elements of&nbsp;Goa Trance and Psychedelic music in&nbsp;general, and typically has a&nbsp;classic Goa kick drum, 303’s sounds, and lush atmospheric pads.</p>
                    </div>

                    

                    
                    

                </div>

            <div data-expose="true" data-effect="slide" data-left="50em" data-continue="true" data-hold="100">
                    <h2><a href="https://open.spotify.com/playlist/48oZeMiO86UmdejumrFZf6?si=jXK2nqSIRJKrSo5C3WLySA">Chillout</a></h2>
                    <p>Also known as: Chill, Ambient, Downtempo</p>
                    

                    <div>

                        <p>BPM range: 80—110</p>
                        <p>Chillout music is&nbsp;very similar to&nbsp;Psychill but less psychedelic influenced. Formally speaking, Chillout is&nbsp;a&nbsp;subgenre of&nbsp;electronic music in&nbsp;general, not Psytrance in&nbsp;particular. However, historically it&nbsp;has a&nbsp;deep connection to&nbsp;the Psy scene and today you can hear many Chillout artists playing at&nbsp;the Psytrance festivals.</p>
                    </div>

                    

                    
                    

                </div>
        </div>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waymo Layoffs (152 pts)]]></title>
            <link>https://sfstandard.com/2023/10/17/tech-layoffs-waymo-san-francisco-robotaxi/</link>
            <guid>37923547</guid>
            <pubDate>Wed, 18 Oct 2023 00:46:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfstandard.com/2023/10/17/tech-layoffs-waymo-san-francisco-robotaxi/">https://sfstandard.com/2023/10/17/tech-layoffs-waymo-san-francisco-robotaxi/</a>, See on <a href="https://news.ycombinator.com/item?id=37923547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Waymo, the robotaxi company whose <a href="https://sfstandard.com/2023/09/03/robotaxi-waymo-cruise-first-responders-how-to-override-manual-mode/">presence has expanded across San Francisco in recent months</a>, has slashed jobs for the third time this year.</p></div><p>A Waymo spokesperson told The Standard that the layoffs are part of an internal reorganization process.</p><p>“A small number of Waymo teams recently made adjustments to their teams as part of normal course of business,” the spokesperson said in an emailed statement Monday evening.</p><p>The spokesperson declined to provide details about the number of affected employees but said the number is small.</p><figure><span><span></span><img alt="" sizes="(min-width: 1001px) 650px, (min-width: 768px) 550px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2023/08/RobotaxiBlindSpot08102023_01-1.jpg?w=2500?w=3840&amp;q=75" decoding="async" data-nimg="responsive" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><figcaption>A pedestrian crosses Ninth Street in San Francisco as a Waymo robotaxi approaches them. | <span>Source: </span>Jeremy Chen/The Standard</figcaption></figure><div><p>Google's parent company Alphabet, which owns the autonomous vehicle operator, <a href="https://techcrunch.com/2023/01/24/waymo-lays-off-staff-as-alphabet-announces-12000-job-cuts/" target="_blank" rel="noreferrer noopener">laid off dozens of Waymo employees</a> at the start of 2023 <a href="https://sfstandard.com/2023/01/20/google-axes-12000-jobs-as-big-tech-layoffs-continue/">as part of wide-scale layoffs</a> across the tech conglomerate. In March, <a href="https://www.reuters.com/technology/alphabets-waymo-cuts-137-jobs-second-round-layoffs-this-year-2023-03-01/" target="_blank" rel="noreferrer noopener">the company sacked another batch of employees</a>.</p></div><p>Waymo employed around 2,500 employees at the start of the year, according to reports. More than 200 were axed in the two layoff rounds earlier this year, but the number of remaining Waymo staffers following this cut is unclear.</p><p>In August, Waymo's operations—along with those of General Motors-owned <a href="https://sfstandard.com/2023/10/17/cruise-gm-federal-investigation-safety/">Cruise</a>—were granted permission by state regulators to expand in San Francisco.</p><p>Alphabet's "Other Bets" division—which includes Waymo—generated $285 million in revenue last quarter, according to filings. However, it lost $813 million. Alphabet's next earnings call is scheduled for Oct. 24.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google opens Falcon, a reliable low-latency hardware transport, to the ecosystem (199 pts)]]></title>
            <link>https://cloud.google.com/blog/topics/systems/introducing-falcon-a-reliable-low-latency-hardware-transport</link>
            <guid>37922948</guid>
            <pubDate>Tue, 17 Oct 2023 23:31:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/topics/systems/introducing-falcon-a-reliable-low-latency-hardware-transport">https://cloud.google.com/blog/topics/systems/introducing-falcon-a-reliable-low-latency-hardware-transport</a>, See on <a href="https://news.ycombinator.com/item?id=37922948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>At Google, we have a long history of solving problems at scale using Ethernet, and rethinking the transport layer to satisfy demanding workloads that require high burst bandwidth, high message rates, and low latency. Workloads such as storage have needed some of these attributes for a long time, however, with newer use cases such as massive-scale AI/ML training and high performance computing (HPC), the need has grown significantly. In the past, we’ve openly shared our learnings in traffic shaping, congestion control, load balancing, and more with the industry by contributing our ideas to the <a href="https://www.acm.org/" target="_blank">Association for Computing Machinery</a> and <a href="https://ietf.org/" target="_blank">Internet Engineering Task Force</a>. These ideas have been implemented in software and a few in hardware for several years. But going forward, we believe the industry at large will see more gains by implementing the set with dedicated and flexible hardware assist.</p><p>To achieve this goal, we developed Falcon to enable a step function in performance over software-only transports. Today at the <a href="https://www.opencompute.org/summit/global-summit" target="_blank">OCP Global Summit</a>, we are excited to open Falcon to the ecosystem through the <a href="https://www.opencompute.org/" target="_blank">Open Compute Project</a>, the natural venue to empower the community with Google’s production learnings to help modernize Ethernet.</p><p>As a hardware-assisted transport layer, Falcon is designed to be reliable, high performance, and low latency and leverages production-proven technologies including <a href="https://research.google/pubs/pub46460/" target="_blank">Carousel</a>, <a href="https://research.google/pubs/pub48630/" target="_blank">Snap</a>, <a href="https://research.google/pubs/pub49448/" target="_blank">Swift</a>, <a href="https://research.google/pubs/pub52149/" target="_blank">PLB</a>, and <a href="https://datatracker.ietf.org/doc/html/draft-ravi-ippm-csig-00" target="_blank">CSIG</a>.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Falcon.max-1618x910.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Falcon.max-1618x910.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Falcon’s layers are illustrated in the figure below, including their associated function. We show the RDMA and NVM Express™ Upper layer protocols (ULPs), however, Falcon is extensible to additional ULPs as needed by the ecosystem.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Falcon.max-1975x1111.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Falcon.max-1975x1111.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>The lower layers of Falcon use three key insights to achieve low latency in high-bandwidth, yet lossy, Ethernet data center networks. Fine-grained hardware-assisted round-trip time (RTT) measurements with flexible, per-flow hardware-enforced traffic shaping, and fast and accurate packet retransmissions, are combined with multipath-capable and <a href="https://cloud.google.com/blog/products/identity-security/announcing-psp-security-protocol-is-now-open-source">PSP-encrypted</a> Falcon connections. On top of this foundation, Falcon has been designed from the ground up as a multi-protocol transport capable of supporting ULPs with widely varying performance requirements and application semantics. The ULP mapping layer not only provides out-of-the-box compatibility with Infiniband Verbs RDMA and NVMe ULPs, but also includes additional innovations critical for warehouse-scale applications such as flexible ordering semantics and graceful error handling. Last but not least, the hardware and software are co-designed to work together to help achieve the desired attributes of high message rate, low latency, and high bandwidth, while maintaining flexibility for programmability and continued innovation.</p><p>Falcon reflects the central role that Ethernet continues to play in our industry. Falcon is designed for predictable high performance at warehouse scale, as well as flexibility and extensibility. We look forward to working with the community and industry partners to modernize Ethernet to serve the networking requirements of our AI-driven future. We believe that Falcon will be a valuable addition to the other ongoing efforts in this space.</p><h3>Industry perspectives</h3><p>Our partners across the industry are enthusiastic about the promise that Falcon holds for developing the next generation of Ethernet.</p><p><i>“We welcome Google’s contribution of Falcon as it shares the Ultra Ethernet Consortium’s vision to drive Ethernet as the best data center fabric for AI and HPC, and look forward to continuing industry innovations in this important space.”</i> - Dr. J Metz, Chair, Ultra Ethernet Consortium (led by AMD, Arista, Broadcom, Cisco, Eviden, Hewlett Packard Enterprise, Intel, Meta, Microsoft, and Oracle)</p><p><i>“Falcon is first available in the Intel IPU E2000 series of products. The value of these IPUs is further enhanced as the first instance of an Ethernet transport to add low tail latency and congestion handling at scale. Intel is a Steering Member of Ultra Ethernet Consortium, which is working to evolve Ethernet for high performance AI and HPC workloads. We plan to deploy the resulting standards-based enhancements in future IPU and Ethernet products.”</i> - Sachin Katti, SVP &amp; GM, Network and Edge Group, Intel</p><p><i>"We are pleased to see a high-performance transport protocol for critical workloads such as AI and HPC that works over standard Ethernet/IP networks and enables massive application bandwidth at scale."</i> - Hugh Holbrook, Group VP, SW Eng., Arista Networks</p><p><i>“Cisco is pleased to see the contribution of Falcon to the OCP. Cisco has long supported open standards and believes in broad ecosystems. The rate and scale of modern data center networks and particularly AI/ML networks is unprecedented, presenting a challenge and opportunity to the industry. Falcon addresses many of the challenges of these networks, enabling efficient network utilization.”</i> - Ofer Iny, Cisco Fellow, Cisco</p><p><i>“Juniper is a strong supporter of open ecosystems, and therefore we are pleased to see Falcon being opened to the OCP community. Falcon allows Ethernet to serve as the data center network-of-choice for demanding workloads, providing high-bandwidth, low tail latency and congestion mitigation. Falcon provides the industry with a proven solution today for demanding AI &amp; ML workloads.”</i> - Raj Yavatkar, Chief Technology Officer, Juniper</p><p><i>“Marvell strongly supports and is committed to the open Ethernet ecosystem as it evolves to support emerging, demanding workloads such as AI. We applaud the contribution of Falcon to OCP and welcome Google sharing practical experiences with the industry.”</i> - Nick Kucharewski, SVP &amp; GM Network Switching Group, Marvell</p><h3>Learn more</h3><p>Networking is a foundational component in building the sustainable, secure, scalable societal infrastructure that we need for this AI-driven future. To learn more about Falcon, join us for the OCP Summit presentation, “A Reliable and Low Latency Ethernet Hardware Transport” by Google’s Nandita Dukkipati at 11:45am at the Expo Hall. We’ll contribute the Falcon specification to OCP in the first quarter of 2024.</p><p>To learn more about Google’s contributions to the Open Compute Project and our presence at the OCP Global Summit, check out the blog “<a href="https://cloud.google.com/blog/topics/systems/google-systems-innovations-at-ocp-global-summit">How we’ll build sustainable, scalable, secure infrastructure for an AI-driven future</a>”.</p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/topics/systems" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/systems" track-metadata-module="tag list" track-metadata-module_headline="posted in">Systems</a></li><li><a href="https://cloud.google.com/blog/products/networking" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/networking" track-metadata-module="tag list" track-metadata-module_headline="posted in">Networking</a></li><li><a href="https://cloud.google.com/blog/topics/hpc" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/hpc" track-metadata-module="tag list" track-metadata-module_headline="posted in">HPC</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Graphics at JetBrains (127 pts)]]></title>
            <link>https://blog.jetbrains.com/blog/2023/10/16/ai-graphics-at-jetbrains-story/</link>
            <guid>37922272</guid>
            <pubDate>Tue, 17 Oct 2023 22:08:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jetbrains.com/blog/2023/10/16/ai-graphics-at-jetbrains-story/">https://blog.jetbrains.com/blog/2023/10/16/ai-graphics-at-jetbrains-story/</a>, See on <a href="https://news.ycombinator.com/item?id=37922272">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    
                        <section data-clarity-region="article">
                <div>
                    				<p><a href="https://blog.jetbrains.com/blog/category/datalore/">Datalore</a>
			<a href="https://blog.jetbrains.com/blog/category/design-decisions/">Design decisions</a>
			<a href="https://blog.jetbrains.com/blog/category/desktopart/">DesktopArt</a>
			<a href="https://blog.jetbrains.com/blog/category/jetbrains/">JetBrains</a>
			<a href="https://blog.jetbrains.com/blog/category/pycharm/">PyCharm</a></p>                    <div>
                            <p><img src="https://blog.jetbrains.com/wp-content/uploads/2023/10/photo_2023-07-13_15-58-17-e1696938091752-200x200.jpg" width="200" height="200" alt="Vladimir Sotnikov" loading="lazy">
                                                                                                                    <img src="https://blog.jetbrains.com/wp-content/uploads/2023/02/Olga_BVG-200x200.png" width="200" height="200" alt="Olga Andreevskikh" loading="lazy">
                                                                                                </p>
                            
                        </div>
                    <h2>Generating art at JetBrains</h2>
<p>At JetBrains, we are constantly refining our approach to creating pieces of art for use as website elements and release graphics. Our mission is to free graphic designers from routine tasks so they can concentrate on their core competence – creativity. The history of internal tools for generating art at JetBrains starts about a decade ago. At first, we mainly used WebGL-based tools, which generated everything randomly in the browser on the fly (the interactive archive is available <strong><a href="https://cai.jetbrains.com/" target="_blank" rel="noopener">here</a></strong><span>). The images below were created with this approach.<br>
<img decoding="async" fetchpriority="high" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/idea_2016-1.png" alt="IDEA 2016.1 splash screen" width="1200" height="800"><br>
<img decoding="async" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/pycharm_2019-1.png" alt="PyCharm Professional 2019.3 splash screen" width="1200" height="800"></span></p>
<p>Splash screens that were created using WebGL.</p>
<p>In 2020, we released our first <strong><a href="https://blog.jetbrains.com/blog/2020/09/29/intelligent-code-art/" target="_blank" rel="noopener">tool based on deep neural networks</a></strong><span>. Since then, everything has been generated in a K8s GPU cluster using PyCharm and Datalore for local and remote development. The browser is used only for input-output. With this approach based on neural networks, we’ve achieved a much higher degree of personalization, allowing us to cater to our designers’ needs, and we are constantly working to improve it.<br>
These pictures were made with a compositional pattern-producing network (CPPN, top) and Stable Diffusion (SD, bottom). This post will cover the technical details of both approaches, as well as the way we combine them to create even more spectacular designs.<br>
<img decoding="async" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image5.png" alt="PyCharm desktop art" width="1200" height="800"><br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image18.png" alt="RubyMine desktop art" width="1200" height="800"></span></p>
<p>Splash screens that were generated with neural networks.</p>
<h2>CPPNs: An overview</h2>
<p>CPPNs are among the simplest generative networks. They simply map pixel coordinates (x, y) to image colors (r, g, b). CPPNs are usually trained on specific images or sets of images. However, we found that randomly initialized CPPNs produce beautiful abstract patterns when the initialization is done correctly).<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image21.png" alt="CPPN architecture" width="1200" height="800"></p>
<p>CPPN architecture: pixel coordinates are inputs, RGB values are outputs.</p>
<p>Using the usage data from an early internal version of the generator, we refined our algorithms to improve the visual quality. Aside from that, we also slightly extended the classical architecture of CPPNs by introducing multiple virtual parameters. Hence, our CPPNs now map (x, y, a, b, c, f) to (r, g, b). This simple change allows us to introduce an easy-to-use, although somewhat unpredictable, method for altering the image, as shown below.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image2.png" alt="Virtual parameters of CPPN" width="1200" height="800"></p>
<p>By updating the virtual parameter (a), we’re slightly changing the picture.</p>
<p>These virtual parameters don’t have to be constant. For example, we can map the value of the virtual parameter f of each pixel to the distance from this pixel to the center of the image. This trick allows us to ensure the image has circular shapes. Or we could map f to the sum of the absolute values of the pixel’s coordinates, which will yield diamond-shaped patterns. This is where math actually meets art!<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image27.png" alt="Virtual parameters of CPPN, second example" width="1200" height="800"></p>
<p>Different functions f(x,y) result in different image patterns.</p>
<p>To ensure that our randomly initialized CPPNs always produce beautiful designs, we trained a recommendation system to predict whether the given set of parameters will result in an image that looks good. We trained our algorithm from user feedback received during internal testing. The figure below shows two examples of images created by randomly initialized CPPNs and their corresponding “beautifulness” scores.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image14.png" alt="Predicting “beautifulness” scores of CPPN images" width="1200" height="800"></p>
<p>Predicting “beautifulness” scores of CPPN images.</p>
<h2>CPPNs: Animation</h2>
<p>Our CPPN-generated works of art really come to life when they are transformed into video graphics. By mapping virtual parameters (a, b, c) over any closed parametric curve (one that starts and ends at the same point), we can create seamlessly looped animations of any desired length!<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image6.png" alt="Sample frames of a CPPN animation video" width="1200" height="800"></p>
<p>Sample frames of a CPPN animation video.</p>
<p>The choice of a curve function is crucial. Animating virtual parameters over a plain circle is the most straightforward approach. However, it has a drawback: when the sign of a parameter changes (for example, from 0.01 to -0.01) while it has a low first derivative value (one that equals zero in the case of a circle trajectory), the result is usually a shaky animation. To account for this issue, we use <strong><a href="https://en.wikipedia.org/wiki/Lemniscate_of_Bernoulli" target="_blank" rel="noopener">Bernoulli’s lemniscate</a></strong><span> to ensure that the signs of the virtual parameters never change (see the image below). This solves the shaky animation problem, but introduces a new one. For most animation frames, one of the parameters is only incrementally updated, making the animation look too shallow. We addressed this by switching to a random spline function. The more complex the trajectories we used, the richer the animation looked!<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image2-1.png" alt="Examples of CPPN curve functions" width="1200" height="800"></span></p>
<p>Examples of CPPN curve functions.</p>
<h2>CPPNs: Color correction</h2>
<p>There’s one more crucial detail: color correction. Our CPPNs – and therefore the resulting images – are randomly generated, but we need to ensure that each uses our brand colors. We tried a few different approaches to achieve this. The first iteration (<strong><a href="https://blog.jetbrains.com/blog/2020/09/29/intelligent-code-art/" target="_blank" rel="noopener">used in the 2020 releases</a></strong><span>) relied on SVG recoloring directly in the browser (using feColorMatrix and feComponentTransfer). This approach was quick – since the recoloring happened in the browser, we could update the palette without re-rendering the image on the server side. However, it was tricky to implement as some palettes are too complex for feColorMatrix and feComponentTransfer and it was generally unreliable. After extensive experimentation, we found that the resulting colors could differ depending on the browser and the operating system. Here is an example from our experiments in early 2020. On the left is a screenshot of a background of the earlier generator version made on a setup using Safari on macOS, and on the right is a screenshot of the same background but from a setup using Google Chrome on Ubuntu Linux. Notice the subtle brightness discrepancies. The more post-processing effects we applied, the more prominent they became.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image3.png" alt="An example of brightness discrepancies" width="1200" height="800"></span></p>
<p>An example of brightness discrepancies.</p>
<p>Another example is <strong><a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/feComponentTransfer" target="_blank" rel="noopener">MDN’s sample</a></strong><span> of feComponentTransfer. This time, both images were made on the same machine using Ubuntu Linux and Google Chrome, but in the top screenshot, hardware acceleration was disabled. There are prominent color discrepancies, especially between the Table lookup examples. Thus, despite being very quick, this approach to color correction was extremely inconsistent.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image11.png" alt="An example of color discrepancies" width="1200" height="800"></span></p>
<p>An example of color discrepancies.</p>
<p>Our current approach (in use since 2021) is more straightforward. We render source images in 32-bit grayscale, meaning that instead of RGB, our CPPNs return only a single luminance value. We then map each pixel to a lookup table with precomputed ideal RGB values. This approach is slower but produces pixel-perfect results.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image7.png" alt="An example of color correction using a grayscale image" width="1200" height="800"></p>
<p>An example of color correction using a grayscale image.</p>
<p><img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image9.png" alt="2020.1 splash screens" width="1200" height="800"></p>
<p>2020.1 splash screens that used SVG recoloring.</p>
<p>When our current approach to color correction is used alongside the CPPN with virtual parameters and spline animation, the result is a video like this!</p>
<p><iframe loading="lazy" width="1200" height="800" src="https://www.youtube.com/embed/LyRNdWnbysg?si=9WMIbkeYIrVJ9ph9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><br>
Another remarkable property of CPPNs is that, due to their simple architecture, it’s very easy to translate their computational graphs to GLSL code. Once the animation video is ready, we can export it as a WebGL fragment shader and then directly run it in the browser. An example of the results of this approach is <strong><a href="https://www.jetbrains.com/qodana/" target="_blank" rel="noopener">Qodana’s landing page</a></strong><span>.</span></p>
<p>Our CPPN-based generator is available <strong><a href="https://gradient-public.labs.jb.gg/" target="_blank" rel="noopener">here</a></strong><span>.<br>
To dive deeper into CPPNs, check out our public Datalore notebook with code examples:</span></p>
<p>
    <a href="https://datalore.jetbrains.com/report/static/2jrFAfMBVhUsYW8njXgysC/9OuleGiEVhxqGen1GS9cjN" target="_blank" rel="noopener">Open Datalore notebook<br>
</a></p>
<h2>Taming Stable Diffusion</h2>
<p>Stable Diffusion offers a high level of versatility and visual fidelity, making it a perfect backbone for our art generators. To make Stable Diffusion appropriate for use as a source of release graphics, we had to adhere to the following criteria:</p>
<ul>
<li>Images should follow the brand palette.</li>
<li>No artifacts or glitches (such as broken pixels) are allowed.</li>
<li>It should be easy to use a specific style (abstract smooth lines) out of the box.</li>
<li>It should require little to no prompting, meaning it should provide accessible and intuitive controls.</li>
</ul>
<p>Though there is always room for improvement, we’ve met all of these requirements. The latest images are <strong><a href="https://code2art.jetbrains.com/" target="_blank" rel="noopener">publicly available</a></strong><span>, and all of the technical details are below.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image8.png" alt="2023.1 splash screens" width="1200" height="800"></span></p>
<p>2023.1 splash screens created with Stable Diffusion.</p>
<p>To produce results that consistently met all of our criteria, we fine-tuned Stable Diffusion using various references provided by our designers. Below are some examples of images generated according to various styles.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image10.png" alt="Experimental styles obtained by fine-tuning Stable Diffusion" width="1200" height="800"><br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image17.png" alt="Experimental styles obtained by fine-tuning Stable Diffusion" width="1200" height="800"><br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image16.png" alt="Experimental styles obtained by fine-tuning Stable Diffusion" width="1200" height="800"></p>
<p>Experimental styles obtained by fine-tuning Stable Diffusion.</p>
<p>Before diving into the technical details of the fine-tuning process, let’s look at the internals of Stable Diffusion. It essentially consists of three parts: the CLIP text encoder (a tiny transformer model used for encoding text into a multi-modal embedding space), a variational autoencoder that compresses and decompresses images to and from latent space, and the denoising UNet.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image19.png" alt="The architecture of Stable Diffusion" width="1200" height="800"></p>
<p>The architecture of Stable Diffusion. Image source: <a href="https://www.philschmid.de/stable-diffusion-inference-endpoints" target="_blank" rel="noopener">www.philschmid.de/stable-diffusion-inference-endpoints</a>.</p>
<p>The generation process is roughly as follows:</p>
<ol>
<li>We encode the prompt text into an embedding, which is a 77×768 floating-point array.</li>
<li>We randomly generate the latent representation of the image, which could be either pure Gaussian noise or a noised representation of an init image.</li>
<li>We repeatedly pass the encoded latent image and encoded text through the denoising UNet for a given number of steps.</li>
<li>After denoising the latent image, we pass it through the decoder, thus decompressing it into a standard RGB image.</li>
</ol>
<p><img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image20.png" alt="The denoising process" width="1200" height="800"></p>
<p>The denoising process. Image source: <a href="https://jalammar.github.io/illustrated-stable-diffusion/" target="_blank" rel="noopener">jalammar.github.io/illustrated-stable-diffusion/</a>.</p>
<p>Crucially for us, the great thing about Stable Diffusion is that it’s possible to fine-tune it with very little data and achieve great results! As a side effect, data-efficient fine-tuning methods are also computing-efficient, which makes it even better.</p>
<p>The most straightforward fine-tuning approach is textual inversion (p-tuning). We freeze all of the weights, such as UNet, VAE, and the text encoder (meaning we don’t update them during training), and only train one new word per embedding for the text encoder. Because we only train one new word per embedding, there are only 768 trainable parameters!<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image26.png" alt="Outline of the text-embedding and inversion process" width="1200" height="800"></p>
<p>Outline of the text-embedding and inversion process. Image source: <a href="https://textual-inversion.github.io/" target="_blank" rel="noopener">textual-inversion.github.io/</a>.</p>
<p>These custom embeddings are composable, meaning we could use up to 77 embeddings in a single prompt. On top of that, they are easy to train, taking ~2 hours on a single RTX 4090. Below is an example of the training process. Both of these images were generated using the prompt “digital art in the style of &lt;sculpture&gt;”, where “&lt;sculpture&gt;” is the new word embedding that we’re training. As we perform more training steps, the image evolves, and the new visual style becomes more and more pronounced.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image23-e1697018482514.png" alt="The image generated with the textual inversion after 500 and 3000 training steps" width="1200" height="800"></p>
<p>The image generated with the textual inversion after 500 and 3000 training steps.</p>
<p>Another popular and efficient fine-tuning method is Low-Rank Adaptation, or simply LoRA. The key idea of LoRA is similar to textual inversion, only this time in addition to freezing the weights we also introduce new ones by adding small adapter layers to attention layers inside UNet.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image22.png" alt="Illustration of the LoRA method within one Transformer layer" width="1200" height="800"></p>
<p>Illustration of the LoRA method within one Transformer layer. Image source: <a href="https://adapterhub.ml/blog/2022/09/updates-in-adapter-transformers-v3-1/" target="_blank" rel="noopener">adapterhub.ml/blog/2022/09/updates-in-adapter-transformers-v3-1/</a>.</p>
<p>Compared to textual inversion, this approach makes it possible to capture more sophisticated patterns from the fine-tuning data (for example, “AI portrait” apps work by training adapter layers on the user’s face), but it uses slightly more resources and, most importantly, multiple LoRAs cannot be composed. In our specific use case, we found that LoRA is most effective when working with Stable Diffusion XL. By contrast, in earlier versions of Stable Diffusion (1.4, 1.5, or 2.1), textual inversion allows for more versatility.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image12.png" alt="The image generated with LoRA after 200 and 1000 training steps" width="1200" height="800"></p>
<p>The image generated with LoRA after 200 and 1000 training steps.</p>
<h2>Combining the strengths of Stable Diffusion and CPPNs</h2>
<p>One of our criteria for using Stable Diffusion was the need to ensure that the generated images follow the color palette of some particular brand, and this is where CPPNs come to our aid! Before generating an image with Stable Diffusion, we generate an image with CPPN using our Gradient generator (described above), apply the desired colors with pixel-perfect accuracy, then encode it with VAE and mix it with Gaussian noise. UNet uses the resulting latent image as its starting point, thus preserving the original colors and composition.<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image24.png" alt="CPPN → Stable Diffusion pipeline" width="1200" height="800"><br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image25.png" alt="CPPN → Stable Diffusion pipeline" width="1200" height="800"></p>
<p>CPPN → Stable Diffusion pipeline.</p>
<p>Once the CPPN image is ready, we can also edit it directly in the browser to achieve any shape and design we could ever imagine!<br>
<img decoding="async" loading="lazy" src="https://blog.jetbrains.com/wp-content/uploads/2023/10/image13.png" alt="CPPN → Stable Diffusion pipeline with manually edited CPPN image" width="1200" height="800"></p>
<p>CPPN → Stable Diffusion pipeline with manually edited CPPN image.</p>
<p>Finally, once we have produced multiple images with our “CPPN → Stable Diffusion” pipeline, we can train another CPPN on those images and turn them into an animation, as described in the <em>CPPNs: Animation</em> section above! Here’s some example <strong><a href="https://www.shadertoy.com/view/DsBSW3" target="_blank" rel="noopener">GLSL code</a></strong><span>, along with some example videos:</span></p>
<p><iframe loading="lazy" width="1200" height="800" src="https://www.youtube.com/embed/videoseries?si=v2QZwkpQvh5LVSsW&amp;list=PLF5prDhdrZ1dcsmkL9AQqpkdeom7j4fLS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>The exploration and implementation of AI-powered graphics at JetBrains has been an adventure. Our tools have evolved and matured over the years, from our initial approach using WebGL-based random generation to our current use of CPPNs and Stable Diffusion to generate sleek and personalized designs. Moving forward, we anticipate greater levels of customization and versatility, and we are excited about the possibilities these technologies will unlock in the graphics generation field.</p>
<p>We hope this in-depth look into our AI art journey has been illuminating! We invite you to explore the examples we’ve provided (including our <strong><a href="https://cai.jetbrains.com/" target="_blank" rel="noopener">interactive archive</a></strong><span>) and share your feedback here in the comments or via <a href="mailto:cai@jetbrains.com">cai@jetbrains.com</a>. Please let us know what kinds of topics you would like to see from the Computational Arts team in the future!</span></p>
                    
                                                                                                                                                        <div>
                                <h4>Subscribe to Blog updates</h4>
                                
                            </div>
                            
                                                            </div>
                <a href="#"></a>
                
                
            </section>
                    <div>
                <p>
                    <h2>Discover more</h2>
                </p>
                
            </div>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The pneumatic tube mail system in New York City (162 pts)]]></title>
            <link>https://untappedcities.com/2023/10/17/pneumatic-tube-mail-new-york-city/</link>
            <guid>37922200</guid>
            <pubDate>Tue, 17 Oct 2023 22:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://untappedcities.com/2023/10/17/pneumatic-tube-mail-new-york-city/">https://untappedcities.com/2023/10/17/pneumatic-tube-mail-new-york-city/</a>, See on <a href="https://news.ycombinator.com/item?id=37922200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>I’m often asked what my favorite weird/obscure fact about New York City was. Ironically, as the founder of Untapped New York, this question frequently proves difficult because there are just so many amazing things about this city. So I went back into my memory archives, thinking what about New York City impelled me to create Untapped New York. The <em>pneumatic tube mail system</em> is top on that list.</p>
<div>
<figure><a href="https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0.jpg"><img data-attachment-id="564168" data-permalink="https://untappedcities.com/pneumatic-mail-tube-smithsonian-untapped-new-york0/" data-orig-file="https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0.jpg" data-orig-size="700,553" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Pneumatic-mail-Tube-smithsonian-&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Pneumatic-mail-Tube-smithsonian-untapped-new-york0" data-image-description="" data-image-caption="" data-medium-file="https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0-300x237.jpg" data-large-file="https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0.jpg" decoding="async" loading="lazy" width="700" height="553" src="https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0.jpg" alt="Pneumatic mail tube" srcset="https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0.jpg 700w, https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0-300x237.jpg 300w, https://untappedcities.com/wp-content/uploads/2020/12/Pneumatic-mail-Tube-smithsonian-untapped-new-york0-600x474.jpg 600w" sizes="(max-width: 700px) 100vw, 700px"></a><figcaption><em>A pneumatic tube mail canister. Photo courtesy National Postal Museum, Smithsonian Institution</em></figcaption></figure>
</div>
<p>The first pneumatic tube mail system was installed in Philadelphia (sorry New York) in 1893. New York City’s came in 1897. Each tube could carry between 400 and 600 letters and traveled at 30-35 miles per hour.&nbsp;In its full glory, the pneumatic tubes covered a 27-mile route, connecting 23 post offices. This network stretched up Manhattan’s east and west sides, from <a href="https://untappedcities.com/2017/04/11/the-top-10-secrets-of-bowling-green-the-oldest-public-park-in-nyc/" target="_blank" rel="noreferrer noopener">Bowling Green</a> and Wall Street, all the way north to <a href="https://untappedcities.com/newyork/2013/02/26/manhattanville-history-and-development/" target="_blank" rel="noopener noreferrer">Manhattanville</a> and East Harlem.</p>

<p><a href="https://about.usps.com/who-we-are/postal-history/pneumatic-tubes.pdf" target="_blank" rel="noopener noreferrer">Anecdotal stories</a> indicate that the system may have extended into the Bronx, with sandwich subs reportedly being delivered via pneumatic tubes from a renowned subway shop in the Bronx to downtown postal stations. Maps at the National Postal Museum show proposed extensions to the Bronx and other areas within Manhattan, many of which were never completed. The system even crossed boroughs into Brooklyn (using the <a href="https://untappedcities.com/2014/12/02/the-top-10-secrets-of-the-brooklyn-bridge/" target="_blank" rel="noopener noreferrer">Brooklyn Bridge</a>), taking four minutes to take letters from Church Street near <a href="https://untappedcities.com/2015/09/09/the-top-10-secrets-of-nycs-city-hall/" target="_blank" rel="noopener noreferrer">City Hall</a> to the General Post Office in Brooklyn (now <a href="https://untappedcities.com/tag/cadman-plaza/" target="_blank" rel="noopener noreferrer">Cadman Plaza</a>). The pneumatic tube mail system in New York City is the subject of the inaugural episode of The Untapped New York Podcast available on <a href="https://podcasts.apple.com/us/podcast/secrets-of-new-york/id1543822668" target="_blank" rel="noopener noreferrer">Apple Podcasts</a>, <a href="https://open.spotify.com/show/6REnRn0EBbMPI8OrvPmCCH" target="_blank" rel="noopener noreferrer">Spotify</a>, and <a href="https://secretsnewyork.com/subscribe" target="_blank" rel="noopener noreferrer"></a><a href="https://secretsofnewyork.buzzsprout.com/share" target="_blank" rel="noreferrer noopener">all of your favorite podcast apps</a>.</p>

<p>The system, which was located 4 to 6 feet below the city streets, was created and owned by private companies, to which the city paid rent and labor. According to The Smithsonian National Postal Museum, “Installation of the tubes was problematic, with previously laid pipes for sewage and gas limiting the size and thus the amount and kind of mail a pneumatic tube could carry. Water table levels also presented difficulties. Later, the New York City system was purchased and operated by the U.S. Postal Service. Using power from old-school electric motors, made by the likes of General Electric and Westinghouse, air pressure was created by rotary blowers and air compressors. Each canister was labeled on the outside with its destination, but all the tubes had to come out at each station. So if a canister was destined for another station, it would be sent back again into the tubes and on its way.</p>
<p>To feed my growing obsession with pneumatic mail, I went to Washington D.C.’s Smithsonian National Postal Museum where I met with Manda Kowalczyk an Accessions Officer at the Museum. She pulled all the items in the Postal Museum that are connected to the pneumatic tube mail systems in America. One of them you can see on a regular visit to the museum is the pneumatic tube mail canister which is on exhibit. This 24 inch long, 8 inch wide metal canister could carry somewhere between 400 and 600 letters. And, it could have definitely fit a small black cat.</p>
<div>
<figure><img data-attachment-id="565091" data-permalink="https://untappedcities.com/olympus-digital-camera-436/" data-orig-file="https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian.jpg" data-orig-size="700,312" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;3.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;u790SW,S790SW&quot;,&quot;caption&quot;:&quot;OLYMPUS DIGITAL CAMERA&quot;,&quot;created_timestamp&quot;:&quot;1329955957&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6.7&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.0166666666667&quot;,&quot;title&quot;:&quot;OLYMPUS DIGITAL CAMERA&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="OLYMPUS DIGITAL CAMERA" data-image-description="" data-image-caption="<p>OLYMPUS DIGITAL CAMERA</p>
" data-medium-file="https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian-300x134.jpg" data-large-file="https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian.jpg" decoding="async" loading="lazy" src="https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian.jpg" alt="Pneumatic Tube Mail system map of New York City" width="780" height="348" srcset="https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian.jpg 700w, https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian-300x134.jpg 300w, https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-System-Map-New-York-City-Smithsonian-600x267.jpg 600w" sizes="(max-width: 780px) 100vw, 780px"><figcaption><em>Pneumatic Tube Mail system map of New York City from November 1937. Photo courtesy National Postal Museum, Smithsonian Institution</em></figcaption></figure></div>
<p>The Postal Museum also has several maps of the New York City pneumatic tube system, mostly from the 1930s and 40s. A 1947 map has some fun facts, including the time it took to send mail between the General Post Office and other stations, the number of canisters that went through the system daily (95,000), the pressure needed (3 to 8 lbs per inch), and the speed (5 tube carriers per minute and 30 mph). That year there were 26.969 miles of 2 way pneumatic tubes tubes. It even has the hours of operation: Weekdays from 5 AM to 10 PM, Saturday from 5 AM to 10 AM, and no service on Sundays and legal holidays. I love the thought of mail getting shot underground at 5 AM to arrive just time for the beginning of the work day.</p>
<div>
<figure><img decoding="async" src="https://untappedcities.com/wp-content/uploads/2021/01/Damaged-Mail-from-Pneumatic-Mail-System.jpg" alt="Damaged Mail from Pneumatic Tube Mail"><figcaption><em>A message you’d get from the Postmaster if your mail was damaged in the pneumatic tube. &nbsp;Photo courtesy National Postal Museum, Smithsonian Institution</em></figcaption></figure></div>
<p>According to Kate Ascher, author of&nbsp;<em><a href="https://www.amazon.com/gp/product/0143112708/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0143112708&amp;linkCode=as2&amp;tag=untapcitie-20" target="_blank" rel="noopener noreferrer">The Works</a></em>, “The high operating costs of the pneumatic system ultimately proved its downfall. By 1918, the federal government considered the annual rental payments ($17,000 per mile per annum) made by the post office to be ‘exorbitant’ and endorsed a new alternative with greater capacity–the automobile–as the delivery method of choice.” In New York City, a successful lobby by contractors led to the reinstatement of pneumatic mail service in 1922. A complete stop didn’t happen until 1953. Paris’ system, which covered 269 miles, continued for an additional 34 years (but was more limited in what it could carry–the pipes were only 2 inches diameter).</p>
<div>
<figure><img decoding="async" src="https://untappedcities.com/wp-content/uploads/2021/01/Pneumatic-Tube-Mail-Remnant-Chelsea-Post-Office-New-York-City1-1.jpg" alt="Pneumatic tube mail remnant in Chelsea Post Office"><figcaption><em>Pneumatic tube mail remnants inside the Old <a title="Chelsea" data-wpil-keyword-link="linked" href="https://untappedcities.com/2021/09/27/secrets-chelsea-new-york/" target="_blank" rel="noopener">Chelsea</a> Post Office</em></figcaption></figure></div>
<p>And <a href="https://untappedcities.com/2013/08/06/untapped-mailbag-where-can-i-find-remnants-of-the-pneumatic-tubes-in-nyc/" target="_blank" rel="noopener noreferrer">what’s left of the pneumatic tubes</a>? Not much, if at all. The location of the tubes within a city’s underbelly basically guaranteed its destruction once no longer in use. The only known remaining remnant of the pneumatic tube mail system is in the Old Chelsea Post Office at 217 W 18th Street, where tubes come through a wall in the basement. They sit at the end of a forgotten brick-lined hallway filled with office supplies. Kate Ascher also notes that there was a time when remnants of the pneumatic tubes were still being found, but not often any longer.</p>
<p>Some additional fun facts about the pneumatic tube mail system:</p>
<ul>
<li>According to this incredible <a href="https://about.usps.com/who-we-are/postal-history/pneumatic-tubes.pdf" target="_blank" rel="noopener noreferrer">article</a> by Robert A. Cohen, the first cylinder tube to travel through the New York City&nbsp;system contained “a&nbsp;Bible, a flag and&nbsp;a copy of the Constitution. The second contained an imitation peach in honor of Senator Chauncy Depew (He was fondly known as “The Peach”).&nbsp;&nbsp;A third carrier had a black cat in it, for&nbsp;reasons unknown.”</li>
<li><span>It had set hours of operation: 5am to 10pm on weekdays, and 5am to 10am on Saturdays</span></li>
<li>The size of the carriers in New York City was 24 inches long, 8 inches across</li>
<li>95,000 letters were moved daily, about 1/3 of all first class letters</li>
<li>It took 4 minutes to get from the General Post Office (now <a href="https://untappedcities.com/2020/12/30/first-look-nyc-moynihan-train-hall/" target="_blank" rel="noopener noreferrer">Moynihan Train Hall</a>) to <a href="https://untappedcities.com/2013/03/13/top-10-secrets-of-grand-central-terminal/" target="_blank" rel="noopener noreferrer">Grand Central</a> using a tranverse tube that cut across Manhattan</li>
<li>It took between 15 and 20 minutes for mail to get from <a href="https://untappedcities.com/tag/herald-square/" target="_blank" rel="noopener noreferrer">Herald Square</a> to Manhattanville and East Harlem</li>
<li>It took 11 minutes to get from the General Post Office to the Planetarium Post Office, near the Museum of Natural History</li>
</ul>
<p><strong>Check out more episodes of the Untapped New York Podcast in the player below!</strong></p>

<p><strong>Here’s where you can find <a href="https://untappedcities.com/2013/08/06/untapped-mailbag-where-can-i-find-remnants-of-the-pneumatic-tubes-in-nyc/" target="_blank" rel="noopener noreferrer">remnants of the pneumatic tube network in New York City</a>. Check out the rest of the episodes of&nbsp;<em>The Untapped New York Podcast</em> on <a href="https://podcasts.apple.com/us/podcast/secrets-of-new-york/id1543822668" target="_blank" rel="noreferrer noopener">Apple Podcasts</a>, <a href="https://open.spotify.com/show/6REnRn0EBbMPI8OrvPmCCH?si=0tWMAivzT7yLzV4bK_Iopw" target="_blank" rel="noreferrer noopener">Spotify</a>, or <a href="https://secretsofnewyork.buzzsprout.com/share" target="_blank" rel="noreferrer noopener">wherever else you get your podcasts!</a></strong></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Universal cancer vaccine trial shows significant improvement in overall survival (194 pts)]]></title>
            <link>https://ultimovacs.com/investors/news/ultimovacs-announces-nipu-results-presented-at-esmo-2023-significant-and-clinically-meaningful-improvement-in-overall-survival-for-patients-receiving-uv1-cancer-vaccine-in-phase-ii-nipu-trial-in-mali</link>
            <guid>37922181</guid>
            <pubDate>Tue, 17 Oct 2023 21:58:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ultimovacs.com/investors/news/ultimovacs-announces-nipu-results-presented-at-esmo-2023-significant-and-clinically-meaningful-improvement-in-overall-survival-for-patients-receiving-uv1-cancer-vaccine-in-phase-ii-nipu-trial-in-mali">https://ultimovacs.com/investors/news/ultimovacs-announces-nipu-results-presented-at-esmo-2023-significant-and-clinically-meaningful-improvement-in-overall-survival-for-patients-receiving-uv1-cancer-vaccine-in-phase-ii-nipu-trial-in-mali</a>, See on <a href="https://news.ycombinator.com/item?id=37922181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="inner-content">

			
							
<article id="post-2607" role="article">

	
	<header>
		
								</header>

	
	<section>
		

<ul>
<li>UV1, in combination with the checkpoint inhibitors ipilimumab and nivolumab from Bristol-Myers Squibb, demonstrated a clinically meaningful overall survival benefit with no added toxicities, compared to ipilimumab and nivolumab alone, in the second-line treatment of patients with malignant mesothelioma </li>
<li>The UV1 cancer vaccination combined with ipilimumab and nivolumab reduced the risk of death by 27%, meeting the protocol predefined threshold for statistical significance, in a hard-to-treat patient group with currently no standard-of-care treatment options</li>
<li>First demonstration of universal cancer vaccine efficacy and therapeutic impact in a randomized Phase II clinical trial, supporting further clinical development </li>
<li>NIPU results to be presented by the Principal Investigator <a href="https://www.esmo.org/about-esmo/biographies/aaslaug-helland" rel="nofollow noopener" target="_blank"><u>Professor Åslaug Helland</u></a>, MD, Ph.D., at the ESMO Congress 2023 happening this week in Madrid
</li>
<li><em>The full dataset will be shared in a separate press release and at the Company website after the </em><em>Principal Investigator’s</em> <em>oral presentation, Saturday October 21, 2023 at 15:15 (CET)</em></li>
<li><em>Webcast with the Principal Investigator and Ultimovacs management to take place </em><em><br> on Mon, Oct 23 2023 at 14:30 (CET) &lt;</em><a href="https://channel.royalcast.com/hegnarmedia/#!/hegnarmedia/20231023_2" rel="nofollow noopener" target="_blank"><em><u>Link</u></em></a><em> to webcast&gt;
</em></li>
</ul>
<p><strong>Oslo, October 17, 2023: </strong>Ultimovacs ASA (“Ultimovacs”) (OSE ULTI), a clinical-stage biotechnology leader in novel immunotherapeutic cancer vaccines, today announced the results from the NIPU clinical trial (<a href="https://www.globenewswire.com/Tracker?data=IDpA1Hp7Djf9XWmP7uXWvcyxo7adyY-aFbIbt2kOL1M_vbdbjrNWqxOA99Z_1C-c6xtxr2EaXrP-WmSVaEfAgC6aGN7JRGnyHoaG5Y1hTUPKx4gVTVJPAZ1kIrmDt5B-" rel="nofollow noopener" target="_blank"><u>NCT04300244</u></a>), an investigator-initiated, randomized, multi-center, open-label Phase II clinical trial for second-line treatment in patients with malignant mesothelioma. The data presented as a late-breaking abstract at the ESMO Congress, shows that Ultimovacs’ cancer vaccine UV1, in combination with ipilimumab and nivolumab, demonstrated a statistically significant and clinically meaningful improvement of overall survival versus ipilimumab and nivolumab alone, a key secondary endpoint. No additional safety concerns were reported from the UV1 treatment. The late-breaking abstract is accessible at the ESMO website.</p>
<p>Malignant mesothelioma is considered an aggressive, complex form of cancer with a high mortality rate and few therapeutic options. Patients affected have often been occupationally or environmentally exposed to asbestos. Several efforts have been made in the last decades to improve the survival outcomes of patients with mesothelioma. There is currently no established standard of care in second-line treatment. </p>
<p>“For patients with malignant mesothelioma, few treatment options are available after first-line chemotherapy. The NIPU study showed that patients receiving UV1 vaccination as add-on to nivolumab and ipilimumab experienced an increased objective response rate and a clinically meaningful prolonged survival. These encouraging results provide a foundation for advancing further clinical development with UV1 vaccination in mesothelioma patients,” said Principal Investigator of the NIPU clinical trial, Professor Åslaug Helland, MD Ph.D.&nbsp;“We want to extend our gratitude to the patients and their families, as well as the dedicated investigators and all our supporters whose invaluable contributions made this study possible.”</p>
<p>The results showed that UV1 plus ipilimumab and nivolumab improved overall survival (OS), reducing the risk of death by 27% (HR=0.73 [80% CI, 0.53-1.00]). The median OS was 15.4 months (95% CI, 11.1-22.6) for UV1 plus ipilimumab and nivolumab (treatment arm) versus 11.1 months (95% CI, 8.8-18.1) for ipilimumab and nivolumab alone (control arm), with a median observation time of 17.3 months. This degree of improvement met protocol predefined threshold for statistical significance. </p>
<p>The data further demonstrated a benefit in terms of objective response rate, as determined by a blinded independent central review. In the UV1 arm, 31% of the patients experienced an objective response, as compared to 16% in the control arm (odds ratio 2.44 [80% CI, 1.35-4.49]).</p>
<p>The safety profile of the combination of UV1 plus ipilimumab and nivolumab observed in the trial was consistent with the safety profile of ipilimumab and nivolumab alone, confirming the good safety profile for UV1. The patients will continue to be monitored for efficacy and safety endpoints over the next years. </p>
<p>The title of the late-breaking ESMO abstract is “<em>LBA99 First survival data from the NIPU trial; A randomized, open-label, phase II study evaluating nivolumab and ipilimumab combined with UV1 vaccination as second line treatment in patients with malignant mesothelioma</em>.”</p>
<p>“We are thrilled to announce the highly advantageous results from the first randomized UV1 Phase II trial, marking a major milestone for Ultimovacs. Overall survival is the ‘gold standard’ in cancer treatment. We believe these data supports further development in mesothelioma, and we are looking forward to discussing the results with the regulatory authorities,” said Carlos de Sousa, CEO of Ultimovacs. “UV1, by demonstrating significant survival improvement in a hard-to-treat indication as malignant mesothelioma, shows that universal cancer vaccines are a treatment modality with the potential to improve the current treatment regime for cancer patients globally. The encouraging NIPU results heighten our optimism and raise our expectations for favorable results in the four additional ongoing UV1 Phase II trials. I would like to thank everyone who has contributed, especially Professor Åslaug Helland, who invited us to participate in the study, and Bristol-Meyers Squibb for their valuable contribution.”</p>
<p>The NIPU study is sponsored by Oslo University Hospital with support from Bristol-Myers Squibb and Ultimovacs. The randomized, open-label, multi-center trial with 118 patients conducted in Australia, Denmark, Norway, Spain, and Sweden, was designed to investigate if combining UV1 with checkpoint inhibitors ipilimumab and nivolumab would provide a benefit compared to ipilimumab and nivolumab alone, in patients with malignant mesothelioma after first-line treatment with platinum-based chemotherapy. The first patient in the NIPU trial was enrolled in June 2020, and the last patient was enrolled in January 2023. </p>
<p>The NIPU study announced topline results in June 2023. Based on blinded independent central review (BICR), the study did not meet the primary endpoint of PFS. Investigator assessment, a pre-defined supportive analysis of the primary endpoint performed by specialized radiologists at the study hospitals, showed a statistically significant positive PFS benefit for the patients in the UV1 arm. The HR per BICR was 1.01 (80% CI 0.75-1.36), with a median PFS of 4.2 months (95% CI 2.9-9.8) for UV1 plus ipilimumab and nivolumab, and 4.7 months (95% CI 3.9-7.0) for ipilimumab and nivolumab alone. The HR per investigator assessment was 0.60 (80% CI 0.45-0.81), with a median PFS of 4.3 months (95% CI 3.0-6.8) for UV1 plus ipilimumab and nivolumab and 2.9 months (95% CI 2.4-5.5) for ipilimumab and nivolumab alone.</p>
<p>The data from June 2023 showed a positive trend of improvement in overall survival in the UV1 arm over the control arm, but the data needed to mature before a conclusion could be reached. As of August, with a median observation time of 17.3 months, the data presented at ESMO demonstrates survival benefit for patients receiving the UV1 vaccine in the NIPU study. &nbsp;</p>
<p>In October 2023, Ultimovacs announced that FDA had granted Orphan Drug Designation for UV1 in the treatment of mesothelioma (based on the NIPU data from June 2023). </p>
<p>UV1 is a therapeutic cancer vaccine used to generate an immune response against the enzyme human telomerase (hTERT).&nbsp; The enzyme is essential for the ability of cancer cells to proliferate. Telomerase is present in 85-90% of all cancers, across the stages of the disease. The vaccine is manufactured as an off-the-shelf product with a long shelf life. UV1 is easy to use and does not require sophisticated hospital infrastructure, enabling patient access to therapy also in community centers, and in rural and underserved communities. </p>
<p> Ultimovacs is evaluating the universal cancer vaccine UV1 in a broad clinical development program across various cancer indications with different biologies and disease stages, in combination with different checkpoint inhibitors. The topline data from NIPU are the first results among the five randomized trials in the UV1 Phase II clinical program. In addition to malignant mesothelioma, Phase II studies are ongoing in patients with malignant melanoma, head and neck cancer, ovarian cancer, and non-small cell lung cancer. The topline data from the malignant melanoma and head and neck cancer trials are expected during the first and second half of 2024. UV1 is a patented, proprietary technology owned by Ultimovacs.</p>
<p>==ENDS==</p>
<p><strong>About NIPU</strong><br>NIPU (<u>N</u>ivolumab and <u>I</u>pilimumab <u>P</u>lus/minus <u>U</u>V1 vaccination) is a randomized, multi-center phase II trial in which Ultimovacs’ universal cancer vaccine, UV1, is evaluated in combination with Bristol-Myers Squibb’s checkpoint inhibitors, nivolumab and ipilimumab, as second-line treatment of malignant mesothelioma. The trial sponsor is Oslo University Hospital, supported in the preparation and execution of the trial by Ultimovacs and Bristol-Myers Squibb. </p>
<p>The 118 patients are randomized 1:1 into two treatment arms. All participants receive treatment with nivolumab (240 mg every 2 weeks) and ipilimumab (1 mg/kg every 6 weeks) until disease progression, unacceptable toxicity or for a maximum of 2 years. Patients randomized to the experimental arm received 8 intradermal injections of UV1 vaccine during the first three months of treatment. The objective of the study is to achieve a clinically meaningful benefit in patients with malignant mesothelioma (MPM) after progression on first-line standard platinum doublet chemotherapy. Subsequent events emerging in patients in both arms of the NIPU study will continue to be monitored beyond read-out of the primary endpoint. The ipilimumab and nivolumab combination has recently been approved as first-line treatment for patients with malignant pleural mesothelioma in Europe and the U.S.</p>
<p>The trial was sized to detect a target PFS HR of 0.6, with 80% power and a 1-sided alpha of 0.1. Overall survival was calculated using the same method as for PFS. </p>
<p><strong><br> About Mesothelioma</strong></p>
<p>Malignant mesothelioma is a rare and aggressive type of cancer that occurs in the thin layer of tissue that surrounds the lungs and inside of the chest. Mesothelioma accounted for 30 870 new cancer cases and 26 278 cancer deaths worldwide in 2020, according to International Agency for Research on Cancer (Globocan 2020). Mesothelioma is a disease with a high unmet medical need, especially in industrialized countries. The median overall survival is approximately 1 year.&nbsp; Occupational asbestos exposure is the No. 1 cause of the disease, and several occupations like firefighters, military veterans, construction, and industry workers, are at risk. This cancer usually takes several decades to develop after a person’s first exposure to asbestos. Most patients are diagnosed after age 70 because of the long latency period. Even though the use of asbestos to a large extent is banned in new constructions in many countries today, new incidences of mesothelioma will continue to be a medical and public health challenge because of the long latency period typical of the illness.&nbsp;For patients with inoperable disease, few treatment options are available after first-line chemotherapy. The combination of ipilimumab and nivolumab has recently shown increased survival compared to standard chemotherapy, but most patients do not respond, and improvements are called for. Telomerase is expressed in mesothelioma cells and is therefore a relevant target for therapeutic vaccination.</p>
<p><strong>About Ultimovacs</strong></p>
<p>Ultimovacs is a clinical-stage biotechnology leader in novel immunotherapeutic cancer vaccines with broad applicability. Ultimovacs’ lead cancer vaccine candidate UV1 is directed against human telomerase (hTERT), an antigen present in 85-90% of cancers in all stages of tumor growth. A broad clinical program, with Phase II trials in five cancer indications enrolling more than 670 patients, aims to demonstrate UV1’s impact in combination with other immunotherapies in multiple cancer types expressing telomerase and where patients have unmet medical needs. UV1 is universal, off-the-shelf and easy to use, and is a patented technology owned by Ultimovacs.</p>
<p> In addition, Ultimovacs’ adjuvant platform, based on the proprietary Tetanus-Epitope-Targeting (TET) technology, combines tumor-specific antigens and adjuvant in the same molecule and is in Phase I clinical development.<br>The Company is listed on Euronext Oslo Stock Exchange (ULTI).</p>
<p><strong>About the UV1 Phase II program</strong></p>
<p>The immunotherapeutic cancer vaccine UV1 is investigated in combination with checkpoint inhibitors in patients with various cancer indications with diverse tumor biology. The diversity of the UV1 Phase II program places Ultimovacs in a favorable position to capture the cancer vaccine’s potential broad applicability when combined with checkpoint inhibitors:</p>
<ul type="disc">
<li><strong>INITIUM</strong>: Evaluating UV1 in combination with ipilimumab and nivolumab as first-line treatment for patients with malignant melanoma. Enrollment of 156 patients completed. Expected readout H1 2024. Sponsored by Ultimovacs.</li>
<li><strong>NIPU</strong>: Evaluating UV1 in combination with ipilimumab and nivolumab as second-line treatment for patients with malignant pleural mesothelioma. Enrollment of 118 patients completed; results will be presented at the ESMO Congress in October 2023. The investigator-initiated study&nbsp;is led by Oslo University Hospital and supported by Bristol-Myers Squibb and Ultimovacs.</li>
<li><strong>FOCUS</strong>: Evaluating UV1 in combination with pembrolizumab as first-line treatment for patients with head and neck cancer. Enrollment of 75 patients completed, expected readout H2 2024. The investigator-initiated study is led by Halle University in Germany, supported by Ultimovacs.</li>
<li><strong>DOVACC</strong>: Evaluating UV1 in combination with olaparib and durvalumab as maintenance therapy in non-BRCA mutated patients with advanced ovarian cancer. &gt;20% of 184 patients enrolled as of Q2 2023 reporting, expected readout H2 2024. The investigator-initiated study is led by NSGO-CTU and supported by ENGOT, AstraZeneca, and Ultimovacs.</li>
<li><strong>LUNGVAC</strong>: Evaluating UV1 combined with cemiplimab as first-line treatment of non-small cell lung cancer patients. &lt;10% of 138 patients enrolled as of Q2 2023 reporting, expected readout H2 2025. The investigator-initiated study is led by Vestre Viken (Drammen Hospital) and supported by Ultimovacs.</li>
</ul>
<p><strong>About UV1</strong></p>
<p>UV1 is a universal cancer vaccine designed to induce a specific T-cell response against telomerase. UV1 consists of long, synthetic peptides representing a sequence in the reverse transcriptase subunit of telomerase (hTERT), shown to induce CD4+ T-cells. These CD4+ T-cells have the potential to provide inflammatory signals, and T-cell support is believed to be critical for triggering a strong anti-tumor immune response. Following intradermal injection, antigen-presenting cells (APCs) in the skin are exposed to the vaccine peptides. These APCs will process the peptides and present vaccine epitopes on Human Leukocyte Antigen (HLA) molecules to naïve T-cells in the lymph nodes. Activated vaccine-specific T-cells will then enter the circulation and search for cells displaying their cognate antigen in the context of HLA molecules.<br>The UV1 peptides contain several epitopes, shown to be non-restrictive in terms of (HLA) alleles for presentation. It is, therefore not required to perform HLA pre-screening of patients, which potentially enables broad population utilization of the vaccine. UV1 is administered over three months as eight intradermal injections together with the immune-modulator GM-CSF.</p>
<p>A link to the webcast and the comprehensive results from the NIPU study may be accessed from the Company website <a href="https://www.globenewswire.com/Tracker?data=1Bh9IeWW56epjirini7LFfkyOC0gzZIoF8_RQUEHXKk6wxf_u3Ix336BNbs52_6IqAwVsZ-iwAOuWg-f7HEICA8yyHu7K_fAxmfGf5sY1_E=" rel="nofollow noopener" target="_blank"><u>www.ultimovacs.com</u></a>. For further information, please contact:</p>
<p><strong>Carlos de Sousa, CEO </strong><br>Email: <a href="https://www.globenewswire.com/Tracker?data=PCzF-dlg_-bIdg1cyyIAY-sYLGf1wUYjJsePdiIVOTzFInBsbBOh0UwtOSmpRIQHhx9nGvlshi9Bhr-b_nN-hyW1zXzEuRRLnVM4_ZfGQRhph74iXJdkUuaT4hqFaAkp" rel="nofollow noopener" target="_blank"><u>carlos.desousa@ultimovacs.com</u></a><br>Phone: +47 908 92507 </p>
<p><strong>Anne Worsøe, Head of Investor Relations</strong><br>Email: <a href="https://www.globenewswire.com/Tracker?data=qR9aM47ER60_t8Tbg6Si6Bd2eUrI1G-CFCrFhzFUeRMaF26CGyNUZJWulQCdjgmaVEs7xqWYslklXnrwIWd4uydsgAt3JUMRG-V_NBVJty-2qQD5VeJktr3FdNCo9gpL" rel="nofollow noopener" target="_blank"><u>anne.worsoe@ultimovacs.com</u></a><br>Phone: +47 90686815</p>
<p><strong><em>This information is considered to be inside information pursuant to the EU Market Abuse Regulation and is subject to the disclosure requirements pursuant to Section 5-12 in the Norwegian Securities Trading Act.&nbsp;</em></strong><strong><em>This stock exchange announcement was published by Anne Worsøe, Head of Investor Relations at Ultimovacs ASA, on October 17, 2023 at 18:05 CET.</em></strong></p>
<p> <img decoding="async" src="https://www.globenewswire.com/newsroom/ti?nf=MTAwMDg2NDU4MSM0MDE2MzM3MzQjMjIwOTM5Mw=="> <br><img decoding="async" src="https://ml-eu.globenewswire.com/media/MzVhNWIyMTUtNWNjOS00MDgzLTgyM2YtOWVlYjA0NmRmOWQ2LTEyMjA5NDY=/tiny/Ultimovacs-ASA.png" referrerpolicy="no-referrer-when-downgrade"></p>
	</section>

	

	
</article>			
						
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["A Young Lady's Illustrated Primer" Simulated by GPT-4 (148 pts)]]></title>
            <link>https://www.andrealyip.com/a-young-ladys-illustrated-primer</link>
            <guid>37921832</guid>
            <pubDate>Tue, 17 Oct 2023 21:27:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.andrealyip.com/a-young-ladys-illustrated-primer">https://www.andrealyip.com/a-young-ladys-illustrated-primer</a>, See on <a href="https://news.ycombinator.com/item?id=37921832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-root"><main id="PAGES_CONTAINER" tabindex="-1" data-main-content="true"><div data-mesh-id="ContainerordbjinlineContent" data-testid="inline-content" id="SITE_PAGES" tabindex="-1" data-page-transition="OutIn"><p id="comp-lnsmomgw11" data-testid="richTextElement"><h2><span>"A Young Lady's Illustrated Primer"<br>
Simulated by GPT-4</span></h2></p><p><span>October 2023</span></p><div data-testid="linkElement" id="comp-lnt7vif6"><wow-image id="img_comp-lnt7vif6" data-image-info="{&quot;containerId&quot;:&quot;comp-lnt7vif6&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;targetWidth&quot;:446,&quot;targetHeight&quot;:446,&quot;isLQIP&quot;:false,&quot;imageData&quot;:{&quot;width&quot;:1024,&quot;height&quot;:1024,&quot;uri&quot;:&quot;03eae2_73e41079795b4714bd293693d270e4c2~mv2.png&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-has-ssr-src=""><img src="https://static.wixstatic.com/media/03eae2_73e41079795b4714bd293693d270e4c2~mv2.png/v1/fill/w_446,h_446,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/03eae2_73e41079795b4714bd293693d270e4c2~mv2.png" alt="" width="446" height="446" srcset="https://static.wixstatic.com/media/03eae2_73e41079795b4714bd293693d270e4c2~mv2.png/v1/fill/w_446,h_446,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/03eae2_73e41079795b4714bd293693d270e4c2~mv2.png 1x, https://static.wixstatic.com/media/03eae2_73e41079795b4714bd293693d270e4c2~mv2.png/v1/fill/w_892,h_892,al_c,q_90,usm_0.66_1.00_0.01,enc_auto/03eae2_73e41079795b4714bd293693d270e4c2~mv2.png 2x" fetchpriority="high"></wow-image></div><p><span><span>Illustrations generated by DALL·E 3, modified by Andrea Y</span></span></p><div id="comp-lnsmomha6" data-testid="richTextElement"><p><span>"The Diamond Age: Or, A Young Lady's Illustrated Primer" is a science fiction novel by Neal Stephenson that takes place in a future where nanotechnology has revolutionized society. The narrative follows the life of Nell, a young girl who comes into possession of <span>A Young Lady's Illustrated Primer</span>. The Primer is an interactive book designed to teach her everything she needs to know, adapting to her individual needs and growing with her. Its creator, John Percival Hackworth, made the Primer with the intention to subvert his daughter, Fiona:</span></p>

<p><span><span>​</span></span></p>

<p><span><span><span>“It was too late for Hackworth to change his personality, but it wasn't too late for Fiona...</span></span></span></p>



<p><span><span><span>How could he inculcate her with the nobleman's emotional stance<span>&nbsp;</span>- the pluck to take risks with her life, to found a company, perhaps found several of them even after the first efforts had failed?"</span></span></span></p>



<p><span>In other words, the Primer is an enabler, one that emboldens its user to focus on intellectual pursuits, build and create for society, and champion an unconventional life path. Today the concept of the Primer inspires technologists and entrepreneurs to consider how such technology can foster social mobility, personalize learning, and advance human development. In this post, I run a short simulation of the Primer using ChatGPT.</span></p>

<p><span><span>​</span></span></p>

<p><span><span>​</span></span></p>

<p><span>GPT-4 vs PRIMER</span></p>

<p><span>A highly intelligent and complex technology, the Primer is more sophisticated than anything humans have built to date, including GPT-4. Here are the differences between these two technologies, as explained by ChatGPT:</span></p>

<p><span><span>​</span></span></p>

<p><span><span>Personalized Learning</span></span></p>

<ul>
<li>
<p><span>PRIMER: designed to be adaptive to its user's needs. It personalized the lessons and adapted the storyline based on Nell's environment, interactions, and decisions.</span></p>
</li>
<li>
<p><span>ChatGPT: provides answers tailored to the questions posed to it, but it doesn't have the same level of long-term adaptive learning or storyline continuity.</span></p>
</li>
</ul>

<p><span><span>​</span></span></p>

<p><span><span>Interactivity</span></span></p>

<ul>
<li>
<p><span>PRIMER: highly interactive, with characters that communicate with the reader, almost like virtual mentors or guardians.</span></p>
</li>
<li>
<p><span>ChatGPT: interactive and responds to user inputs, however, it doesn't have virtual characters with independent personalities or storylines.</span></p>
</li>
</ul>

<p><span><span>​</span></span></p>

<p><span><span>Scope</span></span></p>

<ul>
<li>
<p><span>PRIMER: primarily focuses on education and personal growth, presenting information in a narrative format.</span></p>
</li>
<li>
<p><span>ChatGPT: has a broad knowledge base across various domains and can provide information in a more direct, Q&amp;A format.</span></p>
</li>
</ul>

<p><span><span>​</span></span></p>

<p><span><span>Emotion &amp; Empathy</span></span></p>

<ul>
<li>
<p><span>PRIMER: seems to show a level of empathy and emotional understanding.</span></p>
</li>
<li>
<p><span>ChatGPT: can recognize and respond to emotional cues in the text, but it doesn't "feel" emotions in the way humans do. Its responses are based on patterns in the data it was trained on.</span></p>
</li>
</ul>

<p><span><span>​</span></span></p>

<p><span><span>Independence &amp; Autonomy</span></span></p>

<ul>
<li>
<p><span>PRIMER: AI operates with a high degree of autonomy, making decisions to guide and educate Nell without human intervention.</span></p>
</li>
<li>
<p><span>ChatGPT: responds based on the data and algorithms but doesn't have its own agenda or the same level of decision-making autonomy.</span></p>
</li>
</ul>

<p><span><span>​</span></span></p>

<p><span><span>Long-Term Engagement</span></span></p>

<ul>
<li>
<p><span>PRIMER: the relationship with Nell spans years, with the Primer playing a critical role in her upbringing and personal development.</span></p>
</li>
<li>
<p><span>ChatGPT: doesn't have the same persistent memory or long-term developmental relationship with a user.</span></p>
</li>
</ul>

<p><span><span>​</span></span></p>

<p><span>While today's technology is not advanced enough to achieve the Primer, GPT-4 and DALL·E 3 do a great job of simulating the types of stories and imagery that it evokes. As a fan of The Diamond Age, I created the following fictional person and scenario, and asked ChatGPT to engage with me in the style of the Primer. For this exercise, I've also asked ChatGPT to teach the user something new through its story.</span></p>

<p><span><span>​</span></span></p>

<p><span><span>​</span></span></p>

<p><span><span>​</span></span></p>

<p><span><span>​</span></span></p>

<p><span>*******</span></p></div><div id="comp-lnsobm5c" data-testid="richTextElement"><p><span>A STORY FOR LIN</span></p>

<p><span>Context: Twelve-year-old Lin lives in Taipei, Taiwan with her Uncle. This morning, she wakes up in bed with crimson stained sheets. She just got her first period. Lin feels squeamish and embarrassed. Clutching her favorite stuffed bear, she sits at the corner of her bed and opens up the Primer.</span></p>

<p><span><span>​</span></span></p>

<p><span><span>​</span></span></p></div><div data-mesh-id="comp-lntbls1w2inlineContent" data-testid="columns" id="comp-lntbls0w"><div data-testid="linkElement" id="comp-lntbls216" title="Shop.webp"><wow-image id="img_comp-lntbls216" data-image-info="{&quot;containerId&quot;:&quot;comp-lntbls216&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;targetWidth&quot;:426,&quot;targetHeight&quot;:426,&quot;isLQIP&quot;:true,&quot;imageData&quot;:{&quot;width&quot;:1024,&quot;height&quot;:1024,&quot;uri&quot;:&quot;03eae2_a941161eca574d338c788ec3b23ea146~mv2.png&quot;,&quot;name&quot;:&quot;Painting.png&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-has-ssr-src="true"><img src="https://static.wixstatic.com/media/03eae2_a941161eca574d338c788ec3b23ea146~mv2.png/v1/fill/w_107,h_107,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/Painting.png" alt="Painting.png" width="426" height="426"></wow-image></div><div id="comp-lntbls21" data-testid="richTextElement"><p><span><span><span>In the bustling heart of Taipei, where towering skyscrapers touched the heavens and lanterns painted the streets in hues of red and gold, a young girl named Lin found herself standing at the brink of a new chapter. </span></span></span></p>



<p><span><span><span>On this particular day, as she wandered the streets of her neighborhood, Lin's thoughts were clouded by the unexpected sight of blood, a sign of her body beginning its ancient dance. Feeling uncertain, she decided to visit the city's old temple, seeking solace and wisdom from its ancient walls.</span></span></span></p>



<p><span><span><span>As Lin approached the temple, she noticed an elderly woman painting a beautiful depiction of the Formosan bear. Lin had always been fascinated by the tales of the bear, known not only for its beauty but its strength and resilience.</span></span></span></p>



<p><span><span><span>With hesitation, Lin approached and said, "Grandmother, today I discovered something new about myself, something that makes me feel uncomfortable and out of place."</span></span></span></p></div></div><div id="comp-lnt9xyvy" data-testid="columns" data-mesh-id="comp-lnt9xyxeinlineContent"><p><span><span><span>The elderly painter paused and looked deeply into Lin's eyes. "Ah, young Lin," she began softly, "Much like the Formosan bear, every individual goes through stages of growth and change. These moments might seem unfamiliar and daunting, but they're a testament to your strength and the mysteries of life."</span></span></span></p>



<p><span><span><span>Lin looked curiously at the painting. "But why does it feel so... strange?"</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>The painter dipped her brush into the crimson paint. "Every change brings with it a sense of unfamiliarity. The first time I held a brush, it felt foreign, but with time, it became an extension of me. Your body is starting a new rhythm, a dance that has been celebrated for generations. And just like this bear," she gestured to her painting, "you too have the strength to embrace this change and emerge even more magnificent." She then added, "You are on a journey of discovery. Every experience, every change is a step towards understanding the marvel that is you."</span></span></span></p>



<p><span><span><span>Feeling inspired by the painter's words and the strength of the Formosan bear, Lin left the temple with a renewed sense of purpose. She realized that this was just another facet of her journey, and with time and understanding, she would grow to appreciate and embrace the power within her.</span></span></span></p></div><div data-mesh-id="comp-lntbn5381inlineContent" data-testid="columns" id="comp-lntbn52a"><div id="comp-lntbn539" data-testid="richTextElement"><p><span><span><span>Nestled amidst winding streets and bustling markets, there existed a serene and mystical store called "Whispers of the Moon." This establishment, often missed by the hurried eyes of passersby, was known to those in the know as a place of wisdom and learning, especially for matters of the heart and body.</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>One day, young Lin, with the recent knowledge of her blossoming womanhood, entered the store, drawn by its subtle allure. Inside, amidst a myriad of gentle fragrances, she met Madam Yue, the keeper of the store. With her silvery hair and ageless eyes, Madam Yue was said to have answers to questions many dared not voice.</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>"Madam Yue," Lin began, her voice quivering slightly, "I've begun the dance of the moon, but I'm unsure how to move gracefully through it."</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>Understanding Lin's metaphor, Madam Yue gently smiled and said, "Ah, the dance of the moon. A timeless rhythm, indeed." She then gestured towards a delicate box, adorned with intricate patterns of the lunar phases. "This," she explained, "contains moon whispers, or as they are commonly known, menstrual pads."</span></span></span></p></div><div data-testid="linkElement" id="comp-lntbn5396" title="Shop.webp"><wow-image id="img_comp-lntbn5396" data-image-info="{&quot;containerId&quot;:&quot;comp-lntbn5396&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;targetWidth&quot;:424,&quot;targetHeight&quot;:424,&quot;isLQIP&quot;:true,&quot;imageData&quot;:{&quot;width&quot;:1024,&quot;height&quot;:821,&quot;uri&quot;:&quot;03eae2_8636c46c91474de7811cb5586fa42f0f~mv2.png&quot;,&quot;name&quot;:&quot;Shop_edited.png&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;crop&quot;:{&quot;x&quot;:190,&quot;y&quot;:41,&quot;width&quot;:779,&quot;height&quot;:780,&quot;svgId&quot;:&quot;cf545b123b6e4523b228d62bfa0dea9b.svg&quot;}}}" data-bg-effect-name="" data-has-ssr-src="true"><img src="https://static.wixstatic.com/media/03eae2_8636c46c91474de7811cb5586fa42f0f~mv2.png/v1/crop/x_190,y_41,w_779,h_780/fill/w_106,h_106,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/Shop_edited.png" alt="Shop_edited.png" width="424" height="424"></wow-image></div></div><div data-mesh-id="comp-lntbb9vvinlineContent" data-testid="columns" id="comp-lntbb9uy"><div data-testid="linkElement" id="comp-lntbb9vw4" title="Shop.webp"><wow-image id="img_comp-lntbb9vw4" data-image-info="{&quot;containerId&quot;:&quot;comp-lntbb9vw4&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;targetWidth&quot;:422,&quot;targetHeight&quot;:422,&quot;isLQIP&quot;:false,&quot;imageData&quot;:{&quot;width&quot;:1024,&quot;height&quot;:1024,&quot;uri&quot;:&quot;03eae2_ebaf2cf64cee4e088bc22c5ac303b398~mv2.webp&quot;,&quot;name&quot;:&quot;Pad.webp&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-has-ssr-src=""><img src="https://static.wixstatic.com/media/03eae2_ebaf2cf64cee4e088bc22c5ac303b398~mv2.webp" alt="Pad.webp" width="422" height="422"></wow-image></div><div id="comp-lntbb9vv7" data-testid="richTextElement"><p><span><span><span>Seeing Lin's curiosity, Madam Yue continued, "To dance gracefully, you must ensure comfort and care. The moon whisper is a trusted companion in this dance."</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>She opened the box, revealing a soft, rectangular pad. "First," she began, "ensure your hands are clean. Then, take the whisper and remove the protective backing to unveil its sticky side."</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>Pointing towards a chair resembling a throne, she continued, "Now, position yourself as if you were about to sit, but only hover slightly above the chair. Place the whisper in your underwear, ensuring the sticky side adheres to it. The wider end goes at the back."</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>Lin listened intently, absorbing the guidance. Madam Yue added, "Remember, young dancer, to change your moon whisper when it feels full or after a few hours, and always dispose of it with respect to our Earth."</span></span></span></p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>With gratitude in her eyes, Lin nodded, feeling more prepared for the dance ahead.</span></span></span></p></div></div><div id="comp-lnuuaabp" data-testid="richTextElement"><p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span><span>Note:</span>&nbsp;The image of the Primer (top of page) was created using illustrations generated by DALL·E 3 that I mashed up, modified, and edited. All images used in Lin's story were generated by DALL·E 3 and were not modified.</span></span></span></p></div><div id="comp-lnsmomhw2" data-testid="richTextElement"><p><span><span>​</span></span></p>

<p><span><span><span>Tags: Neal Stephenson, The Diamond Age, Menstruation, GPT, Chat, GPT-4, DALL E, AI</span></span></span></p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What happened to blogging for the hell of it? (222 pts)]]></title>
            <link>https://blog.whiona.me/what-happened-to-blogging-for-the-hell-of-it/</link>
            <guid>37920697</guid>
            <pubDate>Tue, 17 Oct 2023 19:57:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.whiona.me/what-happened-to-blogging-for-the-hell-of-it/">https://blog.whiona.me/what-happened-to-blogging-for-the-hell-of-it/</a>, See on <a href="https://news.ycombinator.com/item?id=37920697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    







<p>
    <i>
        <time datetime="2023-10-07">
            07 Oct 2023
        </time>
    </i>
</p>

<p>My decision to start a capital-B Blog (as opposed to microblogging, which I've been doing since I was a wee one on The Tumbler) was largely spur-of-the-moment and happened roughly two weeks ago. I felt <em>very</em> passionate about mobile web design and disability, wrote a whole bunch of words, and hit that POST button. Yadda yadda.</p>
<p>Since then, I've been at a bit of a loss as to what I should write about next.<sup id="fnref-1"><a href="#fn-1">1</a></sup> I want to write more frequently about anything and everything, because it's good for you, and I have so many thoughts constantly assailing this brain of mine—and good god, I should use that BA in Creative Writing I paid tens of thousands of dollars for to write <em>something</em> besides fanfiction. So I consulted my friend Startpage.com with the obvious prompt: "blog post ideas."</p>
<p>What I got was a roaring cascade of capitalist buzzword swill:</p>
<ul>
<li>120 profitable blog niche ideas and how to pick the right one (Write what'll make you money!)</li>
<li>50+ blog post ideas to drive traffic and increase followers (Get those numbers UP, baby!)</li>
<li>60 blog post ideas to fill your content calendar (Gotta push out that ~content~ often enough for the algorithm!)</li>
<li>101 blog post ideas to refresh your content marketing strategy (Writing is a marketing tool!)</li>
<li>35 blogging ideas that are guaranteed to be popular topics (Do what's popular!)</li>
</ul>
<p>Even in lists of ostensibly personal, creative, or fun blog topics, these prompts were frequently related to businesses, productivity, and social media:</p>
<ul>
<li>If three people who inspire you collaborated to make a product, what would that be? (The people who inspire me make <em>art,</em> thanks)</li>
<li>How to eliminate your top distractions (Gotta stay on task! Don't ever waste time!!!)</li>
<li>Interview an influencer (This on a list of prompts for "creating content that provides valuable advice"........keep telling yourself that.<sup id="fnref-2"><a href="#fn-2">2</a></sup>)</li>
<li>Share your daily work routine! (This list is labelled "Fun"! IT'S FUN!!! DON'T YOU LOVE WORKING???)</li>
<li>Blog about your favourite companies and brands (I closed the tab before my head could explode)</li>
</ul>
<p>And if I do all this, I can become a "thought leader" (huh?) and drive organic traffic! Then my readers will follow my ~brand~!</p>
<p>I get that blogging is a big thing for businesses and influencers now, but I didn't realize just <em>how</em> obsessed the blogging landscape is with this corpo nonsense. I checked Google as well just to make sure that my search engine of choice wasn't skewing the results, but the pages I clicked on still overwhelmingly featured business-focused prompts. Or, even when the prompts were personal in nature, the introduction to the page promised me that these ideas would convert my readers into customers, grow my numbers, and get me more traffic than ever before!!! (To rake in that ad money, natch.)</p>
<p>It's just a bit depressing to see how much it's all become a numbers game, whether those numbers are dollars in your pocket or followers on your Instagram. I'm probably saying nothing new to anybody who's been on the blogging scene for some time, but as a newcomer who's just here to write creatively and have fun, it was a stark reminder of how corporate the web has become.</p>
<p>Why is that the end goal of blogging? Of <em>writing?</em> Just to make money and grow our followers? To increase our traffic so we can expose our visitors to 300 repetitive ads that take up their entire phone screen? To "convert" our readers into our customers, because them reading and enjoying what we have to say simply isn't enough? Personally, I want nothing to do with it. I'm sick of everything having to be a hustle now, even something personal like sharing our ramblings with strangers on the internet.<sup id="fnref-3"><a href="#fn-3">3</a></sup></p>
<p>I have little else to say other than that I hate how capitalism ruins everything fun it touches. I'll continue to write about things that make me feel passionate, not how to make money or gain followers. And if the day comes where my blog ever features a sponsored post or sketchy weight loss ad, just shoot me in the face.</p>
<p>...In the end, perhaps I have to give those listicles a little bit of credit. They <em>did</em> give me the idea for my next blog post. 🤷‍♀️</p>
<hr>
<section>
<ol>
<li id="fn-1"><p>Well, sort of. I really want to write about Baldur's Gate 3, how it compares to Bioware titles, and how my personal feelings on said titles have changed over the years—but it would be pretty silly to do so before I've <em>finished</em> Baldur's Gate 3. I'm 100+ hours in now and just barely got inside the city walls!<a href="#fnref-1">↩</a></p></li>
<li id="fn-2"><p>Sorry, maybe I'm being mean here. I'm sure there are some influencers with valuable life advice to share. But a <em>lot</em> of them are privileged 19-year-olds who became famous by stealing other people's Tiktok dances, so you'll have to forgive me for being a skeptic.<a href="#fnref-2">↩</a></p></li>
<li id="fn-3"><p>I imagine many Bear users feel the same as I do, given the nature of this platform. I'm glad that writing for writing's sake still seems to be a thing in these quieter corners of the web.<a href="#fnref-3">↩</a></p></li>
</ol>
</section>



    
    <p>
    
        <a href="https://blog.whiona.me/blog/?q=blogging">#blogging</a>
    
        <a href="https://blog.whiona.me/blog/?q=capitalism">#capitalism</a>
    
    </p>
    

    
    



    



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi 5 vs. Orange Pi 5 Plus vs. Rock 5 Model B (119 pts)]]></title>
            <link>https://picockpit.com/raspberry-pi/raspberry-pi-5-vs-orange-pi-5-plus-vs-rock-5-model-b/</link>
            <guid>37920682</guid>
            <pubDate>Tue, 17 Oct 2023 19:55:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://picockpit.com/raspberry-pi/raspberry-pi-5-vs-orange-pi-5-plus-vs-rock-5-model-b/">https://picockpit.com/raspberry-pi/raspberry-pi-5-vs-orange-pi-5-plus-vs-rock-5-model-b/</a>, See on <a href="https://news.ycombinator.com/item?id=37920682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
		
<figure><img decoding="async" fetchpriority="high" width="1024" height="576" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Raspberry-Pi-Orange-Pi-Rock-Title-Image-1024x576.png" alt="Raspberry Pi Orange Pi Rock Title Image" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Raspberry-Pi-Orange-Pi-Rock-Title-Image-1024x576.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Raspberry-Pi-Orange-Pi-Rock-Title-Image-300x169.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Raspberry-Pi-Orange-Pi-Rock-Title-Image-768x432.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Raspberry-Pi-Orange-Pi-Rock-Title-Image-18x10.png 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Raspberry-Pi-Orange-Pi-Rock-Title-Image.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>With the announcement of Raspberry Pi 5, a new generation brings a new set of questions – like, how does Raspberry Pi 5 stack up against its competitors? In this article, I want to go over Raspberry Pi 5 vs. Orange Pi 5 Plus vs. Rock 5 Model B.</p>



<p>I have a confession. My first Pi was actually an Orange Pi that I purchased in Moscow in 2015. I was looking to set up a Pi-Hole on my home router. At that time and in that location, it was much cheaper to get an Orange Pi than a Raspberry Pi.</p>



<p>Ever since, I’ve dutifully followed the developments of both Orange Pis and Raspberry Pis.</p>



<p>So, now that Raspberry Pi have released a new generation, I feel like the time has come to compare these two against each other. However, that wouldn’t do justice to the Rock 5 Model B, which belongs in the same category.</p>



<p>So here, in this article, I want to compare and contrast these three SBCs.</p>







<h2>Specs</h2>



<p>So, first, let’s take a look at some of the specs.</p>



<figure><table><tbody><tr><td></td><td data-align="center"><strong>Raspberry Pi 5</strong></td><td data-align="center"><strong>Orange Pi 5 Plus</strong></td><td data-align="center"><strong>Rock 5 Model B</strong></td></tr><tr><td>SoC</td><td data-align="center">BCM2712</td><td data-align="center">RK3588</td><td data-align="center">RK3588</td></tr><tr><td>CPU</td><td data-align="center">4x ARM Cortex-A76</td><td data-align="center">4x ARM Cortex-A76<br>4x ARM Cortex-A55</td><td data-align="center">4x ARM Cortex-A76<br>4x ARM Cortex-A55</td></tr><tr><td>GPU</td><td data-align="center">VideoCore VII</td><td data-align="center">ARM Mali-G610 MP4</td><td data-align="center">ARM Mali-G610 MP4</td></tr><tr><td>RAM</td><td data-align="center">4/8GB LPDDR4X</td><td data-align="center">8/16/32GB LPDDR4X</td><td data-align="center">2/4/8/16/32GB LPDDR4X</td></tr><tr><td>Process Nodes</td><td data-align="center">16nm</td><td data-align="center">8nm</td><td data-align="center">8nm</td></tr><tr><td>Storage</td><td data-align="center">1x PCIe 2.0<br>micro SD card</td><td data-align="center">eMMC<br>1x M.2 (E Key)<br>1x M.2 (M Key)</td><td data-align="center">eMMC<br>1x M.2 (E Key)<br>1x M.2 (M Key)<br>micro SD card</td></tr><tr><td>Network</td><td data-align="center">1Gb Ethernet<br>2.4 GHz and 5.0 GHz 802.11ac Wi-Fi<br>Bluetooth 5.0/BLE</td><td data-align="center">2x 2.5Gb Ethernet ports<br>(No onboard WiFi or Bluetooth)</td><td data-align="center">2.5Gb Ethernet<br>(No onboard WiFi or Bluetooth)</td></tr><tr><td>Video</td><td data-align="center">2x micro HDMI (4Kp60)<br>2x MIPI DSI/CSI</td><td data-align="center">2x HDMI(8Kp60)<br>1x HDMI input (4Kp60)<br>1x MIPI DSI<br>1x MIPI CSI</td><td data-align="center">2x HDMI(8Kp60)<br>1x micro HDMI input (4Kp60)<br>1x MIPI DSI<br>1x MIPI CSI</td></tr><tr><td>Audio</td><td data-align="center">no audio jack</td><td data-align="center">audio jack<br>onboard microphone</td><td data-align="center">audio jack</td></tr><tr><td>USB</td><td data-align="center">2x USB 2.0<br>2x USB 3.0</td><td data-align="center">2x USB 2.0<br>2x USB 3.0<br>1x USB 3.0 Type C</td><td data-align="center">2x USB 2.0<br>2x USB 3.0</td></tr><tr><td>Power</td><td data-align="center">5V/5A (USB-C)</td><td data-align="center">5V/4A (USB-C)</td><td data-align="center">5V/5A (USB-C)</td></tr><tr><td>Size</td><td data-align="center">94x62mm</td><td data-align="center">100x70mm</td><td data-align="center">100x70mm</td></tr><tr><td>Power button</td><td data-align="center">✓</td><td data-align="center">✓</td><td data-align="center">✓</td></tr><tr><td>RTC</td><td data-align="center">✓</td><td data-align="center">✓</td><td data-align="center">✓</td></tr></tbody></table></figure>







<h2>Summarizing the Specs</h2>



<p>The first thing to point out is that Raspberry Pi 5 distinguishes itself from Orange Pi 5 Plus and Rock 5 Model B in the SoC.</p>



<p>While Raspberry Pi 5’s Broadcom BCM2712 has a four-core ARM Cortex-A76 setup with a VideoCore VII GPU, Orange Pi and the Rock have RockChip’s RK3588, which has eight cores and an ARM Mali-G610 MP4 GPU.</p>



<p>These eight cores are notable on the RK3588, because four of them are also ARM Cortex-A76, while the other four are ARM Cortex-A55.</p>



<p>Another thing that quickly jumps out are the differences in RAM sizes. At launch, Raspberry Pi 5 will have 4GB and 8GB variants (with 2GB on the way and potentially 1GB in the future). I’ve also seen discussion about a potential 16GB variant, but nothing official.</p>



<p>By contrast, Orange Pi 5 Plus pushes upwards with 8GB as the lower variant and then 16GB and 32GB at the top. From what I’ve seen, Rock 5 Model B has the largest range with 2, 4, 8, 16, and 32GB options.</p>



<p>When it comes to storage, all three SBCs have micro SD card slots. </p>



<p>But Orange Pi 5 Plus and Rock 5 Model B also come with M.2 M Key and E Key slots. These allow you to hook up a WiFi module (as neither board has onboard WiFi) and boot up via an NVMe SSD. They also come with eMMC sockets.</p>



<p>Raspberry Pi 5 does not come with M.2 slots or eMMC sockets. However, with the PCIe 2.0 lane output, booting up via NVMe SSD is now possible.</p>



<p>When it comes to networking, Raspberry Pi 5 comes with onboard WiFi at 2.4 GHz and 5.0 GHz 802.11ac along with Bluetooth 5.0 and Bluetooth Low Energy (BLE). As I mentioned above, Orange Pi 5 Plus and Rock 5 Model B have M.2 E Key slots and they both provide modules that can get WiFi 6 and Bluetooth 5.2.</p>



<p>All you need to do is install the modules yourself.</p>



<p>When it comes to video, there’s a big difference between the three.</p>



<p>Raspberry Pi 5 has two onboard micro HDMI ports that can provide 4Kp60 simultaneously. Additionally, it has two MIPI sockets that can both be used for camera and display.</p>



<p>Orange Pi 5 Plus has two onboard full HDMI ports that can provide up to 8Kp60 and a full HDMI port for input that can provide up to 4Kp60. Additionally, it has one MIPI socket for camera and a separate MIPI socket for display.</p>



<p>Rock 5 Model B has two onboard full HDMI ports that can provide up to 8Kp60. But it then has a micro HDMI port for input that provides up to 4Kp60. Like the Orange Pi though, it has one dedicated MIPI socket for camera and a separate MIPI socket for display.</p>



<p>Raspberry Pi made the decision to do away with the audio jack for the new model. Orange Pi 5 Plus and Rock 5 Model B both have audio jacks.</p>



<p>Furthermore, Raspberry Pi 5 comes with two USB 2.0 ports and two USB 3.0 ports, as well as the USB-C port for power. Orange Pi 5 Plus, however, comes with two USB 2.0 ports, two USB 3.0 ports, a USB-C port for power, <em>and </em> a USB 3.0 Type-C port. Rock 5 Model B has two USB 2.0 ports, two USB 3.0 ports, and a USB-C port for power that can also function as a DisplayPort output.</p>



<p>They do share some features. Although the three boards have slightly different power supplies, all rely on USB-C. They all have power buttons and RTCs.</p>



<p>One notable thing though, before we move on to benchmarks, is the form factor.</p>



<p>Raspberry Pi 5 remains within the standard Raspberry Pi flagship family with a roughly 90mm x 60mm size. Orange Pi 5 Plus and Rock 5 Model B, however, are observably larger. They are roughly 100mm x 70mm (also called the Pico ITX form factor).</p>



<h2>Benchmarks</h2>



<p>At first, I thought about setting up my own benchmarks for these three boards. But after some thought, I decided that <a href="https://www.youtube.com/watch?v=nBtOEmUqASQ" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Jeff Geerling actually provided all the important benchmarks in his recent video on Raspberry Pi 5</a>.</p>



<p>So, although he uses Orange Pi 5 and not Orange Pi 5 Plus, I think these are the benchmarks you can reliably expect from these three different SBCs.  Jeff also includes Raspberry Pi 4, so you can see how much <em>more </em>powerful Raspberry Pi 5 is.</p>



<p>First, let’s take a look at the HPL benchmark, which measures the floating-point computing power of all three boards.</p>







<figure><img decoding="async" loading="lazy" width="1024" height="430" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56-1024x430.png" alt="HPL (Top 500) and HPL Efficiency Benchmark" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56-1024x430.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56-300x126.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56-768x322.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56-1536x645.png 1536w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56-18x8.png 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-36-56.png 1903w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Credit: <a href="https://www.youtube.com/watch?v=nBtOEmUqASQ" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Jeff Geerling</a>.</figcaption></figure>







<p>These benchmarks measure how quickly each SBC can solve dense linear equations. You’ll notice that Orange Pi 5 and Rock 5 Model B blow the Raspberry Pis out of the water. Orange Pi 5 and Rock 5 Model B have over 50 GigaFLOPS, or 50 billion floating point operations per second.</p>



<p>Meanwhile Raspberry Pi 5 comes in at around 30 GigaFLOPS.</p>



<p>The efficiency of Orange Pi 5 and Rock 5 Model B is pushing double the efficiency of Raspberry Pi 5. Efficiency, in this context, refers to how well it performs the HPL benchmark compared to its theoretical peak performance.</p>



<p>Raspberry Pi 5 comes in at 2.75 GigaFLOPS per Watt, while Rock 5 Model B comes in at 4.28 GigaFLOPS per Watt. Meanwhile, Orange Pi 5 comes in at 4.64 GigaFLOPS per Watt!</p>



<p>Jeff then turns to two benchmarks that I really appreciate. Namely, how long it takes each board to encode MP3 and how long it takes to compile the Linux kernel.</p>



<p>In the first case, Raspberry Pi actually outperforms Orange Pi 5 and Rock 5 Model B. It converts WAV files to MP3 files in under 12 seconds. Orange Pi 5 and Rock 5 Model B, on the other hand, both take slightly more than 12 seconds.</p>







<figure><img decoding="async" loading="lazy" width="1024" height="381" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40-1024x381.png" alt="mp3 encoding and build linux kernel benchmarks" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40-1024x381.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40-300x112.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40-768x286.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40-1536x572.png 1536w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40-18x7.png 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-29-40.png 1899w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Credit: <a href="https://www.youtube.com/watch?v=nBtOEmUqASQ" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Jeff Geerling</a>.</figcaption></figure>







<p>However, when compiling the Linux kernel, Orange Pi 5 and Rock 5 Model B leave Raspberry Pi 5 in the dust by managing to do it in well under 1500 seconds. Raspberry Pi 5 comes in at around 2000 seconds.</p>



<p>But there are some more benchmarks worth noting.</p>



<p>When it comes to video encoding, Raspberry Pi 5 performs much closer to Orange Pi 5 and Rock 5 Model B. Looking at media encoding for 4K video, all three hover around 3.75 frames per second (with Raspberry Pi 4 hitting something around 1.5 frames per second).</p>



<p>However, Orange Pi 5 and Rock 5 Model B outperform Raspberry Pi 5 with video encoding for 1080p video. They both are well above 20 frames per second, while Raspberry Pi 5 doesn’t quite reach 18 frames per second.</p>







<figure><img decoding="async" loading="lazy" width="1024" height="430" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02-1024x430.png" alt="video encoding and PHP benchmarks" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02-1024x430.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02-300x126.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02-768x322.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02-1536x645.png 1536w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02-18x8.png 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-14-30-02.png 1903w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Credit: <a href="https://www.youtube.com/watch?v=nBtOEmUqASQ" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Jeff Geerling</a>.</figcaption></figure>







<p>However, the PHP benchmark on Raspberry Pi 5 actually beats both Orange Pi 5 and Rock 5 Model B.</p>



<p>Nevertheless, I would say that Orange Pi 5 and Rock 5 Model B pretty solidly outperform Raspberry Pi 5 in most of the important benchmarks. And, of course, considering their sizes and prices, this isn’t really all that surprising.</p>



<p>As Jeff puts it in his <a href="https://www.youtube.com/watch?v=nBtOEmUqASQ" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">video</a>, “The Pi 5 isn’t the SBC performance king, but it keeps Pi in the race this generation…”</p>



<h2>Prices</h2>



<p>Now, one of the chief differences between the three SBCs is the price. Indeed, it’s clear that Raspberry Pi traded in a certain amount of performance in order to keep costs down.</p>



<p>When talking about SBCs, people often give you the official price point. They’ll say that a Raspberry Pi 5 for 8GB costs $80, for example. But then you’ll never find a Raspberry Pi 5 at that price. That’s because this is the official price and doesn’t include shipping, taxes, or currency fluctuations.</p>



<p>So I thought I would dive into price a little bit differently.</p>



<p>I want to look at <em>real </em>prices. </p>



<p>But this also means looking at how these companies sell their products officially, because if you simply let the market decide the price, then things can get both expensive and unreliable fairly quickly.</p>



<p>Please keep in mind that I’m in Germany, so I’ll be giving you prices in Euros.</p>



<p>First of all, if you want to buy an Orange Pi 5 Plus, the company itself directs you to Amazon or AliExpress.</p>



<p>The price that I found at <a href="https://www.aliexpress.us/item/1005005572414487.html?spm=5261.ProductManageOnline.0.0.591b2ddbWtPz3x&amp;gatewayAdapt=4itemAdapt" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">AliExpress</a> for the Orange Pi 5 Plus with 16GB of RAM is 153.27€.</p>






<div>
<figure><img decoding="async" loading="lazy" width="1024" height="438" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-16-14-55-1024x438.png" alt="Orange Pi 5 Plus Price" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-16-14-55-1024x438.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-16-14-55-300x128.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-16-14-55-768x329.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-16-14-55-18x8.png 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/Screenshot-from-2023-10-13-16-14-55.png 1086w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>If you want to buy a Rock 5 Model B, things are set up a bit differently. Radxa, the company behind Rock 5 Model B, has what it calls “authorized distributors”. As far as I can tell from their website, there are four: OKDO, Allnet, 3Logic, and Ameridroid.</p>



<p>Again, I’m in Germany, so I went to <a href="https://www.innet24.de/search?sSearch=rock+5+model+b" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">the Allnet site for Germany</a> and found this:</p>






<div>
<figure><img decoding="async" loading="lazy" width="940" height="551" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-60.png" alt="Rock 5 Model B price" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-60.png 940w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-60-300x176.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-60-768x450.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-60-18x12.png 18w" sizes="(max-width: 940px) 100vw, 940px"></figure></div>






<p>The Rock 5 Model B with 16GB is 301.63€.</p>



<p>Now here’s a problem – I haven’t been able to find an Orange Pi 5 Plus or a Rock 5 Model B with 8GB for sale. And there currently isn’t a variant of Raspberry Pi 5 with more than 8GB, so comparing prices here is a little wonky. But it’s worth seeing what’s available and what isn’t.</p>



<p>Raspberry Pi is similarly structured to Radxa, but with a much broader reach. Raspberry Pi has what they call “approved resellers” (and, <em>full disclosure</em>, we are an approved reseller of Raspberry Pis).</p>



<p>You’ll know if you come across an approved resellers website, because they’ll have a logo that looks like this:</p>






<div>
<figure><img decoding="async" loading="lazy" width="1024" height="238" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-1024x238.png" alt="" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-1024x238.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-300x70.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-768x179.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-1536x357.png 1536w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-2048x477.png 2048w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/DIGITAL-APPROVED-RESELLER-LOGO_COLOUR-18x4.png 18w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Anyway, <a href="https://buyzero.de/en/collections/raspberry-pi-5-und-zubehoer/products/raspberry-pi-5" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">we’re selling Raspberry Pi 5s</a> for 93.30€ at our sister company – buyzero.de. That’s notably cheaper than the other two, but it’s also a question of what you’re looking for.</p>



<p>You could say that we’re comparing raspberries and oranges.</p>






<div>
<figure><a href="https://buyzero.de/en/collections/raspberry-pi-5-und-zubehoer/products/raspberry-pi-5" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer"><img decoding="async" loading="lazy" width="1024" height="503" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-62-1024x503.png" alt="" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-62-1024x503.png 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-62-300x147.png 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-62-768x377.png 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-62-18x9.png 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/10/image-62.png 1424w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div>






<p>Jokes aside, if you need more than 8GB of RAM, then going with Raspberry Pis doesn’t make sense at the moment. However, if you’re looking for a cheaper price, then Raspberry Pis are obviously the way to go.</p>







<figure><table><tbody><tr><td></td><td data-align="center">Raspberry Pi 5 (8GB)</td><td data-align="center">Orange Pi 5 Plus (16GB)</td><td data-align="center">Rock 5 Model B (16GB)</td></tr><tr><td>Price</td><td data-align="center">93.30€ </td><td data-align="center">153.27€</td><td data-align="center">301.63€</td></tr></tbody></table></figure>







<p>One thing worth pointing out is also the compatibility of software and the breadth of the community. </p>



<p>Obviously, the Raspberry Pi ecosystem and community is much stronger than the Orange Pi or Rock communities. However, I can basically promise you that the Orange Pi community and Rock community will both grow in coming years.</p>



<p>So these are all things to keep in mind before you buy an SBC.</p>



<p>If you have anything to add, let me know in the comments!</p>



<p>And now, don’t forget about our contest – in which we’re giving away a full Raspberry Pi 5 kit to the winner!</p>



<h2>Contest &amp; Newsletter</h2>



<p>We know how frustrating it is to have to wait until October 23rd for a Raspberry Pi 5.</p>



<p>So we wanted to make it possible for you to play around with one as soon as possible.</p>



<p>So we’ve set up a contest: <em>What’s the craziest thing you can come up with for Raspberry Pi 5?</em></p>



<figure><a href="https://picockpit.com/raspberry-pi/win-a-free-raspberry-pi-5/" data-wpel-link="internal"><img decoding="async" loading="lazy" width="1024" height="192" src="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1-1024x192.jpg" alt="Raspberr Pi 5 Contest" srcset="https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1-1024x192.jpg 1024w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1-300x56.jpg 300w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1-768x144.jpg 768w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1-1536x288.jpg 1536w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1-18x3.jpg 18w, https://picockpit.com/raspberry-pi/wp-content/uploads/2023/09/Raspberry-Pi-5-Idea-Contest1.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Provided your idea doesn’t destroy it, you can send us your idea and we’ll enact it on ours. And we’ll write an article about it!</p>



<p>We’ll announce the winner here and on <a href="https://buyzero.de/" target="_blank" rel="noreferrer noopener nofollow external" data-wpel-link="external">buyzero.de</a> on October 23rd.</p>



<p>The winning idea (determined by us) will win a full Raspberry Pi 5 kit. This includes a 27W USB-C Power Delivery (PD) Power Supply, a Raspberry Pi 5 case, an SD card, and a Raspberry Pi 5. All with free shipping within the EU.</p>



<p>The runner-up will win a Raspberry Pi 5 with free shipping within the EU.</p>



<p>So be sure to send in your ideas. You can go to the following link for more information: <a href="https://picockpit.com/raspberry-pi/win-a-free-raspberry-pi-5/" data-wpel-link="internal">WIN A FREE RASPBERRY PI 5</a>!</p>



<h2>Conclusion</h2>



<p>So when it comes to specs and benchmarks, Orange Pi 5 Plus and Rock 5 Model B both clearly have the upper hand. However, Raspberry Pi clearly traded performance for cost.</p>



<p>After shipping and tax though, is a Raspberry Pi 5 really that much cheaper than an Orange Pi 5 Plus?</p>



<p>It surely depends on where you live and what deals you can find. What do you think?</p>



<p>I honestly am a fan of all three SBCs, but they all have their respective times and places. Anyway, is there anything I forgot? Let me know!</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free IRS-run tax filing pilot to be available in 13 states (820 pts)]]></title>
            <link>https://www.irs.gov/newsroom/irs-advances-innovative-direct-file-project-for-2024-tax-season-free-irs-run-pilot-option-projected-to-be-available-for-eligible-taxpayers-in-13-states</link>
            <guid>37920633</guid>
            <pubDate>Tue, 17 Oct 2023 19:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.irs.gov/newsroom/irs-advances-innovative-direct-file-project-for-2024-tax-season-free-irs-run-pilot-option-projected-to-be-available-for-eligible-taxpayers-in-13-states">https://www.irs.gov/newsroom/irs-advances-innovative-direct-file-project-for-2024-tax-season-free-irs-run-pilot-option-projected-to-be-available-for-eligible-taxpayers-in-13-states</a>, See on <a href="https://news.ycombinator.com/item?id=37920633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      


<article role="article" about="/newsroom/irs-advances-innovative-direct-file-project-for-2024-tax-season-free-irs-run-pilot-option-projected-to-be-available-for-eligible-taxpayers-in-13-states">

  
    

  
            <div><h2>Agency finalizing Direct File pilot scope, details as work continues this fall; EITC, Child Tax Credit among projected provisions covered</h2>

<p>IR-2023-192, Oct. 17, 2023</p>

<p>WASHINGTON — As part of larger transformation efforts underway, the Internal Revenue Service announced today key details about the Direct File pilot for the 2024 filing season with several states planning to join the innovative effort.</p>

<p>The IRS will conduct a limited-scope pilot during the 2024 tax season to further assess customer support and technology needs. It will also provide a platform for the IRS to evaluate successful solutions for potential operational challenges identified in the <a data-entity-substitution="pup_linkit_media" data-entity-type="media" data-entity-uuid="4d6a45b8-50d6-4404-b2c3-72ca06b7e843" href="https://www.irs.gov/pub/irs-pdf/p5788.pdf" title="0523 Publ 5788                           (PDF)">report the IRS submitted to Congress</a><span title="Download pdf file" aria-label="press enter to download pdf file">PDF</span> earlier this year.</p>

<p>Arizona, California, Massachusetts and New York have decided to work with the IRS to integrate their state taxes into the Direct File pilot for filing season 2024. Taxpayers in nine other states without an income tax – Alaska, Florida, New Hampshire, Nevada, South Dakota, Tennessee, Texas, Washington and Wyoming -- may also be eligible to participate in the pilot. Washington has also chosen to join the integration effort for the state's application of the Working Families Tax Credit. All states were invited to join the pilot, but not all states were in a position to join the pilot at this time.</p>

<p>"This is a critical step forward for this innovative effort that will test the feasibility of providing taxpayers a new option to file their returns for free directly with the IRS," said IRS Commissioner Danny Werfel. "In this limited pilot for 2024, we'll be working closely with the states that have agreed to participate in an important test run of the state integration. This will help us gather important information about the future direction of the Direct File program."</p>

<p>People in those 13 states may be eligible to participate in the 2024 Direct File pilot, a new service that will provide taxpayers with the choice to electronically file their federal tax return directly with the IRS for free.</p>

<p>Taxpayer eligibility to participate in the pilot will be limited by the state in which the taxpayer resides and will be limited to taxpayers with certain types of income, credits and deductions – taxpayers with relatively simple returns. The IRS today announced it anticipates specific income types, such as wages on a Form W-2, and important tax credits, like the Earned Income Tax Credit and the Child Tax Credit, will be covered by the Direct File pilot.</p>

<p>The 2022 Inflation Reduction Act provided the IRS with long-term funding for the agency to transform its operations and improve taxpayer service, enforcement and technology. It also directed the IRS to study the possibility of a free, direct e-file program, which the IRS submitted in a report to Congress in May 2023. Projects like Direct File represent a goal of the <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="06d75d0f-2adc-4e9c-9ac8-3b80edd70e57" href="https://www.irs.gov/about-irs/irs-inflation-reduction-act-strategic-operating-plan" title="IRS Inflation Reduction Act Strategic Operating Plan">IRS Strategic Operating Plan</a>, to give taxpayers choices in how they interact with the tax agency. This includes choices in how they prepare and file their taxes, whether it's through a tax professional, commercial tax software or free filing options. Direct File is one more potential option from which qualifying taxpayers will be able to choose to file a 2023 federal tax return during the 2024 filing season.</p>

<p>Since the delivery of the Direct File report in May – as directed by the Treasury Department – the IRS has been working to develop a pilot for the upcoming filing season, paying special attention to issues identified in the report related to customer support and state taxes. This limited-scale pilot will allow the IRS to evaluate the costs, benefits and operational challenges associated with providing a voluntary Direct File option to taxpayers.</p>

<p>"We have more work in front of us on this project," Werfel said. "The Direct File pilot is undergoing continuous testing with taxpayers to identify and resolve issues to ensure its user friendly and easy to understand. We continue to finalize the pilot details and anticipate more changes before we launch for the 2024 tax season. Direct File, if pursued further after the pilot, would be another option eligible taxpayers have to help them prepare their tax returns in addition to existing options such as the use of a tax professional, tax software, Free File or another option. It's consistent with the IRS mission to make sure taxpayers have available options that work the best for their personal situation."</p>

<h3>Direct File pilot basics</h3>

<p>Eligible taxpayers may choose to participate in the pilot next year to file their tax year 2023 federal tax return for free, directly with the IRS.</p>

<p>Direct File will be a mobile-friendly, interview-based service that will work as well on a mobile phone as it does on a laptop, tablet or desktop computer. The service will be available in English and Spanish for the pilot.</p>

<p>The Direct File pilot will be a limited, phased pilot. It will not be available to all eligible taxpayers when the IRS begins accepting tax returns. Because the IRS wants to make sure the program works effectively, Direct File will first be introduced to a small group of eligible taxpayers in filing season 2024. As the filing season progresses, more and more eligible taxpayers will be able to access the service to file their 2023 tax returns.</p>

<p>Direct File does not replace existing filing options like tax professionals, Free File, free return preparation sites, commercial software and authorized e-file providers. Taxpayers will continue to have choices, whether they want to use a tax professional, a software product, Free File, free tax preparation services like Volunteer Income Tax Assistance (VITA) and Tax Counseling for the Elderly (TCE) as well as a paper tax return or Direct File.</p>

<p>Taxpayers participating in the pilot will have access to help by IRS employees staffing the Direct File customer support function. IRS customer service representatives will provide technical support and provide basic clarification of tax law related to the tax scope of Direct File. Questions related to issues other than Direct File will be routed to other IRS customer support, as appropriate.</p>

<h3>Pilot eligibility is limited</h3>

<p>Eligibility for the pilot is limited by the types of income, tax credits and deductions that the product can initially support. Taxpayers who fall outside the pilot's eligibility limits will be unable to participate in the pilot in 2024.</p>

<p>Direct File will cover only individual federal tax returns during the pilot. Also, Direct File will not prepare state returns. However, once a federal return is completed and filed, Direct File will guide taxpayers who want to file a state return to a state-supported tool that taxpayers can use to prepare and file a stand-alone state tax return. For the pilot in 2024, where taxpayers may have state or local tax obligations, the IRS will limit eligibility to states that are actively partnering with the IRS on the pilot.</p>

<p>Eligibility to participate in the pilot will be limited to taxpayers who reside in certain states where the pilot is available. Taxpayers in Alaska, Florida, New Hampshire, Nevada, South Dakota, Tennessee, Texas, Washington and Wyoming may be eligible to participate in the pilot as their states do not levy a state income tax. Washington has also chosen to join the integration effort as a partner for the state's application of the Working Families Tax Credit. For states that do levy a state income tax, Arizona, California, Massachusetts and New York have chosen to partner with the IRS for the 2024 Direct File pilot. The IRS anticipates the pilot will be available in those states as well in 2024.</p>

<p>The IRS and the Departments of Revenue in Arizona, California, Massachusetts, New York and Washington entered into separate Memorandums of Understanding in September for the purposes of collaboration on the IRS's Direct File pilot for filing season 2024.</p>

<p>This approach will test the IRS's ability to successfully integrate with a handful of states and the IRS will continue to work with all states to secure feedback and share what it learns through the course of its work on the pilot.</p>

<h3>2024 Direct File pilot eligibility expected to cover key income, tax credits</h3>

<p>Eligibility to participate in the 2024 pilot will be limited to reporting only certain types of income and claiming limited credits and adjustments. The tax scope for the pilot is still being finalized and is subject to change, but the IRS currently anticipates it will include:</p>

<h4>Income reporting</h4>

<ul><li>W-2 wage income</li>
	<li>Social Security and railroad retirement income&nbsp;</li>
	<li>Unemployment compensation</li>
	<li>Interest of $1,500 or less</li>
</ul><h4>Credits</h4>

<ul><li>Earned Income Tax Credit</li>
	<li>Child Tax Credit</li>
	<li>Credit for Other Dependents</li>
</ul><h4>Deductions</h4>

<ul><li>Standard deduction</li>
	<li>Student loan interest</li>
	<li>Educator expenses</li>
</ul><h3>Evaluating the Direct File Pilot</h3>

<p>The purpose of the Direct File pilot is to test the system the IRS has developed and to learn from that test. This includes testing the technology, customer support, state integration, fraud detection and the overall taxpayer experience. The best way to test a new service offering such as Direct File is in a limited, controlled environment that will allow the IRS to identify issues and make changes prior to any potential large-scale launch in the future.</p>

<p>The 2024 filing season serves as a pilot for Direct File, and the purpose is to learn about the Direct File service itself and the needs of taxpayers who use it. By starting with a pilot, the IRS can efficiently learn about Direct File's effectiveness, identify areas of improvement for future iterations and ensure it meets the needs of taxpayers who want to use it.</p>

<p>The IRS will publicly share the results of the pilot when available.</p>

<p>More information will be available at <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="29183e14-141e-4678-805f-3a9e5e22603e" href="https://www.irs.gov/about-irs/strategic-plan/direct-file" title="Direct File">IRS.gov/directfile</a>.</p>
</div>
      
</article>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using spaced repetition systems to see through a piece of mathematics (2019) (133 pts)]]></title>
            <link>https://cognitivemedium.com/srs-mathematics</link>
            <guid>37920191</guid>
            <pubDate>Tue, 17 Oct 2023 19:16:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cognitivemedium.com/srs-mathematics">https://cognitivemedium.com/srs-mathematics</a>, See on <a href="https://news.ycombinator.com/item?id=37920191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    



<p>By <a href="http://michaelnielsen.org/">Michael Nielsen</a>, January 2019</p>

<p>What does it mean to understand a piece of mathematics? Naively, we
perhaps think of this in relatively black and white terms: initially
you don’t understand a piece of mathematics, then you go through a
brief grey period where you’re learning it, and with some luck and
hard work you emerge out the other side “understanding” the
mathematics.</p>

<p>In reality, mathematical understanding is much more nuanced. My
experience is that it’s nearly always possible to deepen one’s
understanding of any piece of mathematics. This is even true –
perhaps especially true – of what appear to be very simple
mathematical ideas.</p>

<p>I first really appreciated this after reading an essay by the
mathematician Andrey Kolmogorov. You might suppose a great
mathematician such as Kolmogorov would be writing about some very
complicated piece of mathematics, but his subject was the humble
equals sign: what made it a good piece of notation, and what its
deficiencies were. Kolmogorov discussed this in loving detail, and
made many beautiful points along the way, e.g., that the invention of
the equals sign helped make possible notions such as equations (and
algebraic manipulations of equations).</p>

<p>Prior to reading the essay I thought I understood the equals
sign. Indeed, I would have been offended by the suggestion that I did
not. But the essay showed convincingly that I could understand the
equals sign much more deeply.</p>

<p>This experience suggested three broader points. First, it’s possible
to understand other pieces of mathematics far more deeply than I
assumed. Second, mathematical understanding is an open-ended process;
it’s nearly always possible to go deeper. Third, even great
mathematicians – perhaps, especially, great mathematicians
– thought it worth their time to engage in such deepening.</p>

<p>(I found Kolmogorov’s essay in my University library as a
teenager. I’ve unsuccessfully tried to track it down several times in
the intervening years. If anyone can identify the essay, I’d
appreciate it. I’ve put enough effort into tracking it down that I
must admit I’ve sometimes wondered if I imagined the essay. If so, I
have no idea where the above story comes from.)</p>

<p>How can we make actionable this idea that it’s possible to deepen our
mathematical understanding in an open-ended way? What heuristics can
we use to deepen our understanding of a piece of mathematics?</p>

<p>Over the years I’ve collected many such heuristics. In these notes I
describe a heuristic I stumbled upon a year or so ago that I’ve found
especially helpful (albeit time intensive).  I’m still developing the
heuristic, and my articulation will therefore be somewhat
stumbling. I’m certain it can still be much improved upon! But perhaps
it will already be of interest to others.</p>

<p>One caveat is that I’m very uncertain how useful the heuristic will be
to people with backgrounds different to my own. And so it’s perhaps
worth saying a little about what that background is.  I’m not a
professional mathematician, but I was trained and worked as a
professional theoretical physicist for many years. As such, I’ve
written dozens of research papers proving mathematical theorems,
mostly in the field of quantum information and computation. Much of my
life has been spent doing mathematics for many hours each day. It’s
possible someone with a different background would find the heuristic
I’m about to describe much less useful. This applies to people with
both much less and much more mathematical background than I have.</p>

<p>It’s also worth noting that my work mostly involves mathematics only
incidentally these days. I still do some mathematics as a hobby, and
occasionally as part of other research projects. But it’s no longer a
central focus of my life in the way it once was. I suspect the
heuristic I will describe would have been tremendously useful to me
when mathematics was a central focus. But I’m honestly not sure.</p>

<p>The heuristic involves the use of <em>spaced-repetition memory
systems</em>. The system I use is a flashcard program called Anki.  You
enter flashcards with a question on one (virtual) side of the card,
and the answer on the other. Anki then repeatedly tests you on the
questions. The clever thing Anki does is to manage the schedule. If
you get a question right, Anki increases the time interval until
you’re tested again. If you get a question wrong, the interval is
decreased. The effect of this schedule management is to limit the
total time required to learn the answer to the question. Typically, I
estimate total lifetime study for a card to be in the range 5-10
minutes.</p>

<p>I’ve described many elements of my Anki practice in a <a href="http://augmentingcognition.com/ltm.html">separate essay</a>.
Reading that essay isn’t necessary to understand what follows, but
will shed additional light on some of the ideas.  Note that that essay
describes a set of heuristics for reading papers – indeed, of
syntopically reading entire literatures – that are largely
orthogonal to the heuristic I’m about to describe. I find the
heuristics in that essay useful for rapidly getting a broad picture of
a subject, while the heuristics in this essay are for drilling down
deeply.</p>

<p>To explain the heuristic, I need a piece of mathematics to use as an
example.  The piece I will use is a beautiful theorem of linear
algebra. The theorem states that a complex normal matrix is always
diagonalizable by a unitary matrix.  The converse is also true (and is
much easier to prove, so we won’t be concerned with it): a matrix
diagonalizable by a unitary matrix is always normal.</p>

<p>Unpacking that statement, recall that a matrix $M$ is said to be
normal if $MM^\dagger = M^\dagger M$, where $M^\dagger$ is the complex
transpose, $M^\dagger := (M^*)^T$. And a matrix is diagonalizable by a
unitary matrix if there exists a unitary matrix $U$ such that $M = U D
U^\dagger$, where $D$ is a diagonal matrix.</p>

<p>(As shorthand, from now on I will use “diagonalizable” as shorthand to
mean “diagonalizable by a unitary matrix”.)</p>

<p>What’s lovely about this theorem is that the condition $MM^\dagger =
M^\dagger M$ can be checked by simple computation. By contrast,
whether $M$ is diagonalizable seems <em>a priori</em> much harder to check,
since there are infinitely many possible choices of $U$ and $D$. But
the theorem shows that the two conditions are equivalent. So it
converts what seems like a search over an infinite space into simply
checking a small number of algebraic conditions. Furthermore, working
with diagonalizable matrices is often <em>much</em> easier than working with
general matrices, and so it’s extremely useful to have an easy way of
checking whether a matrix is diagonalizable.</p>

<p>Let me explain the proof. I shall explain it at about the level of
detail I would use with a colleague who is a mathematician or quantum
information theorist; people less comfortable with linear algebra may
need to unpack the proof somewhat.</p>

<p>There are two ideas in the proof.</p>

<p>The first idea is to observe that $MM^\dagger = M^\dagger M$ means the
length of the $j$th row of $M$ is equal to the length of the $j$th
column. It’s easiest to see this for the first row and first column.
Suppose we write $M$ as</p><p>

\[M = \left[ \begin{array}{c} r \\ M' \end{array} \right]\]

</p><p>where $r$ is the first row and $M’$ is the remainder of the
matrix. Then the top-left entry in $MM^\dagger$ is:</p><p>

\[MM^\dagger = \left[ \begin{array}{cc} r r^\dagger &amp; \cdots \\ \cdots &amp; \cdots \end{array} \right].\]

</p><p>Similarly, suppose we write $M$ as:</p><p>

\[M = \left[ \begin{array}{cc} c &amp; M'' \end{array} \right]\]

</p><p>where $c$ is the first column and $M’’$ is the remainder of the
matrix. Then the top-leftmost entry in $M^\dagger M$ is:</p><p>

\[M^\dagger M = \left[ \begin{array}{cc} c^\dagger c &amp; \cdots \\ \cdots &amp; \cdots \end{array} \right].\]

</p><p>The normalcy condition $MM^\dagger = M^\dagger M$ then implies that $r
r^\dagger = c^\dagger c$, and thus the length of the first row $r$
must be the same as the length of the first column $c$.</p>

<p>The second idea in the proof is to observe that since $M$ is over the
algebraically complete field of complex numbers, the characteristic
equation $|M-\lambda I|=0$ has at least one solution $\lambda$ and so
there is an eigenvalue $\lambda$ and a basis in which $M$ can be
written:</p><p>

\[M = \left[ \begin{array}{cc} \lambda &amp; \cdots \\ 0 &amp; \cdots \end{array} \right].\]

</p><p>But we just saw that normalcy implies the length of the first column
is equal to the length of the first row, so the remaining entries of
the first row must be zero:</p><p>

\[M = \left[ \begin{array}{cc} \lambda &amp; 0 \\ 0 &amp; \cdots \end{array} \right].\]

</p><p>Recursively applying this to the bottom-right block in the matrix we
can diagonalize $M$.  That completes the proof.</p>

<p>Alright, so that’s the proof. But that’s not the end of the process. I
then use Anki to go much deeper into the proof; I’ll call this the
(deep) Ankification process. This Ankification process works in
(roughly) two phases.</p>

<p><em>Phase I: understanding the proof:</em> This involves multiple passes over
the proof. Initially, it starts out with what I think of as <em>grazing</em>,
picking out single elements of the proof and converting to Anki
cards. For instance, for the above proof, I have Anki cards like the
following:</p>

<p><em>Q: If $M$ is a complex matrix, how is the top-left entry of $M
M^\dagger$ related to the first row $r$ of the matrix $M$?</em></p>

<p><em>A: It’s the length $\|r \|^2$.</em></p>

<p><em>Q: If $M$ is a complex matrix, how is the top-left entry of
$M^\dagger M$ related to the first column $c$ of the matrix $M$?</em></p>

<p><em>A: It’s the length $\|c \|^2$.</em></p>

<p>I work hard to restate ideas in multiple ways. For instance, here’s a
restatement of the first question above:</p>

<p><em>Q: If $M$ is a complex matrix, why is the top-left entry of
$MM^\dagger$ equal to the length squared $|r|^2$ of the first row?</em></p>

<p><em>A: \(\left[ \begin{array}{c} r \\ \cdot \end{array} \right]
\left[ \begin{array}{cc} r^\dagger &amp; \cdot \end{array} \right]
= \left[ \begin{array}{cc} \|r\|^2 &amp; \cdot \\ \cdot &amp; \cdot \end{array} \right]\)</em></p>

<p>Indeed, I worked hard to simplify both questions and answers –
the just given question-and-answer pair started out somewhat more
complicated.  Part of this was some minor complexity in the question,
which I gradually trimmed down. The answer I’ve stated above, though,
is much better than in earlier versions. Earlier versions mentioned
$M$ explicitly (unnecessary), had more blocks in the matrices, used
$\cdots$ rather than $\cdot$, and so on.  You want to aim for the
minimal answer, displaying the core idea as sharply as
possible. Indeed, if it was easy to do I’d de-emphasize the matrix
brackets, and perhaps find some way of highlighting the $r$,
$r^\dagger$ and $\|r\|^2$ entries. Those are the thing that really
matters.</p>

<p>I can’t emphasize enough the value of finding multiple different ways
of thinking about the “same” mathematical ideas.  Here’s a couple more
related restatements:</p>

<p><em>Q: What’s a geometric interpretation of the diagonal entries in the
matrix $MM^\dagger$?</em></p>

<p><em>A: The lengths squared of the respective rows.</em></p>

<p><em>Q: What’s a geometric interpretation of the diagonal entries in the
matrix $M^\dagger M$?</em></p>

<p><em>A: The lengths squared of the respective columns.</em></p>

<p><em>Q: What do the diagonal elements of the normalcy condition
$MM^\dagger = M^\dagger M$ mean geometrically?</em></p>

<p><em>A: The corresponding row and column lengths are the same.</em></p>

<p>What you’re trying to do at this stage is learn your way around the
proof. Every piece should become a comfortable part of your mental
furniture, ideally something you start to really feel.  That means
understanding every idea in multiple ways, and finding as many
connections between different ideas as possible.</p>

<p>People inexperienced at mathematics sometimes memorize proofs as
linear lists of statements. A more useful way is to think of proofs is
as interconnected networks of simple observations. Things are rarely
true for just one reason; finding multiple explanations for things
gives you an improved understanding.  This is in some sense
“inefficient”, but it’s also a way of deepening understanding and
improving intuition. You’re building out the network of the proof,
making more connections between nodes.</p>

<p>One way of doing this is to explore minor variations. For instance,
you might wonder what the normalcy condition $MM^\dagger = M^\dagger
M$ means on the off-diagonal elements. This leads to questions like
(again, it’s useful to enter many different variations of this
question, I’ll just show a couple):</p>

<p><em>Q: What does the normalcy condition $MM^\dagger = M^\dagger M$ mean
for the $jk$th component, in terms of the rows $r_j$ and columns
$c_j$ of the matrix $M$?</em></p>

<p><em>A: The inner product $r_k \cdot r_j = c_j \cdot c_k$.</em></p>

<p><em>Q: The normalcy condition $MM^\dagger = M^\dagger M$ implies $r_k
\cdot r_j = c_j \cdot c_k$ for rows and columns. What does this mean
for row and column lengths?</em></p>

<p><em>A: They must be the same.</em></p>

<p>(By the way, it’s questions like these that make me think it helps to
be fairly mathematically experienced in carrying this Ankification
process out.  For someone who has done a lot of linear algebra these
are very natural observations to make, and questions to ask. But I’m
not sure they would be so natural for everyone. The ability to ask the
“right” questions – insight-generating questions – is a
limiting part of this whole process, and requires some experience.)</p>

<p>I’ve been describing the grazing process, aiming to thoroughly
familiarize yourself with every element of the proof.  This is useful,
but is also a rather undirected process, with no clear end point, and
not necessarily helping you understand the broader to structure of the
proof. I also impose on myself a set of aspirational goals, all
variations on the idea of distilling the entire proof to one question
and (simple) answer. The aim is to fill in the answers to questions
having forms like:</p>

<p><em>Q: In one sentence, what is the core reason a (complex) normal matrix
is diagonalizable?</em></p>

<p>And:</p>

<p><em>Q: What is a simple visual representation of the proof that (complex)
normal matrices are diagonalizable?</em></p>

<p>I think of these question templates as boundary conditions or forcing
functions. They’re things to aim for, and I try to write questions
that will help me move toward answers. That starts with grazing, but
over time moves to more structural questions about the proof, and
about how elements fit together. For instance:</p>

<p><em>Q: How many key ideas are there in the proof that complex normal
matrices are diagonalizable?</em></p>

<p><em>A: Two.</em></p>

<p><em>Q: What are the two key ideas in the proof that complex normal
matrices $M$ are diagonalizable?</em></p>

<p><em>A: (1) Write $M$ in a basis where the first column is all zeroes
except the first entry; and (2) use the normalcy condition to argue
that row lengths are equal to column lengths.</em></p>

<p>The second card here is, in fact, too complicated – it’d be
better to refactor into two or more cards, separating the two ideas,
and sharpening the answers. In general, it’s helpful to make both
questions and answers as atomic as possible; it seems to help build
clarity. That atomicity doesn’t mean the questions and answers can’t
involve quite sophisticated concepts, but they ideally express a
single idea.</p>

<p>In practice, as I understand the proof better and better the
aspirational goal cards change their nature somewhat.  Here’s a good
example of such an aspirational card:</p>

<p><em>Q: What is a simple visual representation of the reason that
(complex) normal matrices are diagonalizable?</em></p>

<p><em>A: \(\left[ \begin{array}{cc} \lambda   &amp; r \\ 0 &amp; \cdot \end{array} \right]
  \left[ \begin{array}{cc} \lambda^* &amp; 0 \\ r^\dagger &amp; \cdot \end{array} \right] =
  \left[ \begin{array}{cc} \lambda^* &amp; 0 \\ r^\dagger &amp; \cdot \end{array} \right]
  \left[ \begin{array}{cc} \lambda   &amp; r \\ 0 &amp; \cdot \end{array} \right]
  \,\, \Rightarrow \,\, |\lambda|^2+r^\dagger r = |\lambda|^2 \,\, \Rightarrow \,\, r = 0.\)</em></p>

<p>This is pretty good – certainly, there’s a sense in which it’s
much better than the original proof! But it’s still somewhat
complicated. What you really want is to feel every element (and the
connections between them) in your bones. Some substantial part of that
feeling comes by actually constructing the cards. That’s a feeling you
can’t get merely by reading an essay, it can only be experienced by
going through the deep Ankification process yourself. Nonetheless, I
find that process, as described up to now, is also not quite
enough. You can improve upon it by asking further questions
elaborating on different parts of the answer, with the intent of
helping you understand the answer better. I <em>haven’t</em> done this nearly
as much as I would like. In part, it’s because the tools I have aren’t
well adapted. For instance, I’d love to have an easy way of
highlighting (say, in yellow) the crucial rows and columns that are
multiplied in the matrices above, and then connecting them to the
crucial inference on the right. But while I can easily imagine
multiple ways of doing that, in practice it’s more effort than I’m
willing to put in.</p>

<p>Another helpful trick is to have multiple ways of writing these
top-level questions. Much of my thinking is non-verbal (especially in
subjects I’m knowledgeable about), but I still find it useful to force
a verbal question-and-answer:</p>

<p><em>Q: In one sentence, what is the core reason a (complex) normal matrix
is diagonalizable?</em></p>

<p><em>A: If an eigenvalue $\lambda$ is in the top-left of $M$, then
normalcy means $|\lambda|^2 + \|r\|^2 = |\lambda|^2$, and so the
remainder $r$ of the first row vanishes.</em></p>

<p>As described, this deep Ankification process can feel rather
wasteful. Inevitably, over time my understanding of the proof
changes. When that happens it’s often useful to rewrite (and sometimes
discard or replace) cards to reflect my improved understanding. And
some of the cards written along the way have the flavor of exhaust,
bad cards that seem to be necessary to get to good cards. I wish I had
a good way of characterizing these, but I haven’t gone through this
often enough to have more than fuzzy ideas about it.</p>

<p>A shortcoming of my description of the Ankification process is that I
cheated in an important way. The proof I wrote above was written
<em>after</em> I’d already gone through the process, and was much clearer
than any proof I could have written before going through the process.
And so part of the benefit is hidden: you refactor and improve your
proof along the way. Indeed, although I haven’t been in the habit of
rewriting the refactored proof after the Ankification process (this
essay is the first time I’ve done it), I suspect it would be a good
practice.</p>

<p><em>The inner experience of mathematics:</em> As I reread the description of
Part I just given, it is rather unsatisfactory in that it conveys
little of the experience of mathematics one is trying to move
toward. Let me try to explain this in the context not of Anki, but
rather of an experience I’ve sometimes had while doing research, an
experience I dub “being inside a piece of mathematics”.</p>

<p>Typically, my mathematical work begins with paper-and-pen and messing
about, often in a rather <em>ad hoc</em> way. But over time if I really get
into something my thinking starts to change. I gradually internalize
the mathematical objects I’m dealing with. It becomes easier and
easier to conduct (most of) my work in my head. I will go on long
walks, and simply think intensively about the objects of
concern. Those are no longer symbolic or verbal or visual in the
conventional way, though they have some secondary aspects of this
nature. Rather, the sense is somehow of working directly with the
objects of concern, without any direct symbolic or verbal or visual
referents. Furthermore, as my understanding of the objects change
– as I learn more about their nature, and correct my own
misconceptions – my sense of what I can do with the objects
changes as well. It’s as though they sprout new affordances, in the
language of user interface design, and I get much practice in learning
to fluidly apply those affordances in multiple ways.</p>

<p>This is a very difficult experience to describe in a way that I’m
confident others will understand, but it really is central to my
experience of mathematics – at least, of mathematics that I
understand well. I must admit I’ve shared it with some trepidation; it
seems to be rather unusual for someone to describe their inner
mathematical experiences in these terms (or, more broadly, in the
terms used in this essay).</p>

<p>If you don’t do mathematics, I expect this all sounds rather strange.
When I was a teenager I vividly recall reading a curious letter Albert
Einstein wrote to the mathematician Jacques Hadamard, describing his
(Einstein’s) thought processes. I won’t quote the whole letter, but
here’s some of the flavor:</p>

<blockquote>
  <p>The words or the language, as they are written or spoken, do not
seem to play any role in my mechanism of thought. The psychical
entities which seem to serve as elements in thought are certain
signs and more or less clear images which can be “voluntarily”
reproduced and combined… The above-mentioned elements are, in my
case, of visual and some of muscular type. Conventional words or
other signs have to be sought for laboriously only in a secondary
stage, when the mentioned associative play is sufficiently
established and can be reproduced at will.</p>
</blockquote>

<p>When I first read this, I had no idea what Einstein was talking
about. It was so different from my experience of physics and
mathematics that I wondered if I was hopelessly unsuited to do work in
physics or mathematics. But if you’d asked me about Einstein’s letter
a decade (of intensive work on physics and mathematics) later, I would
have smiled and said that while my internal experience wasn’t the same
as Einstein’s, I very much empathized with his description.</p>

<p>In retrospect, I think that what’s going on is what psychologists call
<a href="http://augmentingcognition.com/assets/Simon1974.pdf">chunking</a>. People
who intensively study a subject gradually start to build mental
libraries of “chunks” – large-scale patterns that they recognize
and use to reason. This is why some grandmaster chess players can
remember thousands of games move for move. They’re not remembering the
individual moves – they’re remembering the ideas those games
express, in terms of larger patterns. And they’ve studied chess so
much that those ideas and patterns are deeply meaningful, much as the
phrases in a lover’s letter may be meaningful. It’s why <a href="https://www.youtube.com/watch?v=eNVJFRl6f6s">top basketball
players</a> have extraordinary recall of games. Experts begin to
think, perhaps only semi-consciously, using such chunks. The
conventional representations – words or symbols in mathematics,
or moves on a chessboard – are still there, but they are somehow
secondary.</p>

<p>So, my informal pop-psychology explanation is that when I’m doing
mathematics really well, in the deeply internalized state I described
earlier, I’m mostly using such higher-level chunks, and that’s why it
no longer seems symbolic or verbal or even visual. I’m not entirely
conscious of what’s going on – it’s more a sense of just playing
around a lot with the various objects, trying things out, trying to
find unexpected connections. But, presumably, what’s underlying the
process is these chunked patterns.</p>

<p>Now, the only way I’ve reliably found to get to this point is to get
obsessed with some mathematical problem. I will start out thinking
symbolically about the problem as I become familiar with the relevant
ideas, but eventually I internalize those ideas and their patterns of
use, and can carry out a lot (not all) of operations inside my head.</p>

<p>What’s all this got to do with the Ankification process? Well, I said
that the only reliable way I’ve found to get to this deeply
internalized state is to obsess over a problem. But I’ve noticed that
when I do the Ankification process, I also start to think less and
less in terms of the conventional representations. The more questions
I write, the more true this seems to be. And so I wonder if the
Ankification process can be used as a kind of deterministic way of
attaining that type of state. (Unfortunately, I can’t get obsessed
with a problem on demand; it’s a decidedly non-deterministic process!)</p>

<p>One consequence of this for the Ankification process is that over time
I find myself more and more wanting to use blank answers: I don’t have
a conventional symbolic or visual representation for the
answer. Instead, I have to bring to mind the former experience of the
answer. Or, I will sometimes use an answer that would be essentially
unintelligible to anyone else, relying on my internal representation
to fill in the blanks. This all tends to occur pretty late in the
process.</p>

<p>Now, unfortunately, this transition to the chunked,
deeply-internalized state isn’t as thorough when I’m Ankifying as it
is when obsessively problem solving. However, I suspect it greatly
enables such a transition. (I rarely obsessively problem solve these
days, so I haven’t yet had a chance to see this happen.) And I do
wonder if there are types of question I can ask that will help me get
more fully to the deeply-internalized state. What seems to be lacking
is a really strongly-felt internalization of the meaning of answers
like that shown above:</p>

<p><em>A: \(\left[ \begin{array}{cc} \lambda   &amp; r \\ 0 &amp; \cdot \end{array} \right]
  \left[ \begin{array}{cc} \lambda^* &amp; 0 \\ r^\dagger &amp; \cdot \end{array} \right] =
  \left[ \begin{array}{cc} \lambda^* &amp; 0 \\ r^\dagger &amp; \cdot \end{array} \right]
  \left[ \begin{array}{cc} \lambda   &amp; r \\ 0 &amp; \cdot \end{array} \right]
  \,\, \Rightarrow \,\, |\lambda|^2+r^\dagger r = |\lambda|^2 \,\, \Rightarrow \,\, r = 0.\)</em></p>

<p>That type of strongly-felt meaning can, however, be built by using
such representations in many different ways as part of
problem-solving; it builds fluency and familiarity. But I haven’t
actually done it.</p>

<p><em>Phase II: variations, pushing the boundaries:</em> Let’s get back to
details of how the Ankification process works. One way of deepening
your understanding further is to find ways of pushing the boundaries
of the proof and of the theorem. I find it helpful to consider many
different ways of changing the assumptions of the theorem, and to ask
how it breaks down (or generalizes). For instance:</p>

<p><em>Q: Why does the proof that complex normal matrices are diagonalizable
fail for real matrices?</em></p>

<p><em>A: It may not be possible to find an eigenvector for the matrix,
since the real numbers aren’t algebraically complete.</em></p>

<p><em>Q: What’s an example of a real normal matrix that isn’t
diagonalizable by a real orthogonal matrix?</em></p>

<p><em>A: \(\left[ \begin{array}{cc} 1 &amp; -1 \\ 1 &amp; 1 \end{array} \right]\)</em></p>

<p>As per usual, these questions can be extended and varied in many ways.</p>

<p>Another good strategy is to ask if the conditions can be weakened. For
instance, you might have noticed that we only seemed to use the
normality condition on the diagonal.  Can we get away with requiring
$M^\dagger M = MM^\dagger$ just on the diagonal? In fact, some
reflection shows that the answer is no: we need it to be true in a
basis which includes an eigenvector of $M$. So we can add questions
like this:</p>

<p><em>Q: In the proof that normalcy implies diagonalizability, why does it
not suffice to require that $M^\dagger M = MM^\dagger$ only on the
diagonal?</em></p>

<p><em>A: Because we need this to be true in a particular basis, and we
cannot anticipate in advance what that basis will be.</em></p>

<p>Or we can try to generalize:</p>

<p><em>Q: For which fields is it possible to generalize the result that
complex normal matrices are diagonalizable?</em></p>

<p><em>A: [I haven’t checked this carefully!] For algebraically complete
fields.</em></p>

<p>(My actual Anki card doesn’t have the annotation in the last
answer. But it’s true: I haven’t checked the proof carefully. Still,
answering the question helped me understand the original proof and the
result better.)</p>

<p>This second phase really is open-ended: we can keep putting in
variations essentially <em>ad infinitum</em>. The questions are no longer
directly about the proof, but rather are about poking it in various
ways, and seeing what happens. The further I go, and the more I
connect to other results, the better.</p>

<p><em>“The” proof?</em> Having described the two phases in this Ankification
process, let me turn to a few miscellaneous remarks.  One complication
is that throughout I’ve referred to “the” proof. Of course,
mathematical theorem often have two or more proofs. Understanding
multiple proofs and how they relate is a good way of deepening one’s
understanding further. It does raise an issue, which is that some of
the Anki questions refer to “the” proof of a result. I must admit, I
don’t have an elegant way of addressing this!  But it’s something I
expect I’ll need to address eventually.</p>

<p>A related point is how much context-setting to do in the questions
– do we keep referring, over and over, to “the proof that
$MM^\dagger = M^\dagger M$ implies normalcy”, or to “if $M$ is a
complex matrix” (and so on)? In my Anki cards I do (note that I’ve
elided this kind of stuff in some of the questions above), but frankly
find it a bit irritating. However, since the cards are studied at
unknown times in the future, and I like to mix all my cards up in a
single deck, some context-setting is necessary.</p>

<p><em>What have I used this to do?</em> I’ve used this process on
three-and-a-half theorems so far:</p>

<ul>
  <li>Complex normal matrices are diagonalizable.</li>
  <li>Euler’s theorem that $a^{\phi(n)} \equiv 1 (\mod n)$ for any number
$a$ coprime to positive integer $n$, and $\phi(n)$ is Euler’s
totient function.</li>
  <li>Lagrange’s theorem (used in the proof of Euler’s theorem) that the
order of a subgroup of a finite group must divide the order of the
entire group.</li>
  <li>I’ve started the process for the fundamental theorem of algebra,
stating that every non-constant polynomial has a zero in the complex
plane. I was interrupted (I don’t recall why), and never finished
it.</li>
</ul>

<p>It’s quite time-intensive.  I don’t have any easy way to count the
number of questions I’ve added for each of these theorems, but I guess
on the order of dozens of cards for each. It takes a few hours
typically, though I expect I could easily add many more questions.</p>

<p>[Note added: in the initial version of this essay I wrote “100 cards
for each”. I looked, and in fact there are fewer – on the order
of dozens, well short of 100. This surprised me – if anything,
I’d have guessed my error was in underestimation. The card-adding
process was intense, however, which perhaps accounts for my badly
mistaken impression.]</p>

<p><em>Seeing through a piece of mathematics:</em> This is all a lot of work!
The result, though, has been a considerable deepening in my
understanding of all these results.  There’s a sense of being able to
“see through” the result.  Formerly, while I could have written down a
proof that normal matrices are diagonalizable, it was all a bit
murky. Now, it appears almost obvious, I can very nearly <em>see</em>
directly that it’s true. The reason, of course, is that I’m far more
familiar with all the underlying objects, and the relationships
between them.</p>

<p>My research experience has been that this ability to see through a
piece of mathematics isn’t just enjoyable, it’s absolutely invaluable;
it can give you a very rare level of understanding of (and flexibility
in using) a particular set of mathematical ideas.</p>

<p><em>Discovering alternate proofs:</em> After going through the Ankification
process described above I had a rather curious experience. I went for
a multi-hour walk along the San Francisco Embarcadero. I found that my
mind simply and naturally began discovering other facts related to the
result. In particular, I found a handful (perhaps half a dozen) of
different proofs of the basic theorem, as well as noticing many
related ideas. This wasn’t done especially consciously – rather,
my mind simply wanted to find these proofs.</p>

<p>At the time these alternate proofs seemed crystalline, almost
obvious. I didn’t bother writing them down in any form, or adding them
to Anki; they seemed sufficiently clear that I assumed I’d remember
them forever. I regret that, for later I did not recall the proofs at
all.</p>

<p>Curiously, however, in the process of writing these notes I have
recalled the ideas for two of the proofs.  One was something like the
following: apply the condition $M^\dagger M = MM^\dagger$ directly to
the upper triangular form $M = D+T$ where $D$ is diagonal and $T$ is
strictly upper triangular; the result drops out by considering the
diagonal elements. And another was to apply the normalcy condition to
the singular value decomposition for the matrix $M$; the proof drops
out immediately when the singular values are distinct, and can be
recovered with a little work when the singular values are not.</p>

<p><em>Simplicity of the theorems:</em> The three-and-a-half theorems mentioned
above are all quite elementary mathematics. What about using this
Ankification process to deepen my understanding of more advanced
mathematical ideas? I’ll certainly try it at some point, and am
curious about the effect. I’m also curious to try the process with
networks of related theorems – I suspect there will be some
surprising mutual benefits in at least some cases. But I don’t yet
know.</p>

<p><em>In what sense is this really about Anki flashcards?</em> There’s very
little in the above process that explicitly depended on me using
Anki’s spaced-repetition flashcards. Rather, what I’ve described is a
general process for pulling apart the proof of a theorem and making
much more sense of it, essentially by atomizing the elements. There’s
no direct connection to Anki at all – you could carry out the
process using paper and pencil.</p>

<p>Nonetheless, something I find invaluable is the confidence Anki brings
that I will remember what I learn from this process. It’s not so much
any single fact, but rather a sense of familiarity and fluency with
the underlying objects, an ability to simply see relationships between
them. That sense does fade with time, but far less rapidly than if I
simply didn’t think about the proof again.  That’s a large payoff, and
one that I find makes me far more motivated to go through the
process. Perhaps other people, with different motivations, would find
Anki superfluous.</p>

<p>That said, I do have some sense that, as mentioned earlier, some of
the cards I generate are a type of exhaust, and would be better off
excluded from the process. This is especially true of many of the
cards generated early in the process, when I’m still scratching
around, trying to get purchase on the proof. Unfortunately, also as
mentioned above, I don’t yet have much clarity on which cards are
exhaust, and which are crucial.</p>

<p><em>Can I share my deck?</em> When I discuss Anki publicly, some people
always ask if I can share my deck. The answer is no, for reasons I’ve
explained <a href="http://augmentingcognition.com/ltm.html">here</a>. I must admit,
in the present case, I don’t really understand why you’d want to use a
shared deck. In part, that’s because so much of the value is in the
process of constructing the cards. But even more important: I suspect
a deck of 100+ of my cards on the proof above would be largely
illegible to anyone else – keep in mind that you’d see the cards
in a randomized order, and without the benefit of <em>any</em> of the context
above. It’d be an incomprehensible mess.</p>

<p><em>Discovery fiction:</em> I’ve described this Ankification process as a
method for more deeply understanding mathematics. Of course, it’s just
one approach to doing that! I want to briefly mention one other
process I find particularly useful for understanding. It’s to write
what I call <em>discovery fiction</em>. Discovery fiction starts with the
question “how would I have discovered this result?” And then you try
to make up a story about how you might have come to discover it,
following simple, almost-obvious steps.</p>

<p>Two examples of discovery fiction are my <a href="http://www.michaelnielsen.org/ddi/how-the-bitcoin-protocol-actually-works/">essay
explaining how you might have come to invent Bitcoin</a>, and my <a href="http://www.michaelnielsen.org/ddi/why-bloom-filters-work-the-way-they-do/">essay
explaining how you might have invented an advanced data structure (the
Bloom filter)</a>.</p>

<p>Writing discovery fiction can be tough. For the theorem considered in
this essay, it’s not at all clear how you would have come to the
result in the first place.  But maybe you started out already
interested in $M^\dagger$, and in the question of when two matrices
$A$ and $B$ commute.  So you ask yourself: “Hmm, I wonder what it
might mean that $M$ and $M^\dagger$ commute?” If you’re willing to
grant that as a starting point, then with some work you can probably
find a series of simple, “obvious” steps whereby you come to wonder if
maybe $M$ is diagonalizable, and then discover a proof.</p>

<p>Any such “discovery fiction” proof will be long – far longer
than the proof above. Even a cleaned-up version will be – should
be! – messy and contain false turns. But I wanted to mention
discovery fiction as a good example of a process which gives rise to a
very different kind of understanding than the Ankification process.</p>

<p><em>What about other subjects?</em> Mathematics is particularly well suited
to deep Ankification, since much of it is about precise relationships
between precisely-specified objects. Although I use Anki extensively
for studying many other subjects, I haven’t used it at anything like
this kind of depth. In the near future, I plan to use a similar
process to study some of the absolute core results about climate
change, and perhaps also to study some of the qualities of good
writing (e.g., I can imagine using a similar process to analyze the
lead sentences from, say, 30 well-written books).  I don’t know how
this will go, but am curious to try. I’m a little leery of coming to
rely too much on the process – creative work also requires many
skills at managing uncertainty and vagueness. But as a limited-use
cognitive tool, deep Ankification seems potentially valuable in many
areas.</p>

<p><a href="https://twitter.com/michael_nielsen">Follow me on Twitter</a></p>

<h3 id="acknowledgments">Acknowledgments</h3>

<p>Many thanks to everyone who has talked with me about spaced-repetition
memory systems.  Especial thanks to Andy Matuschak, whose conversation
has deeply influenced how I think about nearly all aspects of spaced
repetition. And thanks to Kevin Simler for additional initial
encouragement to write about my spaced repetition practice.</p>

<h3 id="citation-and-licensing">Citation and licensing</h3>

<p><em>In academic work, please cite this as: Michael A. Nielsen, “Using
spaced repetition systems to see through a piece of mathematics”
http://cognitivemedium.com/srs-mathematics, 2019.</em></p>

<p><em>This work is licensed under a Creative Commons
Attribution-NonCommercial 3.0 Unported License. This means you’re free
to copy, share, and build on this essay, but not to sell it. If you’re
interested in commercial use, please contact me.</em></p>


  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Superlinear Returns (205 pts)]]></title>
            <link>http://paulgraham.com/superlinear.html</link>
            <guid>37919949</guid>
            <pubDate>Tue, 17 Oct 2023 19:00:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://paulgraham.com/superlinear.html">http://paulgraham.com/superlinear.html</a>, See on <a href="https://news.ycombinator.com/item?id=37919949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/superlinear-returns-1.gif" width="168" height="18" alt="Superlinear Returns"><span size="2" face="verdana">October 2023<p>One of the most important things I didn't understand about the world
when I was a child is the degree to which the returns for performance
are superlinear.</p><p>Teachers and coaches implicitly told us the returns were linear.
"You get out," I heard a thousand times, "what you put in." They
meant well, but this is rarely true. If your product is only half
as good as your competitor's, you don't get half as many customers.
You get no customers, and you go out of business.</p><p>It's obviously true that the returns for performance are superlinear
in business. Some think this is a flaw of capitalism, and that if
we changed the rules it would stop being true. But superlinear
returns for performance are a feature of the world, not an artifact
of rules we've invented. We see the same pattern in fame, power,
military victories, knowledge, and even benefit to humanity. In all
of these, the rich get richer.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span><p>You can't understand the world without understanding the concept
of superlinear returns. And if you're ambitious you definitely
should, because this will be the wave you surf on.</p><p>It may seem as if there are a lot of different situations with
superlinear returns, but as far as I can tell they reduce to two
fundamental causes: exponential growth and thresholds.</p><p>The most obvious case of superlinear returns is when you're working
on something that grows exponentially. For example, growing bacterial
cultures. When they grow at all, they grow exponentially. But they're
tricky to grow. Which means the difference in outcome between someone
who's adept at it and someone who's not is very great.</p><p>Startups can also grow exponentially, and we see the same pattern
there. Some manage to achieve high growth rates. Most don't. And
as a result you get qualitatively different outcomes: the companies
with high growth rates tend to become immensely valuable, while the
ones with lower growth rates may not even survive.</p><p>Y Combinator encourages founders to focus on growth rate rather
than absolute numbers. It prevents them from being discouraged early
on, when the absolute numbers are still low. It also helps them
decide what to focus on: you can use growth rate as a compass to
tell you how to evolve the company. But the main advantage is that
by focusing on growth rate you tend to get something that grows
exponentially.</p><p>YC doesn't explicitly tell founders that with growth rate "you get
out what you put in," but it's not far from the truth. And if growth
rate were proportional to performance, then the reward for performance
<i>p</i> over time <i>t</i> would be proportional to <i>p<sup>t</sup></i>.</p><p>Even after decades of thinking about this, I find that sentence
startling.</p><p>Whenever how well you do depends on how well you've done, you'll
get exponential growth. But neither our DNA nor our customs prepare
us for it. No one finds exponential growth natural; every child is
surprised, the first time they hear it, by the story of the man who
asks the king for a single grain of rice the first day and double
the amount each successive day.</p><p>What we don't understand naturally we develop customs to deal with,
but we don't have many customs about exponential growth either,
because there have been so few instances of it in human history.
In principle herding should have been one: the more animals you
had, the more offspring they'd have. But in practice grazing land
was the limiting factor, and there was no plan for growing that
exponentially.</p><p>Or more precisely, no generally applicable plan. There <i>was</i> a way
to grow one's territory exponentially: by conquest. The more territory
you control, the more powerful your army becomes, and the easier
it is to conquer new territory. This is why history is full of
empires. But so few people created or ran empires that their
experiences didn't affect customs very much. The emperor was a
remote and terrifying figure, not a source of lessons one could use
in one's own life.</p><p>The most common case of exponential growth in preindustrial times
was probably scholarship. The more you know, the easier it is to
learn new things. The result, then as now, was that some people
were startlingly more knowledgeable than the rest about certain
topics. But this didn't affect customs much either. Although empires
of ideas can overlap and there can thus be far more emperors, in
preindustrial times this type of empire had little practical effect.
</p><span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>That has changed in the last few centuries. Now the emperors of
ideas can design bombs that defeat the emperors of territory. But
this phenomenon is still so new that we haven't fully assimilated
it. Few even of the participants realize they're benefitting from
exponential growth or ask what they can learn from other instances
of it.</p><p>The other source of superlinear returns is embodied in the expression
"winner take all." In a sports match the relationship between
performance and return is a step function: the winning team gets
one win whether they do much better or just slightly better.
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>The source of the step function is not competition per se, however.
It's that there are thresholds in the outcome. You don't need
competition to get those. There can be thresholds in situations
where you're the only participant, like proving a theorem or hitting
a target.</p><p>It's remarkable how often a situation with one source of superlinear
returns also has the other. Crossing thresholds leads to exponential
growth: the winning side in a battle usually suffers less damage,
which makes them more likely to win in the future. And exponential
growth helps you cross thresholds: in a market with network effects,
a company that grows fast enough can shut out potential competitors.</p><p>Fame is an interesting example of a phenomenon that combines both
sources of superlinear returns. Fame grows exponentially because
existing fans bring you new ones. But the fundamental reason it's
so concentrated is thresholds: there's only so much room on the
A-list in the average person's head.</p><p>The most important case combining both sources of superlinear returns
may be learning. Knowledge grows exponentially, but there are also
thresholds in it. Learning to ride a bicycle, for example. Some of
these thresholds are akin to machine tools: once you learn to read,
you're able to learn anything else much faster. But the most important
thresholds of all are those representing new discoveries. Knowledge
seems to be fractal in the sense that if you push hard at the
boundary of one area of knowledge, you sometimes discover a whole
new field. And if you do, you get first crack at all the new
discoveries to be made in it. Newton did this, and so did Durer and
Darwin.</p><p>
Are there general rules for finding situations with superlinear
returns? The most obvious one is to seek work that compounds.</p><p>There are two ways work can compound. It can compound directly, in
the sense that doing well in one cycle causes you to do better in
the next. That happens for example when you're building infrastructure,
or growing an audience or brand. Or work can compound by teaching
you, since learning compounds. This second case is an interesting
one because you may feel you're doing badly as it's happening. You
may be failing to achieve your immediate goal. But if you're learning
a lot, then you're getting exponential growth nonetheless.</p><p>This is one reason Silicon Valley is so tolerant of failure. People
in Silicon Valley aren't blindly tolerant of failure. They'll only
continue to bet on you if you're learning from your failures. But
if you are, you are in fact a good bet: maybe your company didn't
grow the way you wanted, but you yourself have, and that should
yield results eventually.</p><p>Indeed, the forms of exponential growth that don't consist of
learning are so often intermixed with it that we should probably
treat this as the rule rather than the exception. Which yields
another heuristic: always be learning. If you're not learning,
you're probably not on a path that leads to superlinear returns.</p><p>But don't overoptimize <i>what</i> you're learning. Don't limit yourself
to learning things that are already known to be valuable. You're
learning; you don't know for sure yet what's going to be valuable,
and if you're too strict you'll lop off the outliers.</p><p>What about step functions? Are there also useful heuristics of the
form "seek thresholds" or "seek competition?" Here the situation
is trickier. The existence of a threshold doesn't guarantee the
game will be worth playing. If you play a round of Russian roulette,
you'll be in a situation with a threshold, certainly, but in the
best case you're no better off. "Seek competition" is similarly
useless; what if the prize isn't worth competing for? Sufficiently
fast exponential growth guarantees both the shape and magnitude of
the return curve — because something that grows fast enough will
grow big even if it's trivially small at first — but thresholds
only guarantee the shape.
</p><span color="#dddddd">[<a href="#f4n"><span color="#dddddd">4</span></a>]</span><p>A principle for taking advantage of thresholds has to include a
test to ensure the game is worth playing. Here's one that does: if
you come across something that's mediocre yet still popular, it
could be a good idea to replace it. For example, if a company makes
a product that people dislike yet still buy, then presumably they'd
buy a better alternative if you made one.
</p><span color="#dddddd">[<a href="#f5n"><span color="#dddddd">5</span></a>]</span><p>It would be great if there were a way to find promising intellectual
thresholds. Is there a way to tell which questions have whole new
fields beyond them? I doubt we could ever predict this with certainty,
but the prize is so valuable that it would be useful to have
predictors that were even a little better than random, and there's
hope of finding those. We can to some degree predict when a research
problem <i>isn't</i> likely to lead to new discoveries: when it seems
legit but boring. Whereas the kind that do lead to new discoveries
tend to seem very mystifying, but perhaps unimportant. (If they
were mystifying and obviously important, they'd be famous open
questions with lots of people already working on them.) So one
heuristic here is to be driven by curiosity rather than careerism
— to give free rein to your curiosity instead of working on what
you're supposed to.</p><p>
The prospect of superlinear returns for performance is an exciting
one for the ambitious. And there's good news in this department:
this territory is expanding in both directions. There are more types
of work in which you can get superlinear returns, and the returns
themselves are growing.</p><p>There are two reasons for this, though they're so closely intertwined
that they're more like one and a half: progress in technology, and
the decreasing importance of organizations.</p><p>Fifty years ago it used to be much more necessary to be part of an
organization to work on ambitious projects. It was the only way to
get the resources you needed, the only way to have colleagues, and
the only way to get distribution. So in 1970 your prestige was in
most cases the prestige of the organization you belonged to. And
prestige was an accurate predictor, because if you weren't part of
an organization, you weren't likely to achieve much. There were a
handful of exceptions, most notably artists and writers, who worked
alone using inexpensive tools and had their own brands. But even
they were at the mercy of organizations for reaching audiences.
</p><span color="#dddddd">[<a href="#f6n"><span color="#dddddd">6</span></a>]</span><p>A world dominated by organizations damped variation in the returns
for performance. But this world has eroded significantly just in
my lifetime. Now a lot more people can have the freedom that artists
and writers had in the 20th century. There are lots of ambitious
projects that don't require much initial funding, and lots of new
ways to learn, make money, find colleagues, and reach audiences.</p><p>There's still plenty of the old world left, but the rate of change
has been dramatic by historical standards. Especially considering
what's at stake. It's hard to imagine a more fundamental change
than one in the returns for performance.</p><p>Without the damping effect of institutions, there will be more
variation in outcomes. Which doesn't imply everyone will be better
off: people who do well will do even better, but those who do badly
will do worse. That's an important point to bear in mind. Exposing
oneself to superlinear returns is not for everyone. Most people
will be better off as part of the pool. So who should shoot for
superlinear returns? Ambitious people of two types: those who know
they're so good that they'll be net ahead in a world with higher
variation, and those, particularly the young, who can afford to
risk trying it to find out.
</p><span color="#dddddd">[<a href="#f7n"><span color="#dddddd">7</span></a>]</span><p>The switch away from institutions won't simply be an exodus of their
current inhabitants. Many of the new winners will be people they'd
never have let in. So the resulting democratization of opportunity
will be both greater and more authentic than any tame intramural
version the institutions themselves might have cooked up.</p><p>
Not everyone is happy about this great unlocking of ambition. It
threatens some vested interests and contradicts some ideologies.&nbsp;</p><span color="#dddddd">[<a href="#f8n"><span color="#dddddd">8</span></a>]</span>
But if you're an ambitious individual it's good news for you.
How should you take advantage of it?<p>The most obvious way to take advantage of superlinear returns for
performance is by doing exceptionally good work. At the far end of
the curve, incremental effort is a bargain. All the more so because
there's less competition at the far end — and not just for the
obvious reason that it's hard to do something exceptionally well,
but also because people find the prospect so intimidating that few
even try. Which means it's not just a bargain to do exceptional
work, but a bargain even to try to.</p><p>There are many variables that affect how good your work is, and if
you want to be an outlier you need to get nearly all of them right.
For example, to do something exceptionally well, you have to be
interested in it. Mere diligence is not enough. So in a world with
superlinear returns, it's even more valuable to know what you're
interested in, and to find ways to work on it.
</p><span color="#dddddd">[<a href="#f9n"><span color="#dddddd">9</span></a>]</span>
It will also be
important to choose work that suits your circumstances. For example,
if there's a kind of work that inherently requires a huge expenditure
of time and energy, it will be increasingly valuable to do it when
you're young and don't yet have children.<p>There's a surprising amount of technique to doing great work.
It's not just a matter of trying hard. I'm going to take a shot
giving a recipe in one paragraph.</p><p>Choose work you have a natural aptitude for and a deep interest in.
Develop a habit of working on your own projects; it doesn't matter
what they are so long as you find them excitingly ambitious. Work
as hard as you can without burning out, and this will eventually
bring you to one of the frontiers of knowledge. These look smooth
from a distance, but up close they're full of gaps. Notice and
explore such gaps, and if you're lucky one will expand into a whole
new field. Take as much risk as you can afford; if you're not failing
occasionally you're probably being too conservative. Seek out the
best colleagues. Develop good taste and learn from the best examples.
Be honest, especially with yourself. Exercise and eat and sleep
well and avoid the more dangerous drugs. When in doubt, follow your
curiosity. It never lies, and it knows more than you do about what's
worth paying attention to.
</p><span color="#dddddd">[<a href="#f10n"><span color="#dddddd">10</span></a>]</span><p>And there is of course one other thing you need: to be lucky. Luck
is always a factor, but it's even more of a factor when you're
working on your own rather than as part of an organization. And
though there are some valid aphorisms about luck being where
preparedness meets opportunity and so on, there's also a component
of true chance that you can't do anything about. The solution is
to take multiple shots. Which is another reason to start taking
risks early.</p><p>
The best example of a field with superlinear returns is probably
science. It has exponential growth, in the form of learning, combined
with thresholds at the extreme edge of performance — literally at
the limits of knowledge.</p><p>The result has been a level of inequality in scientific discovery
that makes the wealth inequality of even the most stratified societies
seem mild by comparison. Newton's discoveries were arguably greater
than all his contemporaries' combined.
</p><span color="#dddddd">[<a href="#f11n"><span color="#dddddd">11</span></a>]</span><p>This point may seem obvious, but it might be just as well to spell
it out. Superlinear returns imply inequality. The steeper the return
curve, the greater the variation in outcomes.</p><p>In fact, the correlation between superlinear returns and inequality
is so strong that it yields another heuristic for finding work of
this type: look for fields where a few big winners outperform
everyone else. A kind of work where everyone does about the same
is unlikely to be one with superlinear returns.</p><p>What are fields where a few big winners outperform everyone else?
Here are some obvious ones: sports, politics, art, music, acting,
directing, writing, math, science, starting companies, and investing.
In sports the phenomenon is due to externally imposed thresholds;
you only need to be a few percent faster to win every race. In
politics, power grows much as it did in the days of emperors. And
in some of the other fields (including politics) success is driven
largely by fame, which has its own source of superlinear growth.
But when we exclude sports and politics and the effects of fame, a
remarkable pattern emerges: the remaining list is exactly the same
as the list of fields where you have to be </p><a href="http://paulgraham.com/think.html"><u>independent-minded</u></a> to
succeed — where your ideas have to be not just correct, but novel
as well.
<span color="#dddddd">[<a href="#f12n"><span color="#dddddd">12</span></a>]</span><p>This is obviously the case in science. You can't publish papers
saying things that other people have already said. But it's just
as true in investing, for example. It's only useful to believe that
a company will do well if most other investors don't; if everyone
else thinks the company will do well, then its stock price will
already reflect that, and there's no room to make money.</p><p>What else can we learn from these fields? In all of them you have
to put in the initial effort. Superlinear returns seem small at
first. <i>At this rate,</i> you find yourself thinking, <i>I'll never get
anywhere.</i> But because the reward curve rises so steeply at the far
end, it's worth taking extraordinary measures to get there.</p><p>In the startup world, the name for this principle is "do things
that don't scale." If you pay a ridiculous amount of attention to
your tiny initial set of customers, ideally you'll kick off exponential
growth by word of mouth. But this same principle applies to anything
that grows exponentially. Learning, for example. When you first
start learning something, you feel lost. But it's worth making the
initial effort to get a toehold, because the more you learn, the
easier it will get.</p><p>There's another more subtle lesson in the list of fields with
superlinear returns: not to equate work with a job. For most of the
20th century the two were identical for nearly everyone, and as a
result we've inherited a custom that equates productivity with
having a job. Even now to most people the phrase "your work" means
their job. But to a writer or artist or scientist it means whatever
they're currently studying or creating. For someone like that, their
work is something they carry with them from job to job, if they
have jobs at all. It may be done for an employer, but it's part of
their portfolio.</p><p>
It's an intimidating prospect to enter a field where a few big
winners outperform everyone else. Some people do this deliberately,
but you don't need to. If you have sufficient natural ability and
you follow your curiosity sufficiently far, you'll end up in one.
Your curiosity won't let you be interested in boring questions, and
interesting questions tend to create fields with superlinear returns
if they're not already part of one.</p><p>The territory of superlinear returns is by no means static. Indeed,
the most extreme returns come from expanding it. So while both
ambition and curiosity can get you into this territory, curiosity
may be the more powerful of the two. Ambition tends to make you
climb existing peaks, but if you stick close enough to an interesting
enough question, it may grow into a mountain beneath you.</p><p><b>Notes</b></p><p>There's a limit to how sharply you can distinguish between effort,
performance, and return, because they're not sharply distinguished
in fact. What counts as return to one person might be performance
to another. But though the borders of these concepts are blurry,
they're not meaningless. I've tried to write about them as precisely
as I could without crossing into error.</p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
Evolution itself is probably the most pervasive example of
superlinear returns for performance. But this is hard for us to
empathize with because we're not the recipients; we're the returns.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
Knowledge did of course have a practical effect before the
Industrial Revolution. The development of agriculture changed human
life completely. But this kind of change was the result of broad,
gradual improvements in technique, not the discoveries of a few
exceptionally learned people.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
It's not mathematically correct to describe a step function as
superlinear, but a step function starting from zero works like a
superlinear function when it describes the reward curve for effort
by a rational actor. If it starts at zero then the part before the
step is below any linearly increasing return, and the part after
the step must be above the necessary return at that point or no one
would bother.<p>[</p><a name="f4n"><span color="#000000">4</span></a>]
Seeking competition could be a good heuristic in the sense that
some people find it motivating. It's also somewhat of a guide to
promising problems, because it's a sign that other people find them
promising. But it's a very imperfect sign: often there's a clamoring
crowd chasing some problem, and they all end up being trumped by
someone quietly working on another one.<p>[</p><a name="f5n"><span color="#000000">5</span></a>]
Not always, though. You have to be careful with this rule. When
something is popular despite being mediocre, there's often a hidden
reason why. Perhaps monopoly or regulation make it hard to compete.
Perhaps customers have bad taste or have broken procedures for
deciding what to buy. There are huge swathes of mediocre things
that exist for such reasons.<p>[</p><a name="f6n"><span color="#000000">6</span></a>]
In my twenties I wanted to be an <a href="http://paulgraham.com/worked.html"><u>artist</u></a> 
and even went to art
school to study painting. Mostly because I liked art, but a nontrivial
part of my motivation came from the fact that artists seemed least
at the mercy of organizations.<p>[</p><a name="f7n"><span color="#000000">7</span></a>]
In principle everyone is getting superlinear returns. Learning
compounds, and everyone learns in the course of their life. But in
practice few push this kind of everyday learning to the point where
the return curve gets really steep.<p>[</p><a name="f8n"><span color="#000000">8</span></a>]
It's unclear exactly what advocates of "equity" mean by it.
They seem to disagree among themselves. But whatever they mean is
probably at odds with a world in which institutions have less power
to control outcomes, and a handful of outliers do much better than
everyone else.<p>It may seem like bad luck for this concept that it arose at just
the moment when the world was shifting in the opposite direction,
but I don't think this was a coincidence. I think one reason it
arose now is because its adherents feel threatened by rapidly
increasing variation in performance.</p><p>[</p><a name="f9n"><span color="#000000">9</span></a>]
Corollary: Parents who pressure their kids to work on something
prestigious, like medicine, even though they have no interest in
it, will be hosing them even more than they have in the past.<p>[</p><a name="f10n"><span color="#000000">10</span></a>]
The original version of this paragraph was the first draft of
"<a href="http://paulgraham.com/greatwork.html"><u>How to Do Great Work</u></a>." 
As soon as I wrote it I realized it was a more important topic than superlinear
returns, so I paused the present essay to expand this paragraph into its
own. Practically nothing remains of the original version, because
after I finished "How to Do Great Work" I rewrote it based on that.<p>[</p><a name="f11n"><span color="#000000">11</span></a>]
Before the Industrial Revolution, people who got rich usually
did it like emperors: capturing some resource made them more powerful
and enabled them to capture more. Now it can be done like a scientist,
by discovering or building something uniquely valuable. Most people
who get rich use a mix of the old and the new ways, but in the most
advanced economies the ratio has <a href="http://paulgraham.com/richnow.html"><u>shifted dramatically</u></a> toward discovery
just in the last half century.<p>[</p><a name="f12n"><span color="#000000">12</span></a>]
It's not surprising that conventional-minded people would
dislike inequality if independent-mindedness is one of the biggest
drivers of it. But it's not simply that they don't want anyone to
have what they can't. The conventional-minded literally can't imagine
what it's like to have novel ideas. So the whole phenomenon of great
variation in performance seems unnatural to them, and when they
encounter it they assume it must be due to cheating or to some
malign external influence.<span color="888888"><b>Thanks</b> 
to Trevor Blackwell, Patrick Collison, Tyler Cowen,
Jessica Livingston, Harj Taggar, and Garry Tan for reading drafts
of this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ishkur's Guide to Electronic Music (446 pts)]]></title>
            <link>https://music.ishkur.com/</link>
            <guid>37919241</guid>
            <pubDate>Tue, 17 Oct 2023 18:15:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://music.ishkur.com/">https://music.ishkur.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37919241">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Llemma: An Open Language Model for Mathematics (228 pts)]]></title>
            <link>https://arxiv.org/abs/2310.10631</link>
            <guid>37918327</guid>
            <pubDate>Tue, 17 Oct 2023 17:19:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.10631">https://arxiv.org/abs/2310.10631</a>, See on <a href="https://news.ycombinator.com/item?id=37918327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2310.10631.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the MATH benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Zhangir Azerbayev Mr [<a href="https://arxiv.org/show-email/fa9065f2/2310.10631">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 16 Oct 2023 17:54:07 UTC (386 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tech CEO Sentenced to 5 Years in IP Address Scheme (380 pts)]]></title>
            <link>https://krebsonsecurity.com/2023/10/tech-ceo-sentenced-to-5-years-in-ip-address-scheme/</link>
            <guid>37917597</guid>
            <pubDate>Tue, 17 Oct 2023 16:28:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2023/10/tech-ceo-sentenced-to-5-years-in-ip-address-scheme/">https://krebsonsecurity.com/2023/10/tech-ceo-sentenced-to-5-years-in-ip-address-scheme/</a>, See on <a href="https://news.ycombinator.com/item?id=37917597">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p><strong>Amir Golestan</strong>, the 40-year-old CEO of the Charleston, S.C. based technology company <strong>Micfo LLC</strong>, has been sentenced to five years in prison for wire fraud. Golestan’s sentencing comes nearly two years after he pleaded guilty to using an elaborate network of phony companies to secure more than 735,000 Internet Protocol (IP) addresses from the <strong>American Registry for Internet Numbers</strong> (ARIN), the nonprofit which oversees IP addresses assigned to entities in the U.S., Canada, and parts of the Caribbean.</p>
<div id="attachment_48758"><p><img aria-describedby="caption-attachment-48758" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2019/08/amirgolestan-image.png" alt="" width="749" height="476"></p><p id="caption-attachment-48758">Amir Golestan, the former CEO of Micfo.</p></div>
<p>In 2018, ARIN sued Golestan and Micfo, alleging they had obtained hundreds of thousands of IP addresses under false pretenses. ARIN and Micfo settled that dispute in arbitration, with Micfo returning most of the addresses that it hadn’t already sold.</p>
<p>ARIN’s civil case caught the attention of federal prosecutors in South Carolina, who in May 2019 <a href="https://krebsonsecurity.com/2019/05/a-tough-week-for-ip-address-scammers/" target="_blank" rel="noopener">filed criminal wire fraud charges against Golestan</a>, alleging he’d orchestrated a network of shell companies and fake identities to prevent ARIN from knowing the addresses were all going to the same buyer.</p>
<p>Prosecutors showed that each of those shell companies involved the production of notarized affidavits in the names of people who didn’t exist. As a result, the government was able to charge Golestan with 20 counts of wire fraud — one for each payment made by the phony companies that bought the IP addresses from ARIN.</p>
<p>Golestan initially sought to fight those charges. But on just the second day of his trial in November 2021, Golestan changed his mind and <a href="https://krebsonsecurity.com/2021/11/tech-ceo-pleads-to-wire-fraud-in-ip-address-scheme/" target="_blank" rel="noopener">pleaded guilty to 20 counts of wire fraud</a> in connection with the phantom companies he used to secure the IP addresses. Prosecutors estimated those addresses were valued at between $10 million and $14 million.<span id="more-65335"></span></p>
<p>ARIN says the 5-year sentence handed down by the South Carolina judge “sends an important message of deterrence to other parties contemplating fraudulent schemes to obtain or transfer Internet resources.”</p>
<p>“Those who seek to defraud ARIN (or other Regional Internet Registries) are subject to costly and serious civil litigation, criminal charges, and, ultimately, a lengthy term of incarceration,” reads <a href="https://www.arin.net/blog/2023/10/16/micfo-golestan-sentencing/" target="_blank" rel="noopener">a statement</a> from ARIN on Golestan’s sentencing.</p>
<p>By 2013, a number of Micfo’s customers had landed on the radar of <a href="https://www.spamhaus.org/" target="_blank" rel="noopener">Spamhaus</a>, a group that many network operators rely upon to stem the tide of junk email. Shortly after Spamhaus started blocking Micfo’s IP address ranges, Micfo shifted gears and began reselling IP addresses mainly to companies marketing “virtual private networking” or VPN services that help customers hide their real IP addresses online.</p>
<p>Golestan did not respond to a request for comment. But in a 2020 interview with KrebsOnSecurity, Golestan claimed that Micfo was at one point responsible for brokering roughly 40 percent of the IP addresses used by the world’s largest VPN providers. Throughout that conversation, Golestan maintained his innocence, even as he explained that the creation of the phony companies was necessary to prevent entities like Spamhaus from interfering with his business going forward.</p>
<p>There are fewer than four billion so-called “Internet Protocol version 4” or IPv4 addresses available for use, but the vast majority of them have already been allocated. The global dearth of available IP addresses has turned them into a commodity wherein each IPv4 address can fetch between $15-$25 on the open market.</p>
<p>This has led to boom times for those engaged in the acquisition and sale of IP address blocks, but it has likewise emboldened those who specialize in&nbsp;<a href="https://krebsonsecurity.com/2019/12/the-great-50m-african-ip-address-heist/" target="_blank" rel="noopener">absconding with</a>&nbsp;and&nbsp;<a href="https://krebsonsecurity.com/2019/09/feds-allege-adconion-employees-hijacked-ip-addresses-for-spamming/" target="_blank" rel="noopener">spamming from dormant IP address blocks</a>&nbsp;without permission from the rightful owners.</p>
<p>The U.S Department of Justice says Golestan will serve 60 months in prison, followed by a 2-year term of court-ordered supervision. The Micfo CEO also was ordered to pay nearly $77,000 in restitution to ARIN for its work in assisting federal prosecutors.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Goatse to Stop App Theft (633 pts)]]></title>
            <link>https://joshcsimmons.com/post/H4sIAAAAAAAA%2F0xVTY%2FjNgy951c8TA%2BzC0yCQQ9F0dte2gYosIedbdEjbdG2dmRRFakE7q8vKCebXvIBySTfB59%2FwFeNecZvQqYME3wxKfhUCt4WnuxwOKPyyNnShqHFZCAMVa7K9TiQcsBVasBMK%2BMabcG6YaqRc1CMlBIHfPmnX%2Fmg%2Ffs0yvrxhPPzilKlBe%2BptMEWMlz5%2BcIYmDNoSH2elWI2ihkENaawYa7SCmRCoJg20GjxwmjKVSEXrrCFUUgNP2GVbItCKlQQWEs0RhZDEIdNeUNlSqBw4WrRuTgdDn%2B2ZK2y4hpTAl84o8TxHWRYJbAatI0jq0JNamQ9HQ5%2FsxrXQBsks0%2B3bhglJRqkkklVzCKz8%2FG0E%2FEEyh39EhXaaqlR%2BcWHr4yrf5hk9UpTrGrHQjOjsrZkemercn62jvdBLoI4ZycXUBkajRVUGU9dJJrnyrNP9HQ767UWUcMmrYJKQcwaQ0dBGfHX6g%2Bq7Ddt4Q0j5S6HM4fqDDXGVGXda5QqoY12OhzeHN1KgeG981xjF8jLGnSRlgIWujCOXZaBR2rKd89EBWEkXTDKFUdcGUEccm0ZFBSSd%2FQuq9O5n670zi49uxdlRbQXRHtWfGtqmKRiahlHDO3RMRqu5O0KqUbJjuEbj7a7%2BmbpF6isbIt7p7S694zZOFuUTCl5Q%2B6%2BLYk2%2FHV%2B%2B%2F3z1zcf9YSzT0Azxazm7mBbRNF7Br5wksL1rr%2FrNVDO7mnvUaS0om7Ful39xgnnCee%2BksFFolJe%2FD%2BnyBf%2BH7kcvSIGl4fZN%2BFxNjBaOU5VsoEGaYbrTWFoG3SssTguf6i0Oi6kjFLjyC7Mh27fhXMXrhXllFz9jycPjdEbuBY0uJOU2TnrO%2BFekMwW%2F2UnD%2BYWudLW3cJYyXevo66sRbLGHgWddBMEwfVhm54VJqAQ3CrStYDy2Gq0DUVSHDe%2FsIfC7MSB1j7zrZOK%2B92zZYd%2FRuAxBg73bqSonMMtWZhq2vDj6%2Burdulr5k7o%2BI64%2Bo7esrT7hpCdrpVV%2FUhb4RrXIh6cPauiOQUl0djXzRv0BZzuKxDYeLxvvN%2F2ro%2B1dLINC%2BnOxCN75spkHlU0Lm6JlbM93PaLY0vxwsfAJckGwuq%2BvzDmffwdizNrSOxp%2BvMtWW6z0B4%2Ba8w%2BxB%2Fsvok%2BBgiJVX01xQ2Bo8PxH%2B7q1t83j1hxjqP2baF9j3ek6sU9TPRlT2Bf28RztLiSsRvSadSXXrl7IUs3QJV0fw%2BQfbfE0cnz2BoXyjM7LE9%2Fiyuf8DkzPLrvPpAJSeTdJ43ZObiPu3db47x4cny%2F1IvBU6By2hDiNHk2G95j7tWKVKN0OvwHAAD%2F%2FwMASc5Y2XAHAAA%3D</link>
            <guid>37917012</guid>
            <pubDate>Tue, 17 Oct 2023 15:51:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joshcsimmons.com/post/H4sIAAAAAAAA%2F0xVTY%2FjNgy951c8TA%2BzC0yCQQ9F0dte2gYosIedbdEjbdG2dmRRFakE7q8vKCebXvIBySTfB59%2FwFeNecZvQqYME3wxKfhUCt4WnuxwOKPyyNnShqHFZCAMVa7K9TiQcsBVasBMK%2BMabcG6YaqRc1CMlBIHfPmnX%2Fmg%2Ffs0yvrxhPPzilKlBe%2BptMEWMlz5%2BcIYmDNoSH2elWI2ihkENaawYa7SCmRCoJg20GjxwmjKVSEXrrCFUUgNP2GVbItCKlQQWEs0RhZDEIdNeUNlSqBw4WrRuTgdDn%2B2ZK2y4hpTAl84o8TxHWRYJbAatI0jq0JNamQ9HQ5%2FsxrXQBsks0%2B3bhglJRqkkklVzCKz8%2FG0E%2FEEyh39EhXaaqlR%2BcWHr4yrf5hk9UpTrGrHQjOjsrZkemercn62jvdBLoI4ZycXUBkajRVUGU9dJJrnyrNP9HQ767UWUcMmrYJKQcwaQ0dBGfHX6g%2Bq7Ddt4Q0j5S6HM4fqDDXGVGXda5QqoY12OhzeHN1KgeG981xjF8jLGnSRlgIWujCOXZaBR2rKd89EBWEkXTDKFUdcGUEccm0ZFBSSd%2FQuq9O5n670zi49uxdlRbQXRHtWfGtqmKRiahlHDO3RMRqu5O0KqUbJjuEbj7a7%2BmbpF6isbIt7p7S694zZOFuUTCl5Q%2B6%2BLYk2%2FHV%2B%2B%2F3z1zcf9YSzT0Azxazm7mBbRNF7Br5wksL1rr%2FrNVDO7mnvUaS0om7Ful39xgnnCee%2BksFFolJe%2FD%2BnyBf%2BH7kcvSIGl4fZN%2BFxNjBaOU5VsoEGaYbrTWFoG3SssTguf6i0Oi6kjFLjyC7Mh27fhXMXrhXllFz9jycPjdEbuBY0uJOU2TnrO%2BFekMwW%2F2UnD%2BYWudLW3cJYyXevo66sRbLGHgWddBMEwfVhm54VJqAQ3CrStYDy2Gq0DUVSHDe%2FsIfC7MSB1j7zrZOK%2B92zZYd%2FRuAxBg73bqSonMMtWZhq2vDj6%2Burdulr5k7o%2BI64%2Bo7esrT7hpCdrpVV%2FUhb4RrXIh6cPauiOQUl0djXzRv0BZzuKxDYeLxvvN%2F2ro%2B1dLINC%2BnOxCN75spkHlU0Lm6JlbM93PaLY0vxwsfAJckGwuq%2BvzDmffwdizNrSOxp%2BvMtWW6z0B4%2Ba8w%2BxB%2Fsvok%2BBgiJVX01xQ2Bo8PxH%2B7q1t83j1hxjqP2baF9j3ek6sU9TPRlT2Bf28RztLiSsRvSadSXXrl7IUs3QJV0fw%2BQfbfE0cnz2BoXyjM7LE9%2Fiyuf8DkzPLrvPpAJSeTdJ43ZObiPu3db47x4cny%2F1IvBU6By2hDiNHk2G95j7tWKVKN0OvwHAAD%2F%2FwMASc5Y2XAHAAA%3D">https://joshcsimmons.com/post/H4sIAAAAAAAA%2F0xVTY%2FjNgy951c8TA%2BzC0yCQQ9F0dte2gYosIedbdEjbdG2dmRRFakE7q8vKCebXvIBySTfB59%2FwFeNecZvQqYME3wxKfhUCt4WnuxwOKPyyNnShqHFZCAMVa7K9TiQcsBVasBMK%2BMabcG6YaqRc1CMlBIHfPmnX%2Fmg%2Ffs0yvrxhPPzilKlBe%2BptMEWMlz5%2BcIYmDNoSH2elWI2ihkENaawYa7SCmRCoJg20GjxwmjKVSEXrrCFUUgNP2GVbItCKlQQWEs0RhZDEIdNeUNlSqBw4WrRuTgdDn%2B2ZK2y4hpTAl84o8TxHWRYJbAatI0jq0JNamQ9HQ5%2FsxrXQBsks0%2B3bhglJRqkkklVzCKz8%2FG0E%2FEEyh39EhXaaqlR%2BcWHr4yrf5hk9UpTrGrHQjOjsrZkemercn62jvdBLoI4ZycXUBkajRVUGU9dJJrnyrNP9HQ767UWUcMmrYJKQcwaQ0dBGfHX6g%2Bq7Ddt4Q0j5S6HM4fqDDXGVGXda5QqoY12OhzeHN1KgeG981xjF8jLGnSRlgIWujCOXZaBR2rKd89EBWEkXTDKFUdcGUEccm0ZFBSSd%2FQuq9O5n670zi49uxdlRbQXRHtWfGtqmKRiahlHDO3RMRqu5O0KqUbJjuEbj7a7%2BmbpF6isbIt7p7S694zZOFuUTCl5Q%2B6%2BLYk2%2FHV%2B%2B%2F3z1zcf9YSzT0Azxazm7mBbRNF7Br5wksL1rr%2FrNVDO7mnvUaS0om7Ful39xgnnCee%2BksFFolJe%2FD%2BnyBf%2BH7kcvSIGl4fZN%2BFxNjBaOU5VsoEGaYbrTWFoG3SssTguf6i0Oi6kjFLjyC7Mh27fhXMXrhXllFz9jycPjdEbuBY0uJOU2TnrO%2BFekMwW%2F2UnD%2BYWudLW3cJYyXevo66sRbLGHgWddBMEwfVhm54VJqAQ3CrStYDy2Gq0DUVSHDe%2FsIfC7MSB1j7zrZOK%2B92zZYd%2FRuAxBg73bqSonMMtWZhq2vDj6%2Burdulr5k7o%2BI64%2Bo7esrT7hpCdrpVV%2FUhb4RrXIh6cPauiOQUl0djXzRv0BZzuKxDYeLxvvN%2F2ro%2B1dLINC%2BnOxCN75spkHlU0Lm6JlbM93PaLY0vxwsfAJckGwuq%2BvzDmffwdizNrSOxp%2BvMtWW6z0B4%2Ba8w%2BxB%2Fsvok%2BBgiJVX01xQ2Bo8PxH%2B7q1t83j1hxjqP2baF9j3ek6sU9TPRlT2Bf28RztLiSsRvSadSXXrl7IUs3QJV0fw%2BQfbfE0cnz2BoXyjM7LE9%2Fiyuf8DkzPLrvPpAJSeTdJ43ZObiPu3db47x4cny%2F1IvBU6By2hDiNHk2G95j7tWKVKN0OvwHAAD%2F%2FwMASc5Y2XAHAAA%3D</a>, See on <a href="https://news.ycombinator.com/item?id=37917012">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>I recently built a browser-based word game with my friends called Sqword (sqword.com). I'm proud to say that we've been able to maintain a steady group of daily active users over the past 6 months or so despite not doing any real advertising.</p>
<p>Vultures will even pick at modest success stories.</p>
<p>Yesterday one of my collaborators googled "sqword" and to his surprise, there were tons of first-page results that weren't the sqword.com domain. These sites are "game aggregator" sites that host your app inside of an iFrame so that they can steal ad revenue from your product.</p>
<p>This made me angrier than it should have - not because Sqword is a cash cow - we don't run ads on the site and don't make money from it, it's just for fun - but because it was a passion project with friends, something pure and intentionally free to play WITHOUT ads. It's against my ethos as a developer, there are banners and popups everywhere. If I build an app, I believe it should either be free or it should be up-front about what the subscription or purchase price is (and then not upsell you).</p>
<p>I couldn't abide seeing my code monetized in this way.</p>
<p>The mature and responsible thing to do would have been to add a content security policy to the page. I am not mature so instead what I decided to do was render the early 2000s internet shock image Goatse with a nice message superimposed over it in place of the app if Sqword detects that it is in an iFrame.</p>
<p>It has been one of my greatest achievements as a dev: to live-deploy a massive goatse image to at least 8 domains that aren't mine.</p>
<p>Let this be a lesson to you - if you are using an iFrame to display a site that isn't yours, even for legitimate purposes, you have no control over that content - it can change at any time. One day instead of looking into an iFrame, you might be looking at an entirely different kind of portal.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Frasier Fantasy: A Game Boy Color game based on the 'Fraiser' TV series (466 pts)]]></title>
            <link>https://edward-la-barbera.itch.io/frasier-fantasy</link>
            <guid>37916855</guid>
            <pubDate>Tue, 17 Oct 2023 15:40:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://edward-la-barbera.itch.io/frasier-fantasy">https://edward-la-barbera.itch.io/frasier-fantasy</a>, See on <a href="https://news.ycombinator.com/item?id=37916855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Experience the thrilling adventure of living an evening as Dr. Frasier Crane!<br></em></p>
<p><em>FIGHT for your antique silverware!&nbsp;</em></p>
<p><em>SNEAK through the live-in-help's bedroom!</em></p>
<p><em>ATTEMPT to throw</em><em></em><em> the ultimate dinner party!</em></p>
<p><em>Frasier Fantasy is a loving tribute to the show, "Frasier," in turn-based RPG form. Filled with Easter Eggs and callbacks, this is the game for anyone wondering if Eddie ever blinked first.</em></p>
<p><strong>Controls:&nbsp;</strong></p>
<p><strong>Arrow Keys</strong> or <strong>WASD</strong> to move</p>
<p>"<strong>J</strong>" and "<strong>K</strong>" are&nbsp;A and B, respectively</p>
<p>"<strong>Return</strong>" is START</p>
<p>"<strong>Shift</strong>" is SELECT</p>

<p>Special thanks:</p>
<p><strong>StephenMauriceGraham</strong>: <a href="https://stephenmauricegraham.bigcartel.com/" referrerpolicy="origin" rel="nofollow noopener">Original title concept</a></p>
<p><strong>Yogi (Tronimal):</strong> for&nbsp;<a href="https://yogi-tronimal.itch.io/gbfx">SFX Pack</a></p>
<p><strong>Michael Discenza:</strong>&nbsp;<a href="https://unsplash.com/@mdisc" referrerpolicy="origin" rel="nofollow noopener">Seattle Backdrop</a><strong><strong></strong></strong><span></span></p>
<p><a href="https://twitter.com/TheHeroicEffort" referrerpolicy="origin" rel="nofollow noopener">Heroic_Effort</a>: Banner</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Billing Engines Don't Solve Pricing Problems (132 pts)]]></title>
            <link>https://www.tier.run/blog/pricing-engine-vs-billing-engine</link>
            <guid>37916840</guid>
            <pubDate>Tue, 17 Oct 2023 15:39:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tier.run/blog/pricing-engine-vs-billing-engine">https://www.tier.run/blog/pricing-engine-vs-billing-engine</a>, See on <a href="https://news.ycombinator.com/item?id=37916840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><div><p><img loading="lazy" width="20" height="20" decoding="async" data-nimg="1" srcset="https://www.tier.run/_next/image?url=%2Fimages%2Fauthors%2Fissac.avif&amp;w=32&amp;q=75 1x, https://www.tier.run/_next/image?url=%2Fimages%2Fauthors%2Fissac.avif&amp;w=48&amp;q=75 2x" src="https://www.tier.run/_next/image?url=%2Fimages%2Fauthors%2Fissac.avif&amp;w=48&amp;q=75"></p><p><span>Isaac Schlueter</span></p></div><p>Apr 26, 2023</p><p>4 min read</p></div><p>One lesson we've learned talking to companies on their pricing journeys (and from our own in the past) is the importance of separating the concepts of "Billing Engine" and "Pricing Engine".</p>
<p>It's one of those things that feels obvious when you see it, but until you do, it can be hard to grasp why it's important. The result is that we end up with the wrong abstraction trying to do double duty.</p>
<p>Just as you probably wouldn't use a relational database as a message bus, mixing the concepts of Pricing and Billing can bring disaster.</p>

<p>Most companies approach their pricing implementation in the following way:</p>
<ol>
<li>Choose a billing engine (Stripe, Lago, etc.)</li>
<li>Have a bunch of meetings where they argue about the best pricing model (and hopefully write it down somewhere!)</li>
<li>Configure the billing engine with the model they decided on (or realize it's too complicated, and go back to step 2).</li>
<li>Store all the information that the billing engine needs in their application database (identifiers for prices, products, customer IDs associated with each user, etc.), and add the required reporting logic in the application in the appropriate places.</li>
<li>Pray that no one ever has to touch it again. (Or failing that, hope you've got a new job somewhere else before that happens.)</li>
</ol>
<p>Where does the pricing model live? Typically, it's smeared across a variety of loosely connected components, some of which store it as implicit assumptions.</p>
<ul>
<li>The billing engine</li>
<li>The application code</li>
<li>The CFO's spreadsheets</li>
<li>The <code>/pricing</code> page</li>
<li>The terms and conditions of various customer contracts</li>
<li>Feature requests from PMs and PMMs who want to make changes</li>
<li>The fallible human brains of everyone on the team</li>
</ul>

<p>A lot of value can be unlocked by separating these two abstractions.</p>
<p>A <strong>Billing Engine</strong> is the component in the stack that <em>bills customers</em>. Its "one job" is to send an invoice at the right time, in the right amount, to the right buyer.</p>
<p>To do this, it needs to know some information about the customer, what thing they bought, the price they should be charged for it, and in the case of metered billing, the amount of that thing that they consumed.</p>
<p>A <strong>Pricing Engine</strong> is the component in the stack that <em>manages and implements the pricing model</em>. You can think of it as "the thing that does <a href="https://priceops.org/">PriceOps</a>". It knows what the various pricing plans are, and where they live in the Billing Engine, and thus can present a clean API surface for application code to create subscriptions and report usage.</p>
<p>To do its job (and prevent other components from trying to take over!) it needs to store the pricing model itself, and present a clean abstraction to the application code, billing engine, and all other technical and business components that need access to price information.</p>
<p>And perhaps most importantly, it must support making <em>changes</em> to the pricing model, without its abstractions leaking out to consumers.</p>

<p>The most tangible immediate benefit of a comprehensive Pricing Engine is that it can simplify the process of setting up a Billing Engine, and reduce the amount of billing-related metadata that needs to be tracked and managed by application code.</p>
<p>While this is enough of a reason to use it, it doesn't always <em>feel</em> like a huge win. Integrating with a whole new component in the stack feels like adding complexity in one place to maybe save it elsewhere. Even if it makes your code cleaner and simpler, it's not <em>that</em> bad, right? Isn't "having too many customers and complicated deals" sort of a problem I can worry about when I'm rich and successful?</p>
<p>However, the trouble with this line of thinking (which all of us at Tier have learned through painful expensive experience) is that it can be very difficult for a company to <em>become</em> successful if they cannot easily iterate on their approach to pricing and packaging.</p>
<p><strong>Streamlining pricing with a comprehensive Pricing Engine lets everyone focus on their specialty.</strong> This unlocks growth that would otherwise be lost to inefficient processes.</p>

<p>What we've found is that the most experienced and insightful practitioners in this space follow exactly this kind of approach. That's how the concept of PriceOps was born.</p>
<p>Tier is a comprehensive Pricing Engine, which drives your billing engine and application code from a single source of pricing model truth, so that everything in your company can work in concert, even as your business changes and grows.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Patlabor 2, the Movie: realistic portrayal of modern aerial combat (210 pts)]]></title>
            <link>https://taskandpurpose.com/culture/realistic-aerial-combat-movie-patlabor-2/</link>
            <guid>37916306</guid>
            <pubDate>Tue, 17 Oct 2023 15:06:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taskandpurpose.com/culture/realistic-aerial-combat-movie-patlabor-2/">https://taskandpurpose.com/culture/realistic-aerial-combat-movie-patlabor-2/</a>, See on <a href="https://news.ycombinator.com/item?id=37916306">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="251970" id="ArticlesWrap">
      
  
  <article>
          

      <header>
        
        
        
        <section>
                    
          <p>
  Through rigorous attention to technical detail and thorough authenticity, this minor scene from an anime movie gave viewers the most accurate portrayal of modern aerial combat ever seen.
</p>

<p>
                    
                              <a href="https://taskandpurpose.com/author/matt-sampson/" rel="author">
            Matt Sampson
          </a>
                
              |
    <span>
    <time datetime="2022-03-04T14:42:00-05:00">
    Published Mar 4, 2022 2:42 PM EST
    </time>
  </span>
</p>

        </section>
      </header>
    
          <figure>
                    <p><img width="1440" height="779" src="https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131629_VRV.jpg?auto=webp&amp;width=1440&amp;height=779.21424829754" alt="(Screenshot via “Patlabor 2: The Movie&quot;)" decoding="async" srcset="https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131629_VRV.jpg 1909w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131629_VRV-300x162.jpg 300w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131629_VRV-1024x554.jpg 1024w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131629_VRV-768x416.jpg 768w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131629_VRV-1536x831.jpg 1536w" sizes="(max-width: 1440px) 100vw, 1440px" data-dimension="landscape"></p><figcaption>(Screenshot via “Patlabor 2: The Movie").</figcaption></figure>    
    <section>
                  
                      <section>
  <span>SHARE</span>
  <ul>
    <li>
      <a data-href="https://twitter.com/intent/tweet?text=Watch+the+most+realistic+movie+portrayal+of+modern+aerial+combat+ever+made&amp;url=https%3A%2F%2Ftaskandpurpose.com%2Fculture%2Frealistic-aerial-combat-movie-patlabor-2%2F">
        <i></i>
      </a>
    </li>
    <li>
      <a data-href="http://www.facebook.com/sharer.php?u=https%3A%2F%2Ftaskandpurpose.com%2Fculture%2Frealistic-aerial-combat-movie-patlabor-2%2F">
        <i></i>
      </a>
    </li>
    <li>
      <a data-href="https://www.pinterest.com/pin/create/button/?url=https%3A%2F%2Ftaskandpurpose.com%2Fculture%2Frealistic-aerial-combat-movie-patlabor-2%2F&amp;media=https%3A%2F%2Ftaskandpurpose.com%2Fuploads%2F2022%2F03%2F04%2FScreenshot_20210925-131629_VRV.jpg%3Fauto%3Dwebp&amp;description=Through+rigorous+attention+to+technical+detail+and+thorough+authenticity%2C+this+minor+scene+from+an+anime+movie+gave+viewers+the+most+accurate+portrayal+of+modern+aerial+combat+ever+seen.">
        <i></i>
      </a>
    </li>
    <li>
      <a data-href="mailto:?subject=Watch+the+most+realistic+movie+portrayal+of+modern+aerial+combat+ever+made&amp;body=https%3A%2F%2Ftaskandpurpose.com%2Fculture%2Frealistic-aerial-combat-movie-patlabor-2%2F">
        <i></i>
      </a>
    </li>
  </ul>
</section>
                  
        <section id="incArticle">
          
<p><em>Welcome to a </em><em>That One Scene</em><em>, a semi-regular series in which Task &amp; Purpose writers wax nostalgic about that one scene from a beloved movie.</em></p>



<p>Hollywood has attempted, time and again with poor results, to portray what happens when an unidentified or unauthorized aircraft or missile threat penetrates friendly airspace. “Top Gun” and “War Games” tried, but wound up giving us classic 1980s cheeseball cinema. There is a noticeable absence of films that capture the pulse-pounding chess game of ground-controlled interception (GCI) – a sensation that is only amplified when lives are on the line.&nbsp;</p>



<p>Enter “Patlabor 2: The Movie,” an obscure, contemplative anime film from Japanese director Mamouru Oshii of “Ghost In the Shell” fame. In between intricate artwork, a thrilling storyline about a plot to bring civil war to early 2000s Japan, and musings on the ethics of the application of military force, one scene stands out as the single most realistic portrayal of GCI ever put to film.&nbsp;</p>



<p>As tactical displays fill the screen and ominous music plays alongside frantic radio traffic, a scene unfolds that’s so technically dense and authentic, we at Task &amp; Purpose had to consult several subject matter experts to make sure we understood exactly what was going on.&nbsp;</p>



<figure><p>
<iframe loading="lazy" title="PATLABOR 2 拦截F 16（JSDF Intercepts Wyvern）" width="500" height="281" src="https://www.youtube.com/embed/JnOfNQ9VWo0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<p>The scene takes place in the winter of 2002 in Japan. A rogue F-16J aircraft fires a TV-guided missile — meaning a missile that uses a camera feed for steering — at the Tokyo Bay Bridge, destroying the middle section and throwing Japan into a state of fear not experienced since Curtis LeMay’s strategic bombing of the mainland during World War II.&nbsp;</p>



<p>Only days later, Fuchu Central Strategic Operations Center (SOC) detects a sortie of three more F-16Js, call sign “Wyvern,” this time armed with bombs, on a direct flight from Misawa Air Base to the heart of Tokyo. With only minutes to spare, and suspecting another attack, four <a target="_blank" href="https://www.youtube.com/watch?v=IhPhxWgpaC8&amp;t=108s">F-15 STOL/MTDs</a> — a highly maneuverable F-15 prototype — are scrambled to intercept on two separate paths in the hopes that one of the aircraft will make contact with the incoming bogies.&nbsp;</p>



<p>Fuchu officials guide the F-15s, call signs “Wizard” and “Priest,” to the incoming F-16Js. The F-15s attempt to make contact, but Wizard cannot see Wyvern or pick them up on radar, despite being nearly on top of them.</p>



<div><figure><img decoding="async" loading="lazy" src="https://taskandpurpose.com/uploads/2022/03/04/patlabor1.gif" alt="Entertainment photo" width="1024" height="600"><figcaption>(Gif via “Patlabor 2: The Movie”)</figcaption></figure></div>



<p>Wizard disappears in a flurry of radio interference, before transmitting via their transponder that they’d been shot down. Wyvern then pivots into a direct trajectory towards Tokyo central, dropping altitude and accelerating, as if making an attack run, and Priest is given clearance from Fuchu SOC to fire as soon as they make radar contact. In addition, Fuchu SOC alerts the Iruma Air Defense Artillery batteries to prepare to engage, now fully anticipating an airborne attack. Civilian air traffic controllers at Narita International Airport scramble to ensure that the incoming aircraft don’t harm passenger planes in holding patterns, further driving home the dire implications of this incursion.&nbsp;</p>



<p>Just as Priest prepares to fire, the interference clears, and the targeted aircraft reveal themselves to be Wizard flight, frantically asking for orders. Fuchu SOC immediately calls off the attack, bewildered that the airborne threat has suddenly disappeared, and recalls the interceptors back to base.&nbsp;</p>



<p>The entire attack was an elaborate ruse, a hack of the Fuchu SOC radar systems and jamming of their radio communications, in an attempt to cause the responding aircraft to engage each other. At the very least, the digital assailant showed the Japanese Air Self-Defense Force that they had the capability to infiltrate their systems and wreak havoc, sowing further doubt and terror among the ranks.</p>



<p>This scene is extremely dense, so we’re going to do a breakdown of exactly what the filmmakers got right, because the detail is as close to real life as it gets (despite the film being a cartoon). High-octane aerial combat movies like “Top Gun” and “Behind Enemy Lines” do not hold a candle to the precision and attention to detail we see in this film, not to mention the chest-thumping thrill ride of the action as it plays out.</p>



<p>When I interviewed our subject matter expert, a former Navy strike force analyst, he had this to say: “All of the brevity terms are used properly, nothing feels out of place like the typical Hollywood screenwriter trying to sound like the military by using terms they found on Google like a lot of films and shows. The Ground Control Intercept (GCI) depiction is exactly how that would play out (TREBOR vectors PRIEST and WIZARD into the target; the fighters are very reliant on the controllers view of the battlespace with only targeting capabilities with their radar). The radar screens aren’t the spinning ‘sonar blip’ bullshit you get in a lot of games, movies, and animation. It’s very true to the displays you actually see in a control tower, with the IFF/squawk codes identifying each aircraft or flight.”&nbsp;</p>



<p>So, with that in mind, let’s dive deeper into that one scene.</p>



<h3 id="h-the-technology">The technology</h3>



<p>The film uses period-accurate monochrome radar displays that refresh only when the radar beam makes another circuit. Tracked air assets are marked with their “squawk codes,” rather than plane names.&nbsp;</p>



<div><figure><img decoding="async" loading="lazy" src="https://taskandpurpose.com/uploads/2022/03/04/patlabor2.gif" alt="Entertainment photo" width="1024" height="579"><figcaption>(Gif via “Patlabor 2: The Movie”)</figcaption></figure></div>



<p>The choice of aircraft is another authentic touch. The F-15 STOL/MTD, was an F-15 variant designed in the 1980s to test the concept of thrust vectoring and super-mobility, and is one that few people aside from those who read <a target="_blank" href="https://www.janes.com/capabilities/defence-equipment-intelligence/air-combat-systems">Jane’s Fighting Planes</a> books would have known about in 1993.&nbsp;</p>



<p>The radios are harsh, muffled, and staticky, and the pilots’ breathing interrupts their dialogue, which is a <a target="_blank" href="https://taskandpurpose.com/tech-tactics/gulf-war-video-f-16-dodging-missiles/">very real thing.</a> The pilots have to be guided onto their targets due to the fact that features like <a target="_blank" href="https://www.aviationtoday.com/2018/09/04/f-35-data-fusion/">sensor data sharing between aircraft</a> were only in their infancy at the time of the film’s release, meaning the pilots had to manually steer their narrow-view onboard radar onto the target by taking verbal directions from the SOC, whose more powerful 360-degree radar was much better equipped for locating the general position of targets.&nbsp;</p>



<h3 id="h-the-dialogue">The dialogue</h3>



<div><figure><img decoding="async" loading="lazy" width="1024" height="527" src="https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131730_VRV-1024x527.jpg?auto=webp" alt="Entertainment photo" srcset="https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131730_VRV-1024x527.jpg 1024w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131730_VRV-300x155.jpg 300w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131730_VRV-768x396.jpg 768w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131730_VRV-1536x791.jpg 1536w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131730_VRV.jpg 1897w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>(Screenshot via “Patlabor 2: The Movie”)</figcaption></figure></div>



<p>While most movies get radio traffic wrong with amateurish phrases like “over and out” or “I repeat,” Patlabor characters not only use believable dialogue during radio transmissions, but also speak in heavily accented English.&nbsp;</p>



<p>This is a huge detail that most aviation films neglect, even ones that depict NATO allies, which often simply feature the pilots speaking their native language despite the fact that English is the universal language of air traffic communication. The pilots and air traffic controllers speak in measured, subdued tones, suggesting a high level of training and preparedness. Even the air battle manager and director speak to each other in a manner that, while grim, is still calm and businesslike, underscoring the fact that while the situation is quite precarious, shots have not yet been fired. This is contrasted with the excited, terrified shouts of the civilian air traffic controllers at Narita International Airport, which add to the tension of the scene.&nbsp;</p>



<p>The pilots and controllers give their headings in degrees magnetic, saying the numbers individually like “one-niner-zero” instead of “one-ninety,” and provide their altitude in angels (thousands of feet) which adds another layer of credibility. The terms used, such as “no joy” (no visual contact) “bogey dope” (request target heading, altitude, and airspeed) and “say again” as opposed to “repeat,” are spot on, preventing a good deal of cringe from those in the know.</p>



<h3 id="h-tactics-techniques-and-procedures">Tactics, techniques, and procedures</h3>



<div><figure><img decoding="async" loading="lazy" width="1024" height="550" src="https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131712_VRV-1024x550.jpg?auto=webp" alt="Entertainment photo" srcset="https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131712_VRV-1024x550.jpg 1024w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131712_VRV-300x161.jpg 300w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131712_VRV-768x413.jpg 768w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131712_VRV-1536x825.jpg 1536w, https://taskandpurpose.com/uploads/2022/03/04/Screenshot_20210925-131712_VRV.jpg 1906w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>(Screenshot via “Patlabor 2: The Movie”)</figcaption></figure></div>



<p>Contrast this scene with the hyped-up, Aqua Net-and-cocaine pacing of the air combat scenes of classics like “Top Gun,” and you’ll immediately see that this is a more measured, authentic approach to how air operations work. For starters, one of the biggest things that military aviation movies often neglect is that the airborne radars of fighter aircraft are very limited, only sweeping in a narrow ray in front of the aircraft to avoid microwaving the pilots and crew. It stands to reason that Wizard and Priest flights would be heavily dependent on the Fuchu Central SOC for guidance as to the general vicinity of the intruders, and the scene illustrates this beautifully.&nbsp;</p>



<p>The incoming aircraft are identified, radio hails are sent up, and when there’s no response, interceptors are launched. Once the aircraft checks in, the air traffic controllers give guidance, and the initial intercept time is revised while the pilots begin to search for the target visually and with their onboard targeting radar. The coordination is continuous, with Fuchu Central SOC feeding Wizard and Priest targeting data while trying to deconflict the situation on the ground, to no avail. When Wizard gets “shot down,” the squawk code “7700,” — the international code for “mayday,” or an airborne emergency – appears onscreen at their last known position.</p>



<h3 id="h-the-depiction-of-a-cyber-attack">The depiction of a cyber attack</h3>



<p>Cyberspace is an ever-growing domain of warfare on the modern battlefield, and concerns about its role in a conflict with a near-peer adversary are becoming more commonplace. This scene presents three forms of electronic warfare: GPS spoofing, hacking, and signal jamming. The culmination of this multi-pronged cyber attack is when two friendly aircraft come within seconds of firing on one another.&nbsp;</p>



<div><figure><img decoding="async" loading="lazy" src="https://taskandpurpose.com/uploads/2022/03/04/patlabor5.gif" alt="Entertainment photo" width="1024" height="575"><figcaption>(Gif via “Patlabor 2: The Movie”)</figcaption></figure></div>



<p>In the film, this is done to try to incite a civil war, but in real life, GPS spoofing has become so common that hackers sell kits for $300 to allow the user to send false GPS data. Iran has already made dubious claims that they have mounted <a target="_blank" href="https://www.csmonitor.com/World/Middle-East/2011/1215/Exclusive-Iran-hijacked-US-drone-says-Iranian-engineer">GPS spoofing attacks on U.S. air assets.</a> The scene demonstrates this when Wizard says “We had heavy jamming and now lost position,” indicating that their communications and their GPS systems were being tampered with. The producers of this film weren’t in possession of any classified information either, since GPS spoofing and jamming was something that even the Iraqis used during Operation Desert Storm in the hopes of defeating GPS-guided bombs aimed at Saddam’s palace.&nbsp;</p>



<p>Hacking is another daily reality in the modern world, and cyber attacks against various governments are now common shows of force. While it’s not officially known whether or not any tactical systems have been hacked, as revealed in this scene, the possibility of this happening is still greater than zero. Signal jamming, however, is one of the oldest electronic warfare tricks in the book, and involves flooding entire swaths of frequencies with signal noise, which not only forces the enemy to limit communications, but also makes decryption easier by reducing the number of usable frequencies to a select few. This scene accurately portrays electronic warfare when the adversary coordinates Wizard getting “shot down” on the hacked radar display with heavy signal jamming that prevents Fuchu SOC from making contact with them via radio or transponder, adding to the illusion of Wizard being killed, and preventing Priest from deconflicting the airspace once they make radar contact with what they think is the intruding Wyvern flight.</p>



<p>Overall, myself and our subject matter expert both agree that this scene is the most authentic portrayal of air operations ever put to film. Additionally, I interviewed several former military air traffic controllers, strike analysts, and aviators, and their opinion was unanimous: This is pretty dang good. It totally abstains from excessive showmanship, replacing spectacle with the terrifying feeling that something like this could really happen. It’s an outstanding example of how technical detail and thorough authenticity can turn a minor scene, whose only function is to move the storyline forward, into seven minutes of nail-biting suspense.</p>



<p><em>The opinions contained in this article are solely those of the author and the persons interviewed and do not represent the opinions of the Department of Defense or the United States Government</em></p>



<h2 id="h-what-s-new-on-task-purpose">What’s new on <em>Task &amp; Purpose</em></h2>



<ul><li><a target="_blank" href="https://taskandpurpose.com/news/ghost-kyiv/"><strong>The ‘Ghost of Kyiv’ is the first urban legend</strong></a><strong> of Russia’s invasion of Ukraine</strong></li><li><strong>Man calls into public radio with tips on </strong><a target="_blank" href="https://taskandpurpose.com/news/ukraine-molotov-cocktail-wnyc/"><strong>how to make Molotov cocktails in Ukraine</strong></a></li><li><a target="_blank" href="https://taskandpurpose.com/news/ukraine-russia-snake-island-last-stand/"><strong>‘Russian warship, go f–k yourself’</strong></a><strong> — Ukrainian troops make heroic last stand on Black Sea island</strong></li><li><strong>The Navy is moving ahead with court-martial of a </strong><a target="_blank" href="https://taskandpurpose.com/news/navy-court-martial-bonhomme-richard/"><strong>sailor accused of torching a $3 billion warship</strong></a></li><li><a target="_blank" href="https://taskandpurpose.com/news/military-nuclear-experts-explain-dangers-fighting-chernobyl/"><strong>Military nuclear experts explain the actual danger of troops</strong></a><strong> battling in the shadow of Chernobyl</strong></li><li><strong>Here’s what those mysterious </strong><a target="_blank" href="https://taskandpurpose.com/news/russian-military-equipment-white-markings/"><strong>white ‘Z’ markings on Russian military equipment may mean</strong></a></li></ul>



<p><strong>Want to write for Task &amp; Purpose? </strong><a target="_blank" href="https://taskandpurpose.com/military-life/task-purpose-writing-pitching/"><strong>Click here</strong></a><strong>. Or check out the latest stories on </strong><a target="_blank" href="https://taskandpurpose.com/"><strong>our homepage.</strong></a></p>
        </section>

                  <section>
            <section id="SingleAuthor">
          <p><img src="https://taskandpurpose.com/uploads/2021/05/14/matt-sampson.jpg?crop=1:1,smart&amp;width=80" loading="lazy" width="80" height="80" alt="Matt Sampson">
      </p>
        
  </section>
      
  
          </section>
        
        
                          
                  <!--SPOTIM CONVERSATIONS MODULE -->
  
















              </section>
  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making CRDTs 98% More Efficient (247 pts)]]></title>
            <link>https://jakelazaroff.com/words/making-crdts-98-percent-more-efficient/</link>
            <guid>37915934</guid>
            <pubDate>Tue, 17 Oct 2023 14:45:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakelazaroff.com/words/making-crdts-98-percent-more-efficient/">https://jakelazaroff.com/words/making-crdts-98-percent-more-efficient/</a>, See on <a href="https://news.ycombinator.com/item?id=37915934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-content="" data-astro-cid-rnrqlda2="">
<p>This was supposed to be a two-part blog post, but I got inspired to write a part three!</p>
<p>At the end of <a href="https://jakelazaroff.com/words/building-a-collaborative-pixel-art-editor-with-crdts/" data-astro-cid-bi7aps5f="">Building a Collaborative Pixel Art Editor with CRDTs</a><a data-tooltip="" href="https://jakelazaroff.com/words/building-a-collaborative-pixel-art-editor-with-crdts/" data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/og/building-a-collaborative-pixel-art-editor-with-crdts.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Building a Collaborative Pixel Art Editor with CRDTs | jakelazaroff.com</span><span data-astro-cid-bi7aps5f="">CRDTs sound cool, but how are they actually used? Let's learn by building a collaborative pixel art editor.</span><span data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jakelazaroff.com/words/building-a-collaborative-pixel-art-editor-with-crdts/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, we had just that: a fully functional collaborative pixel editor using state-based CRDTs. The drawback to state-based CRDTs is that you need to transmit the full state between peers to sync up. And our CRDT’s full state is pretty big! For a 100x100 image, it’s around 648kb. Yikes!</p>
<p>I won’t bury the lede: we’re going to reduce that by almost 98% to around 14kb. For context, that’s around half as big as the uncompressed image without any CRDT metadata. While we’ll never beat PNG, we can still do pretty well.</p>
<p>The benchmarks I’ll cite in this article are all based on this image I drew, which was encoded here using the same format we’ll create by the end of the post:<sup><a href="#user-content-fn-louvre" id="user-content-fnref-louvre" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">1</a></sup></p>
<compression-table foreshadow="true" url="/public/_example.0525116f.crdt"></compression-table>
<p>This playground uses the same pixel editor we built in the last post. You can change the color and brush size by clicking on the buttons below the canvas. The table to the right shows the size of the data in kilobytes. Right now, it just shows the size of the uncompressed data and the final result in our mystery format. As we compress our data further, we’ll add rows to the table showing how each format stacks up against the others, and their relative sizes.</p>
<p>Currently, our data looks something like this:</p>
<pre><code><span>{</span>
  <span>"0,0"</span><span>:</span> <span>[</span><span>"0442197c-8144-47f7-ae64-340a2df3d796"</span><span>,</span> <span>3</span><span>,</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>]</span><span>,</span>
  <span>"1,0"</span><span>:</span> <span>[</span><span>"0442197c-8144-47f7-ae64-340a2df3d796"</span><span>,</span> <span>4</span><span>,</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>]</span><span>,</span>
  <span>"2,0"</span><span>:</span> <span>[</span><span>"0442197c-8144-47f7-ae64-340a2df3d796"</span><span>,</span> <span>2</span><span>,</span> <span>null</span><span>]</span><span>,</span>
  <span>"0,1"</span><span>:</span> <span>[</span><span>"4ae8bd76-e84c-4652-bcd8-a5e339c574f3"</span><span>,</span> <span>2</span><span>,</span> <span>[</span><span>108</span><span>,</span> <span>79</span><span>,</span> <span>255</span><span>]</span><span>]</span><span>,</span>
  <span>"1,1"</span><span>:</span> <span>[</span><span>"4ae8bd76-e84c-4652-bcd8-a5e339c574f3"</span><span>,</span> <span>3</span><span>,</span> <span>[</span><span>108</span><span>,</span> <span>79</span><span>,</span> <span>255</span><span>]</span><span>]</span>
<span>}</span></code></pre>
<p>It’s just the JSON state of our LWW Map CRDT.<sup><a href="#user-content-fn-minify" id="user-content-fnref-minify" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">2</a></sup> Each key is a string of the pixel’s <em>(x,y)</em> coordinates, and each value is a LWW Register state: a tuple of a peer ID, a timestamp and an RGB value. If a pixel has been erased, its RGB value is <code>null</code>.</p>
<p>Here’s a blank canvas so you can see how quickly the size increases as you draw. Pay attention to the different formats as we go through the article: some will actually start out larger than our uncompressed data, but quickly become smaller as more pixels are drawn!</p>
<compression-table rows="1"></compression-table>
<h3 id="hex-codes">Hex Codes</h3>
<p>The easiest change to make is storing colors as hex codes rather than RGB tuples. As a reminder, here’s the type of each color:</p>
<pre><code><span>type</span> <span><span>RGB</span></span> <span>=</span> <span>[</span>red<span>:</span> <span>number</span><span>,</span> green<span>:</span> <span>number</span><span>,</span> blue<span>:</span> <span>number</span><span>]</span><span>;</span></code></pre>
<p>Each channel has between one and three digits, so our color values look something like this:</p>
<pre><code><span>[</span><span>1</span><span>,</span> <span>234</span><span>,</span> <span>56</span><span>]</span></code></pre>
<p>That’s ten characters: six for the numbers, two for the commas and two for the brackets. If each number had three digits, it would take up a whole 13 characters.</p>
<p>Hex codes come in at eight characters, max. By using sixteen digits (A–F representing the numbers 10–15) instead of our usual ten, we can represent each channel with two characters instead of three. Plus, since we know that each channel is two characters long, we can omit the commas.</p>
<p>There’s one more trick: if both characters in each channel are the same, we can omit one, which takes us down to five characters (including quotes). Here’s what the data looks like now:</p>
<pre><code><span>{</span>
  <span>"0,0"</span><span>:</span> <span>[</span><span>"0442197c-8144-47f7-ae64-340a2df3d796"</span><span>,</span> <span>3</span><span>,</span> <span>"fff"</span><span>]</span><span>,</span>
  <span>"1,0"</span><span>:</span> <span>[</span><span>"0442197c-8144-47f7-ae64-340a2df3d796"</span><span>,</span> <span>4</span><span>,</span> <span>"fff"</span><span>]</span><span>,</span>
  <span>"2,0"</span><span>:</span> <span>[</span><span>"0442197c-8144-47f7-ae64-340a2df3d796"</span><span>,</span> <span>2</span><span>,</span> <span>null</span><span>]</span><span>,</span>
  <span>"0,1"</span><span>:</span> <span>[</span><span>"4ae8bd76-e84c-4652-bcd8-a5e339c574f3"</span><span>,</span> <span>2</span><span>,</span> <span>"6c4fff"</span><span>]</span><span>,</span>
  <span>"1,1"</span><span>:</span> <span>[</span><span>"4ae8bd76-e84c-4652-bcd8-a5e339c574f3"</span><span>,</span> <span>4</span><span>,</span> <span>"6c4fff"</span><span>]</span>
<span>}</span></code></pre>
<p>All in all, using hex codes rather than RGB tuples gets us down from 648kb to 606kb — a 6% improvement. It’s a start, but we’ll need much bigger improvements than that if we’re going to get all the way down to 14kb.</p>
<compression-table rows="2"></compression-table>
<h3 id="uuid-table">UUID Table</h3>
<p>The next things to look at are the UUIDs. They’re a whopping 38 characters each (including quotes) and they show up in every single pixel. We could — and should! — remove the hyphens, but that will only shave off four characters per pixel. We need something more substantial.</p>
<p>Instead of keeping the UUIDs directly in each pixel, we’ll store them in a table. That way, they only appear once in the document. In their place, each pixel will store a table key that maps to the full UUID. When we need the full state back, we perform the same process in reverse, replacing each pixel’s table key with its corresponding UUID.</p>
<p>Here’s what the data looks like now. The 0th element of each array in <code>data</code> represents an index in the <code>uuids</code> array:</p>
<pre><code><span>{</span>
  <span>"uuids"</span><span>:</span> <span>[</span><span>"0442197c814447f7ae64340a2df3d796"</span><span>,</span> <span>"4ae8bd76e84c4652bcd8a5e339c574f3"</span><span>]</span><span>,</span>
  <span>"data"</span><span>:</span> <span>{</span>
    <span>"0,0"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>3</span><span>,</span> <span>"fff"</span><span>]</span><span>,</span>
    <span>"1,0"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>4</span><span>,</span> <span>"fff"</span><span>]</span><span>,</span>
    <span>"2,0"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>2</span><span>,</span> <span>null</span><span>]</span><span>,</span>
    <span>"0,1"</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>"6c4fff"</span><span>]</span><span>,</span>
    <span>"1,1"</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>"6c4fff"</span><span>]</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Our UUID table uses an array rather than a map, which has implied keys: the index of the item in the array. Using numbers as keys also saves two characters every time we reference a UUID, since we don’t need quotation marks as we would with strings.</p>
<p>This turns out to be a substantial savings, taking us down to 236kb — a 63% improvement!</p>
<compression-table rows="3"></compression-table>
<h3 id="palette-table">Palette Table</h3>
<p>We can use the exact same technique for the colors. Rather than storing each color directly in each pixel, we build a table of all the colors used and replace the hex codes in each pixel with table keys.</p>
<p>The last element of each array in <code>data</code> now represents an index in the <code>palette</code> array:</p>
<pre><code><span>{</span>
  <span>"uuids"</span><span>:</span> <span>[</span><span>"0442197c814447f7ae64340a2df3d796"</span><span>,</span> <span>"4ae8bd76e84c4652bcd8a5e339c574f3"</span><span>]</span><span>,</span>
  <span>"palette"</span><span>:</span> <span>[</span><span>"fff"</span><span>,</span> <span>"6c4fff"</span><span>]</span><span>,</span>
  <span>"data"</span><span>:</span> <span>{</span>
    <span>"0,0"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>3</span><span>,</span> <span>0</span><span>]</span><span>,</span>
    <span>"1,0"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>4</span><span>,</span> <span>0</span><span>]</span><span>,</span>
    <span>"2,0"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>2</span><span>,</span> <span>null</span><span>]</span><span>,</span>
    <span>"0,1"</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>]</span><span>,</span>
    <span>"1,1"</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>1</span><span>]</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Using a table like this seems strictly better, but there are some pathological scenarios in which it actually wastes space. Consider the case in which each color only appears once: we’d have the same number of colors as we have pixels, <strong>plus</strong> the overhead of mapping each pixel to a color in the table. Our current strategy works for pixel art, which tends to have a limited palette — but if we were dealing with photographs, we might want to choose another way to compress the color data.</p>
<p>In this case, the palette table slims us down to 187kb — 71% smaller than our uncompressed data.</p>
<compression-table rows="4"></compression-table>
<h3 id="run-length-encoding">Run-Length Encoding</h3>
<p>The next big things are the pixel coordinates — the map keys of our data object. With x and y each between one and three digits, these can take up to ten characters each (including the quotes and colon).</p>
<p>Remember how, when we were drawing to the screen, we mapped indices in the buffer to coordinates? We went down the array four bytes at a time, drawing to each pixel in the first row and wrapping around when we reached the end.</p>
<buffer-diagram width="3" height="3"></buffer-diagram>
<p>Here we’ll do the same thing, but in reverse. We’ll make the data an array, setting the pixel at <code>"0,0"</code> as the first element, <code>"1,0"</code> as the second element, etc.</p>
<p>This raises a new issue: how do we represent blank pixels, where no user has drawn yet? Before, they would just be missing from the map. But now we have to represent them — otherwise, every pixel after a blank space would be in the wrong place!</p>
<p>We could just put some sort of “spacer” value like <code>null</code> in the array where blank pixels would be. That’d work, but it would also waste a lot of space.</p>
<p>Instead, we’ll use something called <a href="https://en.wikipedia.org/wiki/Run-length_encoding" data-astro-cid-bi7aps5f="">run-length encoding</a><a data-tooltip="" href="https://en.wikipedia.org/wiki/Run-length_encoding" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Run-length encoding - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.wikipedia.org/static/favicon/wikipedia.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.wikipedia.org/wiki/Run-length_encoding</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>. It’s a very simple compression algorithm: when the same item appears consecutively in a sequence, instead of storing each item, store one of the item and the number of repeated instances.</p>
<p>Let’s take <a href="https://en.wikipedia.org/wiki/James_while_John_had_had_had_had_had_had_had_had_had_had_had_a_better_effect_on_the_teacher" data-astro-cid-bi7aps5f="">this weird sentence</a><a data-tooltip="" href="https://en.wikipedia.org/wiki/James_while_John_had_had_had_had_had_had_had_had_had_had_had_a_better_effect_on_the_teacher" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">James while John had had had had had had had had had had had a better effect on the teacher - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.wikipedia.org/static/favicon/wikipedia.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.wikipedia.org/wiki/James_while_John_had_had_had_had_had_had_had_had_had_had_had_a_better_effect_on_the_teacher</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> as an example:</p>
<blockquote>
<p>James while John had had had had had had had had had had had a better effect on the teacher.</p>
</blockquote>
<p>There’s a lot of repetition there. The sentence has 92 characters, and the word “had” appears eleven times!</p>
<p>With run-length encoding, the sentence might look like this:</p>
<blockquote>
<p>1James 1while 1John 11had 1a 1better 1effect 1on 1the 1teacher.</p>
</blockquote>
<p>The idea is that before each word, we add a number indicating how many consecutive times it shows up. That lets us skip every consecutive occurrence after the first. If we omit the spaces, this sentence has 54 characters — a 42% reduction from the original!</p>
<p>It’s not an all sunshine and lollipops, though. Consider <a href="https://en.wikipedia.org/wiki/The_quick_brown_fox_jumps_over_the_lazy_dog" data-astro-cid-bi7aps5f="">this classic pangram</a><a data-tooltip="" href="https://en.wikipedia.org/wiki/The_quick_brown_fox_jumps_over_the_lazy_dog" data-astro-cid-bi7aps5f=""><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/MetalTypeZoomIn.JPG/1200px-MetalTypeZoomIn.JPG" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">The quick brown fox jumps over the lazy dog - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.wikipedia.org/static/favicon/wikipedia.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.wikipedia.org/wiki/The_quick_brown_fox_jumps_over_the_lazy_dog</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>:</p>
<blockquote>
<p>The quick brown fox jumps over the lazy dog.</p>
</blockquote>
<p>That sentence is 44 characters and no words repeat consecutively. Here’s what it might look like with run-length encoding:</p>
<blockquote>
<p>1The 1quick 1brown 1fox 1jumps 1over 1the 1lazy 1dog.</p>
</blockquote>
<p>53 characters — a 20% <strong>increase</strong>! What gives?</p>
<p>The issue is that when you compress something, you need to add metadata so that you can figure out what it looked like originally. Compression algorithms make assumptions about what patterns will occur in the original data in order to optimize the metadata. If the assumptions are right, the compressed data (including the metadata) is much smaller than the original data. But if the assumptions are wrong, the “compressed” data can even end up bigger than it was before!</p>
<p>Our assumption here is that run-length encoding will not be a good fit for LWW Register states, since there are three separate pieces of data that can vary independently. All blank spaces are the same, though, which makes them an excellent candidate for run-length encoding!</p>
<p>Rather than somehow representing each individual blank space in the array, we’ll store a number indicating how many consecutive blank spaces we came across. That lets us know exactly which coordinates the next pixel will be at.</p>
<p>Now that we’re no longer storing the coordinates of each pixel, we also need to store the width of the image. That way, when we’re decompressing the data, we know when the pixels should wrap onto the next row.</p>
<p>Here’s what the data looks like now. Since we’re now using a lot of numbers without any labels, I added some comments so it’s clear what everything is referring to.</p>
<pre><code><span>{</span>
  <span>"uuids"</span><span>:</span> <span>[</span><span>"0442197c814447f7ae64340a2df3d796"</span><span>,</span> <span>"4ae8bd76e84c4652bcd8a5e339c574f3"</span><span>]</span><span>,</span>
  <span>"palette"</span><span>:</span> <span>[</span><span>"fff"</span><span>,</span> <span>"6c4fff"</span><span>]</span><span>,</span>
  <span>"width"</span><span>:</span> <span>100</span><span>,</span>
  <span>"data"</span><span>:</span> <span>[</span>
    <span>[</span><span>/* uuid index */</span> <span>0</span><span>,</span> <span>/* timestamp */</span> <span>3</span><span>,</span> <span>/** palette index */</span> <span>0</span><span>]</span><span>,</span>
    <span>[</span><span>/* uuid index */</span> <span>0</span><span>,</span> <span>/* timestamp */</span> <span>4</span><span>,</span> <span>/** palette index */</span> <span>0</span><span>]</span><span>,</span>
    <span>[</span><span>/* uuid index */</span> <span>0</span><span>,</span> <span>/* timestamp */</span> <span>2</span><span>,</span> <span>/** palette index */</span> <span>null</span><span>]</span><span>,</span>
    <span>97</span><span>,</span> <span>// run of blank pixels</span>
    <span>[</span><span>/* uuid index */</span> <span>1</span><span>,</span> <span>/* timestamp */</span> <span>2</span><span>,</span> <span>/** palette index */</span> <span>1</span><span>]</span><span>,</span>
    <span>[</span><span>/* uuid index */</span> <span>1</span><span>,</span> <span>/* timestamp */</span> <span>3</span><span>,</span> <span>/** palette index */</span> <span>1</span><span>]</span>
  <span>]</span>
<span>}</span></code></pre>
<p>Notice how the <code>data</code> array is not homogenous: it contains either a tuple of peer ID, timestamp and color ID <strong>or</strong> a number indicating how many consecutive blank spaces there are.</p>
<p>Using run-length encoding brings us to 129kb — just over 80% smaller than our uncompressed data. We’re doing pretty well, but those last few percentage points are the trickiest ones to eke out. We’re gonna need to try something new.</p>
<compression-table rows="5"></compression-table>
<h3 id="binary-encoding">Binary Encoding</h3>
<p>So far, we’re at just more than an 80% decrease. That’s pretty good, and we could probably get it even smaller if we stopped using JSON. But we’re running into a fundamental limit: it’s inefficient to store things as text. To get much further, we’ll need to use <a href="https://en.wikipedia.org/wiki/Binary_file" data-astro-cid-bi7aps5f="">binary encoding</a><a data-tooltip="" href="https://en.wikipedia.org/wiki/Binary_file" data-astro-cid-bi7aps5f=""><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Wikipedia_favicon_hexdump.svg/1200px-Wikipedia_favicon_hexdump.svg.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Binary file - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.wikipedia.org/static/favicon/wikipedia.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.wikipedia.org/wiki/Binary_file</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>.</p>
<p>When we’re using a plain text format like JSON, we think in characters. When we’re using binary encoding, we think in bytes. A byte holds an integer from <code>0</code> to <code>255</code>. If we consider groups of bytes as a single unit, it can hold much higher numbers — for example, two bytes can hold up to <code>65535</code>.<sup><a href="#user-content-fn-uint8array" id="user-content-fnref-uint8array" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">3</a></sup></p>
<p>The numbers can represent anything we want them to. One common way to interpret them is as <a href="https://en.wikipedia.org/wiki/ASCII" data-astro-cid-bi7aps5f="">ASCII</a><a data-tooltip="" href="https://en.wikipedia.org/wiki/ASCII" data-astro-cid-bi7aps5f=""><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/USASCII_code_chart.png/1200px-USASCII_code_chart.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">ASCII - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.wikipedia.org/static/favicon/wikipedia.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.wikipedia.org/wiki/ASCII</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, meaning each number corresponds to an alphanumeric character. Another way is just as the number they hold, meaning a byte that holds <code>127</code> would represent the number 127. We’ll interpret bytes in a few different ways as we create our format.</p>
<p>We’ll define a format similar to <a href="https://en.wikipedia.org/wiki/Resource_Interchange_File_Format" data-astro-cid-bi7aps5f="">RIFF</a><a data-tooltip="" href="https://en.wikipedia.org/wiki/Resource_Interchange_File_Format" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Resource Interchange File Format - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.wikipedia.org/static/favicon/wikipedia.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.wikipedia.org/wiki/Resource_Interchange_File_Format</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, which serves as the basis for file types like WAV and AVI. It’s made up of “chunks”, each of which has two sections: “data”, which is the actual information we need to store, and a “header” that identifies the chunk type and tells us how to actually parse the bytes in the data.</p>
<p>First, binary files usually have a <a href="https://en.m.wikipedia.org/wiki/File_format#Magic_number" data-astro-cid-bi7aps5f="">magic number</a><a data-tooltip="" href="https://en.m.wikipedia.org/wiki/File_format#Magic_number" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">File format - Wikipedia</span><span data-astro-cid-bi7aps5f=""><img src="https://en.m.wikipedia.org/static/favicon/wikipedia.ico#Magic_number" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">en.m.wikipedia.org/wiki/File_format#Magic_number</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> that identifies the format. Ours will represent the ASCII text <code>CRDT</code>, so the first four bytes of the file will be <code>43 52 44 54</code>.<sup><a href="#user-content-fn-base16" id="user-content-fnref-base16" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">4</a></sup> That goes in the “info” chunk, along with the width of our artboard.</p>
<p>Here’s a diagram of the binary file. The first part contains a human-readable overview; all the data is labeled, and the values are in a format that makes sense to us (for example, you can see that the magic number reads “CRDT” and that the artboard is 100 pixels wide). The second column contains the raw bytes in the file; each byte shows its index in the file and the hex digits representing its number from <code>0</code> to <code>255</code> (or <code>00</code> to <code>ff</code> in hex). You can hover over data on the left and see the corresponding bytes highlighted, and vice versa.</p>
<binary-visualizer buffer="[[[[&quot;txt&quot;, &quot;magic number&quot;, &quot;CRDT&quot;], [&quot;u16&quot;, &quot;artboard width&quot;, 100]], []]]"></binary-visualizer>
<p>After the info chunk, the file has three more chunks: one to hold our UUID table, one to hold our palette table and one to hold our pixel data.</p>
<p>We’ll start with the UUID chunk. The header consists of two parts:</p>
<ol>
<li>Four bytes that read <code>UUID</code> in ASCII.</li>
<li>Two bytes that represent the length of the rest of the chunk in bytes.<sup><a href="#user-content-fn-bounds" id="user-content-fnref-bounds" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">5</a></sup></li>
</ol>
<binary-visualizer buffer="[[[[&quot;txt&quot;, &quot;chunk type&quot;, &quot;UUID&quot;], [&quot;u16&quot;, &quot;chunk length&quot;, 32]], []]]" chunk-start="1"></binary-visualizer>
<p>The UUID chunk’s data is just all the peer UUIDs, one after the other. These each took up 34 characters (including quotes) in our JSON, but here we can represent each of them in a mere 16 bytes. Just like before, the key will be the index of each UUID — so the first one in the chunk will be <code>0</code>, the second will be <code>1</code>, etc.</p>
<p>Here’s the full UUID chunk. Each white block represents one item in the chunk data — in this case, a UUID:</p>
<binary-visualizer buffer="[[[[&quot;txt&quot;, &quot;chunk type&quot;, &quot;UUID&quot;], [&quot;u16&quot;, &quot;chunk length&quot;, 32]], [[&quot;hex&quot;, &quot;uuid 0&quot;, &quot;0442197c814447f7ae64340a2df3d796&quot;], [&quot;hex&quot;, &quot;uuid 1&quot;, &quot;4ae8bd76e84c4652bcd8a5e339c574f3&quot;]]]]" chunk-start="1"></binary-visualizer>
<p>The next chunk is the palette chunk. The header looks similar to the UUID chunk header:</p>
<ol>
<li>Four bytes that read <code>PLTT</code> in ASCII.<sup><a href="#user-content-fn-missing" id="user-content-fnref-missing" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">6</a></sup></li>
<li>Two bytes that represent the length of the rest of the chunk in bytes.</li>
</ol>
<binary-visualizer buffer="[[[[&quot;txt&quot;, &quot;chunk type&quot;, &quot;PLTT&quot;], [&quot;u16&quot;, &quot;chunk length&quot;, 9]], []]]" chunk-start="2"></binary-visualizer>
<p>The palette chunk’s data is also similar to the UUID chunk’s data: all the colors, one after the other. When we represented these with hex codes, they took up either five or eight bytes, but here we can represent each one in a concise three bytes — one for each RGB color channel.<sup><a href="#user-content-fn-rgb" id="user-content-fnref-rgb" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">7</a></sup></p>
<p>This chunk has one extra quirk: when writing to the data, we skip the first item’s place (so the first color starts as the fourth byte of data, or tenth byte including the header). That might not make sense now, but we’ll learn why in a minute.</p>
<p>Here’s the full palette chunk:</p>
<binary-visualizer buffer="[[[[&quot;txt&quot;, &quot;chunk type&quot;, &quot;PLTT&quot;], [&quot;u16&quot;, &quot;chunk length&quot;, 9]], [[&quot;rgb&quot;, &quot;color 0&quot;, [0,0,0]], [&quot;rgb&quot;, &quot;color 1&quot;, [255,255,255]], [&quot;rgb&quot;, &quot;color 2&quot;, [108,79,255]]]]]" chunk-start="2"></binary-visualizer>
<p>The last chunk is the data chunk. You know the drill by now:</p>
<ol>
<li>Four bytes that read <code>DATA</code> in ASCII.</li>
<li>Two bytes that represent the length of the rest of the chunk in bytes.</li>
</ol>
<binary-visualizer buffer="[[[[&quot;txt&quot;, &quot;chunk type&quot;, &quot;DATA&quot;], [&quot;u16&quot;, &quot;chunk length&quot;, 23]], []]]" chunk-start="3"></binary-visualizer>
<p>That’s the header. There are two types of items that can appear in the data chunk: pixels and blanks. Each item will start with a single byte “tag” indicating which type it is — <code>0</code> for blank and <code>1</code> for pixel.</p>
<p>Blank items are easy. After the tag, they have two single bytes indicating how many consecutive blank spaces they represent.</p>
<binary-visualizer buffer="[[[], [[&quot;item&quot;, [&quot;u8&quot;, &quot;blank tag&quot;, &quot;0&quot;], [&quot;u16&quot;, &quot;run length&quot;, 97]]]]]" chunk-start="3"></binary-visualizer>
<p>There’s a tradeoff here: by using two bytes to indicate the run length, a single blank item can represent up to 65,535 blank spaces. But then every blank item needs to use two bytes to represent the number of spaces — even if none of them need the second byte. If we used one byte, it would mean each blank item is more compact, but if there are more than 255 blank pixels in a row we’d need to use two or more consecutive blank items to represent them.</p>
<p>Pixel items are a bit more complicated. Remember, each pixel is really a LWW Register, which has three pieces of information: the peer ID that last wrote to the register, the timestamp and the value. After the tag, a pixel item has a section for each one:</p>
<ol>
<li>A byte for the peer ID, indicating its index in the UUID chunk.</li>
<li>A byte for the timestamp.<sup><a href="#user-content-fn-maxtimestamp" id="user-content-fnref-maxtimestamp" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">8</a></sup></li>
<li>A byte for the color, indicating its index in the palette chunk.</li>
</ol>
<binary-visualizer buffer="[[[], [[&quot;item&quot;, [&quot;u8&quot;, &quot;pixel tag&quot;, &quot;1&quot;], [&quot;u8&quot;, &quot;uuid index&quot;, &quot;0&quot;], [&quot;u8&quot;, &quot;timestamp&quot;, 3], [&quot;u8&quot;, &quot;palette index&quot;, 1]]]]]" chunk-start="3"></binary-visualizer>
<p>We also need a way to store erased pixels. In the JSON format, we stored <code>null</code> as a way to indicate that the pixel had been added and then erased. In binary, there’s no <code>null</code> — all we have are bytes. That’s why we skipped the first three bytes when writing the palette chunk: we know that no color will use the <code>0</code> index. If any pixel has <code>0</code> as its index, that pixel was erased.</p>
<p>Here’s our full file. As you hover over pixel data that refers to items in the UUID and palette chunks, you’ll see arrows pointing back to the actual data in those chunks.</p>
<binary-visualizer buffer="[[[[&quot;txt&quot;,&quot;magic number&quot;,&quot;CRDT&quot;],[&quot;u16&quot;,&quot;artboard width&quot;,100]],[]],[[[&quot;txt&quot;,&quot;chunk tag&quot;,&quot;UUID&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,32]],[[&quot;hex&quot;,&quot;uuid 0&quot;,&quot;0442197c814447f7ae64340a2df3d796&quot;,{&quot;id&quot;:&quot;uuid0&quot;}],[&quot;hex&quot;,&quot;uuid 1&quot;,&quot;4ae8bd76e84c4652bcd8a5e339c574f3&quot;,{&quot;id&quot;:&quot;uuid1&quot;}]]],[[[&quot;txt&quot;,&quot;chunk tag&quot;,&quot;PLTT&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,9]],[[&quot;rgb&quot;,&quot;blank color&quot;,[0,0,0],{&quot;id&quot;:&quot;color0&quot;}],[&quot;rgb&quot;,&quot;color 1&quot;,[255,255,255],{&quot;id&quot;:&quot;color1&quot;}],[&quot;rgb&quot;,&quot;color 2&quot;,[108,79,255],{&quot;id&quot;:&quot;color2&quot;}]]],[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;DATA&quot;], [&quot;u16&quot;,&quot;chunk length&quot;,23]],[[&quot;item&quot;,[&quot;u8&quot;,&quot;pixel tag&quot;,1],[&quot;u8&quot;,&quot;uuid index&quot;,0,{&quot;target&quot;:&quot;uuid0&quot;}],[&quot;u8&quot;,&quot;timestamp&quot;,3],[&quot;u8&quot;,&quot;palette index&quot;,1,{&quot;target&quot;:&quot;color1&quot;}]],[&quot;item&quot;,[&quot;u8&quot;,&quot;pixel tag&quot;,1],[&quot;u8&quot;,&quot;uuid index&quot;,0,{&quot;target&quot;:&quot;uuid0&quot;}],[&quot;u8&quot;,&quot;timestamp&quot;,4],[&quot;u8&quot;,&quot;palette index&quot;,1,{&quot;target&quot;:&quot;color1&quot;}]],[&quot;item&quot;,[&quot;u8&quot;,&quot;pixel tag&quot;,1],[&quot;u8&quot;,&quot;uuid index&quot;,0,{&quot;target&quot;:&quot;uuid0&quot;}],[&quot;u8&quot;,&quot;timestamp&quot;,2],[&quot;u8&quot;,&quot;palette index&quot;,0,{&quot;target&quot;:&quot;color0&quot;}]],[&quot;item&quot;,[&quot;u8&quot;,&quot;blank tag&quot;,0],[&quot;u16&quot;,&quot;run length&quot;,97]],[&quot;item&quot;,[&quot;u8&quot;,&quot;pixel tag&quot;,1],[&quot;u8&quot;,&quot;uuid index&quot;,1,{&quot;target&quot;:&quot;uuid1&quot;}],[&quot;u8&quot;,&quot;timestamp&quot;,2],[&quot;u8&quot;,&quot;palette index&quot;,2,{&quot;target&quot;:&quot;color2&quot;}]],[&quot;item&quot;,[&quot;u8&quot;,&quot;pixel tag&quot;,1],[&quot;u8&quot;,&quot;uuid index&quot;,1,{&quot;target&quot;:&quot;uuid1&quot;}],[&quot;u8&quot;,&quot;timestamp&quot;,3],[&quot;u8&quot;,&quot;palette index&quot;,2,{&quot;target&quot;:&quot;color2&quot;}]]]]]"></binary-visualizer>
<p>This gets us down to just 40kb. An RGB color takes up three bytes, and at this size we’re representing it with only a single byte of overhead! At an almost 94% reduction from the uncompressed data, we’ve already done a great job and could probably stop here if we wanted. But we can take it even further.</p>
<compression-table rows="6"></compression-table>
<h3 id="run-length-binary-encoding">Run-Length Binary Encoding</h3>
<p>We’re in the home stretch now. The info, UUID and palette chunks are about as compact as can be, but we can save a bunch of space in the data chunk.</p>
<p>If you recall a couple sections ago, the reason we run-length encoded the only blank spaces was that each pixel had three pieces of information that could vary independently: the timestamp, the peer ID of the last writer and the color. We’re going to split those up into individual chunks — one for each piece of information. Within each chunk, there will be only one single thing that can vary between items, which will let us use run-length encoding on each individual piece of data. So instead of one data chunk, we’ll have three: a writer chunk, a color chunk and a timestamp chunk.</p>
<p>The writer and color chunks are very similar to each other. Their headers have four bytes that read <code>WRTR</code> (for the writer chunk) or <code>COLR</code> (for the color chunk) in ASCII and two bytes for the length of the rest of the chunk in bytes. Each item in these chunks takes up three bytes: one for the index of the corresponding item in the UUID or palette chunk, and two for the length of the run.</p>
<binary-visualizer buffer="[[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;WRTR&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,6]],[[&quot;item&quot;,[&quot;u8&quot;,&quot;uuid index&quot;,0],[&quot;u16&quot;,&quot;run length&quot;,100]],[&quot;item&quot;,[&quot;u8&quot;,&quot;uuid index&quot;,1],[&quot;u16&quot;,&quot;run length&quot;,2]]]],[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;COLR&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,9]],[[&quot;item&quot;,[&quot;u8&quot;,&quot;palette index&quot;,1],[&quot;u16&quot;,&quot;run length&quot;,2]],[&quot;item&quot;,[&quot;u8&quot;,&quot;palette index&quot;,0],[&quot;u16&quot;,&quot;run length&quot;,98]],[&quot;item&quot;,[&quot;u8&quot;,&quot;palette index&quot;,2],[&quot;u16&quot;,&quot;run length&quot;,2]]]]]" chunk-start="3"></binary-visualizer>
<p>You might notice that there are two items in the writer data, but three items in the color data. It means that — going from the top left pixel to the bottom right — the peer who wrote to each pixel changes twice, but the color changes three times. Because we’re now keeping track of each kind of data separately, we can compress them without worrying about the others.<sup><a href="#user-content-fn-confusing" id="user-content-fnref-confusing" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">9</a></sup></p>
<p>The final chunk is the timestamp chunk. The header has four bytes that read <code>TIME</code> in ASCII, and two bytes for the length of the data items in bytes. Each item in the timestamp chunk starts with a single byte representing the timestamp of that pixel. We can use a clever trick here to disambiguate blank pixels from drawn pixels. When we instantiate a LWW Register, the timestamp is set to <code>1</code>. There will never be a register with a timestamp of <code>0</code>, which means we can use that value to indicate a blank pixel.</p>
<p>We’ll use the same run-length encoding strategy from the previous binary format. If the timestamp is a positive number, the next byte will be the next timestamp. But if the timestamp is <code>0</code>, we’ll interpret the next two bytes as the length of the run of blank pixels.<sup><a href="#user-content-fn-porquenolosdos" id="user-content-fnref-porquenolosdos" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">10</a></sup></p>
<binary-visualizer buffer="[[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;TIME&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,8]],[[&quot;u8&quot;,&quot;timestamp&quot;,3],[&quot;u8&quot;,&quot;timestamp&quot;,4],[&quot;u8&quot;,&quot;timestamp&quot;,2],[&quot;item&quot;,[&quot;u8&quot;,&quot;timestamp&quot;,0],[&quot;u16&quot;,&quot;run-length&quot;,97]],[&quot;u8&quot;,&quot;timestamp&quot;,2],[&quot;u8&quot;,&quot;timestamp&quot;,3]]]]" chunk-start="5"></binary-visualizer>
<p>That also lets us save a bit of space by ignoring runs of blank pixels in the writer and color chunks, by which I mean that a blank pixel doesn’t end the run of a UUID or color. Only when we see a different UUID or color do we start a new run. We consider the timestamp chunk to be the ultimate authority on whether a pixel is blank: if the timestamp is <code>0</code>, then it doesn’t matter what we think the UUID or color is.</p>
<p>Here’s the full file:</p>
<binary-visualizer buffer="[[[[&quot;txt&quot;,&quot;magic number&quot;,&quot;CRDT&quot;],[&quot;u16&quot;,&quot;artboard width&quot;,100]],[]],[[[&quot;txt&quot;,&quot;chunk tag&quot;,&quot;UUID&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,32]],[[&quot;hex&quot;,&quot;uuid 0&quot;,&quot;0442197c814447f7ae64340a2df3d796&quot;,{&quot;id&quot;:&quot;uuid0&quot;}],[&quot;hex&quot;,&quot;uuid 1&quot;,&quot;4ae8bd76e84c4652bcd8a5e339c574f3&quot;,{&quot;id&quot;:&quot;uuid1&quot;}]]],[[[&quot;txt&quot;,&quot;chunk tag&quot;,&quot;PLTT&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,9]],[[&quot;rgb&quot;,&quot;blank color&quot;,[0,0,0],{&quot;id&quot;:&quot;color0&quot;}],[&quot;rgb&quot;,&quot;color 1&quot;,[255,255,255],{&quot;id&quot;:&quot;color1&quot;}],[&quot;rgb&quot;,&quot;color 2&quot;,[108,79,255],{&quot;id&quot;:&quot;color2&quot;}]]],[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;WRTR&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,6]],[[&quot;item&quot;,[&quot;u8&quot;,&quot;uuid index&quot;,0,{&quot;target&quot;:&quot;uuid0&quot;}],[&quot;u16&quot;,&quot;run length&quot;,100]],[&quot;item&quot;,[&quot;u8&quot;,&quot;uuid index&quot;,1,{&quot;target&quot;:&quot;uuid1&quot;}],[&quot;u16&quot;,&quot;run length&quot;,2]]]],[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;COLR&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,9]],[[&quot;item&quot;,[&quot;u8&quot;,&quot;palette index&quot;,1,{&quot;target&quot;:&quot;color1&quot;}],[&quot;u16&quot;,&quot;run length&quot;,2]],[&quot;item&quot;,[&quot;u8&quot;,&quot;palette index&quot;,0,{&quot;target&quot;:&quot;color0&quot;}],[&quot;u16&quot;,&quot;run length&quot;,98]],[&quot;item&quot;,[&quot;u8&quot;,&quot;palette index&quot;,2,{&quot;target&quot;:&quot;color2&quot;}],[&quot;u16&quot;,&quot;run length&quot;,2]]]],[[[&quot;txt&quot;,&quot;chunk type&quot;,&quot;TIME&quot;],[&quot;u16&quot;,&quot;chunk length&quot;,8]],[[&quot;u8&quot;,&quot;timestamp&quot;,3],[&quot;u8&quot;,&quot;timestamp&quot;,4],[&quot;u8&quot;,&quot;timestamp&quot;,2],[&quot;item&quot;,[&quot;u8&quot;,&quot;timestamp&quot;,0],[&quot;u16&quot;,&quot;run-length&quot;,97]],[&quot;u8&quot;,&quot;timestamp&quot;,2],[&quot;u8&quot;,&quot;timestamp&quot;,3]]]]"></binary-visualizer>
<p>This version of our format comes in at 14kb. That’s a 98% decrease from our initial 648kb, and it’s 50% smaller than the uncompressed RGB data — we’re using less than one and a half bytes per pixel!</p>
<compression-table rows="7"></compression-table>
<p>If you’re curious how the formats stack up when the canvas isn’t blank, here’s the benchmark image with all compression formats compared:</p>
<compression-table rows="7" url="/public/_example.0525116f.crdt"></compression-table>
<h3 id="conclusion">Conclusion</h3>
<p>As you can see, even though state-based CRDTs require their whole state to be synced between peers, it’s possible to for the actual data transferred to be significantly more efficient. We took a CRDT state weighing in at 648kb and reduced its size by almost 98% to only 14kb!</p>
<p>The optimization techniques here are inspired by Martin Kleppmann’s video <a href="https://youtu.be/x7drE24geUw?si=9Z9Rl-wVwV2Hhj83&amp;t=3587" data-astro-cid-bi7aps5f="">CRDTs: The Hard Parts</a><a data-tooltip="" href="https://youtu.be/x7drE24geUw?si=9Z9Rl-wVwV2Hhj83&amp;t=3587" data-astro-cid-bi7aps5f=""><img src="https://i.ytimg.com/vi/x7drE24geUw/maxresdefault.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">CRDTs: The Hard Parts</span><span data-astro-cid-bi7aps5f="">A talk on the latest research on CRDTs, originally given at the Hydra distributed computing conference on 6 July 2020.References: https://martin.kleppmann.co...</span><span data-astro-cid-bi7aps5f=""><img src="https://www.youtube.com/s/desktop/cc87ee3e/img/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">youtu.be/x7drE24geUw?si=9Z9Rl-wVwV2Hhj83&amp;t=3587</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>. He and <a href="https://www.inkandswitch.com/" data-astro-cid-bi7aps5f="">Ink and Switch</a><a data-tooltip="" href="https://www.inkandswitch.com/" data-astro-cid-bi7aps5f=""><img src="https://www.inkandswitch.com/assets/logo-favicon-196x196.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Ink &amp; Switch</span><span data-astro-cid-bi7aps5f="">Industrial research lab working on digital tools for creativity and productivity</span><span data-astro-cid-bi7aps5f=""><img src="https://www.inkandswitch.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">www.inkandswitch.com</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> managed to reduce the gzipped size of a 100kb plain text file with CRDT metadata to only 114kb — less than a 10% increase over the uncompressed plain text data (and compressing text is significantly harder than the pixel data example we just went through).</p>
<p>This all might seem like a lot of busywork to get back to a reasonable baseline. But in practice, there are CRDT libraries available that have already made these or similar optimizations for you, including but not limited to:</p>

<p>There’s also a great website called <a href="https://crdt.tech/implementations" data-astro-cid-bi7aps5f="">crdt.tech</a><a data-tooltip="" href="https://crdt.tech/implementations" data-astro-cid-bi7aps5f=""><img src="https://crdt.tech/assets/img/crdt-favicon.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Code • Conflict-free Replicated Data Types</span><span data-astro-cid-bi7aps5f="">Resources and community around CRDT technology — papers, blog posts, code and more.</span><span data-astro-cid-bi7aps5f=""><img src="https://crdt.tech/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">crdt.tech/implementations</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> that has a list of CRDT libraries, as well as blog posts and academic papers.</p>
<p>CRDTs are awesome! Go forth and build something cool!</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-louvre">
<p>I’m imagining this picture hanging in the Louvre soon after this post is published. <a href="#user-content-fnref-louvre" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-minify">
<p>The JSON is formatted for easier reading, but when we’re talking about how much space it takes up, we’ll pretend it’s minified by omitting whitespace. <a href="#user-content-fnref-minify" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-uint8array">
<p>If this is too abstract, here’s how it works in JavaScript: a binary file is just a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array" data-astro-cid-bi7aps5f=""><code>Uint8Array</code></a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array" data-astro-cid-bi7aps5f=""><img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Uint8Array - JavaScript | MDN</span><span data-astro-cid-bi7aps5f="">The Uint8Array typed array represents an array of 8-bit unsigned integers. The contents are initialized to 0. Once established, you can reference elements in the array using the object's methods, or using standard array index syntax (that is, using bracket notation).</span><span data-astro-cid-bi7aps5f=""><img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>. Each element of the array is a single byte. Using multiple bytes to represent numbers greater than 255 gets a little tricky, but this is the basic idea. <a href="#user-content-fnref-uint8array" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-base16">
<p>Note that this is in hexadecimal, so each of those numbers is base 16. In decimal, they come out to <code>67 82 68 84</code>. <a href="#user-content-fnref-base16" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-bounds">
<p>Why do we need to know the length in advance? With binary, we don’t usually use delimiters like quotes or brackets to indicate when things begin or end. Instead, we expect to know the size in bytes of each item in advance. That way, we can just go through the items that many bytes at a time, counting up until we’ve gone through the total number of bytes. <a href="#user-content-fnref-bounds" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-missing">
<p>Yeah, we’re missing a few letters, but we need each chunk name to fit in the same number of bytes. <a href="#user-content-fnref-missing" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-rgb">
<p>Remember how each RGB color channel is an integer between 0 and 255? It’s not a coincidence that those are the exact numbers you can fit in a single byte! <a href="#user-content-fnref-rgb" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-maxtimestamp">
<p>Using one byte for the timestamp makes each pixel smaller, but limits us to a maximum timestamp of 255. Lifting that limit would mean adding another byte to every pixel — even if every timestamp is below that amount. Since we know the maximum timestamp in advance, we could make an optimization here: use two bytes to store the timestamp if and only if one of the timestamps is above 255. Saving one byte per pixel sounds small, but that reduces the size of a 100x100 image by a full 10kb! <a href="#user-content-fnref-maxtimestamp" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-confusing">
<p>One downside is that our data is a bit more confusing: items at the same index in each category might not refer to the same pixel. This is a tradeoff of compressing data: the more we squeeze it into as little space as possible, the less it resembles the original thing we’re compressing. <a href="#user-content-fnref-confusing" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-porquenolosdos">
<p>Why not run-length encode all the timestamps? In my (very limited) testing, the timestamps varied enough that run-length encoding non-blank pixels wasted space. <a href="#user-content-fnref-porquenolosdos" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swedish union declares strike for Tesla employees (179 pts)]]></title>
            <link>https://www.ifmetall.se/aktuellt/tesla/background-information-on-if-metalls-conflict-at-tesla/</link>
            <guid>37915241</guid>
            <pubDate>Tue, 17 Oct 2023 14:04:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ifmetall.se/aktuellt/tesla/background-information-on-if-metalls-conflict-at-tesla/">https://www.ifmetall.se/aktuellt/tesla/background-information-on-if-metalls-conflict-at-tesla/</a>, See on <a href="https://news.ycombinator.com/item?id=37915241">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>  <p> The main reason for IF Metall to take industrial action at Tesla is to ensure that our members have decent and safe working conditions. Over a long period of time, we have attempted to discuss with Tesla the signing of a collective agreement, yet without success. Now we see no solution other than to take industrial action.  </p><div> <figure> <img loading="lazy" alt="" data-interchange="[/contentassets/73054e884d124ce5b655db9d89e00a33/pexels-pixabay-258083-1140x570.jpg?width=640&amp;height=360&amp;mode=max&amp;saved=2023-10-16+09:06, small], [/contentassets/73054e884d124ce5b655db9d89e00a33/pexels-pixabay-258083-1140x570.jpg?width=1280&amp;height=720&amp;mode=max&amp;saved=2023-10-16+09:06, medium], [/contentassets/73054e884d124ce5b655db9d89e00a33/pexels-pixabay-258083-1140x570.jpg?width=1280&amp;height=720&amp;mode=max&amp;saved=2023-10-16+09:06, large]" src="https://www.ifmetall.se/contentassets/73054e884d124ce5b655db9d89e00a33/pexels-pixabay-258083-1140x570.jpg?width=640&amp;height=360&amp;mode=max&amp;saved=2023-10-16+09:06"> <figcaption> <span> <span> </span> </span> </figcaption></figure> </div> <h3>The Swedish labour market model</h3> <p>Collective agreements are the basis of the Swedish labour market model. This means that the trade unions and the employers' organizations determine the rules of the game in the labour market, without interference from the state and politicians. In Sweden, approximately nine out of ten workers are covered by collective agreements. </p><p>The terms of the collective agreement include wages, form of employment, occupational pension, working hours, vacations, and periods of notice. Thus, the employers benefit from industry-specific, long-term, and stable ground rules. </p><p>The collective agreements are negotiated on a sector-by-sector basis, and employees are guaranteed the wages and working conditions that are standard across the sector. This allows for companies to operate on a level playing field, while avoiding the risk of any one employer distorting competition in the sector by imposing poor conditions on their employees. </p><h3>Very few labour market conflicts in Sweden</h3> <p>Once a collective agreement is signed, both employers and employees have the obligation to keep the peace. This applies throughout the term of the agreement and ensures that no one can strike to obtain better conditions than those set out in the agreement. </p><p>As a result, the collective agreement ensures a Swedish labour market with very few industrial actions, conflicts or strikes. It is grounded on a long-standing Swedish tradition of over 100 years of negotiations between the labour market parties. The collective agreement creates a situation of clarity and order for both employees and employers, while avoiding conflicts. </p><h3>We strive for a swift solution</h3> <p>IF Metall signs approximately 200 local collective agreements a year in the industry sector.&nbsp; Very rarely do we end up in conflict. At the most part, we have one conflict a year, usually ending in a signed agreement. </p><p>IF Metall of course want our members at Tesla to have the same decent and safe working conditions as the members at other similar companies in Sweden. </p><p>Even though we have called for industrial action, it is our sincere hope that Tesla will finally start negotiating and sign a collective agreement for their plants in Sweden. </p><p>Tesla is a global leader in the green transition. We hope that they will be willing to express the same level of leadership regarding working conditions for their employees and our members. We strive for and look forward to a swift solution. </p><p><strong>Fact:</strong> IF Metall, Industrial metalworkers in Sweden, is the trade union organizing 300 000 members within the manufacturing and chemical industries, in mining, and in the automotive industry. </p>  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Circulant Matrices, Eigenvectors, and the FFT (108 pts)]]></title>
            <link>https://www.johndcook.com/blog/2023/05/12/circulant-matrices/</link>
            <guid>37915044</guid>
            <pubDate>Tue, 17 Oct 2023 13:51:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.johndcook.com/blog/2023/05/12/circulant-matrices/">https://www.johndcook.com/blog/2023/05/12/circulant-matrices/</a>, See on <a href="https://news.ycombinator.com/item?id=37915044">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>A circulant matrix is a square matrix in which each row is a rotation of the previous row. This post will illustrate a connection between circulant matrices and the FFT (Fast Fourier Transform).</p>

<p>Color in the first row however you want. Then move the last element to the front to make the next row. Repeat this process until the matrix is full.</p>
<p><img decoding="async" fetchpriority="high" src="https://www.johndcook.com/foobazqux.png" alt="" width="277" height="288"></p>
<p>The NumPy function <code>roll</code> will do this rotation for us. Its first argument is the row to rotate, and the second argument is the number of rotations to do. So the following Python code generates a random circulant matrix of size N.</p>
<pre>    import numpy as np

    np.random.seed(20230512)
    N = 5
    row = np.random.random(N)
    M = np.array([np.roll(row, i) for i in range(N)])
</pre>
<p>Here’s the matrix M with entries truncated to 3 decimal places to make it easier to read.</p>
<pre>    [[0.556 0.440 0.083 0.460 0.909]
     [0.909 0.556 0.440 0.083 0.460]
     [0.460 0.909 0.556 0.440 0.083]
     [0.083 0.460 0.909 0.556 0.440]
     [0.440 0.083 0.460 0.909 0.556]]    
</pre>
<h2>Fast Fourier Transform</h2>
<p>The Fast Fourier Transform is a linear transformation and so it can be represented by a matrix [1]. This the <em>N</em> by <em>N</em> matrix whose (<em>j</em>, <em>k</em>) entry is ω<sup><em>jk</em></sup> where ω = exp(-2π<em>i</em>/<em>N</em>), with <em>j</em> and <em>k</em> running from 0 to <em>N</em> – 1. [2]</p>
<p>Each element of the FFT matrix corresponds to a rotation, so you could visualize the matrix using clocks in each entry or by a cycle of colors. A few years ago I created a <a href="https://www.johndcook.com/blog/2016/01/10/visualizing-the-dft-matrix/">visualization</a> using both clock faces and colors:</p>
<p><img decoding="async" src="https://www.johndcook.com/clock_fft.png" alt="" width="450" height="477"></p>
<h2>Eigenvectors and Python code</h2>
<p>Here’s a <strong>surprising property</strong> of circulant matrices: the eigenvectors of a circulant matrix depend only on the size of the matrix, not on the elements of the matrix. Furthermore, these eigenvectors are the columns of the FFT matrix. The eigenvalues depend on the matrix entries, but the eigenvectors do not.</p>
<p>Said another way, when you multiply a circulant matrix by a column of the FFT matrix of the same size, this column will be stretched but not rotated. The amount of stretching depends on the particular circulant matrix.</p>
<p>Here is Python code to illustrate this.</p>
<pre>    for i in range(N):
        ω = np.exp(-2j*np.pi/N)
        col1 = np.array([ω**(i*j) for j in range(N)])
        col2 = np.matmul(M, col1)
        print(col1/col2)
</pre>
<p>In this code <code>col1</code> is a column of the FFT matrix, and <code>col2</code> is the image of the column when multiplied by the circulant matrix <code>M</code>. The print statement shows that the ratios of each elements are the same in each position. This ratio is the eigenvalue associated with each eigenvector. If you were to generate a new random circulant matrix, the ratios would change, but the input and output vectors would still be proportional.</p>
<h2>Notes</h2>
<p>[1] Technically this is the discrete Fourier transform (DFT). The FFT is an <em>algorithm</em> for computing the DFT. Because the DFT is always computed using the FFT, the transformation itself is usually referred to as the FFT.</p>
<p>[2] Conventions vary, so you may see the FFT matrix written differently.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Love after life: Richard Feynman's letter to his departed wife (2017) (177 pts)]]></title>
            <link>https://www.themarginalian.org/2017/10/17/richard-feynman-arline-letter/</link>
            <guid>37914958</guid>
            <pubDate>Tue, 17 Oct 2023 13:45:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.themarginalian.org/2017/10/17/richard-feynman-arline-letter/">https://www.themarginalian.org/2017/10/17/richard-feynman-arline-letter/</a>, See on <a href="https://news.ycombinator.com/item?id=37914958">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="posts">
			<p><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img width="320" height="498" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2016/05/richardfeynman_gleick.jpg?fit=320%2C498&amp;ssl=1&amp;is-pending-load=1" alt="Love After Life: Nobel-Winning Physicist Richard Feynman’s Extraordinary Letter to His Departed Wife" decoding="async" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2016/05/richardfeynman_gleick.jpg?w=321&amp;ssl=1 321w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2016/05/richardfeynman_gleick.jpg?resize=240%2C374&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2016/05/richardfeynman_gleick.jpg?resize=320%2C498&amp;ssl=1 320w" data-lazy-sizes="(max-width: 320px) 100vw, 320px" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2016/05/richardfeynman_gleick.jpg?fit=320%2C498&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><p>Few people have enchanted the popular imagination with science more powerfully and lastingly than physicist <strong>Richard Feynman</strong> (May 11, 1918–February 15, 1988) — the “Great Explainer” with the uncommon gift for bridging the essence of science with the most human and humane dimensions of life.</p>
<p>Several months after Feynman’s death, while working on what would become <a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><strong><em>Genius: The Life and Science of Richard Feynman</em></strong></a> (<a href="http://www.worldcat.org/title/genius-the-life-and-science-of-richard-feynman/oclc/25316182&amp;referer=brief_results" target="_blank"><em>public library</em></a>) — the masterly biography plumbing <a href="https://www.themarginalian.org/2016/05/11/richard-feynman-genius-james-gleick/">the wellspring of Feynman’s genius</a> — James Gleick discovered something of arresting strangeness and splendor. </p>
<p>“My heart stopped,” Gleick tells me. “I have never had an experience like that as a biographer, before or since.”</p>
<p>In a mass of unread papers sent to him by Feynman’s widow, Gweneth, Gleick found a letter that discomposed his most central understanding of Feynman’s character. A generation after computing pioneer Alan Turing <a href="https://www.themarginalian.org/2017/02/17/alan-turing-morcom-letters/">tussled with the binary code of body and spirit in the wake of loss</a>, Feynman — a scientist perhaps <a href="https://www.themarginalian.org/2013/01/01/ode-to-a-flower-richard-feynman/">uncommonly romantic</a> yet resolutely rational and unsentimental in his reverence for the indomitable laws of physics that tend toward decay — penned a remarkable letter to a physical nonentity that was, for the future Nobel-winning physicist, the locus of an irrepressible metaphysical reality. </p>
<figure id="attachment_62637"><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img data-lazy-fallback="1" decoding="async" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?resize=355%2C630&amp;ssl=1" alt="" width="355" height="630" srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?w=355&amp;ssl=1 355w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?resize=240%2C426&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?resize=320%2C568&amp;ssl=1 320w" sizes="(max-width: 355px) 100vw, 355px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?w=355&amp;ssl=1 355w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?resize=240%2C426&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?resize=320%2C568&amp;ssl=1 320w" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_young.jpg?resize=355%2C630&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Richard Feynman as a youth</figcaption></figure>
<p>In high school, the teenage Richard spent summers at the beach in his native Far Rockaway. There, he grew besotted with a striking girl named Arline — a girl he knew he would marry. Both complement and counterpoint to his own nature, Arline met Richard’s inclination for science with ardor for philosophy and art. (The art class he took just to be near her would lay the foundation for his <a href="https://www.themarginalian.org/2013/01/17/richard-feynman-ofey-sketches-drawings/">little-known, lifelong passion for drawing</a>.) By his junior year, Richard proposed. Arline accepted. With the eyes of young love, they peered into a shared future of infinite possibility for bliss. </p>
<figure id="attachment_62639"><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?resize=419%2C689&amp;ssl=1" alt="" width="419" height="689" srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?w=419&amp;ssl=1 419w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?resize=240%2C395&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?resize=320%2C526&amp;ssl=1 320w" sizes="(max-width: 419px) 100vw, 419px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?w=419&amp;ssl=1 419w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?resize=240%2C395&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?resize=320%2C526&amp;ssl=1 320w" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline2.jpg?resize=419%2C689&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Richard and Arline, 1940s</figcaption></figure>
<p>But they were abruptly grounded when a mysterious malady began afflicting Arline with inexplicable symptoms — a lump would appear and disappear on her neck, fevers would roil over her with no apparent cause. Eventually, she was hospitalized for what was believed to be typhoid. </p>
<p>Gleick writes:</p>
<blockquote><p>Feynman began to glimpse the special powerlessness that medical uncertainty can inflict on a scientific person. He had come to believe that the scientific way of thinking brought a measure of calmness and control in difficult situations — but not now.</p></blockquote>
<p>Just as Feynman began bombarding the doctors with questions that steered them toward a closer approximation of the scientific method, Arline began to recover just as mysteriously and unpredictably as she had fallen ill. But the respite was only temporary. The symptoms returned, still shorn of a concrete explanation but now unambiguously pointing toward the terminal — a prognosis Arline’s doctors kept from her. Richard refused to go along with the deception — he and Arline had promised each other to face life with unremitting truthfulness — but he was forced to calibrate his commitment to circumstance. </p>
<p>Gleick writes:</p>
<blockquote><p>His parents, Arline’s parents, and the doctors all urged him not to be so cruel as to tell a young woman she was dying. His sister, Joan, sobbing, told him he was stubborn and heartless. He broke down and bowed to tradition. In her room at Farmingdale Hospital, with her parents at her side, he confirmed that she had glandular fever. Meanwhile, he started carrying around a letter — a “goodbye love letter,” as he called it — that he planned to give her when she discovered the truth. He was sure she would never forgive the unforgivable lie. </p>
<p>He did not have long to wait. Soon after Arline returned home from the hospital she crept to the top of the stairs and overheard her mother weeping with a neighbor down in the kitchen. When she confronted Richard — his letter snug in his pocket — he told her the truth, handed her the letter, and asked her to marry him.</p></blockquote>
<figure id="attachment_62638"><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=680%2C454&amp;ssl=1" alt="" width="680" height="454" srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?w=961&amp;ssl=1 961w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=240%2C160&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=320%2C213&amp;ssl=1 320w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=600%2C400&amp;ssl=1 600w" sizes="(max-width: 680px) 100vw, 680px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?w=961&amp;ssl=1 961w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=240%2C160&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=320%2C213&amp;ssl=1 320w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=600%2C400&amp;ssl=1 600w" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline1.jpg?resize=680%2C454&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Arline and Richard, 1940s</figcaption></figure>
<p>Marriage, however, proved to be a towering practical problem — Princeton, where Feynman was now pursuing a Ph.D., threatened to withdraw the fellowships funding his graduate studies if he were to wed, for the university considered the emotional and pragmatic responsibilities of marriage a grave threat to academic discipline. </p>
<p>Just as Feynman began considering leaving Princeton, a diagnosis detonated the situation — Arline had contracted a rare form of tuberculosis, most likely from unpasteurized milk. </p>
<p>At first, Feynman was relieved that the grim alternative options of Hodgkin’s disease and incurable cancers like lymphoma had been ruled out. But he was underestimating, or perhaps misunderstanding, the gravity of tuberculosis — the very disease which had <a href="https://www.themarginalian.org/2017/02/17/alan-turing-morcom-letters/">taken the love of Alan Turing’s life</a> and which, during its two-century heyday, had claimed more lives around the globe than any other malady and all wars combined. At the time of Arline’s diagnosis in 1941, immunology was in its infancy, the antibiotic treatment of bacterial infections practically nonexistent, and the first successful medical application of penicillin a year away. Tuberculosis was a death sentence, even if it was a slow death with intervals of remission — a fact Richard and Arline faced with an ambivalent mix of brave lucidity and hope against hope. </p>
<p>Meanwhile, Richard’s parents met the prospect of his marriage with bristling dread. His mother, who believed he was marrying Arline out of pity rather than love, admonished him that he would be putting his health and his very life in danger, and coldly worried about how the stigma attached to tuberculosis would impact her brilliant young son’s reputation. “I was surprised to learn such a marriage is not unlawful,” she scoffed unfeelingly. “It ought to be.”</p>
<p>But Richard was buoyed by love — a love so large and luminous that he found himself singing aloud one day as he was arranging Arline’s transfer to a sanatorium. Determined to go through with the wedding, he wrote to his beloved:</p>
<blockquote><p>I guess maybe it is like rolling off of a log — my heart is filled again &amp; I’m choked with emotions — and love is so good &amp; powerful — it’s worth preserving — I know nothing can separate us — we’ve stood the tests of time and our love is as glorious now as the day it was born — dearest riches have never made people great but love does it every day — we’re not little people — we’re giants … I know we both have a future ahead of us — with a world of happiness — now &amp; forever.</p></blockquote>
<p>On June 29, 1942, they promised each other eternity. </p>
<figure id="attachment_62642"><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?resize=535%2C883&amp;ssl=1" alt="" width="535" height="883" srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?w=535&amp;ssl=1 535w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?resize=240%2C396&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?resize=320%2C528&amp;ssl=1 320w" sizes="(max-width: 535px) 100vw, 535px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?w=535&amp;ssl=1 535w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?resize=240%2C396&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?resize=320%2C528&amp;ssl=1 320w" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/richard_arline4.jpg?resize=535%2C883&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Richard and Arline on their wedding day</figcaption></figure>
<p>Gleick writes:</p>
<blockquote><p>He borrowed a station wagon from a Princeton friend, outfitted it with mattresses for the journey, and picked up Arline in Cedarhurst. She walked down her father’s hand-poured concrete driveway wearing a white dress. They crossed New York Harbor on the Staten Island ferry — their honeymoon ship. They married in a city office on Staten Island, in the presence of neither family nor friends, their only witnesses two strangers called in from the next room. Fearful of contagion, Richard did not kiss her on the lips. After the ceremony he helped her slowly down the stairs, and onward they drove to Arline’s new home, a charity hospital in Browns Mills, New Jersey.</p></blockquote>
<p>Meanwhile, WWII was reaching its crescendo of destruction, dragging America into the belly of death with the attack on Pearl Harbor. Now one of the nation’s most promising physicists, Feynman was recruited to work on what would become <a href="https://www.themarginalian.org/2011/10/14/richard-feynman-graphic-novel-biography-ottoviani/">the Manhattan Project</a> and soon joined the secret laboratory in Los Alamos. </p>
<figure id="attachment_62640"><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=680%2C787&amp;ssl=1" alt="" width="680" height="787" srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=240%2C278&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=320%2C370&amp;ssl=1 320w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=600%2C694&amp;ssl=1 600w" sizes="(max-width: 680px) 100vw, 680px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=240%2C278&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=320%2C370&amp;ssl=1 320w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=600%2C694&amp;ssl=1 600w" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_losalamos.jpg?resize=680%2C787&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Feynman’s Los Alamos badge</figcaption></figure>
<p>Arline entered the nearby Albuquerque sanatorium, from where she wrote him letters in code — for the sheer fun of it, because she knew how he cherished puzzles, but the correspondence alarmed the military censors at the laboratory’s Intelligence Office. Tasked with abating any breaches to the secrecy of the operation, they cautioned Feynman that coded messages were against the rules and demanded that his wife include a key in each letter to help them decipher it. This only amplified Arline’s sense of fun — she began cutting holes into her letters, covering passages with ink, and even mail-ordered a jigsaw puzzle kit with which to cut up the pages and completely confound the agents. </p>
<p>But the levity masked the underlying darkness which Richard and Arline tried so desperately to evade — Arline was dying. As her body failed, he steadied himself to her spirit:</p>
<blockquote><p>You are a strong and beautiful woman. You are not always as strong as other times but it rises &amp; falls like the flow of a mountain stream. I feel I am a reservoir for your strength — without you I would be empty and weak… I find it much harder these days to write these things to you.</p></blockquote>
<p>In every single letter, he told her that he loved her. <em>“I have a serious affliction: loving you forever,”</em> he wrote. </p>
<figure id="attachment_62641"><a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?resize=600%2C526&amp;ssl=1" alt="" width="600" height="526" srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?w=600&amp;ssl=1 600w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?resize=240%2C210&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?resize=320%2C281&amp;ssl=1 320w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?w=600&amp;ssl=1 600w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?resize=240%2C210&amp;ssl=1 240w, https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?resize=320%2C281&amp;ssl=1 320w" data-lazy-src="https://i0.wp.com/www.themarginalian.org/wp-content/uploads/2017/10/feynman_arline3.jpg?resize=600%2C526&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Richard and Arline at the Albuquerque sanatorium</figcaption></figure>
<p>In early 1945, two and a half years into their marriage, Richard and Arline made love for the first time. He had been too afraid of harming her frail health somehow, she too afraid of infecting him with the deadly bacterium consuming her. But Arline insisted that this pent up desire could no longer be contained and assured Richard that this would only bring them closer — to each other, and to the life they had so lovingly dreamt up for themselves:</p>
<blockquote><p>I’ll always be your sweetheart &amp; first love — besides a devoted wife — we’ll be proud parents too… I am proud of you always Richard –[you are] a good husband, and lover, &amp; well, coach, I’ll show you what I mean Sunday.</p></blockquote>
<p>But heightened as their hopes were by this new dimension of shared experience, Arline’s health continued to plummet. Her weight dropped to eighty-four pounds. Exasperated by the helplessness of medicine, which Feynman had come to see not as a manifestation but as a mutilation of the scientific method, he invested all hope in an experimental drug made of mold growths. “Keep hanging on,” he exhorted Arline. “Nothing is certain. We lead a charmed life.” She began spitting blood. </p>
<p>At twenty-seven, on the precipice of a brilliant scientific career, he was terminally in love. </p>
<p>On June 16, 1945, while working at the computing room at Los Alamos, Feynman received a call from the sanatorium that Arline was dying. He borrowed a colleague’s car and sped to the hospital, where he found her immobile, her eyes barely tracing his movement. Early in his scientific career, he had been animated by the nature of time. Now, hours stretched and contracted as he sat at her deathbed, until one last small breath tolled the end at 9:21PM.</p>
<p>The wake of loss has a way of tranquilizing grief with the pressing demands of practical arrangements — a tranquilizer we take willingly, almost gratefully. The following morning, Feynman arranged for his beloved’s cremation, methodically collected her personal belongings, and on the final page of the small spiral notebook in which she recorded her symptoms he wrote with scientific remove: “June 16 — Death.”</p>
<p>And so we arrive at Gleick’s improbable discovery in that box of letters — improbable because of the extreme rationality with which Feynman hedged against even the slightest intimation of metaphysical conjectures untestable by science and unprovable by reason. During his courtship of Arline, he had been vexed by her enthusiasm for Descartes, whose “proof” of God’s perfection he found intellectually lazy and unbefitting of Descartes’s reputation as <a href="https://www.themarginalian.org/2016/03/31/descartes-rules-for-the-direction-of-the-mind/">a champion of reason</a>. He had impishly countered Arline’s insistence that there are two sides to everything by cutting a piece of paper and half-twisting it into a Möbius strip, the ends pasted together to render a surface with just one side. </p>
<p>Everything that appeared mystical, Feynman believed, was simply an insufficiently explained mystery with a physical answer not yet found. Even Arline’s dying hour had offered testing ground for conviction. Puzzlingly, the clock in the room had stopped at exactly 9:21PM — the time of death. Aware of how this bizarre occurrence could foment the mystical imagination in unscientific minds, Feynman reasoned for an explanation. Remembering that he had repaired the clock multiple times over the course of Arline’s stay at the sanatorium, he realized that the instrument’s unwieldy mechanism must have choked when the nurse picked it up in the low evening light to see and record the time. </p>
<p>How astonishing and how touchingly human, then, that Feynman penned the letter Gleick found in the box forty-two years later — a letter he wrote to Arline in October of 1946, 488 days after her death:</p>
<blockquote><p>D’Arline,</p>
<p>I adore you, sweetheart.</p>
<p>I know how much you like to hear that — but I don’t only write it because you like it — I write it because it makes me warm all over inside to write it to you.</p>
<p>It is such a terribly long time since I last wrote to you — almost two years but I know you’ll excuse me because you understand how I am, stubborn and realistic; and I thought there was no sense to writing.</p>
<p>But now I know my darling wife that it is right to do what I have delayed in doing, and that I have done so much in the past. I want to tell you I love you. I want to love you. I always will love you.</p>
<p>I find it hard to understand in my mind what it means to love you after you are dead — but I still want to comfort and take care of you — and I want you to love me and care for me. I want to have problems to discuss with you — I want to do little projects with you. I never thought until just now that we can do that. What should we do. We started to learn to make clothes together — or learn Chinese — or getting a movie projector. Can’t I do something now? No. I am alone without you and you were the “idea-woman” and general instigator of all our wild adventures.</p>
<p>When you were sick you worried because you could not give me something that you wanted to and thought I needed. You needn’t have worried. Just as I told you then there was no real need because I loved you in so many ways so much. And now it is clearly even more true — you can give me nothing now yet I love you so that you stand in my way of loving anyone else — but I want you to stand there. You, dead, are so much better than anyone else alive.</p>
<p>I know you will assure me that I am foolish and that you want me to have full happiness and don’t want to be in my way. I’ll bet you are surprised that I don’t even have a girlfriend (except you, sweetheart) after two years. But you can’t help it, darling, nor can I — I don’t understand it, for I have met many girls and very nice ones and I don’t want to remain alone — but in two or three meetings they all seem ashes. You only are left to me. You are real.</p>
<p>My darling wife, I do adore you.</p>
<p>I love my wife. My wife is dead.</p>
<p>Rich.</p></blockquote>
<p>And then, with the sole defibrillator for heartache we have — humor — Feynman adds:</p>
<blockquote><p>PS Please excuse my not mailing this — but I don’t know your new address.</p></blockquote>
<p>Complement this particular portion of the altogether magnificent <a href="https://www.amazon.com/Genius-Life-Science-Richard-Feynman/dp/0679747044/?tag=braipick-20" target="_blank"><strong><em>Genius: The Life and Science of Richard Feynman</em></strong></a> with Rachel Carson’s <a href="https://www.themarginalian.org/2017/01/13/rachel-carson-dorothy-freeman-letters/">stunning deathbed farewell to her beloved</a> and Seneca on <a href="https://www.themarginalian.org/2017/05/02/seneca-consolation-to-helvia/">resilience in the face of loss</a>, then revisit Feynman on <a href="https://www.themarginalian.org/2015/05/11/richard-feynman-science-religion/">science and religion</a> and <a href="https://www.themarginalian.org/2013/08/08/richard-feynman-on-the-meaning-of-life/">the meaning of life</a>.</p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: I made an all-in-one desktop app with a no-BS approach to get work done (114 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37914672</link>
            <guid>37914672</guid>
            <pubDate>Tue, 17 Oct 2023 13:25:34 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37914672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37914672">
      <td><span></span></td>      <td><center><a id="up_37914672" href="https://news.ycombinator.com/vote?id=37914672&amp;how=up&amp;goto=item%3Fid%3D37914672"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37914672">Show HN: I made an all-in-one desktop app with a no-BS approach to get work done</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37914672">114 points</span> by <a href="https://news.ycombinator.com/user?id=daniel_sushil">daniel_sushil</a> <span title="2023-10-17T13:25:34"><a href="https://news.ycombinator.com/item?id=37914672">9 hours ago</a></span> <span id="unv_37914672"></span> | <a href="https://news.ycombinator.com/hide?id=37914672&amp;goto=item%3Fid%3D37914672">hide</a> | <a href="https://hn.algolia.com/?query=Show%20HN%3A%20I%20made%20an%20all-in-one%20desktop%20app%20with%20a%20no-BS%20approach%20to%20get%20work%20done&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37914672&amp;auth=f38a3d6ed7484dc442308956a4d8d2749544a02d">favorite</a> | <a href="https://news.ycombinator.com/item?id=37914672">82&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Hi HN! This is Daniel from Floutwork (<a href="https://www.floutwork.com/" rel="nofollow noreferrer">https://www.floutwork.com</a>)</p><p>Floutwork is an all-in-one desktop app designed to serve as a personal work system, offering a no-BS approach to getting real work done online.</p><p>Background:
 When I transitioned from a development role to a product management role, I realized there was no real organization or structure to the way I worked as a PM. Tasks I needed to complete were scattered across emails, Teams, meetings, etc. I was inundated with emails and found myself juggling multiple browser windows, numerous open tabs, and other desktop applications. This overwhelming situation made it clear that success in my new role hinged on being self-organized and focused. After reading the book "Deep Work" by Cal Newport, I recognized that my work habits were counterproductive to accomplishing meaningful work. After that, I delved further into the "focus and productivity" path, read more books on the subject, and decided to integrate these concepts and methodologies into a single app. I could have created a specialized tool that addressed only one or two problems, like many other apps out there, but I knew that building a single app designed to assist with the workflow from start to finish was the only way to eliminate as many distractions and friction points as possible. Honestly, I could've wrapped up development way sooner if I'd just tackled one issue. But what's the point if one part of my workflow rocks and the rest sucks?</p><p>What's the problem with modern work?
 You might be using a combination of a task manager and a calendar to track tasks. To work on a task, though, you probably bounce to your browser full of tabs. If you use desktop apps like Teams, Slack, or Discord, this bouncing back and forth becomes even worse because every link you click on opens in the browser. The real problem is when we jump to a browser full of tabs every time, we get distracted by all the tabs and get sidetracked, or our old habits kick in due to how our brains are now wired, and we start aimlessly browsing. This causes a lot of friction in our flow. This is one of the main reasons why people today are not able to focus or don't feel motivated to get work done. What usually takes 1 hour to complete can take up to 3 hours.</p><p>What's unique about Floutwork?
 Floutwork has an excellent task management system and a calendar view right next to it to intelligently show you when you can work on your tasks amidst your busy schedule. However, it goes beyond that and lets you pin your work apps right within Floutwork. Once you know you need to work on a task, you can quickly hop on to your web apps right within Floutwork and get that done, and then repeat. Every time you access a web app within Floutwork, any tabs you open within that app stay within that app, so you only get to see the tabs to get your current task done. This powerful flow cuts down all the distractions and friction points that come between tasks and work getting done.</p><p>Now that all your work can be consolidated into one unified system, you can access powerful tools in a distraction-free way to:</p><p>- Monitor your work habits</p><p>- Gamify your tasks</p><p>- Experience an immersive focus mode for tasks</p><p>- Open a command bar without losing your flow to open apps, links, tools, add tasks, ask ChatGPT, etc.</p><p>- Quickly take work notes in context</p><p>- Clean out your emails with a few clicks</p><p>- Access AI tools via ChatGPT meaningfully right within your flow</p><p>This app is designed for people in roles like PMs, freelancers, managers, admins, and marketers, where being self-organized online is crucial for success. I know the HN community has a lot of developers. While this app can offer some benefits to devs, it won't be a game-changer for your workflow, especially if you're primarily in VS Code or other desktop development tools most of the day.</p><p>I'd love to invite you all to try out the product and would appreciate hearing your feedback!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Riffusion with Lyrics (168 pts)]]></title>
            <link>https://www.riffusion.com/</link>
            <guid>37914425</guid>
            <pubDate>Tue, 17 Oct 2023 13:11:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.riffusion.com/">https://www.riffusion.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37914425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><title>Riffusion</title><div><div><header><div><p><a href="https://www.riffusion.com/"><img src="https://www.riffusion.com/riffusion-logo.svg"></a></p></div></header></div><div><a href="https://www.riffusion.com/"><div><p><span>Explore</span></p></div></a></div><div><main><div><div><p><img src="https://www.riffusion.com/riffusion-logo.svg"></p></div><p>Explore riffs</p></div></main></div><div><main><div><div><p><img src="https://www.riffusion.com/riffusion-logo.svg"></p></div><p>Explore riffs</p></div></main></div></div><div><div><p>0:00</p><p>0:00</p></div></div><div role="region" aria-label="Notifications (F8)" tabindex="-1"><ol tabindex="-1"></ol></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Small business owners say they're pressured to hire off-duty cops for security (527 pts)]]></title>
            <link>https://minnesotareformer.com/2023/10/17/small-business-owners-they-are-pressured-to-hire-off-duty-mpd-cops-for-security/</link>
            <guid>37914243</guid>
            <pubDate>Tue, 17 Oct 2023 12:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minnesotareformer.com/2023/10/17/small-business-owners-they-are-pressured-to-hire-off-duty-mpd-cops-for-security/">https://minnesotareformer.com/2023/10/17/small-business-owners-they-are-pressured-to-hire-off-duty-mpd-cops-for-security/</a>, See on <a href="https://news.ycombinator.com/item?id=37914243">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="dataContent">
                                    <p><span>When Maya Santamaria was opening a Minneapolis club in 2003, a city worker handed her a card for a Minneapolis police officer and said, “You’re going to work with this guy.”</span></p>
<p><span>To get a business license, a licensing employee told her she had to hire a certain number of off-duty Minneapolis police officers to provide security.</span></p>
<p><span>Why?</span></p>
<p><span>“Because they’re racist and we’re Mexican,” Santamaria said. “They didn’t want to let Mexicans have nightclubs.”</span></p>
<p><span>That’s her conclusion after seeing other similar-sized, white-owned venues escape the same mandate.</span></p>
<p><span>With over a million dollars invested, Santamaria had little choice. “You gotta do what they say,” she said.</span></p>
<p><span>Then, MPD “socked it to me,” she said. She started out paying the officers $40 to $45 an hour, always more than one officer per night. And they didn’t just work one or two hours; they charged a minimum of four hours no matter how many they actually worked, she said. The pay gradually increased to nearly $60 an hour.</span></p>
<p><span>“I spent hundreds of thousands of dollars,” she said. “There were many years I wasn’t making it, and they didn’t give a damn.”</span></p>
<p><span>Santamaria was later required to come up with security plans outlining the number of officers needed per night. The officers insisted on getting paid cash, she said. She feared if she didn’t oblige, she’d lose her license.</span></p>
<p><span>Eventually, another officer helped schedule off-duty work: Derek Chauvin. He worked security at her club for 17 years.</span></p>
<p><span>“They were in charge and everybody had to go through them,” she said.</span></p>
<p><span>El Nuevo Rodeo became Minnesota’s largest Latino concert venue, and while there were a few brawls, “We never were a problem property,” Santamaria said.</span></p>
<p><span>MPD officers would usually sit in their squad cars, fully uniformed, and do crossword puzzles or chat with their girlfriends or spouses. Sometimes they’d leave to go help MPD with calls.</span></p>
<p><span>“They were gone half the time,” Santamaria said. “They were on my payroll but they were gone.”</span></p>
<p><span>She sold the club in 2019. When Santamaria saw Chauvin pinning George Floyd on the pavement in the video that shocked the world, she recognized both, because Floyd worked as a bouncer inside the club in 2019.&nbsp;</span></p>
<p><span>El Nuevo Rodeo burned to the ground during the subsequent riots.</span></p>
<p><span>Santamaria’s allegations about MPD off-duty work are echoed by the experiences of other business owners, documented in government reports and even remarked upon by the city’s new police chief, Brian O’Hara.</span><a target="_blank" href="https://www.southwestvoices.news/posts/new-police-chief-candidly-talks-about-youth-violence-police-policies"><span> He </span><span>said</span></a><span> the system is “ripe for corruption,” citing a </span><a target="_blank" href="https://www.nj.com/hudson/2020/12/jersey-city-brings-back-off-duty-jobs-program-for-cops-after-halting-it-over-of-corruption.html"><span>federal investigation</span></a><span> in Jersey City, where a dozen cops were arrested due to widespread corruption of off-duty work.&nbsp;</span></p>
<p><span>The timing is favorable for more rigorous oversight: MPD is soon to be operating under both state and federal supervision following damning investigative reports about racist policing, and O’Hara is a newish outsider who speaks the rhetoric of reform.&nbsp;</span></p>
<p><span>Changes to off-duty policy face a key obstacle, however: A 1997 court injunction restricts how much the city can manage officers’ side gigs. Given the injunction, the city can only seek major reforms via the collective bargaining process, which means if the city wants to change off-duty policies, it would likely have to give up something in return.&nbsp;</span></p>
<p><span>Here’s how the off-duty work program works: Some businesses — like large nightclubs —&nbsp;are required by the city to have security, which until 2020, sometimes had to be off-duty Minneapolis police officers.&nbsp;</span></p>
<p><span>The city can also require that organizers of large events and businesses plagued with a lot of 911 calls also hire off-duty MPD officers. Businesses may also voluntarily hire off-duty officers for security and traffic control, and negotiate pay and hours directly with officers.&nbsp;</span></p>
<p><span>The city doesn’t keep track of how much officers are working or how much they’re paid, or even have access to the contracts. Off-duty work often pays a lot more — up to hundreds of dollars per hour — than working overtime for MPD.&nbsp;</span></p>
<p><span>Some officers are still paid in cash, increasing the risk of tax evasion. And, several business owners and Minneapolis officials said some small business owners —&nbsp;particularly those owned by immigrants — have been led to believe they must hire MPD officers, or risk getting ghosted by police.&nbsp;</span></p>
<p><span>It was precisely this arrangement that caught the attention of the U.S. Department of Justice in its 2011 report on the New Orleans Police Department.&nbsp;</span></p>
<p><span>In fact, the MPD off-duty situation has parallels to NOPD before the feds arrived.&nbsp;</span></p>
<p><span>The recent DOJ investigative report about MPD drew only a passing —&nbsp;</span><a target="_blank" href="https://minnesotareformer.com/2023/08/16/doj-mpd-off-duty-work-system-undermines-supervision/"><span>but still condemnatory</span></a><span> — reference to off-duty jobs. The DOJ was looking for racism. Some business owners of color say look no further.&nbsp;</span></p>
    <h4>‘Instead of helping us, they’re hurting us’</h4>

	
<p><span>Basim Sabri, owner of a Somali mall called Karmel Mall and a Latino mall called Plaza Mexico on Lake Street, said he held a Cinco de Mayo party every year for 27 years to encourage people to come to the area and see that “It really isn’t a war zone, it is a beautiful place.”</span></p>
<p><span>For years, they never had police there, and then about a dozen years ago, he said, there was a shooting a few blocks away from the event. The city began requiring him to hire off-duty police.&nbsp;</span></p>
<p><span>“Lake Street has been tremendously damaged, and instead of helping us, they’re hurting us,” said Sabri, who once </span><a target="_blank" href="https://bringmethenews.com/news/developer-convicted-in-bribery-back-at-minneapolis-city-hall-pushing-reforms"><span>went to prison</span></a><span> for bribing a city council member.</span></p>
<p><span>The officer rates have skyrocketed, he said. He pays officers $150 to $160 an hour, and a “scheduler” also charges $15 to $20.</span></p>
<p><span>Despite the big payouts, when he calls the police for help, they don’t always respond, Sabri said. About six weeks ago, a man came into his office with a gun and said he was going to shoot someone. They called 911, but the police never came, Sabri said.&nbsp;</span></p>
<p><span>An MPD spokesman said “Going back to July 1, all calls we found relating to guns at Karmel Mall did have a police response, and none of the calls match the details” of Sabri’s account.&nbsp;&nbsp;</span></p>
<p><span>Jonathan Soto, owner of EME Antro night club at Fifth Avenue and Lake Street, hired MPD officers — including Chauvin — to monitor his parking lot for a couple of years, but stopped after Floyd’s murder.&nbsp;</span></p>
<p><span>The officers wanted to be paid in cash, and would sometimes leave to respond to police calls, which benefited the city, he said.</span></p>
<p><span>“The city kind of liked that,” Soto said.</span></p>
<p><span>The FBI interviewed him after Floyd was killed, asking how much he paid officers.</span></p>
<p><span>Other business owners said the officers don’t always respond to problems right under their noses.</span></p>
<p><span>Santamaria said the club next to her was tiny but “had to have their own cop,” who she described as an “old guy” who would refuse to help anybody from her club,</span></p>
<p><span>After several East African-owned stores on Franklin Avenue in Minneapolis were vandalized in September 2019, Capitol Café owner Abdirahman Awad called his friend KB Brown, owner of a north Minneapolis print shop and a member of the Main Street Alliance of Minnesota, a group of progressive business owners.</span></p>
<p><span>KB Brown said the detectives were rude and disrespectful to Awad. Awad said MPD later told him he’d have to pay off-duty officers $145 an hour to provide security. He returned the next night and saw almost no police presence despite the alleged hate crime. In his view, MPD was sending a message that the cafe would only get protection if it hired off-duty officers.</span></p>
<p><span>“I felt so angry about it,” he said.</span></p>
<p><span>Kevin Brown, another member of the Main Street Alliance, said Somali business owners have told him MPD pressured them to hire off-duty officers, but they’re afraid to go public because they’ve been threatened with being “blacklisted” by MPD — or ignored when they call police for help.</span></p>
<p><span>“They get to make the rules,” Kevin Brown said.</span></p>
<p><span>Not all business owners feel that way, however.</span></p>
<p><span>When John Wolf bought his liquor store, Chicago-Lake Liquors, in 2000, he inherited the off-duty officers who did security there and continued hiring them. Some officers preferred to be paid in cash, but he said he didn’t do that.&nbsp;</span></p>
<p><span>One officer scheduled all the shifts, which were 5 p.m. to closing. The cops roved around inside and outside the liquor store and sometimes left to respond to MPD calls — even though Wolf was paying them. Wolf didn’t mind.</span></p>
<p><span>“I had really, really good people working here,” said Wolf, who</span><a target="_blank" href="https://x.com/nickhaltermpls/status/1295416454880219137?s=20"> <span>appeared</span></a><span> with Donald Trump at an August 2020 campaign stop.</span></p>
<p><span>But after Floyd’s murder, he made a business decision to stop hiring the officers because they were “pricey” and “hard to get.”</span></p>
<p><span>&nbsp;“The situation became very complicated after George Floyd,” Wolf said.</span></p>
    <h4>
Former council member calls off-duty tactics ‘sleazy and illegal’
</h4>

	
<p><span>In the aftermath of Floyd’s killing, MPD went under a microscope, including off-duty work.</span></p>
<p><span>Some private businesses and school districts cut ties with the police. Within days, the Minneapolis Orchestra, Minneapolis Institute of Art and iconic club First Avenue said they’d no longer hire them.&nbsp;</span></p>
<p><span>One of the few things the city does keep tabs on is sites for off-duty work, which must be approved. </span><span>Officers worked off-duty at about 500 sites in 2018, but that number has dropped to about 100 this year. About 200 officers have worked these gigs this year, according to </span><span>Regulatory Services Director Enrique Velazquez</span><span>.</span></p>
<p><span>In 2020, the Minneapolis City Council stopped requiring off-duty officers at licensed events, and let them hire private security instead. In August 2020, </span><span>Velazquez </span><span>told the City Council only four businesses were being required to hire off-duty MPD officers. But some businesses were voluntarily hiring them because they were under the impression they had no choice, he said. Others thought if they hired police officers they would get “some level of preferential treatment,” he said.</span></p>
<p><span>Velazquez said this was discussed with Mayor Jacob Frey’s</span><a target="_blank" href="https://minnesotareformer.com/2020/01/31/mayor-frey-aims-to-rein-in-off-duty-police-work-creates-task-force/"> <span>off-duty task force</span></a><span>, which was launched in January 2020, met twice, and then dissolved.</span></p>
<p><span>Former Minneapolis City Council Member Cam Gordon said small businesses owned by immigrants told him they were led to believe they wouldn’t get police service if they didn’t hire officers. They didn’t want to speak publicly about it, he said, out of fear of retaliation.</span></p>
<p><span>Some people of color said they were told if they wanted to get police to respond to 911 calls, they would have to hire the cops for security, and it could cost, say, $800 per night in cash.</span></p>
<p><span>That’s “sleazy” and illegal, Gordon said.</span></p>
<p><span>Gordon said running a business using city resources — uniforms, guns, squad cars — without city management, should be considered a violation of the city ethics code, even though the city explicitly allows it, even paying insurance for off-duty work.</span></p>
<p><span>“It creates this whole system of unaccountability in terms of the money, especially if people are paid under the table in cash,” Gordon said.</span></p>
<p><span>A</span><a target="_blank" href="https://lims.minneapolismn.gov/Download/File/2859/Police%20Off-Duty%20Work%20Audit%20Report_Revised%2010092019.pdf"> <span>2019 city audit</span></a><span> noted cash payment was preferred by some employers and officers. The audit recommended ending cash payments and putting the city in charge of the program, but like so many other MPD issues, change has been glacial. MPD policy was updated to limit hours — including off-duty gigs — and prioritize overtime over off-duty work. MPD is instituting a new timekeeping system to track off-duty hours.</span></p>
<p><span>The city’s insurance liability for officers working side gigs can get expensive: The city was forced to defend Lt. Mike Sauro after he arrested, handcuffed and beat a 21-year-old college student in a kitchen. Sauro was off duty, working at a club on New Year’s Eve in 1991. A jury awarded the victim over $1 million in damages, the largest civil award in a police misconduct case in the city’s history at the time, </span><a target="_blank" href="https://www.hrw.org/legacy/reports98/police/uspo86.htm"><span>according</span></a><span> to Human Rights Watch.</span></p>
<p><span>After that, former Police Chief Robert Olson vowed to limit officers’ off-duty time, saying the city didn’t have the responsibility to make sure private businesses run smoothly. But 28 years later, the off-duty work continues.&nbsp;</span></p>
<p><span>Even amid the fury after Floyd’s police killing, the council made negligible changes to the off-duty program. Off-duty work is part of the police union contract. The Minneapolis Police Federation said during the last negotiation that any change to off-duty work was a non-starter. Now, negotiations are underway again on the next three-year contract.</span><span>&nbsp;</span></p>
    <h4>City may challenge 1997 injunction that ties its hands on off-duty issues</h4>

	
<p><span>Weeks after Floyd’s death at the hands of his officers, Minneapolis Police Chief Medaria Arradondo withdrew from labor negotiations, saying the contract would be reviewed with the help of outside experts.</span></p>
<p><span>But even as crime spiked, MPD began hemorrhaging officers, and a judge</span><a target="_blank" href="https://minnesotareformer.com/briefs/order-requiring-minneapolis-to-hire-more-cops-reversed-by-court-of-appeals/"> <span>ordered</span></a><span> the city to hire more cops to comply with the city charter. Negotiations were suddenly focused on recruiting and retaining cops.</span></p>
<p><span>A coalition of police reform groups called Minneapolis for a Better Police Contract formed in 2019 to push city officials to use the police labor contract as a tool for reform.</span></p>
<p><span>“Off-duty work is corrupt,” said Stacey Gurian-Sherman, a lawyer on the group’s steering committee.&nbsp;</span></p>
<p><span>The group made 22 recommendations for the contract, including limiting the number of days and hours officers can work, counting overtime and off-duty work. They recommended officers be paid for off-duty work the same way they’re paid for “</span><a target="_blank" href="https://minnesotareformer.com/briefs/downtown-minneapolis-neighborhood-raising-money-for-more-police-patrols/"><span>buyback</span></a><span>” work in which neighborhoods or organizations pay for extra patrols. Those officers are paid $107 an hour, but payroll is handled by the city.</span></p>
<p><span>Aside from labor negotiations, the group says the City Council could make changes to make off-duty work centralized, fair and not subject to the whims of any one police officer. St. Paul, Duluth, Bloomington and Rochester all have such centralized systems.</span></p>
<p><span>In January, the City Council voted to review off-duty work, including how officers get jobs, how much they’re paid and how it affects MPD staffing.&nbsp;</span></p>
<p><span>Council Member Robin Wonsley authored the legislative directive and is working on a policy that would charge businesses fees to recoup city costs, but the city is largely powerless given the 1990s era court injunction against changing the side gigs policy.</span></p>
<p><span>The 1997 injunction and settlement came after former Mayor Sharon Sayles Belton tried to put the system under the city’s control. The union argued changes to off-duty must be negotiated as part of the union contract, and the agreement says officers have the right to contract with outside employers. It also says officers aren’t allowed to act as brokers, though police seem to be ignoring the proscription.</span></p>
    <a href="https://minnesotareformer.com/subscribe">
    <div>
			<p>GET THE MORNING HEADLINES DELIVERED TO YOUR INBOX</p>
        </div>
    </a>
	
<p><span>It would be expensive for the city to take over the off-duty program, however, since officers would be paid through the city, at an overtime rate, and the pay would count toward their pension benefit calculation.</span></p>
<p><span>Mayor Jacob Frey told the </span><i><span>Reformer</span></i><span> off-duty work is “one of the more difficult and intractable” issues facing MPD, and the 1997 injunction is a major roadblock to change.&nbsp;</span></p>
<p><span>Asked whether the city might try to get it revoked, he said, “We’re talking.”&nbsp;</span></p>
<p><span>The police contract doesn’t give the city much authority over off-duty work, but ideally the city would have more managerial oversight, Frey said.</span></p>
<p><span>“It will be a topic that is covered,” during negotiations, he said. “It would make the process more fair and equitable both to police officers and businesses hiring them. We could better ensure officers aren’t overworked by factoring off-duty shifts into work scheduling. It would also streamline the process.”&nbsp;</span></p>
<p><span>Frey said the city needs its officers working more on-duty, rather than off-duty, which he acknowledges will cost more. In other words, pump up their regular pay so they’re less inclined to take the lucrative off-duty work.</span></p>
<p><span>Minneapolis police officers start out making about $73,000 annually, but many are working mega overtime hours due to short staffing, </span><a target="_blank" href="https://minnesotareformer.com/2023/06/15/minneapolis-police-officers-continue-to-rack-up-hefty-overtime-as-understaffing-continues/"><span>pushing their salaries sky-high</span></a><span>; 70% of officers made six figures last year.&nbsp;</span></p>
<p><span>Neither the police union nor MPD responded to multiple requests for comment.</span></p>
    <h4>MPD system mirrors New Orleans, before reforms</h4>

	
<p><span>Many of the concerns about MPD’s off-duty system mirror those federal investigators found in New Orleans when the U.S. Department of Justice</span><a target="_blank" href="https://www.justice.gov/sites/default/files/crt/legacy/2011/03/17/nopd_report.pdf"> <span>found</span></a><span> their off-duty work — what they call paid details — facilitated abuse and corruption, contributed to officer fatigue and inequitable policing and was a financial drain on the city.</span></p>
<p><span>A vestige of the days when NOPD’s starting pay was among the lowest in the nation, paid details became so enticing — with some cops paid $300 to $500 a night to provide security for professional athletes — that some officers were more committed to the side hustles than their actual jobs.</span></p>
<p><span>NOPD Officers would “ghost” work after roll call, leave in the middle of an investigation, and double dip or use sick leave to do details, the DOJ found.</span></p>
<p><span>Last summer, the MPD — down 300 officers —&nbsp;struggled to cover shifts. Some officers were doing off-duty shifts rather than overtime for the city.&nbsp;</span></p>
<p><span>Only a dozen cops were patrolling downtown on weekend night shifts.</span><a target="_blank" href="https://minnesotareformer.com/2022/08/25/policing-minneapolis-amid-a-staffing-shortage/"> <span>One night</span></a><span>, as a police dispatcher tried to find a cop to respond to reports of a man pointing a gun at people, Lt. Kelly O’Rourke, who was in charge of policing the downtown area,</span> <span>pulled into a parking lot where an off-duty officer was sitting in a squad car, monitoring the lot near nightclubs.</span></p>
<p><span>The officers make two to four times as much pulling an off-duty shift, so they prefer to do that, O’Rourke</span><a target="_blank" href="https://minnesotareformer.com/2022/08/25/policing-minneapolis-amid-a-staffing-shortage/"> <span>said</span></a><span> at the time.</span></p>
<p><span>The DOJ said MPD’s system</span><a target="_blank" href="https://minnesotareformer.com/2023/08/16/doj-mpd-off-duty-work-system-undermines-supervision/"> <span>undermines</span></a><span> supervision of officers because patrol officers manage disbursement of the gigs, deciding who gets the work — including supervisors. That creates a disincentive for supervisors to hold those officers accountable for misconduct, the DOJ said.</span></p>
<p><span>In New Orleans, the officers scheduling off-duty work got extra pay from businesses, making up to $200 per week, the DOJ found. MPD officers also get paid for scheduling off-duty officers.</span></p>
<p><span>And as in Minneapolis, some New Orleans business owners felt pressured to hire the police.</span></p>
<p><span>“Businesses sometimes feel they must pay for details to obtain the police services that should be provided by NOPD as a matter of routine policing,” the DOJ said. “In addition, businesses have no way to hold officers accountable when they do not show up for their contracted detail or perform poorly while on detail.”</span></p>
<p><span>In 2010, New Orleans banned cash payments and began centralizing the system, with</span><a target="_blank" href="https://www.police1.com/local-government/articles/judge-new-orleans-cops-can-work-more-off-duty-details-to-combat-crime-tAg98hZYnlbfFplt/"> <span>mixed results</span></a><span>.</span></p>
<p><span>If the city of Minneapolis fails to reform off-duty work, Gurian-Sherman, the lawyer pushing for MPD reforms, hopes the DOJ forces its hand.</span></p>
<p><span>“This is happening in full view,” Gurian-Sherman said. “The city has to stop looking the other way.”</span></p>
    <h4>‘It’s a racket’</h4>

	
<p><span>When it became clear that Chauvin and Floyd knew each other because they both worked at El Nuevo Rodeo, the whole world wanted to hear from Santamaria about her two former employees — one dead and one a cop charged with killing him.</span></p>
<p><span>Later, Chauvin was charged with evading taxes on what she’d paid him.&nbsp;&nbsp;</span></p>
<p><span>Prosecutors said Chauvin failed to pay taxes on $95,920 he earned doing security for El Nuevo Rodeo between 2014 and 2019. In addition to EME Antro Bar, where prosecutors said Chauvin was paid $250 cash for 3.5 hours, he also worked off-duty shifts at Cub Foods and Midtown Global Market.</span></p>
<p><span>Chauvin pleaded guilty to two crimes in March, saying he didn’t report the payments due to financial problems, and was sentenced to 13 months in prison.&nbsp;&nbsp;</span></p>
<p><span>Santamaria — who owns a Spanish language radio station, La Raza 95.7FM — was interviewed by state investigators about her work with MPD.</span></p>
<p><span>She looks back on those days with disgust. She sensed the city licensing division was in cahoots with MPD to make minority business owners hire the police.</span></p>
<p><span>“It’s a racket,” she said. “You were damned if you did, damned if you didn’t … you were always having to break the law.”</span></p>
    <a href="https://minnesotareformer.com/donate">
    
    </a>
	
                                </div><div>
                                        
                                        <p>Our stories may be republished online or in print under Creative Commons license CC BY-NC-ND 4.0. We ask that you edit only for style or to shorten, provide proper attribution and link to our web site. Please see our republishing guidelines for use of photos and graphics.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mypy 1.6 (155 pts)]]></title>
            <link>https://mypy-lang.blogspot.com/2023/10/mypy-16-released.html</link>
            <guid>37914146</guid>
            <pubDate>Tue, 17 Oct 2023 12:51:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mypy-lang.blogspot.com/2023/10/mypy-16-released.html">https://mypy-lang.blogspot.com/2023/10/mypy-16-released.html</a>, See on <a href="https://news.ycombinator.com/item?id=37914146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5084670918402599778" itemprop="description articleBody">

<meta charset="utf-8">

<p>We’ve just uploaded mypy 1.6 to the Python Package Index (<a href="https://pypi.org/project/mypy/">PyPI</a>). Mypy is a static type checker for Python. This release includes new features, performance improvements and bug fixes. You can install it as follows:


</p><pre>    python3 -m pip install -U mypy
</pre>

<p>You can read the full documentation for this release on <a href="http://mypy.readthedocs.io/">Read the Docs</a>.

</p><h2>Introduce Error Subcodes for Import Errors</h2>

<p>Mypy now uses the error code <tt>import-untyped</tt> if an import targets an installed library that doesn’t support static type checking, and no stub files are available. Other invalid imports produce the <tt>import-not-found</tt> error code. They both are subcodes of the <tt>import</tt> error code, which was previously used for both kinds of import-related errors. 

</p><p>Use <tt>--disable-error-code=import-untyped</tt> to only ignore import errors about installed libraries without stubs. This way mypy will still report errors about typos in import statements, for example.

</p><p>If you use  <tt>--warn-unused-ignore</tt> or <tt>--strict</tt>, mypy will complain if you use <tt># type: ignore[import]</tt> to ignore an import error. You are expected to use one of the more specific error codes instead. Otherwise, ignoring the <tt>import</tt> error code continues to silence both errors.

</p><p>This feature was contributed by Shantanu (PR <a href="https://github.com/python/mypy/pull/15840">15840</a>, PR <a href="https://github.com/python/mypy/pull/14740">14740</a>).

</p><h2>Remove Support for Targeting Python 3.6 and Earlier</h2>

<p>Running mypy with <tt>--python-version 3.6</tt>, for example, is no longer supported. Python 3.6 hasn’t been properly supported by mypy for some time now, and this makes it explicit. This was contributed by Nikita Sobolev (PR <a href="https://github.com/python/mypy/pull/15668">15668</a>).

</p><h2>Selective Filtering of <tt>--disallow-untyped-calls</tt> Targets</h2>

<p>Using <tt>--disallow-untyped-calls</tt> could be annoying when using libraries with missing type information, as mypy would generate many errors about code that uses the library. Now you can use <tt>--untyped-calls-exclude=acme</tt>, for example, to disable these errors about calls targeting functions defined in the <tt>acme</tt> package. Refer to the <a href="https://mypy.readthedocs.io/en/latest/command_line.html#cmdoption-mypy-untyped-calls-exclude">documentation</a> for more information.

</p><p>This feature was contributed by Ivan Levkivskyi (PR <a href="https://github.com/python/mypy/pull/15845">15845</a>).

</p><h2>Improved Type Inference between Callable Types</h2>

<p>Mypy now does a better job inferring type variables inside arguments of callable types. For example, this code fragment now type checks correctly:


</p><pre>    def f(c: Callable[[T, S], None]) -&gt; Callable[[str, T, S], None]: ...
    def g(*x: int) -&gt; None: ...
    
    reveal_type(f(g))  # Callable[[str, int, int], None]
</pre>

<p>This was contributed by Ivan Levkivskyi (PR <a href="https://github.com/python/mypy/pull/15910">15910</a>).

</p><h2>Don’t Consider None and TypeVar to Overlap in Overloads</h2>

<p>Mypy now doesn’t consider an overload item with an argument type <tt>None</tt> to overlap with a type variable:

</p><pre>    @overload
    def f(x: None) -&gt; None: ..
    @overload
    def f(x: T) -&gt; Foo[T]: ...
    ...
</pre>

<p>Previously mypy would generate an error about the definition of <tt>f</tt> above. This is slightly unsafe if the upper bound of <tt>T</tt> is <tt>object</tt>, since the value of the type variable could be <tt>None</tt>. We relaxed the rules a little, since this solves a common issue.

</p><p>This feature was contributed by Ivan Levkivskyi (PR <a href="https://github.com/python/mypy/pull/15846">15846</a>).

</p><h2>Improvements to <tt>--</tt><tt>new-type-inference</tt></h2>

<p>The experimental new type inference algorithm (polymorphic inference) introduced as an opt-in feature in mypy 1.5 has several improvements:

</p><ul>
<li>Improve transitive closure computation during constraint solving (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15754">15754</a>)
</li><li>Add support for upper bounds and values with <tt>--new-type-inference</tt> (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15813">15813</a>)
</li><li>Basic support for variadic types with <tt>--new-type-inference</tt> (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15879">15879</a>)
</li><li>Polymorphic inference: support for parameter specifications and lambdas (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15837">15837</a>)
</li><li>Invalidate cache when adding <tt>--new-type-inference</tt> (Marc Mueller, PR <a href="https://github.com/python/mypy/pull/16059">16059</a>)
</li></ul>

<p><b>Note:</b> We are planning to enable <tt>--new-type-inference</tt> by default in mypy 1.7. Please try this out and let us know if you encounter any issues.

</p><h2>ParamSpec Improvements</h2>
<ul>
<li>Support self-types containing ParamSpec (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15903">15903</a>)
</li><li>Allow “…” in Concatenate, and clean up ParamSpec literals (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15905">15905</a>)
</li><li>Fix ParamSpec inference for callback protocols (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15986">15986</a>)
</li><li>Infer ParamSpec constraint from arguments (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15896">15896</a>)
</li><li>Fix crash on invalid type variable with ParamSpec (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15953">15953</a>)
</li><li>Fix subtyping between ParamSpecs (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15892">15892</a>)
</li></ul>
<h2>Stubgen Improvements</h2>
<ul>
<li>Add option to include docstrings with stubgen (chylek, PR <a href="https://github.com/python/mypy/pull/13284">13284</a>)
</li><li>Add required <tt>...</tt> initializer to <tt>NamedTuple</tt> fields with default values (Nikita Sobolev, PR <a href="https://github.com/python/mypy/pull/15680">15680</a>)
</li></ul>
<h2>Stubtest Improvements</h2>
<ul>
<li>Fix <tt>__mypy-replace</tt> false positives (Alex Waygood, PR <a href="https://github.com/python/mypy/pull/15689">15689</a>)
</li><li>Fix edge case for <tt>bytes</tt> enum subclasses (Alex Waygood, PR <a href="https://github.com/python/mypy/pull/15943">15943</a>)
</li><li>Generate error if typeshed is missing modules from the stdlib (Alex Waygood, PR <a href="https://github.com/python/mypy/pull/15729">15729</a>)
</li><li>Fixes to new check for missing stdlib modules (Alex Waygood, PR <a href="https://github.com/python/mypy/pull/15960">15960</a>)
</li><li>Fix stubtest <tt>enum.Flag</tt> edge case (Alex Waygood, PR <a href="https://github.com/python/mypy/pull/15933">15933</a>)
</li></ul>
<h2>Documentation Improvements</h2>
<ul>
<li>Do not advertise to create your own <tt>assert_never</tt> helper (Nikita Sobolev, PR <a href="https://github.com/python/mypy/pull/15947">15947</a>)
</li><li>Fix all the missing references found within the docs (Albert Tugushev, PR <a href="https://github.com/python/mypy/pull/15875">15875</a>)
</li><li>Document <tt>await-not-async</tt> error code (Shantanu, PR <a href="https://github.com/python/mypy/pull/15858">15858</a>)
</li><li>Improve documentation of disabling error codes (Shantanu, PR <a href="https://github.com/python/mypy/pull/15841">15841</a>)
</li></ul>
<h2>Other Notable Changes and Fixes</h2>
<ul>
<li>Make unsupported PEP 695 features (introduced in Python 3.12) give a reasonable error message (Shantanu, PR <a href="https://github.com/python/mypy/pull/16013">16013</a>)
</li><li>Remove the <tt>--py2</tt> command-line argument (Marc Mueller, PR <a href="https://github.com/python/mypy/pull/15670">15670</a>)
</li><li>Change empty tuple from <tt>tuple[]</tt> to <tt>tuple[()]</tt> in error messages (Nikita Sobolev, PR <a href="https://github.com/python/mypy/pull/15783">15783</a>)
</li><li>Fix <tt>assert_type</tt> failures when some nodes are deferred (Nikita Sobolev, PR <a href="https://github.com/python/mypy/pull/15920">15920</a>)
</li><li>Generate error on unbound TypeVar with values (Nikita Sobolev, PR <a href="https://github.com/python/mypy/pull/15732">15732</a>)
</li><li>Fix over-eager <tt>types-google-cloud-ndb</tt> suggestion (Shantanu, PR <a href="https://github.com/python/mypy/pull/15347">15347</a>)
</li><li>Fix type narrowing of <tt>== None</tt> and <tt>in (None,)</tt> conditions (Marti Raudsepp, PR <a href="https://github.com/python/mypy/pull/15760">15760</a>)
</li><li>Fix inference for <tt>attrs.fields</tt> (Shantanu, PR <a href="https://github.com/python/mypy/pull/15688">15688</a>)
</li><li>Make “await in non-async function” a non-blocking error and give it an error code (Gregory Santosa, PR <a href="https://github.com/python/mypy/pull/15384">15384</a>)
</li><li>Add basic support for decorated overloads (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15898">15898</a>)
</li><li>Fix TypeVar regression with self types (Ivan Levkivskyi, PR <a href="https://github.com/python/mypy/pull/15945">15945</a>)
</li><li>Add <tt>__match_args__</tt> to dataclasses with no fields (Ali Hamdan, PR <a href="https://github.com/python/mypy/pull/15749">15749</a>)
</li><li>Include stdout and stderr in dmypy verbose output (Valentin Stanciu, PR <a href="https://github.com/python/mypy/pull/15881">15881</a>)
</li><li>Improve match narrowing and reachability analysis (Shantanu, PR <a href="https://github.com/python/mypy/pull/15882">15882</a>)
</li><li>Support <tt>__bool__</tt> with <tt>Literal</tt> in <tt>--warn-unreachable</tt> (Jannic Warken, PR <a href="https://github.com/python/mypy/pull/15645">15645</a>)
</li><li>Fix inheriting from generic <tt>@frozen</tt> attrs class (Ilya Priven, PR <a href="https://github.com/python/mypy/pull/15700">15700</a>)
</li><li>Correctly narrow types for <tt>tuple[type[X], ...]</tt> (Nikita Sobolev, PR <a href="https://github.com/python/mypy/pull/15691">15691</a>)
</li><li>Don't flag intentionally empty generators unreachable (Ilya Priven, PR <a href="https://github.com/python/mypy/pull/15722">15722</a>)
</li><li>Add tox.ini to mypy sdist (Marcel Telka, PR <a href="https://github.com/python/mypy/pull/15853">15853</a>)
</li><li>Fix mypyc regression with pretty (Shantanu, PR <a href="https://github.com/python/mypy/pull/16124">16124</a>)
</li></ul>
<h2>Typeshed Updates</h2>

<p>Typeshed is now modular and distributed as separate PyPI packages for everything except the standard library stubs. Please see <a href="https://github.com/python/typeshed/commits/main?after=6a8d653a671925b0a3af61729ff8cf3f90c9c662+0&amp;branch=main&amp;path=stdlib">git log</a> for full list of typeshed changes.

</p><h2>Acknowledgements</h2>

<p>Thanks to Max Murin, who did most of the release manager work for this release (I just did
  the final steps).
  
</p><p>Thanks to all mypy contributors who contributed to this release:

</p><ul>
<li>Albert Tugushev
</li><li>Alex Waygood
</li><li>Ali Hamdan
</li><li>chylek
</li><li>EXPLOSION
</li><li>Gregory Santosa
</li><li>Ilya Priven
</li><li>Ivan Levkivskyi
</li><li>Jannic Warken
</li><li>KotlinIsland
</li><li>Marc Mueller
</li><li>Marcel Johannesmann
</li><li>Marcel Telka
</li><li>Mark Byrne
</li><li>Marti Raudsepp
</li><li>Max Murin
</li><li>Nikita Sobolev
</li><li>Shantanu
</li><li>Valentin Stanciu
</li></ul>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Working in Silicon Valley was fun. Now it's just another miserable corporate gig (116 pts)]]></title>
            <link>https://www.businessinsider.com/tech-workers-employees-dissatisfied-jobs-new-data-labor-market-glassdoor-2023-10</link>
            <guid>37913659</guid>
            <pubDate>Tue, 17 Oct 2023 12:03:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/tech-workers-employees-dissatisfied-jobs-new-data-labor-market-glassdoor-2023-10">https://www.businessinsider.com/tech-workers-employees-dissatisfied-jobs-new-data-labor-market-glassdoor-2023-10</a>, See on <a href="https://news.ycombinator.com/item?id=37913659">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <p>For the first time in a long time, <a href="https://www.businessinsider.com/layoffs-google-microsoft-salesforce-tech-industry-employees-work-family-lesson-2023-1" data-analytics-product-module="body_link" rel="">tech workers are in a funk</a>.&nbsp;</p><p>The industry of innovation was long an outlier when it came to employee satisfaction. Sure, the business goals were ambitious and the deadlines were daunting, but the allure of building the future drew eager, educated young people into tech — not to mention the high salaries, potential for stock-market riches, laid-back dress codes, and gleaming offices with meals and gyms. This rare combination of generous compensation and a reasonable work-life balance kept tech workers happier than employees in other industries. Before the pandemic, over 80% of tech workers routinely said they would recommend their company to a friend, according to Glassdoor company reviews, higher than almost every other industry we tracked.&nbsp;</p><p>All that changed in 2023: <a href="https://www.businessinsider.com/tech-industry-fake-work-problem-bad-managers-bosses-layoffs-jobs-2023-7" data-analytics-product-module="body_link" rel="">Employee satisfaction among tech workers</a> has plummeted, falling in line with workers in finance and consulting — industries that often compete for the same pool of highly educated and in-demand talent. The growing angst among the tech class is palpable in anonymous online communities like<a href="https://www.glassdoor.com/apps.htm" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link"> Glassdoor's Fishbowl</a>, in work-focused <a href="https://www.businessinsider.com/how-linkedin-got-weird-work-life-blurred-lines-of-oversharing-2023-9" data-analytics-product-module="body_link" rel="">social media like Linkedin</a>, and even in <a href="https://www.businessinsider.com/amazons-slack-channel-for-workers-on-performance-improvement-plans-2023-4" data-analytics-product-module="body_link" rel="">internal Slack groups</a>. Reading through the anonymous and semi-anonymous woes and tips from the Glassdoor community, it's clear that many laid-off techies and new STEM grads are struggling to find work, applying to more open roles, and in some cases, lowering their expectations for pay and job satisfaction.&nbsp;</p><p>One data analyst in Glassdoor's #JobsInTech group recently wrote: "Cannot believe how difficult it has been this year to get a job. Applied for well over 600 jobs since 1st June, had a fair few interviews, but not getting any further. This is killing me." A <a href="https://joinfishbowl.com/post_c1uc1myi35" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link">project manager</a> expressed similar frustration: "I have been looking for over a year now. 25 years in IT. Sent out more than 900 applications. Reduced my rate in half. Do I just give up at this point and switch professions." These often raw sentiments stand in sharp contrast to the Goldilocks outlook painted by official labor-market data for the broader economy.&nbsp;</p><p>While there are plenty of explanations for this sudden vibe shift — from rising interest rates to stock-market swings — an inconvenient truth is that much of the tech sector's problems stem from the fact that the industry strayed from its roots of listening to the front lines. The collaborative culture at tech companies not only kept employees happy but also helped create better products for customers. The buildup of layers of management without also adding tech-savvy workers that build core products has resulted in a sclerotic environment that is weighing on employees. If the tech industry wants to get back to the flow zone of innovation, productivity, and workplace happiness, executives must restart conversations with the front-line workers that make their products — or risk losing what made Silicon Valley so desirable.&nbsp;&nbsp;</p><h2>Big tech, big money, big worries</h2><p>The easiest way for tech companies to explain away the sudden <a href="https://www.businessinsider.com/tech-job-site-blind-anxiety-burnout-recession-stock-crash-2022-5" data-analytics-product-module="body_link" rel="">sentiment shift</a> among tech workers is to place the blame on the curdling of the broader economic climate.</p><p>For over a decade, low-interest rates, steady consumer confidence, and an increasingly educated workforce created a business ecosystem that encouraged companies to make bold bets on the future. Tech companies, with visions of new ways of connecting the world and living our lives, were uniquely positioned to take advantage of this appetite for growth. To be credible, these bold bets required a patina of scientific innovation — Silicon Valley needed a phalanx of smart, savvy knowledge workers to deliver on the underlying promise of their new products. To woo these potential employees, tech companies had to lure them with cash or a better quality of life than the grueling but lucrative workplace culture of Wall Street firms. Over the past decade, the influx of investor cash facilitated by the favorable economic environment made those promises easy to keep.</p><p>That fertile ground was slowly salted over the past two years as the Federal Reserve pushed interest rates higher. By increasing the cost of borrowing money to fund risky ideas, rate hikes forced businesses across the economy to reevaluate the bets on their balance sheets and cut projects deemed unlikely to bring in profits in the short term. In an industry like tech, where companies regularly make multibillion-dollar bets on emerging technology that may not produce real profits for years, that's a lot of reevaluation.&nbsp;</p><p>Several prominent tech companies have taken an uncompromising stance to limit growth in compensation costs and enforce in-office work mandates: Microsoft <a href="https://www.businessinsider.com/microsoft-wont-raise-salaries-for-full-time-employees-this-year-2023-5" data-analytics-product-module="body_link" rel="">announced</a> in May that full-time employees would not receive raises this year, and Amazon has <a href="https://www.businessinsider.com/amazon-andy-jassy-rto-office-policy-employee-jobs-2023-8" data-analytics-product-module="body_link" rel="">notified</a> employees reluctant to return to the office that their jobs might be at stake. Winter and spring layoffs this year stretched some teams thin, and the looming threat of <a href="https://www.businessinsider.com/chatgpt-ai-technology-end-of-coding-software-developers-jobs-2023-4" data-analytics-product-module="body_link" rel="">generative AI</a> is sparking fears of job insecurity among workers who long viewed themselves as the winners in the enduring race between man and machine.&nbsp;</p><p>This turn in the economy is starting to weigh on the tech job market. Despite largely pristine <a href="https://www.businessinsider.com/jobs-unemployment-rate-labor-market-september-report-2023-10" data-analytics-product-module="body_link" rel="">headline jobs data</a>, the tech job market has become a distinct pocket of weakness. The labor market has softened sharply in at least two prominent tech communities — <a href="https://www.glassdoor.com/research/conversation-starter-tech-metro-recessions" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link">the California Bay Area and Austin, Texas</a> — where the local unemployment rate has increased by more than half a percentage point over the past year, a common signal of imminent recession. <a href="https://www.glassdoor.com/research/jobs-report-preview-september-2023" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link">Unemployment claims</a> from information-sector workers have doubled compared to a year ago — and, pandemic aside, are now on par with the highest levels since 2013.&nbsp;</p><p>But the truth is that the pressures of the broader economy are not the main cause of a sag in tech-worker satisfaction. Many other industries have felt the squeeze of higher interest rates and their spillover to consumer spending, but none have seen their employees' satisfaction dip as significantly as Silicon Valley. The underlying reasons for the unhappiness among tech workers have been building for some time — and they strike at the very heart of the industry's once-vaunted conventions.</p><h2>From hoodies to neckties</h2><p>At the core of the tech industry's current malaise is an aging corporate culture. Glassdoor employee-satisfaction data reveals two big changes that have been unfolding over the past several years, predating but accelerated by the COVID-19 pandemic.&nbsp;</p><p>First, the "<a href="https://www.glassdoor.com/research/jobs-report-preview-february-2023" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link">managementization</a>" of tech. Over the past five years or so, the ratio of front-line workers to managers has deteriorated — meaning there are more managers for every "maker" in tech than before. Earlier this year, before layoffs aimed to flatten organizational hierarchies, the number of front-line jobs was more or less where it stood on the eve of the pandemic, while the number of managerial jobs was 9% higher. Economy wide, there were on average 6.6 front-line workers per manager in 2018 and 2019, but post-pandemic, the ratio dropped to 6 to 1.</p><p>While the trend is not unique to the tech industry — it's also visible in industries like finance and healthcare — it's a sharp contrast from the historically flat hierarchies at companies that fueled the 1990s tech boom and a jarring shift for employees who were used to a more direct line to the top. Of course, many tech managers also perform front-line tasks such as coding or data analysis, and some managers manage processes instead of people (for instance, transportation managers). It's possible that as tech companies have grown into more complex organizations, <a href="https://www.businessinsider.com/middle-managers-great-flattening-organization-meta-tech-layoffs-firing-2023-3" data-analytics-product-module="body_link" rel="">more management layers</a> are necessary. But the underlying result is the same: The people building the products are increasingly removed from the people making strategic decisions.</p><p>Second, it's an open secret that the best jobs in tech aren't necessarily technical. The workers at big tech companies who report the highest job satisfaction in Glassdoor reviews aren't in technical or builder roles like engineering or science. While non-STEM roles — for instance, in human resources and marketing — can and often do contribute to cutting-edge technological innovations, they are more likely to focus on supporting and enabling the core technology.</p><p>It's worth asking why the employees furthest from the technical frontier are happier in their jobs than those making the actual products. Perhaps it's that they are more grateful for the opportunity, suspecting that their job opportunities might be bleaker in other industries — a sentiment suggested by the writer Kristi Coulter in her recently published <a href="https://us.macmillan.com/books/9780374600907/exitinterview" target="_blank" rel="noopener nofollow" data-analytics-product-module="body_link">memoir</a> about her decade-long career at Amazon. Or perhaps the rankings reflect overextended and under-resourced technical ranks.&nbsp;</p><p>The unavoidable truth is that working at the most familiar standard-bearers of tech has become a lot like working elsewhere in the economy: High pay is usually justified by a more demanding schedule and longer workdays (and often "work weekends"). This evolution isn't unusual — it's the well-trodden path for past generations of industry innovators. With time, they become bigger, more stable, and more routine. The tech titans of prior generations — from Ford Motor Company in the 1920s to Intel in the 1990s — were once workplace innovators but came to be known as boring, corporate giants as they aged into staples of the global economy.</p><h2>Can tech turn it around?</h2><p>All is not lost for the tech industry, however. Recapturing the spark of innovation among employees will require executives to recalibrate their organizational compass: flatten org structures, focus on the long horizon so that employees have the opportunity to feel stable in their roles, and re-prioritize investment in the core technical talent that drives the development of crucial products.&nbsp;</p><p>Fundamentally, it's about listening to and elevating the voices of front-line employees. When the workers directly involved in creating the technology are allowed to speak up, unconventional, bold ideas tend to bubble up. By asking questions beyond the senior management echo chamber, engaging employees one-on-one, and creating spaces for employees to voice their hopes and hunches in psychologically safe forums, tech companies can not only reignite their workplace culture but also better serve customers.&nbsp;</p><p>This kind of productive communication has perhaps become harder in an era of remote work — but we shouldn't pretend that it comes effortlessly in the office either. It's a starkly different, humbler skill set from the TED Talk theatrics and fundraising prowess that drove tech success over the past decade. To shake tech workers out of their recent funk and get the industry back on a path of innovation, companies need to start listening to their builders again and empower them to do what they do best.</p><hr><p><em><a href="https://www.businessinsider.com/author/aaron-terrazas" data-analytics-product-module="body_link" rel="">Aaron Terrazas</a> is chief economist at Glassdoor, providing research, analysis and commentary on today's evolving workplace and fast-changing labor market.</em></p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interviews in the Age of AI: Ditch Leetcode – Try Code Reviews Instead (176 pts)]]></title>
            <link>https://chrlschn.dev/blog/2023/07/interviews-age-of-ai-ditch-leetcode-try-code-reviews-instead/</link>
            <guid>37913506</guid>
            <pubDate>Tue, 17 Oct 2023 11:49:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrlschn.dev/blog/2023/07/interviews-age-of-ai-ditch-leetcode-try-code-reviews-instead/">https://chrlschn.dev/blog/2023/07/interviews-age-of-ai-ditch-leetcode-try-code-reviews-instead/</a>, See on <a href="https://news.ycombinator.com/item?id=37913506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <main>
            <main>
    <article>
      
      
      <time>Jul 31, 2023</time>
      
      
      <nav><ol><li><a href="#intro">Intro</a></li><li><a href="#8-reasons-to-consider-code-review-as-interview">8 Reasons to consider code review as interview</a></li><li><a href="#strategies">Strategies</a><ol><li><a href="#au-naturel">“Au naturel”</a></li><li><a href="#bug-hunter">Bug hunter</a></li><li><a href="#refactor-andredesign">Refactor and&nbsp;redesign</a></li><li><a href="#performance-oriented">Performance oriented</a></li><li><a href="#test-focused">Test focused</a></li><li><a href="#security-hawk">Security hawk</a></li><li><a href="#best-practices">Best practices</a></li></ol></li><li><a href="#try-coderevapp">Try CodeRev.app</a></li><li><a href="#closing-thoughts">Closing thoughts</a></li></ol></nav><hr>
<h2 id="intro">Intro</h2>
<p>A Medium story first popped in to my feed last year and it got me thinking about the state of how the tech industry interviews and evaluates candidates.</p>
<p><img src="https://chrlschn.dev/img/code-review-as-interview/coderev-1.png" alt="Medium article focused on why many senior devs fail leetcode interviews">
<em><a href="https://medium.com/the-coding-diaries/why-experienced-programmers-fail-coding-interviews-b22210ba343">https://medium.com/the-coding-diaries/why-experienced-programmers-fail-coding-interviews-b22210ba343</a></em></p>
<p>Recently, a friend shared with  me his plans to take some time off to study for common leetcode problems to practice as he was planning his applications for FAANG companies.</p>
<p>Is that really what one wants to select for when hiring for a new member of an engineering team - the person that had the most free time to invest in studying leetcode challenges?</p>
<p>Having been on both sides of the coin, I have always had a dislike for leetcode exercises as an evaluation mechanism for technical candidates for a number of reasons:</p>
<ol>
<li>As much as solving algorithmically complex problems is fun and rewarding, the reality is that for most productive developers, most of our coding time isn’t really focused on this type of work.</li>
<li>Most of us regularly reference StackOverflow, documentation, and other online resources when solving challenging coding problems day-to-day. We’ll chat with peers and whiteboard different ideas. With the explosion of AI coding tools, many devs are already including Copilot and ChatGPT into their workflows.</li>
<li>Many types/classes of complex problems, we may only code once or twice in a blue moon. For example, I have a complex Firestore abstraction layer that I wrote once, that I just keep reusing. The point of writing complex, high-abstraction code is so that you only write this type of code once.</li>
<li>It creates an artificial situation that induces stress. Few of us code while others are watching over our shoulders. And fewer of us are coding against a fixed time constraint in real life. For hard problems, I may go for a walk, talk to a co-worker, research algorithms, build small toy codebases first, etc. Quite honestly, most of us probably create our best code in isolation when we’re in a flow state; the exact opposite of a high-stakes interview.</li>
<li>Developers code best in their own environments with their own tools. Using an unfamiliar tool can be disorienting and again, add to stress and anxiety as someone watches.</li>
</ol>
<p>All of this means that <em>using this approach could end up measuring for all the wrong metrics or measuring for metrics that have very little impact on how well a candidate can productively fit into a team</em>.&nbsp;</p>
<p>Not only that, as teams become more reliant on generated code to increase productivity - whether Copilot or GPT-I think that the ability to quickly read that code and identify subtle defects in the context of the larger application or domain space becomes more valuable.</p>
<p><img src="https://chrlschn.dev/img/code-review-as-interview/coderev-2.gif" alt="GPT generating a solution to N-Queens">
<em>GPT generating the solution to a common leetcode challenge N-Queens</em></p>
<p>A while back, I had the opportunity to participate in an interview which was structured around <em>reviewing code</em> rather than writing code. It was a revelation. Rather than focus on coding exercises, using code reviews as interview can be a better way to evaluate software engineering candidates.</p>
<hr>
<h2 id="8-reasons-to-consider-code-review-as-interview">8 Reasons to consider code review as interview</h2>
<p>There are a few reasons why I think code reviews make for an inherently better technical interview experience:</p>
<ol>
<li>In the age of AI, an emerging reason is that using AI generated code is a source of risk in terms of performance, security, and internal best practices (especially important in regulated industries).  Being able to effectively evaluate code in the context of the larger codebase becomes an even more important skill when relying on piecemeal generated code.</li>
<li>It is a better reflection of the day-to-day activities that engineers - especially more senior roles - engage in. Providing effective guidance and quality feedback to peers and especially junior team members can improve overall productivity and output quality in the long run.</li>
<li>It provides a more holistic view of how a candidate reasons, thinks, and communicates; in other words, it provides a better picture of the candidate as a teammate on the whole. This includes insights into the candidate’s depth of experience.</li>
<li>Code reviews are inherently more collaborative whereas writing code tends to be a more isolated activity (personally, I tend to code best in complete silence in evening hours). Code reviews are perhaps a better indicator of how it feels to work together with a candidate rather than having the candidate solve a technical puzzle.</li>
<li>There is more subjectivity to a code review; it’s not black or white. It naturally provides more opportunities for discussion and interpretation. It also provides more opportunities to arrive at outliers since there’s no single “solution”. For 5 candidates, you’ll get 5 unique variations whereas common algorithmic challenges may have a small number of optimal responses.</li>
<li>It is hard to “cheat” using generative AI or studying for leetcode problems.&nbsp;</li>
<li>It is better suited for evaluating technical roles that have a bias towards reading code versus writing code. This includes engineering managers, architects, and support staff.</li>
<li>It better reflects how a candidate is going to be spending their first few days or weeks anyways: learning the existing system by reading through the code. Doesn’t it make sense to measure how well they can do this rather than how quickly they can solve N-Queens?</li>
</ol>
<hr>
<h2 id="strategies">Strategies</h2>
<p>If you’re convinced, the next step is to think about different strategies to use when setting up your code review. There are a few strategies that you can mix and match to measure the range of a candidate.</p>
<p>A common thread to each of the strategies is that rather than inventing - or worse finding - a time-boxed puzzle to solve, an approach focused on code reviews lends itself to using bits and pieces of an existing codebase and actual problems that a team has been working on.</p>
<h3 id="au-naturel">“Au naturel”</h3>
<p>Take actual, relevant and interesting parts of an active codebase as-is and use those as the context for review. Data access, exception handling, input handling - these all make for great points of focus to see a candidate’s feedback on an existing codebase and how quickly they can read and understand your existing code.</p>
<h3 id="bug-hunter">Bug hunter</h3>
<p>Intentionally introduce some logical flaw or defect and see if a candidate can spot it. A good idea is to go back and find recent bugs that were solved and pull the source before the fix was applied. Can the candidate identify the root cause? How would the candidate suggest resolving the defect? How does that response differ from the one that was implemented?</p>
<h3 id="refactor-andredesign">Refactor and&nbsp;redesign</h3>
<p>Recently completed a refactor or planning a refactor? Use the code prior to the refactor as the context and see how the candidate thinks about the code before the refactor and what strategies a candidate would use to plan and execute the refactor. See if the candidate can identify why a refactor would be desired and evaluate the sophistication of their approach; you might be surprised and find an entirely novel alternate approach!</p>
<p>This is particularly useful when a candidate is joining a brownfield project.</p>
<h3 id="performance-oriented">Performance oriented</h3>
<p>Find code that was recently fixed for a performance issue and see if the candidate can spot why a piece of code might be slow. See if the candidate can propose an algorithm, alternate design, or fix to improve the performance of the code.&nbsp;</p>
<p>Include existing SQL DDL schema and common natural language queries that the application will perform.  Remove the index definitions and see if the candidate can propose indices or alternate designs to improve performance.</p>
<p>Instead of asking about the principles of Big-O notation, see if the candidate can actually spot some <code>O(n^2)</code> code or <code>N+1</code> issues in data access code!</p>
<h3 id="test-focused">Test focused</h3>
<p>Share a fragment of code and a set of unit tests for the code. Are all the cases covered? Are there cases not covered? How could the unit tests be improved? This perspective may be more important in the coming age of AI generated code: understanding the domain space and use case and how to write high coverage unit tests - or evaluating the completeness of generated unit tests - becomes a key skill.</p>
<h3 id="security-hawk">Security hawk</h3>
<p>Use code that has subtle security flaws and see if the candidate can identify said flaws. Rather than merely asking what an XSS or SQL injection attack is, see if the candidate can identify such flaws in code by using code that lacks protection against said attacks. Again, as teams come to rely on AI-generated code, having the experience to identify potential security flaws in the generated code becomes more important.</p>
<h3 id="best-practices">Best practices</h3>
<p>For more senior positions, focusing on best practices is a great way to find candidates that can identify, communicate, and teach best practices to more junior candidates and direct reports.</p>
<hr>
<h2 id="try-coderevapp">Try CodeRev.app</h2>
<p>If you’re sold on the idea like me, check out my new project <a href="https://coderev.app/">CodeRev.app</a>:</p>
<p><img src="https://chrlschn.dev/img/code-review-as-interview/coderev-3.png" alt="CodeRev screenshot">
<em>CodeRev.app candidate workspace.</em></p>
<p>CodeRev.app is a (free) lightweight tool that’s designed to facilitate code review as interview.&nbsp;</p>
<p>Why use it instead of CodeSandbox, Stackblitz, or GitHub?</p>
<ul>
<li>CodeRev is tightly focused on reading and commenting rather than coding whereas GitHub only has comments on PRs</li>
<li>CodeRev works great with fragments of code and you can mix and match different files without trying to make the project as a whole actually run. Just throw in whatever files make for interesting discussion!</li>
<li>CodeRev eliminates boilerplate that is inherent in modern projects one might be tempted to load into CodeSandbox or Stackblitz. Just pick the interesting source files and put them into CodeRev.</li>
<li>CodeRev lets you quickly toggle between the responses from different candidates so you can compare and see the insights and feedback they provided.</li>
</ul>
<p>It’s still early stage so let me know if you run across bugs or you have ideas!</p>
<hr>
<h2 id="closing-thoughts">Closing thoughts</h2>
<p>In <em>The End of Average</em>, Todd Rose writes:</p>
<blockquote>
Just about any meaningful human characteristic - especially talent - consists of multiple dimensions. The problem is that when trying to measure for talent, we frequently resort to the average, reducing our jagged talent to a single dimension like a score on a standardized test or grades or a job performance ranking.
</blockquote>
<p>Indeed, if we select for a narrow set of problem solving skills, then we end up selecting against an “average” of candidates who have simply studied and prepared to achieve against those dimensions and miss out on many candidates whose <em>jagged talents</em> contribute to the character and productivity of a team.</p>
<p>Incorporating code reviews as interview as part of a team’s repertoire can help better measure a wider range of a candidate’s skill than leetcode alone.</p>
<p>As our industry shifts and the profession comes to rely more on AI tools like Copilot and GPT to generate code for productivity gains, there is a greater importance on finding ways to identify jagged talent; robotically solving algorithmic puzzles becomes the lesser of the qualities we want in a candidate. Instead, perhaps the key skill is the ability to read and review that code for correctness, best practices, and security.</p>
<p>Replacing leetcode with code reviews as interview can help teams not only better measure candidates on the whole, but also prepare for this shift in how we approach building software by focusing on more relevant skills and those aspects of a candidate that make for a better <em>human</em> teammate.</p>
<p><em>Thanks for <a href="https://lefantan.com/">Lefan Tan</a>, Arash Rohani, and Rob Alarcon for reviewing draft versions of this article and providing their feedback.</em></p>
    </article>
  </main>
          </main>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Encrypting private data and private communications is now an ethical duty (422 pts)]]></title>
            <link>https://blog.tripu.info/encrypt/</link>
            <guid>37913256</guid>
            <pubDate>Tue, 17 Oct 2023 11:19:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.tripu.info/encrypt/">https://blog.tripu.info/encrypt/</a>, See on <a href="https://news.ycombinator.com/item?id=37913256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>We have come to a point where end-to-end encrypting all your private data and private communications
is no longer an ethical option, but an ethical <em>duty</em>.</p><p>Imagine a new law was being discussed in your country to make it mandatory that all buildings have glass walls.
All houses would be transparent.
The (stated) goal of the law is to make it harder for criminals to hide their wrongdoings.
It would be difficult to stock up on illegal drugs or to operate an industrial printer of counterfeit money without
the police (and, incidentally, some of your neighbours) noticing.
Domestic violence and child abuse would be visible through transparent walls.
Let's say that the new law will allow you to have a shower curtain, a little folding screen in your bedroom,
and blankets on your bed.
Except for those meagre provisions, assume that your government (and random passers-by, and potentially anyone)
will be able to watch what you do at all times.</p><p><a target="_blank" href="https://blog.tripu.info/assets/files/glass-building-85ed58b05b74f9885df3562f85c6fbb6.png"><img loading="lazy" alt="An illustration for this post generated by Stable Diffusion" src="https://blog.tripu.info/assets/images/glass-building-85ed58b05b74f9885df3562f85c6fbb6.png" width="1152" height="768"></a></p><p>Now imagine you are a regular, law-abiding citizen who can afford to lead a <!-- -->“<!-- -->transparent<!-- -->”<!-- --> life most of
the time, and manage to get some limited <!-- -->“<!-- -->privacy<!-- -->”<!-- --> only occasionally.
Given how hard it is for individual citizens to steer the behemoth that is the State and its government,
and since
<a href="https://www.amnesty.org/en/latest/campaigns/2015/04/7-reasons-why-ive-got-nothing-to-hide-is-the-wrong-response-to-mass-surveillance/" target="_blank" rel="noopener noreferrer">you personally <!-- -->“<!-- -->have nothing to hide<!-- -->”</a>,
you could be tempted to simply give up and prepare to obey the new law.</p><p>But <em>you should resist</em>.</p><p>You should strongly oppose that bill and help build resistance to it.
Most importantly, if such a law ever came into effect you would be morally <em>obliged</em> to disobey, to boycott.</p><p>Under such a law, good people in need of privacy would be at risk.
Whistleblowers, investigative journalists, clinical doctors and psychologists and other health professionals,
lawyers, the courts, the police, the military and spies absolutely need secrecy (to varying degrees, and at different times)
to do their job.
Some scientists and engineers need strong privacy, too (those in charge of vital infrastructure like the electrical grid
or the backbone of the internet, gain-of-function research, nuclear tech, or cybersecurity).
And some people need secrecy to be <em>physically safe</em>: prosecuted minorities, sexual dissidents, opposition leaders,
activists, heterodox thinkers, people who are divergent in many ways.</p><p>Enter the European Commission's <!-- -->“<!-- -->Proposal for a Regulation of the European Parliament and of the Council
Laying Down Rules to Prevent and Combat Child Sexual Abuse<!-- -->”<!-- -->:</p><ul><li>Mullvad VPN: <a href="https://mullvad.net/pdfs/Mullvad-Stop_chat_control_ENG.pdf" target="_blank" rel="noopener noreferrer">“<!-- -->The European Union is about to implement legislation that will mean all
your communication will be monitored.
You probably haven’t even heard of it.<!-- -->”</a></li><li>Patrick Breyer, <abbr title="Member of the European Parliament">MEP</abbr>:
<a href="https://www.patrick-breyer.de/en/posts/chat-control/" target="_blank" rel="noopener noreferrer">“<!-- -->Chat Control: The EU's CSEM [child sexual exploitation material] scanner proposal<!-- -->”</a></li></ul><p>The European Union is
<a href="https://en.wikipedia.org/wiki/List_of_European_Union_member_states_by_political_system" target="_blank" rel="noopener noreferrer">a heterogeneous group of 27 countries</a>.
Some of its member states, like Hungary and Poland, are still immature barely-liberal regimes with more than
a whiff of political repression
(<a href="https://pages.eiu.com/rs/753-RIQ-438/images/DI-final-version-report.pdf" target="_blank" rel="noopener noreferrer">“<!-- -->flawed democracies<!-- -->”</a>).
As recently as last year there was strong evidence of
<a href="https://www.theguardian.com/news/2022/feb/10/eu-close-to-launching-committee-of-inquiry-into-pegasus-spyware" target="_blank" rel="noopener noreferrer">“<!-- -->attempts by national security services to illegally access information on political opponents through their phones<!-- -->”</a>
in those two countries.
But not even
<a href="https://en.wikipedia.org/wiki/Norway#Politics_and_government" target="_blank" rel="noopener noreferrer">the most robust democracy in the world (another European country)</a>
should be trusted with a fundamentally unethical law like Chat Control.</p><p>In light of alarming proposals like Chat Control, everyone should make the effort to escape the opaque protocols and
the convenient Trojan Horses that are popular social networks and messaging services,
and make their daily communication truly private.
We should make strong encryption a staple of our digital life.</p><p>We should all use PGP, SSL or equivalent tools; VPNs, Tor and/or SSH tunnelling; IPFS, or other distributed
file systems<!-- -->&nbsp;<!-- -->—<!-- -->&nbsp;<!-- -->and ditch proprietary OS's in favour of Linux or truly free Android distros.
We should switch to Protonmail or similar webmail;
to Matrix, Signal or similar messaging.
Ad-blocking, URL cleansing and third-party cookie rejection should be the default for everyone.
Those tools and techniques should cease to be arcane nice-to-haves for nerds:
we must get more non-technical people onboard.</p><p>All this is a moral imperative to those of us who have the ability and the means to follow this strategy and to educate others about it.</p><p>As long as we still have access to computing resources, free software and some form of encrypted tunnelling,
we can resist: those are the minimum requirements for a humanist digital environment to sustain itself.
In the future it might be that by developing and using some software and exchanging certain sequences of bits we will be breaking some law.
Such a law would be wrong and unjust.</p><p>More than twenty years ago, some of us were sprinkling our regular e-mail with words like <!-- -->“<!-- -->iraq<!-- -->”<!-- -->,
<!-- -->“<!-- -->bomb<!-- -->”<!-- --> and <!-- -->“<!-- -->attack<!-- -->”<!-- -->, often on a line appended to the end of messages, in response to
<a href="https://en.wikipedia.org/wiki/Patriot_Act" target="_blank" rel="noopener noreferrer">talk about <abbr title="Three Letter Agencies">TLAs</abbr> scanning all digital communication</a>
in the wake of the <!-- -->“<!-- -->war on terror<!-- -->”<!-- -->.
I don't know if that strategy was effective in the end, but the goal we pursued with it was right.</p><p>In the same spirit, today everyone should communicate safely in private, if only to erect
a collective smoke screen that will confuse the mass surveillance apparatus and protect the most vulnerable among us.</p><p>(For similar reasons, everyone should choose free software when that's feasible;
demand open source and open standards and document formats from all public institutions;
and defend blockchains<!-- -->&nbsp;<!-- -->—<!-- -->&nbsp;<!-- -->including cryptocurrencies<!-- -->&nbsp;<!-- -->—<!-- -->&nbsp;<!-- -->and
the <!-- -->“<!-- -->right to repair<!-- -->”<!-- -->.
Strategically though, it may be better to stick to a minimum set of common demands for the sake of building
the largest coalition possible now.)</p><p>There is strength in numbers: that's how civil disobedience works.
It would be naive to think that we can get everyone in the EU to understand the imminent threat of (even deeper)
mass surveillance and to act on it.
But if a significant fraction of European citizens recognised the seriousness of the situation and made
the little effort required to secure their data and their communications, there is no way a law like Chat Control
could be enforced.</p><ul><li><abbr title="Electronic Frontier Foundation">EFF</abbr>'s <a href="https://ssd.eff.org/" target="_blank" rel="noopener noreferrer">surveillance self-defence guide</a></li><li>Bruce Schneier: <a href="https://www.schneier.com/blog/archives/2006/05/the_value_of_pr.html" target="_blank" rel="noopener noreferrer">“<!-- -->The Value of Privacy<!-- -->”</a></li><li><a href="https://stopchatcontrol.eu/" target="_blank" rel="noopener noreferrer">StopChatControl.eu</a> campaign (<code>#StopChatControl</code>)</li></ul><p><a href="https://stopchatcontrol.eu/" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://stopchatcontrol.eu/wp-content/uploads/2023/09/1-1-1024x1024.png" alt="https://stopchatcontrol.eu/"></a></p><div><p>Glass building image by Stable Diffusion <!-- -->&amp;<!-- --> tripu</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>