<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 03 Dec 2024 19:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Broadcom loses another big VMware customer (123 pts)]]></title>
            <link>https://www.theregister.com/2024/12/02/beeks_group_vmware_opennebula_migration/</link>
            <guid>42308184</guid>
            <pubDate>Tue, 03 Dec 2024 16:44:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/12/02/beeks_group_vmware_opennebula_migration/">https://www.theregister.com/2024/12/02/beeks_group_vmware_opennebula_migration/</a>, See on <a href="https://news.ycombinator.com/item?id=42308184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Broadcom has lost another significant customer after UK-based cloud operator Beeks Group decided to adopt the open source OpenNebula stack.</p>
<p>Beeks offers virtual private servers and bare metal boxes for financial services providers and emphasizes low latency for both – and for the trading network it operates.</p>
<p>The biz told <i>The Register</i> it operates in over 20 datacenters and runs a fleet of 20,000-plus virtual machines and more than 3,000 bare metal servers. Most of the VMs now run under OpenNebula – an open source project that provides hybrid cloud features on multiple hypervisors but favors KVM.</p>

    

<p>Beeks head of production management Matthew Cretney told us it moved from VMware due to several factors. A bill from Broadcom for ten times the sum it previously paid for software licenses was one of them. Beeks's customers also told it that VMware was no longer seen as essential infrastructure.</p>

        


        

<p>The tech team also warned management that the quality of VMware's support services and innovation were falling.</p>
<p>A symptom of perceived innovation woes was that Beeks felt VMware's suite had a substantial management overhead – that meant too much of its server fleet was dedicated to managing VMs, not running them for clients.</p>

        

<p>The VMware stack's very nature as a platform to manage virtual machines didn't help, either. Some Beeks customers prefer bare metal, as even the isolation provided by virtualization doesn't satisfy their need for security and low latency. vSphere is not built to manage bare metal servers alongside VMs, and Beeks wanted one tool for both jobs.</p>
<h3>A challenging switch</h3>
<p>Migration wasn't easy. Beeks runs proprietary software that it had tied to VMware APIs, and that had to be rebuilt to interface with OpenNebula.</p>
<p>The open source project's tools to collect metrics Beeks and its clients value – regarding CPU performance, and utilization of CPU, disk, memory, and network resources – were not strong. That's an issue because an overtaxed CPU or disk can be the difference between pleasingly fast trades or missing an opportunity. As OpenNebula is open source, Beeks felt able to develop tools to collect that info – and succeeded to its satisfaction.</p>
<p>Shifting to OpenNebula meant a 200 percent increase in virtual machine efficiency – meaning more VMs on each server, and lower costs for Beeks and its clients.</p>
<ul>

<li><a href="https://www.theregister.com/2024/11/28/broadcom_vmware_vcdx_snafu/">No, Broadcom did not just end VMware's flagship VCDX certification program</a></li>

<li><a href="https://www.theregister.com/2024/11/26/amazon_elastic_vmware_service_preview/">AWS bends to Broadcom's will with VMware Cloud Foundation as-a-service</a></li>

<li><a href="https://www.theregister.com/2024/11/20/hpe_vm_essentials_greenlake/">HPE lets loose VM Essentials to run on third-party platforms</a></li>

<li><a href="https://www.theregister.com/2024/11/18/vmware_vcenter_rce_exploited/">Critical 9.8-rated VMware vCenter RCE bug exploited after patch fumble</a></li>
</ul>
<p>Beeks still offers VMware services for customers that want it, but the majority of its VM estate is now on OpenNebula.</p>
<p>Broadcom has positioned VMware's Cloud Foundation (VCF) stack as ideal for organizations with large and complex IT estates. It argues that, while VCF has a substantial price tag, those who implement the entire suite of compute, storage, and network virtualization components will quickly enjoy ROI that proves the bundle represents exceptional value.</p>
<p>Beeks's offerings are a little unusual – and perhaps therefore an edge case for VCF. Broadcom could therefore argue that losing most of this particular customer's business isn't a blow.</p>

        

<p>Yet the UK cloud's decision comes after Broadcom also lost big names such as insurance giant <a target="_blank" href="https://www.theregister.com/2024/08/28/geico_vmware_openstack_migration/">Geico</a>, fintech <a target="_blank" href="https://www.theregister.com/2024/05/22/computershare_vm_migration_project/">Computershare</a>, <a target="_blank" href="https://www.theregister.com/2024/05/21/nutanix_vmware_migrations/">Boyd Gaming</a>, and <a target="_blank" href="https://www.theregister.com/2024/05/22/john_deere_vms_legacy/">John Deere</a> – with the post-acquisition licensing terms a common theme behind migration decisions.</p>
<p>US telecom titan AT&amp;T has <a target="_blank" href="https://www.theregister.com/2024/09/23/att_vmware_quit_claim_broadcom/">threatened</a> to quit VMware too, and claimed such a move would quickly pay for itself – but that may have been a negotiation tactic as it has since <a target="_blank" href="https://www.theregister.com/2024/11/22/broadcom_vmware_acquisition_first_anniversary/">settled</a> a dispute over a support services contract.</p>
<p>Beeks Group's experience of substantial savings is therefore another example for those considering what to do when their current VMware deals expire – and they face a decision about whether or not to buy into Broadcom's virtual vision. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DuckDuckGo Donates $25,000 to the Perl and Raku Foundation (197 pts)]]></title>
            <link>https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation/</link>
            <guid>42307223</guid>
            <pubDate>Tue, 03 Dec 2024 15:34:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation/">https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation/</a>, See on <a href="https://news.ycombinator.com/item?id=42307223">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
              
              <p>Dec 3, 2024 by
              
              
                
                
                <a href="#author-bio-olaf-alders">Olaf Alders</a>
              
              </p>
              <img alt="" src="https://www.perl.com/images/duck-duck-go/Growth.jpg">
                <p><img src="https://www.perl.com/images/duck-duck-go/Logo-Horizontal-Registered2.svg" alt="DuckDuckGo Growth"></p>

<p>Today, on “Giving Tuesday”, <a href="https://www.perlfoundation.org/">The Perl and Raku Foundation
(TPRF)</a> is extremely pleased to announce <a href="https://spreadprivacy.com/2024-duckduckgo-charitable-donations">a
donation of $25,000 from
DuckDuckGo</a>.
Since 2011, DuckDuckGo has <a href="https://duckduckgo.com/donations">donated over 6 million
dollars</a> to organizations that align with
their “vision of raising the standard of trust online”.</p>

<p>TPRF is dedicated to
advancing the Perl and Raku programming languages through open-source
development, community engagement, and outreach to ensure their ongoing growth,
relevance, and accessibility. This support from DuckDuckGo will allow TPRF to
continue to do things like fund core Perl development, fund grants for
projects which are important to the community and otherwise to support the
community where it can.</p>

<p>Every donation sends a message that this work matters. On the occasion of this
gift, The Perl and Raku Foundation is deeply grateful to
<a href="https://duckduckgo.com/">DuckDuckGo</a> not only for its generosity but also for
its confidence in TPRF’s mission.</p>

<p>To learn more about TPRF’s current activities and goals for the future, please see
 <a href="https://www.perl.com/media/tprf/tprf-prospectus-2024.pdf">the TPRF 2024 prospectus</a></p>

<p>If your organization is interested in becoming a TPRF donor, please <a href="mailto:olaf@perlfoundation.org">reach out
to me</a>. I’d be more than happy to set up a
call so that we can discuss how a donor relationship with TPRF can
benefit your organization.</p>

              </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[South Korea President Yoon declares martial law (111 pts)]]></title>
            <link>https://www.reuters.com/world/asia-pacific/south-korea-president-yoon-declares-martial-law-2024-12-03/</link>
            <guid>42306073</guid>
            <pubDate>Tue, 03 Dec 2024 14:00:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/asia-pacific/south-korea-president-yoon-declares-martial-law-2024-12-03/">https://www.reuters.com/world/asia-pacific/south-korea-president-yoon-declares-martial-law-2024-12-03/</a>, See on <a href="https://news.ycombinator.com/item?id=42306073">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/asia-pacific/south-korea-president-yoon-declares-martial-law-2024-12-03/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[South Korean president declares emergency martial law (422 pts)]]></title>
            <link>https://apnews.com/article/south-korea-yoon-martial-law-997c22ac93f6a9bece68454597e577c1</link>
            <guid>42306020</guid>
            <pubDate>Tue, 03 Dec 2024 13:53:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/south-korea-yoon-martial-law-997c22ac93f6a9bece68454597e577c1">https://apnews.com/article/south-korea-yoon-martial-law-997c22ac93f6a9bece68454597e577c1</a>, See on <a href="https://news.ycombinator.com/item?id=42306020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>SEOUL, South Korea (AP) — South Korean President Yoon Suk Yeol declared an “emergency martial law,” Tuesday accusing the country’s opposition of controlling the parliament, sympathizing with North Korea and paralyzing the government with anti-state activities.</p><p>Yoon made the announcement in a televised briefing Tuesday, vowing to “eradicate pro-North Korean forces and protect the constitutional democratic order.” </p><p>It wasn’t immediately clear how Yoon’s step would affect the country’s governance and democracy. The move drew immediate opposition from politicians, including the leader of his own conservative party, Han Dong-hoon, who called the decision “wrong” and vowed to “stop it with the people.” Opposition leader Lee Jae-myung, who narrowly lost to Yoon in the 2022 presidential election, called Yoon’s announcement “illegal and unconstitutional.”</p>
    

<p>“Through this martial law, I will rebuild and protect the free Republic of Korea, which is falling into the depths of national ruin,” Yoon said during a televised speech, invoking South Korea’s formal name.</p><p>“I will eliminate anti-state forces as quickly as possible and normalize the country,” he said, while asking the people to believe in him and tolerate “some inconveniences.”</p>



<p>Yoon — whose approval rating has dipped in recent months — has struggled to push his agenda against an opposition-controlled parliament since taking office in 2022.</p>
    
    
    
<p>Yoon’s conservative People Power Party had been locked in an impasse with the liberal opposition Democratic Party over next year’s budget bill. The opposition has also been attempting to pass motions to impeach three top prosecutors, including the chief of the Seoul Central District Prosecutors’ Office, in what the conservatives have called a vendetta against their criminal investigations on Lee, who has been seen as the favorite for the next presidential election in 2027 in opinion polls.</p><p>Yoon has also been dismissing calls for independent investigations into scandals involving his wife and top officials, drawing quick, strong rebukes from his political rivals. The Democratic Party reportedly called an emergency meeting of its lawmakers following Yoon’s announcement.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tweaking Stunt Island's 30-year-old 3D Engine (132 pts)]]></title>
            <link>https://annali.netlify.app/2024/11/20/tweaking-stunt-island</link>
            <guid>42305954</guid>
            <pubDate>Tue, 03 Dec 2024 13:44:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://annali.netlify.app/2024/11/20/tweaking-stunt-island">https://annali.netlify.app/2024/11/20/tweaking-stunt-island</a>, See on <a href="https://news.ycombinator.com/item?id=42305954">Hacker News</a></p>
<div id="readability-page-1" class="page">
	  <p><a href="https://annali.netlify.app/">Annali da Samarcanda</a></p>
	  <p>Alberto Marnetto's Notebook</p>
	  <hr>
      

<p>Note: the patch is available at the end of the article (<b><a href="#download">HERE</a></b>). This post is about its making-of.</p>

<h3 id="intro">Intro</h3>

<p>Stunt Island is a flight simulator from the year 1992. You can read more about it in my <a href="https://annali.netlify.app/2024/11/15/stunt-island-elegy">previous post</a>.</p>

<p>Last month I finally beat the game, winning all the missions and getting the title of “Stuntman of the year”. While I was replaying the videos of my attempts, as well as some fan-made SI films in the channel, I wondered if I could somehow mitigate the obvious limitations of the rendering engine.</p>

<p>Also, I was always fascinated by the art of reverse engineering, and I thought this could be a good opportunity to learn something in this field. Assembly is not new to me, but dealing with an archaic DOS program, working without gdb’s features and any kind of debug symbols means entering an entirely different world.</p>

<p>I spent a dozen of hours learning the tools of the trade and trying to figure out the puzzle, and I was very happy of my eventual success. After finding and patching the right location in the executable, the engine got some extra horsepower. No extra resolution unfortunately, but many more details, as one can see in the comparisons below.</p>


<p>
<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/comparison"><b>Click here for the interactive comparison</b></a>
</center>
</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-flight-1x.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-flight-1x.png" alt="drawing" width="320">
</a>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-flight-8x.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-flight-8x.png" alt="drawing" width="320">
</a>
<figcaption>Mission 29, vanilla game (left) and patched (right)</figcaption>
</center>



<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-setdesign-1x.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-setdesign-1x.png" alt="drawing" width="320">
</a>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-setdesign-8x.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-setdesign-8x.png" alt="drawing" width="320">
</a>
<figcaption>Scenario editor, vanilla game (left) and patched (right)</figcaption>
</center>

<p>For a video comparison, one can check out <a href="https://youtu.be/AZMDm-2IIzc?si=7q4pK-dFhUyMhEyJ"><b>this “remaster” of the movie <em>Mickey’s Revenge</em></b></a>, courtesy of Doug Armknecht’s “Stunt Island Central” channel.</p>

<p>In the following, I’ll show the process and some failed tries. Even if this is far from being a professional effort, I hope that publishing this can be of help to other learners, or maybe induce some experts to chime in and suggest improvements (in the name of Cunningham’s Law). Tutorials about debugging with DOSBox are rare to find, so I feel that even this small example can be useful.</p>

<p>Also, I hope to revive some interest in an old, but beautiful and unique game.</p>

<h3 id="start">Start</h3>

<p>Since I have never debugged DOS programs, the first step is to build up the toolset. I need</p>

<ul>
  <li>DOSBox debug to run and live-debug the game</li>
  <li>Ghidra to decompile and analyze the executable. There are other DOS-compatible decompilers around, but I liked Ghidra’s “late Nineties” UI, even if it does not render nicely on Linux. I used the older 10.4 version for compatibility with my Debian’s openjdk package.</li>
  <li>Bless, my favorite hex editor</li>
</ul>

<p>I start by opening the game executable in Ghidra. The first result is underwhelming:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-raw.png">
</a><a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-raw.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-raw.png" alt="drawing" width="800">
</a>

</center>

<p>Just one function and a lot of non-decompiled bytes, that does not look good. Maybe the decompile process failed?</p>

<p>Let’s look at the function. I cannot grasp all the details, but it seems to be copying a buffer. This rings a bell – I remember reading some articles about self-decrypting executables. Could it be that the real game code is obfuscated and only revealed after the startup?</p>

<p>By the way, what does the file header look like?</p>

<div><pre><code>$ hexdump -C STUNT.EXE | head -5 
00000000  4d 5a 18 00 0d 01 00 00  02 00 20 1c ff ff e9 3c  |MZ........ ....&lt;|
00000010  80 00 00 00 0e 00 52 21  1c 00 00 00 4c 5a 39 31  |......R!....LZ91|
00000020  ff 3f e8 64 00 a3 12 62  89 16 14 62 e8 81 00 3b  |.?.d...b...b...;|
00000030  3e ec f9 75 04 3b 06 ef  76 1b ea fd c7 ff 0f 06  |&gt;..u.;..v.......|
00000040  1c 62 00 00 b4 43 cd 67  84 e4 75 37 4f 87 ee 16  |.b...C.g..u7O...|
</code></pre></div>

<p>Seeing the “LZ91” finally clicks for me. This game was probably compressed by some variant of the Lempel-Ziv algorithm. Some googling leads me first to <a href="https://www.lodsb.com/reversing-lz91-from-commander-keen">this article by Sam Russell</a> and then to <a href="https://moddingwiki.shikadi.net/wiki/UNLZEXE">the UNLZEXE unpacker</a>. Turns out that the original compression tool was authored by the prolific genius Fabrice Bellard.</p>

<p>OK, let’s decompress the executable and reload it in Ghidra:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-si-uncompressed.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-si-uncompressed.png" alt="drawing" width="600">
</a>
</center>

<p>Looks better. Can we make any sense of the functions?</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-complex.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-complex.png" alt="drawing" width="600">
</a>
</center>

<p>Nope, this is over my paygrade. But we are in 2024, maybe we can seek the help of a LLM? Copilot says:</p>

<p><small><blockquote>
This looks like assembly code mixed with some higher-level C code constructs, dealing with system-level operations. Here’s a bit of a breakdown:<br>
* Initial Setup: The function begins by initializing variables and handling some immediate checks and adjustments.<br>
* Comparisons and Bit Manipulations: It checks some global variables and performs bit shifts and comparisons to adjust the control flow based on these conditions.<br>
* System Calls: There are several system interrupt calls, likely interacting with hardware or the operating system.<br>
* Function Calls: The code calls other functions (like FUN_1f59_36f7, FUN_1f59_0bc2, and FUN_1f59_0c2c) which perform some specific tasks.<br>
* Loops: The code includes loops and conditional checks to perform repeated tasks or to continue execution based on certain conditions.<br>
* The main flow is about handling and manipulating certain global variables and possibly hardware states, based on the names and types used. However, without more context on these global variables and the overall program architecture, it's tough to pin down the exact purpose.
</blockquote>
</small></p>

<p>Oh, I see, “the code calls other functions which perform some specific tasks”. Awesome. Thanks all the same, AI. See you in some years, and let’s rely on carbon-based intelligence in the meanwhile.</p>

<h3 id="a-matter-of-detail">A matter of detail</h3>

<p>The static analysis has not yielded any result yet, but I have another idea. Stunt Island has a “Detail” setting:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-detail.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-detail.png" alt="drawing" width="640">
</a>
</center>

<p>My hope is to find out where the detail level (here, 75%) is stored in the memory, and to change it to 255, or to see how it is used in the rendering process.</p>

<p>Let’s fire up Dosbox debug. The best manual for the interface is <a href="https://www.vogons.org/viewtopic.php?t=3944">a thread on the Vogons forum</a>.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/dosbox-debug.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/dosbox-debug.png" alt="drawing" width="600">
</a>
</center>

<p>The GUI is nice, even if I miss the amenities of modern debugging, especially the function names. However, credit is due to the authors: they put in nice features like a branch predictor that shows whether a jump instruction will be taken, and in which direction (back or forward), assuming that the current status of registries and memory stays the same.</p>

<p>How to find the location of the detail level variable? I navigate again to the “Preferences” screen and spend a lot of time there, trying to devise a method to extract such information. My list of failed attempts includes:</p>
<ul>
  <li>Break on keyboard input: I set a breakpoint on keypress (<code>BPINT 16</code>) and press “Return” with the mouse pointing on the “plus” sign. The program breaks in a input-reading routine, but stepping through the code I lose my way before being able to understand what the program is doing. Considering I could be in the middle of a complex UI-drawing routine, I give up.</li>
  <li>Break on mouse move or click: there is a <a href="https://www.vogons.org/viewtopic.php?f=31&amp;t=83267">helpful guide</a> for that, but again I end up in a mysterious land.</li>
  <li>Break on pixel change: I manage to break the program when a pixel in the detail scroller changes (<code>bpmem a1000:3500</code>). Again, I cannot find the way out of the graphics code.</li>
  <li>In Ghidra, look for a printf format string with a number and a percent (something like <code>"%u%%"</code>): nothing found</li>
</ul>

<p>While looking for other ideas, I find a nice <a href="https://wiki.scummvm.org/index.php/HOWTO-Reverse_Engineering">list of techniques</a> by the makers of ScummVM. One of the options is “File Access”, which reminds me that the game must store its preferences somewhere. A quick search by date reveals that a file with the promising name <code>GAME.VAR</code> is updated every time I alter the settings. Let’s see how it changes when a different detail level is chosen. At 99% detail we have</p>

<div><pre><code>$ hexdump -C GAME.VAR 
00000000  70 fd ff 01 ff ff ff ff  ff ff 99 e7 0b 00 38 01  |p.............8.|
00000010  64 02 0b 00 57 01 64 02  00 00 00 00 00 00 00 00  |d...W.d.........|
00000020  00 00 00                                          |...|
00000023
</code></pre></div>

<p>Now let’s set 1% detail:</p>

<div><pre><code>$ hexdump -C GAME.VAR 
00000000  8f 02 ff 01 ff ff ff ff  ff ff 99 e7 0b 00 38 01  |..............8.|
00000010  64 02 0b 00 57 01 64 02  00 00 00 00 00 00 00 00  |d...W.d.........|
00000020  00 00 00                                          |...|
00000023
</code></pre></div>

<p>So the detail level is in the very first two bytes. Unluckily, it seems already to be scaled, with 100% = <code>0xffff</code>. No chance to simply set it higher. But let’s not lose hope so soon: we have now more information to find out where in the memory this value is stored, and maybe we can change something else in the 3D computations.</p>

<p>I need a breakpoint when <code>GAME.SAV</code> is written. According to an <a href="https://mrszeto.net/CIT/interrupts.htm">old but practical</a> guide to the interrupt table, a file write is triggered by calling interrupt <code>21h</code> with <code>40h</code> in registry <code>AH</code>. Dosbox can set a breakpoint on precisely this event:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-bpint-21-40.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-bpint-21-40.png" alt="drawing" width="800">
</a>
</center>

<p>I change the detail level, close the preferences window and, bingo! Breakpoint triggered.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-config-save.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-config-save.png" alt="drawing" width="800">
</a>
</center>

<p>The bytes to write are in <code>DS:DX</code>, so <code>1628:2FEA</code>. Let’s have a look:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-2fea.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-2fea.png" alt="drawing" width="800">
</a>
</center>

<p>Yes, the 16-bit value at that address matches the detail level I set (<code>0x3d70/0xffff ~= 0.24</code>). I bet that this is a global variable and will stay there for the whole duration of the program, what I verify by starting a mission:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-detail-global.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-detail-global.png" alt="drawing" width="800">
</a>
</center>

<p>The value is still there. Very nice.</p>

<h3 id="following-the-dataflow">Following the dataflow</h3>

<p>Now I have to see where this variable is used. Let’s go back to Ghidra, and look for the low two bytes.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-2fea.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-2fea.png" alt="drawing" width="800">
</a>
</center>

<p>I am lucky, not too many occurences.</p>

<p>First location: <code>CS:4CDA</code>. Ghidra decompiles the code to</p>

<div><pre><code>    *(int *)0xb86 =
         (int)((ulong)*(uint *)0x2fea * 100 &gt;&gt; 0x10) + *(int *)0xa5a +
         (uint)((int)((ulong)*(uint *)0x2fea * 100) &lt; 0);
</code></pre></div>

<p>Not super clear, but the meaning becomes evident when I set a breakpoint there (<code>BP CS:4CD8</code>): the line is executed only when I open the preferences box. So the “100” in the code must be part of the rescaling to a percentage.</p>

<p>Second location: <code>CS:680E</code>. The assembly is clearer than the C equivalent:</p>

<div><pre><code>       1000:6809 a1 ea 91        MOV        AX,[0x91ea]
       1000:680c f7 26 ea 2f     MUL        word ptr [0x2fea]
       1000:6810 d1 e0           SHL        AX,0x1
       1000:6812 d1 d2           RCL        DX,0x1
       1000:6814 89 16 f2 91     MOV        word ptr [0x91f2],DX
</code></pre></div>

<p>So, the variable at <code>DS:91EA</code> get multiplied by the detail level, and then written at <code>DS:91F2</code>. No idea what <code>DS:91EA</code> is, though. I first think that this routine is calculating some per-polygon quantity, but it turns out that it is only run once per frame. Also, when I run some frames in mission 1 the variable at <code>DS:91EA</code> switches between <code>0x0999</code> and <code>0x7FFF</code>. Let’s ignore the matter: we now know that at <code>DS:91F2</code> something gets written that is proportional to the detail level. Moreover, with Detail set at 100% this variable is often set at <code>0xFFFD</code>, almost the maximum.</p>

<p>I look for <code>f2 91</code> in Ghidra: it only yields two occurrences. One is the fragment we just analyzed, the other is in the middle of some bytes that Ghidra did not decompile automatically.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-91f2.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-91f2.png" alt="drawing" width="800">
</a>
</center>

<p>Well, there is no other place to look, so I ask Ghidra to decompile this section. Some attempts later, a plausible assembly appears:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-91f2-found.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-91f2-found.png" alt="drawing" width="800">
</a>
</center>

<p>I ensure that the decompilation is right by setting a breakpoint at the start of the fragment (<code>BP CS:76E8</code>), and for added safety I verify that the program counter (<code>EIP</code>) really points to the locations shown in the listing. This code gets executed many, many times per frame – have I finally reached the goal?</p>

<h3 id="ace-gets-glasses">Ace gets glasses</h3>

<p>Let’s try to understand the code: first it decrements <code>AX</code> and executes what follows only if it’s still positive. Not sure what this means but some live debugging shows that the condition is met quite often anyway. The following calculation is easier to understand: in the x86 architecture, calling <code>MUL</code> multiplies <code>AX</code> by the operand, leaving the  result in <code>DX:AX</code>. With maximum detail, we know that <code>DS:91F2</code> will be set at <code>0xFFFD</code>, so that the multiplication becomes almost a 16-bit left shift, setting <code>DX</code> to <code>(AX_old - 1)</code>. The lower the detail, the lower <code>DX</code> will be. Then the code executes the following branch only if <code>CX &lt;= DX + BX</code>, otherwise it gets skipped.</p>

<p>In an <a href="https://fabiensanglard.net/stunt_island/">interview by Fabien Sanglard</a>, Stunt Island’s main programmer Adrian Stephens revealed an important aspect of the rendering engine: each 3D entity in the game is represented as a tree, and the game decides whether to render the (coarser) top nodes or the (finer) lower levels according to their distance from the observer. And we see here that a subroutine gets executed if <code>CX</code> is under a certain threshold, which gets bigger the bigger is the detail level. Let’s make the bold hypothesis that <code>CX</code> is the object distance, and <code>(DX + BX)</code> determines the distance threshold under which a higher-resolution model gets loaded.</p>

<p>I can test the hypothesis by overwriting the calculation with new code. Let’s start by setting the threshold to zero. Ghidra shows which bytes to insert:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-patch.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/ghidra-patch.png" alt="drawing" width="800">
</a>
</center>

<p>I can do that in the live program:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/dd-patch-live.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/dd-patch-live.png" alt="drawing" width="800">
</a>
</center>

<p>The experiment works perfectly: all details disappear, Jackson City is reduced to flatland.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/flatland.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/flatland.png" alt="drawing" width="640">
</a>
</center>

<p>But what I want is the contrary: changing the code so that the max resolution gets used for all objects. Let’s just set the threshold to the max:</p>

<div><pre><code>SM cs:76f4 c7 c2 ff 7f 66 90 
(MOV DX, 0x7FFF ; NOP) 
</code></pre></div>

<p>This makes the engine totally unresponsive to the keyboard commands. I guess I was too greedy. My second try is more modest:</p>

<div><pre><code>SM cs:76f4 c7 c2 ff 4f 66 90 
(MOV DX, 0x4FFF ; NOP) 
</code></pre></div>

<p>And here we are: Stunt Island in the best detail you’ll ever get in a 320x200 window! Pity that the system is still just barely responsive: even with DOSBox’s CPU set to max performance, I cannot control my plane, and this is the best screenshot I am able to take before crashing.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/sr71-high-detail.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/sr71-high-detail.png" alt="drawing" width="640">
</a>
</center>

<p>But there is a better way to go sightseeing: the rendering routine is shared across flight sim, video player and set designer, and at least in the last mode I can take all the time I need to steer the camera. It takes some minutes to push the extremely sluggish control, but after a while I can frame Jackson City and surroundings, looking more gorgeous than ever!</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/set-des-high-detail.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/set-des-high-detail.png" alt="drawing" width="640">
</a>
</center>

<p>Now that I explored the limits, it’s time to turn back the dial and find some compromise to make the game playable. The current patch is brutal, it just uses a fixed threshold ignoring the original value in <code>DX</code>. We know that <code>DX</code> is approximately <code>AX_old * (detail_level/100)</code>, maxing out at <code>AX_old - 1</code> if the detail level is 100%. What about putting a multiple of <code>AX</code> there? The space is limited, only 6 bytes, but a bitshift is compact enough. After some experiments, I settle on</p>

<div><pre><code>89 c2 c1   MOV DX,AX 
e2 03      SHL DX,0x3
90         NOP
</code></pre></div>

<p>which would be the equivalent of a 800% detail. I patch it in using the Dosbox command:</p>

<div><pre><code>SM cs:76f4 89 c2 c1 e2 03 90  
</code></pre></div>

<p>And everything goes as hoped: the quality is great and the game (after cranking up Dosbox’s CPU to the max) runs quite fluidly. Time to celebrate!</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/final-quality.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/final-quality.png" alt="drawing" width="640">
</a>
</center>

<p>By the way, the fact that the three most significant bits of <code>DX</code> are discarded does not seem to lead to any noticeable glitch; I could add some code checking for overflow and saturating the value, but this would require more bytes than I am replacing. I might create the algorithm elsewhere and then <code>JMP</code> to it, but at the price of making the code slower and the patching process more difficult. The current version is simple and good enough for me, and after all one must leave some fun to future tinkerers.</p>

<h3 id="washing-the-dishes">Washing the dishes</h3>

<p>Before calling it a day, I still have some housework to do.</p>

<p>First, I need to edit the executables to avoid having to live-patch the code every time. Stunt Island provides not only the game executable (<code>STUNT.EXE</code>), but also a video encoder and a player (<code>MAKEONE</code> and <code>PLAYONE</code>), so that users can distribute and view their films without having to navigate through the game interface. To do a complete work, I want to patch all these files.</p>

<p>Fortunately, the rendering code is the same in all three executables. However, the detail variable is stored at different addresses, so the assembly is not the same. The easiest way to find the relevant location is to search for the instructions that follow the <code>MUL</code> (so the <code>ADD / CMP / JG</code> sequence): they only refer to register values, so their encoding (<code>03 D3 3B CA 7F 1B</code>) is the same in all the files to patch.</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/bless-search.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/bless-search.png" alt="drawing" width="600">
</a>
</center>

<p>Then, we move four bytes back, and we replace the “multiply by the detail level” segment (<code>F7 26 XX XX 03 D3</code>) with the “multiply by 8” code (<code>89 C2 C1 E2 03 90</code>).</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/bless-replace.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/bless-replace.png" alt="drawing" width="600">
</a>
</center>

<p>The operation works well on all three executables. The patched <code>PLAYONE</code> can only play films created by the patched <code>MAKEONE</code>, but this seems reasonable. I guess that the films created by the vanilla <code>MAKEONE</code> are missing the high-polygon versions of the far objects.</p>

<p>Second, I must create a patching program that can upgrade the game without embedding Disney’s code. It would be nice to just implement it as simple search and replace for the six bytes that need to be overwriten, but unfortunately there is the problem of the LZ compression. I cannot bundle <code>unlzexe</code>, whose copyright status is unclear, so I end up recompressing the patched executable and diffing it with the unpatched version. The compression smears my 3-byte change all over the file creating a big diff, but this seems to me the least worst method. The patcher then applies the diff to the original game file, which must be provided by the user. This should put the patch on the safe side, copyright-wise.</p>

<p>Finally, I am informed that Disney released a patch (“#3”) containing some features like an alternative beginner-friendly flight model. It would be good if the 800% mod also worked on this version. Luckily the renderer was not changed so the same patching method can be used. The only surprise happens when uncompressing the new <code>.EXE</code>: it turns that the compression method was slightly changed (from LZ091 to LZ091E), and <code>unlzexe</code> does not recognize the format. However, the algorithm is the same, just the magic number used for the format identification has changed. Commenting out the magic number check in the source code of <code>unlzexe</code> solves the problem: I can uncompress the file and create a patch using the same process of the original game.</p>

<p>So, here the best Stunt Island one can have, with the enhanced rendering engine and the quality-of-life improvements of Disney’s patch:</p>

<center>
<a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/final.png">
<img src="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/final.png" alt="drawing" width="640">
</a>
</center>

<h3 id="want-to-try-it-out">Want to try it out?</h3>

<p>To play the “definitive” version of Stunt Island, three steps are needed:</p>

<ul>
  <li>Get the original game, e.g. on <a href="https://www.gog.com/en/game/stunt_island">GOG</a> or <a href="https://store.steampowered.com/app/602970/Stunt_Island/">Steam</a></li>
  <li>(Optionally) download the “#3” patch from <a href="https://armknechted.com/sicentral/sifiles/index.html">Stunt Island Central</a>, copy it in the game directory, and run the executable in Dosbox</li>
  <li>Download the “8x” patch, copy it in the game directory, and run the Windows or Linux executable (doing it for DOS would have taken longer)</li>
</ul>

<p><a id="download"></a>
Downloads:</p>
<ul>
  <li><b><a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-8x.zip">PATCH</a></b> in zip format (recommended)</li>
  <li><b><a href="https://annali.netlify.app/assets/2024-11-20--tweaking-stunt-island/si-8x.7z">PATCH</a></b> in 7z format, password-protected, password = <code>stunt-island</code> (use in case your browser blocks the download of the zip version)</li>
</ul>


  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi Search API (139 pts)]]></title>
            <link>https://help.kagi.com/kagi/api/search.html</link>
            <guid>42305767</guid>
            <pubDate>Tue, 03 Dec 2024 13:22:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.kagi.com/kagi/api/search.html">https://help.kagi.com/kagi/api/search.html</a>, See on <a href="https://news.ycombinator.com/item?id=42305767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>json</span></p><pre><code><span><span>{</span></span>
<span><span>  </span><span>"</span><span>meta</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>    </span><span>"</span><span>id</span><span>"</span><span>:</span><span> </span><span>"</span><span>69c3f5c4168f66b860e951c585550f1c</span><span>"</span><span>,</span></span>
<span><span>    </span><span>"</span><span>node</span><span>"</span><span>:</span><span> </span><span>"</span><span>us-central1</span><span>"</span><span>,</span></span>
<span><span>    </span><span>"</span><span>ms</span><span>"</span><span>:</span><span> </span><span>213</span><span>,</span></span>
<span><span>    </span><span>"</span><span>api_balance</span><span>"</span><span>:</span><span> </span><span>123.456</span></span>
<span><span>  </span><span>},</span></span>
<span><span>  </span><span>"</span><span>data</span><span>"</span><span>:</span><span> </span><span>[</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://en.wikipedia.org/wiki/Steve_Jobs</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs - Wikipedia</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steven Paul Jobs (February 24, 1955 – October 5, 2011) was an American businessman, inventor, and investor best known for co-founding the technology company ...</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>thumbnail</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>        </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>/proxy/310px-Steve_Jobs_Headshot_2010-CROP_%28cropped_2%29.jpg?c=9cn5Kxse4yD05EJkf6QML9dK4clUbdQ9Oq4d5gDoyHBwiX43u0CCAEVi8DMCHFAXhMAIsLbp8IO0pmQf41WB6CWu9BNfAxhRqV-EQL_l_gnV1yD14xBDf5Sgj1vfjIF0aMOqcVwh-jMVcqkx3GjwnuZrt2Z8-tdYhu3uERcYzLTTqq5TKumyN0Q1c5n3utowEZhefA7WoUo3SNIB1-iHhCnijbEL5iAQo1iTroqppHk%3D</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>width</span><span>"</span><span>:</span><span> </span><span>null,</span></span>
<span><span>        </span><span>"</span><span>height</span><span>"</span><span>:</span><span> </span><span>null</span></span>
<span><span>      </span><span>}</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://en.wikipedia.org/wiki/Steve_Jobs_(film)</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs (film) - Wikipedia</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs is a 2015 biographical drama film directed by Danny Boyle and written by Aaron Sorkin. A British-American co-production, it was adapted from the ...</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>thumbnail</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>        </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>/proxy/310px-Steve_Jobs_Headshot_2010-CROP_%28cropped_2%29.jpg?c=9cn5Kxse4yD05EJkf6QML9dK4clUbdQ9Oq4d5gDoyHBwiX43u0CCAEVi8DMCHFAXhMAIsLbp8IO0pmQf41WB6CWu9BNfAxhRqV-EQL_l_gnV1yD14xBDf5Sgj1vfjIF0aMOqcVwh-jMVcqkx3GjwnuZrt2Z8-tdYhu3uERcYzLTTqq5TKumyN0Q1c5n3utowEZhefA7WoUo3SNIB1-iHhCnijbEL5iAQo1iTroqppHk%3D</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>width</span><span>"</span><span>:</span><span> </span><span>310</span><span>,</span></span>
<span><span>        </span><span>"</span><span>height</span><span>"</span><span>:</span><span> </span><span>300</span></span>
<span><span>      </span><span>}</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.apple.com/stevejobs/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Remembering Steve Jobs - Apple</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>He was a visionary that had the amazing ability to breath life into his ideas. He believed so passionately in his work that his creativity became both seductive ...</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.biography.com/business-leaders/steve-jobs</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs: Biography, Apple Cofounder, Entrepreneur</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs was an American inventor, designer, and entrepreneur who was the cofounder, chief executive, and chairman of Apple Inc. Born in 1955 to two University of Wisconsin graduate students who ...</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.britannica.com/money/Steve-Jobs</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs | Biography, Education, Apple, &amp; Facts | Britannica Money</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs, the visionary co-founder of Apple Inc., revolutionized technology and consumer electronics with his innovative products that ...</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>published</span><span>"</span><span>:</span><span> </span><span>"</span><span>2024-09-30T00:00:00Z</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.amazon.com/Steve-Jobs-Walter-Isaacson/dp/1451648537</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs: 9781451648539: Isaacson, Walter: Books - Amazon.com</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Walter Isaacson&amp;#39;s “enthralling” (The New Yorker) worldwide bestselling biography of Apple cofounder Steve Jobs. Based on more than forty interviews with ...</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://hbr.org/2012/04/the-real-leadership-lessons-of-steve-jobs</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>The Real Leadership Lessons of Steve Jobs</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>The essence of Jobs, I think, is that his personality was integral to his way of doing business. He acted as if the normal rules didn&amp;#39;t apply to him.</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>published</span><span>"</span><span>:</span><span> </span><span>"</span><span>2012-04-01T00:00:00Z</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.youtube.com/watch?v=UF8uR6Z6KLc</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs' 2005 Stanford Commencement Address - YouTube</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Drawing from some of the most pivotal points in his life, Steve Jobs, chief executive officer and ...</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>published</span><span>"</span><span>:</span><span> </span><span>"</span><span>2008-03-07T00:00:00Z</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.forbes.com/profile/steve-jobs/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs - Forbes</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Apple cofounder Steve Jobs finally succumbed to cancer at the age of 56 on October 5th, leaving behind a legacy that changed the computer, music, film and ...</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://allaboutstevejobs.com/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Home | all about Steve Jobs.com</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs. This website is a repository of all things Steve Jobs — biography, pictures, videos of his keynotes and demos, quotes, interviews — you name it.</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.imdb.com/title/tt2080374/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs (2015) - IMDb</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>A film by Danny Boyle and Aaron Sorkin that depicts three pivotal moments in the life of Steve Jobs, the visionary leader of the digital revolution. Michael Fassbender, Kate Winslet, Seth Rogen and Jeff Daniels star in this drama nominated for two Oscars.</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.imdb.com/name/nm0423418/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs - IMDb</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>IMDb provides an overview of the life and career of Steve Jobs, the visionary co-founder of Apple and Pixar. Learn about his achievements, innovations, challenges, and legacy in the fields of technology, entertainment, and design.</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.imdb.com/name/nm0423418/bio/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs - Biography - IMDb</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Learn about the life and achievements of Steve Jobs, the visionary co-founder of Apple and Pixar. From his adoption and dropout to his cancer and legacy, discover his story and trivia on IMDb.</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.thoughtco.com/steve-jobs-biography-1991928</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Biography of Steve Jobs, Co-Founder of Apple Computers - ThoughtCo</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Learn about the life and achievements of Steve Jobs, the visionary entrepreneur who co-founded Apple Computers and Pixar Animation Studios. Explore his early years, inventions, business ventures, and legacy.</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.npr.org/2015/10/09/447165973/steve-jobs-the-story-of-the-man-behind-the-personal-computer</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs: The Story Of The Man Behind The Personal Computer</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>The Apple founder spoke with Fresh Air&amp;#39;s Terry Gross in 1996. Later, after he was diagnosed with cancer, Jobs asked Walter Isaacson to write his biography. Isaacson spoke to Fresh Air Oct. 25, 2011.</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>published</span><span>"</span><span>:</span><span> </span><span>"</span><span>2015-10-09T00:00:00Z</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.npr.org/2011/10/05/123826622/apple-visionary-steve-jobs-dies-at-56</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs, Poet Of Computer World, Dies - NPR</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs (1955-2011) Apple has lost a visionary and creative genius, and the world has lost an amazing human being. Those of us who have been fortunate enough to know and work with Steve have ...</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>published</span><span>"</span><span>:</span><span> </span><span>"</span><span>2011-10-05T00:00:00Z</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.nytimes.com/2011/10/06/business/steve-jobs-of-apple-dies-at-56.html</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs of Apple Dies at 56 - The New York Times</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Jim Wilson/The New York Times. By John Markoff. Oct. 5, 2011. Steven P. Jobs, the visionary co-founder of Apple who helped usher in the era of personal computers and then led a cultural ...</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>published</span><span>"</span><span>:</span><span> </span><span>"</span><span>2011-10-06T00:00:00Z</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.businessinsider.com/steve-jobs</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs' life and Apple career, from cofounder, to exile, to CEO</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Apple CEO Steve Jobs introduces the new iPod mini digital music player at the 2004 Macworld Conference and Expo in San Francisco. The player can hold up to 1,000 tunes, is about the size of a ...</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.entrepreneur.com/growing-a-business/who-was-steve-jobs-see-the-apple-founders-career-and-more/197538</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs Biography | Entrepreneur</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>An overview of Steve Jobs&amp;#39; life. Steven Paul Jobs was an American business owner, entrepreneur, investor and media proprietor. He was best known for co-founding and leading Apple, one of the most ...</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>      </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://www.computerhistory.org/blog/steve-jobs/</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>title</span><span>"</span><span>:</span><span> </span><span>"</span><span>Steve Jobs: From Garage to World’s Most Valuable Company</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>snippet</span><span>"</span><span>:</span><span> </span><span>"</span><span>Learn how Steve Jobs and Steve Wozniak, two young electronics hobbyists, created the Apple-1 and launched the personal computer revolution. Explore their early adventures with Blue Boxes, Atari, HP and the Homebrew Computer Club.</span><span>"</span></span>
<span><span>    </span><span>},</span></span>
<span><span>    </span><span>{</span></span>
<span><span>      </span><span>"</span><span>t</span><span>"</span><span>:</span><span> </span><span>1</span><span>,</span></span>
<span><span>      </span><span>"</span><span>list</span><span>"</span><span>:</span><span> </span><span>[</span></span>
<span><span>        </span><span>"</span><span>Steve Jobs</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs death</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs net worth</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs quotes</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs movie</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs wife</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs daughter</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs biography</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs last words</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>steve jobs age</span><span>"</span></span>
<span><span>      </span><span>]</span></span>
<span><span>    </span><span>}</span></span>
<span><span>  </span><span>]</span></span>
<span><span>}</span></span></code></pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dependency management fatigue, or why I forever ditched React for Go+Htmx+Templ (112 pts)]]></title>
            <link>https://blog.erodriguez.de/dependency-management-fatigue-or-why-i-forever-ditched-react-for-go-htmx-templ/</link>
            <guid>42305348</guid>
            <pubDate>Tue, 03 Dec 2024 12:16:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.erodriguez.de/dependency-management-fatigue-or-why-i-forever-ditched-react-for-go-htmx-templ/">https://blog.erodriguez.de/dependency-management-fatigue-or-why-i-forever-ditched-react-for-go-htmx-templ/</a>, See on <a href="https://news.ycombinator.com/item?id=42305348">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>After getting to work on some personal projects using Go+HTMX+Templ this year, I have decided to give up on using React on any personal projects.</p><p>You can actually find a lot of compelling arguments for ditching React in favor of HTMX in the essays found in the HTMX official website.
But I feel that not that many people are speaking about <strong>dependency management fatigue</strong>.</p><h2 id="what-is-dependency-management-fatigue">What is dependency management fatigue?</h2><p>After working on my last personal project that used React (an <a href="https://github.com/erodrigufer/catDict">interactive Catalan dictionary</a>), I realized that I was spending too much time dealing with dependency updates of mostly React packages.
I would update my packages to their latest release, only to realize that their APIs had breaking changes that forced me to invest time refactoring my code.</p><p>I wanted to keep up with any dependency updates because my webapp was back then deployed as a publicly accessible service in an EC2 instance and I wanted to avoid any possible vulnerabilities.</p><h2 id="do-we-really-need-a-new-major-version-release">Do we really need a new major version release?</h2><p>Some of the worst offenders in this respect were <code>wouter</code> (a React router package) and <code>TanStackQuery</code> (which I was using to fetch, cache and manage state from the backend).
<code>wouter</code> is, as of December 2024, at major version 3, while <code>TanStackQuery</code> is at major version 5.</p><p>I wasn’t using these packages for minor, stylistic features in my webapp, they were fundamental for the proper working of my webapp.
If they broke, my webapp fatally broke as well, i.e. no more data fetching from the backend and no more correct routing.
There was nothing similar to <em>progressive enhancement</em> in this case.</p><p>The first time that one of these React libraries broke my application with a major version bump, I refactored my code without any questioning.</p><p>But the second time that this happened, it just felt odd.
I started asking myself:</p><ul><li>Is my webapp getting some actual <strong>benefits</strong> (apart from maybe security patches) from this major version release?</li><li>Is it necessary to literally <strong>break</strong> the API of a fundamental component in a React webapp <strong>5 times</strong> ?!?!</li><li>How much time am I losing on this, when I could be shipping new features or other products?</li></ul><p>The answers to these questions were:</p><ol><li>No, my webapp wasn’t getting any additional benefits.
I was already happy with the functionality of these packages.</li><li>I am not a core maintainer of these libraries, so it is hard for me to answer the second question.
But I would say no.
Plan your API design wisely.
Only ship features that you plan to maintain in the long-term.
Do not unnecessarily rename your exported objects.</li></ol><p>Look, I am really grateful for open source maintainers, and you can do whatever you want with your projects (I myself do the same with mine).
But if your goal is to sustain a happy userbase, I would say that appreciating the user’s precious time must be a big priority.</p><h2 id="i-just-dont-have-the-time-to-deal-with-this">I just don’t have the time to deal with this…</h2><p>Which gets me to one of the main points of this article.
Why is this such a big issue?</p><p>Well, at least for me, it boils down to me not having that much free time left.
So, if I somehow find some free time to work on my personal coding projects, I don’t want to waste it refactoring my code to work after the major version bump of a dependency.
I actually want to work on features or start new projects.</p><p>If you are building a product for a client, and you will charge for future maintenance work, then be my guest, use as many unstable dependencies as you like.
It might be in your own best financial interest to do so.
But if you are trying to build a product that requires as little upkeep as necessary after being shipped, I’ll stay as far as possible from the JS ecosystem.</p><h2 id="gohtmxtempl">Go+HTMX+Templ</h2><p>That is maybe the main reason why I will solely use Go+HTMX+Templ in my personal projects from now on.
This is maybe just anecdotal evidence, but the Go projects I’ve worked on let me focus on shipping features, while not ignoring general dependency/security updates.
The language itself has kept a remarkably stable stdlib and language specification.</p><p><a href="https://lobste.rs/s/xyvjbb/dependency_management_fatigue_why_i">Discuss in Lobsters</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Company claims 1k% price hike drove it from VMware to open source rival (196 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2024/12/company-claims-1000-percent-price-hike-drove-it-from-vmware-to-open-source-rival/</link>
            <guid>42304955</guid>
            <pubDate>Tue, 03 Dec 2024 11:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2024/12/company-claims-1000-percent-price-hike-drove-it-from-vmware-to-open-source-rival/">https://arstechnica.com/information-technology/2024/12/company-claims-1000-percent-price-hike-drove-it-from-vmware-to-open-source-rival/</a>, See on <a href="https://news.ycombinator.com/item?id=42304955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>Companies have been discussing migrating off of VMware since Broadcom’s takeover a year ago led to higher costs and other <a href="https://arstechnica.com/information-technology/2024/06/price-hikes-of-over-2x-widely-expected-under-broadcoms-vmware-survey-finds/">controversial changes</a>. Now we have an inside look at one of the larger customers that recently made the move.</p>
<p>According to a report from <a href="https://www.theregister.com/2024/12/02/beeks_group_vmware_opennebula_migration/">The Register</a> today, Beeks Group, a cloud operator headquartered in the United Kingdom, has moved most of its 20,000-plus virtual machines (VMs) off VMware and to OpenNebula, an open source cloud and edge computing platform. Beeks Group sells virtual private servers and bare metal servers to financial service providers. It still has some VMware VMs, but “the majority” of its machines are currently on OpenNebula, The Register reported.</p>
<p>Beeks’ head of production management, Matthew Cretney, said that one of the reasons for Beeks' migration was a VMware bill for “10 times the sum it previously paid for software licenses,” per The Register.</p>
<p>According to Beeks, OpenNebula has enabled the company to dedicate more of its 3,000 bare metal server fleet to client loads instead of to VM management, as it had to with VMware. With OpenNebula purportedly requiring less management overhead, Beeks is reporting a 200 percent increase in VM efficiency since it now has more VMs on each server.</p>
<p>Beeks also pointed to customers viewing VMware as non-essential and a decline in VMware support services and innovation as drivers for it migrating from VMware.</p>
<p>Broadcom didn't respond to Ars Technica's request for comment.</p>
<h2>Broadcom loses VMware customers</h2>
<p>Broadcom will likely continue seeing some of VMware's older customers decrease or abandon reliance on VMware offerings. But Broadcom has emphasized the financial success it has seen (<a href="https://cdn.arstechnica.net/wp-content/uploads/2024/10/Broadcom-Inc.-Announces-Third-Quarter-Fiscal-Year-2024-Financial-Results-and-Quarterly-Dividend.pdf" target="_blank" rel="noopener">PDF</a>) from its VMware acquisition, suggesting that it will continue with its strategy even at the risk of losing some business.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No need to email me about Cisco AnyConnect (209 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2024/12/03/no-need-to-email-me-about-cisco-anyconnect/</link>
            <guid>42303903</guid>
            <pubDate>Tue, 03 Dec 2024 07:54:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2024/12/03/no-need-to-email-me-about-cisco-anyconnect/">https://daniel.haxx.se/blog/2024/12/03/no-need-to-email-me-about-cisco-anyconnect/</a>, See on <a href="https://news.ycombinator.com/item?id=42303903">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

	<div id="primary" role="main">
			
<article id="post-25989">
	
		<p><img width="672" height="372" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/10/Screenshot-2018-2-16-BMW-i3-Open-Source-Licences-YouTube-672x372.jpg" alt="" decoding="async" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/10/Screenshot-2018-2-16-BMW-i3-Open-Source-Licences-YouTube-672x372.jpg 672w, https://daniel.haxx.se/blog/wp-content/uploads/2016/10/Screenshot-2018-2-16-BMW-i3-Open-Source-Licences-YouTube-1038x576.jpg 1038w" sizes="(max-width: 672px) 100vw, 672px">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>My name and email address can be found in the VPN client application made by Cisco called AnyConnect.</p>



<p>They are present there as part of the <a href="https://curl.se/docs/copyright.html">curl license</a>, because  this product – like thousands of others – uses libcurl. <a href="https://daniel.haxx.se/my-name-in-products.html">My name appears in many products</a>.</p>



<p>Apparently, people often have problems finding an appropriate address to contact when they have issues with this app. This leads a disproportionate amount of them to send emails to me asking for solutions and fixes to their situations.</p>



<p>So far over the years, close to one hundred different persons have emailed me about problems with Cisco’s AnyConnect. I have not been able to help a single one of them because I know nothing about this application.</p>



<p>The reason my email address is shown there is because I am the lead developer of <a href="https://curl.se/">curl</a>, which is but a small component in this application. I am not associated with Cisco nor this product.</p>



<p>This is the support email address you are looking for:</p>



<p><strong>ac-mobile-feedback@cisco.com</strong></p>



<p><strong>See also</strong>: <a href="https://daniel.haxx.se/email/">other funny emails</a> I got and <a href="https://daniel.haxx.se/blog/2016/10/03/screenshotted-curl-credits/" data-type="post" data-id="9334">curl credit screenshots</a>.</p>
	</div><!-- .entry-content -->
	
	</article><!-- #post-25989 -->
		<nav>
		<h2>
			Post navigation		</h2>
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>curl, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Y Combinator and Power in Silicon Valley (272 pts)]]></title>
            <link>https://commoncog.com/c/cases/y-combinator-power/</link>
            <guid>42303798</guid>
            <pubDate>Tue, 03 Dec 2024 07:34:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://commoncog.com/c/cases/y-combinator-power/">https://commoncog.com/c/cases/y-combinator-power/</a>, See on <a href="https://news.ycombinator.com/item?id=42303798">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article_content">
  <div>
    <p>On September 10, 2010, AdGrok founder Antonio Garcia-Martinez was hanging out at co-founder Argyris Zymnis’s San Francisco apartment when he received a call from Rodger Cole. Rodger Cole was a litigator at Fenwick &amp; West, and Fenwick &amp; West was one of the big three Silicon Valley law firms. Getting an unexpected call from your law firm is never a good sign — this was no exception.</p><p>Cole told them they had just been sued by Adchemy, their former employer. This wasn’t entirely a surprise — when Garcia-Martinez and his co-founders Argyris and Matthew McEachen left Adchemy together to start their new company, Adchemy CEO and their former boss Murthy Nukala made it clear that he was not happy with any of them leaving. Adchemy had sent AdGrok legal warnings a few weeks before filing suit in Santa Clara County Court — these warnings were the “sort of menacing recital of employment-agreement restrictions that serves as the warning shot across the bow in corporate litigation.” The warnings led Garcia-Martinez to secure a preemptive relationship with Fenwick, and explained why it was Cole who received the paperwork.</p><p>At the time, AdGrok was tiny — all of three guys and their laptops. The startup had gone through the famous Silicon Valley startup accelerator Y Combinator, and had <em>just</em> presented at ‘Demo Day’ — the end-of-program event that marked graduation. Demo Day was a day-long presentation to invited investors, and it marked the start of external fundraising. To say the lawsuit complicated matters was to put it lightly. Adchemy named each of AdGrok’s co-founders <em>personally </em>in the suit, meaning that if they lost, the founders would be personally liable. The amounts involved in the suit effectively meant that all three co-founders would have been financially ruined.</p><p>The following events, relayed in Garcia-Martinez’s 2016 book <a href="https://www.goodreads.com/book/show/28259132-chaos-monkeys" rel="nofollow"><em>Chaos Monkeys</em></a>, is only one side of the story; it is not the definitive account of the events that transpired. But that definitive account might not exist: none of the other actors ever commented extensively about the battle.&nbsp;</p><p>That said, the provenance distracts from the purpose of this case. This isn’t really about Garcia-Martinez. Rather, this story is about the actions of Y Combinator, the startup accelerator and investor that Garcia-Martinez allied with, and the moves that its principals executed to protect one of its tiny companies.&nbsp;</p><p>It is also a story of power in Silicon Valley.</p><h2>The Stakes</h2><p>At the time of the lawsuit, Adchemy had raised nearly $60M dollars, and was <em>much</em> larger than AdGrok’s three person team. AdGrok, on the other hand, was struggling to fundraise, and struggling to get the lawyers from Fenwick to defend them in exchange for equity (this was so that they wouldn’t have to pay the lawyers desperately-needed cash). Through some finagling, Garcia-Martinez got legendary Silicon Valley attorney Ted Wang to agree to a $250,000 loan in payment for their services, to be paid either with cash, or with a combination of equity and equity options. Wang was invested in this for more than just financial reasons; to hear Garcia-Martinez tell it, the attorney was also angry that Adchemy had violated Silicon Valley’s unspoken norms. (For the sake of innovation and the good of the overall ecosystem, it was frowned-upon for large companies to attack fly-sized startups).&nbsp;</p><p>Fenwick immediately went to work. Litigator Rodger Cole started “firing sharply worded missives” at Santa Clara County court, rebutting Adchemy’s filed claims, offering to provide externally audited code as proof of innocence, and began the process of hostile depositions (which would suck up time and energy from Adchemy’s executives, including Murthy Nukala himself). But this conventional legal battle was mostly a front: AdGrok could not afford a drawn-out legal entanglement. The key to getting out of the lawsuit was to lean on Adchemy’s weaknesses.</p><p>What weaknesses did Adchemy have? Garcia-Martinez writes that it had two:</p><ol><li><p>It had investors, which sat on its board. This mattered, because board members with voting power could elect to kick out the CEO. Adchemy’s venture capital (VC) investors were from famous firms, and not too difficult to find: they were John Johnston from August Capital and Yogen Dalal from the Mayfield Fund.</p></li><li><p>It had potential business partners — which in Adchemy’s case was doubly important, for the company was floundering. Adchemy had — up to this point — only one major customer for its lead-generation product: Accenture. The entire company was running gigantic losses, with no real chance of turning on real product revenue; Murthy needed to pull in a new business partner to look good in time for Adchemy’s next round of fundraising. Through a stroke of luck, Garcia-Martinez discovered that Murthy was working on a major deal with Microsoft.&nbsp;</p></li></ol><p>If AdGrok could attack either or both weaknesses, Adchemy was likely to back off. The only question was how.</p><h2>The Knife</h2><p>The first angle of attack was with Adchemy’s investors. Here AdGrok was helped by a change in startup funding dynamics that Garcia-Martinez argues had taken place around the start of the 2010s.</p><p>The argument he makes goes something like this: traditionally, the earliest stages of startup fundraising was once done either by using up the entrepreneur’s own savings, or from raised funds from friends or families, or from business ‘angels’ — wealthy individuals who for fun or profit were willing to put their personal money into tiny, nascent companies.&nbsp;</p><p>This changed in the early 2010s, in part due to the emergence of the tech bubble of that decade (propped up, no doubt, by low interest rates). But it was also changed by the emergence of a new generation of rich ex-founders and early-employees — the result of the Google IPO, and also a smattering of startup acquisitions over the course of the late 1990s and 2000s. These newly rich individuals became investors, and some of these folks — such as ex-Googler and prominent angel Chris Sacca — raised small funds in the $20 million to $40 million range. This meant that the angels now had enough firepower to invest $200,000 checks instead of $20,000 checks — and early stage startups could go longer without talking to VC firms.&nbsp;</p><p>This change in capital environment dovetailed with a change in software development during the time. “The emergence of turnkey, on-demand computation like Amazon Web Services, plus off-the-shelf Web-development frameworks like Ruby on Rails, meant that new ideas were easier than ever to test.” Garcia-Martinez writes, “Many entrepreneurs chose to build shovels rather than dig for gold, creating more complex software building blocks to underpin the innovation, such as back-end services like Parse, accelerating the startup explosion in an almost exponential way.”&nbsp;</p><p>All of this meant that by the time AdGrok was formed, it was not shocking for a two-month-old company “with a persuasive CEO” to raise $2 million and have the raise be termed a ‘seed’ round. Nor was it shocking to find these startups hitting its milestones in six months, and raising its next round not too long after the ink had dried on the earlier checks. Garcia-Martinez continues <em>(bold emphasis added)</em>:</p><blockquote><p>With so much money, of all sizes and levels, waiting to invest, the best entrepreneurs had the luxury of choosing investors, rather than vice versa, and many investors found themselves anxiously trying to get into rounds. <strong>Due to contracts stipulating that investors in one round had the right to invest in the next, as well as personal ties between investors and entrepreneurs, investors getting in on oversubscribed A rounds had to be there in the seed round to earn that place. And that was true going up the various funding levels</strong>. That means VCs who would formerly say “Get back to me when you’re raising a series A or B, kid” were basically blocked from popular companies by investors who had nurtured and supported the company since it had been two guys in a trashy office. Heavyweight funds like Mayfield and August knew this, and started doing seed investing, not to own some little piece of a company (they could write small checks all day and still not invest their entire funds) but merely as an option on the real rounds down the road.</p></blockquote><p>This change in dynamic meant that Y Combinator had a unique position in the Silicon Valley ecosystem. Garcia-Martinez continues <em>(again, bold emphasis added)</em>:</p><blockquote><p>… in the day-to-day, the lifeblood of a VC wasn’t money, it was deal flow. Getting a first look at a potential Uber or Airbnb is what distinguishes a first-class VC from an also-ran. <strong>Given Y Combinator’s immense success in drawing the best entrepreneurs, it had a quasi-stranglehold on the best early-stage deal flow in the Valley. And since early-stage deal flow today translated into later-stage deal flow tomorrow, via the follow-on investing phenomena described, Y Combinator was the gatekeeper to the best present and future deals in the Valley</strong>. Like control of the water supply in some arid agricultural region, whoever had the most upstream control of the water sluice controlled everything else—which is what Y Combinator’s Demo Day represented. Thus, powerful and haughty VCs who wanted to attend Y Combinator’s showcase pitch event had to kneel and kowtow to a sandal-wearing bear of a man with a distaste for bullshit and a flair for the written word. That man was Paul Graham, without question the canniest tech investor in human history. And it was to Paul Graham we first turned with our existential problem in those desperate days.</p><p>(...) It was all the more impressive because I had miscast PG as a sort of avuncular, academic presence who dabbled in dense essays about startups, hosted founder dinners, and wrote a few checks. Nothing could be further from the truth. Y Combinator was the sort of unforgiving power player that remembered the names of investors who had crossed portfolio companies in the past, or who had disseminated unflattering portraits of YC, and blacklisted them from any YC dealings, or from the minds of YC founders. This was done with little thought of the size of their funds or their influence in the Valley, leaving more than one self-important VC sputtering at a dressing-down, or left out of a round because the company’s founders had gotten a warning from PG.</p><p>The harsh reality is this: to have influence in the world, you need to be willing and able to reward your friends and punish your enemies.</p></blockquote><p>When Graham first learnt of the lawsuit, he emailed Murthy to discuss the matter. Murthy was polite and deferential, but did not budge on his position. The lawsuit was still on.</p><p>Undeterred, Graham emailed Garcia-Martinez: “Come meet me at home to discuss this on Saturday. Come alone, don’t bring the others, and try to keep them out of it.” (Graham’s goal: to spare AdGrok’s other co-founders from the drama, so that they could continue building whilst the lawsuit resolved itself).</p><p>And so Garcia-Martinez arrived at PG’s house in Old Palo Alto.&nbsp;</p><blockquote><p>PG shared his anti-Adchemy game plan. In a nutshell: YC would anathematize Adchemy’s VCs, and declare that they’d never do business with YC again unless they straightened this out. Knowing PG, not only would they be disinvited from Demo Day, but PG would probably also steer companies to take money from other funds instead. Given that many if not most YC funding rounds were oversubscribed with investors, an excommunicated investor could be excluded without damaging the fund-raising company at all. At the end of the day, who really gave a shit if the check came from August versus Sequoia? That money was just as green either way. That meant that those funds would start losing YC deals wholesale to their competitors, and, as we reviewed earlier, getting locked out in the early rounds likely meant the same in the even juicier later ones. PG was about to flush a whole chunk of their deal flow down the toilet, just like that.</p><p>I smiled, imagining the sputtering fits pitched by the partners over at Mayfield and August when PG read them the riot act. YC was actually willing to sever ties with some of the most illustrious names in Valley investing over the piss squirt that was AdGrok. It may seem like nothing to you, reader, who maybe inhabits a normal realm of twenty-first-century economic life where things like tit-for-tat reciprocity enforce social codes. But in the passive-aggressive popularity contest that is Silicon Valley, someone actually going to bat for you—really going to bat, like telling important people to go fuck themselves—that’s rarer and more short-lived than a snowflake in a bonfire.</p><p>I thanked PG profusely, and then he padded back into the kitchen for his lunch.</p></blockquote><p>The next weakness was Adchemy’s big deal with Microsoft. Here Garcia-Martinez turned to (then) fellow YC founder and mentor, Sam Altman. </p><blockquote><p>[In 2016, when the book was published] Sam Altman is the current head of Y Combinator, and the person whom Paul Graham has entrusted with transforming his brainchild into a long-lived and scalable institution. In 2010, he was CEO and founder of Loopt, a company that had pioneered the location-check-in product that Foursquare would later eclipse (only to itself stumble), and which Facebook eventually worked into its product.</p><p>At the time, though, Loopt was still a location player, and Sam would take an hour out of his busy week, usually late afternoon on a Friday, to field whatever questions I had, no agenda required. The boys came along for the first session, and never again. I think they were scared of him, and with good reason. In one of PG’s essays on desirable founder qualities, he had this to say about Sam: “You could parachute him into an island full of cannibals and come back in five years and he’d be the king.”</p><p>I believed it, as did the boys. His official AdGrok nickname was “Manson Lamps,” after Tony Soprano’s psychotic rival, who possessed an intense and unsettling stare. This was a flip and admittedly unfair comparison; Sam never proved himself anything other than a capable operator and loyal friend to YC companies.</p></blockquote><p>‘Sama’, as Altman was widely known, was a well-connected node in Silicon Valley: “you know him, and you’re not more than two hops from anybody that matters.” Garcia-Martinez emailed Sama to ask if he knew anyone on the Microsoft deal team with Adchemy, explaining, solicitously, what Murthy was attempting to do to AdGrok. Sama called to clarify. Garcia-Martinez describes what happened next:</p><blockquote><p>Sam Altman assured me he’d try to do the best he could, and promptly cut off the call.</p><p>A week went by. Driving on the 280, I saw his number flash on my phone and pulled over; Sam Altman cannot be dealt with at eighty miles per hour.</p><p>“So I talked to [name redacted], who is Adchemy’s business-development contact at Microsoft. He assures me he brought up the AdGrok issue in one of their meetings with Adchemy. He stated it was going to be problematic if Adchemy was embroiled in litigation while discussing the Microsoft deal.”</p><p>I almost dropped my phone. This was precisely the decapitated horse’s head in Murthy’s bed that we needed. Murthy, with his back against the wall, running short of cash and with no salable product even remotely on the horizon, needed both the accounting and the marketing win of a big infusion of Microsoft money. Weasel that he was, Murthy had an overriding sense of self-preservation, and was still rational enough to realize that destroying AdGrok was not worth destroying Adchemy in the process. If indeed Microsoft BD had raised a flag about AdGrok, there’s no way Adchemy could continue the suit. It would be suicidal.</p><p>“Sam, I don’t know how to thank you for this.”</p><p>“No problem.”</p><p><em>Click.</em></p></blockquote><h2>The Resolution</h2><p>Garcia-Martinez did not have eyes everywhere, of course. Much later, he learnt that PG’s pressure on Adchemy’s investors was working:</p><blockquote><p>One of our investor friends had visited Mayfield Capital on unrelated business. Given the open nature of most VC offices, with all conference rooms and partner spaces facing some airy, sunny central area, he could see that Yogen Dalal, the managing partner for the Adchemy investment and Silicon Valley notable, was in a conference room having what appeared to be a strained conversation with Murthy. Board meetings or advisory sessions (not that Murthy took advice from anyone) should have taken place at Adchemy, not Mayfield, at that stage. That, plus the timing, signaled that this conversation was likely about AdGrok. It seemed that PG had delivered, and Adchemy’s investors had started putting the squeeze on Murthy, using their moral (not to mention financial) suasion to get Adchemy to retire the suit.</p></blockquote><p>In late October Adchemy’s tone changed abruptly: where before they were menacing, now they were conciliatory. AdGrok received an offer to dismiss the suit. By February the whole ordeal was over, but for the lawyer’s fees. The three co-founders signed some token agreements, and sent Fenwick a copy of their code for safekeeping (they encrypted the zip archive; so confident were they that nobody would even bother to check).</p><p>AdGrok had won.</p><p>But the episode was not without cost. A few years later, on the event of Adchemy’s death in 2014, Garcia-Martinez would <a href="https://priceonomics.com/the-time-my-startup-got-sued/" rel="nofollow">post on Facebook</a>:</p><blockquote><p>Through the most dogged persistence, we managed to raise a seed round in the teeth of a bitter lawsuit, and continued to fund operations. But the damage had been done. My co-founders and I were tired of the fight, and the startup adventure for us had been a yearlong, unremitting existential battle that had subsumed whatever product vision we had. The company sold to Twitter in May 2011 and the product disappeared. In a way, Murthy won in the end.</p></blockquote><p>After raising around $120 million in funding, Adchemy was bought by Walmart Labs for an alleged <a href="https://www.businessinsider.com/document-from-walmart-adchemy-acquisition-shows-top-managers-got-rich-2014-5" rel="nofollow">$30-$40 million</a> — a “fire-sale ‘acquisition’”. Many employees who purchased stock in the company lost their savings, and the investors lost most if not all of their capital. Murthy Nukala, on the other hand, managed to negotiate a <a href="https://www.businessinsider.com/document-from-walmart-adchemy-acquisition-shows-top-managers-got-rich-2014-5" rel="nofollow">$2.4 million golden parachute deal</a> for himself, and various other amounts for a small group of Adchemy executives. All of those deals were multiples of their salaries.</p><p>If the <a href="https://www.businessinsider.com/document-from-walmart-adchemy-acquisition-shows-top-managers-got-rich-2014-5" rel="nofollow">Business Insider article</a> reporting this arrangement is to be believed, Murthy walked away rich, while stiffing his employees and investors in the back.&nbsp;</p><p>To our knowledge, Garcia-Martinez never crossed paths with Nukala again.</p><h2>Sources</h2><ol><li><p><a href="https://www.goodreads.com/book/show/28259132-chaos-monkeys" rel="nofollow"><em>Chaos Monkeys: Obscene Fortune and Random Failure</em></a><em>, by Antonia Garcia-Martinez&nbsp;</em></p></li><li><p><a href="https://priceonomics.com/the-time-my-startup-got-sued/" rel="nofollow">The Time My Startup Got Sued</a> (<a href="https://archive.is/8kErI" rel="nofollow">archive.is backup</a>)</p></li><li><p><a href="https://www.businessinsider.com/document-from-walmart-adchemy-acquisition-shows-top-managers-got-rich-2014-5" rel="nofollow">https://www.businessinsider.com/document-from-walmart-adchemy-acquisition-shows-top-managers-got-rich-2014-5</a> (<a href="https://archive.is/qCj15" rel="nofollow">archive.is backup</a>)</p></li></ol>
    
  </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blizzard's pulling of Warcraft I and II tests GOG's new Preservation Program (228 pts)]]></title>
            <link>https://arstechnica.com/gaming/2024/12/blizzards-pulling-of-warcraft-i-ii-tests-gogs-new-preservation-program/</link>
            <guid>42303274</guid>
            <pubDate>Tue, 03 Dec 2024 05:26:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gaming/2024/12/blizzards-pulling-of-warcraft-i-ii-tests-gogs-new-preservation-program/">https://arstechnica.com/gaming/2024/12/blizzards-pulling-of-warcraft-i-ii-tests-gogs-new-preservation-program/</a>, See on <a href="https://news.ycombinator.com/item?id=42303274">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>GOG's version goes a bit beyond the classic versions that were on sale on Blizzard.net. Beyond the broad promise that "this is the best version of this game you can buy on any PC platform," GOG has made specific tweaks to the networking code for <em>Warcraft I</em>&nbsp;and fixed up the DirectX wrapper for&nbsp;<em>Warcraft II</em> to improve its scaling on modern monitor resolutions.</p>
<p>It's quite a novel commitment, keeping non-revenue-generating games playable for buyers, even after a publisher no longer makes them available for sale. The&nbsp;Warcraft titles certainly won't be the only games for which publisher enthusiasm lags behind GOG and its classic gamers.</p>
<p>As noted at the <a href="https://arstechnica.com/gaming/2024/11/gogs-preservation-program-is-the-drm-free-store-refocusing-on-the-classics/">Preservation Program's launch</a>, for some titles, GOG does not have the rights to modify a game's build, and only its original developers can do so. So if GOG can't make it work in, say, <a href="https://www.dosbox.com/">DOSBox</a>, extraordinary efforts may be required.</p>
<figure>
    <div>
            <p><a data-pswp-width="1080" data-pswp-height="608" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster.jpeg 1080w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-640x360.jpeg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-1024x576.jpeg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-768x432.jpeg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-384x216.jpeg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-980x552.jpeg 980w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster.jpeg" target="_blank">
              <img width="1080" height="608" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster.jpeg" alt="A screenshot from Blizzard's Warcraft II: Remastered release, showing brick keeps, archers, footsoldiers, dragons around a roost, and knights on horseback units." decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster.jpeg 1080w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-640x360.jpeg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-1024x576.jpeg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-768x432.jpeg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-384x216.jpeg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/warcraft2_remaster-980x552.jpeg 980w" sizes="auto, (max-width: 1080px) 100vw, 1080px">
            </a></p><div id="caption-2064198">
              <p><em>Warcraft II: Remastered</em> lets you switch back and forth between classic and remastered graphics and promises to offer better support for widescreen monitors and more units selected at once.
                              </p><p>
                  Credit:
                                      Blizzard
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p><em>Warcraft II: Remastered</em> lets you switch back and forth between classic and remastered graphics and promises to offer better support for widescreen monitors and more units selected at once.

              <span>
          Credit:

          
          Blizzard

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>Beyond being tied to Blizzard's Battle.net service in perpetuity, there are other reasons&nbsp;<em>Warcraft </em>fans might want to hold onto the originals. Blizzard's 2020 release of <a href="https://arstechnica.com/gaming/2020/01/warcraft-iii-reforged-not-the-flavor-of-chaos-we-were-hoping-for/"><em>Warcraft III Reforged</em></a> was widely panned as uneven, unfinished, and in some ways unfair, as it, too, removed the original&nbsp;<em>Warcraft III </em>from stores.&nbsp;<em>Reforged</em> was still in rough shape a year later, leading <a href="https://arstechnica.com/gaming/2021/01/warcraft-iii-reforged-tops-our-list-of-2020s-most-disappointing-video-games/">Ars' list of 2020's most disappointing games</a>. A 2.0 update promised a total reboot, but fans remain torn on the new art styles and <a href="https://www.ign.com/articles/blizzard-says-warcraft-3-reforged-20-is-a-fresh-start-but-fans-remain-unconvinced-after-rocky-launch">are somewhat wary</a>.</p>
<p>Then again, you can now select more units in the first two&nbsp;<em>Warcraft</em> games' remasters, and you get "numerous visual updates for the UI."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi boosts Pi 5 performance with SDRAM tuning (219 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2024/raspberry-pi-boosts-pi-5-performance-sdram-tuning</link>
            <guid>42303111</guid>
            <pubDate>Tue, 03 Dec 2024 04:39:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2024/raspberry-pi-boosts-pi-5-performance-sdram-tuning">https://www.jeffgeerling.com/blog/2024/raspberry-pi-boosts-pi-5-performance-sdram-tuning</a>, See on <a href="https://news.ycombinator.com/item?id=42303111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>tl;dr</strong> Raspberry Pi engineers tweaked SDRAM timings and other memory settings on the Pi, resulting in a 10-20% speed boost at the default 2.4 GHz clock. I of course had to test overclocking, which got me a <em>32%</em> speedup at 3.2 GHz! Changes may roll out in a firmware update for all Pi 5 and Pi 4 users soon.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/pi-5-overclock-desk-mess.jpeg" alt="Raspberry Pi 5 with SDRAM tweaks applied on desk"></p>

<p>My quest for the <a href="https://browser.geekbench.com/v6/cpu/search?dir=desc&amp;q=Raspberry+Pi+5+Model+B&amp;sort=score">world record Geekbench 6 score on a Pi 5</a> continues, as a couple months ago <a href="https://www.martinrowan.co.uk/2024/09/raspberry-pi-5-overclocking-to-beat-geekbench-record/">Martin Rowan</a> used cooling and <a href="https://www.jeffgeerling.com/blog/2024/numa-emulation-speeds-pi-5-and-other-improvements">NUMA emulation tricks</a> to beat my then-record score.</p>

<p>But Raspberry Pi's engineers are <a href="https://forums.raspberrypi.com/viewtopic.php?t=378276">tweaking memory timings even further</a>. They've talked to Micron and implemented a number of small tweaks that—along with NUMA emulation—really add up to a performance improvement for multi-core workloads. And even a little improvement for single-core!</p>

<blockquote>
  <p>The sdram refresh interval is currently using the default data sheet settings. You can actually monitor the temperature of the sdram and it reports if refresh at half or quarter the rate can be done. That allows the overhead due to refresh to be reduced by a half or a quarter which does improve benchmark results.</p>
  
  <p>We got in contact with Micron, and there is good news. They have said they actually test their 8GB sdram with the 4GB refresh rate timing (rather than the slower jedec timings), and so it was be safe to run the 8GB parts with 4GB timing.</p>
</blockquote>

<p>The tweaks can also give the Pi 4 a boost, but the Pi 5 improves more dramatically:</p>

<blockquote>
  <p>Pi 5 also has faster sdram, better access to sdram (i.e. wider/faster internal buses), so generally the improvements with NUMA are greater.</p>
</blockquote>

<h2>SDRAM Tweaks</h2>

<p>To get the latest RAM speedups <em>for now</em> (this may be default soon):</p>

<ol>
<li>Update the Pi's firmware to the latest version: <code>sudo rpi-update</code> (confirm with <code>Y</code>)</li>
<li>Edit the bootloader config: <code>sudo rpi-eeprom-config -e</code></li>
<li>Add the configuration <code>SDRAM_BANKLOW=1</code> (for Pi 5... for Pi 4, use <code>3</code>)</li>
<li>Reboot</li>
</ol>

<h2>NUMA Emulation</h2>

<p>Since my <a href="https://www.jeffgeerling.com/blog/2024/numa-emulation-speeds-pi-5-and-other-improvements">first post on NUMA emulation on the Pi 5</a>, the patches required have been added to Raspberry Pi's OS kernel.</p>

<p>So to use NUMA, all you have to do is make sure you're on the latest Pi OS (e.g. <code>sudo apt full-upgrade</code>).</p>

<p>To check if NUMA emulation is working, run <code>dmesg | grep NUMA</code> and make sure it says something like <code>mempolicy: NUMA default policy overridden to 'interleave:0-7'</code>. You can tweak the settings if you want by adding <code>numa=fake=[n]</code> inside <code>/boot/firmware/cmdline.txt</code>, though the defaults <em>should</em> be appropriate for most use cases.</p>

<h2>Overclocking</h2>

<p>Following my own guide for <a href="https://www.jeffgeerling.com/blog/2023/overclocking-and-underclocking-raspberry-pi-5">overclocking the Pi 5</a>, I set the following inside <code>/boot/firmware/config.txt</code>:</p>

<pre><code>over_voltage_delta=72000
arm_freq=3200
gpu_freq=1000
</code></pre>

<p>After rebooting, I set the fan to 100%, <a href="https://github.com/geerlingguy/pi-overvolt">hacked the kernel with my pi-overvolt project</a> to boost the core voltage, and set the scaling governor to <code>performance</code>:</p>

<pre><code>$ pinctrl FAN_PWM op dl
$ cd pi-overvolt &amp;&amp; sudo ./removelimit &amp;&amp; vcgencmd cache_flush
$ echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
</code></pre>

<h2>Geekbench World Record, Part 2</h2>

<p>With just the default firmware changes, my Geekbench scores already increase quite a bit (+8% single, +18% multi). Adding a 3.2 GHz overclock on top (using my <a href="https://github.com/geerlingguy/pi-overvolt">pi-overvolt</a> hack to boost voltages), those increases go to +32% single, +31% multi, resulting in yet <a href="https://browser.geekbench.com/v6/cpu/search?dir=desc&amp;q=Raspberry+Pi+5+Model+B&amp;sort=score">another world-record Geekbench 6 score</a>!</p>

<table>
<thead>
<tr>
  <th>Geekbench Result</th>
  <th><a href="https://browser.geekbench.com/v6/cpu/9130658">Pi 5 - defaults</a></th>
  <th><a href="https://browser.geekbench.com/v6/cpu/9202663">SDRAM + NUMA</a></th>
  <th><a href="https://browser.geekbench.com/v6/cpu/9204206">3.2 GHz OC</a></th>
</tr>
</thead>
<tbody>
<tr>
  <td>Single</td>
  <td>833</td>
  <td>899 (+8%)</td>
  <td>1153 (+32%)</td>
</tr>
<tr>
  <td>Multi</td>
  <td>1805</td>
  <td>2169 (+32%)</td>
  <td>2468 (+31%)</td>
</tr>
</tbody>
</table>

<p>I also ran these tests with just an <a href="https://amzn.to/3OAkUo7">Argon THRML 30-AC Active Cooler</a>. To try to keep temps under control, I boosted the fan speed to 100%: <code>pinctrl FAN_PWM op dl</code>.</p>

<blockquote>
  <p><strong>A word on overclocking</strong>: I've now overclocked around 20 Pi 5s, and found most to be capable of 2.6 or 2.8 GHz, and many (about half) to be capable of 3.0 GHz. But beyond that, very few can hit 3.1 GHz or beyond. More exotic overclocking (to 3.4 or 3.5 GHz) is much more difficult, and I've only had <em>one</em> Pi 5 that even boots reliably at those speeds, with more extensive cooling. RAM timings were already not happy at those speeds, and with the extra SDRAM tweaks, I imagine extreme overclocking will be even <em>more</em> unstable.</p>
</blockquote>

<h2>Conclusion</h2>

<p>These optimizations could become default soon. I started looking into this after someone on Twitter mentioned seeing <a href="https://browser.geekbench.com/search?page=2&amp;q=raspberry+500">Pi 500 Geekbench results</a> starting in September—all seemingly with these tweaks in place already!</p>

<p>Memory speed has been a thorn in the Pi 5's side in comparison to many RK3588 boards. It's nice to see the SDRAM tweaks giving it a significant speed boost, over a year post-launch.</p>

<p>And eagle-eyed readers may note I only overclocked to 3.2 GHz instead of 3.4 GHz this time. I'll leave the door open for someone else to combine all the above tricks to hit another new WR score ;)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twice-Yearly HIV Shot Shows 100% Effectiveness in Women (235 pts)]]></title>
            <link>https://apnews.com/article/hiv-infections-aids-prevention-shot-02606f7d7892f0baf55bd0a0ff2ba3de</link>
            <guid>42302963</guid>
            <pubDate>Tue, 03 Dec 2024 03:57:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/hiv-infections-aids-prevention-shot-02606f7d7892f0baf55bd0a0ff2ba3de">https://apnews.com/article/hiv-infections-aids-prevention-shot-02606f7d7892f0baf55bd0a0ff2ba3de</a>, See on <a href="https://news.ycombinator.com/item?id=42302963">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>MEXICO CITY (AP) — It’s been called the closest the world has ever come to a vaccine against the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/hub/hiv-and-aids">AIDS</a></span> virus.</p><p>The <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/africa-aids-hiv-infection-prevention-shot-sunlenca-a94b83717f5b61987822335e11398428">twice-yearly shot</a></span> was 100% effective in preventing HIV infections in a study of women, and results published Wednesday show it worked nearly as well in men.</p><p>Drugmaker <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.gilead.com/news/news-details/2024/gilead-signs-royalty-free-voluntary-licensing-agreements-with-six-generic-manufacturers-to-increase-access-to-lenacapavir-for-hiv-prevention-in-high-incidence-resource-limited-countries" target="_blank" rel="noopener">Gilead</a></span> said it will allow cheap, generic versions to be sold in 120 poor countries with high HIV rates — mostly in Africa, Southeast Asia and the Caribbean. But it has excluded nearly all of <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/hiv-latino-hispanic-treatment-prevention-aids-ca5f73b064e5ed491ee0315dd60d69d1">Latin America</a></span>, where rates are far lower but increasing, sparking concern the world is missing a critical opportunity to stop the disease.</p><p>“This is so far superior to any other prevention method we have, that it’s unprecedented,” said Winnie Byanyima, executive director of UNAIDS. She credited Gilead for developing the drug, but said the world’s ability to stop AIDS hinges on its use in at-risk countries.</p>
    

<p>In a <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://rightspath.unaids.org/?utm_source=UNAIDS%20Newsletter&amp;utm_campaign=e05145dfc2-20241126_world-aids-day-report&amp;utm_medium=email&amp;utm_term=0_e7a6256e25-e05145dfc2-114159125" target="_blank" rel="noopener">report</a></span> issued to mark World AIDS Day on Sunday, UNAIDS said that the number of AIDS death last year — an estimated 630,000 — was at its lowest since peaking in 2004, suggesting the world is now at “a historic crossroads” and has a chance to end the epidemic. </p>



<p>The drug called lenacapavir is already sold under the brand name Sunlenca to treat HIV infections in the U.S., Canada, Europe and elsewhere. The company plans to seek authorization soon for the drug to be used for HIV prevention.</p><p>While there are other ways to guard against infection, like condoms, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/daily-hiv-prevention-pill-urged-for-healthy-people-at-risk-9d45991f257b4800a12e1c32a3b0f308">daily pills</a></span>, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/hiv-africa-women-vaginal-ring-3e9a583a1d0b5f7863a9795ec4d2ff4f">vaginal rings</a></span> and bi-monthly shots, experts say the Gilead twice-yearly shots would be particularly useful for marginalized people often fearful of seeking care, including gay men, sex workers and young women. </p>
    
    
    
<p>“It would be a miracle for these groups because it means they just have to show up twice a year at a clinic and then they’re protected,” said UNAIDS’ Byanyima. </p><p>Such was the case for Luis Ruvalcaba, a 32-year-old man in Guadalajara, Mexico, who participated in the latest published study. He said he was afraid to ask for the daily prevention pills provided by the government, fearing he would be discriminated against as a gay man. Because he took part in the study, he’ll continue to receive the shots for at least another year.</p>
    

<p>“In Latin American countries, there is still a lot of stigma, patients are ashamed to ask for the pills,” said Dr. Alma Minerva Pérez, who recruited and enrolled a dozen study volunteers at a private research center in Guadalajara.</p><p>How widely available the shots will be in Mexico through the country’s health care system isn’t yet known. Health officials declined to comment on any plans to buy them for its citizens; daily pills to prevent HIV were made freely available via the country’s public health system in 2021. </p><p>“If the possibility of using generics has opened, I have faith that Mexico can join,” said Pérez.</p><p>Byanyima said other countries besides Mexico that took part in the research were also excluded from the generics deal, including Brazil, Peru and Argentina. “To now deny them that drug is unconscionable.” she said.</p>
    

<p>In a statement, Gilead said it has “an ongoing commitment to helping enable access to HIV prevention and treatment options where the need is the greatest.” Among the 120 countries eligible for generic version are 18 mostly African countries that comprise 70% of the world’s HIV burden. </p><p> The drugmaker said it is also working on establishing “fast, efficient pathways to reach all people who need or want lenacapavir for HIV prevention.”</p><p>On Thursday, 15 advocacy groups in Peru, Argentina, Ecuador, Chile, Guatemala and Colombia wrote to Gilead, asking for the generic version to be made available in Latin America, citing the “alarming” inequity in access to new HIV prevention tools while infection rates were rising. </p><p>While countries including Norway, France, Spain and the U.S. have paid more than $40,000 per year for Sunlenca, experts have calculated it could be produced for as little as $40 per treatment once generic production expands to cover 10 million people. </p><p>Dr. Chris Beyrer, director of the Global Health Institute at Duke University, said it will be enormously useful to have the Gilead shots available in the hardest-hit countries in Africa and Asia. But he said the rising HIV rates among groups including gay men and transgender populations constituted “a public health emergency” in Latin America.</p>
    

<p>Hannya Danielle Torres, a 30-year-old trans woman and artist who was also in the study in Mexico, said she hoped the government would find a way to provide the shots. “Mexico may have some of the richest people in the world but it also has some of the most vulnerable people living in extreme poverty and violence,” Torres said. </p><p>Another drugmaker, Viiv Healthcare, also left out most of Latin America when it allowed generics of its HIV prevention shot in about 90 countries. Sold as Apretude, the bi-monthly shots are about 80% to 90% effective in preventing HIV. They cost about $1,500 a year in middle-income countries, beyond what most can afford to pay.</p>
    

<p>Asia Russell, executive director of the advocacy group Health Gap, said that with more than 1 million new HIV infections globally every year, established prevention methods are not enough. She urged countries like Brazil and Mexico to issue “compulsory licenses,” a mechanism where countries suspend patents in a health crisis.</p><p>It’s a strategy some countries embraced for previous HIV treatments, including in the late 1990s and 2000s when AIDS drugs were first discovered. More recently, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/bedaquiline-dolutegravir-tuberculosis-hiv-south-africa-0f6de15ea57279b699c147c015b23c02">Colombia</a></span> issued its first-ever compulsory license for the key HIV treatment Tivicay in April, without permission from its drugmaker, Viiv. </p><p>Dr. Salim Abdool Karim, an AIDS expert at South Africa’s University of KwaZulu-Natal, said he had never seen a drug that appeared to be as effective as the Gilead shot in preventing HIV. </p><p> “The missing piece in the puzzle now is how we get it to everyone who needs it,” he said.</p><h2>___</h2><p>Cheng reported from London. </p><h2>___</h2><p>The Associated Press Health and Science Department receives support from the Howard Hughes Medical Institute’s Science and Educational Media Group. The AP is solely responsible for all content.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lessons I learned working at an art gallery (371 pts)]]></title>
            <link>https://www.henrikkarlsson.xyz/p/art-gallery</link>
            <guid>42302784</guid>
            <pubDate>Tue, 03 Dec 2024 03:18:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.henrikkarlsson.xyz/p/art-gallery">https://www.henrikkarlsson.xyz/p/art-gallery</a>, See on <a href="https://news.ycombinator.com/item?id=42302784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em>A few days ago, I resigned from my job at the art gallery to write Escaping Flatland full time.&nbsp;</em></p><p><em>One day I hope to be a good enough writer to put words to how thankful I am to the many people who have helped me reach this point. For now, let me just say that I feel the weight of your care, and I will do my best to honor it.</em></p><p><em>But before I throw myself into new projects, I want to pause and reflect on the last three and a half years at the gallery—it was an important experience for me, and I want to highlight a few lessons I learned.</em></p><p><em>(When I began listing, I realized I had learned a lot so I will only cover a small part of it here, mostly lessons around career stuff and agency. I might write what I learned about making art at a later time, if someone is interested (comment!), and about what I learned from the volunteers at the gallery, a group of high agency 70 and 80-year-olds. So much to say!)</em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg" width="857" height="1056" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1056,&quot;width&quot;:857,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:261725,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe720a953-2771-40ab-8b09-2e6d24c2ba93_857x1056.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><h6><em><strong>The Artist's Garden at Vetheuil, </strong></em><span>Claude Monet, 1880-81</span></h6><p>I was the only person who applied for the job at the gallery because it was so shitty: it was basically selling coffee all weekends with lousy pay and no vacations during summers. But in 2021 we had recently moved to Denmark, so I had no professional network and didn’t speak the language, and Rebecka had just been born, and we needed the money—so I couldn’t be picky.</p><p>I also felt that the place had, as real estate agents say, “good bones”: it was beautiful, they had 6 exhibition halls, and it was a 25-minute bike ride from home.</p><p>For most of my career, I have worked short gigs or at projects that I started—the longest stretch I’ve been employed was, I think, 4 months at a bio lab when I was 19. No, that’s not right; I worked 8 months in a school when I was going down a rabbit hole about education in 2016/17. My working model has been that being employed kind of sucks. But this time, since I knew I couldn’t afford to quit anytime soon with the baby and all, I figured I could try treating it like one of my projects. So instead of selling coffee, I looked into how we could streamline the café and the cash register so that the volunteers who help out at the gallery felt comfortable doing my job, then I made myself a small office where I sat down to analyze the business and figure out how to improve it. You can imagine how popular this was. I had to backtrack for a few months after the board told me to get back to the café. And this was a good lesson for someone who is used to being self-employed: at an institution, you can’t just do what is best, you also have to build trust and coordinate with others so you are on the same page. This, however, doesn’t mean that you should abdicate your judgment and get in line.</p><p><span>I like the approach </span><a href="https://arc.net/l/quote/qiikxitd" rel="">Sholto Douglas expressed</a><span> in his interview with Dwarkesh Patel:</span></p><blockquote><p>If I’m trying to write some code and something isn't working, even if it’s in another part of the code base, I’ll often just go in and fix that thing or at least hack it together to be able to get results. [...] I think that's arguably the most important quality in almost anything. It's just pursuing it to the end of the earth. Whatever you need to do to make it happen, you'll make it happen. [...] I’m just going to vertically solve the entire thing. And that turns out to be remarkably effective.</p></blockquote><p><span>Ie. you don’t say, “This is my job and that thing is outside my area”—no, if the value you are trying to promote requires you to go outside your role and learn new skills and politick to get the authority to go ahead: then that </span><em>is</em><span> your job.</span></p><p>I’m not at the level of Sholto Douglas, but I figured I could at least try. So I made an agreement with my boss, who liked me, that she would let me sit in on the board meetings, and I began mapping out who was who and what they wanted and made sure to talk to all stakeholders when they passed through the gallery, and in 6 months I had a good enough model of what their values and goals were so I could align myself to the mission and make legible to them what I was doing. As my boss learned to trust me, she began to say that my role was “do whatever you think is right,” and eventually, after about a year, “. . . and you work whenever you feel like it.” (It helped that the year I started was the inflection point when the revenue, which had been shrinking or muddling for 5 years, began growing again; this wasn’t all my work, but it made my boss trust me.)</p><p>For the last 2.5 years I’ve mostly set my own agenda, and I’ve worked in uneven sprints and bursts, sometimes doing 70-hour weeks (my contract was 20 hours per week), and sometimes staying home for 10 days to write essays. This bursty way of working fits my temperament well, and I’ve genuinely loved this job in a way I didn’t think I’d ever love a job.</p><p>A bunch of my friends envied my role. But no one else applied.</p><p>I’ve worked with . . . ~150 artists from 33 countries. Quite a few of them have been the way artists are typically portrayed: self-centered, hard to work with, a little crazy. These were the amateurs. The best artists I’ve worked with, for example A and B, a husband and wife duo, were not at all like that. Let me give an example.</p><p>My boss fundraised and sold a large public sculpture A and B had made earlier this year. The day before we were going to install it, A and B came to the gallery and explained that they had found a better electronic component. Not that the old one was bad—it was the best one they had been able to find when they originally made the sculpture. But the new one was a little bit better. So then they proceeded to dismantle the entire sculpture, get their welding kit, and work for seven hours improving the sculpture. Notice three things:</p><ol><li><p>A and B had already been paid and the buyer was more than happy.</p></li><li><p>A and B didn’t tell the customer that they had spent 14 man hours improving it; it was just something they did because it was right, nothing they wanted credit for.</p></li><li><p>A and B have earned enough money from their New York gallerist to retire, but they’d rather use that money to make better art.</p></li></ol><p>It is this kind of attitude that makes someone succeed at their level, as far as I can tell. They are always pushing themselves to the edge, which makes them grow, and they are so selfless and pleasant to work with that you just want to do more stuff with them all the time. And you need that attitude to do anything ambitious: you need support, and funding, and goodwill, and you don’t get that by being disorganized or self-centered. Maybe at the very top of the art world artists can afford to be annoying again, I don’t know.</p><p>This is sort of a corollary to the above. When we work with artists like A and B, they answer their emails within the hour and they never complain when we can’t meet an expectation they have and when they come in they work hard and fast and deliver a great exhibition in a few hours. Certain other artists are more like, “oh, I don’t know what I want to do . . .” “can you get me more funding?” “that scratch on the floor makes my art look bad, you need to fix it” “can you build a wall there?” “no that wall wasn’t right after all, can you take it down” and after weeks of this you end up with something mediocre.</p><p>I got to run something like an experiment on my capacity to predict which exhibitions would end up great, and which would be a waste of time. It was easy. As soon as someone was slow at answering their email, or complained, or wanted us to be their therapist as they worked through the creative worries, I would tell my boss, “I think we should cancel this.” And my boss—whose strength and weakness is that she thinks the best of people and makes everyone feel held—would say, “Ah, but they are just a bit sloppy with email” “if we just fix this thing it will be fine. . .”&nbsp;</p><p>I was right every time; it ended in pain.</p><p>And this is quite nice actually: it means it doesn’t take some Tyler Cowen-level taste in talent to figure out who will do good work. I had limited experience with artists. But it turns out that if you are just a bit patient and say, “No, I’m not going to work with anyone who is demanding or confused or slow at answering their email”—then you are basically home.</p><p>And when you work like that, when you are patient for the right opportunities, you don’t have to do a lot of work at all. You just go around talking to people until you find a good match...and then the work sort of does itself with little effort. Very convenient!</p><p>It is not that I’m some grumpy person who thinks that some people are great and others aren’t, in some predetermined way—I think you can to a large extent decide which kind you want to be. But if someone else isn’t measuring up, I have no idea how to convince them to do so. So I look for people who have already decided.</p><p>An art gallery—especially a co-op art gallery with a non-profit board like the one I worked at—is a strange kind of business. The aim is not to earn money but to create beauty and strengthen the community and all of these other hard-to-measure things. Because of this, the gallery attracted people who prefer to think about higher values, rather than stuff like economic growth, which was seen as icky.</p><p>I am very much in that direction myself; I found it, for example, almost shameful to turn on paid subscriptions on my blog.</p><p>But something that became clear to me at the gallery, and from working with people like A and B who did art at a high level, is that you simply can’t afford to do good stuff if you don’t figure out the funding part.</p><p>Our elevator at the gallery, for example, was falling apart, and it would be illegal for us to keep open without one, which meant that we would be unable to do anything if we couldn’t get the money for the elevator—no community, no art, no nothing. My first boss and the board had not realized this, and when I pointed this out, there was a vague feeling that if this happened “the municipality should pay for it because art is so important.”</p><p><span>But the municipality on our island is in bad economic shape, and is considering cutting back on care for the elderly to balance their budget—so, to me, it feels unethical to angle for more money for the arts.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-151598106" href="https://www.henrikkarlsson.xyz/p/art-gallery#footnote-1-151598106" target="_self" rel="">1</a></span><span> This is the kind of topic that makes me pound the table in fervor as I talk about it; I have often given this sermon to art students. We have a duty to our values and a duty to our community, and we can’t shy away from that because it feels hard, or because we want to be seen in a certain way, and then expect others to bail us out! We should shoulder our responsibility and figure out a way to make the art (or whatever we value) so attractive and meaningful that people feel good about funding it by becoming members or buying art or coffee or whatever.</span></p><p>If we want to make the world a better place, we can’t just think about the lofty stuff: we have to get our hands dirty and make sure the economic engine works.</p><p>It is not unreasonable to feel icky about the business side of art because the incentives of the market (and the grantmakers . . .) often really do pull in directions that actively threaten the very values that we care about. Yes.</p><p>But that is only a rough approximation of the truth.</p><p>If you take the time to actually bang your head against reality and figure out how to fund something, you will discover that there are places in the incentive landscape where the incentives (which are really the desires and needs of other human beings) align with your ineffable values. If you want to bring as much of what you have to give into the world, it is our job to figure out where in the incentive landscape that is.</p><p>I think of it as two vector fields:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg" width="702" height="1075" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1075,&quot;width&quot;:702,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56929dd5-9453-4136-b3fb-b60d0c179e7e_702x1075.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The first vector field is our artistic impulses, and ethics, and curiosity, and so on—all the things that we want to express in our lives (or in our institutions). The other vector field is the market. If you put these vector fields on top of each other and add the vectors together, you find that in most places, the vectors point in different directions which makes them pull each other off course. Ie. it is harder to make money if you also want to honor your curiosity; and, inversely, it is easy to lose contact with your values if you are also trying to earn money.</p><p>But if you are patient enough, and open-minded enough, and willing to work hard, you can iterate your way to parts where the vectors align. And when that happens, the market forces actually boost the artistic process, as when two waves collide forming a double wave.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png" width="808" height="778" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:778,&quot;width&quot;:808,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:46432,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd36e51e-61d1-488b-b38e-4ff9368557ab_808x778.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>What you see in the biographies of great artists, great writers, great anything is that they are good at figuring out where the vectors align. They are able to keep track of their values and be attuned to themselves, and at the same time be cold-headed about how the world works: not shaping themselves to fit the world, but figuring out how to position what they do so that it becomes possible.</p><p>As someone who has been self-employed for most of my life, I have often looked at institutions and felt, “How come they are so slow and bad at their jobs? How hard can it be?” But since I had limited experience, I figured that there was something hard about it that I was too naive to see.</p><p><span>I’m no longer sure I was naive. It was, at the gallery at least, very easy to do much (~3x) better than baseline. For example: when I first came on the board, they would talk about the “three legs” of the gallery: fundraising, workshops, and sales (café, shop, tickets). But when I sneaked away to look at the numbers, two of these “sources of income” were actually cost centers: fundraising and workshops cost us more than we earned.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-151598106" href="https://www.henrikkarlsson.xyz/p/art-gallery#footnote-2-151598106" target="_self" rel="">2</a></span><span> No one had looked at our bookkeeping to figure out how we earned our income! Also, they hadn’t factored in building maintenance costs, and when you did that it was clear that the current strategy would bankrupt us in 2-3 years.</span></p><p><span>These are not hard things to look up; I’m a very amateurish accountant.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-151598106" href="https://www.henrikkarlsson.xyz/p/art-gallery#footnote-3-151598106" target="_self" rel="">3</a></span><span> It is surprising how much edge “let me google that” gives you, 26 years after Google was released. (Not to talk about LLMs.) Most people just seem to come up with an answer in their head and then go with that without checking.</span></p><p>To the credit of the board, they did see the problem as soon as I pointed it out, and acted swiftly, and were able to find solutions that I was too inexperienced to find.</p><p>When we cut back on workshops and fundraising and focused on the parts that worked, we could do that with more care—running experiments, updating our pricing strategies, automating, streamlining, changing the branding, etc—which, as always when you narrow your focus, made a big difference, and we ended up growing revenue by 311 percent.</p><p>Now the expensive maintenance is either done or scheduled to be done, and we’ve built up a war chest, and we’ve set up a strong board, so I feel confident that the place can live on for another ten years—which was the goal I had. I feel ready to get back to my own projects.</p><p>In August, King Frederik X, the new Danish King, made an official visit to the gallery during his first tour. Since I’m not in the least a royalist, I was surprised at how sentimental the event made me—seeing him do his weird kingly walk as the preschoolers waved their flags in front of the gallery. I guess it made me feel like I belonged here, and that this country that has given us refuge told us that we were one of them now, that they saw the work we had done to care for this small corner of the whole. It felt like the end of one of the movies of my life, and above my desk as I write this, I keep, as a memento for my years at the gallery, a framed receipt for a sculpture I sold Queen Mary. That was fun.</p><p><em>Since this blog is my only income now, I want to remind you that you can become a paid subscriber if you want to read more or support the production of free essays.</em></p><p><em><span>I project that I will be able to earn a normal Danish middle-class income from the blog in a year or two if we can pull through; right now, however, support can make a genuine difference for us. (It is also possible to update your subscription </span><a href="https://www.henrikkarlsson.xyz/account?utm_source=user-menu" rel="">here</a><span> to support at a higher level if you want.)&nbsp;</span></em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Distributed Erlang (155 pts)]]></title>
            <link>https://vereis.com/posts/disterl_inbox</link>
            <guid>42302673</guid>
            <pubDate>Tue, 03 Dec 2024 02:51:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vereis.com/posts/disterl_inbox">https://vereis.com/posts/disterl_inbox</a>, See on <a href="https://news.ycombinator.com/item?id=42302673">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
          Approx. 15 minutes
        </p><article>
        
          <p>
  The 
  <a href="https://www.erlang.org/">
    Erlang
  </a>&nbsp; programming language is known for three things:
</p>
<ol>
  <li>
    Concurrency
  </li>
  <li>
    Fault tolerance
  </li>
  <li>
    Distribution
  </li>
</ol>
<p>
  The cool thing is that all three of these things are both built into the language/runtime itself, but they're also all more or less "emergent" properties of the underlying design choices that were made when the language was created.
</p>
<h2>
  The Actor Model
</h2>
<p>
  Erlang is based on the Actor Model, which is a model of computation that was first described by 
  <a href="https://en.wikipedia.org/wiki/Carl_Hewitt">
    Carl Hewitt
  </a>&nbsp; in the 1970s.
</p>
<p>
  The Actor Model is a way of thinking about computation that is based on the idea of "actors" that communicate with each other by sending messages.
</p>
<p>
  You can think of an actor as its own little main "thread" of execution, responsible for managing its own state, and communicating with other actors.
</p>
<h3>
  Processes
</h3>
<p>
  In Erlang, actors are implemented as 
  <a href="https://erlang.org/doc/reference_manual/processes.html">
    processes
  </a>&nbsp;. As each process executes, the 
  <a href="https://en.wikipedia.org/wiki/BEAM_(Erlang_virtual_machine">
    Erlang Virtual Machine
  </a>&nbsp;) is responsible for keeping track of how long each process has been running, and making sure that each process gets a fair share of the CPU.
</p>
<p>
  As described, each process is very lightweight, costing very little in terms of memory to create and run. This means that you can create thousands or even millions of processes in an Erlang system, and the system will still run efficiently.
</p>
<p>
  You can create a new process in Erlang by calling the 
<code>spawn/1</code> function, which takes a single argument: a function that the new process should execute.
</p>
<pre><code>1&gt; spawn(fun() -&gt; io:format("Hello, world!~n") end).
Hello, world!
&lt;0.41.0&gt;
</code></pre>
<p>
  Because each process is scheduled independently by the Erlang Virtual Machine, there isn't a need to worry about locking any kind of main thread:
</p>
<pre><code>1&gt; Loop = fun(F, X) -&gt; F(F, X) end.
#Fun&lt;erl_eval.12.57235823&gt;
2&gt; spawn(fun() -&gt; Loop(Loop, foo) end).
&lt;0.42.0&gt;
% Note the shell is still responsive
3&gt; 1 + 1.
2
</code></pre>
<p>
  In fact, "infinitely looping" functions being spawned as processes is the fundamental way that Erlang programs are written: these long running processes poll for messages, and based on the messages they receive, they decide what to do next.
</p>
<h3>
  Message Passing
</h3>
<p>
  To enable communication between processes, Erlang provides a mechanism called 
  <a href="https://erlang.org/doc/reference_manual/distributed.html#message-passing">
    message passing
  </a>&nbsp;. This is a way for one process to send a message to another process, and for the receiving process to handle the message in some way.
</p>
<p>
  A process can send a message (which can be any piece of data) to another process; additionally, a process can halt its execution and wait for a message to arrive.
</p>
<p>
  Processes each have their own mailbox, which is a queue of messages that have been sent to the process.
</p>
<p>
  When a process receives a message, it can choose to handle the message, or to ignore it.
</p>
<p>
  For example, here's a simple program that sends a message to a process, and then waits for a response:
</p>
<pre><code>-module(example).
-export([start/0, resp/0]).

start() -&gt;
  Pid = spawn(fun resp/0),
  % Send a message to the spawned process
  Pid ! {self(), hello},
  % And wait for a response, which is just a tuple tagged with the spawned process's PID
  % so we can identify which process sent the message
  receive
    {Pid, Response} -&gt; io:format("Received response: ~p~n", [Response])
  end.

% This process just waits for a message, and then sends a response before exiting.
resp() -&gt;
  receive
    {From, hello} -&gt; From ! {self(), world}
  end.
</code></pre>
<p>
  With just these two features, message passing and processes, you have first-class concurrency baked into the language without 
  <a href="https://en.wikipedia.org/wiki/Function_coloring">
    function coloring
  </a>&nbsp;.
</p>
<h2>
  Fault Tolerance
</h2>
<p>
  Erlang is also known for its fault tolerance. This is because the Erlang Virtual Machine is designed to be able to handle failures gracefully.
</p>
<p>
  What this means is that the Erlang Virtual Machine and runtime have primitives for:
</p>
<ol>
  <li>
    Linking processes together.
  </li>
  <li>
    Monitoring processes.
  </li>
</ol>
<h3>
  Linking Processes
</h3>
<p>
  When two processes are linked together, if one of the processes crashes, the other process will also crash. This is a way of ensuring that if one part of your system fails, the rest of the system can be notified and take appropriate action.
</p>
<p>
  You can link two processes together using the 
<code>link/1</code> function, or you can atomically spawn a process and link it to the current process using the 
<code>spawn_link/1</code> function.
</p>
<p>
  When a process crashes, it generates an exit signal, which is sent to all linked processes. This exit signal contains information about why the process crashed, and what the process's PID was.
</p>
<p>
  Like any other message, you can receive and pattern match on exit signals in Erlang:
</p>
<pre><code>1&gt; Pid = spawn_link(fun() -&gt; exit(normal) end).
&lt;0.41.0&gt;
2&gt; receive
..   {'EXIT', Pid, Reason} -&gt; Reason
.. end.
normal
</code></pre>
<p>
  This allows you to write code that can handle failures gracefully, by restarting processes that have crashed, or by shutting down the entire system if a critical process has crashed.
</p>
<h3>
  Monitoring Processes
</h3>
<p>
  In addition to linking processes together, you can also monitor processes. This is a way of being notified when a process crashes, without crashing the monitoring process.
</p>
<p>
  When you monitor a process, you receive a message when the monitored process crashes. This message contains information about why the process crashed, and what the process's PID was.
</p>
<p>
  You can monitor a process using the 
<code>erlang:monitor/2</code> function, which takes two arguments: the type of monitoring you want to do (either 
<code>process</code> or 
<code>port</code>), and the PID of the process you want to monitor.
</p>
<p>
  When a process crashes, it generates an exit signal, which is sent to all monitoring processes. This exit signal contains information about why the process crashed, and what the process's PID was.
</p>
<p>
  This, in tandem with pattern matching on exit signals, allows you to write code that can can monitor, say, worker processes and manage them as needed.
</p>
<h2>
  OTP
</h2>
<p>
  The 
  <a href="https://erlang.org/doc/design_principles/des_princ.html">
    Open Telecom Platform
  </a>&nbsp;(OTP) is a set of libraries and design principles that are built on top of Erlang.
</p>
<p>
  One of the confusing things about OTP is that it's often referred to as a "framework", but it's really more of a set of abstractions that make it easier to write fault-tolerant and scalable systems in Erlang.
</p>
<p>
  Unlike a "framework" in other languages, OTP is bundled with the Erlang runtime itself. OTP very much is Erlang, and Erlang is OTP.
</p>
<p>
  The three main components of OTP are:
</p>
<ol>
  <li>
    <a href="https://erlang.org/doc/design_principles/des_princ.html#behaviours">
      Behaviours
    </a>&nbsp;</li>
  <li>
    <a href="https://erlang.org/doc/design_principles/des_princ.html#supervisors">
      Supervisors
    </a>&nbsp;</li>
  <li>
    <a href="https://erlang.org/doc/design_principles/des_princ.html#gen-servers">
      GenServers
    </a>&nbsp;</li>
</ol>
<p>
  Behaviours are a way of defining a set of functions that a module must implement in order to be considered a "behaviour". This is a way of enforcing a contract between modules, and making sure that they all implement the same set of functions.
</p>
<p>
  Supervisors are a way of managing a set of worker processes. A supervisor is responsible for starting, stopping, and restarting worker processes as needed.
</p>
<p>
  GenServers are a way of implementing a server process that can handle requests from clients. A GenServer is a process that runs a loop, waiting for messages from clients, and responding to those messages.
</p>
<p>
  There are additional components of OTP, but day-to-day, these are the three that you'll interact with most often. Some of the other components include:
</p>
<ul>
  <li>
    <a href="https://erlang.org/doc/design_principles/des_princ.html#gen-states">
      GenStatem
    </a>&nbsp;-- a way of implementing state machines.
  </li>
  <li>
    <a href="https://erlang.org/doc/design_principles/des_princ.html#gen-events">
      GenEvent
    </a>&nbsp;-- a way of implementing event handlers.
  </li>
</ul>
<p>
  By composing these components together, you build systems that are fault-tolerant, scalable, and easy to reason about (within the remit of Erlang applications, at least).
</p>
<h2>
  Distribution
</h2>
<p>
  Having covered the basics of concurrency and fault tolerance, we can now talk about distribution.
</p>
<p>
  Distribution is, as stated, one of the touted benefits of using Erlang. Distribution is the mechanism by which you can run Erlang programs on multiple machines, and have them communicate with each other.
</p>
<p>
  Erlang has built-in support for distribution, but the underlying mechanisms can be swapped out for other implementations. However, the majority of Erlang programs in the wild use the built-in distribution mechanisms, which is what we'll cover here.
</p>
<h3>
  Nodes
</h3>
<p>
  In Erlang, a 
<code>node</code> is a running instance of the Erlang Virtual Machine.
</p>
<p>
  When you start an Erlang program, you start a node. This node is identified by a name, which is a string that is unique to the node. Nodes can have short names, which are just strings, or long names, which are strings that look like email addresses, i.e. 
<code>node@hostname</code>.
</p>
<p>
  When nodes are started, they can connect to each other over a network. This is done using a mechanism called 
  <a href="https://www.erlang.org/docs/26/man/epmd">
    epmd
  </a>&nbsp; which acts a little like a DNS server for Erlang nodes.
</p>
<p>
  When a node starts, it registers itself with 
<code>epmd</code>, and then other nodes can connect to it by looking up its name in 
<code>epmd</code>'s registry.
</p>
<blockquote>
  <p>
    Much of this is pluggable however, i.e. see 
    <a href="https://github.com/tsloughter/epmdless">
      epmdless
    </a>&nbsp;.
  </p>
</blockquote>
<p>
  You can connect to a remote node using the 
<code>net_kernel:connect_node/1</code> function, which takes the name of the node you want to connect to as an argument; additionally, you can look up a list of all connected nodes using the 
<code>nodes/0</code> function.
</p>
<pre><code>1&gt; net_kernel:connect_node('node@hostname').
true
2&gt; nodes().
['node@hostname']
</code></pre>
<p>
  Note that 
<code>node/0</code> is a built-in function that returns the name of the current node.
</p>
<h3>
  Networking
</h3>
<p>
  Before you can send messages between nodes, you need to set up a network connection between them.
</p>
<p>
  This is done using the 
<code>net_adm:ping/1</code> function, which takes the name of the node you want to ping as an argument.
</p>
<pre><code>% Start nodes
% erl -name node1@hostname
% erl -name node2@hostname
1&gt; net_adm:ping('node2@hostname').
pong
2&gt; nodes().
['node2@hostname']
</code></pre>
<p>
  Before attempting a connection however, each node needs to exchange a 
<code>cookie</code>, this is a shared secret that is used to authenticate connections between nodes.
</p>
<blockquote>
  <p>
    The cookie is stored in a file called 
<code>.erlang.cookie</code> in the user's home directory.
  </p>
  <p>
    
There is also no built-in mechanism for communicating the cookie between nodes, so you'll need to do this manually.
  </p>
</blockquote>
<h3>
  Network Transparency
</h3>
<p>
  One of the cool things about Erlang's distribution is that it's network transparent.
</p>
<p>
  For example, taking the above example of spawning a process, note the format of the returned 
<code>PID</code>:
</p>
<pre><code>1&gt; Pid = spawn(fun() -&gt; io:format("Hello, world!~n") end).
Hello, world!
&lt;0.41.0&gt;
</code></pre>
<p>
  In this example, the returned PID is 
<code>&lt;0.41.0&gt;</code>, which is a reference to a process (that may, or may not still be running).
</p>
<p>
  There are two different types of PIDs in Erlang: local 
<code>PID</code> s and global 
<code>PID</code> s; the former is always in the format 
<code>&lt;0.X.Y&gt;</code>, where 
<code>X</code> and 
<code>Y</code> are different bits identifying the process on the local node.
</p>
<p>
  For global 
<code>PID</code> s, the format is 
<code>&lt; X.Y.Z &gt;</code>, where 
<code>X</code> is the node number, and 
<code>Y</code> and 
<code>Z</code> continue to represent the process's identifier.
</p>
<p>
  This means that you can send messages to processes on other nodes in the same way that you send messages to processes on the local node.
</p>
<pre><code>% assuming we have a remote PID stored in `RemotePid`
1&gt; RemotePid ! {self(), ping}.
{&lt;0.41.0&gt;, ping}
% and then we can receive the message in the same way
2&gt; receive
..   {RemotePid, Response} -&gt; {RemotePid, Response}
.. end.
{&lt;12042.3.0&gt;, pong}
</code></pre>
<p>
  This is an extremely powerful feature of Erlang, as it allows you to write code that is completely agnostic to the location of the processes it's communicating with.
</p>
<h2>
  Distribution Gotchas
</h2>
<p>
  Despite the fact, however, that distribution is one of the much-touted features of Erlang, it is not without its pitfalls.
</p>
<p>
  Compared to the concurrency and fault tolerance features of Erlang, distribution is much more complex, much more difficult to get right, and arguably somewhat half-baked.
</p>
<p>
  Here are some of the main gotchas to be aware of when working with distributed Erlang systems that I've run into in my career.
</p>
<h3>
  Scalability in Large Clusters
</h3>
<p>
  When clustering using Distributed Erlang, the overall cluster forms a mesh network, where each node is connected to every other node in the cluster.
</p>
<p>
  This means that as the number of nodes in the cluster grows, the number of connections that each node needs to maintain also grows. In a system with 
<code>N</code> nodes, each node needs to maintain 
<code>N-1</code> connections to every other node in the cluster.
</p>
<p>
  This means that as the number of nodes in the cluster grows, the number of connections that each node needs to maintain linearly, and the number of connections between nodes in the cluster grows quadratically.
</p>
<blockquote>
  <p>
    Note: the original version of this article mistakenly stated that the number of connections grows exponentially, this is incorrect, and I have since corrected it.
  </p>
  <p>
    
Thanks 
<code>toast0</code> for pointing this out!
  </p>
</blockquote>
<p>
  Distributed Erlang relies on each node periodically sending heartbeat messages to every other node in the cluster to ensure that the connections are still alive; so as the number of connections between nodes grows, the number of heartbeat messages that need to be sent also grows at the same rate.
</p>
<p>
  This can lead to a lot of network traffic in large clusters, which can put a strain on the network.
</p>
<p>
  Historically, a "large" cluster in Erlang was considered to be around 50-100 nodes. This may have changed in recent years, but it's still something to be aware of when designing distributed Erlang systems.
</p>
<blockquote>
  <p>
    Note: this number comes from an anecdote from Franceso Cesarini which I admit may have been misremembered on my part.
  </p>
  <p>
    
In practice, certain applications have been known to run on clusters of 400+ nodes, and in WhatsApp's case, 1,000+ nodes. Whether or not this was done without 
<code>hidden node</code> s is unknown to me.
  </p>
</blockquote>
<p>
  You can mitigate this by strategically "partitioning" you cluster into smaller groups of nodes that are connected to eachother via a mechanism known as a 
<code>hidden node</code>, though this may prove unwieldy in practice.
</p>
<h3>
  Lack of Fine-Grained Control
</h3>
<p>
  One of the issues with Distributed Erlang is that it lacks fine-grained control over the distribution mechanism.
</p>
<p>
  You can't 
  <i>
    easily
  </i>
  , for example, specify which nodes should be connected to which other nodes, or which nodes should be connected to which other nodes, likewise, you're not able to throttle traffic out of the box.
</p>
<p>
  This can lead to situations where a single node in the cluster can overwhelm the network with traffic, leading to network congestion and dropped packets.
</p>
<p>
  One cool feature of Distributed Erlang is the fact that members of a cluster don't have to be homogeneous, i.e. you can have different nodes responsible for serving different purposes in your cluster (so long as they share the same cookie).
</p>
<p>
  At 
  <a href="https://vetspire.com/">
    Vetspire
  </a>&nbsp;, we utilise this feature heavily, though we've had to build a custom routing layer on top of Distributed Erlang in order to route requests/rpc calls to the appropriate nodes.
</p>
<blockquote>
  <p>
    Aside: In the Elixir world, there's a great library called 
    <a href="https://github.com/phoenixframework/flame">
      FLAME
    </a>&nbsp; that provides an API for spinning up new nodes on demand.
  </p>
  <p>
    
Definitely check it out!
  </p>
</blockquote>
<h3>
  Network Partitions
</h3>
<p>
  Unlike when writing applications that run on a single machine, when writing distributed systems, you need to be aware of the possibility of network partitions.
</p>
<p>
  A network partition is when a network becomes divided into two or more separate subnetworks that are unable to communicate with each other.
</p>
<p>
  Network partitions can happen for a variety of reasons, such as network failures, misconfigured routers, or software bugs.
</p>
<p>
  Generally speaking, network partitions are less an issue of "if" they're a problem and more an issue of "when" they're a problem.
</p>
<p>
  This is particularly important when designing systems reliant on a 
<code>single global process</code>-- i.e. a system whereby a single instance of a process is required to be running at any given time, once and only once in the system.
</p>
<p>
  The general advice is to avoid relying on a single global process, and instead to design your system in such a way that it can tolerate the failure of any single node.
</p>
<blockquote>
  <p>
    In the Elixir world, there are libraries such as 
    <a href="https://https//hexdocs.pm/swarm/Swarm.html">
      Swarm
    </a>&nbsp; and 
    <a href="https://hexdocs.pm/horde/readme.html">
      Horde
    </a>&nbsp; that attempt to mitigate this issue some, though its on the implementor to reconcile the state of the system after a partition has been resolved.
  </p>
</blockquote>
<p>
  One way to do this is to use a distributed consensus algorithm, such as 
  <a href="https://raft.github.io/">
    Raft
  </a>&nbsp;, to ensure that all nodes in the cluster agree on the state of the system.
</p>
<p>
  If one must rely on a single global process, using something like consistent hashing may help ensure only a single process is running in your cluster, but this is not a panacea as that particular node may not be alive or reachable during a network partition.
</p>
<blockquote>
  <p>
    Definitely take a look at 
    <a href="https://github.com/basho/riak_core">
      <i>
        core
      </i>
      riak
    </a>&nbsp; as a resource for learning about engineering around Distributed Erlang in general.
  </p>
</blockquote>
<h3>
  Single Mailbox Bottleneck
</h3>
<p>
  In Erlang, each process has its own mailbox, which is a queue of messages that have been sent to the process.
</p>
<p>
  However, in contrast to the standard case, when sending messages to a process on another node, that process is first handled by that remote node's distribution layer's mailbox.
</p>
<p>
  This distribution-layer mailbox is a singleton on any given node, and as such, like with high-traffic 
<code>genserver</code> s, they quickly become a bottleneck in high-traffic systems.
</p>
<p>
  This is particularly an issue when sending either a large number of messages to a remote node, or when sending large data payloads to a remote node.
</p>
<p>
  As mailboxes in Erlang are FIFO, this can lead to a situation where a single process on a remote node is overwhelmed with messages, and is unable to process them all in a timely manner -- the worst case scenario being that the mailbox blocks pending heartbeat messages, leading to the node being considered down.
</p>
<p>
  There are some alternative distribution mechanisms that can be used to mitigate this, such as 
  <a href="https://github.com/priestjim/gen_rpc">
    <i>
      rpc
    </i>
    gen
  </a>&nbsp;, which re-implements the built in 
<code>rpc</code> and 
<code>erpc</code> modules to use HTTP rather than Erlang's built-in distribution mechanisms.
</p>
<blockquote>
  <p>
    This comes with additional advantages, such as the ability to send messages via SSL.
  </p>
</blockquote>
<h3>
  Node Discovery
</h3>
<p>
  It's important to note that the design and chosen trade-offs of pretty much anything in Erlang were made in the 80s, and whilst some choices like the focus on the actor model have aged well, others have not.
</p>
<p>
  When it comes to Distributed Erlang, one of the differences between most deployments today and those of the 80s is the prevalence of cloud computing -- namely the fact that modern applications are oftentimes deployed in environments such as Kubernetes.
</p>
<p>
  For node discovery in such environments, Erlang's built-in mechanisms need to be supplemented with something like 
  <a href="https://hex.pm/packages/libcluster">
    libcluster
  </a>&nbsp; which provides pluggable strategies for node discovery via Kubernetes DNS, Consul, etc.
</p>
<h3>
  Physics
</h3>
<p>
  Finally, there's the issue of physics.
</p>
<p>
  When you're writing distributed systems, you need to be aware of the speed of light, and the fact that it takes time for messages to travel between nodes.
</p>
<p>
  This means that if you're designing a system that relies on low-latency communication between nodes, you need to be aware of the physical distance between the nodes, and the speed of light.
</p>
<p>
  Especially during normal development on a single laptop, it's easy to forget that the network latency between two nodes on the same machine is going to be much lower than the network latency between two nodes on different continents. This can lead to situations where your system works fine in development, but falls over in production.
</p>
<p>
  Clock synchronization is another issue that can crop up when working with distributed systems. Trying to keep track of the causal order of events across multiple nodes can be difficult. Using protocols like 
  <a href="https://en.wikipedia.org/wiki/Network_Time_Protocol">
    NTP
  </a>&nbsp; can help, as well as designing resilience to clock skew in your systems can help as well.
</p>
<blockquote>
  <p>
    See 
    <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">
      the fallacies of distributed computing
    </a>&nbsp; for more on this.
  </p>
</blockquote>
<h2>
  Conclusion
</h2>
<p>
  Erlang is a powerful language for building distributed systems, thanks to its built-in support for concurrency, fault tolerance, and distribution.
</p>
<p>
  However, building distributed systems is hard, and there are many pitfalls to be aware of when working with distributed Erlang systems.
</p>
<p>
  By understanding the underlying principles of Erlang, and by being aware of the potential pitfalls, you can build systems that are fault-tolerant, scalable, and easy to reason about.
</p>
        

        <blink>(END)</blink>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[8 months of OCaml after 8 years of Haskell in production (2023) (243 pts)]]></title>
            <link>https://chshersh.com/blog/2023-12-16-8-months-of-ocaml-after-8-years-of-haskell.html</link>
            <guid>42302426</guid>
            <pubDate>Tue, 03 Dec 2024 02:14:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chshersh.com/blog/2023-12-16-8-months-of-ocaml-after-8-years-of-haskell.html">https://chshersh.com/blog/2023-12-16-8-months-of-ocaml-after-8-years-of-haskell.html</a>, See on <a href="https://news.ycombinator.com/item?id=42302426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I’ve been using Haskell in production for 8 years. I’ve been using OCaml in production for 8 months.</p>
<p>It’s time to compare those two languages.</p>
<h2 id="syntax">Syntax</h2>
<p>Haskell probably has the most elegant syntax across all languages I’ve seen (maybe Idris is better because dependently typed code can become ugly in Haskell really quickly).</p>
<p>There’s utter joy in expressing your ideas by typing as few characters as possible.</p>
<p>OCaml, being a language from the ML family is great too, but still, Haskell is more tacit.</p>
<p>Compare a few examples:</p>
<h2 id="sum-of-all-numbers-in-a-string">Sum of all numbers in a string</h2>
<blockquote>
<p>Using just the standard library</p>
</blockquote>
<p><strong>Haskell</strong></p>
<div id="cb1"><pre><code><span id="cb1-1"><span>-- strSum "100  -42 15" = 73</span></span>
<span id="cb1-2"><span>strSum ::</span> <span>String</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb1-3">strSum <span>=</span> <span>sum</span> <span>.</span> <span>map</span> <span>read</span> <span>.</span> <span>words</span></span></code></pre></div>
<p><strong>OCaml</strong></p>
<div id="cb2"><pre><code><span id="cb2-1"><span>(* str_sum "100  -42 15" = 73 *)</span></span>
<span id="cb2-2"><span>let</span> str_sum (str: <span>string</span>): <span>int</span> =</span>
<span id="cb2-3">  str</span>
<span id="cb2-4">  |&gt; <span>String</span>.split_on_char <span>' '</span></span>
<span id="cb2-5">  |&gt; <span>List</span>.filter_map int_of_string_opt</span>
<span id="cb2-6">  |&gt; <span>List</span>.fold_left (+) <span>0</span></span></code></pre></div>
<h2 id="defining-a-new-binary-tree-type">Defining a new binary tree type</h2>
<p><strong>Haskell</strong></p>
<div id="cb3"><pre><code><span id="cb3-1"><span>data</span> <span>Tree</span> a</span>
<span id="cb3-2">  <span>=</span> <span>Leaf</span></span>
<span id="cb3-3">  <span>|</span> <span>Node</span> a (<span>Tree</span> a) (<span>Tree</span> a)</span></code></pre></div>
<p><strong>OCaml</strong></p>
<div id="cb4"><pre><code><span id="cb4-1"><span>type</span> 'a tree =</span>
<span id="cb4-2">  | Leaf</span>
<span id="cb4-3">  | Node <span>of</span> 'a * 'a tree * 'a tree</span></code></pre></div>
<h2 id="parsing">Parsing</h2>
<blockquote>
<p>Return the result on successful parsing of lines like the one below where “Status” equals to zero and the result is an even number</p>
<pre><code>"Status: -1 | Result: 42"</code></pre>
</blockquote>
<p><strong>Haskell</strong></p>
<div id="cb6"><pre><code><span id="cb6-1"><span>parseLine ::</span> <span>String</span> <span>-&gt;</span> <span>Maybe</span> <span>Int</span></span>
<span id="cb6-2">parseLine line <span>=</span> <span>do</span></span>
<span id="cb6-3">    [<span>"Status:"</span>, <span>"0"</span>, _, <span>"Result:"</span>, result] <span>&lt;-</span> <span>Just</span> <span>$</span> <span>words</span> line</span>
<span id="cb6-4">    n <span>&lt;-</span> readMaybe result</span>
<span id="cb6-5">    guard <span>$</span> <span>even</span> n</span>
<span id="cb6-6">    <span>pure</span> n</span></code></pre></div>
<p><strong>OCaml</strong></p>
<div id="cb7"><pre><code><span id="cb7-1"><span>let</span> parse_line (line: <span>string</span>): <span>int</span> <span>option</span> =</span>
<span id="cb7-2">  <span>let</span> ( <span>let</span>* ) = Option.bind <span>in</span></span>
<span id="cb7-3">  <span>let</span>* result =</span>
<span id="cb7-4">    <span>match</span> <span>String</span>.split_on_char <span>' '</span> line <span>with</span></span>
<span id="cb7-5">    | [<span>"Status:"</span>; <span>"0"</span>; _; <span>"Result:"</span>; result] -&gt; <span>Some</span> result</span>
<span id="cb7-6">    | _ -&gt; <span>None</span></span>
<span id="cb7-7">  <span>in</span></span>
<span id="cb7-8">  <span>let</span>* n = int_of_string_opt result <span>in</span></span>
<span id="cb7-9">  <span>if</span> n <span>mod</span> <span>2</span> = <span>0</span> <span>then</span> <span>Some</span> n <span>else</span> <span>None</span></span></code></pre></div>
<hr>
<p>The above are just a few random code snippets. They don’t give an idea of all possible programs that could be written in those languages. But I hope they can quickly highlight the similarities and differences between the two languages.</p>
<p>This slowly leads us to the next point.</p>
<h2 id="features">Features</h2>
<p>Haskell has waaaaaay more features than probably any other programming language (well, C++ can compete). This is both good and bad.</p>
<p>It’s good because you have the tools to solve your problems in the best way.</p>
<p>It’s bad because you have those tools. They’re distracting. Every time I need to solve a problem in Haskell, I’m immediately thinking about all the ways I can design the solution instead of, ahem, actually implementing this solution.</p>
<p>I’m interested in building stuff, not sitting near my pond on a warm summer day, thinking if TypeFamilies + DataKinds would be better than GADTs for making illegal states unrepresentable.</p>
<p>If I come to an existing OCaml project, the worst thing previous developers could do to it is have poor variable names, minimal documentation, and 200+ LOC functions. That’s fine, nothing extraordinary, I can handle that.</p>
<p>If I come to an existing Haskell project, the worst thing previous developers could do… Well, my previous 8 years of Haskell experience can’t prepare me for that 😅</p>
<p>That’s why I feel more productive in OCaml.</p>
<p>I do miss some Haskell features at times. But I’ve seen their ugly side and what they can do to your output.</p>
<p>Consider the following table with a full comparison of major features.</p>
<h3 id="feature-comparison-table">Feature comparison table</h3>
<table>
<thead>
<tr>
<th><strong>Feature</strong></th>
<th><strong>OCaml</strong></th>
<th><strong>Haskell</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Expression-oriented syntax</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Immutability by default</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Higher-Order Functions (HOFs)</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Anonymous functions (lambdas)</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Algebraic Data Types (ADTs)</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Pattern Matching</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Parametric Polymorphism</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Type Inference</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Monadic Syntax Sugar</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Garbage Collector</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Multithreading</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>GADTs</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Purity by default</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Composable laziness</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Type classes</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Higher-Kinded Types</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Opt-in language features</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>First-class modules</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Polymorphic variants</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Objects</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Classes and Inheritance</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Ergonomic mutability</td>
<td>✅</td>
<td>❌</td>
</tr>
</tbody>
</table>
<h2 id="ecosystem">Ecosystem</h2>
<p>Let’s be honest, both programming languages are niche FP langs. So you shouldn’t expect first-class support for the latest modern framework that just got published.</p>
<p>However, in my experience, despite needing to write more custom bindings, you have solutions for the majority of common tasks.</p>
<p>For example, in OCaml, you can find:</p>
<ul>
<li><a href="https://github.com/dmbaturin/otoml/">otoml: A TOML parser</a></li>
<li><a href="https://github.com/leostera/minttea">Mint Tea: A TUI framework</a></li>
<li><a href="https://github.com/imandra-ai/ocaml-opentelemetry">ocaml-opentelemetry: Instrumentation for OpenTelemetry</a></li>
<li><a href="https://github.com/solvuu/awsm">awsm: OCaml AWS Client</a></li>
<li><a href="https://github.com/gopiandcode/petrol">petrol: An OCaml SQL API made to go FAST</a></li>
</ul>
<p>And so on. Similar story for Haskell.</p>
<p>I’d still say that the Haskell ecosystem has more packages and more ready-to-go solutions.</p>
<p>It’s easy to show the difference in the following example.</p>
<p>Number of <a href="https://stripe.com/docs/api">Stripe API</a> client libraries:</p>
<ul>
<li>Haskell: 13</li>
<li>OCaml: 1 (last change was 8 years ago, so it’s more like zero)</li>
</ul>
<p>You may find a solution in Haskell. But often you’ll discover <strong>too many</strong> solutions, you won’t know which one to choose.</p>
<p>Choosing a library in Haskell becomes a separate skill you need to master. Haskellers <a href="https://www.haskellforall.com/2018/05/how-i-evaluate-haskell-packages.html">even blog their recommendations</a> on how to choose a library! And you’ll face this dilemma over and over again.</p>
<p>Often, a new Haskell library is created not because it solves a different problem.</p>
<p>But because the author wanted to <em>write it differently</em> (using different abstractions, playing with new features, etc. Who doesn’t want a new streaming library based on LinearTypes???).</p>
<p>It’s not exciting to write a GitHub API client and parse tons of JSON.</p>
<p>But it is exciting to design a <a href="https://www.youtube.com/watch?v=elqPlMyryjc">logger with comonads</a>.</p>

<p>The Haskell tooling evokes the most controversial feelings. It’s like an emotional roller coaster:</p>
<ul>
<li>🤩 Hoogle is the best! I can search through the entire ecosystem by using just a type signature!!!</li>
<li>😨 Wait, why build tooling error messages are so bad, what do you mean it couldn’t find a build plan for a working project???</li>
<li>🤩 Global content-addressable storage for all dependencies is such an amazing idea!!!</li>
<li>😨 What do you mean I need to recompile my IDE because I changed my package???</li>
<li>🤩 I can automatically test all the code snippets in my package docs!!!</li>
<li>😨 Wait, why the standard library doesn’t have docs at all for this version I use???</li>
</ul>
<p>And so on.</p>
<p>Using Haskell tooling is like always being in the quantum superposition of <strong>“How do you even use other PLs without such wholesome Haskell tools???”</strong> and <strong>“How Haskellers can live like that without these usability essentials???”</strong>.</p>
<hr>
<p>OCaml, on the other hand, hits differently. Because its ecosystem is smaller, you actually get surprised every time you find something working!</p>
<p>For example, the VSCode plugin for OCaml based on Language Server Protocol (LSP) works out-of-the-box. I never had any issues with it. It <strong>just works</strong> ™️</p>
<p>The ergonomics of starting with OCaml tooling might not be the best but they’re straightforward and robust. And they work most of the time.</p>
<hr>
<p>To get a full picture, refer to the following table for the full comparison of available tooling in both languages.</p>
<h3 id="tooling-comparison-table">Tooling comparison table</h3>
<table>
<colgroup>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th><strong>Tool</strong></th>
<th><strong>OCaml</strong></th>
<th><strong>Haskell</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Compiler</td>
<td><a href="https://github.com/ocaml/ocaml">ocaml</a></td>
<td><a href="https://gitlab.haskell.org/ghc/ghc">ghc</a></td>
</tr>
<tr>
<td>REPL</td>
<td><a href="https://github.com/ocaml-community/utop">utop</a></td>
<td><a href="https://downloads.haskell.org/ghc/latest/docs/users_guide/ghci.html">ghci</a></td>
</tr>
<tr>
<td>Build tool</td>
<td><a href="https://dune.build/">dune</a></td>
<td><a href="https://cabal.readthedocs.io/en/latest/">cabal</a>, <a href="https://docs.haskellstack.org/en/stable/">stack</a></td>
</tr>
<tr>
<td>Package manager</td>
<td><a href="https://opam.ocaml.org/">opam</a></td>
<td><a href="https://cabal.readthedocs.io/en/latest/">cabal</a></td>
</tr>
<tr>
<td>Package repository</td>
<td><a href="https://opam.ocaml.org/">opam</a></td>
<td><a href="https://hackage.haskell.org/">Hackage</a></td>
</tr>
<tr>
<td>Toolchain installer</td>
<td>-</td>
<td><a href="https://www.haskell.org/ghcup/">ghcup</a></td>
</tr>
<tr>
<td>Linter</td>
<td><a href="https://github.com/Kakadu/zanuda">zanuda</a></td>
<td><a href="https://github.com/ndmitchell/hlint">hlint</a></td>
</tr>
<tr>
<td>Formatter</td>
<td><a href="https://github.com/ocaml-ppx/ocamlformat">ocamlformat</a>, <a href="https://github.com/tweag/topiary">topiary</a></td>
<td><a href="https://fourmolu.github.io/">fourmolu</a>, <a href="https://github.com/haskell/stylish-haskell">stylish-haskell</a>, <a href="https://github.com/mihaimaruseac/hindent">hindent</a>, <a href="https://github.com/tweag/ormolu">ormolu</a></td>
</tr>
<tr>
<td>Type Search</td>
<td><a href="https://doc.sherlocode.com/">Sherlodoc</a></td>
<td><a href="https://hoogle.haskell.org/">Hoogle</a></td>
</tr>
<tr>
<td>Code search</td>
<td><a href="https://sherlocode.com/">Sherlocode</a></td>
<td><a href="https://hackage-search.serokell.io/">Hackage Search</a></td>
</tr>
<tr>
<td>Online playground</td>
<td><a href="https://try.ocamlpro.com/">TryOCaml</a></td>
<td><a href="https://play.haskell.org/">Haskell Playground</a></td>
</tr>
<tr>
<td>LSP</td>
<td><a href="https://github.com/ocaml/ocaml-lsp">ocaml-lsp</a></td>
<td><a href="https://github.com/haskell/haskell-language-server">HLS</a></td>
</tr>
</tbody>
</table>
<h2 id="compiler-messages">Compiler messages</h2>
<p>I want to highlight the compiler aspect of tooling separately since this is the tool you interact the most with.</p>
<p>Especially, compiler suggestions.</p>
<p>When using FP languages, the compiler is your best friend! You rely on it heavily to understand why your assumptions haven’t been codified precisely.</p>
<p>Therefore, the compiler must present the information in the most accessible way.</p>
<p>In my view, Haskell compiler messages tend to be verbose with lots of contextual, often redundant, and distracting information.</p>
<p>OCaml compiler messages, on the other hand, are quite succinct. Sometimes too succinct.</p>
<p>Consider the following example.</p>
<h2 id="haskell-compiler-messages-example">Haskell: Compiler messages example</h2>
<p><strong>Program with an error</strong></p>

<p><strong>Compiler output</strong></p>
<figure>
<img src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kh45ype7j5lo9gns76d7.png" alt=""><figcaption>Haskell Compiler Error Message</figcaption>
</figure>
<h2 id="ocaml-compiler-messages-example">OCaml: Compiler messages example</h2>
<p><strong>Program with an error</strong></p>

<p><strong>Compiler output</strong></p>
<figure>
<img src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/t44lbbjywfvpj3d4gnv4.png" alt=""><figcaption>OCaml Compiler Error Message</figcaption>
</figure>
<hr>
<p>This is just one example (and most likely not the best one), but you can already see the differences in how information is presented and how types work in different languages.</p>
<h2 id="standard-library">Standard library</h2>
<p>I believe the standard library deserves a separate mention too.</p>
<p>It shapes your first program in a language and guides you through all future journeys.</p>
<p>A great standard library is a cornerstone of your PL success.</p>
<p>A poor standard library is a cornerstone of never-ending bikesheds about a better standard library (including an endless variety of alternative competing standard libraries).</p>
<p>I’m a big proponent of the idea that a standard library should be batteries-included.</p>
<p>Give me an Option-like type, a UTF-8 string, Map and HashMap, JSON and XML parsers, async primitives, and so on, so I can avoid learning your poor implementation of dependency tracking and build tooling. (<a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">Build Systems a la Carte</a> is a thorough analysis of the space of dependency trackers and build tools.).</p>
<p>Both Haskell and OCaml have kinda barebones standard libraries. They have minor differences (e.g.&nbsp;Haskell doesn’t include Map and HashMap; OCaml doesn’t have non-empty lists and Bitraversable). But overall they’re similar in the spirit.</p>
<p>The Haskell standard library is called <code>base</code> and OCaml standard library is called.. well, it’s just “the standard library”.</p>
<ul>
<li><a href="https://hackage.haskell.org/package/base">base: The Haskell Standard Library</a></li>
<li><a href="https://v2.ocaml.org/api/index.html">OCaml: The standard library</a></li>
</ul>
<p>However, one difference is striking. The quality of Haskell documentation sometimes can amaze even a seasoned developer.</p>
<blockquote>
<p>Haskell has a few more nice features, like the ability to jump to sources from docs but I’ve been told such features are being cooked for OCaml too 👀</p>
</blockquote>
<p>Compare a few doc snippets for the List data type (one of the fundamental structures in FP):</p>
<p><strong>Haskell</strong></p>
<p><a href="https://hackage.haskell.org/package/base-4.19.0.0/docs/Data-List.html#v:head">Haskell: Data.List.head</a></p>
<figure>
<img src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/j38mezm8mld79emi3me9.png" alt=""><figcaption>Haskell head</figcaption>
</figure>
<p><a href="https://hackage.haskell.org/package/base-4.19.0.0/docs/Data-List.html#v:-33--63-">Haskell: !?</a></p>
<figure>
<img src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/chphke0bux2l3fq0x93y.png" alt=""><figcaption>Haskell index</figcaption>
</figure>
<p><strong>OCaml</strong></p>
<p><a href="https://v2.ocaml.org/api/List.html">OCaml: List.hd</a></p>
<figure>
<img src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/l7cmzh4pd66kmgpav9xl.png" alt=""><figcaption>OCaml hd</figcaption>
</figure>
<p><a href="https://v2.ocaml.org/api/List.html">OCaml: List.nth_opt</a></p>
<figure>
<img src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mvn0bo84lbf6pibvbq7l.png" alt=""><figcaption>OCaml nth_opt</figcaption>
</figure>
<hr>
<p>You may argue that the result of such functions is obvious, therefore there’s no need to write essays under each function.</p>
<p>I’m a fan of example-driven documentation, and I love seeing usage examples in docs! This immediately gives me an idea of how I can leverage the API in the best way.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I want to end this blog post by saying:</p>
<p><strong>Both languages came a long way to support real industrial needs.</strong></p>
<p>They’re still small compared to mainstream languages.</p>
<p>If you’re not critically dependent on the presence of some specific SDK, you can choose any and have lots of joy while coding your next app 🧡</p>
<p>However, I prefer OCaml nowadays because I feel that I can focus on actually building stuff with this language.</p>
<h2 id="discussions">Discussions</h2>
<p>Besides the comment section below, you can also find the discussions of this blog post in various places:</p>
<ul>
<li><a href="https://twitter.com/ChShersh/status/1740303405678006422">𝕏 by chshersh</a> (210+ 🧡, 14+ comments)</li>
<li><a href="https://discuss.ocaml.org/t/8-months-of-ocaml-after-8-years-of-haskell-in-production/13729">OCaml Discuss</a> (16+ 🧡, 16+ comments)</li>
<li><a href="https://discourse.haskell.org/t/8-months-of-ocaml-after-8-years-of-haskell-in-production/8405">Haskell Discourse</a> (27+ 🧡, 107+ comments)</li>
<li><a href="https://lobste.rs/s/0xsnfj/8_months_ocaml_after_8_years_haskell">Lobste.rs: ml</a> (39+ ⬆️, 16+ comments)</li>
<li><a href="https://www.reddit.com/r/ocaml/comments/18sq1p5/8_months_of_ocaml_after_8_years_of_haskell_in/">Reddit: /r/ocaml</a> (22+ ⬆️, 18+ comments)</li>
<li><a href="https://www.reddit.com/r/haskell/comments/18sq4gp/8_months_of_ocaml_after_8_years_of_haskell_in/">Reddit: /r/haskell</a> (91+ ⬆️, 57+ comments)</li>
</ul>

<hr>
<blockquote>
<p>If you liked this blog post, consider supporting my work on GitHub Sponsors, or following me on the Internet:</p>
<ul>
<li><a target="_blank" href="https://github.com/sponsors/chshersh">GitHub Sponsors: @chshersh</a></li>
<li><a target="_blank" href="https://youtube.com/c/chshersh">YouTube: @chshersh</a></li>
<li><a target="_blank" href="https://x.com/ChShersh">𝕏: @chshersh</a></li>
<li><a target="_blank" href="https://bsky.app/profile/chshersh.com">BlueSky: @chshersh</a></li>
<li><a target="_blank" href="https://functional.cafe/@chshersh">Mastodon: functional.cafe@chshersh</a></li>
<li><a target="_blank" href="https://www.twitch.tv/chshersh">Twitch: @chshersh </a></li>
</ul>
</blockquote>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Copper – Open-source robotics in Rust with deterministic log replay (152 pts)]]></title>
            <link>https://github.com/copper-project/copper-rs/wiki/Copper-Release-Log</link>
            <guid>42302026</guid>
            <pubDate>Tue, 03 Dec 2024 00:58:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/copper-project/copper-rs/wiki/Copper-Release-Log">https://github.com/copper-project/copper-rs/wiki/Copper-Release-Log</a>, See on <a href="https://news.ycombinator.com/item?id=42302026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wiki-body" data-view-component="true">
                <p><h2>Release Notes - v0.5.0 - 2024-12-02</h2><a id="user-content-release-notes---v050---2024-12-02" aria-label="Permalink: Release Notes - v0.5.0 - 2024-12-02" href="#release-notes---v050---2024-12-02"></a></p>
<p><h3>New Features</h3><a id="user-content-new-features" aria-label="Permalink: New Features" href="#new-features"></a></p>
<ul>
<li>
<p><strong>Deterministic Log Replay</strong>: Copper can now replay a log through your code in a deterministic fashion ie. if your tasks are deterministic, it will always output the same output from the same input! See the balancebot-resim for example.</p>
</li>
<li>
<p><strong>Aligner Task <a href="https://github.com/copper-project/copper-rs/pull/114">#114</a>:</strong> Added an aligner task that synchronizes multiple inputs by aligning matching time windows, facilitating coordinated data processing. This is particularly useful for sensor fusion.</p>
</li>
<li>
<p>❗ <strong>Lifecycle Trait Removal <a href="https://github.com/copper-project/copper-rs/pull/115">#115</a>:</strong> Removed the lifecycle trait to simplify task implementation and decouple passed types, streamlining the codebase. To build a minimum task a user needed to implement one method from the CuTaskLifecycle trait (new) and at least the process method from they flavor of tasks. This was forcing the implementation of 2 mandatory traits which is not necessary or useful for the user. Now we moved all the lifecycle methods in the tasks trait to only have to implement 2 traits (the task and Freezable, the serialization of its state)</p>
</li>
</ul>
<p><h3>Enhancements</h3><a id="user-content-enhancements" aria-label="Permalink: Enhancements" href="#enhancements"></a></p>
<ul>
<li>
<p><strong>Named Output Mapping on CopperLists <a href="https://github.com/copper-project/copper-rs/pull/121">#121</a>:</strong> Implemented mapping of Copperlist indices to named outputs from tasks, allowing users to access task outputs symbolically without relying on execution order.</p>
</li>
<li>
<p><strong>CuTimeRange Introduction <a href="https://github.com/copper-project/copper-rs/pull/106">#106</a>:</strong> Introduced <code>CuTimeRange</code> to represent messages containing multiple Time of Validity (TOV) instances, such as sequences of images or IMU measurements.</p>
</li>
<li>
<p><strong>Windows Compatibility <a href="https://github.com/copper-project/copper-rs/pull/110">#110</a>:</strong> Enhanced compatibility by adding a mock for <code>cu_ads7883</code>, enabling compilation on Windows platforms.</p>
</li>
<li>
<p><strong>Dependency Updates <a href="https://github.com/copper-project/copper-rs/pull/104">#104</a>:</strong> Performed a general dependency bump post-release to incorporate the latest improvements and fixes.</p>
</li>
</ul>
<p><h3>Bug Fixes</h3><a id="user-content-bug-fixes" aria-label="Permalink: Bug Fixes" href="#bug-fixes"></a></p>
<ul>
<li>
<p><strong>BalanceBot Simulation Stability <a href="https://github.com/copper-project/copper-rs/pull/118">#118</a>:</strong> Resolved a core dump issue on exit for <code>balancebot-sim</code> by enforcing specific graphics backends, ensuring clean termination.</p>
</li>
<li>
<p><strong>CuCompactStr Serialization <a href="https://github.com/copper-project/copper-rs/pull/119">#119</a>:</strong> Fixed serialization and deserialization issues with <code>CuCompactStr</code> to ensure correct data handling.</p>
</li>
<li>
<p><strong>Project Generation Fix <a href="https://github.com/copper-project/copper-rs/pull/120">#120</a>:</strong> Addressed issues in project generation by adding <code>crate::</code> for <code>cumsgs</code> generation, ensuring correct module resolution.</p>
</li>
<li>
<p><strong>Unused Code Cleanup <a href="https://github.com/copper-project/copper-rs/pull/121">#121</a>:</strong> Removed unused imports and methods to maintain code cleanliness and reduce potential maintenance overhead.</p>
</li>
<li>
<p><strong>Test Stability <a href="https://github.com/copper-project/copper-rs/pull/107">#107</a>:</strong> Ignored hardware-dependent tests and added <code>test --workspace</code> to CI/CD to enhance test reliability across different environments.</p>
</li>
</ul>
<hr>
<p><h2>Release Notes - v0.4.1 - 2024-11-15</h2><a id="user-content-release-notes---v041---2024-11-15" aria-label="Permalink: Release Notes - v0.4.1 - 2024-11-15" href="#release-notes---v041---2024-11-15"></a></p>
<p><h3>New Features</h3><a id="user-content-new-features-1" aria-label="Permalink: New Features" href="#new-features-1"></a></p>
<ul>
<li>
<strong>Iceoryx2 Support <a href="https://github.com/copper-project/copper-rs/pull/87">#87</a>:</strong> Introduced Iceoryx2 support. Iceoryx2 is the successor to Iceoryx in pure Rust. The Copper support included a source component to receive messages, a sink component to send messages.</li>
<li>
<strong>Hesai XT32 Support <a href="https://github.com/copper-project/copper-rs/pull/101">#101</a>:</strong> Added the preliminary support for the Hesai XT32. If you have the actual HW handy, feel free to provide us the feedback!</li>
<li>
<strong>First standard Lidar Message Design <a href="https://github.com/copper-project/copper-rs/pull/99">#99</a>:</strong> For now in SOA out or the lidar sensors it allows SIMD optimizations for the first operations that are usually a frame transform.</li>
</ul>
<p><h3>Enhancements</h3><a id="user-content-enhancements-1" aria-label="Permalink: Enhancements" href="#enhancements-1"></a></p>
<ul>
<li>
<strong>Variable-Length SoAs <a href="https://github.com/copper-project/copper-rs/pull/100">#100</a>:</strong> Improved <code>SoA</code> (Structure of Arrays) to support variable lengths on top of their fixed size in the Copper List.</li>
<li>
<strong>CI Improvements <a href="https://github.com/copper-project/copper-rs/pull/98">#98</a>:</strong> Integrated clippy warnings into CI, thanks to <a href="https://github.com/makeecat">makeecat</a>
</li>
</ul>
<p><h3>Bug Fixes</h3><a id="user-content-bug-fixes-1" aria-label="Permalink: Bug Fixes" href="#bug-fixes-1"></a></p>
<ul>
<li>
<strong>BalanceBot Simulation Reset <a href="https://github.com/copper-project/copper-rs/pull/86">#86</a>:</strong> Improved the <code>reset_sim</code> functionality for the balance bot. Thanks to <a href="https://github.com/makeecat">makeecat</a>.</li>
<li>
<strong>Publishing Fixes <a href="https://github.com/copper-project/copper-rs/pull/103">#103</a>:</strong> Resolved various publishing issues and added dry-run validations to avoid disruptions.</li>
</ul>
<hr>
<p><h2>Release Notes - v0.4.0 - 2024-10-29</h2><a id="user-content-release-notes---v040---2024-10-29" aria-label="Permalink: Release Notes - v0.4.0 - 2024-10-29" href="#release-notes---v040---2024-10-29"></a></p>
<p><h4>New Features</h4><a id="user-content-new-features-2" aria-label="Permalink: New Features" href="#new-features-2"></a></p>
<ul>
<li>
<strong>Simulation API Support</strong>: With sim-mode=true in the main Copper macro, Copper will generate for you all the callbacks at all the tasks states it is going through (Start, Preprocess, Process, etc...). Combined with the already mockable Clock it allows a very easy integration with a virtual environment.</li>
<li>
<strong>BalanceBot Simulation <a href="https://github.com/copper-project/copper-rs/pull/69">#69</a>:</strong>  Built on that and leveraging Bevy and Avian3D for realistic motion dynamics, we made a little demo of our little real world demonstrator. The real world code and the sim code are 100% identical.</li>
<li>
<strong>Config Embedding <a href="https://github.com/copper-project/copper-rs/pull/78">#78</a>:</strong> Embedded the default <code>copperconfig.ron</code> directly into the Copper executable, simplifying deployment for the main case (just one executable to copy and that's it!!). If the file is present, it will take precedence over the embedded version. We also do log the actual config used in the logs so you can come back to it in doubt.</li>
</ul>
<p><h4>Enhancements</h4><a id="user-content-enhancements-2" aria-label="Permalink: Enhancements" href="#enhancements-2"></a></p>
<ul>
<li>
<strong>Cross-Platform Compatibility for Mocking <a href="https://github.com/copper-project/copper-rs/pull/75">#75</a>:</strong> Enhanced feature flags to better support various platforms, particularly macOS, enabling testing with mocked hardware dependencies. The full repo now compile under CI/CD on MacOS and Linux (previously it we could only compile and test the Core)</li>
</ul>
<p><h4>Bug Fixes</h4><a id="user-content-bug-fixes-2" aria-label="Permalink: Bug Fixes" href="#bug-fixes-2"></a></p>
<ul>
<li>
<strong>Terminal Restoration <a href="https://github.com/copper-project/copper-rs/pull/73">#73</a>:</strong> Fixed issues with terminal states not restoring properly upon exit, preventing corruption and enhancing the overall stability of simulator sessions.</li>
<li>
<strong>Print Output Cleanup <a href="https://github.com/copper-project/copper-rs/pull/80">#80</a>:</strong> Streamlined console logging to minimize redundant or unnecessary print statements, making debugging output more manageable.</li>
<li>
<strong>Git LFS Migration <a href="https://github.com/copper-project/copper-rs/pull/76">#76</a>:</strong> Moved heavy assets to a CDN to mitigate GitHub LFS limitations, reducing operational overhead and streamlining asset distribution.</li>
</ul>
<p><h4>Infrastructure and CI/CD</h4><a id="user-content-infrastructure-and-cicd" aria-label="Permalink: Infrastructure and CI/CD" href="#infrastructure-and-cicd"></a></p>
<ul>
<li>
<strong>Asset CDN Integration <a href="https://github.com/copper-project/copper-rs/pull/35">#35</a>:</strong> Transitioned assets to a content delivery network to avoid the super costly Github LFS.</li>
<li>
<strong>Improved Documentation <a href="https://github.com/copper-project/copper-rs/pull/82">#82</a>:</strong> Expanded and refined documentation across modules, enhancing clarity for new users and developers.</li>
</ul>
<p><h4>Internal Refactoring</h4><a id="user-content-internal-refactoring" aria-label="Permalink: Internal Refactoring" href="#internal-refactoring"></a></p>
<ul>
<li>
<strong>Logging Value Enhancements <a href="https://github.com/copper-project/copper-rs/pull/80">#80</a>:</strong> Fine-tuned value logging to increase logging granularity and simplify troubleshooting in complex simulation states.</li>
<li>
<strong>Feature Flag Revamp <a href="https://github.com/copper-project/copper-rs/pull/75">#75</a>:</strong> Restructured feature flags to better support debugging and cross-platform configurations, especially for macOS compatibility.</li>
</ul>
<hr>
<p><h2>Release Notes - v0.3.1 - 2024-10-12</h2><a id="user-content-release-notes---v031---2024-10-12" aria-label="Permalink: Release Notes - v0.3.1 - 2024-10-12" href="#release-notes---v031---2024-10-12"></a></p>
<p>A Minor release with 2 new components and some fixes.</p>
<p><h2>New Components</h2><a id="user-content-new-components" aria-label="Permalink: New Components" href="#new-components"></a></p>
<ul>
<li>
<p>New cu-pid task: this is the first algorithm we publish. It is from the balancebot, a generalized PID controller logic you can reuse in your projects, see the readme in the crate.</p>
</li>
<li>
<p>New cu-consolemon monitoring: this is a TUI for Copper showing the information exposed by the new monitoring interface released in 0.3.0.</p>
</li>
</ul>
<p><h2>API improvements</h2><a id="user-content-api-improvements" aria-label="Permalink: API improvements" href="#api-improvements"></a></p>
<ul>
<li>Added <code>Mul</code> to <code>CuDuration</code> for easy time offset computations.</li>
</ul>
<p><h2>Various</h2><a id="user-content-various" aria-label="Permalink: Various" href="#various"></a></p>
<ul>
<li>
<strong>Tree Reorganization</strong>:
<ul>
<li>Major reorganization of the repository structure for improved clarity and maintainability.</li>
</ul>
</li>
</ul>
<p><h2>Bug Fixes</h2><a id="user-content-bug-fixes-3" aria-label="Permalink: Bug Fixes" href="#bug-fixes-3"></a></p>
<ul>
<li>
<strong>Logging Fixes</strong>:
<ul>
<li>Resolved an issue where <code>OnceLock</code> was not releasing the unified logger, preventing a clean shutdown of the logger.</li>
<li>Addressed an issue with a double close in the logger during shutdown.</li>
</ul>
</li>
</ul>
<hr>
<p><h2>Release Notes - v0.3.0 - 2024-09-30</h2><a id="user-content-release-notes---v030---2024-09-30" aria-label="Permalink: Release Notes - v0.3.0 - 2024-09-30" href="#release-notes---v030---2024-09-30"></a></p>
<p>This alpha release introduces substantial improvements to the Copper framework's monitoring capabilities and API flexibility.</p>
<p><h2>Highlights</h2><a id="user-content-highlights" aria-label="Permalink: Highlights" href="#highlights"></a></p>
<ul>
<li>
<strong>New multisource and optional input API</strong>: The Copper engine now supports multiple and optional inputs/outputs (see PR #44).</li>
</ul>
<p>This is a <strong>breaking change</strong>.</p>
<p>Now you can link 2 tasks to one in the RON file like this:</p>
<div data-snippet-clipboard-copy-content="
    tasks: [
        (
            id: &quot;balpos&quot;,
            type: &quot;cu_ads7883::ADS7883&quot;,
        ),
        (
            id: &quot;railpos&quot;,
            type: &quot;cu_rp_encoder::Encoder&quot;,
        ),
        (
            id: &quot;pidctrl&quot;,
            type: &quot;pidtask::PIDTask&quot;,
            config: {
               [...]
            },
        ),
        (
            id: &quot;motor&quot;,
            type: &quot;cu_rp_sn754410::SN754410&quot;,
            [...]
        ),
     ],
    cnx: [
        //                    vvvvvvvvvv   same dest!
        (src: &quot;balpos&quot;,   dst: &quot;pidctrl&quot;,   msg: &quot;cu_ads7883::ADSReadingPayload&quot;),
        (src: &quot;railpos&quot;,  dst: &quot;pidctrl&quot;,   msg: &quot;cu_rp_encoder::EncoderPayload&quot;),
        (src: &quot;pidctrl&quot;,  dst: &quot;motor&quot;,   msg: &quot;cu_rp_sn754410::MotorPayload&quot;),
    ],
)
"><pre>    <span>tasks</span>: [
        (
            <span>id</span>: <span>"balpos"</span>,
            <span>type</span>: <span>"cu_ads7883::ADS7883"</span>,
        ),
        (
            <span>id</span>: <span>"railpos"</span>,
            <span>type</span>: <span>"cu_rp_encoder::Encoder"</span>,
        ),
        (
            <span>id</span>: <span>"pidctrl"</span>,
            <span>type</span>: <span>"pidtask::PIDTask"</span>,
            <span>config</span>: {
               [...]
            },
        ),
        (
            <span>id</span>: <span>"motor"</span>,
            <span>type</span>: <span>"cu_rp_sn754410::SN754410"</span>,
            [...]
        ),
     ],
    <span>cnx</span>: [
        <span>//                    vvvvvvvvvv   same dest!</span>
        (<span>src</span>: <span>"balpos"</span>,   <span>dst</span>: <span>"pidctrl"</span>,   <span>msg</span>: <span>"cu_ads7883::ADSReadingPayload"</span>),
        (<span>src</span>: <span>"railpos"</span>,  <span>dst</span>: <span>"pidctrl"</span>,   <span>msg</span>: <span>"cu_rp_encoder::EncoderPayload"</span>),
        (<span>src</span>: <span>"pidctrl"</span>,  <span>dst</span>: <span>"motor"</span>,   <span>msg</span>: <span>"cu_rp_sn754410::MotorPayload"</span>),
    ],
)
</pre></div>
<p>To help you manage the types that are generated, we are giving a set of macros to help you matching the correct input / output types:</p>
<div data-snippet-clipboard-copy-content="impl<'cl> CuTask<'cl> for PIDTask {
    // This tasks takes 2 inputs!
    // They are given in the order of task declaration
    // the input_msg! macro build a (&amp;CuMsg<ADSReadingPayload>, &amp;CuMsg<EncoderPayload>) tuple under the hood.
    // it also works with 1 input and then you will get a straight &amp;CuMsg<> immutable ref.
    // For technical Rust reasons, you need to explicitely tie the lifetime ('cl means copperlist if you are curious: the internal structure of copper for messages)
    type Input = input_msg!('cl, ADSReadingPayload, EncoderPayload);

    // same thing but as an output this is a &amp;mut CuMsg<MotorPayload>
    type Output = output_msg!('cl, MotorPayload);

    fn process(
        &amp;mut self,
        clock: &amp;RobotClock,
        input: Self::Input,  // here this is now straight the input type, it is a little simpler.
        output: Self::Output,
    ) -> CuResult<()> {
        let (bal_pos, rail_pos) = input;  // you can unpack the tuple directly those are resp. &amp;CuMsg<ADSReadingPayload> and &amp;CuMsg<EncoderPayload>
        let bal_tov = bal_pos.metadata.tov.expect(&quot;we should have had a message here!&quot;);  // the messages are now optional depending on the context they could be expected or really optional.
        // we have a new method called set_payload for the output
        output.set_payload(MotorPayload { power: 0.0 }); // If you don't do that it will send away a message with a None payload"><pre><span>impl</span><span>&lt;</span><span>'</span>cl<span>&gt;</span> <span>CuTask</span><span>&lt;</span><span>'</span>cl<span>&gt;</span> <span>for</span> <span>PIDTask</span> <span>{</span>
    <span>// This tasks takes 2 inputs!</span>
    <span>// They are given in the order of task declaration</span>
    <span>// the input_msg! macro build a (&amp;CuMsg&lt;ADSReadingPayload&gt;, &amp;CuMsg&lt;EncoderPayload&gt;) tuple under the hood.</span>
    <span>// it also works with 1 input and then you will get a straight &amp;CuMsg&lt;&gt; immutable ref.</span>
    <span>// For technical Rust reasons, you need to explicitely tie the lifetime ('cl means copperlist if you are curious: the internal structure of copper for messages)</span>
    <span>type</span> <span>Input</span> = <span>input_msg</span><span>!</span><span>(</span><span>'</span>cl, <span>ADSReadingPayload</span>, <span>EncoderPayload</span><span>)</span><span>;</span>

    <span>// same thing but as an output this is a &amp;mut CuMsg&lt;MotorPayload&gt;</span>
    <span>type</span> <span>Output</span> = <span>output_msg</span><span>!</span><span>(</span><span>'</span>cl, <span>MotorPayload</span><span>)</span><span>;</span>

    <span>fn</span> process<span>(</span>
        <span>&amp;</span><span>mut</span> <span>self</span><span>,</span>
        <span>clock</span><span>:</span> <span>&amp;</span><span>RobotClock</span><span>,</span>
        <span>input</span><span>:</span> <span>Self</span><span>::</span><span>Input</span><span>,</span>  <span>// here this is now straight the input type, it is a little simpler.</span>
        <span>output</span><span>:</span> <span>Self</span><span>::</span><span>Output</span><span>,</span>
    <span>)</span> -&gt; <span>CuResult</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
        <span>let</span> <span>(</span>bal_pos<span>,</span> rail_pos<span>)</span> = input<span>;</span>  <span>// you can unpack the tuple directly those are resp. &amp;CuMsg&lt;ADSReadingPayload&gt; and &amp;CuMsg&lt;EncoderPayload&gt;</span>
        <span>let</span> bal_tov = bal_pos<span>.</span><span>metadata</span><span>.</span><span>tov</span><span>.</span><span>expect</span><span>(</span><span>"we should have had a message here!"</span><span>)</span><span>;</span>  <span>// the messages are now optional depending on the context they could be expected or really optional.</span>
        <span>// we have a new method called set_payload for the output</span>
        output<span>.</span><span>set_payload</span><span>(</span><span>MotorPayload</span> <span>{</span> <span>power</span><span>:</span> <span>0.0</span> <span>}</span><span>)</span><span>;</span> <span>// If you don't do that it will send away a message with a None payload</span></pre></div>
<ul>
<li>
<strong>Monitoring System</strong>: The monitoring framework is now fully integrated, allowing real-time stats collection and cumulative statistics (see PRs #49, #50, and #51). We can imagine complex decision trees happening at that stage for complex robots and various degraded modes.</li>
</ul>
<p>The monitoring component is really similar to a task, but with specialized callbacks:</p>
<div data-snippet-clipboard-copy-content="// This is in the RON file, just add a monitor entry like this:

    tasks: [
        (
            id: &quot;task0&quot;,
            type: &quot;tasks::ExampleSrc&quot;,
        ),
        [...]
     ],
    cnx: [
        (src: &quot;task0&quot;, dst: &quot;task1&quot;, msg: &quot;i32&quot;),
        [...]
    ],
    monitor: (type: &quot;ExampleMonitor&quot;)  // here, add a config entry if necessary
)"><pre><span>// This is in the RON file, just add a monitor entry like this:</span>

    <span>tasks</span>: [
        (
            <span>id</span>: <span>"task0"</span>,
            <span>type</span>: <span>"tasks::ExampleSrc"</span>,
        ),
        [...]
     ],
    <span>cnx</span>: [
        (<span>src</span>: <span>"task0"</span>, <span>dst</span>: <span>"task1"</span>, <span>msg</span>: <span>"i32"</span>),
        [...]
    ],
    <span>monitor</span>: (<span>type</span>: <span>"ExampleMonitor"</span>)  <span>// here, add a config entry if necessary</span>
)</pre></div>
<div data-snippet-clipboard-copy-content="struct ExampleMonitor {
    tasks: &amp;'static [&amp;'static str], // We give you the task ordinal to task id mapping (so it is stable as long as you don't change your task ids.
}

impl CuMonitor for ExampleMonitor {
    // We pass you the config you gave in the RON file exactly like for the tasks.
    fn new(_config: Option<&amp;ComponentConfig>, taskids: &amp;'static [&amp;str]) -> CuResult<Self> {
        Ok(ExampleMonitor { tasks: taskids })
    }

    fn start(&amp;mut self, clock: &amp;_RobotClock) -> CuResult<()> {
        // callbacked when all the tasks, start called.
    }

    fn process_copperlist(&amp;self, msgs: &amp;[&amp;CuMsgMetadata]) -> CuResult<()> {
        // This is callbacked at the end of the processing of a copper list (basically near when the CL is getting serialized to disk after a success. 
        // The metadata gives you all the timings you need to check if your robot is still behaving nominally.
        for t in msgs.iter().enumerate() {
            let (taskid, metadata) = t;
            debug!(&quot;Task: {} -> {}&quot;, taskid, metadata);
        }
        Ok(())
    }

    fn process_error(&amp;self, taskid: usize, step: CuTaskState, error: &amp;CuError) -> Decision {
        // This is called back if any task reports an error at any step (start, process, ...)
        // You can then match that taskid and compute a decision for your robot: Abort, Ignore, Shutdown (see the cu28/monitoring.rs file for semantic details. 
        Decision::Ignore
    }

    fn stop(&amp;mut self, clock: &amp;_RobotClock) -> CuResult<()> {
        // call when the stack is stopping
        Ok(())
    }
}"><pre><span>struct</span> <span>ExampleMonitor</span> <span>{</span>
    <span>tasks</span><span>:</span> <span>&amp;</span><span>'</span>static <span>[</span><span>&amp;</span><span>'</span>static <span>str</span><span>]</span><span>,</span> <span>// We give you the task ordinal to task id mapping (so it is stable as long as you don't change your task ids.</span>
<span>}</span>

<span>impl</span> <span>CuMonitor</span> <span>for</span> <span>ExampleMonitor</span> <span>{</span>
    <span>// We pass you the config you gave in the RON file exactly like for the tasks.</span>
    <span>fn</span> <span>new</span><span>(</span><span>_config</span><span>:</span> <span>Option</span><span>&lt;</span><span>&amp;</span><span>ComponentConfig</span><span>&gt;</span><span>,</span> <span>taskids</span><span>:</span> <span>&amp;</span><span>'</span>static <span>[</span><span>&amp;</span><span>str</span><span>]</span><span>)</span> -&gt; <span>CuResult</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>Ok</span><span>(</span><span>ExampleMonitor</span> <span>{</span> <span>tasks</span><span>:</span> taskids <span>}</span><span>)</span>
    <span>}</span>

    <span>fn</span> <span>start</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>clock</span><span>:</span> <span>&amp;</span><span>_RobotClock</span><span>)</span> -&gt; <span>CuResult</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
        <span>// callbacked when all the tasks, start called.</span>
    <span>}</span>

    <span>fn</span> <span>process_copperlist</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>msgs</span><span>:</span> <span>&amp;</span><span>[</span><span>&amp;</span><span>CuMsgMetadata</span><span>]</span><span>)</span> -&gt; <span>CuResult</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
        <span>// This is callbacked at the end of the processing of a copper list (basically near when the CL is getting serialized to disk after a success. </span>
        <span>// The metadata gives you all the timings you need to check if your robot is still behaving nominally.</span>
        <span>for</span> t <span>in</span> msgs<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>enumerate</span><span>(</span><span>)</span> <span>{</span>
            <span>let</span> <span>(</span>taskid<span>,</span> metadata<span>)</span> = t<span>;</span>
            <span>debug</span><span>!</span><span>(</span><span>"Task: {} -&gt; {}"</span>, taskid, metadata<span>)</span><span>;</span>
        <span>}</span>
        <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
    <span>}</span>

    <span>fn</span> <span>process_error</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>taskid</span><span>:</span> <span>usize</span><span>,</span> <span>step</span><span>:</span> <span>CuTaskState</span><span>,</span> <span>error</span><span>:</span> <span>&amp;</span><span>CuError</span><span>)</span> -&gt; <span>Decision</span> <span>{</span>
        <span>// This is called back if any task reports an error at any step (start, process, ...)</span>
        <span>// You can then match that taskid and compute a decision for your robot: Abort, Ignore, Shutdown (see the cu28/monitoring.rs file for semantic details. </span>
        <span>Decision</span><span>::</span><span>Ignore</span>
    <span>}</span>

    <span>fn</span> <span>stop</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>clock</span><span>:</span> <span>&amp;</span><span>_RobotClock</span><span>)</span> -&gt; <span>CuResult</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
        <span>// call when the stack is stopping</span>
        <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
    <span>}</span>
<span>}</span></pre></div>
<p><h2>Other Notable Changes</h2><a id="user-content-other-notable-changes" aria-label="Permalink: Other Notable Changes" href="#other-notable-changes"></a></p>
<p><h3>New Features</h3><a id="user-content-new-features-3" aria-label="Permalink: New Features" href="#new-features-3"></a></p>
<ul>
<li>Real-time cumulative stats for <code>CuDurations</code>. See cu29/monitoring.rs we built an histogramming feature for timings this is super useful for monitoring components. Here is the list of everything you get it is not only pretty comprehensive but it is fixed size on memory so it should be pretty swift for any real time monitoring needs or UIs.</li>
</ul>
<div data-snippet-clipboard-copy-content="    // on the CuDurationStatistics struct
    pub fn min(&amp;self) -> CuDuration;
    pub fn max(&amp;self) -> CuDuration;
    pub fn mean(&amp;self) -> CuDuration 
    pub fn percentile(&amp;self, percentile: f64) -> CuDuration;
    pub fn stddev(&amp;self) -> CuDuration;
    pub fn jitter_min(&amp;self) -> CuDuration;
    pub fn jitter_max(&amp;self) -> CuDuration;
    pub fn jitter_mean(&amp;self) -> CuDuration;
    pub fn jitter_stddev(&amp;self) -> CuDuration;
    pub fn jitter_percentile(&amp;self, percentile: f64) -> CuDuration;"><pre>    <span>// on the CuDurationStatistics struct</span>
    <span>pub</span> <span>fn</span> <span>min</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>max</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>mean</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span></span> 
    <span>pub</span> <span>fn</span> <span>percentile</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>percentile</span><span>:</span> <span>f64</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>stddev</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>jitter_min</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>jitter_max</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>jitter_mean</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>jitter_stddev</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span>
    <span>pub</span> <span>fn</span> <span>jitter_percentile</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>percentile</span><span>:</span> <span>f64</span><span>)</span> -&gt; <span>CuDuration</span><span>;</span></pre></div>
<p><h3>Fixes</h3><a id="user-content-fixes" aria-label="Permalink: Fixes" href="#fixes"></a></p>
<ul>
<li>
<strong>Serialization / Deserialization Bug on Value</strong> (#42). A code reformat shuffled the serialization IDs Oo.</li>
</ul>
<p><h3>Enhancements</h3><a id="user-content-enhancements-3" aria-label="Permalink: Enhancements" href="#enhancements-3"></a></p>
<ul>
<li>
<p><strong>Virtual Output for Sinks</strong> (#53):</p>
<ul>
<li>before that there was no mean to monitor sinks (or hacks you might have seen on the incoming message). Now the stack behind the scene generates a () empty message for each sink you you get the perf number cleanly for them even if they don't output anything.</li>
</ul>
</li>
<li>
<p><strong>Balance Bot Demo</strong> (#46):</p>
<ul>
<li>a more complete example of a real robot demo we will bring at conferences.</li>
</ul>
</li>
</ul>
<p><h3>Miscellaneous</h3><a id="user-content-miscellaneous" aria-label="Permalink: Miscellaneous" href="#miscellaneous"></a></p>
<ul>
<li>And a bunch of cleanup / doc improments.</li>
</ul>
<hr>
<p><h2>Copper - v0.2.3 - 2024-09-11</h2><a id="user-content-copper---v023---2024-09-11" aria-label="Permalink: Copper - v0.2.3 - 2024-09-11" href="#copper---v023---2024-09-11"></a></p>
<p>We are pleased to announce the release of Copper v0.2.3, which includes several new features, enhancements, and bug fixes. Below is a summary of the key changes in this release:</p>
<p><h4>New Features</h4><a id="user-content-new-features-4" aria-label="Permalink: New Features" href="#new-features-4"></a></p>
<ul>
<li>
<strong>SN754410 Driver Support <a href="https://github.com/copper-project/copper-rs/pull/40">#40</a>:</strong> Added a new driver for the SN754410 motor driver. This driver allows easy integration with motor control applications, providing robust support for H-bridge motor control on a wide range of systems. <em>This driver is fully compatible with the BalanceHAT.</em>
</li>
<li>
<strong>ADS7883 Driver <a href="https://github.com/copper-project/copper-rs/pull/39">#39</a>:</strong> Introduced a driver for the ADS7883, a 12-bit SPI ADC. This addition includes comprehensive documentation in the README to facilitate setup and integration. <em>The ADS7883 driver is also compatible with the BalanceHAT.</em>
</li>
</ul>
<p><h4>Enhancements</h4><a id="user-content-enhancements-4" aria-label="Permalink: Enhancements" href="#enhancements-4"></a></p>
<ul>
<li>
<strong>macOS Development Support <a href="https://github.com/copper-project/copper-rs/pull/25">#25</a>:</strong> Copper can now be developed on macOS! The CI/CD pipeline has been updated to support macOS, ensuring cross-platform compatibility for all users.</li>
<li>
<strong>cu29_clock Enhancements <a href="https://github.com/copper-project/copper-rs/pull/32">#32</a>:</strong> Added a division feature to the cu29_clock, allowing more granular time management and synchronization within the Copper runtime.</li>
<li>
<strong>Structured Log Index File in Debug Mode <a href="https://github.com/copper-project/copper-rs/pull/30">#30</a>:</strong> Removed the requirement for an index file in debug mode within struct_log, simplifying the debugging process ie. only the config and the executable needs to be deployed for the debug build and you get a standard debug text logging.</li>
<li>
<strong>Logging Slabs Addition <a href="https://github.com/copper-project/copper-rs/pull/24">#24</a>:</strong> The current unified logger works with big memory mapped files. Initially we thought we could rely on the mmap resize feature of the kernel api but it just doesn't work. We are reverting into building "slabs", ie dividing the data logger into large files. Those files can be concatenated and read or directly read from the log exporter.</li>
</ul>
<p><h4>Bug Fixes</h4><a id="user-content-bug-fixes-4" aria-label="Permalink: Bug Fixes" href="#bug-fixes-4"></a></p>
<ul>
<li>
<strong>Compilation Feedback Adjustments <a href="https://github.com/copper-project/copper-rs/pull/33">#33</a>:</strong> Moved compilation feedback from standard output to standard error to better align with conventional logging practices.</li>
<li>
<strong>Flush and Core Dump Fixes <a href="https://github.com/copper-project/copper-rs/pull/29">#29</a>:</strong> Resolved issues where changes after a section flush could cause a core dump, improving the stability of the logging system.</li>
</ul>
<p><h4>Infrastructure and CI/CD</h4><a id="user-content-infrastructure-and-cicd-1" aria-label="Permalink: Infrastructure and CI/CD" href="#infrastructure-and-cicd-1"></a></p>
<ul>
<li>
<strong>CI/CD Pipeline Enhancements <a href="https://github.com/copper-project/copper-rs/pull/25">#25</a>:</strong> Added macOS support to the CI/CD pipeline, ensuring better cross-platform compatibility.</li>
<li>
<strong>Removed 'Continue on Error' in CI/CD <a href="https://github.com/copper-project/copper-rs/pull/36">#36</a>:</strong> Addressed a CI/CD issue where the pipeline was green while failing Oo.</li>
</ul>
<p><h4>Refactoring and Internal Changes</h4><a id="user-content-refactoring-and-internal-changes" aria-label="Permalink: Refactoring and Internal Changes" href="#refactoring-and-internal-changes"></a></p>
<ul>
<li>
<p><strong>Unified Logger Refactor <a href="https://github.com/copper-project/copper-rs/pull/27">#27</a>:</strong> Refactored the Unified Logger to introduce a dual-slab logging system, improving performance and eliminating the need for remap/resize operations.</p>
</li>
<li>
<p><strong>Runtime Loop Enhancements <a href="https://github.com/copper-project/copper-rs/pull/21">#21</a>:</strong> Added a new notion of loops in the runtime plan, setting the stage for more flexible and powerful runtime behavior.</p>
</li>
</ul>
<hr>
<p><em>If you're looking to build your own interfacing with the SN754410 or ADS7883 drivers, we share detailed connectivity schematics with a Raspberry Pi to help you get started.</em></p>
<p>We recommend updating to this latest version to take advantage of these improvements. As always, please refer to the updated documentation and release notes for detailed information on how to integrate these changes into your projects.</p>
<p>If you have any questions or need further assistance, feel free to reach out to our support team.</p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimality of Gerver's Sofa (117 pts)]]></title>
            <link>https://arxiv.org/abs/2411.19826</link>
            <guid>42300382</guid>
            <pubDate>Mon, 02 Dec 2024 21:05:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2411.19826">https://arxiv.org/abs/2411.19826</a>, See on <a href="https://news.ycombinator.com/item?id=42300382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="labstabs"><p>
    <label for="tabone">Bibliographic Tools</label></p><div>
      <h2>Bibliographic and Citation Tools</h2>
      <div>
          <p><label>
              
              <span></span>
              <span>Bibliographic Explorer Toggle</span>
            </label>
          </p>
          
        </div>
        
        
        
        
    </div>


    <p>
    <label for="tabtwo">Code, Data, Media</label></p><div>
      <h2>Code, Data and Media Associated with this Article</h2>
      

      
      
      
      
      
      
      
      
    </div>


      <p>
      <label for="labstabs-demos-input" id="labstabs-demos-label">Demos</label></p><div>
        <h2>Demos</h2>
        
        
        
        
      </div>
      <p>
      <label for="tabfour">Related Papers</label></p><div>
        <h2>Recommenders and Search Tools</h2>
        
        
        
        
        
      </div>

      <p>
      <label for="tabfive">
        About arXivLabs
      </label></p><div>
            <h2>arXivLabs: experimental projects with community collaborators</h2>
            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
            <p>Have an idea for a project that will add value for arXiv's community? <a href="https://info.arxiv.org/labs/index.html"><strong>Learn more about arXivLabs</strong></a>.</p>
          </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook's Little Red Book (472 pts)]]></title>
            <link>https://www.map.cv/blog/redbook</link>
            <guid>42299863</guid>
            <pubDate>Mon, 02 Dec 2024 20:07:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.map.cv/blog/redbook">https://www.map.cv/blog/redbook</a>, See on <a href="https://news.ycombinator.com/item?id=42299863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>In 2012, Facebook was facing a challenge as it hit a billion users: rapid scaling was outpacing their ability to maintain focus on the big picture. Narratives became fragmented, and with them, the essence of what tied the company to Zuckerberg's vision began to fade.</p><p>They made a bold move by codifying their story into a <em>Little Red Book</em>. Which they distributed internally.</p><p>Created by designer <!--$--><a href="https://benbarry.com/" target="_blank" rel="noopener">Ben Barry</a><!--/$-->, the book distilled Facebook’s ethos—breaking things, thinking big, and moving fast—into a manifesto. More than a handbook, it was a declaration of identity, solving the problem of scaling culture during explosive growth. It reminded employees: <em>This is who we are. This is why we exist.</em></p><p>Few copies remain today, and most of the digital versions floating around the internet are low resolution.</p><p>After years of sporadically checking eBay, I found a copy. It arrived at our office a few weeks ago.</p><p><img alt="" data-framer-asset="data:framer/asset-reference,Il710XsKIqtIBh4o3bxWhOTafsI.png" data-framer-height="723" data-framer-width="1410" height="361" src="https://framerusercontent.com/images/Il710XsKIqtIBh4o3bxWhOTafsI.png" srcset="https://framerusercontent.com/images/Il710XsKIqtIBh4o3bxWhOTafsI.png?scale-down-to=512 512w,https://framerusercontent.com/images/Il710XsKIqtIBh4o3bxWhOTafsI.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/Il710XsKIqtIBh4o3bxWhOTafsI.png 1410w" width="705" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (min-width: 810px) and (max-width: 1199px) 100vw, (max-width: 809px) 100vw"></p><h6>Determined to create a <em>better</em> digital version, I reached out to a few public libraries and universities in NYC. One gave me access to their $150,000 DT-BC100 scanner.</h6><p>This isn’t just a scan of a book; it’s a testament to the power of storytelling.</p><p>Stories build belief. They turn strangers into teammates, teams into movements, and movements into businesses that can change the world.</p><p>So here it is, the highest quality publicly available version of the <em>Little Red Book</em>,<em> </em>preserved for anyone curious about how great companies scale culture and ideas.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Static IPs for Serverless Containers (115 pts)]]></title>
            <link>https://modal.com/blog/vprox</link>
            <guid>42299829</guid>
            <pubDate>Mon, 02 Dec 2024 20:04:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modal.com/blog/vprox">https://modal.com/blog/vprox</a>, See on <a href="https://news.ycombinator.com/item?id=42299829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-svelte-h="svelte-3sbs4s">At Modal, we built a high-availability, Go-based VPN proxy called <em>vprox</em>.</p> <p>This is a deployment of <a rel="nofollow" href="https://www.wireguard.com/">WireGuard</a>, so it operates
on Layer 3 (IP) of the network stack and allows us to funnel outbound traffic
from containers around the world through static IPv4 addresses. In the event of
a single-node failure, its static IPs are associated with other proxy nodes, and
containers reconnect within seconds.</p> <p> <img src="https://modal-cdn.com/vprox-blog-post/vprox-1.svg" alt="Map of Modal containers in different places funneling through a static IP proxy with WireGuard tunnels"> </p> <p>This blog post is about the guts of our network infrastructure, which powers
<a href="https://modal.com/docs/guide/proxy-ips">Static IP Proxies</a>.</p> <h2 id="scenario" data-svelte-h="svelte-15axy86">Scenario</h2> <p data-svelte-h="svelte-15b9ky8">The year is 2024, and you are deciding on a serverless cloud platform. You
stumble upon Modal. Run <code>pip install modal</code>, write a short Python function, and
<code>modal deploy</code> it. Amazing, now you’ve got a cron job and API endpoint in the
cloud, within seconds.</p>  <p>Modal functions run on hardware around the world, in
<a href="https://modal.com/blog/region-selection-launch">dozens of regions</a> across multiple cloud
providers. This is how we optimize the prices on your compute and scale
dynamically to meet demand. It’s all to make developers happy, since now you
don’t have to think about this stuff. (We get it, we’re infrastructure
engineers.)</p> <p data-svelte-h="svelte-13b1bl8">But now let’s say you want to connect your serverless function to your MongoDB
cloud database, and it requires a specific IP access list. Uh oh…</p> <center data-svelte-h="svelte-jd7vgl"><img src="https://modal-cdn.com/cdnbot/tmpr5_wsi7u_2639b00c.webp" alt="Edit IP Access List Entry" width="600"></center> <p data-svelte-h="svelte-aezq97">Usually, with a traditional provider you’d deploy some VMs and assign them a
static IP address or two, then distribute them across your machines and add
those to your access list. So now your application runs on cloud hosts at some
particular IPs, like <code>20.21.20.21</code>. Only these machines can access your MongoDB
database, and no one else can around the world.</p> <p data-svelte-h="svelte-1vqftv1">But if you’re running a serverless computing workload, which can not only run in
any data center around the world, but also scale up and down… you won’t know
what IP address your code is running on! So that access list would have
thousands of entries and will be constantly changing, which really isn’t going
to cut it.</p> <p data-svelte-h="svelte-1lizj1k">Plus, Modal has an isolated container runtime that lets us share each host’s CPU
and memory between workloads. If a host has one IP, your container and
another customer’s container on that host would have the same IP, so that
bypasses the security of your access list.</p> <h2 id="okay-but-i-want-to-access-my-database-from-modal" data-svelte-h="svelte-3g7uaz">Okay but I want to access my database from Modal</h2> <p data-svelte-h="svelte-118b262">So you need a static outbound IP address. Is that possible? Let’s break it down.
IP addresses act as identifiers for sending and receiving internet data. When
two different containers communicate with a web service like Google, each has a
unique source IP. This allows Google’s server to reply directly to the correct
container.</p> <p> <img src="https://modal-cdn.com/vprox-blog-post/vprox-2.svg" alt="Two containers, both sending data to a server, with different IPs"> </p> <p data-svelte-h="svelte-n4o15x">In this standard setup, the outbound IP address is tightly coupled to the
container. How can you decouple static IP addresses from the actual compute
resources? There’s a solution for this: <strong>You use a proxy.</strong></p> <p>We started by adding <a rel="nofollow" href="https://en.wikipedia.org/wiki/SOCKS">SOCKS5</a> proxies to
Modal. SOCKS5 is an unsung hero of the Internet proxy world; it’s a technology
from 1996 (<a rel="nofollow" href="https://datatracker.ietf.org/doc/html/rfc1928">RFC 1928</a>) that lets
you send a request <em data-svelte-h="svelte-q4pvpt">through</em> another computer. SOCKS5 is secretly built into a
lot of software like OpenSSH, if you pass in the obscure <code data-svelte-h="svelte-hyyf4p">-D</code> flag that enables
the feature. But SOCKS5 doesn’t work out-of-the-box. You need to edit your
application to use an esoteric network shim.</p> <p data-svelte-h="svelte-1dp56pp">If you wanted containers running your function to use a SOCKS5-based Modal
Proxy, we would define one for your workspace. Once the Proxy object is created,
you can use it like so:</p>  <p data-svelte-h="svelte-coa8qv">Now other functions can call <code>get_user_count()</code> remotely as a serverless
invocation. The proxy is only spun up within the <code>get_user_count()</code> function.</p>  <p data-svelte-h="svelte-12yw1j5">Slick! But this is brittle. Replacing the standard library’s <code>socket.socket</code>
object doesn’t work for libraries that don’t use <code>socket</code> directly. And many
common libraries don’t, such as asyncpg, datadog, aiohttp, httpx, or grpcio.</p> <p data-svelte-h="svelte-1hwzmna">The broader issue is that the API is not obvious. It passes on the complexity to
the user, who needs to figure out how to wire up the SOCKS5 proxy to their
libraries. Modal is a cloud provider, and our philosophy on developer experience
is that things “just work” — we should implement features that are correct and
efficient by design.</p> <p>So we stepped down a layer. Since we own the entire runtime, how can we
configure networking so that <em data-svelte-h="svelte-9ary3k">all outbound Internet</em> <em data-svelte-h="svelte-1mjeabc">access</em> goes through that
IP? You should be able to just send a simple request to
<a rel="nofollow" href="https://ifconfig.me/">ifconfig.me</a> and get back your proxy’s IP, for instance.</p> <h2 id="enter-wireguard" data-svelte-h="svelte-1nd9c0t">Enter WireGuard</h2> <p data-svelte-h="svelte-qzj7qn">At Layer 3, the Internet Protocol, all traffic looks the same—whether it’s
Wikipedia, YouTube, or MongoDB. It’s just MTU-sized packets, usually a few
kilobytes each, traveling through routers to their destinations. To ensure a
consistent source IP address for outbound internet traffic across multiple
containers, we can route all container traffic through a VPN. A VPN not only
encrypts traffic but also can mask its source IP address, achieving the desired
consistency.</p> <p data-svelte-h="svelte-1s32srq">WireGuard is a really simple VPN, and it’s included in the mainline Linux
kernel. So we just have to bootstrap a WireGuard network between the proxy
server and Modal workers (machines that run containers), configure traffic
routing, and we’re all set!</p> <p> <img src="https://modal-cdn.com/vprox-blog-post/vprox-3.svg" alt="Two containers sending data to a server, with a proxy in the middle"> </p> <p data-svelte-h="svelte-1r3j2pr">To set up the actual WireGuard network, we start an HTTPS listener on port 443
of the WireGuard server. This binds to the public IP of the proxy node, and it
takes “connect” POST requests to set up connections to the WireGuard network. We
can rely on the security of TLS to handle VPN key distribution.</p> <p>When a POST request is received with the client’s public key, the server
validates the credentials of the client, then allocates an IP in the subnet and
adds it as a peer at that IP. The server also has a loop that removes idle peers
after a few minutes of not receiving WireGuard handshakes. We use the
<a rel="nofollow" href="https://github.com/WireGuard/wgctrl-go">wgctrl</a> library for this, which
provides Go bindings for the WireGuard API, including access to the
<code data-svelte-h="svelte-1encs16">LastHandshakeTime</code> property of each peer.</p>  <p data-svelte-h="svelte-b0r7kw">On the client side, we periodically probe the WireGuard VPN connection every few
seconds. This is implemented by the <code>CheckConnection</code> function below. If the
pings fail, the client assumes that the connection is dead, and it then begins
trying to reconnect to the server and recover by sending a new “connect” POST
request.</p>  <p>This behavior is implemented in our open-source Go package
<a rel="nofollow" href="https://github.com/modal-labs/vprox">vprox</a>, which we’ll talk about more at the
end of this blog post.</p> <h2 id="policy-based-routing-on-container-traffic" data-svelte-h="svelte-i7tp1m">Policy-based routing on container traffic</h2> <p>There’s still a missing piece to the puzzle: Modal workers are multi-tenant. We
run gVisor sandboxes from multiple functions on the same host, which is what
lets us provide a serverless compute product with <a href="https://modal.com/pricing">flexible pricing</a>.</p> <p data-svelte-h="svelte-dnrj5b">How does container networking work? Well, very briefly:</p> <ul><li>Each worker machine runs multiple containers, and each container gets its own
<em><a rel="nofollow" href="https://man7.org/linux/man-pages/man7/network_namespaces.7.html">network namespace</a></em>.</li> <li data-svelte-h="svelte-adf55u">Inside the network namespace, the container has a <em>veth (virtual Ethernet)
interface</em>. This acts as a virtual network card, similar to the WiFi card on
your laptop.</li> <li>Veth’s come in pairs. The other half of the veth lives on a
<a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#bridge">bridge device</a>
(like a <a rel="nofollow" href="https://en.wikipedia.org/wiki/Network_switch">switch</a>).</li> <li>When containers send outbound packets to the Internet, they pass through the
veth and arrive at the bridge, where the host Linux kernel is configured to
<strong><a rel="nofollow" href="https://en.wikipedia.org/wiki/Network_address_translation">masquerade</a>
each packet’s source IP address</strong> before exiting the machine.</li></ul> <p>If you didn’t get all that, it’s fine! The important part is the last step, IP
masquerade. This is a form of network address translation, or
<a rel="nofollow" href="https://en.wikipedia.org/wiki/Network_address_translation">SNAT</a>. It’s just
like how your home router uses SNAT to make all devices in your house have the
same public IP address. Each cloud host at Modal uses SNAT so containers running
on that host appear to the outside world to have the host’s public IP.</p> <p> <img src="https://modal-cdn.com/vprox-blog-post/vprox-4.svg" alt="Multiple containers on a host behind a network bridge and masquerade rule"> </p> <p>This is the classic container networking setup. To introduce WireGuard, we need
to tell traffic from one container to go to a designated WireGuard interface
without affecting its neighbors. This requires an update to the kernel’s
<a rel="nofollow" href="https://en.wikipedia.org/wiki/Routing_table">routing table</a>. When a container
sends a packet to the outside world, we should inspect the packet’s source IP
and redirect it to the proper VPN interface based on the container’s metadata.</p> <p>But people familiar with Linux might see a problem here: the
<a rel="nofollow" href="https://en.wikipedia.org/wiki/Iproute2">iproute2</a> system in Linux doesn’t
actually let you put down routing table entries by source IP! In Linux, routing
tables are based on
<a rel="nofollow" href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR blocks</a> of
destination IPs. So you can route packets <em data-svelte-h="svelte-1wkmrfv">to</em> <code data-svelte-h="svelte-5wv3mt">142.251.40.174</code> (google.com)
from all containers, but you can’t tell packets <em data-svelte-h="svelte-yvfinu">from</em> a specific container to
go through a VPN.</p> <p data-svelte-h="svelte-k4co4f">There’s a solution, but it means we need to sin a bit. We’re going to write some
<em>policy-based routing</em> rules. 🫢</p>  <p>Policy-based routing works by switching between multiple routing tables. The
routing tables in Linux are numbered from 1 to 2^31. So we can assign a routing
table to each container that requests a proxy, allocating indices to avoid
repeats, then
<a rel="nofollow" href="https://www.man7.org/linux/man-pages/man8/ip-rule.8.html">edit the policy database</a>
so that traffic from that container goes through the routing table.</p> <p> <img src="https://modal-cdn.com/vprox-blog-post/vprox-5.svg" alt="Diagram of container traffic through a policy database and route table"> </p> <p data-svelte-h="svelte-1xhepix">We really <em>didn’t</em> want to do this, it’s tricky! For example, what happens if
two containers start up at the same time? They need to synchronize and decide
which one gets the next numbered routing table. And if a container crashes
early, it adds another kernel resource to clean up. Dynamically configuring the
policy database was not our first choice of solution.</p> <p>(Technical detail: As an alternative approach, we tried doing it in eBPF first
with <a rel="nofollow" href="https://docs.kernel.org/bpf/redirect.html"><code data-svelte-h="svelte-vmildm">xdp_redirect()</code></a> in our packet
filter attached to the container bridge device. But this didn’t work. It was
incompatible with SNAT because eBPF skips the Linux netfilter stack.)</p> <p data-svelte-h="svelte-bpoc2p">Luckily, our runtime is pretty resilient to unexpected crashes (it’s written in
safe Rust, with testing, monitoring and conscious async-oriented design), and
overall we haven’t run into any reliability issues with our implementation so
far.</p> <p data-svelte-h="svelte-dt4uos">That concludes our worker-side implementation of the proxy! Now, back to the
server…</p> <h2 id="so-you-have-a-proxy-server-running-for-every-ip" data-svelte-h="svelte-eppjj4">So you have a proxy server running for every IP?</h2> <p data-svelte-h="svelte-gb5fyl">We did initially! But starting one cloud VM for every proxy server is pretty
expensive, and it’s not very efficient on resource utilization. The entire point
of serverless is shared tenancy, after all. To make this faster and more
reliable, we started assigning multiple IPs to each proxy server, so that one
unit of shared hardware could manage all of these associations.</p> <p data-svelte-h="svelte-1ovxg7s">Each <code>vprox server</code> node has one or more IPs living on one or more network
interfaces. For example, on AWS, the latest <code>c7gn.8xlarge</code> instance type ($2.00
/ hr) with 100 Gigabit networking can have up to 8 network interfaces, with 30
IPv4 addresses per interface. This is a pretty good deal — at full packing of
240 IPs, each costs less than $0.01 / hr while also allowing for individual
proxies to burst up to 100 Gbps of shared bandwidth.</p> <p>To avoid contention and control the bandwidth used by different IP proxies on
the same server, we can use the
<a rel="nofollow" href="https://man7.org/linux/man-pages/man8/tc.8.html">tc traffic shaping system</a> in
Linux.</p> <h3 id="juggling-ips-between-servers" data-svelte-h="svelte-6rhytx">Juggling IPs between servers</h3> <p data-svelte-h="svelte-n2rfhb">We didn’t just stop there though. We wrote some code that hits the cloud
instance metadata endpoint and detects within a couple seconds if you made any
changes to the IP addresses associated with the instance. If you did, <code>vprox</code>
automatically reconfigures itself to reallocate blocks of WireGuard IPs, move
around connections, bootstrap WireGuard interfaces, and start accepting
connections from clients to the new IP address.</p> <p>This may seem like overengineering, but it reduces the amount of configuration
for <code data-svelte-h="svelte-133xquj">vprox</code> and makes the server significantly more flexible. Plus, it’s
fault-tolerant by design!
<a rel="nofollow" href="https://queue.acm.org/detail.cfm?id=2898444">Reconciliation loops</a> are the
hidden heroes of distributed systems, as we all know.</p> <p data-svelte-h="svelte-v6gysk">When enabled, the network proxy is on the hot path of every request from a
serverless function, so high availability is crucial. You wouldn’t want your API
to start failing because you can’t connect to MongoDB anymore due to the <em>one</em>
proxy instance going down! So we implemented another reconciliation loop,
globally, that creates many servers and juggles the IPs around in event of a
termination.</p> <p> <img src="https://modal-cdn.com/vprox-blog-post/vprox-6.svg" alt="Failover of one proxy node causing IP reassignment"> </p> <p data-svelte-h="svelte-120w2ex">This can happen if the compute instance becomes unhealthy or needs to be taken
down for maintenance for any reason. The <code>vprox</code> client is also designed to
detect network partitions by periodically sending pings, and when it detects
that it has disconnected, we can automatically recover the connection to the new
server in under 10 seconds.</p> <p data-svelte-h="svelte-e7pm6o">Since IP is an inherently unreliable and unordered protocol, you’ll probably
never even notice if your proxy goes down! Even if you’re running an HTTP
request at that exact moment, it will just result in a few dropped packets,
which are automatically retried at the TCP layer. No database errors for you — a
perfect recovery.</p> <h3 id="what-is-rp_filter-anyway" data-svelte-h="svelte-1kqfb28">What is rp_filter anyway?</h3> <p>(We’re going to get into <a rel="nofollow" href="https://en.wikipedia.org/wiki/Sysctl">sysctl</a> here.
Sysctl is a way to configure attributes of the Linux kernel. Think of it like an
OS-wide configuration file.)</p> <p data-svelte-h="svelte-kuqel1">When testing <code>vprox</code> on different distributions of Linux, we ran into a problem
that we had to debug. Specifically, it was tested to be working on Ubuntu 24.04,
but it didn’t seem to be working on Oracle Linux 9. What happened? WireGuard is
part of the kernel, and iptables / iproute2 are supported by both distributions,
so this should be cross-platform.</p> <p>The issue turned out to be caused by a feature called <em data-svelte-h="svelte-h1xfux">reverse path filtering</em>.
Basically, the sysctl
<a rel="nofollow" href="https://sysctl-explorer.net/net/ipv4/rp_filter/"><code data-svelte-h="svelte-bvzrnk">net.ipv4.conf.all.rp_filter</code></a>
controls whether IP packets received on an interface are dropped. If strict
filtering is set, Linux will drop packets whose source address doesn’t appear to
match the path in the routing table that would otherwise be used to send packets
to that destination.</p> <p data-svelte-h="svelte-1mynh39">Since we’re sending packets to all kinds of public Internet sources through
these WireGuard interfaces, when they return on the interface, the kernel isn’t
happy about their source IP and drops them. It detects that a more “direct” path
would be to go through the default interface on the host instead. We need to
relax rp_filter.</p> <p data-svelte-h="svelte-gmy1dn">Curiously, when we disabled the rp_filter setting by setting it to 0, vprox
didn’t work. We had to explicitly set it to 2, which is “loose mode” that checks
the incoming packet against the kernel’s FIB (forwarding information bus).</p>  <p data-svelte-h="svelte-6q1f9f">Honestly, I don’t know why vprox only works when reverse path filtering is in
loose mode and not when it is disabled. But we switched the value of the sysctl,
and now it works reliably across Linux distributions.</p> <h2 id="using-vprox" data-svelte-h="svelte-1uk36qr">Using vprox</h2> <p>If you’re a developer on Modal, you can get access to our
<a href="https://modal.com/docs/guide/proxy-ips">static IP proxies</a> feature on the Team plan. Just create
a proxy and voilà, you’ve got an outbound IP. No SOCKS5 required!</p>  <p data-svelte-h="svelte-isox7e">Right now each Proxy corresponds to a single static IP address, but we’re
planning to extend this to region-specific proxies where your container may
automatically select an IP from the nearest geographic location to minimize
latency.</p> <p>But this blog post is about the internals, and as mentioned before, we
open-sourced our control plane — how we run WireGuard in production and
integrate it into the Modal serverless function runtime. You can find this in
the <a rel="nofollow" href="https://github.com/modal-labs/vprox">modal-labs/vprox</a> repository on
GitHub. With just a couple commands, you can run a VPN server and any number of
clients. All aspects of the networking are configurable.</p> <p data-svelte-h="svelte-1s8dxqa">A nice thing about this implementation is IP discovery. On AWS, we periodically
poll the instance metadata endpoint to find the IPs attached, so you don’t have
to update this manually. Just run <code>vprox server --cloud aws</code> and watch the magic
happen. (It should be easy to port this code to other cloud providers, but we’ve
only tried deploying on AWS ourselves.)</p> <hr> <p data-svelte-h="svelte-19au1nm">We’re excited to see how you use static IPs at Modal! This project has been fun
for many of us. I’m grateful to my coworker Luis Capelo for deploying vprox
in production, and to our intern Jeffrey Meng for implementing IP discovery and
client reconnection.</p> <p>If you’re interested in crafting reliable, secure systems at scale for the next
generation of cloud infrastructure, <a href="https://modal.com/careers">we’re hiring</a> at Modal.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unlocking the power of time-series data with multimodal models (123 pts)]]></title>
            <link>https://research.google/blog/unlocking-the-power-of-time-series-data-with-multimodal-models/</link>
            <guid>42299590</guid>
            <pubDate>Mon, 02 Dec 2024 19:40:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/unlocking-the-power-of-time-series-data-with-multimodal-models/">https://research.google/blog/unlocking-the-power-of-time-series-data-with-multimodal-models/</a>, See on <a href="https://news.ycombinator.com/item?id=42299590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20241125">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="h3lap">The successful application of machine learning to understand the behavior of complex real-world systems from healthcare to climate requires robust methods for processing <a href="https://en.wikipedia.org/wiki/Time_series" target="_blank" rel="noopener noreferrer">time series</a> data. This type of data is made up of streams of values that change over time, and can represent topics as varied as a patient’s <a href="https://en.wikipedia.org/wiki/Electrocardiography" target="_blank" rel="noopener noreferrer">ECG</a> signal in the <a href="https://en.wikipedia.org/wiki/Intensive_care_unit" target="_blank" rel="noopener noreferrer">ICU</a> or a <a href="https://cloud.google.com/blog/topics/sustainability/weather-prediction-with-ai" target="_blank" rel="noopener noreferrer">storm system moving across the Earth</a>.</p><p data-block-key="djbhr">Highly capable multimodal foundation models, such as <a href="https://deepmind.google/technologies/gemini/pro/" target="_blank" rel="noopener noreferrer">Gemini Pro</a>, have recently burst onto the scene and are able to reason not only about text, like the large language models (LLMs) that preceded them, but also about other modalities of input, including images. These new models are powerful in their abilities to consume and understand different kinds of data for real-world use cases, such as <a href="https://arxiv.org/abs/2404.18416v2" target="_blank" rel="noopener noreferrer">demonstrating expert medical knowledge</a> or <a href="https://arxiv.org/abs/2312.11805" target="_blank" rel="noopener noreferrer">answering physics questions</a>, but haven’t yet been leveraged to make sense of time-series data at scale, despite the clear importance of this type of data. As chat interfaces mature generally across industries and data modalities, products will need the ability to interrogate time series data via natural language to meet user needs. When working with time series data, previous attempts to improve performance of LLMs have included <a href="https://arxiv.org/pdf/2305.15525" target="_blank" rel="noopener noreferrer">sophisticated prompt tuning and engineering</a> or <a href="https://arxiv.org/pdf/2408.07773" target="_blank" rel="noopener noreferrer">training a domain specific encoder</a>.</p><p data-block-key="99bn3">Today we present work from our recent paper, “<a href="https://arxiv.org/abs/2410.02637" target="_blank" rel="noopener noreferrer">Plots Unlock Time-Series Understanding in Multimodal Models</a>”, in which we show that for multimodal models, much like for humans, it is easier to make sense of the data visually by looking at plots of the data rather than sifting through the raw time-series values themselves. Importantly, we show that this does not require any expensive additional training, and instead relies on the native multimodal capabilities of these foundation models. Compared to only using a text format for prompting a multimodal model, we demonstrate that using plots of the time series data can increase performance on classification tasks up to 120%.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Investigation overview</h2>
            
        
        
    </p>



    <p data-block-key="h3lap">We investigated the hypothesis that multimodal models understand time-series data better through their vision encoders than through the textual representation of long arrays of floating point numbers. We tested both synthetic tasks that we devised to allow us to probe specific types of reasoning, and real-world tasks that contain representatively noisy data whose analysis is important for advancing digital health. For each task we ran experiments using a <i>text method</i> and a <i>plot method</i> to prompt the model with the time-series data. The text method used the raw time-series data to create a series of numbers that were used directly to prompt the model. The plot method took the raw time-series data, created a visual plot of that data and then used an image of the plot to prompt the model. To show that this generalizes across different foundation models, we performed experiments on both small and large models of two best-of-class families of frontier models: <a href="https://deepmind.google/technologies/gemini/pro/" target="_blank" rel="noopener noreferrer">Gemini Pro 1.5</a> and <a href="https://openai.com/index/hello-gpt-4o/" target="_blank" rel="noopener noreferrer">GPT4o</a>, and two smaller models <a href="https://deepmind.google/technologies/gemini/flash/" target="_blank" rel="noopener noreferrer">Gemini Flash 1.5</a> and <a href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/" target="_blank" rel="noopener noreferrer">GPT4o-mini</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Real world digital health tasks</h2>
            
        
        
    </p>



    <p data-block-key="h3lap">We tested our approach on anonymized real world data collected from research study participants through mobile or wearable devices for health-relevant tasks.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Detecting falls</h3>
            
        
        
    </p>



    <p data-block-key="h3lap">One such task that we explored was using a publicly available <a href="https://www.frdr-dfdr.ca/repo/dataset/6998d4cd-bd13-4776-ae60-6d80221e0365" target="_blank" rel="noopener noreferrer">IMU (Inertial Measurement Unit) dataset</a> curated and labeled for fall detection, since <a href="https://link.springer.com/article/10.1186/1475-925X-12-66" target="_blank" rel="noopener noreferrer">falls are an important health risk</a>, especially amongst the older and more vulnerable people. <a href="https://en.wikipedia.org/wiki/Inertial_measurement_unit" target="_blank" rel="noopener noreferrer">IMU sensors</a> report six dimensions of acceleration and angular velocity data sampled at over 100Hz and are commonly found in today's smartphones and smartwatches. In this task, we instruct the models to classify the sensor data into normal daily living without a fall, near falls, or actual falls. A <a href="https://pilotfeasibilitystudies.biomedcentral.com/articles/10.1186/s40814-020-00748-1#:~:text=A%20near%2Dfall%20is%20defined,recovery%20manoeuvres%20are%20not%20executed." target="_blank" rel="noopener noreferrer">near fall</a> is characterized as a loss of balance that would result in a fall if sufficient balance recovery maneuvers are not executed. Identifying when a near fall is occurring is important, since older adults may not recognize it as one; <a href="https://www.sciencedirect.com/science/article/abs/pii/S0003999309000860" target="_blank" rel="noopener noreferrer">near falls may also predict the risk of true falls</a>. This particular dataset was deliberately curated to include examples where the user had a near fall, such as a recovering from a slip without actually falling, making it more challenging to determine whether the user actually had a fall.</p><p data-block-key="945oe">This task was structured as a few-shot task, where the model was shown a number of IMU time-series examples for each outcome before being asked to classify an IMU time-series example that it had not seen before.</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="h3lap">Overall the plot method outperformed the text method on this task and, in general, improved as more few-shot examples were provided. This indicated that the models were able to extract additional information from the few-shot examples when they were presented as plots.</p>

    </div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Recognizing physical activity</h3>
            
        
        
    </p>



    <p data-block-key="h3lap">We also used IMU data for a different task, in which we tested the models’ abilities to discriminate the type of physical activity being performed by a user between sitting, standing, using stairs, walking or biking. This kind of <a href="https://ieeexplore.ieee.org/abstract/document/7742959" target="_blank" rel="noopener noreferrer">activity recognition is regularly used</a> in fitness and wellbeing products that users rely on to track and improve their physical health. The <a href="https://dl.acm.org/doi/10.1145/2809695.2809718" target="_blank" rel="noopener noreferrer">publicly available dataset we used</a> was designed to collect IMU data from a variety of different devices such as phones and smartwatches, with this heterogeneity of data sources increasing the difficulty of the classification task.</p><p data-block-key="bemnk">We presented this as a few-shot prompt to the models and, like the fall detection task, we find that the plot-based approach outperforms the text-based method. Again increasing the number of few-shot examples generally increased the plot performance in most models.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Synthetic tasks</h2>
            
        
        
    </p>



    <p data-block-key="h3lap">Having shown that plots improve model performance in contexts that are relevant to digital health, we also investigated model performance in synthetic experiments of our own design. We did this to probe performance generally on tasks of increasing difficulty and reasoning sophistication, ranging from naming the pattern being plotted to multiple choice questions a university calculus student might encounter.</p><p data-block-key="18jce">The simplest synthetic task we used was functional form identification, where the model had to classify a series of data points into the type of underlying function that created it, such as a linear or quadratic. With this relatively simple task the median classification accuracy of the plot method was up to 120% better than the text method, indicating that when presented visually as a plot, the multimodal foundation models could more easily understand the overall trend and discern the underlying function than when they were just provided the raw data.</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="h3lap">A harder task involved synthetic data series where the data was clustered in 1 to 9 discrete clusters and the model was asked to count the number of clusters in the data. The plot method had a 55-85% lower mean absolute error than the text method.</p>

    </div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="h3lap">Additional synthetic tasks we tested include classifying linear correlations and identifying derivatives, which also generally showed that the plot performance was better than, or at least as good as, the text performance.</p>

    </div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>The art of the chart</h3>
            
        
        
    </p>



    <p data-block-key="h3lap">Having shown that for time-series data, the reasoning power of these foundation models are best leveraged through plots, we also investigated whether the models preferred any specific style of plot. We tried many different aesthetic choices such as changing the color scheme, marker size and axis display, but in the end found that there wasn’t a strong dependence of the results on these choices.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>A picture is worth 1,000 words</h3>
            
        
        
    </p>



    <p data-block-key="h3lap">Beyond the performance gain of the models ingesting plots over text, we also found that using plots made more efficient use of the limited context window of the models we studied. The fundamental reason for this is the mechanism in which multimodal models ingest either textual or visual information – when presented as numeric strings, time series data must be split into many granular tokens that the model ingests, while a plotted image is more efficiently represented with fewer tokens. As a result, plotting a time-series made more efficient use of available model context lengths, especially in cases where passing the full textual form of a time-series would generate more tokens than the model can ingest.</p><p data-block-key="3jcsh">We also found that the cost of reasoning about a plotted time-series could be up to 10x cheaper than reasoning about its textual representation, as model API cost increases with the number of input tokens.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Conclusion</h2>
            
        
        
    </p>



    <p data-block-key="h3lap">Our results show that plotting as an approach amplifies the capabilities of multimodal models currently available to consumers to make sense of complicated time-series data. Our work sets the stage for increasing the power of tools and assistants powered by multimodal models to incorporate time-series data for end-user benefit.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Acknowledgements</h2>
            
        
        
    </p>



    <p data-block-key="h3lap"><i>We would like to acknowledge Mayank Daswani for leading this work and all the collaborators across Google including Desislav Ivanov, Mikhail Papkov, Eva Schnider, Jing Tang, Kay Lamerigts, Gabriela Botea, Michael Sanchez, Yojan Patel, Shruthi Prabhakara, Shravya Shetty and Umesh Telang for contributing to the research and to Sebastien Baur, Yun Liu and Diego Ardila for their valuable input. We also want to thank Tiya Tiyasirichokchai for designing the graphic for this post and Dr. Stephen Robinovitch for granting permission to include plots of examples from the IMU Fall Detection dataset.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
    </channel>
</rss>