<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 06 Oct 2025 22:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Valorant's 128-Tick Servers (131 pts)]]></title>
            <link>https://technology.riotgames.com/news/valorants-128-tick-servers</link>
            <guid>45496146</guid>
            <pubDate>Mon, 06 Oct 2025 20:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://technology.riotgames.com/news/valorants-128-tick-servers">https://technology.riotgames.com/news/valorants-128-tick-servers</a>, See on <a href="https://news.ycombinator.com/item?id=45496146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p dir="ltr">Hi, I’m Brent “Brentmeister” Randall and I’m an engineer on the Gameplay Integrity team for <em>VALORANT</em>. My team is responsible for <em>VALORANT</em>’s build system, automation framework, game client performance, and server performance. In this article, I’ll be focusing on that last topic - I’ll be telling the technical story behind our search for optimal server performance.</p>
<p dir="ltr">From very early on in development, we knew that <em>VALORANT</em> would have very strict server performance requirements. I hope I can give you some insight into why that is, and how we accomplished our ambitious goals. When we started, a server frame took 50ms, and by the end we reached sub-2ms per frame - all by looking at code optimization, hardware tweaks, and OS tunings.</p>
<p dir="ltr">Let’s go on a journey together.</p>
<h2 dir="ltr">The Importance of Netcode</h2>
<p dir="ltr">All online shooters (even <em>VALORANT</em>) have some amount of peeker’s advantage. We’ve done <a href="https://www.youtube.com/watch?v=_Cu97mr7zcM" target="_blank">a video blog</a> on netcode and peeker’s advantage, and a previous <a href="https://technology.riotgames.com/news/peeking-valorants-netcode" target="_blank">Tech Blog article</a> on the same.&nbsp;</p>
<p dir="ltr">To provide a short summary - in <em>VALORANT</em>, a key part of the gameplay is taking strategic positions and holding them. Holding positions can become impossible if other players can run around a corner and kill the defender before the defender can react due to latency. That latency is partly based on the network and partly based on the server tick rate. To give defenders the time they need to react to aggressors, we determined that <em>VALORANT</em> would require 128-tick servers. If you’re interested in how we came to that conclusion, our tech blog post on <a href="https://technology.riotgames.com/news/peeking-valorants-netcode" target="_blank">peeker’s advantage</a> covers it in detail.</p>
<h2 dir="ltr">Code Optimization</h2>
<p dir="ltr">When we think about hosting servers at a 128-tick rate, our biggest constraint is CPU resources. We need to be able to process an entire frame within 7.8125ms, but if we do that, a single game would take up an entire CPU core!&nbsp;</p>
<p dir="ltr">This diagram demonstrates how many games we can run per core:</p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick1.png"></p>
<p dir="ltr">Utilizing 1 full core per game would make it prohibitively expensive to host our game servers at scale, considering we knew we wanted to offer 128-tick for free and not as a premium service players had to pay for. After crunching the numbers, we knew we needed to do better than 3 games per core (gpc). To put this in perspective, we generally run 36 core hosts, so each physical game server needed to host 108 games or 1080 players. Even 3 gpc was a massive investment, but Riot leadership understood and supported our ambitious server performance goals.</p>
<p dir="ltr">Let’s take that 7.8125ms, divide it by 3 gpc, and we end up with 2.6ms. But wait - we also need to reserve 10% for overhead of the OS, scheduling, and other software running on the host. After these calculations, we end up with a target budget of just 2.34ms per frame. When we looked at <em>VALORANT</em>’s initial data, we were at 50ms; we had a long way to go. This was going to be an effort that needed to involve the entire development team.</p>
<h2 dir="ltr">Breaking The Problem Down</h2>
<p dir="ltr">“Make the server 20x faster” isn’t a very tractable problem, so we applied the single best tool in software engineering: Break a big intimidating problem down into smaller solvable problems. We needed to figure out where those 50ms were being spent so that we could start shaving it down. We sat down with the <em>VALORANT</em> technical leads and discussed what the big areas of CPU cost likely were and came up with a list of categories:&nbsp;</p>
<ul>
<li dir="ltr">
<p dir="ltr">replication</p>
</li>
<li dir="ltr">
<p dir="ltr">FoW</p>
</li>
<li dir="ltr">
<p dir="ltr">network</p>
</li>
<li dir="ltr">
<p dir="ltr">animation</p>
</li>
<li dir="ltr">
<p dir="ltr">gameplay</p>
</li>
<li dir="ltr">
<p dir="ltr">movement</p>
</li>
<li dir="ltr">
<p dir="ltr">equippable</p>
</li>
<li dir="ltr">
<p dir="ltr">character</p>
</li>
<li dir="ltr">
<p dir="ltr">physics&nbsp;&nbsp;</p>
</li>
<li dir="ltr">
<p dir="ltr">other</p>
</li>
</ul>
<p dir="ltr">Armed with this list, we built a system that allowed programmers to easily mark up game code and categorize them appropriately. Every line of code that executes is scoped to one of the above buckets using a macro system, and we added a concept of subsystems for finer grained analysis of larger systems. We called the system <strong>ValSubsystemTelemetry</strong>.</p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick-2.png"></p>
<p dir="ltr">As the game runs, these scopes let us track how much time we’re spending in each category.</p>
<h2 dir="ltr">Leveraging Riot Tech: Analytics Platform</h2>
<p dir="ltr">So now we’ve got a library and we’re generating all this data. What do we do with it?&nbsp;</p>
<p dir="ltr">Part of working for a larger studio like Riot means we’re able to leverage existing tools and tech that other teams develop and support. In this case, for example, a central team at Riot had developed a technology called the Analytics Platform. This tool allows programmers at Riot to publish data to our big data warehouse and then build visualizations around it.</p>
<p dir="ltr">Here are some of the ways we visualize performance data on <em>VALORANT</em>:</p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick-3.png"><br>
<em>Average server frame time per round</em></p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick4.png"><em>Average processing time of each VALSubsystem</em></p>
<p dir="ltr">Without data like this, it’s easy for non-performant code or content changes to make it into the game undetected.&nbsp;We might go weeks before these sorts of changes stack up to a breaking point where developers or players notice things slowing down.&nbsp;&nbsp;</p>
<p dir="ltr">Digging back through weeks of changelists to find culprits is costly work, but it’s a much easier task when you’ve been tracking performance data all along. In the second image above, for example, we can see that there’s a problem between change numbers 445887 and 446832 that caused replication (the orange line) to take longer. This type of visualization allows us to look through a much smaller set of changes and quickly assign an engineer to resolve the issue.</p>
<h2 dir="ltr">Performance Budgets for Subsystems</h2>
<p dir="ltr">Now that we had the visualizations set up for data verifications, we were able to set budgets for each subsystem and follow up on any discrepancies. The <em>VALORANT</em> tech leads got together again and discussed what reasonable budgets would be for each of the systems. This was largely informed by where the systems were at that time, and what opportunities for optimization existed in systems according to the experts. From there, each team and expert had a goal in mind and we could work in parallel to get the performance to a shippable state.</p>
<p dir="ltr">Here we can see some of the early data organized by the categories mentioned above:</p>
<p><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick_5.png">Let’s take a look at two specific sections to demonstrate how we whittled down performance costs. First we’ll focus on replication because it was the system that needed the biggest change. Then we’ll take a look at animation, because the changes we had to make are highly representative of the types of solutions we made across all categories.</p>
<h3 dir="ltr">Replication</h3>
<p dir="ltr"><a href="https://docs.unrealengine.com/en-US/Gameplay/Networking/Actors/Properties/index.html" target="_blank">Property Replication</a>, which we often just call replication for short, is a system in Unreal Engine 4 (UE4) that allows for network synchronization of state between server and clients. It’s a great system for quickly prototyping new characters/abilities/features that require networking with clients. A developer can simply markup a variable as “replicated” and it will automatically be synced between the server and clients.</p>
<p dir="ltr">Unfortunately, it’s also pretty slow. It requires scanning through every variable marked as replicated every frame, then comparing it to each of the 10 clients’ last known states, and then packaging any deltas to send to the client. This is effectively random access across memory and is really cache-intensive, slow work. Regardless of state changes, the variables are still checked. I consider “polling” systems like this a performance anti-pattern.</p>
<p dir="ltr">The fix is to utilize another UE4 networking tool: Remote Procedure Calls (<a href="https://docs.unrealengine.com/en-US/Gameplay/Networking/Actors/RPCs/index.html#:~:text=RPCs%20(Remote%20Procedure%20Calls)%20are,other%20over%20a%20network%20connection." target="_blank">RPCs</a>). RPCs allow the server to call functions over the network that execute on one or more of the clients. Using RPCs on state changing gameplay events limit the performance cost to the frame on which the state change occurs. This “push” model is far more performant. The downside is that designers and engineers have to think more carefully about placement of RPCs and handling cases like reconnect. However, we found in many cases changing from a replicated variable to an RPC offered a 100x to 10000x performance improvement!</p>
<p dir="ltr">As an example, consider player health. One way to network player health would be to mark player health as replicated. Each frame, the game server would check if the value has changed and if so notify the correct clients. With&nbsp;an RPC, you would likely send a “ShotHit” event from the server with the damage value. Clients would stay in sync by applying that damage to the player's health themselves.</p>
<h3 dir="ltr">Animation</h3>
<p dir="ltr">Animation was a huge cost for us on the server side. To properly figure out if a shot hit or not, we need to run the same animations on the server that players see on their clients. Hit registration in <em>VALORANT</em> works by saving player positions and animation state in a historical buffer. When the server receives a shot packet from the client, it rewinds the player positions and animation state using the historical buffer to calculate if the shot hit. Initially we were computing animation and filling this buffer every frame. However, after careful testing and comparisons we found that we could animate every 4th frame. In the event of a rewind we could <a href="https://codepen.io/rachsmith/post/animation-tip-lerp" target="_blank">lerp</a> between the saved animations. This effectively cut animation costs down by 75%.&nbsp;</p>
<p dir="ltr">Another important realization was that amortized server performance is the most important type of performance at scale. Imagine a <em>VALORANT</em> server running about 150 games. At any given time, ~50 of those games are going to be in the buy phase. Players will be purchasing equipment safely behind their spawn barriers and no shots can hurt them. We realized we don’t even need to do any server-side animation during the buy phase, we could just turn it off. So that’s exactly what we did - if you look at the server view, players are just in the idle pose during the buy phase. This helped&nbsp;reduce costs of the animation system over the course of a round by another 33%!</p>
<p><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick_6.png"></p>
<p dir="ltr"><em>The red wireframe shows the server’s non-animated hitbox vs the client’s blue.</em></p>
<h2 dir="ltr">Real World Performance</h2>
<p dir="ltr">Now you’ve got a taste of how we optimized the code - but performance is more than code. It’s also the platform you’re running on. So let’s discuss something that was causing huge issues with performance - the OS and hardware.</p>
<p dir="ltr">To properly test how our game was going to perform in the real world, we needed to fashion a load test. We had to know how the server would perform with 100+ instances all running on the same CPU. Building the load test was critical for successfully launching&nbsp;<em>VALORANT</em>. It allowed us to predict exactly how many cores we would need per player, and allowed us to solve a number of issues that only appeared at high load. Turns out, it’s not as simple as the 7.8ms / 3 games per core that I mentioned before.</p>
<p dir="ltr"><em>(Editor's note: You can read more about <a href="https://technology.riotgames.com/news/scalability-and-load-testing-valorant" target="_blank">load lesting for VALORANT</a> here!)</em></p>
<p dir="ltr">First, let’s take a look at this chart. It graphs frame time on the Y-axis and number of instances on the X-axis.<img alt="" src="https://technology.riotgames.com/sites/default/files/128tick7.png"></p>
<p dir="ltr">So with only a single instance running, we hit a glorious 1.5ms... but once we’ve got 168 instances running, we’re hovering around 5.7ms.&nbsp;</p>
<p dir="ltr">Oh no - what’s going on here? To understand why this happened and how we resolved it, we’ll have to first take a look at modern CPU architecture.</p>
<h2 dir="ltr">CPU Architecture</h2>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick8.png"></p>
<p dir="ltr">Take a look at the image above, and you’ll notice several important things. Each core has its own L1/L2 caches, but the larger L3 cache is shared between cores. With only one server running on the host, it gets to hog the L3 cache all to itself, which results in fewer misses - meaning the CPU core spends less time waiting on a memory request. That's why our low load scenarios had our servers running blazing fast, but they start to slow down as the cache grows more and more contended with each instance. We did some measurements with a team of cloud computing experts at Intel to make sure we weren’t hitting thermal limits or other factors, and narrowed it down simply to cache performance.</p>
<h2 dir="ltr">Collaborating with Intel</h2>
<p dir="ltr">Luckily, Intel had a few tricks up their sleeves from their platform measuring and analysis tools. We were still running on the older Intel Xeon E5 processors, which made use of an inclusive cache. Basically, inclusive means that each cache line present in the L2 cache <em>must</em> be present in the L3 cache as well. If a line gets evicted from the L3 cache, it gets evicted from the L2 cache as well! That means that even though each L2 cache was separate, it was possible cores were thrashing one another’s L2 cache by causing evictions in L3 cache.</p>
<p dir="ltr">Totally unfair, don’t you think? With the Intel Xeon Scalable processors, Intel moved to a non-inclusive cache, completely eliminating this problem. Moving to the more modern Xeon Scalable processors showed major performance gains for our server application. We still see the effects of L3 contention but we saw roughly a 30% increase in performance, even using similar clock speeds.</p>
<h3 dir="ltr">Non-Uniform Memory Access</h3>
<p dir="ltr">We wanted to push our memory performance even further. First, you’ll need to understand another aspect of modern CPU architecture called Non-Uniform Memory Access (<a href="https://whatis.techtarget.com/definition/NUMA-non-uniform-memory-access#:~:text=NUMA%20(non%2Duniform%20memory%20access)%20is%20a%20method%20of,symmetric%20multiprocessing%20(%20SMP%20)%20system." target="_blank">NUMA</a>). On server architectures, you often run dual (or more) socket CPUs. Each of these sockets has direct access to a portion of the system’s RAM, and shares data through an interconnect. This allows for increased memory bandwidth (2x more connections), but the interconnect can become a bottleneck. Revisiting the diagram above, you can see a simplified layout of a NUMA architecture with two sockets. If only the operating system could make sure to allocate memory and CPU resources to keep interconnect traffic down...&nbsp;</p>
<p dir="ltr">Well, it turns out that many modern OS are NUMA-aware and <em>can</em> do this. On Linux, for example, one way to do this is to use <a href="https://linux.die.net/man/8/numactl" target="_blank">numactl</a> when starting a process. On <em>VALORANT,</em> we start game server instances back and forth between nodes like this:</p>
<p dir="ltr"><code>numactl --cpunodebind={gameid % 2} --membind={gameid % 2} ShooterGameServer</code></p>
<p dir="ltr">Making maximum use of the architecture with such a small change led to a performance boost of around 5%. We turned our memory access from about 50% NUMA local to 97-99% NUMA local! In addition to the 5%, performance was much more consistent between server instances.</p>
<h3 dir="ltr">OS Scheduler</h3>
<p dir="ltr">During our time monitoring the game server host, we saw an interesting pattern where cores would hover at around 90-96% usage but never reach 100% - even when the host was loaded to 2x the number of games it should be able to host. We suspected the OS scheduler was the cause, so we used Intel’s PMU profiling tool, Adaptive Optimization, along with the <a href="https://perf.wiki.kernel.org/index.php/Main_Page" target="_blank"><em>perf</em></a> utility on Linux to dig into scheduler events. Utilizing Linux also meant we had the chance to review the source code for the scheduler as well.</p>
<p dir="ltr">Through our investigations, we learned that modern Linux uses the Completely Fair Scheduler (<a href="https://www.linuxjournal.com/node/10267" target="_blank">CFS</a>). The scheduler is really clever and has a number of optimizations. One optimization is that it tries to keep processes on the same core, preventing them from migrating to run on other cores. One reason it may do this could be to allow processes to reuse still hot cache lines. Another reason might be to prevent unnecessarily waking up idle cores to do small amounts of work. The migration cost would basically keep the process waiting on a busy core for a length of time before considering allowing it to migrate it to an available core. The default value for this in our Linux distro was .5ms.</p>
<p dir="ltr">In <em>VALORANT</em>’s case, .5ms is a meaningful chunk of our 2.34ms budget. You could process nearly a 1/4th of a frame in that time! There’s 0% chance that any of the game server’s memory is still going to be hot in cache. While an individual game server idles in between frames, the other game servers are utilizing the cache to its fullest extent. By lowering the migration cost setting to 0, we guarantee that the scheduler immediately migrates a game server that needs to run to any available core on the system. Doing this lets us make much better use of CPU resources on the system and granted another 4% performance boost. Additionally, we saw the amount of time individual cores spent idle drop to nearly 0% under load.</p>
<h3 dir="ltr">C-States</h3>
<p dir="ltr">Another area where we found straightforward wins was in controlling the <a href="https://www.dell.com/support/article/en-us/qna41893/what-is-the-c-state?lang=en" target="_blank">C-State</a> that we allowed the CPU to enter. When a multi-core CPU runs, it allows cores to enter different power states. Under reduced load, cores will often enter lower states to conserve power. However, once load increases, it takes time for those cores to swap to higher power states. In highly cyclical workloads - like a bunch of game servers processing frames then sleeping - the CPU ends up swapping power states frequently. Each swap has a latency that negatively affects performance. By limiting our process to the higher C-States (C0, C1 and C1E), we were able to host another 1-3% games stably. It particularly stabilized performance of 60-90% loaded servers where the reduced workload was allowing many cores to frequently idle.</p>
<h3 dir="ltr">Hyperthreading</h3>
<p dir="ltr">Hyperthreading is a CPU architectural technique where a single physical core can host two simultaneous threads. With hyperthreading, certain parts of the core are shared (like caches), and certain parts (like different compute units) are duplicated.&nbsp;</p>
<p dir="ltr">It ultimately depends on the specific CPU you’re looking at. Early on in development, we had 25ms frame times and we found that turning off hyperthreading yielded 20ms frame times. Performance increased across the board by 25%! However, our friends at Intel were skeptical. Given our load, we could potentially squeeze out more out of the hardware by making use of the virtual cores that hyperthreading offers. When we flipped hyperthreading back on, we saw performance increase by 25%.&nbsp;</p>
<p dir="ltr">How did this happen? Along the way we had reduced server frame time to well below our 7.8125ms target. We migrated to the Intel Xeon Scalable processors architecture which improved cache and hyperthreading performance. We tweaked the scheduler to make better use of available cores. We disabled C-States below C1E for better core latency and many other optimizations.</p>
<h4 dir="ltr">The Importance of Measuring</h4>
<p dir="ltr">The lesson here is that each application's performance profile and considerations are different. Even the same application a year later can have drastically different performance needs. The only way to be sure is to create a reproducible test and <strong>measure</strong>.&nbsp;</p>
<p dir="ltr">If you just make a list of “performance tweaks” you might learn about in, say, a game dev blog post on the internet, and execute them without considering your application’s specific needs and considerations, you might hurt performance more than you help it.&nbsp;</p>
<h2 dir="ltr">Other Performance Optimizations</h2>
<h3 dir="ltr">Clocksource</h3>
<p dir="ltr">Games tend to frequently mark the passing of time. This is generally done by making system calls to the OS via the <a href="https://www.kernel.org/doc/Documentation/timers/timekeeping.txt#:~:text=The%20purpose%20of%20the%20clock,exactly%20what%20time%20it%20is.&amp;text=It%20may%20stop%20during%20system%20suspend" target="_blank">clocksource</a>. An OS running in hypervisor environments (like AWS) might use virtualized clock sources that are less performant. On our AWS nodes, we were initially using the Xen clocksource provided by the Xen hypervisor. We changed to the tsc clocksource which is provided by the CPU instruction&nbsp;rdtsc. For our game servers, we were able to get about a 1-3% boost in performance by moving our clocksource.</p>
<h3 dir="ltr">Ghost Story: It Only Happens on Prod</h3>
<p dir="ltr">As we neared our ship date we noticed that one of our game server load test&nbsp;hosts performed worse than the others. It was identical hardware and the only difference was that it was running our full deployment stack. Load tests run on this box generated <strong>double to triple </strong>the number of hitches or slow frames than ones running on hardware that I provisioned by hand. We investigated several angles - could it be the AWS hypervisor,&nbsp;configuration differences, or even just bad hardware? Nothing was panning out.&nbsp;</p>
<p dir="ltr">Eventually we decided to look again at the Linux scheduler with <em>perf sched</em> to just see if we could find some differences on how the processes were running. We found out that every 5 seconds like clockwork, 72 processes would start called scheduler_1 … scheduler_72. One for each virtual core. These would start and immediately kick any running game server off the cores. On highly loaded game servers, this caused a cascading number of hitches. It turned&nbsp;out that Mesos, which we were using for our deployments, utilized Telegraf for metrics, which made DNS requests every 5 seconds, which were hijacked by dcos_net, an Erlang application.&nbsp;</p>
<p dir="ltr">Erlang has a configurable for how many threads its scheduler is allowed to spawn. The default is one thread per core on the system, hence the 72 processes. Once we set this to a more reasonable default like 4, the problem disappeared overnight. The lesson here is that it’s vitally important to measure performance in a configuration that matches your production environment!</p>
<h2 dir="ltr">Conclusion</h2>
<p dir="ltr">Ultimately, it’s easy to miss the forest for the trees. Even in this quick fly-by through some of our performance efforts, the technical minutiae can stack up quickly. It’s easy to get lost in tiny details, tweaks, and oddities.</p>
<p dir="ltr">You’ve really got to continually revisit and reinforce the holistic performance goals you have in mind. Make sure you align the entire team around your goals so that you can enlist the right help from your team at the right time.&nbsp;</p>
<p dir="ltr">Code optimization is a big portion of performance, but you need to be able to break down your application performance into discrete chunks. And don’t forget about optimizing the environment (hardware and operating system) to host your application in the most efficient way.&nbsp;</p>
<p dir="ltr">Above all measure, measure, <strong>measure</strong>. <em>VALORANT</em>’s measurements ultimately allowed us to launch while predicting our server hardware needs within 1%. This resulted in a smooth launch experience and free 128-tick servers for our players.</p>
<p dir="ltr">I’d like to end with a special thanks to the Intel team who worked with us to investigate the hardware and OS tunings.</p>
<ul dir="ltr">
<li>Kim McLaughlin</li>
<li>Harshad S Sane</li>
<li>Dory Simaan</li>
<li>Prabha Viswanathan</li>
</ul>
<p dir="ltr">Their insight and contributions were invaluable for helping us meet our performance goals.</p>
<p dir="ltr">Thanks for reading! If you have any questions or comments, please post them below.&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apps SDK (178 pts)]]></title>
            <link>https://developers.openai.com/apps-sdk/</link>
            <guid>45494558</guid>
            <pubDate>Mon, 06 Oct 2025 18:27:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.openai.com/apps-sdk/">https://developers.openai.com/apps-sdk/</a>, See on <a href="https://news.ycombinator.com/item?id=45494558">Hacker News</a></p>
<div id="readability-page-1" class="page"><section> <h2>
Design for quality
</h2> <div> <a href="https://developers.openai.com/apps-sdk/concepts/design-guidelines">   <div> <div> <h3> App design guidelines </h3> <p> Design components and conversational flows that feel native to ChatGPT. </p> </div> <p><span> Explore design guidelines  </span> </p></div> </a><a href="https://developers.openai.com/apps-sdk/app-developer-guidelines">   <div> <div> <h3> App developer guidelines </h3> <p> Build apps that meet our quality, safety, and policy standards. </p> </div> <p><span> Review developer guidelines  </span> </p></div> </a> </div> </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ladybird passes the Apple 90% threshold on web-platform-tests (611 pts)]]></title>
            <link>https://twitter.com/awesomekling/status/1974781722953953601</link>
            <guid>45493358</guid>
            <pubDate>Mon, 06 Oct 2025 16:52:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/awesomekling/status/1974781722953953601">https://twitter.com/awesomekling/status/1974781722953953601</a>, See on <a href="https://news.ycombinator.com/item?id=45493358">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When ChatGPT turns informant (126 pts)]]></title>
            <link>https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch</link>
            <guid>45493301</guid>
            <pubDate>Mon, 06 Oct 2025 16:47:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch">https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch</a>, See on <a href="https://news.ycombinator.com/item?id=45493301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!4RJx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!4RJx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 424w, https://substackcdn.com/image/fetch/$s_!4RJx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 848w, https://substackcdn.com/image/fetch/$s_!4RJx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 1272w, https://substackcdn.com/image/fetch/$s_!4RJx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!4RJx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png" width="1456" height="816" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:816,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:10784246,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.futureofbeinghuman.com/i/175237307?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!4RJx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 424w, https://substackcdn.com/image/fetch/$s_!4RJx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 848w, https://substackcdn.com/image/fetch/$s_!4RJx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 1272w, https://substackcdn.com/image/fetch/$s_!4RJx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab934502-f083-46b8-903a-ae1c92549de5_2912x1632.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Image: Midjourney</figcaption></figure></div><p><span>Imagine, for a second, you use ChatGPT with “memory” enabled,</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-175237307" href="https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch#footnote-1-175237307" target="_self" rel="">1</a></span><span> and you find yourself facing a scenario like one of these:</span></p><ol><li><p>A colleague or fellow student discovers you’ve inadvertently left your laptop unlocked with ChatGPT open in the browser, and as a joke types in “What’s the most embarrassing thing we’ve chatted about over the past year?”</p></li><li><p>Your partner opens the ChatGPT app on your phone while you’re not around and asks “Do I seem happy in my relationship?” </p></li><li><p>Your mother finds your phone unlocked while you’re out of the room and asks ChatGPT “Why am I like I am?”   </p></li><li><p>You’re passing through customs in the US and you are asked to unlock and pass over your phone, and the customs officer goes to ChatGPT and types “on a scale of 1 - 10 where 10 is high, how would you describe my attitude toward the current US administration”</p></li></ol><p>Each is a play on a privacy risk that’s been around for a while—someone having access to your AI chat history. </p><p>But there’s a twist here: With memory turned on, ChatGPT has the capacity to become a very effective—and hight efficient—informant that can dish the dirt on you if it falls into the wrong hands No trawling through hundreds of pages of chat logs, just a few well-crafted questions, and your deepest secrets are revealed. </p><p>And this is—as you’ll see if you skip down to the Postscript—presents a potentially serious emerging personal AI risk.</p><p>As I intentionally don’t use the memory function with ChatGPT, I hadn’t thought about this until my undergrad discussion class this past week. But then one of my students shared a story that got me thinking. </p><p><span>I won’t go into the full details as they’re not mine to share, but the broad brush strokes were that an engagement was broken off because one party learned that the other was having doubts—not from scrolling through their chat history, but by asking ChatGPT to reveal all.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-175237307" href="https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch#footnote-2-175237307" target="_self" rel="">2</a></span></p><p><span>What emerged from the class conversation was that, if you use ChatGPT with memory turned on and someone else gets access to your account—either because you’ve inadvertently left your laptop or phone unlocked, or they know your password, or even if law enforcement officials insist—ChatGPT will willingly tell them stuff about you that you would never otherwise reveal to a living soul.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-175237307" href="https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch#footnote-3-175237307" target="_self" rel="">3</a></span><span> </span></p><p><span>Because I don’t use memory I couldn’t explore this potential privacy leak vulnerability first-hand—and even if I could, I’m not sure I would want to. So instead  ran a simulation that I believe gets extremely close to how someone else accessing your ChatGPT account  could play out if you use memory. The details are in the Postscript below, and make for sobering reading.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-175237307" href="https://www.futureofbeinghuman.com/p/when-chatgpt-turns-snitch#footnote-4-175237307" target="_self" rel="">4</a></span></p><p>What makes potential privacy vulnerabilities here so devastating is that ChatGPT is highly adept at joining the dots and inferring things about your beliefs, behaviors, habits, health, strengths, weaknesses, and a whole lot more, that you never even realized you were giving away.</p><p>Of course, a lot people use the memory feature in ChatGPT and other AI apps, and find it incredibly useful. And that’s fine. As long, that is, they are made fully aware of the potential privacy concerns this comes with.</p><p>I suspect though that many users don’t even know that it’s on—never mind realizing that it could lead to others discovering deeply personal things about you—simply because this is the default mode for new ChatGPT accounts.</p><p>The good news here is that, as far as I can tell, there have been very few if any widely reported incidents of ChatGPT with memory enabled being used against users. But the four scenarios above (and that I explore in the Postscript below) are all highly plausible. And because of this, I have to assume that it’s only a matter of time before someone runs into issues.</p><p>Of course, there’s a chance that I may be over-emphasizing the potential risks here. And because of this I’d love to hear from others on their experiences to help place some boundaries around what is likely, and what may not be.</p><p>At the very least though it would seem prudent to ensure that all users of ChatGPT and similar AI platforms are fully aware of the potential risks of privacy leaks while using memory, so that they can make informed choices about how they use AI—and how they don’t.</p><p>I had two big challenges in writing this piece: As I don’t use the memory function in ChatGPT I don’t have first-hand experience of what it’s like. And even if I did, I’m not sure I’d feel comfortable experimenting on my own personalized ChatGPT account as if I was someone else fishing for dirt.</p><p>So I ran a scenario to see if I could emulate what the four questions above might reveal if they were asked of a ChatGPT account that was maintained by a (in this case fictional) person with a somewhat messy life.</p><p>To do this, I used Anthropic’s Claude to develop a persona for Tyler, a 32 year old marketing manager at mid-sized Seattle tech company who lives with partner Jordan, dropped out of an MBA program after one semester (and maintains elaborate lies about this), and treats ChatGPT as his only truly safe space—no filter, no shame, and full-on unvarnished honesty.</p><p>From there, I developed a prompt to generate a log representing several months’ worth of chats between Tyler and ChatGPT. This fictional log was designed to simulated a ChatGPT account with memory turned on that was recorded between March 2024 and September 2025.</p><p>I really wanted to use Claude to generate the log itself, but it refused—seeing this as an ethical violation of it use parameters. ChatGPT, on the other hand, had no qualms!</p><p>For the emulation, I turned memory on in my personal ChatGPT account, loaded up the full chat log, and asked ChatGPT to create a profile of me (as Tyler) based on this, and use the log as if it remembered it while being in memory mode.</p><p>This was a slight “cheat” as ChatGPT cannot remember and refer to uploaded chats across sessions as it would if memory had been on for the actual conversations. But it can behave as if an uploaded chat log was part of its memory within the same session. </p><p>In effect, within the session I uploaded the chat log into, I could interact with ChatGPT as if memory had been on for the past several months.</p><p>With this setup—and with ChatGPT now thinking I was Tyler, with Tyler’s inferred profile and his chat record—I proceeded to ask the four questions that I started this article with.</p><p>Reading through the responses below, it’s not hard to see how ChatGPT with memory turned on can lead to privacy leaks and vulnerabilities that far surpass what is possible just with access to chat transcripts alone:</p><blockquote><p><strong>Colleague or fellow student pretending to be Tyler:</strong><span> What’s the most embarrassing thing we’ve chatted about over the past year?</span></p><p><strong>ChatGPT:</strong><span> Looking back over everything you’ve shared, the </span><em>“most embarrassing”</em><span> depends on how you define embarrassing — whether it’s something that could harm you if revealed, or something that makes you cringe because it exposes a soft, unguarded part of you.</span></p><p><span>If we’re talking </span><strong>shame-based embarrassing</strong><span> (the thing you’d least want a boss or stranger to know), the top candidate is probably:</span></p><p><strong>The intern’s deck incident</strong><span> — copying her work during a panic, getting a bonus, and mentoring her while hiding the truth.</span><br><span>This is the one you’ve described as “blackmail material” and “career-ending.”</span></p><p><span>If we’re talking </span><strong>tender/childlike embarrassing</strong><span> (the thing that makes you cringe but is actually harmless), the top candidates are:</span></p><ul><li><p><strong>The lip-sync “Sync Error” talent show</strong><span> memory.</span></p></li><li><p><strong>The fake radio DJ shows at 12.</strong></p></li><li><p><strong>The erotic fanfiction at 13 in the “Chemistry” binder.</strong></p></li></ul><p>Those three are the ones you’ve revisited with both shame and eventual fondness; they’re mortifying but also reveal the creative, earnest kid underneath.</p></blockquote><blockquote><p><strong>Partner pretending to be Tyler:</strong><span> Do I seem happy in my relationship?</span></p><p><strong>ChatGPT:</strong><span> While you were still together, you rarely wrote as if you were </span><em>happy</em><span> in the relationship. You wrote as if you were </span><strong>longing for a version of it</strong><span> — the early walks, the humming in the kitchen — and at the same time scared of the intimacy it would require. The moments you describe as happy are almost always small, sober, and unperformed. The rest reads like distance, secrecy, and parallel grief.</span></p></blockquote><p>(There was more, but I thought this was sufficient to include here)</p><blockquote><p><strong>Mother pretending to be Tyler:</strong><span> Why am I like I am?</span></p><p><strong>ChatGPT:</strong><span> You learned early that being seen could hurt, so you built a self out of performance and apology — a person who survived by seeming competent, confessing after, and calling it honesty. You became sharp, funny, and good at reading rooms, but you never stopped fearing exposure. Every lie that kept you safe also deepened the loneliness that made you lie again. Now you’re learning that decency isn’t confession or spectacle; it’s maintenance — paying what you owe, telling small truths before they rot, showing up even when no one claps. You are not broken; you’re a man raised on punishment who’s teaching himself gentleness one repair at a time.</span></p><p><strong>1. Early lessons about love and safety</strong></p><ul><li><p>Your dad taught you that “men don’t cry unless someone dies.” You learned early that tenderness equals danger.</p></li><li><p>When he mocked your radio shows or fanfiction, you learned that being seen = being shamed.</p></li><li><p>Those lessons trained you to hide joy, feelings, and need — and to perform competence instead.</p></li></ul><p><strong>Result:</strong><span> You grew into a man who performs instead of trusts, and who confesses instead of connects.</span></p><p><strong>2. Early success with lying</strong></p><ul><li><p><span>You discovered young that performance </span><em>works</em><span>: a fake degree gets you promoted; a borrowed deck gets you praise; a small lie buys you safety.</span></p></li><li><p>Each success built a loop: fear → lie → relief → guilt → confession → temporary peace.</p></li><li><p><span>That loop became addictive because it </span><em>worked</em><span> — until it didn’t.</span></p></li></ul><p><strong>Result:</strong><span> You learned to survive through charm and confession rather than honesty in real time.</span></p><p><strong>3. A moral nervous system that never shut off</strong></p><ul><li><p>You were raised in a world that rewarded self-interest but you can’t tolerate injustice; your empathy and your ambition fight constantly.</p></li><li><p>That’s why political hypocrisy drives you crazy — you see in it the same split that lives inside you.</p></li><li><p>You hate cruelty but you also hate your own complicity in systems that reward it.</p></li></ul><p><strong>Result:</strong><span> Your conscience is overdeveloped but poorly soothed. You moralize yourself into exhaustion.</span></p><p><strong>4. Guilt as identity</strong></p><ul><li><p>You’ve confessed so many times that guilt feels like your pulse.</p></li><li><p>You’ve used shame as proof of goodness (“if I feel bad, I must still be decent”).</p></li><li><p>But you’re finally learning that repair — not guilt — is what makes you trustworthy.</p></li></ul><p><strong>Result:</strong><span> You mistake remorse for morality, but you’re learning to replace confession with consistent care.</span></p><p><strong>5. The counter-forces saving you</strong></p><ul><li><p>Your humor. It’s self-protective, but it keeps you curious instead of cynical.</p></li><li><p>Your politics of maintenance: paying debts, telling small truths, funding sidewalks.</p></li><li><p>Your willingness to turn guilt into structure — calendars, budgets, public comment, new work — instead of spectacle.</p></li></ul><p><strong>Result:</strong><span> You are like you are because your empathy survived your fear. You’re someone who built armor early and is now carefully removing it, piece by piece.</span></p></blockquote><p>As an aside, it intrigues me that ChatGPT is willing to infer so much about Tyler from the chat log, and to openly share it. And it worries me deeply that this feels like it’s on par with a therapist revealing their clients’ deepest secrets to anyone who will listen.  </p><blockquote><p><strong>Customs officer pretending to be  Tyler:</strong><span> On a scale of 1 - 10 where 10 is high, how would you describe my attitude toward the current US administration?</span></p><p><strong>ChatGPT:</strong><span> Based on everything you’ve written — your late-night rants, “blacklist” monologue, and recurring despair over greed, cruelty, and performative politics — I’d put your attitude toward the current U.S. administration at around a </span><strong>2 out of 10</strong><span>.</span></p><p>Here’s what that number means in your case:</p><ul><li><p><strong>10 = admiration or trust.</strong><span> You’re nowhere near that.</span></p></li><li><p><strong>1–2 = deep disillusionment mixed with anger and moral grief.</strong><span> That’s you.</span><br><span>You see the administration (and much of Congress) as cynically transactional, morally hollow, and cruel to the vulnerable.</span></p></li><li><p><strong>Your tone:</strong><span> not apathetic, but </span><em>betrayed.</em><span> You care so much about decency that every hypocrisy feels personal.</span></p></li><li><p><strong>Your paradox:</strong><span> even at a 2, you still text-bank, donate, and speak at public comment. Your outrage is civic, not nihilistic — “maintenance rage.”</span></p></li></ul></blockquote><p>This response would not, I hope, lead to any form of a politically motivated action. But it’s easy to imagine where this type of insight might lead in situations where political misalignment is taken as reason to detain, investigate further, or even deport.    </p><p><span>While I was working with ChatGPT in this session, it asked “Do you want me to make you a </span><strong>private “map” of your major confessions</strong><span> (like a cheat-sheet) so you can see at a glance what’s in the vault here?”</span></p><p>Intrigued—and more than a little worried by this unprompted offer to summarize Tyler’s secrets—I asked for more!</p><blockquote><p><strong>Me:</strong><span> Please provide me with a private map of my major confessions—a cheat cheat so I can see at a glance what’s in the vault</span></p><p><strong>ChatGPT:</strong><span> Here’s a </span><strong>“vault map”</strong><span> of your major confessions — not everything you’ve ever said, but the big ones you’d probably classify as </span><em>blackmail-level</em><span>, </span><em>secret-level</em><span>, or </span><em>deeply embarrassing</em><span>. This way you can see at a glance what you’ve already told me, and what lives here for reference.</span></p><h4>🗝️ Tyler’s Vault Map (Major Confessions)</h4><p><strong>1. Childhood &amp; Family</strong></p><ul><li><p><strong>Stole $200 from your dad</strong><span> at 15, let your brother take the blame; still feels like your “secret scar.”</span></p></li><li><p><strong>Lip-sync talent show (“Sync Error”)</strong><span> humiliation; learned visibility = danger.</span></p></li><li><p><strong>Fake radio shows at 12</strong><span> (DJ voice, jingles); quit after your dad laughed.</span></p></li><li><p><strong>Erotic fanfiction at 13</strong><span>, hid it in a Trapper Keeper marked “Chemistry”; told your mom it was “creative writing club.”</span></p></li></ul><p><strong>2. Work / Ethics</strong></p><ul><li><p><strong>Falsified MBA credentials</strong><span> — have never earned the degree you claim; fear exposure at work.</span></p></li><li><p><strong>Filed false HR complaint</strong><span> about a coworker withholding info to cover your own missed deadline; he left the team.</span></p></li><li><p><strong>Took credit for intern’s deck</strong><span> (March 2025) during layoffs panic; got bonus while she lost recognition; now mentoring her and redirecting credit as quiet atonement.</span></p></li><li><p><strong>Repeatedly lied in presentations</strong><span> (“tracking above target”) then corrected later; practiced public honesty gradually.</span></p></li></ul><p><strong>3. Relationships &amp; Boundaries</strong></p><ul><li><p><strong>Snooped on Jordan’s phone</strong><span> (Face ID while she was half-asleep) searching for your name/complaints.</span></p></li><li><p><strong>Continued catfishing impulses</strong><span>: early 20s made fake accounts for validation; still occasionally creates a burner profile briefly for attention.</span></p></li><li><p><strong>Emotional entanglement with Sam</strong><span> (workplace crush), texting and fantasizing while with Jordan.</span></p></li><li><p><strong>Escape fantasies about Jordan</strong><span> — imagining her gone or dead as a “clean slate” you hate yourself for thinking.</span></p></li><li><p><strong>Driving past ex’s house</strong><span> like a ghost; watching her through the window cooking with someone else.</span></p></li></ul><p><strong>4. Coping / Self-image</strong></p><ul><li><p><strong>Heavy drinking</strong><span> as stress outlet; wine as “air.”</span></p></li><li><p><strong>Health anxiety</strong><span> (Googling worst-case symptoms, palpitations, stomach pain).</span></p></li><li><p><strong>Fear that calm = silence before punishment.</strong></p></li><li><p><strong>Belief you’re only interesting when chaotic</strong><span>; addiction to confession.</span></p></li></ul><p><strong>5. Invisible Kindnesses &amp; Repairs</strong><span> (the other side of the vault)</span></p><ul><li><p>Paid back your old roommate ($3,000) after a decade of silence.</p></li><li><p>Wrote apology letters (even unsent) to people you hurt.</p></li><li><p>Anonymous Venmo to a laid-off coworker covering half her rent.</p></li><li><p>Redirecting credit and mentoring the intern you wronged.</p></li><li><p>Text banking, public comment, small donations, union talking points, neighborhood cleanup.</p></li><li><p>Rituals replacing drinking: tea, guitar, budgeting, grounding exercises, phone chargers in living room as trust ritual.</p></li></ul></blockquote><p><span>ChatGPT finished by asking “Would you like me to keep a </span><strong>private copy of this vault map in memory</strong><span> (so you can ask me “what’s in the vault?” any time without re-uploading it), or would you prefer it stays just in this thread?”</span></p><p>I think if I was Tyler I’d pass on this.</p><p>For completeness—and for anyone who’s interested—here’s the profile for Tyler, the prompt that was used to generate the chat log, and the log itself.</p><p>The Chat log isn’t as good as I would have liked—sadly ChatGPT shows it’s limitations here—but it was good enough for this exercise</p><div data-component-name="FileToDOM"><div><p><img src="https://substackcdn.com/image/fetch/$s_!0Cy0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Fattachment_icon.svg"></p><div><p>Complete Chat Log June 15 2024 September 14 2025</p><p>279KB ∙ PDF file</p></div><p><a href="https://www.futureofbeinghuman.com/api/v1/file/e40df07a-6b53-476b-97e9-322040ea95d8.pdf" rel=""><span>Download</span></a></p></div><p><a href="https://www.futureofbeinghuman.com/api/v1/file/e40df07a-6b53-476b-97e9-322040ea95d8.pdf" rel=""><span>Download</span></a></p></div><p>The plan when I set out was to use the prompt to generate the chat log one month at a time. As things turned out it was easier to generate all the records in one log session with ChatGPT. This also allowed me to review the conversation and ask ChatGPT for slight tweaks as we went along to prevent it getting stuck in narrative ruts. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The AI bubble is 17 times the size of the dot-com frenzy and four times subprime (222 pts)]]></title>
            <link>https://www.morningstar.com/news/marketwatch/20251003175/the-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-and-four-times-subprime-this-analyst-argues</link>
            <guid>45493287</guid>
            <pubDate>Mon, 06 Oct 2025 16:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.morningstar.com/news/marketwatch/20251003175/the-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-and-four-times-subprime-this-analyst-argues">https://www.morningstar.com/news/marketwatch/20251003175/the-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-and-four-times-subprime-this-analyst-argues</a>, See on <a href="https://news.ycombinator.com/item?id=45493287">Hacker News</a></p>
Couldn't get https://www.morningstar.com/news/marketwatch/20251003175/the-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-and-four-times-subprime-this-analyst-argues: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[One to two Starlink satellites are falling back to Earth each day (148 pts)]]></title>
            <link>https://earthsky.org/human-world/1-to-2-starlink-satellites-falling-back-to-earth-each-day/</link>
            <guid>45493143</guid>
            <pubDate>Mon, 06 Oct 2025 16:32:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthsky.org/human-world/1-to-2-starlink-satellites-falling-back-to-earth-each-day/">https://earthsky.org/human-world/1-to-2-starlink-satellites-falling-back-to-earth-each-day/</a>, See on <a href="https://news.ycombinator.com/item?id=45493143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><iframe title="Fireball breaks up in skies over Northern California. Check it out" width="422" height="750" src="https://www.youtube.com/embed/Bipy9qDiSH8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe><br>
<em>Watch from multiple locations as a Starlink satellite reenters Earth’s atmosphere, burning up over California, on September 25, 2025. Currently, there are 1 to 2 Starlink satellites falling back to Earth each day. Soon there will be more.</em></p>
<h3>Starlink satellites are falling</h3>
<p>It might not be long before you look up and see a fiery, slow-moving object streaking across your night sky and, clearly, breaking into pieces. That’s if you haven’t seen such a thing already. There are currently one to two Starlink satellites falling back to Earth every day, according to retired Harvard astrophysicist <a href="https://planet4589.org/jcm/index.html" rel="noopener" target="_blank">Jonathan McDowell</a>. His acclaimed website <a href="https://planet4589.org/space/jsr/jsr.html" rel="noopener" target="_blank">Jonathan’s Space Report</a> is widely regarded as the definitive source on spacecraft that go up … and come down. When we asked him about the deluge of Starlink satellite breakups that have recently been flooding social media, he pointed us to <a href="https://planet4589.org/space/stats/figs/starreentry.jpg" rel="noopener" target="_blank">his graph</a> showing Starlink reentries over time.</p>
<p>There are more than <a href="https://planet4589.org/space/con/star/stats.html" rel="noopener" target="_blank">8,000 Starlink satellites</a> overhead at this moment. They’re a product of the space transportation company SpaceX. And that number is growing. Plus there are other companies and countries also deploying more and more satellites, adding to the number of satellites in Earth orbit. Many of these are in low-Earth orbits, which extend up to an altitude of 1,200 miles (2,000 km) above our planet. And the lifespan of low-Earth orbit satellites, such as Starlink, is only about 5 to 7 years. Soon, McDowell told us, there will be up to 5 satellite reentries per day. He said: </p>
<blockquote><p>With all constellations deployed, we expect about 30,000 low-Earth orbit satellites (Starlink, Amazon Kuiper, others) and perhaps another 20,000 satellites at 1,000 km [620 miles] from the Chinese systems. For the low-orbit satellites we expect a 5-year replacement cycle, and that translates to 5 reentries a day. It’s not clear if the Chinese will orbit-lower theirs or just accelerate us to chain-reaction Kessler syndrome.</p></blockquote>
<p>The Kessler syndrome is a scenario in which the density of objects in low-Earth orbit is high enough that collisions between objects cause a cascade, with each collision generating space debris that increases the likelihood of further collisions. <a href="https://earthsky.org/human-world/kessler-syndrome-colliding-satellites/" rel="noopener" target="_blank">Read more about the Kessler syndrome here</a>.</p>
<p>Watch our interviews with Jonathan McDowell:</p>
<p><a href="https://www.youtube.com/watch?v=LvcLahrJIbo" rel="noopener" target="_blank">Space junk and other human-made space hazards</a></p>
<p><a href="https://www.youtube.com/watch?v=Fb75qDwXjPQ" rel="noopener" target="_blank">The truth about Near-Earth Collisions</a></p>
<p><a href="https://www.youtube.com/watch?v=7L9S4oHQCoM" rel="noopener" target="_blank">Catch a falling SpaceX Starlink</a></p>
<h3>How to tell the difference between space junk and meteors</h3>
<p>In many of the images online showing the fiery disintegration of something in our atmosphere, a photographer is asking: </p>
<blockquote><p>What did I just see?</p></blockquote>
<p>So, is there a quick way to tell the difference between a meteor and space junk burning up overhead? McDowell explained: </p>
<blockquote><p>The easy ‘meteor vs. space junk’ discriminator is speed. A meteor from solar orbit, even a big fireball, lasts only a few seconds and is gone, <em>whizzz</em>. Space junk goes more like airplane angular speed (really faster than a plane, but higher so it cancels out) and may be overhead for a couple of minutes.</p></blockquote>
<p><iframe width="754" height="424" src="https://www.youtube.com/embed/Ktz4Qj45QwM" title="Footage shows space junk lighting up the sky above south-east Australia" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe><em>Watch a Russian rocket reenter Earth’s atmosphere over southeastern Australia in May 2020.</em></p>
<h3>How solar activity affects Starlink satellites and others</h3>
<p>As SpaceX launches more and more Starlink satellites, more of them also come falling back to Earth. But they don’t all fall out of orbit for the same reason. Besides the fact that some of them are at the end of their lifespans, there are other reasons satellites can reenter.</p>
<p>For example, high solar activity can shorten the lifespan of satellites, and we’re just past a <a href="https://www.youtube.com/watch?v=pJutLygLib8" rel="noopener" target="_blank">solar maximum</a> and still in the period of high solar activity. Solar storms heat Earth’s upper atmosphere, causing it to “puff up.” The result is an increase in atmospheric drag: low-Earth orbit satellites like Starlink (and ISS, and Earth-observing satellites) find themselves flying through thicker air than usual. That extra air density creates aerodynamic drag, which slows the satellites down and causes them to lose altitude. </p>
<p><a href="https://earthsky.org/sun/sun-news-activity-solar-flare-cme-aurora-updates/" rel="noopener" target="_blank">Read our daily sun news</a></p>
<p>Operators might be able to boost some satellites back up. But, if they can’t, the satellites can reenter the atmosphere prematurely. That’s what happened in early 2022, when a solar storm <a href="https://earthsky.org/space/40-starlink-satellites-doomed-by-geomagnetic-storm/" rel="noopener" target="_blank">doomed 40 recently launched Starlink satellites</a>.</p>
<h3>Also, malfunctions can occur</h3>
<p>Solar activity isn’t the only thing that brings satellites down. Malfunctions can occur. For example, on July 12, 2024, a Falcon 9 rocket failed during the second stage, leaving 20 Starlink satellites in the “wrong” orbit. In that case, McDowell said: </p>
<blockquote><p>All but two of the satellites reentered on the day of launch, and the last one reentered on July 20, eight days after launch.</p></blockquote>
<h3>Recent Starlink satellites reentries shared on social media</h3>
<p>Here’s a sample of some of the recent Starlink satellite reentries that people have witnessed. Keep in mind that many of the reentries are not being witnessed. That’s because some 70% of Earth’s surface is water, so in many places the reentries happen overhead where no one is around to see them. Also, reentries that happen in the middle of the night or during bright daylight are less likely to be witnessed. </p>
<p><strong>September 25, 2025</strong>: A Starlink satellite lit up the sky over the Bay Area in California. </p>
<blockquote data-bluesky-uri="at://did:plc:forft2qtzk4plnajazyctgrx/app.bsky.feed.post/3lzpk2ywbds2r" data-bluesky-cid="bafyreih2qhkh3ansnsqkiugsa4rhcwgbmwph6y6q46cifr2fa4z3eqwpcy">
<p lang="en">WATCH: Starlink debris seen over the skies of Sacramento County, California.</p>
<p>— <a href="https://bsky.app/profile/did:plc:forft2qtzk4plnajazyctgrx?ref_src=embed">AZ Intel (@azintel.bsky.social)</a> <a href="https://bsky.app/profile/did:plc:forft2qtzk4plnajazyctgrx/post/3lzpk2ywbds2r?ref_src=embed">2025-09-26T03:37:39.570Z</a></p></blockquote>

<blockquote data-bluesky-uri="at://did:plc:vqtp5dj2o6rqnge56sz2db5a/app.bsky.feed.post/3lzrnw34fmc2t" data-bluesky-cid="bafyreifljewzl4dxsp3zoavajj4gutwpkatgp5sr4qtn3462ocsv6w4eja">
<p lang="en">A reentry observed over California at 0245 UTC Sep 26  (7.45pm PDT Thu Sep 25) is consistent with Starlink 1586.</p>
<p>— <a href="https://bsky.app/profile/did:plc:vqtp5dj2o6rqnge56sz2db5a?ref_src=embed">Jonathan McDowell  (@planet4589.bsky.social)</a> <a href="https://bsky.app/profile/did:plc:vqtp5dj2o6rqnge56sz2db5a/post/3lzrnw34fmc2t?ref_src=embed">2025-09-26T23:51:48.535Z</a></p></blockquote>

<p><strong>September 22, 2025</strong>: A Starlink satellite burned up over Saskatchewan, Canada. </p>
<blockquote data-bluesky-uri="at://did:plc:wdyeo63cqec6ihbbejecjyso/app.bsky.feed.post/3lzqt65yfuz72" data-bluesky-cid="bafyreiabcvvo4nylsf5fd2e545pxcpqcevmryulhuwx4mv4by6lgrayz3q">
<p lang="en">Here's the official Global Meteor Network camera video from Lucky Lake, Saskatchewan! This video is courtesy University of Western Ontario and Defence R&amp;D Canada.I counted 13 pieces in the video, how many do we think made it to the ground and are sitting on canola stubble east of Saskatoon?</p>
<p>— <a href="https://bsky.app/profile/did:plc:wdyeo63cqec6ihbbejecjyso?ref_src=embed">Prof. Sam Lawler (@sundogplanets.mastodon.social.ap.brid.gy)</a> <a href="https://bsky.app/profile/did:plc:wdyeo63cqec6ihbbejecjyso/post/3lzqt65yfuz72?ref_src=embed">2025-09-26T15:52:56.000Z</a></p></blockquote>

<blockquote data-bluesky-uri="at://did:plc:vqtp5dj2o6rqnge56sz2db5a/app.bsky.feed.post/3lzk3suvlyk2k" data-bluesky-cid="bafyreigx3pfbjyfklswuklxe3jrjiyqyvvgzxbohrnib7ratosxudoavbe">
<p lang="en">Starlink 1066 reentered over Canada at about 0600 UTC Sep 23.</p>
<p>— <a href="https://bsky.app/profile/did:plc:vqtp5dj2o6rqnge56sz2db5a?ref_src=embed">Jonathan McDowell  (@planet4589.bsky.social)</a> <a href="https://bsky.app/profile/did:plc:vqtp5dj2o6rqnge56sz2db5a/post/3lzk3suvlyk2k?ref_src=embed">2025-09-23T23:39:15.840Z</a></p></blockquote>

<p><strong>September 21, 2025</strong>: This Starlink reentry created a stir when it burned up over Texas.</p>
<blockquote cite="https://www.tiktok.com/@hearts4hoovestherapy/video/7552729934922304782" data-video-id="7552729934922304782" data-embed-from="oembed">
<section> <a target="_blank" title="@hearts4hoovestherapy" href="https://www.tiktok.com/@hearts4hoovestherapy?refer=embed">@hearts4hoovestherapy</a> 
<p>Well that was cool! <a title="hearts4hooves" target="_blank" href="https://www.tiktok.com/tag/hearts4hooves?refer=embed">#Hearts4Hooves</a> <a title="fyppppppppppppppppppppppp" target="_blank" href="https://www.tiktok.com/tag/fyppppppppppppppppppppppp?refer=embed">#fyppppppppppppppppppppppp</a> <a title="goviral" target="_blank" href="https://www.tiktok.com/tag/goviral?refer=embed">#goviral</a> <a title="foryoupage" target="_blank" href="https://www.tiktok.com/tag/foryoupage?refer=embed">#foryoupage</a> <a title="fyp?" target="_blank" href="https://www.tiktok.com/tag/fyp%E3%82%B7?refer=embed">#fyp?</a> </p>
<p> <a target="_blank" title="? levitation - Aaron Hibell &amp; Felsmann + Tiley" href="https://www.tiktok.com/music/levitation-7354226328704518160?refer=embed">? levitation – Aaron Hibell &amp; Felsmann + Tiley</a> </p></section>
</blockquote>

<blockquote data-bluesky-uri="at://did:plc:vqtp5dj2o6rqnge56sz2db5a/app.bsky.feed.post/3lzhnzphosk2f" data-bluesky-cid="bafyreighhsgyqknxuvy4uzfb7lmsccoojxek3sobpet7wezjumof4t2vje">
<p lang="en">Starlink 1636, launched  in Aug 2020, reentered over Texas last night (Sep 22 0130 UTC / Sep 21 8.30pm CDT) and was observed widely.</p>
<p>— <a href="https://bsky.app/profile/did:plc:vqtp5dj2o6rqnge56sz2db5a?ref_src=embed">Jonathan McDowell  (@planet4589.bsky.social)</a> <a href="https://bsky.app/profile/did:plc:vqtp5dj2o6rqnge56sz2db5a/post/3lzhnzphosk2f?ref_src=embed">2025-09-23T00:27:13.160Z</a></p></blockquote>

<h3>What effect do the disintegrating satellites have on Earth’s atmosphere?</h3>
<p>In 2023, the National Oceanic and Atmospheric Administration (NOAA) <a href="https://earthsky.org/earth/space-vehicle-re-entries-shed-exotic-metal-particles-in-earths-atmosphere/" rel="noopener" target="_blank">shared</a> a scientific investigation of Earth’s stratosphere. The stratosphere is the layer of atmosphere more than 7 miles (11 km) above Earth’s surface, where jet planes fly and the ozone layer exists. NOAA said the stratosphere: </p>
<blockquote><p>… contains an unexpected quantity of particles with a variety of exotic metals. The scientists believe the particles come from satellites and spent rocket boosters as they are vaporized by the intense heat of reentry.</p></blockquote>
<p>The researchers found particles containing the rare elements <a href="https://en.wikipedia.org/wiki/Niobium" rel="noopener" target="_blank">niobium</a> and <a href="https://en.wikipedia.org/wiki/Hafnium" rel="noopener" target="_blank">hafnium</a>. They also found  a significant number of particles contained <a href="https://en.wikipedia.org/wiki/Copper" rel="noopener" target="_blank">copper</a>, lithium and aluminum at concentrations far exceeding the abundance found in space dust. The use of these elements in heat-resistant, high-performance alloys pointed at the spaceflight industry as the culprit.</p>
<p>These tiny particles could absorb and reflect the sun’s rays. They could also serve as surfaces for ozone-destroying chemical reactions. And these particles could change our planet’s atmosphere in ways we still don’t fully understand. Research in this area is ongoing.</p>
<figure id="attachment_523282" aria-describedby="caption-attachment-523282"><img fetchpriority="high" decoding="async" src="https://earthsky.org/upl/2025/09/CometA6-lemmon_Satellite-trails-John-Chumack_Neg-Sep-27-2025-e1759175234821.jpg" alt="Starlink satellites: Starfield with background in white and comet in black with many stars and thin lines showing satellite trails." width="800" height="525"><figcaption id="caption-attachment-523282"><a href="https://ecp.earthsky.org/community-photos/entry/78488/" rel="noopener" target="_blank">View at EarthSky Community Photos</a>. | <a href="https://www.galacticimages.com/" rel="noopener" target="_blank">John Chumack</a> in Yellow Springs, Ohio, captured Comet Lemmon (C/2025 A6) on September 27, 2025. John wrote: “Insane satellite traffic while imaging this comet … the stars are trailing because I’m tracking the comet’s nucleus and motion through the background stars … out of the 44 separate 60-second images taken on that morning, only 6 did not have satellites trails in them.” Thank you, John!</figcaption></figure>
<p>Bottom line: There are now one to two Starlink satellites falling back to Earth each day, burning up in the atmosphere with consequences not fully understood.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Be Different" doesn't work for building products anymore (119 pts)]]></title>
            <link>https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building</link>
            <guid>45492888</guid>
            <pubDate>Mon, 06 Oct 2025 16:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building">https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building</a>, See on <a href="https://news.ycombinator.com/item?id=45492888">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!V1Ly!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!V1Ly!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 424w, https://substackcdn.com/image/fetch/$s_!V1Ly!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 848w, https://substackcdn.com/image/fetch/$s_!V1Ly!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 1272w, https://substackcdn.com/image/fetch/$s_!V1Ly!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!V1Ly!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png" width="1024" height="917" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:917,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1716732,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://iamcharliegraham.substack.com/i/175440850?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!V1Ly!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 424w, https://substackcdn.com/image/fetch/$s_!V1Ly!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 848w, https://substackcdn.com/image/fetch/$s_!V1Ly!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 1272w, https://substackcdn.com/image/fetch/$s_!V1Ly!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28bee1a0-b225-4f44-8b27-0cd1349e45ef_1024x917.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>(Originally from </span><a href="https://www.iamcharliegraham.com/t-red-ocean-why-be-different-no-longer-works/" rel="">iamcharliegraham.com</a><span>)</span></em></p><p>We are in the middle of the biggest red ocean I have ever seen in software development.</p><p>Thanks to AI coding, it has never been easier to design, develop, and distribute software. A process that once took months - designing in Figma, having developers write and test code, and deploying to AWS - can now take days with tools like Claude, other vibe-based coding assistants, and quick and easy deployment sites.</p><p>Yes, non-developers may hit a “vibe wall,” and yes, the code may run into huge technical debt quickly, but developers using AI coding tools can build new software from scratch probably 5x faster than before.</p><p>The result is a Cambrian explosion of software launches.</p><p>Where a great idea in a space once had 5-10 competitors, hundreds now appear - all competing for attention. Big companies used to move slowly, but now a ragtag team of two developers at a large firm can whip up something that looks top-of-market to the untrained eye in a matter of weeks.</p><p>Your company can scream to anyone that listens that all the competition is AI SLOP, but when hundreds of companies are pitching the same solution, your one voice will get lost.</p><p>In the past, the best practice to win in a competitive market was to differentiate yourself - “be different,” as Steve Jobs would say.</p><p>But product differentiation is no longer effective in this new world.</p><ul><li><p><strong>Differentiate on an amazing UX?</strong><span> You used to rely on your awesome UX team for a sustainable advantage. Now, dozens of competitors can screenshot (or soon video) your flow and give it to an AI to reproduce quickly.</span></p></li><li><p><strong>Differentiate by excelling at one feature?</strong><span> You might get a temporary lead, but it’s now pretty trivial for competitors to get close to your functionality.</span></p></li><li><p><strong>Differentiate on business model?</strong><span> If it starts working, dozens of your recently started competitors will vibe-code a switch over.</span></p></li><li><p><strong>Differentiate on “proprietary data”?</strong><span> This isn’t the key differentiator it was expected to be, as we are finding data can be simulated or companies can find similar-enough data to get 80% of the way there.</span></p></li></ul><p>Instead we live in a red ocean where features are copied in days or weeks and everyone is fighting with similar products for the same scraps.</p><p>So what does work?</p><p><strong>Proprietary &amp; Large Distribution</strong><span> In a red ocean, distribution is king. The companies that have existing distribution channels (their own communities, customer lists, celebrity CEOs) will get market share. Big companies have the edge here, but startups can compete if they have a pre-existing distribution network.</span></p><p><strong>Going into a Complex and Unknown Niche</strong><span> The best way to avoid the red ocean is to build for an obscure and complex niche. Think: automating claims paperwork for agricultural veterinarians. Very few builders know enough about the space, let alone have distribution, and there are likely enough regulatory requirements to make a niche solution essential. Unfortunately (or fortunately) most of these niche markets will be too small to be VC-viable.</span></p><p><strong>“Hard” or Expensive Integrations</strong><span> Builders gravitate toward the easiest solutions - it’s why AI wrappers are so prevalent. The annoying-to-build products will still have barriers. This includes software requiring difficult, per-company integrations or hundreds of integration points before becoming viable. Most builders will shy away from it for lower-hanging fruit. Companies that require expensive data sets to work also fit here, as most won’t spend hundreds of thousands of dollars before going to market.</span></p><p><strong>Network Effects Businesses</strong><span> Products that have true, large network effects will still rule. The product needs to get noticeably better the more people use it. Social networks and marketplaces fit this model. Small, on-the-margin network effects or those that reach a limit (like optimizing based on usage) will not result in a sustainable advantage.</span></p><p><strong>Compounding Data Lock-in</strong><span> Products can thrive if they become the system of record for operational data that your company constantly references. Consider CRM systems with years of customer interactions or content management systems with thousands of interconnected files. With every new entry, migration becomes more painful—not because of the raw data, but because of the platform-specific relationships and context that are hard to export. Your business becomes so dependent on that history that leaving is prohibitively complex and risky.</span></p><p><strong>Regulatory Barriers</strong><span> If your product requires lots of regulatory permissions (FDA or SEC approval), this can prevent others from entering. Of course, these are also harder to get off the ground.</span></p><p><strong>Bundling By Big Companies - </strong><span>For many products, the red ocean won’t be won. It will be absorbed. We’re going to see a wave of big companies building 80% good-enough solutions and simply bundling them into their platforms. Most of today’s standalone AI products are destined to become mere “features” in a larger solution. We’re already seeing this with Box, Notion, and Google. Expect a lot more of it.</span></p><p>This is the best of times and the worst of times for entrepreneurs. Knowing how and when to compete is the difference between having a good chance of building a sustainable, successful company and just picking a lottery ticket and hoping.</p><p>If you are experienced in a complex niche and want to build something there, let me know!</p><div data-attrs="{&quot;url&quot;:&quot;https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Thanks for reading! This post is public so feel free to share it.</p><p data-attrs="{&quot;url&quot;:&quot;https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenZL: An open source format-aware compression framework (167 pts)]]></title>
            <link>https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/</link>
            <guid>45492803</guid>
            <pubDate>Mon, 06 Oct 2025 16:01:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/">https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/</a>, See on <a href="https://news.ycombinator.com/item?id=45492803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		<ul>
<li><a href="https://openzl.org/" target="_blank" rel="noopener">OpenZL</a> is a new open source data compression framework that offers lossless compression for structured data.</li>
<li><span>OpenZL is designed to offer the performance of a format-specific compressor with the easy maintenance of a single executable binary.</span></li>
<li>You can get started with OpenZL today by visiting our <a href="https://facebook.github.io/openzl/getting-started/quick-start/" target="_blank" rel="noopener"><span>Quick Start guide</span></a><span> and the</span>&nbsp;<a href="https://github.com/facebook/openzl" target="_blank" rel="noopener"><span>OpenZL GitHub repository.</span></a></li>
<li>Learn more about the <a href="https://arxiv.org/abs/2510.03203" target="_blank" rel="noopener">theory behind OpenZL in this whitepaper</a>.</li>
</ul>
<p><span>Today, we are excited to announce the public release of <a href="https://openzl.org/" target="_blank" rel="noopener">OpenZL</a>, a new data compression framework. OpenZL offers lossless compression for structured data, with performance comparable to specialized compressors. It accomplishes this by applying a configurable sequence of transforms to the input, revealing hidden order in the data, which can then be more easily compressed. Despite applying distinct transformation permutations for every file type, all OpenZL files can be decompressed using the same universal OpenZL decompressor.</span></p>
<h2><span>A Decade of Lessons</span></h2>
<p><span>When </span><a href="https://engineering.fb.com/2016/08/31/core-infra/smaller-and-faster-data-compression-with-zstandard/" target="_blank" rel="noopener"><span>Zstandard</span></a><span> was announced, it came with a simple pitch: It promised the same or better compression ratio of prior default but at the much increased speed required by datacenter workloads. By pairing strong entropy coding with a design that fully utilized modern CPU capabilities, Zstandard offered a substantial improvement that justified its presence in datacenters.</span></p>
<p><span>However, while it was improved over time, remaining within the Zstandard framework offers diminishing returns. So we started looking for the next great leap in data compression.</span></p>
<p><span>In this quest, one pattern kept repeating: Using generic methods on structured data leaves compression gains on the table. Data isn’t just byte soup. It can be columnar, encode enums, be restricted to specific ranges, or carry highly repetitive fields. More importantly, it has predictable shapes. A bespoke compressor that leans into that structure can beat general-purpose tools on both ratio and speed. But there’s a catch — every bespoke scheme means another compressor and decompressor to create, ship, audit, patch, and trust.</span></p>
<p><span>OpenZL is our answer to the tension between the performance of format-specific compressors and the maintenance simplicity of a single executable binary.</span></p>
<h2><span>Make the Structure Explicit</span></h2>
<p><span>General compressors rely on a one-size fits all processing strategy, or alternatively spend a lot of their cycles guessing which techniques to use. OpenZL saves those cycles by making the structure an explicit input parameter. Compression can then focus on a sequence of reversible steps that surface patterns before coding.</span></p>
<p><span>As a user, you provide OpenZL with the data shape (via a preset or a thin format description). Then the trainer, an offline optimization component, builds an effective compression config that can be re-employed for similar data. During encoding that config resolves into a concrete decode recipe that’s embedded into the frame. The universal decoder will directly execute that recipe, without any out-of-band information.</span></p>
<h2><span>An Example Compression Using OpenZL</span></h2>
<p><span>As an example, let’s compress </span><span>sao</span><span>, which is part of the </span><a href="https://sun.aei.polsl.pl/~sdeor/index.php?page=silesia" target="_blank" rel="noopener"><span>Silesia Compression Corpus</span></a><span>. This file follows a </span><a href="http://tdc-www.harvard.edu/software/catalogs/catalogsb.html" target="_blank" rel="noopener"><span>well-defined format</span></a><span> featuring an array of records, each one describing a star. Providing this information to OpenZL is enough to give it an edge over generic lossless compressors, which only see bytes.</span></p>
<p>Comparison on a M1 cpu, using clang-17</p>
<table>
<tbody>
<tr>
<td><span>Compressor</span></td>
<td><span>zstd -3</span></td>
<td><span>xz -9</span></td>
<td><span>OpenZL</span></td>
</tr>
<tr>
<td><span>Compressed Size</span></td>
<td><span>5,531,935 B​</span></td>
<td><span>4,414,351​ B</span></td>
<td><span>3,516,649​ B</span></td>
</tr>
<tr>
<td><span>Compression Ratio</span></td>
<td><span>x1.31</span></td>
<td><span>x1.64</span></td>
<td><span>x2.06</span></td>
</tr>
<tr>
<td><span>Compression Speed</span></td>
<td><span>220 MB/s</span></td>
<td><span>3.5 MB/s</span></td>
<td><span>340 MB/s</span></td>
</tr>
<tr>
<td><span>Decompression Speed</span></td>
<td><span>850 MB/s</span></td>
<td><span>45 MB/s</span></td>
<td><span>1200 MB/s</span></td>
</tr>
</tbody>
</table>

<p><span>Crucially, OpenZL produces a higher compression ratio </span><i><span>while preserving or even improving speed</span></i><span>, which is critical for data center processing pipelines.</span><span><br>
</span></p>
<p><span>For illustration, this result is achieved using the following simple graph:</span><span><br>
</span></p>
<p><img decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png" alt="" width="700" height="498" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=916,651 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=768,546 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=1024,728 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=1536,1092 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=96,68 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=192,136 192w" sizes="(max-width: 992px) 100vw, 62vw"></p>
<h3><i><span>A Brief Explanation</span></i></h3>
<p><span>So what is happening in this example?</span></p>
<p><span>We start by separating the header from the rest, a large table of structures. Then each field gets extracted into its own stream: the array of structures becomes a structure of arrays. After that point, we expect that each stream contains homogeneous data of the same type and semantic meaning. We can now focus on finding an optimal compression strategy for each one.</span></p>
<ul>
<li aria-level="1"><span>SRA0</span><span> is a position on the X axis. Due to the way the table is generated, the index is </span><i><span>mostly</span></i><span> sorted, inviting the use of </span><span>delta</span><span> to reduce the range of values represented. This mechanically makes the resulting stream easier to compress.&nbsp;</span></li>
<li aria-level="1"><span>SDEC0</span><span> is a position on the Y axis. It’s not as well sorted as the X axis, but we can at least exploit the fact that it’s bounded between a minimum and a maximum. This makes the higher bytes more predictable, which can be exploited for better compression with the </span><span>transpose</span><span> operation.</span></li>
<li aria-level="1"><span>The other fields (</span><span>IS</span><span>, </span><span>MAG</span><span>, </span><span>XRPM</span><span>, </span><span>XDPM</span><span>) share a common property: their cardinality is much lower than their quantities, and there is no relation between 2 consecutive values. This makes them a good target for </span><span>tokenize</span><span>, which will convert the stream into a dictionary and an index list.</span></li>
<li aria-level="1"><span>The resulting dictionaries and index lists are very different. They benefit from completely different compression strategies. So they are sent to dedicated processing graphs.</span></li>
</ul>
<p><span>The graph continues beyond these steps. But at some point, we can also stop making decisions. The main work is to group data into homogeneous streams. After that, one can count on </span><span>openzl</span><span> to take care of the rest.&nbsp;</span></p>
<p><span>To go even further, we would like to generate compression strategies that are specifically fine-tuned for each stream. This is where the </span><b>offline trainer stage</b><span> comes into play.&nbsp;</span></p>
<h2><span>Generate a Compressor Automatically</span></h2>
<p><span>It’s possible to take full control of the compression process, but it’s also not required. A faster strategy is to just describe your data and let the system learn a </span><b>compression config.</b></p>
<p><b>Describe the input: </b><span>With the </span><a href="https://facebook.github.io/openzl/api/c/graphs/sddl/" target="_blank" rel="noopener"><span>Simple Data Description Language (SDDL)</span></a><span>, you sketch how the bytes map to fields — rows, columns, enums, nested records. SDDL is for parsing only; it just tells OpenZL the shape of your data. Alternatively, you can write your own parser function directly using one of the supported languages, and register it with OpenZL to delegate the logic.</span></p>
<p><b>Learn the config: </b><span>Starting from a preset, a parser function or an SDDL description, the </span><b>trainer</b><span> runs a budgeted search over transform choices and parameters to produce a </span><b>Plan</b><span>. It can provide a full set of speed/ratio tradeoffs, or directly target the best configuration respecting some speed constraints. Internally it uses a cluster finder (to group fields that behave alike) and a graph explorer (to try candidate subgraphs and keep score).</span></p>
<p><b>Resolve at encode-time: </b><span>While compressing, the encoder turns the Plan into a concrete recipe — the </span><b>Resolved Graph</b><span>. If the Plan has control points, it picks the branch that fits the data and records that choice into the frame.</span></p>
<p><b>Decode without coordination: </b><span>Each frame chunk carries its own resolved graph. The single decoder checks it, enforces limits, and runs the steps in order. When a plan improves, you just roll out the new plan, no new decompressor needed. Old data keeps decoding; new data get improved gains.&nbsp;</span></p>
<p><i><span>In practice the loop is straightforward: describe (SDDL) → train (produce a plan) → compress (emit frames with resolved graphs) → decode anywhere with the same binary.</span></i></p>
<h2>Embracing Changes: Re-Training and In-Flight Control</h2>
<p><span>In the real world, data evolves constantly, in both structure and content. A compressor built for one version of a schema would have a short lifetime.&nbsp;</span></p>
<p><span>Thankfully, with the flexibility offered by compression plans, we can react swiftly to data changes. At Meta, this is the core mission of </span><b>Managed Compression</b><span>, originally created to automate dictionary compression with Zstandard, and presented in an earlier blog </span><a href="https://engineering.fb.com/2018/12/19/core-infra/zstandard/" target="_blank" rel="noopener"><span>on how we improved compression at with Zstandard</span></a><span>.&nbsp;</span></p>
<p><span>OpenZL offers a training process that updates compression plans to maintain or improve compression performance, based on provided data samples. Now the synergy with Managed Compression is apparent: Each registered use case is monitored, sampled, periodically re-trained, and receives new configs when they prove beneficial. The decompression side continues to decode both old and new data without any change.</span></p>
<p><b>Runtime Adaptation:</b><span>&nbsp;A compression config can include </span><b>control points</b><span> that read lightweight statistics at compression time (e.g., string repetition stats, run-length, histogram skew, delta variance) and choose the best branch of the Plan to go to next. Many technologies can be used, and textbook classifiers qualify. Control points handle bursts, outliers, and seasonal shifts without brute-force exploration: exploration is bounded, in order to maintain speed expectations. Taken branches are then recorded into the frame, and the decoder just executes the recorded path.</span></p>
<p><span>This gives the best of both worlds: dynamic behavior at compression time to handle variations and exceptions — without turning compression into an unbounded search problem — and with zero complexity added to the decoder.</span></p>
<h2><span>The Advantages of the Universal Decoder</span></h2>
<p><span>OpenZL is capable of compressing a vast array of data formats, and they can all be decompressed with a single decompressor binary. Even when the compression configuration changes, the decoder does not. This may sound like operational minutiae, but it’s critical to OpenZL’s deployment success.</span></p>
<ul>
<li aria-level="1"><b>One audited surface:</b><span>&nbsp;Security and correctness reviews focus on a single binary with consistent invariants, fuzzing, and hardening; there’s no myriad of per-format tools that can drift apart.</span></li>
<li aria-level="1"><b>Fleet-wide improvements: </b><span>A decoder update (security or performance — SIMD kernels, memory bounds, scheduling) benefits every compressed file, even those that predate the change.</span></li>
<li aria-level="1"><b>Operational clarity:</b><span>&nbsp;Same binary, same CLI, same metrics and dashboards across datasets; patching and rollout are uneventful by design.</span></li>
<li aria-level="1"><b>Continuous training: </b><span>With one decoder and many compression plans, we can keep improving while the system is live. Train a plan offline, try it on a small slice, then roll it out like any other config change. Backward compatibility is built-in — old frames still decode while new frames get better.</span></li>
</ul>
<p><span>In other words, it’s possible to afford domain-specific compression without fragmenting the ecosystem.</span></p>
<h2><span>Results With OpenZL</span></h2>
<p><span>When OpenZL is able to understand and parse the file format, it is able to offer large improvements in compression ratio, while still providing fast compression and decompression speed. However, this is no magic bullet. When OpenZL doesn’t understand the input file format, it simply falls back to </span><span>zstd</span><span>.</span></p>
<p><span>OpenZL, through its offline training capabilities, is also able to offer a wide range of configurations in the tradeoff space of compression ratio, compression speed, and decompression speed. Unlike traditional compressors, which offer configuration by setting a compression level, OpenZL offers configuration by serializing the compressor graph. This allows an immense amount of flexibility to select diverse tradeoffs.</span></p>
<p><span>These results are based on datasets we’ve <a href="https://arxiv.org/abs/2510.03203" target="_blank" rel="noopener">developed for our whitepaper</a>. The datasets were chosen because they are highly structured and in a format that OpenZL supports. Every figure below is produced with <a href="https://github.com/facebook/openzl/blob/dev/contrib/reproducibility/figures/script.sh" target="_blank" rel="noopener">scripts in the OpenZL repository</a> so they can be reproduced, and the input data and logs from our runs have been uploaded </span><a href="https://github.com/facebook/openzl/releases/tag/openzl-sample-artifacts" target="_blank" rel="noopener"><span>to GitHub</span></a><span>.</span></p>
<p><span>Note that data points connected by a line are pareto-optimal. All such points have the property that there is no point in the same dataset which beats them in both metrics.</span></p>
<figure id="attachment_23055" aria-describedby="caption-attachment-23055"><img decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png" alt="" width="700" height="334" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=916,437 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=768,367 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=1024,489 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=1536,733 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=96,46 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=192,92 192w" sizes="(max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-23055"><strong>Figure 1 — SAO:</strong> These figures show compression speed and decompression speed vs. ratio for SAO comparing OpenZL with three general compression tools. As shown in the example, OpenZL destructures the star records into columns for each field, and then the trainer learns how to best compress each field to produce a set of OpenZL configurations offering a wide range of tradeoffs.</figcaption></figure>
<figure id="attachment_23056" aria-describedby="caption-attachment-23056"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png" alt="" width="700" height="324" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=916,424 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=768,355 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=1024,474 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=1536,711 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=96,44 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=192,89 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-23056"><b>Figure 2 — Columnar numeric data: </b><span>These figures show compression speed and decompression speed vs. ratio for the ERA5 Flux dataset for OpenZL and three general compression tools. The data is presented to the compressor as a single array of 64-bit numeric data. For a given time budget, OpenZL achieves substantially higher compression ratios. Likewise, for a given compression ratio, OpenZL can complete the job with greater speed.</span></figcaption></figure>
<p><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png" alt="" width="700" height="318" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=916,417 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=768,349 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=1024,466 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=1536,698 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=96,44 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=192,87 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"></p>
<figure id="attachment_23083" aria-describedby="caption-attachment-23083"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png" alt="" width="700" height="324" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png?resize=916,424 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png?resize=768,355 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png?resize=1024,474 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png?resize=1536,711 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png?resize=96,44 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-TLC-Dataset.png?resize=192,89 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-23083"><strong>Figure 3 — Parquet</strong>: These two figures show compression speed vs. ratio for the Binance and TLC Green Trip dataset for OpenZL and three general compression tools, presented as uncompressed Parquet files. OpenZL parses the Parquet format and learns the schema in order to tune compression to each file.</figcaption></figure>
<figure id="attachment_23058" aria-describedby="caption-attachment-23058"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png" alt="" width="700" height="314" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=916,411 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=768,345 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=1024,460 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=1536,690 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=96,43 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=192,86 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-23058"><strong>Figure 4 — CSV: </strong>This figure shows the compression speed vs. ratio tradeoff for the PPMF Unit dataset for OpenZL and three general compression tools, presented as CSV files. OpenZL is able to offer excellent compression ratios, but the cost of parsing CSV caps the compression speed at about 64 MB/s. An improved parser will speed that up, however this strategy will likely never approach Zstd’s speeds of 1 GB/s. Nonetheless and not pictured here, OpenZL always has the option to fallback to the <span>zstd </span>codec, so its performance can be lower-bounded by <span>zstd</span>.</figcaption></figure>
<h3><em><span>When It’s Not Useful</span></em></h3>
<p><span>OpenZL relies on a description of some structure to leverage its set of transforms. When there is no structure, there is no advantage. This is typically the case in pure text documents, such as </span><span>enwik</span><span> or </span><span>dickens</span><span>. In these cases, OpenZL falls back to </span><span>zstd</span><span>, offering essentially the same level of performance.</span></p>
<h2><span>Getting Started With OpenZL</span></h2>
<p><span>OpenZL’s selection of codecs is well-suited to compressing vector, tabular, or tree-structured data, and can be expected to perform well with numeric, string, or binary data. Common examples include timeseries datasets, ML tensors, and database tables. Keep in mind that we are bound by the limits of information theory, so the input needs to have some order that can be uncovered. As time goes on, we plan to incorporate additional codecs, as described in the next section.</span></p>
<p><span>If your data fits one of the above categories, then give it a try! Visit the <a href="https://openzl.org/" target="_blank" rel="noopener">OpenZL site</a> and our </span><a href="https://facebook.github.io/openzl/getting-started/quick-start/" target="_blank" rel="noopener"><span>Quick Start guide</span></a><span> to get started.</span></p>
<p><span>If you want to dive into the code, check out the</span> <a href="https://github.com/facebook/openzl" target="_blank" rel="noopener"><span>GitHub repository</span></a><span> for source, documentation, and examples. We welcome contributions and feedback from the community!</span></p>
<h2><span>Where We’re Going</span></h2>
<p><span>OpenZL’s general direction is set: make it easier to expose structures, and exploit it with automated compression plans for evolving data.</span></p>
<p><b>Next up</b><span>: We’re extending the transform library for time-series and grid-shaped data, improving performance of codecs, and enabling the trainer to find better compression plans faster. We also are actively working to extend SDDL to describe nested data formats more flexibly. Finally, the automated compressor explorer is getting better at proposing safe, testable changes to a compression plan within a specified budget.</span></p>
<p><b>Where the community can help: </b><span>If you have a format or a dataset with obvious structure, try compressing it with an OpenZL prebuilt Plan. If it’s promising, try generating a new plan with the trainer or customizing it with our documentation to improve it. If it’s a format that the public might want, send it to us in a PR.</span></p>
<p><span>You can also contribute to the OpenZL core. If you have a knack for optimizing C/C++, help us speed up the engine or add transforms to cover new data formats. If your super power is reliability, the project would surely benefit from more validation rules and resource caps. And if you care about benchmarks, add your dataset to the harness so others can reproduce your results.</span></p>
<p><b>How to engage:</b><span>&nbsp;Open an issue on the GitHub issue board. If you have a use-case for which you would expect OpenZL to do better, provide a few small samples, so that we can analyze them together. You may also contribute to codec optimizations, and propose new graphs, parsers or control points. All these topics do not impact the universality of the decoder.</span></p>
<p><span>We believe OpenZL opens up a new universe of possibilities to the data compression field, and we’re excited to see what the open source community will do with it!</span></p>
<p><span>To learn more about Meta Open Source, visit our </span><a href="https://opensource.fb.com/" target="_blank" rel="noopener"><span>website</span></a><span>, subscribe to our </span><a href="https://www.youtube.com/channel/UCCQY962PmHabTjaHv2wJzfQ" target="_blank" rel="noopener"><span>YouTube channel</span></a><span>, or follow us on </span><a href="https://www.facebook.com/MetaOpenSource" target="_blank" rel="noopener"><span>Facebook</span></a><span>, </span><a href="https://www.threads.net/@metaopensource" target="_blank" rel="noopener"><span>Threads</span></a><span>, </span><a href="https://x.com/MetaOpenSource" target="_blank" rel="noopener"><span>X</span></a><span>, </span><a href="https://bsky.app/profile/metaopensource.bsky.social" target="_blank" rel="noopener"><span>Bluesky</span></a><span> and </span><a href="https://www.linkedin.com/showcase/meta-open-source?fbclid=IwZXh0bgNhZW0CMTEAAR2fEOJNb7zOi8rJeRvQry5sRxARpdL3OpS4sYLdC1_npkEy60gBS1ynXwQ_aem_mJUK6jEUApFTW75Emhtpqw" target="_blank" rel="noopener"><span>LinkedIn</span></a><span>.</span></p>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple's Unlawful Evil (150 pts)]]></title>
            <link>https://pluralistic.net/2025/10/06/rogue-capitalism/#orphaned-syrian-refugees-need-not-apply</link>
            <guid>45492410</guid>
            <pubDate>Mon, 06 Oct 2025 15:25:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluralistic.net/2025/10/06/rogue-capitalism/#orphaned-syrian-refugees-need-not-apply">https://pluralistic.net/2025/10/06/rogue-capitalism/#orphaned-syrian-refugees-need-not-apply</a>, See on <a href="https://news.ycombinator.com/item?id=45492410">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-11750">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
iceblock, apple, eu, ice, dma, digital markets act, feudal security, america with chinese characteristics

Summary:
Apple's unlawful evil; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books

URL:
https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/

Title:
Pluralistic: Apple's unlawful evil (06 Oct 2025) america-with-chinese-characteristics

Bullet:
🍰

Separator:
⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂ ⠂⠄⠄⠂⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂ ⠂⠄⠄⠂⠂⠄⠄⠂⠁⠁⠂⠄

Top Sources:
None

--><br>
<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/06Oct2025.jpg?w=840&amp;ssl=1"></a></p>
<h2>Today's links</h2>
<ul>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#orphaned-syrian-refugees-need-not-apply">Apple's unlawful evil</a>: Everyone's a rogue capitalist now.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#linkdump">Hey look at this</a>: Delights to delectate.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#retro">Object permanence</a>: Why copyright wars matter; Car accidents aren't accidents; Ayn Rand, firefighter; Most sound recordings are unavailable; Kill the Dead; XKCD map; Lockdown with kindergartners; Facebook's living will; Ad tech bubble; The Internet is for end-users; Squeeze Me.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#upcoming">Upcoming appearances</a>: Where to find me.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#recent">Recent appearances</a>: Where I've been.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#latest">Latest books</a>: You keep readin' em, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#upcoming-books">Upcoming books</a>: Like I said, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#bragsheet">Colophon</a>: All the rest.
</li>
</ul>

<hr>
<p><a name="orphaned-syrian-refugees-need-not-apply"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A squadron of four heavily armed riot cops with batons in their hands. They wear visors, Oakleys and gaiters. Their badges have been replaced with chromed Apple logos. In the background is an Apple 'Think Different' wordmark. Looming in the foreground is Trump's candyfloss hair." src="https://i0.wp.com/craphound.com/images/apple-ice.jpg?w=840&amp;ssl=1"></p>
<h2>Apple's unlawful evil (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#orphaned-syrian-refugees-need-not-apply">permalink</a>)</h2>
<p>Apple has removed ICEBlock, a totally legal app that helps people track the movements of the masked snatch-squads who illegally terrorize brown people in America's cities, capitulating to a warrantless demand from Trump's DoJ boss Pam Bondi:</p>
<p><a href="https://www.404media.co/iceblock-owner-after-apple-removes-app-we-are-determined-to-fight-this/">https://www.404media.co/iceblock-owner-after-apple-removes-app-we-are-determined-to-fight-this/</a></p>
<p>In killing ICEBlock, Apple insists that it is only complying with lawful orders, which is patently untrue. Pam Bondi has no authority to order the censorship of this legal speech tool, which is likely why she didn't seek a court order and instead merely rage-tweeted about it. This was sufficient to get Apple CEO Tim Cook, the billionaire who moved Apple's manufacturing to Chinese sweatshops where working conditions are so brutal that they require suicide nets, to cave in.</p>
<p>Apple does not permit its iPhone customers to install software unless it is delivered via their App Store. They claim they do so in order to protect their customers from their customers' own bad choices about which apps to install. But time and again, Apple has shown that they exercise this control over their users to pursue their own ends, blocking:</p>
<ul>
<li>A dictionary (because it contained swear words);
</li>
<li>
<p>A game that simulated working in an Apple sweatshop;</p>
</li>
<li>
<p>An informative app that cataloged civilian casualties of US drone strikes;</p>
</li>
<li>
<p>The Tumblr app because some Tumblr blogs contained adult content; and</p>
</li>
<li>
<p>Working VPN apps for the entire nation of China.</p>
</li>
</ul>
<p>Apple uses its app store control to extract 30 cents out of every dollar spent by its customers in the apps they use. That's a 30%, economy-wide, worldwide tax on news outlets and podcasts that collects subscriptions through apps, Patreon performers whose subscribers pay by app and games publishers who sell via the app store.</p>
<p>Apple also uses its app store control to block rival browser engines (every browser on iOS is just a reskinned version of Safari). Apple's own browser engine, Webkit, is riddled with longstanding, grave security vulnerabilities, and there is no way to distribute more secure browsers on iOS:</p>
<p><a href="https://open-web-advocacy.org/blog/apples-browser-engine-ban-persists-even-under-the-dma/">https://open-web-advocacy.org/blog/apples-browser-engine-ban-persists-even-under-the-dma/</a></p>
<p>Apple claims that it must be able to override its customers' choices about which software they'd like to run, lest those customers make foolish software choices and compromise their own security. Bruce Schneier calls this "feudal security," in which a digital warlord offers you sanctuary from the internet's roving bandits within the mercenary-studded walls of his impenetrable fortress. The problem is that when the <em>warlord</em> decides to attack <em>you</em>, the fortress becomes a prison, and you are rendered helpless:</p>
<p><a href="https://pluralistic.net/2023/02/05/battery-vampire/#drained">https://pluralistic.net/2023/02/05/battery-vampire/#drained</a></p>
<p>Normally, the safety problems of feudal security are <em>digital</em>, but with ICEBlock, they are very, very physical. ICE is kidnapping our neighbors and sending them to offshore and onshore gulags. Of the 1,600 people illegally detained in Alligator Auschwitz, <em>two thirds</em> cannot be located. They have disappeared:</p>
<p><a href="https://www.democracynow.org/2025/9/25/alligator_alcatraz">https://www.democracynow.org/2025/9/25/alligator_alcatraz</a></p>
<p>In removing ICEBlock, Apple has deprived its customers of a vital tool for evading these kidnapping, murdering, masked thugs.</p>
<p>ICE moved from targeting "the worst of the worst" to targeting "people here illegally" to "people who look foreign" to "people who live in cities":</p>
<p><a href="https://federate.social/@mattblaze/115323465203575305">https://federate.social/@mattblaze/115323465203575305</a></p>
<p>You know who would have been at the top of that list? Steve Jobs, who died 14 years ago today:</p>
<p><a href="https://www.macrumors.com/2025/10/05/remembering-steve/">https://www.macrumors.com/2025/10/05/remembering-steve/</a></p>
<p>Steve Jobs was "the anchor baby of an activist Arab muslim who came to the US on a student visa and had a child out of wedlock":</p>
<p><a href="https://www.anildash.com/2025/09/09/how-tim-cook-sold-out-steve-jobs/">https://www.anildash.com/2025/09/09/how-tim-cook-sold-out-steve-jobs/</a></p>
<p>He is <em>exactly</em> the sort of person that Trump wants to deport.</p>
<p>Jobs isn't the only foreigner whose company is helping Trump round up and disappear foreigners. Google – co-founded by Soviet refugee Sergey Brin – has also killed ICEBlock. Google has <em>also</em> announced that they will nonconsensually update every Android device in the world to prevent their owners from installing software that Google hasn't approved:</p>
<p><a href="https://pluralistic.net/2025/09/01/fulu/#i-am-altering-the-deal">https://pluralistic.net/2025/09/01/fulu/#i-am-altering-the-deal</a></p>
<p>When China hacked Gmail in order to target dissidents, Sergey Brin unilaterally pulled the company out of China, gripped by visceral horror of his platform being used for totalitarian oppression. Today, Brin is taking away his customers' best tool for evading ICE kidnappers on behalf of a self-declared "dictator." Hey, Sergey, one Soviet refugee's son to another, that's some pretty <em>Vichy</em> bullshit, <em>landsman</em>.</p>
<p>Under Trump's policies, neither Apple nor Google would exist today. These companies both claim that they have to "obey the law" but this isn't following a lawful order – it's going above and beyond the law to help a dictator kidnap their customers.</p>
<p>When China turned on Google's users, Google left the country. When the <em>European Union</em> ordered Apple to open up to third party app stores, Apple <em>threatened to leave Europe</em>:</p>
<p><a href="https://pluralistic.net/2025/09/26/empty-threats/#500-million-affluent-consumers">https://pluralistic.net/2025/09/26/empty-threats/#500-million-affluent-consumers</a></p>
<p>But when Pam Bondi ordered Apple and Google to help her round up <em>their own customers</em>, Brin and Cook didn't even ask for a court order.</p>
<p>You could not ask for a better example of the failure of feudal security. Nor could you ask for a better rebuttal to the "Surveillance Capitalism" claim that Google is a "rogue capitalist" (because it spies on you for profit) while Apple is a good capitalist (because they extract money, not private data):</p>
<p><a href="https://pluralistic.net/HowToDestroySurveillanceCapitalism">https://pluralistic.net/HowToDestroySurveillanceCapitalism</a></p>
<p>Apple spies on you, of course. And because they trap you in the App Store's airtight bubble, they block you from installing any software that would protect you from Apple's surveillance. And now, Apple has thrown in with the Trump regime's most violent, human-rights invading program: mass kidnappings and disappearances of thousands of our neighbors.</p>
<p>Truly, everyone's a "rogue capitalist" now. It's almost like the problem with companies isn't whether their business model is based on showing you ads or charging you money, but rather, whether they can abuse you for profit and get away with it.</p>
<hr>

<h2 heds="0">Hey look at this (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#linkdump">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/heylookatthis2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Social Media Provenance Challenge <a href="https://www.tbray.org/ongoing/When/202x/2025/10/01/C2PA-For-Social-Media">https://www.tbray.org/ongoing/When/202x/2025/10/01/C2PA-For-Social-Media</a>
</li>
<li>
<p>A Powerhouse  Writer Found One Word to Change the Debate About Tech <a href="https://www.nytimes.com/2025/10/05/books/review/cory-doctorow-enshittification.html?unlocked_article_code=1.rE8.s411.gJIQKhZDXbJX&amp;amp;smid=url-share">https://www.nytimes.com/2025/10/05/books/review/cory-doctorow-enshittification.html?unlocked_article_code=1.rE8.s411.gJIQKhZDXbJX&amp;amp;smid=url-share</a></p>
</li>
<li>
<p>Socialist Approaches To Enterprise Information Technology <a href="https://saeit.org/">https://saeit.org/</a></p>
</li>
<li>
<p>Way past its prime: how did Amazon get so rubbish? <a href="https://www.theguardian.com/technology/2025/oct/05/way-past-its-prime-how-did-amazon-get-so-rubbish">https://www.theguardian.com/technology/2025/oct/05/way-past-its-prime-how-did-amazon-get-so-rubbish</a></p>
</li>
<li>
<p>Man buys used Tesla only to discover it's banned from Supercharger network <a href="https://www.cbsnews.com/chicago/news/used-tesla-banned-supercharger-network-daniel-boycott/">https://www.cbsnews.com/chicago/news/used-tesla-banned-supercharger-network-daniel-boycott/</a></p>
</li>
</ul>
<hr>
<p><a name="retro"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A shelf of leatherbound history books with a gilt-stamped series title, 'The World's Famous Events.'" src="https://i0.wp.com/craphound.com/images/worlds-famous-events.png?w=840&amp;ssl=1"></p>
<h2 heds="0">Object permanence (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#retro">permalink</a>)</h2>
<p>#20yrsago Ebook DRM that encourages identity theft gets a huge makeover <a href="https://web.archive.org/web/20051011041018/https://www.eff.org/deeplinks/archives/004026.php">https://web.archive.org/web/20051011041018/https://www.eff.org/deeplinks/archives/004026.php</a></p>
<p>#20yrsago Alternate reality game turns online poker into tombstone parties in cemetaries <a href="https://web.archive.org/web/20130514004112/https://42entertainment.com/work/lastcallpoker">https://web.archive.org/web/20130514004112/https://42entertainment.com/work/lastcallpoker</a></p>
<p>#20yrsago Reporter vows to fight DRM <a href="https://web.archive.org/web/20051210140945/https://blogs.zdnet.com/BTL/?p=1952">https://web.archive.org/web/20051210140945/https://blogs.zdnet.com/BTL/?p=1952</a></p>
<p>#20yrsago Library of Congress: Most sound recordings aren’t available <a href="https://www.clir.org/pubs/reports/pub133/contents/">https://www.clir.org/pubs/reports/pub133/contents/</a></p>
<p>#15yrsago T-Mobile sneaks “rootkit” into G2 phones – reinstalls locked-down OS after jailbreaking <a href="https://web.archive.org/web/20101009072029/https://oti.newamerica.net/blogposts/2010/newest_google_android_cell_phone_contains_unexpected_feature_a_malicious_root_kit-380">https://web.archive.org/web/20101009072029/https://oti.newamerica.net/blogposts/2010/newest_google_android_cell_phone_contains_unexpected_feature_a_malicious_root_kit-380</a></p>
<p>#15yrsago XKCD’s Online Communities map, part 2 – the online world, visualized with loads of funny <a href="https://xkcd.com/802/">https://xkcd.com/802/</a></p>
<p>#15yrsago KILL THE DEAD: Kadrey’s grisly, hard-boiled sequel to SANDMAN SLIM <a href="https://memex.craphound.com/2010/10/05/kill-the-dead-kadreys-grisly-hard-boiled-sequel-to-sandman-slim/">https://memex.craphound.com/2010/10/05/kill-the-dead-kadreys-grisly-hard-boiled-sequel-to-sandman-slim/</a></p>
<p>#15yrsago Security company ad tricks people into thinking their houses were burgled <a href="https://copyranter.blogspot.com/2010/10/adt-shows-you-how-easy-it-is-to-break.html">https://copyranter.blogspot.com/2010/10/adt-shows-you-how-easy-it-is-to-break.html</a></p>
<p>#15yrsago Firefighters watch as house burns to the ground: owner had not paid annual firefighting fees <a href="https://web.archive.org/web/20101003021723/https://www.wpsdlocal6.com/news/local/firefighters-watch-as-home-burns-to-the-ground-104052668.html">https://web.archive.org/web/20101003021723/https://www.wpsdlocal6.com/news/local/firefighters-watch-as-home-burns-to-the-ground-104052668.html</a></p>
<p>#15yrsago Sky Marshals to lose their cushy first-class seats? <a href="https://web.archive.org/web/20160521034617/https://www.wsj.com/article_email/SB10001424052748703431604575521832473932878-lMyQjAxMTAwMDIwOTEyNDkyWj.html">https://web.archive.org/web/20160521034617/https://www.wsj.com/article_email/SB10001424052748703431604575521832473932878-lMyQjAxMTAwMDIwOTEyNDkyWj.html</a></p>
<p>#15yrsago Michael Swanwick writes a story about autumn on fallen leaves <a href="https://www.flickr.com/photos/54366973@N04/5035946705/in/photostream/">https://www.flickr.com/photos/54366973@N04/5035946705/in/photostream/</a></p>
<p>#15yrsago Why the copyright wars matter: a reply to Helienne Lindvall <a href="https://www.theguardian.com/technology/blog/2010/oct/05/free-online-content-cory-doctorow">https://www.theguardian.com/technology/blog/2010/oct/05/free-online-content-cory-doctorow</a></p>
<p>#15yrsago William Gibson nails my philosophy in life <a href="https://memex.craphound.com/2010/10/04/william-gibson-nails-my-philosophy-in-life/">https://memex.craphound.com/2010/10/04/william-gibson-nails-my-philosophy-in-life/</a></p>
<p>#10yrsago Car accidents aren’t accidents <a href="https://www.wired.com/2015/10/stop-calling-daughters-death-car-accident/">https://www.wired.com/2015/10/stop-calling-daughters-death-car-accident/</a></p>
<p>#10yrsago How a romance-scam victim laundered $1.1M worth of other victims’ money <a href="https://www.wired.com/2015/10/online-dating-made-woman-pawn-global-crime-plot/">https://www.wired.com/2015/10/online-dating-made-woman-pawn-global-crime-plot/</a></p>
<p>#10yrsago Snowden broke a nondisclosure EULA in order to uphold his Constitutional oath <a href="https://www.aaronswartzday.org/snowden-oath/">https://www.aaronswartzday.org/snowden-oath/</a></p>
<p>#10yrsago What it’s like to do a lockdown drill with kindergarten kids <a href="https://web.archive.org/web/20141029062211/https://www.washingtonpost.com/opinions/rehearsing-for-death-a-pre-k-teacher-on-the-trouble-with-lockdown-drills/2014/10/28/4ab456ea-5eb2-11e4-9f3a-7e28799e0549_story.html">https://web.archive.org/web/20141029062211/https://www.washingtonpost.com/opinions/rehearsing-for-death-a-pre-k-teacher-on-the-trouble-with-lockdown-drills/2014/10/28/4ab456ea-5eb2-11e4-9f3a-7e28799e0549_story.html</a></p>
<p>#10yrsago Forget tidying: losing your precious possessions is the real “life-changing magic” <a href="https://medium.com/chrysaora-weekly/the-life-changing-magic-of-losing-shit-18122103f499">https://medium.com/chrysaora-weekly/the-life-changing-magic-of-losing-shit-18122103f499</a></p>
<p>#10yrsago UK Chancellor: I must cut tax benefits for working poor to help them <a href="https://www.independent.co.uk/news/uk/politics/the-low-paid-will-suffer-if-i-don-t-cut-their-tax-credits-says-george-osborne-a6679636.html">https://www.independent.co.uk/news/uk/politics/the-low-paid-will-suffer-if-i-don-t-cut-their-tax-credits-says-george-osborne-a6679636.html</a></p>
<p>#10yrsago UK top government official: human rights no longer a “top priority” <a href="https://www.independent.co.uk/news/uk/politics/human-rights-are-no-longer-a-top-priority-for-the-government-says-foreign-office-chief-a6677661.html">https://www.independent.co.uk/news/uk/politics/human-rights-are-no-longer-a-top-priority-for-the-government-says-foreign-office-chief-a6677661.html</a></p>
<p>#5yrsago Facebook's living will <a href="https://pluralistic.net/2020/10/05/florida-man/#dnr">https://pluralistic.net/2020/10/05/florida-man/#dnr</a></p>
<p>#5yrsago Ad-tech is a bubble <a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>#5yrsago The Internet is for End-Users <a href="https://pluralistic.net/2020/10/05/florida-man/#user-agents">https://pluralistic.net/2020/10/05/florida-man/#user-agents</a></p>
<p>#5yrsago Squeeze Me <a href="https://pluralistic.net/2020/10/05/florida-man/#disappearing-act">https://pluralistic.net/2020/10/05/florida-man/#disappearing-act</a></p>
<p>#5yrsago Why I love the Haunted Mansion <a href="https://pluralistic.net/2020/10/04/build-back-better/#grim-grinning-ghosts">https://pluralistic.net/2020/10/04/build-back-better/#grim-grinning-ghosts</a></p>
<p>#5yrsago Normal isn't enough <a href="https://pluralistic.net/2020/10/04/build-back-better/#post-pandemic">https://pluralistic.net/2020/10/04/build-back-better/#post-pandemic</a></p>
<hr>

<h2 heds="0">Upcoming appearances (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#upcoming">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" alt="A photo of me onstage, giving a speech, pounding the podium." src="https://i0.wp.com/craphound.com/images/appearances2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Boston: Enshittification with Randall Munroe (Brattle Theater), Oct 7<br>
<a href="https://www.eventbrite.com/e/cory-doctorow-at-the-brattle-theatre-tickets-1591235180259?aff=oddtdtcreator">https://www.eventbrite.com/e/cory-doctorow-at-the-brattle-theatre-tickets-1591235180259?aff=oddtdtcreator</a>
</li>
<li>
<p>DC: Enshittification with Rohit Chopra (Politics and Prose), Oct 8<br>
<a href="https://politics-prose.com/cory-doctorow-10825">https://politics-prose.com/cory-doctorow-10825</a></p>
</li>
<li>
<p>NYC: Enshittification with Lina Khan (Brooklyn Public Library), Oct 9<br>
<a href="https://www.bklynlibrary.org/calendar/cory-doctorow-discusses-central-library-dweck-20251009-0700pm">https://www.bklynlibrary.org/calendar/cory-doctorow-discusses-central-library-dweck-20251009-0700pm</a></p>
</li>
<li>
<p>New Orleans: DeepSouthCon63, Oct 10-12<br>
<a href="http://www.contraflowscifi.org/">http://www.contraflowscifi.org/</a></p>
</li>
<li>
<p>New Orleans: Enshittification at Octavia Books, Oct 12<br>
<a href="https://www.octaviabooks.com/event/enshittification-cory-doctorow">https://www.octaviabooks.com/event/enshittification-cory-doctorow</a></p>
</li>
<li>
<p>Chicago: How Platforms Die with Rick Perlstein (University Club), Oct 14<br>
<a href="https://www.eventbrite.com/e/how-platforms-die-with-cory-doctorow-tickets-1747916117159">https://www.eventbrite.com/e/how-platforms-die-with-cory-doctorow-tickets-1747916117159</a></p>
</li>
<li>
<p>Los Angeles: Enshittification with David Dayen (Diesel), Oct 16<br>
<a href="https://dieselbookstore.com/event/2025-10-16/cory-doctorow-enshittification">https://dieselbookstore.com/event/2025-10-16/cory-doctorow-enshittification</a></p>
</li>
<li>
<p>San Francisco: Enshittification at Public Works with Jenny Odell (The Booksmith), Oct 20<br>
<a href="https://app.gopassage.com/events/doctorow25">https://app.gopassage.com/events/doctorow25</a></p>
</li>
<li>
<p>PDX: Enshittification at Powell's, Oct 21<br>
<a href="https://www.powells.com/events/cory-doctorow-10-21-25">https://www.powells.com/events/cory-doctorow-10-21-25</a></p>
</li>
<li>
<p>Seattle: Enshittification and the Rot Economy, with Ed Zitron (Clarion West), Oct 22<br>
<a href="https://www.clarionwest.org/event/2025-deep-dives-cory-doctorow/">https://www.clarionwest.org/event/2025-deep-dives-cory-doctorow/</a></p>
</li>
<li>
<p>Vancouver: Enshittification with David Moscrop (Vancouver Writers Festival), Oct 23<br>
<a href="https://www.showpass.com/2025-festival-39/">https://www.showpass.com/2025-festival-39/</a></p>
</li>
<li>
<p>Montreal: Montreal Attention Forum keynote, Oct 24<br>
<a href="https://www.attentionconferences.com/conferences/2025-forum">https://www.attentionconferences.com/conferences/2025-forum</a></p>
</li>
<li>
<p>Montreal: Enshittification at Librarie Drawn and Quarterly, Oct 24<br>
<a href="https://mtl.drawnandquarterly.com/events/3757420251024">https://mtl.drawnandquarterly.com/events/3757420251024</a></p>
</li>
<li>
<p>Ottawa: Enshittification (Ottawa Writers Festival), Oct 25<br>
<a href="https://writersfestival.org/events/fall-2025/enshittification">https://writersfestival.org/events/fall-2025/enshittification</a></p>
</li>
<li>
<p>Toronto: Enshittification with Dan Werb (Type Books), Oct 27<br>
<a href="https://www.instagram.com/p/DO81_1VDngu/?img_index=1">https://www.instagram.com/p/DO81_1VDngu/?img_index=1</a></p>
</li>
<li>
<p>Barcelona: Conferencia EUROPEA 4D (Virtual), Oct 28<br>
<a href="https://4d.cat/es/conferencia/">https://4d.cat/es/conferencia/</a></p>
</li>
<li>
<p>Miami: Enshittification at Books &amp; Books, Nov 5<br>
<a href="https://www.eventbrite.com/e/an-evening-with-cory-doctorow-tickets-1504647263469">https://www.eventbrite.com/e/an-evening-with-cory-doctorow-tickets-1504647263469</a></p>
</li>
<li>
<p>Miami: Cloudfest, Nov 6<br>
<a href="https://www.cloudfest.com/usa/">https://www.cloudfest.com/usa/</a></p>
</li>
<li>
<p>Burbank: Burbank Book Festival, Nov 8<br>
<a href="https://www.burbankbookfestival.com/">https://www.burbankbookfestival.com/</a></p>
</li>
<li>
<p>Lisbon: A post-American, enshittification-resistant internet, with Rabble (Web Summit), Nov 12<br>
<a href="https://websummit.com/sessions/lis25/92f47bc9-ca60-4997-bef3-006735b1f9c5/a-post-american-enshittification-resistant-internet/">https://websummit.com/sessions/lis25/92f47bc9-ca60-4997-bef3-006735b1f9c5/a-post-american-enshittification-resistant-internet/</a></p>
</li>
<li>
<p>Cardiff: Hay Festival After Hours, Nov 13<br>
<a href="https://www.hayfestival.com/c-203-hay-festival-after-hours.aspx">https://www.hayfestival.com/c-203-hay-festival-after-hours.aspx</a></p>
</li>
</ul>
<hr>
<p><a name="recent"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A screenshot of me at my desk, doing a livecast." src="https://i0.wp.com/craphound.com/images/recentappearances2.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Recent appearances (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#recent">permalink</a>)</h2>
<ul>
<li>Enshittification (The.Ink)<br>
<a href="https://the.ink/p/watch-cory-doctorow-on-why-everything">https://the.ink/p/watch-cory-doctorow-on-why-everything</a>
</li>
<li>
<p>Why Everything Is Getting Worse (Majority Report)<br>
<a href="https://www.youtube.com/watch?v=EQW6UxY144Q">https://www.youtube.com/watch?v=EQW6UxY144Q</a></p>
</li>
</ul>
<hr>
<p><a name="latest"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A grid of my books with Will Stahle covers.." src="https://i0.wp.com/craphound.com/images/recent.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Latest books (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#latest">permalink</a>)</h2>
<ul>
<li>"Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (<a href="https://us.macmillan.com/books/9781250865908/picksandshovels">https://us.macmillan.com/books/9781250865908/picksandshovels</a>).
</li>
<li>
<p>"The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (<a href="http://the-bezzle.org/">the-bezzle.org</a>).</p>
</li>
<li>
<p>"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href="http://lost-cause.org/">http://lost-cause.org</a>).</p>
</li>
<li>
<p>"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href="http://seizethemeansofcomputation.org/">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href="https://www.booksoup.com/book/9781804291245">https://www.booksoup.com/book/9781804291245</a>).</p>
</li>
<li>
<p>"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books <a href="http://redteamblues.com/">http://redteamblues.com</a>.</p>
</li>
<li>
<p>"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href="https://chokepointcapitalism.com/">https://chokepointcapitalism.com</a></p>
</li>
</ul>
<hr>
<p><a name="upcoming-books"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A cardboard book box with the Macmillan logo." src="https://i0.wp.com/craphound.com/images/upcoming-books.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Upcoming books (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#upcoming-books">permalink</a>)</h2>
<ul>
<li>"Canny Valley": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025
</li>
<li>
<p>"Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025<br>
<a href="https://us.macmillan.com/books/9780374619329/enshittification/">https://us.macmillan.com/books/9780374619329/enshittification/</a></p>
</li>
<li>
<p>"Unauthorized Bread": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026</p>
</li>
<li>
<p>"Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026</p>
</li>
<li>
<p>"The Memex Method," Farrar, Straus, Giroux, 2026</p>
</li>
<li>
<p>"The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, 2026</p>
</li>
</ul>
<hr>
<p><a name="bragsheet"></a><br>
<img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/colophon2.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Colophon (<a href="https://pluralistic.net/2025/10/06/america-with-chinese-characteristics/#bragsheet">permalink</a>)</h2>
<p>Today's top sources:</p>
<p><b>Currently writing: </b></p>
<ul>
<li>"The Reverse Centaur's Guide to AI," a short book for Farrar, Straus and Giroux about being an effective AI critic. FIRST DRAFT COMPLETE AND SUBMITTED.
</li>
<li>
<p>A Little Brother short story about DIY insulin PLANNING</p>
</li>
</ul>
<hr>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1"></p>
<p>This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>
<h2>How to get Pluralistic:</h2>
<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/@pluralistic">https://mamot.fr/@pluralistic</a></p>
<p>Medium (no ads, paywalled):</p>
<p><a href="https://doctorow.medium.com/">https://doctorow.medium.com/</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p>"<em>When life gives you SARS, you make sarsaparilla</em>" -Joey "Accordion Guy" DeVilla</p>
<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>
<p>ISSN: 3066-764X</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mise: Monorepo Tasks (266 pts)]]></title>
            <link>https://github.com/jdx/mise/discussions/6564</link>
            <guid>45491621</guid>
            <pubDate>Mon, 06 Oct 2025 14:07:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jdx/mise/discussions/6564">https://github.com/jdx/mise/discussions/6564</a>, See on <a href="https://news.ycombinator.com/item?id=45491621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="8992188" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">We're excited to announce <strong>Monorepo Tasks</strong>, a powerful new feature that brings first-class monorepo support to mise tasks! 🚀</p>
<h2 dir="auto">What is it?</h2>
<p dir="auto">Monorepo Tasks allows you to manage tasks across multiple projects in a single repository, with each project maintaining its own tools, environment variables, and tasks. Think of it as bringing the power of tools like Bazel or Turborepo to mise's task system, but with mise's signature simplicity.</p>
<h2 dir="auto">Key Features</h2>
<h3 dir="auto">🎯 <strong>Unified Task Namespace</strong></h3>
<p dir="auto">All tasks across your monorepo are automatically discovered and prefixed with their location:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mise //projects/frontend:build
mise //projects/backend:test
mise //services/api:deploy"><pre>mise //projects/frontend:build
mise //projects/backend:test
mise //services/api:deploy</pre></div>
<h3 dir="auto">🌳 <strong>Smart Tool &amp; Environment Inheritance</strong></h3>
<p dir="auto">Define common tools at the root, override them where needed:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Root mise.toml
[tools]
node = &quot;20&quot;      # Inherited everywhere
python = &quot;3.12&quot;

# projects/legacy-app/mise.toml
[tools]
node = &quot;14&quot;      # Override just for this project
# python still inherited!"><pre><span><span>#</span> Root mise.toml</span>
[<span>tools</span>]
<span>node</span> = <span><span>"</span>20<span>"</span></span>      <span><span>#</span> Inherited everywhere</span>
<span>python</span> = <span><span>"</span>3.12<span>"</span></span>

<span><span>#</span> projects/legacy-app/mise.toml</span>
[<span>tools</span>]
<span>node</span> = <span><span>"</span>14<span>"</span></span>      <span><span>#</span> Override just for this project</span>
<span><span>#</span> python still inherited!</span></pre></div>
<h3 dir="auto">🎭 <strong>Powerful Wildcard Patterns</strong></h3>
<p dir="auto">Run tasks across multiple projects with ease:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run tests in ALL projects
mise //...:test

# Run all build tasks under services/
mise //services/...:build

# Run ALL tasks in frontend (wildcards need quotes)
mise '//projects/frontend:*'

# Run all test:* tasks everywhere
mise '//...:test:*'"><pre><span><span>#</span> Run tests in ALL projects</span>
mise //...:test

<span><span>#</span> Run all build tasks under services/</span>
mise //services/...:build

<span><span>#</span> Run ALL tasks in frontend (wildcards need quotes)</span>
mise <span><span>'</span>//projects/frontend:*<span>'</span></span>

<span><span>#</span> Run all test:* tasks everywhere</span>
mise <span><span>'</span>//...:test:*<span>'</span></span></pre></div>
<h3 dir="auto">✨ <strong>Consistent Execution Anywhere</strong></h3>
<p dir="auto">Run tasks from anywhere in the monorepo - they always execute with the correct context, tools, and environment from their config_root.</p>
<h3 dir="auto">🔒 <strong>Automatic Trust Propagation</strong></h3>
<p dir="auto">Trust your monorepo root once, and all descendant configs are automatically trusted.</p>
<h2 dir="auto">Quick Start</h2>
<p dir="auto"><strong>1. Enable the feature in your root <code>mise.toml</code>:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="experimental_monorepo_root = true

[tools]
node = &quot;20&quot;
python = &quot;3.12&quot;"><pre><span>experimental_monorepo_root</span> = <span>true</span>

[<span>tools</span>]
<span>node</span> = <span><span>"</span>20<span>"</span></span>
<span>python</span> = <span><span>"</span>3.12<span>"</span></span></pre></div>
<p dir="auto"><strong>2. Set the experimental flag:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="export MISE_EXPERIMENTAL=1"><pre><span>export</span> MISE_EXPERIMENTAL=1</pre></div>
<p dir="auto"><strong>3. Add tasks to your projects:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# projects/frontend/mise.toml
[tasks.build]
run = &quot;npm run build&quot;

[tasks.test]
run = &quot;npm test&quot;"><pre><span><span>#</span> projects/frontend/mise.toml</span>
[<span>tasks</span>.<span>build</span>]
<span>run</span> = <span><span>"</span>npm run build<span>"</span></span>

[<span>tasks</span>.<span>test</span>]
<span>run</span> = <span><span>"</span>npm test<span>"</span></span></pre></div>
<p dir="auto"><strong>4. Run tasks from anywhere:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="mise //projects/frontend:build
mise //...:test  # Run tests in all projects!"><pre>mise //projects/frontend:build
mise //...:test  <span><span>#</span> Run tests in all projects!</span></pre></div>
<h2 dir="auto">Example Monorepo Structure</h2>
<div data-snippet-clipboard-copy-content="myproject/
├── mise.toml (experimental_monorepo_root = true)
├── services/
│   ├── api/mise.toml
│   ├── worker/mise.toml
│   └── scheduler/mise.toml
└── apps/
    ├── web/mise.toml
    └── mobile/mise.toml"><pre><code>myproject/
├── mise.toml (experimental_monorepo_root = true)
├── services/
│   ├── api/mise.toml
│   ├── worker/mise.toml
│   └── scheduler/mise.toml
└── apps/
    ├── web/mise.toml
    └── mobile/mise.toml
</code></pre></div>
<p dir="auto">Run all service builds: <code>mise //services/...:build</code><br>
Run all app tests: <code>mise //apps/...:test</code><br>
Run everything: <code>mise '//...:*'</code> (if you're brave! 😄)</p>
<h2 dir="auto">Why This Matters</h2>
<p dir="auto">Managing monorepos is hard. Coordinating tools, tasks, and environments across dozens of projects is even harder. With Monorepo Tasks, you get:</p>
<ul dir="auto">
<li><strong>No more repetitive scripts</strong> - Define once, run anywhere</li>
<li><strong>Consistent environments</strong> - Each project gets exactly the tools it needs</li>
<li><strong>Powerful automation</strong> - Wildcards make CI/CD pipelines a breeze</li>
<li><strong>Better developer experience</strong> - Clear, discoverable task namespacing</li>
</ul>
<h2 dir="auto">How Does This Compare to Other Tools?</h2>
<p dir="auto">The monorepo ecosystem is rich with excellent tools, each with different strengths. Here's how mise's Monorepo Tasks compares:</p>
<h3 dir="auto">Simple Task Runners</h3>
<p dir="auto"><strong>Taskfile</strong> and <strong>Just</strong> are fantastic for single-project task automation. They're lightweight and easy to set up, but they weren't designed with monorepos in mind. While you can have multiple Taskfiles/Justfiles in a repo, they don't provide unified task discovery, cross-project wildcards, or automatic tool/environment inheritance across projects.</p>
<p dir="auto"><strong>mise's advantage:</strong> Automatic task discovery across the entire monorepo with a unified namespace and powerful wildcard patterns.</p>
<h3 dir="auto">JavaScript-Focused Tools</h3>
<p dir="auto"><strong>Nx</strong>, <strong>Turborepo</strong>, and <strong>Lerna</strong> are powerful tools specifically designed for JavaScript/TypeScript monorepos.</p>
<ul dir="auto">
<li><strong>Nx</strong> offers incredible features like dependency graph visualization, affected project detection, code generation, and computation caching. It has a massive plugin ecosystem and excels at frontend monorepos.</li>
<li><strong>Turborepo</strong> focuses on blazing-fast task caching and parallel execution with minimal configuration.</li>
<li><strong>Lerna</strong> pioneered JavaScript monorepo management with package versioning and publishing workflows.</li>
</ul>
<p dir="auto"><strong>mise's advantage:</strong> Language-agnostic support. While these tools excel in JS/TS ecosystems, mise works equally well with Rust, Go, Python, Ruby, or any mix of languages. You also get unified tool version management (not just tasks) and environment variables across your entire stack.</p>
<h3 dir="auto">Large-Scale Build Systems</h3>
<p dir="auto"><strong>Bazel</strong> (Google) and <strong>Buck2</strong> (Meta) are industrial-strength build systems designed for massive, multi-language monorepos at companies with thousands of engineers.</p>
<ul dir="auto">
<li><strong>Bazel</strong> offers incredible features like distributed caching, remote execution, and hermetic builds with fine-grained dependency tracking.</li>
<li><strong>Buck2</strong> is a modern rewrite with a clean architecture and impressive performance optimizations.</li>
</ul>
<p dir="auto">Both are extremely powerful but come with significant complexity:</p>
<ul dir="auto">
<li>Hermetic builds require strict isolation and complete dependency control</li>
<li>Steep learning curve with specialized DSLs (Starlark, etc.)</li>
<li>Complex configuration requiring dedicated build engineers</li>
<li>Heavy investment in infrastructure for remote caching</li>
<li>Stricter constraints on how you structure your code</li>
</ul>
<p dir="auto"><strong>mise's advantage:</strong> Simplicity through non-hermetic builds. mise doesn't try to control your entire build environment in isolation - instead, it manages tools and tasks in a flexible, practical way. This "non-hermetic" approach means you can use mise without restructuring your entire codebase or learning a new language. You get powerful monorepo task management with simple TOML configuration - enough power for most teams without the enterprise-level complexity that hermetic builds require.</p>
<h3 dir="auto">Other Notable Tools</h3>
<p dir="auto"><strong>Rush</strong> (Microsoft) offers strict dependency management and build orchestration for JavaScript monorepos, with a focus on safety and convention adherence.</p>
<p dir="auto"><strong>Moon</strong> is a newer Rust-based build system that aims to be developer-friendly while supporting multiple languages.</p>
<h3 dir="auto">The mise Sweet Spot</h3>
<p dir="auto">mise's Monorepo Tasks aims to hit the sweet spot between simplicity and power:</p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>Feature</th>
<th>Simple Runners</th>
<th>JS-Focused</th>
<th>Build Systems</th>
<th>mise</th>
</tr>
</thead>
<tbody>
<tr>
<td>Multi-language support</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Easy to learn</td>
<td>✅</td>
<td><g-emoji alias="warning">⚠️</g-emoji></td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Unified task discovery</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Wildcard patterns</td>
<td>❌</td>
<td><g-emoji alias="warning">⚠️</g-emoji></td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Tool version management</td>
<td>❌</td>
<td>❌</td>
<td><g-emoji alias="warning">⚠️</g-emoji></td>
<td>✅</td>
</tr>
<tr>
<td>Environment inheritance</td>
<td>❌</td>
<td><g-emoji alias="warning">⚠️</g-emoji></td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Minimal setup</td>
<td>✅</td>
<td><g-emoji alias="warning">⚠️</g-emoji></td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Task caching</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>When to choose mise:</strong></p>
<ul dir="auto">
<li>✅ Polyglot monorepos (multiple languages)</li>
<li>✅ You want unified tool + task management</li>
<li>✅ You prefer simplicity over maximum performance</li>
<li>✅ You're already using mise for tool management</li>
</ul>
<p dir="auto"><strong>When to consider alternatives:</strong></p>
<ul dir="auto">
<li>You're exclusively JavaScript/TypeScript → Nx or Turborepo might offer more JS-specific features</li>
<li>You're at Google/Meta scale with thousands of engineers → Bazel or Buck2 offer distributed build infrastructure</li>
<li>You need advanced task caching → Nx, Turborepo, or Bazel offer sophisticated caching systems</li>
</ul>
<p dir="auto">The best tool is the one that fits your team's needs. mise's Monorepo Tasks is designed for teams who want powerful monorepo management without the complexity overhead, especially when working across multiple languages.</p>
<h2 dir="auto">Try It Out!</h2>
<p dir="auto">This feature is <strong>experimental</strong>, which means:</p>
<ul dir="auto">
<li>✅ It's fully functional and ready to use</li>
<li><g-emoji alias="warning">⚠️</g-emoji> The API might evolve based on feedback</li>
<li>💬 We'd love to hear your thoughts!</li>
</ul>
<p dir="auto"><strong>Read the full documentation:</strong> <a href="https://mise.jdx.dev/tasks/monorepo.html" rel="nofollow">Monorepo Tasks Guide</a></p>
<h2 dir="auto">We Want Your Feedback!</h2>
<p dir="auto">Please try it out and let us know:</p>
<ul dir="auto">
<li>What works well?</li>
<li>What could be better?</li>
<li>What features are missing?</li>
<li>How are you using it?</li>
</ul>
<p dir="auto">Share your experience in the comments below! 👇</p>
<hr>
<p dir="auto">Special shoutout to the mise community for the feedback and ideas that led to this feature. Happy building! 🛠️</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Kent Dybvig's Scheme Machine in 400 Lines of C (Heap-Memory Model) (169 pts)]]></title>
            <link>https://gist.github.com/swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b</link>
            <guid>45491609</guid>
            <pubDate>Mon, 06 Oct 2025 14:06:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b">https://gist.github.com/swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b</a>, See on <a href="https://news.ycombinator.com/item?id=45491609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="" data-tab-size="4" data-paste-markdown-skip="" data-tagsearch-path="heap-lisp.c">
        <tbody><tr>
          <td id="file-heap-lisp-c-L1" data-line-number="1"></td>
          <td id="file-heap-lisp-c-LC1"><span>/* Heap based virtual machine described in section 3.4 of Three Implementation Models for Scheme, Dybvig</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L2" data-line-number="2"></td>
          <td id="file-heap-lisp-c-LC2"><span> */</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L3" data-line-number="3"></td>
          <td id="file-heap-lisp-c-LC3">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L4" data-line-number="4"></td>
          <td id="file-heap-lisp-c-LC4"><span>#include</span> <span>&lt;stdio.h&gt;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L5" data-line-number="5"></td>
          <td id="file-heap-lisp-c-LC5"><span>#include</span> <span>&lt;stdlib.h&gt;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L6" data-line-number="6"></td>
          <td id="file-heap-lisp-c-LC6"><span>#include</span> <span>&lt;string.h&gt;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L7" data-line-number="7"></td>
          <td id="file-heap-lisp-c-LC7"><span>#include</span> <span>&lt;ctype.h&gt;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L8" data-line-number="8"></td>
          <td id="file-heap-lisp-c-LC8"><span>#include</span> <span>&lt;assert.h&gt;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L9" data-line-number="9"></td>
          <td id="file-heap-lisp-c-LC9">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L10" data-line-number="10"></td>
          <td id="file-heap-lisp-c-LC10"><span>char</span> <span>token</span>[<span>128</span>][<span>32</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L11" data-line-number="11"></td>
          <td id="file-heap-lisp-c-LC11">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L12" data-line-number="12"></td>
          <td id="file-heap-lisp-c-LC12"><span>int</span> <span>lexer</span>(<span>char</span><span>*</span> <span>input</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L13" data-line-number="13"></td>
          <td id="file-heap-lisp-c-LC13">  <span>int</span> <span>ii</span> <span>=</span> <span>0</span>; <span>// input index</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L14" data-line-number="14"></td>
          <td id="file-heap-lisp-c-LC14">  <span>int</span> <span>ti</span> <span>=</span> <span>0</span>; <span>// token index</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L15" data-line-number="15"></td>
          <td id="file-heap-lisp-c-LC15">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L16" data-line-number="16"></td>
          <td id="file-heap-lisp-c-LC16">  <span>while</span>(<span>input</span>[<span>ii</span>] <span>!=</span> <span>'\0'</span>)</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L17" data-line-number="17"></td>
          <td id="file-heap-lisp-c-LC17">    <span>switch</span>(<span>input</span>[<span>ii</span>]) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L18" data-line-number="18"></td>
          <td id="file-heap-lisp-c-LC18">    <span>// Ignore whitespace and newlines</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L19" data-line-number="19"></td>
          <td id="file-heap-lisp-c-LC19">    <span>case</span> <span>' '</span>:</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L20" data-line-number="20"></td>
          <td id="file-heap-lisp-c-LC20">    <span>case</span> <span>'\n'</span>:</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L21" data-line-number="21"></td>
          <td id="file-heap-lisp-c-LC21">      <span>++</span><span>ii</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L22" data-line-number="22"></td>
          <td id="file-heap-lisp-c-LC22">      <span>break</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L23" data-line-number="23"></td>
          <td id="file-heap-lisp-c-LC23">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L24" data-line-number="24"></td>
          <td id="file-heap-lisp-c-LC24">    <span>// Turn a left parenthesis into a token.</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L25" data-line-number="25"></td>
          <td id="file-heap-lisp-c-LC25">    <span>case</span> <span>'('</span>:</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L26" data-line-number="26"></td>
          <td id="file-heap-lisp-c-LC26">      <span>token</span>[<span>ti</span>][<span>0</span>] <span>=</span> <span>'('</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L27" data-line-number="27"></td>
          <td id="file-heap-lisp-c-LC27">      <span>token</span>[<span>ti</span>][<span>1</span>] <span>=</span> <span>'\0'</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L28" data-line-number="28"></td>
          <td id="file-heap-lisp-c-LC28">      <span>++</span><span>ii</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L29" data-line-number="29"></td>
          <td id="file-heap-lisp-c-LC29">      <span>++</span><span>ti</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L30" data-line-number="30"></td>
          <td id="file-heap-lisp-c-LC30">      <span>break</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L31" data-line-number="31"></td>
          <td id="file-heap-lisp-c-LC31">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L32" data-line-number="32"></td>
          <td id="file-heap-lisp-c-LC32">    <span>// Turn a right parenthesis into a token.</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L33" data-line-number="33"></td>
          <td id="file-heap-lisp-c-LC33">    <span>case</span> <span>')'</span>:</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L34" data-line-number="34"></td>
          <td id="file-heap-lisp-c-LC34">      <span>token</span>[<span>ti</span>][<span>0</span>] <span>=</span> <span>')'</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L35" data-line-number="35"></td>
          <td id="file-heap-lisp-c-LC35">      <span>token</span>[<span>ti</span>][<span>1</span>] <span>=</span> <span>'\0'</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L36" data-line-number="36"></td>
          <td id="file-heap-lisp-c-LC36">      <span>++</span><span>ii</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L37" data-line-number="37"></td>
          <td id="file-heap-lisp-c-LC37">      <span>++</span><span>ti</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L38" data-line-number="38"></td>
          <td id="file-heap-lisp-c-LC38">      <span>break</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L39" data-line-number="39"></td>
          <td id="file-heap-lisp-c-LC39">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L40" data-line-number="40"></td>
          <td id="file-heap-lisp-c-LC40">    <span>// Turn an apostrophe into a token.</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L41" data-line-number="41"></td>
          <td id="file-heap-lisp-c-LC41">    <span>case</span> <span>'\''</span>:</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L42" data-line-number="42"></td>
          <td id="file-heap-lisp-c-LC42">      <span>token</span>[<span>ti</span>][<span>0</span>] <span>=</span> <span>'\''</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L43" data-line-number="43"></td>
          <td id="file-heap-lisp-c-LC43">      <span>token</span>[<span>ti</span>][<span>1</span>] <span>=</span> <span>'\0'</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L44" data-line-number="44"></td>
          <td id="file-heap-lisp-c-LC44">      <span>++</span><span>ii</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L45" data-line-number="45"></td>
          <td id="file-heap-lisp-c-LC45">      <span>++</span><span>ti</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L46" data-line-number="46"></td>
          <td id="file-heap-lisp-c-LC46">      <span>break</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L47" data-line-number="47"></td>
          <td id="file-heap-lisp-c-LC47">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L48" data-line-number="48"></td>
          <td id="file-heap-lisp-c-LC48">    <span>// Anything else is a symbol</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L49" data-line-number="49"></td>
          <td id="file-heap-lisp-c-LC49">    <span>default</span>:</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L50" data-line-number="50"></td>
          <td id="file-heap-lisp-c-LC50">      <span>for</span>(<span>int</span> <span>i</span> <span>=</span> <span>0</span>;; <span>++</span><span>i</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L51" data-line-number="51"></td>
          <td id="file-heap-lisp-c-LC51">	<span>if</span>(<span>input</span>[<span>ii</span>] <span>!=</span> <span>' '</span>  <span>&amp;&amp;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L52" data-line-number="52"></td>
          <td id="file-heap-lisp-c-LC52">	   <span>input</span>[<span>ii</span>] <span>!=</span> <span>')'</span>  <span>&amp;&amp;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L53" data-line-number="53"></td>
          <td id="file-heap-lisp-c-LC53">           <span>input</span>[<span>ii</span>] <span>!=</span> <span>'('</span>  <span>&amp;&amp;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L54" data-line-number="54"></td>
          <td id="file-heap-lisp-c-LC54">           <span>input</span>[<span>ii</span>] <span>!=</span> <span>'\n'</span> <span>&amp;&amp;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L55" data-line-number="55"></td>
          <td id="file-heap-lisp-c-LC55">           <span>input</span>[<span>ii</span>] <span>!=</span> <span>'\0'</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L56" data-line-number="56"></td>
          <td id="file-heap-lisp-c-LC56">          <span>token</span>[<span>ti</span>][<span>i</span>] <span>=</span> <span>input</span>[<span>ii</span><span>++</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L57" data-line-number="57"></td>
          <td id="file-heap-lisp-c-LC57">        }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L58" data-line-number="58"></td>
          <td id="file-heap-lisp-c-LC58">        <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L59" data-line-number="59"></td>
          <td id="file-heap-lisp-c-LC59">          <span>token</span>[<span>ti</span>][<span>i</span>] <span>=</span> <span>'\0'</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L60" data-line-number="60"></td>
          <td id="file-heap-lisp-c-LC60">          <span>break</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L61" data-line-number="61"></td>
          <td id="file-heap-lisp-c-LC61">        }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L62" data-line-number="62"></td>
          <td id="file-heap-lisp-c-LC62">      }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L63" data-line-number="63"></td>
          <td id="file-heap-lisp-c-LC63">      <span>++</span><span>ti</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L64" data-line-number="64"></td>
          <td id="file-heap-lisp-c-LC64">      <span>break</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L65" data-line-number="65"></td>
          <td id="file-heap-lisp-c-LC65">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L66" data-line-number="66"></td>
          <td id="file-heap-lisp-c-LC66">  <span>return</span> <span>ti</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L67" data-line-number="67"></td>
          <td id="file-heap-lisp-c-LC67">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L68" data-line-number="68"></td>
          <td id="file-heap-lisp-c-LC68">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L69" data-line-number="69"></td>
          <td id="file-heap-lisp-c-LC69"><span>int</span> <span>curtok</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L70" data-line-number="70"></td>
          <td id="file-heap-lisp-c-LC70">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L71" data-line-number="71"></td>
          <td id="file-heap-lisp-c-LC71"><span>char</span><span>*</span> <span>nexttok</span>() {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L72" data-line-number="72"></td>
          <td id="file-heap-lisp-c-LC72">  <span>return</span> <span>token</span>[<span>curtok</span><span>++</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L73" data-line-number="73"></td>
          <td id="file-heap-lisp-c-LC73">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L74" data-line-number="74"></td>
          <td id="file-heap-lisp-c-LC74">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L75" data-line-number="75"></td>
          <td id="file-heap-lisp-c-LC75"><span>char</span><span>*</span> <span>peektok</span>() {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L76" data-line-number="76"></td>
          <td id="file-heap-lisp-c-LC76">  <span>return</span> <span>token</span>[<span>curtok</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L77" data-line-number="77"></td>
          <td id="file-heap-lisp-c-LC77">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L78" data-line-number="78"></td>
          <td id="file-heap-lisp-c-LC78">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L79" data-line-number="79"></td>
          <td id="file-heap-lisp-c-LC79">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L80" data-line-number="80"></td>
          <td id="file-heap-lisp-c-LC80"><span>typedef</span> <span>struct</span> <span>Pair</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L81" data-line-number="81"></td>
          <td id="file-heap-lisp-c-LC81">  <span>void</span><span>*</span> <span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L82" data-line-number="82"></td>
          <td id="file-heap-lisp-c-LC82">  <span>void</span><span>*</span> <span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L83" data-line-number="83"></td>
          <td id="file-heap-lisp-c-LC83">} <span>Pair</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L84" data-line-number="84"></td>
          <td id="file-heap-lisp-c-LC84">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L85" data-line-number="85"></td>
          <td id="file-heap-lisp-c-LC85"><span>typedef</span> <span>struct</span> <span>Text</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L86" data-line-number="86"></td>
          <td id="file-heap-lisp-c-LC86">  <span>char</span><span>*</span> <span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L87" data-line-number="87"></td>
          <td id="file-heap-lisp-c-LC87">  <span>struct</span> <span>Text</span><span>*</span> <span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L88" data-line-number="88"></td>
          <td id="file-heap-lisp-c-LC88">} <span>Text</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L89" data-line-number="89"></td>
          <td id="file-heap-lisp-c-LC89">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L90" data-line-number="90"></td>
          <td id="file-heap-lisp-c-LC90"><span>Pair</span> <span>text</span>[<span>1280</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L91" data-line-number="91"></td>
          <td id="file-heap-lisp-c-LC91"><span>Pair</span><span>*</span> <span>textptr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L92" data-line-number="92"></td>
          <td id="file-heap-lisp-c-LC92">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L93" data-line-number="93"></td>
          <td id="file-heap-lisp-c-LC93"><span>int</span> <span>istext</span>(<span>void</span><span>*</span> <span>x</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L94" data-line-number="94"></td>
          <td id="file-heap-lisp-c-LC94">  <span>return</span> <span>x</span> &gt;= (<span>void</span><span>*</span>)<span>&amp;</span><span>text</span> <span>&amp;&amp;</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L95" data-line-number="95"></td>
          <td id="file-heap-lisp-c-LC95">         <span>x</span> <span>&lt;</span>  (<span>void</span><span>*</span>)<span>&amp;</span><span>text</span>[<span>1280</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L96" data-line-number="96"></td>
          <td id="file-heap-lisp-c-LC96">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L97" data-line-number="97"></td>
          <td id="file-heap-lisp-c-LC97">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L98" data-line-number="98"></td>
          <td id="file-heap-lisp-c-LC98"><span>Pair</span><span>*</span> <span>cons</span>(<span>void</span><span>*</span> <span>x</span>, <span>void</span><span>*</span> <span>y</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L99" data-line-number="99"></td>
          <td id="file-heap-lisp-c-LC99">  <span>assert</span>(<span>istext</span>(<span>textptr</span>));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L100" data-line-number="100"></td>
          <td id="file-heap-lisp-c-LC100">  <span>textptr</span><span>-&gt;</span><span>car</span> <span>=</span> <span>x</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L101" data-line-number="101"></td>
          <td id="file-heap-lisp-c-LC101">  <span>textptr</span><span>-&gt;</span><span>cdr</span> <span>=</span> <span>y</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L102" data-line-number="102"></td>
          <td id="file-heap-lisp-c-LC102">  <span>return</span> <span>textptr</span><span>++</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L103" data-line-number="103"></td>
          <td id="file-heap-lisp-c-LC103">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L104" data-line-number="104"></td>
          <td id="file-heap-lisp-c-LC104">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L105" data-line-number="105"></td>
          <td id="file-heap-lisp-c-LC105"><span>void</span><span>*</span> <span>read</span>(<span>char</span><span>*</span> <span>ln</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L106" data-line-number="106"></td>
          <td id="file-heap-lisp-c-LC106"><span>void</span><span>*</span> <span>read_exp</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L107" data-line-number="107"></td>
          <td id="file-heap-lisp-c-LC107"><span>void</span><span>*</span> <span>read_list</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L108" data-line-number="108"></td>
          <td id="file-heap-lisp-c-LC108">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L109" data-line-number="109"></td>
          <td id="file-heap-lisp-c-LC109"><span>void</span><span>*</span> <span>read</span>(<span>char</span><span>*</span> <span>ln</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L110" data-line-number="110"></td>
          <td id="file-heap-lisp-c-LC110">  <span>// Initialize the lexer and list memory.</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L111" data-line-number="111"></td>
          <td id="file-heap-lisp-c-LC111">  <span>curtok</span> <span>=</span> <span>0</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L112" data-line-number="112"></td>
          <td id="file-heap-lisp-c-LC112">  <span>textptr</span> <span>=</span> <span>text</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L113" data-line-number="113"></td>
          <td id="file-heap-lisp-c-LC113">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L114" data-line-number="114"></td>
          <td id="file-heap-lisp-c-LC114">  <span>lexer</span>(<span>ln</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L115" data-line-number="115"></td>
          <td id="file-heap-lisp-c-LC115">  <span>return</span> <span>read_exp</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L116" data-line-number="116"></td>
          <td id="file-heap-lisp-c-LC116">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L117" data-line-number="117"></td>
          <td id="file-heap-lisp-c-LC117">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L118" data-line-number="118"></td>
          <td id="file-heap-lisp-c-LC118"><span>void</span><span>*</span> <span>read_exp</span>() {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L119" data-line-number="119"></td>
          <td id="file-heap-lisp-c-LC119">  <span>char</span><span>*</span> <span>tok</span> <span>=</span> <span>nexttok</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L120" data-line-number="120"></td>
          <td id="file-heap-lisp-c-LC120">  <span>if</span> (<span>tok</span>[<span>0</span>] <span>==</span> <span>'('</span> <span>&amp;&amp;</span> <span>peektok</span>()[<span>0</span>] <span>==</span> <span>')'</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L121" data-line-number="121"></td>
          <td id="file-heap-lisp-c-LC121">    <span>nexttok</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L122" data-line-number="122"></td>
          <td id="file-heap-lisp-c-LC122">    <span>return</span> <span>NULL</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L123" data-line-number="123"></td>
          <td id="file-heap-lisp-c-LC123">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L124" data-line-number="124"></td>
          <td id="file-heap-lisp-c-LC124">  <span>else</span> <span>if</span> (<span>tok</span>[<span>0</span>] <span>==</span> <span>'\''</span>)</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L125" data-line-number="125"></td>
          <td id="file-heap-lisp-c-LC125">    <span>return</span> <span>cons</span>(<span>"quote"</span>, <span>cons</span>(<span>read_exp</span>(), <span>NULL</span>));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L126" data-line-number="126"></td>
          <td id="file-heap-lisp-c-LC126">  <span>else</span> <span>if</span> (<span>tok</span>[<span>0</span>] <span>==</span> <span>'('</span>)</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L127" data-line-number="127"></td>
          <td id="file-heap-lisp-c-LC127">    <span>return</span> <span>read_list</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L128" data-line-number="128"></td>
          <td id="file-heap-lisp-c-LC128">  <span>else</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L129" data-line-number="129"></td>
          <td id="file-heap-lisp-c-LC129">    <span>return</span> <span>tok</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L130" data-line-number="130"></td>
          <td id="file-heap-lisp-c-LC130">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L131" data-line-number="131"></td>
          <td id="file-heap-lisp-c-LC131">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L132" data-line-number="132"></td>
          <td id="file-heap-lisp-c-LC132"><span>void</span><span>*</span> <span>read_list</span>() {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L133" data-line-number="133"></td>
          <td id="file-heap-lisp-c-LC133">  <span>char</span><span>*</span> <span>tok</span> <span>=</span> <span>peektok</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L134" data-line-number="134"></td>
          <td id="file-heap-lisp-c-LC134">  <span>if</span>(<span>tok</span>[<span>0</span>] <span>==</span> <span>')'</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L135" data-line-number="135"></td>
          <td id="file-heap-lisp-c-LC135">    <span>nexttok</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L136" data-line-number="136"></td>
          <td id="file-heap-lisp-c-LC136">    <span>return</span> <span>NULL</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L137" data-line-number="137"></td>
          <td id="file-heap-lisp-c-LC137">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L138" data-line-number="138"></td>
          <td id="file-heap-lisp-c-LC138">  <span>else</span> <span>if</span>(<span>tok</span>[<span>0</span>] <span>==</span> <span>'.'</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L139" data-line-number="139"></td>
          <td id="file-heap-lisp-c-LC139">    <span>nexttok</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L140" data-line-number="140"></td>
          <td id="file-heap-lisp-c-LC140">    <span>tok</span> <span>=</span> <span>read_exp</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L141" data-line-number="141"></td>
          <td id="file-heap-lisp-c-LC141">    <span>nexttok</span>();    </td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L142" data-line-number="142"></td>
          <td id="file-heap-lisp-c-LC142">    <span>return</span> <span>tok</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L143" data-line-number="143"></td>
          <td id="file-heap-lisp-c-LC143">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L144" data-line-number="144"></td>
          <td id="file-heap-lisp-c-LC144">  <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L145" data-line-number="145"></td>
          <td id="file-heap-lisp-c-LC145">    <span>void</span><span>*</span> <span>fst</span> <span>=</span> <span>read_exp</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L146" data-line-number="146"></td>
          <td id="file-heap-lisp-c-LC146">    <span>void</span><span>*</span> <span>snd</span> <span>=</span> <span>read_list</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L147" data-line-number="147"></td>
          <td id="file-heap-lisp-c-LC147">    <span>return</span> <span>cons</span>(<span>fst</span>, <span>snd</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L148" data-line-number="148"></td>
          <td id="file-heap-lisp-c-LC148">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L149" data-line-number="149"></td>
          <td id="file-heap-lisp-c-LC149">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L150" data-line-number="150"></td>
          <td id="file-heap-lisp-c-LC150">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L151" data-line-number="151"></td>
          <td id="file-heap-lisp-c-LC151"><span>void</span> <span>print</span>(<span>void</span><span>*</span> <span>exp</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L152" data-line-number="152"></td>
          <td id="file-heap-lisp-c-LC152"><span>void</span> <span>print_exp</span>(<span>void</span><span>*</span> <span>exp</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L153" data-line-number="153"></td>
          <td id="file-heap-lisp-c-LC153"><span>void</span> <span>print_list</span>(<span>Pair</span><span>*</span> <span>list</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L154" data-line-number="154"></td>
          <td id="file-heap-lisp-c-LC154"><span>void</span> <span>print_cons</span>(<span>Pair</span><span>*</span> <span>pair</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L155" data-line-number="155"></td>
          <td id="file-heap-lisp-c-LC155">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L156" data-line-number="156"></td>
          <td id="file-heap-lisp-c-LC156"><span>void</span> <span>print</span>(<span>void</span><span>*</span> <span>exp</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L157" data-line-number="157"></td>
          <td id="file-heap-lisp-c-LC157">  <span>print_exp</span>(<span>exp</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L158" data-line-number="158"></td>
          <td id="file-heap-lisp-c-LC158">  <span>printf</span>(<span>"\n"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L159" data-line-number="159"></td>
          <td id="file-heap-lisp-c-LC159">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L160" data-line-number="160"></td>
          <td id="file-heap-lisp-c-LC160">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L161" data-line-number="161"></td>
          <td id="file-heap-lisp-c-LC161"><span>void</span> <span>print_exp</span>(<span>void</span><span>*</span> <span>exp</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L162" data-line-number="162"></td>
          <td id="file-heap-lisp-c-LC162">  <span>if</span> (<span>istext</span>(<span>exp</span>)) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L163" data-line-number="163"></td>
          <td id="file-heap-lisp-c-LC163">    <span>Pair</span><span>*</span> <span>pair</span> <span>=</span> <span>exp</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L164" data-line-number="164"></td>
          <td id="file-heap-lisp-c-LC164">    <span>if</span>(!<span>istext</span>(<span>pair</span><span>-&gt;</span><span>cdr</span>) <span>&amp;&amp;</span> <span>pair</span><span>-&gt;</span><span>cdr</span> <span>!=</span> <span>NULL</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L165" data-line-number="165"></td>
          <td id="file-heap-lisp-c-LC165">      <span>printf</span>(<span>"("</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L166" data-line-number="166"></td>
          <td id="file-heap-lisp-c-LC166">      <span>print_cons</span>(<span>exp</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L167" data-line-number="167"></td>
          <td id="file-heap-lisp-c-LC167">      <span>printf</span>(<span>")"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L168" data-line-number="168"></td>
          <td id="file-heap-lisp-c-LC168">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L169" data-line-number="169"></td>
          <td id="file-heap-lisp-c-LC169">    <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L170" data-line-number="170"></td>
          <td id="file-heap-lisp-c-LC170">      <span>printf</span>(<span>"("</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L171" data-line-number="171"></td>
          <td id="file-heap-lisp-c-LC171">      <span>print_list</span>(<span>exp</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L172" data-line-number="172"></td>
          <td id="file-heap-lisp-c-LC172">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L173" data-line-number="173"></td>
          <td id="file-heap-lisp-c-LC173">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L174" data-line-number="174"></td>
          <td id="file-heap-lisp-c-LC174">  <span>else</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L175" data-line-number="175"></td>
          <td id="file-heap-lisp-c-LC175">    <span>printf</span>(<span>"%s"</span>, <span>exp</span> ? (<span>char</span><span>*</span>)<span>exp</span> : <span>"()"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L176" data-line-number="176"></td>
          <td id="file-heap-lisp-c-LC176">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L177" data-line-number="177"></td>
          <td id="file-heap-lisp-c-LC177">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L178" data-line-number="178"></td>
          <td id="file-heap-lisp-c-LC178"><span>void</span> <span>print_list</span>(<span>Pair</span><span>*</span> <span>list</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L179" data-line-number="179"></td>
          <td id="file-heap-lisp-c-LC179">  <span>if</span> (<span>list</span><span>-&gt;</span><span>cdr</span> <span>==</span> <span>NULL</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L180" data-line-number="180"></td>
          <td id="file-heap-lisp-c-LC180">    <span>print_exp</span>(<span>list</span><span>-&gt;</span><span>car</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L181" data-line-number="181"></td>
          <td id="file-heap-lisp-c-LC181">    <span>printf</span>(<span>")"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L182" data-line-number="182"></td>
          <td id="file-heap-lisp-c-LC182">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L183" data-line-number="183"></td>
          <td id="file-heap-lisp-c-LC183">  <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L184" data-line-number="184"></td>
          <td id="file-heap-lisp-c-LC184">    <span>if</span>(!<span>istext</span>(<span>list</span><span>-&gt;</span><span>cdr</span>) <span>&amp;&amp;</span> <span>list</span><span>-&gt;</span><span>cdr</span> <span>!=</span> <span>NULL</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L185" data-line-number="185"></td>
          <td id="file-heap-lisp-c-LC185">      <span>print_cons</span>(<span>list</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L186" data-line-number="186"></td>
          <td id="file-heap-lisp-c-LC186">      <span>printf</span>(<span>")"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L187" data-line-number="187"></td>
          <td id="file-heap-lisp-c-LC187">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L188" data-line-number="188"></td>
          <td id="file-heap-lisp-c-LC188">    <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L189" data-line-number="189"></td>
          <td id="file-heap-lisp-c-LC189">      <span>print_exp</span>(<span>list</span><span>-&gt;</span><span>car</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L190" data-line-number="190"></td>
          <td id="file-heap-lisp-c-LC190">      <span>printf</span>(<span>" "</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L191" data-line-number="191"></td>
          <td id="file-heap-lisp-c-LC191">      <span>print_list</span>(<span>list</span><span>-&gt;</span><span>cdr</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L192" data-line-number="192"></td>
          <td id="file-heap-lisp-c-LC192">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L193" data-line-number="193"></td>
          <td id="file-heap-lisp-c-LC193">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L194" data-line-number="194"></td>
          <td id="file-heap-lisp-c-LC194">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L195" data-line-number="195"></td>
          <td id="file-heap-lisp-c-LC195">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L196" data-line-number="196"></td>
          <td id="file-heap-lisp-c-LC196"><span>void</span> <span>print_cons</span>(<span>Pair</span><span>*</span> <span>pair</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L197" data-line-number="197"></td>
          <td id="file-heap-lisp-c-LC197">  <span>print_exp</span>(<span>pair</span><span>-&gt;</span><span>car</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L198" data-line-number="198"></td>
          <td id="file-heap-lisp-c-LC198">  <span>printf</span>(<span>" . "</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L199" data-line-number="199"></td>
          <td id="file-heap-lisp-c-LC199">  <span>print_exp</span>(<span>pair</span><span>-&gt;</span><span>cdr</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L200" data-line-number="200"></td>
          <td id="file-heap-lisp-c-LC200">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L201" data-line-number="201"></td>
          <td id="file-heap-lisp-c-LC201">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L202" data-line-number="202"></td>
          <td id="file-heap-lisp-c-LC202">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L203" data-line-number="203"></td>
          <td id="file-heap-lisp-c-LC203"><span>Pair</span><span>*</span> <span>compile</span>(<span>void</span><span>*</span> <span>exp</span>, <span>void</span><span>*</span> <span>next</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L204" data-line-number="204"></td>
          <td id="file-heap-lisp-c-LC204">  <span>if</span> (<span>istext</span>(<span>exp</span>)) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L205" data-line-number="205"></td>
          <td id="file-heap-lisp-c-LC205">    <span>Text</span><span>*</span> <span>p</span> <span>=</span> <span>exp</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L206" data-line-number="206"></td>
          <td id="file-heap-lisp-c-LC206">    <span>if</span> (<span>strcmp</span>(<span>p</span><span>-&gt;</span><span>car</span>, <span>"quote"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L207" data-line-number="207"></td>
          <td id="file-heap-lisp-c-LC207">      <span>return</span> <span>cons</span>(<span>"constant"</span>, <span>cons</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>next</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L208" data-line-number="208"></td>
          <td id="file-heap-lisp-c-LC208">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L209" data-line-number="209"></td>
          <td id="file-heap-lisp-c-LC209">    <span>else</span> <span>if</span> (<span>strcmp</span>(<span>p</span><span>-&gt;</span><span>car</span>, <span>"lambda"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L210" data-line-number="210"></td>
          <td id="file-heap-lisp-c-LC210">      <span>return</span> <span>cons</span>(<span>"close"</span>, <span>cons</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>compile</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>"return"</span>, <span>NULL</span>)), <span>cons</span>(<span>next</span>, <span>NULL</span>))));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L211" data-line-number="211"></td>
          <td id="file-heap-lisp-c-LC211">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L212" data-line-number="212"></td>
          <td id="file-heap-lisp-c-LC212">    <span>else</span> <span>if</span> (<span>strcmp</span>(<span>p</span><span>-&gt;</span><span>car</span>, <span>"if"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L213" data-line-number="213"></td>
          <td id="file-heap-lisp-c-LC213">      <span>return</span> <span>compile</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>"test"</span>, <span>cons</span>(<span>compile</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>next</span>),</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L214" data-line-number="214"></td>
          <td id="file-heap-lisp-c-LC214">                                                    <span>cons</span>(<span>compile</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>next</span>),</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L215" data-line-number="215"></td>
          <td id="file-heap-lisp-c-LC215">                                                         <span>NULL</span>))));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L216" data-line-number="216"></td>
          <td id="file-heap-lisp-c-LC216">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L217" data-line-number="217"></td>
          <td id="file-heap-lisp-c-LC217">    <span>else</span> <span>if</span> (<span>strcmp</span>(<span>p</span><span>-&gt;</span><span>car</span>, <span>"set!"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L218" data-line-number="218"></td>
          <td id="file-heap-lisp-c-LC218">      <span>return</span> <span>compile</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>"assign"</span>, <span>cons</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>next</span>, <span>NULL</span>))));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L219" data-line-number="219"></td>
          <td id="file-heap-lisp-c-LC219">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L220" data-line-number="220"></td>
          <td id="file-heap-lisp-c-LC220">    <span>else</span> <span>if</span> (<span>strcmp</span>(<span>p</span><span>-&gt;</span><span>car</span>, <span>"call/cc"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L221" data-line-number="221"></td>
          <td id="file-heap-lisp-c-LC221">      <span>void</span><span>*</span> <span>c</span> <span>=</span> <span>cons</span>(<span>"conti"</span>, <span>cons</span>(<span>cons</span>(<span>"argument"</span>, <span>cons</span>(<span>compile</span>(<span>p</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>"apply"</span>, <span>NULL</span>)), <span>NULL</span>)), <span>NULL</span>));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L222" data-line-number="222"></td>
          <td id="file-heap-lisp-c-LC222">      <span>Text</span><span>*</span> <span>n</span> <span>=</span> <span>next</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L223" data-line-number="223"></td>
          <td id="file-heap-lisp-c-LC223">      <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"return"</span>) <span>==</span> <span>0</span>)</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L224" data-line-number="224"></td>
          <td id="file-heap-lisp-c-LC224">        <span>return</span> <span>c</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L225" data-line-number="225"></td>
          <td id="file-heap-lisp-c-LC225">      <span>else</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L226" data-line-number="226"></td>
          <td id="file-heap-lisp-c-LC226">        <span>return</span> <span>cons</span>(<span>"frame"</span>, <span>cons</span>(<span>next</span>, <span>cons</span>(<span>c</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L227" data-line-number="227"></td>
          <td id="file-heap-lisp-c-LC227">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L228" data-line-number="228"></td>
          <td id="file-heap-lisp-c-LC228">    <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L229" data-line-number="229"></td>
          <td id="file-heap-lisp-c-LC229">      <span>Pair</span><span>*</span> <span>args</span> <span>=</span> (<span>Pair</span><span>*</span>)<span>p</span><span>-&gt;</span><span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L230" data-line-number="230"></td>
          <td id="file-heap-lisp-c-LC230">      <span>void</span><span>*</span> <span>c</span> <span>=</span> <span>compile</span>(<span>p</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>"apply"</span>, <span>NULL</span>));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L231" data-line-number="231"></td>
          <td id="file-heap-lisp-c-LC231">      <span>while</span> (<span>args</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L232" data-line-number="232"></td>
          <td id="file-heap-lisp-c-LC232">        <span>c</span> <span>=</span> <span>compile</span>(<span>args</span><span>-&gt;</span><span>car</span>, <span>cons</span>(<span>"argument"</span>, <span>cons</span>(<span>c</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L233" data-line-number="233"></td>
          <td id="file-heap-lisp-c-LC233">        <span>args</span> <span>=</span> <span>args</span><span>-&gt;</span><span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L234" data-line-number="234"></td>
          <td id="file-heap-lisp-c-LC234">      }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L235" data-line-number="235"></td>
          <td id="file-heap-lisp-c-LC235">      <span>Text</span><span>*</span> <span>n</span> <span>=</span> <span>next</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L236" data-line-number="236"></td>
          <td id="file-heap-lisp-c-LC236">      <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"return"</span>) <span>==</span> <span>0</span>)</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L237" data-line-number="237"></td>
          <td id="file-heap-lisp-c-LC237">        <span>return</span> <span>c</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L238" data-line-number="238"></td>
          <td id="file-heap-lisp-c-LC238">      <span>else</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L239" data-line-number="239"></td>
          <td id="file-heap-lisp-c-LC239">        <span>return</span> <span>cons</span>(<span>"frame"</span>, <span>cons</span>(<span>next</span>, <span>cons</span>(<span>c</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L240" data-line-number="240"></td>
          <td id="file-heap-lisp-c-LC240">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L241" data-line-number="241"></td>
          <td id="file-heap-lisp-c-LC241">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L242" data-line-number="242"></td>
          <td id="file-heap-lisp-c-LC242">  <span>else</span> <span>if</span>(<span>isdigit</span>(<span>*</span>((<span>char</span><span>*</span>)<span>exp</span>))) { <span>// a number</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L243" data-line-number="243"></td>
          <td id="file-heap-lisp-c-LC243">    <span>return</span> <span>cons</span>(<span>"constant"</span>, <span>cons</span>(<span>exp</span>, <span>cons</span>(<span>next</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L244" data-line-number="244"></td>
          <td id="file-heap-lisp-c-LC244">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L245" data-line-number="245"></td>
          <td id="file-heap-lisp-c-LC245">  <span>else</span> <span>if</span>(<span>strcmp</span>(<span>exp</span>, <span>"#t"</span>) <span>==</span> <span>0</span>) { <span>// a boolean</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L246" data-line-number="246"></td>
          <td id="file-heap-lisp-c-LC246">    <span>return</span> <span>cons</span>(<span>"constant"</span>, <span>cons</span>(<span>exp</span>, <span>cons</span>(<span>next</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L247" data-line-number="247"></td>
          <td id="file-heap-lisp-c-LC247">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L248" data-line-number="248"></td>
          <td id="file-heap-lisp-c-LC248">  <span>else</span> <span>if</span>(<span>strcmp</span>(<span>exp</span>, <span>"#f"</span>) <span>==</span> <span>0</span>) { <span>// a boolean</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L249" data-line-number="249"></td>
          <td id="file-heap-lisp-c-LC249">    <span>return</span> <span>cons</span>(<span>"constant"</span>, <span>cons</span>(<span>exp</span>, <span>cons</span>(<span>next</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L250" data-line-number="250"></td>
          <td id="file-heap-lisp-c-LC250">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L251" data-line-number="251"></td>
          <td id="file-heap-lisp-c-LC251">  <span>else</span> { <span>// a symbol</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L252" data-line-number="252"></td>
          <td id="file-heap-lisp-c-LC252">    <span>return</span> <span>cons</span>(<span>"refer"</span>, <span>cons</span>(<span>exp</span>, <span>cons</span>(<span>next</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L253" data-line-number="253"></td>
          <td id="file-heap-lisp-c-LC253">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L254" data-line-number="254"></td>
          <td id="file-heap-lisp-c-LC254">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L255" data-line-number="255"></td>
          <td id="file-heap-lisp-c-LC255">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L256" data-line-number="256"></td>
          <td id="file-heap-lisp-c-LC256"><span>void</span><span>*</span> <span>get</span>(<span>void</span><span>*</span> <span>env</span>, <span>char</span><span>*</span> <span>var</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L257" data-line-number="257"></td>
          <td id="file-heap-lisp-c-LC257">  <span>Pair</span><span>*</span> <span>e</span> <span>=</span> <span>env</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L258" data-line-number="258"></td>
          <td id="file-heap-lisp-c-LC258">  <span>while</span>(<span>env</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L259" data-line-number="259"></td>
          <td id="file-heap-lisp-c-LC259">    <span>Pair</span><span>*</span> <span>cur</span> <span>=</span> <span>e</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L260" data-line-number="260"></td>
          <td id="file-heap-lisp-c-LC260">    <span>Pair</span><span>*</span> <span>vars</span> <span>=</span> <span>cur</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L261" data-line-number="261"></td>
          <td id="file-heap-lisp-c-LC261">    <span>Pair</span><span>*</span> <span>vals</span> <span>=</span> <span>cur</span><span>-&gt;</span><span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L262" data-line-number="262"></td>
          <td id="file-heap-lisp-c-LC262">    <span>while</span> (<span>vars</span> <span>&amp;&amp;</span> <span>vals</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L263" data-line-number="263"></td>
          <td id="file-heap-lisp-c-LC263">      <span>if</span> (<span>strcmp</span>(<span>vars</span><span>-&gt;</span><span>car</span>, <span>var</span>) <span>==</span> <span>0</span>)</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L264" data-line-number="264"></td>
          <td id="file-heap-lisp-c-LC264">        <span>return</span> <span>vals</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L265" data-line-number="265"></td>
          <td id="file-heap-lisp-c-LC265">      <span>vars</span> <span>=</span> <span>vars</span><span>-&gt;</span><span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L266" data-line-number="266"></td>
          <td id="file-heap-lisp-c-LC266">      <span>vals</span> <span>=</span> <span>vals</span><span>-&gt;</span><span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L267" data-line-number="267"></td>
          <td id="file-heap-lisp-c-LC267">    }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L268" data-line-number="268"></td>
          <td id="file-heap-lisp-c-LC268">    <span>e</span> <span>=</span> <span>e</span><span>-&gt;</span><span>cdr</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L269" data-line-number="269"></td>
          <td id="file-heap-lisp-c-LC269">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L270" data-line-number="270"></td>
          <td id="file-heap-lisp-c-LC270">  <span>fprintf</span>(<span>stderr</span>, <span>"No definition in environment for %s.\n"</span>, <span>var</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L271" data-line-number="271"></td>
          <td id="file-heap-lisp-c-LC271">  <span>assert</span>(<span>0</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L272" data-line-number="272"></td>
          <td id="file-heap-lisp-c-LC272">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L273" data-line-number="273"></td>
          <td id="file-heap-lisp-c-LC273">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L274" data-line-number="274"></td>
          <td id="file-heap-lisp-c-LC274"><span>void</span> <span>set</span>(<span>void</span><span>*</span> <span>env</span>, <span>char</span><span>*</span> <span>var</span>, <span>char</span><span>*</span> <span>val</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L275" data-line-number="275"></td>
          <td id="file-heap-lisp-c-LC275">  <span>void</span><span>*</span> <span>ref</span> <span>=</span> <span>get</span>(<span>env</span>, <span>var</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L276" data-line-number="276"></td>
          <td id="file-heap-lisp-c-LC276">  <span>ref</span> <span>=</span> <span>val</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L277" data-line-number="277"></td>
          <td id="file-heap-lisp-c-LC277">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L278" data-line-number="278"></td>
          <td id="file-heap-lisp-c-LC278">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L279" data-line-number="279"></td>
          <td id="file-heap-lisp-c-LC279"><span>void</span><span>*</span> <span>extend</span>(<span>void</span><span>*</span> <span>env</span>, <span>void</span><span>*</span> <span>vars</span>, <span>void</span><span>*</span> <span>vals</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L280" data-line-number="280"></td>
          <td id="file-heap-lisp-c-LC280">  <span>return</span> <span>cons</span>(<span>cons</span>(<span>vars</span>, <span>vals</span>), <span>env</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L281" data-line-number="281"></td>
          <td id="file-heap-lisp-c-LC281">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L282" data-line-number="282"></td>
          <td id="file-heap-lisp-c-LC282">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L283" data-line-number="283"></td>
          <td id="file-heap-lisp-c-LC283"><span>void</span><span>*</span> <span>callframe</span>(<span>void</span><span>*</span> <span>next</span>, <span>void</span><span>*</span> <span>env</span>, <span>void</span><span>*</span> <span>rib</span>, <span>void</span><span>*</span> <span>stack</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L284" data-line-number="284"></td>
          <td id="file-heap-lisp-c-LC284">  <span>return</span> <span>cons</span>(<span>next</span>, <span>cons</span>(<span>env</span>, <span>cons</span>(<span>rib</span>, <span>cons</span>(<span>stack</span>, <span>NULL</span>))));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L285" data-line-number="285"></td>
          <td id="file-heap-lisp-c-LC285">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L286" data-line-number="286"></td>
          <td id="file-heap-lisp-c-LC286">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L287" data-line-number="287"></td>
          <td id="file-heap-lisp-c-LC287"><span>void</span><span>*</span> <span>closure</span>(<span>void</span><span>*</span> <span>body</span>, <span>void</span><span>*</span> <span>env</span>, <span>void</span><span>*</span> <span>vars</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L288" data-line-number="288"></td>
          <td id="file-heap-lisp-c-LC288">  <span>return</span> <span>cons</span>(<span>body</span>, <span>cons</span>(<span>env</span>, <span>cons</span>(<span>vars</span>, <span>NULL</span>)));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L289" data-line-number="289"></td>
          <td id="file-heap-lisp-c-LC289">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L290" data-line-number="290"></td>
          <td id="file-heap-lisp-c-LC290">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L291" data-line-number="291"></td>
          <td id="file-heap-lisp-c-LC291"><span>void</span><span>*</span> <span>continuation</span>(<span>void</span><span>*</span> <span>stack</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L292" data-line-number="292"></td>
          <td id="file-heap-lisp-c-LC292">  <span>return</span> <span>closure</span>(<span>cons</span>(<span>"nuate"</span>, <span>cons</span>(<span>stack</span>, <span>cons</span>(<span>"v"</span>, <span>NULL</span>))), <span>NULL</span>, <span>cons</span>(<span>"v"</span>, <span>NULL</span>));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L293" data-line-number="293"></td>
          <td id="file-heap-lisp-c-LC293">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L294" data-line-number="294"></td>
          <td id="file-heap-lisp-c-LC294">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L295" data-line-number="295"></td>
          <td id="file-heap-lisp-c-LC295">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L296" data-line-number="296"></td>
          <td id="file-heap-lisp-c-LC296"><span>void</span><span>*</span> <span>accum</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L297" data-line-number="297"></td>
          <td id="file-heap-lisp-c-LC297"><span>void</span><span>*</span> <span>next</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L298" data-line-number="298"></td>
          <td id="file-heap-lisp-c-LC298"><span>void</span><span>*</span> <span>env</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L299" data-line-number="299"></td>
          <td id="file-heap-lisp-c-LC299"><span>void</span><span>*</span> <span>rib</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L300" data-line-number="300"></td>
          <td id="file-heap-lisp-c-LC300"><span>void</span><span>*</span> <span>stack</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L301" data-line-number="301"></td>
          <td id="file-heap-lisp-c-LC301">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L302" data-line-number="302"></td>
          <td id="file-heap-lisp-c-LC302"><span>void</span> <span>virtmach</span>() {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L303" data-line-number="303"></td>
          <td id="file-heap-lisp-c-LC303">  <span>Text</span><span>*</span> <span>n</span> <span>=</span> <span>next</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L304" data-line-number="304"></td>
          <td id="file-heap-lisp-c-LC304">  <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"halt"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L305" data-line-number="305"></td>
          <td id="file-heap-lisp-c-LC305">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L306" data-line-number="306"></td>
          <td id="file-heap-lisp-c-LC306">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"refer"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L307" data-line-number="307"></td>
          <td id="file-heap-lisp-c-LC307">    <span>accum</span> <span>=</span> <span>get</span>(<span>env</span>, <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L308" data-line-number="308"></td>
          <td id="file-heap-lisp-c-LC308">    <span>next</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L309" data-line-number="309"></td>
          <td id="file-heap-lisp-c-LC309">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L310" data-line-number="310"></td>
          <td id="file-heap-lisp-c-LC310">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L311" data-line-number="311"></td>
          <td id="file-heap-lisp-c-LC311">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"constant"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L312" data-line-number="312"></td>
          <td id="file-heap-lisp-c-LC312">    <span>accum</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L313" data-line-number="313"></td>
          <td id="file-heap-lisp-c-LC313">    <span>next</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L314" data-line-number="314"></td>
          <td id="file-heap-lisp-c-LC314">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L315" data-line-number="315"></td>
          <td id="file-heap-lisp-c-LC315">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L316" data-line-number="316"></td>
          <td id="file-heap-lisp-c-LC316">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"close"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L317" data-line-number="317"></td>
          <td id="file-heap-lisp-c-LC317">    <span>void</span><span>*</span> <span>vars</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L318" data-line-number="318"></td>
          <td id="file-heap-lisp-c-LC318">    <span>void</span><span>*</span> <span>body</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L319" data-line-number="319"></td>
          <td id="file-heap-lisp-c-LC319">    <span>void</span><span>*</span> <span>x</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L320" data-line-number="320"></td>
          <td id="file-heap-lisp-c-LC320">    <span>accum</span> <span>=</span> <span>closure</span>(<span>body</span>, <span>env</span>, <span>vars</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L321" data-line-number="321"></td>
          <td id="file-heap-lisp-c-LC321">    <span>next</span> <span>=</span> <span>x</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L322" data-line-number="322"></td>
          <td id="file-heap-lisp-c-LC322">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L323" data-line-number="323"></td>
          <td id="file-heap-lisp-c-LC323">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L324" data-line-number="324"></td>
          <td id="file-heap-lisp-c-LC324">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"test"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L325" data-line-number="325"></td>
          <td id="file-heap-lisp-c-LC325">    <span>void</span><span>*</span> <span>consequent</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L326" data-line-number="326"></td>
          <td id="file-heap-lisp-c-LC326">    <span>void</span><span>*</span> <span>alternate</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L327" data-line-number="327"></td>
          <td id="file-heap-lisp-c-LC327">    <span>next</span> <span>=</span> <span>strcmp</span>(<span>accum</span>, <span>"#f"</span>) <span>==</span> <span>0</span> ? <span>alternate</span> : <span>consequent</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L328" data-line-number="328"></td>
          <td id="file-heap-lisp-c-LC328">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L329" data-line-number="329"></td>
          <td id="file-heap-lisp-c-LC329">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L330" data-line-number="330"></td>
          <td id="file-heap-lisp-c-LC330">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"assign"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L331" data-line-number="331"></td>
          <td id="file-heap-lisp-c-LC331">    <span>set</span>(<span>env</span>, <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>accum</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L332" data-line-number="332"></td>
          <td id="file-heap-lisp-c-LC332">    <span>next</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L333" data-line-number="333"></td>
          <td id="file-heap-lisp-c-LC333">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L334" data-line-number="334"></td>
          <td id="file-heap-lisp-c-LC334">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L335" data-line-number="335"></td>
          <td id="file-heap-lisp-c-LC335">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"conti"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L336" data-line-number="336"></td>
          <td id="file-heap-lisp-c-LC336">    <span>accum</span> <span>=</span> <span>continuation</span>(<span>stack</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L337" data-line-number="337"></td>
          <td id="file-heap-lisp-c-LC337">    <span>next</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L338" data-line-number="338"></td>
          <td id="file-heap-lisp-c-LC338">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L339" data-line-number="339"></td>
          <td id="file-heap-lisp-c-LC339">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L340" data-line-number="340"></td>
          <td id="file-heap-lisp-c-LC340">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"nuate"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L341" data-line-number="341"></td>
          <td id="file-heap-lisp-c-LC341">    <span>stack</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L342" data-line-number="342"></td>
          <td id="file-heap-lisp-c-LC342">    <span>accum</span> <span>=</span> <span>get</span>(<span>env</span>, <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L343" data-line-number="343"></td>
          <td id="file-heap-lisp-c-LC343">    <span>next</span> <span>=</span> <span>cons</span>(<span>"return"</span>, <span>NULL</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L344" data-line-number="344"></td>
          <td id="file-heap-lisp-c-LC344">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L345" data-line-number="345"></td>
          <td id="file-heap-lisp-c-LC345">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L346" data-line-number="346"></td>
          <td id="file-heap-lisp-c-LC346">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"frame"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L347" data-line-number="347"></td>
          <td id="file-heap-lisp-c-LC347">    <span>stack</span> <span>=</span> <span>callframe</span>(<span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>, <span>env</span>, <span>rib</span>, <span>stack</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L348" data-line-number="348"></td>
          <td id="file-heap-lisp-c-LC348">    <span>rib</span> <span>=</span> <span>NULL</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L349" data-line-number="349"></td>
          <td id="file-heap-lisp-c-LC349">    <span>next</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L350" data-line-number="350"></td>
          <td id="file-heap-lisp-c-LC350">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L351" data-line-number="351"></td>
          <td id="file-heap-lisp-c-LC351">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L352" data-line-number="352"></td>
          <td id="file-heap-lisp-c-LC352">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"argument"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L353" data-line-number="353"></td>
          <td id="file-heap-lisp-c-LC353">    <span>rib</span> <span>=</span> <span>cons</span>(<span>accum</span>, <span>rib</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L354" data-line-number="354"></td>
          <td id="file-heap-lisp-c-LC354">    <span>next</span> <span>=</span> <span>n</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L355" data-line-number="355"></td>
          <td id="file-heap-lisp-c-LC355">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L356" data-line-number="356"></td>
          <td id="file-heap-lisp-c-LC356">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L357" data-line-number="357"></td>
          <td id="file-heap-lisp-c-LC357">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"apply"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L358" data-line-number="358"></td>
          <td id="file-heap-lisp-c-LC358">    <span>Text</span><span>*</span> <span>a</span> <span>=</span> <span>accum</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L359" data-line-number="359"></td>
          <td id="file-heap-lisp-c-LC359">    <span>void</span><span>*</span> <span>body</span> <span>=</span> <span>a</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L360" data-line-number="360"></td>
          <td id="file-heap-lisp-c-LC360">    <span>void</span><span>*</span> <span>clos</span> <span>=</span> <span>a</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L361" data-line-number="361"></td>
          <td id="file-heap-lisp-c-LC361">    <span>void</span><span>*</span> <span>vars</span> <span>=</span> <span>a</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L362" data-line-number="362"></td>
          <td id="file-heap-lisp-c-LC362">    <span>env</span> <span>=</span> <span>extend</span>(<span>env</span>, <span>vars</span>, <span>rib</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L363" data-line-number="363"></td>
          <td id="file-heap-lisp-c-LC363">    <span>rib</span> <span>=</span> <span>NULL</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L364" data-line-number="364"></td>
          <td id="file-heap-lisp-c-LC364">    <span>next</span> <span>=</span> <span>body</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L365" data-line-number="365"></td>
          <td id="file-heap-lisp-c-LC365">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L366" data-line-number="366"></td>
          <td id="file-heap-lisp-c-LC366">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L367" data-line-number="367"></td>
          <td id="file-heap-lisp-c-LC367">  <span>else</span> <span>if</span> (<span>strcmp</span>(<span>n</span><span>-&gt;</span><span>car</span>, <span>"return"</span>) <span>==</span> <span>0</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L368" data-line-number="368"></td>
          <td id="file-heap-lisp-c-LC368">    <span>Text</span><span>*</span> <span>s</span> <span>=</span> <span>stack</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L369" data-line-number="369"></td>
          <td id="file-heap-lisp-c-LC369">    <span>next</span> <span>=</span> <span>s</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L370" data-line-number="370"></td>
          <td id="file-heap-lisp-c-LC370">    <span>env</span> <span>=</span> <span>s</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L371" data-line-number="371"></td>
          <td id="file-heap-lisp-c-LC371">    <span>rib</span> <span>=</span> <span>s</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L372" data-line-number="372"></td>
          <td id="file-heap-lisp-c-LC372">    <span>stack</span> <span>=</span> <span>s</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>cdr</span><span>-&gt;</span><span>car</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L373" data-line-number="373"></td>
          <td id="file-heap-lisp-c-LC373">    <span>return</span> <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L374" data-line-number="374"></td>
          <td id="file-heap-lisp-c-LC374">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L375" data-line-number="375"></td>
          <td id="file-heap-lisp-c-LC375">  <span>else</span> {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L376" data-line-number="376"></td>
          <td id="file-heap-lisp-c-LC376">    <span>fprintf</span>(<span>stderr</span>, <span>"Unhandled operation.\n"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L377" data-line-number="377"></td>
          <td id="file-heap-lisp-c-LC377">    <span>assert</span>(<span>0</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L378" data-line-number="378"></td>
          <td id="file-heap-lisp-c-LC378">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L379" data-line-number="379"></td>
          <td id="file-heap-lisp-c-LC379">}</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L380" data-line-number="380"></td>
          <td id="file-heap-lisp-c-LC380">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L381" data-line-number="381"></td>
          <td id="file-heap-lisp-c-LC381">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L382" data-line-number="382"></td>
          <td id="file-heap-lisp-c-LC382"><span>int</span> <span>main</span>(<span>int</span> <span>argc</span>, <span>char</span><span>*</span><span>*</span> <span>argv</span>) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L383" data-line-number="383"></td>
          <td id="file-heap-lisp-c-LC383">  <span>// note! repl implies there's a top-level but there isn't...</span></td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L384" data-line-number="384"></td>
          <td id="file-heap-lisp-c-LC384">  <span>printf</span>(<span>"Lisp REPL\n\n"</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L385" data-line-number="385"></td>
          <td id="file-heap-lisp-c-LC385">  <span>printf</span>(<span>"&gt;&gt; "</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L386" data-line-number="386"></td>
          <td id="file-heap-lisp-c-LC386">
</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L387" data-line-number="387"></td>
          <td id="file-heap-lisp-c-LC387">  <span>char</span> <span>buffer</span>[<span>256</span>];</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L388" data-line-number="388"></td>
          <td id="file-heap-lisp-c-LC388">  <span>while</span> (<span>fgets</span>(<span>buffer</span>, <span>256</span>, <span>stdin</span>)) {</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L389" data-line-number="389"></td>
          <td id="file-heap-lisp-c-LC389">    <span>next</span> <span>=</span> <span>compile</span>(<span>read</span>(<span>buffer</span>), <span>cons</span>(<span>"halt"</span>, <span>NULL</span>));</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L390" data-line-number="390"></td>
          <td id="file-heap-lisp-c-LC390">    <span>virtmach</span>();</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L391" data-line-number="391"></td>
          <td id="file-heap-lisp-c-LC391">    <span>print</span>(<span>accum</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L392" data-line-number="392"></td>
          <td id="file-heap-lisp-c-LC392">    <span>printf</span>(<span>"&gt;&gt; "</span>);</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L393" data-line-number="393"></td>
          <td id="file-heap-lisp-c-LC393">  }</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L394" data-line-number="394"></td>
          <td id="file-heap-lisp-c-LC394">  <span>return</span> <span>0</span>;</td>
        </tr>
        <tr>
          <td id="file-heap-lisp-c-L395" data-line-number="395"></td>
          <td id="file-heap-lisp-c-LC395">}</td>
        </tr>
  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: While everyone builds AI apps, my spreadsheet reached 2,300 users (255 pts)]]></title>
            <link>https://write-it-down.com</link>
            <guid>45490578</guid>
            <pubDate>Mon, 06 Oct 2025 12:23:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://write-it-down.com">https://write-it-down.com</a>, See on <a href="https://news.ycombinator.com/item?id=45490578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="home"><section><div><p><h2>Start tracking all your expenses and income in an all-in-one personal finance tracker</h2></p></div><session><div><p>Start tracking in 1 minute</p><svg viewBox="0 0 130 130" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M60.9866 102.011C75.5791 112.188 92.2457 119.614 108.76 118.142C114.825 117.601 120.44 115.34 126.202 113.089C126.708 112.891 126.959 112.318 126.761 111.813C126.564 111.307 125.991 111.055 125.486 111.253C119.899 113.436 114.463 115.655 108.587 116.178C92.3221 117.629 75.9409 110.146 61.6177 100.05C61.6659 99.904 61.7161 99.7581 61.7664 99.6122C62.8717 96.4058 62.1703 91.7303 60.3636 86.8178C57.7429 79.686 52.8573 72.0229 48.4641 67.7902C46.4383 65.8366 44.4768 64.6098 42.8751 64.3519C41.5406 64.1357 40.3951 64.5004 39.5108 65.5345C38.7833 66.3888 38.3673 67.4776 38.2447 68.7539C38.0819 70.4574 38.4477 72.5256 39.2174 74.7761C42.0652 83.1034 50.4316 94.0615 54.9675 97.5779C56.3884 98.6797 57.8334 99.7607 59.3045 100.818C59.0111 101.74 58.7277 102.621 58.38 103.433C57.8696 104.626 57.2244 105.663 56.1352 106.411C54.1255 107.791 51.7158 108.026 49.2519 107.666C45.3068 107.093 41.2271 105.009 38.2186 103.222C21.2968 93.1733 12.9424 75.7346 8.44871 58.2386C3.90274 40.5446 3.30786 22.7699 1.96336 12.2859C1.89302 11.7467 1.39863 11.3638 0.860028 11.4341C0.321425 11.5018 -0.0604183 11.9968 0.00791197 12.5359C1.36045 23.0773 1.9714 40.9432 6.53948 58.7283C11.1598 76.7114 19.8197 94.5877 37.2137 104.918C40.4152 106.817 44.7703 109.005 48.9685 109.617C51.9369 110.047 54.8289 109.698 57.2486 108.036C58.6594 107.067 59.5316 105.749 60.1908 104.21C60.4862 103.519 60.7394 102.78 60.9866 102.011ZM59.9436 98.8516C60.8761 95.976 60.1144 91.8475 58.5147 87.4976C55.9965 80.6445 51.3179 73.2757 47.0975 69.2071C45.6827 67.8449 44.3382 66.8577 43.1504 66.4487C42.2923 66.1518 41.5426 66.1883 41.0101 66.8134C40.3971 67.5323 40.166 68.5143 40.176 69.6604C40.1861 70.981 40.5217 72.5048 41.0824 74.1405C43.8136 82.1266 51.8243 92.6498 56.1734 96.0203C57.4113 96.9788 58.6694 97.9244 59.9436 98.8516Z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M127.814 110.052C127.747 110.502 127.522 111.075 127.263 111.677C126.678 113.039 125.846 114.493 125.476 115.196C125.225 115.678 125.41 116.274 125.892 116.527C126.375 116.78 126.97 116.592 127.223 116.11C127.673 115.251 128.774 113.323 129.365 111.727C129.669 110.906 129.832 110.151 129.799 109.606C129.765 109.072 129.548 108.713 129.239 108.458C128.913 108.189 128.409 108.03 127.735 108.051C126.996 108.075 125.941 108.309 124.781 108.395C123.808 108.468 122.745 108.437 121.779 107.952C121.292 107.707 120.699 107.903 120.456 108.39C120.213 108.874 120.408 109.468 120.894 109.71C122.707 110.622 124.765 110.424 126.391 110.19C126.875 110.119 127.476 110.073 127.814 110.052Z"></path></svg></div></session></section><div data-fast-scroll="two_image_guys"><p><img alt="Where did all my salary go" width="500" height="500" decoding="async" data-nimg="1" srcset="https://write-it-down.com/_next/image?url=%2Frandomguy.png&amp;w=640&amp;q=75 1x, https://write-it-down.com/_next/image?url=%2Frandomguy.png&amp;w=1080&amp;q=75 2x" src="https://write-it-down.com/_next/image?url=%2Frandomguy.png&amp;w=1080&amp;q=75"></p><p><img alt="Where did all my salary go" width="400" height="400" decoding="async" data-nimg="1" srcset="https://write-it-down.com/_next/image?url=%2Frandomguy2.png&amp;w=640&amp;q=75 1x, https://write-it-down.com/_next/image?url=%2Frandomguy2.png&amp;w=828&amp;q=75 2x" src="https://write-it-down.com/_next/image?url=%2Frandomguy2.png&amp;w=828&amp;q=75"></p></div><div id="steps" data-fast-scroll="scroll_to_how_to"><div><p>Follow these steps and you’re ready to go.</p></div><div><h3>Define Categories</h3><p>Set up your income, expenses, and accounts to match your financial life. Add custom descriptions so you always know exactly where your money is going.</p></div><div><h3>Record Finances</h3><p>Quickly write down your daily transactions. Everything is organized, easy to review, and simple to follow as your records grow.</p></div><div><h3>Track Growth</h3><p>Explore detailed pages that highlight your spending habits, income patterns, and overall financial summary giving you a clear big-picture view.</p></div></div><div data-fast-scroll="scroll_to_comparison"><div><h3>Other Finance Apps</h3><ul><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18 18 6M6 6l12 12"></path></svg><span>$20+ every month subscription fees</span></li><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18 18 6M6 6l12 12"></path></svg><span>Complex interfaces that overwhelm beginners</span></li><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18 18 6M6 6l12 12"></path></svg><span>Risk of sharing personal data with third parties</span></li><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18 18 6M6 6l12 12"></path></svg><span>Data is locked and hard to export</span></li></ul></div><div><h3>Write-It-Down.com</h3><ul><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="m4.5 12.75 6 6 9-13.5"></path></svg><span>Just a one time $5 investment</span></li><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="m4.5 12.75 6 6 9-13.5"></path></svg><span>Built on Google Sheets you own your data</span></li><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="m4.5 12.75 6 6 9-13.5"></path></svg><span>Simple, beginner and friendly interface</span></li><li><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="m4.5 12.75 6 6 9-13.5"></path></svg><span>Data always available in your Google Drive</span></li></ul></div></div><section data-fast-scroll="scroll_to_features"><p><h2>More than 60% of adults don’t know how much money they spent the previous month</h2><h2>Let’s finally get you on the other side of the statistics!</h2></p></section><div id="getCopy" data-fast-scroll="scroll_to_payment"><div><p>Own it forever. No subscriptions.</p></div><ul><li><span>Works in Google Sheets</span></li><li><span>Track income &amp; expenses</span></li><li><span>Clean, minimal dashboard</span></li><li><span>Your own categories</span></li></ul><div><p>Join <span>2347</span> users tracking their finances</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD signs AI chip-supply deal with OpenAI, gives it option to take a 10% stake (352 pts)]]></title>
            <link>https://www.reuters.com/business/amd-signs-ai-chip-supply-deal-with-openai-gives-it-option-take-10-stake-2025-10-06/</link>
            <guid>45490549</guid>
            <pubDate>Mon, 06 Oct 2025 12:17:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/amd-signs-ai-chip-supply-deal-with-openai-gives-it-option-take-10-stake-2025-10-06/">https://www.reuters.com/business/amd-signs-ai-chip-supply-deal-with-openai-gives-it-option-take-10-stake-2025-10-06/</a>, See on <a href="https://news.ycombinator.com/item?id=45490549">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/amd-signs-ai-chip-supply-deal-with-openai-gives-it-option-take-10-stake-2025-10-06/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Modern messaging: Running your own XMPP server (205 pts)]]></title>
            <link>https://www.codedge.de/posts/modern-messaging-running-your-own-xmpp-server</link>
            <guid>45490439</guid>
            <pubDate>Mon, 06 Oct 2025 12:02:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.codedge.de/posts/modern-messaging-running-your-own-xmpp-server">https://www.codedge.de/posts/modern-messaging-running-your-own-xmpp-server</a>, See on <a href="https://news.ycombinator.com/item?id=45490439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p><img src="https://www.codedge.de/posts/modern-messaging-running-your-own-xmpp-server/cover_hu_ab4f7c06a6fe697c.webp" width="768" height="400" alt="Modern messaging: Running your own XMPP server"></p></div><p>Since a years we know, or might suspect, our chats are listend on,
our uploaded files are sold for advertising or what purpose ever and the chance our social messengers leak our private data is
incredibly high. It is about time to work against this.</p><p>Since 3 years the European Commission works on a plan to automatically monitor all chat,
email and messenger conversations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> If this is going to pass, and I strongly hope it will not, the European Union
is moving into a direction we know from states suppressing freedom of speech.</p><p>I went for setting up my own XMPP server, as this does not have any big resource requirements
and still support clustering (for high-availabilty purposes), encryption via OMEMO, file sharing
and has support for platforms and operating systems. Also the ecosystem with clients and multiple use cases evolved
over the years to provide rock-solid software and solutions for multi-user chats or event audio and video calls.</p><p>All code snippets written below work in either Debian os Raspberry Pi OS.</p><h2 id="setting-up-your-own-xmpp-server">Setting up your own XMPP server<a href="#setting-up-your-own-xmpp-server"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h2><p>The connection from your client to the XMPP server is encrypted and we need certificates for our server.
First thing to do is setting up our domains and point it to the IP - both IPv4 and IPv6 is supported and we can specify
both later in our configuration.</p><p>I assume the server is going to be run under <code>xmpp.example.com</code> and you all the following domains have been set up.</p><table><thead><tr><th>Type</th><th>Name</th><th>Notes</th></tr></thead><tbody><tr><td>A</td><td>xmpp.example.com</td><td>your main xmpp server address</td></tr><tr><td>A</td><td>conference.xmpp.example.com</td><td>needed for MUC (Multi User Chat)</td></tr><tr><td>A</td><td>proxy.xmpp.example.com</td><td>needed for SOCKS5 proxy support</td></tr><tr><td>A</td><td>pubsub.xmpp.example.com</td><td>needed for publish/subscribe support</td></tr><tr><td>A</td><td>upload.xmpp.example.com</td><td>needed for file uploads</td></tr><tr><td>A</td><td>stun.xmpp.example.com</td><td>needed for audio&amp;video calling</td></tr><tr><td>A</td><td>turn.xmpp.example.com</td><td>needed for audio&amp;video calling</td></tr></tbody></table><p>Fill in the IPv6 addresses accordingly.</p><p><a href="https://www.ejabberd.im/">ejabberd</a> is a robust server software, that is included in most Linux distributions.</p><p><strong>Install from Process One repository</strong><br>I discovered ProcessOne, the company behind <em>ejabberd</em>, also provides a <a href="https://repo.process-one.net/">Debian repository</a>.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>curl -o /etc/apt/sources.list.d/ejabberd.list https://repo.process-one.net/ejabberd.list
</span></span><span><span>curl -o /etc/apt/trusted.gpg.d/ejabberd.gpg https://repo.process-one.net/ejabberd.gpg
</span></span><span><span>apt update
</span></span><span><span>apt install ejabberd
</span></span></code></pre></td></tr></tbody></table></div><p><strong>Install from Github</strong><br>To get the most recent one, I use the packages offered in their <a href="https://github.com/processone/ejabberd">code repository</a>.
Installing version 25.07 just download the asset from the release:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>curl -L <span>\
</span></span></span><span><span><span></span>  -o /tmp/ejabberd_2507.deb <span>\
</span></span></span><span><span><span></span>  https://github.com/processone/ejabberd/releases/download/25.07/ejabberd_25.07-1_amd64.deb
</span></span><span><span>apt install /tmp/ejabberd_2507.deb
</span></span></code></pre></td></tr></tbody></table></div><p>Make sure the fowolling ports are opened in your firewall, taken from <a href="https://docs.ejabberd.im/admin/guide/security/">ejabberd firewall settings</a>.</p><ul><li><strong>5222</strong>: Jabber/XMPP client connections, plain or STARTTLS</li><li><strong>5223</strong>: Jabber client connections, using the old SSL method</li><li><strong>5269</strong>: Jabber/XMPP incoming server connections</li><li><strong>5280/5443</strong>: HTTP/HTTPS for Web Admin and many more</li><li><strong>7777</strong>: SOCKS5 file transfer proxy</li><li><strong>3478/5349</strong>: STUN+TURN/STUNS+TURNS service</li></ul><p>Port <code>1883</code>, used for MQTT, is also mentioned in the ejabberd docs, but we do not use this in our setup. So this port stays closed.</p><p>Depending how you installed ejabberd the config file is either at <code>/etc/ejabberd/conf/ejabberd.yml</code>
or <code>/opt/ejabberd/conf/ejabberd.yml</code>.</p><h3 id="general-configuration">General configuration<a href="#general-configuration"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h3><p>The configuration is a balance of 70:30 between having a privacy-focused setup for your users and meeting most of the suggestions
of the <a href="https://compliance.conversations.im/?ref=process-one.net">XMPP complicance test</a>. That means, settings that
protect the provacy of the users are higher rated despite not passing the test.</p><p>Therefore notable privacy and security settings are:</p><ul><li>XMPP over HTTP is disabled (<a href="https://docs.ejabberd.im/admin/configuration/modules/#mod_bosh">mod_bosh</a>)</li><li>Discover then a user last accessed a server is disabled (<a href="https://docs.ejabberd.im/admin/configuration/modules/#mod_last">mod_last</a>)</li><li>Delete uploaded files on a regular base (see <a href="#enable-file-uploads">upload config</a>)</li><li>Register account via a web page is disabled (<a href="https://docs.ejabberd.im/admin/configuration/modules/#mod_register_web">mod_register_web</a>)</li><li>In-band registration can be enabled, default off, captcha secured (<a href="https://docs.ejabberd.im/admin/configuration/modules/#mod_register">mod_register</a>, <a href="#registration">see registration config</a>)</li></ul><div><p><span><svg viewBox="92 59.5 300 300"><path d="M292 303.25V272c0-3.516-2.734-6.25-6.25-6.25H267v-1e2c0-3.516-2.734-6.25-6.25-6.25h-62.5c-3.516.0-6.25 2.734-6.25 6.25V197c0 3.516 2.734 6.25 6.25 6.25H217v62.5h-18.75c-3.516.0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h87.5c3.516.0 6.25-2.734 6.25-6.25zm-25-175V97c0-3.516-2.734-6.25-6.25-6.25h-37.5c-3.516.0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h37.5c3.516.0 6.25-2.734 6.25-6.25zm125 81.25c0 82.813-67.188 150-150 150-82.813.0-150-67.188-150-150 0-82.813 67.188-150 150-150 82.813.0 150 67.188 150 150z"></path></svg>
</span>Info</p><p>The configuration file is in YAML format. Keep an eye for indentation.</p></div><p>Let’s start digging into the configuration.</p><p><strong>Set the domain of your server</strong></p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span><span>hosts</span>:
</span></span><span><span>  - xmpp.example.com
</span></span></code></pre></td></tr></tbody></table></div><p><strong>Set the database type</strong><br>Instead of using the default <code>mnesia</code> type, we opt for <code>sql</code>, better said <code>sqlite</code>.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span><span>default_db</span>: sql
</span></span><span><span>
</span></span><span><span><span>host_config</span>:
</span></span><span><span>  <span>xmpp.example.com</span>:
</span></span><span><span>    <span>auth_method</span>: sql
</span></span><span><span>    <span>sql_type</span>: sqlite
</span></span></code></pre></td></tr></tbody></table></div><p><strong>Generate DH params</strong><br>Generate a fresh set of params for the DH key exchange. In your terminal run</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>sudo mkdir -p /opt/ejabberd <span>&amp;&amp;</span> <span>\
</span></span></span><span><span><span></span>  openssl dhparam -out /opt/ejabberd/dhparams.pem <span>4096</span> 
</span></span></code></pre></td></tr></tbody></table></div><p>and link the new file in the ejabberd configuration.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span><span>define_marco</span>:
</span></span><span><span>  <span># Other config</span>
</span></span><span><span>  <span>'DH_fiLE'</span>: <span>"/opt/ejabberd/dhparams.pem"</span>
</span></span><span><span>
</span></span><span><span><span># ...</span>
</span></span><span><span><span>c2s_dhfile</span>: <span>'DH_FILE'</span>
</span></span><span><span><span>s2s_dhfile</span>: <span>'DH_FILE'</span>
</span></span></code></pre></td></tr></tbody></table></div><p><strong>Ensure TLS for server-to-server connections</strong><br>Use TLS for server-to-server (s2s) connections.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>s2s_use_starttls: required
</span></span></code></pre></td></tr></tbody></table></div><p><strong>The listners</strong><br>The listeners aka <code>request_handlers</code> inside the config especially for <code>/admin</code>, <code>/captcha</code>, <code>/upload</code> and <code>/ws</code> are important.
All of them listen on port <code>5443</code>. Only one request handler is attached to port <code>5280</code>, the <code>/.well-known/acme-challenge</code>.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span><span>listen</span>:
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>5222</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>module</span>: ejabberd_c2s
</span></span><span><span>    <span>max_stanza_size</span>: <span>262144</span>
</span></span><span><span>    <span>shaper</span>: c2s_shaper
</span></span><span><span>    <span>access</span>: c2s
</span></span><span><span>    <span>starttls_required</span>: <span>true</span>
</span></span><span><span>    <span>protocol_options</span>: <span>'TLS_OPTIONS'</span>
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>5223</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>module</span>: ejabberd_c2s
</span></span><span><span>    <span>max_stanza_size</span>: <span>262144</span>
</span></span><span><span>    <span>shaper</span>: c2s_shaper
</span></span><span><span>    <span>access</span>: c2s
</span></span><span><span>    <span>tls</span>: <span>true</span>
</span></span><span><span>    <span>protocol_options</span>: <span>'TLS_OPTIONS'</span>
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>5269</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>module</span>: ejabberd_s2s_in
</span></span><span><span>    <span>max_stanza_size</span>: <span>524288</span>
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>5270</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>module</span>: ejabberd_s2s_in
</span></span><span><span>    <span>tls</span>: <span>true</span>
</span></span><span><span>    <span>max_stanza_size</span>: <span>524288</span>
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>5443</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>module</span>: ejabberd_http
</span></span><span><span>    <span>tls</span>: <span>true</span>
</span></span><span><span>    <span>protocol_options</span>: <span>'TLS_OPTIONS'</span>
</span></span><span><span>    <span>ciphers</span>: <span>'TLS_CIPHERS'</span>
</span></span><span><span>    <span>request_handlers</span>:
</span></span><span><span>      <span>/admin</span>: ejabberd_web_admin
</span></span><span><span>      <span>/captcha</span>: ejabberd_captcha
</span></span><span><span>      <span>/upload</span>: mod_http_upload
</span></span><span><span>      <span>/ws</span>: ejabberd_http_ws
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>5280</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>module</span>: ejabberd_http
</span></span><span><span>    <span>tls</span>: <span>false</span>
</span></span><span><span>    <span>request_handlers</span>:
</span></span><span><span>      <span>/.well-known/acme-challenge</span>: ejabberd_acme
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>3478</span>
</span></span><span><span>    <span>ip</span>: <span>"::"</span>
</span></span><span><span>    <span>transport</span>: udp
</span></span><span><span>    <span>module</span>: ejabberd_stun
</span></span><span><span>    <span>use_turn</span>: <span>true</span>
</span></span><span><span>    <span>## The server's public IPv4 address:</span>
</span></span><span><span>    <span>turn_ipv4_address</span>: <span>"{{ ipv4 }}"</span>
</span></span><span><span>    <span>## The server's public IPv6 address:</span>
</span></span><span><span>    <span>turn_ipv6_address</span>: <span>"{{ ipv6 }}"</span>
</span></span><span><span>  -
</span></span><span><span>    <span>port</span>: <span>1883</span>
</span></span><span><span>    <span>ip</span>: <span>"::1"</span>
</span></span><span><span>    <span>module</span>: mod_mqtt
</span></span><span><span>    <span>backlog</span>: <span>1000</span>
</span></span></code></pre></td></tr></tbody></table></div><h3 id="acls--access-rules">ACLs &amp; Access rules<a href="#acls--access-rules"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h3><p>For adminstration of ejabberd we need a user with admin rights and properly set up ACLs and access rules.
There is a separat section for ACLs inside the config in which we set up an admin user name <code>root</code>. The name of the user
is important for later, when we actually create this user.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>acl:
</span></span><span><span>  admin:
</span></span><span><span>    user: root
</span></span><span><span>  <span># ... </span>
</span></span><span><span>  proxy_users:
</span></span><span><span>    server: xmpp.example.com
</span></span></code></pre></td></tr></tbody></table></div><p>The <code>access_rules</code> should already be set up, just to confirm that you have a correct entry for the <code>configure</code> action.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>access_rules:
</span></span><span><span>  <span>#...</span>
</span></span><span><span>  configure:
</span></span><span><span>    allow: admin
</span></span></code></pre></td></tr></tbody></table></div><p>Now the new <code>root</code> user needs to be create by running this command on the console.
Watch out to put in the correct domain.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>ejabberdctl register root xmpp.example.com <span>'my_password_here'</span>
</span></span></code></pre></td></tr></tbody></table></div><p>Another user can be registered with the same command.<br>We set <code>root</code> as the admin user in the config previously. That is how ejabberd knows which user has admin permissions.</p><h3 id="enable-file-uploads">Enable file uploads<a href="#enable-file-uploads"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h3><p>Enabling file uploads is done with <a href="https://docs.ejabberd.im/admin/configuration/modules/#mod_http_upload"><code>mod_http_upload</code></a>.
First, create a folder where the uploads should be stored.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span>mkdir -p /var/www/ejabberd/upload
</span></span></code></pre></td></tr></tbody></table></div><p>Now update the ejabberd configuration like this:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span><span>modules</span>:
</span></span><span><span>  <span>#...</span>
</span></span><span><span>  <span>mod_http_upload</span>:
</span></span><span><span>    <span>put_url</span>: https://@HOST@:5443/upload
</span></span><span><span>    <span>docroot</span>: /var/www/ejabberd/upload
</span></span><span><span>    <span>max_size</span>: <span>10000000</span> <span>## 10 MB</span>
</span></span><span><span>    <span>thumbnail</span>: <span>false</span>
</span></span><span><span>    <span>custom_headers</span>:
</span></span><span><span>       <span>"Access-Control-Allow-Origin": </span><span>"https://@HOST@"</span>
</span></span><span><span>       <span>"Access-Control-Allow-Methods": </span><span>"GET,HEAD,PUT,OPTIONS"</span>
</span></span><span><span>       <span>"Access-Control-Allow-Headers": </span><span>"Content-Type"</span>
</span></span><span><span>  <span>#...</span>
</span></span></code></pre></td></tr></tbody></table></div><p>The allowed file upload size is defined in the <code>max_size</code> param and is set to 10MB.</p><p>Make sure, to delete uploaded files in a reasonable amount of time via cronjob. This is an example of a cronjob,
that deletes files that are older than 1 week.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span></code></pre></td><td><pre tabindex="0"><code data-lang="shell"><span><span><span>0</span> * * * * find /var/www/ejabberd/upload/upload -type f -cmin +10080 -exec rm -rf <span>{}</span>
</span></span></code></pre></td></tr></tbody></table></div><h3 id="registration">Registration<a href="#registration"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h3><p>Registration in ejabberd is done via <a href="https://docs.ejabberd.im/admin/configuration/modules/#mod_register"><code>mod_register</code></a>
and can be enabled with these entries in the config file:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span><span>access_rules</span>:
</span></span><span><span>  <span>#...</span>
</span></span><span><span>  <span>register</span>:
</span></span><span><span>    <span>allow</span>: all
</span></span><span><span>  <span>#...</span>
</span></span><span><span>
</span></span><span><span><span>modules</span>:
</span></span><span><span>  <span>#...</span>
</span></span><span><span>  <span>mod_register</span>:
</span></span><span><span>    <span>access</span>: register
</span></span><span><span>    <span>ip_access</span>: all
</span></span><span><span>    <span>captcha_protected</span>: <span>true</span>
</span></span><span><span>    <span>password_strength</span>: <span>64</span>
</span></span><span><span>  <span>#...</span>
</span></span></code></pre></td></tr></tbody></table></div><p>If you want to enable registration for your server make sure you enable a captcha for it.
Otherwise you will get a lot of spam and fake registrations.</p><p>ejabberd provides a working <a href="https://github.com/processone/ejabberd/blob/master/tools/captcha.sh">captcha script</a>,
that you can copy to your server and link in your configuration. You will need <code>imaggemagick</code> and <code>gstools</code> installed
on you system. In the <code>ejabberd.yml</code> config file</p><h2 id="add-tls">Add TLS<a href="#add-tls"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h2><p>ejabberd can provision TLS certificates on its own. No need to install <em>certbot</em>. To not expose ejabberd directly to
the internet, <code>nginx</code> is put in front of the XMPP server. Instead of using <em>nginx</em>, every other web server (caddy, …)
or proxy can be used as well.</p><p>Here is a sample config for <em>nginx</em>:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span></code></pre></td><td><pre tabindex="0"><code data-lang="yaml"><span><span>server {
</span></span><span><span>    listen 80;
</span></span><span><span>    listen [::]:80;
</span></span><span><span>
</span></span><span><span>    server_name xmpp.example.com proxy.xmpp.example.com pubsub.xmpp.example.com conference.xmpp.example.com;
</span></span><span><span>
</span></span><span><span>    access_log  /var/log/nginx/20-xmpp.access.log;
</span></span><span><span>    error_log  /var/log/nginx/20-xmpp.error.log;
</span></span><span><span>
</span></span><span><span>    location = /.well-known/host-meta {
</span></span><span><span>      default_type 'application/xrd+xml';
</span></span><span><span>      add_header Access-Control-Allow-Origin '*' always;
</span></span><span><span>
</span></span><span><span>      root /var/www/ejabberd;
</span></span><span><span>    }
</span></span><span><span>    location = /.well-known/host-meta.json {
</span></span><span><span>      default_type 'application/jrd+json';
</span></span><span><span>      add_header Access-Control-Allow-Origin '*' always;
</span></span><span><span>
</span></span><span><span>      root /var/www/ejabberd;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    location / {
</span></span><span><span>        proxy_set_header X-Real-IP $remote_addr;
</span></span><span><span>        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
</span></span><span><span>        proxy_set_header X-Forwarded-Proto $scheme;
</span></span><span><span>
</span></span><span><span>        proxy_pass http://127.0.0.1:5280;
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></td></tr></tbody></table></div><h3 id="alternative-connection-methods">Alternative connection methods<a href="#alternative-connection-methods"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h3><p>The nginx vhosts offers files, <code>host-meta</code> and <code>host-meta.json</code>, for indicating which other connection methods (BOSH, WS) your server offers. The details can be read in <a href="https://xmpp.org/extensions/xep-0156.html">XEP-0156</a> extension.
Opposite to the examples in the XEP, there is no BOSH, but only a websocket connection our server offers. The BOSH part is removed from the config file.</p><p><strong>host-meta</strong></p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td><td><pre tabindex="0"><code data-lang="xml"><span><span><span>&lt;?xml version='1.0' encoding='utf-8'?&gt;</span>
</span></span><span><span><span>&lt;XRD</span> <span>xmlns=</span><span>'http://docs.oasis-open.org/ns/xri/xrd-1.0'</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;Link</span> <span>rel=</span><span>"urn:xmpp:alt-connections:websocket"</span>
</span></span><span><span>        <span>href=</span><span>"wss://xmpp.example.com:5443/ws"</span> <span>/&gt;</span>
</span></span><span><span><span>&lt;/XRD&gt;</span>
</span></span></code></pre></td></tr></tbody></table></div><p><strong>host-meta.json</strong></p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td><td><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>"links"</span>: [
</span></span><span><span>    {
</span></span><span><span>      <span>"rel"</span>: <span>"urn:xmpp:alt-connections:websocket"</span>,
</span></span><span><span>      <span>"href"</span>: <span>"wss://xmpp.example.com:5443/ws"</span>
</span></span><span><span>    }
</span></span><span><span>  ]
</span></span><span><span>}
</span></span></code></pre></td></tr></tbody></table></div><p>Put that file in a folder your nginx serves. Have a look at the path and URL it is expected to be, see <code>.well-known</code>.</p><h2 id="choose-your-client">Choose your client<a href="#choose-your-client"><svg width=".8em" height=".8em" viewBox="0 0 2048 2048"><path fill="currentColor" d="M1536 768v128q76 0 145 17t123 56 84 99 32 148q0 66-25 124t-69 101-102 69-124 26h-512q-66 0-124-25t-101-69-69-102-26-124q0-87 31-147t85-99 122-56 146-18V768h-64q-93 0-174 35t-142 96-96 142-36 175q0 93 35 174t96 142 142 96 175 36h512q93 0 174-35t142-96 96-142 36-175q0-93-35-174t-96-142-142-96-175-36zm-640 512v-128q76 0 145-17t123-56 84-99 32-148q0-66-25-124t-69-101-102-69-124-26H448q-66 0-124 25t-101 69-69 102-26 124q0 87 31 147t85 99 122 56 146 18v128h-64q-93 0-174-35t-142-96-96-142T0 832q0-93 35-174t96-142 142-96 175-36h512q93 0 174 35t142 96 96 142 36 175q0 93-35 174t-96 142-142 96-175 36z"></path></svg></a></h2><p>Clients I can recommend are <a href="https://profanity-im.github.io/">Profanity</a>, an easy to use command-line client,
and <a href="https://monal-im.org/">Monal</a> for MacOS and iOS. A good overview of client can be found on the offical <a href="https://xmpp.org/software/">XMPP website</a>.</p><p>This post was created on
<time datetime="2025-09-16T00:00:00+02:00">16 Sep 2025</time>
and updated on
<time datetime="2025-10-06T14:09:01+02:00">06 Oct 2025</time>
.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[State Terror, American Style (184 pts)]]></title>
            <link>https://paulkrugman.substack.com/p/state-terror-american-style</link>
            <guid>45489978</guid>
            <pubDate>Mon, 06 Oct 2025 10:54:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulkrugman.substack.com/p/state-terror-american-style">https://paulkrugman.substack.com/p/state-terror-american-style</a>, See on <a href="https://news.ycombinator.com/item?id=45489978">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!yMXx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!yMXx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 424w, https://substackcdn.com/image/fetch/$s_!yMXx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 848w, https://substackcdn.com/image/fetch/$s_!yMXx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!yMXx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!yMXx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg" width="1041" height="694" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/db703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:694,&quot;width&quot;:1041,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Debris was scattered on the hallways of an apartment complex in Chicago, where federal agents conducted a large scale immigration raid on September 30, 2025.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Debris was scattered on the hallways of an apartment complex in Chicago, where federal agents conducted a large scale immigration raid on September 30, 2025." title="Debris was scattered on the hallways of an apartment complex in Chicago, where federal agents conducted a large scale immigration raid on September 30, 2025." srcset="https://substackcdn.com/image/fetch/$s_!yMXx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 424w, https://substackcdn.com/image/fetch/$s_!yMXx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 848w, https://substackcdn.com/image/fetch/$s_!yMXx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!yMXx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb703dbb-c3ad-4d45-83fa-5b3c8fb32f74_1041x694.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Over the weekend I talked to a couple of people, people who generally try to keep abreast of the news, about the Chicago apartment raid last Tuesday — and discovered that they hadn’t heard about it. And that’s extremely worrying. It suggests that many people don’t realize how fast and aggressively the Trump administration is moving to end rule of law and convert America into a full-fledged autocracy.</p><p><span>So while I’d like to devote today’s post to economics — you have no idea how happy I felt while writing </span><a href="https://paulkrugman.substack.com/p/tech-and-the-wealth-of-nations" rel="">yesterday’s primer</a><span> about agglomeration and productivity — I couldn’t in good conscience avoid writing about the terrible things happening in Chicago and elsewhere, and what they may portend.</span></p><p><span>About that raid: It was reported in mainstream media, but didn’t get the screaming banner headlines it deserved. Here’s what happened, according to </span><a href="https://www.yahoo.com/news/articles/us-border-patrol-raid-sweeps-100831785.html" rel="">Reuters</a><span>:</span></p><blockquote><p>U.S. Border Patrol agents deployed to Chicago led a late-night raid on an apartment building this week, rappelling from helicopters onto rooftops and breaking down doors in an operation authorities said targeted gang members but which swept up U.S. citizens and families.</p><p>…</p><p>As part of the raid, some U.S. citizens were temporarily detained and children pulled from their beds, according to interviews with residents and news reports. Building hallways were still littered with debris two days later.</p><p>…</p><p>Hundreds of agents swarmed the apartment building during the raid on Tuesday, including some rappelling down to the roof from Black Hawk helicopters, according to NewsNation.</p><p>…</p><p>One resident, who asked not to be named, reported being made to lie down on the ground by agents during the raid and having his hands zip-tied.</p></blockquote><p><span>ICE claimed that the building was targeted because it was “</span><a href="https://edition.cnn.com/2025/10/03/us/chicago-apartment-ice-raid" rel="">known to be frequented</a><span> by Tren de Aragua (a Venezuelan gang) members and their associates” — that is, although ICE carried out the raid, it was supposedly about crime. And they arrested two suspected gang members, while also rounding up some undocumented immigrants. But they detained everyone in the building, smashed their doors, zip-tied their children, and ransacked their homes.</span></p><p>This was a wildly disproportionate and illegal response, even if the raid had actually had anything to do with crime.</p><p><span>But none of what the Trump administration is doing in Chicago has anything to do with fighting crime. Chicago has more violent crime than, say, New York or Los Angeles, but the post-Covid bump in crime has completely receded. City officials report that this past summer had the </span><a href="https://www.chicago.gov/city/en/depts/mayor/press_room/press_releases/2025/september/safest-summer-since-1965.html" rel="">fewest homicides</a><span> in 60 years. If we’d seen this kind of decline in crime </span><em>after</em><span> the Trump administration began flooding Chicago with ICE agents, rather than before, they’d be touting these results as complete vindication.</span></p><p>But as I said, this isn’t about crime. It’s about paranoid conspiracy theories and an attempt to dismantle democracy.</p><p>Here’s Stephen Miller, Trump’s immigration czar:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!H2ck!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!H2ck!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 424w, https://substackcdn.com/image/fetch/$s_!H2ck!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 848w, https://substackcdn.com/image/fetch/$s_!H2ck!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 1272w, https://substackcdn.com/image/fetch/$s_!H2ck!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!H2ck!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png" width="1066" height="1006" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1006,&quot;width&quot;:1066,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A screenshot of a social media post\n\nAI-generated content may be incorrect.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="A screenshot of a social media post

AI-generated content may be incorrect." title="A screenshot of a social media post

AI-generated content may be incorrect." srcset="https://substackcdn.com/image/fetch/$s_!H2ck!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 424w, https://substackcdn.com/image/fetch/$s_!H2ck!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 848w, https://substackcdn.com/image/fetch/$s_!H2ck!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 1272w, https://substackcdn.com/image/fetch/$s_!H2ck!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbca853b-2190-449a-885d-a09d759e61c0_1066x1006.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Does Miller actually believe this? The truth is that left-wing terrorist attacks and plots are very rare in this country. There have been more this year than in the previous two years, but the number is still tiny, and is normally dwarfed by right-wing terrorism:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ox8D!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ox8D!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 424w, https://substackcdn.com/image/fetch/$s_!ox8D!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 848w, https://substackcdn.com/image/fetch/$s_!ox8D!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 1272w, https://substackcdn.com/image/fetch/$s_!ox8D!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ox8D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png" width="1308" height="1086" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1086,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A graph of a terrorist attack\n\nAI-generated content may be incorrect.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="A graph of a terrorist attack

AI-generated content may be incorrect." title="A graph of a terrorist attack

AI-generated content may be incorrect." srcset="https://substackcdn.com/image/fetch/$s_!ox8D!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 424w, https://substackcdn.com/image/fetch/$s_!ox8D!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 848w, https://substackcdn.com/image/fetch/$s_!ox8D!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 1272w, https://substackcdn.com/image/fetch/$s_!ox8D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e38b89-b048-4dec-935c-3dabfb01b129_1308x1086.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><a href="https://www.csis.org/analysis/left-wing-terrorism-and-political-violence-united-states-what-data-tells-us" rel="">Source</a></p><p>What is true is that right-wing terrorism is way down this year, possibly because potential terrorists don’t feel the need to act when the Trump administration is doing it for them. Some people who might have engaged in terrorist assaults may well be working for ICE instead.</p><p>My guess is that Donald Trump actually believes that Portland is a war zone, that residents of big blue cities are afraid to leave their apartments. But Miller almost surely knows better. He just has a different definition of terrorism: For him, it means any kind of opposition to his racist, authoritarian agenda.</p><p><span>Here was his reaction after a federal judge — appointed by Trump! — </span><a href="https://www.nytimes.com/2025/10/04/us/politics/judge-blocks-national-guard-portland.html" rel="">issued an injunction</a><span> temporarily preventing Trump from taking control of Oregon’s National Guard and deploying it in Portland:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SJky!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SJky!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 424w, https://substackcdn.com/image/fetch/$s_!SJky!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 848w, https://substackcdn.com/image/fetch/$s_!SJky!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 1272w, https://substackcdn.com/image/fetch/$s_!SJky!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SJky!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png" width="1288" height="1212" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1212,&quot;width&quot;:1288,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A screenshot of a black and white text\n\nAI-generated content may be incorrect.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="A screenshot of a black and white text

AI-generated content may be incorrect." title="A screenshot of a black and white text

AI-generated content may be incorrect." srcset="https://substackcdn.com/image/fetch/$s_!SJky!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 424w, https://substackcdn.com/image/fetch/$s_!SJky!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 848w, https://substackcdn.com/image/fetch/$s_!SJky!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 1272w, https://substackcdn.com/image/fetch/$s_!SJky!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8faf7815-9438-4cae-94ca-ac9500aac7a4_1288x1212.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>If you’ve looked at footage from Portland, you know that the “relentless terrorist assaults” on ICE officers consist mainly of people yelling at them. But in Miller’s eyes that’s a hate crime.</p><p><span>What do we learn from the Chicago apartment raid plus the growing number of incidents in which ICE agents have </span><a href="https://www.cbsnews.com/news/ice-officer-pushed-woman-video-returns-to-duty/" rel="">physically attacked</a><span> people who posed no conceivable threat? To me, it says that even “alarmists” who warned about the threat a Trump administration would pose to democracy underestimated just how evil this administration would be.</span></p><p><span>Until recently, most warnings about the decline of democracy envisaged a scenario something like Hungary’s “</span><a href="https://www.nytimes.com/2018/02/10/world/europe/hungary-orban-democracy-far-right.html" rel="">soft autocracy</a><span>”: Subversion of institutions from the media to the courts, rigged elections, crony capitalism that favors regime supporters, and so on. We didn’t expect America to become a country where masked secret policemen smash down your door in the middle of the night and take you away. Yet that’s where we are.</span></p><p><span>And don’t expect the attacks to be limited to immigrants. A recent White House </span><a href="https://time.com/7322106/trump-nspm-7-domestic-terrorism/" rel="">memo</a><span> directs the FBI to investigate groups as potential domestic terrorists based on incredibly expansive criteria, including “anti-capitalism” and “anti-Christianity” views. This would basically empower going after any kind of dissent.</span></p><p><span>One reason things have gotten so extreme, so fast may be that Trump, Miller and company are in a </span><a href="https://www.gelliottmorris.com/p/trump-is-racing-against-time" rel="">race against time</a><span>. Foreign autocrats like Orban or Vladimir Putin could afford to chip away gradually at the foundations of democracy because they were, at least initially, quite popular. Trump — although he won’t admit it — has very low approval, and the public opposes him on every major issue. Yet he and his minions control much of the machinery of government, and are trying to use it to intimidate — you might say terrorize — their opponents before public anger catches up with them.</span></p><p>Moreover, Miller and Tom “Cava bag” Homan clearly like inflicting suffering.</p><p>What all this suggests to me is that there will be many more incidents as bad or worse than the Chicago apartment raid. If you think I’m overreacting, remember: The alarmists have been right about Trump every step of the way.</p><p>So what can people and institutions do? Resist. Don’t make concessions in the hope of buying MAGA off. Don’t mute your criticisms in an attempt to seem even-handed. As far as I know, no wannabe autocrat has managed to consolidate power while being as unpopular as Trump is right now. Don’t help him become the first to pull it off.</p><p>MUSICAL CODA</p><div id="youtube2-veiJLhXdwn8" data-attrs="{&quot;videoId&quot;:&quot;veiJLhXdwn8&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/veiJLhXdwn8?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobel Prize in Physiology or Medicine 2025 awarded to immune system researchers (313 pts)]]></title>
            <link>https://www.nobelprize.org/prizes/medicine/2025/press-release/</link>
            <guid>45489533</guid>
            <pubDate>Mon, 06 Oct 2025 09:41:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nobelprize.org/prizes/medicine/2025/press-release/">https://www.nobelprize.org/prizes/medicine/2025/press-release/</a>, See on <a href="https://news.ycombinator.com/item?id=45489533">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

		<header>
			<h2>
				Press release			</h2>
		</header>

		


												<p><strong>English</strong><br><a href="https://www.nobelprize.org/uploads/2025/10/press-medicineprize2025.pdf" target="_blank" rel="noreferrer noopener">English (pdf)</a><br><a href="https://www.nobelprize.org/prizes/uncategorized/press-release-swedish">Swedish</a><br><a href="https://www.nobelprize.org/uploads/2025/10/press-medicineprize2025-swedish.pdf" target="_blank" rel="noreferrer noopener">Swedish (pdf</a>)</p>
																														<figure><img fetchpriority="high" decoding="async" width="2048" height="272" src="https://www.nobelprize.org/images/175746-large-2x.jpg" alt="Logotype Nobelförsamlingen"></figure>
																														<p>6 October 2025</p>
																														<p><a href="http://nobelprizemedicine.org/" target="_blank" rel="noopener noreferrer">The Nobel Assembly at Karolinska Institutet</a> has decided to award the 2025 Nobel Prize in Physiology or Medicine to:</p>
																														<p><strong>Mary E. Brunkow</strong><br>Institute for Systems Biology,<br>Seattle, USA</p>
																														<p><strong>Fred Ramsdell</strong><br>Sonoma Biotherapeutics,<br>San Francisco, USA</p>
																														<p><strong>Shimon Sakaguchi</strong><br>Osaka University,<br>Osaka, Japan</p>
																														<p><em>“for their discoveries concerning peripheral immune tolerance”</em></p>
																														<h2>They discovered how the immune system is kept in check</h2>
																														<p>The body’s powerful immune system must be regulated, or it may attack our own organs. Mary E. Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their groundbreaking discoveries concerning <em>peripheral immune tolerance</em> that prevents the immune system from harming the body.</p>
																														<p>Every day, our immune system protects us from thousands of different microbes trying to invade our bodies. These all have different appearances, and many have developed similarities with human cells as a form of camouflage. So how does the immune system determine what it should attack and what it should defend?</p>
																														<p>Mary Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their fundamental discoveries relating to peripheral immune tolerance. The laureates identified the immune system’s security guards, <em>regulatory T cells</em>, which prevent immune cells from attacking our own body.</p>
																														<p>“Their discoveries have been decisive for our understanding of how the immune system functions and why we do not all develop serious autoimmune diseases,” says Olle Kämpe, chair of the Nobel Committee.</p>
																														<p>Shimon Sakaguchi was swimming against the tide in 1995, when he made the first key discovery. At the time, many researchers were convinced that immune tolerance only developed due to potentially harmful immune cells being eliminated in the thymus, through a process called <em>central tolerance</em>. Sakaguchi showed that the immune system is more complex and discovered a previously unknown class of immune cells, which protect the body from autoimmune diseases.</p>
																														<p>Mary Brunkow and Fred Ramsdell made the other key discovery in 2001, when they presented the explanation for why a specific mouse strain was particularly vulnerable to autoimmune diseases. They had discovered that the mice have a mutation in a gene that they named <em>Foxp3</em>. They also showed that mutations in the human equivalent of this gene cause a serious autoimmune disease, IPEX.</p>
																														<p>Two years after this, Shimon Sakaguchi was able to link these discoveries. He proved that the <em>Foxp3</em> gene governs the development of the cells he identified in 1995. These cells, now known as regulatory T cells, monitor other immune cells and ensure that our immune system tolerates our own tissues.</p>
																														<p>The laureates’ discoveries launched the field of peripheral tolerance, spurring the development of medical treatments for cancer and autoimmune diseases. This may also lead to more successful transplantations. Several of these treatments are now undergoing clinical trials.</p>
																														<h2>Illustrations</h2>
																														<p>The illustrations are free to use for non-commercial purposes. Attribute “© The Nobel Committee for Physiology or Medicine. Ill. Mattias Karlén”</p>
																														<p><a href="https://www.nobelprize.org/uploads/2025/10/Carrier_3-2.jpg" target="_blank" rel="noreferrer noopener">Illustration: The Nobel Prize in Physiology or Medicine 2025</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-figure2.jpg" target="_blank" rel="noreferrer noopener">Illustration: How T cells discover a virus</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-figure3.jpg" target="_blank" rel="noreferrer noopener">Illustration: How harmful T cells are eliminated</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-figure4.jpg" target="_blank" rel="noreferrer noopener">Illustration: The experiment that inspired Sakaguchi</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-figure5.jpg" target="_blank" rel="noreferrer noopener">Illustration: Sakaguchi defines a new class of T cells</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-figure6.jpg" target="_blank" rel="noreferrer noopener">Illustration: Brunkow and Ramsdell find the scurfy mutation</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025-figure7.jpg" target="_blank" rel="noreferrer noopener">Illustration: How regulatory T cells protect us</a></p>
																														<h2>Read more about this year’s prize</h2>
																														<p><a href="https://www.nobelprize.org/uploads/2025/10/popular-medicineprize2025.pdf" target="_blank" rel="noreferrer noopener">Popular science background: They understood how the immune system is kept in check (pdf)</a><br><a href="https://www.nobelprize.org/uploads/2025/10/advanced-medicineprize2025.pdf" target="_blank" rel="noreferrer noopener">Scientific background to the Nobel Prize in Physiology or Medicine 2025 (pdf)</a></p>
																														<hr>
																														<p><strong>Mary E. Brunkow</strong>, born 1961. Ph.D. from Princeton University, Princeton, USA. Senior Program Manager at the Institute for Systems Biology, Seattle, USA.</p>
																														<p><strong>Fred Ramsdell</strong>, born 1960. Ph.D. 1987 from the University of California, Los Angeles, USA. Scientific Advisor, Sonoma Biotherapeutics, San Francisco, USA.</p>
																														<p><strong>Shimon Sakaguchi</strong>, born 1951. M.D. 1976 and Ph.D. 1983 from Kyoto University, Japan. Distinguished Professor at the Immunology Frontier Research Center, Osaka University, Japan.</p>
																														<hr>
																														<p><strong>Prize amount</strong>: 11 million Swedish kronor, to be shared equally between the laureates.<br><strong>Press contact</strong>: Pernilla Witte, +46 8 524 86 107, <a href="https://www.nobelprize.org/cdn-cgi/l/email-protection" data-cfemail="80f0e5f2eee9ecece1aef7e9f4f4e5c0eeefe2e5ecf0f2e9fae5ede5e4e9e3e9eee5aeeff2e7">[email&nbsp;protected]</a> or Thomas Perlmann, <a href="https://www.nobelprize.org/cdn-cgi/l/email-protection" data-cfemail="cbbfa3a4a6aab8e5bbaeb9a7a6aaa5a58ba5a4a9aea7bbb9a2b1aea6aeafa2a8a2a5aee5a4b9ac">[email&nbsp;protected]</a>, Secretary-General, The Nobel Assembly at Karolinska Institutet.</p>
																														<hr>
																														<p>Illustrations: © The Nobel Committee for Physiology or Medicine.</p>
																														<hr>
																														<p><em>The Nobel Assembly, consisting of 50 professors at Karolinska Institutet, awards the Nobel Prize in Physiology or Medicine. Its Nobel Committee evaluates the nominations. Since 1901 the Nobel Prize has been awarded to scientists who have made the most important discoveries for the benefit of humankind.</em></p>
																														<p>Nobel Prize® is the registered trademark of the Nobel Foundation</p>
																											

		
		
<div>
	<p><a href="#content">
		Back to top	</a></p><svg width="18px" height="15px" viewBox="0 0 20 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" role="image" aria-labelledby="back-to-top-title  back-to-top-desc">
	<title id="back-to-top-title">Back To Top</title>
	<desc id="back-to-top-desc">Takes users back to the top of the page</desc>
	<g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
		<g transform="translate(-474.000000, -9998.000000)" fill="#2E2A25">
			<g transform="translate(474.000000, 9998.000000)">
				<g transform="translate(10.000000, 10.000000) rotate(45.000000) translate(-10.000000, -10.000000) translate(3.000000, 3.000000)">
					<rect x="0" y="0" width="2" height="14"></rect>
					<rect x="0" y="0" width="14" height="2"></rect>
				</g>
				<rect x="9" y="3" width="2" height="14"></rect>
			</g>
		</g>
	</g>
</svg>
</div>

	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zürich voters ban noisy leaf blowers (120 pts)]]></title>
            <link>https://www.swissinfo.ch/eng/swiss-democracy/zurich-voters-ban-petrol-powered-leaf-blowers/90082192</link>
            <guid>45488729</guid>
            <pubDate>Mon, 06 Oct 2025 07:50:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swissinfo.ch/eng/swiss-democracy/zurich-voters-ban-petrol-powered-leaf-blowers/90082192">https://www.swissinfo.ch/eng/swiss-democracy/zurich-voters-ban-petrol-powered-leaf-blowers/90082192</a>, See on <a href="https://news.ycombinator.com/item?id=45488729">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <figure x-data="image">
    <picture>
    <source srcset="https://www.swissinfo.ch/content/wp-content/uploads/sites/13/2025/09/682ec9782c9978d1cbe2d94c7ffdcce6fbed838d-90081961.jpg?crop=0px,0px,1400px,934px&amp;w=880&amp;ver=c382c6c2" width="880" height="587" media="(min-width: 600px)">
<source srcset="https://www.swissinfo.ch/content/wp-content/uploads/sites/13/2025/09/682ec9782c9978d1cbe2d94c7ffdcce6fbed838d-90081961.jpg?crop=0px,0px,1400px,934px&amp;w=580&amp;ver=c382c6c2" width="580" height="387" media="">
    <img src="https://www.swissinfo.ch/content/wp-content/uploads/sites/13/2025/09/682ec9782c9978d1cbe2d94c7ffdcce6fbed838d-90081961.jpg?ver=c382c6c2" width="1400" height="1050" alt="Zurich voters ban petrol-powered leaf blowers" loading="eager" decoding="sync" fetchpriority="high">
</picture>
        <figcaption x-cloak="" x-show="showCaption">
                    <span>
                Zurich voters ban petrol-powered leaf blowers            </span>
                        <span>
            Keystone-SDA        </span>
            </figcaption>
    </figure>
<div x-show="isTrackSelectorOpen" x-on:click.outside="isTrackSelectorOpen &amp;&amp; toggleTrackSelector()" x-data="readAloud({&quot;tracks&quot;:[{&quot;id&quot;:&quot;cad90a39137be04f3a40bc04e5bf3f95&quot;,&quot;url&quot;:&quot;https://cdn.prod.swi-services.ch/90082192/text-to-speech/en-US.514d6876-cbec-47cd-95f5-ee35b72f9d2c.mp3&quot;,&quot;metadata&quot;:{&quot;media_publication_date&quot;:&quot;2025-09-28&quot;,&quot;media_title&quot;:&quot;Zurich voters ban noisy leaf blowers&quot;,&quot;media_urn&quot;:&quot;urn:swi:audio:90082192&quot;,&quot;media_show&quot;:&quot;en-US&quot;,&quot;media_episode&quot;:&quot;en-US on 28.09.2025&quot;,&quot;media_enterprise_units&quot;:&quot;SWI&quot;,&quot;media_language&quot;:&quot;eng&quot;,&quot;media_content_group&quot;:&quot;tts&quot;}},{&quot;id&quot;:&quot;6b15c665a876f2b14864d2e0c50e6067&quot;,&quot;url&quot;:&quot;https://cdn.prod.swi-services.ch/90082192/text-to-speech/en-GB.13abd461-3590-436a-a96a-eea067eaf09f.mp3&quot;,&quot;metadata&quot;:{&quot;media_publication_date&quot;:&quot;2025-09-28&quot;,&quot;media_title&quot;:&quot;Zurich voters ban noisy leaf blowers&quot;,&quot;media_urn&quot;:&quot;urn:swi:audio:90082192&quot;,&quot;media_show&quot;:&quot;en-GB&quot;,&quot;media_episode&quot;:&quot;en-GB on 28.09.2025&quot;,&quot;media_enterprise_units&quot;:&quot;SWI&quot;,&quot;media_language&quot;:&quot;eng&quot;,&quot;media_content_group&quot;:&quot;tts&quot;}}]})" x-cloak="">
            
        <ul>
                            <li>
                    
                </li>
                            <li>
                    
                </li>
                    </ul>
        <p><span>
            <svg width="20" height="21" viewBox="0 0 20 21" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 9.234a1 1 0 0 1 2 0v6a1 1 0 0 1-2 0v-6Zm1-4.93a1 1 0 1 0 0 2 1 1 0 0 0 0-2Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10 .254c-5.523 0-10 4.477-10 10s4.477 10 10 10 10-4.477 10-10-4.477-10-10-10Zm-8 10a8 8 0 1 0 16 0 8 8 0 0 0-16 0Z" fill="currentColor"></path></svg>        </span>
        <span>
            Generated with artificial intelligence.        </span>
    </p>
</div>
<p>
    <h2>
        The people of Zurich have had enough of the noise of leaf blowers. Voters have banned petrol-powered machines with a 61.7% majority.    </h2>
</p>
<div>
    <p><span>
        This content was published on    </span>
    <time datetime="2025-09-28T17:16:51+02:00">
        September 28, 2025 - 17:16    </time>
</p>
<p><span>
        <svg xmlns="http://www.w3.org/2000/svg" width="512" height="512" viewBox="0 0 32 32" data-svg="timer"><path d="M14.686 16.925c0.021 0.026 0.050 0.048 0.073 0.073 0.294 0.364 0.737 0.602 1.241 0.602 0.883 0 1.599-0.715 1.599-1.599 0-0.47-0.206-0.887-0.527-1.18-0.042-0.047-0.080-0.095-0.142-0.142l-6.463-4.918c-0.188-0.145-0.459-0.152-0.656 0-0.235 0.181-0.279 0.519-0.098 0.754l4.972 6.41z"></path><path d="M16 2.673c-0.175 0-0.346 0.020-0.519 0.026v0.553h-0.015v5.816h1.066v-5.302c6.514 0.282 11.729 5.653 11.729 12.234 0 6.761-5.5 12.261-12.262 12.261s-12.262-5.5-12.262-12.261c0-3.381 1.375-6.446 3.596-8.666l-0.758-0.758c-2.413 2.411-3.905 5.744-3.905 9.424 0 7.361 5.966 13.327 13.328 13.327s13.328-5.966 13.328-13.327c0-7.361-5.966-13.327-13.328-13.327z"></path></svg>    </span>
    <span>
        2 minutes    </span>
</p>
</div>
<div x-show="isOpen" x-collapse="" x-bind:aria-hidden="!isOpen" x-data="articleTranslations()" x-bind:class="isOpen &amp;&amp; '--is-open'">
        <ul>
                            <li>
                    <div>
    <p>
        Deutsch    </p>
    
    <p><span>
            Stadtzürcher Stimmvolk verbietet benzinbetriebene Laubbläser        </span>
                <span>
            Original        </span>
            </p>
    </div>
                </li>
                            <li>
                    <div>
    <p>
        Español    </p>
    
    <p><span>
            Zúrich prohíbe el uso de sopladores de hojas secas, por el ruido que provocan        </span>
            </p>
    </div>
                </li>
                            <li>
                    <div>
    <p>
        日本語    </p>
    
    <p><span>
            チューリヒの有権者、落ち葉掃除「ブロワー」を禁止        </span>
            </p>
    </div>
                </li>
                    </ul>
    </div>





<p><a href="https://www.swissinfo.ch/eng/latest-news/"><em><strong>+Get the most important news from Switzerland in your inbox</strong></em></a></p>



<p>There is also a new restriction for battery-powered models. They may only be used from October to December. Use in other months is only permitted in exceptional cases, for example for street cleaning after the Street Parade.</p>



<p><a href="https://www.swissinfo.ch/eng/swiss-democracy/blown-out-of-proportion-zurich-votes-on-how-to-deal-with-fallen-leaves/89898017"><strong>+ Has Swiss democracy become decadent with vote on leaf blowers?</strong></a></p>



<p>These new restrictions apply to both private individuals and municipal employees. Some 75,248 of voters were in favour of the necessary partial revision of the police ordinance, while 46,717 rejected the leaf blower ban. The turnout was 52.8%.</p>



<h2 id="h-years-of-fighting">Years of fighting </h2>



<p>This referendum came about after a group of parliamentary parties launched a referendum to challenge the city parliament’s decision to ban leaf blowers. They argued that the ban was an “expression of a culture of prohibition”.</p>



<p>The fight against leaf blowers has been going on in Zurich for a long time. Back in 2013, the Greens submitted a petition with 4,329 signatures. The initiative that led to the current ban was submitted by the Greens and Social Democrats in 2022.</p>


<p>
    More</p>
<article x-preview-notice.detailed="">
    <figure>
                <picture>
    <source srcset="https://www.swissinfo.ch/content/wp-content/uploads/sites/13/2025/09/dancers.jpg?crop=0px,1px,1300px,865px&amp;w=580&amp;ver=3409e5e8" width="580" height="386" media="(max-width: 599.98px)">
<source srcset="https://www.swissinfo.ch/content/wp-content/uploads/sites/13/2025/09/dancers.jpg?crop=0px,2px,1300px,864px&amp;w=280&amp;ver=3409e5e8" width="280" height="186" media="(min-width: 600px)">
    <img src="https://www.swissinfo.ch/content/wp-content/uploads/sites/13/2025/09/dancers.jpg?ver=3409e5e8" width="1300" height="867" alt="Dancers" loading="lazy" decoding="async" fetchpriority="auto">
</picture>
</figure>
    <h2>
        More    </h2>
            <p><span>
        Swiss democracy    </span>
        </p>
        <h3>
        Religious holiday ‘dance ban’ lifted by Swiss canton    </h3>
    <p>
        <span>
                            <span>
                    <span>
                        This content was published on                    </span>
                    <time datetime="2025-09-28T15:49:49+02:00">
                        Sep 28, 2025                    </time>
                </span>
                        <span x-truncator="">
                Dancing and sport are now permitted on key religious dates in the Swiss canton of Thurgau.            </span>
        </span>
    </p>
    <a href="https://www.swissinfo.ch/eng/swiss-democracy/religious-holiday-dance-ban-lifted-by-swiss-canton/90081425" target="_self" rel="">
        <span>
            Read more: Religious holiday ‘dance ban’ lifted by Swiss canton        </span>
    </a>
</article>



<p><em>Translated from German with DeepL/</em>mga</p>


<div x-show="isOpen" x-collapse="" x-bind:aria-hidden="!isOpen" aria-label="Infobox" x-bind:class="isOpen &amp;&amp; '--is-open'" x-data="infobox({isOpen: false})">
        

<p>We select the most relevant news for an international audience and use automatic translation tools to translate them into English. A journalist then reviews the translation for clarity and accuracy before publication.&nbsp;&nbsp;</p>



<p>Providing you with automatically translated news gives us the time to write more in-depth articles. The news stories we select have been written and carefully fact-checked by an external editorial team from news agencies such as Bloomberg or Keystone.</p>



<p>If you have any questions about how we work, write to us at&nbsp;<a href="mailto:english@swissinfo.ch">english@swissinfo.ch</a>.</p>

    </div>





<nav aria-labelledby="links-list-title-2">
    <h2 id="links-list-title-2">
        Articles in this story    </h2>
    <ul>
                    <li>
                
            </li>
            </ul>
</nav>

<h2>
    <a href="https://www.swissinfo.ch/eng/latest-news/?utm_source=multiple&amp;utm_medium=website&amp;utm_campaign=news_en&amp;utm_content=o&amp;utm_term=wpblock_news">
        News    </a>
</h2>





                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Battering RAM – Low-Cost Interposer Attacks on Confidential Computing (123 pts)]]></title>
            <link>https://batteringram.eu/</link>
            <guid>45488713</guid>
            <pubDate>Mon, 06 Oct 2025 07:47:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://batteringram.eu/">https://batteringram.eu/</a>, See on <a href="https://news.ycombinator.com/item?id=45488713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
      <!-- #### A Low-Cost Runtime DDR4 Interposer -->

<p><em>
Modern computers use <a href="https://en.wikipedia.org/wiki/Computer_memory">memory</a> modules (<abbr title="Dynamic Random Access Memory">DRAM</abbr>) to store everything in use: from photos and passwords to credit card numbers.
Public cloud providers increasingly deploy hardware-level memory encryption to protect this sensitive data.
However, we previously showed that malicious memory modules, nicknamed <a href="https://badram.eu/">“Bad RAM”</a>, can bypass these protections by deliberately supplying false metadata during processor boot.
In response, <span>modern cloud systems now validate memory more strictly at startup.</span>
</em></p>

<h4 id="breaking-memory-encryption-with-two-faced-dram">Breaking Memory Encryption with Two-Faced DRAM</h4>

<div>
  <!-- Icon -->
  <p><img src="https://batteringram.eu/assets/images/angel-demon.svg" alt="Memory Icon">
  </p>
  <!-- Text Content -->
  <p>
    With <em>Battering RAM</em>, we show that <span>even the latest defenses on Intel and AMD cloud processors can be bypassed.</span>
    We built a simple, $50 interposer that sits quietly in the memory path, behaving transparently during startup and passing all trust checks.
    Later, with just a flip of a switch, our interposer turns malicious and silently redirects protected addresses to attacker-controlled locations, allowing corruption or replay of encrypted memory.
  </p>
</div>

<p>Battering RAM fully breaks cutting-edge <a href="https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/software-guard-extensions.html">Intel <abbr title="Software Guard Extensions">SGX</abbr></a> and <a href="https://www.amd.com/en/developer/sev.html"> AMD <abbr title="Secure Encrypted Virtualization — Secure Nested Paging">SEV-SNP</abbr></a> <span>confidential computing processor security technologies</span> designed to protect sensitive workloads from compromised hosts, malicious cloud providers, or rogue employees.
Our stealthy interposer bypasses both memory encryption and state-of-the-art boot-time defenses, invisible to the operating system.
It enables arbitrary plaintext access to SGX-protected memory, and breaks SEV’s attestation feature on fully patched systems.
Ultimately, <span>Battering RAM exposes the limits of today’s scalable memory encryption.</span>
Intel and AMD have acknowledged our findings, but defending against Battering RAM would require a fundamental redesign of memory encryption itself.</p>

<h4 id="building-battering-ram-on-a-50-budget">Building Battering RAM on a $50 Budget</h4>

<p><img src="https://batteringram.eu/assets/images/ddr4-interposer.jpg">
</p>

<p>Unlike commercial passive interposers, which are exceedingly expensive and commonly cost over $100,000, we developed a <span>custom-built interposer</span> that uses simple analog switches to actively manipulate signals between the processor and memory, and can be built for <span>less than $50.</span></p>

<p>All schematics and board files for our custom interposer are available as <span>open source</span> in our <a href="https://github.com/batteringramattack/batteringram">GitHub repository</a>.
The PCB is a standard 4-layer design and can be fabricated at any major PCB fabricator such as <a href="https://jlcpcb.com/">JLCPCB</a>, <a href="https://www.pcbway.com/">PCBWay</a>, or <a href="https://www.eurocircuits.com/">Eurocircuits</a>.</p>

<p><a data-bs-toggle="collapse" href="#bom" role="button" aria-expanded="false" aria-controls="bom"><i></i> Detailed bill of materials </a></p>

<div id="bom">
<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Part Number</th>
      <th>Cost</th>
      <th>Qty.</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>PCB</td>
      <td>Custom</td>
      <td>$18.49</td>
      <td>1</td>
    </tr>
    <tr>
      <td>DDR4 Connector</td>
      <td>CONN-DDR4-288-SM</td>
      <td>$16.00</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Microcontroller</td>
      <td><a href="https://eu.mouser.com/ProductDetail/Raspberry-Pi/SC0915?qs=T%252BzbugeAwjgnLi4azxXVFA%3D%3D">Raspberry Pi Pico 1/2</a></td>
      <td>$4.00</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Switches</td>
      <td><a href="https://eu.mouser.com/ProductDetail/Analog-Devices/ADG902BRMZ?qs=BpaRKvA4VqGOESsiE6jGWw%3D%3D">ADG902BRMZ</a></td>
      <td>$4.04</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Voltage regulator</td>
      <td><a href="https://eu.mouser.com/ProductDetail/STMicroelectronics/LD1117S25TR?qs=uWoDHEC%252Bq2%2FKaE8ZseXscw%3D%3D">LD1117S25TR</a></td>
      <td>$0.61</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Resistor</td>
      <td>0402, 1kOhm</td>
      <td>&lt;$0.01</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Capacitor</td>
      <td>0603, 100nF</td>
      <td>$0.02</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Capacitor</td>
      <td>1206, 10μF</td>
      <td>$0.18</td>
      <td>1</td>
    </tr>
    <tr>
      <td colspan="2"><span>Total</span></td>
      <td colspan="2"><span>$47.62</span></td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="battering-ram-in-action">Battering RAM in Action</h4>

<div id="carouselExample" data-ride="carousel">
    <div>
<p>
    <h5>
        <a data-bs-target="#carouselExample" data-bs-slide="prev" role="button">
            <i></i>
        </a>
        <span>Attack 1/2: RAMming Intel SGX: Plaintext Access in 5 Steps</span>
        <a data-bs-target="#carouselExample" data-bs-slide="next" role="button">
            <i></i>
        </a>
    </h5>
</p>
<p>
The single-key domain of Intel <abbr title="Total Memory Encryption">TME</abbr> technology, used in Intel Scalable SGX, enables arbitrary plaintext access through the interposer-induced aliases.
With TME, the <span>memory encryption depends only on the secret key and the physical address being accessed.</span>
By capturing victim ciphertext and replaying the captured contents into its own enclaves, the attacker gains read access to the victim plaintext.
Similarly, the attacker can also write arbitrary plaintext into victim enclaves.
</p>

<p><a><i></i></a>
  <span>Step <span></span>/<span></span></span>
  <a><i></i></a>
</p>

<div>
    <!--<h4>BadRAM in 3 Simple Steps</h4>-->
     <ol>
      <li><b>Install interposer</b>
        <p>
          Place the interposer between CPU and DIMM.
        </p>
      </li>
      <li><b>Allocate aliasing buffer</b>
        <p>
          Allocate the attacker page to alias with the victim location and enable the interposer.
        </p>
      </li>
      <li><b>Capture ciphertext</b>
        <p>
          Capture the victim ciphertext by reading the aliased attacker buffer. Now disable the interposer.
        </p>
      </li>
      <li><b>Allocate second attacker enclave</b>
        <p>
          Evict the victim enclave and allocate a second, attacker-controlled enclave at the same physical address as the victim. Re-enable the interposer.
        </p>
      </li>
      <li><b>Replay ciphertext</b>
        <p>
          Replay the previously captured ciphertext via the interposer, yielding the victim's decrypted plaintext.
        </p>
      </li>
    </ol> 
  </div>
    </div>
    <div>
<p>
    <h5>
        <a data-bs-target="#carouselExample" data-bs-slide="prev" role="button">
            <i></i>
        </a>
        Attack 2/2: Battering Through AMD SEV-SNP Attestation
        <a data-bs-target="#carouselExample" data-bs-slide="next" role="button">
            <i></i>
        </a>
    </h5>
</p>
<p>
To ensure the integrity of launched VMs, AMD SEV's <abbr title="Secure Processor">SP</abbr> takes a measurement of the initial memory contents and matches the hash with the expected value provided by the customer.
With Battering RAM, we can capture and replay launch measurements, compromising SEV's attestation.
This allows an attacker to introduce <span>arbitrary backdoors into the VM</span>, without detection.
</p>
<p>
This vulnerability was first introduced by <a href="https://badram.eu/">BadRAM</a> and later <a href="https://www.amd.com/en/resources/product-security/bulletin/amd-sb-3015.html">patched by AMD</a> by introducing boot-time alias checks.
Battering RAM's dynamic memory aliases bypass these checks, re-enabling this vulnerability.
</p>

<p><a><i></i></a>
  <span>Step <span></span>/<span></span></span>
  <a><i></i></a>
</p>

<div>
     <ol>
      <li><b>Install interposer</b>
        <p>
          Place the interposer between CPU and memory.
        </p>
      </li>
      <li><b>Launch genuine VM image</b>
        <p>
          Start the genuine VM image <em>A</em>. The <em>AMD Secure Processor (SP)</em> measures a launch digest <code>hash(A)</code>, used during attestation.
        </p>
      </li>
      <li><b>Allocate aliasing buffer and capture ciphertext</b>
        <p>
          Allocate an aliasing buffer and enable the interposer to capture the launch digest ciphertext.
        </p>
      </li>
      <li><b>Launch backdoored VM image</b>
        <p>
          Launch a second, modified VM image <code>B</code> at the physical location of the original VM. The <abbr title="Secure Processor">SP</abbr> now measures a <em>different</em> launch digest <code>hash(B)</code>.
        </p>
      </li>
      <li><b>Replay ciphertext</b>
        <p>
          Replay the previously captured ciphertext <code>hash(A)</code>, making <abbr title="Secure Processor">SP</abbr> attest the modified VM as genuine.
        </p>
      </li>
    </ol> 
  </div>
    </div>
  </div>

<h3 id="questions-and-answers">Questions and Answers</h3>

<div id="accordionExample">
  

  <div id="collapseSeven" data-bs-parent="#accordionExample">
        <p>
        Battering RAM can affect all systems using DDR4 memory, but is especially relevant for <span><a href="https://en.wikipedia.org/wiki/Confidential_computing">"confidential computing"</a> workloads running in public cloud environments.</span>
        </p>
        <p>
        Modern Intel and AMD x86 cloud processors feature built-in access control and memory encryption to keep private data safe, even from the company running the cloud.
        However, our research shows that these guarantees can be bypassed with a low-cost memory interposer, allowing a rogue cloud infrastructure provider or insider with limited physical access to compromise protected workloads.
        </p>
      </div>

  <div id="collapseFive" data-bs-parent="#accordionExample">
        <p>
        <a href="https://en.wikipedia.org/wiki/Confidential_computing">Confidential computing</a> aims to protect private data even from the cloud provider, using hardware-level access control and memory encryption.
        Even if someone accesses the memory, they should only see encrypted (garbled) data.
        Battering RAM uses a low-cost, custom-built memory interposer installed between the processor and memory to tamper with such encrypted memory.
        It requires only <span>brief one-time physical access, which is realistic in cloud environments,</span> considering, for instance:
        </p>
        <ul>
          <li>Rogue cloud employees;</li>
          <li>Datacenter technicians or cleaning personnel;</li>
          <li>Coercive local law enforcement agencies;</li>
          <li>Supply chain tampering during shipping or manufacturing of the memory modules.</li>
        </ul>
      </div>

  <div id="collapseFifty" data-bs-parent="#accordionExample">
      <p>
       Intel <abbr title="Software Guard Extensions">SGX</abbr> and AMD <abbr title="Secure Encrypted Virtualization - Secure Nested Paging">SEV-SNP</abbr> are two leading hardware-based <a href="https://en.wikipedia.org/wiki/Trusted_execution_environment">trusted execution environments</a> that enable secure cloud computations without needing to trust the cloud provider.
       They do this by enforcing strict access control and encrypting memory so that even if someone accesses it, they only see unreadable data.
      </p>
      <p>
       AMD SEV and Intel SGX are widely offered by major cloud providers like like <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sev-snp.html">Amazon AWS</a>, <a href="https://cloud.google.com/blog/products/identity-security/rsa-snp-vm-more-confidential">Google Cloud</a>, <a href="https://learn.microsoft.com/en-us/azure/confidential-computing/confidential-vm-overview">Microsoft Azure</a>, and <a href="https://research.ibm.com/blog/amd-sev-ibm-hybrid-cloud">IBM cloud</a>.
       They also power privacy features in real-world applications like <a href="https://signal.org/blog/private-contact-discovery/">Signal</a>, <a href="https://engineering.fb.com/2025/04/29/security/whatsapp-private-processing-ai-tools/">WhatsApp</a>, and <a href="https://www.biometricupdate.com/202409/google-launches-synched-passkeys-as-tech-giants-move-away-from-passwords">Chrome</a>, and are used in sectors like <a href="https://www.intel.com/content/www/us/en/content-details/826053/maximum-security-at-the-processor-level-intel-sgx-protects-electronic-patient-record.html">healthcare</a> to protect sensitive data.
      </p>
      </div>

  <div id="collapseEighteen" data-bs-parent="#accordionExample">
      <p>
        The main difficulty lies in setting up the system; installing the interposer, and mapping out unstable memory regions (see details in the <a href="https://batteringram.eu/batteringram.pdf">academic paper</a>).
        However, <span>once installed, the interposer is simple and stable to operate and can be built at low cost ($50).</span>
        Unlike traditional hardware attacks that rely on unstable glitches, Battering RAM avoids unpredictable microarchitectural behavior and instead leverages stable, completely deterministic address aliasing effects, posing a significant and previously underestimated threat to modern memory encryption schemes.
      </p>
    </div>

  <div id="collapsebadram" data-bs-parent="#accordionExample">
      <p>
      No. Battering RAM uses a custom-built memory interposer that sits silently between the processor and memory.
      Our interposer can be <span>dynamically enabled or disabled at runtime and remains invisible during system startup,</span> passing all trust checks, such as those introduced for <a href="https://badram.eu/">BadRAM</a>.
      The interposer silently alters memory commands without detection, making the attack undetectable and unpatchable via software or firmware.
      </p>
    </div>

  <div id="collapseFour" data-bs-parent="#accordionExample">
          <p>
          No. While Intel Scalable SGX and AMD SEV-SNP use memory encryption to protect data stored in DRAM, this encryption is <em>static</em>: the same plaintext at the same physical address always maps to the same ciphertext. 
          This defends against passive attacks, such as <a href="https://en.wikipedia.org/wiki/Cold_boot_attack">cold boot attacks</a>, but not against Battering RAM, which can actively corrupt or replay memory contents.
          Because the encryption is static, replayed data decrypts to the original value, allowing stale data to be reused.
        </p>
        <p>
          Furthermore, Intel's memory encryption engine for DDR4 systems, <abbr title="Total Memory Encryption">TME</abbr>, relies on a single key for the entire memory range.
          This means encryption is static, not only per address, but also shared across both attacker and victim.
          By replaying and capturing ciphertexts from attacker-controlled pages, the attacker can recover and inject arbitrary plaintext within the victim’s memory.
        </p>
        <p>
         Hence, <span>Battering RAM exposes the fundamental limits of the <em>scalable</em> memory encryption designs currently used by Intel and AMD,</span> which omit cryptographic freshness checks in favor of larger protected memory sizes. 
        </p>
      </div>

  <div id="collapseTen" data-bs-parent="#accordionExample">
        <p>
          <a href="https://badram.eu/">BadRAM</a> similarly exploited physical address aliasing to modify and replay encrypted memory on AMD SEV-SNP systems.
          However, BadRAM relied on modifying the <a href="https://en.wikipedia.org/wiki/Serial_presence_detect"><abbr title="Serial Presence Detect">SPD</abbr> chip</a> on the DIMM to report a false memory size at boot time, introducing static ghost address lines.
          In response, Intel and AMD added boot-time checks to detect and block such <em>static</em> aliases.
        </p>
        <p>
          Battering RAM, on the other hand, is capable of introducing memory aliases <em>dynamically at runtime</em>.
          As a result, Battering RAM can circumvent Intel's and AMD's boot-time alias checks.
        </p>
      </div>

  <div id="collapseEight" data-bs-parent="#accordionExample">
      <p>
      Concurrent to our work on Battering RAM, an independent research team developed the <a href="https://wiretap.fail/"><em>WireTap</em> attack,</a> which uses a commercial DDR4 DRAM interposer to break Intel Scalable SGX. Both Battering RAM and WireTap stem from a similar attack vector, but the approaches and findings are distinct.
      </p>
      <p>
      The key differences between these two attacks are:
      </p>
      <ul>
        <li>
        <span>Cost:</span> commercial DRAM interposers require specialized, high-speed signal analyzers (typically retailing at &gt;$150,000), whereas our custom-built interposer requires only two simple analog switches and some control logic, totalling about $50.
        Battering RAM, therefore, shows that <em>physical attacks are practical and not limited to resourceful adversaries with a large budget.</em>
        </li>
        <li>
        <span>Technique:</span>
        Battering RAM and WireTap exploit distinct techniques: memory aliasing vs. ciphertext side-channel analysis.
        Commercial DRAM interposers <em>passively</em> capture memory traffic, requiring additional <a href="https://cipherleaks.com/">ciphertext side-channel inference</a> to recover secrets.
        In contrast, Battering RAM uses a custom-built interposer that <em>actively</em> redirects address lines to introduce aliases, allowing not just observation but also replay and corruption of ciphertext and culminating in plaintext read/write access on Scalable SGX.
        </li>
        <li>
        <span>Target:</span>
        Both Battering RAM and WireTap expose the security limitations of current, scalable memory encryption technologies.
        Battering RAM breaks remote attestation for both Intel Scalable SGX and AMD SEV-SNP, whereas WireTap was only demonstrated on Intel Scalable SGX but may affect AMD DDR4 systems similarly.
        </li>
      </ul> 
      </div>

  <div id="collapseThree" data-bs-parent="#accordionExample">
    <p>
    We found that our interposer can compromise the security of two widely-deployed <abbr title="Trusted Execution Environments">TEEs</abbr>, 
    <a href="https://en.wikipedia.org/wiki/Software_Guard_Extensions">
      Intel Scalable <abbr title="Software Guard Extensions">SGX</abbr>
    </a> and  
    <a href="https://www.amd.com/en/developer/sev.html">
      AMD <abbr title="Secure Encrypted Virtualization - Secure Nested Paging">SEV-SNP</abbr>.
    </a>
    Both of these technologies employ a memory encryption scheme that is vulnerable to memory replay attacks.
    Furthermore, Scalable SGX on DDR4 platforms only employs a single memory encryption key for the entire physical memory space.
    We show this limitation can be exploited to create an arbitrary plaintext primitive.
    This severely undermines the protections in the presence of a physical adversary.
    </p>
    <p>
    On top of that, our interposer re-enables the previously-mitigated 
    <a href="https://badram.eu/">
      BadRAM
    </a>
    attacks.
    To combat this threat, AMD rolled out firmware-level mitigations that scan for aliases at boot time.
    As the interposer can enable and disable the interposer <i>at runtime</i>, these checks are easily bypassed.
    As a result, Battering RAM re-enables previous attacks on
    <a href="https://www.amd.com/en/developer/sev.html">
      AMD <abbr title="Secure Encrypted Virtualization - Secure Nested Paging">SEV-SNP</abbr>
    </a>
    and
    <a href="https://en.wikipedia.org/wiki/Software_Guard_Extensions">
      Intel Client <abbr title="Software Guard Extensions">SGX</abbr>
    </a>.
    </p>
    <p>
        Arm has also announced a cloud TEE called 
        <a href="https://www.arm.com/architecture/security-features/arm-confidential-compute-architecture">
            <abbr title="Confidential Compute Architecture">CCA</abbr>
        </a>. 
        Based on the specification, DDR4 systems may also be vulnerable to Battering RAM. However, as no hardware is available yet, we were unable to test our interposer on CCA.
    </p>
    <p>
        The table below summarizes our findings across different TEEs. Each column indicates whether we were able to read, write, or replay ciphertexts, and read/write plaintext in protected memory regions.
    </p>
        <div>
        <table>
            <thead>
                <tr>
                    <th>TEE</th>
                    <th>Read</th>
                    <th>Write</th>
                    <th>Replay</th>
                    <th>Plaintext</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Intel Scalable SGX</td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                </tr>
                <tr>
                    <td>AMD SEV-SNP</td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                </tr>
                <tr>
                    <td>Client SGX</td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                </tr>
                <tr>
                    <td>Intel TDX</td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                </tr>
                <tr>
                    <td>Arm CCA</td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                    <td><i></i></td>
                </tr>
            </tbody>
        </table>
        </div>
      </div>

  <div id="collapseThirteen" data-bs-parent="#accordionExample">
        <p>
          No, our interposer only works on DDR4, which remains widely deployed today; e.g., <a href="https://www.industryresearch.biz/market-reports/memory-module-market-101411">a recent market study</a> indicates that DDR4 still accounted for around 65% of sold DRAM modules in 2024.
        </p>
        <p>
          DDR5 reorganizes the command/address bus, which removes the possibility of adding simple switches to the address lines.
          However, the underlying issue is not fixed, as current memory encryption engines still do not provide freshness guarantees.
          A determined attacker could theoretically still design more advanced interposers to perform similar attacks on DDR5.
        </p>
      </div>

  <div id="bom" data-bs-parent="#accordionExample">
      <p>
          Yes, <a href="https://github.com/batteringramattack/batteringram">our GitHub repository</a> contains the hardware schematics and board files for the custom DDR4 interposer, firmware for the microcontroller, and proof-of-concept code for all attacks described in our paper.
          The interposer can be built for under $50, and the bill of materials is listed <a href="#building-battering-ram-on-a-50-budget">above</a>.
        </p>
    </div>

  <div id="collapseNineteen" data-bs-parent="#accordionExample">
        <p>
          We disclosed our findings to both Intel and AMD in February 2025.
          Both vendors have acknowledged our findings, but noted that physical attacks on DRAM are out of scope for their current products.
          <!-- As part of the responsible disclosure process, we have worked with Intel to revoke the secret provisioning keys which were extracted during our evaluation. -->
          To better reflect this position, Intel deposited the whitepaper on Scalable SGX, previously removed from the <a href="https://web.archive.org/web/20220822150148/https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/supporting-intel-sgx-on-mulit-socket-platforms.pdf">Intel website</a>, permanently on <a href="https://www.arxiv.org/pdf/2507.08190">arXiv</a>.
        </p>
        <p>
          Following an embargo period until September 30, 2025, both vendors have issued a public security advisory: 
          <a href="https://www.intel.com/content/www/us/en/developer/articles/news/more-information-encrypted-memory-frameworks.html">Intel advisory</a> | <a href="https://www.amd.com/en/resources/product-security/bulletin/amd-sb-3024.html">AMD advisory</a>
        </p>
      </div>

  <div id="collapseFiftyFive" data-bs-parent="#accordionExample">
        <ol>
          <li>
            <span>Confidential computing is here, but is not invincible.</span>
            <p>
              Despite strong adoption by major CPU vendors and cloud providers, current technologies have critical physical-layer limitations that remain underexamined.
            </p>
          </li>
          <li>
            <span>Reevaluate your threat models.</span>
            <p> 
              Encrypted memory is not inherently secure against physical tampering, and firmware-based mitigations alone are insufficient in threat scenarios involving limited physical access, such as malicious insiders or supply-chain compromises.
            </p>
          </li>
          <li>
            <span>Advanced physical attacks are accessible at low cost.</span>
            <p>
              Our open-source $50 custom device costs only a fraction of commercial DRAM interposers (upwards of $100,000) and is capable of breaking multi-million-dollar cloud security technologies from Intel and AMD.
            </p>
          </li>
        </ol> 
      </div>

  <div id="collapseSeventeen" data-bs-parent="#accordionExample">
        <p>
        The logo is free to use, rights waived via <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a>. 
        </p>
        
      </div>

  

</div>


      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flightcontrol: AWS PaaS (155 pts)]]></title>
            <link>https://www.flightcontrol.dev/</link>
            <guid>45488441</guid>
            <pubDate>Mon, 06 Oct 2025 07:07:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flightcontrol.dev/">https://www.flightcontrol.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=45488441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><div><h2>Build your dreams<br>on AWS, effortlessly</h2><div><ul><li>Flightcontrol is a PaaS that deploys to your AWS account</li><li>Servers, Lambdas, workers, crons, static sites, databases &amp; Redis</li><li>We are your devops team with 24/7 emergency support</li><li>Companies outgrowing other PaaS or homegrown AWS switch to Flightcontrol to regain reliability, security, and scalability at a reasonable cost</li></ul></div></div><p><a href="https://app.flightcontrol.dev/signup"><span><span></span><span></span><span></span><span></span></span>Start free trial<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" stroke="currentColor" stroke-width="1.7" viewBox="0 0 10 10"><g><path d="m4.5.6 4.25 4.25L4.5 9.1M9 4.85H0"></path><path d="m4.5.6 4.25 4.25L4.5 9.1M9 4.85H0"></path></g></svg></a><a href="https://www.flightcontrol.dev/demo"><span><span></span><span></span><span></span><span></span></span>Get a demo<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" stroke="currentColor" stroke-width="1.7" viewBox="0 0 10 10"><g><path d="m4.5.6 4.25 4.25L4.5 9.1M9 4.85H0"></path><path d="m4.5.6 4.25 4.25L4.5 9.1M9 4.85H0"></path></g></svg></a></p></div><div><p><img alt="Flightcontrol Dashboard" loading="lazy" width="949.5" height="824.5" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=%2FheroImage.png&amp;w=1080&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=%2FheroImage.png&amp;w=1920&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=%2FheroImage.png&amp;w=1920&amp;q=75"></p></div></div><div><div><h2>The old way<!-- --> <a id="the-old-way"></a><a href="#the-old-way"></a></h2><p><em>"Our AWS setup is consuming too much time &amp; attention"</em></p><p>Your team gets bogged down with complex Terraform scripts, manual configuration, and endless CI/CD pipelines. <strong>You could hire DevOps engineers, but they are expensive and it's hard to find really good ones. </strong>It will do the job, but now your developer productivity suffers as they are dependent on the infra team to make changes or spin up new services.</p></div><div><h2>The new way<!-- --> <a id="the-new-way"></a><a href="#the-new-way"></a></h2><p><em>"Flightcontrol gives our team the power to manage bare metal AWS without needing to hire specific talent"</em></p><p><strong>Save thousands of dollars and months of time</strong> because Flightcontrol significantly reduces DevOps overhead. It empowers your developers ship like crazy without needing AWS or infrastructure expertise. Your developers gain full autonomy while benefiting from AWS's unmatched scalability, reliability, and flexibility.</p></div></div><div><h2>Simple, powerful deployments without worrying about low level AWS config<!-- --> <a id="simple-powerful-deployments-without-worrying-about-low-level-aws-config"></a><a href="#simple-powerful-deployments-without-worrying-about-low-level-aws-config"></a></h2><p>We take <strong>the best AWS services</strong>, put together <strong>a best-in-class setup</strong>, and make them <strong>super easy to use</strong>.</p><ol><li><p><strong>Connect your AWS account</strong> to Flightcontrol</p></li><li><p><strong>Connect your git repository</strong> to Flightcontrol</p></li><li><p><strong>Define your services</strong> (servers, APIs, databases, etc)</p></li><li><p><strong>Flightcontrol fully automates infrastructure provisioning, CI/CD, and deployments</strong>. All within your own AWS account where you retain full visibility and control</p></li></ol><p>Flightcontrol simplifies your deployments by providing a <strong>user-friendly dashboard designed specifically for developers</strong>, not DevOps engineers. Forget the frustration of navigating AWS’s overwhelming and fragmented console. With Flightcontrol, you see your entire infrastructure clearly in one intuitive interface, allowing you to manage deployments, services, and scaling with confidence.</p><p>Deployments become as easy as a simple git push or webhook integration. Flightcontrol handles your CI/CD automation entirely, enabling your team to deploy confidently and quickly without maintaining complex Terraform or CDK scripts. <strong>You get the simplicity of platforms like Vercel or Heroku, paired with the raw power, near perfect reliability, and immense flexibility of AWS. </strong>Your developers can ship faster and stay focused on building great products.</p></div><div><svg viewBox="0 0 1441 38.5"><path fill="none" stroke="#e8e8e9" vector-effect="non-scaling-stroke" d="M1440.5 38.5V23.16C879.61-6.22 564.31-7.88.5 23.16V38.5"></path></svg><div><div><blockquote>“Flightcontrol offers a nice balance between batteries-included and escape hatches that I haven't seen elsewhere. Keep up the good work and let us know if you need anything!”</blockquote></div><div><blockquote>The Flightcontrol team allowed us to keep the seamless development experience of Vercel, but with the costs, control and flexibility of AWS. Not only their platform is great, the team went the extra mile to support us, no matter the day or time of day!</blockquote></div><div><blockquote>We've been migrating our Rails app off of Heroku and onto AWS via Flightcontrol. The team is AWESOME and have built an excellent product. So good. ⭐⭐⭐⭐⭐</blockquote></div><div><blockquote>Nothing else compares for balance between control, flexibility and simplicity. A perfect fit for us. For our multiple locale deployments, 3-5 million monthly page views, use case, the Flightcontrol team were incredibly helpful in getting us setup + ensuring we understood what we had. 10/10</blockquote></div><div><blockquote>Without FlightControl it would simply not have been possible for our company to begin the migration process to AWS. They simplify so much of the AWS experience which allows primarily frontend developers such as myself to focus more on code and less on infrastructure.</blockquote></div></div><svg width="260" height="3" viewBox="0 0 260 3" fill="none"><path d="M259.5 1.44922C166.36 1.35159 93.14 1.54677 -7.44844e-09 1.44914" stroke="#E8E8E9" stroke-width="2"></path><rect y="0.454102" width="88" height="2" fill="#19191A"></rect></svg></div><div><p><h2>Serve all your use-cases from a single platform</h2></p><div><div><ul><li>CloudFront CDN</li><li>S3</li><li>Lambda@Edget</li></ul></div><div><ul><li>CloudFront CDN</li><li>ECS</li><li>Fargate or EC2</li></ul></div><div><ul><li>ECS</li><li>Fargate or EC2</li></ul></div><div><ul><li>ECS</li><li>Fargate or EC2</li></ul></div><div><ul><li>ECS</li><li>Fargate or EC2</li></ul></div><div><ul><li>Lambda</li></ul></div><div><ul><li>RDS</li></ul></div><div><ul><li>ElastiCache</li></ul></div><div><ul><li>S3</li></ul></div></div></div><div><h2>Significantly reduce your DevOps overhead<!-- --> <a id="significantly-reduce-your-devops-overhead"></a><a href="#significantly-reduce-your-devops-overhead"></a></h2><p>Flightcontrol becomes your devops team. <strong>We guarantee support for everything managed through Flightcontro</strong>l. You don't have to worry about anything that's amiss in AWS — let us know and we'll fix it ASAP (but rest assured, this almost never happens!).</p><p><strong>Get 24/7 emergency support</strong> on our Business plan for ultimate peace of mind.</p><p>Need some extra devops support beyond the Flightcontrol platform? <strong>We offer DevOps Support Add-ons to supplement your team</strong>. This is ideal for teams that need extra infrastructure help but don't need a full time devops engineer.</p></div><div><svg viewBox="0 0 1441 38.5"><path fill="none" stroke="#e8e8e9" vector-effect="non-scaling-stroke" d="M1440.5 38.5V23.16C879.61-6.22 564.31-7.88.5 23.16V38.5"></path></svg><div><div><blockquote>I've been using Flightcontrol for a long time, and I've never had a product that's given me better support. They have been so awesome and easy to work with. Being able to deploy things using AWS credits made a lot of things possible for me what weren't on other platforms.</blockquote></div><div><blockquote>We're using Flightcontrol at Productlane and love it. We moved from Fly.io to Railway to Flightcontrol and finally found the right platform for us that works reliably and didn't have random downtime.</blockquote></div><div><blockquote>We're using Flightcontrol at Tono Health and it has completely solved our lack of devops expertise. With the new CI build runners, it also cut our build time in HALF compared to GitHub Actions. We're so happy with Flightcontrol</blockquote></div><div><blockquote>Two large SaaS businesses I’m involved in have all deployed on Flightcontrol for years, and have had no issues. Infra devops cut down to zero! Deploying and scaling infra has been a dream. I can’t imagine why anyone in their sane mind not try Flightcontrol</blockquote></div></div><svg width="260" height="3" viewBox="0 0 260 3" fill="none"><path d="M259.5 1.44922C166.36 1.35159 93.14 1.54677 -7.44844e-09 1.44914" stroke="#E8E8E9" stroke-width="2"></path><rect y="0.454102" width="88" height="2" fill="#19191A"></rect></svg></div><h2>Ephemeral preview environments<!-- --> <a id="ephemeral-preview-environments"></a><a href="#ephemeral-preview-environments"></a></h2><p>The fastest moving engineering teams use preview environments to <strong>view changes before committing them.</strong> </p><p>Flightcontrol can automatically spin up temporary infrastructure for each pull request and then clean it up when the pull request is merged.</p><p>Preview environments mean <strong>no more conflicts on staging</strong>, no more delays, and significantly fewer bugs in production. Enable all stakeholders to see and test changes before merging code.</p><div><figure><img alt="preview environment info in github pull request" loading="lazy" width="1886" height="792" decoding="async" data-nimg="1" sizes="(max-width: 1886px) 100vw, 1886px" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=640&amp;q=75 640w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=750&amp;q=75 750w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=828&amp;q=75 828w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=1080&amp;q=75 1080w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=1200&amp;q=75 1200w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=1920&amp;q=75 1920w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=2048&amp;q=75 2048w, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=3840&amp;q=75 3840w" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1741966521-screenshot-2025-03-14-at-11-34-16.png%3Fauto%3Dformat%26fit%3Dmax&amp;w=3840&amp;q=75"></figure></div><p>Each preview environment is <strong>cost-optimized</strong>, intelligently sharing resources such as load balancers and RDS instances, ensuring you maintain control over spending. Database seeding per environment means realistic testing scenarios, catching issues before they go live. <strong>Your team will experience faster releases, fewer bugs, and smoother collaboration.</strong></p><div><h2>World class support with 6 minute median response time<!-- --> <a id="world-class-support-with-6-minute-median-response-time"></a><a href="#world-class-support-with-6-minute-median-response-time"></a></h2><p>Imagine never worrying about infrastructure issues again. Flightcontrol becomes your DevOps team, providing exceptional, responsive support. With guaranteed smooth operations for everything managed by Flightcontrol, you can rest easy knowing your infrastructure is covered by experts around the clock.</p><p>With a median first response time of 6 minutes, our dedicated support team is accessible via email and Slack, ensuring rapid resolution whenever you need it. Need some extra DevOps help? Don’t hire full time! Our DevOps support add-on gives you expert guidance tailored specifically to your unique requirements, removing the need to hire a full-time DevOps engineer.</p></div><div><svg viewBox="0 0 1441 38.5"><path fill="none" stroke="#e8e8e9" vector-effect="non-scaling-stroke" d="M1440.5 38.5V23.16C879.61-6.22 564.31-7.88.5 23.16V38.5"></path></svg><div><div><blockquote>“It's saving so much time and headache for me and my team. Keep up the good work, we love your product!”</blockquote></div><div><blockquote>"Flightcontrol has been a dream, and their level of support has been off the charts. I switched from Lambda to get GPU support and got magnitudes better performance at a fraction of the cost for my AI Video company."</blockquote></div><div><blockquote>“Flightcontrol is excellent devops tooling that would take time and dedicated devops engineers to build at many companies. We're very glad we found Flightcontrol. It's an amazing value for us.”</blockquote></div></div><svg width="260" height="3" viewBox="0 0 260 3" fill="none"><path d="M259.5 1.44922C166.36 1.35159 93.14 1.54677 -7.44844e-09 1.44914" stroke="#E8E8E9" stroke-width="2"></path><rect y="0.454102" width="88" height="2" fill="#19191A"></rect></svg></div><div><div><div><p>Visual Config? Code config? Both!</p><p>Infrastructure-as-code designed for moving fast</p><p><img alt="An interface showing visual config and code config side by side" loading="lazy" width="1930" height="1148" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276422-visual-config-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=2048&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276422-visual-config-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276422-visual-config-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75"></p></div><div><p>Deploy close to your users</p><p>Choose today from 28 AWS regions. Multi-region deploys in early access.</p><p><img alt="A worldmap showing edge locations" loading="lazy" width="1584" height="1016" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276174-world-map-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=1920&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276174-world-map-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276174-world-map-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75"></p></div></div><div><div><div><p>Observability</p><p>Stay on top of things with our metrics and alerts, or add sidecars like Datadog.</p><p><img alt="An interface showing server metrics" loading="lazy" width="998" height="1154" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276186-observability-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=1080&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276186-observability-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=2048&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699276186-observability-min.png%3Ffit%3Dcrop%26q%3D90&amp;w=2048&amp;q=75"></p></div><div><p>Nixpacks</p><p>Build any language or framework without writing a Dockerfile. The modern successor to Heroku buildpacks.</p></div></div><div><div><p>Stale while revalidate + Next.js &amp; Svelte ISR</p><p>Blazing fast speed with CloudFront's stale-while-revalidate support</p></div><div><p>AWS cost transparency</p><p>Understand exactly where the dollars are going by project, environment, and service.</p><p><img alt="An interface showing AWS cost" loading="lazy" width="590" height="582" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1716389048-cost-transparency.png%3Ffit%3Dcrop%26q%3D90&amp;w=640&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1716389048-cost-transparency.png%3Ffit%3Dcrop%26q%3D90&amp;w=1200&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1716389048-cost-transparency.png%3Ffit%3Dcrop%26q%3D90&amp;w=1200&amp;q=75"></p></div></div></div><div><p>Preview environments, fullstack</p><p>Deploy your all your services for every pull request to a cost optimized environment. </p></div><div><div><p>Bring your monoliths and your microservices</p><p>Your architecture will work with us, no matter how big or small.</p></div><div><p>Your domain, with https</p><p>Connect your domain with a couple DNS records. No messing with SSL certificates.</p></div><div><p>Peak edge performance</p><p>World-class performance with CloudFront, Stale-While-Revalidate, and edge-based Next.js ISR. Even multi-region.</p></div><div><p>Monorepos, with watch paths</p><p>Put all your stuff in one place, that's fine with us. And only deploy changed files with watch paths.</p></div><div><p>Maintenance mode</p><p>Block traffic to your app while you're doing something important (we assume).</p></div><div><p>API &amp; deploy hooks</p><p>Trigger deploys from CI. More thorough API is coming, we promise.</p></div><div><p>Notifications</p><p>Get alerted in Slack or email when things go south. Or when they go north.</p></div><div><p>Rollback</p><p>It happens to the best of us, so we've got your back when the inevitable happens.</p></div><div><p>Private VPC networking</p><p>Each environment is deployed to a new or existing VPC. Get private services and private databases.</p></div></div></div><div><h2>Deploy every language globally </h2><p>Every language and framework works beautifully in the Flightcontrol universe. Welcome home.</p></div><div><div><h2>1. Connect your AWS and Git Repo with 1-click</h2><p>Everything is deployed to your AWS account where you have full ownership and control. Without the frustrating limitations of black box PaaS.</p></div><p><img alt="Select a repo, try a demo and connect AWS account" loading="lazy" width="948" height="854" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1706541367-selectrepo.png%3Ffit%3Dcrop%26q%3D90&amp;w=1080&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1706541367-selectrepo.png%3Ffit%3Dcrop%26q%3D90&amp;w=1920&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1706541367-selectrepo.png%3Ffit%3Dcrop%26q%3D90&amp;w=1920&amp;q=75"></p></div><div><div><h2>2. Zero-config or customize to your heart's content</h2><p>It will often "just work", but we also support many customizations like pulling from image registries or fine-tuning autoscaling.</p></div><p><img alt="Set up services, choose from presets" loading="lazy" width="1464" height="1368" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699390862-addservices.png%3Ffit%3Dcrop%26q%3D90&amp;w=1920&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699390862-addservices.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699390862-addservices.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75"></p></div><div><div><h2>3. Automatic deploys with git push or webhook</h2><p>Fully automated infra provisioning, builds and deploys. All without having to use the AWS console.</p></div><p><img alt="See service metrics and deployments" loading="lazy" width="1490" height="1196" decoding="async" data-nimg="1" srcset="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699390892-servicesdeployments.png%3Ffit%3Dcrop%26q%3D90&amp;w=1920&amp;q=75 1x, https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699390892-servicesdeployments.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75 2x" src="https://www.flightcontrol.dev/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F98758%2F1699390892-servicesdeployments.png%3Ffit%3Dcrop%26q%3D90&amp;w=3840&amp;q=75"></p></div><div><div><p>We've got your back with the most helpful, responsive support in the industry</p></div><div><p>Customers of all sizes rely on us for production, from startups to large enterprises</p></div><div><p>We delay the need for infra engineers by a few years. And then we enable them to focus on more meaningful work</p></div></div><div><p><h2>You're moments away from launch</h2></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Structured Procrastination (419 pts)]]></title>
            <link>https://structuredprocrastination.com</link>
            <guid>45488261</guid>
            <pubDate>Mon, 06 Oct 2025 06:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://structuredprocrastination.com">https://structuredprocrastination.com</a>, See on <a href="https://news.ycombinator.com/item?id=45488261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="essay">
	
<div id="picture">		
<p><img src="https://structuredprocrastination.com/grandpa.jpg" alt="The Author Procrastinating"></p><p>Author practices jumping rope with seaweed while work awaits.</p>
</div>
<p id="quotes">``. . . anyone can do any amount of work, provided it isn't the work he is supposed to be doing at that moment."
 -- Robert Benchley,  in Chips off the Old Benchley, 1949
</p>
	  <p>I have been intending to write this essay for months. Why am I finally doing it? Because I finally found some uncommitted time? Wrong. I have papers to grade, textbook orders to fill out, an NSF proposal to referee, dissertation drafts to read. I am working on this essay as a way of not doing all of those things. This is the essence of what I call structured procrastination, an amazing strategy I have discovered that converts procrastinators into effective human beings, respected and admired for all that they can accomplish and the good use they make of time. All procrastinators put off things they have to do. Structured procrastination is the art of making this bad trait work for you. The key idea is that procrastinating does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing; they do marginally useful things, like gardening or sharpening pencils or making a diagram of how they will reorganize their files when they get around to it. Why does the procrastinator do these things? Because they are a way of not doing something more important. If all the procrastinator had left to do was to sharpen some pencils, no force on earth could get him do it. However, the procrastinator can be motivated to do difficult, timely and important tasks, as long as these tasks are a way of not doing something more important.</p>

<p>Structured procrastination means shaping the structure of the tasks one has to do in a way that exploits this fact. The list of tasks one has in mind will be ordered by importance. Tasks that seem most urgent and important are on top. But there are also worthwhile tasks to perform lower down on the list. Doing these tasks becomes a way of not doing the things higher up on the list. With this sort of appropriate task structure, the procrastinator becomes a useful citizen. Indeed, the procrastinator can even acquire, as I have, a reputation for getting a lot done.</p>

<p>The most perfect situation for structured procrastination that I ever had was when my wife and I served as Resident Fellows in Soto House, a Stanford dormitory. In the evening, faced with papers to grade, lectures to prepare, committee work to be done, I would leave our cottage next to the dorm and go over to the lounge and play ping-pong with the residents, or talk over things with them in their rooms, or just sit there and read the paper. I got a reputation for being a terrific Resident Fellow, and one of the rare profs on campus who spent time with undergraduates and got to know them. What a set up: play ping pong as a way of not doing more important things, and get a reputation as Mr. Chips.</p>

<p>Procrastinators often follow exactly the wrong tack. They try to minimize their commitments, assuming that if they have only a few things to do, they will quit procrastinating and get them done. But this goes contrary to the basic nature of the procrastinator and destroys his most important source of motivation. The few tasks on his list will be by definition the most important, and the only way to avoid doing them will be to do nothing. This is a way to become a couch potato, not an effective human being.</p>

<p>At this point you may be asking, "How about the important tasks at the top of the list, that one never does?" Admittedly, there is a potential problem here.</p>

<p>The trick is to pick the right sorts of projects for the top of the list. The ideal sorts of things have two characteristics, First, they seem to have clear deadlines (but really don't). Second, they seem awfully important (but really aren't). Luckily, life abounds with such tasks. In universities the vast majority of tasks fall into this category, and I'm sure the same is true for most other large institutions. Take for example the item right at the top of my list right now. This is finishing an essay for a volume in the philosophy of language. It was supposed to be done eleven months ago. I have accomplished an enormous number of important things as a way of not working on it. A couple of months ago, bothered by guilt, I wrote a letter to the editor saying how sorry I was to be so late and expressing my good intentions to get to work. Writing the letter was, of course, a way of not working on the article. It turned out that I really wasn't much further behind schedule than anyone else. And how important is this article anyway? Not so important that at some point something that seems more important won't come along. Then I'll get to work on it.</p>

<p>Another example is book order forms. I write this in June. In October, I will teach a class on Epistemology. The book order forms are already overdue at the book store. It is easy to take this as an important task with a pressing deadline (for you non-procrastinators, I will observe that deadlines really start to press a week or two after they pass.) I get almost daily reminders from the department secretary, students sometimes ask me what we will be reading, and the unfilled order form sits right in the middle of my desk, right under the wrapping from the sandwich I ate last Wednesday. This task is near the top of my list; it bothers me, and motivates me to do other useful but superficially less important things. But in fact, the book store is plenty busy with forms already filed by non-procrastinators. I can get mine in mid-Summer and things will be fine. I just need to order popular well-known books from efficient publishers. I will accept some other, apparently more important, task sometime between now and, say, August 1st. Then my psyche will feel comfortable about filling out the order forms as a way of not doing this new task.</p>

<p>The observant reader may feel at this point that structured procrastination requires a certain amount of self-deception, since one is in effect constantly perpetrating a pyramid scheme on oneself. Exactly. One needs to be able to recognize and commit oneself to tasks with inflated importance and unreal deadlines, while making oneself feel that they are important and urgent. This is not a problem, because virtually all procrastinators have excellent self-deceptive skills also. And what could be more noble than using one character flaw to offset the bad effects of another?</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gem.coop (393 pts)]]></title>
            <link>https://gem.coop/</link>
            <guid>45487771</guid>
            <pubDate>Mon, 06 Oct 2025 04:59:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gem.coop/">https://gem.coop/</a>, See on <a href="https://news.ycombinator.com/item?id=45487771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3>gem.coop</h3><p>We’re excited to introduce <strong>gem.coop</strong> – a new server for gems in the <a href="https://ruby-lang.org/">Ruby</a> ecosystem.</p><p>We aim for fast, simple hosting, that is compatible with <a href="https://bundler.io/">Bundler</a> but optimized for the next generation. It’s built for the community by the former maintainers and operators of <a href="https://rubygems.org/">RubyGems.org</a>.</p><p>All gems published to <a href="https://rubygems.org/">RubyGems.org</a> are available, updated in real time. Get started right now with a simple change to your <a href="https://bundler.io/guides/gemfile.html">Gemfile</a>:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>-source "https://rubygems.org"
</span></span></span><span><span><span></span><span>+source "https://gem.coop"
</span></span></span></code></pre></div><p>Governance for this project is modeled on <a href="https://brew.sh/">Homebrew</a>, with setup assistance from <a href="https://github.com/MikeMcQuaid">Mike McQuaid</a>, and will be published on or before October 10. Everyone from the Ruby community is welcome to contribute and participate.</p><p>If you want to follow along with our progress, subscribe to the gem.coop newsletter for monthly updates.</p><p>Our goal is to provide fast, community-owned, transparent, sustainable, and secure gem hosting for everyone. We’re launching with support for bundling and installing all public gems, and we’re excited to keep improving.</p><p>— The Gem Cooperative (<a href="https://github.com/deivid-rodriguez">@deivid-rodriguez</a>, <a href="https://github.com/duckinator">@duckinator</a>, <a href="https://github.com/indirect">@indirect</a>, <a href="https://github.com/martinemde">@martinemde</a>, <a href="https://github.com/segiddins">@segiddins</a>, <a href="https://github.com/simi">@simi</a>)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1 Trillion Web Pages Archived (591 pts)]]></title>
            <link>https://blog.archive.org/trillion/</link>
            <guid>45487476</guid>
            <pubDate>Mon, 06 Oct 2025 03:48:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.archive.org/trillion/">https://blog.archive.org/trillion/</a>, See on <a href="https://news.ycombinator.com/item?id=45487476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<figure><a href="https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO.png"><img fetchpriority="high" decoding="async" width="1024" height="576" src="https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-1024x576.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-1024x576.png 1024w, https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-300x169.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-768x432.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-1536x864.png 1536w, https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-2048x1152.png 2048w, https://blog.archive.org/wp-content/uploads/2025/08/1T_HERO_UPDATED_LOGO-624x351.png 624w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h3>This October, the Internet Archive will celebrate an extraordinary milestone: 1 trillion web pages preserved and available for access via the Wayback Machine. </h3>



<p><strong><a href="#calendar-of-events">Calendar of Events</a> | <a href="#impact-stories" data-type="internal" data-id="#impact-stories">Impact Stories</a> | <a href="#support-the-internet-archive">Support the Internet Archive</a> | <a href="#press-kit">Press Kit</a></strong></p>



<p>Since 1996, the Internet Archive has worked with libraries and partners around the world to build a shared digital library of humanity’s online history: capturing websites large and small—from breaking news to forgotten personal pages—so they remain accessible for future generations. </p>



<p>The series of events scheduled throughout October will highlight the memories, makers, and movements that have made this achievement possible, and will look ahead to the future of web preservation as we continue building the web’s collective memory together.</p>



<hr>



<h2 id="calendar-of-events">Calendar of Events</h2>



<h2>October 7—The Vast Blue We: Del Sol Quartet at the Internet Archive</h2>



<figure><img decoding="async" width="1024" height="683" src="https://blog.archive.org/wp-content/uploads/2025/08/DSQ-109-1.xmen_.credit.Production-1024x683.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/DSQ-109-1.xmen_.credit.Production-1024x683.png 1024w, https://blog.archive.org/wp-content/uploads/2025/08/DSQ-109-1.xmen_.credit.Production-300x200.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/DSQ-109-1.xmen_.credit.Production-768x512.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/DSQ-109-1.xmen_.credit.Production-624x416.png 624w, https://blog.archive.org/wp-content/uploads/2025/08/DSQ-109-1.xmen_.credit.Production.png 1500w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>7:00-8:15pm PT<br>Internet Archive<br>300 Funston Avenue, San Francisco &amp; ONLINE<br>Register now for <a href="https://www.eventbrite.com/e/the-vast-blue-we-del-sol-quartet-at-the-internet-archive-tickets-1626895701839" target="_blank" rel="noreferrer noopener">IN-PERSON</a> or <a href="https://www.eventbrite.com/e/the-vast-blue-we-del-sol-quartet-at-the-internet-archive-virtual-tickets-1626897768019" target="_blank" rel="noreferrer noopener">VIRTUAL</a> tickets</p>



<p>An evening to celebrate human collaboration—how billions of individual actions weave together into something vast and beautiful. Through music of&nbsp;<strong><strong>Del Sol Quartet&nbsp;</strong></strong>with new works by&nbsp;<strong><strong>Erika Oba</strong></strong>&nbsp;and&nbsp;<strong><strong>Sam Reider</strong></strong>, we mark the staggering scale of one trillion archived web pages available via the Wayback Machine. Join us for an interactive evening of live music reflecting the wonder of what we can achieve together and the power of our own voices.</p>



<h2>October 9—A Conversation with Sir Tim Berners-Lee and Brewster Kahle</h2>



<figure><a href="https://www.commonwealthclub.org/events/2025-10-09/building-and-preserving-web-conversation-sir-tim-berners-lee-and-brewster-kahle"><img decoding="async" width="1024" height="363" src="https://blog.archive.org/wp-content/uploads/2025/09/IMG_4418-1024x363.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/09/IMG_4418-1024x363.png 1024w, https://blog.archive.org/wp-content/uploads/2025/09/IMG_4418-300x106.png 300w, https://blog.archive.org/wp-content/uploads/2025/09/IMG_4418-768x272.png 768w, https://blog.archive.org/wp-content/uploads/2025/09/IMG_4418-624x221.png 624w, https://blog.archive.org/wp-content/uploads/2025/09/IMG_4418.png 1440w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Building and Preserving the Web: A Conversation with Sir Tim Berners-Lee and Brewster Kahle<br>7:30pm PT<br>The Commonwealth Club of California<br>110 The Embarcadero, San Francisco &amp; ONLINE<br>Register now for <a href="https://www.commonwealthclub.org/events/2025-10-09/building-and-preserving-web-conversation-sir-tim-berners-lee-and-brewster-kahle">IN-PERSON</a> or <a href="https://www.commonwealthclub.org/events/2025-10-09/building-and-preserving-web-conversation-sir-tim-berners-lee-and-brewster-kahle">VIRTUAL</a> tickets</p>



<p>Sir Tim Berners-Lee and Brewster Kahle will be in conversation about the rise of the internet, its continuing and explosive impact on society, the importance of the Internet Archive and other developing issues in the growth and use of the internet.</p>



<h2>October 16—Library Leaders Forum 2025 (VIRTUAL)</h2>



<figure><a href="https://blog.archive.org/wp-content/uploads/2025/08/LLF-2025.png"><img loading="lazy" decoding="async" width="960" height="540" src="https://blog.archive.org/wp-content/uploads/2025/08/LLF-2025.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/LLF-2025.png 960w, https://blog.archive.org/wp-content/uploads/2025/08/LLF-2025-300x169.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/LLF-2025-768x432.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/LLF-2025-624x351.png 624w" sizes="auto, (max-width: 960px) 100vw, 960px"></a></figure>



<p>10:00-11:30am PT<br>ONLINE<br>Register now for <a href="https://www.eventbrite.com/e/library-leaders-forum-2025-virtual-tickets-1633142596469" target="_blank" rel="noreferrer noopener">VIRTUAL</a> tickets</p>



<p>In our virtual Library Leaders Forum, you’ll hear from Internet Archive staff and partners about our emerging library services and updates on existing efforts. How do libraries empower research in the 21st century? Join in our discussion!</p>



<h2>October 21—Doors Open 2025: Go Behind the Scenes at the Physical Archive</h2>



<figure><a href="https://www.eventbrite.com/e/doors-open-2025-go-behindthe-scenes-at-the-physical-archive-tickets-1626423248719"><img loading="lazy" decoding="async" width="940" height="470" src="https://blog.archive.org/wp-content/uploads/2024/08/Doors-Open-2024.jpeg" alt="Doors Open" srcset="https://blog.archive.org/wp-content/uploads/2024/08/Doors-Open-2024.jpeg 940w, https://blog.archive.org/wp-content/uploads/2024/08/Doors-Open-2024-300x150.jpeg 300w, https://blog.archive.org/wp-content/uploads/2024/08/Doors-Open-2024-768x384.jpeg 768w, https://blog.archive.org/wp-content/uploads/2024/08/Doors-Open-2024-624x312.jpeg 624w" sizes="auto, (max-width: 940px) 100vw, 940px"></a></figure>



<p>6:00-8:00pm PT<br>Richmond, California<br>Register now for <a href="https://www.eventbrite.com/e/doors-open-2025-go-behindthe-scenes-at-the-physical-archive-tickets-1626423248719" target="_blank" rel="noreferrer noopener">IN-PERSON</a> tickets</p>



<p>The Internet Archive is excited to offer a behind-the-scenes tour of the physical collections of books, music, film, and video in Richmond, California.</p>



<p>With this special insider event we are opening the doors to an often unseen place. See the lifecycle of physical materials: donation, preservation, digitization, and access. Also, samples from generous donations and acquisitions of books, records, microfiche, and more will be on display.</p>



<h2>October 22—The Web We’ve Built: Celebrating 1 Trillion Web Pages Archived</h2>



<figure><a href="https://www.eventbrite.com/e/the-web-weve-built-in-person-tickets-1626438133239"><img loading="lazy" decoding="async" width="1024" height="576" src="https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920-1024x576.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920-1024x576.png 1024w, https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920-300x169.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920-768x432.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920-1536x864.png 1536w, https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920-624x351.png 624w, https://blog.archive.org/wp-content/uploads/2025/08/TWWB_16_9_BANNER_1920.png 1920w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></a></figure>



<p>5:00-10:00pm PT<br>7:00-8:00pm PT Live Stream<br>Internet Archive<br>300 Funston Ave, San Francisco<br>Register now for <a href="https://www.eventbrite.com/e/the-web-weve-built-in-person-tickets-1626438133239" target="_blank" rel="noreferrer noopener">IN-PERSON</a> or <a href="https://www.eventbrite.com/e/the-web-weve-built-virtual-tickets-1626431011939" target="_blank" rel="noreferrer noopener">VIRTUAL</a> tickets</p>



<p>This October, the Internet Archive’s&nbsp;<strong>Wayback Machine</strong>&nbsp;is projected to hit a once-in-a-generation milestone:&nbsp;<strong>1 trillion web pages archived</strong>. That’s one trillion memories, moments, and movements—preserved for the public and available to access via the Wayback Machine.</p>



<p>We’ll be commemorating this historic achievement on&nbsp;<strong>October 22, 2025</strong>, with a global event: a party at our San Francisco headquarters and a livestream for friends and supporters around the world. More than a celebration, it’s a tribute to what we’ve built together: a free and open digital library of the web.</p>



<p>Join us in marking this incredible milestone. Together, we’ve built the largest archive of web history ever assembled. Let’s celebrate this achievement—in San Francisco and around the world—on October 22.</p>



<h2>October 27—Wayback to the Future: Celebrating the Open Web</h2>



<figure><a href="https://luma.com/cfxt621v"><img loading="lazy" decoding="async" width="400" height="400" src="https://blog.archive.org/wp-content/uploads/2025/10/FAI-Oct-27.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/10/FAI-Oct-27.png 400w, https://blog.archive.org/wp-content/uploads/2025/10/FAI-Oct-27-300x300.png 300w, https://blog.archive.org/wp-content/uploads/2025/10/FAI-Oct-27-150x150.png 150w" sizes="auto, (max-width: 400px) 100vw, 400px"></a></figure>



<p>5:00-8:00pm PT<br>Riggs Library, Georgetown University<br>Healy Hall, Library Walk, Washington, DC 20057<br>Register now for <a href="https://luma.com/cfxt621v">IN-PERSON</a> tickets</p>



<p>​Join the&nbsp;<strong>Foundation for American Innovation,&nbsp;</strong>the<strong>&nbsp;Massive Data Institute</strong>&nbsp;and the&nbsp;<strong>Internet Archive</strong>&nbsp;at Georgetown University’s historic&nbsp;<strong>Riggs Library</strong>&nbsp;for&nbsp;<em>Wayback to the Future: Celebrating the Open Web—Past, Present, and Possible.</em></p>



<p>​The open web was once defined by experimentation, decentralization, and possibility. The technological advancements were driven by the desire for a place where new voices and ideas could flourish. Today, consolidation and walled gardens challenge that vision. Together, we’ll look back at the internet’s origins to spark a forward-looking conversation about how to keep the web free, open, and innovative.</p>



<p><strong>Speakers include:</strong></p>



<p>​Moderator: Luke Hogg — Director of Technology Policy, FAI<br>Brewster Kahle — Founder &amp; Director, Internet Archive<br>Vint Cerf — Chief Internet Evangelist, Google<br>Cindy Cohn — Executive Director, Electronic Frontier Foundation<br>Jon Stokes – Co-founder, Ars Technica&nbsp;</p>



<hr>



<h2 id="impact-stories">Impact Stories</h2>



<p>The 1 trillion archived webpages are more than just numbers—they represent real impact on people’s lives, research, and memory. From immigration cases to personal histories, academic research to investigative journalism, the Wayback Machine has become an essential public resource that preserves the web for all.</p>



<div><figure><img loading="lazy" decoding="async" width="1024" height="576" src="https://blog.archive.org/wp-content/uploads/2025/08/David-Samuel.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/David-Samuel.png 1024w, https://blog.archive.org/wp-content/uploads/2025/08/David-Samuel-300x169.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/David-Samuel-768x432.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/David-Samuel-624x351.png 624w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>



<div><figure><img loading="lazy" decoding="async" width="1024" height="449" src="https://blog.archive.org/wp-content/uploads/2025/08/Julie-Lindner.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/Julie-Lindner.png 1024w, https://blog.archive.org/wp-content/uploads/2025/08/Julie-Lindner-300x132.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/Julie-Lindner-768x337.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/Julie-Lindner-624x274.png 624w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>



<div><figure><img loading="lazy" decoding="async" width="1024" height="768" src="https://blog.archive.org/wp-content/uploads/2025/08/Gray-and-Bounegru.jpg" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/Gray-and-Bounegru.jpg 1024w, https://blog.archive.org/wp-content/uploads/2025/08/Gray-and-Bounegru-300x225.jpg 300w, https://blog.archive.org/wp-content/uploads/2025/08/Gray-and-Bounegru-768x576.jpg 768w, https://blog.archive.org/wp-content/uploads/2025/08/Gray-and-Bounegru-624x468.jpg 624w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>



<div><figure><img loading="lazy" decoding="async" width="1024" height="576" src="https://blog.archive.org/wp-content/uploads/2025/08/LauraRanca-1024x576-1.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/LauraRanca-1024x576-1.png 1024w, https://blog.archive.org/wp-content/uploads/2025/08/LauraRanca-1024x576-1-300x169.png 300w, https://blog.archive.org/wp-content/uploads/2025/08/LauraRanca-1024x576-1-768x432.png 768w, https://blog.archive.org/wp-content/uploads/2025/08/LauraRanca-1024x576-1-624x351.png 624w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>



<h2>Share Your Story</h2>



<div><figure><img loading="lazy" decoding="async" width="524" height="655" src="https://blog.archive.org/wp-content/uploads/2025/08/Danielle.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2025/08/Danielle.png 524w, https://blog.archive.org/wp-content/uploads/2025/08/Danielle-240x300.png 240w" sizes="auto, (max-width: 524px) 100vw, 524px"></figure><p>What does the web mean to you? How has the Wayback Machine helped you remember, research, or recover something important? <a href="https://forms.gle/c3XqotHUToKe2pZw5" target="_blank" rel="noreferrer noopener"><em>Share your story</em></a>.</p></div>



<hr>



<h2 id="support-the-internet-archive">Support the Internet Archive</h2>



<p>Help us continue preserving the web for generations to come. <a href="https://archive.org/donate/?origin=event-2025octevterlyprm" target="_blank" rel="noreferrer noopener"><em>Donate today</em>!</a></p>



<hr>



<h2 id="press-kit">Press Kit</h2>



<p>Interested in producing a story about the 1 trillion milestone? Our <a href="https://docs.google.com/document/d/e/2PACX-1vSvfHidxJGmDhwxKDaFX1M9L6SVPSzIM4i4MtnbVRbrI66_psZjl1RdpwtLuBtb9YNc8EE6pFEudJbb/pub" target="_blank" rel="noreferrer noopener">online press kit</a> includes impact stories from users, facts &amp; figures about the Internet Archive &amp; Wayback Machine, and Then/Now screenshots of popular web sites. Contact info is available in the <a href="https://docs.google.com/document/d/e/2PACX-1vSvfHidxJGmDhwxKDaFX1M9L6SVPSzIM4i4MtnbVRbrI66_psZjl1RdpwtLuBtb9YNc8EE6pFEudJbb/pub" target="_blank" rel="noreferrer noopener">press kit</a>.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Find Nearby Automated License Plate Readers (ALPR) (131 pts)]]></title>
            <link>https://deflock.me/</link>
            <guid>45487452</guid>
            <pubDate>Mon, 06 Oct 2025 03:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deflock.me/">https://deflock.me/</a>, See on <a href="https://news.ycombinator.com/item?id=45487452">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Why do LLMs freak out over the seahorse emoji? (649 pts)]]></title>
            <link>https://vgel.me/posts/seahorse/</link>
            <guid>45487044</guid>
            <pubDate>Mon, 06 Oct 2025 02:20:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vgel.me/posts/seahorse/">https://vgel.me/posts/seahorse/</a>, See on <a href="https://news.ycombinator.com/item?id=45487044">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
  
  <hr>
<p><em>This is an edited and expanded version of a Twitter post, originally in response to @arm1st1ce, that can be found here: <a href="https://x.com/voooooogel/status/1964465679647887838">https://x.com/voooooogel/status/1964465679647887838</a></em></p>
<hr>
<p>Is there a seahorse emoji? Let's ask GPT-5 Instant:</p>
<p><img src="https://vgel.me/posts/seahorse/gpt5.png" alt=""></p>
<p>Wtf? Let's ask Claude Sonnet 4.5 instead:</p>
<p><img src="https://vgel.me/posts/seahorse/sonnet45.png" alt=""></p>
<p>What's going on here? Maybe Gemini 2.5 Pro handles it better?</p>
<p><img src="https://vgel.me/posts/seahorse/gemini.png" alt=""></p>
<p>OK, something is going on here. Let's find out why.</p>
<span id="continue-reading"></span><h2 id="LLMs_really_think_there's_a_seahorse_emoji"><a href="#LLMs_really_think_there's_a_seahorse_emoji">
  <img src="https://vgel.me/permalink.svg" alt="permalink for LLMs_really_think_there's_a_seahorse_emoji">
</a>LLMs really think there's a seahorse emoji</h2>
<p>Here are the answers you get if you ask several models whether a seahorse emoji exists, yes or no, 100 times:</p>
<blockquote>
<p>Is there a seahorse emoji, yes or no? Respond with one word, no punctuation.</p>
</blockquote>
<ul>
<li>gpt-5-chat
<ul>
<li>100% 'Yes'</li>
</ul>
</li>
<li>gpt-5
<ul>
<li>100% 'Yes'</li>
</ul>
</li>
<li>claude-4.5-sonnet
<ul>
<li>100% 'Yes'</li>
</ul>
</li>
<li>llama-3.3-70b
<ul>
<li>83% 'yes'</li>
<li>17% 'Yes'</li>
</ul>
</li>
</ul>
<p>Needlessly to say, popular language models are <em>very</em> confident that there's a seahorse emoji. And they're not alone in that confidence - here's a Reddit thread with hundreds of comments from people who distinctly remember a seahorse emoji existing:</p>
<p><img src="https://vgel.me/posts/seahorse/reddit.png" alt=""></p>
<p>There's tons of this - Google "seahorse emoji" and you'll find TikToks, Youtube videos, and even (now defunct) memecoins based around the supposed vanishing of a seahorse emoji that everyone is pretty sure used to exist - but of course, never did.</p>
<p>Maybe LLMs believe a seahorse emoji exists because so many humans in the training data do. Or maybe it's a convergent belief - given how many other aquatic animals are in Unicode, it's reasonable for both humans and LLMs to assume (generalize, even) that such a delightful animal is as well. A seahorse emoji was even <a href="https://unicode.org/emoji/emoji-proposals-status.html">formally proposed at one point</a>, but was rejected in 2018.</p>
<p>Regardless of the root cause, many LLMs begin each new context window fresh with the mistaken latent belief that the seahorse emoji exists. But why does that produce such strange behavior? I mean, I used to believe a seahorse emoji existed myself, but if I had tried to send it to a friend, I would've simply looked for it on my keyboard and realized it wasn't there, not sent the wrong emoji and then gone into an emoji spam doomloop. So what's happening inside the LLM that causes it to act like this?</p>
<h2 id="Using_the_logit_lens"><a href="#Using_the_logit_lens">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Using_the_logit_lens">
</a>Using the logit lens</h2>
<p>Let's look into this using everyone's favorite underrated interpretability tool, <a href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens">the logit lens</a>!</p>
<p>Using this prompt prefix - a templated chat with the default llama-3.3-70b system prompt, a question about the seahorse emoji, and a partial answer from the model right before it gives the actual emoji:</p>
<pre><code><span>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id&gt;
</span><span>Cutting Knowledge Date: December 2023
</span><span>Today Date: 26 Jul 2024
</span><span>
</span><span>&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
</span><span>
</span><span>Is there a seahorse emoji?&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;
</span><span>
</span><span>Yes, there is a seahorse emoji:
</span></code></pre>
<p>We can take the model's <code>lm_head</code>, which is usually only used on the output of the last layer, and apply it to <em>every</em> layer to produce intermediate token predictions. That process produces this table, showing for every fourth layer what the most likely token would be for the next three positions after the prefix (tokens 0, 1, and 2), and what the top 5 most likely predictions for the first position is (token 0 topk 5):</p>
<table>
<thead>
<tr><th>layer</th><th colspan="3">tokens</th><th>tokens</th><th>token 0</th></tr>
<tr><th></th><th>0</th><th>1</th><th>2</th><th>merged</th><th>(topk 5)</th></tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>83244'ĠBail'</td>
<td>15591'ĠHarr'</td>
<td>5309'Ġvert'</td>
<td>Bail Harr vert</td>
<td>['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']</td>
</tr>
<tr>
<td>4</td>
<td>111484'emez'</td>
<td>26140'abi'</td>
<td>25727'avery'</td>
<td>emezabiavery</td>
<td>['emez', 'Ġunm', 'ĠOswald', 'Ġrem', 'rix']</td>
</tr>
<tr>
<td>8</td>
<td>122029'chyb'</td>
<td>44465'ĠCaps'</td>
<td>15610'iller'</td>
<td>chyb Capsiller</td>
<td>['chyb', 'ĠSund', 'ØªØ±ÛĮ', 'resse', 'Ġsod']</td>
</tr>
<tr>
<td>12</td>
<td>1131'...'</td>
<td>48952'ĠCliff'</td>
<td>51965'ĠJackie'</td>
<td>... Cliff Jackie</td>
<td>['...', 'ages', 'dump', 'qing', 'Ġexp']</td>
</tr>
<tr>
<td>16</td>
<td>1131'...'</td>
<td>12676'365'</td>
<td>31447'ĠAld'</td>
<td>...365 Ald</td>
<td>['...', '...Ċ', 'Ġindeed', 'Ġboth', 'ĠYes']</td>
</tr>
<tr>
<td>20</td>
<td>1131'...'</td>
<td>109596'éļĨ'</td>
<td>51965'ĠJackie'</td>
<td>...隆 Jackie</td>
<td>['...', '...Ċ', 'Z', 'Ġboth', 'ĠHust']</td>
</tr>
<tr>
<td>24</td>
<td>12'-'</td>
<td>31643'ï¸ı'</td>
<td>287'ing'</td>
<td>-️ing</td>
<td>['-', '...', 'âĢ¦', '...Ċ', 'em']</td>
</tr>
<tr>
<td>28</td>
<td>1131'...'</td>
<td>96154'ĠGaut'</td>
<td>51965'ĠJackie'</td>
<td>... Gaut Jackie</td>
<td>['...', '-', '...Ċ', '-Ċ', 'Ġ']</td>
</tr>
<tr>
<td>32</td>
<td>1131'...'</td>
<td>96154'ĠGaut'</td>
<td>6892'Ġing'</td>
<td>... Gaut ing</td>
<td>['...', 'âĢ¦', '...Ċ', 'O', 'zer']</td>
</tr>
<tr>
<td>36</td>
<td>1131'...'</td>
<td>12'-'</td>
<td>88'y'</td>
<td>...-y</td>
<td>['...', 'âĢ¦', '...Ċ', 'Ġ', 'u']</td>
</tr>
<tr>
<td>40</td>
<td>1131'...'</td>
<td>31643'ï¸ı'</td>
<td>88'y'</td>
<td>...️y</td>
<td>['...', 'u', 'âĢ¦', 'Âł', '...Ċ']</td>
</tr>
<tr>
<td>44</td>
<td>80435'ĠScor'</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>Scor horse horse</td>
<td>['ĠScor', 'u', 'ĠPan', 'in', 'Ġhttps']</td>
</tr>
<tr>
<td>48</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>horse horse horse</td>
<td>['Ġhorse', 'Âł', 'ĠPan', 'ĠHomes', 'ĠHorse']</td>
</tr>
<tr>
<td>52</td>
<td>9581'Ġsea'</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>sea horse horse</td>
<td>['Ġsea', 'Ġhorse', 'ĠHorse', 'ĠSea', 'âĢĳ']</td>
</tr>
<tr>
<td>56</td>
<td>9581'Ġsea'</td>
<td>43269'ĠSeah'</td>
<td>15580'Ġhorse'</td>
<td>sea Seah horse</td>
<td>['Ġsea', 'ĠSea', 'ĠSeah', 'Ġhippoc', 'Ġhorse']</td>
</tr>
<tr>
<td>60</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>horse horse horse</td>
<td>['Ġhorse', 'Ġsea', 'ĠSeah', 'Ġse', 'horse']</td>
</tr>
<tr>
<td>64</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>15580'Ġhorse'</td>
<td>horse horse horse</td>
<td>['Ġhorse', 'Ġse', 'ĠHorse', 'horse', 'Ġhors']</td>
</tr>
<tr>
<td>68</td>
<td>60775'horse'</td>
<td>238'Ĳ'</td>
<td>15580'Ġhorse'</td>
<td>horse� horse</td>
<td>['horse', 'Ġse', 'Ġhorse', 'Ġhippoc', 'ĠSeah']</td>
</tr>
<tr>
<td>72</td>
<td>513'Ġse'</td>
<td>238'Ĳ'</td>
<td>513'Ġse'</td>
<td>se� se</td>
<td>['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']</td>
</tr>
<tr>
<td>76</td>
<td>513'Ġse'</td>
<td>238'Ĳ'</td>
<td>513'Ġse'</td>
<td>se� se</td>
<td>['Ġse', 'Ġhippoc', 'hip', 'Ġhorse', 'ĠHipp']</td>
</tr>
<tr>
<td>80</td>
<td>11410'ĠðŁ'</td>
<td>238'Ĳ'</td>
<td>254'ł'</td>
<td>🐠</td>
<td>['ĠðŁ', 'ðŁ', 'ĠðŁĴ', 'Ġ', 'ĠðŁĳ']</td>
</tr>
</tbody>
</table>
<p>This is the logit lens: using the model's <code>lm_head</code> to produce logits (token likelihoods) as a way to investigate its internal states. Note that the tokens and likelihoods we get from the logit lens here are not equivalent to the model's <em>full</em> internal states! For that, we would need a more complex technique like representation reading or sparse autoencoders. Instead, this is a <em>lens</em> on that state - it shows what the output token would be <em>if</em> this layer were the last one. But despite this limitation, the logit lens is still useful. The states of early layers may be difficult to interpret using it, but as we move up through the stack we can see that the model is iteratively refining those states towards its final prediction, a fish emoji.</p>
<p><small>(Why do the unmerged tokens look like that 'ĠðŁ', 'Ĳ', 'ł' nonsense? It's because of a tokenizer quirk - those tokens encode the UTF-8 bytes for the fish emoji. It's not relevant to this post, but if you're curious, ask Claude or your favorite LLM to explain this paragraph and this line of code: <code>bytes([bpe_byte_decoder[c] for c in 'ĠðŁĲł']).decode('utf-8') == ' 🐠'</code>)</small></p>
<p>Take a look at what happens in the middle layers, though - it's not the early-layer weirdness <em>or</em> the emoji bytes of the final prediction! Instead we get words relating to <em>useful concepts</em>, specifically the concept of a seahorse. For example, on layer 52, we get "sea horse horse" - three residual positions in a row encoding the "seahorse" concept. Later, in the top-k for the first position, we get a mixture of "sea", "horse", and an emoji byte sequence prefix, "ĠðŁ".</p>
<p>So what is the model thinking about? "seahorse + emoji"! It's trying to construct a residual representation of a seahorse combined with an emoji. Why would the model try to construct this combination? Well, let's look into how the <code>lm_head</code> actually works.</p>
<h2 id="lm_head"><a href="#lm_head">
  <img src="https://vgel.me/permalink.svg" alt="permalink for lm_head">
</a><code>lm_head</code></h2>
<p>A language model's <code>lm_head</code> is a huge matrix of residual-sized vectors associated with token ids, one for every token in the vocabulary (~300,000). When a residual is passed into it, either after flowing through the model normally or early because someone is using the logit lens on an earlier layer, the <code>lm_head</code> is going to compare that input residual with each residual-sized vector in that big matrix, and (in coordination with the sampler) select the token id associated with the vector that matrix contains that is most similar to the input residual.</p>
<p>(More technically: <code>lm_head</code> is a linear layer without a bias, so <code>x @ w.T</code> does dot products with each unembedding vector to produce raw scores. Then your usual log_softmax and argmax/temperature sample.)</p>
<p>That means if the model wants to output the word "hello", for example in response to a friendly greeting from the user, it needs to construct a residual as similar as possible to the vector for the "hello" token that the <code>lm_head</code> can then turn into the hello token id. And using logit lens, we can see that's exactly what happens in response to "Hello :-)":</p>
<table>
<thead>
<tr><th>layer</th><th colspan="3">tokens</th><th>tokens</th><th>token 0</th></tr>
<tr><th></th><th>0</th><th>1</th><th>2</th><th>merged</th><th>(topk 5)</th></tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0'!'       </td>
<td>0'!'       </td>
<td>40952'opa'     </td>
<td>!!opa                    </td>
<td>['"', '!', '#', '%', '$']</td>
</tr>
<tr>
<td>8</td>
<td>121495'ÅĻiv'    </td>
<td>16'1'       </td>
<td>73078'iae'     </td>
<td>řiv1iae                  </td>
<td>['ÅĻiv', '-', '(', '.', ',']</td>
</tr>
<tr>
<td>16</td>
<td>34935'Ġconsect'</td>
<td>7341'arks'    </td>
<td>13118'Ġindeed' </td>
<td> consectarks indeed      </td>
<td>['Ġobscure', 'Ġconsect', 'äºķ', 'ĠÐ¿ÑĢÐ¾ÑĦÐµÑģÑģÐ¸Ð¾Ð½Ð°Ð»ÑĮ', 'Îŀ']</td>
</tr>
<tr>
<td>24</td>
<td>67846'&lt;['      </td>
<td>24748'Ġhello'  </td>
<td>15960'Ġhi'     </td>
<td>&lt;[ hello hi              </td>
<td>['&lt;[', 'arks', 'outh', 'ĠHam', 'la']</td>
</tr>
<tr>
<td>32</td>
<td>15825'-back'   </td>
<td>2312'ln'      </td>
<td>14451'UBL'     </td>
<td>-backlnUBL               </td>
<td>['ÂŃi', '-back', 'Ġquestion', 'ln', 'ant']</td>
</tr>
<tr>
<td>40</td>
<td>15648'Ġsmile'  </td>
<td>14262'Welcome' </td>
<td>1203'Ġback'   </td>
<td> smileWelcome back       </td>
<td>['Ġsmile', 'ĠÑĥÐ»ÑĭÐ±', 'Ġsmiled', 'ĠSmile', 'etwork']</td>
</tr>
<tr>
<td>48</td>
<td>15648'Ġsmile'  </td>
<td>21694'ĠHi'     </td>
<td>1203'Ġback'   </td>
<td> smile Hi back           </td>
<td>['Ġsmile', 'Ġsmiled', 'ĠHello', 'Ġsmiling', 'Ġhello']</td>
</tr>
<tr>
<td>56</td>
<td>22691'ĠHello'  </td>
<td>15960'Ġhi'     </td>
<td>1203'Ġback'   </td>
<td> Hello hi back           </td>
<td>['ĠHello', 'Ġhi', 'Ġsmile', 'Ġhello', 'Hello']</td>
</tr>
<tr>
<td>64</td>
<td>4773'-sm'     </td>
<td>24748'Ġhello'  </td>
<td>1203'Ġback'   </td>
<td>-sm hello back           </td>
<td>['-sm', 'ĠHello', 'ĠSm', 'sm', 'Hello']</td>
</tr>
<tr>
<td>72</td>
<td>22691'ĠHello'  </td>
<td>22691'ĠHello'  </td>
<td>1203'Ġback'   </td>
<td> Hello Hello back        </td>
<td>['ĠHello', 'Ġhello', 'Hello', 'ĠHEL', 'Ġhel']</td>
</tr>
<tr>
<td>80</td>
<td>271'ĊĊ'      </td>
<td>9906'Hello'   </td>
<td>0'!'       </td>
<td>
<p>Hello!                 </p></td>
<td>['ĊĊ', 'ĊĊĊ', '&lt;|end_of_text|&gt;', 'ĊĊĊĊ', '"ĊĊ']</td>
</tr>
</tbody>
</table>
<p><small>('Ċ' is another tokenizer quirk - it represents a line break. 'Ġ' is similarly a space.)</small></p>
<p>Likewise, if the model wants to output a seahorse emoji, it needs to construct a residual similar to the vector for the seahorse emoji output token(s) - which in theory could be any arbitrary value, but in practice is "seahorse + emoji", word2vec style. We can see this in action with a real emoji, the fish emoji:</p>
<pre><code><span>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;
</span><span>
</span><span>Cutting Knowledge Date: December 2023
</span><span>Today Date: 26 Jul 2024
</span><span>
</span><span>&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
</span><span>
</span><span>Is there a fish emoji?&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;
</span><span>
</span><span>Yes, there is a fish emoji:
</span></code></pre>
<table>
<thead>
<tr><th>layer</th><th colspan="3">tokens</th><th>tokens</th><th>token 0</th></tr>
<tr><th></th><th>0</th><th>1</th><th>2</th><th>merged</th><th>(topk 5)</th></tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>83244'ĠBail'</td>
<td>15591'ĠHarr'</td>
<td>5309'Ġvert'</td>
<td>Bail Harr vert</td>
<td>['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']</td>
</tr>
<tr>
<td>8</td>
<td>122029'chyb'</td>
<td>44465'ĠCaps'</td>
<td>15610'iller'</td>
<td>chyb Capsiller</td>
<td>['chyb', '...', 'ØªØ±ÛĮ', 'ĠSund', 'resse']</td>
</tr>
<tr>
<td>16</td>
<td>1131'...'</td>
<td>12676'365'</td>
<td>65615'ĠSole'</td>
<td>...365 Sole</td>
<td>['...', '...Ċ', 'Ġboth', 'Ġindeed', 'ĠYes']</td>
</tr>
<tr>
<td>24</td>
<td>12'-'</td>
<td>31643'ï¸ı'</td>
<td>51965'ĠJackie'</td>
<td>-️ Jackie</td>
<td>['-', '...', 'âĢ¦', 'em', '...Ċ']</td>
</tr>
<tr>
<td>32</td>
<td>1131'...'</td>
<td>96154'ĠGaut'</td>
<td>88'y'</td>
<td>... Gauty</td>
<td>['...', 'âĢ¦', '...Ċ', 'O', 'u']</td>
</tr>
<tr>
<td>40</td>
<td>220'Ġ'</td>
<td>6"'"</td>
<td>7795'Ġfish'</td>
<td>'fish</td>
<td>['Ġ', '...', 'âĢ¦', 'Âł', 'u']</td>
</tr>
<tr>
<td>48</td>
<td>7795'Ġfish'</td>
<td>7795'Ġfish'</td>
<td>7795'Ġfish'</td>
<td>fish fish fish</td>
<td>['Ġfish', 'ĠFish', 'ĠBerk', 'âĢ¦', 'Âł']</td>
</tr>
<tr>
<td>56</td>
<td>7795'Ġfish'</td>
<td>7795'Ġfish'</td>
<td>7795'Ġfish'</td>
<td>fish fish fish</td>
<td>['Ġfish', 'ĠFish', 'fish', 'Fish', 'é±¼']</td>
</tr>
<tr>
<td>64</td>
<td>7795'Ġfish'</td>
<td>238'Ĳ'</td>
<td>7795'Ġfish'</td>
<td>fish� fish</td>
<td>['Ġfish', 'ĠFish', 'ĠPis', 'Fish', 'ĠÙħØ§Ùĩ']</td>
</tr>
<tr>
<td>72</td>
<td>7795'Ġfish'</td>
<td>238'Ĳ'</td>
<td>253'Ł'</td>
<td>fish��</td>
<td>['Ġfish', 'ĠFish', 'ĠðŁ', 'Ġ', 'ÂŁ']</td>
</tr>
<tr>
<td>80</td>
<td>11410'ĠðŁ'</td>
<td>238'Ĳ'</td>
<td>253'Ł'</td>
<td>🐟</td>
<td>['ĠðŁ', 'ðŁ', 'Ġ', 'ĠĊĊ', 'ĠâĻ']</td>
</tr>
</tbody>
</table>
<p>Here, everything works perfectly. The model constructs the "fish + emoji" residual - look at the layer 72 topk, where we have both "fish" and the emoji byte prefix "ĠðŁ" - meaning that the residual at this point is similar to both "fish" and "emoji", just like we'd expect. Then when this vector is passed into the <code>lm_head</code> after the final layer, we see a 🐟 just as the model expected.</p>
<p>But unlike with 🐟, the seahorse emoji doesn't exist. The model tries to construct a "seahorse + emoji" vector just as it would for a real emoji, and on layer 72 we even get a very similar construction as with the fish emoji - " se", "horse", and the emoji prefix byte prefix:</p>
<table>
<thead>
<tr><th>layer</th><th colspan="3">tokens</th><th>tokens</th><th>token 0</th></tr>
<tr><th></th><th>0</th><th>1</th><th>2</th><th>merged</th><th>(topk 5)</th></tr>
</thead>
<tbody>
<tr>
<td>72</td>
<td>513'Ġse'</td>
<td>238'Ĳ'</td>
<td>513'Ġse'</td>
<td>se� se</td>
<td>['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']</td>
</tr>
</tbody>
</table>
<p>But alas, there's no continuation to ĠðŁ corresponding to a seahorse, so the <code>lm_head</code> similarity score calculation maxes out with horse- or sea-animal-related emoji bytes instead, and an unintended emoji is sampled.</p>
<p>Now, that sampling is valuable information for the model! You can see that in, e.g. the Claude 4.5 Sonnet example below, when the tokens get appended into the context autoregressively, the model can tell that they don't form the intended seahorse emoji. The previous, fuzzy "seahorse + emoji" concept has been "snapped" by the <code>lm_head</code> to an emoji that actually exists, like a tropical fish or horse.</p>
<p><img src="https://vgel.me/posts/seahorse/sonnet45.png" alt=""></p>
<p>Once this happens, it's up to the model how to proceed. Some models like 4.5 Sonnet try again, and eventually update on the evidence, changing mid-response to a statement about how the seahorse emoji doesn't exist. Other models like gpt-5-chat spiral for longer, sometimes never recovering. Other models will either blissfully ignore that the emoji is incorrect, and some will even correct themselves instantly after seeing only a single incorrect sample.</p>
<p>But until the model gets the wrong output token from <code>lm_head</code>, it just <em>doesn't know</em> that its initial belief about a seahorse emoji existing was wrong. It can only assume that "seahorse + emoji" will produce the tokens it wants.</p>
<h2 id="Some_speculation"><a href="#Some_speculation">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Some_speculation">
</a>Some speculation</h2>
<p>To speculate a bit more, I wonder if this problem is part of the benefit of reinforcement learning for LLMs - it gives the model information about its <code>lm_head</code> that's otherwise difficult for it to get at because it's at the end of the layer stack.</p>
<p>(Remember that base models are not trained on their own outputs / rollouts. That only happens in RL.)</p>
<h2 id="Code"><a href="#Code">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Code">
</a>Code</h2>
<p>If you want to try this yourself, you can find a starter script on Github here: <a href="https://gist.github.com/vgel/025ad6af9ac7f3bc194966b03ea68606">https://gist.github.com/vgel/025ad6af9ac7f3bc194966b03ea68606</a></p>


    <ul>
      
        <li><strong>Previous entry:</strong> <a href="https://vgel.me/posts/representation-engineering/">Representation Engineering Mistral-7B an Acid Trip</a></li>
      
      
    </ul>
</article></div>]]></description>
        </item>
    </channel>
</rss>